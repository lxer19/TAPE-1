URL: http://www.cs.tamu.edu/research/phoenix/cortex/publications/thesis.ps.gz
Refering-URL: http://www.cs.tamu.edu/people/anishk/publications.html
Root-URL: http://www.cs.tamu.edu
Title: A FRAMEWORK FOR COMMUNICATION SUPPORT IN OBJECT ORIENTED DISTRIBUTED SYSTEMS  
Author: ANISH S. KARMARKAR 
Degree: A Dissertation by  in partial fulfillment of the requirements for the degree of DOCTOR OF PHILOSOPHY  
Date: December 1997  
Affiliation: of Graduate Studies of Texas A&M University  
Note: Submitted to the Office  Major Subject: Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> D. C. Rine, </editor> <booktitle> Readings in Object Oriented Systems and Applications. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <year> 1995. </year>
Reference-contexts: The economics of work stations and desktops make distributed computing more feasible than mainframes. The object oriented methodology for software development has been accepted as the better way to develop and manage software over functional/procedural software development <ref> [1] </ref>. Unfortunately, distributed systems and applications are hard to design as compared to centralized systems and applications. A process group support makes the design of distributed applications and fault tolerant distributed systems much simpler. <p> Thus a client-server system consists of request-response sequences. B. Object Oriented Systems Object oriented design has been accepted as a better way to design a system over a functional design <ref> [1] </ref>. An object has an identity, object state and interface/methods to access that state. An object is an instance of a general class. The external world interacts with an object by invoking methods on the object or passing messages to the object.
Reference: [2] <author> A. S. Tanenbaum, </author> <title> "Distributed operating systems anno 1992. What have we learned so far?," Distrib. </title> <journal> Syst. </journal> <volume> Engng, </volume> <pages> pp. 3-10, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: A Generic Distributed System. 4 An ideal distributed system should look like a single system image to the user. The user need not be aware of the different components of the system. An analogy has been drawn between an ideal distributed system and the world-wide telephone system <ref> [2] </ref>. In a telephone system, there are a number of computers that interact with each other to get a call through, without the user being aware of it. Making this vision of a distributed system a reality is difficult. Distributed systems [3, 4] make the design of software more difficult.
Reference: [3] <author> S. Mullender, </author> <title> Distributed Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: In a telephone system, there are a number of computers that interact with each other to get a call through, without the user being aware of it. Making this vision of a distributed system a reality is difficult. Distributed systems <ref> [3, 4] </ref> make the design of software more difficult. Many factors contribute to the difficulty in the design of a distributed system. 1.
Reference: [4] <author> S. Mullender, </author> <title> Distributed Systems, 2nd Edition. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1993. </year>
Reference-contexts: In a telephone system, there are a number of computers that interact with each other to get a call through, without the user being aware of it. Making this vision of a distributed system a reality is difficult. Distributed systems <ref> [3, 4] </ref> make the design of software more difficult. Many factors contribute to the difficulty in the design of a distributed system. 1. <p> A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. Atomic Multicast is a very popular abstraction used in fault-tolerant computing and cooperative computing <ref> [4, 8] </ref>. It gives the application programmer a programming paradigm, that can be used to view a set of processes as a single entity. An Atomic Multicast is either implemented in the operating system [23] or as a middle-ware/API [22].
Reference: [5] <author> R. Orfali, D. Harkey, and J. Edwards, </author> <title> The Essential Client/Server Survival Guide. </title> <publisher> John Wiley & Sons Inc., </publisher> <address> New York, New York, </address> <year> 1994. </year>
Reference-contexts: Dependence on network performance: The performance of a distributed sys 5 tem/application depends a lot on the performance of the network that connects the processing nodes. This performance can be hard to predict. The ubiquity of distributed systems gave rise to the popularity of client-server systems <ref> [5] </ref>. An architecture consisting of a robust expensive server and desktop clients utilizing its service is no longer just for research systems. The popularity and availability of the Web makes the client-server model of computing even more attractive and accessible over a wider area.
Reference: [6] <author> T. J. Mowbray and R. Zahavi, </author> <title> The Essential Corba: System Integration Using Distributed Objects. </title> <publisher> John Wiley & Sons Inc., </publisher> <address> New York, New York, </address> <year> 1995. </year>
Reference-contexts: The external world interacts with an object by invoking methods on the object or passing messages to the object. In an object oriented system, all the services are available as object invocations. Thus, the system consists of communicating objects at an abstract level. With OMG's CORBA <ref> [6, 7] </ref> as a standard, interoperability between different object models is easier. This model is very similar to the client-server model of computing. Clients and servers can be packaged as distributed objects. This makes development of distributed applications much easier. <p> The application developer can concentrate on the application logic as a good framework would provide the underlying infrastructural facilities. For successful frameworks they must be complete, flexible, Extensible and understandable. Examples of frameworks are MFC [75], Java RMI [76], implementation of CORBA <ref> [6] </ref>. An application program can make method invocations in the framework and the framework can also make calls to handler methods in the application program. This results in an `inversion of control' at run time. A framework makes calls to the application programs when an event of interest occurs. <p> For large group sizes this may not be feasible. The Cortex framework does not conform to any distributed processing standard. A research direction that warrants investigation is, how does group communication and delivery guarantees fit in a distributed processing standard such as DCE [86], 168 RM-ODP [87] or CORBA <ref> [6] </ref>. 5. Failure Detectors and Timeouts The failure of a process or a missed message is detected using timeouts, retransmis-sions and sequence numbers. The performance of the framework is affected by the values of the timeouts used. The timeout also determines the fault detection time and recovery.
Reference: [7] <author> R. Orfali, D. Harkey, and J. Edwards, </author> <title> The Essential Distributed Objects Survival Guide. </title> <publisher> John Wiley & Sons Inc., </publisher> <address> New York, New York, </address> <year> 1996. </year>
Reference-contexts: The external world interacts with an object by invoking methods on the object or passing messages to the object. In an object oriented system, all the services are available as object invocations. Thus, the system consists of communicating objects at an abstract level. With OMG's CORBA <ref> [6, 7] </ref> as a standard, interoperability between different object models is easier. This model is very similar to the client-server model of computing. Clients and servers can be packaged as distributed objects. This makes development of distributed applications much easier.
Reference: [8] <author> P. Jalote, </author> <title> Fault Tolerance in Distributed Systems. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1994. </year>
Reference-contexts: There are also situations where, though not catastrophic, a system failure can lead to a great financial loss, e.g., stock markets, banking. There are several levels of abstraction in a fault tolerant distribured system 7 Fig. 2. Levels in a Fault Tolerant Distributed System. 8 <ref> [8] </ref>. The different levels provide different fault tolerant services. These levels are shown in Figure 2. At the lowest level are the abstractions which are frequently used by those at the higher level and are therefore considered to be the basic building blocks. <p> A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. Atomic Multicast is a very popular abstraction used in fault-tolerant computing and cooperative computing <ref> [4, 8] </ref>. It gives the application programmer a programming paradigm, that can be used to view a set of processes as a single entity. An Atomic Multicast is either implemented in the operating system [23] or as a middle-ware/API [22].
Reference: [9] <author> R. D. Schlichting and F. B. Schneider, </author> <title> "Fail-stop processors: An approach to designing fault-tolerant systems," </title> <journal> ACM Trans. on Computer Sys., </journal> <volume> vol. 1, </volume> <editor> p. </editor> <volume> 222, </volume> <month> August </month> <year> 1983. </year> <month> 170 </month>
Reference-contexts: These levels are shown in Figure 2. At the lowest level are the abstractions which are frequently used by those at the higher level and are therefore considered to be the basic building blocks. They consist of abstractions of fail stop processors <ref> [9] </ref>, stable storage, reliable communication and failure detection. The level above this consists of the abstraction of reliable and atomic broadcast 1 , which is a building block of many fault tolerance techniques. The five levels on top offer fault tolerant services based on the lower layers. D.
Reference: [10] <author> L. Liang, S. T. Chason, and G. W. Neufeld, </author> <title> "Process groups and group communications: Classifications and requirements," </title> <journal> IEEE Computer, </journal> <volume> vol. 23, </volume> <pages> pp. 56-66, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: In fact, a client using the services of the group 1 In this dissertation we will use the words `broadcast' and `multicast' interchange-bly, the meaning should be clear from the context. 9 may be unaware of the existence of the group itself <ref> [10] </ref>. Even when hidden, message passing lies at the heart of any distributed system.
Reference: [11] <author> K. P. Birman, </author> <title> "The process group approach to reliable distributed computing," </title> <journal> Comm. ACM, </journal> <volume> vol. 36, </volume> <pages> pp. 37-53, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Even when hidden, message passing lies at the heart of any distributed system. A process group abstraction can be used for load balancing, distributed naming service, replicated server group, distributed date bases etc. <ref> [11] </ref> gives good reasons for supporting a process group abstraction in a shared software subsystem: * Standardization: Process groups are a basic and heavily used programming construct. A single, general mechanism can support a diverse user community. <p> The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> It allows a variety of services to the applications. GBCAST allows the application to multicast without any synchronization requirement. CBCAST multicasts messages which respect causal delivery. ABCAST delivers totally ordered messages. Isis makes a very good case for process group communication <ref> [11] </ref>. It also establishes the concept of virtual synchrony [48], which is expanded to `extended virtual synchrony' by [30], to maintain a consistent view in distributed systems.
Reference: [12] <author> A. S. Tanenbaum, </author> <title> Computer Networks, </title> <publisher> 3rd Ed. Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1996. </year>
Reference-contexts: The application developer then does not have to worry about the details of group communication, membership, consistency and synchronization. He/she can concentrate on the application logic. This idea is very similar to the seven layers of the OSI reference model <ref> [12] </ref>. There has been a lot of research work done in group communication for a distributed environment. This chapter provides an overview of the past research. In section B the requirements for supporting a process/object group paradigm are presented. <p> Algorithm The reliable and FIFO problem can be solved by using sequence numbers and acknowledgment (ACK) messages. The algorithm used is very similar to the one described in <ref> [12] </ref>. The reliable FIFO algorithm is not a new contribution, but is one of the essential services required of a communication support framework and is described here for completeness. The sender process keeps a running sequence number corresponding to each receiver.
Reference: [13] <author> M. Raynal, A. Schiper, and S. Toueg, </author> <title> "The causal ordering abstration and a simple way to implement it," </title> <journal> Information Processing Letters, </journal> <volume> vol. 39, no. 6, </volume> <pages> pp. 343-350, </pages> <year> 1991. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21]. <p> In case of a network partition and a simultaneous primary failure, the algorithm does not rejoin the partitions correctly. Causal ordering for a fault-tolerant system was first proposed in [35]. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge [36, 37]. [14] and <ref> [13] </ref> propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. They also provide a membership service for a real-time system [39]. <p> Figures 4, 5, 18 show three examples of causal violation in an environment where processes can send multicast messages as well as unicast messages within a group. <ref> [14, 13] </ref> propose algorithms to provide causal violation of messages for unicast message. They use a timestamp array (a 2-D matrix) instead of a vector.
Reference: [14] <author> Schiper, Eggli, and Sandoz, </author> <title> "A new algorithm to implement causal ordering," </title> <booktitle> in WDAG: International Workshop on Distributed Algorithms, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21]. <p> In case of a network partition and a simultaneous primary failure, the algorithm does not rejoin the partitions correctly. Causal ordering for a fault-tolerant system was first proposed in [35]. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge [36, 37]. <ref> [14] </ref> and [13] propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. <p> Figures 4, 5, 18 show three examples of causal violation in an environment where processes can send multicast messages as well as unicast messages within a group. <ref> [14, 13] </ref> propose algorithms to provide causal violation of messages for unicast message. They use a timestamp array (a 2-D matrix) instead of a vector.
Reference: [15] <author> R. V. </author> <title> Renesse, </title> <booktitle> "Causal Controversy at Le Mont St.-Michel (5th ACM SIGOPS Workshop 1992)," ACM Operating Systems Review, </booktitle> <volume> vol. 27, </volume> <pages> pp. 44-53, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [16] <author> D. R. Cheriton and D. Skeen, </author> <title> "Understanding the Limitations of Causally and Totally Ordered Communication," </title> <booktitle> in Proc. of the 14th ACM Symp. on Operating Systems Principles, </booktitle> <address> Asheville, </address> <publisher> North Carolina, </publisher> <pages> pp. 44-57, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [17] <author> K. Birman, </author> <title> "A Response to Cheriton and Skeen's Criticism of Causal and Totally Ordered Communication," </title> <journal> ACM Operating Systems Review, </journal> <volume> vol. 28, </volume> <pages> pp. 11-20, </pages> <month> January </month> <year> 1994. </year> <month> 171 </month>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [18] <author> R. V. Renesse, </author> <title> "Why Bother with CATOCS?," </title> <journal> ACM Operating Systems Review, </journal> <volume> vol. 28, </volume> <pages> pp. 22-27, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [19] <author> R. Cooper, </author> <title> "Experience with Causally and Totally Ordered Communication Support: A cautionary tale," </title> <journal> ACM Operating Systems Review, </journal> <volume> vol. 28, </volume> <pages> pp. 28-31, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [20] <author> S. K. Shrivastava, </author> <title> "To CATOCS or Not to CATOCS, </title> <journal> that is the ..," ACM Operating Systems Review, </journal> <volume> vol. 28, </volume> <pages> pp. 11-14, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Role of Group Communication in a Distributed System. be below the transport layer depending on the implementation. Some services provided by the group communication layer are described below. 1. Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering <ref> [13, 14, 15, 16, 17, 18, 19, 20] </ref>. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation [21].
Reference: [21] <author> L. Lamport, </author> <title> "Time, clocks and the ordering of events in a distributed system," </title> <journal> Comm. ACM, </journal> <volume> vol. 21, </volume> <pages> pp. 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Causal Ordering of Messages Causal ordering of messages/invocations is a natural extension of FIFO ordering [13, 14, 15, 16, 17, 18, 19, 20]. It provides synchronization guarantees that make co-operative distributed programming easier. A causal order is a partial order which follows directly from Lamport's Happened-Before relation <ref> [21] </ref>. Informally, the requirements of causal ordering are: If the send of a message m1 Happened-Before send of message m2 then message m1 must be received before message m2, if the destination of both m1 and m2 is the same. <p> The Deliver event in the process corresponds to handing of the message by the Cortex object to the Application object (c in Figure 13). The execution of the processes is a partially ordered sequence of events. The events in the system follow the Lamport's Happened-Before relation <ref> [21] </ref> which is transitive. This relation is denoted by "! ".
Reference: [22] <author> K. P. Birman and R. V. Renesse, </author> <title> Reliable Distributed Computing with the ISIS Toolkit. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <year> 1994. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> The membership maintenance messages are delivered among the streams of regular messages. The protocol 24 is based on two stages: suggest a new membership set, and then wait for agreement from every machine. The same protocol is also used when machines start up. The Isis system <ref> [22] </ref> provides an interface for applications. It allows a variety of services to the applications. GBCAST allows the application to multicast without any synchronization requirement. CBCAST multicasts messages which respect causal delivery. ABCAST delivers totally ordered messages. Isis makes a very good case for process group communication [11]. <p> D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm [43], Trans/Total [45], Transis [24], Totem [26], Isis <ref> [22] </ref> and Amoeba [23]. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. <p> It gives the application programmer a programming paradigm, that can be used to view a set of processes as a single entity. An Atomic Multicast is either implemented in the operating system [23] or as a middle-ware/API <ref> [22] </ref>. In [54], it is proved that it is impossible to solve deterministically the Consensus problem in a purely asynchronous environment with even one faulty processes. In [55], it is proved that in an asynchronous environment Consensus and Atomic Broadcast are equivalent. <p> This impossibility arises due to the fact that in an asynchronous system it is not possible to distinguish between a very slow process and a failed process. Most systems <ref> [22, 23, 24, 25, 26] </ref> circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. <p> For safe delivery there is also a post-transmission delay. Virtual synchrony and extended virtual synchrony ensure that messages are not lost or inconsistently ordered, when configuration changes. Levels of services available in Totem are: basic, FIFO, causal, agreed (total) and safe. 5. Isis Isis <ref> [22] </ref> is based on the idea of ordering messages, multicast to process groups. A recent version [49] uses token passing similar to CM. It focuses on the application interface and provides levels of services, at increasing cost, reliability, and synchronization: GBCAST, CBCAST, ABCAST.
Reference: [23] <author> M. F. Kaashoek and A. S. Tanenbaum, </author> <title> "Group communication in the amoeba distributed operating system," </title> <booktitle> in Proceedings of the 11th International Conference on Distributed Computing Systems (ICDCS), </booktitle> <address> Arlington, Texas, (Arlington, Texas), </address> <pages> pp. 222-230, </pages> <year> 1991. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> The algorithms in [51, 52] are for Atomic Multicast on a point-to-point network over a spanning tree. [53] uses a 3 phase commit protocol to order messages. Their algorithm uses voting to avoid blocking. The efficiency is low at low loads but increases with increasing load. Amoeba <ref> [23] </ref> implements a reliable totally ordered multicast, at the kernel-level. A sequencer in the group orders messages for the group. Their algorithm is similar to [43], but they add process group membership to it. Amoeba gives the user an API for maintaining group membership. <p> D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm [43], Trans/Total [45], Transis [24], Totem [26], Isis [22] and Amoeba <ref> [23] </ref>. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. <p> Atomic Multicast is a very popular abstraction used in fault-tolerant computing and cooperative computing [4, 8]. It gives the application programmer a programming paradigm, that can be used to view a set of processes as a single entity. An Atomic Multicast is either implemented in the operating system <ref> [23] </ref> or as a middle-ware/API [22]. In [54], it is proved that it is impossible to solve deterministically the Consensus problem in a purely asynchronous environment with even one faulty processes. In [55], it is proved that in an asynchronous environment Consensus and Atomic Broadcast are equivalent. <p> This impossibility arises due to the fact that in an asynchronous system it is not possible to distinguish between a very slow process and a failed process. Most systems <ref> [22, 23, 24, 25, 26] </ref> circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. <p> This is also called ABCAST. In this algorithm, the sender causally broadcasts the message to everyone in the group. The sequencer (which is a special member) then casually broadcasts the sequence number of the message in the total order to everyone. 6. Amoeba Amoeba <ref> [23] </ref> uses an algorithm similar to CM. They add process membership maintenance to CM. Amoeba gives different APIs for group maintenance: join group, send to group, leave group, create group, receive f rom group and reset group.
Reference: [24] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki, "Transis: </author> <title> A Communication Sub-System for High Availability," </title> <booktitle> in 22nd International Symposium on Fault-Tolerant Computing, </booktitle> <address> Boston, Massachusetts, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> There is no partial order as in Total. Totem provides extended virtual synchrony [30] and tolerates network partitions. It has high message latency under low loads and low message latency under high loads and provides total order and safe delivery of messages. The Transis system <ref> [24, 46, 47] </ref> extends the Trans/Total algorithm. It provides a total order which respects the partial order (causal-ordering of messages), with certainty (unlike Total). It is based on the Lansis [47] algorithm, which assumes a broadcast network. <p> D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm [43], Trans/Total [45], Transis <ref> [24] </ref>, Totem [26], Isis [22] and Amoeba [23]. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. <p> This impossibility arises due to the fact that in an asynchronous system it is not possible to distinguish between a very slow process and a failed process. Most systems <ref> [22, 23, 24, 25, 26] </ref> circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. <p> It generates a total order by considering candidate sets. A message is a candidate if all the messages that it acknowledges (directly or transitively) are already delivered. The order is determined by voting. For this voting no additional messages are send. 3. Transis Transis <ref> [24, 46, 47] </ref> is a multicast communication layer that facilitates the development of fault tolerant distributed applications in a network of machines. It supports reliable group communication for high availability applications. It uses a protocol for reliable message delivery that takes advantage of the broadcast feature of a LAN.
Reference: [25] <author> L. E. Moser, P. Melliar-Smith, and V. Agrawala, </author> <title> "Processor membership in asynchronous distributed systems," </title> <journal> IEEE Trans. Par. Distr. Syst., </journal> <volume> vol. 5, </volume> <pages> pp. 459-473, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> The Trans [45] system also provides Atomic Multicast service for a broadcast network. It is based on piggy-backing positive acknowledgments on regular messages, and sending explicit negative acknowledgments when messages are missed. The Total <ref> [25] </ref> protocol builds on the Trans system. It provides total ordering of messages in a group. The total order is built from a partial order, which is the causal order for the 23 group. The algorithm provides a total order only with a very high probability. <p> The algorithm provides a total order only with a very high probability. The algorithm makes use of logical time stamps similar to [36, 37]. For the fault free case only one message is required for each broadcast. This protocol is computationally intensive compared with Totem. They <ref> [25] </ref> also provide membership algorithms on top of total ordering protocols. The algorithm has the advantage that even if there is a process failure, messages can still be broadcast by surviving processes, before reconfiguration takes place. The Totem system [26] builds on the experience of the Trans/Total stem. <p> This impossibility arises due to the fact that in an asynchronous system it is not possible to distinguish between a very slow process and a failed process. Most systems <ref> [22, 23, 24, 25, 26] </ref> circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. <p> One can get a set of algorithms by varying the token transfer frequency and commit delay. These algorithms will have different storage requirements, resiliency to failures, message delays and number of acknowledgments send. 2. Trans/Total Protocol In <ref> [25, 45] </ref> the authors provide an Atomic Broadcast and membership algorithm that assumes a broadcast network. Trans is a protocol for reliable multicast and Total is a protocol for total ordering.
Reference: [26] <author> Y. Amir, L. E. Moser, P. Melliar-Smith, D. A. Agrawal, and P. Ciarfella, </author> <title> "Fast message ordering and membership using a logical token passing ring," </title> <booktitle> in Proceed 172 ings of the 13th Intl. Conf. on Dist. Comp. Syst., </booktitle> <address> Washington DC, </address> <pages> pp. 551-560, </pages> <year> 1993. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> This protocol is computationally intensive compared with Totem. They [25] also provide membership algorithms on top of total ordering protocols. The algorithm has the advantage that even if there is a process failure, messages can still be broadcast by surviving processes, before reconfiguration takes place. The Totem system <ref> [26] </ref> builds on the experience of the Trans/Total stem. It uses a logical token passing ring similar to the one proposed by Chang and Maxemchuk [43]. But in [43] the token holder acknowledges the broadcast messages, whereas in Totem only the token holder can send a message to the group. <p> D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm [43], Trans/Total [45], Transis [24], Totem <ref> [26] </ref>, Isis [22] and Amoeba [23]. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. <p> This impossibility arises due to the fact that in an asynchronous system it is not possible to distinguish between a very slow process and a failed process. Most systems <ref> [22, 23, 24, 25, 26] </ref> circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. <p> The protocol is based on two stages suggest a new membership set, and then wait for agreement from every process. The same protocol is also used when processes start up. 4. Totem Totem <ref> [30, 26] </ref> is based on the experience of Trans/Total. It provides an agreed (total ordering) and safe reliable multicast service for a broadcast network, and membership service. It tolerates network partition, provides virtual synchrony and extended virtual synchrony.
Reference: [27] <author> F. Cristian, H. Aghili, R. Strong, and D. Dolev, </author> <title> "Atomic broadcast: From simple message diffusion to byzantine agreement," </title> <booktitle> in Fifteenth Intl. Conf. on Fault Tolerant Computing, </booktitle> <address> Ann Arbor, </address> <publisher> Michigan, </publisher> <pages> pp. 1-12, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. They also provide a membership service for a real-time system [39]. Their algorithm gives a high performance but less 22 flexibility. Cristian <ref> [27] </ref> has developed an Atomic Broadcast protocol for distributed systems with loosely synchronized clocks and an upper bound on the message transit time. Membership algorithms have also been developed for synchronous systems [40, 41]. Psync [42] provides totally ordered messages using a context graph.
Reference: [28] <author> D. Powell, P. Verissimo, G. Bonn, F. Waeselynck, and D. Seaton, </author> <title> "The Delta-4 approach to dependability in open distributed computing systems," </title> <booktitle> in International Symposium on Fault-Tolerant Computing, </booktitle> <address> Washington, DC, </address> <pages> pp. 246-251, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6.
Reference: [29] <author> P. D. Ezhilchelvan, R. A. Mac^edo, and S. K. Shrivastava, "Newtop: </author> <title> A fault-tolerant group communication protocol," </title> <booktitle> in Proceedings of the 15th International Conference on Distributed Computing Systems (ICDCS'95), </booktitle> <address> Vancouver, BC, Canada, </address> <pages> pp. 296-306, </pages> <year> 1995. </year>
Reference-contexts: The total order and agreement properties of Atomic Broadcast ensure that all correct processes deliver the same sequence of messages. Atomic Broadcast is a powerful communication paradigm for fault-tolerant distributed computing <ref> [22, 23, 24, 25, 26, 27, 11, 28, 29] </ref>. This abstraction of Atomic Multicast frees the distributed application developer from synchronization details and delivery guarantees in the system and help him/her concentrate on the application logic. Atomic Broadcasts are very useful in fault-tolerant applications. Consider Figure 6. <p> Amoeba gives the user an API for maintaining group membership. Their algorithm is valid for point-to-point networks and their total order corresponds to ABCAST of Isis, but does it in less number of messages. The Arjuna <ref> [29] </ref> system also implements a reliable ordered broadcast. It uses the concept of nested atomic transactions, with commit and roll-back for 25 transactions. D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts.
Reference: [30] <author> L. E. Moser, Y. Amir, P. M. Melliar-Smith, and D. A. Agarwal, </author> <title> "Extended virtual synchrony," </title> <booktitle> in Proceedings of the 14th International Conference on Distributed Computing Systems (ICDCS'94), </booktitle> <pages> pp. 56-65, </pages> <year> 1994. </year>
Reference-contexts: Virtual synchrony extends the requirements of total ordering to reconfigurations within a group. Partitionable operation allows network partitions and re-merging. It is also re 19 Fig. 8. Example of a Network Partition. ferred to as extended virtual synchrony <ref> [30] </ref>. If network partitions can occur and partitioned networks can rejoin, then the group membership should allow delivery of message under such conditions. <p> But in [43] the token holder acknowledges the broadcast messages, whereas in Totem only the token holder can send a message to the group. Totem assumes a broadcast network. There is no partial order as in Total. Totem provides extended virtual synchrony <ref> [30] </ref> and tolerates network partitions. It has high message latency under low loads and low message latency under high loads and provides total order and safe delivery of messages. The Transis system [24, 46, 47] extends the Trans/Total algorithm. <p> CBCAST multicasts messages which respect causal delivery. ABCAST delivers totally ordered messages. Isis makes a very good case for process group communication [11]. It also establishes the concept of virtual synchrony [48], which is expanded to `extended virtual synchrony' by <ref> [30] </ref>, to maintain a consistent view in distributed systems. The initial Isis algorithm is based on a 2-phase algorithm [35] where all the processes in a group agree on the order of delivery, which is later changed to a logical token passing ring [49] similar to [43]. <p> The protocol is based on two stages suggest a new membership set, and then wait for agreement from every process. The same protocol is also used when processes start up. 4. Totem Totem <ref> [30, 26] </ref> is based on the experience of Trans/Total. It provides an agreed (total ordering) and safe reliable multicast service for a broadcast network, and membership service. It tolerates network partition, provides virtual synchrony and extended virtual synchrony.
Reference: [31] <author> S. T. Chanson, D. W. Neufeld, and L. Liang, </author> <title> "A bibliography on multicast and group communications," </title> <journal> ACM Operating Systems Review, </journal> <volume> vol. 23, </volume> <pages> pp. 20-25, </pages> <month> [10] </month> <year> 1989. </year>
Reference-contexts: Since the group membership is dynamic, the group membership protocol has to be integrated with the naming service. C. Related Work Group communication support for distributed computing has been available for some time now. Most of these though do not offer reliable communication <ref> [31, 32] </ref> (e.g.:IP multicast [33]). V-system offered a multicast service for process group communication. But, it did not offer a reliable multicast service or a total ordering service. Navaratnam et al [34] proposed an algorithm for reliable group communication and implemented it on the V-system.
Reference: [32] <author> M. Ahamad, ed., </author> <title> Multicast Communication in Distributed Systems. </title> <publisher> IEEE, Los Alamitos, </publisher> <address> California, </address> <year> 1990. </year>
Reference-contexts: Since the group membership is dynamic, the group membership protocol has to be integrated with the naming service. C. Related Work Group communication support for distributed computing has been available for some time now. Most of these though do not offer reliable communication <ref> [31, 32] </ref> (e.g.:IP multicast [33]). V-system offered a multicast service for process group communication. But, it did not offer a reliable multicast service or a total ordering service. Navaratnam et al [34] proposed an algorithm for reliable group communication and implemented it on the V-system.
Reference: [33] <author> S. Deering, </author> <title> "Host Extensions for IP Multicasting," RFC 1112, Request for Comments, </title> <month> August </month> <year> 1989. </year> <month> 173 </month>
Reference-contexts: Since the group membership is dynamic, the group membership protocol has to be integrated with the naming service. C. Related Work Group communication support for distributed computing has been available for some time now. Most of these though do not offer reliable communication [31, 32] (e.g.:IP multicast <ref> [33] </ref>). V-system offered a multicast service for process group communication. But, it did not offer a reliable multicast service or a total ordering service. Navaratnam et al [34] proposed an algorithm for reliable group communication and implemented it on the V-system.
Reference: [34] <author> S. Navaratnum, S. Chanson, and G. Neufeld, </author> <title> "Reliable group communication in distributed systems," </title> <booktitle> in Proc. 8th Intl. Conf. on Dist. Comp. Syst., </booktitle> <address> San Jose, California, </address> <pages> pp. 439-446, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Most of these though do not offer reliable communication [31, 32] (e.g.:IP multicast [33]). V-system offered a multicast service for process group communication. But, it did not offer a reliable multicast service or a total ordering service. Navaratnam et al <ref> [34] </ref> proposed an algorithm for reliable group communication and implemented it on the V-system.
Reference: [35] <author> K. P. Birman and T. A. Joseph, </author> <title> "Reliable communication in the presence of failure," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 5, </volume> <pages> pp. 47-76, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: All UGSEND messages are funneled through the primary manager. Failures are detected by periodic ARE U ALIVE messages. In case of a network partition and a simultaneous primary failure, the algorithm does not rejoin the partitions correctly. Causal ordering for a fault-tolerant system was first proposed in <ref> [35] </ref>. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge [36, 37]. [14] and [13] propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. <p> Isis makes a very good case for process group communication [11]. It also establishes the concept of virtual synchrony [48], which is expanded to `extended virtual synchrony' by [30], to maintain a consistent view in distributed systems. The initial Isis algorithm is based on a 2-phase algorithm <ref> [35] </ref> where all the processes in a group agree on the order of delivery, which is later changed to a logical token passing ring [49] similar to [43]. Isis also provides for the ordering of messages in overlapping process groups. <p> Isis provides causal, total and safe (all-stable service) delivery of messages, but does not provide extended virtual synchrony. It does not allow network partitioning and only considers processes that fail and never recover (or are regarded as new processes.) For total ordering the initial version of the Isis algorithm <ref> [35] </ref> worked as a 2-phase algorithm. The logic of the algorithm is given in Figure 10. 32 Fig. 10. Isis 2-phase Algorithm. A sender wanting to broadcast a message broadcasts the message to everyone in the group.
Reference: [36] <author> C. Fidge, </author> <title> "Timestamps in message-passing systems that preserve the partial ordering," </title> <journal> Australian Computer Science Communications, </journal> <volume> vol. 10, </volume> <pages> pp. 56-66, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: In case of a network partition and a simultaneous primary failure, the algorithm does not rejoin the partitions correctly. Causal ordering for a fault-tolerant system was first proposed in [35]. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge <ref> [36, 37] </ref>. [14] and [13] propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. <p> It provides total ordering of messages in a group. The total order is built from a partial order, which is the causal order for the 23 group. The algorithm provides a total order only with a very high probability. The algorithm makes use of logical time stamps similar to <ref> [36, 37] </ref>. For the fault free case only one message is required for each broadcast. This protocol is computationally intensive compared with Totem. They [25] also provide membership algorithms on top of total ordering protocols. <p> Leading to a contradiction to our assumption. Therefore the algorithm delivers reliable FIFO multicast messages. E. Causal Multicast Causal ordering of messages requires that all messages must be delivered in an order consistent with causality. Causal multicast can be solved using vector timestamps <ref> [36, 37] </ref>. This requires each multicast message to be tagged with a vector timestamp. In an environment where all messages are multicast messages this is satisfactory but, 1 A process logs all the messages that it receives in a receive log. 63 Fig. 18.
Reference: [37] <author> F. Mattern, </author> <title> "Virtual time and global states in distributed systems," </title> <booktitle> in Proc. Int. Workshop on Parallel and Distributed Algorithms, Gers, France, </booktitle> <pages> pp. 215-226, </pages> <year> 1988. </year>
Reference-contexts: In case of a network partition and a simultaneous primary failure, the algorithm does not rejoin the partitions correctly. Causal ordering for a fault-tolerant system was first proposed in [35]. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge <ref> [36, 37] </ref>. [14] and [13] propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. <p> It provides total ordering of messages in a group. The total order is built from a partial order, which is the causal order for the 23 group. The algorithm provides a total order only with a very high probability. The algorithm makes use of logical time stamps similar to <ref> [36, 37] </ref>. For the fault free case only one message is required for each broadcast. This protocol is computationally intensive compared with Totem. They [25] also provide membership algorithms on top of total ordering protocols. <p> Leading to a contradiction to our assumption. Therefore the algorithm delivers reliable FIFO multicast messages. E. Causal Multicast Causal ordering of messages requires that all messages must be delivered in an order consistent with causality. Causal multicast can be solved using vector timestamps <ref> [36, 37] </ref>. This requires each multicast message to be tagged with a vector timestamp. In an environment where all messages are multicast messages this is satisfactory but, 1 A process logs all the messages that it receives in a receive log. 63 Fig. 18.
Reference: [38] <author> H. Kopetz, A. Damm, C. Koza, M. Mulazzani, W. Schwabl, C. Senft, and R. Zainlinger, </author> <title> "Distributed fault-tolerant real-time systems: The MARS approach," </title> <journal> IEEE Micro, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 25-40, </pages> <year> 1989. </year>
Reference-contexts: Causal ordering for a fault-tolerant system was first proposed in [35]. Most Causal ordering algorithms use logical vector clocks proposed by Mattern and Fidge [36, 37]. [14] and [13] propose causal ordering algorithms for non fault tolerant cases, but put a bound on the storage requirement. Kopetz et al. <ref> [38] </ref> have developed a protocol for the ordering of messages in a synchronous system for real-time applications. They also provide a membership service for a real-time system [39]. Their algorithm gives a high performance but less 22 flexibility.
Reference: [39] <author> H. Kopetz, G. Grunstel, and J. Reisinger, </author> <title> "Fault-tolerant membership in a synchronous distributed real-time system," </title> <booktitle> in In Proceedings of the International Working Conference on Dependable Computing for Critical Applications, </booktitle> <pages> pp. 167-174, </pages> <year> 1989. </year>
Reference-contexts: Kopetz et al. [38] have developed a protocol for the ordering of messages in a synchronous system for real-time applications. They also provide a membership service for a real-time system <ref> [39] </ref>. Their algorithm gives a high performance but less 22 flexibility. Cristian [27] has developed an Atomic Broadcast protocol for distributed systems with loosely synchronized clocks and an upper bound on the message transit time. Membership algorithms have also been developed for synchronous systems [40, 41].
Reference: [40] <author> F. Cristian, </author> <title> "Agreeing on who is present and who is absent in a synchronous distributed system," </title> <booktitle> in Proc. 18th Int. Symp. on Fault-Tolerant Computing (FTCS-18), </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 206-211, </pages> <year> 1988. </year>
Reference-contexts: Their algorithm gives a high performance but less 22 flexibility. Cristian [27] has developed an Atomic Broadcast protocol for distributed systems with loosely synchronized clocks and an upper bound on the message transit time. Membership algorithms have also been developed for synchronous systems <ref> [40, 41] </ref>. Psync [42] provides totally ordered messages using a context graph. In case of a process failure, the system blocks till the process is removed from the configuration. One of the earliest reliable total ordering broadcast protocols for asynchronous systems were proposed by Chang and Maxemchuk [43]. <p> Since Consensus is impossible in a truly asynchronous system, atomic broadcast is also impossible in a truly asynchronous system. Researchers have defined slightly different models to implement Consensus and atomic broadcasts. In a synchronous system with timing and scheduling guarantees the impossibility result in [54] does not hold. Cristian <ref> [56, 40] </ref> defines a synchronous and a timed asynchronous model which incorporates failure detectors in the form of time-outs.
Reference: [41] <author> F. Cristian, </author> <title> "Reaching agreement on processor-group membership in synchronous distributed systems," </title> <journal> Distributed Computing, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 175 174 </pages>
Reference-contexts: Their algorithm gives a high performance but less 22 flexibility. Cristian [27] has developed an Atomic Broadcast protocol for distributed systems with loosely synchronized clocks and an upper bound on the message transit time. Membership algorithms have also been developed for synchronous systems <ref> [40, 41] </ref>. Psync [42] provides totally ordered messages using a context graph. In case of a process failure, the system blocks till the process is removed from the configuration. One of the earliest reliable total ordering broadcast protocols for asynchronous systems were proposed by Chang and Maxemchuk [43].
Reference: [42] <author> L. L. Peterson, N. C. Buchholz, and R. D. Schlichting, </author> <title> "Preserving and using context information in interprocess communication," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 7, </volume> <pages> pp. 217-246, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Their algorithm gives a high performance but less 22 flexibility. Cristian [27] has developed an Atomic Broadcast protocol for distributed systems with loosely synchronized clocks and an upper bound on the message transit time. Membership algorithms have also been developed for synchronous systems [40, 41]. Psync <ref> [42] </ref> provides totally ordered messages using a context graph. In case of a process failure, the system blocks till the process is removed from the configuration. One of the earliest reliable total ordering broadcast protocols for asynchronous systems were proposed by Chang and Maxemchuk [43].
Reference: [43] <author> J.-M. Chang and N. F. Maxemchuk, </author> <title> "Reliable broadcast protocols," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 2, </volume> <pages> pp. 251-273, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Psync [42] provides totally ordered messages using a context graph. In case of a process failure, the system blocks till the process is removed from the configuration. One of the earliest reliable total ordering broadcast protocols for asynchronous systems were proposed by Chang and Maxemchuk <ref> [43] </ref>. They proposed a set of protocols that totally ordered messages reliably in a broadcast network. Their protocols form a logical token passing ring. The protocols are for varying degree of resiliency, message latency and token passing frequency. In a group, the sender broadcasts the message to the group. <p> To make the algorithm fault tolerant, the token is rotated between sites. The algorithm is based on positive acknowledgments for token transfers and negative acknowledgments for missed messages and time-stamps. In this algorithm, there is a trade-off between message commit time and resiliency. [44] improvess on <ref> [43] </ref>, by removing explicit token passing messages. The network assumed is point-to-point. Each site in the logical ring receives multicast messages from the token holder. The token is (implicitly) passed after every multicast message. <p> The Totem system [26] builds on the experience of the Trans/Total stem. It uses a logical token passing ring similar to the one proposed by Chang and Maxemchuk <ref> [43] </ref>. But in [43] the token holder acknowledges the broadcast messages, whereas in Totem only the token holder can send a message to the group. Totem assumes a broadcast network. There is no partial order as in Total. Totem provides extended virtual synchrony [30] and tolerates network partitions. <p> The Totem system [26] builds on the experience of the Trans/Total stem. It uses a logical token passing ring similar to the one proposed by Chang and Maxemchuk <ref> [43] </ref>. But in [43] the token holder acknowledges the broadcast messages, whereas in Totem only the token holder can send a message to the group. Totem assumes a broadcast network. There is no partial order as in Total. Totem provides extended virtual synchrony [30] and tolerates network partitions. <p> The initial Isis algorithm is based on a 2-phase algorithm [35] where all the processes in a group agree on the order of delivery, which is later changed to a logical token passing ring [49] similar to <ref> [43] </ref>. Isis also provides for the ordering of messages in overlapping process groups. It provides support for causal, totally ordered and safe delivery of messages. In [48] the role of Atomic Broadcast in distributed systems is compared to that of message passing mechanism in the operating systems of today. <p> Their algorithm uses voting to avoid blocking. The efficiency is low at low loads but increases with increasing load. Amoeba [23] implements a reliable totally ordered multicast, at the kernel-level. A sequencer in the group orders messages for the group. Their algorithm is similar to <ref> [43] </ref>, but they add process group membership to it. Amoeba gives the user an API for maintaining group membership. Their algorithm is valid for point-to-point networks and their total order corresponds to ABCAST of Isis, but does it in less number of messages. <p> It uses the concept of nested atomic transactions, with commit and roll-back for 25 transactions. D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm <ref> [43] </ref>, Trans/Total [45], Transis [24], Totem [26], Isis [22] and Amoeba [23]. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. <p> Chandra and Toueg [55] propose a formal model for unreliable failure detectors and determine what can be and what cannot be solved for different types of failure detectors. 1. Chang and Maxemchuk's (CM) Protocol Chang and Maxemchuk provide a reliable broadcast with total order <ref> [43] </ref>. They assume a broadcast network connecting all the processes. The idea behind their algorithm is as follows: If there are multiple senders and receivers then total order is difficult. If there is only one sender or only one receiver then total order is easy. <p> It provides an agreed (total ordering) and safe reliable multicast service for a broadcast network, and membership service. It tolerates network partition, provides virtual synchrony and extended virtual synchrony. It provides for merging of two groups after a partition. 31 The algorithm forms a logical token ring. In <ref> [43] </ref> the token holder acknowledges the message, whereas in Totem only the token holder can transmit. Each process waits for the token to arrive and then transmits messages.
Reference: [44] <author> W.-J. Jia, J. Kaiser, and E. Nett, </author> <title> "An efficient and reliable group multicast protocol," </title> <booktitle> in Proceedings of the International Symposium on Autonomous and Decentralized Systems, Phoenix, Arizona, </booktitle> <pages> pp. 127-133, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: To make the algorithm fault tolerant, the token is rotated between sites. The algorithm is based on positive acknowledgments for token transfers and negative acknowledgments for missed messages and time-stamps. In this algorithm, there is a trade-off between message commit time and resiliency. <ref> [44] </ref> improvess on [43], by removing explicit token passing messages. The network assumed is point-to-point. Each site in the logical ring receives multicast messages from the token holder. The token is (implicitly) passed after every multicast message.
Reference: [45] <author> P. M. Melliar-Smith, L. E. Moser, and V. Agrawala, </author> <title> "Broadcast protocols for distributed systems," </title> <journal> IEEE Trans. Par. Distr. Syst., </journal> <volume> vol. 1, </volume> <pages> pp. 17-25, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: The token is (implicitly) passed after every multicast message. A site wanting to multicast a message to the group, sends a request to the token holder (which is calculated, using the number of multicast messages it has received and the size of the ring). The Trans <ref> [45] </ref> system also provides Atomic Multicast service for a broadcast network. It is based on piggy-backing positive acknowledgments on regular messages, and sending explicit negative acknowledgments when messages are missed. The Total [25] protocol builds on the Trans system. It provides total ordering of messages in a group. <p> It uses the concept of nested atomic transactions, with commit and roll-back for 25 transactions. D. Example Systems In this section we briefly describe six Atomic Multicast algorithms, which we believe represent most of the existing algorithms for Atomic Multicasts. Namely, we describe Chang and Maxemchuk's algorithm [43], Trans/Total <ref> [45] </ref>, Transis [24], Totem [26], Isis [22] and Amoeba [23]. We discuss the criteria that should be used to compare different algorithms. A brief comparison is made of the six algorithms presented, with their advantages and disadvantages. We also make certain observations about Atomic Multicast algorithms and their performance. <p> One can get a set of algorithms by varying the token transfer frequency and commit delay. These algorithms will have different storage requirements, resiliency to failures, message delays and number of acknowledgments send. 2. Trans/Total Protocol In <ref> [25, 45] </ref> the authors provide an Atomic Broadcast and membership algorithm that assumes a broadcast network. Trans is a protocol for reliable multicast and Total is a protocol for total ordering.
Reference: [46] <author> D. Dolev and D. Malki, </author> <title> "The Transis approach to high availability cluster communication," </title> <journal> Comm. ACM, </journal> <volume> vol. 39, </volume> <pages> pp. 64-70, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: There is no partial order as in Total. Totem provides extended virtual synchrony [30] and tolerates network partitions. It has high message latency under low loads and low message latency under high loads and provides total order and safe delivery of messages. The Transis system <ref> [24, 46, 47] </ref> extends the Trans/Total algorithm. It provides a total order which respects the partial order (causal-ordering of messages), with certainty (unlike Total). It is based on the Lansis [47] algorithm, which assumes a broadcast network. <p> It generates a total order by considering candidate sets. A message is a candidate if all the messages that it acknowledges (directly or transitively) are already delivered. The order is determined by voting. For this voting no additional messages are send. 3. Transis Transis <ref> [24, 46, 47] </ref> is a multicast communication layer that facilitates the development of fault tolerant distributed applications in a network of machines. It supports reliable group communication for high availability applications. It uses a protocol for reliable message delivery that takes advantage of the broadcast feature of a LAN.
Reference: [47] <author> D. Dolev and D. </author> <title> Malki, </title> <booktitle> "The design of the transis system," Lecture Notes in Computer Science, </booktitle> <volume> vol. 938, </volume> <pages> pp. </pages> <address> 83-, </address> <year> 1995. </year>
Reference-contexts: There is no partial order as in Total. Totem provides extended virtual synchrony [30] and tolerates network partitions. It has high message latency under low loads and low message latency under high loads and provides total order and safe delivery of messages. The Transis system <ref> [24, 46, 47] </ref> extends the Trans/Total algorithm. It provides a total order which respects the partial order (causal-ordering of messages), with certainty (unlike Total). It is based on the Lansis [47] algorithm, which assumes a broadcast network. <p> The Transis system [24, 46, 47] extends the Trans/Total algorithm. It provides a total order which respects the partial order (causal-ordering of messages), with certainty (unlike Total). It is based on the Lansis <ref> [47] </ref> algorithm, which assumes a broadcast network. Like Trans, Lansis also is based on piggy-backing positive acknowledgments on broadcast messages, and sending explicit negative acknowledgments. It can provide a reliable total order in a highly efficient way, in a broadcast domain. The Transis algorithm is more complex and than Totem. <p> It generates a total order by considering candidate sets. A message is a candidate if all the messages that it acknowledges (directly or transitively) are already delivered. The order is determined by voting. For this voting no additional messages are send. 3. Transis Transis <ref> [24, 46, 47] </ref> is a multicast communication layer that facilitates the development of fault tolerant distributed applications in a network of machines. It supports reliable group communication for high availability applications. It uses a protocol for reliable message delivery that takes advantage of the broadcast feature of a LAN.
Reference: [48] <author> K. Birman and T. Joseph, </author> <title> "Exploiting virtual synchrony in distributed systems," </title> <booktitle> in Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <address> Austin, Texas, </address> <pages> pp. 123-138, </pages> <month> 8-11 November </month> <year> 1987. </year>
Reference-contexts: GBCAST allows the application to multicast without any synchronization requirement. CBCAST multicasts messages which respect causal delivery. ABCAST delivers totally ordered messages. Isis makes a very good case for process group communication [11]. It also establishes the concept of virtual synchrony <ref> [48] </ref>, which is expanded to `extended virtual synchrony' by [30], to maintain a consistent view in distributed systems. <p> Isis also provides for the ordering of messages in overlapping process groups. It provides support for causal, totally ordered and safe delivery of messages. In <ref> [48] </ref> the role of Atomic Broadcast in distributed systems is compared to that of message passing mechanism in the operating systems of today. Horus [50] is the object oriented extension of Isis.
Reference: [49] <author> K. Birman, A. Schiper, and P. Stephenson, </author> <title> "Lightweight causal and atomic group multicast," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 9, </volume> <editor> p. </editor> <volume> 272, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: The initial Isis algorithm is based on a 2-phase algorithm [35] where all the processes in a group agree on the order of delivery, which is later changed to a logical token passing ring <ref> [49] </ref> similar to [43]. Isis also provides for the ordering of messages in overlapping process groups. It provides support for causal, totally ordered and safe delivery of messages. <p> Levels of services available in Totem are: basic, FIFO, causal, agreed (total) and safe. 5. Isis Isis [22] is based on the idea of ordering messages, multicast to process groups. A recent version <ref> [49] </ref> uses token passing similar to CM. It focuses on the application interface and provides levels of services, at increasing cost, reliability, and synchronization: GBCAST, CBCAST, ABCAST. Isis establishes the idea of virtual synchrony to maintain consistency in fault tolerant distributed systems. <p> The sender collects all the estimates, and sends the maximum of the estimates to everyone. That estimate is the sequence of the message in the total order. The new version <ref> [49] </ref> of the algorithm is shown in Figure 11. This is also called ABCAST. In this algorithm, the sender causally broadcasts the message to everyone in the group.
Reference: [50] <author> R. van Renesse, K. P. Birman, and S. Maffeis, "Horus: </author> <title> A flexible group communication system," </title> <journal> Comm. ACM, </journal> <volume> vol. 39, </volume> <pages> pp. 76-83, </pages> <month> April </month> <year> 1996. </year> <month> 175 </month>
Reference-contexts: Isis also provides for the ordering of messages in overlapping process groups. It provides support for causal, totally ordered and safe delivery of messages. In [48] the role of Atomic Broadcast in distributed systems is compared to that of message passing mechanism in the operating systems of today. Horus <ref> [50] </ref> is the object oriented extension of Isis. The algorithms in [51, 52] are for Atomic Multicast on a point-to-point network over a spanning tree. [53] uses a 3 phase commit protocol to order messages. Their algorithm uses voting to avoid blocking.
Reference: [51] <author> H. Garcia-Molina and A. M. Spauster, </author> <title> "Message ordering in a multicast environment," </title> <booktitle> in Proceedings of the 9th International Conference on Distributed Computing Systems (ICDCS), </booktitle> <address> Newport Beach, California, </address> <pages> pp. 354-361, </pages> <year> 1989. </year>
Reference-contexts: It provides support for causal, totally ordered and safe delivery of messages. In [48] the role of Atomic Broadcast in distributed systems is compared to that of message passing mechanism in the operating systems of today. Horus [50] is the object oriented extension of Isis. The algorithms in <ref> [51, 52] </ref> are for Atomic Multicast on a point-to-point network over a spanning tree. [53] uses a 3 phase commit protocol to order messages. Their algorithm uses voting to avoid blocking. The efficiency is low at low loads but increases with increasing load.
Reference: [52] <author> H. Garcia-Molina and A. Spauster, </author> <title> "Ordered and reliable multicast communication," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 9, </volume> <pages> pp. 242-271, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: It provides support for causal, totally ordered and safe delivery of messages. In [48] the role of Atomic Broadcast in distributed systems is compared to that of message passing mechanism in the operating systems of today. Horus [50] is the object oriented extension of Isis. The algorithms in <ref> [51, 52] </ref> are for Atomic Multicast on a point-to-point network over a spanning tree. [53] uses a 3 phase commit protocol to order messages. Their algorithm uses voting to avoid blocking. The efficiency is low at low loads but increases with increasing load.
Reference: [53] <author> V. Gligor and W. Luan, </author> <title> "A fault-tolerant protocol for atomic broadcast," </title> <journal> IEEE Trans. Par. Distr. Syst., </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 271-285, </pages> <year> 1990. </year>
Reference-contexts: Horus [50] is the object oriented extension of Isis. The algorithms in [51, 52] are for Atomic Multicast on a point-to-point network over a spanning tree. <ref> [53] </ref> uses a 3 phase commit protocol to order messages. Their algorithm uses voting to avoid blocking. The efficiency is low at low loads but increases with increasing load. Amoeba [23] implements a reliable totally ordered multicast, at the kernel-level. A sequencer in the group orders messages for the group.
Reference: [54] <author> M. J. Fischer, N. A. Lynch, and M. S. Paterson, </author> <title> "Impossibility of distributed consensus with one faulty process," </title> <journal> J. ACM, </journal> <volume> vol. 32, </volume> <pages> pp. 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: It gives the application programmer a programming paradigm, that can be used to view a set of processes as a single entity. An Atomic Multicast is either implemented in the operating system [23] or as a middle-ware/API [22]. In <ref> [54] </ref>, it is proved that it is impossible to solve deterministically the Consensus problem in a purely asynchronous environment with even one faulty processes. In [55], it is proved that in an asynchronous environment Consensus and Atomic Broadcast are equivalent. <p> Each pair of processes are connected by two one-way channels in opposite directions. We will consider the communication in the system as timed asynchronous (as opposed to synchronous and purely asynchronous [56]). Synchronous systems have clock synchronization, message delivery 42 guarantees and process scheduling guarantees. A purely asynchronous system <ref> [54] </ref> has no bound on the delay in the delivery of messages, no bound on process speeds, no synchronous clocks or a global clock. In a purely asynchronous system a process waits for a message forever, so a very slow process and a failed process cannot be distinguished. <p> Asynchronous systems have no time restriction on the process speed, no global clock and no restriction on the delay in receiving messages. This gives rise to the problem, that in an asynchronous system a very slow process and a crashed process cannot be distinguished <ref> [54] </ref>. This creates a problem in implementing fault tolerant systems as the failure detectors cannot be accurate. Atomic broadcast (which is same as total ordering) and Consensus [64], which are very important abstractions in building distributed systems, cannot be solved in such an asynchronous distributed system [54]. <p> process cannot be distinguished <ref> [54] </ref>. This creates a problem in implementing fault tolerant systems as the failure detectors cannot be accurate. Atomic broadcast (which is same as total ordering) and Consensus [64], which are very important abstractions in building distributed systems, cannot be solved in such an asynchronous distributed system [54]. Atomic broadcast is equivalent to Consensus in an asynchronous system (irrespective of the existence of failure detectors). If we have an algorithm for atomic broadcast in an asynchronous system, we can use it to solve Consensus. <p> Since Consensus is impossible in a truly asynchronous system, atomic broadcast is also impossible in a truly asynchronous system. Researchers have defined slightly different models to implement Consensus and atomic broadcasts. In a synchronous system with timing and scheduling guarantees the impossibility result in <ref> [54] </ref> does not hold. Cristian [56, 40] defines a synchronous and a timed asynchronous model which incorporates failure detectors in the form of time-outs. <p> Real vs Virtual Failures The communication medium assumed is unreliable. There is no process scheduling guarantee on the hosts and no limit on the process/host load. These factors can lead to processes that have not failed but cannot respond to suspect messages. Extension of <ref> [54] </ref> leads to the conclusion that in a purely asynchronous system, accurate detection of failures is not possible. This can lead to two kinds of failures: real failures and 104 virtual failures.
Reference: [55] <author> T. D. Chandra and S. Toueg, </author> <title> "Unreliable failure detectors for reliable distributed systems," </title> <type> Technical Report TR93-1374, </type> <institution> Cornell University, Computer Science Department, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: An Atomic Multicast is either implemented in the operating system [23] or as a middle-ware/API [22]. In [54], it is proved that it is impossible to solve deterministically the Consensus problem in a purely asynchronous environment with even one faulty processes. In <ref> [55] </ref>, it is proved that in an asynchronous environment Consensus and Atomic Broadcast are equivalent. This means that in a purely asynchronous environment, where there is no restriction on process speed and the delay incurred on the messages, there is no deterministic solution for the Atomic Broadcast problem. <p> Most systems [22, 23, 24, 25, 26] circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 [56]. These time-outs are in fact unreliable failure detectors. Chandra and Toueg <ref> [55] </ref> propose a formal model for unreliable failure detectors and determine what can be and what cannot be solved for different types of failure detectors. 1. Chang and Maxemchuk's (CM) Protocol Chang and Maxemchuk provide a reliable broadcast with total order [43]. <p> Thus Consensus is reducible to atomic broadcast. Atomic broadcast can also be reduced to Consensus. Atomic broadcast can be achieved using the Consensus algorithm and reliable broadcast. Any process wanting 1 The failure detectors can be classified as belonging to the category W in <ref> [55] </ref>. 48 to atomically broadcast a message reliably broadcasts it. When a process reliably delivers a message, it proposes the order number (in the total order). Since an algorithm for Consensus is available, the order of that message at all the processes is the same. <p> The fundamental problem in implementing distributed systems is occurrence of partial failures and the inability to detect accurately the state of a system. Distributed systems need failure detectors (or a health checker) in some form for implementation. In <ref> [55] </ref>, the authors introduce the concept of unreliable failure detectors that can make mistakes and use them to solve Consensus (and therefore atomic broadcast). They define failure detectors in terms of abstract properties as opposed to giving specific implementations.
Reference: [56] <author> F. Cristian, </author> <title> "Synchronous and asynchronous group communication," </title> <journal> Comm. ACM, </journal> <volume> vol. 39, </volume> <pages> pp. 88-97, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Most systems [22, 23, 24, 25, 26] circumvent this problem by implementing failure detectors in the form of time-outs and retransmission. Cristian refers to such systems as timed-asynchronous system 26 <ref> [56] </ref>. These time-outs are in fact unreliable failure detectors. Chandra and Toueg [55] propose a formal model for unreliable failure detectors and determine what can be and what cannot be solved for different types of failure detectors. 1. <p> The membership in a group changes with time. A timed asynchronous system is assumed. Each pair of processes are connected by two one-way channels in opposite directions. We will consider the communication in the system as timed asynchronous (as opposed to synchronous and purely asynchronous <ref> [56] </ref>). Synchronous systems have clock synchronization, message delivery 42 guarantees and process scheduling guarantees. A purely asynchronous system [54] has no bound on the delay in the delivery of messages, no bound on process speeds, no synchronous clocks or a global clock. <p> In a purely asynchronous system a process waits for a message forever, so a very slow process and a failed process cannot be distinguished. A timed asynchronous system <ref> [56] </ref>, is an asynchronous system in the sense that it has no clock synchronization, no message delivery and no process scheduling guarantees. But in a timed asynchronous system a process does not wait for a message forever. <p> Since Consensus is impossible in a truly asynchronous system, atomic broadcast is also impossible in a truly asynchronous system. Researchers have defined slightly different models to implement Consensus and atomic broadcasts. In a synchronous system with timing and scheduling guarantees the impossibility result in [54] does not hold. Cristian <ref> [56, 40] </ref> defines a synchronous and a timed asynchronous model which incorporates failure detectors in the form of time-outs.
Reference: [57] <author> F. Cristian, R. de Beijer, and S. Mishra, </author> <title> "A performance comparison of asynchronous atomic broadcast," </title> <journal> Distributed Systems Engineering Journal, </journal> <volume> vol. 1, no. 4, </volume> <pages> pp. 177-201, </pages> <year> 1994. </year>
Reference-contexts: The sequencer handles the majority of the load. Spontaneous broadcasts are not allowed. They also assume a point-to-point network and do not allow network partition. The ordering of messages is centralized. A performance comparison of some of the Atomic Broadcast protocols in a simulation environment is given in <ref> [57] </ref>. F. Issues Most communication support algorithms can be divided into token-passing and non token passing. Non-token passing algorithms are spontaneous and all the members can broadcast messages without waiting for a token-holder or a sequencer to transmit messages.
Reference: [58] <author> M. J. Fischer, </author> <title> "The consensus problem in unreliable distributed systems (A brief survey)," </title> <booktitle> in Proc. Int. Conf. on Foundations of Computations Theory, Borgholm, Sweden, </booktitle> <pages> pp. 127-140, </pages> <year> 1983. </year>
Reference-contexts: The role of the name service is discussed in section D and the failure assumptions are explained in section E. Description of the failure detectors in the system is given in section F and section G comments on Consensus <ref> [58] </ref> and the system assumptions. B. Assumptions The system S, S fp 1 ; p 2 ; : : :g consists of processes p 1 ; p 2 ; : : :. The total number of processes in the system is not known. Processes can form non-empty groups.
Reference: [59] <author> G. Beedubail, A. Karmarkar, A. Gurijala, W. Marti, and U. Pooch, </author> <title> "An algorithm for supporting fault tolerant objects in distributed object oriented op 176 erating systems," </title> <booktitle> in Proc. of International Workshop on Object-Orientation in Operating Systems, Lund, </booktitle> <address> Sweden, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: NS is assumed not to fail. A name service is very important in a distributed system since without a name service clients cannot reach the servers. A name service can be made fault tolerant using the techniques in <ref> [59, 60, 61, 62, 63] </ref>. 46 E. Failure Model The fault model that is assumed for the system is crash failure for the processes and fail-silent for the communication system. Processors can fail only by crashing, there are no byzantine failures.
Reference: [60] <author> G. Beedubail, A. Karmarkar, A. Gurijala, W. Marti, and U. Pooch, </author> <title> "Fault tolerant objects in distributed systems using hot replication," </title> <booktitle> in Proc. of 15th Int'l Phoenix Conf. on Computers and Communications (IPCCC'96), </booktitle> <address> Phoenix, Ari-zona, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: NS is assumed not to fail. A name service is very important in a distributed system since without a name service clients cannot reach the servers. A name service can be made fault tolerant using the techniques in <ref> [59, 60, 61, 62, 63] </ref>. 46 E. Failure Model The fault model that is assumed for the system is crash failure for the processes and fail-silent for the communication system. Processors can fail only by crashing, there are no byzantine failures. <p> For example, consider a group consisting of replicated servers, where each server in the group executes every client request, so that in case of a failure of a server another can immediately take over <ref> [60] </ref>. In such a case, if the server replies back to the client, the effect of that client request has to be preserved in spite of the failure of the client and/or the replying server.
Reference: [61] <author> G. Beedubail, P. Kessler, and U. Pooch, </author> <title> "Object replication in spring using subcontracts," </title> <type> Tech. Rep. </type> <institution> TR95-041, Computer Science Department,Texas A&M University, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: NS is assumed not to fail. A name service is very important in a distributed system since without a name service clients cannot reach the servers. A name service can be made fault tolerant using the techniques in <ref> [59, 60, 61, 62, 63] </ref>. 46 E. Failure Model The fault model that is assumed for the system is crash failure for the processes and fail-silent for the communication system. Processors can fail only by crashing, there are no byzantine failures.
Reference: [62] <author> G. Beedubail, A. Karmarkar, and U. Pooch, </author> <title> "Object replication protocol using remote procedure calls," </title> <type> Tech. Rep. </type> <institution> TR95-042, Computer Science Department,Texas A&M University, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: NS is assumed not to fail. A name service is very important in a distributed system since without a name service clients cannot reach the servers. A name service can be made fault tolerant using the techniques in <ref> [59, 60, 61, 62, 63] </ref>. 46 E. Failure Model The fault model that is assumed for the system is crash failure for the processes and fail-silent for the communication system. Processors can fail only by crashing, there are no byzantine failures.
Reference: [63] <author> G. Beedubail, P. Kessler, and U. Pooch, </author> <title> "Replicated naming service in spring," </title> <type> Tech. Rep. </type> <institution> TR95-048, Computer Science Department,Texas A&M University, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: NS is assumed not to fail. A name service is very important in a distributed system since without a name service clients cannot reach the servers. A name service can be made fault tolerant using the techniques in <ref> [59, 60, 61, 62, 63] </ref>. 46 E. Failure Model The fault model that is assumed for the system is crash failure for the processes and fail-silent for the communication system. Processors can fail only by crashing, there are no byzantine failures.
Reference: [64] <author> D. Dolev, C. Dwork, and L. Stockmeyer, </author> <title> "On the minimal synchrony needed for distributed consensus," </title> <journal> Journal of the ACM, </journal> <volume> vol. 34, </volume> <pages> pp. 77-97, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: This gives rise to the problem, that in an asynchronous system a very slow process and a crashed process cannot be distinguished [54]. This creates a problem in implementing fault tolerant systems as the failure detectors cannot be accurate. Atomic broadcast (which is same as total ordering) and Consensus <ref> [64] </ref>, which are very important abstractions in building distributed systems, cannot be solved in such an asynchronous distributed system [54]. Atomic broadcast is equivalent to Consensus in an asynchronous system (irrespective of the existence of failure detectors). <p> This allows clients of a services to associate timeout delays with each of the provided operation. <ref> [64, 65] </ref> study partially synchronous systems. The fundamental problem in implementing distributed systems is occurrence of partial failures and the inability to detect accurately the state of a system. Distributed systems need failure detectors (or a health checker) in some form for implementation.
Reference: [65] <author> C. Dwork, N. Lynch, and L. Stockmeyer, </author> <title> "Consensus in the presence of partial synchrony," </title> <booktitle> in Symposium on Principles of Distributed Systems, </booktitle> <address> Vancouver, Canada, </address> <pages> pp. 103-118, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: This allows clients of a services to associate timeout delays with each of the provided operation. <ref> [64, 65] </ref> study partially synchronous systems. The fundamental problem in implementing distributed systems is occurrence of partial failures and the inability to detect accurately the state of a system. Distributed systems need failure detectors (or a health checker) in some form for implementation.
Reference: [66] <author> K. Arnold and J. Gosling, </author> <title> The Java Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year> <month> 177 </month>
Reference-contexts: The framework supports the semantics necessary for distributed application domains in general and fault-tolerant distributed applications in specific. The framework is developed keeping the Internet in mind. The implementation language is J ava T M <ref> [66, 67, 68] </ref>. The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package [69] which is part of the language, is network centric [70] build with the Internet in mind and is portable.
Reference: [67] <author> C. Fraizer and J. Bond, </author> <title> Java T M Api Reference. </title> <publisher> New Riders Publishing, </publisher> <address> Indi-anapolis, Indiana, </address> <year> 1996. </year>
Reference-contexts: The framework supports the semantics necessary for distributed application domains in general and fault-tolerant distributed applications in specific. The framework is developed keeping the Internet in mind. The implementation language is J ava T M <ref> [66, 67, 68] </ref>. The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package [69] which is part of the language, is network centric [70] build with the Internet in mind and is portable.
Reference: [68] <author> J. Gosling, B. Joy, and G. Steele, </author> <title> The Java T M Language Specification. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year>
Reference-contexts: The framework supports the semantics necessary for distributed application domains in general and fault-tolerant distributed applications in specific. The framework is developed keeping the Internet in mind. The implementation language is J ava T M <ref> [66, 67, 68] </ref>. The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package [69] which is part of the language, is network centric [70] build with the Internet in mind and is portable.
Reference: [69] <author> D. Lea, </author> <title> Concurrent Programming in Java : Design Principles and Patterns. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year>
Reference-contexts: The framework is developed keeping the Internet in mind. The implementation language is J ava T M [66, 67, 68]. The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package <ref> [69] </ref> which is part of the language, is network centric [70] build with the Internet in mind and is portable. The framework is build using Sun Microsystem's JDK 1.1.1 [71] and tested on Solaris 2.5 and Windows NT 4.0.
Reference: [70] <author> E. R. Harold, </author> <title> Java Network Programming. </title> <publisher> O'Reilly and Associates Inc, </publisher> <address> Se-bastopol, California, </address> <year> 1997. </year>
Reference-contexts: The framework is developed keeping the Internet in mind. The implementation language is J ava T M [66, 67, 68]. The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package [69] which is part of the language, is network centric <ref> [70] </ref> build with the Internet in mind and is portable. The framework is build using Sun Microsystem's JDK 1.1.1 [71] and tested on Solaris 2.5 and Windows NT 4.0. The Cortex framework uses IP multicast for unreliable multicast on the Internet.
Reference: [71] <institution> Sun Microsystems Inc., </institution> <note> JDK 1.1.1 Documentation, Available: http://java.sun.com/products/jdk/1.1/docs/index.html, March 1997. </note>
Reference-contexts: The reason for using this language is that it is object-oriented, easy to program, has a multi-threaded package [69] which is part of the language, is network centric [70] build with the Internet in mind and is portable. The framework is build using Sun Microsystem's JDK 1.1.1 <ref> [71] </ref> and tested on Solaris 2.5 and Windows NT 4.0. The Cortex framework uses IP multicast for unreliable multicast on the Internet. By using IP multicast, the Cortex framework can view the group to be in a broadcast domain at an abstract level.
Reference: [72] <author> T. J. Biggerstaff and C. Richter, </author> <title> "Reusability framework, assessment, and directions," </title> <journal> IEEE Software, </journal> <volume> vol. 4, </volume> <pages> pp. 41-49, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: The FTIW serves as a `proof of concept' for the Cortex framework. Experimental results and discussions are included in Section G. Section H concludes this chapter by summarizing it. B. Object Oriented Frameworks A framework <ref> [72] </ref> is a reusable design expressed as a set of abstract classes and the way their instances collaborate. By definition, a framework is an object-oriented design. It doesn't have to be implemented in an object-oriented language, though it usually is.
Reference: [73] <author> R. E. Johnson, </author> <title> "Frameworks = (components + patterns)," </title> <journal> Communications of the ACM, </journal> <volume> vol. 40, </volume> <pages> pp. 39-42, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: By definition, a framework is an object-oriented design. It doesn't have to be implemented in an object-oriented language, though it usually is. It is the skeleton of an application that can be customized by an application developer. A widely accepted definition comes from Ralph E. Johnson <ref> [73] </ref>: A framework is a set of classes that embodies an abstract design for solu tions to a family of related problems. A framework defines the behavior of a collection of objects, providing an innovative way to reuse both software designs and code.
Reference: [74] <author> M. E. Fayad and D. C. Schmidt, </author> <title> "Object-oriented application frameworks," </title> <journal> Communications of the ACM, </journal> <volume> vol. 40, </volume> <pages> pp. 32-38, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: It is a set of prefabricated software building blocks that application programmers can use, extend, or customize for specific computing solutions. Application developers can use the framework to write the application by customizing it <ref> [74] </ref>. The developer does not have to start from scratch. Object-oriented frameworks represent the scaling up of the fundamental principle of object-oriented programming. In object-oriented programming a new class inherits from a more general class. This new class contains only code that is different from the superclass.
Reference: [75] <author> G. Shepherd and S. Wingo, </author> <title> MFC Internals : Inside the Microsoft Foundation Class Architecture. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year>
Reference-contexts: The application developer can concentrate on the application logic as a good framework would provide the underlying infrastructural facilities. For successful frameworks they must be complete, flexible, Extensible and understandable. Examples of frameworks are MFC <ref> [75] </ref>, Java RMI [76], implementation of CORBA [6]. An application program can make method invocations in the framework and the framework can also make calls to handler methods in the application program. This results in an `inversion of control' at run time.
Reference: [76] <author> Sun Microsystems Inc., </author> <title> Java Remote Method Invocation (RMI), </title> <note> Available: http://www.javasoft.com/products/jdk/rmi/index.html, January 1997. 178 </note>
Reference-contexts: The application developer can concentrate on the application logic as a good framework would provide the underlying infrastructural facilities. For successful frameworks they must be complete, flexible, Extensible and understandable. Examples of frameworks are MFC [75], Java RMI <ref> [76] </ref>, implementation of CORBA [6]. An application program can make method invocations in the framework and the framework can also make calls to handler methods in the application program. This results in an `inversion of control' at run time.
Reference: [77] <author> Taligent Inc., </author> <title> Building Object-Oriented Framework, </title> <note> Available: http://www.taligent.com/Technology/WhitePapers/BuildingFwks/BuildingFr-ameworks.html, 1993. </note>
Reference-contexts: Application programs using frameworks are also hard to debug as the application programmer does not have control over the flow of control. A Framework also requires documentation, and support. 110 Frameworks are very similar to class libraries <ref> [77] </ref>. In fact frameworks are class libraries and more. In an application using a class library, a set of classes are instantiated by the application and the application calls the methods in the class library. So there is a defined flow of control.
Reference: [78] <author> J. O. Coplien, </author> <title> Patterns. </title> <publisher> SIGS Publication, </publisher> <address> New York, New York, </address> <year> 1996. </year>
Reference-contexts: Frameworks can be used for developing components and vice versa. In general, frameworks are often used to simplify the development of infrastructure and middle-ware software, whereas components are often used to simplify the development of end-user application software. Another object-oriented concept that is used for reusability are patterns <ref> [78, 79] </ref>. Patterns represent recurring solutions to software development problems within a particular context. The primary difference between patterns and frameworks is that frameworks focus on reuse of concrete designs, algorithms, and implementations in a particular programming language.
Reference: [79] <author> E. Gamma, R. Helm, R. Johnson, and J. Vlissides, </author> <title> Design Patterns: Elements of Reusable Object-Oriented Software. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1995. </year>
Reference-contexts: Frameworks can be used for developing components and vice versa. In general, frameworks are often used to simplify the development of infrastructure and middle-ware software, whereas components are often used to simplify the development of end-user application software. Another object-oriented concept that is used for reusability are patterns <ref> [78, 79] </ref>. Patterns represent recurring solutions to software development problems within a particular context. The primary difference between patterns and frameworks is that frameworks focus on reuse of concrete designs, algorithms, and implementations in a particular programming language.
Reference: [80] <author> K. Savetz, N. Randall, and Y. Lepage, MBONE: </author> <title> Multicasting Tomorrow's Internet. </title> <publisher> IDG Books Worldwide, Inc., </publisher> <address> Foster City, California, </address> <year> 1996. </year>
Reference-contexts: In contrast, patterns focus on reuse of abstract 111 designs and software micro-architectures. C. IP Multicast The usual way of moving information around the Internet is by using unicast protocols. IP multicast <ref> [80, 81] </ref> allows multicast messages to be send on the internet. This is similar to a television station that broadcasts its signal. The signal originates from one source, but it can reach everyone in the station's signal area.
Reference: [81] <author> S. Deering, </author> <title> "Host extensions for ip multicasting." </title> <address> rfc1112, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: In contrast, patterns focus on reuse of abstract 111 designs and software micro-architectures. C. IP Multicast The usual way of moving information around the Internet is by using unicast protocols. IP multicast <ref> [80, 81] </ref> allows multicast messages to be send on the internet. This is similar to a television station that broadcasts its signal. The signal originates from one source, but it can reach everyone in the station's signal area. <p> The TTL field acts like a counter that is decremented every time the packet passes through an mrouter. Once the TTL field becomes zero, it does not get forwarded. 3. IGMP The Internet Group Management Protocol (IGMP) <ref> [81] </ref> is used by hosts to report their host group memberships to any immediately-neighboring mrouters. IGMP is an integral part of IP. IGMP messages are encapsulated in IP datagrams. Multicast routers send periodic host membership query messages to discover which host groups have members on attached local networks.
Reference: [82] <institution> A Map of the MBone, </institution> <note> Available: http://www.cs.berkeley.edu/~elan/mbone.html, August 1996. </note>
Reference-contexts: The MBONE topology of mrouters is designed in such a manner that it facilitates efficient distribution of packets without congesting any node inappropriately. A map of MBONE topology is given in <ref> [82] </ref>. MBONE is a virtual overlay network on top of the Internet. It consists of multicast-capable islands connected by tunnels. Each island supports hardware multicast to its hosts. The islands also contain one or more mrouters. The tunnels propagate IP multicast packets between islands.
Reference: [83] <author> W. Yeong, T. Howes, and S. Kille, </author> <title> "Lightweight directory access protocol," </title> <month> March </month> <year> 1995. </year>
Reference-contexts: The nameservice package gives the minimum functionality needed for a name service. The Cortex framework can be modified slightly and used with any other name service or directory service that might be available in the distributed system, for example LDAP <ref> [83] </ref>. The ftl package will have to be modified to include the APIs corresponding to the name service used. The package nameservice consists of bare minimum functionality required of a name service. The name service consists of a flat database with two fields for every tuple in the database.
Reference: [84] <institution> Old Domininion University, </institution> <note> The Java Collaborator Toolset, Available: http://www.cs.odu.edu/~kvande/Projects/Collaborator/, March 1996. </note>
Reference-contexts: The communication of different events to the group, the ordering of events and the fault-tolerance requirements are satisfied by instantiating the To-talOrder class. The GUI part of the FTIW is the modified version of the one found in <ref> [84] </ref>. 147 55. Class Hierarc h for whiteb o ar P k 148 The class hierarchy for the whiteboard package is given in Figure 55. These classes give necessary components for creating the graphical user interface needed for a whiteboard.
Reference: [85] <author> A. Schiper and M. Raynal, </author> <title> "From group communication to transactions in distributed systems," </title> <journal> Comm. ACM, </journal> <volume> vol. 39, </volume> <pages> pp. 84-87, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: When the trans 166 Fig. 59. An Example of Nested Object Invocation. action is committed (or aborted) all the object implementations in the group have to be notified. Now if there are overlapping groups then there is a need for the ordering of messages in overlapping groups <ref> [85] </ref>. 2. Support for Nested Invocations The current implementation does not support nested object invocations for a server replica group. In a nested object invocation, a server invokes a method on another server on behalf of a client, as shown in Figure 59.
Reference: [86] <author> J. Harold W. Lockhart, </author> <title> OSF DCE: Guide to Developing Distributed Applications. </title> <publisher> McGraw-Hill Inc., </publisher> <address> New York, New York, </address> <year> 1994. </year>
Reference-contexts: For large group sizes this may not be feasible. The Cortex framework does not conform to any distributed processing standard. A research direction that warrants investigation is, how does group communication and delivery guarantees fit in a distributed processing standard such as DCE <ref> [86] </ref>, 168 RM-ODP [87] or CORBA [6]. 5. Failure Detectors and Timeouts The failure of a process or a missed message is detected using timeouts, retransmis-sions and sequence numbers. The performance of the framework is affected by the values of the timeouts used.

References-found: 86

