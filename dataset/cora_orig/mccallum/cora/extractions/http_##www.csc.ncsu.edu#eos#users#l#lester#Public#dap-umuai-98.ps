URL: http://www.csc.ncsu.edu/eos/users/l/lester/Public/dap-umuai-98.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/young/aivr/readings.html
Root-URL: http://www.csc.ncsu.edu
Title: Lifelike Pedagogical Agents for Mixed-Initiative Problem Solving in Constructivist Learning Environments  
Author: JAMES C. LESTER, BRIAN A. STONE and GARY D. STELLING 
Keyword: Key words: Lifelike agents, pedagogical agents, animated agents, knowledge-basedlearning environments, mixed-initiative interaction, intelligent tutoring systems, intelligent multimedia presentation, intelligent interfaces, task models.  
Affiliation: Department of Computer Science North Carolina State University  
Abstract: Mixed-initiative problem solving lies at the heart of knowledge-based learning environments. While learners are actively engaged in problem-solving activities, learning environments should monitor their progress and provide them with feedback in a manner that contributes to achieving the twin goals of learning effectiveness and learning efficiency. Mixed-initiative interactions are particularly critical for constructivist learning environments in which learners participate in active problem solving. We have recently begun to see the emergence of believable agents with lifelike qualities. Featured prominently in constructivist learning environments, lifelike pedagogical agents could couple key feedback functionalities with a strong visual presence by observing learners' progress and providing them with visually contextualized advice during mixed-initiative problem solving. For the past three years, we have been engaged in a large-scale research program on lifelike pedagogical agents and their role in constructivist learning environments. In the resulting computational framework, lifelike pedagogical agents are specified by (1) a behavior space containing animated and vocal behaviors, (2) a design-centered context model that maintains constructivist problem representations, multimodal advisory contexts, and evolving problem-solving tasks, and (3) a behavior sequencing engine that in realtime dynamically selects and assembles agents' actions to create pedagogically effective, lifelike behaviors. To empirically investigate this framework, it has been instantiated in a full-scale implementation of a lifelike pedagogical agent for DESIGN-A-PLANT, a learning environment developed for the domain of botanical anatomy and physiology for middle school students. Experience with focus group studies conducted with middle school students interacting with the implemented agent suggests that lifelike pedagogical agents hold much promise for mixed-initiative learning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J., A. Corbett, K. Koedinger, and R. Pelletier: </author> <year> 1995, </year> <title> `Cognitive Tutors: Lessons Learned'. </title> <journal> Journal of the Learning Sciences 4(2), </journal> <pages> 167-207. </pages>
Reference: <author> Anderson, J. R.: </author> <year> 1983, </year> <title> The Architecture of Cognition. </title> <publisher> Harvard University Press. </publisher>
Reference: <author> Andre, E., W. Finkler, W. Graf, T. Rist, A. Schauder, and W. Wahlster: </author> <year> 1993, </year> <title> `WIP: The Automatic Synthesis of Multi-Modal Presentations'. </title> <editor> In: M. T. Maybury (ed.): </editor> <title> Intelligent Multimedia Interfaces. </title> <publisher> AAAI Press, Chapt. </publisher> <pages> 3. </pages>
Reference: <author> Andre, E. and T. Rist: </author> <year> 1996, </year> <title> `Coping with Temporal Constraints in Multimedia Presentation Planning'. </title> <booktitle> In: Proceedings of the Thirteenth National Conference on Artificial Intelligence. </booktitle> <pages> pp. 142-147. </pages>
Reference: <author> Bates, J.: </author> <year> 1994, </year> <title> `The Role of Emotion in Believable Agents'. </title> <journal> Communications of the ACM 37(7), </journal> <pages> 122-125. </pages>
Reference-contexts: For example, it would go against the spirit of constructivist learning to prevent the learner from pursuing his or her design activities in order to issue a number of probes to detect precisely which misconceptions were active at a given time. To achieve mixed-initiative interaction with lifelike agents, believability <ref> (Bates, 1994) </ref> is a key feature of these agents. We define the believability of lifelike agents as the extent to which users interacting with them come to believe that they are observing a sentient being with its own beliefs, desires, intentions, and personality.
Reference: <author> Blumberg, B. and T. Galyean: </author> <year> 1995, </year> <title> `Multi-Level Direction of Autonomous Creatures for Real-Time Virtual Environments'. </title> <booktitle> In: Computer Graphics Proceedings. </booktitle> <pages> pp. 47-54. </pages>
Reference: <author> Brown, J., A. Collins, and P. Duguid: </author> <year> 1989, </year> <title> `Situated Cognition and the Culture of Learning'. </title> <booktitle> Educational Researcher 18(1), </booktitle> <pages> 32-42. </pages>
Reference-contexts: In the same manner that coherence plays a critical role in assisting readers' comprehension of text (Grimes, 1975), the behaviors of an animated pedagogical agent should be molded by considerations of pedagogical coherence. Perhaps most central among these requirements is that an agent's advisory and explanatory interjections be situated <ref> (Brown et al., 1989) </ref>: all of its explanatory behaviorsnot merely its advisory actions but also its communication of fundamental conceptual knowledgeshould take place in concrete problem-solving contexts.
Reference: <author> Brown, J. S. and R. R. Burton: </author> <year> 1978, </year> <title> `Diagnostic Models for Procedural Bugs in Basic Mathematical Skills'. </title> <booktitle> Cognitive Science 2, </booktitle> <pages> 155-191. </pages>
Reference: <author> Brusilovsky, P.: </author> <year> 1992, </year> <title> `A Framework for Intelligent Knowledge Sequencing and Task Sequencing'. </title> <booktitle> In: Proceedings of the Second International Conference, ITS '92. </booktitle> <pages> pp. 499-506. </pages>
Reference: <author> Burton, R. R.: </author> <year> 1982, </year> <title> `Diagnosing Bugs in a Simple Procedural Skill'. </title> <editor> In: D. Sleeman and J. S. Brown (eds.): </editor> <booktitle> Intelligent Tutoring Systems. </booktitle> <address> London: </address> <publisher> Academic Press. </publisher>
Reference: <author> Carberry, S.: </author> <year> 1989, </year> <title> `Plan Recognition and Its Use in Understanding Dialog'. </title> <editor> In: A. </editor> <publisher> Kobsa and W. </publisher>
Reference: <author> Wahlster (eds.): </author> <title> User Models in Dialog Systems. </title> <publisher> Berlin: Springer-Verlag, </publisher> <pages> pp. 133-162. </pages>
Reference: <author> Carbonell, J. R.: </author> <year> 1970, </year> <title> `AI in CAI: An Artificial-Intelligence Approach to Computer-Assisted Instruction'. </title> <journal> IEEE Transactions on Man-Machine Systems 4, </journal> <pages> 190-202. </pages>
Reference: <author> Carr, B. and I. P. Goldstein: </author> <year> 1977, </year> <title> `Overlays: A Theory of Modelling for Computer Aided Instruction'. </title> <type> Technical Report AI Memo 406, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory. </institution>
Reference-contexts: Hence, frequency annotations indicate the number of times that the agent has advised the learner about the given topic (s) of the entry. Annotations on particular topics are suggestive of marks on an overlay user model <ref> (Carr and Goldstein, 1977) </ref>; overlay marks indicate which subskills a learner has mastered, while frequency annotations indicate the topics about which the agent has advised the student. ? Frequency annotations are used by the behavior sequencing engine to assess the level of abstraction at which advice should be provided, as discussed
Reference: <author> Cassell, J., C. Pelachaud, N. Badler, M. Steedman, B. Achorn, T. Becket, B. Douville, S. Prevost, and M. Stone: </author> <year> 1994, </year> <title> `Modeling the Interaction between Speech and Gesture'. </title> <note> In: SIGGRAPH '94. </note>
Reference: <author> Cauzinille-Marmeche, E. and J. Mathieu: </author> <year> 1988, </year> <title> `Experimental Data for the Design of a Microworld-Based System for Algebra'. </title> <editor> In: H. Mandl and A. Lesgold (eds.): </editor> <booktitle> Learning Issues for Intelligent Tutoring Systems. </booktitle> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <pages> pp. 278-286. </pages>
Reference: <author> Cawsey, A.: </author> <year> 1992, </year> <title> Explanation and Interaction: The Computer Generation of Explanatory Dialogues. </title> <publisher> MIT Press. </publisher>
Reference: <author> Chu-Carroll, J. and S. Carberry: </author> <year> 1994, </year> <title> `A Plan-Based Model for Response Generation in Collaborative Task-Oriented Dialogues'. </title> <booktitle> In: AAAI-94: Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <volume> Vol. 1. </volume> <pages> pp. 799-805. </pages> <note> paper.tex; 14/06/1998; 17:35; no v.; p.41 42 J. </note> <author> LESTER, B. STONE, AND G. STELLING Cohen, R., C. Allaby, C. Cumbaa, M. Fitzgerald, K. Ho, B. Hui, C. Latulipe, F. Lu, N. </author> <title> Moussa, </title> <address> D. </address>
Reference: <author> Pooley, A. Qian, and S. Siddiqi: </author> <year> 1998, </year> <title> `What is Initiative'. User Modeling and User-Adapted Interaction. </title> <note> in this issue. </note>
Reference: <author> Collins, J., J. Greer, V. Kumar, G. McCalla, P. Meagher, and R. Tkatch: </author> <year> 1997, </year> <title> `Inspectable User Models for Just-In-Time Workplace Training'. </title> <booktitle> In: Proceedings of the Sixth International Conference on User Modeling. </booktitle> <pages> pp. 327-337. </pages>
Reference-contexts: However, this does not imply that unusually expressive task models are required. In fact, the artifact-based task models employed in DESIGN-A-PLANT are of the lightweight variety. The task models are lightweight in somewhat the same sense that the user models in the PHELPS just-in-time training system <ref> (Collins et al., 1997) </ref> are lightweight: while they are not particularly expressive, they are in practice highly accurate and can provide essential problem-solving tracking knowledge. Moreover, they permit non-invasive diagnosis.
Reference: <author> Elhadad, M.: </author> <year> 1991, </year> <title> `FUF: The Universal Unifier User Manual Version 5.0'. </title> <type> Technical Report CUCS-038-91, </type> <institution> Department of Computer Science, Columbia University. </institution>
Reference-contexts: Creating these capabilities will entail incorporating state-of-the-art explanation generation techniques (Suthers, 1991; Cawsey, 1992; Hovy, 1993; Mittal, 1993; Moore, 1995; Lester and Porter, 1997) and surface generators <ref> (Elhadad, 1991) </ref> and then extending them to take into account conversational, gestural, and deictic aspects of discourse (Cassell et al., 1994; Towns et al., 1998). In summary, it appears that lifelike pedagogical agents have much to offer and that much remains to be done to bring them to fruition.
Reference: <author> Feiner, S. K. and K. R. McKeown: </author> <year> 1990, </year> <title> `Coordinating Text and Graphics in ExplanationGeneration'. </title> <booktitle> In: Proceedings of the Eighth National Conference on Artificial Intelligence. </booktitle> <address> Boston, MA, </address> <pages> pp. 442-449. </pages>
Reference: <author> Freedman, R. K.: </author> <year> 1996, </year> <title> `Interaction of Discourse Planning, Instructional Planning and Dialogue Management in an Interactive Tutoring System'. </title> <type> Ph.D. thesis, </type> <institution> Northwestern University. </institution>
Reference: <author> Green, N. and S. Carberry: </author> <year> 1998, </year> <title> `A Computational Mechanism for Initiative in Answer Generation'. User Modeling and User-Adapted Interaction. </title> <note> in this issue. </note>
Reference-contexts: In the same manner that human interlocutors engaged in mixed-initiative interactions frequently generate responses that include highly relevant information that was not specifically requested <ref> (Green and Carberry, 1998) </ref>, the agent should be prepared to provide learners with assistance even though it may not be explicitly requested. Once problem solving is successfully completed by the learner, the agent should again regain control to complete the problem-solving transaction.
Reference: <author> Grimes, J. E.: </author> <year> 1975, </year> <title> The Thread of Discourse. The Hague: </title> <publisher> Mouton. </publisher>
Reference-contexts: LESTER, B. STONE, AND G. STELLING priate for the particular aspects of the design task on which the learner is focusing, and advice should be relevant to the problem-solving goals currently being pursued. In the same manner that coherence plays a critical role in assisting readers' comprehension of text <ref> (Grimes, 1975) </ref>, the behaviors of an animated pedagogical agent should be molded by considerations of pedagogical coherence. <p> Consequently, the behavior sequencing engine is designed to maximize usage of bandwidth while simultaneously minimizing visual interruptions. 4.2.6. Verbal and Visual Transitions In the same manner that coherence plays a critical role in assisting readers' comprehension of text <ref> (Grimes, 1975) </ref>, the behaviors of lifelike pedagogical agents should be molded by considerations of both verbal and visual coherence. To achieve this, paper.tex; 14/06/1998; 17:35; no v.; p.27 28 J. LESTER, B. STONE, AND G. STELLING the behavior sequencing engine introduces both audio and visual transitions.
Reference: <author> Guinn, C. I.: </author> <year> 1995, </year> <title> `Meta-Dialogue Behaviors: Improving the Efficiency of Human-Machine Dialogue </title>
References-found: 26

