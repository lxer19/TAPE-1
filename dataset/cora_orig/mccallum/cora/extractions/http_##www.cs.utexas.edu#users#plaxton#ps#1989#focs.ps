URL: http://www.cs.utexas.edu/users/plaxton/ps/1989/focs.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: On the Network Complexity of Selection  
Author: C. Greg Plaxton 
Address: Stanford, CA 94305  
Affiliation: Department of Computer Science Stanford University  
Abstract: The selection problem is to determine the kth largest out of a given set of n keys, and its sequential complexity is well known to be linear. Thus, given a p processor parallel machine, it is natural to ask whether or not an O(n=p) selection algorithm can be devised for that machine. The main result of this paper is an ((n=p) log log p + log p) lower bound for selection on any network that satisfies a particular low expansion property. The class of networks satisfying this property includes all of the common network families such as the tree, multi-dimensional mesh, hypercube, butterfly and shu*e exchange. When n=p is sufficiently large (for example, greater than log 2 p on the butterfly, hypercube and shu*e exchange), this result is matched by the upper bound presented in [4]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Borodin, L. J. Guibas, N. A. Lynch, and A. C. Yao. </author> <title> Efficient searching using partial ordering. </title> <journal> IPL, </journal> <volume> 12 </volume> <pages> 71-75, </pages> <year> 1981. </year>
Reference-contexts: The corresponding sequential tradeoff between preprocessing time and search time is well understood, see <ref> [1] </ref> and [3]. The running time of the ith stage is readily shown to be O (2 i (n=p) log log p + T 1 + T 2 log p), which implies the overall time bound for Select stated in Equation (1). <p> The adversary maintains such a comparison tree for every block. A comparison tree of the same sort was used by Borodin et al. <ref> [1] </ref> to obtain an easy (though not their strongest) sequential tradeoff between preprocessing time and search time in a partial order. A comparison tree is a binary tree with tokens placed at certain nodes.
Reference: [2] <author> R. Cole. </author> <title> An optimally efficient parallel selection algorithm. </title> <journal> IPL, </journal> <volume> 26 </volume> <pages> 295-299, </pages> <year> 1988. </year>
Reference-contexts: The two models of network computation defined in this section will be referred to as the upper bound model and lower bound model, respectively. 3 Upper Bounds For the EREW PRAM, Cole has exhibited an algorithm with a running time of O (n=p + log p log fl p) <ref> [2] </ref>. Note that Cole's algorithm provides optimal speedup for n = (p log p log fl p). The network algorithm Select presented in [4] achieves nearly optimal speedup when the ratio n=p is sufficiently large.
Reference: [3] <author> R. M. Karp, R. Motwani, and P. Raghavan. </author> <title> Deferred data structuring. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 883-902, </pages> <year> 1988. </year>
Reference-contexts: The corresponding sequential tradeoff between preprocessing time and search time is well understood, see [1] and <ref> [3] </ref>. The running time of the ith stage is readily shown to be O (2 i (n=p) log log p + T 1 + T 2 log p), which implies the overall time bound for Select stated in Equation (1).
Reference: [4] <author> C. G. Plaxton. </author> <title> Load balancing, selection, and sorting on the hypercube. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The lower bound is proven in Sections 4 and 5. When n=p is sufficiently large (for example, greater than log 2 p on the hypercube and shu*e-exchange), the lower bound is tight to within a multiplicative constant. The matching upper bound is provided by the algorithm Select presented in <ref> [4] </ref>. Section 3 contains fl This work was supported in part by a grant from the AT&T Foundation, NSF grant DCR-8351757 and ONR grant N00014-88-K-0166. <p> It will also be assumed that n = O (p c ) for some positive constant c. Having bounded n in this manner, it may be assumed without loss of generality that all of the keys are distinct <ref> [4] </ref>. The selection algorithm presented in [4] obeys all of the above restrictions. Section 3 contains a brief outline of that algorithm along with a summary of its asymptotic performance on a variety of networks. <p> It will also be assumed that n = O (p c ) for some positive constant c. Having bounded n in this manner, it may be assumed without loss of generality that all of the keys are distinct <ref> [4] </ref>. The selection algorithm presented in [4] obeys all of the above restrictions. Section 3 contains a brief outline of that algorithm along with a summary of its asymptotic performance on a variety of networks. <p> Note that Cole's algorithm provides optimal speedup for n = (p log p log fl p). The network algorithm Select presented in <ref> [4] </ref> achieves nearly optimal speedup when the ratio n=p is sufficiently large. To be precise, assume that a particular network is capable of sorting n = p keys located one per processor in time T 1 and can perform broadcasting and summing operations in time T 2 . <p> This median is the desired key y and, as proven in <ref> [4] </ref>, it can be used to eliminate half of the live items at every processor.
Reference: [5] <author> C. G. Plaxton. </author> <title> On the network complexity of selection. </title> <type> Technical Report STAN-CS-89-1276, </type> <institution> Stanford University, Department of Computer Science, </institution> <month> August </month> <year> 1989. </year> <month> 6 </month>
Reference-contexts: Due to space limitations, a number of proofs and additional remarks have been omitted from this version of the paper. The statement of a theorem or lemma for which the proof has been omitted is immediately followed by a . The reader is referred to <ref> [5] </ref> for a complete version. 2 The Network Model A p processor fixed interconnection network may be viewed as an undirected graph, where vertices correspond to processors and edges correspond to communication channels. Each processor has an infinite local memory.
References-found: 5

