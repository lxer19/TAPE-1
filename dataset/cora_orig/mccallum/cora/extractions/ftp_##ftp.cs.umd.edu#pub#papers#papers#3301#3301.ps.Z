URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3301/3301.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: lionel, basili-@cs.umd.edu  morasca@elet.polimi.it  
Title: Defining and Validating High-Level Design Metrics 1  
Author: Lionel Briand*, Sandro Morasca**, Victor R. Basili* 
Address: College Park, MD, 20742  Piazza Leonardo da Vinci 32, I-20133 Milano, Italy  Ab str act  
Date: 1  
Affiliation: University of Maryland  Computer Science Department University of Maryland,  Dipartimento di Elettronica e Informazione Politecnico di Milano  
Pubnum: CS-TR-3301  
Abstract: The availability of significant metrics in the early phases of the software development process allows for a better management of the later phases, and a more effective quality assessment when software quality can still be easily affected by preventive or corrective actions. In this paper, we introduce and compare four strategies for defining high-level design metrics. They are based on different sets of assumptions (about the design process) related to a well defined experimental goal they help reach: identify error-prone software parts. In particular, we define ratioscale metrics for cohesion and coupling that show interesting properties. An in-depth experimental validation, conducted on large scale projects demonstrates the usefulness of the metrics we define. 
Abstract-found: 1
Intro-found: 1
Reference: [AE92] <author> W. Agresti and W. Evanco, </author> <title> "Projecting Software Defects from Analyzing Ada Designs," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 18 (11), </volume> <month> November, </month> <year> 1992. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts. <p> Besides this focus on information flow, most of the existing approaches share two common characteristics. (1) They define metrics without making clear assumptions about the contexts (i.e., processes, problem domain, environmental factors, etc.) in which they can be applied (with the exception of <ref> [AE92] </ref>, where this issue was partially addressed). This implies they should have general validity, and be applicable to different environments and problem domains. (2) There are not fully explicit goals, for whose achievement the metrics are defined.
Reference: [BBH93] <author> L. Briand, V. Basili and C. Hetmanski, </author> <title> "Developing Interpretable Models with Optimized Set Reduction for Identifying High Risk Software Components," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 19 (11), </volume> <month> November, </month> <year> 1993. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts.
Reference: [BO87] <author> G. Booch, </author> <title> "Software Engineering with Ada," </title> <publisher> Benjamin/Cumming Publishing Company, Inc., </publisher> <address> Menlo Park, California, </address> <year> 1987. </year>
Reference-contexts: The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services <ref> [BO87, GJM92] </ref>. In this view, a module is the implementation of an Abstract Data Type / Object. In this paper, unless otherwise specified, we will use the term subroutine for the first category, and reserve the term module for the second category.
Reference: [BR88] <author> V. Basili and H. Rombach,"The TAME Project: </author> <title> Towards Improvement-Oriented Software Environments," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 14 (6), </volume> <month> June, </month> <year> 1988. </year> <institution> University of Maryland - CS-TR-3301 - 31 </institution>
Reference-contexts: 1 Introduction Software metrics can help address the most critical issues in software development and provide support for planning, predicting, monitoring, controlling, and evaluating the quality of both software products and processes <ref> [BR88, F91] </ref>. Most existing software metrics attempt to capture characteristics of software code [F91]; however, software code is just one of the artifacts produced during software development, and, moreover, it is only available at a late stage.
Reference: [BTH93] <author> L. Briand, W. Thomas and C. Hetmanski, </author> <title> "Modeling and Managing Risk early in Software Development," </title> <booktitle> International Conference on Software Engineering, </booktitle> <address> Maryland, </address> <month> May </month> <year> 1993 </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts.
Reference: [CAP88] <author> J. Capon, </author> <title> Statistics for the Social Sciences, </title> <publisher> Wadworth publishing company, </publisher> <year> 1988 </year>
Reference-contexts: We report those related to the metrics 2 In addition, in order to confirm the obtained results, we used non-parametric tests for rank distributions such as the Mann-Whitney U test <ref> [CAP88] </ref>. Results appeared to be consistent across techniques and, in order to limit the amount of statistics provided to the reader and preserve the clarity of the text, we only show the results obtained with logistic regression.
Reference: [CY79] <author> L. Constantine, E. Yourdon, </author> <title> "Structured Design," </title> <publisher> Prentice Hall, </publisher> <year> 1979 </year>
Reference-contexts: To define it, we will start from its elementary constituents: software modules. In the literature, there are two commonly accepted definitions of modules. The first one sees a module as a routine, either procedural or functional, and has been used in most of the design measurement publications <ref> [M77, CY79, HK84, R87, S90] </ref>. The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services [BO87, GJM92]. In this view, a module is the implementation of an Abstract Data Type / Object. <p> Next, we will define high-level design metrics for cohesion and coupling, based on the above definitions. It is generally acknowledged that system architecture should have low coupling and high cohesion <ref> [CY79] </ref>. This is assumed to improve the capability of a system to be decomposed in highly independent and easy to understand pieces. However, the reader should bear in mind that high cohesion and low coupling may be conflicting goals, i.e., a tradeoff between the two may exist.
Reference: [DG84] <author> W. Dillon and M. Goldstein, </author> <title> Multivariate Analysis: Methods and Applications, </title> <publisher> Wiley and Sons, </publisher> <year> 1984. </year>
Reference-contexts: In this case, a careful outlier analysis must be performed in order to make sure that University of Maryland - CS-TR-3301 - 24 the observed trend is not the result of few observations <ref> [DG84] </ref> 2 . In particular, we first used univariate logistic regression, to evaluate the impact of each of the metrics in isolation on error-proneness. <p> When looking more carefully at the associations (not only the narrower concept of linear correlation) between metrics, it can be determined that this is the results of strong association between DIC and ISP in GO A DA and TON S. These associations are a typical source of coefficient instability <ref> [DG84] </ref>, e.g., the coefficient of ISP in GOADA varies from -0.9 to -0.39 when DIC is removed from the equation. TIC remains nonsignificant because of its strong linear correlation (R 2 = 0.76) with DIC in the TONS dataset.
Reference: [DoD83] <author> ANSI/MIL-STD-1815A-1983, </author> <title> Reference Manual of the Ada Programming Languages, </title> <type> U.S. </type> <institution> Department of Defense, </institution> <year> 1983 </year>
Reference: [F91] <author> Norman Fenton, </author> <title> "Software Metrics, A Rigorous Approach," </title> <address> Chapman&Hall, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Software metrics can help address the most critical issues in software development and provide support for planning, predicting, monitoring, controlling, and evaluating the quality of both software products and processes <ref> [BR88, F91] </ref>. Most existing software metrics attempt to capture characteristics of software code [F91]; however, software code is just one of the artifacts produced during software development, and, moreover, it is only available at a late stage. <p> 1 Introduction Software metrics can help address the most critical issues in software development and provide support for planning, predicting, monitoring, controlling, and evaluating the quality of both software products and processes [BR88, F91]. Most existing software metrics attempt to capture characteristics of software code <ref> [F91] </ref>; however, software code is just one of the artifacts produced during software development, and, moreover, it is only available at a late stage. <p> In particular, we introduce a family of metrics based on data declaration dependency links (Section 2.2.4). This strategy allows us to introduce metrics for cohesion (Section 2.2.4.1) and coupling (Section 2.2.4.2) <ref> [F91] </ref> that are characterized by interesting properties and are based on consistent principles. Such a consistency is important because it should facilitate future research on quantitative tradeoff mechanisms between coupling and cohesion, i.e., variations can be expressed using consistent measurement units. <p> Metric 8: Ratio of Cohesive Interactions (RCI) for a Software Part. The Ratio of Cohesive Interactions for sp is RCI (sp)= |M (sp)| It is straightforward to prove that RCI (sp) satisfies the above properties 1-3, and that, based on properties 1-3, it is defined on a ratio scale <ref> [F91] </ref>. Furthermore, RCI (sp) can also be computed as a weighted sum of the RCI (m)'s of the single modules m belonging to sp. <p> It is straightforward to prove that IC (sp) and EC (sp) satisfy the above properties 4-6, and that, based on properties 4-6, these metrics are defined on a ratio scale <ref> [F91] </ref>. Each box in Figure 4 represents a module interface. Module interfaces m2 and m3 are located in their parent's interface m1. m2 is assumed to be declared before m3 and therefore visible to m3. Tij and OBJECTij data declarations represent respectively types and objects in module mi.
Reference: [G86] <author> J. Gannon, E. Katz, V. Basili, </author> <title> "Metrics for Ada Packages: an Initial Study," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 29, </volume> <editor> N. </editor> <volume> 7, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts.
Reference: [GJM92] <author> C. Ghezzi, M. Jazayeri, D. Mandrioli, </author> <title> "Fundamentals of Software Engineering," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992 </year>
Reference-contexts: Such a consistency is important because it should facilitate future research on quantitative tradeoff mechanisms between coupling and cohesion, i.e., variations can be expressed using consistent measurement units. Other metric families include: metrics based on declaration counts (Section 2.2.1), metrics based on the USES relationships between modules <ref> [GJM92] </ref> (Section 2.2.2), and metrics based on the IS_COMPONENT_OF relationships [GJM92] (Section 2.2.3). In addition, we experimentally compare and validate the metrics introduced in Section 2 on three NASA projects. The results are shown in Section 3. <p> Other metric families include: metrics based on declaration counts (Section 2.2.1), metrics based on the USES relationships between modules <ref> [GJM92] </ref> (Section 2.2.2), and metrics based on the IS_COMPONENT_OF relationships [GJM92] (Section 2.2.3). In addition, we experimentally compare and validate the metrics introduced in Section 2 on three NASA projects. The results are shown in Section 3. In Section 4, we summarize the lessons we have learned, and outline directions for future research activities based on these lessons. <p> The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services <ref> [BO87, GJM92] </ref>. In this view, a module is the implementation of an Abstract Data Type / Object. In this paper, unless otherwise specified, we will use the term subroutine for the first category, and reserve the term module for the second category. <p> At a higher level of abstraction, modules can be seen as the components of higher level aggregations, as defined below. Definition 1: Library Module Hierarchy (LMH). A library module hierarchy is a hierarchy where nodes are modules and subroutines, arcs between modules are IS_COMPONENT_OF <ref> [GJM92] </ref> relationships, and there is just one top level node, which is a module. In the remainder of this paper, we will define concepts and metrics that can be applied to both modules and LMHs, which are the most significant syntactic aggregation levels below the subsystem level. <p> Therefore, we define the high-level design of a software system as follows. Definition 2: High-level Design The high-level design of a software system is a collection of module and subroutine interfaces related to each other by means of USES <ref> [GJM92] </ref> and IS_COMPONENT_OF relationships. No body information is yet available at this stage. 2 . 2 Strategies to Define High-level Design Metrics In this section, we investigate several strategies for defining high-level design metrics.
Reference: [HK84] <author> S. Henry, D. Kafura, </author> <title> "The Evaluation of Systems' Structure Using Quantitative Metrics," </title> <journal> Software Practice and Experience, </journal> <volume> 14 (6), </volume> <month> June, </month> <year> 1984. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts. <p> To define it, we will start from its elementary constituents: software modules. In the literature, there are two commonly accepted definitions of modules. The first one sees a module as a routine, either procedural or functional, and has been used in most of the design measurement publications <ref> [M77, CY79, HK84, R87, S90] </ref>. The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services [BO87, GJM92]. In this view, a module is the implementation of an Abstract Data Type / Object. <p> As a consequence, a metric of the form (fan_in fan_out) 2 , suggested in numerous occasions in the literature <ref> [HK84, IS88, S90, Z91] </ref>, does not appear to be significant. From a more general perspective, metrics based on imports, regardless of the associated concepts, appear to predict more accurately the error-proneness of software parts.
Reference: [IS88] <author> D. Ince, M. Shepperd, </author> <title> "System Design Metrics: a Review and Perspective," </title> <booktitle> Proc. Software Engineering 88, </booktitle> <pages> pages 23-27, </pages> <year> 1988 </year>
Reference-contexts: This may cause problems in their application, since they may be defined based on implicit assumptions which the context may not satisfy; interpretation, University of Maryland - CS-TR-3301 - 3 since their meaning is not clear; and validation <ref> [IS88, K88] </ref>, since their relevance with respect to a clearly stated goal is not established. The definition of universal metrics (like in physical sciences) is an acceptable long-term goal, which, however, is only achievable after we gain better insights into specific processes from specific perspectives in the short term. <p> As a consequence, a metric of the form (fan_in fan_out) 2 , suggested in numerous occasions in the literature <ref> [HK84, IS88, S90, Z91] </ref>, does not appear to be significant. From a more general perspective, metrics based on imports, regardless of the associated concepts, appear to predict more accurately the error-proneness of software parts.
Reference: [K88] <author> B. Kitchenham, </author> <title> "An Evaluation of Software Structure Metrics," </title> <booktitle> Proc. COMPSAC 88, </booktitle> <year> 1988 </year>
Reference-contexts: This may cause problems in their application, since they may be defined based on implicit assumptions which the context may not satisfy; interpretation, University of Maryland - CS-TR-3301 - 3 since their meaning is not clear; and validation <ref> [IS88, K88] </ref>, since their relevance with respect to a clearly stated goal is not established. The definition of universal metrics (like in physical sciences) is an acceptable long-term goal, which, however, is only achievable after we gain better insights into specific processes from specific perspectives in the short term.
Reference: [LY92] <author> J. Levine, T. Mason, D. Brown, </author> <title> "lex & yacc," </title> <publisher> O'Reilly & Associates, Inc., </publisher> <year> 1992 </year>
Reference-contexts: Tool A tool analyzing the interface parts of Ada source code has been developed in order to capture the design characteristics of these systems. This tool is based on LEX&YACC <ref> [LY92] </ref> and extracts generic high-level design information about the visibility and interactions of the system declarations. This information is consequently used to compute the metrics presented in Section 2.2, and others that might be defined.
Reference: [M77] <author> J. Myers, </author> <title> "An Extension to the Cyclomatic Measure of Program Complexity," </title> <journal> SIGPLAN Notices, </journal> <volume> 12(10) </volume> <pages> 61-64, </pages> <year> 1977 </year>
Reference-contexts: To define it, we will start from its elementary constituents: software modules. In the literature, there are two commonly accepted definitions of modules. The first one sees a module as a routine, either procedural or functional, and has been used in most of the design measurement publications <ref> [M77, CY79, HK84, R87, S90] </ref>. The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services [BO87, GJM92]. In this view, a module is the implementation of an Abstract Data Type / Object.
Reference: [MGBB90] <author> A. Melton, D. Gustafson, J. Bieman, A. Baker, </author> <title> "A Mathematical Perspective for Software Measures Research," </title> <journal> Software Engineering Journal, </journal> <month> September </month> <year> 1990. </year>
Reference-contexts: We introduce four families of metrics, which are based on different types of mathematical abstractions of program designs <ref> [MGBB90] </ref>. In particular, we introduce a family of metrics based on data declaration dependency links (Section 2.2.4). This strategy allows us to introduce metrics for cohesion (Section 2.2.4.1) and coupling (Section 2.2.4.2) [F91] that are characterized by interesting properties and are based on consistent principles.
Reference: [R87] <author> H. D. Rombach, </author> <title> "A Controlled Experiment on the Impact of Software Structure and Maintainability:," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 13 (5), </volume> <month> May, </month> <year> 1987. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts. <p> To define it, we will start from its elementary constituents: software modules. In the literature, there are two commonly accepted definitions of modules. The first one sees a module as a routine, either procedural or functional, and has been used in most of the design measurement publications <ref> [M77, CY79, HK84, R87, S90] </ref>. The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services [BO87, GJM92]. In this view, a module is the implementation of an Abstract Data Type / Object.
Reference: [R90] <author> H. D. Rombach, </author> <title> "Design Measurement: Some Lessons Learned," </title> <journal> IEEE Software, </journal> <month> March </month> <year> 1990. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts.
Reference: [S90] <author> M. Shepperd, </author> <title> "Design Metrics: An Empirical Analysis," </title> <journal> Software Engineering Journal, </journal> <month> January </month> <year> 1990. </year> <institution> University of Maryland - CS-TR-3301 - 32 </institution>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts. <p> To define it, we will start from its elementary constituents: software modules. In the literature, there are two commonly accepted definitions of modules. The first one sees a module as a routine, either procedural or functional, and has been used in most of the design measurement publications <ref> [M77, CY79, HK84, R87, S90] </ref>. The second definition, which takes an objectoriented perspective, sees a module as a collection of type, data, and subroutine definitions, i.e., a provider of computational services [BO87, GJM92]. In this view, a module is the implementation of an Abstract Data Type / Object. <p> As a consequence, a metric of the form (fan_in fan_out) 2 , suggested in numerous occasions in the literature <ref> [HK84, IS88, S90, Z91] </ref>, does not appear to be significant. From a more general perspective, metrics based on imports, regardless of the associated concepts, appear to predict more accurately the error-proneness of software parts.
Reference: [SB91] <author> R. Selby and V. Basili, </author> <title> "Analyzing Error-Prone System Structure," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 17 (2), </volume> <month> February, </month> <year> 1991. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts.
Reference: [Z91] <author> W. Zage, D. Zage, P. McDaniel, I. Khan, </author> <title> "Evaluating Design Metrics on Large-Scale Software," </title> <address> SERC-TR-106-P, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: In this paper, we will focus on high-level design metrics for software systems. A number of studies have been published on software design metrics in recent years. It has been shown that system architecture has an impact on maintainability and error-proneness <ref> [HK84, G86, R87, R90, S90, SB91, Z91, AE92, BTH93, BBH93] </ref>. These studies have attempted to capture the design characteristics affecting the ease of maintaining and debugging a software system. Most of the design metrics are based on information flow between subroutines or declaration counts. <p> As a consequence, a metric of the form (fan_in fan_out) 2 , suggested in numerous occasions in the literature <ref> [HK84, IS88, S90, Z91] </ref>, does not appear to be significant. From a more general perspective, metrics based on imports, regardless of the associated concepts, appear to predict more accurately the error-proneness of software parts.
References-found: 23

