URL: http://www.cs.tamu.edu/faculty/vaidya/618/holygrail.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/618/lectures.html
Root-URL: http://www.cs.tamu.edu
Email: schwarz@informatik.uni-kl.de  mattern@cs.uni-sb.de  
Title: 2 Detecting Causal Relationships in Distributed Computations: In Search of the Holy Grail  
Author: Reinhard Schwarz Friedemann Mattern 
Keyword: Distributed Computation, Causality, Distributed System, Causal Ordering, Logical Time, Vector Time, Global Predicate Detection, Distributed Debugging, Time stamps  
Address: P.O. Box 3049, D 67653 Kaiserslautern, Germany  Im Stadtwald 36, D 66041 Saarbrcken, Germany  
Affiliation: Department of Computer Science, University of Kaiserslautern,  Department of Computer Science, University of Saarland  
Abstract: The paper shows that characterizing the causal relationship between significant events is an important but non-trivial aspect for understanding the behavior of distributed programs. An introduction to the notion of causality and its relation to logical time is given; some fundamental results concerning the characterization of causality are presented. Recent work on the detection of causal relationships in distributed computations is surveyed. The issue of observing distributed computations in a causally consistent way and the basic problems of detecting global predicates are discussed. To illustrate the major difficulties, some typical monitoring and debugging approaches are assessed, and it is demonstrated how their feasibility is severely limited by the fundamental problem to master the complexity of causal relationships. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya and B.R. Badrinath. </author> <title> Recording Distributed Snapshots Based on Causal Order of Message Delivery. </title> <journal> Information Processing Letters 44, </journal> <pages> pp. 317-321, </pages> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: The total event order fi E E is defined by (1) If L (e) &lt; L (e'), then e fi e'. (2) If L (e) = L (e') and i &lt; j holds, then e fi e'. P 1 P 3 <ref> [1] </ref> [4] [5] [7] [4][3][2] e 21 e 22 e 23 15 Clearly, (L, fi) is consistent with causality (i.e., fi fi). Hence, if we order all events by fi, then an event will not occur prior to any other event that might have caused it. <p> This is illustrated in Figure 5. In both scenarios shown, P 3 receives messages m 1 and m 2 at times V (r 1 ) = <ref> [1, 0, 1] </ref> and V (r 2 ) = [2, 3, 4], respectively; the 17 compressed message timestamps are S (m 1 ) = -(1,1)- and S (m 2 ) = -(2, 3)-. <p> In Figure 20, for example, the monitor should delay the delivery of G until F which clearly belongs to C (G) has been delivered. Causal delivery order at M guarantees that M has always a consistent view of the global state <ref> [1, 63] </ref>, i.e., that the sequence of observed events is a linear extension of the causality relation.
Reference: [2] <author> M. Ahamad, P. Hutto, and R. John. </author> <title> Implementing and Programming Causal Distributed Shared Memory. </title> <type> Technical Report GIT-CC-90-49, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: For multicast operations, this technique was successfully employed in the ISIS system [6, 8]. Causally ordered broadcast protocols are useful, for example, for the realization of fault tolerant systems [7]. A similar idea is used in the implementation of causal shared memory <ref> [2, 31] </ref>, a weak form of shared virtual memory. In the theory of distributed computing, causality has also been used for reasoning about the properties of asynchronous systems. <p> This is illustrated in Figure 5. In both scenarios shown, P 3 receives messages m 1 and m 2 at times V (r 1 ) = [1, 0, 1] and V (r 2 ) = <ref> [2, 3, 4] </ref>, respectively; the 17 compressed message timestamps are S (m 1 ) = -(1,1)- and S (m 2 ) = -(2, 3)-. <p> scenario 1 -(1,1)- -(1,2)- P 2 scenario 2 -(1,1)- -(1,2)- m 1 r 1 r 1 r 2 0 2 0 0 2 2 1 0 0 3 2 3 3 1 0 0 2 3 3 2 0 2 2 0 0 1 2 18 ([1, 0, 0] &lt; <ref> [2, 3, 0] </ref> in the second scenario). In particular, P 3 would then be able to determine that it received m 1 out of causal order if in the second scenario m 1 is delayed such that it arrives after m 2 .
Reference: [3] <author> M. Ahuja, T. Carlson, A. Gahlot, and D. Shands. </author> <title> Timestamping Events for Inferring Affects Relation and Potential Causality. </title> <booktitle> Proc. 15th IEEE Int. Computer Software and Application Conference COMPSAC 91, </booktitle> <year> 1991. </year>
Reference-contexts: vector V (e) of cardinal numbers, where V (e)[k] = | C (e)[k] | holds for the k-th component (k = 1,, N) of vector V (e) 2 As an example, the causal history of event e 23 in Figure 1 can be represented by V (e 23 ) = <ref> [3, 3, 0] </ref> because the cardinality of C (e 23 )[1], C (e 23 )[2], and C (e 23 )[3] is 3, 3, and 0, respectively. Figure 2 depicts a distributed computation, with the associated vectors assigned to each event. <p> This is illustrated in Figure 5. In both scenarios shown, P 3 receives messages m 1 and m 2 at times V (r 1 ) = [1, 0, 1] and V (r 2 ) = <ref> [2, 3, 4] </ref>, respectively; the 17 compressed message timestamps are S (m 1 ) = -(1,1)- and S (m 2 ) = -(2, 3)-. <p> From P 3 s point of view, the two different scenarios are indistinguishable. Note that if messages were equipped with the full vector timestamps, then the receiver P 3 would know whether m 1 and m 2 are causally unrelated ([1, 0, 0] || <ref> [0, 3, 0] </ref> in the first scenario) or not P 1 P 3 -(2,1) -(2,1), (3,3)- 1 0 1 4 3 3 0 3 1 0 1 1 0 3 1 5 3 P 1 P 3 scenario 1 -(1,1)- -(1,2)- P 2 scenario 2 -(1,1)- -(1,2)- m 1 r 1 <p> scenario 1 -(1,1)- -(1,2)- P 2 scenario 2 -(1,1)- -(1,2)- m 1 r 1 r 1 r 2 0 2 0 0 2 2 1 0 0 3 2 3 3 1 0 0 2 3 3 2 0 2 2 0 0 1 2 18 ([1, 0, 0] &lt; <ref> [2, 3, 0] </ref> in the second scenario). In particular, P 3 would then be able to determine that it received m 1 out of causal order if in the second scenario m 1 is delayed such that it arrives after m 2 . <p> Nevertheless, it may be interesting to investigate the potential benefits of actual causality (such as indicating potential intra-process concur-rency and yielding more accurate debugging information on the cause for unexpected observed behavior), and to find means to handle the more sophisticated structure of actual causality. In <ref> [3] </ref>, Ahuja et al. discuss these aspects and propose a timestamping scheme which reflects actual causality.
Reference: [4] <author> P. Baldy, H. Dicky, R. Medina, M. Morvan, and J.-F. Vilarem. </author> <title> Efficient Reconstruction of the Causal Relationship in 60 Distributed Computations. </title> <type> Technical Report 92-013, </type> <institution> Laboratoire dInformatique, de Robotique et de Microlectron-ique de Montpellier, France, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: The total event order fi E E is defined by (1) If L (e) &lt; L (e'), then e fi e'. (2) If L (e) = L (e') and i &lt; j holds, then e fi e'. P 1 P 3 [1] <ref> [4] </ref> [5] [7] [4][3][2] e 21 e 22 e 23 15 Clearly, (L, fi) is consistent with causality (i.e., fi fi). Hence, if we order all events by fi, then an event will not occur prior to any other event that might have caused it. <p> This is illustrated in Figure 5. In both scenarios shown, P 3 receives messages m 1 and m 2 at times V (r 1 ) = [1, 0, 1] and V (r 2 ) = <ref> [2, 3, 4] </ref>, respectively; the 17 compressed message timestamps are S (m 1 ) = -(1,1)- and S (m 2 ) = -(2, 3)-. <p> The details of their algorithm and a derivation of its complexity bound may be found in [24]. Recently, Baldy et al. <ref> [4] </ref> proposed an improved variant. <p> Figure 10 shows the resulting algorithm. A formal proof of its correctness may be found in <ref> [4] </ref>; here, we merely present an informal correctness argument. Initially, the algorithm starts with D (e) as a first approximation of V (e). Consider the first iteration of the algorithms outer loop. What the algorithm actually does is to visit all direct causal predecessors of event e. <p> Essentially the same scheme was independently developed by Masuzawa and Tokura. The interested reader is referred to <ref> [4, 42] </ref> for further details. Like Fowlers and Zwaenepoels method, the O (N 2 ) reconstruction algorithm requires random access to all local event streams.
Reference: [5] <author> P.C. Bates and J.C. Wileden. </author> <title> High-Level Debugging of Distributed Systems: The Behavioral Abstraction Approach. </title> <journal> Journal of Systems and Software, </journal> <volume> Vol. 4, No. 3, </volume> <pages> pp. 255-264, </pages> <month> Dec. </month> <year> 1983. </year>
Reference-contexts: The total event order fi E E is defined by (1) If L (e) &lt; L (e'), then e fi e'. (2) If L (e) = L (e') and i &lt; j holds, then e fi e'. P 1 P 3 [1] [4] <ref> [5] </ref> [7] [4][3][2] e 21 e 22 e 23 15 Clearly, (L, fi) is consistent with causality (i.e., fi fi). Hence, if we order all events by fi, then an event will not occur prior to any other event that might have caused it. <p> Detecting such basic patterns of a systems behavior and combining them into high-level abstractions of activity is generally referred to as the behavioral abstraction approach <ref> [5] </ref>. In practice, the detection of behavioral patterns and the detection of global states can be combined by enriching the events with appropriate local state information which is passed to a central monitor for evaluation. In fact, current approaches typically apply such hybrid techniques [9, 48, 54]. <p> One important step towards the detection of behavioral patterns appears in [48]. In this seminal paper, Miller and Choi define a class of distributed predicates, and they present a detection algorithm for that class. Their work is inuenced by the event description language EDL proposed by Bates and Wile-den <ref> [5] </ref>, but in contrast to EDL Millers and Chois specifications do not require global time. Furthermore, not only the relative order, but also the causal relationship between events can be expressed in their formalism.
Reference: [6] <author> K. Birman and T. Joseph. </author> <title> Exploiting Virtual Synchrony in Distributed Systems. </title> <journal> Operating Systems Review, </journal> <volume> Vol. 22, No. 1, </volume> <pages> pp. 123-138, </pages> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: Communication protocols for point-to-point or multicast communications which enforce only a causal delivery order (instead of insisting on synchronous delivery) are based on this idea <ref> [6, 64] </ref>. Here, different communication activities can proceed in parallel, only the delivery of messages has to be delayed according to causality constraints. For multicast operations, this technique was successfully employed in the ISIS system [6, 8]. <p> Here, different communication activities can proceed in parallel, only the delivery of messages has to be delayed according to causality constraints. For multicast operations, this technique was successfully employed in the ISIS system <ref> [6, 8] </ref>. Causally ordered broadcast protocols are useful, for example, for the realization of fault tolerant systems [7]. A similar idea is used in the implementation of causal shared memory [2, 31], a weak form of shared virtual memory.
Reference: [7] <author> K. Birman. </author> <title> The Process Group Approach to Reliable Distributed Computing. </title> <type> Technical Report, </type> <institution> Computer Science Department, Cornell University, </institution> <address> Ithaca, New York, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: For multicast operations, this technique was successfully employed in the ISIS system [6, 8]. Causally ordered broadcast protocols are useful, for example, for the realization of fault tolerant systems <ref> [7] </ref>. A similar idea is used in the implementation of causal shared memory [2, 31], a weak form of shared virtual memory. In the theory of distributed computing, causality has also been used for reasoning about the properties of asynchronous systems. <p> The total event order fi E E is defined by (1) If L (e) &lt; L (e'), then e fi e'. (2) If L (e) = L (e') and i &lt; j holds, then e fi e'. P 1 P 3 [1] [4] [5] <ref> [7] </ref> [4][3][2] e 21 e 22 e 23 15 Clearly, (L, fi) is consistent with causality (i.e., fi fi). Hence, if we order all events by fi, then an event will not occur prior to any other event that might have caused it.
Reference: [8] <author> K. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight Causal and Atomic Group Multicast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 9, No. 3, </volume> <pages> pp. 272-314, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: Here, different communication activities can proceed in parallel, only the delivery of messages has to be delayed according to causality constraints. For multicast operations, this technique was successfully employed in the ISIS system <ref> [6, 8] </ref>. Causally ordered broadcast protocols are useful, for example, for the realization of fault tolerant systems [7]. A similar idea is used in the implementation of causal shared memory [2, 31], a weak form of shared virtual memory. <p> Thus, in applications like, e.g., causally ordered message delivery protocols <ref> [8, 14, 64] </ref> where such detailed knowledge is required, some additional book-keeping and computational effort is needed to locally restore the suppressed information.
Reference: [9] <author> B. Bruegge and P. Hibbard. </author> <title> Generalized Path Expressions. </title> <journal> The Journal of Systems and Software, </journal> <volume> Vol. 2, No. 2, </volume> <pages> pp. 265-276, </pages> <year> 1983. </year>
Reference-contexts: In practice, the detection of behavioral patterns and the detection of global states can be combined by enriching the events with appropriate local state information which is passed to a central monitor for evaluation. In fact, current approaches typically apply such hybrid techniques <ref> [9, 48, 54] </ref>. One important step towards the detection of behavioral patterns appears in [48]. In this seminal paper, Miller and Choi define a class of distributed predicates, and they present a detection algorithm for that class. <p> particular, negation (like, e.g., Habans and Weigels @ operator) is excluded. (Negation is problematic because it is often difficult or even impossible to define when exactly a negated event first occurs, in particular, if upper bounds for transmission delays are not known.) Basically, data path expressions extend generalized path expressions <ref> [9] </ref> with a concurrency operator such that both causal dependence and causal independence between event occurrences can be expressed.
Reference: [10] <author> K.M. Chandy and L. Lamport. </author> <title> Distributed Snapshots: Determining Global States of Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 3, No. 1, </volume> <pages> pp. 63-75, </pages> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: For example, determining a consistent global snapshot of a distributed computation <ref> [10, 24, 45] </ref> essentially requires to find a set of local snapshots such that the causal relation between all events that are included in the snapshots is respected in the following sense: if e' is contained in the global snapshot formed by the union of the local snapshots, and e fi <p> It should be noted, however, that detecting possibly F or definitely F is quite different from the classical stable predicate detection problem <ref> [10] </ref>.
Reference: [11] <author> B. Charron-Bost. </author> <title> Combinatorics and Geometry of Consistent Cuts: Application to Concurrency Theory. In Distributed Algorithms, </title> <editor> J.-C. Bermond and M. Raynal (eds.), </editor> <publisher> Springer-Verlag, LNCS 392, </publisher> <pages> pp. 45-56, </pages> <year> 1989. </year>
Reference-contexts: Causality plays also an important role in the exploitation of maximum parallelism, i.e., for distributed applications which are required to run as asynchronous as possible. An analysis of the causality relation can therefore serve as an abstract concurrency measure of an algorithm <ref> [11, 20] </ref>. Note that all events which are not causally related can be executed in parallel at least in principle.
Reference: [12] <author> B. Charron-Bost. </author> <title> Concerning the Size of Logical Clocks in Distributed Systems. </title> <journal> Information Processing Letters 39, </journal> <pages> pp. 11-16, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The question remains whether it is really necessary to use time vectors of that size. Is there a way to find a better timestamping algorithm based on smaller time vectors which truly characterizes causality? As it seems, the answer is negative. Charron-Bost showed in <ref> [12] </ref> that causality can be characterized only by vector timestamps of size N. More precisely, she showed that the causal order (E, fi) of a distributed computation of N processes has in general dimension N. <p> The cardinality of a smallest real izer of (X, &lt;) is called the dimension of (X, &lt;), denoted dim (X, &lt;). We cite Ores characterization of the dimension of a partial order from <ref> [12] </ref>: Theorem 4.4 (Ore) A finite partially ordered set (X, &lt;') can be isomorphically embedded into (R , &lt;) if and only if k dim (X, &lt;'). The following theorem is the key result of [12]: 25 Theorem 4.5 For every N there exist processes P 1 ,, P N forming <p> We cite Ores characterization of the dimension of a partial order from <ref> [12] </ref>: Theorem 4.4 (Ore) A finite partially ordered set (X, &lt;') can be isomorphically embedded into (R , &lt;) if and only if k dim (X, &lt;'). The following theorem is the key result of [12]: 25 Theorem 4.5 For every N there exist processes P 1 ,, P N forming a distributed computation, and a set E of events produced by that computation, such that dim (E, fi) = N. For a proof the reader is referred to [12]. <p> theorem is the key result of <ref> [12] </ref>: 25 Theorem 4.5 For every N there exist processes P 1 ,, P N forming a distributed computation, and a set E of events produced by that computation, such that dim (E, fi) = N. For a proof the reader is referred to [12]. <p> But still, it is not immediately evident that for a more sophisticated type of vector order than &lt; a smaller vector could not suffice to characterize causality, although the result of Charron-Bost seems to indicate that this is rather unlikely. At least we have the following fact <ref> [12] </ref>: Corollary 4.6 Let T denote a set of an arbitrary kind of timestamps assigned to the events of arbitrary computations of N processes. Any partial order (T, &lt;') that characterizes causality must have a dimension dim (T, &lt;') N. Proof. (By contradiction).
Reference: [13] <author> B. Charron-Bost, C. Delporte-Gallet, and H. Fauconnier. </author> <title> Local and Temporal Predicates in Distributed Systems. </title> <type> Technical Report, </type> <institution> LITP, IBP, Universit Paris 7, France, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice [32, 44, 51, 73]. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice <ref> [13, 15, 44, 56] </ref> as shown in in P 1 , and each horizontal line represents an event in P 2 . <p> Stable predicates have the following remarkable property (see also <ref> [33, 34, 13] </ref>): Lemma 6.6 For a stable predicate F defined on the global states of a distributed computation, possibly F and definitely F are equivalent. Proof. As remarked above, definitely F implies possibly F. Conversely, suppose that possibly F holds for a given computation. <p> There exists another class of predicates for which it is possible to generalize from one observer to all observers, namely predicates which depend on a property local to a single process <ref> [33, 34, 13] </ref>. An in-depth treatment of such observer-independent predicates may be found in [13]. Because until recently only the detection of stable predicates was discussed in the literature, Lemma 6.6 might explain why modal operators such as possibly or definitely were not considered there. <p> There exists another class of predicates for which it is possible to generalize from one observer to all observers, namely predicates which depend on a property local to a single process [33, 34, 13]. An in-depth treatment of such observer-independent predicates may be found in <ref> [13] </ref>. Because until recently only the detection of stable predicates was discussed in the literature, Lemma 6.6 might explain why modal operators such as possibly or definitely were not considered there. <p> By executing the computation in 41 such a sequential fashion, we reduce the computational complexity of the detection scheme from O (K N to O (KN), or more precisely, to O (E). Approaches similar to the one sketched here are described in <ref> [13, 26, 39] </ref>. Executing a computation in the proposed manner is, however, somewhat difficult to achieve in a distributed system where computations are typically nondeterministic. Blocking all processes but one to obtain the required sequential execution would generally cause an unbearable distortion of the systems normal behavior.
Reference: [14] <author> B. Charron-Bost, F. Mattern, and G. Tel. </author> <title> Synchronous and Asynchronous Communication in Distributed Computations. </title> <journal> Distributed Computing, </journal> <note> to appear. </note>
Reference-contexts: Thus, in applications like, e.g., causally ordered message delivery protocols <ref> [8, 14, 64] </ref> where such detailed knowledge is required, some additional book-keeping and computational effort is needed to locally restore the suppressed information.
Reference: [15] <author> R. Cooper and K. Marzullo. </author> <title> Consistent Detection of Global Predicates. </title> <booktitle> Proc. ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <address> Santa Cruz, California, </address> <pages> pp. 163-173, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In distributed debugging, detecting global predicates is a key issue, and the causality relation is of utmost importance <ref> [15, 27, 30, 41] </ref>. Again, the problem is to obtain a consistent view in order to correctly evaluate the global predicate. Analyzing the causal relationship between events is also helpful for the detection of race conditions and other synchronization errors one of the most difficult problems in distributed programming. <p> Consequently, without going into the details of the detection algorithm presented in [66], our discussion reveals that Spezialettis and Kearns notion of concurrency must be incomplete in some way or the other. In fact, Cooper and Marzullo <ref> [15] </ref> present a simple scenario where the proposed algorithm fails to detect a global event that actually occurred. 31 The discussion presented in this section supports our claim that detecting causal relationships in distributed computations is far from being trivial. <p> The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice [32, 44, 51, 73]. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice <ref> [13, 15, 44, 56] </ref> as shown in in P 1 , and each horizontal line represents an event in P 2 . <p> In <ref> [15] </ref>, Cooper and Marzullo address this issue, and they introduce two useful predicate qualifiers, defined as follows: Definition 6.4 Let F denote a predicate defined on the global states of a distributed computation, let L denote the state lattice of that computation, and let F holds at p mean that F <p> In <ref> [15] </ref>, two algorithms based on vector time for the detection of possibly F and definitely F in finite computations (i.e., computations where E is finite) are presented. Let us call |C ( p)| the level of intersection point p. <p> If we consider such intractable predicates, we have to confine ourselves to simpler, although maybe less powerful modalities. In <ref> [15] </ref>, Cooper and Marzullo propose a modality which is based on a single observation, the real-time observation of the computation, which we define as follows: Definition 6.7 The total order (E, &lt;) of the events of a distributed computation ordered according to their real-time occurrence is called the real-time observation of <p> This, of course, raises the question to what degree such an inuence of the observer on the observed system is tolerable we would certainly not accept a central scheduler that forces a synchronized sequential execution of the computation. In <ref> [15] </ref>, a qualified global predicate called currently F is defined as follows: Definition 6.8 The global predicate currently F defined on the local process states of a distributed computation is said to hold, if F is still satisfied at the moment at which it is reported by some dedi cated monitoring <p> The details of the algorithm may be found in <ref> [15] </ref>. Interestingly, the monitor M does not actually perform a real-time observation because, according to rule (2), the event notification messages are not necessarily received in real-time order by M. <p> Avoiding this problem would require to introduce some additional blocking. For example, one could block each process on every relevant event not just invalidating events as suggested in <ref> [15] </ref>; alternatively, each process could be blocked after sending an ACK message, until F has been decided. Both methods would, of course, mean to substantially increase the intrusiveness of the algorithm.
Reference: [16] <author> C. Diehl and C. Jard. </author> <title> Interval Approximations and Message Causality in Distributed Systems. </title> <booktitle> Proc. of the 9th Annual Symposium on Theoretical Aspects of Computer Science STACS 92, </booktitle> <editor> A. Finkel, M. Jantzen (eds.), </editor> <publisher> Springer-Verlag, LNCS 577, </publisher> <pages> pp. 363-374, </pages> <year> 1992. </year>
Reference-contexts: The aim is to trade accuracy for ease of computation. In <ref> [16] </ref>, Diehl and Jard propose interval orders [22] as a means to obtain event timestamps of pairs of integers with relatively little computational effort. If the causal structure of a distributed computation is in fact that of an interval order, then their scheme yields timestamps which actually characterize causality.
Reference: [17] <author> C.J. Fidge. </author> <title> Timestamps in Message-Passing Systems That Preserve the Partial Ordering. </title> <booktitle> Proc. 11th Australian Computer Science Conference, University of Queensland, </booktitle> <pages> pp. 55-66, </pages> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: In fact, the resulting algorithm is essentially the same as the one given in <ref> [17] </ref> or in [44]. There, the vectors defined as in Observation 2.3 are called time vectors, and the general concept is called vector time 3 . We state the operational definition from [44] here: Definition 2.5 Let P 1 ,, P N denote the processes of a distributed computation. <p> Several authors re-invented time vectors for their purposes, with different motivation, and often without knowing of each other. To the best of our knowledge, the first applications of dependency tracking vectors [70] appeared in the early 80s in the field of distributed database management [21, 74]. In <ref> [17] </ref> and [44], however, vector time is introduced as a generalization of Lamports logical time, and its mathematical structure and its general properties are analyzed. 11 We conclude our discussion of vector time with a knowledge-based interpretation.
Reference: [18] <author> C.J. Fidge. </author> <title> Partial Orders for Parallel Debugging. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 24, No. 1, </volume> <pages> pp. 183-194, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Consequently, the timestamps of all subexpressions should in some way or the other affect the satisfaction of a global specification. This, however, rules out simple timestamp inheritance such as those considered above. The question of how to specify the occurrence of non-atomic events is addressed by Fidge in <ref> [18, 19] </ref>. Like Haban and Weigel, he aims at the detection of significant global state changes which are char P 1 B P 3 1 2 0 0 0 0 0 2 54 acterized by specifications based on local (i.e., primitive) predicate expressions. <p> Similar definitions for G 1 G 2 as well as for G 1 G 2 are feasible as long as G 1 and G 2 are primitive specifications local to the same process. The details may be found in <ref> [18, 19] </ref>. Unfortunately, it is rather difficult if not impossible to extend the relations between primitive specifications to arbitrary global specifications in a sensible way. In particular, assigning meaningful intervals to compound specifications is an open problem.
Reference: [19] <author> C.J. Fidge. </author> <title> Dynamic Analysis of Event Orderings in Message-Passing Systems. </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Australian National University, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: Consequently, the timestamps of all subexpressions should in some way or the other affect the satisfaction of a global specification. This, however, rules out simple timestamp inheritance such as those considered above. The question of how to specify the occurrence of non-atomic events is addressed by Fidge in <ref> [18, 19] </ref>. Like Haban and Weigel, he aims at the detection of significant global state changes which are char P 1 B P 3 1 2 0 0 0 0 0 2 54 acterized by specifications based on local (i.e., primitive) predicate expressions. <p> Similar definitions for G 1 G 2 as well as for G 1 G 2 are feasible as long as G 1 and G 2 are primitive specifications local to the same process. The details may be found in <ref> [18, 19] </ref>. Unfortunately, it is rather difficult if not impossible to extend the relations between primitive specifications to arbitrary global specifications in a sensible way. In particular, assigning meaningful intervals to compound specifications is an open problem.
Reference: [20] <author> C.J. Fidge. </author> <title> Logical Time in Distributed Computing Systems. </title> <journal> IEEE Computer, </journal> <volume> Vol. 24, No. 8, </volume> <pages> pp. 28-33, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: Causality plays also an important role in the exploitation of maximum parallelism, i.e., for distributed applications which are required to run as asynchronous as possible. An analysis of the causality relation can therefore serve as an abstract concurrency measure of an algorithm <ref> [11, 20] </ref>. Note that all events which are not causally related can be executed in parallel at least in principle.
Reference: [21] <author> M.J. Fischer and A. Michael. </author> <title> Sacrificing Serializability to Attain High Availability of Data in an Unreliable Network. </title> <booktitle> Proc. ACM SIGACT-SIGOPS Symposium on Principles of Database Systems, </booktitle> <pages> pp. 70-75, </pages> <year> 1982. </year> <month> 61 </month>
Reference-contexts: Several authors re-invented time vectors for their purposes, with different motivation, and often without knowing of each other. To the best of our knowledge, the first applications of dependency tracking vectors [70] appeared in the early 80s in the field of distributed database management <ref> [21, 74] </ref>. In [17] and [44], however, vector time is introduced as a generalization of Lamports logical time, and its mathematical structure and its general properties are analyzed. 11 We conclude our discussion of vector time with a knowledge-based interpretation.
Reference: [22] <author> P.C. Fishburn. </author> <title> Interval Orders and Interval Graphs. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: The aim is to trade accuracy for ease of computation. In [16], Diehl and Jard propose interval orders <ref> [22] </ref> as a means to obtain event timestamps of pairs of integers with relatively little computational effort. If the causal structure of a distributed computation is in fact that of an interval order, then their scheme yields timestamps which actually characterize causality. In general, however, this condition is not satisfied.
Reference: [23] <author> R.W. Floyd. </author> <title> Algorithm 97, Shortest Path. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 5, </volume> <editor> p. </editor> <volume> 345, </volume> <year> 1962. </year>
Reference-contexts: That is, a graph that represents a distributed computation comprising N processes contains N local chains. As a result, the general algorithms are too inefficient; the Floyd-Warshall algorithm, for example, requires O (K 3 ) steps to determine the reachability matrix for a directed, acyclic graph containing K vertices <ref> [23, 72] </ref>. For the special case of time diagrams, more efficient solutions are feasible. of an event e E. Basically, the algorithm determines V (e) by applying a recursive backward search on the directed graph, and by counting the events belonging to C (e).
Reference: [24] <author> J. Fowler and W. Zwaenepoel. </author> <title> Causal Distributed Breakpoints. </title> <booktitle> Proc. 10th Int. Conference on Distributed Computing Systems, Paris, France, </booktitle> <pages> pp. 134-141, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: For example, determining a consistent global snapshot of a distributed computation <ref> [10, 24, 45] </ref> essentially requires to find a set of local snapshots such that the causal relation between all events that are included in the snapshots is respected in the following sense: if e' is contained in the global snapshot formed by the union of the local snapshots, and e fi <p> The approach described here is due to Fowler and Zwaenepoel <ref> [24] </ref>. Basically, their time vectors only reflect direct dependencies, while vector time takes into account also transitive dependencies. By ignoring indirect causal relationships, it suffices to attach only a single event index (i.e., a scalar instead of a vector) to each message that is transmitted. <p> In order to determine the transitive causal dependencies necessary for the full time vectors, V (e) is derived from D (e) by recursively retracing the direct dependencies, i.e., by computing the transitive left-closure of the direct dependence relation. In <ref> [24] </ref>, Fowler and Zwaenepoel present a simple procedure which transforms D (e) into the corresponding V (e). <p> The details of their algorithm and a derivation of its complexity bound may be found in <ref> [24] </ref>. Recently, Baldy et al. [4] proposed an improved variant.
Reference: [25] <author> J. Gait. </author> <title> A Probe Effect in Concurrent Programs. </title> <journal> Software Practice and Experience, </journal> <volume> Vol. 16, No. 3, </volume> <pages> pp. 225-233, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: Blocking all processes but one to obtain the required sequential execution would generally cause an unbearable distortion of the systems normal behavior. That is, the so-called probe effect <ref> [25] </ref> induced by such a method may lead to a completely abnormal behavior of the system which would render the conclusions drawn from its observation almost irrelevant.
Reference: [26] <author> V.K. Garg and B. Waldecker. </author> <title> Detection of Unstable Predicates in Distributed Programs. </title> <booktitle> Proc. 12th Conference on the Foundation of Software Technology and Theoretical Computer Science, </booktitle> <editor> R. Shyamasundra (ed.), </editor> <publisher> Springer-Verlag, LNCS 652, </publisher> <pages> pp. 253-264, </pages> <year> 1992. </year>
Reference-contexts: It is therefore computationally expensive. While in general the situation for possibly F is not much better, there exist certain predicates F for which possibly F can be detected quite efficiently. Garg and Waldecker give a more formal characterization of these predicates in <ref> [26] </ref>; in essence, their definitions comprise global predicates which are decomposable into locally detectable parts such as conjunctions or disjunctions of local predicates whose validity can be established in isolation. <p> By executing the computation in 41 such a sequential fashion, we reduce the computational complexity of the detection scheme from O (K N to O (KN), or more precisely, to O (E). Approaches similar to the one sketched here are described in <ref> [13, 26, 39] </ref>. Executing a computation in the proposed manner is, however, somewhat difficult to achieve in a distributed system where computations are typically nondeterministic. Blocking all processes but one to obtain the required sequential execution would generally cause an unbearable distortion of the systems normal behavior. <p> For instance, one could put all traced events in event queues, one for each process, and fetch the next event from the respective queue instead of performing an execution step of a single process. This approach was taken, for example, by Garg and Waldecker <ref> [26] </ref>. The number of relevant events produced in the course of a distributed computation could be quite substantial, however, and therefore the queues may rapidly grow.
Reference: [27] <author> D. Haban and W. Weigel. </author> <title> Global Events and Global Breakpoints in Distributed Systems. </title> <booktitle> Proc. 21th Annual Hawaii Int. Conference on System Sciences, </booktitle> <pages> pp. 166-175, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: In distributed debugging, detecting global predicates is a key issue, and the causality relation is of utmost importance <ref> [15, 27, 30, 41] </ref>. Again, the problem is to obtain a consistent view in order to correctly evaluate the global predicate. Analyzing the causal relationship between events is also helpful for the detection of race conditions and other synchronization errors one of the most difficult problems in distributed programming. <p> In fact, instead of comparing whole time vectors, the necessary computations can often be reduced even further, according to the following lemma. A proof is straightforward and may be found, for example, in <ref> [27] </ref>. Lemma 3.4 For two events e E i and e' E j , e e', we have (1) e fi e' iff V (e)[i] V (e')[i]. <p> Thus, their algorithm can only detect a limited class of behavioral specifications. In fair 50 ness to their work, it should be noted that Millers and Chois approach works on-the-y and does not require complex mechanisms such as vector time. Haban and Weigel <ref> [27] </ref> address the problem of more sophisticated specifications. They aim at the detection of arbitrary causal relations between events, and they assume that vector time is available. <p> The details of the detection scheme may be found in <ref> [27] </ref>. An important aspect of the algorithm is its requirement that each event may contribute to a global event specification at most once; i.e., as soon as an event has been used to satisfy part of a specification, this event is consumed with respect to that specification. <p> According to the definition given in <ref> [27] </ref>, the specification @B (C, D), which reads there is no event of type B between an event of type C and an event of type D, is satisfied, because the first occurrence C 1 of C is concealed by the second, C 2 . <p> It follows by induction that this delivery rule ensures causal delivery order. It is also easy to see that eventually every notification message becomes deliverable. Thus, by adding this algorithm to the protocol described in <ref> [27] </ref>, the satisfaction of specifications like @F (E, G) in Figure 20 can indeed be correctly detected. <p> Is it sat 53 isfied? If we suppose that B is detected later than A, then according to the definition given in <ref> [27] </ref> it is not because the subexpression (A || B) inherits the timestamp V (B), which means that V (A || B) &lt; V (C) does not hold as required. <p> If, however, B is detected before A, then V (A || B) = V (A), and (A || B) fi C is satisfied. To exclude such ambiguities, Haban et al. [28] revised the original definitions of <ref> [27] </ref>. In particular, they define V (A || B) = sup-V (A), V (B)- which means that (A || B) fi C does not hold in Figure 21 regardless of the order in which A and B are detected. <p> However, instead of assigning unique time instants to event specifications as in <ref> [27] </ref>, he proposes to determine appropriate state intervals instead.
Reference: [28] <author> D. Haban, S. Zhou, D. Maurer, and R. Wilhelm. </author> <title> Specification and Detection of Global Breakpoints in Distributed Systems. </title> <type> Technical Report SFB124 - 08/1991, </type> <institution> Universitt des Saarlandes, Saarbrcken, Germany, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: If, however, B is detected before A, then V (A || B) = V (A), and (A || B) fi C is satisfied. To exclude such ambiguities, Haban et al. <ref> [28] </ref> revised the original definitions of [27]. In particular, they define V (A || B) = sup-V (A), V (B)- which means that (A || B) fi C does not hold in Figure 21 regardless of the order in which A and B are detected.
Reference: [29] <author> D. Harel and A. Pnueli. </author> <title> On the Development of Reactive Systems. In Logics and Models of Concurrent Systems, </title> <editor> K. Apt (ed.), Springer-Verlag, </editor> <booktitle> NATO ASI Series F, </booktitle> <volume> Vol. 13, </volume> <pages> pp. 477-498, </pages> <year> 1985. </year>
Reference-contexts: For application domains like, e.g., debugging, the effects of intrusion are clearly undesirable they are the price we have to pay for the efficiency of the detection algorithm. In cases, however, where the detection of global states is an integral part of the system (e.g., in distributed reactive systems <ref> [29, 41] </ref> where the system itself is essentially a monitor receiving stimuli from its environment through a network of sensors, and reacting to these stimuli through actuators) a moderate amount of intrusion may be tolerable as long as sufficient potential for concurrency is retained.
Reference: [30] <author> W. Hseush and G.E. Kaiser. </author> <title> Modeling Concurrency in Parallel Debugging. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 25, No. 3, </volume> <pages> pp. 11-20, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In distributed debugging, detecting global predicates is a key issue, and the causality relation is of utmost importance <ref> [15, 27, 30, 41] </ref>. Again, the problem is to obtain a consistent view in order to correctly evaluate the global predicate. Analyzing the causal relationship between events is also helpful for the detection of race conditions and other synchronization errors one of the most difficult problems in distributed programming. <p> It seems that such problems are inherent to all specifications based on atomic event occurrences, even if time intervals instead of time instants are used. Another approach to behavioral pattern detection is due to Hseush and Kaiser. They propose a formalism called data path expressions <ref> [30] </ref> which bears a strong resemblance to Habans and Weigels global event specifications, but avoids most of their problematical aspects in particular, negation (like, e.g., Habans and Weigels @ operator) is excluded. (Negation is problematic because it is often difficult or even impossible to define when exactly a negated event first <p> For a given data path expression, Hseush and Kaiser construct an equivalent predecessor automaton which is able to recognize that expression. Predecessor automata are similar to, but extend the concept of finite-state automata. In <ref> [30] </ref>, a rule set for recursively transforming data path expressions into their recognizing automata is presented. For brevity, we do not further discuss the concept of predecessor automata and the recognition process.
Reference: [31] <author> P. Hutto and M. Ahamad. </author> <title> Slow Memory: Weakening Consistency to Enhance Concurrency in Distributed Shared Memories. </title> <booktitle> Proc. 10th Int. Conference on Distributed Computing Systems, Paris, France, </booktitle> <pages> pp. 302-309, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: For multicast operations, this technique was successfully employed in the ISIS system [6, 8]. Causally ordered broadcast protocols are useful, for example, for the realization of fault tolerant systems [7]. A similar idea is used in the implementation of causal shared memory <ref> [2, 31] </ref>, a weak form of shared virtual memory. In the theory of distributed computing, causality has also been used for reasoning about the properties of asynchronous systems.
Reference: [32] <author> D.B. Johnson and W. Zwaenepoel. </author> <title> Recovery in Distributed Systems Using Optimistic Message Logging and Check-pointing. </title> <journal> Journal of Algorithms, </journal> <volume> Vol. 11, No. 3, </volume> <pages> pp. 462-491, </pages> <month> Sep. </month> <year> 1990. </year>
Reference-contexts: Hence, every observation induces a totally ordered sequence of consistent global states. The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice <ref> [32, 44, 51, 73] </ref>. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice [13, 15, 44, 56] as shown in in P 1 , and each horizontal line represents an event in P 2 .
Reference: [33] <author> S. Katz and D. Peled. </author> <title> Interleaving Set Temporal Logic. </title> <booktitle> Theoretical Computer Science 75, </booktitle> <pages> pp. 263-287, </pages> <year> 1990. </year>
Reference-contexts: Before continuing our discussion, we need to elaborate these concepts a little further. Our discussion is based on some notions which have their origin in concurrency theory and in temporal logic. In particular, the subsequent presentation shares many concepts with Katzs and Peleds work on interleaving set temporal logic <ref> [33, 34] </ref>, with Pratts geometric model of concurrency [56], and with Reisigs causality based partial order semantics of non-sequential systems [60, 61]. <p> The intersection points corresponding to an observed event sequence form a path <ref> [33] </ref> in the lattice diagram: Definition 6.3 Let L be the state lattice of a distributed computation comprising N processes, and let C (p) denote the consistent cut that corresponds to a valid intersection point p. (1) A sequence p 0 , p 1 , p 2 , of valid intersection <p> Coopers and Marzullos predicate qualifiers are closely related to some modalities known from modal and temporal logic [40]. For example, there is a direct correspondence between the two qualifiers possibly and definitely and the sequence quantifiers EF and AF of Katzs and Peleds interleaving set temporal logic <ref> [33, 34] </ref>. Note, however, that we excluded conicts from our conceptual framework. Therefore, we only deal with a single execution (E, fi) of a distributed system and its possible observations. <p> Stable predicates have the following remarkable property (see also <ref> [33, 34, 13] </ref>): Lemma 6.6 For a stable predicate F defined on the global states of a distributed computation, possibly F and definitely F are equivalent. Proof. As remarked above, definitely F implies possibly F. Conversely, suppose that possibly F holds for a given computation. <p> There exists another class of predicates for which it is possible to generalize from one observer to all observers, namely predicates which depend on a property local to a single process <ref> [33, 34, 13] </ref>. An in-depth treatment of such observer-independent predicates may be found in [13]. Because until recently only the detection of stable predicates was discussed in the literature, Lemma 6.6 might explain why modal operators such as possibly or definitely were not considered there. <p> Events occurring at the same process, for example, are totally ordered by the causality relation, although some of them are presumably not causally related. One of the reasons why most contemporary work only considers potential causality or essential causality, as it is called in <ref> [33] </ref> is that the order of events within each process is uniquely determined by the local thread of control. It may therefore be argued that although not causally enforced, the local event order is in fact total all observers of a process will see the same sequence of events.
Reference: [34] <author> S. Katz and D. Peled. </author> <title> Verification of Distributed Programs Using Representative Interleaving Sequences. </title> <journal> Distributed Computing, </journal> <volume> Vol. 6, </volume> <pages> pp. 107-120, </pages> <year> 1992. </year>
Reference-contexts: Before continuing our discussion, we need to elaborate these concepts a little further. Our discussion is based on some notions which have their origin in concurrency theory and in temporal logic. In particular, the subsequent presentation shares many concepts with Katzs and Peleds work on interleaving set temporal logic <ref> [33, 34] </ref>, with Pratts geometric model of concurrency [56], and with Reisigs causality based partial order semantics of non-sequential systems [60, 61]. <p> Coopers and Marzullos predicate qualifiers are closely related to some modalities known from modal and temporal logic [40]. For example, there is a direct correspondence between the two qualifiers possibly and definitely and the sequence quantifiers EF and AF of Katzs and Peleds interleaving set temporal logic <ref> [33, 34] </ref>. Note, however, that we excluded conicts from our conceptual framework. Therefore, we only deal with a single execution (E, fi) of a distributed system and its possible observations. <p> Stable predicates have the following remarkable property (see also <ref> [33, 34, 13] </ref>): Lemma 6.6 For a stable predicate F defined on the global states of a distributed computation, possibly F and definitely F are equivalent. Proof. As remarked above, definitely F implies possibly F. Conversely, suppose that possibly F holds for a given computation. <p> There exists another class of predicates for which it is possible to generalize from one observer to all observers, namely predicates which depend on a property local to a single process <ref> [33, 34, 13] </ref>. An in-depth treatment of such observer-independent predicates may be found in [13]. Because until recently only the detection of stable predicates was discussed in the literature, Lemma 6.6 might explain why modal operators such as possibly or definitely were not considered there.
Reference: [35] <author> J.P. Kearns and B. Koodalattupuram. </author> <title> Immediate Ordered Service in Distributed Systems. </title> <booktitle> Proc. 9th Int. Conference on Distributed Computing Systems, </booktitle> <address> Newport Beach, California, </address> <pages> pp. 611-618, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Causal delivery order at M guarantees that M has always a consistent view of the global state [1, 63], i.e., that the sequence of observed events is a linear extension of the causality relation. There is a straightforward protocol which implements causal delivery order <ref> [35, 58, 64] </ref>: (1) For each process P i , M maintains a counter observed [i], initialized to 0. (2) On receiving a notification message m = (e, i) indicating the occurrence of event e at process P i with vector timestamp V (e), the delivery of m is delayed until
Reference: [36] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 21, No. 7, </volume> <pages> pp. 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: The causality relation fi of Definition 1.1 is actually identical to the happened before relation defined by Lamport in <ref> [36] </ref>. We prefer to use the term causality rather than happened before because P 1 P 3 e 32 e 11 e 23 time a real-time instant 6 the relation defined in Definition 1.1 is causal rather than temporal. <p> Clearly, the converse arguments are equally valid for both cases. 3.2 Real Time and Lamport Time The analysis of causality is closely related to temporal reasoning. As everyday experience tells us, every cause must precede its effect. Names such as happened before <ref> [36] </ref> and is concurrent with for relations which are causal rather than temporal reect this fact. However, such a terminology although quite suggestive is somewhat misleading. In this section, we briey discuss the relationship between time and causality. <p> Fortunately, it is possible to realize a system of logical clocks which 14 guarantees that the timestamps derived are still consistent with causality. This was shown by Lamport in <ref> [36] </ref>. <p> local predeces sor, then L (r) = L (s) + 1; if r has a (unique) local predecessor e', then L (r) = max-L (s), L (e')- + 1. can be implemented easily with a scheme similar to the one of Definition 2.5, but with simple integers instead of vectors <ref> [36] </ref>. One can easily see that by construction, Lamport time (L, &lt;) is consistent with causality. However, as Figure 3 shows, it does not characterize causality: L (e 11 ) &lt; L (e 22 ) although e 11 and e 22 are causally independent. <p> The partial order semantics of distributed computations expressed by the happened before relation <ref> [36] </ref> as opposed to the traditional interleaving semantics where an underlying total order of event occurrences (i.e., the real-time order) is implicitly assumed triggered major progress in the theory of distributed computing.
Reference: [37] <author> T.J. LeBlanc and J.M. Mellor-Crummey. </author> <title> Debugging Parallel Programs with Instant Replay. </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 36, No. 4, </volume> <pages> pp. 471-482, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: One might, for example, try to employ a deterministic scheduling discipline to enforce reproducibility of the execution. Unfortunately, centralized scheduling is not appropriate in a distributed setting as it would severely limit the potential for parallelism. Therefore, a better solution is to provide an execution replay facility <ref> [37, 38] </ref>. This mechanism is based on a trace of the outcome of all nondeterministic steps which each process took during an original execution of the distributed system (e.g., the selection of an incoming message, or reading some volatile data). <p> It should be noted, however, that the problem of replaying distributed computations is difficult in its own right, and may require substantial computational effort. For a more detailed discussion, see <ref> [37, 38] </ref>. To continue our discussion of the navigation scheme sketched above, consider, for example, the distributed computation depicted in Figure 14 and the global predicate F ((x = 1) (y = 1)), where x and y are local variables of P 1 and P 2 , respectively.
Reference: [38] <author> E. Leu, A. Schiper, and A. Zramdini. </author> <title> Efficient Execution Replay for Distributed Memory Architectures. </title> <booktitle> Proc. 2nd European Distributed Memory Computing Conference, </booktitle> <address> Munich, </address> <publisher> Germany, </publisher> <editor> A. Bode (ed.), </editor> <publisher> Springer-Verlag, LNCS 487, </publisher> <pages> pp. 315-324, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: One might, for example, try to employ a deterministic scheduling discipline to enforce reproducibility of the execution. Unfortunately, centralized scheduling is not appropriate in a distributed setting as it would severely limit the potential for parallelism. Therefore, a better solution is to provide an execution replay facility <ref> [37, 38] </ref>. This mechanism is based on a trace of the outcome of all nondeterministic steps which each process took during an original execution of the distributed system (e.g., the selection of an incoming message, or reading some volatile data). <p> It should be noted, however, that the problem of replaying distributed computations is difficult in its own right, and may require substantial computational effort. For a more detailed discussion, see <ref> [37, 38] </ref>. To continue our discussion of the navigation scheme sketched above, consider, for example, the distributed computation depicted in Figure 14 and the global predicate F ((x = 1) (y = 1)), where x and y are local variables of P 1 and P 2 , respectively.
Reference: [39] <author> Y. Manabe and M. Imase. </author> <title> Global Conditions in Debugging Distributed Programs. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> No. 15, </volume> <pages> pp. 62-69, </pages> <year> 1992. </year> <month> 62 </month>
Reference-contexts: By executing the computation in 41 such a sequential fashion, we reduce the computational complexity of the detection scheme from O (K N to O (KN), or more precisely, to O (E). Approaches similar to the one sketched here are described in <ref> [13, 26, 39] </ref>. Executing a computation in the proposed manner is, however, somewhat difficult to achieve in a distributed system where computations are typically nondeterministic. Blocking all processes but one to obtain the required sequential execution would generally cause an unbearable distortion of the systems normal behavior. <p> Tracing only nondeterministic events (instead of all events which may affect F) diminishes the probe effect, reduces the amount of trace data, and 42 allows to detect global predicates during replay with virtually no (logical) detection delay <ref> [39] </ref>. Moreover, during replay the execution speed may be reduced in order to match the observers processing capacity, and on each re-execution the observer may concentrate on particular aspects, thus reducing the space requirements for each analysis.
Reference: [40] <author> Z. Manna and A. Pnueli. </author> <title> The Temporal Logic of Reactive and Concurrent Systems. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Coopers and Marzullos predicate qualifiers are closely related to some modalities known from modal and temporal logic <ref> [40] </ref>. For example, there is a direct correspondence between the two qualifiers possibly and definitely and the sequence quantifiers EF and AF of Katzs and Peleds interleaving set temporal logic [33, 34]. Note, however, that we excluded conicts from our conceptual framework.
Reference: [41] <author> K. Marzullo and G. Neiger. </author> <title> Detection of Global State Predicates. </title> <booktitle> Proc. 5th Workshop on Distributed Algorithms (WDAG-91), Delphi, </booktitle> <address> Greece, </address> <publisher> S.Toueg, </publisher> <editor> P.G. Spirakis, L. Kirousis (eds.), </editor> <publisher> Springer-Verlag, LNCS 579, </publisher> <pages> pp. 254-272, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: In distributed debugging, detecting global predicates is a key issue, and the causality relation is of utmost importance <ref> [15, 27, 30, 41] </ref>. Again, the problem is to obtain a consistent view in order to correctly evaluate the global predicate. Analyzing the causal relationship between events is also helpful for the detection of race conditions and other synchronization errors one of the most difficult problems in distributed programming. <p> For application domains like, e.g., debugging, the effects of intrusion are clearly undesirable they are the price we have to pay for the efficiency of the detection algorithm. In cases, however, where the detection of global states is an integral part of the system (e.g., in distributed reactive systems <ref> [29, 41] </ref> where the system itself is essentially a monitor receiving stimuli from its environment through a network of sensors, and reacting to these stimuli through actuators) a moderate amount of intrusion may be tolerable as long as sufficient potential for concurrency is retained.
Reference: [42] <author> T. Masuzawa and N. Tokura. </author> <title> A Causal Distributed Breakpoint Algorithm for Distributed Debugger. </title> <booktitle> Proc. ICICE Fall Conference, SD-1-8, </booktitle> <pages> pp. 6-373 - 6-374, </pages> <year> 1992. </year>
Reference-contexts: Essentially the same scheme was independently developed by Masuzawa and Tokura. The interested reader is referred to <ref> [4, 42] </ref> for further details. Like Fowlers and Zwaenepoels method, the O (N 2 ) reconstruction algorithm requires random access to all local event streams.
Reference: [43] <author> F. Mattern. </author> <title> Algorithms for Distributed Termination Detection. </title> <journal> Distributed Computing, </journal> <volume> Vol. 2, </volume> <pages> pp. 161-175, </pages> <year> 1987. </year>
Reference-contexts: Causal consistency has many important applications. For example, determining consistent recovery points is a well-known problem in the field of distributed database management. For determining deadlocks or detecting the termination of a distributed computation <ref> [43] </ref>, the global view of the computation state must also be causally consistent in order to prevent so-called phantom deadlocks and false termination states. In distributed debugging, detecting global predicates is a key issue, and the causality relation is of utmost importance [15, 27, 30, 41].
Reference: [44] <author> F. Mattern. </author> <title> Virtual Time and Global States in Distributed Systems. </title> <booktitle> Proc. Workshop on Parallel and Distributed Algorithms, </booktitle> <address> Chateau de Bonas, </address> <month> Oct. </month> <year> 1988, </year> <editor> M. Cosnard et al. (eds.), </editor> <publisher> Elsevier / North Holland, </publisher> <pages> pp. 215-226, </pages> <year> 1989. </year>
Reference-contexts: In fact, the resulting algorithm is essentially the same as the one given in [17] or in <ref> [44] </ref>. There, the vectors defined as in Observation 2.3 are called time vectors, and the general concept is called vector time 3 . We state the operational definition from [44] here: Definition 2.5 Let P 1 ,, P N denote the processes of a distributed computation. <p> In fact, the resulting algorithm is essentially the same as the one given in [17] or in <ref> [44] </ref>. There, the vectors defined as in Observation 2.3 are called time vectors, and the general concept is called vector time 3 . We state the operational definition from [44] here: Definition 2.5 Let P 1 ,, P N denote the processes of a distributed computation. <p> Several authors re-invented time vectors for their purposes, with different motivation, and often without knowing of each other. To the best of our knowledge, the first applications of dependency tracking vectors [70] appeared in the early 80s in the field of distributed database management [21, 74]. In [17] and <ref> [44] </ref>, however, vector time is introduced as a generalization of Lamports logical time, and its mathematical structure and its general properties are analyzed. 11 We conclude our discussion of vector time with a knowledge-based interpretation. <p> introduced the concept of vector time, we now study its relation to causality and real time. 3.1 Characterizing Causality with Vector Time Vector time has several interesting properties, for example, its mathematical structure is similar to Minkowskis relativistic space-time [49] in the sense that causal histories correspond to light cones <ref> [44] </ref>. Most interestingly, however, the structure of vector time is isomorphic to the causality structure of the underlying distributed computation. In this section, we prove this fact by rephrasing Lemma 2.2 in terms of time vectors. <p> Hence, every observation induces a totally ordered sequence of consistent global states. The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice <ref> [32, 44, 51, 73] </ref>. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice [13, 15, 44, 56] as shown in in P 1 , and each horizontal line represents an event in P 2 . <p> The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice [32, 44, 51, 73]. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice <ref> [13, 15, 44, 56] </ref> as shown in in P 1 , and each horizontal line represents an event in P 2 .
Reference: [45] <author> F. Mattern. </author> <title> Efficient Algorithms for Distributed Snapshots and Global Virtual Time Approximation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 18, </volume> <pages> pp. 423-434, </pages> <year> 1993. </year>
Reference-contexts: For example, determining a consistent global snapshot of a distributed computation <ref> [10, 24, 45] </ref> essentially requires to find a set of local snapshots such that the causal relation between all events that are included in the snapshots is respected in the following sense: if e' is contained in the global snapshot formed by the union of the local snapshots, and e fi
Reference: [46] <author> R. Medina. </author> <title> Incremental Garbage Collection of Causal Relationship Computation in Distributed Systems. </title> <booktitle> Proc. 5th IEEE Symposium on Parallel and Distributed Processing, Irving, </booktitle> <address> Texas, </address> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: On the other hand, if events occur very frequently, then it might be impossible to record the complete event traces which are required for a reconstruction of all vector timestamps, even in cases where state-saving techniques such as those described in <ref> [46] </ref> are applicable. In such cases, vector time has to be maintained on-the-fly by the classical scheme described earlier. Typically, on-line monitors belong to this type of applications; there, complex reconstruction schemes are prohibitive anyway because they are too time expensive.
Reference: [47] <author> S. Meldal, S. Sankar, and J. Vera. </author> <title> Exploiting Locality in Maintaining Potential Causality. </title> <booktitle> Proc. 10th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Montreal, Canada, </address> <pages> pp. 231-239, </pages> <year> 1991. </year>
Reference-contexts: Figure 4 shows an example of how the technique works. For large systems, the proposed method can result in substantial savings in communication bandwidth. However, it suffers from a slight deficiency, as mentioned by Meldal et al. in <ref> [47] </ref>. By compressing the message timestamps, we lose immediate access to some information about the causal relationship between different messages sent to the same receiver. <p> In general, however, this condition is not satisfied. Nevertheless, it might be fruitful to develop new programming paradigms which induce causal orders that are guaranteed to be as easy to handle as, for example, interval orders. A different approach is pursued by Meldal et al. in <ref> [47] </ref>. Like Diehl and Jard, they aim at a more efficient computation of the causality relation by restricting the problem domain.
Reference: [48] <author> B.P. Miller and J.-D. Choi. </author> <title> Breakpoints and Halting in Distributed Programs. </title> <booktitle> Proc. 8th Int. Conference on Distributed Computing Systems, </booktitle> <pages> pp. 316-323, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: In practice, the detection of behavioral patterns and the detection of global states can be combined by enriching the events with appropriate local state information which is passed to a central monitor for evaluation. In fact, current approaches typically apply such hybrid techniques <ref> [9, 48, 54] </ref>. One important step towards the detection of behavioral patterns appears in [48]. In this seminal paper, Miller and Choi define a class of distributed predicates, and they present a detection algorithm for that class. <p> In fact, current approaches typically apply such hybrid techniques [9, 48, 54]. One important step towards the detection of behavioral patterns appears in <ref> [48] </ref>. In this seminal paper, Miller and Choi define a class of distributed predicates, and they present a detection algorithm for that class.
Reference: [49] <editor> H. Minkowski. Raum und Zeit. In H.A. Lorentz, A. Einstein, and H. Minkowski: Das Relativittsprinzip. Eine Sammlung von Abhandlungen. Teubner-Verlag, </editor> <booktitle> Leipzig, </booktitle> <pages> pp. 56-68, </pages> <year> 1915. </year>
Reference-contexts: able to obtain within the system. 3 Causality and Time Having introduced the concept of vector time, we now study its relation to causality and real time. 3.1 Characterizing Causality with Vector Time Vector time has several interesting properties, for example, its mathematical structure is similar to Minkowskis relativistic space-time <ref> [49] </ref> in the sense that causal histories correspond to light cones [44]. Most interestingly, however, the structure of vector time is isomorphic to the causality structure of the underlying distributed computation. In this section, we prove this fact by rephrasing Lemma 2.2 in terms of time vectors.
Reference: [50] <author> R.H.B. Netzer and B.P. Miller. </author> <title> Optimal Tracing and Replay for Debugging Message-Passing Parallel Programs. </title> <booktitle> Proc. </booktitle> <address> Supercomputing92, Minneapolis, MN, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Here, the causal relation determines the sequence in 7 which events must be processed so that cause and effect appear in the correct order. When replaying trace data, the amount of stored information can significantly be reduced by appropriately representing the causal structure of the computation <ref> [50] </ref>. Causality plays also an important role in the exploitation of maximum parallelism, i.e., for distributed applications which are required to run as asynchronous as possible. An analysis of the causality relation can therefore serve as an abstract concurrency measure of an algorithm [11, 20].
Reference: [51] <author> M. Nielsen, G. Plotkin, and G. Winskel. </author> <title> Petri Nets, Event Structures and Domains, Part I. </title> <journal> Theoretical Computer Science, </journal> <volume> Vol. 13, </volume> <pages> pp. 85-108, </pages> <year> 1981. </year>
Reference-contexts: It should be noted that our model does not explicitly deal with conicts, as is common practice in Petri net theory or related concurrency theories <ref> [51, 56, 73] </ref>. This does, however, not imply that the local algorithms are required to work deterministically, i.e., that the possibility of conflicts is excluded. <p> A discussion of further interesting properties of causal histories may be found in <ref> [51, 57, 73] </ref>. Lemma 2.2 Let e, e' E, e e'. Causality and causal history are related as follows: (1) e fi e' iff e C (e'). Proof. <p> Hence, every observation induces a totally ordered sequence of consistent global states. The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice <ref> [32, 44, 51, 73] </ref>. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice [13, 15, 44, 56] as shown in in P 1 , and each horizontal line represents an event in P 2 .
Reference: [52] <author> E. Ochmanski. </author> <title> Inevitability in Concurrent Systems. </title> <journal> Information Processing Letters 25, </journal> <pages> pp. 221-225, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The use of vector time and the immense number of valid intersections render an on-the-y application of the above algorithms almost prohibitive. As a final remark, it should be noted that possibly and definitely can be defined without referring to complete paths, i.e., observations. In <ref> [52] </ref>, Ochmanski introduces the concept of inevitable global states an equivalent to definitely and extends this notion even to systems for which an observation in the sense of Definition 6.1 does not exist; it is, however, doubtful, whether an efficient algorithm for the detection of inevitability in non-observable systems is feasible.
Reference: [53] <author> P. Panangaden and K. Taylor. </author> <title> Concurrent Common Knowledge: Defining Agreement for Asynchronous Systems. </title> <journal> Distributed Computing, </journal> <volume> Vol. 6, No. 2, </volume> <pages> pp. 73-93, </pages> <year> 1992. </year>
Reference-contexts: A similar idea is used in the implementation of causal shared memory [2, 31], a weak form of shared virtual memory. In the theory of distributed computing, causality has also been used for reasoning about the properties of asynchronous systems. In <ref> [53] </ref>, for example, it is argued that in many cases causality can serve as a more appropriate substitute for the traditional notion of real-time, and that reasoning based on the causal rather than on the temporal structure of a system is the correct level of abstraction in a distributed setting.
Reference: [54] <author> M.K. Ponamgi, W. Hseush, and G.E. Kaiser. </author> <title> Debugging Multithreaded Programs with MPD. </title> <journal> IEEE Software, </journal> <pages> pp. 37-43, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In practice, the detection of behavioral patterns and the detection of global states can be combined by enriching the events with appropriate local state information which is passed to a central monitor for evaluation. In fact, current approaches typically apply such hybrid techniques <ref> [9, 48, 54] </ref>. One important step towards the detection of behavioral patterns appears in [48]. In this seminal paper, Miller and Choi define a class of distributed predicates, and they present a detection algorithm for that class. <p> Ponamgi et al. have implemented a debugging tool for multithreaded programs based on data path expressions and predecessor automata <ref> [54] </ref>. However, their prototype tool lacks support for a more convenient specification of high-level patterns of behavior. In [54], it is also noted that an auto 56 matic reduction of data path expressions would be desirable in order to obtain more compact predecessor automata, thus making recognition more efficient. <p> Ponamgi et al. have implemented a debugging tool for multithreaded programs based on data path expressions and predecessor automata <ref> [54] </ref>. However, their prototype tool lacks support for a more convenient specification of high-level patterns of behavior. In [54], it is also noted that an auto 56 matic reduction of data path expressions would be desirable in order to obtain more compact predecessor automata, thus making recognition more efficient.
Reference: [55] <author> V. Pratt. </author> <title> Modeling Concurrency with Partial Orders. </title> <journal> Int. Journal of Parallel Programming, </journal> <volume> Vol. 15, No. 1, </volume> <pages> pp. 33-71, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: It is now widely accepted that the traditional Newto-nian model of distributed computations, which is based on the notion of absolute global time, is insufficient to reect the relativistic aspects of systems which are asynchronous, physically distributed, and suffer from noticeable communication delays <ref> [55] </ref>. The partial order semantics of distributed computations expressed by the happened before relation [36] as opposed to the traditional interleaving semantics where an underlying total order of event occurrences (i.e., the real-time order) is implicitly assumed triggered major progress in the theory of distributed computing.
Reference: [56] <author> V. Pratt. </author> <title> Modeling Concurrency with Geometry. </title> <booktitle> Proc. 18th Annual Symposium on Principles of Programming Languages (POPL-91), </booktitle> <pages> pp. 311-322, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: It should be noted that our model does not explicitly deal with conicts, as is common practice in Petri net theory or related concurrency theories <ref> [51, 56, 73] </ref>. This does, however, not imply that the local algorithms are required to work deterministically, i.e., that the possibility of conflicts is excluded. <p> Our discussion is based on some notions which have their origin in concurrency theory and in temporal logic. In particular, the subsequent presentation shares many concepts with Katzs and Peleds work on interleaving set temporal logic [33, 34], with Pratts geometric model of concurrency <ref> [56] </ref>, and with Reisigs causality based partial order semantics of non-sequential systems [60, 61]. <p> The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice [32, 44, 51, 73]. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice <ref> [13, 15, 44, 56] </ref> as shown in in P 1 , and each horizontal line represents an event in P 2 .
Reference: [57] <author> V. Pratt. </author> <title> Arithmetic + Logic + Geometry = Concurrency. </title> <booktitle> Proc. </booktitle> <editor> LATIN92, I. Simon (ed), </editor> <publisher> Springer-Verlag, LNCS 583, </publisher> <pages> pp. 430-447, </pages> <year> 1992. </year>
Reference-contexts: A discussion of further interesting properties of causal histories may be found in <ref> [51, 57, 73] </ref>. Lemma 2.2 Let e, e' E, e e'. Causality and causal history are related as follows: (1) e fi e' iff e C (e'). Proof. <p> This can be done, for example, by using a causal delivery order protocol as will be described in Section 7. Basically, such a protocol ensures that the delivery of notification messages obeys the so-called triangle inequality <ref> [57] </ref>, requiring that direct notification paths are always shorter than indirect channels via some intermediate process, such that the direct messages arrive first and that the event itself is observed before its effects.
Reference: [58] <author> M. Raynal, A. Schiper, and S. Toueg. </author> <title> The Causal Ordering Abstraction and a Simple Way to Implement it. </title> <journal> Informa 63 tion Processing Letters 39, </journal> <pages> pp. 343-350, </pages> <month> Sep. </month> <year> 1991. </year>
Reference-contexts: Causal delivery order at M guarantees that M has always a consistent view of the global state [1, 63], i.e., that the sequence of observed events is a linear extension of the causality relation. There is a straightforward protocol which implements causal delivery order <ref> [35, 58, 64] </ref>: (1) For each process P i , M maintains a counter observed [i], initialized to 0. (2) On receiving a notification message m = (e, i) indicating the occurrence of event e at process P i with vector timestamp V (e), the delivery of m is delayed until
Reference: [59] <author> W. Reisig. </author> <title> A Strong Part of Concurrency. In Advances in Petri Nets, </title> <editor> G. Rozenberg (ed.), </editor> <publisher> Springer-Verlag, LNCS 266, </publisher> <pages> pp. 238-272, </pages> <year> 1987. </year>
Reference-contexts: This view, which has been advocated since a long time by the theory of Petri nets <ref> [59] </ref>, is now also shared by most researchers working on distributed operating systems as a recent debate among experts shows [62]. 2 Causal History and Vector Time In this section, we aim at a practical method to determine the causal relationship between events.
Reference: [60] <author> W. Reisig. </author> <title> Temporal Logic and Causality in Concurrent Systems. </title> <booktitle> Proc. </booktitle> <editor> Concurrency88, F.H. Vogt (ed.), </editor> <publisher> Springer-Verlag, LNCS 335, </publisher> <pages> pp. 121-139, </pages> <year> 1988. </year>
Reference-contexts: In particular, the subsequent presentation shares many concepts with Katzs and Peleds work on interleaving set temporal logic [33, 34], with Pratts geometric model of concurrency [56], and with Reisigs causality based partial order semantics of non-sequential systems <ref> [60, 61] </ref>. It should be noted, however, that most of these theories are based on more abstract models (where, for example, the notion of processes in the sense of linearly ordered disjoint subsets of events does not exist), and that a different terminology is 32 used in most cases.
Reference: [61] <author> W. Reisig. </author> <title> Parallel Composition of Liveness. </title> <type> Technical Report SFB342/30/91A, </type> <institution> Technische Universitt Mnchen, Germany, </institution> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: In particular, the subsequent presentation shares many concepts with Katzs and Peleds work on interleaving set temporal logic [33, 34], with Pratts geometric model of concurrency [56], and with Reisigs causality based partial order semantics of non-sequential systems <ref> [60, 61] </ref>. It should be noted, however, that most of these theories are based on more abstract models (where, for example, the notion of processes in the sense of linearly ordered disjoint subsets of events does not exist), and that a different terminology is 32 used in most cases.
Reference: [62] <author> R. van Renesse. </author> <title> Causal Controversy at Le Mont St.-Michel. </title> <journal> ACM Operating Systems Review, </journal> <volume> Vol. 27, No. 2, </volume> <pages> pp. 44-53, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: This view, which has been advocated since a long time by the theory of Petri nets [59], is now also shared by most researchers working on distributed operating systems as a recent debate among experts shows <ref> [62] </ref>. 2 Causal History and Vector Time In this section, we aim at a practical method to determine the causal relationship between events.
Reference: [63] <author> A. Sandoz and A. Schiper. </author> <title> A Characterization of Consistent Distributed Snapshots Using Causal Order. </title> <type> Technical Report 92-14, </type> <institution> Dpartement dInformatique, Ecole Polytechnique Fdrale de Lausanne, Switzerland, </institution> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: In Figure 20, for example, the monitor should delay the delivery of G until F which clearly belongs to C (G) has been delivered. Causal delivery order at M guarantees that M has always a consistent view of the global state <ref> [1, 63] </ref>, i.e., that the sequence of observed events is a linear extension of the causality relation.
Reference: [64] <author> A. Schiper, J. Eggli, and A. Sandoz. </author> <title> A New Algorithm to Implement Causal Ordering. </title> <booktitle> Proc. Workshop on Distributed Algorithms, Nice, France, </booktitle> <editor> J.-C. Bermond and M. Raynal (eds.), </editor> <publisher> Springer-Verlag, LNCS 392, </publisher> <pages> pp. 219-232, </pages> <year> 1989. </year>
Reference-contexts: Communication protocols for point-to-point or multicast communications which enforce only a causal delivery order (instead of insisting on synchronous delivery) are based on this idea <ref> [6, 64] </ref>. Here, different communication activities can proceed in parallel, only the delivery of messages has to be delayed according to causality constraints. For multicast operations, this technique was successfully employed in the ISIS system [6, 8]. <p> Thus, in applications like, e.g., causally ordered message delivery protocols <ref> [8, 14, 64] </ref> where such detailed knowledge is required, some additional book-keeping and computational effort is needed to locally restore the suppressed information. <p> Causal delivery order at M guarantees that M has always a consistent view of the global state [1, 63], i.e., that the sequence of observed events is a linear extension of the causality relation. There is a straightforward protocol which implements causal delivery order <ref> [35, 58, 64] </ref>: (1) For each process P i , M maintains a counter observed [i], initialized to 0. (2) On receiving a notification message m = (e, i) indicating the occurrence of event e at process P i with vector timestamp V (e), the delivery of m is delayed until
Reference: [65] <author> M. Singhal and A. Kshemkalyani. </author> <title> An Efficient Implementation of Vector Clocks. </title> <journal> Information Processing Letters 43, </journal> <pages> pp. 47-52, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: The first observation motivates the second, since, if two processes never directly or indirectly interact, they will never receive new knowledge about each others causal histories, and hence the corresponding vector entries remain unchanged. Based on Observation 4.1, Singhal and Kshemkalyani <ref> [65] </ref> propose an improved implementation technique for vector clocks which typically saves communication bandwidth at the cost of slightly increased storage requirements. <p> An approach to recover the full timestamp of each message requiring O (N 2 ) space at each process may be found in <ref> [65] </ref>. 4.2 Reconstructing Time Vectors In the previous section, it was shown how message timestamps can be efficiently coded so as to save communication bandwidth in typical cases. The technique is especially valuable if the number N of processes is large.
Reference: [66] <author> M. Spezialetti and J.P. Kearns. </author> <title> Simultaneous Regions: A Framework for the Consistent Monitoring of Distributed Systems. </title> <booktitle> Proc. 9th Int. Conference on Distributed Computing Systems, </booktitle> <address> Newport Beach, California, </address> <pages> pp. 61-68, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Anyhow, whatever actual size of vectors is required for a realization of vector time, region numbers require vectors of essentially the same size. An approach for the detection of concurrency based on comparing the numbers of concurrent regions is described by Spezialetti and Kearns in <ref> [66] </ref>. In their model, it is assumed that there exists an event monitor which observes the local state changes (i.e., events) and determines global state changes by combining appropriate concurrent local events into so-called global events. <p> According to Observation 1.3, however, concurrency is not an equivalence relation; it follows that (N, =) cannot suffice to characterize concurrency. Consequently, without going into the details of the detection algorithm presented in <ref> [66] </ref>, our discussion reveals that Spezialettis and Kearns notion of concurrency must be incomplete in some way or the other.
Reference: [67] <author> J.M. Stone. </author> <title> Visualizing Concurrent Processes. </title> <type> Technical Report RC 12973, </type> <institution> IBM T.J. Watson Research Center, </institution> <month> July </month> <year> 1987. </year>
Reference-contexts: A concurrency map (together with its feasible transformations) implicitly represents all possible total event orderings which are consistent with causality. In <ref> [67] </ref> it is shown that for every distributed computation the construction of a concurrency map is in fact possible, and that for two given events e and e', e || e' holds if and only if there is a transformation of the concurrency map such that e and e' occur in
Reference: [68] <author> J.M. Stone. </author> <title> Debugging Concurrent Processes: A Case Study. </title> <booktitle> Proc. SIGPLAN Conf. on Programming Language Design and Implementation, Atlanta, Georgia, </booktitle> <pages> pp. 145-153, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: This approach was proposed by Stone, who suggested the use of concurrency maps to support the visual analysis of concurrent processes <ref> [68, 69] </ref>. To this end, the local event streams of a distributed computation are partitioned into so-called dependence blocks.
Reference: [69] <author> J.M. Stone. </author> <title> A Graphical Representation of Concurrent Processes. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 24, No. 1, </volume> <pages> pp. 226-235, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: This approach was proposed by Stone, who suggested the use of concurrency maps to support the visual analysis of concurrent processes <ref> [68, 69] </ref>. To this end, the local event streams of a distributed computation are partitioned into so-called dependence blocks. <p> Figure 12 shows a con-currency map of the computation depicted in Figure 11. For more details about the construction of con-currency maps, the interested reader is referred to <ref> [69] </ref>.
Reference: [70] <author> R. Strom and S. Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 3, No. 3, </volume> <pages> pp. 204-226, </pages> <year> 1985. </year>
Reference-contexts: Actually, the concept of vector time cannot be attributed to a single person. Several authors re-invented time vectors for their purposes, with different motivation, and often without knowing of each other. To the best of our knowledge, the first applications of dependency tracking vectors <ref> [70] </ref> appeared in the early 80s in the field of distributed database management [21, 74].
Reference: [71] <author> E. Szpilrajn. Sur lextension de lordre partiel. </author> <title> Fund. </title> <journal> Math. </journal> <volume> 16, </volume> <pages> pp. 386-389, </pages> <year> 1930. </year>
Reference-contexts: In general, many different observations of a single computation exist; a special case is a computation consisting of only a single process, namely, a sequential program: Here, exactly one observation is possible. Interestingly, it follows from Szpilrajns theorem <ref> [71] </ref> that the intersection of all possible observations, i.e., what all observations have in common, is precisely the causality relation (E, fi) which is the essence of the computation.
Reference: [72] <author> S. Warshall. </author> <title> A Theorem on Boolean Matrices. </title> <journal> Journal of the ACM, </journal> <volume> Vol. 9, </volume> <pages> pp. 11-12, </pages> <year> 1962. </year>
Reference-contexts: That is, a graph that represents a distributed computation comprising N processes contains N local chains. As a result, the general algorithms are too inefficient; the Floyd-Warshall algorithm, for example, requires O (K 3 ) steps to determine the reachability matrix for a directed, acyclic graph containing K vertices <ref> [23, 72] </ref>. For the special case of time diagrams, more efficient solutions are feasible. of an event e E. Basically, the algorithm determines V (e) by applying a recursive backward search on the directed graph, and by counting the events belonging to C (e).
Reference: [73] <author> G. Winskel. </author> <title> An Introduction to Event Structures. Proc. Workshop on Linear Time, Branching Time and Partial Order in Logics and Models for Concurrency, Noordwijkerhout, The Netherlands, </title> <editor> J.W. de Bakker, W.-P. de Roever, and G. Rozenberg (eds.), </editor> <publisher> Springer-Verlag, LNCS 354, </publisher> <pages> pp 364-397, </pages> <year> 1988. </year>
Reference-contexts: It should be noted that our model does not explicitly deal with conicts, as is common practice in Petri net theory or related concurrency theories <ref> [51, 56, 73] </ref>. This does, however, not imply that the local algorithms are required to work deterministically, i.e., that the possibility of conflicts is excluded. <p> A discussion of further interesting properties of causal histories may be found in <ref> [51, 57, 73] </ref>. Lemma 2.2 Let e, e' E, e e'. Causality and causal history are related as follows: (1) e fi e' iff e C (e'). Proof. <p> An entity that is capable of obtaining a specific observation is called an observer. The required finite cardinality of -e' E | e' e- the so-called axiom of finite causes <ref> [73] </ref> ensures that, even for an infinite set of events, the observation is fair in the sense that every event on every process is observed within finite time. <p> Hence, every observation induces a totally ordered sequence of consistent global states. The set of all consistent cuts of a computation together with operations and has the mathematical structure of a lattice <ref> [32, 44, 51, 73] </ref>. Therefore, a convenient method to graphically represent the consistent cuts of a distributed computation is an N-dimensional state lattice [13, 15, 44, 56] as shown in in P 1 , and each horizontal line represents an event in P 2 .
Reference: [74] <author> G.T.J. Wuu and A.J. Bernstein. </author> <title> Efficient Solutions to the Replicated Log and Dictionary Problems. </title> <booktitle> Proc. ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 233-242, </pages> <year> 1984. </year>
Reference-contexts: Several authors re-invented time vectors for their purposes, with different motivation, and often without knowing of each other. To the best of our knowledge, the first applications of dependency tracking vectors [70] appeared in the early 80s in the field of distributed database management <ref> [21, 74] </ref>. In [17] and [44], however, vector time is introduced as a generalization of Lamports logical time, and its mathematical structure and its general properties are analyzed. 11 We conclude our discussion of vector time with a knowledge-based interpretation.
References-found: 74

