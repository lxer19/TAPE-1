URL: http://www.is.cs.cmu.edu/papers/speech/EUROSPEECH97/EUROSPEECH97-yeyi.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: Email: fyyw,waibelg@cs.cmu.edu  
Title: STATISTICAL ANALYSIS OF DIALOGUE STRUCTURE  
Author: Ye-Yi Wang and Alex Waibel 
Address: Pittsburgh, PA 15213, USA  
Affiliation: Language Technology Institute School of Computer Science Carnegie Mellon University  
Abstract: We introduce a statistical model for dialogues. We describe a dynamic programming algorithm that can be used to bracket a dialogue into segments and label each segment with its speech act. We evaluate the performance of the model. We also use this model for language modelling and get perplexity reduction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Young. </author> <title> Dialog Structure and Plan Recognition in Spontaneous Spoken Dialog. </title> <booktitle> In EU-ROSPEECH 1993, </booktitle> <volume> volume 2, </volume> <pages> pages 1169-1172, </pages> <year> 1993. </year>
Reference-contexts: 1 INTRODUCTION Dialogue structure provides important information for spoken language understanding. This structure comprises the current topic, discourse state, and speech act, etc. Many researchers used topic information to reduce the perplexity of a task <ref> [1, 2] </ref>. In our experiments, we also found that dialogue structure information also helps to reduce ambiguities and improve spoken language translation performance.
Reference: [2] <author> R. Kneser and V. Steinbiss. </author> <title> On the Dynamic Adaptation of Stochastic Language Models. </title> <booktitle> In ICASSP '93, </booktitle> <volume> volume 2, </volume> <pages> pages 586-589. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: 1 INTRODUCTION Dialogue structure provides important information for spoken language understanding. This structure comprises the current topic, discourse state, and speech act, etc. Many researchers used topic information to reduce the perplexity of a task <ref> [1, 2] </ref>. In our experiments, we also found that dialogue structure information also helps to reduce ambiguities and improve spoken language translation performance.
Reference: [3] <author> B. J. Grosz and C. J. Sidner. </author> <title> Attention, intention, and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12 (3), </volume> <year> 1986. </year>
Reference-contexts: Many researchers used topic information to reduce the perplexity of a task [1, 2]. In our experiments, we also found that dialogue structure information also helps to reduce ambiguities and improve spoken language translation performance. While knowledge-based approaches are used widely and successfully in dialogue structure analysis <ref> [3, 4] </ref>, they require intensive human effort in defining linguistic structures and developing grammars to detect the structures. We would like to build a model that is able to learn from examples to analyze dialogue structures. [5] used a statistical approach for dialogue analysis.
Reference: [4] <author> Diane J. Litman and James F. Allen. </author> <title> Discourse processing and commonsense plans. </title> <booktitle> In Intentions in Communications, </booktitle> <year> 1990. </year>
Reference-contexts: Many researchers used topic information to reduce the perplexity of a task [1, 2]. In our experiments, we also found that dialogue structure information also helps to reduce ambiguities and improve spoken language translation performance. While knowledge-based approaches are used widely and successfully in dialogue structure analysis <ref> [3, 4] </ref>, they require intensive human effort in defining linguistic structures and developing grammars to detect the structures. We would like to build a model that is able to learn from examples to analyze dialogue structures. [5] used a statistical approach for dialogue analysis.
Reference: [5] <author> M. Woszczyna and Alex Waibel. </author> <title> Inferring Linguistic Structure in Spoken Language. </title> <booktitle> In ICSLP 1994, </booktitle> <year> 1994. </year>
Reference-contexts: While knowledge-based approaches are used widely and successfully in dialogue structure analysis [3, 4], they require intensive human effort in defining linguistic structures and developing grammars to detect the structures. We would like to build a model that is able to learn from examples to analyze dialogue structures. <ref> [5] </ref> used a statistical approach for dialogue analysis. They modeled dialogue structure with a 6-state Markov chain. Each state represents a speech act, and it emits words to form sentences of that speech act. <p> Many of the missing segment and added segment errors were caused by mislabelling of correct segmentations. We also measured the performance in the same way as <ref> [5] </ref>, namely for each word in a dialogue we found its state | the speech act of the segment that the word is in, and compared it with its state in a reference bracketing. <p> In this case, mis-segmentation by adding or deleting a few words around segment boundaries would not hurt the performance measure very much. The correct word to state classification rate was 89%. This is much better than the 74.1% accuracy in <ref> [5] </ref>. It is even more significant if we consider that the task in [5] was an easier one with only five speech acts for a similar JANUS data set. We also calculated the perplexity of a 20 dialogues test set with around 2,400 words. <p> The correct word to state classification rate was 89%. This is much better than the 74.1% accuracy in <ref> [5] </ref>. It is even more significant if we consider that the task in [5] was an easier one with only five speech acts for a similar JANUS data set. We also calculated the perplexity of a 20 dialogues test set with around 2,400 words.
Reference: [6] <author> B. Suhm, P.Geutner, T. Kemp, A. Lavie, L. May-field, A. McNair, I. Rogina, T. Schultz, T. Slo-boda, W. Ward, M. Woszczyna, and A. Waibel. </author> <title> JANUS: Towards multilingual spoken language translation. </title> <booktitle> In Proceedings of the ARPA Speech Spoken Language Technology Workshop, </booktitle> <address> Austin, TX, </address> <year> 1995, 1995. </year>
Reference-contexts: The time complexity of the dynamic programs al gorithms is O (n 2 fl l 2 ), where l is the number of different speech act labels, and n is the length of a dialogue. 4 PERFORMANCE We applied the bracketing model to the JANUS <ref> [6] </ref> scheduling data with 19 different speech acts, exclusive of &lt;d&gt; and &lt;/d&gt;. We hand bracketed 96 dialogues with 1400 utterances or around 40,000 words. The data were segmented into around 6900 segments and each is labeled with a speech act.
Reference: [7] <author> F. Jelinek and E. L. Mercer. </author> <title> Interpolated Estimation of Markov Source Parameters from Sparse Data. </title> <editor> In D. Gelsema and L. Kanal, editors, </editor> <booktitle> Pattern Recognition in Practice. </booktitle> <publisher> North-Holland, </publisher> <year> 1980. </year>
Reference-contexts: The data were segmented into around 6900 segments and each is labeled with a speech act. We trained a speech act bigram model and 19 speech act dependent word bigram models. We smoothed the speech act dependent bigram models with a speech act independent model using deleted interpolation <ref> [7] </ref>. The speech act independent bigram model was trained with a corpus of around 420,000 words in the same domain. training data: The amount of training data were mea sured as the number of utterances.
References-found: 7

