URL: ftp://ftp.stat.wisc.edu/pub/wahba/talks/nips.96/m-c.talk.ps
Refering-URL: http://www.cs.wisc.edu/~paulb/cv.html
Root-URL: 
Title: RBF's, SBF's, TreeBF's, Smoothing Spline ANOVA: Representers and pseudo-representers for a dictionary of basis functions
Author: by Grace Wahba 
Date: December 2 1996  December 9.  
Note: NIPS 96 MODEL COMPLEXITY WORKSHOP NOTES  1 These draft notes were prepared on December 2 as handouts/overheads for G. Wahba's talk at the Neural Information Processing Society Workshop on Model Complexity, December 6, 1996, Snowmass CO, organized by Chris Williams and Joachim Utans. Permission to quote with attribution granted. Some minor typos and additions based on the actual talk have been added on  
Address: 1210 West Dayton St. Madison, WI 53706  
Affiliation: DEPARTMENT OF STATISTICS University of Wisconsin  
Abstract-found: 0
Intro-found: 0
Reference: <author> Aronszajn, N. </author> <year> (1950), </year> <title> `Theory of reproducing kernels', </title> <journal> Trans. Am. Math. Soc. </journal> <volume> 68, </volume> <pages> 337-404. </pages>
Reference: <author> Chambers, J. & Hastie, T. </author> <year> (1992), </year> <title> Statistical Models in S, </title> <publisher> Wadsworth and Brooks. </publisher>
Reference: <author> Girosi, F., Jones, M. & Poggio, T. </author> <year> (1995), </year> <title> `Regularization theory and neural networks architectures', </title> <booktitle> Neural Computation 7, </booktitle> <pages> 219-269. </pages>
Reference: <author> Gu, C. & Wahba, G. </author> <year> (1993a), </year> <title> `Semiparametric analysis of variance with tensor product thin plate splines', </title> <journal> J. Royal Statistical Soc. Ser. </journal> <volume> B 55, </volume> <pages> 353-368. </pages>
Reference: <author> Gu, C. & Wahba, G. </author> <year> (1993b), </year> <title> `Smoothing spline ANOVA with component-wise Bayesian "confidence intervals"', </title> <journal> J. Computational and Graphical Statistics 2, </journal> <pages> 97-117. </pages>
Reference: <author> Hastie, T. & Tibshirani, R. </author> <year> (1990), </year> <title> Generalized Additive Models, </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Kimeldorf, G. & Wahba, G. </author> <year> (1971), </year> <title> `Some results on Tchebycheffian spline functions', </title> <journal> J. Math. Anal. Applic. </journal> <volume> 33, </volume> <pages> 82-95. </pages>
Reference-contexts: f n g i;j = fR (t (i); t (j))g Important Remark: If R is isotropic then f is a linear combination of RBF's with centers at the data points. 5 Grace Wahba NIPS.96 Model Complexity Workshop Talk December 2, 1996 PENALIZED LIKELIHOOD, OR, THE VARIATIONAL MODEL, OR, REGULARIZATION Theorem <ref> (Special case of Kimeldorf & Wahba 1971, see Wahba, 1990) </ref>. Let kf k R be the norm in H R .
Reference: <author> Luo, Z. & Wahba, G. </author> <year> (1995), </year> <title> Hybrid adaptive splines, </title> <type> Technical Report 947, </type> <institution> Dept. of Statistics, University of Wisconsin, Madison WI, </institution> <note> to appear, J.A.S.A. </note>
Reference: <author> Moody, J. </author> <year> (1992), </year> <title> The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems, </title> <editor> in J. Moody, S. Hanson & R. Lippman, eds, </editor> <booktitle> `Advances in Neural Information Processing Systems 4', </booktitle> <publisher> Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp. 847-854. </pages>
Reference: <author> Moody, J. & Rognvaldsson, T. </author> <year> (1996), </year> <title> Smoothing regularizers for projective basis function networks, </title> <type> Technical Report 96-006, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <address> Portland OR. </address>
Reference: <author> Orr, M. </author> <year> (1995), </year> <title> `Regularization in the selection of radial basis function centers', </title> <booktitle> Neural Computation 7, </booktitle> <pages> 606-623. </pages>
Reference: <author> Orr, M. </author> <year> (1996), </year> <title> `Introduction to radial basis function networks', </title> <type> Manuscript. </type> <note> in http://www.cns.ed.ac.uk/people/mark/neuro.html. </note>
Reference: <author> O'Sullivan, F. </author> <year> (1990), </year> <title> `An iterative approach to two-dimensional laplacian smoothing with application to image restoration', </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 85, </volume> <pages> 213-219. </pages>
Reference: <author> Sin, S. & DeFigueiredo, R. </author> <year> (1993), </year> <title> `Efficient learning procedures for optimal interpolative nets', </title> <booktitle> Neural Networks 6, </booktitle> <pages> 99-113. </pages>
Reference: <author> Vapnik, V. </author> <year> (1995), </year> <title> The Nature of Statistical Learning Theory, </title> <publisher> Springer. </publisher>
Reference-contexts: A boundary is a better candidate if knowing which side of the boundary a data point is on provides more useful predictive information about its response value. Clever methods needed. 2 Support vector methods <ref> (Vapnik 1995, KW 1971) </ref> could be used to screen out basis functions. Letting fh 1 ; ; h N g be a list of candidate basis functions, let f = P k c k h k . <p> Use a quadratic optimization program to find the c k to minimize kf k 2 R = c 0 N c, say, subject to jy i k=1 c k h k (t (i))j ffi; i = 1; ; n. Such programs run fast, and in practice <ref> (Vapnik 1995, Villalobos and Wahba 1987) </ref> it has been found that, even with fairly small ffi, many of the c k will be 0, suggesting that the basis functions associated with them can be discarded. 2 Added December 9: In the talk in the Error Surfaces Workshop, I suggested generating a
Reference: <author> Villalobos, M. & Wahba, G. </author> <year> (1987), </year> <title> `Inequality constrained multivariate smoothing splines with application to the estimation of posterior probabilities', </title> <journal> J. Am. Statist. Assoc. </journal> <volume> 82, </volume> <pages> 239-248. </pages>
Reference: <institution> Grace Wahba NIPS.96 Model Complexity Workshop Talk December 2, </institution> <note> 1996 Wahba, </note> <author> G. </author> <year> (1980), </year> <title> Spline bases, regularization, and generalized cross validation for solving approximation problems with large quantities of noisy data, </title> <editor> in W. Cheney, ed., </editor> <title> `Approximation Theory III', </title> <publisher> Academic Press, </publisher> <pages> pp. 905-912. </pages>
Reference: <author> Wahba, G. </author> <year> (1990), </year> <title> Spline Models for Observational Data, </title> <booktitle> SIAM. CBMS-NSF Regional Conference Series in Applied Mathematics, v. </booktitle> <pages> 59. </pages>
Reference: <author> Wahba, G. </author> <year> (1995), </year> <title> Generalization and regularization in nonlinear learning systems, </title> <editor> in M. Ar-bib, ed., </editor> <title> `Handbook of Brain Theory and Neural Networks', </title> <publisher> MIT Press, </publisher> <pages> pp. 426-430. </pages>
Reference-contexts: Use a quadratic optimization program to find the c k to minimize kf k 2 R = c 0 N c, say, subject to jy i k=1 c k h k (t (i))j ffi; i = 1; ; n. Such programs run fast, and in practice <ref> (Vapnik 1995, Villalobos and Wahba 1987) </ref> it has been found that, even with fairly small ffi, many of the c k will be 0, suggesting that the basis functions associated with them can be discarded. 2 Added December 9: In the talk in the Error Surfaces Workshop, I suggested generating a <p> Luo and Wahba 1996 used the = 0 updating formula with a modified GCV stopping criteria followed by regularization. 13 Grace Wahba NIPS.96 Model Complexity Workshop Talk December 2, 1996 SMOOTHING SPLINE ANOVA, NON-GAUSSIAN DATA Smoothing spline ANOVA models <ref> (Wahba, Wang, Gu, Klein and Klein 1995 and references cited there) </ref> can be incorporated into a super-Hilbert space with H R as a subspace.
Reference: <author> Wahba, G., Johnson, D., Gao, F. & Gong, J. </author> <year> (1995a), </year> <title> `Adaptive tuning of nummerical weather prediction models: randomized GCV in three and four dimensional data assimilation', </title> <journal> Mon. Wea. Rev. </journal> <volume> 123, </volume> <pages> 3358-3369. </pages>
Reference: <author> Wahba, G., Wang, Y., Gu, C., Klein, R. & Klein, B. </author> <year> (1995b), </year> <title> `Smoothing spline ANOVA for exponential families, with application to the Wisconsin Epidemiological Study of Diabetic Retinopathy', </title> <journal> Ann. Statist. </journal> <volume> 23, </volume> <pages> 1865-1895. </pages>
Reference: <author> Xiang, D. & Wahba, G. </author> <year> (1996), </year> <title> `A generalized approximate cross validation for smoothing splines with non-Gaussian data', </title> <booktitle> Statistica Sinica 6, </booktitle> <pages> 675-692. 16 </pages>
References-found: 22

