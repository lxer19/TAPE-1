URL: http://www.cs.vt.edu/~ltw/genetic_alg/gaPAA98.ps
Refering-URL: http://www.cs.vt.edu/~ltw/genetic_alg/
Root-URL: http://www.cs.vt.edu
Title: A DISTRIBUTED GENETIC ALGORITHM WITH MIGRATION FOR THE DESIGN OF COMPOSITE LAMINATE STRUCTURES  
Author: MATTHEW T. MCMAHON and LAYNE T. *WATSON 
Keyword: KEY WORDS: Genetic Algorithms, Composite laminate design C.R. CATEGORIES: C.1.2, D.1.3, G.1.6, J.2 NOMENCLATURE  
Note: Author to whom correspondence should be addressed  
Address: VA 24061-0106, USA  
Affiliation: Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg,  
Abstract: This paper describes the development of a general Fortran 90 framework for the solution of composite laminate design problems using a genetic algorithm (GA). The initial Fortran 90 module and package of operators result in a standard genetic algorithm (sGA). The sGA is extended to operate on a parallel processor, and a migration algorithm is introduced. These extensions result in the distributed genetic algorithm with migration (dGA). The performance of the dGA in terms of cost and reliability is studied and compared to a sGA baseline, using two types of composite laminate design problems. The nondeterminism of GAs and the migration and dynamic load balancing algorithm used in this work result in a changed (diminished) workload, so conventional measures of parallelizability are not meaningful. Thus, a set of experiments is devised to characterize the run time performance of the dGA. A average number of optima found per run for a set of GA runs C n normalized cost for a set of GA runs dGA distributed GA EL elitist selection ME1 multiple elitist 1 selection ME2 multiple elitist 2 selection N g average number of generations to convergence for a set of GA runs N x strain in the x direction N y strain in the y direction N xy strain in the xy plane n k the number of individuals retained by ME selection strategies n m maximum number of migrants in a single mutation n s actual number of migrants in a single migration P subpopulation size p the number of processors used in a distributed computation p a probability of gene addition p c probability of crossover p d probability of gene deletion p i the ith processor in a distributed computation p m probability of migration p mm probability of material gene mutation p mo probability of orientation gene mutation p p probability of gene permutation 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Bremermann, </author> <title> Optimization through evolution and recombination, </title> <booktitle> Self-Organizing Systems 7 (1958), </booktitle> <pages> 282-287. </pages>
Reference: [2] <author> R. M. Friedberg, </author> <title> A learning machine: Part I, IBM J. </title> <booktitle> of Research and Development 1 (1958), </booktitle> <pages> 2-13. </pages>
Reference: [3] <author> R. M. Friedberg, </author> <title> A learning machine: Part II, IBM J. </title> <booktitle> of Research and Development 7 (1959), </booktitle> <pages> 282-287. </pages>
Reference: [4] <author> T. </author> <title> Back, Evolutionary Algorithms in Theory and Practice , Oxford University Press, </title> <address> NY, </address> <year> 1996. </year>
Reference-contexts: GENETIC ALGORITHMS As early as the 1950's, the biological metaphor of evolution was being applied to computation (e.g., [1]-[3]). As computational power has increased and the foundations of these evolutionary algorithms have been formalized and improved, they have increasingly been used in the solution of optimization problems. Currently, Back <ref> [4] </ref> identifies three strongly related but independently developed approaches to evolutionary computation: genetic algorithms, evolutionary programming, and evolution strategies. Although identified as distinct aspects of evolutionary programming, the three evolutionary strategies are closely related by their mimicry of natural evolutionary processes. <p> Goldberg's principle of meaningful building blocks and principle of minimum alphabets [6] indicate that low-cardinality alphabets should be used|and often variables are encoded using binary or Gray codes. Higher cardinality alphabets are used if the problem requires it, and in fact real-valued genes have been used <ref> [4] </ref> to encode real variables. 3.2. Reproduction of Individuals In genetic algorithms, evolution from generation to generation is simulated both by preserving the genetic information contained in the chromosome strings of fit individuals and by altering this information by means of random genetic changes. <p> The continuous variable crossover is essentially how evolutionary algorithms <ref> [4] </ref> work, where the value of itself can be adapted as the evolution proceeds. The benefit of the GA module and package of operators is that the design of a genetic algorithm for composite material design optimization is simplified.
Reference: [5] <author> J. H. Holland, </author> <title> Adaptation in Natural and Artificial Systems, </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1976. </year> <month> 25 </month>
Reference-contexts: Although identified as distinct aspects of evolutionary programming, the three evolutionary strategies are closely related by their mimicry of natural evolutionary processes. The work described here is concerned with the application of genetic algorithms (GAs) as optimization tools. Since their formal introduction in 1975 by Holland <ref> [5] </ref>, genetic algorithms have been applied to a variety of fields|from medicine and engineering to business|to optimize functions which do not lend themselves to optimization by traditional methods, and other applications of GAs include automatic programming and simulation of natural systems. <p> The plies are held together by a matrix material such as epoxy, which serves to support the fibers and distribute the load amongst them. The strength and stiffness of the fibers is strongest in the direction of their orientation, and weakest in the direction perpendicular to their orientation <ref> [5] </ref>. The goal of composite laminate design is to find the number of plies, along with the plies' material types and orientations, that yield the best performance for a given set of loading conditions. Additional buckling, manufacturing, or geometry constraints may also be applied to the design.
Reference: [6] <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning , Addison--Wesley, </title> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Research has shown GAs to be amenable to the solution of composite laminate design problems (e.g., [12], [19]. Genetic algorithms employ Darwin's concept of natural selection by creating a population of candidate designs and applying probabilistic rules to simulate the evolution of the population <ref> [6] </ref>. Individuals in the population are discrete encodings of candidate solutions to the problem being solved, and the evolutionary process searches for optimal designs using payoff (objective function) information only. <p> More recently, the study and practical development of the GA by Goldberg <ref> [6] </ref> and DeJong [7] has resulted in great growth in the application of GAs to optimization problems. <p> The nature of the alphabet used to encode the chromosome strings depends on the particular problem being optimized. Goldberg's principle of meaningful building blocks and principle of minimum alphabets <ref> [6] </ref> indicate that low-cardinality alphabets should be used|and often variables are encoded using binary or Gray codes. Higher cardinality alphabets are used if the problem requires it, and in fact real-valued genes have been used [4] to encode real variables. 3.2. <p> Individuals are chosen for mating by randomly choosing them from the population, with selection biased towards those individuals with higher relative fitnesses. Biasing the selection process may be accomplished with, for example, roulette wheel selection (see <ref> [6] </ref>). The roulette wheel ascribes to each individual a probability of being selected for mating based on its relative position in the population, when the individuals are ranked and sorted according to objective function value.
Reference: [7] <author> K. A. De Jong, </author> <title> An analysis of the behavior of a class of genetic adaptive systems, </title> <type> PhD. Dissertation, </type> <institution> Univ. of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: More recently, the study and practical development of the GA by Goldberg [6] and DeJong <ref> [7] </ref> has resulted in great growth in the application of GAs to optimization problems.
Reference: [8] <author> R. T. Haftka, </author> <title> Elements of Structural Optimization, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference: [9] <author> R. Foye, </author> <title> Advanced Design for Advanced Composite Airframes, </title> <institution> Air Force Materials Laboratory, Wright-Patterson Air Force Base, Ohio, </institution> <month> AFML-TR-69-251 </month> <year> (1969). </year>
Reference-contexts: Various optimization methods have been applied to finding the optimal stacking sequence for the smallest number of plies which satisfy a given set of design requirements. Using ply orientation angles and the number of plies as design variables, random search has been employed <ref> [9] </ref>, as well as exhaustive search through the entire solution space [10]. Again using ply orientation and thickness as design variables, the problem has also been formulated as a continuous optimization problem [11]. 4.2.
Reference: [10] <author> M. E. Waddoups, </author> <title> Structural Airframe Application of Advanced Composite Materials| Analytical Methods, </title> <institution> Air Force Materials Laboratory, Wright-Patterson Air Force Base, Ohio, </institution> <month> AFML-TR-69-101 </month> <year> (1969). </year>
Reference-contexts: Using ply orientation angles and the number of plies as design variables, random search has been employed [9], as well as exhaustive search through the entire solution space <ref> [10] </ref>. Again using ply orientation and thickness as design variables, the problem has also been formulated as a continuous optimization problem [11]. 4.2. Genetic Algorithm Optimization The optimization methods mentioned in the preceding subsection often prove to be impractical for composite material design.
Reference: [11] <author> Z. Gurdal and R. T. Haftka, </author> <title> Optimization of Composite Laminates, </title> <booktitle> Presented at the NATO Advanced Study Institute on Optimization of Large Structural Systems (1991), </booktitle> <address> Berchtesgaden, Germany. </address>
Reference-contexts: Using ply orientation angles and the number of plies as design variables, random search has been employed [9], as well as exhaustive search through the entire solution space [10]. Again using ply orientation and thickness as design variables, the problem has also been formulated as a continuous optimization problem <ref> [11] </ref>. 4.2. Genetic Algorithm Optimization The optimization methods mentioned in the preceding subsection often prove to be impractical for composite material design.
Reference: [12] <author> R. Le Riche and R. T. Haftka, </author> <title> Optimization of Laminate Stacking Sequence for Buckling Load Maximization by Genetic Algorithm, </title> <journal> AIAA Journal 31 (1993), </journal> <pages> 951-956. </pages>
Reference-contexts: 1. INTRODUCTION Numeric optimization problems are often solved using continuous techniques. The problem of composite laminate stacking sequence optimization has been formulated as a continuous design problem and solved using gradient based techniques <ref> [12] </ref>, but these methods of solution are not always successful, for two reasons. First, stacking sequence design often involves discrete design variables, such as ply thickness and orientation, which must be converted to continuous variables for solution. <p> Research has shown GAs to be amenable to the solution of composite laminate design problems (e.g., <ref> [12] </ref>, [19]. Genetic algorithms employ Darwin's concept of natural selection by creating a population of candidate designs and applying probabilistic rules to simulate the evolution of the population [6].
Reference: [13] <author> R. Le Riche and R. T. Haftka, </author> <title> Improved Genetic Algorithm for Minimum Thickness Composite Laminate Design, </title> <booktitle> Proceedings of International Conf. on Composite Engineering, (1994), </booktitle> <address> New Orleans, LA. </address>
Reference: [14] <author> N. Kogiso, L. T. Watson, Z. Gurdal, R. T. Haftka, and S. Nagendra, </author> <title> Design of Composite Laminates by a Genetic Algorithm with Memory, </title> <booktitle> Mechanics of Composite Materials and Structures 1 (1994), </booktitle> <pages> 95-117. </pages>
Reference: [15] <author> N. Kogiso, L. T. Watson, Z. Gurdal, and R. T. Haftka, </author> <title> Genetic algorithms with local improvement for composite laminate design, Structural Optim. </title> <booktitle> 7 (1994), </booktitle> <pages> 207-218. </pages>
Reference: [16] <author> G. A. Soremekun, </author> <title> Genetic Algorithms for Composite Laminate Design and Optimization, </title> <type> MS Thesis, </type> <institution> Department of Engineering Mechanics, Virginia Polytechnic Institute and State University, Blacksburg, VA, </institution> <year> 1997. </year>
Reference-contexts: GA Performance Analysis This section introduces the two criteria used for characterizing the performance of the GA during a set of optimization runs: the apparent reliability and the normalized cost per genetic search <ref> [16] </ref>. The apparent reliability R is a reflection of the reliability of the GA in finding an optimum for a given set of conditions.
Reference: [17] <author> S. Nagendra, D. Jestin, Z. Gurdal, R. T. Haftka, and L. T. Watson, </author> <title> Improved genetic algorithms for the design of stiffened composite panels, </title> <booktitle> Comput. & Structures 58 (1996), </booktitle> <pages> 543-555. </pages>
Reference-contexts: The goal of the GA is to minimize this fitness value. These penalty functions are subtle, and must be chosen carefully so that an infeasible design is not more fit than a near optimal feasible design. Such details are discussed in <ref> [17] </ref>, [18]. 12 The panel design is encoded in a single chromosome. Each gene in the chromosome corresponds to a ply in the structure.
Reference: [18] <author> S. Nagendra, S., Z. Gurdal, R. T. Haftka, and L. T. Watson, </author> <title> "Derivative based approximation for predicting the effect of changes in laminate stacking sequence", Structural Optim. </title> <booktitle> 11 (1996), </booktitle> <pages> 235-243. </pages>
Reference-contexts: The goal of the GA is to minimize this fitness value. These penalty functions are subtle, and must be chosen carefully so that an infeasible design is not more fit than a near optimal feasible design. Such details are discussed in [17], <ref> [18] </ref>. 12 The panel design is encoded in a single chromosome. Each gene in the chromosome corresponds to a ply in the structure.
Reference: [19] <author> S. Nagendra, R. T. Haftka, and Z. Gurdal, </author> <title> Design of Blade Stiffened Composite Panels by a Genetic Algorithm Approach, </title> <booktitle> Proceedings of the 34th AIAA/ASME/AHS SDM Conf., </booktitle> <address> La Jolla, CA, </address> <year> (1993), </year> <pages> 2418-2436. </pages>
Reference-contexts: Research has shown GAs to be amenable to the solution of composite laminate design problems (e.g., [12], <ref> [19] </ref>. Genetic algorithms employ Darwin's concept of natural selection by creating a population of candidate designs and applying probabilistic rules to simulate the evolution of the population [6].
Reference: [20] <author> S. Nagendra, R. T. Haftka, and Z. Gurdal, </author> <title> PASCO-GA : A Genetic Algorithm based Design Procedure For Stiffened Composite Panels under Stability and Strain Constraints, </title> <booktitle> Tenth DOD/NASA/FAA Conf. on Fibrous Composites in Structural Design, </booktitle> <address> Hilton Head, SC, </address> <year> (1993). </year>
Reference: [21] <author> T. Back and F. Hoffmeister, </author> <title> Extended Selection Mechanisms in Genetic Algorithms, </title> <booktitle> Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> (1991), </year> <pages> 92-99. </pages>
Reference: [22] <author> T. </author> <title> Back, Selective Pressure in Evolutionary Algorithms: A Characterization of Selection Mechanisms, </title> <booktitle> Proceedings of the First International IEEE Conference on Evolutionary Computation, </booktitle> <publisher> IEEE Press, </publisher> <address> NY, </address> <year> (1994), </year> <pages> 57-62. 26 </pages>
Reference-contexts: Two different multiple elitist schemes are applied to test problem 2. These strategies are inspired by the (; ) and ( + ) strategies developed by Back ([21], <ref> [22] </ref>). The first multiple elitist selection strategy (ME1) works as follows: for each iteration of the GA loop, a child population is generated equal in size to the parent population. The children are required to be distinct from each other and from all the parents.
Reference: [23] <author> M. T. McMahon, L. T. Watson, G. A. Soremekun, Z. Gurdal, and R. T. Haftka, </author> <title> A Fortran 90 Genetic Algorithm Module for Composite Laminate Structure Design, Engineering with Computers (1998). </title>
Reference-contexts: The globally optimum designs for the two test problems are enumerated in Appendix A. Also, see <ref> [23] </ref> for a discussion of language performance tradeoffs between the custom FORTRAN 77 codes and the Fortran 90 template.
Reference: [24] <author> J. J. Grefenstette and J. E. Baker, </author> <title> How genetic algorithms work: A critical look at implicit parallelism, </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms and Their Applications, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1989), </year> <pages> 20-27. </pages>
Reference-contexts: PARALLEL IMPLEMENTATION As parallel computers become more commonplace in scientific computing, it becomes more feasible to harness their power for use with genetic algorithms. The GA is inherently parallel <ref> [24] </ref>. Genetic operations can be applied to individuals in a population in parallel, a population may be partitioned into separately evolving subpopulations, or independent runs|such as those made in Section 5|can run on different processors.
Reference: [25] <author> J. P. Cohoon, S. U. Hedge, W. N. Martin, and D. Richards, </author> <title> Punctuated equilibria: A parallel genetic algorithm, </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms and Their Applications, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1987), </year> <pages> 750-755. </pages>
Reference-contexts: Migration may occur in a 16 variety of ways. Each processing element in a parallel GA may contain an independently evolving standard GA which periodically migrates fit individuals to other processors (as in <ref> [25] </ref>), or the GA itself may be parallelized. In the latter case, each individual in a population is itself a single process, and migration is characterized as a diffusion process as individuals reproduce within a local neighborhood (see, for example [27]).
Reference: [26] <author> V. S. Gordon and D. Whitley, </author> <title> Serial and Parallel Genetic Algorithms as Function Optimizers, </title> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms and Their Applications, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1993), </year> <pages> 177-183. </pages>
Reference-contexts: A GA running in parallel can be exploited further as an optimization tool by implementing communications between processing elements. Indeed, Gordon and Whitley <ref> [26] </ref> report that the performance of parallel genetic algorithms is superior to standard GAs in function optimization, even without taking parallel hardware into account. The migration model takes the idea of separately evolving subpopulations and extends it by adding a means of selectively sharing genetic information between them.
Reference: [27] <author> M. Gorges-Schleuter, </author> <title> Asparagos: an asynchronous parallel genetic optimization strategy, </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms and Their Applications, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1987), </year> <pages> 422-427. </pages>
Reference-contexts: In the latter case, each individual in a population is itself a single process, and migration is characterized as a diffusion process as individuals reproduce within a local neighborhood (see, for example <ref> [27] </ref>). The implementation of a distributed migration algorithm should ensure that the performance of the algorithm is not constrained by the number of processors involved or by the communication between those processors. The mechanisms of communication, load balancing, and termination detection all determine the distributed algorithm's parallel performance.
Reference: [28] <author> F. Hoffmeister, </author> <title> Scalable Parallelism by Evolutionary Algorithms, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems 367 (1991), </booktitle> <publisher> Springer Verlag, Berlin, </publisher> <pages> 177-198. </pages>
Reference-contexts: As powerful parallel computers become more accessible to researchers, it becomes more feasible to harness their power for use with GAs. The GA is inherently parallel, through its population structure, and different parallel algorithms have been introduced to take advantage of this aspect (see, for example, <ref> [28] </ref>, [29]. One benefit of a parallel GA implementation is that further exploitation of genetic information is made possible, through migration. Migration is an extension to the standard genetic algorithm in which otherwise separately evolving subpopulations occasionally identify and exchange genetic information.
Reference: [29] <author> R. Tanese, </author> <title> Distributed Genetic Algorithms, </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms and Their Applications, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1989), </year> <pages> 434-439. </pages>
Reference-contexts: As powerful parallel computers become more accessible to researchers, it becomes more feasible to harness their power for use with GAs. The GA is inherently parallel, through its population structure, and different parallel algorithms have been introduced to take advantage of this aspect (see, for example, [28], <ref> [29] </ref>. One benefit of a parallel GA implementation is that further exploitation of genetic information is made possible, through migration. Migration is an extension to the standard genetic algorithm in which otherwise separately evolving subpopulations occasionally identify and exchange genetic information. <p> Section 7 quantifies the performance of the migration algorithm and the performance of the parallel algorithm. 6.1. Migration The migration algorithm partitions a population of designs into a set of subpopulations and, at specified intervals, shares information between these subpopulations. Tanese <ref> [29] </ref> introduces the parameters associated with the migration algorithm: the migration interval and the migration rate. The migration interval is the number of generations between each migration, and the migration rate is the number of individuals selected for migration.
Reference: [30] <author> M. J. Quinn, </author> <title> Parallel Computing, Theory and Practice, </title> <publisher> McGraw-Hill, </publisher> <address> NY, </address> <year> 1994. </year> <month> 27 </month>
Reference-contexts: An important measure of the quality of a parallel algorithm is its parallelizability <ref> [30] </ref>. The parallelizability is the ratio between the time taken by a parallel computer executing a parallel algorithm on one processor and the time taken by the same parallel computer executing the same parallel algorithm on p processors.
References-found: 30

