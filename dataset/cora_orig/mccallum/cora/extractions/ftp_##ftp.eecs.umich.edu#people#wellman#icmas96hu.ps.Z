URL: ftp://ftp.eecs.umich.edu/people/wellman/icmas96hu.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/wellman/Publications.html
Root-URL: http://www.cs.umich.edu
Email: fjunling, wellmang@umich.edu  
Title: Self-fulfilling Bias in Multiagent Learning  
Author: Junling Hu and Michael P. Wellman 
Address: Ann Arbor, MI 48109-2110 USA  
Affiliation: Department of EECS, AI Laboratory University of Michigan  
Date: December 1996  
Note: In Proceedings of the Second International Conference on Multiagent Systems (ICMAS-96), Kyoto, Japan,  
Abstract: Learning in a multiagent environment is complicated by the fact that as other agents learn, the environment effectively changes. Moreover, other agents' actions are often not directly observable, and the actions taken by the learning agent can strongly bias which range of behaviors are encountered. We define the concept of a conjectural equilibrium, where all agents' expectations are realized, and each agent responds optimally to its expectations. We present a generic multiagent exchange situation, in which competitive behavior constitutes a conjectural equilibrium. We then introduce an agent that executes a more sophisticated strategic learning strategy, building a model of the response of other agents. We find that the system reliably converges to a conjectural equilibrium, but that the final result achieved is highly sensitive to initial belief. In essence, the strategic learner's actions tend to fulfill its expectations. Depending on the starting point, the agent may be better or worse off than had it not attempted to learn a model of the other agents at all. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Boutilier, C. </author> <year> 1996. </year> <title> Learning conventions in multia-gent stochastic domains using likelihood estimates. In 6 See (Kephart, Hogg, & Huberman 1989) for another setting where sophisticated agents that try to anticipate the actions of others often make results worse for themselves. </title> <booktitle> Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 106-114. </pages>
Reference-contexts: First, it applies at each stage of an extensive form game, rather than for single-stage games or in the limit of a repeated game. Second, it takes individual actions of other agents as observable, whereas in our framework the agents observe only resulting state. Boutilier <ref> (Boutilier 1996) </ref> also considers a model where only outcomes are observable, comparing the effectiveness of alternate learning mechanisms for solving multiagent coordination problems. The basic concept of conjectural equilibrium was first introduced by Hahn, in the context of a market model (Hahn 1977).
Reference: <author> Boyle, K. </author> <year> 1985. </year> <title> Starting point bias in contingent valuation bidding games. </title> <booktitle> Land Economics 61 </booktitle> <pages> 188-194. </pages>
Reference: <author> Cheng, J. Q., and Wellman, M. P. </author> <year> 1996. </year> <title> The WAL-RAS algorithm: A convergent distributed implementation of general-equilibrium outcomes. </title> <note> Submitted for publication. </note>
Reference-contexts: If the aggregate demand obeys gross substitutability (an increase in the price of one good raises demand for others, which hence serve as substitutes), then this method is guaranteed to converge to a competitive equilibrium (under the conditions under which it is guaranteed to exist). The walras algorithm <ref> (Cheng & Wellman 1996) </ref> is a variant of tatonnement. In walras, agent i submits to the auction for good j at time t its solution to (2), expressed as a function of P j , assuming that the prices of goods other than j take their expected values. <p> Given the bidding behavior described, with expectations formed as by the simple competitive agent, the walras algorithm is guaranteed to converge to competitive equilibrium, under the standard conditions <ref> (Cheng & Wellman 1996) </ref>. Such an equilibrium also represents a conjectural equilibrium, according to the definition above. Thus, the simple competitive learning regime is convergent, with respect to both the tatonnement and walras price adjustment protocols. Learning Agents Agents learn when they modify their conjectures based on observations.
Reference: <author> Fudenberg, D., and Levine, D. K. </author> <year> 1993. </year> <title> Self-confirming equilibrium. </title> <type> Econometrica 61 </type> <pages> 523-545. </pages>
Reference: <author> Gibbsons, R. </author> <year> 1992. </year> <title> Game Theory for Applied Economists. </title> <publisher> Princeton University Press. </publisher>
Reference-contexts: This situation differs from the traditional game theory framework, where the joint payoff matrix is known to every agent. Uncertainty can be accommodated in the standard game-theoretic concept of incomplete information <ref> (Gibbsons 1992) </ref>, where agents have probabilities over the payoffs of other agents. However, a state of complete ignorance about other agents' options and preferences can be expressed more directly, albeit abstractly, by omitting any direct consideration of interagent beliefs. Consider an n-player game G = (A; U; S; s).
Reference: <editor> Grefenstette, J. J., et al., eds. </editor> <booktitle> 1996. AAAI Spring Symposium on Adaptation, Coevolution, and Learning in Multiagent Systems. </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Hahn, F. </author> <year> 1977. </year> <title> Exercises in conjectural equilibrium analysis. </title> <booktitle> Scandinavian Journal of Economics 79 </booktitle> <pages> 210-226. </pages>
Reference-contexts: Boutilier (Boutilier 1996) also considers a model where only outcomes are observable, comparing the effectiveness of alternate learning mechanisms for solving multiagent coordination problems. The basic concept of conjectural equilibrium was first introduced by Hahn, in the context of a market model <ref> (Hahn 1977) </ref>. Though we also focus on market interactions, our basic definition applies the concept to the more general case. Hahn also included a specific model for conjecture formation in the equilibrium concept, whereas we relegate this process to the learning regime of participating agents.
Reference: <author> Kephart, J. O.; Hogg, T.; and Huberman, B. A. </author> <year> 1989. </year> <title> Dynamics of computational ecosystems. </title> <journal> Physical Review A 40 </journal> <pages> 404-421. </pages>
Reference: <author> Russell, S., and Norvig, P. </author> <year> 1995. </year> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Here bias is defined as in the standard machine learning literature|the preference for one hypothesis over another, beyond mere consistency with the examples <ref> (Russell & Norvig 1995) </ref>. In reinforcement learning, the initial hypothesis is a source of bias, as is the hypothesis space (in multiagent environments, expressible models of the other agents).
Reference: <author> Samples, K. </author> <year> 1985. </year> <title> A note on the existence of starting point bias in iterative bidding games. </title> <journal> Western Journal of Agricultural Economics 10 </journal> <pages> 32-40. </pages>
Reference: <author> Sen, S. </author> <year> 1996. </year> <booktitle> IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems. AI Magazine 17(1) </booktitle> <pages> 87-89. </pages>
Reference: <author> Spivak, B. </author> <year> 1965. </year> <title> Calculus on Manifolds. </title> <publisher> Ben-jamin/Cummings. </publisher>
Reference-contexts: The conditions also ensure the existence of a competitive equilibrium P fl , and therefore there is a point (P fl ; (P fl ; 0)) such that F (P fl ; (P fl ; 0)) = 0. Then by the Implicit Function Theorem <ref> (Spivak 1965) </ref>, there exists an open set P containing P fl and an open set B containing (P fl ; 0) such that for each P 2 P, 5 Here we refer to the vectors ff = (ff 1 ; : : : ; ff m ) and fi 1 ;
Reference: <author> Takayama, A. </author> <year> 1985. </year> <title> Mathematical Economics. </title> <publisher> Cam-bridge University Press. </publisher>
Reference-contexts: The excess demand set for consumer i is Z i = fz i 2 R m j e i + z i 2 X i g. A basic result of general equilibrium theory <ref> (Takayama 1985) </ref> states that if the utility function of every agent is quasiconcave and twice differentiable, then E has a unique competitive equilibrium. 2 Observe that any competitive equilibrium can be viewed as a conjectural equilibrium, for an appropriate interpretation of conjectures.
Reference: <author> Tan, M. </author> <year> 1993. </year> <title> Multi-agent reinforcement learning: Independent vs. </title> <booktitle> cooperative agents. In Proceedings of the Tenth International Conference on Machine Learning. </booktitle> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Wei, G. </author> <year> 1993. </year> <title> Learning to coordinate actions in multi-agent systems. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 311-316. </pages>
Reference: <author> Wellman, M. P. </author> <year> 1993. </year> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research 1 </journal> <pages> 1-22. </pages>
Reference-contexts: The market context is generic enough to capture a wide range of interesting multiagent systems, yet affords analytically simple characterizations of conjectures and dynamics. Our model is based on the framework of general equilibrium theory from economics, and our implementation uses the walras market-oriented programming system <ref> (Wellman 1993) </ref>, which is also based on general equilibrium theory.
References-found: 16

