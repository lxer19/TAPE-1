URL: http://www.cs.jhu.edu/~sheppard/cs.605.754/papers/paper10b.ps.gz
Refering-URL: http://www.cs.jhu.edu/~sheppard/cs.605.754/sched.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: whitley@cs.colostate.edu  
Title: Evaluating Evolutionary Algorithms  
Author: D. Whitley, K. Mathias, S. Rana, J. Dzubera 
Address: Fort Collins, Colorado 80523 USA  
Affiliation: Department of Computer Science Colorado State University  
Abstract: Test functions are commonly used to evaluate the effectiveness of different search algorithms. However, the results of evaluation are as dependent on the test problems as they are on the algorithms that are the subject of comparison. Unfortunately, developing a test suite for evaluating competing search algorithms is difficult without clearly defined evaluation goals. In this paper we discuss some basic principles that can be used to develop test suites and we examine the role of test suites as they have been used to evaluate evolutionary search algorithms. Current test suites include functions that are easily solved by simple search methods such as greedy hill-climbers. Some test functions also have undesirable characteristics that are exaggerated as the dimensionality of the search space is increased. New methods are examined for constructing functions with different degrees of nonlinearity, where the interactions and the cost of evaluation scale with respect to the dimensionality of the search space.
Abstract-found: 1
Intro-found: 1
Reference: <author> David Ackley. </author> <title> A Connectionist Machine for Genetic Hillclimbing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year>
Reference: <author> T. Back, F. Hoffmeister, </author> <title> and H.P. Schwefel. A Survey of Evolution Strategies. </title> <editor> In L. Booker and R. Belew, editors, </editor> <booktitle> Proc. of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1991. </year>
Reference: <author> T. </author> <title> Back and H.P. Schwefel. An Overview of Evolutionary Algorithms for Parameter Optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1 </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference: <editor> Richard Belew. Paradigmatic over-fitting. GA-Digest, </editor> <volume> 6(18), </volume> <month> May </month> <year> 1992. </year>
Reference: <editor> Lashon Booker. </editor> <title> Improving Search in Genetic Algorithms. </title> <editor> In Lawrence Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 5, </booktitle> <pages> pages 61-73. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference: <author> R. Brent. </author> <title> Algorithms for Minimization without Derivatives. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: F2 is also known as Rosenbrock's function (1960) in the optimization literature. Solutions to this function can be obtained using minimization methods that do not require derivatives and which employ linear search <ref> (Brent 1973) </ref>. Of all the test problems in table 1, only F8 (Griewangk's function) is scalable, nonlinear and nonseparable. Nevertheless we have found that F8 exhibits undesirable properties as the dimensionality of the function is increased. <p> In order to provide a baseline for test functions, local search and hill-climbing algorithms should be included in any comparative study. There is also a body of literature on optimization without derivatives <ref> (e.g. Brent 1973) </ref> that seems to have been largely ignored by the evolutionary algorithms communities and perhaps by other heuristic search communities. We would also argue that the use of test suites should be hypothesis driven.
Reference: <author> T. Cormen, C. Leiserson and R. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: We do not consider combinatorial optimization problems in this paper. Well known test cases exist for problems such as the Traveling Salesman Problem. The inherent difficulty of these problems and their status as NP-Complete problems is more thoroughly documented than the difficulty of most parameter optimization problems <ref> (Cormen, et al. 1990) </ref>. Furthermore, researchers often use specialized representations and operators when applying evolutionary algorithms and other heuristic search methods to this class of problems. Parameter optimization problems have simple representations (e.g. bit strings or float strings) that are 2 manipulated by a general set of operators. <p> On the other hand, for some objective functions evaluation can be relatively fast. Many NP-Complete problems have simple objective functions, where the cost of evaluation scales in a linear fashion <ref> (Cormen et al. 1990) </ref>. Therefore, the designer of a test suite should consider how the cost of evaluation scales with respect to the dimensionality of the search problem. 5. Test Problems Should Have a Canonical Form.
Reference: <author> Yuval Davidor. </author> <title> A Naturally Occurring Niche & Species Phenomenon: The Model and First Results. </title>
Reference: <editor> In L. Booker and R. Belew, editors, </editor> <booktitle> Proc. of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 257-263. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1991. </year>
Reference-contexts: We also show that higher order symmetries can exist which may make some types of genetic algorithms an inappropriate method of search. Separable functions are commonly used as test problems because they are scalable. This allows search algorithms to be tested on problems with progressively higher dimensionality <ref> (Muhlenbein, 1991) </ref>. Scalability is indeed desirable, but the nonlinear interactions in a test function should also be sensitive to scaling. We show that simple methods can be used for constructing test functions that allow nonlinear interactions between variables to be selectively scaled as the dimensionality of the problem is increased. <p> F8 are known as the Rastrigin (F6), Schwefel (F7) and Griewangk (F8) functions and can be scaled to any number of variables <ref> (Muhlenbein, 1991) </ref>. The functions labeled F9 and F10 are known as the sine envelope sine wave and the stretched V sine wave functions (Schaffer, et. al., 1989).
Reference: <author> Lawrence Davis. </author> <title> Bit-Climbing, Representational Bias, and Test Suite Design. </title> <editor> In L. Booker and R. Belew, editors, </editor> <booktitle> Proc. of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 18-23. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1991. </year>
Reference: <author> Ken De Jong. </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, Dept. Computer and Communication Sciences. Ann Arbor, Michigan, </institution> <year> 1975. </year>
Reference: <author> Ken De Jong. </author> <title> Genetic Algorithms are NOT Function Optimizers. </title> <editor> In D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms 2, </booktitle> <pages> pages 5-17. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: <editor> Larry Eshelman. </editor> <title> The CHC Adaptive Search Algorithm. How to Have Safe Search When Engaging in Nontraditional Genetic Recombination. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 265-283. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference: <author> L.J. Fogel, Owens A.J., and M.J. Walsh. </author> <title> Artificial Intelligence Through Simulated Evolution. </title> <publisher> John Wiley, </publisher> <year> 1966. </year>
Reference: <author> D. B. Fogel. </author> <title> On the philosophical differences between evolutionary algorithms and genetic algorithms. </title> <editor> In D. B. Fogel and W. Atmar, editors, </editor> <booktitle> Proc. 2nd Annual Conference on Evolutionary Programming, </booktitle> <pages> pages 23-29. </pages> <booktitle> Evolutionary Programming Society, 1993. </booktitle> <address> 33 D. </address> <publisher> B. </publisher> <editor> Fogel. </editor> <title> Evolutionary programming: an introduction and some current directions. </title> <journal> Statistics and Computing, </journal> <volume> 4 </volume> <pages> 113-130, </pages> <year> 1994. </year>
Reference: <editor> Stephanie Forrest and Melanie Mitchell. </editor> <title> Relative Building-Block Fitness and the Building Block Hypothesis. </title> <editor> In L. Darrell Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms - 2, </booktitle> <pages> pages 109-126. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: <author> F. Glover. </author> <title> Tabu search, Part I. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1 </volume> <pages> 190-206, </pages> <year> 1989. </year>
Reference-contexts: Such functions are also often readily solved by local search methods and hence may be easily solved by any algorithm that explicitly builds on local search, such as simulated annealing (Kirkpatrick et al. 1983) or TABU search <ref> (Glover 1989) </ref>. Test functions can also display symmetries which may make them easier to solve by some methods. For 2-dimensional functions symmetry exists if F (x,y) = F (y,x). In higher dimensions, up to N! equivalent solutions may exists for a function of N variables. <p> Finally, the results presented in this paper should alert researchers using common test suites for experimental evaluation on evolutionary algorithms, or for comparisons of evolutionary algorithms to other methods such as TABU search <ref> (Glover 1989) </ref> and simulated annealing (Kirkpatrick et al. 1983). Evolutionary algorithms are best applied where simpler methods fail. If satisfactory solutions can be obtained for application problems using simpler optimization methods, then there may be no advantage in using evolutionary algorithms.
Reference: <author> David Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference: <author> David Goldberg. </author> <title> A Note on Boltzmann Tournament Selection for Genetic Algorithms and Population-oriented Simulated Annealing. </title> <type> Technical Report Nb. 90003, </type> <institution> Department of Engineering Mechanics, University of Alabama, </institution> <year> 1990. </year>
Reference: <author> Frank Hoffmeister and Thomas Back. </author> <title> Genetic Algorithms and Evolution Strategies: Similarities and Differences. In H.P. </title> <editor> Schwefel and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 455-469. </pages> <address> Springer/Verlag, </address> <year> 1991. </year> <editor> John Holland. </editor> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <publisher> University of Michigan Press, </publisher> <address> 1975. (1992 edition, </address> <publisher> MIT Press.) </publisher> <editor> J. Hooker. </editor> <title> Testing Heuristics: We Have It All Wrong. </title> <journal> Journal of Heuristics, </journal> <note> 1(1), to appear, </note> <year> 1995. </year>
Reference: <author> E. Horowitz and S. Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <year> 1978. </year>
Reference-contexts: If one considers the class of combinatorial optimization problems, it is clear that the scale of such problems is critical. Exact methods, such as branch and bound algorithms <ref> (Horowitz and Sahni, 1978) </ref>, exactly solve many NP-Complete problems when these problems are relatively small. For example, Padberg and Rinaldi (1987) have solved 500 city problems using exact methods; it is also relatively easy to solve knapsack problems with up to 100,000 variables (Martello and Toth, 1990).
Reference: <author> Kauffman, S. </author> <year> (1989). </year> <title> Adaptation on Rugged Fitness Landscapes. </title> <editor> In Stein, D., editor, </editor> <booktitle> Lectures in the Science of Complexity, </booktitle> <pages> pages 527-618. </pages> <publisher> Addison-Wesley. </publisher>
Reference: <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> Optimization by Simulated Annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: This is problematic in that separable functions can be solved by exact methods. Such functions are also often readily solved by local search methods and hence may be easily solved by any algorithm that explicitly builds on local search, such as simulated annealing <ref> (Kirkpatrick et al. 1983) </ref> or TABU search (Glover 1989). Test functions can also display symmetries which may make them easier to solve by some methods. For 2-dimensional functions symmetry exists if F (x,y) = F (y,x). <p> Finally, the results presented in this paper should alert researchers using common test suites for experimental evaluation on evolutionary algorithms, or for comparisons of evolutionary algorithms to other methods such as TABU search (Glover 1989) and simulated annealing <ref> (Kirkpatrick et al. 1983) </ref>. Evolutionary algorithms are best applied where simpler methods fail. If satisfactory solutions can be obtained for application problems using simpler optimization methods, then there may be no advantage in using evolutionary algorithms.
Reference: <author> G. Liepins and M. Vose. </author> <title> Representation Issues in Genetic Algorithms. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 101-115, </pages> <year> 1990. </year>
Reference-contexts: It can be proven that for any given problem there are multiple problem representations that can be easily hill-climbed <ref> (Liepins and Vose, 1990) </ref>; however, the space of all possible representations is dramatically larger than the search space itself.
Reference: <author> S. Martello and P. Toth. </author> <title> Knapsack Problems: Algorithms and Computer Implementations. </title> <editor> J. </editor> <publisher> Wiley and Sons, </publisher> <year> 1990. </year>
Reference-contexts: For example, Padberg and Rinaldi (1987) have solved 500 city problems using exact methods; it is also relatively easy to solve knapsack problems with up to 100,000 variables <ref> (Martello and Toth, 1990) </ref>. It is only as these problems are scaled that the inherent difficulty of the problem is expressed. 4. Test Suites Should Contain Problems with Scalable Evaluation Cost.
Reference: <author> Keith E. Mathias and L. Darrell Whitley. </author> <title> Changing Representations During Search: A Comparative Study of Delta Coding. </title> <journal> Journal of Evolutionary Computation, </journal> <year> 1994a. </year>
Reference: <author> Keith E. Mathias and L. Darrell Whitley. </author> <title> Transforming the Search Space with Gray Coding. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proc. of the IEEE International Conference on Evolutionary Computation, </booktitle> <pages> pages 513-518. </pages> <publisher> IEEE Service Center, </publisher> <year> 1994b. </year>
Reference: <author> Keith E. Mathias, L. Darrell Whitley, Christof Stork, and Tony Kusuma. </author> <title> Staged Hybrid Genetic Search for Seismic Data Imaging. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proc. of the IEEE International Conference on Evolutionary Computation, </booktitle> <pages> pages 356-361. </pages> <publisher> IEEE Service Center, </publisher> <year> 1994. </year>
Reference: <author> D. Montana and L. Davis. </author> <title> Training Feedforward Neural Networks Using Genetic Algorithms. </title> <booktitle> Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 762-767. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <title> 34 H. Muhlenbein. Evolution in Time and Space: The Parallel Genetic Algorithm. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 316-337. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference: <author> H. Muhlenbein, M. Schomisch and J. Born. </author> <title> The Parallel Genetic Genetic Algorithm as Function Optimizer. </title> <editor> In L. Booker and R. Belew, editors, </editor> <booktitle> Proc. of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 271-278. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1991. </year>
Reference-contexts: We also show that higher order symmetries can exist which may make some types of genetic algorithms an inappropriate method of search. Separable functions are commonly used as test problems because they are scalable. This allows search algorithms to be tested on problems with progressively higher dimensionality <ref> (Muhlenbein, 1991) </ref>. Scalability is indeed desirable, but the nonlinear interactions in a test function should also be sensitive to scaling. We show that simple methods can be used for constructing test functions that allow nonlinear interactions between variables to be selectively scaled as the dimensionality of the problem is increased. <p> F8 are known as the Rastrigin (F6), Schwefel (F7) and Griewangk (F8) functions and can be scaled to any number of variables <ref> (Muhlenbein, 1991) </ref>. The functions labeled F9 and F10 are known as the sine envelope sine wave and the stretched V sine wave functions (Schaffer, et. al., 1989).
Reference: <author> H. Muhlenbein and D. Schlierkamp-Voosen. </author> <title> Predictive Models for the Breeder Genetic Algorithm. </title> <journal> Journal of Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 25-49, </pages> <year> 1993. </year>
Reference: <author> Padberg and Rinaldi (1987) W. Padberg and G. Rinaldi, </author> <title> Optimization of a 532 City Symmetric TSP. </title> <journal> Optimization Research Letters, </journal> <volume> 6(1) </volume> <pages> 1-7, </pages> <year> 1987. </year>
Reference: <author> M.J.D. Powell. </author> <title> An Iterative Method for Finding Stationary Values of a Function of Several Variables. </title>
Reference: <editor> Comp. J., </editor> <volume> 5 </volume> <pages> 147-151, </pages> <year> 1962. </year>
Reference: <author> N.J. Radcliffe. </author> <title> Genetic Neural Networks on MIMD Computers. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <address> Edinburgh Scotland, </address> <year> 1990. </year>
Reference: <author> I. Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biologis-chen Evolution. </title> <address> Frommann-Holzboof, Stuttgart, </address> <year> 1973. </year>
Reference: <author> H.H. </author> <title> Rosenbrock. An Automatic Method for Finding the Greatest or Least Values of a Function. </title>
Reference: <editor> Comp. J., </editor> <volume> 3 </volume> <pages> 175-184, </pages> <year> 1960. </year>
Reference: <editor> J.D. Schaffer, R.A. Caruana, L.J. Eshelman, and R. </editor> <title> Das. A Study of Control Parameters Affecting Online Performance of Genetic Algorithms for Function Optimization. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proc. of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1989. </year>
Reference-contexts: F8 are known as the Rastrigin (F6), Schwefel (F7) and Griewangk (F8) functions and can be scaled to any number of variables (Muhlenbein, 1991). The functions labeled F9 and F10 are known as the sine envelope sine wave and the stretched V sine wave functions <ref> (Schaffer, et. al., 1989) </ref>. These test problems have often been used to tune and refine variants of a single evolutionary algorithm and to argue the superiority of one approach over another.
Reference: <editor> J.D. Schaffer, D. Whitley and L.J. Eshelman. </editor> <title> Combinations of Genetic Algorithms and Neural Networks: A Survey of the State of the Art In D. </title> <editor> Whitley and J.D. Schaffer, editors, </editor> <booktitle> Proc. of an International Workshop on Combinations of Genetic Algorithms and Neural Networks, </booktitle> <pages> pages 1-37. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year> <editor> Hans-Paul Schwefel. </editor> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <year> 1981. </year>
Reference: <author> Gilbert Syswerda. </author> <title> A Study of Reproduction in Generational and Steady State Genetic Algorithms. </title>
Reference: <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 94-101. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: We also show that higher order symmetries can exist which may make some types of genetic algorithms an inappropriate method of search. Separable functions are commonly used as test problems because they are scalable. This allows search algorithms to be tested on problems with progressively higher dimensionality <ref> (Muhlenbein, 1991) </ref>. Scalability is indeed desirable, but the nonlinear interactions in a test function should also be sensitive to scaling. We show that simple methods can be used for constructing test functions that allow nonlinear interactions between variables to be selectively scaled as the dimensionality of the problem is increased. <p> F8 are known as the Rastrigin (F6), Schwefel (F7) and Griewangk (F8) functions and can be scaled to any number of variables <ref> (Muhlenbein, 1991) </ref>. The functions labeled F9 and F10 are known as the sine envelope sine wave and the stretched V sine wave functions (Schaffer, et. al., 1989).
Reference: <author> Darrell Whitley. </author> <title> A Genetic Algorithm Tutorial. </title> <journal> Statistics and Computing, </journal> <volume> 4 </volume> <pages> 65-85, </pages> <year> 1994. </year>
Reference: <author> D. Whitley, T. Starkweather and C. Bogart. </author> <title> Genetic Algorithms and Neural Networks: Optimizing Connections and Connectivity. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 347-361, </pages> <year> 1990. </year>
Reference: <author> D. Whitley, K. Mathias, R. Rana, and J. Dzubera. </author> <title> Building Better Test Functions. </title> <editor> In L.J. Schaffer, editor, </editor> <booktitle> Proc. of the Fifth International Conference on Genetic Algorithms, </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1995. </year> <month> 35 </month>
References-found: 45

