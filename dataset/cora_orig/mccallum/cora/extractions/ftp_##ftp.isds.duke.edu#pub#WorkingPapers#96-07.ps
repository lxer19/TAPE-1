URL: ftp://ftp.isds.duke.edu/pub/WorkingPapers/96-07.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Decision Analysis by Augmented Probability Simulation  
Author: Concha Bielza Peter Muller David Ros Insua 
Address: Rey Juan Carlos, Spain  
Affiliation: 1 Decision Analysis Group, Madrid Technical University, Spain 2 Institute of Statistics and Decision Sciences, Duke University 3 School of Engineering, Universidad  
Abstract: We provide a generic Monte Carlo method to find the alternative of maximum expected utility in a decision analysis. We define an artificial distribution on the product space of alternatives and states, and show that the optimal alternative is the mode of the implied marginal distribution on the alternatives. After drawing a sample from the artificial distribution, we may use exploratory data analysis tools to approximately identify the optimal alternative. We illustrate our method for some important types of influence diagrams. (Decision Analysis, Influence Diagrams, Markov chain Monte Carlo, Simulation) 
Abstract-found: 1
Intro-found: 1
Reference: <author> Best, N., Cowles, M., Vines, K., CODA: </author> <title> Convergence Diagnosis and Output Analysis Software for Gibbs sampling output, </title> <type> Version 0.30, </type> <institution> Univ. of Cambridge, MRC Biostatistics Unit, </institution> <year> 1995. </year>
Reference-contexts: However, practical convergence may be judged with a number of criteria, see, e.g., Cowles and Carlin (1996) or Brooks and Roberts (1997). Most of these methods have been implemented in CODA <ref> (Best et al, 1995) </ref>, which we have used in our examples.
Reference: <author> Bielza, C., and Shenoy, P. </author> <title> "A comparison of graphical techniques for asymmetric decision problems", </title> <note> to appear in Management Sc., (1996). 26 Brewer, </note> <author> M., Aitken, C., and Talbot, M., </author> <title> "A comparison of hybrid strategies for Gibbs sampling in mixed graphical models," </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 21 (1996), </volume> <pages> 343-365. </pages>
Reference: <author> Brooks, S., and Roberts, G., </author> <title> "Assesing convergence of Markov chain Monte Carlo algorithms," </title> <type> Working Paper, </type> <institution> University of Cambridge, </institution> <year> 1997. </year>
Reference: <author> Carlin, B., Kadane, J., and Gelfand, A. </author> <title> "Approaches for optimal sequential decision analysis in clinical trials," </title> <type> Working Paper, </type> <institution> Univ. of Minnesota, </institution> <year> 1997. </year>
Reference: <author> Charnes, J., and Shenoy, P., </author> <title> "A forward Monte Carlo method for solving influence diagrams using local computation," </title> <type> Working paper, </type> <institution> School of Business, Univ. of Kansas, </institution> <year> 1996. </year>
Reference: <author> Clyde, M., Muller, P., and Parmigiani, G., </author> <title> "Exploring expected utility surfaces by Markov changes," </title> <type> Working Paper, </type> <institution> Duke University, </institution> <year> 1995. </year>
Reference: <author> Cooper, G., </author> <title> "A method for using belief networks as influence diagrams," </title> <booktitle> Uncertainty in Artificial Intelligence, Volume 4, Association for Uncertainty in AI, </booktitle> <publisher> Inc., </publisher> <address> Rome, N.Y., </address> <year> 1989, </year> <pages> 55-63. </pages>
Reference: <author> Cowles M., and Carlin, B., </author> <title> "Markov chain Monte Carlo convergence diagnostics: a comparative review," </title> <journal> J. American Statistal Association, </journal> <volume> 91 (1996), </volume> <pages> 883-904. </pages>
Reference: <author> Gelman, A., Roberts, G., and Gilks, W., </author> <title> "Efficient Metropolis jumping rules," </title> <type> Working Paper, </type> <institution> Univ. California, </institution> <year> 1994. </year>
Reference: <author> Gelfand, A., and Smith, A., </author> <title> "Sampling based approaches to calculating marginal densities," </title> <journal> J. American Statistical Association, </journal> <volume> 85 (1990), </volume> <pages> 398-409. </pages>
Reference-contexts: The strategy we propose now is very simple, but may be only undertaken in limited cases. Suppose the conditional distributions h (dj) and h (jd) are available for efficient random variate generation. Then, we suggest the following scheme, which is known as Gibbs sampler in the statistical literature <ref> (Gelfand and Smith, 1990) </ref>: (i) Start at an arbitrary value d 0 2 A, and set i = 1; (ii) Generate i ~ h (jd i1 ); (iii) Generate d i ~ h (dj i ); Set i = i + 1 and repeat steps (ii) and (iii) until convergence is
Reference: <author> Henrion, M., </author> <title> "Propagating uncertainty in bayesian networks by probabilistic logic sampling", </title> <note> 27 in J. </note> <editor> Lemmer and L. Kanal (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> Volume 2, </volume> <publisher> North Holland, </publisher> <pages> 149-163, </pages> <year> 1988. </year>
Reference-contexts: Exact algorithms, e.g. using clique join trees (Lauritzen and Spiegelhalter 1988), cutset conditioning (Pearl 1986) or arc reversal (Shachter 1986, 1988) proved to be intractable in many real-world networks, leading to approximate inference algorithms, comprising those based on simulation methods. This includes short run algorithms, such as Logic Sampling <ref> (Henrion 1988) </ref>, Likelihood Weighting (Shachter and Peot 1990) and its improved modifications: Bounded Variance and AA algorithms (Pradhan and Dagum 1996); and long run algorithms, using Markov chain Monte Carlo sampling like Gibbs sampling (Pearl 1987, Hrycej 1990, York 1992) or hybrid strategies (Brewer et al. 1996). <p> Depending on the specific choices of the implemented MCMC scheme and termination criteria, one would typically use order of magnitude 10,000 iterations (Palmer and Muller 1998). Discretizing the sample space, one could, in principle, also use Logic Sampling <ref> (Henrion, 1988) </ref>. However, Logic Sampling would not be advisable for this problem since the fraction of simulated experiments which generate variables corresponding to the actual observations would be close to zero (i.e., p (x fl E ) 0, in the notation of Shachter and 23 Peot, 1990).
Reference: <author> Hrycej, T., </author> <title> "Gibbs sampling in Bayesian networks," </title> <journal> Artificial Intelligence, </journal> <volume> 46 (1990), </volume> <pages> 351-364. </pages>
Reference: <author> Jenzarli, A., </author> <title> Solving Influence Diagrams using Gibbs sampling, </title> <type> Working Paper, </type> <institution> College of Business, University of Tampa, </institution> <year> 1995. </year>
Reference: <author> Lauritzen, S., and Spiegelhalter, D., </author> <title> "Local computations with probabilities on graphical structures and their application to expert systems," </title> <journal> Jour. Roy. Stat. Soc. B, </journal> <volume> 50 (1988), </volume> <pages> 157-224. </pages>
Reference-contexts: The problem of solving BN's is summarized, for example, in Shachter and Peot (1990). Exact algorithms, e.g. using clique join trees <ref> (Lauritzen and Spiegelhalter 1988) </ref>, cutset conditioning (Pearl 1986) or arc reversal (Shachter 1986, 1988) proved to be intractable in many real-world networks, leading to approximate inference algorithms, comprising those based on simulation methods.
Reference: <author> Matzkevich, I., and Abramson, B., </author> <booktitle> "Decision analytic networks in Artificial Intelligence," Management Sci., 41 (1995), </booktitle> <pages> 1-22. </pages>
Reference: <author> Miller, A.C., and Rice, T.R., </author> <title> "Discrete approximations of probability distributions," </title> <institution> Management Sci., </institution> <month> 29 </month> <year> (1983), </year> <pages> 352-363. </pages>
Reference-contexts: Therefore, only particular probability models are studied, as the multivariate Gaussian in Shachter and Kenley (1989), and inclusion of continuous variables in simple problems is carried out through discretization <ref> (Miller and Rice 1983, Smith 1991) </ref>, through summaries of the first few moments and derivatives (Smith 1993), or through approximations by means of Gaussian mixtures (Poland 1994).
Reference: <author> Muller, P., and Parmigiani, G., </author> <title> "Optimal design via curve fitting of Monte Carlo experiments," </title> <journal> J. American Statistical Association, </journal> <volume> 90 (1996), </volume> <pages> 1322-1330. </pages>
Reference: <author> Palmer, J.L., and Muller, P., </author> <title> "Bayesian Optimal Design in Population Models of Hematologic Data," </title> <journal> Statistics in Medicine, </journal> <note> to appear (1998). </note>
Reference-contexts: Following Jenzarli's (1995) proposal we could use Gibbs sampling to compute expected utilities. Depending on the specific choices of the implemented MCMC scheme and termination criteria, one would typically use order of magnitude 10,000 iterations <ref> (Palmer and Muller 1998) </ref>. Discretizing the sample space, one could, in principle, also use Logic Sampling (Henrion, 1988).
Reference: <author> Pearl, J., </author> <title> "Fusion, propagation and structuring in belief networks," </title> <journal> Artificial Intelligence, </journal> <volume> 29 (1986), </volume> <pages> 241-288. </pages>
Reference-contexts: The problem of solving BN's is summarized, for example, in Shachter and Peot (1990). Exact algorithms, e.g. using clique join trees (Lauritzen and Spiegelhalter 1988), cutset conditioning <ref> (Pearl 1986) </ref> or arc reversal (Shachter 1986, 1988) proved to be intractable in many real-world networks, leading to approximate inference algorithms, comprising those based on simulation methods.
Reference: <author> Pearl, J., </author> <title> "Evidential reasoning using stochastic simulation of causal models," </title> <journal> Artificial Intelligence, </journal> <volume> 32 (1987), </volume> <pages> 245-257. </pages> <note> 28 Pearl, </note> <editor> J. </editor> <booktitle> Probabilistic reasoning in intelligent systems, </booktitle> <publisher> Morgan-Kaufmann, </publisher> <address> San Francisco, </address> <year> 1988. </year>
Reference-contexts: This includes short run algorithms, such as Logic Sampling (Henrion 1988), Likelihood Weighting (Shachter and Peot 1990) and its improved modifications: Bounded Variance and AA algorithms (Pradhan and Dagum 1996); and long run algorithms, using Markov chain Monte Carlo sampling like Gibbs sampling <ref> (Pearl 1987, Hrycej 1990, York 1992) </ref> or hybrid strategies (Brewer et al. 1996). However, see Matzkevich and Abramson (1995), we only know of a couple of outlines of 2 simulation methods specifically for ID's in Jenzarli (1995) and Charnes and Shenoy (1996).
Reference: <author> Poland, W.B., </author> <title> Decision Analysis with continuous and discrete variables: a mixture distribution approach, </title> <type> PhD thesis, </type> <institution> Stanford University, Dept. of Engineering-Economic Systems, Stanford, </institution> <address> CA, </address> <year> 1994. </year>
Reference-contexts: models are studied, as the multivariate Gaussian in Shachter and Kenley (1989), and inclusion of continuous variables in simple problems is carried out through discretization (Miller and Rice 1983, Smith 1991), through summaries of the first few moments and derivatives (Smith 1993), or through approximations by means of Gaussian mixtures <ref> (Poland 1994) </ref>. In complicated problems, there may be no hope for an exact solution method and we may have to turn to approximate methods, specifically simulation.
Reference: <author> Polson, N.G., </author> <title> "Convergence of Markov chain Monte Carlo algorithms," </title> <editor> in J.M. Bernardo, J.O. Berger, A.P. Dawid, A.F.M. Smith (Eds), </editor> <booktitle> Bayesian Statistics 5, </booktitle> <address> Oxford U.P., </address> <year> 1996. </year>
Reference: <author> Pradhan, M., and Dagum, P., </author> <title> "Optimal Monte Carlo estimation of belief network inference," </title> <editor> in E. Horvitz and F. Jensen (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> Volume 12, </volume> <publisher> Morgan-Kaufmann, </publisher> <address> San Francisco, </address> <year> 1996, </year> <pages> 446-453. </pages>
Reference-contexts: This includes short run algorithms, such as Logic Sampling (Henrion 1988), Likelihood Weighting (Shachter and Peot 1990) and its improved modifications: Bounded Variance and AA algorithms <ref> (Pradhan and Dagum 1996) </ref>; and long run algorithms, using Markov chain Monte Carlo sampling like Gibbs sampling (Pearl 1987, Hrycej 1990, York 1992) or hybrid strategies (Brewer et al. 1996).
Reference: <author> Ros Insua, D., Salewicz, K., Muller, P., Bielza, C., </author> <title> "Bayesian methods in reservoir operations: the Zambezi river case," </title> <editor> in S. French and J.Q. Smith (Eds.), </editor> <title> The Practice of Bayesian Analysis, </title> <publisher> Arnold, </publisher> <year> 1997, </year> <pages> 107-130. </pages>
Reference: <author> Robert, </author> <title> C.P., "Convergence control methods for Markov chain Monte Carlo algorithms," </title> <journal> Statistical Sci., </journal> <volume> 10 (1995), </volume> <pages> 473-511. </pages>
Reference: <author> Shachter, R., </author> <title> "Evaluating influence diagrams," </title> <institution> Operations Res., </institution> <month> 34 </month> <year> (1986), </year> <month> 871-882. </month> |-, <title> "Probabilistic inference and influence diagrams," </title> <journal> Operations Res., </journal> <volume> 36 (1988), </volume> <pages> 589-604. </pages> |- <editor> and Kenley, R., </editor> <title> "Gaussian Influence Diagrams," </title> <institution> Management Sci., </institution> <note> 35 (1989), 527-550. </note> |- <author> and Peot, M., </author> <title> "Simulation approaches to general probabilistic inference on belief networks," </title> <editor> in M. Henrion, R. Shachter, L. Kanal and J. Lemmer (Eds.), </editor> <booktitle> Uncertainty in 29 Artificial Intelligence, </booktitle> <volume> Volume 5, </volume> <publisher> Elsevier, </publisher> <address> New York, </address> <year> 1990, </year> <note> 221-231. </note> |- <author> and Peot, M., </author> <title> "Decision making using probabilistic inference methods," </title> <booktitle> in Uncertainty in Artificial Intelligence, </booktitle> <volume> Volume 8, </volume> <publisher> Morgan Kauffman, </publisher> <address> San Francisco, </address> <year> 1992, </year> <pages> 276-283. </pages>
Reference-contexts: The problem of solving BN's is summarized, for example, in Shachter and Peot (1990). Exact algorithms, e.g. using clique join trees (Lauritzen and Spiegelhalter 1988), cutset conditioning (Pearl 1986) or arc reversal <ref> (Shachter 1986, 1988) </ref> proved to be intractable in many real-world networks, leading to approximate inference algorithms, comprising those based on simulation methods. <p> However, some general observations about the relative efficiency of the methods are possible. In problems with few alternatives, analytic solutions using methods like arc reversal <ref> (Shachter 1986) </ref>, and simulation methods which use simulation to pointwise evaluate expected utilities, like Likelihood Weighting (Shachter and Peot 1990), are typically more efficient than simulation over the auxiliary probability model.
Reference: <author> Shenoy, P., </author> <title> "A comparison of graphical techniques for decision analysis," </title> <journal> European Journal of Operational Research, </journal> <volume> 78 (1994), </volume> <pages> 1-21. </pages>
Reference: <author> Smith, A., </author> <title> "Bayesian computational methods," </title> <journal> Philosophical Transactions of the Royal Society of London, Series A, </journal> <volume> 337 (1991), </volume> <pages> 369-386. </pages>
Reference: <author> Smith, </author> <title> J.E., "Moment methods for Decision Analysis," </title> <institution> Management Sci., </institution> <month> 39 </month> <year> (1993), </year> <pages> 340-358. </pages>
Reference-contexts: Therefore, only particular probability models are studied, as the multivariate Gaussian in Shachter and Kenley (1989), and inclusion of continuous variables in simple problems is carried out through discretization (Miller and Rice 1983, Smith 1991), through summaries of the first few moments and derivatives <ref> (Smith 1993) </ref>, or through approximations by means of Gaussian mixtures (Poland 1994). In complicated problems, there may be no hope for an exact solution method and we may have to turn to approximate methods, specifically simulation.
Reference: <author> Smith, A., and Roberts, G., </author> <title> "Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods," </title> <journal> J. Royal Statistical Soc., B, </journal> <volume> 55 (1993), </volume> <pages> 3-24. </pages>
Reference-contexts: Therefore, only particular probability models are studied, as the multivariate Gaussian in Shachter and Kenley (1989), and inclusion of continuous variables in simple problems is carried out through discretization (Miller and Rice 1983, Smith 1991), through summaries of the first few moments and derivatives <ref> (Smith 1993) </ref>, or through approximations by means of Gaussian mixtures (Poland 1994). In complicated problems, there may be no hope for an exact solution method and we may have to turn to approximate methods, specifically simulation.
Reference: <author> Tanner, M. </author> <title> Tools for Statistical Inference, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1994. </year>
Reference: <author> Tierney, L., </author> <title> "Markov chains for exploring posterior distributions (with discussion)," </title> <journal> Annals of Statistics, </journal> <volume> 22 (1994), </volume> <pages> 1701-1762. </pages>
Reference: <author> York, J., </author> <title> "Use of the Gibbs sampler in expert systems," </title> <journal> Artificial Intelligence, </journal> <volume> 56 (1992), </volume> <pages> 115-130. </pages>
References-found: 33

