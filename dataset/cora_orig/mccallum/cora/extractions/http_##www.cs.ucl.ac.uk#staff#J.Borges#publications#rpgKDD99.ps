URL: http://www.cs.ucl.ac.uk/staff/J.Borges/publications/rpgKDD99.ps
Refering-URL: http://www.cs.ucl.ac.uk/staff/J.Borges/
Root-URL: http://www.cs.ucl.ac.uk
Email: Email:fj.borges, mleveneg@cs.ucl.ac.uk  
Title: Mining Navigation Patterns with Hypertext Probabilistic Grammars  
Author: Jose Borges and Mark Levene 
Keyword: Web data mining, hypertext, trails, probabilistic grammars.  
Web: RN/99/08  
Address: Gower Street London WC1E 6BT, U.K.  
Affiliation: Department of Computer Science University College London  
Abstract: The continuous growth in the size and use of the World Wide Web is creating difficulties in both the design of Web sites to suit a variety of different users and in the navigation through very large web structures of pages and links. We propose a data mining model that captures the user navigation behaviour patterns. The set of user navigation sessions, which characterise the interaction with the Web pages visited, are modelled as a Hypertext probabilistic grammar, whose higher probability derivated strings correspond to the user's preferred trails. An algorithm to efficiently mine such trails is given. In addition, we make use of the N - gram model which assumes that, when the user is browsing a given page, only the last n pages browsed affect the probability of the next page to be visited. Moreover, we propose the use of entropy as an estimator of the statistical properties of the grammar. Extensive experiments with both real and random data were conducted and the results show that, in practice, our algorithm runs in linear time in the size of the grammar. Our experiments also show that the entropy of the grammar is a good estimator of the number of mined trails, i.e. the mined rules, and the results from the experiments with the real data confirm the effectiveness of our model. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Borges, J., and Levene, M. </author> <year> 1998. </year> <title> Mining association rules in hypertext databasess. </title> <booktitle> In Proc. of the fourth Int. Conf. on Knowledge Discovery and Data Mining, </booktitle> <pages> 149-153. </pages>
Reference-contexts: In the first approach the log data is mapped into relational tables and then standard data mining techniques are invoked (Chen, Park, & Yu 1998). In the second approach new models and techniques have been developed which can be invoked directly on the log data <ref> (Borges & Levene 1998) </ref>. In this paper we adopt the second approach by specifying a new model for handling the problem which directly captures the semantics of the user navigation sessions. <p> roductions:update (Lef tState; State); 11. end for 13. end. 3.2 Depth-First Search Algorithm The algorithm proposed to mine for the grammar strings with probability above the confidence and support thresholds is a special case of the directed graph Depth-First Search (DFS) (Tarjan 1972) and is similar to that presented in <ref> (Borges & Levene 1998) </ref>. This algorithm essentially performs an exhaustive search of all the strings with the required characteristics. <p> In the experiments with random data we had two main objectives: (i) to evaluate the performance of the algorithms and (ii) to evaluate how the grammar entropy could be used as estimators of rules characteristics. The experiments were conducted for various grammar configurations. Since the model in <ref> (Borges & Levene 1998) </ref> was not sensitive to variations in the average density, O N , of the graph and was also not sensitive to the probability distribution of the weights of the links we decided to maintain these parameters fixed in this experiments. <p> In our previous work, <ref> (Borges & Levene 1998) </ref>, we propose to model the log data as directed graph with the arcs weights being probabilities that reflect the user interaction with the site and we generalised the association rule concept. (Schechter, Krishnan, & Smith 1998) proposes the use of log data to predict the next URL
Reference: <author> Charniak, E. </author> <year> 1996. </year> <title> Statistical Language Learning. </title> <publisher> The MIT Press. </publisher>
Reference-contexts: One model widely used in statistical language modeling for speech recognition is the N -gram model <ref> (Charniak 1996) </ref>. This model makes the assumption that only the previous n symbols have a direct effect on the probability of the next symbol to appear.
Reference: <author> Chen, M.-S.; Park, J. S.; and Yu, P. S. </author> <year> 1998. </year> <title> Efficient data mining for traversal patterns. </title> <journal> IEEE Trans. on Knowledge and Data Eng. </journal> <volume> 10(2) </volume> <pages> 209-221. </pages>
Reference-contexts: There have been so far two approaches to mining for user navigating patterns. In the first approach the log data is mapped into relational tables and then standard data mining techniques are invoked <ref> (Chen, Park, & Yu 1998) </ref>. In the second approach new models and techniques have been developed which can be invoked directly on the log data (Borges & Levene 1998). <p> average pattern is linear there is a significative variation in the results; therefore, the grammar entropy has an important role as the estimator of the number of rules for a specific grammar. 17 5 Related Work The use of data mining techniques to analyse log data was first proposed by <ref> (Chen, Park, & Yu 1998) </ref> and (Yan et al. 1996). In (Chen, Park, & Yu 1998) a technique for mining of user access navigation patterns is proposed. <p> results; therefore, the grammar entropy has an important role as the estimator of the number of rules for a specific grammar. 17 5 Related Work The use of data mining techniques to analyse log data was first proposed by <ref> (Chen, Park, & Yu 1998) </ref> and (Yan et al. 1996). In (Chen, Park, & Yu 1998) a technique for mining of user access navigation patterns is proposed.
Reference: <author> Cooley, R.; Mobasher, B.; and Srivastava, J. </author> <year> 1999. </year> <title> Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems 1(1). 19 Cover, </title> <editor> T. M., and Thomas, J. A. </editor> <year> 1991. </year> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: Finally, (Zaiane, Xin, & Han 1998) propose the use of data warehousing and data mining techniques to analyse Web records and <ref> (Cooley, Mobasher, & Srivastava 1999) </ref> study cleaning and preparation techniques to convert log data into user navigation sessions in a form amenable by the existing data mining techniques. 18 6 Concluding Remarks and Future Work We have proposed a model of Hypertext to capture user navigation preferences when navigating through the
Reference: <author> Craven, M.; DiPasquo, D.; Freitag, D.; McCallum, A.; Mitchell, T.; Nigam, K.; and Slattery, S. </author> <year> 1998. </year> <title> Learning to extract symbolic knowledge from the world wide web. </title> <booktitle> In Proc. of the 15th National Conf. on Artificial Intelligence. </booktitle>
Reference-contexts: Mining for information focuses on the development of techniques to assist users in processing the large amounts of data faced during navigating and help them find the information they are looking for; see for example <ref> (Craven et al. 1998) </ref>. On the other hand, mining for user navigation patterns focuses on techniques which study the user behaviour when navigating within a Web site.
Reference: <author> Feller, W. </author> <year> 1971. </year> <title> An Introduction to Probability Theory and Its Applications. </title> <publisher> John Wiley & Sons, second edition. </publisher>
Reference-contexts: two hypotheses when modelling a Hypertext grammar as a Markov chain by adding a further production F ! S to the grammar: (i) if p (F ! S) = 0 the chain is absorbing in state F ; (ii) if p (F ! S) = 1 the chain is irreducible <ref> (Feller 1971) </ref>. Note that there is always a path to F . In (i) a HPG corresponds to an absorbing Markov chain where the state F is a unique absorbing state.
Reference: <author> Hopcroft, J. E., and Ullman, J. D. </author> <year> 1979. </year> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In Figure 1 we show the grammar with n = 1 built from the set of navigation trails (sessions) shown in the figure. This example will be used throughout the paper, where the details will be clarified. (We freely utilise the duality between grammars and automata in our figures <ref> (Hopcroft & Ullman 1979) </ref>) ID Trail 1 A 1 ! A 2 ! A 3 ! A 4 3 A 5 ! A 2 ! A 4 5 A 5 ! A 2 ! A 4 ! A 6 In the inferred grammar, the probability of a production is proportional to <p> every state is a potential source and destination of a trail, i.e., a user is free to start or finish the navigation in any page of the Hypertext system depending on the topology of R. 4 2.2 Regular Grammars We now give the necessary background concerning regular grammars; refer to <ref> (Hopcroft & Ullman 1979) </ref> for more detail. An alphabet is a finite nonempty set of symbols, such as A = fa 1 ; : : : ; a n g.
Reference: <author> Levene, M., and Loizou, G. </author> <year> 1999. </year> <title> A probabilistic approach to navigation in hypertext. </title> <booktitle> Information Sciences 114 </booktitle> <pages> 165-186. </pages>
Reference-contexts: It is shown in <ref> (Levene & Loizou 1999) </ref> that the class of Hypertext languages, generated from Hypertext grammars, is closed under substrings, join and intersection but is not closed under union, complement or concatenation.
Reference: <author> Nielsen, J. </author> <year> 1990. </year> <title> Hypertext & Hypermedia. </title> <publisher> Academic Press. </publisher>
Reference-contexts: Finally, Section 6 presents our concluding remarks and plans for future work. 2 Hypertext Model 2.1 Hypertext Databases We formalise the essential characteristics of navigation in a Hypertext system, <ref> (Nielsen 1990) </ref>, via a Hypertext database which is a directed graph whose nodes represent units of information and whose arcs allow a user to follow links between the information units.
Reference: <author> Perkowitz, M., and Etzioni, O. </author> <year> 1997. </year> <title> Adaptive web sites: an AI challenge. </title> <booktitle> In Proc. of Int. Joint Conf. on Artificial Intelligence. </booktitle>
Reference-contexts: Understanding the visitors navigation preferences is an essential step both in the process of customising the site interface for the individual user (adaptive web sites as suggested in <ref> (Perkowitz & Etzioni 1997) </ref>) and of improving the site's static structure of the underlying hypertext system (Rosenfeld & Morville 1998). When Web users interact with a site, data recording their behaviour is stored in Web server logs. <p> A algorithm is then applied to find clusters of similar vectors. In <ref> (Perkowitz & Etzioni 1997) </ref> the authors formally challenged the AI community to use the the log data to create adaptive Web sites and in (Perkowitz & Etzioni 1998) they present their own approach, which consists in using log data to automatically create index pages, i.e., pages containing collections of links which
Reference: <author> Perkowitz, M., and Etzioni, O. </author> <year> 1998. </year> <title> Adaptive sites: Automatically synthesizing web pages. </title> <booktitle> In Proc. of the 15th National Conf. on Artificial Intelligence. </booktitle>
Reference-contexts: The experimental results also show that the entropy is not an estimator of the number of iterations or of the average rule length. 4.2 Real Data In this section we describe the experiments performed with real log files. The data was obtained from the authors of <ref> (Perkowitz & Etzioni 1998) </ref> and can be found in http://www.cs.washington.edu/research/adaptive/download.html. The log data contains two months of usage from the site http://www.hyperreal.- org/music/machines/. It should be noticed that: (i) the data was collected while the cache was disabled and (ii) we used the data without cleaning it. <p> A algorithm is then applied to find clusters of similar vectors. In (Perkowitz & Etzioni 1997) the authors formally challenged the AI community to use the the log data to create adaptive Web sites and in <ref> (Perkowitz & Etzioni 1998) </ref> they present their own approach, which consists in using log data to automatically create index pages, i.e., pages containing collections of links which the user navigation behaviour suggests are related.
Reference: <author> Rosenfeld, L., and Morville, P. </author> <year> 1998. </year> <title> Information Architecture for the World Wide Web. </title> <publisher> O'Reilly. </publisher>
Reference-contexts: Understanding the visitors navigation preferences is an essential step both in the process of customising the site interface for the individual user (adaptive web sites as suggested in (Perkowitz & Etzioni 1997)) and of improving the site's static structure of the underlying hypertext system <ref> (Rosenfeld & Morville 1998) </ref>. When Web users interact with a site, data recording their behaviour is stored in Web server logs. In a medium size site the log files can amount of several megabytes per day.
Reference: <author> Schechter, S.; Krishnan, M.; and Smith, M. D. </author> <year> 1998. </year> <title> Using path profiles to predict http requests. </title> <booktitle> Computer Networks and ISDN Systems 30 </booktitle> <pages> 457-467. </pages>
Reference-contexts: In our previous work, (Borges & Levene 1998), we propose to model the log data as directed graph with the arcs weights being probabilities that reflect the user interaction with the site and we generalised the association rule concept. <ref> (Schechter, Krishnan, & Smith 1998) </ref> proposes the use of log data to predict the next URL to be requested by a user so the server can generate dynamic content in advance, and reduce the latency of the request.
Reference: <author> Soule, S. </author> <year> 1974. </year> <title> Entropies of probabilistic grammars. </title> <booktitle> Information and Control 25 </booktitle> <pages> 57-74. </pages>
Reference-contexts: In a probabilistic grammar the sample space is the set of all generated strings leading to the next definition of grammar entropy according to <ref> (Soule 1974) </ref>. <p> In <ref> (Soule 1974) </ref> the entropy of probabilistic grammar with a unique absorbing state is defined as the vector H (G p ) = (I A) 1 j.
Reference: <author> Spiliopoulou, M., and Faulstich, L. C. </author> <year> 1998. </year> <title> WUM: A web utilization miner. </title> <booktitle> Int. Workshop on the Web and Databases. </booktitle>
Reference-contexts: A tree which contains the user paths is generated from the log data and an algorithm is proposed to predict the next request given the tree and the current user session. In <ref> (Spiliopoulou & Faulstich 1998) </ref> the authors propose a log data mining system composed of an aggregation module and a mining module.
Reference: <author> Stout, R. </author> <year> 1997. </year> <title> Web Site Stats: tracking hits and analyzing traffic. </title> <publisher> Osborne McGraw-Hill. </publisher>
Reference-contexts: In a medium size site the log files can amount of several megabytes per day. Moreover, since the log data is collected in a raw format it is an ideal target for being analysed by automated tools. There are currently available several commercial log analysis tools, <ref> (Stout 1997) </ref>; however, these tools have limited analysis capabilities producing only results such as summary statistics and frequency counts of page visits. There have been so far two approaches to mining for user navigating patterns.
Reference: <author> Tarjan, R. </author> <year> 1972. </year> <title> Depth-first search and linear graph algorithms. </title> <journal> SIAM Journal on Computing 1(2) </journal> <pages> 146-160. </pages>
Reference-contexts: StateSet:update (State); 10. P roductions:update (Lef tState; State); 11. end for 13. end. 3.2 Depth-First Search Algorithm The algorithm proposed to mine for the grammar strings with probability above the confidence and support thresholds is a special case of the directed graph Depth-First Search (DFS) <ref> (Tarjan 1972) </ref> and is similar to that presented in (Borges & Levene 1998). This algorithm essentially performs an exhaustive search of all the strings with the required characteristics.
Reference: <author> Wetherell, C. S. </author> <year> 1980. </year> <title> Probabilistic languages: A review and some open questions. </title> <journal> Computing Surveys 12(4) </journal> <pages> 361-379. </pages>
Reference-contexts: The productions are assigned a two-index numbering, P i;j , to facilitate their reference; the first index corresponds to the nonterminal in its left-hand side and the second to its position in the group of productions with the same left-hand side. 5 2.3 Probabilistic Regular Grammars In a probabilistic grammar <ref> (Wetherell 1980) </ref> each production has an attached probability; therefore, each string in the grammar language have an associated probability.
Reference: <author> Yan, T. W.; Jacobsen, M.; Garcia-Molina, H.; and Dayal, U. </author> <year> 1996. </year> <title> From user access patterns to dynamic hypertext linking. </title> <booktitle> In Proc. of the 5th Int. World Wide Web Conference, </booktitle> <pages> 1007-1014. </pages>
Reference-contexts: a significative variation in the results; therefore, the grammar entropy has an important role as the estimator of the number of rules for a specific grammar. 17 5 Related Work The use of data mining techniques to analyse log data was first proposed by (Chen, Park, & Yu 1998) and <ref> (Yan et al. 1996) </ref>. In (Chen, Park, & Yu 1998) a technique for mining of user access navigation patterns is proposed. <p> In (Chen, Park, & Yu 1998) a technique for mining of user access navigation patterns is proposed. The log data is converted into a form amenable by the existing data mining techniques and two algorithms are proposed to deal with the specificity of the rules in this context. <ref> (Yan et al. 1996) </ref> propose a method in which for each user session, inferred from log data, a vector is created that stores the number of visits in each page. A algorithm is then applied to find clusters of similar vectors.
Reference: <author> Zaiane, O. R.; Xin, M.; and Han, J. </author> <year> 1998. </year> <title> Discovering web access patterns and trends by applying olap and data mining technology on web logs. </title> <booktitle> In Proc. Advances in Digital Libraries Conf., </booktitle> <pages> 12-29. 20 </pages>
Reference-contexts: The aggregation module prepares the data for mining by constructing a tree, where trails with the same prefix are merged, and in which the mining is performed by a human expert using a mining query language which allows him to specify the characteristics of the required patterns. Finally, <ref> (Zaiane, Xin, & Han 1998) </ref> propose the use of data warehousing and data mining techniques to analyse Web records and (Cooley, Mobasher, & Srivastava 1999) study cleaning and preparation techniques to convert log data into user navigation sessions in a form amenable by the existing data mining techniques. 18 6 Concluding
References-found: 20

