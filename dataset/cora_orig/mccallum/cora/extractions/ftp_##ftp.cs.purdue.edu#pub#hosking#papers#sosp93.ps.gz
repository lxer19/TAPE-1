URL: ftp://ftp.cs.purdue.edu/pub/hosking/papers/sosp93.ps.gz
Refering-URL: http://www.cs.purdue.edu/homes/hosking/papers.html
Root-URL: http://www.cs.purdue.edu
Title: Protection traps and alternatives for memory management of an object-oriented language.  
Author: Antony L. Hosking J. Eliot B. Moss 
Address: Amherst, MA 01003  
Affiliation: Object Systems Laboratory Department of Computer Science University of Massachusetts  
Abstract: Many operating systems allow user programs to specify the protection level (inaccessible, read-only, read-write) of pages in their virtual memory address space, and to handle any protection violations that may occur. Such page-protection techniques have been exploited by several user-level algorithms for applications including generational garbage collection and persistent stores. Unfortunately, modern hardware has made efficient handling of page protection faults more difficult. Moreover, page-sized granularity may not match the natural granularity of a given application. In light of these problems, we reevaluate the usefulness of page-protection primitives in such applications, by comparing the performance of implementations that make use of the primitives with others that do not. Our results show that for certain applications software solutions outperform solutions that rely on page-protection or other related virtual memory primitives. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. E. Anderson, H. M. Levy, B. N. Bershad, and E. D. Lazowska. </author> <title> The interaction of architecture and operating system design. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 108-120, </pages> <address> Santa Clara, California, </address> <month> Apr. </month> <year> 1991. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 26, </volume> <month> 4 (Apr. </month> <year> 1991). </year> <pages> Page 13 </pages>
Reference-contexts: Meanwhile, there is evidence <ref> [1] </ref> to indicate that the evolution of architectures towards pipelined RISC microprocessors, and operating systems towards micro-kernels, is making efficient implementation of these operating system primitives more difficult. <p> The system call would clear the user-level dirty bits and enable traps on the specified pages. Traps could then be handled directly in the operating system. This can have substantial savings. As reported for a MIPS R2000 <ref> [1] </ref>, the time for a user program to trap to a null C routine in the kernel and return to the user program is 15.4s round trip.
Reference: [2] <author> A. Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software: Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: A number of schemes have been suggested for generating and maintaining the older-to-younger pointer information needed by generational collectors, including special-purpose hardware support [23, 24] and generation by compilers of the necessary inline code to perform the checks in software <ref> [2] </ref> (adding to the overhead of pointer stores). Ungar [23, 24] uses remembered sets to maintain the necessary information on a per-generation basis, recording the locations in older generations that may contain pointers into the generation.
Reference: [3] <author> A. W. Appel and K. Li. </author> <title> Virtual memory primitives for user programs. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 96-107, </pages> <address> Santa Clara, California, </address> <month> Apr. </month> <year> 1991. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 26, </volume> <month> 4 (Apr. </month> <year> 1991). </year>
Reference-contexts: As a result, application programmers have exercised their ingenuity in devising implementation solutions that make use of these virtual memory primitives. A number of these applications are enumerated by Appel and Li <ref> [3] </ref>, where they argue that in light of programmers demands, designers of operating systems and hardware architectures must pay more attention to support for virtual memory primitives to make their implementations more efficient and robust. <p> We then present the experimental setup used for gathering performance data, and our alternative implementations Page 1 of each of the applications along with their their relative per-formance. Finally, we summarize the major points of the paper and present our conclusions. 2 Applications Appel and Li <ref> [3] </ref> describe a number of applications of virtual memory primitives, including concurrent garbage collection, shared virtual memory, concurrent checkpointing, generational garbage collection, persistent stores, extending addressability, data-compression paging, and heap overflow detection. <p> Since modern operating systems and architectures typically use a relatively large virtual memory page size (on the order of thousands of bytes), scanning overheads will be proportionally higher. 2.1.1 User-level dirty bits If operating systems were to provide user-level dirty bits (as suggested by Shaw [20], and Appel and Li <ref> [3] </ref>), the overhead to reflect page traps through to the user-level protection violation handler can be avoided.
Reference: [4] <author> M. P. Atkinson, P. J. Bailey, K. J. Chisholm, P. W. Cockshott, and R. Morrison. </author> <title> An approach to persistent programming. </title> <journal> The Computer Journal, </journal> <volume> 26(4) </volume> <pages> 360-365, </pages> <month> Nov. </month> <year> 1983. </year>
Reference-contexts: more expensive than current primitives for manipulating page protections, except in copying out the dirty bit information, adding little if any extra overhead to applications that use the new primitive. 2.2 Persistent stores A persistent store is a dynamic allocation heap that persists from one program invocation to the next <ref> [4, 5] </ref>. Persistent programming languages allow traversal of the data structures in a persistent store to be programmed transparently, without the need for complicated I/O or database calls to retrieve the data.
Reference: [5] <author> M. P. Atkinson, K. J. Chisholm, W. P. Cockshott, and R. M. Marshall. </author> <title> Algorithms for a persistent heap. </title> <journal> Software: Practice and Experience, </journal> <volume> 13(7) </volume> <pages> 259-271, </pages> <month> Mar. </month> <year> 1983. </year>
Reference-contexts: more expensive than current primitives for manipulating page protections, except in copying out the dirty bit information, adding little if any extra overhead to applications that use the new primitive. 2.2 Persistent stores A persistent store is a dynamic allocation heap that persists from one program invocation to the next <ref> [4, 5] </ref>. Persistent programming languages allow traversal of the data structures in a persistent store to be programmed transparently, without the need for complicated I/O or database calls to retrieve the data.
Reference: [6] <author> R. G. G. Cattell and J. Skeen. </author> <title> Object operations benchmark. </title> <journal> ACM Trans. Database Syst., </journal> <volume> 17(1) </volume> <pages> 1-31, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Table 4 enumerates the variants. 3.3.2 Benchmarks We use the Lookup and Traversal portions of the OO1 object operations benchmarks <ref> [6] </ref>. The OO1 benchmark database consists of a collection of 20,000 part objects, indexed by part numbers in the range 1 through 20,000, with exactly three connections from each part to other parts.
Reference: [7] <author> A. Goldberg and D. Robson. </author> <title> Smalltalk-80: The Language and its Implementation. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: While unswizzling we may see references to new (not yet persistent) objects, which are assigned OIDs and made persistent. 3 Experiments All of our experiments are based on a high-performance Smalltalk interpreter of our own design, using the abstract definition of Goldberg and Robson <ref> [7] </ref>. The implementation consists of two components: the virtual machine and the virtual image. The virtual machine implements a bytecode instruction set to which Smalltalk source code is compiled, as well as other primitive functionality. While we have retained the standard bytecode instruction set of Goldberg and Robson [7], our implementation <p> and Robson <ref> [7] </ref>. The implementation consists of two components: the virtual machine and the virtual image. The virtual machine implements a bytecode instruction set to which Smalltalk source code is compiled, as well as other primitive functionality. While we have retained the standard bytecode instruction set of Goldberg and Robson [7], our implementation of the virtual machine differs somewhat from their original definition to allow for more efficient execution. Our virtual machine running on the DECstation 3100 performs around three times faster than a microcoded implementation on the Xerox Dorado.
Reference: [8] <author> A. L. Hosking, E. Brown, and J. E. B. Moss. </author> <title> Update logging for persistent programming languages: A comparative performance evaluation. </title> <booktitle> In Proceedings of the Nineteenth International Conference on Very Large Data Bases, </booktitle> <address> Dublin, Ireland, Aug. 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [9] <author> A. L. Hosking and J. E. B. Moss. </author> <title> Object fault handling for persistent programming languages: A performance evaluation. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <address> Washington, DC, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: For a fair comparison with hardware-assisted variants we also apply this indirection elimination to the software scheme. The architecture leaves open the possibility of making any number of objects resident at one time. In an earlier study <ref> [9] </ref> we considered the granularities inherent in the underlying object storage manager: individual objects, logical segments, and physical segments. Swizzling just one object at a time has the advantage of faulting just those objects needed by the program for it to continue execution.
Reference: [10] <author> A. L. Hosking, J. E. B. Moss, and D. Stefanovic. </author> <title> A comparative performance evaluation of write barrier implementations. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 92-109, </pages> <address> Vancouver, Canada, </address> <month> Oct. </month> <year> 1992. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 27, </volume> <month> 10 (Oct. </month> <year> 1992). </year>
Reference-contexts: Subsequent writes to the now dirty page incur no further overhead. Note that all writes to a clean page cause a protection trap, not just those that store pointers. The time required to determine the relevant older-to-younger pointers for garbage collection varies with the granularity of the information recorded <ref> [10] </ref>. Remembered sets have the advantage of recording just those locations that can possibly contain older-to-younger pointers. In contrast, the time to scan dirty cards is proportional to the size of the cards. <p> In contrast to our earlier performance studies <ref> [10] </ref>, we have reimplemented the card and page trap schemes to avoid unnecessary scanning, by combining the precision of remembered sets with the simplicity of card marking. <p> The results for the Interactive benchmark are similarly shown in Figure 3. To the extent that garbage collection overheads affect total execution time, the results are conclusive, with the page-sized granularity imposing significant overhead in scanning to determine root objects for collection. In contrast with our earlier results <ref> [10] </ref>, we see that summarizing interesting pointer information into remembered sets for use in subsequent scavenges can reduce this scanning overhead, such that the card schemes are competitive with the pure remembered set scheme. Nevertheless, the pure remembered set scheme has markedly less overhead to determine the roots.
Reference: [11] <author> T. Kaehler. </author> <title> Virtual memory on a narrow machine for an object-oriented language. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 87-106, </pages> <address> Portland, Oregon, </address> <month> Sept. </month> <year> 1986. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 21, </volume> <month> 11 (Nov. </month> <year> 1986). </year>
Reference-contexts: This technique originated in early attempts to extend the address space of Smalltalk-80 <ref> [11, 12] </ref>.
Reference: [12] <author> T. Kaehler and G. Krasner. </author> <title> LOOMlarge object-oriented memory for Smalltalk-80 systems. </title> <booktitle> In Krasner [13], chapter 14, </booktitle> <pages> pages 251-270. </pages>
Reference-contexts: This technique originated in early attempts to extend the address space of Smalltalk-80 <ref> [11, 12] </ref>.
Reference: [13] <author> G. Krasner, </author> <title> editor. Smalltalk-80: Bits of History, Words of Advice. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference: [14] <author> C. Lamb, G. Landis, J. Orenstein, and D. Weinreb. </author> <title> The ObjectStore database system. </title> <journal> Commun. ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The fault and indirect block pages are then reprotected before resuming execution of the program. Other approaches use page protections in a different way <ref> [14, 19, 21, 27] </ref>. When a given persistent object is to be assigned a virtual address, a page of virtual memory is reserved (although not necessarily allocated) for the page in the persistent store that contains the object.
Reference: [15] <author> H. Lieberman and C. Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Commun. ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Our results also have implications for the other applications, since they show that well-designed software solutions are competitive with hardware-assisted techniques. 2.1 Generational garbage collection Generational garbage collectors <ref> [15, 23, 24] </ref> achieve short collection pause times partly because they separate heap-allocated objects into two or more generations and do not process all generations during each collection.
Reference: [16] <author> K. McCall. </author> <title> The Smalltalk-80 benchmarks. </title> <booktitle> In Krasner [13], chapter 9, </booktitle> <pages> pages 153-173. </pages>
Reference-contexts: The first is a synthetic benchmark of our own devising based on tree creation. The second consists of several iterations through the standard macro benchmark suite that is used to compare the relative performance of Smalltalk implementations <ref> [16] </ref>. Our benchmarks have the following characteristics: * Destroytrees with destructive updates: A large initial tree (~2M bytes) is repeatedly mutated by randomly choosing a subtree to be replaced and fully recreated.
Reference: [17] <author> J. E. B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Rather, all extensions involve the virtual machine, so that objects are faulted as they are needed by the executing image. Permanent storage for the virtual image is provided by an underlying persistent object storage manager <ref> [17] </ref>. Since objects are too small a unit for efficient individual transfer to and from disk, the storage manager groups objects together into physical segments for transfer between the permanent database and its in-memory buffers. Physical segments may have arbitrary size (up to some large system-defined limit).
Reference: [18] <author> J. E. B. Moss. </author> <title> Working with persistent objects: To swizzle or not to swizzle. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 18(8) </volume> <pages> 657-673, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: only ever see virtual memory addresses. 2.2.2 Extending addressability Persistent stores may grow so large that they contain more objects than can be addressed directly by the available hardware. 1 Dealing with this problem involves converting persistent store OIDs into virtual memory addresses, a process which has been termed swizzling <ref> [18] </ref>. This technique originated in early attempts to extend the address space of Smalltalk-80 [11, 12].
Reference: [19] <institution> Object Design, Inc. ObjectStore User Guide, </institution> <month> Oct. </month> <year> 1990. </year> <note> Release 1.0. </note>
Reference-contexts: The fault and indirect block pages are then reprotected before resuming execution of the program. Other approaches use page protections in a different way <ref> [14, 19, 21, 27] </ref>. When a given persistent object is to be assigned a virtual address, a page of virtual memory is reserved (although not necessarily allocated) for the page in the persistent store that contains the object.
Reference: [20] <author> R. A. Shaw. </author> <title> Improving garbage collector performance in virtual memory. </title> <type> Technical Report CSL-TR-87-323, </type> <institution> Stanford University, </institution> <month> Mar. </month> <year> 1987. </year>
Reference-contexts: Since modern operating systems and architectures typically use a relatively large virtual memory page size (on the order of thousands of bytes), scanning overheads will be proportionally higher. 2.1.1 User-level dirty bits If operating systems were to provide user-level dirty bits (as suggested by Shaw <ref> [20] </ref>, and Appel and Li [3]), the overhead to reflect page traps through to the user-level protection violation handler can be avoided.
Reference: [21] <author> V. Singhal, S. V. Kakkad, and P. R. Wilson. </author> <title> Texas, an efficient, portable persistent store. </title> <booktitle> In Proceedings of the Fifth International Workshop on Persistent Object Systems, </booktitle> <pages> pages 11-33, </pages> <address> San Miniato, Italy, </address> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: The fault and indirect block pages are then reprotected before resuming execution of the program. Other approaches use page protections in a different way <ref> [14, 19, 21, 27] </ref>. When a given persistent object is to be assigned a virtual address, a page of virtual memory is reserved (although not necessarily allocated) for the page in the persistent store that contains the object.
Reference: [22] <author> P. G. Sobalvarro. </author> <title> A lifetime-based garbage collector for LISP systems on general-purpose computers, 1988. B.S. </title> <type> Thesis, </type> <institution> Dept. of EECS, Massachusetts Institute of Technology, </institution> <address> Cambridge. </address>
Reference-contexts: The heap is divided into aligned logical regions of size 2 k bytesthe address of the first byte in the region will have k low bits zero. These regions are called cards <ref> [22, 28] </ref>. Each card has a corresponding entry in a table indicating whether the card might contain a pointer of interest to the garbage collector. Mapping an address to an entry in the table involves shifting the address right by k bits and using the result to index the table.
Reference: [23] <author> D. Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 157-167, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> Apr. </month> <year> 1984. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 19, </volume> <month> 5 (May </month> <year> 1984). </year>
Reference-contexts: Our results also have implications for the other applications, since they show that well-designed software solutions are competitive with hardware-assisted techniques. 2.1 Generational garbage collection Generational garbage collectors <ref> [15, 23, 24] </ref> achieve short collection pause times partly because they separate heap-allocated objects into two or more generations and do not process all generations during each collection. <p> A number of schemes have been suggested for generating and maintaining the older-to-younger pointer information needed by generational collectors, including special-purpose hardware support <ref> [23, 24] </ref> and generation by compilers of the necessary inline code to perform the checks in software [2] (adding to the overhead of pointer stores). Ungar [23, 24] uses remembered sets to maintain the necessary information on a per-generation basis, recording the locations in older generations that may contain pointers into <p> A number of schemes have been suggested for generating and maintaining the older-to-younger pointer information needed by generational collectors, including special-purpose hardware support <ref> [23, 24] </ref> and generation by compilers of the necessary inline code to perform the checks in software [2] (adding to the overhead of pointer stores). Ungar [23, 24] uses remembered sets to maintain the necessary information on a per-generation basis, recording the locations in older generations that may contain pointers into the generation.
Reference: [24] <author> D. M. Ungar. </author> <title> The Design and Evaluation of a High Performance Smalltalk System. </title> <publisher> ACM Distinguished Dissertations. The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year> <type> Ph.D. Dissertation, </type> <institution> University of California at Berkeley, </institution> <month> February </month> <year> 1986. </year>
Reference-contexts: Our results also have implications for the other applications, since they show that well-designed software solutions are competitive with hardware-assisted techniques. 2.1 Generational garbage collection Generational garbage collectors <ref> [15, 23, 24] </ref> achieve short collection pause times partly because they separate heap-allocated objects into two or more generations and do not process all generations during each collection. <p> A number of schemes have been suggested for generating and maintaining the older-to-younger pointer information needed by generational collectors, including special-purpose hardware support <ref> [23, 24] </ref> and generation by compilers of the necessary inline code to perform the checks in software [2] (adding to the overhead of pointer stores). Ungar [23, 24] uses remembered sets to maintain the necessary information on a per-generation basis, recording the locations in older generations that may contain pointers into <p> A number of schemes have been suggested for generating and maintaining the older-to-younger pointer information needed by generational collectors, including special-purpose hardware support <ref> [23, 24] </ref> and generation by compilers of the necessary inline code to perform the checks in software [2] (adding to the overhead of pointer stores). Ungar [23, 24] uses remembered sets to maintain the necessary information on a per-generation basis, recording the locations in older generations that may contain pointers into the generation.
Reference: [25] <author> R. Wahbe. </author> <title> Efficient data breakpoints. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 200-212, </pages> <address> Boston, Massachusetts, </address> <month> Sept. </month> <year> 1992. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 27, </volume> <month> 9 (Sept. </month> <year> 1991). </year>
Reference-contexts: It is worthwhile noting that similar results have been obtained in other very different application areas, such as efficient implementation of data breakpoints for debuggers <ref> [25] </ref>. We speculate that sub-page protection and dirty bits, along with appropriate operating systems interfaces, might somewhat overcome the performance disadvantages we observed. However, it is clear that while user level virtual memory primitives are transparent solutions to various memory management problems, they do not necessarily offer the best performance.
Reference: [26] <author> S. J. White and D. J. DeWitt. </author> <title> A performance study of alternative object faulting and pointer swizzling strategies. </title> <booktitle> In Proceedings of the Eighteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 419-431, </pages> <address> Vancouver, Canada, Aug. 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These benchmarks all use the exact same object faulting and swizzling scheme, while varying the update detection mechanism. 3.4.2 Benchmarks Previous studies have extended the Traversal operation of the OO1 object database benchmarks to also perform some modification of part objects <ref> [26] </ref>. Each part accessed during the traversal may be updated based on some known probability fixed in advance. For example, if the probability of update is 0.5 then approximately half of all parts visited will be modified. <p> Given these observations, we believe that our results are likely to carry over to compiled languages, at least for the most part, but certainly admit the necessity of further experimentation. We do note that the somewhat contrary results of White and DeWitt <ref> [26] </ref>, for the E persistent programming language, are for a compiler that does not incorporate any of the techniques for eliminating explicit checks that we describe in this section. 5 Conclusions We compared the performance of application implementations that exploit virtual memory primitives against implementations using software techniques.
Reference: [27] <author> P. R. Wilson and S. V. Kakkad. </author> <title> Pointer swizzling at page fault time: Efficiently and compatibly supporting huge address spaces on standard hardware. </title> <booktitle> In Proceedings of the 1992 International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 364-377, </pages> <address> Paris, France, Sept. 1992. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: The fault and indirect block pages are then reprotected before resuming execution of the program. Other approaches use page protections in a different way <ref> [14, 19, 21, 27] </ref>. When a given persistent object is to be assigned a virtual address, a page of virtual memory is reserved (although not necessarily allocated) for the page in the persistent store that contains the object.
Reference: [28] <author> P. R. Wilson and T. G. Moher. </author> <title> Design of the Opportunistic Garbage Collector. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 23-35, </pages> <address> New Orleans, Louisiana, </address> <month> Oct. </month> <year> 1989. </year> <journal> ACM SIGPLAN Not. </journal> <volume> 24, </volume> <month> 10 (Oct. </month> <year> 1989). </year> <pages> Page 14 </pages>
Reference-contexts: The heap is divided into aligned logical regions of size 2 k bytesthe address of the first byte in the region will have k low bits zero. These regions are called cards <ref> [22, 28] </ref>. Each card has a corresponding entry in a table indicating whether the card might contain a pointer of interest to the garbage collector. Mapping an address to an entry in the table involves shifting the address right by k bits and using the result to index the table.
References-found: 28

