URL: http://www.mli.gmu.edu/~bloedorn/papers/Spring96.ps
Refering-URL: http://www.mli.gmu.edu/~bloedorn/pubs.html
Root-URL: 
Email: -bloedorn,imani,macmilla-@mitre.org  
Title: Representational Issues in Machine Learning of User Profiles  
Author: Eric Bloedorn, Inderjeet Mani, and T. Richard MacMillan 
Keyword: Machine Learning and Inference Laboratory  
Address: Z401 7525 Colshire Drive, McLean, VA 22102  Fairfax, VA 22030  
Affiliation: Artificial Intelligence Technical Center The MITRE Corporation,  George Mason University,  
Abstract: As more information becomes available electronically, tools for finding information of interest to users become increasingly important. Building tools for assisting users in finding relevant information is often complicated by the difficulty in articulating user interest in a form that can be used for searching. The goal of the research described here is to build a system for generating comprehensible user profiles that accurately capture user interest with minimum user interaction. Machine learning methods offer a promising approach to solving this problem. The research described here focuses on the importance of a suitable generalization hierarchy and representation for learning profiles which are predictively accurate and comprehensible. In our experiments using AQ15c and C4.5 we evaluated both traditional features based on weighted term vectors as well as subject features corresponding to categories which could be drawn from a thesaurus. Our experiments, conducted in the context of a content-based profiling system for online newspapers on the World Wide Web (the IDD News Browser) demonstrate the importance of a generalization hierarchy in obtaining high predictive accuracy, precision and recall, and stability of learning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Armstrong, R.; Freitag, T.; Joachims, T.; and Mitchell, T. </author> <year> 1995. </year> <title> WebWatcher: A learning apprentice for the World Wide Web, </title> <booktitle> In Proceedings 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher <ref> (Armstrong et al. 1995) </ref>, WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests.
Reference: <author> Belew, R. </author> <year> 1989. </year> <title> Adaptive Information Retrieval: Using a Connectionist Representation to Retrieve and Learn about Documents, </title> <booktitle> ACM SIGIR, </booktitle> <pages> 11-20. </pages>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), <ref> (Belew 1989) </ref>, (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Belkin N. and Croft, B. </author> <year> 1992. </year> <title> Information Filtering and Information Retrieval: Two Sides of the Same Coin?, </title> <journal> CACM, </journal> <month> December </month> <year> 1992, </year> <pages> 35, (12): 29-38. </pages>
Reference-contexts: Introduction As more information becomes available on the Internet, the need for effective personalized information filters becomes critical. In particular, there is a need for tools to capture profiles of users information needs, and to find articles relevant to these needs, as these needs change over time. Information filtering, as <ref> (Belkin and Croft 92) </ref>, (Foltz and Dumais 92) point out, is an information access activity similar to information retrieval, but where the profiles represent evolving interests of users over a long-term period, and where the filters are applied to dynamic streams of incoming data.
Reference: <author> Bloedorn, E.; Michalski, R. and Wnek, J. </author> <year> 1993. </year> <title> Multistrategy Constructive Induction: </title> <booktitle> AQ17-MCI, In Proceedings of the Second International Workshop on Multistrategy Learning, </booktitle> <pages> 188-203. </pages>
Reference: <author> Bloedorn, E. and Michalski, R. </author> <year> 1996. </year> <title> The AQ17-DCI system for Data-Driven Constructive Induction. </title> <booktitle> In Proceedings of the International Symposium on Methodologies for Intelligent Systems. </booktitle> <publisher> Forthcoming. </publisher>
Reference: <author> Broglio, J. and Croft, B. </author> <year> 1993. </year> <title> Query Processing for Retrieval from Large Text Bases. </title> <booktitle> In Proceedings of Human Language Technology Workshop. </booktitle>
Reference-contexts: These features were provided by a name tagger (discussed in the next section). That such features could help profile learning was suggested in part by some recent query reformulation research <ref> (Broglio & Croft 1993) </ref>, which had shown improved retrieval performance on TIPSTER queries using such features. In summary, our experiments evaluated the effects of different subsets of features on the learning of intelligible profiles.
Reference: <author> Buckley, C.; Salton, G. and Allan, J. </author> <year> 1994. </year> <title> The Effect of Adding Relevance Information in a Relevance Feedback Environment. </title> <booktitle> ACM SIGIR 1994. </booktitle>
Reference-contexts: Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), <ref> (Buckley, Salton, & Allan 1994) </ref>, have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion. While this body of work is not necessarily focused exclusively on the information filtering problem, it demonstrates effectively how learning can be used to improve queries. <p> In these experiments individual articles are represented as vectors of 30,000 tf-idf features. Our Rocchio method is based on the procedure described in <ref> (Buckley, Salton, & Allan 1994) </ref>. As before, the training involved induction of a new profile based on feedback from the pre-classified training examples, as follows. <p> This average was converted from a tf.idf measure to a tf measure by dividing each tf.idf value by the idf. The profile was then reweighted using the modified Rocchio formula below. This formula transforms the weight of a profile term k from pold to p-new as follows <ref> (Buckley, Salton, & Allan 1994) </ref>: p-new k =(a * p-old k ) + ( r i=1 dw ik ) - ( s i=1 dw ik ) r = number of relevant documents s= number of nonrelevant documents (all nonrelevant documents) dw ik = tf weight of term k in document i
Reference: <author> Foltz, P. and Dumais, S. </author> <year> 1992. </year> <title> Personalized Information Delivery: An Analysis of Information-Filtering Methods. </title> <type> CACM 35 </type> (12):51-60. 
Reference-contexts: In particular, there is a need for tools to capture profiles of users information needs, and to find articles relevant to these needs, as these needs change over time. Information filtering, as (Belkin and Croft 92), <ref> (Foltz and Dumais 92) </ref> point out, is an information access activity similar to information retrieval, but where the profiles represent evolving interests of users over a long-term period, and where the filters are applied to dynamic streams of incoming data.
Reference: <author> Evans, D.; Hersh, W.; Monarch, I.; Lefferts, R. and Henderson, S. </author> <year> 1991a. </year> <title> Automatic Indexing of Abstracts via Natural-Language Processing Using a Simple Thesaurus, Medical Decision Making 11 (supp), </title> <publisher> S108-S115. </publisher>
Reference: <author> Evans, D.; Ginther-Webster, K.; Hart, M.; Lefferts, R. and Monarch, I. </author> <year> 1991b. </year> <title> Automatic Indexing using Selective NLP and First-Order Thesauri. </title> <booktitle> In Proceedings of RIAO-91. </booktitle> <pages> 624-644. </pages>
Reference: <author> Haines, D. and Croft, B. </author> <year> 1993. </year> <title> Relevance Feedback and Inference Networks. </title> <booktitle> ACM SIGIR 1993. </booktitle>
Reference-contexts: Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), <ref> (Haines & Croft 1993) </ref>, (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Harman, D. </author> <year> 1992. </year> <title> Relevance Feedback Revisited. </title> <booktitle> ACM SIGIR 1992. </booktitle>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), <ref> (Harman 1992) </ref>, (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Harman, D. </author> <year> 1994. </year> <title> Overview of the Third Text Retrieval Conference (TREC-3). </title> <institution> Computer Systems Laboratory, National Institute of Standards and Technology. </institution>
Reference: <author> Hearst, M. and Schutze, H. </author> <year> 1992. </year> <title> Customizing a Lexicon to Better Suit a Computational Task. </title> <booktitle> In Proceedings of the ACL SIGLEX Workshop on Acquisition of Lexical Knowledge from Text, </booktitle> <address> Columbus, Ohio. </address>
Reference: <author> Jones, S.; Gatford, M.; Robertson, S.; Hancock-Beaulieu, M. Secker, J. and Walker, S. </author> <title> Interactive Thesaurus Navigation: </title> <journal> Intelligence Rules OK? Journal of the American Society for Information Science, </journal> <volume> 46 </volume> (1):52-59. 
Reference: <author> Lang, K. </author> <year> 1995. </year> <title> NewsWeeder: Learning to Filter Netnews. </title> <booktitle> In Proceedings of the Twelth International Workshop on Machine Learning. </booktitle> <pages> 331-339. </pages>
Reference-contexts: Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder <ref> (Lang 1995) </ref>. One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests.
Reference: <author> Lashkari, Y.; Metral, M. and Maes, P. </author> <year> 1994. </year> <title> Collaborative interface agents. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound <ref> (Lashkari, Metral, & Maes 1994) </ref>, WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests.
Reference: <author> Liddy, E. and Myaeng, S. </author> <year> 1992. </year> <title> DR-LINK's Linguistic-Conceptual Approach to Document Detection. </title> <booktitle> In Proceedings of the First Text Retrieval Conference. </booktitle> <institution> Natl. Institute of Standards and Technology. </institution>
Reference-contexts: One well-known problem which arises here is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term. We decided to apply the approach used by <ref> (Liddy & Paik 1992) </ref> (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. <p> One well-known problem which arises here is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term. We decided to apply the approach used by (Liddy & Paik 1992) <ref> (Liddy & Myaeng 1992) </ref>, which exploits evidence from local context and large-scale statistics. <p> We decided to apply the approach used by (Liddy & Paik 1992) (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. This resulted in our using the Subject Field Coder (SFC) <ref> (Liddy and Myaeng 1992) </ref> (Liddy and Paik 1992) (from TextWise, Inc.), which produces a vector representation of a text's subject categories, based on a thesaurus of 124 subject categories (the SFC is discussed in more detail in the next section). <p> We decided to apply the approach used by (Liddy & Paik 1992) (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. This resulted in our using the Subject Field Coder (SFC) (Liddy and Myaeng 1992) <ref> (Liddy and Paik 1992) </ref> (from TextWise, Inc.), which produces a vector representation of a text's subject categories, based on a thesaurus of 124 subject categories (the SFC is discussed in more detail in the next section). <p> The experiments reported here investigate the effect of different representations on learning new profiles. Text Representation As mentioned earlier, we used a hybrid representation with three different sources of features. We now describe these in turn. The Subject Field Coder (SFC) <ref> (Liddy & Myaeng 1992) </ref> (Liddy & Paik 1992) (from TextWise, Inc.) produces a summary-level semantic representation of a text's contents, based on a thesaurus of 124 subject categories. <p> The experiments reported here investigate the effect of different representations on learning new profiles. Text Representation As mentioned earlier, we used a hybrid representation with three different sources of features. We now describe these in turn. The Subject Field Coder (SFC) (Liddy & Myaeng 1992) <ref> (Liddy & Paik 1992) </ref> (from TextWise, Inc.) produces a summary-level semantic representation of a text's contents, based on a thesaurus of 124 subject categories. <p> An earlier version of the SFC, which used subject codes from Longmans Dictionary of Contemporary English (LDOCE), was tested on 166 sentences from the Wall Street Journal (1638 words). It gave the right category on 87% of the words <ref> (Liddy & Myaeng 1992) </ref>.
Reference: <author> Liddy, E. and Paik, W. </author> <year> 1992. </year> <title> Statistically Guided Word-Sense Disambiguation. </title> <booktitle> In Proceedings of the AAAI Fall Symposium Series: Probabilistic Approaches to Natural Language. </booktitle> <address> Menlo Park, Calif.; </address> <booktitle> American Association for Artificial Intelligence. </booktitle>
Reference-contexts: One well-known problem which arises here is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term. We decided to apply the approach used by <ref> (Liddy & Paik 1992) </ref> (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. <p> One well-known problem which arises here is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term. We decided to apply the approach used by (Liddy & Paik 1992) <ref> (Liddy & Myaeng 1992) </ref>, which exploits evidence from local context and large-scale statistics. <p> We decided to apply the approach used by (Liddy & Paik 1992) (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. This resulted in our using the Subject Field Coder (SFC) <ref> (Liddy and Myaeng 1992) </ref> (Liddy and Paik 1992) (from TextWise, Inc.), which produces a vector representation of a text's subject categories, based on a thesaurus of 124 subject categories (the SFC is discussed in more detail in the next section). <p> We decided to apply the approach used by (Liddy & Paik 1992) (Liddy & Myaeng 1992), which exploits evidence from local context and large-scale statistics. This resulted in our using the Subject Field Coder (SFC) (Liddy and Myaeng 1992) <ref> (Liddy and Paik 1992) </ref> (from TextWise, Inc.), which produces a vector representation of a text's subject categories, based on a thesaurus of 124 subject categories (the SFC is discussed in more detail in the next section). <p> The experiments reported here investigate the effect of different representations on learning new profiles. Text Representation As mentioned earlier, we used a hybrid representation with three different sources of features. We now describe these in turn. The Subject Field Coder (SFC) <ref> (Liddy & Myaeng 1992) </ref> (Liddy & Paik 1992) (from TextWise, Inc.) produces a summary-level semantic representation of a text's contents, based on a thesaurus of 124 subject categories. <p> The experiments reported here investigate the effect of different representations on learning new profiles. Text Representation As mentioned earlier, we used a hybrid representation with three different sources of features. We now describe these in turn. The Subject Field Coder (SFC) (Liddy & Myaeng 1992) <ref> (Liddy & Paik 1992) </ref> (from TextWise, Inc.) produces a summary-level semantic representation of a text's contents, based on a thesaurus of 124 subject categories. <p> An earlier version of the SFC, which used subject codes from Longmans Dictionary of Contemporary English (LDOCE), was tested on 166 sentences from the Wall Street Journal (1638 words). It gave the right category on 87% of the words <ref> (Liddy & Myaeng 1992) </ref>.
Reference: <author> Maes, P. </author> <year> 1994. </year> <title> Agents That Reduce Work and Information Overload. </title> <journal> CACM, </journal> <volume> 37 </volume> (7):31-40, 146-147. 
Reference-contexts: One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT <ref> (Maes 1994) </ref>, Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests. <p> Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound <ref> (Lashkari, Metral, & Maes 1994) </ref>, WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests.
Reference: <author> Mani, I.; MacMillan T.; Luperfoy, S. Lusher, E. and Laskowski, J. </author> <year> 1993. </year> <title> Identification of Unknown Proper Names in Newswire Text. </title> <booktitle> In Proceedings of the ACL SIGLEX Workshop on Acquisition of Lexical Knowledge from Text. </booktitle>
Reference-contexts: It gave the right category on 87% of the words (Liddy & Myaeng 1992). The second extraction system we used was the IDD POL Tagger <ref> (Mani et al 1993) </ref>, (Mani & MacMillan 1995) which classifies names in unrestricted newswire text in terms of a hierarchy of different types of people (military officers, corporate officers, etc.), organizations (drug companies, government organizations, etc.), and places (cities, countries, etc.), along with their attributes (e.g., a persons title, an organizations
Reference: <author> Mani, I. and MacMillan, T. </author> <year> 1995. </year> <title> Identifying Unknown Proper Names in Newswire Text. </title> <editor> in J. Pustejovsky, ed., </editor> <title> Corpus Processing for Lexical Acquisition, </title> <publisher> MIT Press. </publisher>
Reference-contexts: In summary, our experiments evaluated the effects of different subsets of features on the learning of intelligible profiles. Our experiments were conducted in the context of a content-based profiling system for online newspapers on the World Wide Web, the IDD News Browser <ref> (Mani et al. 1995) </ref>. In this system, which is in use at MITRE, the user can set up and edit profiles, which are periodically run against various collections built from live Internet newspaper and USENET feeds, to generate matches in the form of personalized newspapers. <p> It gave the right category on 87% of the words (Liddy & Myaeng 1992). The second extraction system we used was the IDD POL Tagger (Mani et al 1993), <ref> (Mani & MacMillan 1995) </ref> which classifies names in unrestricted newswire text in terms of a hierarchy of different types of people (military officers, corporate officers, etc.), organizations (drug companies, government organizations, etc.), and places (cities, countries, etc.), along with their attributes (e.g., a persons title, an organizations business, a citys country,
Reference: <author> Menczer, F.; Willuhn, W. and Belew, R. </author> <year> 1994. </year> <title> An Endogenous Fitness Paradigm for Adaptive Information Agents. </title> <booktitle> In Proceedings of the CIKM94 Workshop on Intelligent Information Agents. </booktitle>
Reference: <author> Millet, G.; Beckwith, R.; Fellbaum, C.; Gross, D. and Miller, K. </author> <year> 1990. </year> <title> Introduction to WordNet: An online lexical database. </title> <journal> Journal of Lexicography, </journal> <volume> 3 </volume> (4):235-244. 
Reference: <author> Mitchell, T.; Caruana, R. Freitag, D. McDermott, J. and Zabowski, D. </author> <year> 1994. </year> <title> Experience with a Learning Personal Assistant. </title> <journal> CACM 37(7) </journal> <pages> 81-91. </pages>
Reference-contexts: A personalized news filtering agent which engages in exploratory behavior must gain the confidence of the user. In many practical situations, a human may need to validate or edit the systems learnt profiles; as <ref> (Mitchell et al. 1994) </ref> point out, intelligibility of profiles to humans is important in such situations. We speculated that the use of such a hybrid representation which exploits summary-level features such as subject categories would increase the intelligibility of profiles.
Reference: <author> Pazzani, M.; Nguyen, L. and Mantik, S. </author> <year> 1995. </year> <title> Learning from Hotlists and Coldlists: Towards a WWW Information Filtering and Seeking Agent. </title> <booktitle> In Proceedings of the AI Tools Conference. </booktitle>
Reference-contexts: Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner <ref> (Pazzani et al. 1995) </ref> and NewsWeeder (Lang 1995). One of the motivations for our approach was the discovery that the above research had paid little attention to learning generalizations about users interests.
Reference: <author> Quinlan, J. </author> <year> 1992. </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We wanted to use learning methods which performed inductive generalization, where the SFC generalization hierarchy could be exploited. Also, we required a learning algorithm whose learnt rules could be made easily intelligible to users. We decided to try both AQ15c (Wnek, Bloedorn, & Michalski 1994) and C4.5-Rules <ref> (Quinlan, 1992) </ref> because they meet these requirements (the generalization hierarchy is made available to C4.5 by extending the attribute set), are well-known in the field and are readily available. AQ15c is based on the A q algorithm for generating disjunctive normal form (DNF) expressions with internal disjunction from examples.
Reference: <author> Quinlan, J. </author> <year> 1995. </year> <type> personal communication. </type>
Reference-contexts: Here AQ15c has the hierarchy available to it in the form of hierarchical domain definitions for attributes x1 through x5. C4.5 has a hierarchy available to it through an extended attribute set. In this extension, based on a pointer from Quinlan <ref> (Quinlan, 1995) </ref>, we extended the attribute set to include attributes which describe nodes higher up on the generalization hierarchy.
Reference: <author> Robertson, S. and Sparck-Jones, K. </author> <year> 1976. </year> <title> Relevance Weighting of Search Terms. </title> <journal> Journal of the American Society for Information Science 27 </journal> (3):129-146. 
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), <ref> (Robertson & Sparck-Jones 1976) </ref>, (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Rocchio, J. </author> <year> 1971. </year> <title> Relevance Feedback in Information Retrieval. in The SMART Retrieval System: Experiments in Automatic Document Processing. </title> <address> 313-323, </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., <ref> (Rocchio 1971) </ref>, (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Salton, G. and Buckley, C. </author> <year> 1990. </year> <title> Improving Retrieval Performance by Relevance Feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <note> :88-297 Salton, </note> <author> G. and McGill, M. </author> <year> 1983. </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), <ref> (Salton & Buckley 1990) </ref>, (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Schutze, H.; Hull, D. and Pedersen, J. </author> <year> 1995. </year> <title> A Comparison of Classifiers and Document Representations for the Routing Problem. </title> <booktitle> ACM SIGIR 1995. </booktitle>
Reference: <author> Sheth, B. </author> <year> 1993. </year> <title> A Learning Approach to Personalized Information Filtering. M.S. </title> <type> Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, MIT. </institution>
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Some early MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback <ref> (Sheth & Maes 1993) </ref>, (Sheth 1993). One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). <p> Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Some early MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback (Sheth & Maes 1993), <ref> (Sheth 1993) </ref>. One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). <p> MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback <ref> (Sheth & Maes 1993) </ref>, (Sheth 1993). One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995).
Reference: <author> Sheth, B. and Maes, P. </author> <year> 1993. </year> <title> Evolving Agents for Personalized Information Filtering. </title> <booktitle> In Proceedings of the Ninth IEEE Conference on Artificial Intelligence Applications. </booktitle>
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Some early MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback <ref> (Sheth & Maes 1993) </ref>, (Sheth 1993). One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). <p> Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Some early MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback (Sheth & Maes 1993), <ref> (Sheth 1993) </ref>. One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). <p> MIT Media Lab work used a genetic algorithm approach to generate new profiles, which were evaluated based on user feedback <ref> (Sheth & Maes 1993) </ref>, (Sheth 1993). One of the goals of that approach was exploratory behavior.... so as to explore newer domains that might be of interest to the user. (Sheth & Maes 1993). Since that time, a number of other systems for personalized information filtering have appeared on the scene, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995).
Reference: <author> Sparck-Jones, K. </author> <year> 1972. </year> <title> A Statistical Interpretation of Term Specificity and Its Application in Retrieval. </title> <journal> Journal of Documentation 28 </journal> (1):11-20. 
Reference: <author> Wnek, J.; Kaufman, K.; Bloedorn, E. and Michalski, R. </author> <year> 1995. </year> <title> Selective Inductive Learning Method AQ15c: The Method and User's Guide. Reports of the Machine Learning and Inference Laboratory, </title> <institution> ML95-4, George Mason Univ. </institution>
References-found: 36

