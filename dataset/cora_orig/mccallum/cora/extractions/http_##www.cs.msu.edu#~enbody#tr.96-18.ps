URL: http://www.cs.msu.edu/~enbody/tr.96-18.ps
Refering-URL: http://www.cs.msu.edu/~enbody/
Root-URL: http://www.cs.msu.edu
Title: A Load-Balanced Parallel Algorithm For Eigenvalue Problems  
Author: Xiaozhuo Yang 
Date: April 11, 1996  
Address: East Lansing, MI 48824  
Affiliation: Department of Computer Science Michigan State University  
Pubnum: Technical Report 96-18  
Abstract: This project presents a balanced parallel algorithm to solve the eigenvalue problems. A divide-and-conquer technique is used to generate the initial approximations; then the Aberth method is used to refine the approximations simultaneously. The straightforward approach leads to an unbalanced utilization of processors so a dynamically load balanced approach was developed and demonstrated. We implemented the algorithm on both the Intel Touchstone Delta multicomputer and a cluster of workstations running the Message Passing Interface. Our results show that the method is competitive to the fastest serial code: hqr from Eispack. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Aberth, </author> <title> Iteration Methods for Finding all Zeros of a Polynomial Simultaneously. </title> <journal> Math. Comp., </journal> <volume> Vol.27,1973, </volume> <pages> pp. 339-344 </pages>
Reference-contexts: Notice that the zeros at t = 0 are the eigenvalues of D and that the zeros at t = 1 are the eigenvalues of A. We begin by choosing points t i in the interval <ref> [0; 1] </ref> such that 0 = t 0 &lt; t 1 &lt; t 2 &lt; &lt; t m = 1 for some positive integer m. The idea is to use the zeros at t i as the initial approximations of the zeros at t i+1 . <p> Then we discuss how the Aberth method is applied to eigenvalue problems. The Aberth method was proposed independently by several authors <ref> [1, 3, 7] </ref>. This method is an iterative method of simultaneously finding all roots of a monic complex polynomial.
Reference: [2] <author> J.Cuppen, </author> <title> A divide and conquer method for the symmetric tridiagonal matrices, </title> <journal> Numer. Math., </journal> <volume> 36(1981), </volume> <pages> pp. 177-195. </pages>
Reference-contexts: 1 Introduction The algebraic eigenvalue problem is one of the fundamental problems in computational mathematics. In recent years parallel algorithms for eigenvalue problems have attracted many researchers. Significant success in parallel algorithms for symmetric eigenvalue problem has been achieved <ref> [2, 4] </ref>. The success for symmetric eigenvalue problems relies heavily on the interlacing property of the eigenvalues of the original matrix and the eigenvalues of the modified problem. In parallel algorithms for non-symmetric eigenvalue problems, the eigenvalues of the modified problem no longer interlace with those of the original matrix.
Reference: [3] <author> K. Docev, </author> <title> A modified Newton method for the simultaneous approximation of all roots of the given algebraic equations, </title> <journal> Fiz. Mat. </journal>
Reference-contexts: Then we discuss how the Aberth method is applied to eigenvalue problems. The Aberth method was proposed independently by several authors <ref> [1, 3, 7] </ref>. This method is an iterative method of simultaneously finding all roots of a monic complex polynomial.
Reference: [4] <author> J. Dongarra, C. Sorensen, </author> <title> A fully parallel algorithm for the symmetric eigenvalue problem, </title> <journal> SIAM J. Sci. Statist. Comput. </journal> <volume> 8(1978), </volume> <pages> pp. 139-154. </pages>
Reference-contexts: 1 Introduction The algebraic eigenvalue problem is one of the fundamental problems in computational mathematics. In recent years parallel algorithms for eigenvalue problems have attracted many researchers. Significant success in parallel algorithms for symmetric eigenvalue problem has been achieved <ref> [2, 4] </ref>. The success for symmetric eigenvalue problems relies heavily on the interlacing property of the eigenvalues of the original matrix and the eigenvalues of the modified problem. In parallel algorithms for non-symmetric eigenvalue problems, the eigenvalues of the modified problem no longer interlace with those of the original matrix.
Reference: [5] <author> J. Dongarra, M. Sidani, </author> <title> A parallel algorithm for the nonsymmetric eigenvalue problem, </title> <journal> SIAM J. Sci. Comput. </journal> <volume> 5(1993), </volume> <pages> pp. 542-569. </pages>
Reference-contexts: In parallel algorithms for non-symmetric eigenvalue problems, the eigenvalues of the modified problem no longer interlace with those of the original matrix. Recently, T.Y. Li and Z. Zeng [14], J. Dongarra and M. Sidani <ref> [5] </ref> proposed parallel algorithms for non-symmetric eigenvalue problems from two different points of view. The former used the idea of homotopy and exploited the property of real homotopy. They handled the bifurcations and curve jumpings effectively. The latter used a divide-and-conquer approach and rank one teasing.
Reference: [6] <author> E. Durand, </author> <title> Solutions Numeriques des Equations Algebriques, T.I. </title> <address> Paris 1960. </address>
Reference-contexts: The values of the left-hand side of the first equation in (4) is then @F @ . 5 Related Work There are other methods which find all the roots of a polynomial simultaneously, see for example, <ref> [6, 13, 9] </ref>.
Reference: [7] <author> L.W. Ehrlich, </author> <title> A modified Newton method for polynomials , Comm. </title> <booktitle> ACM 10 (1967) pp. </booktitle> <pages> 107-108. </pages>
Reference-contexts: Then we discuss how the Aberth method is applied to eigenvalue problems. The Aberth method was proposed independently by several authors <ref> [1, 3, 7] </ref>. This method is an iterative method of simultaneously finding all roots of a monic complex polynomial.
Reference: [8] <author> Enbody, R.J., Li, T.Y., Xiaozhuo, Y., </author> <title> A Parallel Algorithm For The Nonsymmetric Eigenvalue Problems, </title> <booktitle> 7th SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> San Francisco, </address> <year> 1995, </year> <pages> pp. 569-570. </pages>
Reference-contexts: The n approximations are divided into m blocks, each has k approximations. The i-th node is responsible for the i-th block of approximations. In <ref> [8] </ref> we implemented this approach and showed that this parallel algorithm can beat the best serial algorithm, HQR from Eispack, for a sufficiently large number of processors using an Intel Touchstone Delta multicomputer. In our implementation, the matrix is divided in the middle into two smaller real upper Hessenberg matrices. <p> We tested the matrices of degree up to 360 fi 360. The results show that the balanced program saves about 10% for the chosen class of matrices compared to the unbalanced program. (See <ref> [8] </ref> for a comparison of the unbalanced program to the serial HQR.) Figures 5 and 6 show the timing information for test matrices of degree 240 fi 240 and degree 360 fi 360.
Reference: [9] <author> M.R.Farmer, G. Loizou, </author> <title> A Class Of Iteration Functions For Improving, Simultaneously, Approximations To The Zeros Of A Polynomial, </title> <journal> BIT 15 (1975),pp. </journal> <volume> 250 - 158. </volume> <pages> 21 </pages>
Reference-contexts: The values of the left-hand side of the first equation in (4) is then @F @ . 5 Related Work There are other methods which find all the roots of a polynomial simultaneously, see for example, <ref> [6, 13, 9] </ref>.
Reference: [10] <author> T.L. </author> <title> Freeman Calculating Polynomial zeros on a local memory parallel computer, </title> <address> Paralle Com--puting 12(1989) 351-358. </address>
Reference-contexts: 1 Q 1 (x 1 ; x 2 ; ; x (k) x 2 = x 2 Q 2 (x 1 ; x 2 ; ; x (k) n = x (k) (k) (k) n ) ; While most papers discuss the local convergence properties of the proposed methods, Freeman <ref> [10] </ref> implemented three methods on Transputers to find the zeros of polynomials. Given m slave Transputers and a polynomial p (z) of degree n, the initial n approximations are evenly distributed across the m slave Transputers.
Reference: [11] <author> H.J. Hamilton, </author> <title> A Type of Variation on Newton's Method, </title> <journal> Amer. Math. Monthly, </journal> <volume> 57, </volume> <pages> 517-522(1950). </pages>
Reference-contexts: x (k) j n = x (k) p (x n ) (k) (k) P 1 n x (k) ; The Aberth method converges cubically without evaluating the second derivatives while most other methods which converge cubically require the evaluation of the second derivative, e.g., La-guerre's method [16] and Halley's method <ref> [11] </ref>. Many people have observed that the Aberth method converges globally in practice. In the following we give a simple example to demonstrate how the Aberth method works.
Reference: [12] <author> M. Hyman, </author> <title> Eigenvalues and Eigenvectors of General Matrices, </title> <booktitle> presented at the 12th National Meeting of the ACM, </booktitle> <address> Houston, Texas, </address> <month> June </month> <year> 1957. </year>
Reference-contexts: For this purpose, Hyman's method <ref> [12] </ref> is used which is remarkably backward stable as pointed out by Wilkinson [18]. Notice that det (DI) = det (A 11 I) det (A 22 I).
Reference: [13] <author> I Kerner, </author> <title> Ein Gessamtschrittverfahren zur Berechung der Nullstellen von Polynooem. </title> <journal> Num. Math. </journal> <volume> 8(1966), </volume> <pages> 290-294. </pages>
Reference-contexts: The values of the left-hand side of the first equation in (4) is then @F @ . 5 Related Work There are other methods which find all the roots of a polynomial simultaneously, see for example, <ref> [6, 13, 9] </ref>.
Reference: [14] <author> T.Y.Li , Zhonggang Zeng, </author> <title> Homotopy-determinant algorithm for solving nonsymmetric eigenvalue problems, </title> <journal> Math. Comp. </journal> <volume> 10(1992), </volume> <pages> pp. 483-502. </pages>
Reference-contexts: In parallel algorithms for non-symmetric eigenvalue problems, the eigenvalues of the modified problem no longer interlace with those of the original matrix. Recently, T.Y. Li and Z. Zeng <ref> [14] </ref>, J. Dongarra and M. Sidani [5] proposed parallel algorithms for non-symmetric eigenvalue problems from two different points of view. The former used the idea of homotopy and exploited the property of real homotopy. They handled the bifurcations and curve jumpings effectively.
Reference: [15] <author> T.Y. Li, T. Sauer, J. Yorke, </author> <title> The random product homotopy and deficient polynomial systems, </title> <type> preprint, </type> <institution> the Department of Mathematics, Michigan State University. </institution>
Reference-contexts: Since H (; t) is a polynomial in of degree n for any fixed t, there are n zeros 1 (t), 2 (t), : : : , n (t) . They are called the eigenpaths of (1). From <ref> [15] </ref> we know that the eigenpaths do not meet 3 in the t interval (0; 1); it is an important property of the above homotopy. Basically, the result says that for a randomly chosen complex number c, the eigenpaths do not meet in the space C 2 fi (0; 1).
Reference: [16] <author> B.N.Parlett, </author> <title> Laguerre's Method Applied to Matrix Eigenvalue Problem, </title> <journal> Math. Comp. </journal> <volume> 18(1965), </volume> <pages> pp. 464-485. </pages>
Reference-contexts: (x 2 ) j6=2 x (k) j n = x (k) p (x n ) (k) (k) P 1 n x (k) ; The Aberth method converges cubically without evaluating the second derivatives while most other methods which converge cubically require the evaluation of the second derivative, e.g., La-guerre's method <ref> [16] </ref> and Halley's method [11]. Many people have observed that the Aberth method converges globally in practice. In the following we give a simple example to demonstrate how the Aberth method works.
Reference: [17] <author> Steve Smale, </author> <title> The Fundamental Theorem of Algebra and Complexity Theory, </title> <journal> Bull. Amer. Math. Soc., </journal> <volume> 4(1981), </volume> <pages> pp. 1-36. </pages>
Reference-contexts: Table 1, Table 2, Table 3 and Table 4 show how Newton's iterations converge. Starting from the four chosen initial approximations, Newton's method finds only three roots. The approximations starting from 1:95 and 30 converge to the same root, 2. Moreover, Newton's method does not always converges <ref> [17] </ref>.
Reference: [18] <author> J.H. Wilkinson, </author> <title> Error Analysis of Floating-point Computation, </title> <journal> Numer. Math. </journal> <volume> 2(1960, </volume> <pages> 319-340. 22 </pages>
Reference-contexts: For this purpose, Hyman's method [12] is used which is remarkably backward stable as pointed out by Wilkinson <ref> [18] </ref>. Notice that det (DI) = det (A 11 I) det (A 22 I).
References-found: 18

