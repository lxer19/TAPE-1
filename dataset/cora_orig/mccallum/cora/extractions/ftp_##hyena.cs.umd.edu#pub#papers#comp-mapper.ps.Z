URL: ftp://hyena.cs.umd.edu/pub/papers/comp-mapper.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/hpsl/compilers/compilers-pub-abs.html
Root-URL: 
Title: Runtime Compilation Techniques for Data Partitioning and Communication Schedule Reuse  
Author: Ravi Ponnusamy yz Joel Saltz Alok Choudhary 
Address: College Park, MD 20742 Syracuse, NY 13244  
Affiliation: Computer Science Department Northeast Parallel Architectures Center University of Maryland Syracuse University  
Abstract: In this paper, we describe two new ideas by which HPF compiler can deal with irregular computations effectively. The first mechanism invokes a user specified mapping procedure via a set of compiler directives. The directives allow the user to use program arrays to describe graph connectivity, spatial location of array elements and computational load. The second is a simple conservative method that in many cases enables a compiler to recognize that it is possible to reuse previously computed results from inspectors (e.g. communication schedules, loop iteration partitions, information that associates off-processor data copies with on-processor buffer locations). We present performance results for these mechanisms from a Fortran 90D compiler implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Baden. </author> <title> Programming abstractions for dynamically partitioning and coordinating localized scientific calculations running on multiprocessors. </title> <journal> SIAM J. Sci. and Stat. Computation., </journal> <volume> 12(1), </volume> <month> January </month> <year> 1991. </year>
Reference-contexts: Our GEOMETRY construct can be viewed as a particular type of value based decomposition. Several researchers have developed programming environments that are targeted towards particular classes of irregular or adaptive problems. Williams [25] describes a programming environment (DIME) for calculations with unstructured triangular meshes using distributed memory machines. Baden <ref> [1] </ref> has developed a programming environment targeted towards particle computations. This programming environment provides facilities that support dynamic load balancing. There are a variety of compiler projects targeted at distributed memory multiprocessors [27, 16].
Reference: [2] <author> M.J. Berger and S. H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36(5):570-580, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function. <p> There are many partitioning heuristics methods available based on physical phenomena and physical proximity <ref> [24, 2, 25, 13] </ref>. Currently these partitioners must be coupled to user programs in a manual fashion. This manual coupling is particularly troublesome and tedious when we wish to make use of parallelized partitioners. <p> In such cases, each mesh point is associated with a location in space. We can assign each graph vertex a set of coordinates that describe its spatial location. These spatial locations can be used to partition data structures <ref> [2, 22] </ref>. Vertices may also be assigned weights to represent estimated computational costs. In order to accurately estimate computational costs, we need information on how work will be partitioned. <p> We present the performance of our runtime techniques on different number of processors on an Intel iPSC/860. To map arrays we employed two different kinds of parallel partitioners 1) a geometry based partitioner ( coordinate bisection <ref> [2] </ref>) and 2) a connectivity based partitioner (recursive spectral bisection [24]). The performance of the compiler embedded mapper version and hand parallelized version are shown in Table 2.
Reference: [3] <author> Harry Berryman, Joel Saltz, and Jeffrey Scroggs. </author> <title> Execution time support for adaptive scientific algorithms on distributed memory machines. </title> <journal> Concur-rency: Practice and Experience, </journal> <volume> 3(3) </volume> <pages> 159-178, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Future work will include exploration of this optimization. Supercomputing '93 5 4 Coupling Partitioners In irregular problems, it is often desirable to allocate computational work to processors by assigning all computations that involve a given loop iteration to a single processor <ref> [3] </ref>. Consequently, we partition both distributed arrays and loop iterations using a two-phase approach (Figure 2). In the first phase, termed a "data partitioning" phase, distributed arrays are partitioned. In the second phase, called "workload partitioning", loop iterations are partitioned using the information from the first phase.
Reference: [4] <author> B. R. Brooks, R. E. Bruccoleri, B. D. Olafson, D. J. States, S. Swaminathan, and M. Karplus. Charmm: </author> <title> A program for macromolecular energy, minimization, and dynamics calculations. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 4:187, </volume> <year> 1983. </year>
Reference-contexts: These timings involve a loop over edges of an 3-D unstructured Euler solver [20] for 10K and 53K mesh points and an electrostatic force calculation loop in a molecular dynamics code for 648 atom water simulation <ref> [4] </ref>; the functionality of these loops is equivalent to the loop L2 in Figure 1. <p> We tested our prototype compiler on computational templates extracted from an unstructured mesh computational fluid dynamics code [20] and from a molecular dynamics code <ref> [4] </ref>. We embedded our runtime support by hand and compared its performance against the compiler generated code. The compiler's performance on these templates was within about 10% of the hand compiled code.
Reference: [5] <author> T. W. Clark, R. v. Hanxleden, J. A. McCammon, and L. R. Scott. </author> <title> Parallelization strategies for a molecular dynamics program. In Intel Supercomputer University Partners Conference, </title> <address> Timberline Lodge, Mt. Hood, OR, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: For instance, we find that it is sometimes important to take estimated computational costs into account when carrying out coordinate or inertial bisection for problems where computational costs vary greatly from node to node. Other par-titioners make use of both geometrical and connectivity information <ref> [5] </ref>.
Reference: [6] <author> R. Das, R. Ponnusamy, J. Saltz, and D. Mavriplis. </author> <title> Distributed memory compiler methods for irregular problems data copy reuse and runtime partitioning. In Compilers and Runtime Software for Scalable Multiprocessors, </title> <editor> J. Saltz and P. Mehrotra Editors, Ams-terdam, </editor> <address> The Netherlands, 1992. </address> <publisher> Elsevier. </publisher>
Reference-contexts: In earlier work, several of the authors of the current paper outlined a strategy (but did not attempt a compiler implementation) that would make it possible for compilers to generate compiler embedded connectivity based parti-tioners directly from marked loops <ref> [6] </ref>. The approach described here requires more input from the user and lesser compiler support. 8 Conclusions In this paper, we have described and and presented timing data for a prototype Fortran 90D compiler implementation. The work described here demonstrates two new ideas for dealing effectively with irregular computations.
Reference: [7] <author> R. Das and J. H. Saltz. </author> <title> Program slicing techniques for compiling irregular problems. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland , OR, </address> <month> August </month> <year> 1993. </year> <booktitle> Supercomputing '93 11 </booktitle>
Reference-contexts: Compile time analysis needed to reuse inspector communication schedules is touched upon in <ref> [12, 7] </ref>. We propose a simple conservative method that in many cases allows us to reuse the results from inspectors.
Reference: [8] <author> D. Loveman (Ed.). </author> <title> Draft High Performance Fortran language specification, version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Vienna Fortran, Fortran D and HPF (evolved from Fortran D and Fortran 90) provide a rich set of data decomposition specifications; a definition of such language extensions may be found in <ref> [10, 8] </ref>. These languages, as currently specified, require that users explicitly define how data is to be distributed. Fortran D can be used to explicitly specify an irregular inter-processor partition of distributed array elements. In Figure 3, we present an example of such a Fortran D declaration.
Reference: [9] <author> Z. Bozkus et al. </author> <title> Compiling fortran 90d/hpf for distributed memory mimd computers. </title> <type> Report SCCS-444, </type> <institution> NPAC, Syracuse University, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: We use this loop to demonstrate our runtime procedures and compiler transformations in the following sections. We have implemented our methods as part of the Fortran 90D compiler being developed by Syracuse University <ref> [9] </ref>. Our implementation results on simple templates reveal that the performance of the compiler generated code is within 10% of the hand parallelized version. This paper is organized as follows. We set the context of the work in Section 2.
Reference: [10] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <institution> Department of Computer Science Rice COMP TR90-141, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: In this paper, we present methods and a prototype implementation where we demonstrate techniques that make it possible for compilers to efficiently handle irregular problems coded using a set of language extensions closely related to Fortran D <ref> [10] </ref> or Vienna Fortran [28]. On distributed memory architectures, loops with indirect array accesses can be handled by transforming the original fl This work was sponsored in part by ARPA (NAG-1-1485), NSF (ASC 9213821) and ONR (SC292-1-22913). Author Choudhary was also supported by NSF Young Investigator award (CCR-9357840). <p> Vienna Fortran, Fortran D and HPF (evolved from Fortran D and Fortran 90) provide a rich set of data decomposition specifications; a definition of such language extensions may be found in <ref> [10, 8] </ref>. These languages, as currently specified, require that users explicitly define how data is to be distributed. Fortran D can be used to explicitly specify an irregular inter-processor partition of distributed array elements. In Figure 3, we present an example of such a Fortran D declaration.
Reference: [11] <author> R. v. Hanxleden. </author> <title> Compiler support for machine independent parallelization of irregulr problems. </title> <type> Technical report, </type> <note> Center for Research on Parallel Computation, </note> <year> 1992. </year>
Reference-contexts: The GEOMETRY construct is closely related to the geometrical partitioning or value based decomposition directives proposed by von Hanxleden <ref> [11] </ref>. Similarly, a GeoCoL data structure which specifies only vertex weights can be constructed using the keyword LOAD as follows. C$ CONSTRUCT G2 (N, LOAD (weight)) Here, a GeoCoL construct called G2 consists of N ver tices with vertex i having LOAD weight (i). <p> Irregular distribution of arrays performs much better than the existing BLOCK distribution supported by HPF. 7 Related Work Research has been carried out by von Hanxleden <ref> [11] </ref> on compiler-linked partitioners which decompose arrays based on distributed array element values, these are called value based decompositions. Our GEOMETRY construct can be viewed as a particular type of value based decomposition. Several researchers have developed programming environments that are targeted towards particular classes of irregular or adaptive problems.
Reference: [12] <author> R. v. Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in Fortran D. </title> <booktitle> In Proceedings of the 5th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Compile time analysis needed to reuse inspector communication schedules is touched upon in <ref> [12, 7] </ref>. We propose a simple conservative method that in many cases allows us to reuse the results from inspectors.
Reference: [13] <author> R. v. Hanxleden and L. R. Scott. </author> <title> Load balancing on message passing architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 312-324, </pages> <year> 1991. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function. <p> There are many partitioning heuristics methods available based on physical phenomena and physical proximity <ref> [24, 2, 25, 13] </ref>. Currently these partitioners must be coupled to user programs in a manual fashion. This manual coupling is particularly troublesome and tedious when we wish to make use of parallelized partitioners.
Reference: [14] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. In Compilers and Runtime Software for Scalable Multiprocessors, </title> <editor> J. Saltz and P. Mehrotra Editors, </editor> <address> Amsterdam, The Netherlands, </address> <note> To appear 1991. Elsevier. </note>
Reference-contexts: There are a variety of compiler projects targeted at distributed memory multiprocessors [27, 16]. Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project <ref> [14] </ref>, the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project [21, 26, 23].
Reference: [15] <author> B.W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference: [16] <author> C. Koelbel, P. Mehrotra, and J. Van Rosendale. </author> <title> Supporting shared data structures on distributed memory architectures. </title> <booktitle> In 2nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 177-186. </pages> <publisher> ACM, </publisher> <month> March </month> <year> 1990. </year>
Reference-contexts: The inspector partitions loop iterations, allocates local memory for each unique off-processor distributed array element accessed by a loop, and builds a communication schedule to prefetch required off-processor data. In the executor phase, the actual communication and computation are carried out [21]. The ARF compiler [26] and KALI compiler <ref> [16] </ref> used this kind of transformation to handle loops with indirectly referenced arrays (irregular loops). We propose a simple conservative method that often makes it possible to reuse previously computed results from inspectors (e.g. communication schedules, loop iteration partitions, information that associates off-processor data copies with on-processor buffer locations). <p> Baden [1] has developed a programming environment targeted towards particle computations. This programming environment provides facilities that support dynamic load balancing. There are a variety of compiler projects targeted at distributed memory multiprocessors <ref> [27, 16] </ref>. Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project [21, 26, 23]. <p> There are a variety of compiler projects targeted at distributed memory multiprocessors [27, 16]. Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project <ref> [16] </ref>, Marina Chen's work at Yale [18] and our PARTI project [21, 26, 23]. <p> 16 16 32 64 4 8 16 Inspector 1.5 0.9 0.5 3.9 1.9 1.0 2.7 1.5 0.8 Remap 3.1 1.6 0.8 4.9 2.8 1.7 4.5 2.6 1.5 Executor 26.0 20.8 14.7 74.1 54.7 35.3 10.3 7.6 7.3 Total 30.4 23.3 16.0 82.9 59.4 38.0 17.5 11.7 9.6 Supercomputing '93 10 <ref> [16] </ref> and the ARF compiler was the first compiler to support irregularly distributed arrays [26].
Reference: [17] <author> W. E. Leland. </author> <title> Load-balancing heuristics and process behavior. </title> <booktitle> In Proceedings of Performance 86 and ACM SIGMETRICS 86, </booktitle> <pages> pages 54-69, </pages> <year> 1986. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function.
Reference: [18] <author> L. C. Lu and M.C. Chen. </author> <title> Parallelizing loops with indirect array references or pointers. </title> <booktitle> In Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale <ref> [18] </ref> and our PARTI project [21, 26, 23].
Reference: [19] <author> N. Mansour. </author> <title> Physical optimization algorithms for mapping data to distributed-memory multiprocessors. </title> <type> Technical report, Ph.D. Dissertation, </type> <institution> School of Computer Science,Syracuse Universit y, </institution> <year> 1992. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function. <p> Data structure partitioners can make use of different kinds of program information. Some partition-ers operate on data structures that represent undirected graphs [24],[15], <ref> [19] </ref>. Graph vertices represent array indices, graph edges represent dependencies. Consider the example loops in Figure 1. In both loops, the graph vertices represent the N elements of arrays x and y.
Reference: [20] <author> D. J. Mavriplis. </author> <title> Three dimensional unstructured multigrid for the Euler equations, paper 91-1549cp. </title> <booktitle> In AIAA 10th Computational Fluid Dynamics Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: These timings involve a loop over edges of an 3-D unstructured Euler solver <ref> [20] </ref> for 10K and 53K mesh points and an electrostatic force calculation loop in a molecular dynamics code for 648 atom water simulation [4]; the functionality of these loops is equivalent to the loop L2 in Figure 1. <p> The runtime support can be employed in other High Performance Fortran type compilers, and in fact, a subset of the runtime support described here has been incorporated into the Vienna Fortran compiler. We tested our prototype compiler on computational templates extracted from an unstructured mesh computational fluid dynamics code <ref> [20] </ref> and from a molecular dynamics code [4]. We embedded our runtime support by hand and compared its performance against the compiler generated code. The compiler's performance on these templates was within about 10% of the hand compiled code.
Reference: [21] <author> R. Mirchandaney, J. H. Saltz, R. M. Smith, D. M. Nicol, and Kay Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In Proceedings of the 1988 ACM International Conference on Supercomputing, </booktitle> <pages> pages 140-152, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The inspector partitions loop iterations, allocates local memory for each unique off-processor distributed array element accessed by a loop, and builds a communication schedule to prefetch required off-processor data. In the executor phase, the actual communication and computation are carried out <ref> [21] </ref>. The ARF compiler [26] and KALI compiler [16] used this kind of transformation to handle loops with indirectly referenced arrays (irregular loops). <p> The project is called CHAOS; the runtime support is called the CHAOS library. The CHAOS library is a superset of the earlier PARTI library <ref> [21, 26, 23] </ref>. Solving concurrent irregular problems on distributed memory machines using our runtime support, involves five major steps (Figure 2). The first three steps in the figure concern mapping data and computations onto processors. <p> Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project <ref> [21, 26, 23] </ref>.
Reference: [22] <author> B. Nour-Omid, A. Raefsky, and G. Lyzenga. </author> <title> Solving finite element equations on concurrent computers. </title> <booktitle> In Proc. of Symposium on Parallel Computations and theis Impact on Mechanics, </booktitle> <address> Boston, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: In such cases, each mesh point is associated with a location in space. We can assign each graph vertex a set of coordinates that describe its spatial location. These spatial locations can be used to partition data structures <ref> [2, 22] </ref>. Vertices may also be assigned weights to represent estimated computational costs. In order to accurately estimate computational costs, we need information on how work will be partitioned.
Reference: [23] <author> J. Saltz, H. Berryman, and J. Wu. </author> <title> Runtime compilation for multiprocessors. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(6) </volume> <pages> 573-592, </pages> <year> 1991. </year>
Reference-contexts: In these cases, programmers carry out preproces-sig to partition work, map data structures and schedule the movement of data between the memories of processors. The code needed to carry out runtime preprocessing can also be generated by a distributed memory compiler in a process we call runtime compilation <ref> [23] </ref>. In this paper, we present methods and a prototype implementation where we demonstrate techniques that make it possible for compilers to efficiently handle irregular problems coded using a set of language extensions closely related to Fortran D [10] or Vienna Fortran [28]. <p> The project is called CHAOS; the runtime support is called the CHAOS library. The CHAOS library is a superset of the earlier PARTI library <ref> [21, 26, 23] </ref>. Solving concurrent irregular problems on distributed memory machines using our runtime support, involves five major steps (Figure 2). The first three steps in the figure concern mapping data and computations onto processors. <p> Finally, in Phase E we use information from the earlier phases to carry out the necessary computation. CHAOS and PARTI procedures have been used in a variety of applications, including sparse matrix linear solvers, adaptive computational fluid dynamics codes, molecular dynamics codes and a prototype compiler <ref> [23] </ref> aimed at distributed memory multiprocessors. 2.2 Overview of Existing Language Sup port The data decomposition directives we employ for irregular problems will be presented in the context of Fortran D. <p> Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project <ref> [21, 26, 23] </ref>.
Reference: [24] <author> H. Simon. </author> <title> Partitioning of unstructured mesh problems for parallel processing. </title> <booktitle> In Proceedings of the Conference on Parallel Methods on Large Scale Structural Analysis and Physics Applications. </booktitle> <publisher> Pergamon Press, </publisher> <year> 1991. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function. <p> There are many partitioning heuristics methods available based on physical phenomena and physical proximity <ref> [24, 2, 25, 13] </ref>. Currently these partitioners must be coupled to user programs in a manual fashion. This manual coupling is particularly troublesome and tedious when we wish to make use of parallelized partitioners. <p> We present the performance of our runtime techniques on different number of processors on an Intel iPSC/860. To map arrays we employed two different kinds of parallel partitioners 1) a geometry based partitioner ( coordinate bisection [2]) and 2) a connectivity based partitioner (recursive spectral bisection <ref> [24] </ref>). The performance of the compiler embedded mapper version and hand parallelized version are shown in Table 2. <p> In Table 2, Partition under Spectral Bisection depicts the time needed to partition the GeoCoL graph data structure using a parallelized version of Simon's eigenvalue partitioner <ref> [24] </ref>. We partitioned the GeoCoL graph into a number of subgraphs equal to the number of processors employed. It should be noted that any common parallelized partitioner could be used as a mapper. The graph generation time depicts the time required to generate GeoCoL graph.
Reference: [25] <author> R. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency, Practice and Experience, </journal> <volume> 3(5) </volume> <pages> 457-482, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: When we partition the data structures in such a problem in a way that minimizes interprocessor communication, we may need to assign arbitrary array elements to each processor. In recent years promising heuristics have been developed and tradeoffs associated with the different partitioning methods have been studied <ref> [24, 25, 19, 17, 2, 13] </ref>. We have implemented the runtime support and compiler transformations needed to allow users to specify the information needed to produce a customized distribution function. <p> There are many partitioning heuristics methods available based on physical phenomena and physical proximity <ref> [24, 2, 25, 13] </ref>. Currently these partitioners must be coupled to user programs in a manual fashion. This manual coupling is particularly troublesome and tedious when we wish to make use of parallelized partitioners. <p> Our GEOMETRY construct can be viewed as a particular type of value based decomposition. Several researchers have developed programming environments that are targeted towards particular classes of irregular or adaptive problems. Williams <ref> [25] </ref> describes a programming environment (DIME) for calculations with unstructured triangular meshes using distributed memory machines. Baden [1] has developed a programming environment targeted towards particle computations. This programming environment provides facilities that support dynamic load balancing.
Reference: [26] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 26-30, </pages> <year> 1991. </year>
Reference-contexts: The inspector partitions loop iterations, allocates local memory for each unique off-processor distributed array element accessed by a loop, and builds a communication schedule to prefetch required off-processor data. In the executor phase, the actual communication and computation are carried out [21]. The ARF compiler <ref> [26] </ref> and KALI compiler [16] used this kind of transformation to handle loops with indirectly referenced arrays (irregular loops). <p> The project is called CHAOS; the runtime support is called the CHAOS library. The CHAOS library is a superset of the earlier PARTI library <ref> [21, 26, 23] </ref>. Solving concurrent irregular problems on distributed memory machines using our runtime support, involves five major steps (Figure 2). The first three steps in the figure concern mapping data and computations onto processors. <p> Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project <ref> [21, 26, 23] </ref>. <p> 2.7 1.5 0.8 Remap 3.1 1.6 0.8 4.9 2.8 1.7 4.5 2.6 1.5 Executor 26.0 20.8 14.7 74.1 54.7 35.3 10.3 7.6 7.3 Total 30.4 23.3 16.0 82.9 59.4 38.0 17.5 11.7 9.6 Supercomputing '93 10 [16] and the ARF compiler was the first compiler to support irregularly distributed arrays <ref> [26] </ref>. In earlier work, several of the authors of the current paper outlined a strategy (but did not attempt a compiler implementation) that would make it possible for compilers to generate compiler embedded connectivity based parti-tioners directly from marked loops [6].
Reference: [27] <author> H. Zima, H. Bast, and M. Gerndt. </author> <title> Superb: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year>
Reference-contexts: Baden [1] has developed a programming environment targeted towards particle computations. This programming environment provides facilities that support dynamic load balancing. There are a variety of compiler projects targeted at distributed memory multiprocessors <ref> [27, 16] </ref>. Jade project at Stanford, DINO project at Colorado and CODE project at Austin provide parallel programming environments. Run-time compilation methods are employed in four compiler projects; the Fortran D project [14], the Kali project [16], Marina Chen's work at Yale [18] and our PARTI project [21, 26, 23].
Reference: [28] <author> H. Zima, P. Brezany, B. Chapman, P. Mehrotra, and A. Schwald. </author> <title> Vienna Fortran a language specification. </title> <type> Report ACPC-TR92-4, </type> <institution> Austrian Center for Parallel Computation, University of Vienna, Vienna, Austria, </institution> <year> 1992. </year>
Reference-contexts: In this paper, we present methods and a prototype implementation where we demonstrate techniques that make it possible for compilers to efficiently handle irregular problems coded using a set of language extensions closely related to Fortran D [10] or Vienna Fortran <ref> [28] </ref>. On distributed memory architectures, loops with indirect array accesses can be handled by transforming the original fl This work was sponsored in part by ARPA (NAG-1-1485), NSF (ASC 9213821) and ONR (SC292-1-22913). Author Choudhary was also supported by NSF Young Investigator award (CCR-9357840). <p> The compiler also generates code that, at runtime, produces a data structure that is used to partition loop iterations. To our knowledge, the implementation described in this paper is the first distributed memory Fortran compiler to provide this kind of support. We also note that in the Vienna Fortran <ref> [28] </ref> language definition, a user can also specify a customized distribution function. The runtime support and compiler transformation strategies described here can also be applied to Vienna Fortran. We will describe the runtime support, compiler transformations and language extensions required to provide the new capabilities described above.
References-found: 28

