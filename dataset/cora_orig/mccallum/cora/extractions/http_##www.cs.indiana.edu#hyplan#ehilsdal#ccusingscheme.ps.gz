URL: http://www.cs.indiana.edu/hyplan/ehilsdal/ccusingscheme.ps.gz
Refering-URL: http://www.cs.indiana.edu/hyplan/ehilsdal/home.html
Root-URL: http://www.cs.indiana.edu
Email: fehilsdal,jashley,dyb,dfried g@cs.indiana.edu  
Title: Compiler Construction Using Scheme  
Author: Erik Hilsdale J. Michael Ashley R. Kent Dybvig Daniel P. Friedman 
Address: Lindley Hall 215 Bloomington, Indiana 47405  
Affiliation: Indiana University Computer Science Department  
Abstract: This paper describes a course in compiler design that focuses on the Scheme implementation of a Scheme compiler that generates native assembly code for a real architecture. The course is suitable for advanced undergraduate and beginning graduate students. It is intended both to provide a general knowledge about compiler design and implementation and to serve as a springboard to more advanced courses. Although this paper concentrates on the implementation of a compiler, an outline for an advanced topics course that builds upon the compiler is also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred D. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The students write an LL (1) grammar for the new syntax and implement a parser that recognizes expressions in the language specified in Figure 7. The parser returns an equivalent Scheme datum that can be fed to the rest of the compiler. Although traditional parsing techniques are taught <ref> [1] </ref>, a more functional approach [21] might be an attractive alternative. The third and fourth assignments involve implementing the transformations described in Sections 2.3.2 and 2.3.3. <p> The topics can be broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion [9], * destination-driven code generation [10], * copy propagation and constant folding <ref> [1] </ref>, * register allocation [6], and * type check elimination by abstract interpretation [16, 4]. With the exception of macro expansion, the compile-time topics are about compiler optimizations.
Reference: [2] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: It is notable that our compiler does not convert its input to continuation-passing style (CPS). Such a transformation simplifies the regularized language and is a transformation employed by some compilers for (mostly) functional languages <ref> [2, 18, 22] </ref>. While simplifying the regularized language is appealing, converting to CPS would not simplify the compiler used in this course. Pedagogically, converting to CPS requires an extra pass and obscures the correlation between the intermediate program and its source-level counterpart. This hinders debugging.
Reference: [3] <author> Andrew W. Appell and Zhong Shao. </author> <title> An empirical and analytic study of stack vs. heap cost for languages with closures. </title> <note> To appear in Journal of Functional Programming. </note>
Reference-contexts: We have chosen to use a stack rather than a heap model. While abandoning a stack discipline and using closures to represent continuations makes call-with-current-continuation trivial to implement, procedure calls are more expensive <ref> [3] </ref> unless some effort is taken to share continuation closures [19].
Reference: [4] <author> J. Michael Ashley. </author> <title> A practical and flexible flow analysis for higher-order languages. </title> <booktitle> To appear in Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1996. </year>
Reference-contexts: broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion [9], * destination-driven code generation [10], * copy propagation and constant folding [1], * register allocation [6], and * type check elimination by abstract interpretation <ref> [16, 4] </ref>. With the exception of macro expansion, the compile-time topics are about compiler optimizations. To motivate them, an assignment is given early in which the students are told to hand-optimize a program that solves the eight queens problem.
Reference: [5] <author> Henk P. Barendregt. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <booktitle> Number 103 in Studies in Logic and the Foundations of Mathematics. </booktitle> <publisher> North-Holland, </publisher> <year> 1984. </year>
Reference-contexts: These omissions are not detrimental. A primitive can be treated as a value through an inverse-eta transformation <ref> [5, page 63] </ref> by putting it in a lambda expression that accepts arguments that are in turn passed to the primitive.
Reference: [6] <author> Robert G. Burger, Oscar Waddell, and R. Kent Dybvig. </author> <title> Register allocation using lazy saves, eager restores, and greedy shu*ing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 130-138, </pages> <year> 1995. </year>
Reference-contexts: The topics can be broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion [9], * destination-driven code generation [10], * copy propagation and constant folding [1], * register allocation <ref> [6] </ref>, and * type check elimination by abstract interpretation [16, 4]. With the exception of macro expansion, the compile-time topics are about compiler optimizations. To motivate them, an assignment is given early in which the students are told to hand-optimize a program that solves the eight queens problem.
Reference: [7] <editor> William Clinger and Jonathan Rees (editors). </editor> <title> Revised 4 report on the algorithmic language Scheme. </title> <journal> Lisp Pointers, </journal> <volume> 5(3) </volume> <pages> 1-55, </pages> <month> July-September </month> <year> 1991. </year>
Reference-contexts: Section 3 discusses issues affecting the design of the compiler and the course. Section 4 outlines an advanced topics course that uses the compiler. Section 5 gives our conclusions. 2 The Compiler The compiler accepts a subset of legal Scheme programs as defined in the Revised 4 Report <ref> [7] </ref>, a subset strong enough to compile itself. * the language is syntactically restricted so that the only numbers accepted are integers in a bounded range, * all lambda expressions have a fixed arity, i.e., no rest arguments. * programs cannot have free variables other than references to primitives in operator
Reference: [8] <author> William D. Clinger and Lars Thomas Hansen. </author> <title> Lambda, the ultimate label, or a simple optimizing compiler for scheme. </title> <booktitle> In Proceedings of the 1994 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 128-139, </pages> <year> 1994. </year>
Reference-contexts: If time is a premium, e.g., in a ten-week quarter system, The Scheme 48 compiler [17] may be simpler to implement, though it sacrifices our goal of targeting genuine hardware. For another exploration of a simple Scheme compiler see Clinger and Hansen <ref> [8] </ref>. Additional background reading emphasizing proof of correctness of a Scheme compiler, with an extensive bibliography, can be found in [13]. It is notable that our compiler does not convert its input to continuation-passing style (CPS).
Reference: [9] <author> R. Kent Dybvig, Daniel P. Friedman, and Christopher T. Haynes. </author> <title> Expansion-passing style: A general macro mechanism. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 1(1) </volume> <pages> 53-75, </pages> <year> 1988. </year>
Reference-contexts: The topics can be broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion <ref> [9] </ref>, * destination-driven code generation [10], * copy propagation and constant folding [1], * register allocation [6], and * type check elimination by abstract interpretation [16, 4]. With the exception of macro expansion, the compile-time topics are about compiler optimizations.
Reference: [10] <author> R. Kent Dybvig, Robert Hieb, and Tom Butler. </author> <title> Destination-driven code generation. </title> <type> Technical Report 302, </type> <institution> Indiana University, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: The topics can be broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion [9], * destination-driven code generation <ref> [10] </ref>, * copy propagation and constant folding [1], * register allocation [6], and * type check elimination by abstract interpretation [16, 4]. With the exception of macro expansion, the compile-time topics are about compiler optimizations.
Reference: [11] <author> Cormac Flanagan and Matthias Felleisen. </author> <title> The semantics of future and its use in program optimization. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 209-220, </pages> <year> 1995. </year>
Reference-contexts: It is similar to CPS, but the representation of control is not made explicit at the source level. Like conversion to CPS, A-normalization simplifies the source language and is an appropriate move in some contexts, e.g., for the static analysis of programs <ref> [11] </ref>. It is inappropriate, however, for a one-semester course in compiler construction. Assigning a temporary location to every intermediate value, e.g., the test part of a conditional, is unnecessary and results in the generation of poor code unless the pass that assigns locations to variables is made more sophisticated.
Reference: [12] <author> Cormac Flanagan, Amr Sabry, Bruce F. Duba, and Matthias Felleisen. </author> <title> The essence of compiling with continuations. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 237-247, </pages> <year> 1993. </year>
Reference-contexts: Pedagogically, converting to CPS requires an extra pass and obscures the correlation between the intermediate program and its source-level counterpart. This hinders debugging. An alternative to converting to CPS is to A-normalize <ref> [12] </ref> the source program. An A-normalized program names all complex intermediate expressions and fixes the order of evaluation. It is similar to CPS, but the representation of control is not made explicit at the source level.
Reference: [13] <author> Joshua D. Guttman and Mitchell Wand, editors. VLISP: </author> <title> A Verified Implementation of Scheme. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1995. </year> <note> Originally published as a special double issue of the journal Lisp and Symbolic Computation (Volume 8, Issue 1/2). </note>
Reference-contexts: For another exploration of a simple Scheme compiler see Clinger and Hansen [8]. Additional background reading emphasizing proof of correctness of a Scheme compiler, with an extensive bibliography, can be found in <ref> [13] </ref>. It is notable that our compiler does not convert its input to continuation-passing style (CPS). Such a transformation simplifies the regularized language and is a transformation employed by some compilers for (mostly) functional languages [2, 18, 22].
Reference: [14] <author> Robert Hieb, R. Kent Dybvig, and Carl Bruggeman. </author> <title> Representing control in the presence of first-class continuations. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 66-77, </pages> <year> 1990. </year>
Reference-contexts: Some of the topics covered in a past course have been: * separate compilation, * buffered I/O, * first-class continuations <ref> [14] </ref>, and * garbage collection. The bulk of the run-time support code is written in Scheme using a set of low-level primitives supported by the compiler's code generator.
Reference: [15] <author> Erik Hilsdale and Daniel P. Friedman. </author> <title> A Scheme-based course on compiler construction. </title> <note> In Preparation. </note>
Reference-contexts: An early project in the semester is to implement a simple separate compilation facility that supports this model of program development. The details of the implementation can be found in the extended version of this paper <ref> [15] </ref>. With a separate compilation facility in hand, it is possible to implement substantial projects to enhance the run-time system. One possible set of topics is first-class continuations, garbage collection, and input/output. While others are possible, this choice allows students to bootstrap their compiler by the end of the semester. <p> Besides covering basic compilation issues, the course yields an implemented compiler that can serve as a testbed for advanced coursework in language implementation. The compiler has been used, for example, to study advanced topics such as the implementation of first-class continuations and register allocation. A technical report <ref> [15] </ref> giving more details is in preparation. The report describes the implementation of the compiler in considerably more detail. Furthermore, curricular materials such as the Alpha simulator and the synlambda, declare-table, and state-case macros are also described.
Reference: [16] <author> Suresh Jagannathan and Andrew Wright. </author> <title> Effective flow analysis for avoiding runtime checks. </title> <booktitle> In Proceedings of the 1995 International Static Analysis Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: broadly classified as either compile-time or run-time. 4.1 Compile-time Topics The following compile-time topics have been successfully covered in a follow-up course: * macro expansion [9], * destination-driven code generation [10], * copy propagation and constant folding [1], * register allocation [6], and * type check elimination by abstract interpretation <ref> [16, 4] </ref>. With the exception of macro expansion, the compile-time topics are about compiler optimizations. To motivate them, an assignment is given early in which the students are told to hand-optimize a program that solves the eight queens problem.
Reference: [17] <author> Richard A. Kelsey and Jonathan A. Rees. </author> <title> A tractable Scheme implementation. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 7(4) </volume> <pages> 315-335, </pages> <year> 1994. </year>
Reference-contexts: If time is a premium, e.g., in a ten-week quarter system, The Scheme 48 compiler <ref> [17] </ref> may be simpler to implement, though it sacrifices our goal of targeting genuine hardware. For another exploration of a simple Scheme compiler see Clinger and Hansen [8]. Additional background reading emphasizing proof of correctness of a Scheme compiler, with an extensive bibliography, can be found in [13].
Reference: [18] <author> David A. Kranz, Richard Kelsey, Jonathan A. Rees, Paul Hudak, J. Philbin, and Norman I. Adams. </author> <title> Orbit: an optimizing compiler for Scheme. </title> <booktitle> SIG-PLAN Notices, ACM Symposium on Compiler Construction, </booktitle> <volume> 21(7) </volume> <pages> 219-233, </pages> <year> 1986. </year>
Reference-contexts: It is notable that our compiler does not convert its input to continuation-passing style (CPS). Such a transformation simplifies the regularized language and is a transformation employed by some compilers for (mostly) functional languages <ref> [2, 18, 22] </ref>. While simplifying the regularized language is appealing, converting to CPS would not simplify the compiler used in this course. Pedagogically, converting to CPS requires an extra pass and obscures the correlation between the intermediate program and its source-level counterpart. This hinders debugging.
Reference: [19] <author> Zhong Shao and Andrew W. Appel. </author> <title> Space-efficient closure representations. </title> <booktitle> In Proceedings of the 1994 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 130-161, </pages> <year> 1994. </year>
Reference-contexts: We have chosen to use a stack rather than a heap model. While abandoning a stack discipline and using closures to represent continuations makes call-with-current-continuation trivial to implement, procedure calls are more expensive [3] unless some effort is taken to share continuation closures <ref> [19] </ref>.
Reference: [20] <author> Richard L. </author> <title> Sites, editor. Alpha Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <year> 1992. </year>
Reference-contexts: The source-to-source nature of the transformations can be obscured, however, if performed on records. The last project is the implementation of the code generator described in Section 2.2. Students use the Alpha Architecture Reference Manual <ref> [20] </ref> for information on the general form of the assembly code generated.
Reference: [21] <author> Michael Sperber and Peter Thiemann. </author> <title> The essence of LR parsing. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <volume> PEPM '95, </volume> <pages> pages 146-155, </pages> <year> 1995. </year>
Reference-contexts: The parser returns an equivalent Scheme datum that can be fed to the rest of the compiler. Although traditional parsing techniques are taught [1], a more functional approach <ref> [21] </ref> might be an attractive alternative. The third and fourth assignments involve implementing the transformations described in Sections 2.3.2 and 2.3.3.
Reference: [22] <author> Guy L. Steele Jr. Rabbit: </author> <title> A compiler for Scheme. </title> <type> Master's thesis, </type> <institution> M.I.T (A.I. LAB.), Massachusetts, U.S.A, </institution> <year> 1978. </year> <note> Also available as MIT AI Memo 474. </note>
Reference-contexts: It is notable that our compiler does not convert its input to continuation-passing style (CPS). Such a transformation simplifies the regularized language and is a transformation employed by some compilers for (mostly) functional languages <ref> [2, 18, 22] </ref>. While simplifying the regularized language is appealing, converting to CPS would not simplify the compiler used in this course. Pedagogically, converting to CPS requires an extra pass and obscures the correlation between the intermediate program and its source-level counterpart. This hinders debugging.
Reference: [23] <author> Peter A. Steenkiste. </author> <title> The implementation of tags and run-time type checking. </title> <editor> In Peter Lee, editor, </editor> <booktitle> Topics in Advanced Language Implementation, </booktitle> <pages> pages 3-24. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: E) j (let ((v E) . . . ) E) R = (free n v) j (bound n v) j (local v) P 2 Primitives i 2 Immediates v 2 Variables n 2 N Values are represented using 64-bit tagged pointers with the low three bits used for tag information <ref> [23] </ref>. Four of the nine data-types, booleans, characters, fixnums, and the empty list, are immediate data-types and are encoded directly in the pointer. Vectors, pairs, closures, strings, and symbols are allocated in the heap. Since the low three bits are used for the tag, allocation must proceed on eight-byte boundaries.
References-found: 23

