URL: http://www.cs.wisc.edu/~minos/Papers/sigmod96-cam.ps
Refering-URL: 
Root-URL: 
Email: minos@cs.wisc.edu  yannis@cs.wisc.edu  
Title: Multi-dimensional Resource Scheduling for Parallel Queries  
Author: Minos N. Garofalakis Yannis E. Ioannidis 
Address: Madison, WI 53706  Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin  Computer Sciences Department University of Wisconsin  
Abstract: Scheduling query execution plans is an important component of query optimization in parallel database systems. The problem is particularly complex in a shared-nothing execution environment, where each system node represents a collection of time-shareable resources (e.g., CPU(s), disk(s), etc.) and communicates with other nodes only by message-passing. Significant research effort has concentrated on only a subset of the various forms of intra-query parallelism so that scheduling and synchronization is simplified. In addition, most previous work has focused its attention on one-dimensional models of parallel query scheduling, effectively ignoring the potential benefits of resource sharing. In this paper, we develop an approach that is more general in both directions, capturing all forms of intra-query parallelism and exploiting sharing of multi-dimensional resource nodes among concurrent plan operators. This allows scheduling a set of independent query tasks (i.e., operator pipelines) to be seen as an instance of the multidimensional bin-design problem. Using a novel quantification of coarse grain parallelism, we present a list scheduling heuristic algorithm that is provably near-optimal in the class of coarse grain parallel executions (with a worst-case performance ratio that depends on the number of resources per node and the granularity parameter). We then extend this algorithm to handle the operator precedence constraints in a bushy query plan by splitting the execution of the plan into synchronized phases. Preliminary performance results confirm the effectiveness of our scheduling algorithm compared both to previous approaches and the optimal solution. Finally, we present a technique that allows us to relax the coarse granularity restriction and obtain a list scheduling method that is provably near-optimal in the space of all possible parallel schedules. 
Abstract-found: 1
Intro-found: 1
Reference: [BB90] <author> K. P. Belkhale and P. Banerjee. </author> <title> Approximate Algorithms for the Partitionable Independent Task Scheduling Problem. </title> <booktitle> In Proc. of the 1990 Intl. Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: However, scheduling query plans on shared-nothing architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92] </ref> efforts in that field.
Reference: [BB91] <author> K. P. Belkhale and P. Banerjee. </author> <title> A Scheduling Algorithm for Parallelizable Dependent Tasks. </title> <booktitle> In Proc. of the 5th Intl. Parallel Processing Symposium, </booktitle> <year> 1991. </year>
Reference-contexts: However, scheduling query plans on shared-nothing architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92] </ref> efforts in that field.
Reference: [CGJ84] <author> E.G. Coffman, Jr., M.R. Garey, and D.S. Johnson. </author> <title> Approximation Algorithms for Bin-Packing An Updated Survey. In Algorithm Design for Computing System Design. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Based on this framework, the problem of resource scheduling for a collection of concurrently executed operators is reduced to an instance of the multi-dimensional bin-design problem <ref> [CGJ84] </ref> for work vector packings. For this, we develop a fast resource scheduling algorithm called OPERATORSCHEDULE that belongs to the class of list scheduling algorithms [Gra66]. <p> This is essentially an instance of the d-dimensional bin-design problem (the dual of the d-dimensional vector-packing problem) <ref> [CGJ84] </ref>.
Reference: [CHM95] <author> C. Chekuri, W. Hasan, and R. Motwani. </author> <title> Scheduling Problems in Parallel Query Optimization. </title> <booktitle> In Proc. of the 14th ACM Symposium on Principles of Database Systems, </booktitle> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: scheduling has typically concentrated on two important problems: 1. compile-time optimization: minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites (the plan is usually the result of an earlier phase of conventional centralized query optimization) <ref> [CHM95, GW93, HM94, Hon92, HCY94, LCRY93] </ref>; and 2. run-time execution: achieving some system-wide performance goals (e.g., maximizing query throughput) by adaptive scheduling of the operators of multiple concur rent queries [MD93, MD95, RM95]. We address the first problem, i.e., parallelization of query execution plans. <p> Previous work on parallel query scheduling has typically ignored the multi-dimensional nature of database queries. It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like work or time <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In this paper, we present a framework for multidimensional resource scheduling in shared-nothing parallel 365 database systems. <p> Hasan and Motwani [HM94] study the tradeoff between pipelined parallelism and its communication overhead and develop near-optimal heuristics for scheduling a star or a path of pipelined relational operators on a multiprocessor architecture. Chekuri et al. <ref> [CHM95] </ref> extend these results to arbitrary pipelined operator trees. The heuristics proposed in these papers ignore both independent and partitioned parallelism. Ganguly and Wang [GW93] describe the design of a parallelizing scheduler for a tree of coarse grain operators.
Reference: [CLYY92] <author> M.-S. Chen, M.-L. Lo, P. S. Yu, and H. C. Young. </author> <title> Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins. </title> <booktitle> In Proc. of the 18th Intl. Conference on Very Large Data Bases, </booktitle> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In addition, many proposals have simplified the scheduling issues by ignoring independent (bushy tree) parallelism; these include the right-deep trees of Schneider [Sch90] and the segmented right-deep trees of Chen et al. <ref> [CLYY92] </ref>. Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research [CYW92].
Reference: [CYW92] <author> M.-S. Chen, P. S. Yu, and K.-L. Wu. </author> <title> Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries. </title> <booktitle> In Proc. of the 8th Intl. Conference on Data Engineering, </booktitle> <address> Phoenix, Arizona, </address> <month> February </month> <year> 1992. </year> <month> 375 </month>
Reference-contexts: Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research <ref> [CYW92] </ref>. Tan and Lu [TL93] and Niccum et al. [NSHL95] consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins. <p> We selected SYNCHRONOUS as a one-dimensional adversary since it is the state-of-the-art method for exploiting bushy tree parallelism in parallel query execution 3 [WFA95]. Prior research has demonstrated the advantages offered by such parallelism, especially for large queries <ref> [CYW92] </ref>. To the best of our knowledge, optimal processor distribution within general join pipelines remains an open problem. We therefore decided to restrict our experiments to bushy hash-join query plans so that the optimal technique of Lo et al. could be used in SYNCHRONOUS.
Reference: [DG92] <author> D. J. DeWitt and J. Gray. </author> <title> Parallel Database Systems: The Future of High Performance Database Database Systems. </title> <journal> Communications of the ACM, </journal> <volume> 35(6), </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: In Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, Mon treal, Canada, June 1996. architecture has emerged as the most scalable to support very large database management <ref> [DG92] </ref>. In this, each site consists of its own set of local resources and communicates with other sites only by message-passing. Despite the popularity of this architecture, the development of effective and efficient query processing and optimization techniques to exploit its full potential still remains an issue of concern.
Reference: [DGS + 90] <author> D. J. DeWitt, S. Ghandeharizadeh, D. A. Schneider, A. Bricker, H.-I Hsiao, and R. Rasmussen. </author> <title> The Gamma Database Machine Project. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: [i]g T seq (W ) i=1 4.2 Quantifying Coarse Grain Parallelism As is well known, increasing the parallelism of an operator reduces its execution time until a saturation point is reached, beyond which additional parallelism causes a speed-down, due to excessive communication startup and coordination overhead over too many sites <ref> [DGS + 90] </ref>. To avoid operating beyond that point, we need to ensure that the granules of the parallel execution are sufficienty coarse. <p> This model of operator communication costs is substantiated by the experimental results of DeWitt et al. on the Gamma shared-nothing database machine <ref> [DGS + 90] </ref>, and simpler forms of this model have been adopted in previous studies of shared-nothing systems [GMSY93, WFA92]. Note that the startup cost cannot, in general, be distributed among the participating sites.
Reference: [DL89] <author> J. Du and J. Y-T. Leung. </author> <title> Complexity of Scheduling Parallel Task Systems. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 2(4), </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: Moving away from the database field, there is a significant body of work on parallel task scheduling in the field of deterministic scheduling theory. Since the problem is N P-hard in the strong sense <ref> [DL89] </ref>, research efforts have concentrated on providing fast heuristics with provable worst case bounds on the suboptimality of the solution.
Reference: [GGW95] <author> S. Ganguly, A. Gerasoulis, and W. Wang. </author> <title> Partitioning Pipelines with Communication Costs. </title> <booktitle> In Proc. of the 6th Intl. Conference on Information Systems and Data Management (CISMOD'95), </booktitle> <address> Bombay, In-dia, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Based on a one-dimensional model of query operator costs, the authors show their scheduler to be near-optimal for a limited space of query plans (i.e., left-deep join trees with a single materialization point in any right subtree). Ganguly et al. <ref> [GGW95] </ref> obtain similar results for the problem of partitioning independent pipelines without the coarse granularity restriction. The benefits of resource sharing and the multi-dimensionality of query operators are not addressed in these papers. Furthermore, no experimental results are reported.
Reference: [GHK92] <author> S. Ganguly, W. Hasan, and R. Krishnamurthy. </author> <title> Query Optimization for Parallel Execution. </title> <booktitle> In Proc. of the 1992 ACM SIGMOD Intl. Conference on Management of Data, </booktitle> <address> San Diego, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: One of the main sources of complexity of query plan scheduling is the multi-dimensionality of the resource needs of database queries. That is, during their execution queries alternate between multiple resources, most of which are preemptable <ref> [GHK92] </ref>, e.g., the CPU and disk bandwidth. This introduces a range of possibilities for effectively timesharing system resources among concurrent query operators, which can substantially increase the utilization of these resources and reduce the response time of the query. <p> This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In this paper, we present a framework for multidimensional resource scheduling in shared-nothing parallel 365 database systems. Building on the work of Ganguly et al. <ref> [GHK92] </ref>, we represent query operator costs as work vectors with one dimension per resource. In order to account for the communication overhead of parallelism, we initially restrict our attention to operator parallelizations that are sufficiently coarse grain. <p> Resources like the CPU (s), the disk (s), and the network interface (s) or communication processor (s) are preemptable, while memory is not. An operator tree <ref> [GHK92, Hon92, Sch90] </ref> is created as a macro-expansion of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> To the best of our knowledge, developing an accurate memory usage model for parallel query optimization is an open problem. A2. No Time-Sharing Overhead. Following Ganguly et al. <ref> [GHK92] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A3. Uniform Resource Usage. Following Ganguly et al. [GHK92], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A4. Non-increasing Operator Execution Times. <p> To the best of our knowledge, developing an accurate memory usage model for parallel query optimization is an open problem. A2. No Time-Sharing Overhead. Following Ganguly et al. <ref> [GHK92] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A3. Uniform Resource Usage. Following Ganguly et al. [GHK92], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A4. Non-increasing Operator Execution Times. <p> of pipelined joins are different, the degrees of partitioned parallelism differ, or different declustering schemes must be used for load balancing. 4 Coarse Grain Parallelization of Operators 4.1 A Resource Usage Model Our treatment of resource usage is based on the model of preemptable resources proposed by Ganguly et al. <ref> [GHK92] </ref>, which we briefly describe here. <p> Although this abstraction can model the true utilization of a system resource, it does not allow us to predict exactly when the busy periods are. Thus, we make assumption A3 which, in conjunction with assumption A2, leads to straightforward quantification of the effects of resource sharing <ref> [GHK92] </ref>. (a) perfect overlap and (b) zero overlap. We extend the model of Ganguly et al. [GHK92] and describe the usage by an isolated operator of a site comprising of d preemptable resources by the pair (T seq ; W ). <p> Thus, we make assumption A3 which, in conjunction with assumption A2, leads to straightforward quantification of the effects of resource sharing <ref> [GHK92] </ref>. (a) perfect overlap and (b) zero overlap. We extend the model of Ganguly et al. [GHK92] and describe the usage by an isolated operator of a site comprising of d preemptable resources by the pair (T seq ; W ). <p> resource sharing on the response time of a parallel execution. 2 The actual distribution of costs among the vector's components is immaterial as far as our model is concerned. 369 5.2.1 Partitioned Parallelism In partitioned parallelism, the work vector of an operator is partitioned among a set of operator clones <ref> [GHK92] </ref>. Each clone executes on a single site and works on a portion of the operator's data. Consider an operator op i that is distributed across N i sites and runs in isolation, without experiencing resource contention.
Reference: [GI96] <author> M. N. Garofalakis and Y. E. Ioannidis. </author> <title> Multidimensional Resource Scheduling for Parallel Queries. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1996. </year>
Reference-contexts: As with all theoretical results presented here, the theorem is stated without proof due to space constraints. The details can be found in the full version of this paper <ref> [GI96] </ref>. <p> By assumption A4, OPTBOUND is indeed a lower bound on the length of the optimal CG f execution <ref> [GI96] </ref>. The results for queries of 20 and 40 joins are shown in curves verified our expectations, showing that the average performance of TREESCHEDULE is much closer to optimal than what we would expect from the worst-case bound derived in Theorem 5.1 for each plan phase. <p> Finally, define h (N ) = max 1iM fT par (op i ; N i )g, i.e., the parallel execution time of the slowest operator. In proving the (2d + 1) suboptimality bound for OPERATORSCHEDULE <ref> [GI96] </ref> we actually show that the makespan of the schedule produced by our list scheduling rule for any given operator parallelization N satisfies the following inequality: T par (SCHED; P; N) (2d + 1) maxf l (S (N )) ; h (N ) g; where LB (N ) = maxf l
Reference: [GLLRK79] <author> R.L. Graham, E.L. Lawler, J.K. Lenstra, and A.H.G. Rinnooy Kan. </author> <title> Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 5, </volume> <year> 1979. </year>
Reference-contexts: However, scheduling query plans on shared-nothing architectures requires a significantly richer model of parallelization than what is assumed in the classical <ref> [Gra66, GLLRK79] </ref> or even more recent [BB90, BB91, KM92, TWY92, WC92] efforts in that field.
Reference: [GMSY93] <author> S. Ghandeharizadeh, R. R. Meyer, G. L. Schultz, and J. Yackel. </author> <title> Optimal Balanced Assignments and a Parallel Database Application. </title> <journal> ORSA Journal on Computing, </journal> <volume> 5(2), </volume> <month> Spring </month> <year> 1993. </year>
Reference-contexts: This model of operator communication costs is substantiated by the experimental results of DeWitt et al. on the Gamma shared-nothing database machine [DGS + 90], and simpler forms of this model have been adopted in previous studies of shared-nothing systems <ref> [GMSY93, WFA92] </ref>. Note that the startup cost cannot, in general, be distributed among the participating sites. Rather, it is inherently serial and is incurred at a single site (the designated coordinator for the parallel execution).
Reference: [Gra66] <author> R.L. Graham. </author> <title> Bounds for Certain Multiprocessing Anomalies. </title> <journal> The Bell System Technical Journal, </journal> <volume> 45, </volume> <month> November </month> <year> 1966. </year>
Reference-contexts: For this, we develop a fast resource scheduling algorithm called OPERATORSCHEDULE that belongs to the class of list scheduling algorithms <ref> [Gra66] </ref>. <p> However, scheduling query plans on shared-nothing architectures requires a significantly richer model of parallelization than what is assumed in the classical <ref> [Gra66, GLLRK79] </ref> or even more recent [BB90, BB91, KM92, TWY92, WC92] efforts in that field. <p> Given the intractability of the problem, we develop an approximation algorithm, OPERATORSCHEDULE , that runs in polynomial time and guarantees a constant bound on the performance ratio. OPERATORSCHEDULE belongs to the class of list scheduling algorithms originally proposed by Graham <ref> [Gra66] </ref>. The algorithm begins by placing the work vectors of all rooted operators at their respective sites and computing the degree of coarse grain parallelism for all floating operators.
Reference: [GW93] <author> S. Ganguly and W. Wang. </author> <title> Optimizing Queries for Coarse Grain Parallelism. </title> <type> Technical Report LCSR-TR-218, </type> <institution> Dept. of Computer Sciences, Rutgers University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: scheduling has typically concentrated on two important problems: 1. compile-time optimization: minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites (the plan is usually the result of an earlier phase of conventional centralized query optimization) <ref> [CHM95, GW93, HM94, Hon92, HCY94, LCRY93] </ref>; and 2. run-time execution: achieving some system-wide performance goals (e.g., maximizing query throughput) by adaptive scheduling of the operators of multiple concur rent queries [MD93, MD95, RM95]. We address the first problem, i.e., parallelization of query execution plans. <p> Previous work on parallel query scheduling has typically ignored the multi-dimensional nature of database queries. It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like work or time <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In this paper, we present a framework for multidimensional resource scheduling in shared-nothing parallel 365 database systems. <p> Chekuri et al. [CHM95] extend these results to arbitrary pipelined operator trees. The heuristics proposed in these papers ignore both independent and partitioned parallelism. Ganguly and Wang <ref> [GW93] </ref> describe the design of a parallelizing scheduler for a tree of coarse grain operators. <p> Given a query execution plan, our goal is to find a parallel schedule with minimal response time. To account for the communication overhead of parallelism, we initially restrict our attention to partitioned parallelism that is coarse grain <ref> [GW93, GY93] </ref>. That is, we ignore operator parallelizations whose ratio of computation costs to communication overhead is not sufficiently high, as most of them are bound to be ineffective. <p> operator op as the ratio W p (op)=W c (op; N ), where * W p (op) denotes the total amount of work performed during the execution of op on a single site, when all its operands are locally resident (i.e., zero communication cost); it corresponds to the processing area <ref> [GW93] </ref> of op and is constant for all possible executions of op; and 1 Figure 2 is actually a little misleading since, by assumption A3, the work performed on any resource should be uniformly spread over T seq . 368 * W c (op; N ) denotes the total communication overhead <p> Using the above notions, we extend earlier quantifications of coarse grain parallelism <ref> [GW93] </ref> to our multi-dimensional operator model as follows: Definition 4.1 A parallel execution of an operator op on N resource sites is coarse grain with parameter f (referred to as a CG f execution) if the communication area of the execution is no more than f times the processing area of <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. [HCY94]. The communication costs were calculated using the model described in Section 4.2. The values of the cost model parameters were obtained from the literature <ref> [GW93, HCY94, WFA92] </ref> and are summarized in Table 2 4 .
Reference: [GY93] <author> A. Gerasoulis and T. Yang. </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6), </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Given a query execution plan, our goal is to find a parallel schedule with minimal response time. To account for the communication overhead of parallelism, we initially restrict our attention to partitioned parallelism that is coarse grain <ref> [GW93, GY93] </ref>. That is, we ignore operator parallelizations whose ratio of computation costs to communication overhead is not sufficiently high, as most of them are bound to be ineffective.
Reference: [HCY94] <author> H.-I Hsiao, M.-S. Chen, and P. S. Yu. </author> <title> On Parallel Execution of Multiple Pipelined Hash Joins. </title> <booktitle> In Proc. of the 1994 ACM SIGMOD Intl. Conference on Management of Data, </booktitle> <address> Minneapolis, Minnesota, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: scheduling has typically concentrated on two important problems: 1. compile-time optimization: minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites (the plan is usually the result of an earlier phase of conventional centralized query optimization) <ref> [CHM95, GW93, HM94, Hon92, HCY94, LCRY93] </ref>; and 2. run-time execution: achieving some system-wide performance goals (e.g., maximizing query throughput) by adaptive scheduling of the operators of multiple concur rent queries [MD93, MD95, RM95]. We address the first problem, i.e., parallelization of query execution plans. <p> Previous work on parallel query scheduling has typically ignored the multi-dimensional nature of database queries. It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like work or time <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In this paper, we present a framework for multidimensional resource scheduling in shared-nothing parallel 365 database systems. <p> Tan and Lu [TL93] and Niccum et al. [NSHL95] consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins. For the same problem, Hsiao et al. <ref> [HCY94] </ref> propose a processor allocation scheme based on the concept of synchronous execution time: the set of processors allotted to a parent join pipeline are recursively partitioned among its subtrees in such a way that those subtrees can be completed at approximately the same time. <p> Construct the corresponding operator and task trees, and deterministically split the latter into synchronized phases [TL93], where each phase contains tasks with no (blocking) paths between them. 2. For each operator, determine its individual resource requirements using hardware parameters, DBMS statistics, and conventional optimizer cost models (e.g., <ref> [HCY94, SAC + 79] </ref>). 3. For each floating operator, determine the degree of coarse grain parallelism based on the relative cost of computa tion and communication (partitioned parallelism). 4. <p> of a preliminary experimental evaluation presented in the next section. 6 Experimental Performance Evaluation In this section, we describe the results of several experiments we have conducted comparing the average performance of our multi-dimensional scheduling algorithm with a one-dimensional synchronous execution time algorithm that we developed based on previous work <ref> [HCY94, LCRY93] </ref>. Another point of interest is examining how close the response time of the generated schedule is to that of the optimal coarse grain schedule on the average. <p> We start by presenting our experimental testbed and methodology. 6.1 Experimental Testbed We have experimented with the following algorithms: * SYNCHRONOUS : Combination of the synchronous execution time method of Hsiao et al. <ref> [HCY94] </ref> for processor allocation for independent parallelism with the two-phase minimax technique of Lo et al. [LCRY93] for optimally distributing processors across the stages of a hash-join pipeline. <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. <ref> [HCY94] </ref>. The communication costs were calculated using the model described in Section 4.2. The values of the cost model parameters were obtained from the literature [GW93, HCY94, WFA92] and are summarized in Table 2 4 . <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. [HCY94]. The communication costs were calculated using the model described in Section 4.2. The values of the cost model parameters were obtained from the literature <ref> [GW93, HCY94, WFA92] </ref> and are summarized in Table 2 4 .
Reference: [HM94] <author> W. Hasan and R. Motwani. </author> <title> Optimization Algorithms for Exploiting the Parallelism-Communication Tradeoff in Pipelined Parallelism. </title> <booktitle> In Proc. of the 20th Intl. Conference on Very Large Data Bases, </booktitle> <address> Santiago, Chile, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: scheduling has typically concentrated on two important problems: 1. compile-time optimization: minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites (the plan is usually the result of an earlier phase of conventional centralized query optimization) <ref> [CHM95, GW93, HM94, Hon92, HCY94, LCRY93] </ref>; and 2. run-time execution: achieving some system-wide performance goals (e.g., maximizing query throughput) by adaptive scheduling of the operators of multiple concur rent queries [MD93, MD95, RM95]. We address the first problem, i.e., parallelization of query execution plans. <p> Previous work on parallel query scheduling has typically ignored the multi-dimensional nature of database queries. It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like work or time <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In this paper, we present a framework for multidimensional resource scheduling in shared-nothing parallel 365 database systems. <p> Hasan and Motwani <ref> [HM94] </ref> study the tradeoff between pipelined parallelism and its communication overhead and develop near-optimal heuristics for scheduling a star or a path of pipelined relational operators on a multiprocessor architecture. Chekuri et al. [CHM95] extend these results to arbitrary pipelined operator trees.
Reference: [Hon92] <author> W. Hong. </author> <title> Exploiting Inter-Operation Parallelism in XPRS. </title> <booktitle> In Proc. of the 1992 ACM SIGMOD Intl. Conference on Management of Data, </booktitle> <address> San Diego, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: scheduling has typically concentrated on two important problems: 1. compile-time optimization: minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites (the plan is usually the result of an earlier phase of conventional centralized query optimization) <ref> [CHM95, GW93, HM94, Hon92, HCY94, LCRY93] </ref>; and 2. run-time execution: achieving some system-wide performance goals (e.g., maximizing query throughput) by adaptive scheduling of the operators of multiple concur rent queries [MD93, MD95, RM95]. We address the first problem, i.e., parallelization of query execution plans. <p> Perhaps the only exception is Hong's method for exploiting independent parallelism in the XPRS shared-memory database system <ref> [Hon92] </ref>. He suggests a scheduling algorithm that combines one I/O-bound and one CPU-bound operator pipeline through independent parallelism to maximize the system resource utilizations and 366 thus minimize the elapsed time. <p> Resources like the CPU (s), the disk (s), and the network interface (s) or communication processor (s) are preemptable, while memory is not. An operator tree <ref> [GHK92, Hon92, Sch90] </ref> is created as a macro-expansion of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)).
Reference: [KLMS84] <author> R. M. Karp, M. Luby, and A. </author> <note> Marchetti-Spaccamela. </note>
Reference-contexts: In general, the expected output quality of our heuristic should 371 be much better than the worst-case bounds, especially for a set of operators with a good mix of resource requirements. This conjecture is supported by theoretical results on the expected performance of vector packing <ref> [KLMS84] </ref>. The big advantage of OPERATORSCHEDULE compared to previous approaches is its ability to explore resource sharing possibilities and balance the resource workloads at individual sites. Deriving performance bounds for the schedule produced by the TREESCHEDULE algorithm is a much more difficult problem. <p> These results are in accordance with the theoretical results of Karp et al. <ref> [KLMS84] </ref> who used a probabilistic model to prove that even very simple vector-packing heuristics can be expected to produce packings in which very little of the capacity of the bins is wasted. 373 7 Extensions for Malleable Operators In this section, we extend our list scheduling technique to handle the more
References-found: 21

