URL: http://www.cs.rice.edu/~adve/CS615/apples-sched.sc96.ps
Refering-URL: http://www.cs.rice.edu/~adve/comp615.html
Root-URL: 
Title: Application-Level Scheduling on Distributed Heterogeneous Networks  
Author: Fran Berman and Rich Wolski Silvia Figueira, Jennifer Schopf, Gary Shao 
Address: La Jolla, Calif. 92093  
Affiliation: Department of Computer Science and Engineering 0114 University of California, San Diego  
Note: To appear in Supercomputing '96  
Pubnum: (Technical Paper)  
Abstract: Heterogeneous networks are increasingly being used as platforms for resource-intensive distributed parallel applications. A critical contributor to the performance of such applications is the scheduling of constituent application tasks on the network. Since often the distributed resources cannot be brought under the control of a single global scheduler, the application must be scheduled by the user. To obtain the best performance, the user must take into account both application-specific and dynamic system information in developing a schedule which meets his or her performance criteria. In this paper, we define a set of principles underlying application-level scheduling and describe our work-in-progress building AppLeS (application-level scheduling) agents. We illustrate the application-level scheduling approach with a detailed description and results for a distributed 2D Jacobi application on two production heteroge neous platforms.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Berman, F. and Moore, R., </author> <title> Heterogeneous working group report, </title> <booktitle> Proceedings of the Second Pasadena Workshop on System Software and Tools for High Performance Computing Environments, </booktitle> <year> 1995. </year> <note> http://cesdis.gsfc.nasa.gov/PAS2.index.html. </note>
Reference-contexts: 1 Introduction Fast networks have made it possible to coordinate distributed CPU, memory, and storage resources to provide the potential for application performance superior to that achievable from any single system <ref> [1] </ref>. Parallel applications targeted to such systems are typically resource-intensive, i.e. they require more resources than are available at a single site [16].
Reference: [2] <author> Brewer, E. A., </author> <title> High-level optimization via automated statistical modeling, </title> <booktitle> Proceedings of Principles and Practice of Parallel Programming, PPoPP'95 (1995), </booktitle> <pages> pp. 80-91. </pages>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [23] [7] 16 etc.). Application-level scheduling is related to the work of Brewer <ref> [2] </ref>, and more directly to the Mars project [8]. Brewer's work, which attempts to select the correct implementation of an algorithm for a given machine based on a small set of static parameters, uses application-specific information to improve performance. <p> Model templates may be provided by the user. Default model templates for classes of applications (e.g. data parallel regular grid applications) will be available in the Model pool. Note that model templates can leverage successful models from the literature such as <ref> [2] </ref>, [18] [10], [24], [22], etc. to predict the performance of the application and its tasks. 4.4 Resource Selector The Resource Selector produces viable active sets to be considered by the Coordinator. It may iterate multiple times to identify a set of candidate active sets according to different selection criteria.
Reference: [3] <author> DeFanti, T., Foster, I., Papka, M., Stevens, R. and Kuhfuss, T., </author> <title> Overview of the I-way: Wide area visual supercomputing, </title> <note> to appear in the International Journal of Supercomputer Applications. </note>
Reference-contexts: We term these agents AppLeS Application-Level Schedulers. Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus <ref> [3, 11] </ref>, Legion [12, 17], or PVM [9, 20] to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project [12], [17] and from the Globus project <ref> [3] </ref>, [11] to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [4] <author> Figueira, S. M. and Berman, F., </author> <title> Modeling the effects of contention on the performance of heterogeneous applications, </title> <booktitle> to appear in the Proceedings of the High Performance Distributed Computing Conference (1996). </booktitle>
Reference-contexts: Note that it is important to estimate the behavior of the application tasks in the context of the production systems in which they will be used. For this reason, we are developing models which forecast the slowdown of tasks on shared resources (networks and machines) <ref> [4] </ref>. Factoring slowdown into the model will provide a more realistic estimate of application and task performance in the presence of contention. 4.7 Actuator AppLeS does not function as a resource manager it relies on the services of existing resource managers to perform resource allocation and task instantiation.
Reference: [5] <author> Fink, S., </author> <note> http://www-cse.ucsd.edu/groups/hpcl/scg/kelp.html, 1995. </note>
Reference-contexts: Solving the partitioning problem optimally is NP-complete, so it is necessary for the user to employ heuristics to arrive at a "good" solution. 2.1 Deriving Partitions that Optimize Resource Performance The version of Jacobi2D we use in this example is written in a data-parallel SPMD style using KeLP <ref> [6, 5] </ref>. The KeLP system provides high-level abstractions, in the form of C++ objects, that support runtime data decomposition.
Reference: [6] <author> Fink, S. J., Baden, S. B. and Kohn, S. R., </author> <title> Flexible communication mechanisms for dynamic structured applications, </title> <note> in preparation, </note> <year> 1996. </year>
Reference-contexts: Solving the partitioning problem optimally is NP-complete, so it is necessary for the user to employ heuristics to arrive at a "good" solution. 2.1 Deriving Partitions that Optimize Resource Performance The version of Jacobi2D we use in this example is written in a data-parallel SPMD style using KeLP <ref> [6, 5] </ref>. The KeLP system provides high-level abstractions, in the form of C++ objects, that support runtime data decomposition.
Reference: [7] <author> Freund, R., </author> <booktitle> Proceedings of the 1996 IPPS Workshop on Heterogeneous Computing. </booktitle>
Reference-contexts: In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [23] <ref> [7] </ref> 16 etc.). Application-level scheduling is related to the work of Brewer [2], and more directly to the Mars project [8].
Reference: [8] <author> Gehrinf, J. and Reinfeld, A., </author> <title> Mars a framework for minimizing the job execution time in a metacomputing environment, </title> <booktitle> Proceedings of Future general Computer Systems (1996). </booktitle>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [23] [7] 16 etc.). Application-level scheduling is related to the work of Brewer [2], and more directly to the Mars project <ref> [8] </ref>. Brewer's work, which attempts to select the correct implementation of an algorithm for a given machine based on a small set of static parameters, uses application-specific information to improve performance. The MARS project [8], whose goal is to produce more general-purpose software, is more similar in scope and intent to <p> scheduling is related to the work of Brewer [2], and more directly to the Mars project <ref> [8] </ref>. Brewer's work, which attempts to select the correct implementation of an algorithm for a given machine based on a small set of static parameters, uses application-specific information to improve performance. The MARS project [8], whose goal is to produce more general-purpose software, is more similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [9] <author> Geist, A., Beguelin, A., Dongarra, J., Jiang, W., Manchek, R. and Sunderam, V., </author> <title> PVM: Parallel Virtual Machine A Users' Guide and Tutorial for Networked Parallel Computing, </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus [3, 11], Legion [12, 17], or PVM <ref> [9, 20] </ref> to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user.
Reference: [10] <author> Getov, V. S., Hockney, R. W. and Hey, A. J. G., </author> <title> Performance analysis of distributed applications by suitability functions, </title> <booktitle> in Proceedings of the MPPM Conference (1993). </booktitle>
Reference-contexts: Model templates may be provided by the user. Default model templates for classes of applications (e.g. data parallel regular grid applications) will be available in the Model pool. Note that model templates can leverage successful models from the literature such as [2], [18] <ref> [10] </ref>, [24], [22], etc. to predict the performance of the application and its tasks. 4.4 Resource Selector The Resource Selector produces viable active sets to be considered by the Coordinator. It may iterate multiple times to identify a set of candidate active sets according to different selection criteria.
Reference: [11] <author> Globus, </author> <note> http://www.mcs.anl.gov/globus. </note>
Reference-contexts: We term these agents AppLeS Application-Level Schedulers. Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus <ref> [3, 11] </ref>, Legion [12, 17], or PVM [9, 20] to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project [12], [17] and from the Globus project [3], <ref> [11] </ref> to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [12] <author> Grimshaw, A. S., Wulf, W. A., French, J. C., Weaver, A. C. and Reynolds, P. F., Legion: </author> <title> The next logical step toward a nationwide virtual computer, </title> <type> Tech. Rep. </type> <institution> CS-94-21, University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus [3, 11], Legion <ref> [12, 17] </ref>, or PVM [9, 20] to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project <ref> [12] </ref>, [17] and from the Globus project [3], [11] to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [13] <author> Hensgen, D. A., Moore, L., Kidd, T., Freund, R., Keith, E., Kussow, M., Lima, J. and Campbell, M., </author> <title> Adding rescheduling to and integrating condor with smartnet, </title> <booktitle> in Proceedings of the Heterogeneous workshop (1995). </booktitle>
Reference-contexts: In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], <ref> [13] </ref>, [19], [23] [7] 16 etc.). Application-level scheduling is related to the work of Brewer [2], and more directly to the Mars project [8].
Reference: [14] <author> High Performance Fortran Forum, </author> <title> High performance fortran language specification, </title> <institution> Rice Univeristy, Houston, Texas, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The first method [Compile-time blocked] uses a conventional HPF-style <ref> [14] </ref> block partitioning in which each processor is assigned (at compile-time) a relatively equal-sized square region of the grid to compute. The other three partitioning methods utilize versions of the application-level scheduling approach described in the previous section.
Reference: [15] <author> Hoffman, J. D., </author> <title> Numerical Methods for Engineers and Scientists, </title> <publisher> McGraw-Hill , Inc, </publisher> <year> 1992. </year>
Reference-contexts: Consider the problem of executing a distributed data-parallel two dimensional Jacobi iterative solver (Jacobi2D) using a heterogeneous network of machines. The Jacobi method is commonly used to solve the finite-difference approximation to Poisson's equation <ref> [15] </ref> which arises in many heat flow, electrostatic, and gravitational problems. Variable coefficients are represented as elements of a two-dimensional grid. At each iteration, the new value of each grid element is defined to be the average of its four nearest neighbors during the previous iteration (see Figure 1).
Reference: [16] <author> Korab, H. and Brown, M., </author> <title> Virtual environments and distributed computing at SC'95: GII testbed and HPC challenge applications on the I-way. </title> <booktitle> in Proceedings of Supercomputing '95 (1995). </booktitle>
Reference-contexts: Parallel applications targeted to such systems are typically resource-intensive, i.e. they require more resources than are available at a single site <ref> [16] </ref>. Critical resources may include large aggregated and distributed memory, fixed data sources, fl The authors were supported in part by NSF grants ASC-9301788, ASC-9308900, and a scholarship from CAPES and UFRJ (Brazil). y Presenting author. z Email addresses of the authors are fberman, rich, silvia, jenny, gshao g@cs.ucsd.edu.
Reference: [17] <author> Legion, </author> <note> http://www.cs.virginia.edu/~mentat/legion/legion.html. 24 </note>
Reference-contexts: Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus [3, 11], Legion <ref> [12, 17] </ref>, or PVM [9, 20] to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project [12], <ref> [17] </ref> and from the Globus project [3], [11] to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [18] <author> Messina, P. and Heirich, A., </author> <type> personal communication, </type> <year> 1995. </year>
Reference-contexts: Model templates may be provided by the user. Default model templates for classes of applications (e.g. data parallel regular grid applications) will be available in the Model pool. Note that model templates can leverage successful models from the literature such as [2], <ref> [18] </ref> [10], [24], [22], etc. to predict the performance of the application and its tasks. 4.4 Resource Selector The Resource Selector produces viable active sets to be considered by the Coordinator. It may iterate multiple times to identify a set of candidate active sets according to different selection criteria.
Reference: [19] <author> Pruyne, J. and Livny, M., </author> <title> Parallel processing on dynamic resources with Carmi, </title> <booktitle> in Proceedings of the Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <address> IPPS '95 (April 1995). </address>
Reference-contexts: In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], <ref> [19] </ref>, [23] [7] 16 etc.). Application-level scheduling is related to the work of Brewer [2], and more directly to the Mars project [8].
Reference: [20] <author> PVM, </author> <note> http://www.epm.ornl.gov:80/pvm/. </note>
Reference-contexts: Each application will have its own AppLeS to determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. Note that AppLeS is not a resource management system; rather, it interacts with systems such as Globus [3, 11], Legion [12, 17], or PVM <ref> [9, 20] </ref> to perform that function. As such, AppLeS is an application-management system which manages the scheduling of the application for the benefit of the end-user.
Reference: [21] <author> Rudolph, L. and Feitelson, D., </author> <booktitle> Proceedings of the 1996 IPPS Workshop on Job Scheduling Strategies for Parallel Processing (1996). </booktitle>
Reference: [22] <author> Sarkar, V., </author> <title> Automatic partitioning of a program dependence graph into parallel tasks, </title> <journal> IBM Journal of Research and Development 35, </journal> <note> 5/6 (Sept/Nov 1991). </note>
Reference-contexts: Model templates may be provided by the user. Default model templates for classes of applications (e.g. data parallel regular grid applications) will be available in the Model pool. Note that model templates can leverage successful models from the literature such as [2], [18] [10], [24], <ref> [22] </ref>, etc. to predict the performance of the application and its tasks. 4.4 Resource Selector The Resource Selector produces viable active sets to be considered by the Coordinator. It may iterate multiple times to identify a set of candidate active sets according to different selection criteria.
Reference: [23] <author> Siegel, H., Antonio, J., Metzger, R., Tan, M. and Li, Y. A., </author> <title> Heterogeneous computing. </title> <type> Tech. Rep., </type> <institution> Purdue University EE Technical Report TR-EE 94-37. </institution>
Reference-contexts: In addition, we are progressing on an implementation which uses MPI as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], <ref> [23] </ref> [7] 16 etc.). Application-level scheduling is related to the work of Brewer [2], and more directly to the Mars project [8].
Reference: [24] <author> Zhang, X. and Yan, Y., </author> <title> A framework of performance prediction of parallel computing nondedicated heterogeneous now, </title> <booktitle> in Proceedings of the 1995 International Conference on Parallel Processing (1995), </booktitle> <pages> pp. </pages> <month> 163-7. </month> <title> 25 decomposition of the application, and lets a user identify an active set for the application. 26 specific platform. </title> <type> 27 28 </type>
Reference-contexts: Model templates may be provided by the user. Default model templates for classes of applications (e.g. data parallel regular grid applications) will be available in the Model pool. Note that model templates can leverage successful models from the literature such as [2], [18] [10], <ref> [24] </ref>, [22], etc. to predict the performance of the application and its tasks. 4.4 Resource Selector The Resource Selector produces viable active sets to be considered by the Coordinator. It may iterate multiple times to identify a set of candidate active sets according to different selection criteria.
References-found: 24

