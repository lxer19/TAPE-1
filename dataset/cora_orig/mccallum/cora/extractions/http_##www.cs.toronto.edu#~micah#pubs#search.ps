URL: http://www.cs.toronto.edu/~micah/pubs/search.ps
Refering-URL: http://www.cs.toronto.edu/~micah/pubs/pubs.html
Root-URL: 
Email: micah@cs.berkeley.edu  
Title: Asynchronous Shared Memory Search Structures  
Author: Micah Adler 
Date: December 19, 1996  
Affiliation: Computer Science Division University of California Berkeley and International Computer Science Institute  
Abstract: We study the problem of storing an ordered set on an asynchronous shared memory parallel computer. We examine the case where we want to efficiently perform successor (least upper bound) queries on the set members that are stored. We also examine the case where processors insert and delete members of the set. Due to asynchrony, we require processors to perform queries and to maintain the structure independently. Although several such structures have been proposed, the analysis of these structures has been very limited. We here use the recently proposed QRQW PRAM model to provide upper and lower bounds on the performance of such data structures. In the asynchronous QRQW PRAM, the problem of processors concurrently and independently searching a shared data structure is very similar to the problem of routing packets through a network. Using this as a guide, we introduce the Search-Butterfly, a search structure that combines the efficient packet routing properties of the butterfly graph with the efficient search structure properties of the B-Tree. We analyze the behavior of the Search-Butterfly when the following operations are performed: arbitrary searches, random searches, and random searches, insertions and deletions. We also provide lower bounds that show that the results are within a factor of O(log n) of optimal where n is the number of keys in the structure. When the searches are random, the results are within a constant factor of optimal. Many of the proofs are derived from closely related results for packet routing. Others are of independent interest, most notably a method of adding queues to any network belonging to a large class of queuing networks with non-Markovian routing in a manner that allows us to bound the delay experienced by packets in the augmented network.
Abstract-found: 1
Intro-found: 1
Reference: [AFK+96] <author> B. Awerbuch, A. Fernandez, J. Kleinberg, T. Leighton, and Z. Liu. </author> <title> Universal Stability Results in Adversarial Queueing Theory. </title> <booktitle> In Proc. 37 th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1996. </year> <month> 22 </month>
Reference-contexts: Lastly, we would like to remove the assumption that the arrival times of accesses to the search structure can be described by a Poisson process. Other possibilities for modeling the arrival process include Adversarial Queuing Theory <ref> [AFK+96] </ref>. 8 Acknowledgments The author would like to thank the following people for their many useful comments and suggestions: John Byers, Soumen Chakrabarti, Mor Harchol-Balter, Dick Karp, Mike Luby, Mike Mitzenmacher, Satish Rao, and Kathy Yelick.
Reference: [AHU74] <author> A. Aho, J. Hopcroft, and J. Ullman, </author> <title> The Design and Analysis of Computer Algorithms Addison-Wesley, </title> <address> Reading, Massachusetts, </address> <year> 1974. </year>
Reference-contexts: Provided that no 2-3 Tree contains more than O (log n) nodes, this can be done using O (log log n) memory accesses (see <ref> [AHU74] </ref> pp. 155-157). Before unlocking the old 2-3 Tree, a marker is added to that 2-3 Tree that indicates the range of keys that have been moved to the new 2-3 Tree.
Reference: [Ajt88] <author> A. Ajtai. </author> <title> A Lower Bound for Finding Predecessors in Yao's Cell Probe Model Combina-torica 8 (3) 235 - 247, </title> <year> 1988. </year>
Reference: [BS77] <author> R. Bayer, M. Schkolnick. </author> <title> Concurrency of Operations on B-Trees. </title> <journal> Acta Informatica 9 </journal> <pages> 1-22, </pages> <year> 1977. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including <ref> [BS77] </ref>, [Ell80], [LY81], [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [CZ89] <author> R. Cole, O. Zajicek. </author> <title> The APRAM: Incorporating Asynchrony into the PRAM Model In Proc. </title> <booktitle> 1 st ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 169-178, </pages> <year> 1989. </year>
Reference-contexts: We use the asynchronous version of the QRQW PRAM, where each memory location has a FIFO queue, memory requests must first traverse the queue, and each memory location handles one item per time step. Processors behave asynchronously, and this can be modeled in several different ways: <ref> [CZ89] </ref>, [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [CZ90] <author> R. Cole, O. Zajicek. </author> <title> The Expected Advantage of Asynchrony In Proc. </title> <booktitle> 2 nd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 85-94, </pages> <year> 1990. </year>
Reference-contexts: We use the asynchronous version of the QRQW PRAM, where each memory location has a FIFO queue, memory requests must first traverse the queue, and each memory location handles one item per time step. Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], <ref> [CZ90] </ref>, [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [CKP+93] <author> D. Culler, R. M. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subra-monian and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Proc. 4th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: This approach was introduced in [Gib89] and has since been used in the analysis of other models, for example the LogP model <ref> [CKP+93] </ref>. We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation. Memory accesses are queued according 5 to the asynchronous QRQW rule.
Reference: [Ell80] <author> C. Ellis. </author> <title> Concurrent Search and Inserts in 2-3 Trees. </title> <journal> Acta Informatica 14(1): </journal> <pages> pp. 63-86, </pages> <year> 1980. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], <ref> [Ell80] </ref>, [LY81], [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [Gib89] <author> P. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proc. 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 158 - 168, </pages> <year> 1989. </year>
Reference-contexts: This approach was introduced in <ref> [Gib89] </ref> and has since been used in the analysis of other models, for example the LogP model [CKP+93]. We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation.
Reference: [GMR94a] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for Contention in Parallel Algorithms. </title> <booktitle> In Proc. 5th ACM SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 638-648, </pages> <year> 1994. </year>
Reference-contexts: However, although some of these designs have been shown to perform well in simulations, none have been analyzed in any parallel machine model. 1.2 New Techniques We use the QRQW PRAM (Queued Read, Queued Write) model <ref> [GMR94a] </ref>, [GMR94b], a recent advance in the modeling of shared memory parallel computation, to develop a framework for evaluating the performance of strongly independent concurrent search structures. <p> say a queuing network is stable, if as t ! 1, where t is the time since the first arrival to any queue in the network, the number of times that the network has emptied also approaches 1. 2 The QRQW PRAM model The QRQW PRAM model is introduced in <ref> [GMR94a] </ref> and [GMR94b]. The authors argue that allowing concurrent reading and writing to memory cells, as is allowed in the CRCW PRAM, is too permissive, but requiring exclusive reading and writing, such as in the EREW PRAM, is too restrictive. <p> Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH <ref> [GMR94a] </ref>. The existing analysis of asynchronous QRQW algorithms [GMR96] has taken the following approach: the algorithm must work correctly for all possible interleavings of the instructions, but when analyzing the performance of the algorithms, it is assumed that there are no delays between the steps: each individual processor behaves synchronously. <p> We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation. Memory accesses are queued according 5 to the asynchronous QRQW rule. When more than one request arrives simultaneously to a location, the asynchronous QRQW model of <ref> [GMR94a] </ref> assumes that these ties are resolved arbitrarily: they assume the worst case. Our results for the continuous case all hold for this pessimistic assumption. For the fixed case, however, we need something slightly stronger.
Reference: [GMR94b] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient Low-Contention Parallel Algorithms. </title> <booktitle> In Proc. 6th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. </pages> <month> 236 - 247 </month> <year> 1994. </year>
Reference-contexts: When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. A strongly independent search structure called the Binary Search Fat Tree is introduced in <ref> [GMR94b] </ref>. This structure performs quite well in the case where the keys that processors search for are chosen independently and uniformly at random from the set of keys that are stored. The drawback of this structure, however, is that it requires fi (n log n) memory to store n keys. <p> However, although some of these designs have been shown to perform well in simulations, none have been analyzed in any parallel machine model. 1.2 New Techniques We use the QRQW PRAM (Queued Read, Queued Write) model [GMR94a], <ref> [GMR94b] </ref>, a recent advance in the modeling of shared memory parallel computation, to develop a framework for evaluating the performance of strongly independent concurrent search structures. <p> queuing network is stable, if as t ! 1, where t is the time since the first arrival to any queue in the network, the number of times that the network has emptied also approaches 1. 2 The QRQW PRAM model The QRQW PRAM model is introduced in [GMR94a] and <ref> [GMR94b] </ref>. The authors argue that allowing concurrent reading and writing to memory cells, as is allowed in the CRCW PRAM, is too permissive, but requiring exclusive reading and writing, such as in the EREW PRAM, is too restrictive.
Reference: [GMR96] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queue-Read Queue-Write Asynchronous PRAM. </title> <note> To appear 1996. </note>
Reference-contexts: Prior to the introduction of the QRQW PRAM, the only PRAM model used to study asynchronous machines was the CRCW PRAM. This is due to the fact that asynchrony makes scenarios where processors concurrently access the same memory location very difficult to avoid <ref> [GMR96] </ref>. We use the asynchronous version of the QRQW PRAM, where each memory location has a FIFO queue, memory requests must first traverse the queue, and each memory location handles one item per time step. Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. <p> Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a]. The existing analysis of asynchronous QRQW algorithms <ref> [GMR96] </ref> has taken the following approach: the algorithm must work correctly for all possible interleavings of the instructions, but when analyzing the performance of the algorithms, it is assumed that there are no delays between the steps: each individual processor behaves synchronously.
Reference: [HW95] <author> M. Harchol-Balter, and D. Wolfe. </author> <title> Bounding Delays in Packet-routing Networks. </title> <booktitle> In Proc. 27th ACM Symposium on Theory of Computing pp. </booktitle> <pages> 248-257, </pages> <year> 1995. </year>
Reference-contexts: A queuing network has Markovian routing if any routing decision is based solely on the current location of the packet to be routed. Very little is known about the delay associated with constant service time queues in networks with non-Markovian routing. For a good summary of this, see <ref> [HW95] </ref>. The remainder of this paper is organized as follows. In Section 2, we discuss the asynchronous QRQW model. In Section 3, we introduce the Search-Butterfly. In Sections 4 and 5, we analyze the behavior of the Search-Butterfly in the static and dynamic cases, respectively. <p> It follows that for any given sample path, N N (t) N N 0 (t): Since the actual behaviors of the queuing networks are distributions over sample paths, we have that N N (t) st N N 0 (t): To prove Claim 2, we induct over time (as in <ref> [HW95] </ref>). Clearly Claim 2 is true at time 0. Assume it is true for the interval of time [0; t 0 ]. <p> Note that all routing decisions in N 0 are Markovian. This allows us to use the following theorem about Processor Sharing (PS) queues: Theorem 5 <ref> [HW95] </ref> Let R be a network with constant service time, FIFO queues and Markovian routing. Let R 0 be identical, except with PS queues.
Reference: [HLS92] <author> M. Herlihy, B. Lim, and N. Shavit. </author> <title> Low Contention Load Balancing on Large Scale Multiprocessors. </title> <booktitle> In Proc. 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. </pages> <address> 219 -227, </address> <year> 1992. </year>
Reference-contexts: Butterfly networks have been shown to efficiently route packets by [Ran88], [Lei92], [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks <ref> [HLS92] </ref>.
Reference: [JC94] <author> T. Johnson, A. Colbrook. </author> <title> A Distributed, Replicated, Data-Balanced Search Structure Int. </title> <journal> Jour. of High Speed Computing 6:4 pp. </journal> <pages> 475-500, </pages> <year> 1994. </year>
Reference-contexts: at methods to reduce resource contention at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], <ref> [JC94] </ref> and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root. <p> at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], <ref> [JC94] </ref> and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root.
Reference: [JS93] <author> T. Johnson, D. Shasha. </author> <booktitle> The Performance of Concurrent B-Tree Algorithms ACM Transactions on Database Systems, </booktitle> <pages> 18:1 pp. 51-101, </pages> <year> 1993. </year>
Reference-contexts: Also, it does not allow for an efficient means of inserting and deleting keys. Many strongly independent search structures that allow updates have been proposed, but analytical evaluation of these structures has been very limited, and has been cited as lacking, for example in <ref> [JS93] </ref> and [Wan91]. In these search structures, correctness of the data structure during updates is usually provided by adding locks to the tree: shared variables that keep some processors from reading sections of the tree that are currently being modified. <p> Since the node currently being modified needs to be locked, this is very close to optimal in terms of the maximum number of locks held by any processor. 2 Stating the need for more analysis of search tree algorithms, <ref> [JS93] </ref> analyze B-Link trees (and other structures that reduce the number of locks held by processors), and conclude that in B-Link tree algorithms, the limiting factor is resource contention: several processors trying to access the same shared resource. <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in <ref> [JS93] </ref>, [Wan91], [Par89], and [Yao78]. Table 1 summarizes the behavior of the Search-Butterfly. The results for the static problem in the table assume that processors are searching for keys that are chosen independently and uniformly at random from the set of keys stored in the Search-Butterfly.
Reference: [JS93b] <author> T. Johnson, D. Shasha. </author> <title> B-Trees with Inserts and Deletes: </title> <journal> Why-Free-at-Empty is better than Merge-at-Half Journal of Computer and System Sciences, </journal> <volume> 47: </volume> <pages> pp. 45-76, </pages> <year> 1993. </year> <month> 23 </month>
Reference: [Lei92] <author> T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures, </title> <publisher> Morgan Kaugmann, </publisher> <year> 1992. </year>
Reference-contexts: Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by [Ran88], <ref> [Lei92] </ref>, [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> Note that FIFO contention resolution with up-to-present arbitrary resolution of ties is non-predictive. This proof can also be extended to the case where the inputs are chosen randomly and the outputs are fixed (see <ref> [Lei92] </ref>, p. 569). Thus, the problem of "routing" the processors to the correct 2-3 Trees w.h.p. requires time O (Y + log n).
Reference: [LY81] <author> P. Lehman, S.B. Yao. </author> <title> Efficient Locking for Concurrent Operations on B-Trees ACM Transactions on Database Systems, </title> <journal> 6:4 pp. </journal> <pages> 650-670, </pages> <year> 1981. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], [Ell80], <ref> [LY81] </ref>, [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [ML84] <author> U. Manber, R. Ladner. </author> <title> Concurrency Control in a Dynamic Search Structure ACM Transactions on Database Systems, </title> <journal> 9:3 pp. </journal> <pages> 439-455, </pages> <year> 1984. </year>
Reference: [Nis90] <author> N. Nishimura. </author> <booktitle> Asynchronous Shared Memory Parallel Computation In Proc. 2 nd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 76-84, </pages> <year> 1990. </year>
Reference-contexts: We use the asynchronous version of the QRQW PRAM, where each memory location has a FIFO queue, memory requests must first traverse the queue, and each memory location handles one item per time step. Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], <ref> [Nis90] </ref>. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [Par89] <author> J. Parker. </author> <title> A Concurrent Search Structure Journal of Parallel and Distributed Computing 7: </title> <journal> pp. </journal> <pages> 256-278, </pages> <year> 1989. </year>
Reference-contexts: However, the authors concede that their analysis requires some strong assumptions about both the arrival times and the service times of operations at each node of the search structure. Several authors have looked at methods to reduce resource contention at the root of a search tree. <ref> [Par89] </ref> introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], [JC94] and others (the bibliography in [JC94] is extensive and thorough) have looked at <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], [Wan91], <ref> [Par89] </ref>, and [Yao78]. Table 1 summarizes the behavior of the Search-Butterfly. The results for the static problem in the table assume that processors are searching for keys that are chosen independently and uniformly at random from the set of keys stored in the Search-Butterfly.
Reference: [PVW83] <author> W. Paul, U. Vishkin, H. Wagner. </author> <note> Parallel Dictionaries on 2-3 Trees ICALP 83 </note>
Reference-contexts: In other words, the sequence of memory locations accessed by a processor performing a search is unchanged by other processors performing searches concurrently. Concurrent updates are allowed to effect the memory location access pattern, since this is necessary when the set of keys being stored changes. 1.1 Previous Work <ref> [PVW83] </ref> provide an algorithm for the synchronous EREW PRAM that performs p concurrent operations on a 2-3 Tree containing n keys in time O (log n + log p). Their algorithm is not, however, reasonable in an asynchronous environment. <p> For example, both the method from <ref> [PVW83] </ref> and from [Ran92] require an initial phase where the keys that are being searched for are sorted. When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. <p> This lower bound means that when the accesses by different processors are very localized, any strongly independent search structure must perform poorly when compared to the tightly coupled algorithms of <ref> [PVW83] </ref> and [Ran92]. To deal with this case for asynchronous shared memory 4 machines, we need to find some middle ground between strongly independent algorithms and algo-rithms that require very close cooperation between processors.
Reference: [Ran92] <author> A. Ranade. </author> <title> Maintaining Dynamic Ordered Sets on Processor Networks In Proc. </title> <booktitle> 4 th ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <volume> 127 - 137, </volume> <year> 1992. </year>
Reference-contexts: Their algorithm is not, however, reasonable in an asynchronous environment. Their algorithm assumes that every access by a processor to the search structure is accompanied by simultaneous accesses by all the other processors, and during these accesses, processors cooperate to a high degree. <ref> [Ran92] </ref> studies search structures for fixed connection distributed memory machines, but again the processors do not function independently. For example, both the method from [PVW83] and from [Ran92] require an initial phase where the keys that are being searched for are sorted. <p> the search structure is accompanied by simultaneous accesses by all the other processors, and during these accesses, processors cooperate to a high degree. <ref> [Ran92] </ref> studies search structures for fixed connection distributed memory machines, but again the processors do not function independently. For example, both the method from [PVW83] and from [Ran92] require an initial phase where the keys that are being searched for are sorted. When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. <p> This lower bound means that when the accesses by different processors are very localized, any strongly independent search structure must perform poorly when compared to the tightly coupled algorithms of [PVW83] and <ref> [Ran92] </ref>. To deal with this case for asynchronous shared memory 4 machines, we need to find some middle ground between strongly independent algorithms and algo-rithms that require very close cooperation between processors. We believe that the upper bound techniques presented here provide a good starting point for this goal.
Reference: [Ran88] <author> A. Ranade. </author> <title> Fluent Parallel Computation. </title> <type> Ph.D. Thesis, </type> <institution> Yale University, </institution> <year> 1988. </year>
Reference-contexts: Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by <ref> [Ran88] </ref>, [Lei92], [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> Proof: The largest number of processors that access any given output of the butterfly is Y . Since every processor accesses a randomly chosen input node of the butterfly, w.h.p., at most Y + log n processors access any input node of the butterfly. <ref> [Ran88] </ref> gives a proof that realizing a p packet per input routing problem to random destinations in a butterfly with any non-predictive contention resolution scheme requires only time O (log n+Y ). Note that FIFO contention resolution with up-to-present arbitrary resolution of ties is non-predictive.
Reference: [Sag86] <author> Y. Sagiv. </author> <title> Concurrent Operations on B fl -Trees with Overtaking Journal of Computer and System Sciences 33: </title> <journal> pp. </journal> <pages> 275-296, </pages> <year> 1986. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], [Ell80], [LY81], <ref> [Sag86] </ref>. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [ST91] <author> G. Stamoulis, J. Tsitsiklis. </author> <title> The Efficiency of Greedy Routing in Hypercubes and Butterflies. </title> <booktitle> In Proc. 3 rd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 248-259, </pages> <year> 1991. </year>
Reference-contexts: Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by [Ran88], [Lei92], <ref> [ST91] </ref>, and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> The arrivals to the roots of D are partitioned randomly, and thus the arrivals at each of the root nodes are described by a Poisson process. It is easily seen that S is a leveled network with Markovian routing (see <ref> [ST91] </ref>). Thus, we only need to show that the total arrival rate to any node in the Search-Butterfly is &lt; fi n fl. <p> We show that combining this observation with the technique developed by Stamoulis and Tsitsiklis in <ref> [ST91] </ref> yields the lemma. Claim 1 [ST91] Let a = t 1 ; t 2 ; : : : and a 0 = t 0 1 ; t 0 2 ; : : : be two arrival time streams to a determin istic FIFO queue, where t 1 t 0 1 <p> We show that combining this observation with the technique developed by Stamoulis and Tsitsiklis in <ref> [ST91] </ref> yields the lemma. Claim 1 [ST91] Let a = t 1 ; t 2 ; : : : and a 0 = t 0 1 ; t 0 2 ; : : : be two arrival time streams to a determin istic FIFO queue, where t 1 t 0 1 ; t 2 t 0 2 <p> Then the two corresponding departure time streams d 1 ; d 2 ; : : :, and d 0 2 ; : : :, satisfy d 1 d 0 1 ; d 2 d 0 The proof of <ref> [ST91] </ref> extends to the case where the service time is not constant, but the service time of all arrivals in stream a is no greater than the smallest service time of any arrival in stream a 0 . We now use the technique of sample path analysis developed in [ST91]. <p> of <ref> [ST91] </ref> extends to the case where the service time is not constant, but the service time of all arrivals in stream a is no greater than the smallest service time of any arrival in stream a 0 . We now use the technique of sample path analysis developed in [ST91]. Let a sample path S consist of the set of all arrival times to the network, and all routing decisions defined as follows: the nth packet of type l to depart from queue i proceeds to queue j as a packet of type k.
Reference: [Wal89] <author> J. Walrand. </author> <title> Introduction to Queueing Networks. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: st N N 00 (t); which in turn implies: N N (t) st N N 00 (t): Since the arrivals to N 00 are Poisson, routing in N 00 is Markovian, and all queues in N 00 are PS, we see that N 00 is product form (see for example <ref> [Wal89] </ref>). Since 8i; l, l i &lt; r i i , network N 00 is stable, and thus as t ! 1, the number of times that N N 00 (t) = 0 approaches 1.
Reference: [Wan91] <author> P. Wang. </author> <title> An In-Depth Analysis of Concurrent B-Tree Algorithms Masters Thesis, </title> <publisher> MIT 1991. </publisher>
Reference-contexts: Also, it does not allow for an efficient means of inserting and deleting keys. Many strongly independent search structures that allow updates have been proposed, but analytical evaluation of these structures has been very limited, and has been cited as lacking, for example in [JS93] and <ref> [Wan91] </ref>. In these search structures, correctness of the data structure during updates is usually provided by adding locks to the tree: shared variables that keep some processors from reading sections of the tree that are currently being modified. <p> looked at methods to reduce resource contention at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. <ref> [Wan91] </ref>, [JC94] and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root. <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], <ref> [Wan91] </ref>, [Par89], and [Yao78]. Table 1 summarizes the behavior of the Search-Butterfly. The results for the static problem in the table assume that processors are searching for keys that are chosen independently and uniformly at random from the set of keys stored in the Search-Butterfly.
Reference: [Yao78] <author> A. </author> <title> Yao. </title> <journal> On Random 2-3 Trees Acta Informatica 9, </journal> <pages> pp. 159-170, </pages> <year> 1978. </year>
Reference-contexts: Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], [Wan91], [Par89], and <ref> [Yao78] </ref>. Table 1 summarizes the behavior of the Search-Butterfly. The results for the static problem in the table assume that processors are searching for keys that are chosen independently and uniformly at random from the set of keys stored in the Search-Butterfly.
Reference: [Yao81] <author> A. Yao. </author> <note> Should Tables Be Sorted? Journal of ACM 28, 3 pp. 615-628, 1981. 24 </note>
Reference-contexts: We combine Yao's cell probe model <ref> [Yao81] </ref> with the asynchronous QRQW PRAM: we assume the data structure consists of O (n) memory cells, and that each cell contains only the value of a key and can service at most one probe per time step. <p> and search set S containing p keys, the expected time required to perform S on T is ( p Proof: Since the keys are arbitrarily chosen real numbers, and A is strongly independent, the expected number of probes that each of the p searches needs to perform is (log n) <ref> [Yao81] </ref>. Thus, the expected total number of cell probes is (p log n). Since A is space efficient, there are only O (n) cells to perform these probes in, and the bound follows from the fact that each location can handle only one probe per time step.
References-found: 31

