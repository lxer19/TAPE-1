URL: http://www.cs.umd.edu/users/melo/ADELE/CS-TR-3498.ps.Z
Refering-URL: http://www.cs.umd.edu/users/melo/papers/CS-TR-3498.html
Root-URL: 
Title: AINSI An Inductive Method for Software Process Improvement: Concrete Steps and Guidelines* Measurement and Training
Author: Lionel Briand, Khaled El Emam and Walclio L. Melo** 
Address: Vienna, Austria.  
Note: CS-TR-3498 1 UMIACS-TR-95-77  Paper Published in the Proc. of the ESI-ISCN95:  Sep. 11-12 1995,  1 Introduction Authors are listed in alphabetical order.  
Abstract: Technical Report, University of Maryland, Computer Science Dep., College Park, MD 20742. August, 1995. Abstract Top-down approaches to process improvement based on generic "best practice" models (e.g., CMM, TRILLIUM, BOOTSTRAP, SPICE) have become popular. Despite the idiosyncrasies of each of these approaches, they share some common characteristics: all of them are based on numerous assumptions about what are best practices, and about the business goals of organizations and the problems they face. Other organizations, like the Software Engineering Laboratory of the NASA Goddard Space Flight Center, HP and CRIM in Canada, have adopted the Quality Improvement Paradigm (QIP). The QIP stipulates a more bottom-up and inductive approach to process improvement. The focus of this paradigm is to first understand what processes exist in the organization and to determine what causes the most significant problems. Based on this, opportunities for improvement are devised, and empirical studies are conducted to evaluate potential solutions. In this paper, we present a method, named AINSI 1 (An INductive Software process Improvment method), which defines general but concrete steps and guidelines for putting in place the QIP. This method is the result of the collective experiences of the authors and integrates many lessons learned from process improvement efforts in different environments. It also integrates many complementary techniques such as qualitative analysis, methods for data collection (e.g., the Goal/Question/Metric paradigm), and quantitative evaluation. Top-down process improvement approaches (e.g., the Software Engineering Institutes Capability Maturity Model for software (Paulk et al. 1993), TRILLIUM (Coallier 1995), BOOTSTRAP (Haase et al., 1994), SPICE (Drouin 1995)) provide a high-level model of what ought to be the process of a software development organization. Such models are based on the consensus of a designated working group about how software should be developed or maintained. They are very useful in the sense that they provide general guidelines to people who do not know where to start improving, and in which order. Also, these models are useful in contract award situations where alternative bidders may be comparatively evaluated. A general assumption of these models is that the more an organizations processes match the stipulations of the model, the greater its effectiveness on some criteria (e.g., product quality, productivity, predictability etc.). In general, there is a dearth of evidence supporting this * Briand and El Emam are with the Centre de Recherche Informatique de Montral (CRIM), 1801 McGill College Av., Suite 800, Montral (Qubec), H3A 2N4, Canada; Melo is with the University of Maryland, Institute for Advanced Computer Studies, College Park, MD, 20742. Emails: - lbriand | kelemam-@crim.ca, melo@cs.umd.edu. 
Abstract-found: 1
Intro-found: 1
Reference: <author> J. Armitage and M. </author> <title> Kellner (1994). A conceptual schema for process definitions and models. </title> <booktitle> In Proc. of the 3rd Int'l Conf. on the S/W Process, </booktitle> <address> pp.153-165. </address>
Reference-contexts: are: What are the tasks in the process? What are the dependencies between these tasks? When do the tasks start and end? Who are the actors that perform these tasks? What are the interdependencies between the actors? A conceptual framework defining information that could be collected has been presented in <ref> (Armitage and Kellner 1994) </ref>. This framework has three entity classes (activities, agents, and artifacts) and two aspects (relationships within and among entity classes, and behavior of the entity classes and the relationships).
Reference: <author> V. </author> <title> Basili (1992). The experimental paradigm in software engineering. </title> <editor> In D. Rombach, </editor> <publisher> V. </publisher>
Reference-contexts: Alternatively, one could adopt a more inductive approach to process improvement where the focus of the first step would be to understand what exists in an organization and determine what causes significant problems. Then, solutions could be devised and evaluated in pilot studies or even controlled experiments <ref> (Basili, 1992) </ref>. Only after a solution is found to be effective and efficient, then it should be integrated into the existing process or the process may be modified. Such an approach is inspired by the Quality Improvement Paradigm (QIP) recommended by several researchers and practitioners (Basili, 1992). <p> studies or even controlled experiments <ref> (Basili, 1992) </ref>. Only after a solution is found to be effective and efficient, then it should be integrated into the existing process or the process may be modified. Such an approach is inspired by the Quality Improvement Paradigm (QIP) recommended by several researchers and practitioners (Basili, 1992). The QIP is a specialization of the scientific method for software engineering research. The question now is to determine how such an approach can realistically be implemented in different software organizations. <p> Consequently, the organization would not know if all the activities that have been implemented really provided any quality, productivity, or predictability benefits. Putting practices in place on the faith that they are somehow "good" is not prudent. As noted in <ref> (Basili, 1992) </ref>, many of our intuitive ideas about software development may turn out to be incorrect once put to empirical test. <p> August, 1995. CS-TR-3498 1 1 UMIACS-TR-95-77 9 . Conclusions We have presented in this paper a bottom-up approach for the practical improvement of software processes and products (AINSI: An INductive Software process Improvement method). It may be seen as an instantiation of the more general Quality Improvement Paradigm <ref> (Basili, 1992) </ref>. AINSI differs from top-down approaches which are intended to provide an ideal framework for process improvement, e.g., SEI CMM, because it relies on a more detailed interpretation of available and interdependent sources of information on the software organization.
Reference: <author> Basili and R. </author> <title> Selby (editors), Experimental Software Engineering Issues: Critical Assessment and Future Directions. </title> <booktitle> LNCS, </booktitle> <volume> Vol 706. </volume> <month> Spring-Verlag. </month>
Reference: <author> V. Basili and S. </author> <title> Green (1994). Software process evolution at the SEL. </title> <booktitle> In IEEE Software, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: For example, at the SEL, only after the execution of some case studies did it become evident that Cleanroom produced benefits in quality and productivity <ref> (Basili and Green, 1994) </ref> only if a few modifications to the original method were implemented . Second, qualitative studies should be seen as complementary to quantitative studies.
Reference: <author> V. Basili and H. D. </author> <title> Rombach (1988). The TAME project: towards improvement-oriented software environments. </title> <journal> In IEEE Transactions on Software Engineering, </journal> <volume> 14(6) </volume> <pages> 758-773, </pages> <month> June. </month> <type> Technical Report, </type> <institution> University of Maryland, Computer Science Dep., College Park, MD 20742. </institution> <month> August, </month> <year> 1995. </year> <note> CS-TR-3498 1 2 UMIACS-TR-95-77 V. </note> <author> Basili; L. Briand; W. </author> <title> Melo (1995). An Validation of ObjectOriented Design Metrics. </title> <institution> University of Maryland, Dep. of Computer Science, College Park, MD 20742. CS-TR-3443. </institution>
Reference: <author> M. J. Bassman; F. McGarry; R. </author> <month> Pajerski </month> <year> (1994). </year> <title> Software Measurement Guidebook. </title> <booktitle> Software Engineering Series, </booktitle> <address> SEL-94-002. </address>
Reference: <author> N. Belkhatir and W. L. </author> <title> Melo (1994). Evolving softwre processes by tailoring the behavior of software objects. </title> <booktitle> In Proc. of the IEEE Intl Conf. on S/W Maintenance, </booktitle> <address> Victoria, Canada. </address>
Reference-contexts: As the process improvement effort progresses, it will be necessary to change the process models. The formalism that is chosen ought to be easy to change. This may be facilitated by the use of an automated tool that supports the chosen formalism, e.g. TEMPO <ref> (Belkhatir and Melo 1994) </ref>. It is difficult to decide how deep we must go into the software process definition and modeling. In general, we would discourage the development of very detailed models, mainly because we have not found this excessive to be useful and their construction consumes considerable resources.
Reference: <author> L. Briand; V. Basili; Y.M. Kim; D. R. </author> <title> Squier (1994). "A change analysis process to characterize software maintenance projects". </title> <booktitle> Proc. of the Int'l Conf. on S/W Maintenance. </booktitle> <address> Victoria, Canada. </address>
Reference: <author> L. Briand; W. L Melo; C. Seaman; V. </author> <title> Basili (1995). "Characterizing and assessing a large-scale software maintenance organization". </title> <booktitle> In Proc. of the 17th Int'l Conf. on S/W Eng., </booktitle> <address> Seattle, WA. </address>
Reference: <author> L. Briand, S. Morasca, V. </author> <title> Basili (1994). </title> <booktitle> "Property-Based Software Engineering Measurement", </booktitle> <institution> CS-TR-3368, University of Maryland, College Park, MD, 20742, </institution> <month> November </month> <year> 1994. </year>
Reference: <author> R. Chillarege, I. Bhandhari, J. Chaar, M. Halliday, D. Moebus, B. Ray, and M.Y. Wong. </author> <title> Orthogonal defect classification - a concept for in-process measurement. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(11) </volume> <pages> 943-956, </pages> <month> November. </month>
Reference: <author> F. </author> <title> Coallier (1995). TRILLIUM: A model for the assessment of telecom product development and support capability. </title> <journal> In Software Process Newsletter, </journal> <volume> No. 2, </volume> <pages> pp. 3-8, </pages> <month> Winter. </month>
Reference-contexts: 1 . Introduction Top-down process improvement approaches (e.g., the Software Engineering Institutes Capability Maturity Model for software (Paulk et al. 1993), TRILLIUM <ref> (Coallier 1995) </ref>, BOOTSTRAP (Haase et al., 1994), SPICE (Drouin 1995)) provide a high-level model of what ought to be the process of a software development organization. Such models are based on the consensus of a designated working group about how software should be developed or maintained.
Reference: <author> J. Collofello and B. </author> <month> Gosalia </month> <year> (1993). </year> <title> An application of causal analysis to the software production process. </title> <journal> In Software Practice and Experience, </journal> <volume> 23(10) </volume> <pages> 1095-1105, </pages> <month> October. </month>
Reference: <author> T. Cook and D. Campbell (1979). Quasi-experimentation: </author> <title> Design and Analysis Issues for Field Settings, </title> <publisher> Rand McNally, </publisher> <address> Chicago. </address> <month> J-N Drouin </month> <year> (1995). </year> <title> The SPICE project: An overview. </title> <journal> In Software Process Newsletter, </journal> <volume> No. 2, </volume> <pages> pp. 8-9, </pages> <month> Winter. </month>
Reference-contexts: Kitchenham et al. (1994) have identified three strategies that may be followed: (a) formal experiments, (b) case studies and (c) surveys. In the same the authors express a strong preference for case studies in conducting evaluations in industrial settings. However, another evaluation strategy may be followed, namely quasi-experiments <ref> (Cook and Campbell 1979) </ref>. In quasi-experimental designs, it is recognized that there are many variables that are difficult to control (as one would attempt to do in a formal experiment). In particular, subjects are not assigned to treatment and control groups randomly, resulting in nonequivalent groups. <p> For example, controlled experiments allow a better level of control of the factors under study; and they can be more easily replicated in different environments. However, this is because it may be difficult or impossible to apply such an approach that social scientists have developed techniques such as quasi-experimentation <ref> (Cook and Campbell, 1979) </ref>. Since it takes time for a technology to mature in an organization, case studies are in general also necessary in order to tailor it to the organization based on the feedback from developers and managers [Kitchenham et al., 1995].
Reference: <author> K. El Emam and N. H. </author> <title> Madhavji (1995a). A field study of requirements engineeirng practices in information systems development. </title> <booktitle> In Proc. of the 2nd IEEE Intl Syposium on Requirements Engineering, </booktitle> <pages> pages 68-80. </pages>
Reference: <author> K. El Emam and N. H. Madhavji. </author> <year> (1995b). </year> <title> Measuring the success of requirements engineering processes. </title> <booktitle> In Proc. of the 2nd IEEE Intl Syposium on Requirements Engineering, </booktitle> <pages> pages 204-211. </pages>
Reference: <author> K. El Emam and N. H. </author> <title> Madhavji (1995c). The reliability of measuring organizational maturity. </title> <journal> In Software Process Improvement and Practice Journal, </journal> <volume> 1(1). </volume>
Reference-contexts: Similar studies are being conducted as part of the SPICE project (El Emam and Goldenson 1995). However, despite such commendable efforts, the overall evidence remains weak and is contradicted by other works <ref> (El Emam and Madhavji 1995c) </ref>. Furthermore, in practice, it is not so obvious that these models will address the causes of problems in all organizations.
Reference: <author> K. El Emam and D. R. </author> <month> Goldenson </month> <year> (1995). </year> <title> SPICE: An empiricists perspective. </title> <booktitle> In Proceedings of the Second IEEE International Software Engineering Standards Syposium, </booktitle> <month> August. </month>
Reference-contexts: In addition there is some initial evidence based on two BOOTSTRAP case studies showing that when weaknesses identified by an assessment are addressed, improvements in quality and productivity result (Haase et al., 1994). Similar studies are being conducted as part of the SPICE project <ref> (El Emam and Goldenson 1995) </ref>. However, despite such commendable efforts, the overall evidence remains weak and is contradicted by other works (El Emam and Madhavji 1995c). Furthermore, in practice, it is not so obvious that these models will address the causes of problems in all organizations.
Reference: <author> N. </author> <title> Fenton (1993). Objectives and context of measurement/experimentation. </title> <editor> In D. Rombach, V. Basili and R. Selby (editors), </editor> <title> Experimental Software Engineering Issues: Critical Assessment and Future Directions. </title> <booktitle> LNCS, </booktitle> <volume> Vol 706. </volume> <month> Spring-Verlag. </month>
Reference: <author> N. Fenton; S.L. Pfleeger, </author> <title> R.L Glass (1994). Science and substance: A challenge to software engineers. </title> <journal> IEEE Software, </journal> <month> July, </month> <pages> pp. 86-95. </pages>
Reference-contexts: Evaluation in the context of the host organization is important. This is because for many new, or even old, technologies in software engineering, there is little empirical evidence supporting their claimed benefits. A good discussion of this is given in <ref> (Fenton et al., 1994) </ref> for formal methods, and a good example in (Melo et al., 1995; Basili et al., 1995) for ObjectOriented methods. For instance, most OO methods currently available have never been empirically validated.
Reference: <author> A. Finkelstein; J. Kramer; B. Nuseibeh, eds. </author> <year> (1994). </year> <title> Software Process Modeling and Technology. Research Studies Press (distributed by Wiley & Sons). </title> <type> Technical Report, </type> <institution> University of Maryland, Computer Science Dep., College Park, MD 20742. </institution> <month> August, </month> <year> 1995. </year> <note> CS-TR-3498 1 3 UMIACS-TR-95-77 P. </note> <author> Fowler and S. </author> <title> Rifkin (1990). Software Engineering process Group Guide. </title> <type> Technical Report CMU/SEI-90-TR-24, </type> <institution> Software Engineering Institute. </institution>
Reference-contexts: The purpose of this is to enlist the support and cooperation of the organization's members. This is necessary in preparation for the subsequent activities of the improvement effort. 3 . Model the existing process Process modeling may serve many purposes and is believed to have many benefits <ref> (Finkelstein et al. 1994) </ref>. In the context of process improvement, descriptive process models are useful for understanding the way things currently work in the organization and for communicating this understanding.
Reference: <author> D. </author> <title> Frailey (1991). Defining a corporate-wide software process. </title> <booktitle> In Proc. of the 1st Int'l Conf. on the Software Process, </booktitle> <pages> pp. 113-121. </pages>
Reference-contexts: Some that have been used and that have been found to be useful are Statemate (Kellner and Hansen 1989), structured English, ETVX (Radice et al. 1985), the Actor-Dependency modeling approach (Briand et al. 1995; Yu and Mylopolous 1994), the commonly used Data Flow Diagrams <ref> (Frailey 1991) </ref> and the SADT notation (McGowan and Bohner 1993). The latter four support a single perspective, while the former integrates multiple perspectives (these are state-transition, data flow, and structure). The models developed at this point will be useful for the analyses to be conducted later.
Reference: <author> D. Goldenson and J. </author> <month> Herbsleb </month> <year> (1995). </year> <title> What happens after the appraisal? A survey of process improvement efforts. </title> <note> Paper presented at the 1995 SEPG Conf.. </note>
Reference-contexts: There is now some initial evidence supporting a positive relationship between the CMMs maturity levels and some subjective criteria of including quality and productivity <ref> (Goldenson and Herbsleb 1995) </ref>. In addition there is some initial evidence based on two BOOTSTRAP case studies showing that when weaknesses identified by an assessment are addressed, improvements in quality and productivity result (Haase et al., 1994). <p> In addition there is some initial evidence based on two BOOTSTRAP case studies showing that when weaknesses identified by an assessment are addressed, improvements in quality and productivity result (Haase et al., 1994). Similar studies are being conducted as part of the SPICE project <ref> (El Emam and Goldenson 1995) </ref>. However, despite such commendable efforts, the overall evidence remains weak and is contradicted by other works (El Emam and Madhavji 1995c). Furthermore, in practice, it is not so obvious that these models will address the causes of problems in all organizations.
Reference: <author> R. B. </author> <title> Grady (1992). Practical Software Metrics for Project Management and Process Improvement, </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference: <author> V. Haase, R. Messnarz, G. Koch, H. Kugler, and P. </author> <month> Decrinis </month> <year> (1994). </year> <title> Bootstrap: Fine tuning processs assessment. </title> <booktitle> In IEEE Software, </booktitle> <pages> pp. 25-35, </pages> <month> July. </month>
Reference-contexts: 1 . Introduction Top-down process improvement approaches (e.g., the Software Engineering Institutes Capability Maturity Model for software (Paulk et al. 1993), TRILLIUM (Coallier 1995), BOOTSTRAP <ref> (Haase et al., 1994) </ref>, SPICE (Drouin 1995)) provide a high-level model of what ought to be the process of a software development organization. Such models are based on the consensus of a designated working group about how software should be developed or maintained. <p> In addition there is some initial evidence based on two BOOTSTRAP case studies showing that when weaknesses identified by an assessment are addressed, improvements in quality and productivity result <ref> (Haase et al., 1994) </ref>. Similar studies are being conducted as part of the SPICE project (El Emam and Goldenson 1995). However, despite such commendable efforts, the overall evidence remains weak and is contradicted by other works (El Emam and Madhavji 1995c).
Reference: <author> T. Hall and N. </author> <title> Fenton (1994). Implementing software metrics the critical success factors. In Software Quality Journal, </title> <publisher> 3(4):195208. </publisher>
Reference: <author> J. Henry and B. </author> <month> Blasewitz </month> <year> (1992). </year> <title> Process definition: theory and reality. </title> <booktitle> In IEEE Software, </booktitle> <address> pp.105, </address> <month> November. </month>
Reference-contexts: These three methods should serve as reasonable starting points for a process modeling effort. Furthermore, a discussion of issues to consider in a real world process modeling exercise is given in <ref> (Henry and Blasewitz 1992) </ref>. In particular, the authors of that article suggest tasking the developer groups to build models describing their own processes.
Reference: <author> A. </author> <title> Hersh (1993). Where's the return on process improvement?. </title> <booktitle> In IEEE Software, </booktitle> <pages> page 12, </pages> <month> July. </month>
Reference: <author> M. Kellner and G. </author> <title> Hansen (1989). Software process modeling: a case study. </title> <booktitle> In Proc. of the 22nd Annual Hawaii Int'l Conf. on System Sciences, </booktitle> <volume> vol. II, </volume> <pages> pp. 175-188. </pages>
Reference-contexts: Many formalisms for process modeling have been developed. Few of these formalisms have actually been used in practice. Some that have been used and that have been found to be useful are Statemate <ref> (Kellner and Hansen 1989) </ref>, structured English, ETVX (Radice et al. 1985), the Actor-Dependency modeling approach (Briand et al. 1995; Yu and Mylopolous 1994), the commonly used Data Flow Diagrams (Frailey 1991) and the SADT notation (McGowan and Bohner 1993).
Reference: <author> B. Kitchenham, S. Linkman, and D. </author> <title> Law (1994). Critical review of quantitative assessment. </title> <journal> In Software Engineering Journal, </journal> <volume> 9(2) </volume> <pages> 43-53, </pages> <month> March. </month>
Reference-contexts: If such personnel are not too eager, then the pilot project may fail. Conversely, if such personnel have too much enthusiasm, this may be indicative of another agenda that may place the project at risk. Some general recommendations on selection of personnel are <ref> (Kitchenham et al. 1994) </ref>: do not allow technology "champions" to run evaluation exercises use normal procedures to staff pilot projects; do not select people who are particularly enthusiastic or particularly cynical about the technology The pilot project should be sufficiently small and simple (otherwise it may take too long and may
Reference: <author> B. Kitchenham; L. </author> <title> Pickard; S.L. Pfleeger (1995). Case studies for method and tool evaluation. </title> <journal> IEEE Software, 12(4):5262. </journal>
Reference: <author> D. Kitson and S. </author> <title> Masters (1993). An analysis of SEI software process assessment results: 1987-1991. </title> <booktitle> In Proc. of the 15th Int'l Conf. on S/W Engineering, </booktitle> <pages> pp. 68-77. </pages>
Reference-contexts: For example, an analysis of findings from assessments based on the CMM (for which the appropriate data was available) identified that more than half the organizations had problems in areas not covered by the CMM <ref> (Kitson and Masters 1993) </ref>. Alternatively, one could adopt a more inductive approach to process improvement where the focus of the first step would be to understand what exists in an organization and determine what causes significant problems.
Reference: <author> D. Leonard-Barton and W. </author> <title> Kraus (1985). Implementing new technology. </title> <booktitle> In Harvard Business Review, </booktitle> <pages> pp. 102-110, </pages> <month> November-December. </month>
Reference: <author> N. Madhavji, D. Hoeltje, W.K. Hong, and T. </author> <month> Bruckhaus </month> <year> (1994). </year> <title> Elicit: a method for eliciting process models. </title> <booktitle> In Proc. of the 3rd Int'l Conf. on the S/W Process, </booktitle> <address> pp.111-122. </address>
Reference-contexts: Another article presents a set of process modeling attributes which has perspectives (such as process steps, roles, resources, and constraints) and properties for each of the perspectives <ref> (Madhavji et al. 1994) </ref>. Based on contemporary knowledge, these articles provide a comprehensive view of process information that can be collected.
Reference: <author> W. Melo; L. Briand; V. </author> <title> Basili (1995). Measuring the Impact of Software Reuse on Productivity and Quality in ObjectOriented Systems. </title> <institution> University of Maryland, Dep. of Computer Science, College Park, MD, 20742. CS-TR-3395. </institution> <note> [To appear in the Communications of the ACM] C. </note> <author> McGowan and S. </author> <month> Bohner </month> <year> (1993). </year> <title> Model based process assessments. </title> <booktitle> In Proc. of the Int'l Conf. on S/W Engineering, </booktitle> <pages> pp. 202-211. </pages>
Reference: <author> T. Nakajo and H. </author> <month> Kume </month> <year> (1991). </year> <title> A case history analysis of software error cause-effect relationship. </title> <journal> In IEEE Transactions on Software Engineering, </journal> <volume> 17(8), </volume> <month> August. </month>
Reference: <author> M. Paulk, B. Curtis, M-B Chrissis, and C. </author> <title> Weber (1993). Capability Maturity Model, version 1.1. </title> <booktitle> In IEEE Software, </booktitle> <pages> pp. 18-27, </pages> <month> July. </month>
Reference-contexts: 1 . Introduction Top-down process improvement approaches (e.g., the Software Engineering Institutes Capability Maturity Model for software <ref> (Paulk et al. 1993) </ref>, TRILLIUM (Coallier 1995), BOOTSTRAP (Haase et al., 1994), SPICE (Drouin 1995)) provide a high-level model of what ought to be the process of a software development organization.
Reference: <author> R. Radice, N. Roth, A. OHara, Jr., W. </author> <month> Ciarfella </month> <year> (1985). </year> <title> A programming process architecture. </title> <journal> In IBM Systems Journal, </journal> <volume> 24(2) </volume> <pages> 79-90. </pages>
Reference-contexts: Many formalisms for process modeling have been developed. Few of these formalisms have actually been used in practice. Some that have been used and that have been found to be useful are Statemate (Kellner and Hansen 1989), structured English, ETVX <ref> (Radice et al. 1985) </ref>, the Actor-Dependency modeling approach (Briand et al. 1995; Yu and Mylopolous 1994), the commonly used Data Flow Diagrams (Frailey 1991) and the SADT notation (McGowan and Bohner 1993).
Reference: <author> R. Schaffer and H. </author> <title> Thomson (1992). Successful change programs begin with results. </title> <booktitle> In Harvard Business Review, </booktitle> <pages> pp. 80-89, </pages> <month> January-February. </month> <type> Technical Report, </type> <institution> University of Maryland, Computer Science Dep., College Park, MD 20742. </institution> <month> August, </month> <year> 1995. </year> <institution> CS-TR-3498 1 4 UMIACS-TR-95-77 Software Engineering Laboratory (1995). Software Process Improvement Guidebook. Software Engineering Laboratory Series, </institution> <month> April, SEL-95-002. </month>
Reference-contexts: Progress is then measured by the proportion of Level 3 practices that have been implemented or the extent of compliance to ISO 9001 clauses. Success is measured by having all necessary practices implemented and ISO 9001 clauses adequately satisfied. This, using the terminology in <ref> (Schaffer and Thomson 1992) </ref>, is termed an activity-driven approach to improvement. Strict adherence to the activity-driven approach has a number of disadvantages.
Reference: <author> R. </author> <month> Veryard </month> <year> (1987). </year> <title> Implementing a methodology. </title> <journal> In Information and Software Technology, </journal> <volume> 29(9): </volume> <pages> 46-474, </pages> <month> November. </month>
Reference: <author> C. </author> <note> Vogel (1988). Gnie cognitif, Masson, Paris. </note>
Reference-contexts: The analysis that will lead him/her to determine what happened will be based on multiple sources of information: the process documentation, the product documentation, the project (release or new development) documentation, (structured) interviews <ref> (Vogel, 1988) </ref> with the people involved in the process and, if possible, the originator of the problem report and the owner (s) of the product part where the problem was identified. <p> Second, qualitative studies should be seen as complementary to quantitative studies. In general, developers in an organization have many useful insights into existing problems and ways to address them; they are a valuable source of information in process improvement. Knowledge acquisition methods like structured interviews <ref> (Vogel, 1988) </ref> would help interpret quantitative data and provide ideas for solving problems. In closing, one problem we have witnessed is the attempt by some organizations to try to solve their problems too rapidly. This is manifested in improvement programs with dozens of working groups and technologies being introduced concurrently.
Reference: <author> S. Waligora, J. Bailey, and M. </author> <title> Stark (1995). Impact of ADA and ObjectOriented Design in the Flight Dynamics Division at Goddard Space Flight Center. </title> <journal> Software Engineering Laboratories Series, </journal> <month> March, SEL-95-001. </month>
Reference-contexts: Example options would be the introduction of new practices, like code inspections, changing of Technical Report, University of Maryland, Computer Science Dep., College Park, MD 20742. August, 1995. CS-TR-3498 9 UMIACS-TR-95-77 programming language <ref> (e.g., Waligora et al. 1995) </ref>, the introduction of new tools, like tools for enforcing coding standards, etc. In all cases, however, the identified problems should guide the identification and selection of possible options. <p> With case studies one compares the outcome of the pilot with an existing baseline. It would not be useful to conduct a case study where no baseline exists. A good set of examples of case studies are the experiences of the SEL with ADA and an ObjectOriented analysis/design method <ref> (Waligora et al. 1995) </ref>. Technical Report, University of Maryland, Computer Science Dep., College Park, MD 20742. August, 1995.
Reference: <author> E. Yu and J. </author> <month> Mylopolous </month> <year> (1994). </year> <title> Understanding why in software process modeling, analysis, </title> <booktitle> and design. In Proc. of the 16th Int'l Conf. on Software Engineering, </booktitle> <address> Italy. </address>
References-found: 43

