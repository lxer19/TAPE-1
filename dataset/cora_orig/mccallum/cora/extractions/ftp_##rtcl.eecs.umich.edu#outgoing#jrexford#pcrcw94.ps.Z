URL: ftp://rtcl.eecs.umich.edu/outgoing/jrexford/pcrcw94.ps.Z
Refering-URL: http://www.eecs.umich.edu/RTCL/routing/
Root-URL: http://www.cs.umich.edu
Title: Support for Multiple Classes of Traffic in Multicomputer Routers  
Author: Jennifer Rexford and Kang G. Shin 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Real-Time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: Emerging parallel real-time and multimedia applications broaden the range of performance requirements imposed on the interconnection network. This communication typically consists of a mixture of different traffic classes, where guaranteed packets require bounds on latency or throughput while good average performance suffices for the best-effort traffic. This paper investigates how multicomputer routers can capitalize on low-latency routing and switching techniques for best-effort traffic while still supporting guaranteed communication. Through simulation experiments, we show that certain architectural features are best-suited to particular performance requirements. Based on these results, the paper proposes and evaluates a router architecture that tailors low-level routing, switching, and flow-control policies to the unique needs of best-effort and guaranteed traffic. Careful selection of these policies, coupled with fine-grain arbitration between the classes, allows the guaranteed and best-effort packets to share network bandwidth without sacrificing the performance of either class.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Cohen, G. G. Finn, R. Felderman, and A. DeSchon, </author> <title> "The use of message-based multicomputer components to construct gigabit networks," </title> <journal> Computer Communication Review, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 32-44, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Although multicomputer router design has traditionally emphasized providing low-latency communication, modern parallel applications require additional services from the interconnection network <ref> [1, 2] </ref>. Multimedia and real-time applications, such as scientific visualization and process control, necessitate control over delay variance and throughput, in addition to low average latency [3]. While guaranteed traffic necessitates deterministic or probabilistic bounds on throughput or end-to-end delay, best-effort service often suffices for the remaining traffic.
Reference: 2. <author> R. Cypher, A. Ho, S. Konstantinidou, and P. Messina, </author> <title> "Architectural requirements of parallel scientific applications with explicit communication," </title> <booktitle> in Proc. Int'l Symposium on Computer Architecture, </booktitle> <pages> pp. 2-13, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Although multicomputer router design has traditionally emphasized providing low-latency communication, modern parallel applications require additional services from the interconnection network <ref> [1, 2] </ref>. Multimedia and real-time applications, such as scientific visualization and process control, necessitate control over delay variance and throughput, in addition to low average latency [3]. While guaranteed traffic necessitates deterministic or probabilistic bounds on throughput or end-to-end delay, best-effort service often suffices for the remaining traffic.
Reference: 3. <author> D. Ferrari, </author> <title> "Client requirements for real-time communication services," </title> <journal> IEEE Communications Magazine, </journal> <pages> pp. 65-72, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Although multicomputer router design has traditionally emphasized providing low-latency communication, modern parallel applications require additional services from the interconnection network [1, 2]. Multimedia and real-time applications, such as scientific visualization and process control, necessitate control over delay variance and throughput, in addition to low average latency <ref> [3] </ref>. While guaranteed traffic necessitates deterministic or probabilistic bounds on throughput or end-to-end delay, best-effort service often suffices for the remaining traffic.
Reference: 4. <author> P. Kermani and L. Kleinrock, </author> <title> "Virtual cut-through: A new computer communication switching technique," </title> <journal> Computer Networks, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 267-286, </pages> <month> Septem-ber </month> <year> 1979. </year>
Reference-contexts: Additionally, the design should not unduly penalize the performance of best-effort packets. Modern parallel routers significantly reduce average latency by avoiding unnecessary packet delay at intermediate nodes; however, these low-latency techniques often impinge on control over packet scheduling. In particular, cut-through switching <ref> [4, 5] </ref> decentralizes bandwidth allocation and packet scheduling by allowing an incoming packet to proceed directly to the next node in its route if a suitable outgoing link is available. <p> Best-effort packets, on the other hand, may forego these restrictions in exchange for lower latency and reduced buffer requirements. 3.1 Average Latency Traditional packet switching requires an arriving packet to buffer completely before transmission to a subsequent node can begin. In contrast, cut-through switching schemes, such as virtual cut-through <ref> [4] </ref> and wormhole [5], try to forward an incoming packet directly to an idle output link. If the packet encounters a busy outgoing channel, virtual cut-through switching buffers the packet, while a blocked wormhole packet stalls pending access to the link.
Reference: 5. <author> W. J. Dally and C. L. Seitz, </author> <title> "The torus routing chip," </title> <journal> Journal of Distributed Computing, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 187-196, </pages> <year> 1986. </year>
Reference-contexts: Additionally, the design should not unduly penalize the performance of best-effort packets. Modern parallel routers significantly reduce average latency by avoiding unnecessary packet delay at intermediate nodes; however, these low-latency techniques often impinge on control over packet scheduling. In particular, cut-through switching <ref> [4, 5] </ref> decentralizes bandwidth allocation and packet scheduling by allowing an incoming packet to proceed directly to the next node in its route if a suitable outgoing link is available. <p> In contrast, cut-through switching schemes, such as virtual cut-through [4] and wormhole <ref> [5] </ref>, try to forward an incoming packet directly to an idle output link. If the packet encounters a busy outgoing channel, virtual cut-through switching buffers the packet, while a blocked wormhole packet stalls pending access to the link.
Reference: 6. <author> J. J. Bae and T. Suda, </author> <title> "Survey of traffic control schemes and protocols in ATM networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 79, no. 2, </volume> <pages> pp. 170-189, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Other multicomputer router features, such as FIFO queueing and adaptive routing, further complicate the effort to provide predictable or guaranteed service. Research in networking considers techniques for the effective mixing of multiple traffic classes in a communication fabric <ref> [6, 7] </ref>. However, the design tradeoffs for parallel machines differ significantly from those in a heterogeneous, distributed environment. In parallel machines, router design trade-offs reflect the large network size and the tight coupling between nodes. <p> Arbitration and flow-control schemes enable the router to export bounded network access delay, packet service time, and throughput for guaranteed traffic, even in the presence of best-effort flits. Hardware or software protocols can then build on these abstractions to allocate communication resources and schedule guaranteed packets <ref> [6, 7, 28] </ref>. Traditionally, real-time systems have employed packet switching, coupled with scheduling algorithms, for predictable performance. However, in tightly-coupled parallel machines, this approach unduly penalizes best-effort packets.
Reference: 7. <author> C. M. Aras, J. F. Kurose, D. S. Reeves, and H. Schulzrinne, </author> <title> "Real-time communication in packet-switched networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 122-139, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Other multicomputer router features, such as FIFO queueing and adaptive routing, further complicate the effort to provide predictable or guaranteed service. Research in networking considers techniques for the effective mixing of multiple traffic classes in a communication fabric <ref> [6, 7] </ref>. However, the design tradeoffs for parallel machines differ significantly from those in a heterogeneous, distributed environment. In parallel machines, router design trade-offs reflect the large network size and the tight coupling between nodes. <p> Providing separate buffers for each priority level is effective for coarse-grain priority assignment, but this approach incurs significant cost for fine-grain resolution. With packet queues at each node, the router can effectively utilize fine-grain priorities, such as deadlines, to assign access to output links <ref> [7, 28] </ref>. Instead of providing separate logic and buffer space for each priority level, the router can include a single priority queue for each output link [29, 30]. By buffering packets at each node, packet switching enables the router to schedule traffic to provide latency or bandwidth guarantees [28]. <p> Arbitration and flow-control schemes enable the router to export bounded network access delay, packet service time, and throughput for guaranteed traffic, even in the presence of best-effort flits. Hardware or software protocols can then build on these abstractions to allocate communication resources and schedule guaranteed packets <ref> [6, 7, 28] </ref>. Traditionally, real-time systems have employed packet switching, coupled with scheduling algorithms, for predictable performance. However, in tightly-coupled parallel machines, this approach unduly penalizes best-effort packets.
Reference: 8. <author> W. J. Dally and P. Song, </author> <title> "Design of a self-timed VLSI multicomputer communication controller," </title> <booktitle> in IEEE Int'l Conf. on Computer Design: VLSI in Computers, </booktitle> <pages> pp. 230-234, </pages> <year> 1987. </year>
Reference: 9. <author> W. J. Dally, J. A. S. Fiske, J. S. Keen, R. A. Lethin, M. D. Noakes, P. R. Nuth, R. E. Davison, and G. A. Fyler, </author> <title> "The Message-Driven Processor: A multicomputer processing node with efficient mechanisms," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 23-39, </pages> <month> April </month> <year> 1992. </year>
Reference: 10. <author> C. Peterson, J. Sutton, and P. Wiley, </author> <title> "iWarp: A 100-MOPS LIW microprocessor for multicomputers," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. </pages> <address> 26-29,81-87, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Although each physical link services at most one virtual channel in each flit cycle, multiple virtual channels can be active at the injection and reception ports; this enables the model to represent router designs that have multiple physical or logical injection/reception ports <ref> [10, 14, 15] </ref>. Upon receiving the header flits of an incoming packet, the receiver (RX) decides whether to buffer, stall, or forward the packet, based on the routing and switching policies and prevailing network conditions. <p> Virtual channels provide an effective mechanism for reducing the interaction between packets while still allowing traffic to share network bandwidth [8-10, 14, 31]. Exporting the virtual channel abstraction to the injection and reception ports further prevents intrusion between packets at the network entry and exit points <ref> [10, 14, 15] </ref>. By tailoring the routing, switching, and flow-control policies for each virtual network, multicomputer routers can support traffic classes with conflicting performance requirements. Packets on separate virtual networks interact only to compete for access to the physical links and ports.
Reference: 11. <author> D. Talia, </author> <title> "Message-routing systems for transputer-based multicomputers," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 62-72, </pages> <month> June </month> <year> 1993. </year>
Reference: 12. <author> M. G. Norman and P. Thanisch, </author> <title> "Models of machines and computation for mapping in multicomputers," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 25, no. 3, </volume> <pages> pp. 263-302, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: These low-latency channels broaden the spectrum of flow-control schemes that can be implemented efficiently. The fine-grain interaction between and within the nodes necessitates effective mapping of application tasks onto the interconnection network <ref> [12] </ref>. Effective router techniques for handling multiple traffic classes should provide useful software abstractions to parallel applications. The remainder of this paper is organized as follows. Section 2 presents a simulation model for studying the impact of routing and switching on interconnection network performance.
Reference: 13. <author> W. Dally, </author> <title> "Virtual-channel flow control," </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 194-205, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Based on these results, Section 4 proposes and evaluates a router architecture that allows best-effort packets to capitalize on low-latency routing and switching techniques without compromising the performance of guaranteed traffic. This architecture uses virtual channels <ref> [13] </ref> to logically partition the inter Fig. 1. Router model connection network into multiple virtual networks that each employs different low-level policies for managing communication. <p> In contrast, a blocked wormhole packet stalls in the network, effectively dilating its length until its outgoing channel becomes available. As a result, wormhole networks typically utilize only a fraction of the available network bandwidth <ref> [13, 21] </ref>, as seen by the early saturation of the wormhole plot in Figure 2. At higher loads, this effect enables packet switching to outperform wormhole switching, even though packet switching introduces buffering delay at each hop in a packet's route. <p> At higher loads, this effect enables packet switching to outperform wormhole switching, even though packet switching introduces buffering delay at each hop in a packet's route. While adding virtual channels can increase wormhole throughput <ref> [13] </ref>, channel contention still creates dependencies amongst packets spanning multiple nodes. The sensitivity of wormhole networks to slight changes in load, including short communication bursts [22], complicates the use of wormhole switching for guaranteed traffic. <p> While these decentralized queues complicate packet scheduling, a wormhole router can influence resource allocation through the virtual channel reservation and arbitration policies. Priority assignment of virtual channels to incoming packets improves predictability; adaptive arbitration policies can further reduce variability by basing flit bandwidth allocation on packet deadlines or priority <ref> [13, 24-26] </ref>. While assigning priorities to virtual channels provides some control over packet scheduling, this ties priority resolution to the number of virtual channels.
Reference: 14. <author> J. Dolter, S. Daniel, A. Mehra, J. Rexford, W. Feng, and K. G. Shin, "SPIDER: </author> <title> Flexible and efficient communication support for point-to-point distributed systems," </title> <type> Technical Report CSE-TR-180-93, </type> <institution> University of Michigan, </institution> <month> October </month> <year> 1993. </year> <note> To appear in Proc. Int. Conf. on Distributed Computing Systems, </note> <month> June </month> <year> 1994. </year>
Reference-contexts: Although each physical link services at most one virtual channel in each flit cycle, multiple virtual channels can be active at the injection and reception ports; this enables the model to represent router designs that have multiple physical or logical injection/reception ports <ref> [10, 14, 15] </ref>. Upon receiving the header flits of an incoming packet, the receiver (RX) decides whether to buffer, stall, or forward the packet, based on the routing and switching policies and prevailing network conditions. <p> This section evaluates the ability of wormhole, virtual cut-through, and packet switching to meet different Fig. 2. Average packet latency performance requirements in multicomputer routers. Each switching scheme is best-suited for certain traffic classes with particular characteristics and performance requirements <ref> [14, 18] </ref>. To effectively support multiple traffic classes, the router should bound both network access time and the service rate for guaranteed packets. These bounds provide necessary abstractions for the scheduling and mapping of communicating tasks. <p> The router divides each physical link into multiple virtual channels, where some virtual channels carry best-effort packets and the rest accept only guaranteed traffic. Virtual channels provide an effective mechanism for reducing the interaction between packets while still allowing traffic to share network bandwidth <ref> [8-10, 14, 31] </ref>. Exporting the virtual channel abstraction to the injection and reception ports further prevents intrusion between packets at the network entry and exit points [10, 14, 15]. <p> Virtual channels provide an effective mechanism for reducing the interaction between packets while still allowing traffic to share network bandwidth [8-10, 14, 31]. Exporting the virtual channel abstraction to the injection and reception ports further prevents intrusion between packets at the network entry and exit points <ref> [10, 14, 15] </ref>. By tailoring the routing, switching, and flow-control policies for each virtual network, multicomputer routers can support traffic classes with conflicting performance requirements. Packets on separate virtual networks interact only to compete for access to the physical links and ports.
Reference: 15. <author> J. H. Kim and A. A. Chien, </author> <title> "Evaluation of wormhole routed networks under hybrid traffic loads," </title> <booktitle> in Proc. Hawaii Int'l Conf. on System Sciences, </booktitle> <pages> pp. 276-285, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Although each physical link services at most one virtual channel in each flit cycle, multiple virtual channels can be active at the injection and reception ports; this enables the model to represent router designs that have multiple physical or logical injection/reception ports <ref> [10, 14, 15] </ref>. Upon receiving the header flits of an incoming packet, the receiver (RX) decides whether to buffer, stall, or forward the packet, based on the routing and switching policies and prevailing network conditions. <p> Virtual channels provide an effective mechanism for reducing the interaction between packets while still allowing traffic to share network bandwidth [8-10, 14, 31]. Exporting the virtual channel abstraction to the injection and reception ports further prevents intrusion between packets at the network entry and exit points <ref> [10, 14, 15] </ref>. By tailoring the routing, switching, and flow-control policies for each virtual network, multicomputer routers can support traffic classes with conflicting performance requirements. Packets on separate virtual networks interact only to compete for access to the physical links and ports.
Reference: 16. <author> J. Dolter, </author> <title> A Programmable Routing Controller Supporting Multi-mode Routing and Switching in Distributed Real-Time Systems, </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Once a packet reserves an outgoing virtual channel, it competes with other virtual channels for access to the physical link (TX) through an arbitration policy. The model includes several arbitration policies, including round-robin and priority-driven schemes. The router model is evaluated in the pp-mess-sim (point-to-point message simulator) environment <ref> [16, 17] </ref>. Implemented in C++, pp-mess-sim is an object-oriented discrete-event simulation tool for evaluating multicomputer router architectures. Using a high-level specification language, the user can select the network topology, internal router policies, and the traffic patterns generated by each node.
Reference: 17. <author> W. Feng, J. Rexford, A. Mehra, S. Daniel, J. Dolter, and K. Shin, </author> <title> "Architectural support for managing communication in point-to-point distributed systems," </title> <type> Technical Report CSE-TR-197-94, </type> <institution> University of Michigan, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Once a packet reserves an outgoing virtual channel, it competes with other virtual channels for access to the physical link (TX) through an arbitration policy. The model includes several arbitration policies, including round-robin and priority-driven schemes. The router model is evaluated in the pp-mess-sim (point-to-point message simulator) environment <ref> [16, 17] </ref>. Implemented in C++, pp-mess-sim is an object-oriented discrete-event simulation tool for evaluating multicomputer router architectures. Using a high-level specification language, the user can select the network topology, internal router policies, and the traffic patterns generated by each node.
Reference: 18. <author> J. Rexford, J. Dolter, and K. G. Shin, </author> <title> "Hardware support for controlled interaction of guaranteed and best-effort communication," </title> <booktitle> in Proc. Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: This section evaluates the ability of wormhole, virtual cut-through, and packet switching to meet different Fig. 2. Average packet latency performance requirements in multicomputer routers. Each switching scheme is best-suited for certain traffic classes with particular characteristics and performance requirements <ref> [14, 18] </ref>. To effectively support multiple traffic classes, the router should bound both network access time and the service rate for guaranteed packets. These bounds provide necessary abstractions for the scheduling and mapping of communicating tasks.
Reference: 19. <author> X. Zhang, </author> <title> "System effects of interprocessor communication latency in multicom-puters," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. </pages> <address> 12-15,52-55, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: If the packet encounters a busy outgoing channel, virtual cut-through switching buffers the packet, while a blocked wormhole packet stalls pending access to the link. While first-generation multicomputers employed packet switching, most existing research and commercial routers utilize cut-through switching for lower latency and reduced buffer space requirements <ref> [19] </ref>. The usage of memory and link resources determines both average packet latency and the influence an in-transit packet can have on other network traffic. schemes as a function of the packet injection rate.
Reference: 20. <author> W. J. Dally and C. L. Seitz, </author> <title> "Deadlock-free message routing in multiprocessor interconnection networks," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-36, no. 5, </volume> <pages> pp. 547-553, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: In the simulation experiments, virtual cut-through and packet switching utilize one virtual channel for each physical link and store buffered packets in output queues in the router. Wormhole packets employ deadlock-free routing on a pair of virtual channels <ref> [20] </ref> with demand-driven, round-robin arbitration amongst the virtual channels; each vir-tual channel can hold a single flit pending access to the output link. Even with this small amount of memory resources, wormhole switching performs well at low loads, slightly outperforming virtual cut-through switching.
Reference: 21. <author> J. Ngai and C. Seitz, </author> <title> "A framework for adaptive routing in multicomputer networks," </title> <booktitle> in Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 1-9, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: In contrast, a blocked wormhole packet stalls in the network, effectively dilating its length until its outgoing channel becomes available. As a result, wormhole networks typically utilize only a fraction of the available network bandwidth <ref> [13, 21] </ref>, as seen by the early saturation of the wormhole plot in Figure 2. At higher loads, this effect enables packet switching to outperform wormhole switching, even though packet switching introduces buffering delay at each hop in a packet's route.
Reference: 22. <author> W. Dally and H. Aoki, </author> <title> "Deadlock-free adaptive routing in multicomputer networks using virtual channels," </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 466-475, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: While adding virtual channels can increase wormhole throughput [13], channel contention still creates dependencies amongst packets spanning multiple nodes. The sensitivity of wormhole networks to slight changes in load, including short communication bursts <ref> [22] </ref>, complicates the use of wormhole switching for guaranteed traffic. Still, wormhole switching is particularly well-suited to best-effort packets, due to its low latency and minimal buffer space requirements.
Reference: 23. <author> R. Jain, </author> <title> The Art of Computer Systems Performance Analysis, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Figure 3 shows the coefficient of variation for packet latency for the three switching schemes, where the coefficient of variation measures the ratio of the standard deviation to the mean <ref> [23] </ref>. Since latency characteristics vary depending on the distance between source-destination pairs, the graph shows results only for packets traveling a fixed distance in the network. While each source generates traffic with uniform random selection of destination nodes, data collection for Figure 3 includes only packets traveling exactly five hops.
Reference: 24. <author> B. Tsai and K. G. Shin, </author> <title> "Sequencing of concurrent communication traffic in a mesh multicomputer with virtual channels," </title> <booktitle> to appear in Proc. Int'l Conf. on Parallel Processing, </booktitle> <month> August </month> <year> 1994. </year>
Reference: 25. <author> J.-P. Li and M. W. </author> <title> Mutka, "Priority based real-time communication for large scale wormhole networks," </title> <booktitle> in Proc. International Parallel Processing Symposium, </booktitle> <pages> pp. 433-438, </pages> <month> April </month> <year> 1994. </year>
Reference: 26. <author> J.-P. Li and M. W. </author> <title> Mutka, "Real-time virtual channel flow control," </title> <booktitle> in Phoenix Conference on Computers and Communication, </booktitle> <month> April </month> <year> 1994. </year>
Reference: 27. <author> A. A. Chien, </author> <title> "A cost and speed model for k-ary n-cube wormhole routers," </title> <booktitle> in Proc. Hot Interconnects, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: If packets at different priority levels share virtual channels, the application must account for blocking time when a lower priority packet holds resources needed by higher priority traffic. While adding more virtual channels can improve priority resolution, this also incurs increased latency overhead and implementation complexity for the router <ref> [27] </ref>. In addition, the router must enforce the multiple priority levels at its injection and reception ports to avoid unpredictable stalling at the network entry and exit points. Providing separate buffers for each priority level is effective for coarse-grain priority assignment, but this approach incurs significant cost for fine-grain resolution.
Reference: 28. <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <booktitle> in Proc. Int. Conf. on Distributed Computer Systems, </booktitle> <pages> pp. 300-307, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Providing separate buffers for each priority level is effective for coarse-grain priority assignment, but this approach incurs significant cost for fine-grain resolution. With packet queues at each node, the router can effectively utilize fine-grain priorities, such as deadlines, to assign access to output links <ref> [7, 28] </ref>. Instead of providing separate logic and buffer space for each priority level, the router can include a single priority queue for each output link [29, 30]. By buffering packets at each node, packet switching enables the router to schedule traffic to provide latency or bandwidth guarantees [28]. <p> Instead of providing separate logic and buffer space for each priority level, the router can include a single priority queue for each output link [29, 30]. By buffering packets at each node, packet switching enables the router to schedule traffic to provide latency or bandwidth guarantees <ref> [28] </ref>. For example, suppose a guaranteed packet enters an intermediate node well in advance of its deadline. <p> Arbitration and flow-control schemes enable the router to export bounded network access delay, packet service time, and throughput for guaranteed traffic, even in the presence of best-effort flits. Hardware or software protocols can then build on these abstractions to allocate communication resources and schedule guaranteed packets <ref> [6, 7, 28] </ref>. Traditionally, real-time systems have employed packet switching, coupled with scheduling algorithms, for predictable performance. However, in tightly-coupled parallel machines, this approach unduly penalizes best-effort packets.
Reference: 29. <author> H. J. Chao and N. Uzun, </author> <title> "A VLSI sequencer chip for ATM traffic shaper and queue manager," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 27, no. 11, </volume> <pages> pp. 1634-1643, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: With packet queues at each node, the router can effectively utilize fine-grain priorities, such as deadlines, to assign access to output links [7, 28]. Instead of providing separate logic and buffer space for each priority level, the router can include a single priority queue for each output link <ref> [29, 30] </ref>. By buffering packets at each node, packet switching enables the router to schedule traffic to provide latency or bandwidth guarantees [28]. For example, suppose a guaranteed packet enters an intermediate node well in advance of its deadline.
Reference: 30. <author> K. Toda, K. Nishida, E. Takahashi, N. Michell, and Y. Yamaguchi, </author> <title> "Implementation of a priority forwarding router chip for real-time interconnection networks," </title> <booktitle> in Proc. Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: With packet queues at each node, the router can effectively utilize fine-grain priorities, such as deadlines, to assign access to output links [7, 28]. Instead of providing separate logic and buffer space for each priority level, the router can include a single priority queue for each output link <ref> [29, 30] </ref>. By buffering packets at each node, packet switching enables the router to schedule traffic to provide latency or bandwidth guarantees [28]. For example, suppose a guaranteed packet enters an intermediate node well in advance of its deadline.
Reference: 31. <author> S. Konstantinidou, </author> <title> "Segment router: A novel router design for parallel computers," </title> <booktitle> to appear in Proc. Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: The router divides each physical link into multiple virtual channels, where some virtual channels carry best-effort packets and the rest accept only guaranteed traffic. Virtual channels provide an effective mechanism for reducing the interaction between packets while still allowing traffic to share network bandwidth <ref> [8-10, 14, 31] </ref>. Exporting the virtual channel abstraction to the injection and reception ports further prevents intrusion between packets at the network entry and exit points [10, 14, 15].
Reference: 32. <author> M. W. </author> <title> Mutka, "Using rate monotonic scheduling technology for real-time communications in a wormhole network," </title> <booktitle> in Proc. Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1994. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
References-found: 32

