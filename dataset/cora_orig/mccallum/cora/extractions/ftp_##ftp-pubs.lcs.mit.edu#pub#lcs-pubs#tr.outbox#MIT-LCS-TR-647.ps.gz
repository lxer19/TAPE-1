URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-647.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: Functional Encapsulation and Type Reconstruction in a Strongly-typed, Polymorphic Language  
Author: Shail Aditya Gupta 
Date: February 1995  
Pubnum: MIT LCS TR-647  
Abstract-found: 0
Intro-found: 1
Reference: [AA91] <author> Zena M. Ariola and Arvind. </author> <title> Compilation of Id. </title> <booktitle> In Proceedings of the fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, California, </address> <month> August </month> <year> 1991. </year> <note> Also available as CSG Memo 341, </note> <institution> MIT Lab. for Computer Sc., </institution> <address> Cam-bridge, MA 02139. </address>
Reference-contexts: Simply nested let-bindings are generalized to a recursive letrec-style block of bindings. Similarly, a 2-way conditional operator (if...then...else...) is generalized to an m-way Case dispatch operator. The semantics of this language has been given directly in terms of graph rewriting rules as shown in <ref> [AA91, AA94] </ref>. Although, we will use the operational machinery described in Chapter 3 while showing the correctness of our type reconstruction algorithm. Kernel Id is a more realistic abstraction of actual intermediate form used in the Id compiler [AA91, Tra86] than the tiny expression language used in Chapter 3. <p> Although, we will use the operational machinery described in Chapter 3 while showing the correctness of our type reconstruction algorithm. Kernel Id is a more realistic abstraction of actual intermediate form used in the Id compiler <ref> [AA91, Tra86] </ref> than the tiny expression language used in Chapter 3. The Id source language supports special syntactic constructs such as list and array comprehensions, complex pattern matching, and nested function and type declarations [Nik91]. <p> [Binding; ] fl in SE g Binding ::= Identifier = E Declaration ::= Binding j Type-Decl Type-Decl ::= type T ff 1 ff n = C 1 t 11 t 1k 1 j Program ::= [Declaration; ] fl E ses and transformations such as comprehension-desugaring, scope-analysis, type-checking, and pattern-matching compilation <ref> [AA91, Gup90, Tra86] </ref>. These transformations result in a Kernel Id program where every sub-expression has a unique name and a well-defined Hindley/Milner type, so that all internal type declarations can be lifted to the top-level.
Reference: [AA93] <author> Zena M. Ariola and Arvind. </author> <title> Graph Rewriting Systems: Capturing Sharing of Computation in Language Implementations. Computation Structures Group Memo 347, </title> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: But it would be useful to show the soundness proofs directly in a parallel setting. This would also allow us to directly model the different closing strategies required with different memory synchronization protocols as discussed in Section 2.3.5. We feel that a graph rewriting framework such as <ref> [AA93] </ref> would be more appropriate for this purpose than the relational semantics approach taken here. Applications to Other Compiler Analyses This type system may also be used to infer useful static information that is conventionally determined using dataflow analysis or abstract interpretation.
Reference: [AA94] <author> Zena M. Ariola and Arvind. </author> <title> Properties of a First-order Functional Language with Sharing. </title> <type> CSG Memo 347-1, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <month> June </month> <year> 1994. </year> <note> To appear in Theoretical Computer Science, </note> <month> September </month> <year> 1995. </year>
Reference-contexts: Simply nested let-bindings are generalized to a recursive letrec-style block of bindings. Similarly, a 2-way conditional operator (if...then...else...) is generalized to an m-way Case dispatch operator. The semantics of this language has been given directly in terms of graph rewriting rules as shown in <ref> [AA91, AA94] </ref>. Although, we will use the operational machinery described in Chapter 3 while showing the correctness of our type reconstruction algorithm. Kernel Id is a more realistic abstraction of actual intermediate form used in the Id compiler [AA91, Tra86] than the tiny expression language used in Chapter 3.
Reference: [AC93] <author> Shail Aditya and Alejandro Caro. </author> <title> Compiler-directed Type Reconstruction for Polymorphic Languages. </title> <booktitle> In Proceedings of the ACM Conference on Functional Programming Languages and Computer Architecture, Copenhagen, Denmark, </booktitle> <pages> pages 74-82, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: A preliminary version of the type reconstruction scheme described in this chapter was implemented during the fall of 1992 in the context of the Id source debugger [Car93] for the Monsoon dataflow architecture and was reported in <ref> [AC93] </ref>. The Id compiler [Tra86] was modified to perform the type analysis and hint generation for every function within the user program as shown in Section 6.3. A simple Id datatype encoding was used for type-hints as shown in Section 6.3.3. <p> In <ref> [AC93] </ref>, we presented a preliminary compilation and type reconstruction scheme which omitted some of the formal details. <p> Second, we cache the reconstructed type-maps of all activation frames for future references by their child frames. Therefore, no activation frame may need to be reconstructed more than 6 In our earlier paper <ref> [AC93] </ref>, this operation was abstracted into the auxiliary function Unify-Aligned. 144 once. Furthermore, since the root frame is already marked as reconstructed at the start of the program, the algorithm is guaranteed to terminate properly as it recursively climbs the activation tree at Line 15.
Reference: [AFH94] <author> Shail Aditya, Christine H. Flood, and James E. Hicks. </author> <title> Garbage Collection for Strongly-Typed Languages using Run-time Type Reconstruction. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming, </booktitle> <address> Orlando, Florida, USA, </address> <pages> pages 12-23. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: We compared the performance of this scheme against a conservative garbage collector and a compiler-directed explicit allocation/deallocation scheme, all implemented within the same framework. The results of this study were first reported in <ref> [AFH94] </ref> and are presented here in Chapter 8. The study showed that tagless garbage collection based on type reconstruction was not only feasible but also beneficial for scientific programs with large scalar arrays.
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: We partition the nodes of this graph into strongly connected components (SCC) <ref> [AHU74] </ref> according to this (directed) edge criterion. This puts mutually recursive datatypes into the same component. We will use this information to assign the same region and closure extension parameters to mutually recursive datatypes. 3.
Reference: [AM89] <author> Andrew W. Appel and David B. MacQueen. </author> <title> Standard ML Reference Manual. </title> <institution> Princeton University and AT&T Bell Laboratories, </institution> <note> Preliminary edition, </note> <year> 1989. </year> <title> Distributed along with the Standard ML of New Jersey Compiler. </title>
Reference-contexts: We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> This problem of typing partial applications was fixed in part by the type system of Standard ML of New Jersey, which we discuss next. 2.2.3 Type System of Standard ML of New Jersey The type system of Standard ML of New Jersey <ref> [AM89] </ref> assigns an integer rank to each imperative type variable. We write these ranks as superscripts on the type variables. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns
Reference: [ANP89] <author> Arvind, Rishiyur S. Nikhil, and Keshav K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <year> 1989. </year>
Reference-contexts: Id is a high-level, strongly-typed language and it uses the Hindley/Milner polymorphic type system and its automatic type inference mechanism [Mil78, DM82] at its functional core. Id also offers imperative data-structures (I-structures <ref> [ANP89] </ref> and M-structures [BNA91]) that cater to imperative styles of programming. Id is a layered language by design (see Figure 1.1). The language and its implementation can be divided into three distinct layers: the user-level functional layer, the system-level imperative layer, and the architecture-level implementation layer. <p> Under the non-strict, parallel evaluation model of Id, the array a is returned as soon as it is allocated; its filling loop executes in parallel. However, this does not create any race condition for the array because the I-structure protocol <ref> [ANP89] </ref> supports fine-grain producer-consumer synchronization on every memory location: multiple readers wait at an empty location until a single writer fills it with the desired value. Nevertheless, as it stands, there are some technical problems with the above implementation. <p> Each memory transaction is assumed to be exclusive and non-blocking. There is no synchronization of any kind between readers and writers. I-Structure Synchronization | The I-structure protocol <ref> [ANP89] </ref> enforces producer-consumer synchronization between a single writer and multiple readers using full/empty presence 42 bits on memory locations. A location is deemed empty initially. Multiple readers may issue I-fetches all of which block until the single writer performs an I-store changing the state of the location to full. <p> We present an efficient implementation of the map list function that does not even require reversing the final list (c.f. function imp map in Example 2.6) because the list is generated from left to right using a technique known as "open-lists" <ref> [ANP89] </ref>: 5 We abuse our notation slightly by calling locations embedded inside a constructor value as field values just like the other values present directly within the constructor, although bare locations are no longer considered to be proper values. <p> Furthermore, these pointers are always aligned on 8-byte boundaries when stored in memory. Each 64-bit double word in the heap has an associated 2-bit presence value in the presence-bit area. These presence bits are used to implement Id's I-structure <ref> [ANP89] </ref>, and M-structure [BNA91] synchronization operations. 6 If the network is blocked, the message is buffered and is tried again at a later point.
Reference: [App89] <author> Andrew W. Appel. </author> <title> Runtime tags aren't necessary. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 2(2) </volume> <pages> 153-163, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The run-time system may load and process the information before program execution or upon request from another application. 5.2.4 Type Maintenance vs. Type Reconstruction Recently, several type reconstruction schemes have been proposed for statically-typed polymorphic languages that do not incur the run-time tag management overhead <ref> [App89, Gol91, GG92] </ref>. In these schemes, static type information may be combined with clues from the dynamic state of the machine (the call stack) to automatically reconstruct the run-time type of most run-time objects. <p> Of course, we need to ensure that complete type reconstruction is possible for all run-time objects under all circumstances. However, the existing schemes <ref> [App89, Gol91, GG92] </ref> do not guarantee complete type reconstruction for all run-time objects under all circumstances. <p> Furthermore, it supports a polymorphic type inference system and uses an untagged run-time system. Our goal is to use run-time type reconstruction in order to determine the exact type of all objects within the Id run-time system. 108 As mentioned earlier, the existing schemes <ref> [App89, Gol91, GG92] </ref> are unable to reconstruct the types of some objects. We would like to fix this situation so that the exact type of all run-time objects may be reconstructed automatically. <p> In case of polymorphic functions, the types of the objects contained within the function body would depend on the types of the arguments that it receives at a given application site. Appel <ref> [App89] </ref> first noted that if the exact types of the arguments of a polymorphic function were known at run-time, then its entire body could be instantiated appropriately using its compile-time typing. <p> This completely instantiates h3's type-map yielding the exact types of its function parameter z and its other local identifiers. As noted in Section 6.1.2, the type reconstruction schemes described earlier <ref> [App89, Gol91, GG92] </ref> would fail to reconstruct the type of x in the body of h3. The reason is that these schemes only use the type information derived from the current stack of activation frames. <p> Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction <ref> [App89, Gol91, GG92] </ref> or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects.
Reference: [App90] <author> Andrew W. Appel. </author> <title> A runtime system. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3(4) </volume> <pages> 343-380, </pages> <month> November </month> <year> 1990. </year> <month> 181 </month>
Reference-contexts: All dynamically-typed languages such as Lisp and Smalltalk use extensive tagging of objects in order to perform type consistency checks at run-time. Some implementations of statically-typed languages such as the Standard ML of New Jersey <ref> [App90] </ref> also make use of object tagging, usually for the benefit of the garbage collector. Tagging every object is costly. Keeping tag bits in every word reduces the range of representable scalars and pointers in conventional architectures, and the user application also pays the additional cost of tag maintenance. <p> For instance, it may be possible to entirely skip the traversal of large arrays while searching for embedded pointers to heap objects, if the exact run-time type of their elements turns out to be a scalar. Clever compilers and run-time systems that tag every object <ref> [App90] </ref> may sometimes be able to encode such information within the header of the array if its type is statically known to be a scalar, but this is not possible with polymorphic array constructors such as the make vector function of Example 2.1 which could be used in both scalar and <p> Usually, it is more convenient to use some automatic mechanism for storage reclamation such as an independent garbage collector that reclaims storage periodically once it is no longer in use. Traditionally, run-time systems geared towards automatic garbage collection use a tagged object representation model <ref> [App90, Wil92] </ref>. This enables the garbage collector to distinguish between scalar objects and pointers to heap objects without any support from the user or the compiler, although the user application has to pay the price of tagging and boxing objects and performing continuous tag maintenance.
Reference: [Bar88] <author> Joel F. Bartlett. </author> <title> Compacting Garbage Collection with Ambiguous Roots. </title> <type> Research Report 88/2, </type> <institution> Western Research Laboratory, Digital Equipment Corporation, </institution> <month> Febru-ary </month> <year> 1988. </year>
Reference-contexts: The motivation comes from a desire to use the full pointer addressability and native representation for scalars rather than a tagged representation, and to avoid the overhead of continuous tag maintenance. Some techniques, such as conservative garbage collection <ref> [Bar88, BW88] </ref> and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction [App89, Gol91, GG92] or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects. <p> It may also be possible to compact or copy part of the live data that is definitely known to reside on the heap as shown by Bartlett <ref> [Bar88] </ref>. The feasibility and efficiency of such schemes depend crucially on the object representation convention used within the run-time system and the possibility of obscuring pointer/non-pointer information within the source language and the compiler. <p> Also, CGC cannot compact or copy all objects because conservatively identified pointers cannot be updated. However, there are some more sophisticated schemes that allow compaction and/or copying of a large fraction of the heap objects <ref> [Bar88] </ref>. Finally, CGC has no knowledge of the source types, therefore it must examine every slot of every reachable object and no short-circuiting based on scalar-type information is possible.
Reference: [Bar92] <author> Paul S. Barth. </author> <title> Atomic Data Structures for Parallel Computing. </title> <type> PhD thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <month> March </month> <year> 1992. </year> <note> Available as Technical Report MIT/LCS/TR-532. </note>
Reference-contexts: Most 9 The notation "a![i]" in Id denotes M-take/M-put operations on mutable arrays with read-and-lock/write-and-unlock semantics. The notation "---" denotes a local barrier. All the computation above the barrier must terminate before any of the computation below the barrier is allowed to proceed. See <ref> [BNA91, Bar92] </ref> for details. 41 strongly-typed systems would only allow creating an internal mutable array to which accumu-lations are made, then copy the final tallies to a functional array which is returned. <p> The stored data is then distributed to all the blocked and subsequent readers. Multiple writes to the same location are considered to be an error. M-Structure Synchronization | The M-structure protocol <ref> [BNA91, Bar92] </ref> enforces mutual exclusion synchronization among multiple readers and writers. Readers issue M-take operations on full memory locations that read the location and leave it empty. A subsequent M-put on the location restores the status to full and makes the data available to other readers. <p> Finally, while closing M-structure objects into functional objects that are implemented using the I-structure protocol, if only one outstanding put is allowed, then it is possible to use only a take-barrier <ref> [Bar92] </ref> instead of the usual full barrier. This is because once a location is empty after a successful M-take operation, multiple functional I-fetches may be allowed to queue up and the ensuing M-put can be made to satisfy them just like an I-store would.
Reference: [Bec92] <author> Michael J. Beckerle. </author> <title> An Overview of the START(*T) Computer System. </title> <type> Mo-torola Technical Report MCRC-TR-28, </type> <institution> Motorola Cambridge Research Center, One Kendall Square, </institution> <address> Building 200, Cambridge, MA 02139, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The *T architecture extends a basic RISC instruction set with low-overhead, user-mode communication and synchronization primitives. The details of the architecture may be found elsewhere <ref> [Bec92] </ref>.
Reference: [Blo89] <author> A. Bloss. </author> <title> Update analysis and the efficient implementation of functional aggregates. </title> <booktitle> In Proceedings of the ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> London, UK. </address> <publisher> ACM, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: In a purely functional setting, some compilers would perform extensive destructive update analysis, linearity analysis, use linear type systems, abstract datatypes or monadic language constructs <ref> [Blo89, Wad90, Hud92, PJW93, LPJ94] </ref> to determine that the histogram may be safely single-threaded through the computation and hence modified in place.
Reference: [BNA91] <author> Paul S. Barth, Rishiyur S. Nikhil, and Arvind. M-Structures: </author> <title> Extending a Parallel, Non-Strict, Functional Language with State. </title> <booktitle> In Proceedings of the ACM Comference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 538-568. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> LNCS 523. </note>
Reference-contexts: Id is a high-level, strongly-typed language and it uses the Hindley/Milner polymorphic type system and its automatic type inference mechanism [Mil78, DM82] at its functional core. Id also offers imperative data-structures (I-structures [ANP89] and M-structures <ref> [BNA91] </ref>) that cater to imperative styles of programming. Id is a layered language by design (see Figure 1.1). The language and its implementation can be divided into three distinct layers: the user-level functional layer, the system-level imperative layer, and the architecture-level implementation layer. <p> Thus, the close construct serves as a true interface between the low-level, imperative layer and the high-level functional layer of the language. 2.3.4 Efficiency and Parallelism Consider the following example adapted from <ref> [BNA91] </ref> that builds a n-bucket functional histogram of objects stored in a binary search tree. <p> Most 9 The notation "a![i]" in Id denotes M-take/M-put operations on mutable arrays with read-and-lock/write-and-unlock semantics. The notation "---" denotes a local barrier. All the computation above the barrier must terminate before any of the computation below the barrier is allowed to proceed. See <ref> [BNA91, Bar92] </ref> for details. 41 strongly-typed systems would only allow creating an internal mutable array to which accumu-lations are made, then copy the final tallies to a functional array which is returned. <p> The stored data is then distributed to all the blocked and subsequent readers. Multiple writes to the same location are considered to be an error. M-Structure Synchronization | The M-structure protocol <ref> [BNA91, Bar92] </ref> enforces mutual exclusion synchronization among multiple readers and writers. Readers issue M-take operations on full memory locations that read the location and leave it empty. A subsequent M-put on the location restores the status to full and makes the data available to other readers. <p> Furthermore, these pointers are always aligned on 8-byte boundaries when stored in memory. Each 64-bit double word in the heap has an associated 2-bit presence value in the presence-bit area. These presence bits are used to implement Id's I-structure [ANP89], and M-structure <ref> [BNA91] </ref> synchronization operations. 6 If the network is blocked, the message is buffered and is tried again at a later point.
Reference: [Bur77] <author> Rod M. Burstall. </author> <title> Design Considerations for a Functional Programming Language. </title> <booktitle> In Infotech State of the Art Conference: The Software Revolution, </booktitle> <month> October </month> <year> 1977. </year>
Reference-contexts: For this reason, many high-level languages offer only a fixed set of high-level constructs with pre-defined semantics rather than provide the user with the complete flexibility and the raw power of a low-level kernel language. The list comprehension mechanism, first introduced in NPL <ref> [Bur77, Dar77] </ref> and later adopted in Miranda [Tur85] and Haskell, is an example of such a language construct.
Reference: [BW88] <author> H.-J. Boehm and M. Weiser. </author> <title> Garbage Collection in an Uncooperative Environment. </title> <journal> Software|Practice and Experience, </journal> <volume> 18(9) </volume> <pages> 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The motivation comes from a desire to use the full pointer addressability and native representation for scalars rather than a tagged representation, and to avoid the overhead of continuous tag maintenance. Some techniques, such as conservative garbage collection <ref> [Bar88, BW88] </ref> and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction [App89, Gol91, GG92] or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects. <p> Still, it is possible to perform garbage collection using a conservative object identification strategy as shown by Boehm and Weiser <ref> [BW88] </ref>. In this scheme, the garbage collector guesses whether a given value is a scalar or a pointer to a heap object. Typically, the guess is based on certain assumptions about the location and alignment of actual pointer data.
Reference: [Car89] <author> L. Cardelli. </author> <title> Typeful Programming. </title> <editor> In E. J. Neuhold and M. Paul, editors, </editor> <booktitle> Formal Description of Programming Concepts, </booktitle> <pages> pages 431-507. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Leroy showed in [Ler93] that the naive Hindley/Milner typing rules are sound with respect to polymorphism-by-name semantics for imperative references and continuations. This approach is used in languages like Quest <ref> [Car89] </ref> and to a limited extent in CLU [LAB + 81] where explicit type parameters are used to abstract and instantiate polymorphic objects. Unfortunately, suspension and re-evaluation of polymorphic objects destroys their sharing characteristics which are very important in the dynamic semantics of the Id language.
Reference: [Car93] <author> Alejandro Caro. </author> <title> A Debugger for Id. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: A preliminary version of the type reconstruction scheme described in this chapter was implemented during the fall of 1992 in the context of the Id source debugger <ref> [Car93] </ref> for the Monsoon dataflow architecture and was reported in [AC93]. The Id compiler [Tra86] was modified to perform the type analysis and hint generation for every function within the user program as shown in Section 6.3. <p> In order to reduce the book-keeping within the debugger, the types of temporary, internal identifiers were dropped from the type-map of a function; only source-level, user-defined identifiers were kept together with their position in the function's activation frame. The Id debugger <ref> [Car93] </ref> was written in Lisp and executed on the host processor in the front. It allowed a user to stop the Id program executing on the Monsoon processor in the back when certain pre-specified events were triggered.
Reference: [CCF + 93] <author> Derek Chiou, Alejandro Caro, Christine Flood, James E. Hicks, and Michael J. Beckerle. </author> <title> Run time support for Id running on *T, version 1.4. Computation structures group memo, </title> <institution> MIT, Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: and the type reconstruction algorithm now appears in Chapter 7 along with a proof of its correctness. 6.6.2 Type Reconstruction for Tagless Garbage Collection During the fall of 1993, full support for run-time type reconstruction was integrated into the Id compiler for the *T multi-threaded architecture and its run-time system <ref> [CCF + 93] </ref> for the purpose of performing tagless garbage collection. Naturally, this required complete type reconstruction for every slot of every function activation frame and all the heap objects reachable from them including higher-order function closures. <p> However, registers may still be used to pass parameters to C functions called within a single microthread. The Id run-time system consists of the frame manager, the heap manager, and protocol handlers for I-structure and M-structure memory operations <ref> [CCF + 93] </ref>. All run-time system calls are initiated and serviced as split-phase transactions. A microthread sends a message to a run-time system request handler passing it the descriptor of a microthread that would receive the reply.
Reference: [Dam85] <author> L. Damas. </author> <title> Type Assignment in Programming Languages. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, Department of Computer Science, </institution> <year> 1985. </year>
Reference-contexts: We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns
Reference: [Dar77] <author> John Darlington. </author> <title> Program Transformation and Synthesis: Present Capabilities. </title> <type> Research Report 77/43, </type> <institution> Department of Computing and Control, Imperial College of Science and Technology, </institution> <address> London, </address> <month> September </month> <year> 1977. </year> <note> Also appears as Report No. 48, </note> <institution> Department of Artificial Intelligence, University of Edinburgh. </institution>
Reference-contexts: For this reason, many high-level languages offer only a fixed set of high-level constructs with pre-defined semantics rather than provide the user with the complete flexibility and the raw power of a low-level kernel language. The list comprehension mechanism, first introduced in NPL <ref> [Bur77, Dar77] </ref> and later adopted in Miranda [Tur85] and Haskell, is an example of such a language construct.
Reference: [DM82] <author> L. Damas and R. Milner. </author> <title> Principal Type-schemes for Functional Programs. </title> <booktitle> In Proceedings of the 9th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-212, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: Id is a high-level, strongly-typed language and it uses the Hindley/Milner polymorphic type system and its automatic type inference mechanism <ref> [Mil78, DM82] </ref> at its functional core. Id also offers imperative data-structures (I-structures [ANP89] and M-structures [BNA91]) that cater to imperative styles of programming. Id is a layered language by design (see Figure 1.1).
Reference: [FLR + 94] <author> Babak Falsafi, Alvin R. Lebeck, Steven K. Reinhardt, Ioannis Schoinas, Mark D. Hill, James R. Larus, Anne Rogers, and David A. Wood. </author> <title> Application-Specific Protocols for User-Level Shared Memory. </title> <booktitle> In Supercomputing '94, Proceedings. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1994. </year> <month> 182 </month>
Reference-contexts: This property leads to obvious compile-time optimizations such as common sub-expression elimination, code-hoisting, and memory-fetch elimination that attempt to reduce the number of copies. This also permits unlimited caching of such functional data in a parallel machine without any risk of write-invalidation. In parallel systems using software-controlled shared-memory protocols <ref> [Nik94, FLR + 94] </ref> this may directly translates into cheaper protocols for object access and migration.
Reference: [GG92] <author> Benjamin Goldberg and Michael Gloger. </author> <title> Polymorphic Type Reconstruction for Garbage Collection without Tags. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 53-65, </pages> <year> 1992. </year>
Reference-contexts: The run-time system may load and process the information before program execution or upon request from another application. 5.2.4 Type Maintenance vs. Type Reconstruction Recently, several type reconstruction schemes have been proposed for statically-typed polymorphic languages that do not incur the run-time tag management overhead <ref> [App89, Gol91, GG92] </ref>. In these schemes, static type information may be combined with clues from the dynamic state of the machine (the call stack) to automatically reconstruct the run-time type of most run-time objects. <p> Of course, we need to ensure that complete type reconstruction is possible for all run-time objects under all circumstances. However, the existing schemes <ref> [App89, Gol91, GG92] </ref> do not guarantee complete type reconstruction for all run-time objects under all circumstances. <p> Furthermore, it supports a polymorphic type inference system and uses an untagged run-time system. Our goal is to use run-time type reconstruction in order to determine the exact type of all objects within the Id run-time system. 108 As mentioned earlier, the existing schemes <ref> [App89, Gol91, GG92] </ref> are unable to reconstruct the types of some objects. We would like to fix this situation so that the exact type of all run-time objects may be reconstructed automatically. <p> Then, both t 1 and t 0 can be instantiated to int giving the actual type of x as desired. 6.1.2 Problems with Closures and Free Variables Unfortunately, the above scheme is incomplete. Goldberg and Gloger <ref> [GG92] </ref> noted that sometimes types of objects hidden inside a closure are impossible to reconstruct. <p> It may appear that this problem arises only when an argument of a function is never used within its body, but the following example adapted from <ref> [GG92] </ref> shows that this is not the case: 2 Example 6.3: def f3 x (list t 0 ) = f def h3 z t 1 = if length x (list t 0 ) == 1 then z:nil else z:z:nil; in h3 g; then f3 (1:nil) (list int) else f3 (true:nil) (list <p> Goldberg and Gloger argue in <ref> [GG92] </ref> that since h3 does not use the elements of its free variable list x but only its spine (to compute its length), a garbage collector can ignore these elements and copy just the spine. <p> This completely instantiates h3's type-map yielding the exact types of its function parameter z and its other local identifiers. As noted in Section 6.1.2, the type reconstruction schemes described earlier <ref> [App89, Gol91, GG92] </ref> would fail to reconstruct the type of x in the body of h3. The reason is that these schemes only use the type information derived from the current stack of activation frames. <p> Moreover, no additional hash-tables would be necessary in order to keep track of partially traversed polymorphic shared objects as shown in <ref> [GG92] </ref> because complete type reconstruction ensures that the entire traversal of a shared object can be completed the very first time it is encountered. 6.6 Implementation Status The type reconstruction scheme described in this chapter has been implemented in two different applications within the Id programming environment. <p> Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction <ref> [App89, Gol91, GG92] </ref> or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects. <p> Since these functions are specialized to the type of a particular object, they may be more efficient than interpreting the run-time reconstructed types of the objects. 8.1.3 Related Work Goldberg and Gloger used type reconstruction to garbage collect a polymorphic language <ref> [GG92] </ref>. But their system did not guarantee complete type reconstruction.
Reference: [GJLS87] <author> David K. Gifford, Pierre Jouvelot, John M. Lucassen, and Mark A. Sheldon. </author> <title> FX-87 Reference Manual. </title> <type> Technical Report MIT/LCS/TR-407, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization [LG88]. One such type and effect system was successfully used in the FX-87 language <ref> [GJLS87] </ref> which supported explicitly declared type polymorphism. More recently, automatic type and effect inference techniques have been developed [TJ92, Wri92] that use the effect propagation mechanism to infer types that model polymorphic imperative objects more accurately than the systems given above. <p> the form (effect-variable w effect) which means that the effect on the right hand side is a lower bound on the actual effect denoted by the effect-variable on the left hand side. 8 Indeed, region analysis was dropped from FX-91 language [GJSO91] which is a more recent version of FX-87 <ref> [GJLS87] </ref>. 34 Analysis of Effect Systems On the whole, effect systems seem to be a powerful tool to summarize a variety of dynamic behaviors of programs accurately.
Reference: [GJSO91] <author> David K. Gifford, Pierre Jouvelot, Mark A. Sheldon, and James W. O'Toole. </author> <title> Report on the FX-91 Programming Language. </title> <type> Technical Report MIT/LCS/TR-531, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1991. </year>
Reference-contexts: At least two effect-based systems [TJ92, Wri92] propose such inference mechanisms based on structural unification [Rob65]. The effect system of FX-91 <ref> [GJSO91] </ref> uses the more complex algebraic unification [JG91] which permits unification modulo algebraic identities such as associativity and commutativity. This provides more expressive power to the inference system, albeit at the cost of simplicity and efficiency. Here, we will only discuss the inference system based on standard structural unification. <p> might result by erroneously masking this effect. are of the form (effect-variable w effect) which means that the effect on the right hand side is a lower bound on the actual effect denoted by the effect-variable on the left hand side. 8 Indeed, region analysis was dropped from FX-91 language <ref> [GJSO91] </ref> which is a more recent version of FX-87 [GJLS87]. 34 Analysis of Effect Systems On the whole, effect systems seem to be a powerful tool to summarize a variety of dynamic behaviors of programs accurately.
Reference: [Gol91] <author> Benjamin Goldberg. </author> <title> Tag-free garbage collection for strongly typed programming languages. </title> <booktitle> In SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 165-176, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The run-time system may load and process the information before program execution or upon request from another application. 5.2.4 Type Maintenance vs. Type Reconstruction Recently, several type reconstruction schemes have been proposed for statically-typed polymorphic languages that do not incur the run-time tag management overhead <ref> [App89, Gol91, GG92] </ref>. In these schemes, static type information may be combined with clues from the dynamic state of the machine (the call stack) to automatically reconstruct the run-time type of most run-time objects. <p> Of course, we need to ensure that complete type reconstruction is possible for all run-time objects under all circumstances. However, the existing schemes <ref> [App89, Gol91, GG92] </ref> do not guarantee complete type reconstruction for all run-time objects under all circumstances. <p> Furthermore, it supports a polymorphic type inference system and uses an untagged run-time system. Our goal is to use run-time type reconstruction in order to determine the exact type of all objects within the Id run-time system. 108 As mentioned earlier, the existing schemes <ref> [App89, Gol91, GG92] </ref> are unable to reconstruct the types of some objects. We would like to fix this situation so that the exact type of all run-time objects may be reconstructed automatically. <p> The exact types of the arguments present at an application site may, in turn, be determined by reconstructing the type of the parent's body containing that application site and so on. Goldberg <ref> [Gol91] </ref> made the above ideas more concrete in the context of tagless garbage collection for strongly-typed, sequential languages. <p> At that point, all polymorphic functions in the call chain can be correctly instantiated revealing the run-time types of their internal objects. In the context of sequential execution, Goldberg <ref> [Gol91] </ref> also showed that the entire state of the machine may be reconstructed in one pass by starting from the root frame at the bottom of the activation stack and working towards the most recent frame at the top of the activation stack. <p> This completely instantiates h3's type-map yielding the exact types of its function parameter z and its other local identifiers. As noted in Section 6.1.2, the type reconstruction schemes described earlier <ref> [App89, Gol91, GG92] </ref> would fail to reconstruct the type of x in the body of h3. The reason is that these schemes only use the type information derived from the current stack of activation frames. <p> These parameter routines would be picked up automatically by the GC-routine (s) of the function from its activation frame at the time of garbage collection. This scheme would operate in the same way as the tagless garbage collection mechanism proposed by Goldberg <ref> [Gol91] </ref> where function-specific and site-specific garbage collection routines are generated that understand the structure and the liveness properties of the local identifiers of a function. <p> The climbing process terminates at the first ancestor frame that has already been reconstructed, or earlier if sufficient information is available via the type-hints. This avoids traversing the activation tree from the root activation frame to all its leaves as suggested in <ref> [Gol91] </ref> which would involve reconstructing all the activation frames within the dynamic activation tree. Our algorithm pays only incremental cost for each request for reconstruction, which is a very useful feature for interactive applications such as a source debugger. <p> Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction <ref> [App89, Gol91, GG92] </ref> or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects.
Reference: [GP90] <author> Benjamin Goldberg and Young Gil Park. </author> <title> Higher Order Escape Analysis: Optimizing Stack Allocation in Functional Program Implementations. </title> <booktitle> In Proceedings of the 3rd European Symposium on Programming, </booktitle> <pages> pages 152-160. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year> <note> LNCS 432. </note>
Reference-contexts: For polymorphic objects, non-mutability implies type-safety and vice versa, but that is not the case for monomorphic objects. As the preceding discussion shows, ensuring non-mutability involves a simple form of escape analysis on the part of the compiler which is conventionally performed using dataflow analysis or abstract interpretation <ref> [GP90, GPG91, HI89] </ref>. Indeed, all the imperative type systems in the literature concentrate on the issue of type-safety alone. In our case, we intend to model such simple form of escape analysis for free using the existing machinery of our type system that is already required to ensure its type-safety.
Reference: [GPG91] <author> Young Gil Park and Benjamin Goldberg. </author> <title> Reference Escape Analysis: Optimizing Reference Counting based on the Lifetime of References. </title> <booktitle> In Proceedings of the ACM Symposium on Partial Evaluation and Semantics-based Program Manipulation, </booktitle> <institution> Yale University, </institution> <address> New Haven, CT, USA, </address> <pages> pages 178-189. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: For polymorphic objects, non-mutability implies type-safety and vice versa, but that is not the case for monomorphic objects. As the preceding discussion shows, ensuring non-mutability involves a simple form of escape analysis on the part of the compiler which is conventionally performed using dataflow analysis or abstract interpretation <ref> [GP90, GPG91, HI89] </ref>. Indeed, all the imperative type systems in the literature concentrate on the issue of type-safety alone. In our case, we intend to model such simple form of escape analysis for free using the existing machinery of our type system that is already required to ensure its type-safety.
Reference: [Gup90] <author> Shail Aditya Gupta. </author> <title> An Incremental Type Inference System for the Programming Language Id. </title> <type> Master's thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <month> September </month> <year> 1990. </year> <note> Available as Technical Report MIT/LCS/TR-488. </note>
Reference-contexts: It is interesting to note that the propagation of type information from closure creation sites to their final application sites for non-type-conserving functions may be formulated as an overloading resolution problem which may then be handled using well-known techniques in the literature <ref> [Gup90, PJW92, WB89] </ref>. These techniques systematically translate overloading into parametric polymorphism by replacing unresolved instances of overloaded identifiers in a function with additional parameters that are supplied at its application site. In our scheme, these parameters are the explicit type-hints that are used by the type reconstruction algorithm. <p> Likewise, 4 We follow the terminology of <ref> [Gup90, WB89] </ref> where the usual Hindley/Milner type of a function is extended with predicates to model overloaded identifiers. In Haskell [HWe90] these are known as contexts. <p> [Binding; ] fl in SE g Binding ::= Identifier = E Declaration ::= Binding j Type-Decl Type-Decl ::= type T ff 1 ff n = C 1 t 11 t 1k 1 j Program ::= [Declaration; ] fl E ses and transformations such as comprehension-desugaring, scope-analysis, type-checking, and pattern-matching compilation <ref> [AA91, Gup90, Tra86] </ref>. These transformations result in a Kernel Id program where every sub-expression has a unique name and a well-defined Hindley/Milner type, so that all internal type declarations can be lifted to the top-level. <p> Each group of mutually recursive bindings is type-checked within a type environment that assigns polymorphic type schemes to the identifiers bound in previous groups and monomorphic types to the identifiers bound within the same group. This transformation maximizes Hindley/Milner polymorphism for an unordered sequence of bindings <ref> [Gup90, HWe90] </ref>. 2 This property ensures that each type-variable instantiation may be treated as an independent parameter to be inserted at that site during translation, although it may introduce some subtle typing discrepancies as discussed in Section 7.2.4. 136 7.2.2 Type Inference The type system shown in Figure 7.2 may be
Reference: [HI89] <author> W.L. Harrison III. </author> <title> The interprocedural analysis and automatic parallelization of scheme programs. Lisp and Symbolic Computation, </title> <address> 2(3-4):179-396, </address> <year> 1989. </year>
Reference-contexts: For polymorphic objects, non-mutability implies type-safety and vice versa, but that is not the case for monomorphic objects. As the preceding discussion shows, ensuring non-mutability involves a simple form of escape analysis on the part of the compiler which is conventionally performed using dataflow analysis or abstract interpretation <ref> [GP90, GPG91, HI89] </ref>. Indeed, all the imperative type systems in the literature concentrate on the issue of type-safety alone. In our case, we intend to model such simple form of escape analysis for free using the existing machinery of our type system that is already required to ensure its type-safety.
Reference: [Hic93] <author> James E. Hicks. </author> <title> Experiences with compiler-directed storage reclamation. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <year> 1993. </year>
Reference-contexts: The motivation comes from a desire to use the full pointer addressability and native representation for scalars rather than a tagged representation, and to avoid the overhead of continuous tag maintenance. Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation <ref> [HJ92, Hic93] </ref>, do not use any run-time type information. While, garbage collection based on type reconstruction [App89, Gol91, GG92] or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects. <p> The feasibility and efficiency of such schemes depend crucially on the object representation convention used within the run-time system and the possibility of obscuring pointer/non-pointer information within the source language and the compiler. In another scheme proposed by Hicks <ref> [HJ92, Hic93] </ref>, the compiler performs life-time analysis of objects and automatically inserts explicit deallocation calls for an object that is determined to be dead at a particular point in the program.
Reference: [HJ92] <author> James E. Hicks Jr. </author> <title> Compiler-directed Storage Reclamation using Object Lifetime Analysis. </title> <type> PhD thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <year> 1992. </year> <note> Available as Technical Report MIT/LCS/TR-555. </note>
Reference-contexts: This is because no references to that object may escape this scope. This information may be used to allocate such objects on stack instead of the heap as shown in [TT93], or insert additional code at compile-time to reclaim that storage automatically on the lines of <ref> [HJ92] </ref>. 102 Part II Types in Run-time System Design: Type Reconstruction 103 Chapter 5 A Typed Run-time System 5.1 Introduction Traditionally, programming environments of dynamically-typed languages such as Lisp or Small-talk maintain type information in the form of run-time type descriptors on every object. <p> The motivation comes from a desire to use the full pointer addressability and native representation for scalars rather than a tagged representation, and to avoid the overhead of continuous tag maintenance. Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation <ref> [HJ92, Hic93] </ref>, do not use any run-time type information. While, garbage collection based on type reconstruction [App89, Gol91, GG92] or explicit type propagation [Tol94] use source type information for identifying and traversing live heap objects. <p> The feasibility and efficiency of such schemes depend crucially on the object representation convention used within the run-time system and the possibility of obscuring pointer/non-pointer information within the source language and the compiler. In another scheme proposed by Hicks <ref> [HJ92, Hic93] </ref>, the compiler performs life-time analysis of objects and automatically inserts explicit deallocation calls for an object that is determined to be dead at a particular point in the program.
Reference: [HM93] <author> R. Harper and J. C. Mitchell. </author> <title> On the Type Structure of Standard ML. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15 </volume> <pages> 211-252, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Another interesting scheme has been proposed by Tolmach [Tol94] where type instantiation and propagation is made explicit in the program by converting it into an intermediate form based on the second-order -calculus <ref> [Rey74, HM93] </ref>. Under this transformation, every polymorphic object is parameterized with explicit type parameters for each of its polymorphic type-variables that are instantiated at the time of application to actual type arguments.
Reference: [HMV93] <author> My Hoang, John Mitchell, and Ramesh Viswanathan. </author> <title> Standard ML weak polymor-phism and imperative constructs. </title> <booktitle> In Proceedings of the Eighth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 15-25. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: The resulting type system is slightly more complex than Standard ML but still relatively easy to implement and has been recently shown to be sound <ref> [HMV93] </ref>. Without going into details, it should be clear that this modification handles the function list identity in Example 2.6 quite well. <p> Hence, the type system must conservatively assume that all imperative functions create mutable references when passed as arguments. The formalization for the above type system presented in <ref> [HMV93] </ref> is somewhat more powerful than the SML/NJ compiler implementation and it can deal with the above situation correctly. Although, it requires a more complicated mechanism for rank book-keeping and uses rank variables instead of fixed integral ranks. <p> Although, it requires a more complicated mechanism for rank book-keeping and uses rank variables instead of fixed integral ranks. It also entails a more complicated type unification mechanism that needs to resolve algebraic constraints on rank variables. The interested reader is referred to <ref> [HMV93] </ref>. 2.2.4 Limitations of the Standard ML Type Systems Although the two type systems presented above cover a lot of practically useful cases of imperative programming, they are still not sufficiently powerful for our purposes.
Reference: [Hud92] <author> Paul Hudak. </author> <title> Mutable Abstract Datatypes -or- How to Have Your State and Munge It Too. </title> <institution> Research Report YALEU/DCS/RR-914, Department of Computer Science, Yale University, </institution> <address> New Haven, CT 06520, </address> <month> December </month> <year> 1992. </year> <note> Revised May 1993. 183 </note>
Reference-contexts: In a purely functional setting, some compilers would perform extensive destructive update analysis, linearity analysis, use linear type systems, abstract datatypes or monadic language constructs <ref> [Blo89, Wad90, Hud92, PJW93, LPJ94] </ref> to determine that the histogram may be safely single-threaded through the computation and hence modified in place.
Reference: [HWe90] <editor> P. Hudak and P. Wadler (editors). </editor> <title> Report on the programming language Haskell, a non-strict purely functional language (Version 1.0). </title> <type> Technical Report YALEU/DCS/RR777, </type> <institution> Yale University, Department of Computer Science, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: either a language includes a large repertoire of common datatypes and their manipulation functions as part of its definition as in Common Lisp [SJ90], or these objects are defined separately in a standard prelude or in system and user libraries as in the case of Standard ML [MT91, MTH90], Haskell <ref> [HWe90] </ref>, or C [Pla92]. The 15 first approach sometimes leads to language definitions that may be too large to understand, implement and reason about. The second approach usually leads to small and simple language kernels that may be used to "implement" high-level datatypes and their associated functions as independent libraries. <p> Likewise, 4 We follow the terminology of [Gup90, WB89] where the usual Hindley/Milner type of a function is extended with predicates to model overloaded identifiers. In Haskell <ref> [HWe90] </ref> these are known as contexts. The predicate name trec? in our scheme stands for type-reconstructible?. 125 a predicate (trec? t ) appearing at a function application site is transformed into a type-hint encoding t that is passed as an explicit argument at that application site. <p> Each group of mutually recursive bindings is type-checked within a type environment that assigns polymorphic type schemes to the identifiers bound in previous groups and monomorphic types to the identifiers bound within the same group. This transformation maximizes Hindley/Milner polymorphism for an unordered sequence of bindings <ref> [Gup90, HWe90] </ref>. 2 This property ensures that each type-variable instantiation may be treated as an independent parameter to be inserted at that site during translation, although it may introduce some subtle typing discrepancies as discussed in Section 7.2.4. 136 7.2.2 Type Inference The type system shown in Figure 7.2 may be <p> The *T architecture extends a basic RISC instruction set with low-overhead, user-mode communication and synchronization primitives. The details of the architecture may be found elsewhere [Bec92]. In this section, we briefly summarize some of the 5 Readers familiar with Haskell's type classes <ref> [HWe90, WB89] </ref> would immediately recognize that in Haskell, we can accommodate all variations of type reconstruction and its applications by declaring a universal class trec that provides type encodings, mark functions, print functions etc. as independent methods. 166 design features and the terminology of the *T architecture that are relevant to
Reference: [JG91] <author> Pierre Jouvelot and David K. Gifford. </author> <title> Algebraic Reconstruction of Types and Effects. </title> <booktitle> In Proceedings of the 1991 ACM Conference on Principles of Programming Languages, </booktitle> <pages> pages 303-310. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> At least two effect-based systems [TJ92, Wri92] propose such inference mechanisms based on structural unification [Rob65]. The effect system of FX-91 [GJSO91] uses the more complex algebraic unification <ref> [JG91] </ref> which permits unification modulo algebraic identities such as associativity and commutativity. This provides more expressive power to the inference system, albeit at the cost of simplicity and efficiency. Here, we will only discuss the inference system based on standard structural unification.
Reference: [Joh85] <author> Thomas Johnsson. </author> <title> Lambda lifting: Transforming programs to recursive equations. </title> <booktitle> In Springer-Verlag LNCS 201 (Proc. Functional Programming Languages and Computer Architecture, </booktitle> <address> Nancy, France), </address> <month> September </month> <year> 1985. </year>
Reference-contexts: Therefore, the function definition site or the partial application site that creates a closure is not guaranteed to be accessible when that closure is used in further computation. As shown in Figure 6.4, such application sites are termed as 3 Lambda-lifting transformation <ref> [Joh85] </ref> may be used to lift nested functions with free identifiers into top-level super-combinators that refer to only top-level identifiers. But, this transformation restricts the type polymor-phism of free identifiers and does nothing to change a higher-order program into a first-order program.
Reference: [JW75] <author> Kathleen Jensen and Niklaus Wirth. </author> <title> PASCAL User Manual and Report. </title> <publisher> Springer-Verlag, </publisher> <year> 1975. </year>
Reference-contexts: On the other hand, it provides a tool 6 This is also true in Pascal and Fortran even though Pascal allows internal function declarations <ref> [JW75] </ref>. This is because in all these languages functions are never passed outside the scope of their definitions. 100 for the end-user to design arbitrary new functional data-structures more efficiently using im-perative kernel constructs and then safely close them (e.g., histogram in Example 2.16 and polar2rect in Example 4.4).
Reference: [KR88] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Pren-tice Hall, </publisher> <address> second edition, </address> <year> 1988. </year>
Reference-contexts: In order for such kernel implementations to be sound and transparent to the end-user, a proper data and type abstraction mechanism must be provided in the kernel language. Otherwise, the semantic correctness of the implementation may be in doubt. An example of this situation is the C language <ref> [KR88] </ref> which offers complete flexibility of a low-level kernel language but lacks a tight abstraction mechanism, leading sometimes to subtle errors in user programs. <p> It is clear that in order to make any kind of guarantees based on the type system, we must have a strongly-typed language. C is not strongly-typed because it allows unrestricted type conversion among object at the discretion of the user via type-casting <ref> [KR88] </ref>. Using this facility the user may convert pointers to closable objects into non-pointer datatypes and vice-versa, thereby completely throwing off our type analysis. Therefore, no type-casting may be allowed in order to ensure sound, verifiable functional encapsulation.
Reference: [LAB + 81] <author> Barbara Liskov, Russell Atkinson, Toby Bloom, Eliot Moss, J. Craig Schaffert, Robert Scheifler, and Alan Snyder. </author> <title> CLU Reference Manual, </title> <booktitle> volume 114 of Lecture Note in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Leroy showed in [Ler93] that the naive Hindley/Milner typing rules are sound with respect to polymorphism-by-name semantics for imperative references and continuations. This approach is used in languages like Quest [Car89] and to a limited extent in CLU <ref> [LAB + 81] </ref> where explicit type parameters are used to abstract and instantiate polymorphic objects. Unfortunately, suspension and re-evaluation of polymorphic objects destroys their sharing characteristics which are very important in the dynamic semantics of the Id language.
Reference: [Ler92] <author> Xavier Leroy. </author> <title> Polymorphic Typing of an Algorithmic Language. </title> <institution> Rapports de Recherche 1778, INRIA, Rocquencourt, France, </institution> <month> October </month> <year> 1992. </year> <title> English translation of the author's Ph.D. </title> <note> thesis originally in French. </note>
Reference-contexts: mechanics of the proposed type system and its extensions, possibly with a view towards implementing it, should look at the semantic machinery described in Sections 3.1 20 and 3.2 of Chapter 3, the extensions discussed in Chapter 4, as well as the type inference ma-chinery described in Chapter 3 of <ref> [Ler92] </ref>. Of course, theoretical enthusiasts may want to go through all the detailed proofs provided in Chapter 3. <p> We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> Since our main task is to provide an encapsulation mechanism for imperative program fragments, we prefer to extend an existing imperative type system that meets our needs rather than design a new one. We have chosen the Closure Typing system proposed by Xavier Leroy in this thesis <ref> [Ler92] </ref> as a convenient starting point for our encapsulation extensions. We motivate this choice in Section 2.2.7. In Section 2.3, we informally describe the meaning and the use of the close construct via examples and discuss issues of type-safety, non-mutability, efficiency, parallelism, and memory synchronization in their context. <p> This was possible only because we correctly kept track of the type t 0 of the free variable x in the closure type of the body of the function K. Type Soundness and Type Inference Mechanism Leroy developed this idea in his thesis <ref> [Ler92] </ref> showing the soundness of a type system with closure types with respect to the dynamic operational semantics of a ML-like language with higher-order functions. He also showed a type inference algorithm based on this type system that is sound and infers principal types and closure types. <p> The type inference mechanism then computes the usual Hindley/Milner types for all objects while accumulating a set of closure types for every function using simple structural unification. The interested readers may refer to <ref> [Ler92] </ref> for details. Analysis of the Closure Typing System Leroy's syntactic system also succeeds in giving the same polymorphic type to imp map and fn map functions just like the effect-based systems with effect masking. In his thesis [Ler92], 36 Leroy makes some interesting comparisons of the expressive power of the <p> The interested readers may refer to <ref> [Ler92] </ref> for details. Analysis of the Closure Typing System Leroy's syntactic system also succeeds in giving the same polymorphic type to imp map and fn map functions just like the effect-based systems with effect masking. In his thesis [Ler92], 36 Leroy makes some interesting comparisons of the expressive power of the various systems we have seen so far. His system turns out to be incomparable to the effect-based systems in power. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns <p> In that case, only the latter class is a candidate for potential type-safety violation, the functions that only read from a mutable object may be allowed to close those objects. 2.5 Summary To summarize, we have informally shown above how to extend a state of the art imperative type system <ref> [Ler92] </ref> with a type abstraction mechanism that can be used to convert imperative objects into functional objects in a type-safe and transparent manner without the loss of storage efficiency or parallelism. Specifically, we have proposed a new type-domain construct called close that controls this type abstraction as a program encapsulator. <p> In Chapter 4, we will extend this system to handle more general data-structures such as arrays and algebraic types. Our type system is a direct extension of the Closure Typing system presented in Chapter 3 of Xavier Leroy's Ph.D. thesis <ref> [Ler92] </ref>. We present the static and the dynamic semantics of our kernel language and show a correspondence between the two in the form of a soundness theorem (Theorem 3.16). This is our main result. It gives us the guarantee that well-typed terms do not run into run-time type-errors. <p> Finally, we use the same type inference algorithm as described in <ref> [Ler92] </ref> that infers the correct and most general type of every expression in the program. As far as possible, we have kept the same mathematical notation as used in [Ler92]. Throughout this thesis, all symbols appearing in typewriter font are taken verbatim. They denote syntactic entities that stand for themselves. <p> Finally, we use the same type inference algorithm as described in <ref> [Ler92] </ref> that infers the correct and most general type of every expression in the program. As far as possible, we have kept the same mathematical notation as used in [Ler92]. Throughout this thesis, all symbols appearing in typewriter font are taken verbatim. They denote syntactic entities that stand for themselves. Symbols appearing in small capitals denote classes of objects. <p> Furthermore, the values present at these locations are the same as those in the store s 1 . Thus, the result follows from induction hypothesis. 2 3.2 A Closure Typing System Now we will describe our extension to Xavier Leroy's closure typing system <ref> [Ler92] </ref>. 3.2.1 Type Syntax The type grammar is defined below: 61 type variables: ff; fi ::= t regular type variable j u closure extension variable j r region variable types: t ::= t regular type variable j base type j t 1 hi! t 2 function type j t 1 ; <p> As a consequence, S j= v : 8ff 1 : : : ff m :t . Proof: by structural induction over v. Only the case for a closed location is different from <ref> [Ler92] </ref>, but we show all cases for the sake of completeness. Case 1: v is c | By definition, S j= c : typeof (c) and therefore we must have typeof (c) t using the hypothesis S j= c : t . <p> We argue by case analysis on a and hence on the last rule used in the typing derivation. Again, only the case for the close rule is different from <ref> [Ler92] </ref>, but we show all cases. Case 1: Constants | The typing rule is: typeof (c) t E ` c : t The only possible evaluation is e ` c=s ) c=s. <p> This algorithm is a direct extension of the one described in Leroy's thesis <ref> [Ler92] </ref> to region variables. We only need to ensure that region variables are allowed to be unified only with other region variables and never with the null region (*). This guarantees that we do not accidentally "close" a mutable reference type by unification. <p> This guarantees that we do not accidentally "close" a mutable reference type by unification. That operation should only be performed explicitly using the close construct. We will not discuss the details of the inference algorithm here since it is a trivial extension of that in <ref> [Ler92] </ref>. We only state the following propositions that characterize the soundness and the completeness of the inference algorithm with respect to the type system described in Section 3.2: Proposition 3.19 (Soundness of Type Inference) Let a be an expression and E be a type environment. <p> The proof of these proposition follows exactly as described in <ref> [Ler92] </ref>. 79 80 Chapter 4 Closing Data-Structures So far, we have shown how to close a single mutable reference location. In this chapter, we show how to extend the use of the close construct to complex, multi-level data-structures involving tuples, arrays, and general algebraic datatypes.
Reference: [Ler93] <author> Xavier Leroy. </author> <title> Polymorphism by name for references and continuations. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages. </booktitle> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: In this case, the conventional data abstraction mechanism would be sufficient to hide the imperative implementation of a functional datatype. In this alternate semantics, called polymorphism-by-name <ref> [Ler93] </ref>, the evaluation of a polymorphic object is suspended and each type instantiation re-evaluates the suspension in the current context to produce a fresh instance. <p> In contrast, the usual ML-like polymorphism is called polymorphism-by-value where polymorphic objects are evaluated only once and the resulting value is shared among all its instances. Leroy showed in <ref> [Ler93] </ref> that the naive Hindley/Milner typing rules are sound with respect to polymorphism-by-name semantics for imperative references and continuations. This approach is used in languages like Quest [Car89] and to a limited extent in CLU [LAB + 81] where explicit type parameters are used to abstract and instantiate polymorphic objects.
Reference: [LG88] <author> John M. Lucassen and David K. Gifford. </author> <title> Polymorphic Effect Systems. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming languages, </booktitle> <address> San Diego, California, </address> <pages> pages 47-57, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> systems where this information is tracked independently, leading to a much more complete and cleaner characterization of imperative objects. 2.2.5 Effect Systems Effect systems are a broad class of polymorphic typing systems that use static type-checking and inference techniques to model the dynamic behavior of programs written in imperative languages <ref> [Luc87, LG88, TJ92, Wri92] </ref>. Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization [LG88]. One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. <p> Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization <ref> [LG88] </ref>. One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. <p> Region Analysis and Effect Masking Some effect systems also carry out a region analysis of memory allocation and sharing <ref> [LG88, TJ92] </ref>. The static description of an expression also summarizes a conservative approximation of the memory regions (locations) manipulated within the expression, in addition to its type and effects.
Reference: [LPJ94] <author> John Launchbury and Simon L. Peyton Jones. </author> <title> Lazy Functional State Threads. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <address> Orlando, Florida, USA. </address> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: In a purely functional setting, some compilers would perform extensive destructive update analysis, linearity analysis, use linear type systems, abstract datatypes or monadic language constructs <ref> [Blo89, Wad90, Hud92, PJW93, LPJ94] </ref> to determine that the histogram may be safely single-threaded through the computation and hence modified in place.
Reference: [Luc87] <author> John M. Lucassen. </author> <title> Types and Effects Towards the Integration of Functional and Imperative Programming. </title> <type> PhD thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cam-bridge, MA 02139, </address> <month> August </month> <year> 1987. </year> <note> Available as Technical Report MIT/LCS/TR-408. </note>
Reference-contexts: systems where this information is tracked independently, leading to a much more complete and cleaner characterization of imperative objects. 2.2.5 Effect Systems Effect systems are a broad class of polymorphic typing systems that use static type-checking and inference techniques to model the dynamic behavior of programs written in imperative languages <ref> [Luc87, LG88, TJ92, Wri92] </ref>. Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization [LG88]. One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism.
Reference: [LW91] <author> Xavier Leroy and Pierre Weis. </author> <title> Polymorphic type inference and assignment. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 291-302. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1991. </year>
Reference-contexts: We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> Instead of approximating the dynamic behavior of the program, Leroy and Weis <ref> [LW91] </ref> introduced a more direct, syntactic way of identifying and safely typing mutable objects using an extension of the Hindley/Milner type system. We discuss their technique below. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns
Reference: [Mai90] <author> Harry G. Mairson. </author> <title> Deciding ML Typability is Complete for Deterministic Exponential Time. </title> <booktitle> In Proceedings of the 17th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 382-401, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Similarly, the cost of unification is proportional to the size of the function's instantiated type. Although it is possible to write functions whose Hindley/Milner types are exponentially large compared to the size of the function itself <ref> [Mai90] </ref>, such cases are rare. Typically, functions possess small type signatures that can be efficiently manipulated using graphical representations. Non-conserving functions are rare as well and run-time type instantiations of non-conserving type-variables are also small.
Reference: [Mil78] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year> <month> 184 </month>
Reference-contexts: Id is a high-level, strongly-typed language and it uses the Hindley/Milner polymorphic type system and its automatic type inference mechanism <ref> [Mil78, DM82] </ref> at its functional core. Id also offers imperative data-structures (I-structures [ANP89] and M-structures [BNA91]) that cater to imperative styles of programming. Id is a layered language by design (see Figure 1.1). <p> Type Declaration Type inference is a convenient mechanism that frees the user from the task of declaring every identifier in the program with an appropriate type. Most modern programming languages such as Standard ML, Haskell, and Id use a systematic type inference system <ref> [Mil78] </ref>. Even languages favoring type declaration such as Pascal and C perform some ad hoctype inference in order to support automatic type coercions. <p> We have modified the usual Hindley/Milner typing rules <ref> [Mil78] </ref> to compute and propagate additional type-hint information. <p> site during translation, although it may introduce some subtle typing discrepancies as discussed in Section 7.2.4. 136 7.2.2 Type Inference The type system shown in Figure 7.2 may be directly used as a basis for automatically inferring augmented Hindley/Milner types along the lines of the standard Hindley/Milner type inference algorithm <ref> [Mil78] </ref>. The type-hint sets are considered to be ordered and of fixed size, and may be treated as part of the type signature of a function. In particular, note that a non-empty set can never be unified with an empty set.
Reference: [MT91] <author> Robin Milner and Mads Tofte. </author> <title> Commentary on Standard ML. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: following two categories: either a language includes a large repertoire of common datatypes and their manipulation functions as part of its definition as in Common Lisp [SJ90], or these objects are defined separately in a standard prelude or in system and user libraries as in the case of Standard ML <ref> [MT91, MTH90] </ref>, Haskell [HWe90], or C [Pla92]. The 15 first approach sometimes leads to language definitions that may be too large to understand, implement and reason about. <p> Then, we will describe two more recent type systems that are more complex but are much more powerful in dealing with higher-order functions. 2.2.2 Type System of Standard ML In Standard ML <ref> [MT91, MTH90] </ref>, type variables are syntactically classified into two separate categories: imperative type variables (u 0 ; u 1 ; : : :) that may occur in the type of a mutable object at some stage of type inference and therefore implicitly model the abstract mutable store, and applicative type variables
Reference: [MTH90] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: following two categories: either a language includes a large repertoire of common datatypes and their manipulation functions as part of its definition as in Common Lisp [SJ90], or these objects are defined separately in a standard prelude or in system and user libraries as in the case of Standard ML <ref> [MT91, MTH90] </ref>, Haskell [HWe90], or C [Pla92]. The 15 first approach sometimes leads to language definitions that may be too large to understand, implement and reason about. <p> Then, we will describe two more recent type systems that are more complex but are much more powerful in dealing with higher-order functions. 2.2.2 Type System of Standard ML In Standard ML <ref> [MT91, MTH90] </ref>, type variables are syntactically classified into two separate categories: imperative type variables (u 0 ; u 1 ; : : :) that may occur in the type of a mutable object at some stage of type inference and therefore implicitly model the abstract mutable store, and applicative type variables <p> As an example, the type of the application (mkref identity) (Example 2.3) is shown below under various type systems: 10 10 Standard ML notation <ref> [MTH90] </ref> uses postfix type constructors in type expressions, as in (u ! u) ref. We will follow that notation in Chapter 3 when discussing formal semantics.
Reference: [NAH93] <author> Rishiyur S. Nikhil, Arvind, and James Hicks. </author> <title> pH Language Proposal (Preliminary). Circulated on the pH mailing list, </title> <month> September </month> <year> 1993. </year>
Reference-contexts: Our type system would also combine three different type declarations used for M-structure, I-structure, and functional data objects into a single declaration as discussed in Section 4.2.4. Currently, the Id language is undergoing major revisions and in its next incarnation as pH <ref> [NAH93] </ref> we hope to include some of the ideas embodied in this thesis. 4.5.3 Future Work As mentioned above, the obvious first task for us is to implement this type system fully and study its usefulness not only in terms of the semantic cleanliness but also its implementation efficiency and ease
Reference: [Nik91] <author> Rishiyur S. Nikhil. </author> <title> Id Language Reference Manual Version 90.1. </title> <type> Technical Report CSG Memo 284-2, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> July 15 </month> <year> 1991. </year>
Reference-contexts: This research is geared towards such an integrated approach to managing type information in the context of the parallel programming language Id <ref> [Nik91] </ref>, developed at the Computation Structures Group, Laboratory for Computer Science, MIT. Id is a high-level, strongly-typed language and it uses the Hindley/Milner polymorphic type system and its automatic type inference mechanism [Mil78, DM82] at its functional core. <p> They also increase the complexity of the compiler and the language it must manipulate. Moreover, this solution does not apply to user-defined functional abstractions in addition to those already present in the language. 1 All our examples use the Id language syntax <ref> [Nik91] </ref>. We will provide brief explanations as necessary. <p> The primitive operations of allocation, dereference, and assignment extend naturally to constructor disjuncts and their embedded mutable and non-mutable fields. The reader is referred to <ref> [Nik91] </ref> for details of the exact syntax used in Id. The dynamic semantics of these operations is given by a family of allocation, dereference, and assignment rules on the lines of those shown for reference cells in Chapter 3. <p> 1 Example 6.1: def enlist x t 0 = x:nil; def map f nil = nil | map f (y:ys) (list t 1 ) = (f y t 1 ):(map f ys); map enlist (1:2:nil) (list int) ; 1 All the examples in this chapter use the Id language syntax <ref> [Nik91] </ref>. <p> The Id source language supports special syntactic constructs such as list and array comprehensions, complex pattern matching, and nested function and type declarations <ref> [Nik91] </ref>. <p> In order to make a reasonable performance comparison, we have implemented all the three schemes for the same source language, compiler, and the target architecture. Our source language is Id, which is a polymorphic, strongly-typed, implicitly parallel programming language <ref> [Nik91] </ref>. We are compiling Id for the *T multiprocessor architecture [NPA92, PBGB93] and executing it on an emulator for that machine. We have chosen a very simple "mark-and-sweep" garbage collection algorithm so that the 157 cost of object identification can be clearly identified during the mark phase.
Reference: [Nik94] <author> Rishiyur S. Nikhil. </author> <title> Cid : A Parallel, "Shared-memory" C for Distributed-memory Machines. </title> <booktitle> In Proceedings of the 7th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, NY. </address> <institution> Cornell Theory Center, Cornell University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: This property leads to obvious compile-time optimizations such as common sub-expression elimination, code-hoisting, and memory-fetch elimination that attempt to reduce the number of copies. This also permits unlimited caching of such functional data in a parallel machine without any risk of write-invalidation. In parallel systems using software-controlled shared-memory protocols <ref> [Nik94, FLR + 94] </ref> this may directly translates into cheaper protocols for object access and migration.
Reference: [NPA92] <author> Rishiyur S. Nikhil, Gregory M. Papadopoulos, and Arvind. </author> <title> *T: A Multithreaded Massively Parallel Architecture. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <address> Queensland, Australia. </address> <publisher> ACM Press, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: In order to make a reasonable performance comparison, we have implemented all the three schemes for the same source language, compiler, and the target architecture. Our source language is Id, which is a polymorphic, strongly-typed, implicitly parallel programming language [Nik91]. We are compiling Id for the *T multiprocessor architecture <ref> [NPA92, PBGB93] </ref> and executing it on an emulator for that machine. We have chosen a very simple "mark-and-sweep" garbage collection algorithm so that the 157 cost of object identification can be clearly identified during the mark phase. <p> This would clearly reduce the overhead of using higher-order marking functions. 8.5 *T Implementation *T is a parallel, distributed-memory machine with a high performance interconnection network <ref> [NPA92, PBGB93] </ref>. The *T architecture extends a basic RISC instruction set with low-overhead, user-mode communication and synchronization primitives. The details of the architecture may be found elsewhere [Bec92].
Reference: [OJ91] <author> James William O'Toole Jr. </author> <title> Type Abstraction Rules for References: A comparison of four which have achieved notoriety. </title> <type> Technical Memo MIT/LCS/TM-390, </type> <institution> Laboratory for Computer Science, MIT, 545 Technology Square, </institution> <address> Cambridge, Massachusetts 02139, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Many type systems in the literature follow this general framework [Dam85, Tof90, LG88, JG91, Wri92, TJ92]. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in <ref> [OJ91] </ref>. First, we will briefly describe two such systems that are simple extensions of the original Hindley/Milner type system and have been successfully used in practical programming languages.
Reference: [PBGB93] <author> G. M. Papadopoulos, G. A. Boughton, R. Greiner, and M. J. Beckerle. </author> <title> *T: Integrated building blocks for parallel computing. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <year> 1993. </year>
Reference-contexts: In order to make a reasonable performance comparison, we have implemented all the three schemes for the same source language, compiler, and the target architecture. Our source language is Id, which is a polymorphic, strongly-typed, implicitly parallel programming language [Nik91]. We are compiling Id for the *T multiprocessor architecture <ref> [NPA92, PBGB93] </ref> and executing it on an emulator for that machine. We have chosen a very simple "mark-and-sweep" garbage collection algorithm so that the 157 cost of object identification can be clearly identified during the mark phase. <p> This would clearly reduce the overhead of using higher-order marking functions. 8.5 *T Implementation *T is a parallel, distributed-memory machine with a high performance interconnection network <ref> [NPA92, PBGB93] </ref>. The *T architecture extends a basic RISC instruction set with low-overhead, user-mode communication and synchronization primitives. The details of the architecture may be found elsewhere [Bec92].
Reference: [PJ92] <author> Simon L. Peyton Jones. </author> <title> Implementing lazy functional languages on stock hardware: </title> <journal> the Spineless Tagless G-machine. Journal of Functional Programming, </journal> <volume> 2(2) </volume> <pages> 127-202, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Intelligent compilers can use this information while performing important optimizations such as boxing/unboxing of data, code specialization, and register allocation. 16 Unfortunately, very few compilers actually propagate the full source type information all the way to the back-end, the Glasgow Haskell compiler <ref> [PJ92] </ref> being a notable exception. In a layered language, this task is considerably simplified since only a small number of kernel language constructs are involved within the later phases of the compiler. <p> Maintaining tags on every object is the only way to ensure dynamic type consistency. Similarly, in the implementation of lazy languages such as Haskell <ref> [PJ92] </ref>, all objects are boxed into closures to ensure lazy evaluation semantics. These closures can easily identify themselves and the object they contain via their code pointers. Independent type reconstruction does not provide any advantage in this situation.
Reference: [PJW92] <editor> Simon L. Peyton Jones and Philip Wadler. </editor> <title> A static semantics for Haskell, </title> <month> February </month> <year> 1992. </year>
Reference-contexts: It is interesting to note that the propagation of type information from closure creation sites to their final application sites for non-type-conserving functions may be formulated as an overloading resolution problem which may then be handled using well-known techniques in the literature <ref> [Gup90, PJW92, WB89] </ref>. These techniques systematically translate overloading into parametric polymorphism by replacing unresolved instances of overloaded identifiers in a function with additional parameters that are supplied at its application site. In our scheme, these parameters are the explicit type-hints that are used by the type reconstruction algorithm.
Reference: [PJW93] <editor> Simon L. Peyton Jones and Philip Wadler. </editor> <title> Imperative Functional Programming. </title> <booktitle> In Proceedings of the 20th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Charleston, South Carolina, USA, </address> <pages> pages 71-84. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: In a purely functional setting, some compilers would perform extensive destructive update analysis, linearity analysis, use linear type systems, abstract datatypes or monadic language constructs <ref> [Blo89, Wad90, Hud92, PJW93, LPJ94] </ref> to determine that the histogram may be safely single-threaded through the computation and hence modified in place.
Reference: [Pla92] <author> P.J. Plauger. </author> <title> The Standard C Library. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey 07632, </address> <year> 1992. </year>
Reference-contexts: includes a large repertoire of common datatypes and their manipulation functions as part of its definition as in Common Lisp [SJ90], or these objects are defined separately in a standard prelude or in system and user libraries as in the case of Standard ML [MT91, MTH90], Haskell [HWe90], or C <ref> [Pla92] </ref>. The 15 first approach sometimes leads to language definitions that may be too large to understand, implement and reason about. The second approach usually leads to small and simple language kernels that may be used to "implement" high-level datatypes and their associated functions as independent libraries.
Reference: [Plo81] <author> G. D. Plotkin. </author> <title> A Structural Approach to Operational Semantics. </title> <type> Technical Report DAIMI FN-19, </type> <institution> Computer Science Department, Aarhus University, Aarhus, Den-mark, </institution> <month> September </month> <year> 1981. </year>
Reference-contexts: Evaluation judgments are established using a system of axioms and inference rules. This technique is also known as "Structured Operational Semantics" (SOS) <ref> [Plo81] </ref>.
Reference: [Rey74] <author> J. C. Reynolds. </author> <title> Towards a Theory of Type Structure. </title> <booktitle> In Paris Colloquium on Programming, volume 19 of Lecture Notes in Computer Science, </booktitle> <pages> pages 408-425. </pages> <publisher> Springer-Verlag, </publisher> <year> 1974. </year> <month> 185 </month>
Reference-contexts: Another interesting scheme has been proposed by Tolmach [Tol94] where type instantiation and propagation is made explicit in the program by converting it into an intermediate form based on the second-order -calculus <ref> [Rey74, HM93] </ref>. Under this transformation, every polymorphic object is parameterized with explicit type parameters for each of its polymorphic type-variables that are instantiated at the time of application to actual type arguments.
Reference: [Rob65] <author> J. A. Robinson. </author> <title> A Machine-Oriented Logic Based on the Resolution Principle. </title> <journal> Journal of the ACM, </journal> <volume> 12(1) </volume> <pages> 23-41, </pages> <year> 1965. </year>
Reference-contexts: At least two effect-based systems [TJ92, Wri92] propose such inference mechanisms based on structural unification <ref> [Rob65] </ref>. The effect system of FX-91 [GJSO91] uses the more complex algebraic unification [JG91] which permits unification modulo algebraic identities such as associativity and commutativity. This provides more expressive power to the inference system, albeit at the cost of simplicity and efficiency. <p> The type-hint sets are considered to be ordered and of fixed size, and may be treated as part of the type signature of a function. In particular, note that a non-empty set can never be unified with an empty set. Therefore, the usual structural term unification algorithm <ref> [Rob65] </ref> would suffice for matching types. 3 The type inference algorithm would be similar to the infer algorithm cited in Section 3.4 with minor modifications. We need to do some book-keeping in order to collect and propagate type-hint instantiations from within expressions and process them at the enclosing function definition.
Reference: [SJ90] <author> Guy L. Steele Jr. </author> <title> Common Lisp: The Language. </title> <note> Digital Press, second edition, </note> <year> 1990. </year>
Reference-contexts: Most programming language designs fall into one of the following two categories: either a language includes a large repertoire of common datatypes and their manipulation functions as part of its definition as in Common Lisp <ref> [SJ90] </ref>, or these objects are defined separately in a standard prelude or in system and user libraries as in the case of Standard ML [MT91, MTH90], Haskell [HWe90], or C [Pla92].
Reference: [TJ92] <author> Jean-Pierre Talpin and Pierre Jouvelot. </author> <title> The Type and Effect Discipline. </title> <booktitle> In Proceedings of the ACM Symposium on Logic in Computer Science, </booktitle> <pages> pages 162-173. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> systems where this information is tracked independently, leading to a much more complete and cleaner characterization of imperative objects. 2.2.5 Effect Systems Effect systems are a broad class of polymorphic typing systems that use static type-checking and inference techniques to model the dynamic behavior of programs written in imperative languages <ref> [Luc87, LG88, TJ92, Wri92] </ref>. Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization [LG88]. One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. <p> One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. More recently, automatic type and effect inference techniques have been developed <ref> [TJ92, Wri92] </ref> that use the effect propagation mechanism to infer types that model polymorphic imperative objects more accurately than the systems given above. As we will see shortly, such type and effect systems can be viewed as a logical extension of the type systems described above. <p> Principal Types and Minimal Effects In order to compute the type and the effect of every expression automatically and efficiently, one must show that the system admits unique principal types and effects for expressions and that they are computable using an efficient inference algorithm. At least two effect-based systems <ref> [TJ92, Wri92] </ref> propose such inference mechanisms based on structural unification [Rob65]. The effect system of FX-91 [GJSO91] uses the more complex algebraic unification [JG91] which permits unification modulo algebraic identities such as associativity and commutativity. <p> The function h represents an interesting case. Depending on the desired semantic interpretation of effects, the least effect satisfying this constraint may be taken to be infinite and such expressions may be classified as ill-formed (system <ref> [TJ92] </ref>), or this constraint may be simplified to ff 0 w ff 0 gg which yields the null effect as the minimal solution (system [Wri92]). Region Analysis and Effect Masking Some effect systems also carry out a region analysis of memory allocation and sharing [LG88, TJ92]. <p> Region Analysis and Effect Masking Some effect systems also carry out a region analysis of memory allocation and sharing <ref> [LG88, TJ92] </ref>. The static description of an expression also summarizes a conservative approximation of the memory regions (locations) manipulated within the expression, in addition to its type and effects. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns <p> This is expressed in the following strategy: Closing Strategy 3 Region variables occurring within the closure type of a function are never allowed to be closed. In a more expressive effect-based system <ref> [TJ92] </ref>, one might be able to separate functions that only read from a mutable object from those that both read and write the object.
Reference: [Tof90] <author> Mads Tofte. </author> <title> Type Inference for Polymorphic References. </title> <journal> Information and Computation, </journal> <volume> 89 </volume> <pages> 1-34, </pages> <year> 1990. </year>
Reference-contexts: Therefore, returning an assignable I-structure from make vector is not appropriate. Furthermore, in the Hindley/Milner type system, imperative objects are allowed only a restricted form of polymorphism to ensure type-safety <ref> [Tof90] </ref>. Thus, the functional arrays implemented using I-structures in this manner would have restricted polymorphism, which reduces the utility of such library implementations. <p> We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> The resulting type system is sound <ref> [Tof90] </ref>, easy to implement, and correctly rejects Example 2.3 as a type-error. To see this, note that under this scheme, storage allocating functions such as mkref always contain imperative type variables in their type-schemes because they allocate and return mutable memory locations. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns
Reference: [Tol94] <author> Andrew Tolmach. </author> <title> Tag-free Garbage Collection Using Explicit Type Parameters. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 1-11. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Some techniques, such as conservative garbage collection [Bar88, BW88] and compiler-directed storage reclamation [HJ92, Hic93], do not use any run-time type information. While, garbage collection based on type reconstruction [App89, Gol91, GG92] or explicit type propagation <ref> [Tol94] </ref> use source type information for identifying and traversing live heap objects. <p> This scheme was both cumbersome and costly. On the other hand, our scheme of full type reconstruction allows the garbage collector to traverse the whole object the very first time without using any additional data-structures. Another interesting scheme has been proposed by Tolmach <ref> [Tol94] </ref> where type instantiation and propagation is made explicit in the program by converting it into an intermediate form based on the second-order -calculus [Rey74, HM93].
Reference: [Tra86] <author> Kenneth R. Traub. </author> <title> A Compiler for the MIT Tagged-Token Dataflow Architecture. </title> <type> Master's thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <month> August </month> <year> 1986. </year> <note> Available as Technical Report MIT/LCS/TR-370. </note>
Reference-contexts: A preliminary version of the type reconstruction scheme described in this chapter was implemented during the fall of 1992 in the context of the Id source debugger [Car93] for the Monsoon dataflow architecture and was reported in [AC93]. The Id compiler <ref> [Tra86] </ref> was modified to perform the type analysis and hint generation for every function within the user program as shown in Section 6.3. A simple Id datatype encoding was used for type-hints as shown in Section 6.3.3. The compiler also generated the type-map and the hint-map for every function. <p> Although, we will use the operational machinery described in Chapter 3 while showing the correctness of our type reconstruction algorithm. Kernel Id is a more realistic abstraction of actual intermediate form used in the Id compiler <ref> [AA91, Tra86] </ref> than the tiny expression language used in Chapter 3. The Id source language supports special syntactic constructs such as list and array comprehensions, complex pattern matching, and nested function and type declarations [Nik91]. <p> [Binding; ] fl in SE g Binding ::= Identifier = E Declaration ::= Binding j Type-Decl Type-Decl ::= type T ff 1 ff n = C 1 t 11 t 1k 1 j Program ::= [Declaration; ] fl E ses and transformations such as comprehension-desugaring, scope-analysis, type-checking, and pattern-matching compilation <ref> [AA91, Gup90, Tra86] </ref>. These transformations result in a Kernel Id program where every sub-expression has a unique name and a well-defined Hindley/Milner type, so that all internal type declarations can be lifted to the top-level.
Reference: [TT93] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> A Theory of Stack Allocation in Polymorphi-cally Typed Languages. </title> <type> Technical Report 93/15, </type> <institution> Department of Computer Science (DIKU), Copenhagen University, </institution> <year> 1993. </year>
Reference-contexts: This is because no references to that object may escape this scope. This information may be used to allocate such objects on stack instead of the heap as shown in <ref> [TT93] </ref>, or insert additional code at compile-time to reclaim that storage automatically on the lines of [HJ92]. 102 Part II Types in Run-time System Design: Type Reconstruction 103 Chapter 5 A Typed Run-time System 5.1 Introduction Traditionally, programming environments of dynamically-typed languages such as Lisp or Small-talk maintain type information in
Reference: [Tur85] <author> D. A. Turner. Miranda: </author> <title> A non-strict functional language with polymorphic types. </title> <booktitle> In Lecture notes in Computer Science, </booktitle> <volume> volume 201. </volume> <publisher> Springer Verlag, </publisher> <month> September </month> <year> 1985. </year>
Reference-contexts: The list comprehension mechanism, first introduced in NPL [Bur77, Dar77] and later adopted in Miranda <ref> [Tur85] </ref> and Haskell, is an example of such a language construct. From a language design standpoint, a powerful type system can be used to enforce the type abstraction desired for kernel language implementations of high-level datatypes in libraries without changing the high-level language definition or modifying the compiler.
Reference: [Wad90] <editor> Philip Wadler. </editor> <booktitle> Linear types can change the world! In Proceedings of the Working Conference on Programming Concepts and Methods, Israel, </booktitle> <pages> pages 385-407. </pages> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: In a purely functional setting, some compilers would perform extensive destructive update analysis, linearity analysis, use linear type systems, abstract datatypes or monadic language constructs <ref> [Blo89, Wad90, Hud92, PJW93, LPJ94] </ref> to determine that the histogram may be safely single-threaded through the computation and hence modified in place.
Reference: [WB89] <author> Philip Wadler and Stephen Blott. </author> <title> How to make ad-hoc polymorphism less ad hoc. </title> <booktitle> In Proceedings of the 16th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Austin, Texas, </address> <pages> pages 60-76, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: This frees up the system from the responsibility of checking for type consistency at run-time. Some modern languages like Haskell also provide systematic mechanisms to resolve overloading of operators and selection of methods at compile-time based on the static types of their arguments <ref> [WB89] </ref>. Therefore, static typing offers many of the advantages of dynamic availability of type information without actually carrying that information at run-time. Moreover, all the static type information may be saved and used in optimizations during the compilation phase itself or in other run-time 106 applications during program execution. <p> It is interesting to note that the propagation of type information from closure creation sites to their final application sites for non-type-conserving functions may be formulated as an overloading resolution problem which may then be handled using well-known techniques in the literature <ref> [Gup90, PJW92, WB89] </ref>. These techniques systematically translate overloading into parametric polymorphism by replacing unresolved instances of overloaded identifiers in a function with additional parameters that are supplied at its application site. In our scheme, these parameters are the explicit type-hints that are used by the type reconstruction algorithm. <p> Likewise, 4 We follow the terminology of <ref> [Gup90, WB89] </ref> where the usual Hindley/Milner type of a function is extended with predicates to model overloaded identifiers. In Haskell [HWe90] these are known as contexts. <p> The *T architecture extends a basic RISC instruction set with low-overhead, user-mode communication and synchronization primitives. The details of the architecture may be found elsewhere [Bec92]. In this section, we briefly summarize some of the 5 Readers familiar with Haskell's type classes <ref> [HWe90, WB89] </ref> would immediately recognize that in Haskell, we can accommodate all variations of type reconstruction and its applications by declaring a universal class trec that provides type encodings, mark functions, print functions etc. as independent methods. 166 design features and the terminology of the *T architecture that are relevant to
Reference: [Wil92] <author> Paul R. Wilson. </author> <title> Uniprocessor Garbage Collection Techniques. </title> <booktitle> In Proceedings of the International Workshop on Memory Management, </booktitle> <address> St. Malo, France, </address> <pages> pages 1-42. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year> <note> LNCS 637. </note>
Reference-contexts: Pointers may be tagged using one bit to distinguish them from scalars values and objects may be provided with header tags or may be allocated in separate areas of memory to keep track of their size. The reader is referred to a recent such techniques in <ref> [Wil92] </ref>. Unlike source debugging, garbage collection does not require complete source type information per say, but additional type information may be helpful in optimizing the marking of live objects. <p> Usually, it is more convenient to use some automatic mechanism for storage reclamation such as an independent garbage collector that reclaims storage periodically once it is no longer in use. Traditionally, run-time systems geared towards automatic garbage collection use a tagged object representation model <ref> [App90, Wil92] </ref>. This enables the garbage collector to distinguish between scalar objects and pointers to heap objects without any support from the user or the compiler, although the user application has to pay the price of tagging and boxing objects and performing continuous tag maintenance.
Reference: [Wri92] <author> Andrew K. Wright. </author> <title> Typing References by Effect Inference. </title> <booktitle> In Proceedings of the 4th European Symposium on Programming, Rennes, France, </booktitle> <pages> pages 473-491. </pages> <publisher> Springer-Verlag, </publisher> <month> February </month> <year> 1992. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 582. </volume>
Reference-contexts: We present a new language construct called close that achieves this functionality through the type system. The interaction of polymorphism and imperative programming has been the subject of active research in the past decade <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref>. Several 27 type systems have been proposed in the literature spanning a wide range of expressiveness and complexity. We present a brief survey in Section 2.2. <p> This has to be achieved in a flexible but sound manner within and across function and local block boundaries. Many type systems in the literature follow this general framework <ref> [Dam85, Tof90, LG88, JG91, Wri92, TJ92] </ref>. The various systems differ in their notion of a store abstraction and the amount of information propagated across function boundaries. An illustrative comparison of some of these systems is presented in [OJ91]. <p> systems where this information is tracked independently, leading to a much more complete and cleaner characterization of imperative objects. 2.2.5 Effect Systems Effect systems are a broad class of polymorphic typing systems that use static type-checking and inference techniques to model the dynamic behavior of programs written in imperative languages <ref> [Luc87, LG88, TJ92, Wri92] </ref>. Originally, such systems were used to collect and propagate side-effect information across program fragments for compiler optimizations and parallelization [LG88]. One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. <p> One such type and effect system was successfully used in the FX-87 language [GJLS87] which supported explicitly declared type polymorphism. More recently, automatic type and effect inference techniques have been developed <ref> [TJ92, Wri92] </ref> that use the effect propagation mechanism to infer types that model polymorphic imperative objects more accurately than the systems given above. As we will see shortly, such type and effect systems can be viewed as a logical extension of the type systems described above. <p> The effect information propagated and accumulated in this manner may then be used to accurately identify the creation of polymorphic imperative objects and avoid their unsafe generalization. In one of the simpler effect systems proposed by Wright <ref> [Wri92] </ref>, all type variables present in the type of a freshly allocated mutable data-structure are collected as part of the effect of that allocation. The explicit effect computation and propagation mechanism obviates the need to mark such type variables as imperative. <p> Principal Types and Minimal Effects In order to compute the type and the effect of every expression automatically and efficiently, one must show that the system admits unique principal types and effects for expressions and that they are computable using an efficient inference algorithm. At least two effect-based systems <ref> [TJ92, Wri92] </ref> propose such inference mechanisms based on structural unification [Rob65]. The effect system of FX-91 [GJSO91] uses the more complex algebraic unification [JG91] which permits unification modulo algebraic identities such as associativity and commutativity. <p> desired semantic interpretation of effects, the least effect satisfying this constraint may be taken to be infinite and such expressions may be classified as ill-formed (system [TJ92]), or this constraint may be simplified to ff 0 w ff 0 gg which yields the null effect as the minimal solution (system <ref> [Wri92] </ref>). Region Analysis and Effect Masking Some effect systems also carry out a region analysis of memory allocation and sharing [LG88, TJ92]. The static description of an expression also summarizes a conservative approximation of the memory regions (locations) manipulated within the expression, in addition to its type and effects. <p> This is necessary because the indices i and j may be turn out to be the same at run-time, in which case this application would lead to a run-time type-error. All imperative type systems in the literature <ref> [Dam85, Tof90, AM89, LW91, Ler92, TJ92, Wri92] </ref> catch this type-error at compile-time by restricting the polymorphism of imperative objects in one way or another. "Close" as a Type Converter Although the above behavior for make vector is correct, ultimately, we want it to behave like a functional array constructor that returns
Reference: [Wri93] <author> Andrew K. Wright. </author> <title> Polymorphism for Imperative Languages without Imperative Types. </title> <type> Technical Report TR93-200, </type> <institution> Rice University, </institution> <month> February </month> <year> 1993. </year> <month> 186 </month>
Reference-contexts: In another case, Wright experimented with the type system of Standard ML by restricting polymorphism to only certain classes of syntactically recognizable values such as function declarations, constants, and known functional constructors <ref> [Wri93] </ref>. These functional values can be recognized statically and therefore can be generalized and shared safely. Mutable data-structures are always classified as dynamic entities and therefore can never be generalized. <p> A minor problem in using this scheme is that in order to preserve the call-by-value semantics of ML-like programs, the polymorphic objects appearing on the right-hand-side of a let-binding must be restricted to syntactic values, i.e., identifiers, constants, or -expressions. Wright showed <ref> [Wri93] </ref> that this restriction is not too serious in practice. The explicit type parameters used in Tolmach's system are similar in spirit to the explicit type-hints of our type reconstruction scheme, although we add explicit type parameters only for non-conserved type-variables.
References-found: 78

