URL: http://robotics.stanford.edu/users/sahami/papers-dir/LUL.ecml95.ps
Refering-URL: http://robotics.stanford.edu/users/sahami/papers.html
Root-URL: 
Email: Email: sahami@CS.Stanford.EDU  
Title: Learning Classification Rules Using Lattices (Extended Abstract)  
Phone: 1995.  
Author: Mehran Sahami 
Address: Heraklion, Crete, Greece,  Stanford, CA 94305, USA  
Affiliation: Learning,  Computer Science Department, Stanford University,  
Note: In ECML-95: Proceedings of the Eighth European Conference on Machine  
Abstract: This paper presents a novel induction algorithm, Rulearner, which induces classification rules using a Galois lattice as an explicit map through the search space of rules. The Rulearner system is shown to compare favorably with commonly used symbolic learning methods which use heuristics rather than an explicit map to guide their search through the rule space. Furthermore, our learning system is shown to be robust in the presence of noisy data. The Rulearner system is also capable of learning both decision lists and unordered rule sets allowing for comparisons of these different learning paradigms within the same algorithmic framework.
Abstract-found: 1
Intro-found: 1
Reference: [CN, 1989] <author> Clark, P. and Niblett, T. </author> <title> The CN2 Induction Algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 261-83, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Research in rule induction by means of search <ref> [MC, 1969; MI, 1982; CN, 1989] </ref> has been ongoing for some time. While some systems, such as Version Spaces, make direct use of the data to be learned during rule induction, such methods are highly sensitive to noisy data. <p> This allows for the Rulearner system to be used in making direct comparisons between these two learning paradigms within a single algorithmic framework. Several experiments with the Rulearner system are presented comparing it with the commonly used symbolic learning systems C4.5 [QU, 1993] and CN2 <ref> [CN, 1989] </ref>. 2 Lattice Definitions A lattice is defined to be a directed acyclic graph in which any two nodes, u and v, have a unique join (a node "higher" in the graph to which a u and v are connected by minimal length paths) and a unique meet (a node
Reference: [GA, 1987] <author> Ganascia, J.G. CHARADE: </author> <title> A Rule System Learning System. </title> <booktitle> In Proceedings of the Tenth IJCAI, </booktitle> <volume> Volume 1, </volume> <pages> pp. 345-347, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: Methods for automatic noise parameter selection will also be pursued. The interested reader should also be aware of the systems CHARADE <ref> [GA, 1987] </ref> and GRAND [OO, 1988] which also make use of lattices to guide the formation of classification rules. These systems, however, differ from ours in their induction mechanisms, biases, and methods for dealing with noise. Acknowledgments The author thanks Nils Nilsson and Deon Oosthuizen for their thought provoking discussions.
Reference: [MC, 1969] <author> Michalski, </author> <title> R.S. On the Quasi-minimal Solution of the General Covering Problem. </title> <booktitle> In Proceedings of the Fifth International Symposium on Information Processing, </booktitle> <pages> pp. 125-128, </pages> <address> Bled, Yugoslavia, </address> <year> 1969. </year>
Reference-contexts: 1 Introduction Research in rule induction by means of search <ref> [MC, 1969; MI, 1982; CN, 1989] </ref> has been ongoing for some time. While some systems, such as Version Spaces, make direct use of the data to be learned during rule induction, such methods are highly sensitive to noisy data.
Reference: [MI, 1982] <author> Mitchell, </author> <title> T.M. Generalization as Search. </title> <journal> Artif. Intel., </journal> <volume> 18(2): </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference-contexts: 1 Introduction Research in rule induction by means of search <ref> [MC, 1969; MI, 1982; CN, 1989] </ref> has been ongoing for some time. While some systems, such as Version Spaces, make direct use of the data to be learned during rule induction, such methods are highly sensitive to noisy data.
Reference: [NI, 1992] <author> Nilsson, N. J. </author> <title> N-Cube Lattices and Their Role in Machine Learning. </title> <type> Working paper, </type> <institution> Department of Computer Science, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1992. </year>
Reference: [OO, 1988] <author> Oosthuizen, G.D. </author> <title> The Use of a Lattice in Knowledge Processing. </title> <type> PhD Thesis, </type> <institution> University of Strathclyde, Glasgow, </institution> <year> 1988. </year>
Reference-contexts: We present the Rulearner system which seeks to combine both the direct use of data with robustness in the presence of noise during the rule induction process. Since the algorithm uses a Galois lattice constructed from training data <ref> [OO, 1988] </ref> as an explicit guide through the rule space, the algorithm is directly data-driven as it does not simply heuristically fit the training data. Our system is also capable of inducing both an unordered set of classification rules as well as a decision list [RI, 1987]. <p> These two sets of nodes uniquely define a set of internal arcs and nodes which comprise the complete lattice. We use the GRAND algorithm <ref> [OO, 1988] </ref> for lattice construction in our experiments. 3 The Rulearner Algorithm The Rulearner algorithm takes as input (i) a lattice, L, (ii) a set of instance classification labelings, C, which correspond to the instance nodes in L, and (iii) a noise parameter, N, indicating a percentage by which each induced <p> Methods for automatic noise parameter selection will also be pursued. The interested reader should also be aware of the systems CHARADE [GA, 1987] and GRAND <ref> [OO, 1988] </ref> which also make use of lattices to guide the formation of classification rules. These systems, however, differ from ours in their induction mechanisms, biases, and methods for dealing with noise. Acknowledgments The author thanks Nils Nilsson and Deon Oosthuizen for their thought provoking discussions.
Reference: [OO, 1994] <author> Oosthuizen, G.D. </author> <title> The Application of Concept Lattices to Machine Learning. </title> <note> University of Pretoria Technical Report CSTR 94/01, </note> <year> 1994. </year>
Reference: [OM, 1988] <author> Oosthuizen, G.D. and McGregor, </author> <title> D.R. Induction Through Knowledge Base Normalization. </title> <booktitle> Proceedings of the European Conf. on Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference: [QU, 1993] <author> Quinlan, J.R. </author> <year> 1993. </year> <title> C4.5: Programs For Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This allows for the Rulearner system to be used in making direct comparisons between these two learning paradigms within a single algorithmic framework. Several experiments with the Rulearner system are presented comparing it with the commonly used symbolic learning systems C4.5 <ref> [QU, 1993] </ref> and CN2 [CN, 1989]. 2 Lattice Definitions A lattice is defined to be a directed acyclic graph in which any two nodes, u and v, have a unique join (a node "higher" in the graph to which a u and v are connected by minimal length paths) and a
Reference: [RI, 1987] <author> Rivest, </author> <title> R.L. Learning Decision Lists. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: Our system is also capable of inducing both an unordered set of classification rules as well as a decision list <ref> [RI, 1987] </ref>. This allows for the Rulearner system to be used in making direct comparisons between these two learning paradigms within a single algorithmic framework.
Reference: [TH, 1991] <editor> Thrun, S.B. et al. </editor> <title> The MONK'S Problems. </title> <institution> Carnegie-Mellon University Technical Report CMU-CS-91-197, </institution> <month> December, </month> <year> 1991. </year>
Reference-contexts: Pseudo-code for the Rulearner algorithm. 4 Experimental Results The Rulearner system was first tested on the Monks Problems <ref> [TH, 1991] </ref>. As a comparison, we tried several configuration of other induction systems to capture the best performance of those systems compared to Rulearner.
References-found: 11

