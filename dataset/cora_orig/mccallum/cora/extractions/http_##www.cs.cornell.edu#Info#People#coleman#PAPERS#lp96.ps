URL: http://www.cs.cornell.edu/Info/People/coleman/PAPERS/lp96.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/coleman/papers.html
Root-URL: http://www.cs.brown.edu/
Title: pPCx: Parallel Software for Linear Programming  
Author: Thomas F. Coleman Joseph Czyzyk Chunguang Sun Michael Wagner Stephen J. Wright k 
Abstract: We describe pPCx, a parallel variant of the PCx interior-point code for linear programming. We outline the major computational operation|parallel multifrontal Cholesky factorization|and present computational results on the IBM-SP multipro cessor.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Czyzyk, S. Mehrotra, and S. J. Wright, </author> <title> PCx User Guide, </title> <type> Technical Report OTC 96/01, </type> <institution> Optimization Technology Center, Argonne National Laboratory and Northwestern University, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: The scalar 2 <ref> [0; 1] </ref> in (13) is chosen by a simple heuristic; for details, consult the PCx User Guide [1]. The search direction (; x; s; r; w) for PCx is obtained by simply adding the predictor and corrector directions. <p> The scalar 2 [0; 1] in (13) is chosen by a simple heuristic; for details, consult the PCx User Guide <ref> [1] </ref>. The search direction (; x; s; r; w) for PCx is obtained by simply adding the predictor and corrector directions. The step taken by the algorithm is then a fraction of the maximum steps ff max;P , ff max;D to the boundary in the primal and dual variables, respectively. <p> The step taken by the algorithm is then a fraction of the maximum steps ff max;P , ff max;D to the boundary in the primal and dual variables, respectively. We calculate ff max;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x; w) 0g;(14) ff max;D = inffff 2 [0; 1] j (s; r) + ff (s; r) 0g;(15) and set where fl P and fl D are two scaling factors [5, p. 588]. <p> We calculate ff max;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x; w) 0g;(14) ff max;D = inffff 2 [0; 1] j (s; r) + ff (s; r) 0g;(15) and set where fl P and fl D are two scaling factors [5, p. 588]. Since the matrix A is generally large and sparse, the coefficient matrix in the step equations (10) is sparse and highly structured. <p> Details on our parallel multifrontal Cholesky factorization and parallel sparse triangular solution are given by Sun [8]. The strategy for handling small pivots during the Cholesky factorization of M is described in the PCx User Guide <ref> [1] </ref> and analyzed by Wright [10]. The elimination tree of L is defined to be the structure with m nodes f1; 2; ; mg such that node j is the parent of node i if and only if j = minfk &gt; i j L ki 6= 0g. <p> For further details, consult the PCx User Guide <ref> [1] </ref>. In the current implementation the matrix M = AD 2 A T is formed in parallel in the sense that each processor only computes the matrix entries it will need for the Cholesky factorization. As described in the previous section, the numerical factorization is also performed in parallel.
Reference: [2] <author> J. R. Gilbert, E. Ng, and B. W. Peyton, </author> <title> An efficient algorithm to compute row and column counts for sparse Cholesky factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 1075-1091. </pages>
Reference-contexts: Much of the speedup in pPCx is obtained by replacing the sparse Cholesky procedure <ref> [4, 2] </ref> used in PCx with the parallel sparse Cholesky factorization code of Sun [8]. fl To appear: Proceedings of the Eighth SIAM Conference on Parallel Processing in Scientific Computing, Minneapolis, March, 1997. Work partially supported by the U.S.
Reference: [3] <author> A. Gupta, WGPP: </author> <title> Watson Graph Partitioning (and sparse matrix ordering) Package, </title> <institution> IBM Research Report RC 20453 (90427), </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Minimizing fill and imbalance can be conflicting goals, so it is interesting to look at the behaviour of different ordering algorithms. We ran pPCx with a well-known ordering scheme| the multiple minimum degree ordering [4]|as well as a more recent ordering, WGPP <ref> [3] </ref>, which is based on graph partitioning ideas. The results differ significantly. Although there does not seem to be a clear winner, it seems that graph partitioning algorithms have a significant advantage for larger problems and larger numbers of processors.
Reference: [4] <author> J. W.-H. Liu, </author> <title> Modification of the minimum degree algorithm by multiple elimination, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 11 (1985), </volume> <pages> pp. 141-153. </pages>
Reference-contexts: Much of the speedup in pPCx is obtained by replacing the sparse Cholesky procedure <ref> [4, 2] </ref> used in PCx with the parallel sparse Cholesky factorization code of Sun [8]. fl To appear: Proceedings of the Eighth SIAM Conference on Parallel Processing in Scientific Computing, Minneapolis, March, 1997. Work partially supported by the U.S.
Reference: [5] <author> S. Mehrotra, </author> <title> On the implementation of a primal-dual interior point method, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 2 (1992), </volume> <pages> pp. 575-601. </pages>
Reference-contexts: 1 Introduction PCx is a linear programming solver developed at the Optimization Technology Center at Argonne National Laboratory and Northwestern University. It implements a variant of Mehrotra's predictor-corrector algorithm <ref> [5] </ref>, a primal-dual interior-point approach that has proved to be highly efficient on large-scale linear programming problems. In this paper we describe pPCx, a parallel variant of PCx developed at Cornell University, and present computational results from the IBM-SP multiprocessor system. <p> We calculate ff max;P = inffff 2 [0; 1] j (x; w) + ff (x; w) 0g;(14) ff max;D = inffff 2 [0; 1] j (s; r) + ff (s; r) 0g;(15) and set where fl P and fl D are two scaling factors <ref> [5, p. 588] </ref>. Since the matrix A is generally large and sparse, the coefficient matrix in the step equations (10) is sparse and highly structured. By performing simple block elimination steps, we obtain the following equivalent procedure.
Reference: [6] <author> A. Pothen and C. Sun, </author> <title> A mapping algorithm for parallel sparse Cholesky factorization, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 14 (1993), </volume> <pages> pp. 1253-1257. </pages>
Reference-contexts: Computation starts with the leaves of the tree and progresses toward the root of the tree. Disjoints subtrees can be processed independently. In a parallel setting, the computational tasks are mapped onto node processors by a proportional mapping scheme proposed in <ref> [6] </ref>. If a task associated with a supernode S is partitioned among a set of processors, then the frontal matrix F S is distributed among the set of processors. In our implementation, the columns of F S are assigned to the set of processors in a wrap-around manner. <p> Since M = AD 2 A T , M ij = k=1 A ik A jk d 2 k : A processor computes M ij if (i; j) 2 S . The proportional mapping scheme <ref> [6] </ref> used in our parallel multifrontal code ensures that the distribution of 6 M among processors is roughly balanced.
Reference: [7] <author> E. Rothberg and B. Hendrickson, </author> <title> Sparse matrix ordering methods for interior point linear programming, </title> <type> Sandia National Laboratories Technical Report 96-0475, </type> <month> January, </month> <year> 1996. </year>
Reference-contexts: The current implementation requires that A be available on every processor (although the Cholesky factor of M is distributed), a memory limitation that can be severe for very large problems. * Further investigate ordering strategies, especially the graph partitioning algorithms (for example, those of Rothberg and Hendrickson <ref> [7] </ref>). * Investigate algorithmic variants that allow concurrent solution of triangular systems with multiple right-hand-sides.
Reference: [8] <author> C. Sun, </author> <title> Efficient parallel solutions of large sparse SPD systems on distributed-memory multiprocessors, </title> <type> Technical Report CTC92TR102, </type> <institution> Advanced Computing Research Institute, Cornell Theory Center, Cornell University, </institution> <address> Ithaca, NY, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Much of the speedup in pPCx is obtained by replacing the sparse Cholesky procedure [4, 2] used in PCx with the parallel sparse Cholesky factorization code of Sun <ref> [8] </ref>. fl To appear: Proceedings of the Eighth SIAM Conference on Parallel Processing in Scientific Computing, Minneapolis, March, 1997. Work partially supported by the U.S. <p> The numeric phase computes the numerical values of L. Since the sparsity structure of M remains the same from one iteration to the next, the symbolic phase is performed only once. Details on our parallel multifrontal Cholesky factorization and parallel sparse triangular solution are given by Sun <ref> [8] </ref>. The strategy for handling small pivots during the Cholesky factorization of M is described in the PCx User Guide [1] and analyzed by Wright [10].
Reference: [9] <author> S. J. Wright, </author> <title> Primal-Dual Interior-Point Methods, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, Pa, </address> <year> 1996. </year>
Reference-contexts: In pPCx, the formation of the matrix AD 2 A T , the Cholesky factorization of AD 2 A T , and the sparse triangular substitutions are performed in parallel. For further details on Mehrotra's algorithm and primal-dual software for linear programming, see the book by Wright <ref> [9] </ref> and its associated Web site at the following 4 URL: http://www.mcs.anl.gov/home/wright/IPPD/. A user guide for PCx, which applies for the most part to pPCx as well, can be obtained from the following URL: http://www.mcs.anl.gov/otc/Library/PCx/.
Reference: [10] <author> S. J. Wright, </author> <title> The Cholesky factorization in interior-point and barrier methods, </title> <type> Preprint MCS-P600-0598, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Details on our parallel multifrontal Cholesky factorization and parallel sparse triangular solution are given by Sun [8]. The strategy for handling small pivots during the Cholesky factorization of M is described in the PCx User Guide [1] and analyzed by Wright <ref> [10] </ref>. The elimination tree of L is defined to be the structure with m nodes f1; 2; ; mg such that node j is the parent of node i if and only if j = minfk &gt; i j L ki 6= 0g.
References-found: 10

