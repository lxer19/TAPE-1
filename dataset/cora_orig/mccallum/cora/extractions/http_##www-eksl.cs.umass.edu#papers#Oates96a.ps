URL: http://www-eksl.cs.umass.edu/papers/Oates96a.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Email: foates,schmill,coheng@cs.umass.edu  
Phone: Voice: 1-413-545-3616 Fax: 1-413-545-1249  
Title: Parallel and Distributed Search for Structure in Multivariate Time Series  
Author: Tim Oates, Matthew D. Schmill and Paul R. Cohen 
Keyword: data mining, parallel and distributed algorithms, systematic search, multivariate time series  
Address: Box 34610 Amherst, MA 01003-4610  
Affiliation: Computer Science Department, LGRC University of Massachusetts  
Abstract: Efficient data mining algorithms are crucial for effective knowledge discovery. We present the Multi-Stream Dependency Detection (msdd) data mining algorithm that performs a systematic search for structure in multivariate time series of categorical data. The systematicity of msdd's search makes implementation of both parallel and distributed versions straightforward. Distributing the search for structure over multiple processors or networked machines makes mining of large numbers of databases or very large databases feasible. We present results showing that msdd efficiently finds complex structure in multivariate time series, and that the distributed version finds the same structure in approximately 1=n of the time required by msdd, where n is the number of machines across which the search is distributed. msdd differs from other data mining algorithms in the complexity of the structure that it can find. msdd also requires no domain knowledge to focus or limit its search, although such knowledge is easily incorporated when it is available. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John M. Aronis and Foster J. Provost. </author> <title> Efficiently constructing relational features from background knowledge for inductive machine learning. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 347-358, </pages> <year> 1994. </year>
Reference-contexts: However, their system is limited to classification rules (a conjunct of literals predicting a single literal), and it can miss high quality rules due to the use of beam search. Aronis and Provost developed a parallel algorithm that builds new features from existing features in relational databases <ref> [1] </ref>. The newly constructed features are then passed to a standard (serial) inductive learning algorithm. While parallelism speeds the search for new features, it does not affect the speed with which rules using those features can be learned.
Reference: [2] <author> Donald J. Berndt and James Clifford. </author> <title> Using dynamic time warping to find patterns in time series. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 359-370, </pages> <year> 1994. </year>
Reference-contexts: While parallelism speeds the search for new features, it does not affect the speed with which rules using those features can be learned. Finally, Berndt and Clifford describe a dynamic programming algorithm for finding recurring patterns in univariate time series <ref> [2] </ref>. Our approach to rule discovery in databases differs from others, including all of those cited above that perform systematic search, in that it does not require the user to specify a set of target concepts to serve as rule right-hand-sides.
Reference: [3] <author> Marcel Holsheimer and Martin L. Kersten. </author> <title> Architectural support for data mining. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 217-228, </pages> <year> 1994. </year>
Reference-contexts: Holsheimer and Kersten describe a system for inducing rules from large relational databases that performs a parallelized beam search over the space of possible rules and accesses the data through a parallel DBMS <ref> [3] </ref>. However, their system is limited to classification rules (a conjunct of literals predicting a single literal), and it can miss high quality rules due to the use of beam search. Aronis and Provost developed a parallel algorithm that builds new features from existing features in relational databases [1].
Reference: [4] <author> Tim Oates. </author> <title> Fault identification in computer networks: A review and a new approach. </title> <type> Technical Report 95-113, </type> <institution> University of Massachusetts at Amherst, Computer Science Department, </institution> <year> 1995. </year>
Reference-contexts: Second, we are using msdd to learn how current and past states of computer networks are related to future states for the purpose of acquiring rules that will allow network managers to predict and avoid problems in their networks before they arise <ref> [4] </ref>. Acknowledgements This research was supported by ARPA/Rome Laboratory under contract numbers F30602-91-C-0076 and F30602-93-0100, and by a National Defense Science and Engineering Graduate Fellowship. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes not withstanding any copyright notation hereon.
Reference: [5] <author> Tim Oates and Paul R. Cohen. </author> <title> Searching for structure in multiple streams of data. </title> <booktitle> Submitted to the Thirteenth International Conference on Machine Learning, </booktitle> <year> 1996. </year>
Reference-contexts: In terms of applications, work is proceeding in two areas. First, we are using msdd to find structure in the interactions of an artificial agent with its environment for the purpose of learning planning operators <ref> [5] </ref>. Precursor multitokens encode state/action pairs, and successor multitokens encode state changes. Strong dependencies capture state changes that the agent can reliably bring about.
Reference: [6] <author> Tim Oates, Dawn E. Gregory, and Paul R. Cohen. </author> <title> Detecting complex dependencies in categorical data. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 417-423, </pages> <year> 1994. </year> <title> Does not contain work on incremental algorithm reported in book version. </title>
Reference-contexts: However, KDD and EDA share the same underlying principles and goals. 2 search over the space of all possible dependencies. Systematic search expands the children of search nodes in a manner that ensures that no node can ever be generated more than once <ref> [6, 8-10, 15] </ref>. Because non-redundant expansion is achieved without access to large, rapidly changing data structures, such as lists of open and closed nodes, the search space can be divided between multiple processes on multiple machines. <p> That is, terms in T p are ordered first by their 2 The definition of a multitoken given here is an extension of the one given in previous descriptions of the algorithm <ref> [6] </ref>. 6 S1: . A B . . . . . . A B . . . . . . A B . . . S3: . C . . Y . . . . C . . Y . . . . C . . <p> Algorithm Search Nodes CPU Cycles Messages msdd 12,199 805,920 0 d-msdd - 2 13,544 906,188 457 d-msdd - 3 17,941 1,095,695 1,706 Table 4: Comparison of msdd and d-msdd on the solar flares dataset. 12 6 Related Work Several systematic search algorithms have appeared in the literature <ref> [6, 8-10, 15] </ref>, all of them variations on the basic idea of imposing an order on search operators, and applying only those operators at a node that are higher in the order than all other operators that have been applied on the path from the root to the node.
Reference: [7] <author> M. O'neill. </author> <title> Escherichia coli promoters: I consensus as it relates to spacing class, specificity, retreat substructure, and three dimensional organization. </title> <journal> Journal of Biological Chemistry, </journal> <volume> 264 </volume> <pages> 5522-5530, </pages> <year> 1989. </year>
Reference-contexts: Note that the space of dependencies between patterns of nucleotides is enormous, containing in excess of 10 80 elements. The biological literature suggests that a small subset of the 57 positions in each sequence are important in distinguishing promoters from non-promoters <ref> [7] </ref>; valid positions range from 50 to +6, and are denoted Px where 50 x +6. Therefore, we ran an initial msdd search with k = 50 to depth five in an attempt to determine those positions.
Reference: [8] <author> Patricia Riddle, Richard Segal, and Oren Etzioni. </author> <title> Representation design and brute-force induction in a boeing manufacturing domain. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 125-147, </pages> <year> 1994. </year>
Reference-contexts: Some of these cut off the search at an arbitrary depth to limit the size of the search space (e.g. <ref> [8, 10] </ref>). In contrast, msdd returns a list of the k strongest dependencies, regardless of the depth at which they exists in the search tree.
Reference: [9] <author> Ron Rymon. </author> <title> Search through systematic set enumeration. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992. </year>
Reference: [10] <author> Jeffrey C. Schlimmer. </author> <title> Efficiently inducing determinations: A complete and systematic search algorithm that uses optimal pruning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 284-290, </pages> <year> 1993. </year>
Reference-contexts: Some of these cut off the search at an arbitrary depth to limit the size of the search space (e.g. <ref> [8, 10] </ref>). In contrast, msdd returns a list of the k strongest dependencies, regardless of the depth at which they exists in the search tree. <p> Often, such algorithms must be run multiple times to learn rules for multiple concepts, once for each concept <ref> [10, 15] </ref>, losing the benefit of pruning information generated during previous runs. The itrule algorithm is somewhat more general in that it simultaneously searches for rules whose right-hand-sides can specify the value of any single domain variable, not just the one containing the class label.
Reference: [11] <author> Matthew D. Schmill, Tim Oates, and Paul R. Cohen. </author> <title> Tools for detecting dependencies in AI systems. </title> <booktitle> In Proceedings of the 7th IEEE International Conference on Tools with Artificial Intelligence, </booktitle> <pages> pages 148-155, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Current work includes an incremental version (i-msdd) of the basic algorithm <ref> [11] </ref>, and an investigation of techniques for dynamically adjusting the search operator ordering to maximize the effects of pruning [15]. In terms of applications, work is proceeding in two areas.
Reference: [12] <author> Padhraic Smyth and Rodney M. Goodman. </author> <title> An information theoretic approach to rule induction from databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(4) </volume> <pages> 301-316, </pages> <year> 1992. </year>
Reference-contexts: Pruning based on optimistic estimates of the value of the descendants of a node has been used infrequently in rule induction algorithms, with itrule <ref> [12] </ref> and opus [15] being notable exceptions. The G statistic computed for 2x2 contingency tables is a statistical measure of nonindependence, and we have derived bounds on the value of G for the descendants of a node, making it an ideal candidate for f . <p> Our use of optimistic bounds on the value of the node evaluation function for pruning systematic search spaces is similar to the opus algorithm [15], which in turn is a generalization of the same idea as applied to non-systematic search in the itrule induction algorithm <ref> [12] </ref>. msdd and itrule return the k best rules, whereas opus returns a single goal node or the single node with the highest value. Both parallel algorithms and consideration of data with a temporal component are rare in the KDD and data mining literature.
Reference: [13] <author> Geoffrey G. Towell, Jude W. Shavlik, and Michiel O. Noordeweir. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866, </pages> <year> 1990. </year>
Reference-contexts: The rules in Table 1 capture semantically interesting structure in the data, as demonstrated by comparing them to a previously published domain theory derived from the biological literature <ref> [13] </ref>. The domain theory states that promoters contain patterns drawn from each of three sets, two different sets of contact patterns (ct 1 and ct 2 ) and one set of conformation patterns.
Reference: [14] <author> John W. Tukey. </author> <title> Exploratory Data Analysis. </title> <publisher> Addison-Wesley, </publisher> <year> 1977. </year>
Reference-contexts: the values of a single pre-specified feature can serve as rule right-hand-sides. msdd discovers structure that these algorithms cannot even represent. msdd finds the k strongest dependencies in a set of streams by performing a systematic 1 KDD is a new term for an old activity, exploratory data analysis (EDA) <ref> [14] </ref>. Whereas EDA is typically associated with continuous-valued data and statistical procedures for transformation and analysis, KDD encompasses more complex forms of data (e.g. relational data) and transformation and analysis techniques (e.g. induction learning algorithms).
Reference: [15] <author> Geoffrey I. Webb. </author> <title> OPUS: An efficient admissible algorithm for unordered search. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3 </volume> <pages> 45-83, </pages> <year> 1996. </year>
Reference-contexts: However, KDD and EDA share the same underlying principles and goals. 2 search over the space of all possible dependencies. Systematic search expands the children of search nodes in a manner that ensures that no node can ever be generated more than once <ref> [6, 8-10, 15] </ref>. Because non-redundant expansion is achieved without access to large, rapidly changing data structures, such as lists of open and closed nodes, the search space can be divided between multiple processes on multiple machines. <p> Systematic search non-redundantly enumerates the elements of search spaces for which the value or semantics of any given node are independent of the path from the root to that node. Webb calls such search spaces unordered <ref> [15] </ref>. Consider the space of disjunctive concepts over the set of literals fA; B; Cg. <p> Pruning based on optimistic estimates of the value of the descendants of a node has been used infrequently in rule induction algorithms, with itrule [12] and opus <ref> [15] </ref> being notable exceptions. The G statistic computed for 2x2 contingency tables is a statistical measure of nonindependence, and we have derived bounds on the value of G for the descendants of a node, making it an ideal candidate for f . <p> Algorithm Search Nodes CPU Cycles Messages msdd 12,199 805,920 0 d-msdd - 2 13,544 906,188 457 d-msdd - 3 17,941 1,095,695 1,706 Table 4: Comparison of msdd and d-msdd on the solar flares dataset. 12 6 Related Work Several systematic search algorithms have appeared in the literature <ref> [6, 8-10, 15] </ref>, all of them variations on the basic idea of imposing an order on search operators, and applying only those operators at a node that are higher in the order than all other operators that have been applied on the path from the root to the node. <p> In contrast, msdd returns a list of the k strongest dependencies, regardless of the depth at which they exists in the search tree. Our use of optimistic bounds on the value of the node evaluation function for pruning systematic search spaces is similar to the opus algorithm <ref> [15] </ref>, which in turn is a generalization of the same idea as applied to non-systematic search in the itrule induction algorithm [12]. msdd and itrule return the k best rules, whereas opus returns a single goal node or the single node with the highest value. <p> Often, such algorithms must be run multiple times to learn rules for multiple concepts, once for each concept <ref> [10, 15] </ref>, losing the benefit of pruning information generated during previous runs. The itrule algorithm is somewhat more general in that it simultaneously searches for rules whose right-hand-sides can specify the value of any single domain variable, not just the one containing the class label. <p> Current work includes an incremental version (i-msdd) of the basic algorithm [11], and an investigation of techniques for dynamically adjusting the search operator ordering to maximize the effects of pruning <ref> [15] </ref>. In terms of applications, work is proceeding in two areas. First, we are using msdd to find structure in the interactions of an artificial agent with its environment for the purpose of learning planning operators [5]. Precursor multitokens encode state/action pairs, and successor multitokens encode state changes.
Reference: [16] <author> Thomas D. Wickens. </author> <title> Multiway Contingency Tables Analysis for the Social Sciences. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1989. </year> <month> 15 </month>
Reference-contexts: non-occurrences of the precursor are followed ffi time steps later by occurrences and non-occurrences of the successor, G is computed as follows: G = 2 i=1 ^n i is the expected value of n i under the assumption of independence, and is computed from the margins and the table total <ref> [16] </ref>. Because the ordering imposed on msdd's search operators causes precursors to be elaborated before successors, it is possible to reason about how the mass of a contingency table may move as one descends along a path in the search tree.
References-found: 16

