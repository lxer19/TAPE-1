URL: http://www.cs.toronto.edu/~greiner/PAPERS/default.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: dale@cs.toronto.edu  greiner@learning.siemens.com  
Title: Learning Default Concepts  
Author: Dale Schuurmans Russell Greiner 
Date: May 1994.  
Note: Banff,  
Address: Toronto, Toronto, ON M5S 1A4  Princeton, NJ 08540  
Affiliation: Department of Computer Science University of  Siemens Corporate Research  
Abstract: Classical concepts, based on necessary and sufficient defining conditions, cannot classify logically insufficient object descriptions. Many reasoning systems avoid this limitation by using "default concepts" to classify incompletely described objects. This paper addresses the task of learning such default concepts from observational data. We first model the underlying performance task | classifying incomplete examples | as a probabilistic process that passes random test examples through a "blocker" that can hide object attributes from the classifier. We then address the task of learning accurate default concepts from random training examples. After surveying the learning techniques that have been proposed for this task in the machine learning and knowledge representation literatures, and investigating their relative merits, we present a more data-efficient learning technique, developed from well-known statistical principles. Finally, we extend Valiant's pac-learning framework to this context and obtain a number of useful learnability results. Appears in the Proceedings of the Tenth Canadian Conference on Artificial Intelligence (CSCSI-94), 
Abstract-found: 1
Intro-found: 1
Reference: [Bac90] <author> F. Bacchus. </author> <title> Representing and Reasoning with Probabilistic Knowledge. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning [Rei87], and even a recent trend towards probabilistic interpretations of default logics <ref> [Pea88, Bac90] </ref>, the issue of learning defaults has scarcely been raised. <p> Existing default logics based on *-semantics (e.g., [Pea89]) all satisfy the consistent inheritance axiom and so tacitly assume independent blocking fi I . Here the meaning of a rule x fl !c can be given a "majority" semantics under fi I akin to that of <ref> [Bac90] </ref>. 3.2 Arbitrary blocking While fi I is a simple and convenient model, it does not capture every practical situation; in particular, it cannot deal with circumstances where our knowledge of an attribute is correlated with its value; e.g., ex-inmates are unlikely to answer the question "have you ever been in <p> Furthermore, there is no empirical data to support the efficacy of this approach. It is often stated that the crux of this type of statistical reasoning is the problem of "choosing the right reference class" <ref> [Bac90, BGHK92] </ref>. However, this premise might actually be leading us away from the most effective learning approaches here. Fundamentally, our goal should be to preserve all available statistical information, rather than throwing away statistics from one class in favor of those from another. <p> We then tested the techniques on random domain distributions and blocking rates, and recorded the accuracies 7 Philosophical discussions often mention the difficulty in choosing the candidate reference classes to participate in any conflict resolution procedure (cf., <ref> [Bac90, Chapter 5] </ref>). Ky-burg simply adopts the reference classes considered here, and ignores other "disjunctive" classes (cf., Section 2) by fiat.
Reference: [BE89] <author> A. Borgida and D. Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In KR-89, </booktitle> <year> 1989. </year>
Reference-contexts: matches n 2 's antecedent will also match n 1 's. 4 Notice the blocking process fi introduces only a restricted form of ambiguity: fi may produce descriptions corresponding to disjunctions like 0fl 00 _ 01, but cannot produce a description corresponding to 01 _ 10 (this is reminiscent of <ref> [BE89] </ref>) | i.e., it cannot express the claim that an object is "either a non-green plant or a green non-plant".
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> J. of ACM, </journal> <volume> 36(4), </volume> <year> 1989. </year>
Reference-contexts: Notice also that we are only addressing the sample complexity of learning, not computational complexity. 10 This is the same measure used when learning ccds. See <ref> [BEHW89] </ref> for a precise definition of VCdim and its application to determining the difficulty of learning sets of ccds.
Reference: [BFOS84] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: Unfortunately, the task of learning default concept definitions has received relatively little attention, especially when compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87, p.245]. This means there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> Here we quantify bias by 8 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications <ref> [Qui89, BFOS84] </ref>, and for mli by applications of the EM algorithm to parameterized domain distributions [LR87]. its measurable effects on the quality of learning that can be guaranteed.
Reference: [BGHK92] <author> F. Bacchus, A. Grove, J. Halpern, and D. Koller. </author> <title> From statistics to beliefs. </title> <booktitle> In AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Furthermore, there is no empirical data to support the efficacy of this approach. It is often stated that the crux of this type of statistical reasoning is the problem of "choosing the right reference class" <ref> [Bac90, BGHK92] </ref>. However, this premise might actually be leading us away from the most effective learning approaches here. Fundamentally, our goal should be to preserve all available statistical information, rather than throwing away statistics from one class in favor of those from another.
Reference: [Cla85] <author> W. Clancey. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27, </volume> <year> 1985. </year>
Reference-contexts: 1 Introduction Many reasoning tasks involve "classification" <ref> [Cla85] </ref> | i.e., determining whether a particular object belongs to a specified class, given a description of that object. <p> There are, however, formalisms designed to classify partial object descriptions. Default concept definitions (dcd s) are a natural generalization of ccds, which avoid this limitation by using default classification rules [Rei87]. These classifiers play an important role in many expert systems <ref> [Cla85, PBH90] </ref>. Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., [PBH90].
Reference: [DH73] <author> R. O. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: Lemma 2 Under fi I , for any domain distribution P XC , the optimally accurate dcd d makes maximum conditional likelihood (mcl) classifications under P XC , given the ob served attributes of an object (cf., <ref> [DH73] </ref>).
Reference: [GHR94] <author> R. Greiner, T. Hancock, and R. B. Rao. </author> <title> Knowing what doesn't matter. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1994. </year>
Reference-contexts: Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model such tasks; <ref> [GHR94] </ref> provides an initial analysis of this situation. We are currently investigating other intermediate blocking models that can more accurately model such domains and (we hope) lead to better empirical learning performance.
Reference: [Gin87] <editor> M. Ginsberg, editor. </editor> <booktitle> Readings in Nonmonotonic Reasoning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1987. </year>
Reference-contexts: Our acceptance conditions (rules of the form x fl !1) correspond to Reiter's "default" sufficient conditions (a.k.a. frame selectors). However our rejection conditions (rules of the form x fl ! 0) and Reiter's "default" necessary conditions (frame instantiations) are contra-positives, and do not serve precisely the same function <ref> [Gin87] </ref>. Still, the similarities are striking given the far different motivations behind these formalizations. 3 Model: Random Test Examples We assume there is a "natural" source of random test examples against which we can evaluate the accuracy of any classifier.
Reference: [KS90] <author> M. J. Kearns and R. E. Shapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In FOCS-90, </booktitle> <year> 1990. </year>
Reference-contexts: Also, a probabilistic concept <ref> [KS90] </ref> is a mapping c i : X n 7! [0; 1] from the space of complete object descriptions X n to probability values; such mappings do not directly handle missing attribute values. 2 Default Concepts Following standard practice, we consider a set of domain objects X n = f0; 1g
Reference: [Kyb83] <author> H. Kyburg. </author> <title> The reference class. </title> <journal> Philosophy of Science, </journal> <volume> 50, </volume> <year> 1983. </year>
Reference-contexts: A learning technique that attempts to do just this has been proposed in the philosophy of statistics literature | namely Kyburg's proposals for choosing the best ref erence class on which to base statistical judgements. ref (Reference class) <ref> [Kyb83, Kyb91] </ref> For description x fl , first select a "reference-class" description x fl r (either x fl itself, or possibly a more general description), then predict the most likely classification given all training descriptions that match the reference class description x fl r .
Reference: [Kyb91] <author> H. Kyburg. </author> <title> Evidential probability. </title> <booktitle> In IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: A learning technique that attempts to do just this has been proposed in the philosophy of statistics literature | namely Kyburg's proposals for choosing the best ref erence class on which to base statistical judgements. ref (Reference class) <ref> [Kyb83, Kyb91] </ref> For description x fl , first select a "reference-class" description x fl r (either x fl itself, or possibly a more general description), then predict the most likely classification given all training descriptions that match the reference class description x fl r . <p> Then employ a conflict resolution strategy (which trades-off interval bias and width) to decide whether to adopt, for this x fl , the classification associated with successively more general reference classes <ref> [Kyb91] </ref>. 7 Although the ref strategy can override the predictions from specific descriptions with those from more general descriptions, it is not clear that it does so in the best conceivable way.
Reference: [LR87] <author> J. A. Little and D. B. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: The best approach should involve combining all of the available statistics in a principled way. Here we note that a well-known idea from theoretical statistics is applicable: namely, first determine the maximum likelihood distribution that accounts for all the data, then perform inferences according to this distribution <ref> [LR87] </ref>. This approach yields an effective method for determining the most likely classifications given incomplete training examples. mli (Maximum Likelihood (Incomplete)) [LR87] First, determine the domain distribution P max XC that maximizes the likelihood of the observed training ex amples. <p> that a well-known idea from theoretical statistics is applicable: namely, first determine the maximum likelihood distribution that accounts for all the data, then perform inferences according to this distribution <ref> [LR87] </ref>. This approach yields an effective method for determining the most likely classifications given incomplete training examples. mli (Maximum Likelihood (Incomplete)) [LR87] First, determine the domain distribution P max XC that maximizes the likelihood of the observed training ex amples. Then, for description x fl , predict the most probable classification according to P max XC , given x fl 's observed attributes. <p> Here we quantify bias by 8 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications [Qui89, BFOS84], and for mli by applications of the EM algorithm to parameterized domain distributions <ref> [LR87] </ref>. its measurable effects on the quality of learning that can be guaranteed. A la Valiant, we consider prior domain knowledge that can be expressed by a restricted set of dcds D, which is known to include the optimal dcd.
Reference: [Min75] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <booktitle> In The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: This will restrict the type of "reference classes" we must consider when learning dcds; see Footnote 7 below. "RealWorld" P XC hx; ci Blocker fi hx fl ; ci * fi Learner ffi -x fl * fi Classifier frames <ref> [Min75] </ref>: frame selectors can be viewed as "default" sufficient conditions for the frame concept, and frame instantiations can be viewed as "default" necessary conditions. These notions of non-classical concepts appear quite similar to the account of dcds developed here.
Reference: [PBH90] <author> B. Porter, R. Bareiss, and R. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45, </volume> <year> 1990. </year>
Reference-contexts: There are, however, formalisms designed to classify partial object descriptions. Default concept definitions (dcd s) are a natural generalization of ccds, which avoid this limitation by using default classification rules [Rei87]. These classifiers play an important role in many expert systems <ref> [Cla85, PBH90] </ref>. Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., [PBH90]. <p> Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., <ref> [PBH90] </ref>. Unfortunately, the task of learning default concept definitions has received relatively little attention, especially when compared to the vast literature on the subject of learning to classify complete object descriptions. <p> Unfortunately, the task of learning default concept definitions has received relatively little attention, especially when compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87, p.245]. This means there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> We are also beginning to examine many extensions to better cope with practical problems. For example, many application domains like medical diagnosis have the property that missing attribute values actually give useful information | namely that the missing attributes are irrelevant to the classification, given the known attribute values <ref> [PBH90] </ref>. Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model such tasks; [GHR94] provides an initial analysis of this situation.
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning [Rei87], and even a recent trend towards probabilistic interpretations of default logics <ref> [Pea88, Bac90] </ref>, the issue of learning defaults has scarcely been raised.
Reference: [Pea89] <author> J. Pearl. </author> <title> Probabilistic semantics for nonmono-tonic reasoning: A survey. </title> <booktitle> In KR-89, </booktitle> <year> 1989. </year>
Reference-contexts: Existing default logics based on *-semantics (e.g., <ref> [Pea89] </ref>) all satisfy the consistent inheritance axiom and so tacitly assume independent blocking fi I .
Reference: [Qui89] <author> J. R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In ML-89, </booktitle> <year> 1989. </year>
Reference-contexts: Unfortunately, the task of learning default concept definitions has received relatively little attention, especially when compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87, p.245]. This means there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> gathers separate statistics for each description x fl ; effectively treating "fl" as a third attribute value. 6 Given the benign assumption that L's guesses for a description x fl are conditionally independent of the training labels of domain objects x that do not match x fl . thv (Three-valued) <ref> [Qui89] </ref> For description x fl , predict the most frequent classification among training ex amples of the form hx fl ; ci. thv clearly does not make the most effective use of the available training data, given that attributes are blocked independently of their values. <p> Here we quantify bias by 8 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications <ref> [Qui89, BFOS84] </ref>, and for mli by applications of the EM algorithm to parameterized domain distributions [LR87]. its measurable effects on the quality of learning that can be guaranteed. <p> In contrast, thv is the only provably effective technique for learning under fi A , given incomplete training examples, and so clearly dominates in this case. These theoretical observations can actually help explain some of the results obtained by recent empirical studies: Quinlan <ref> [Qui89] </ref> compared applications of the lem and thv techniques (along with some other ad hoc approaches) to decision-tree learning, and found that no single technique dominated the others over the set of test problem he considered.
Reference: [Rei87] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <year> 1987. </year>
Reference-contexts: There are, however, formalisms designed to classify partial object descriptions. Default concept definitions (dcd s) are a natural generalization of ccds, which avoid this limitation by using default classification rules <ref> [Rei87] </ref>. These classifiers play an important role in many expert systems [Cla85, PBH90]. Of course these dcds must somehow be acquired for such applications. <p> framework to the present case: assessing the effects of prior knowledge on learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning <ref> [Rei87] </ref>, and even a recent trend towards probabilistic interpretations of default logics [Pea88, Bac90], the issue of learning defaults has scarcely been raised. <p> For example, even though non-green-plants plants things, the predicted photosynthesis properties are 0, 1, 0, respectively. Such a classifier cannot be specified by a classical concept. 4 There are many unexpected similarities between dcds and existing nonmonotonic knowledge representation formalisms. For example, Reiter <ref> [Rei87] </ref> considers com-monsense concepts like "bird", "chair", and "game" and notes that they do not have classical definitions in terms of necessary and sufficient conditions.
Reference: [Riv87] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3), </volume> <year> 1987. </year>
Reference-contexts: To date, only a few empirical studies have been published [PBH90, Qui89, BFOS84], and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., <ref> [Riv87, p.245] </ref>. This means there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. We attempt to fill this void by studying the problem of learning accurate default concepts from examples within a precise mathematical framework.
Reference: [RS88] <author> R. Rivest and R. Sloan. </author> <title> Learning complicated concepts reliably and usefully. </title> <booktitle> In AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: Other interesting research directions involve alternative generalizations of standard classification learning: This work has assumed that default definitions categorically classify every description, no matter how incomplete. An interesting direction is to consider partial default definitions that sometimes say "I don't know" a la <ref> [RS88] </ref>. Such classifiers could prove useful in domains where the consequences of an incorrect classification sometimes outweigh those of remaining silent. Another interesting extension is to consider active classifiers. That is, we have assumed that classifiers passively observe test examples and play no role in determining which attributes are observed.
Reference: [Sch94] <author> D. Schuurmans. </author> <title> Efficient, Accurate, and Reliable Machine Learning. </title> <type> PhD thesis, </type> <institution> Univ. of Toronto, Dept. Computer Science (forthcoming) </institution>
Reference-contexts: The space of possible examples is denoted X fl n fi f0; 1g. 1 Unfortunately, space constraints preclude presenting proofs of the results stated in this abstract; see <ref> [Sch94] </ref>. A classical concept definition (ccd) is a subset of X n , which we represent by its indicator function c : X n ! f0; 1g; thus c (x) = 1 iff x belongs to the concept.
Reference: [SV88] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In COLT-88, </booktitle> <year> 1988. </year>
Reference-contexts: Second, to avoid possible confusions, it is worth explicitly distinguishing our "missing attribute" framework from two other models of learning from the learnability community: A system that learns with attribute noise <ref> [SV88] </ref> does not know which attribute values have been corrupted; by contrast, we know explicitly which values are missing.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11), </volume> <year> 1984. </year>
Reference-contexts: This points to the necessity of bias. In any successful application, the learning system must be constrained to search a restricted space of appropriate classifiers, which here are dcds. 8 Following the methodology pioneered by Valiant <ref> [Val84] </ref>, we consider how learning performance scales as a function of prior knowledge.
References-found: 24

