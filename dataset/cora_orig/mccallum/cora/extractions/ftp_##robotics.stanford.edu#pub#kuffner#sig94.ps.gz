URL: ftp://robotics.stanford.edu/pub/kuffner/sig94.ps.gz
Refering-URL: http://robotics.stanford.edu/~kuffner/publications.html
Root-URL: http://www.cs.stanford.edu
Title: Planning Motions with Intentions  
Author: Yoshihito Koga Koichi Kondo James Kuffner and Jean-Claude Latombe R D 
Address: Stanford, CA 94305, USA  4-1 Ukishima-cho, Kawasaki, 210, Japan  
Affiliation: Robotics Laboratory Department of Computer Science, Stanford University  Center, Toshiba Corporation,  
Abstract: We apply manipulation planning to computer animation. A new path planner is presented that automatically computes the collision-free trajectories for several cooperating arms to manipulate a movable object between two configurations. This implemented planner is capable of dealing with complicated tasks where re-grasping is involved. In addition, we present a new inverse kinematics algorithm for the human arms. This algorithm is utilized by the planner for the generation of realistic human arm motions as they manipulate objects. We view our system as a tool for facilitating the production of animation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.G. Atkeson and J.M. Hollerbach, </author> <title> "Kinematic Features of Unrestrained Arm Movements," </title> <publisher> MIT AI Memo 790, </publisher> <year> 1984. </year>
Reference-contexts: From the neurophysiological viewpoint this is not a problem. It is widely agreed upon that arm movement is represented kinematically [26]. It is then a postprocessing step, where the dynamics or muscle activation patterns are determined. With our method, by applying the appropriate time parameterization to the planned path <ref> [8, 1] </ref> one can emulate results found in neurophysiology. However, this is not done in our current planner yet. Inverse Kinematics: The sensorimotor transformation model is derived from static arm postures. <p> The technique described in [11] to deal with multiple movable objects in a 2D space should also be applicable to our planner. Furthermore, we hope to time parameterize the motion paths to yield realistic velocities, by implementing one of the many such algorithms for robot and human arms <ref> [8, 1, 4] </ref>. Finally, we hope to explore and devise other inverse kinematics algorithms for the arms, as well as incorporating twisting and bending of the torso. Ultimately, we aim to create a task-level animation package for human motions.
Reference: [2] <author> D. Baraff, </author> <title> "Analytical Method for Dynamic Simulation of Non-Penetrating Rigid Bodies," </title> <journal> Computer Graphics, </journal> <volume> 23(3), </volume> <year> 1989, </year> <pages> pp. 223-232. </pages>
Reference-contexts: The arms move not through some predictable trajectory due to the laws of physics (as is the case with a falling object <ref> [2, 9] </ref>) but with the intention of completing some task. A planner is needed to determine how the arms must move to complete the task at hand. Although there has been previous work on simulating walking and lifting motions, this is the first attempt to automatically generate complex manipulation motions.
Reference: [3] <author> J. Barraquand and J.C. Latombe, </author> <title> "Robot Motion Planning: A Distributed Representation Approach," </title> <journal> Int. J. Robotics Research, </journal> <volume> 10(6), </volume> <month> Decem-ber </month> <year> 1991. </year> <month> 10 </month>
Reference-contexts: The planner computes the path t obj so that M avoids collision with the static obstacles B j . This is done using RPP (Randomized Path Planner), which is thus a component of our planner. RPP is described in detail in <ref> [3, 16] </ref>. RPP generates t obj as a list of adjacent configurations in a fine grid placed over C obj (the 6D C-space of M), by inserting one configuration after the other starting with the initial configuration of M. The original RPP only checks that each inserted configuration is collision-free. <p> An obvious example where this limitation may prevent our planner from finding a path is when the system contains a single arm; no regrasp is then possible. RPP is only probabilistically complete <ref> [3] </ref>. If a path exists for M, it will find it, but the computation time cannot be bounded in advance. Furthermore, if no path exists, RPP may run forever.
Reference: [4] <author> J.E. Bobrow, S. Dubowsky, J.S. Gibson, </author> <title> "Time-Optimal Control of Robotic Manipulators Along Specified Paths," </title> <journal> International Journal of Robotics Research, </journal> <volume> Vol. 4, No. 3, </volume> <year> 1985. </year>
Reference-contexts: The technique described in [11] to deal with multiple movable objects in a 2D space should also be applicable to our planner. Furthermore, we hope to time parameterize the motion paths to yield realistic velocities, by implementing one of the many such algorithms for robot and human arms <ref> [8, 1, 4] </ref>. Finally, we hope to explore and devise other inverse kinematics algorithms for the arms, as well as incorporating twisting and bending of the torso. Ultimately, we aim to create a task-level animation package for human motions.
Reference: [5] <author> A. Bruderlin and T.W. Calvert, </author> <title> "Goal-directed, dynamic animation of human walking," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. 3, </volume> <year> 1989, </year> <month> pp.233-242. </month>
Reference-contexts: A quite substantial amount of research has been done on this topic. See [22] for a commented list of bibliographical references. Animation of Human Figures: Human gaits have been successfully simulated. For example, Brud-erlin and Calvert <ref> [5] </ref> have proposed a hybrid approach to the animation of human locomotion which combines goal-directed and dynamic motion control. McKenna and Zeltzer [21] have successfully simulated the gait of a virtual insect by combining forward dynamic simulation and a biologically-based motion coordination mechanism.
Reference: [6] <author> W. Ching and N. Badler, </author> <title> "Fast motion planning for anthropometric figures with many degrees of freedom," </title> <booktitle> Proc. 1992 IEEE Int. Conf. on Robotics and Automation, </booktitle> <year> 1992, </year> <month> pp.2340-2345. </month>
Reference-contexts: We justify this approach in Section 5. There has been previous work in applying motion planning algorithms to animating human figures. Ching and Badler <ref> [6] </ref> present a motion planning algorithm for anthropometric figures with many degrees of freedom. Essentially, they use a sequential search strategy to find a collision-free motion of the figure to a specified goal configuration. They do not consider manipulation or imposing naturalness on the motions.
Reference: [7] <author> P. Ferbach and J. Barraquand, </author> <title> A Penalty Function Method for Constrained Motion Planning, </title> <type> Rep. No. 34, </type> <institution> Paris Research Lab., </institution> <month> DEC, Sept. </month> <year> 1993. </year>
Reference-contexts: Our problem is thus to find a collision-free path for the arms to grasp and then carry some specified movable object from its initial location to a desired goal location. This problem is known as the multi-arm manipulation planning problem <ref> [12, 7] </ref>. A crucial difference, relative to more classical path planning, is that we must account for the ability of the arms to change their grasp of the object.
Reference: [8] <author> T. Flash and N. Hogan, </author> <title> "The Coordination of Arm Movements: An Experimentally Confirmed Mathematical Model," </title> <publisher> MIT AI Memo 786, </publisher> <year> 1984. </year>
Reference-contexts: From the neurophysiological viewpoint this is not a problem. It is widely agreed upon that arm movement is represented kinematically [26]. It is then a postprocessing step, where the dynamics or muscle activation patterns are determined. With our method, by applying the appropriate time parameterization to the planned path <ref> [8, 1] </ref> one can emulate results found in neurophysiology. However, this is not done in our current planner yet. Inverse Kinematics: The sensorimotor transformation model is derived from static arm postures. <p> The technique described in [11] to deal with multiple movable objects in a 2D space should also be applicable to our planner. Furthermore, we hope to time parameterize the motion paths to yield realistic velocities, by implementing one of the many such algorithms for robot and human arms <ref> [8, 1, 4] </ref>. Finally, we hope to explore and devise other inverse kinematics algorithms for the arms, as well as incorporating twisting and bending of the torso. Ultimately, we aim to create a task-level animation package for human motions.
Reference: [9] <author> J. Hahn, </author> <title> "Realistic Animation of Rigid Bodies," </title> <journal> Computer Graphics, </journal> <volume> 22(4): </volume> <year> 1988, </year> <pages> pp. 299-308. </pages>
Reference-contexts: The arms move not through some predictable trajectory due to the laws of physics (as is the case with a falling object <ref> [2, 9] </ref>) but with the intention of completing some task. A planner is needed to determine how the arms must move to complete the task at hand. Although there has been previous work on simulating walking and lifting motions, this is the first attempt to automatically generate complex manipulation motions.
Reference: [10] <author> J.M. Hollerbach and C.G. Atkeson, </author> <title> "Deducing Planning Variables from Experimental Arm Trajectories: Pitfalls and Possibilities," </title> <journal> Biological Cybernetics, </journal> <volume> 56(5), </volume> <year> 1987, </year> <pages> pp. 279-292. </pages>
Reference-contexts: This smoothing is achieved by attempting to shorten the path by interpolating between its points. The result is essentially a piecewise joint interpolated path. Hollerbach and Atke-son speculate that the underlying planning strategy for such arm motions is a staggered joint interpolation <ref> [10] </ref>. Staggered joint interpolation is a generalization of joint interpolation introduced by Hollerbach and Atkeson to fit a greater range of experimental data.
Reference: [11] <author> Y. Koga, T. Lastennet, J.C. Latombe, and T.Y. </author> <title> Li "Multi-Arm Manipulation Planning," </title> <booktitle> Proc. 9th Int. Symp. Automation and Robotics in Construction, </booktitle> <address> Tokyo, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: We also plan to use existing results to automatically compute the grasp set of an object from its geometric model. The technique described in <ref> [11] </ref> to deal with multiple movable objects in a 2D space should also be applicable to our planner. Furthermore, we hope to time parameterize the motion paths to yield realistic velocities, by implementing one of the many such algorithms for robot and human arms [8, 1, 4].
Reference: [12] <author> Y. </author> <title> Koga, </title> <type> PhD. </type> <note> dissertation (in preparation) </note>
Reference-contexts: Our problem is thus to find a collision-free path for the arms to grasp and then carry some specified movable object from its initial location to a desired goal location. This problem is known as the multi-arm manipulation planning problem <ref> [12, 7] </ref>. A crucial difference, relative to more classical path planning, is that we must account for the ability of the arms to change their grasp of the object. <p> Indeed, for some tasks the arms may need to ungrasp the object and regrasp it in a new manner to successfully complete the motion. We present a new planner that solves this multi-arm manipulation problem <ref> [12] </ref>. The planner needs as input the geometry of the environment, the initial and goal configurations of the movable object and arms, a set of potential grasps of the movable object, and the inverse kinematics of the arms.
Reference: [13] <author> K. Kondo, </author> <title> "Inverse Kinematics of a Human Arm," </title> <note> (in preparation) </note>
Reference-contexts: We reproduced their experiment by tracing curvilinear wrist motions and generating the arm parameters using the human arm inverse kinematics algorithm. Our finding is that the computed and experimental values match quite nicely. We refer the reader to <ref> [13] </ref> for a detailed explanation. Furthermore, Soechting and Terzuolo find that for learned trajectories, their results for curvilinear wrist motions in a plane hold true in three-dimensional space [28]. We justify the use of our inverse kinematics algorithm for manipulation planning based on these experimental results.
Reference: [14] <author> F. Lacquaniti and J.F. Soechting, </author> <title> "Coordination of Arm and Wrist Motion During A Reaching Task," </title> <journal> The Journal of Neuroscience, </journal> <volume> Vol. 2, No. 2, </volume> <year> 1982, </year> <month> pp399-408. </month>
Reference-contexts: The first result has to do with decoupling the problem into two more manageable subproblems. Lacquaniti and Soechting have shown that the arm and wrist posture are for the most part independent of each other <ref> [14] </ref>. This allows us to decouple the problem into finding first, the forearm and upper arm posture to match the hand position, and then determining the joint angles for the wrist to match the hand orientation.
Reference: [15] <author> J.P. Laumond and R. Alami, </author> <title> A Geometrical Approach to Planning Manipulation Tasks: The Case of a Circular Robot and a Movable Circular Object Amidst Polygonal Obstacles, </title> <journal> Rep. </journal> <volume> No. 88314, </volume> <pages> LAAS, </pages> <address> Toulouse, </address> <year> 1989. </year>
Reference-contexts: Laumond and Alami <ref> [15] </ref> propose an O (n 4 ) algorithm to solve a similar problem where the robot and the movable object are both discs and the obstacles are polygonal. Our work differs from this previous research in several ways.
Reference: [16] <author> J.C. Latombe, </author> <title> Robot Motion Planning, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: The object M can only move by having one or several of the arms grasp and carry it to some destination. Let C i and C obj be the C-spaces (configuration spaces) of the arms A i and the object M, respectively <ref> [19, 16] </ref>. Each C i has dimension n i , where n i is the number of degrees of freedom of the arm A i , and C obj has dimension 6. <p> The planner computes the path t obj so that M avoids collision with the static obstacles B j . This is done using RPP (Randomized Path Planner), which is thus a component of our planner. RPP is described in detail in <ref> [3, 16] </ref>. RPP generates t obj as a list of adjacent configurations in a fine grid placed over C obj (the 6D C-space of M), by inserting one configuration after the other starting with the initial configuration of M. The original RPP only checks that each inserted configuration is collision-free. <p> Note that the motion of the fingers for the human and the robot are considered in the transit paths (in moving from one grasp to another the fingers may change their posture). In computing t obj RPP uses an NF2-based potential with three control points <ref> [16] </ref>. In finding both the transit paths and t obj , we limit the amount of computation spent in RPP to three backtrack operations [16], after which the planner returns failure. Failure to find t obj results in the immediate failure to find a manipulation path. <p> In computing t obj RPP uses an NF2-based potential with three control points <ref> [16] </ref>. In finding both the transit paths and t obj , we limit the amount of computation spent in RPP to three backtrack operations [16], after which the planner returns failure. Failure to find t obj results in the immediate failure to find a manipulation path. Similarly, a failure to find transit paths to link together the layers of transfer paths results in a failure to find a manipulation path.
Reference: [17] <author> P. Lee, S. Wei, J. Zhao, and N.I. Badler, </author> <title> "Strength guided motion," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 4, </volume> <year> 1990, </year> <month> pp.253-262. </month>
Reference-contexts: For simulating the motion of human arms, there exist methods for specific tasks. For example, Lee et al. <ref> [17] </ref> have focused on the simulation of arm motions for lifting based on human muscle models. Their method considers such factors as comfort level, perceived exertion, and strength.
Reference: [18] <author> J. Lengyel, M. Reichert, B.R. Donald and D.P. Greenberg, </author> <title> "Real-Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 4, </volume> <year> 1990, </year> <month> pp.327-335. </month>
Reference-contexts: We roughly classify this related work into three categories, manipulation planning, animation of human figures, and neurophysiology. Manipulation Planning: The use of path planning to automatically generate graphic animation was already suggested in <ref> [18] </ref>. Research strictly addressing manipulation planning is fairly recent. The first paper to tackle this problem is by Wilfong [34]. It considers a single-body robot translating in a 2D workspace with multiple movable objects. The robot, the movable objects and obstacles are modelled as convex polygons.
Reference: [19] <author> T. Lozano-Perez, </author> <title> "Spatial Planning: A Configuration Space Approach," </title> <journal> IEEE Tr. Computers, </journal> <volume> 32(2), </volume> <year> 1983, </year> <pages> pp. 108-120. </pages>
Reference-contexts: The object M can only move by having one or several of the arms grasp and carry it to some destination. Let C i and C obj be the C-spaces (configuration spaces) of the arms A i and the object M, respectively <ref> [19, 16] </ref>. Each C i has dimension n i , where n i is the number of degrees of freedom of the arm A i , and C obj has dimension 6.
Reference: [20] <author> E.J. McCormick and M.S. Sanders, </author> <booktitle> Human Factors in Engineering and Design, </booktitle> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: By adding this extra degree of freedom, we allow the arms to access a greater region, and hence tackle more interesting manipulation tasks. The rotation of the chair tracks the object to keep it, essentially, in an optimal position with respect to the workspace of the arms <ref> [20] </ref>. Fig. 1 shows a path generated by the planner for the human arms to bring the glasses on the table to the head of the human figure. We specify that both arms should be used to manipulate the glasses (this is defined in the grasp set).
Reference: [21] <author> M. McKenna and D. Zeltzer, </author> <title> "Dynamic simulation of autonomous legged locomotion," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 4, </volume> <year> 1990, </year> <month> pp.29-38. </month>
Reference-contexts: See [22] for a commented list of bibliographical references. Animation of Human Figures: Human gaits have been successfully simulated. For example, Brud-erlin and Calvert [5] have proposed a hybrid approach to the animation of human locomotion which combines goal-directed and dynamic motion control. McKenna and Zeltzer <ref> [21] </ref> have successfully simulated the gait of a virtual insect by combining forward dynamic simulation and a biologically-based motion coordination mechanism. Control algorithms have been successfully applied to the animation of dynamic legged locomotion [25].
Reference: [22] <author> J. Pertin-Troccaz, "Grasping: </author> <title> A State of the Art," in The Robotics Review 1, </title> <editor> O. Khatib, J.J. Craig, and T. Lozano-Perez, eds., </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989, </year> <pages> pp. 71-98. </pages>
Reference-contexts: Grasp planning is potentially an important component of manipulation planning. In our planner, grasps are only selected from a finite predefined set. An improvement for the future will be to include the automatic computation of grasps. A quite substantial amount of research has been done on this topic. See <ref> [22] </ref> for a commented list of bibliographical references. Animation of Human Figures: Human gaits have been successfully simulated. For example, Brud-erlin and Calvert [5] have proposed a hybrid approach to the animation of human locomotion which combines goal-directed and dynamic motion control.
Reference: [23] <author> D. Pieper and B. Roth, </author> <title> "The Kinematics of Manipulators Under Computer Control," </title> <booktitle> Proceedings of the Second International Congress on Theory of Machines and Mechanisms, </booktitle> <volume> Vol. </volume> <pages> 2, </pages> <address> Za-kopane, Poland, </address> <year> 1969, </year> <pages> pp. 159-169. </pages>
Reference-contexts: This is exactly the approach taken in solving the inverse kinematics of a robot manipulator with six degrees of freedom and whose wrist joints intersect at a point <ref> [23] </ref>. It is also known in neurophysiology that the arm posture for pointing is mainly determined by a simple sensorimotor transformation model. Soechting and Flanders [29, 30] conducted experiments where the test subject was instructed to move the end of a pen-sized stylus to various targets in their vicinity.
Reference: [24] <author> S. Quinlan, </author> <type> PhD. </type> <note> dissertation (in preparation) </note>
Reference-contexts: The time for the planner to report failure depends on the problem, with some examples ranging from 30 seconds to a few minutes. The collision checking algorithm utilized is that of Quinlan <ref> [24] </ref>. 7 Conclusion We have presented a novel approach for solving the complicated multi-arm manipulation planning problem. Our approach embeds several simplifications yielding an implemented planner that is not fully general.
Reference: [25] <author> M.H. Raibert and J.K. Hodgins, </author> <title> "Animation of Dynamic Legged Locomotion," </title> <journal> Computer Graphics, </journal> <volume> Vol. 25, No. 4, </volume> <year> 1991, </year> <month> pp.349-358. </month>
Reference-contexts: McKenna and Zeltzer [21] have successfully simulated the gait of a virtual insect by combining forward dynamic simulation and a biologically-based motion coordination mechanism. Control algorithms have been successfully applied to the animation of dynamic legged locomotion <ref> [25] </ref>. While dynamic models and the use of motor coordination models have been successfully applied to a wide range of walking motions, such a strategy has yet to be discovered to encompass human arm motions. For simulating the motion of human arms, there exist methods for specific tasks.
Reference: [26] <author> A.M. Smith et al., </author> <title> "Group Report: What Do Studies of Specific Motor Acts Such as Reaching and Grasping Tell Us about the General Principles of Goal-Directed Motor Behaviour?'," Motor Contro: Concepts and Issues, D.R Humphrey and H,J, Freund, </title> <editor> eds., </editor> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1991, </year> <pages> pp. 357-381. </pages>
Reference-contexts: Dynamics versus Kinematics: We make no consideration of dynamics in our planning. From the neurophysiological viewpoint this is not a problem. It is widely agreed upon that arm movement is represented kinematically <ref> [26] </ref>. It is then a postprocessing step, where the dynamics or muscle activation patterns are determined. With our method, by applying the appropriate time parameterization to the planned path [8, 1] one can emulate results found in neurophysiology. However, this is not done in our current planner yet.
Reference: [27] <author> J.F. Soechting and C.A. Terzuolo, </author> <title> "An Algorithm for the Generation of Curvilinear Wrist Motion in an Arbitrary Plane in Three Dimensional Space," </title> <journal> Neuroscience, </journal> <volume> Vol. 19, No. 4, </volume> <year> 1986, </year> <pages> pp. 1393-1405. </pages>
Reference-contexts: However, this is not done in our current planner yet. Inverse Kinematics: The sensorimotor transformation model is derived from static arm postures. To verify that our inverse kinematics algorithm is applicable to manipulation motions, we consider the experimental results of Soechting and Terzuolo <ref> [27] </ref>. Their experiment is for curvilinear wrist motions in an arbitrary plane. They find that humans exhibit the following behavior: 1. The modulation in the elevation and yaw angles of the upper arm and forearm (, , fi, and ff) are close to sinusoidal. 2.
Reference: [28] <author> J.F. Soechting and C.A. Terzuolo, </author> <title> "Organization of Arm Movements in Three Dimensional Space. Wrist Motion is Piecewise Planar," </title> <journal> Neuroscience, </journal> <volume> Vol. 23, No. 1, </volume> <year> 1987, </year> <pages> pp. 53-61. </pages>
Reference-contexts: Our finding is that the computed and experimental values match quite nicely. We refer the reader to [13] for a detailed explanation. Furthermore, Soechting and Terzuolo find that for learned trajectories, their results for curvilinear wrist motions in a plane hold true in three-dimensional space <ref> [28] </ref>. We justify the use of our inverse kinematics algorithm for manipulation planning based on these experimental results. Note, we do not claim that the posture found by our algorithm is the only one that is natural. Clearly, there are other postures that humans assume depending upon the situation.
Reference: [29] <author> J.F. Soechting and M. Flanders, </author> <title> "Sensorimotor Representations for Pointing to Targets in Three Dimensional Space," </title> <journal> Journal of Neurophysiology, </journal> <volume> Vol. 62, No. 2, </volume> <year> 1989, </year> <note> pp.582-594. 11 </note>
Reference-contexts: Thus, in addition to the planner, we present a new inverse kinematics algorithm for the human arms based on results from neurophysiology. This algorithm 1 resolves the redundancy of the human arms by utiliz-ing a sensorimotor transformation model <ref> [29, 30] </ref>. The result is the automatic animation of human arm manipulation tasks. In addition to the motion planning aspect, we address the issue of producing natural motions when human figures are animated. <p> Soechting [31] gives a good survey of various empirical studies and their results for human arm motions. One relevant finding is the sensorimotor transformation model devised by Soechting and Flanders <ref> [29, 30] </ref>. They found that the desired position of the hand roughly determines the arm posture. Our inverse kinematics algorithm for the human arm is based on this result. 3 Manipulation Planner In this section we present our manipulation planning algorithm. <p> It is also known in neurophysiology that the arm posture for pointing is mainly determined by a simple sensorimotor transformation model. Soechting and Flanders <ref> [29, 30] </ref> conducted experiments where the test subject was instructed to move the end of a pen-sized stylus to various targets in their vicinity. <p> We use this model to determine the shoulder and elbow joint angles given the position of the hand. Then, determining the wrist joint angles is a simple additional step. 4.1 Arm posture Using the sensorimotor transformation model of Soechting and Flanders <ref> [29, 30] </ref> we determine the arm posture given the location of the hand. To explain their model we first define some generalized coordinates. ff R Denote the coordinate frame centered on the shoulder as the shoulder frame.
Reference: [30] <author> J.F. Soechting and M. Flanders, </author> <title> "Errors in Point--ing are Due to Approximations in Sensorimo-tor Transformations," </title> <journal> Journal of Neurophysiology, </journal> <volume> Vol. 62, No. 2, </volume> <year> 1989, </year> <month> pp.595-608. </month>
Reference-contexts: Thus, in addition to the planner, we present a new inverse kinematics algorithm for the human arms based on results from neurophysiology. This algorithm 1 resolves the redundancy of the human arms by utiliz-ing a sensorimotor transformation model <ref> [29, 30] </ref>. The result is the automatic animation of human arm manipulation tasks. In addition to the motion planning aspect, we address the issue of producing natural motions when human figures are animated. <p> Soechting [31] gives a good survey of various empirical studies and their results for human arm motions. One relevant finding is the sensorimotor transformation model devised by Soechting and Flanders <ref> [29, 30] </ref>. They found that the desired position of the hand roughly determines the arm posture. Our inverse kinematics algorithm for the human arm is based on this result. 3 Manipulation Planner In this section we present our manipulation planning algorithm. <p> It is also known in neurophysiology that the arm posture for pointing is mainly determined by a simple sensorimotor transformation model. Soechting and Flanders <ref> [29, 30] </ref> conducted experiments where the test subject was instructed to move the end of a pen-sized stylus to various targets in their vicinity. <p> We use this model to determine the shoulder and elbow joint angles given the position of the hand. Then, determining the wrist joint angles is a simple additional step. 4.1 Arm posture Using the sensorimotor transformation model of Soechting and Flanders <ref> [29, 30] </ref> we determine the arm posture given the location of the hand. To explain their model we first define some generalized coordinates. ff R Denote the coordinate frame centered on the shoulder as the shoulder frame.
Reference: [31] <author> J.F. Soechting, </author> <title> "Elements of Coordinated Arm Movements in Three-Dimensional Space," Perspectives on the Coordination of Movement, edited by S.A. Wallace, </title> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1989, </year> <month> pp.47-83. </month>
Reference-contexts: They utilize models to create realistic motions, however they do not consider complex manipulation motions. Neurophysiology: There are many scientists in psychology and neurophysiology working to determine how the human brain manages to coordinate the motion of its limbs. Soechting <ref> [31] </ref> gives a good survey of various empirical studies and their results for human arm motions. One relevant finding is the sensorimotor transformation model devised by Soechting and Flanders [29, 30]. They found that the desired position of the hand roughly determines the arm posture.
Reference: [32] <author> P. Tournassoud, T. Lozano-Perez, and E. Mazer, "Regrasping," </author> <booktitle> Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <address> Raleigh, NC, </address> <year> 1987, </year> <pages> pp. 1924-1928. </pages>
Reference-contexts: Regrasping is a vital component in manipulation tasks. Tournassoud, Lozano-Perez, and Mazer <ref> [32] </ref> specifically address this problem. They describe a method for planning a sequence of regrasp operations by a single arm to change an initial grasp into a goal grasp. At every regrasp, the object is temporarily placed on a horizontal table in a stable position selected by the planner.
Reference: [33] <author> B. Webber, N. Badler, F.B. Baldwin, W. Beck-ett, B. DiEugenio, C. Geib, M. Jung, L. Levin-son, M. Moore, and M. White, </author> <title> "Doing what you're told: following task instructions in changing, but hospitable environments," SIGGRAPH '93 Course note 80 "Recent Techniques in Human Modeling, Animation and Rendering", </title> <booktitle> 1993, </booktitle> <pages> pp. </pages> <month> 4.3-4.31. </month>
Reference-contexts: Essentially, they use a sequential search strategy to find a collision-free motion of the figure to a specified goal configuration. They do not consider manipulation or imposing naturalness on the motions. The AnimNL project at the University of Pennsyl-vania <ref> [33] </ref> is working to automate the generation of human figure movements from natural language instructions. Their focus is mainly on determining the sequence of primitive actions from a high-level description of the task. They utilize models to create realistic motions, however they do not consider complex manipulation motions.
Reference: [34] <author> G. Wilfong, </author> <title> "Motion Planning in the Presence of Movable Obstacles," </title> <booktitle> Proc. 4th ACM Symp. Computational Geometry, </booktitle> <year> 1988, </year> <pages> pp. 279-288. 12 </pages>
Reference-contexts: Manipulation Planning: The use of path planning to automatically generate graphic animation was already suggested in [18]. Research strictly addressing manipulation planning is fairly recent. The first paper to tackle this problem is by Wilfong <ref> [34] </ref>. It considers a single-body robot translating in a 2D workspace with multiple movable objects. The robot, the movable objects and obstacles are modelled as convex polygons. In order for the movable objects to reach their specified goal the robot must "grasp" and carry them there.
References-found: 34

