URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1206/CS-TR-94-1206.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1206/
Root-URL: http://www.cs.wisc.edu
Title: AUGMENTING DATABASES WITH GENERALIZED TRANSITIVE CLOSURE  
Author: by Shaul Dar 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1993  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [ADJ88a] <author> R. Agrawal, S. Dar and H. V. Jagadish, </author> <title> ``Transitive Closure Algorithms Revisited: The Case of Path Computations'', </title> <type> Technical Memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey, </address> <year> 1988. </year>
Reference-contexts: However, through some additional checking the iterative algorithms can be rendered terminating as well as discriminating <ref> [ADJ88a, KIC92] </ref>. If there is a (negative weight) cycle in a graph, than for every node on this cycle there must exist a non-null (negative weight) path to itself.
Reference: [ADJ88b] <author> R. Agrawal, S. Dar and H. V. Jagadish, </author> <title> ``On Transitive Closure Problems Involving Path Computations'', </title> <type> Technical Memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey, </address> <year> 1988. </year>
Reference-contexts: a set S of source nodes in by changing the initialization phase as follows: R f -t R 0 t. src S-; The resulting Semi-naive evaluation has also been called the d-Wavefront algorithm [QHK89]. 5.1.6 Generalized Transitive Closure To perform label computations, the Semi-naive algorithm can be generalized as follows <ref> [ADJ88b, CrN89] </ref>: 68 69 R D R 0 ; while (R f changes) - R D AGG (CON (R D ,R 0 ) ); - When the path problem is ordered, we can ignore a newly generated path when a better path has already been established and write [ADJ88b, CrN89]: R <p> as follows <ref> [ADJ88b, CrN89] </ref>: 68 69 R D R 0 ; while (R f changes) - R D AGG (CON (R D ,R 0 ) ); - When the path problem is ordered, we can ignore a newly generated path when a better path has already been established and write [ADJ88b, CrN89]: R f R 0 ; (* 2 *) while (R f changes) - R D AGG (CON (R D ,R 0 ) ) - R f ; - Where the subtraction is defined by S - T = -( x,y,L S ) S s. t. " / ( x,y,L
Reference: [AgJ90] <author> R. Agrawal and H. V. Jagadish, </author> <title> ``Hybrid Transitive Closure Algorithms'', </title> <booktitle> Proc. 16th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> The algorithm, referred to as the Grid algorithm in <ref> [AgJ90] </ref>, proceeds as follows: 75 76 Partition the matrix into f f square sub-matrices. <p> However, with the Grid algorithm, the block sizes must all be equal, and dynamic block sizing is difficult <ref> [AgJ90] </ref>. The determination of the size of each submatrix is conservative, and unless the submatrices do fill up, memory is underutilized. The only performance study of this algorithm, conducted in [AgJ90], found it to be inferior to the Hybrid algorithm. 5.3 Graph-Based Algorithms In this section, we study graph-based algorithms using <p> However, with the Grid algorithm, the block sizes must all be equal, and dynamic block sizing is difficult <ref> [AgJ90] </ref>. The determination of the size of each submatrix is conservative, and unless the submatrices do fill up, memory is underutilized. The only performance study of this algorithm, conducted in [AgJ90], found it to be inferior to the Hybrid algorithm. 5.3 Graph-Based Algorithms In this section, we study graph-based algorithms using the Purdom algorithm as the basis for our study. <p> By processing nodes in reverse topological order, one need add to a node only the successor lists of its immediate successors since the latter would already have been fully expanded. We call this idea the immediate successor optimization <ref> [AgJ90] </ref>. 2. All nodes within a strongly connected component (SCC) in a graph have identical reachability properties, and the condensation graph obtained by collapsing all the nodes in each strongly connected component into a single node is acyclic. Weaving these ideas together, Purdom proposed a four-phase algorithm: i. <p> The union of S j with S i is therefore redundant, and Ebert's algorithm avoids this union. This optimization was also utilized in [Sch83] and in several algorithms in <ref> [AgJ90, IRW] </ref>. <p> This optimization was also utilized in [Sch83] and in several algorithms in [AgJ90, IRW]. The latter algorithms mark those immediate successors of a node i that should not be processed, and we therefore refer to this technique as the marking optimization <ref> [AgJ90] </ref>. 17 5.3.4 The Goralcikova-Koubek Algorithm As Figure 5.2 demonstrates, whether the marking optimization may be applied to a particular arc from a node to its child, such as (i,j), depends on the relative order in which the children of the node (e.g., j and k) are visited. <p> In other words, if we remove from the original graph all marked arcs, we end up with the minimal graph that has an identical closure to the original graph. The combination of topological sort and the marking optimization was used, among others, in the Hybrid algorithm <ref> [AgJ90] </ref> and the BTC algorithm [IRW]. <p> They also compare the performance of the algorithms for a set of shortest path queries. 5.4 Hybrid Algorithms In this section, we study algorithms that use a hybrid or mixed approach. The algorithms presented below combine ideas from both matrix and graph-based algorithms 5.4.1 The Hybrid Algorithm In <ref> [AgJ90] </ref> it has been shown that if the nodes of a DAG are first sorted in reverse topological order, then a matrix-based computation of the closure is equivalent to a graph-based computation, and has the advantage that blocking can be used to reduce the I/O cost. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> The use of successor trees is a general technique that may be applied to different algorithms. The Spanning Tree transitive closure algorithm presented in [DaJ92] is a modification of the hybrid algorithm of <ref> [AgJ90] </ref>. A modification of the Semi-naive algorithm is presented in [Jak91]. A modification of Warshall's algorithm is developed in [Jak92]. <p> This observation lead to a uniform implementation framework, which highlights the relationship between the algorithms. The candidate algorithms are the following: The BTC algorithm [IRW] (see Section 5.3.6). The Hybrid algorithm <ref> [AgJ90] </ref> (see Section 5.4.1). The BFS algorithm [Jia90] (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm [DaJ92] (see Section 5.4.2). The Compute_Tree algorithm [Jak92] (see Section 5.4.3). This chapter is organized as follows. <p> The major difficulty with metrics using successor lists is that they are not uniform: successor lists of different nodes can have very different sizes, and the size of each successor list may change dramatically during the computation. 86 87 7. Tuple I/O <ref> [AgJ90, DaJ92] </ref>. <p> We denote our implementation of the BTC algorithm by BTC. 6.3.2 The Hybrid Algorithm In the Hybrid algorithm <ref> [AgJ90] </ref>, as in the Direct algorithms [ADJ90], successor lists are processed in blocks in order to take advantage of locality and reduce I/O (see Figure 5.1). Block sizes are determined by a parameter called ILIMIT. <p> If the memory is filled up during expansion, the current block size is decreased by discarding one or more pages from the current block (this is called dynamic blocking in <ref> [AgJ90, ADJ90] </ref>.) With a block size of 1, the Hybrid algorithm is essentially identical to the BTC algorithm, in spite of their different representation. Thus, we wanted to see what effect the extra dimension of blocking had on the performance of the algorithm. <p> Thus, we wanted to see what effect the extra dimension of blocking had on the performance of the algorithm. The implementation of the Hybrid algorithm in <ref> [AgJ90] </ref> maintained a copy of each (unexpanded) successor list in the current block, thus reducing the effective size of available memory. This was done in order to distinguish immediate and non-immediate successors to apply the immediate successor optimization. <p> This was done in order to distinguish immediate and non-immediate successors to apply the immediate successor optimization. This overhead is not necessary in our implementation the successor list structure distinguishes the two by negating the last immediate 91 92 successor, as illustrated in Figure 6.4. The algorithm presented in <ref> [AgJ90] </ref> is only applicable to acyclic graphs. After the initial topological sort, all the ``1'' values in the matrix are concentrated in the lower left half-matrix. The Hybrid algorithm only processed this half-matrix, i.e. it is a one-pass algorithm. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> The results of [ADJ90, AgJ87, KIC92] demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish <ref> [AgJ90] </ref> compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm [UlY90] and a DFS algorithm based on [IoR88] and extended with caching of successor lists. Tuple I/O was the performance metric. Hybrid was found to be the best performer. <p> The main results were that BFS was better than DFS for computing multi-source queries, and that the use of the single-parent optimization reduces the cost of the algorithms by avoiding both reads and unions of single-parent successor lists. Taken together, the results reported in <ref> [AgJ90, DaJ92, IRW, Jia90] </ref> clearly demonstrate that the graph-based algorithms and their hybrid variants are superior to the iterative and matrix-based algorithms, both for the computation of CTC and for the computation of PTC with low selectivity (large number of source nodes).
Reference: [AgK93] <author> R. Agrawal and G. Kiernan, </author> <title> ``An Access Structure for Generalized Transitive Closure Queries'', </title> <booktitle> Proc. IEEE 9th Int'l Conf. on Data Engineering, </booktitle> <address> Vienna, Austria, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [AgD89] <author> R. Agrawal and P. Devanbu, </author> <title> ``Moving Selections into Linear Least Fixpoint Queries'', </title> <journal> IEEE Trans. Knowledge and Data Engineering 1, </journal> <month> 4 (Dec. </month> <year> 1989), </year> <pages> 452-461. </pages> <booktitle> Also Proc. IEEE 4th Int'l Conf. Data Engineering (Feb. </booktitle> <year> 1988). </year>
Reference-contexts: The types of selections that can be pushed into a recursion have been characterized by Kifer and Lozinskii [KiL86], by Beeri et al [BKB90] and by Agrawal and Devanbu <ref> [AgD89] </ref>. A large body of knowledge was accumulated in recent years on general techniques for rewriting a collection of Datalog rules into an equivalent yet more efficient form.
Reference: [Agr87] <author> R. Agrawal, </author> <title> ``Alpha: An Extension of Relational Algebra to Express a Class of Recursive Queries'', </title> <booktitle> Proc. IEEE 3rd Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1987, </year> <pages> 580-590. </pages> <note> Also in IEEE Trans. </note> <institution> Software Eng. </institution> <month> 14, 7 (July </month> <year> 1988), </year> <pages> 879-885. </pages>
Reference-contexts: A transitive closure operator was also needed to traverse a shared (overlapping) hierarchy of objects. A QUEL extension utilizing both operators was presented. A later paper, [SHS87], generalized the transitive closure to an Alpha operator based on a <ref> [Agr87] </ref>. An SQL extension was illustrated by queries on different types of complex objects. However, neither the selections (r operator) nor the label computation capabilities (m list) of a are used. Thus, the expressive power of the operator is very limited.
Reference: [ADJ89] <author> R. Agrawal, S. Dar and H. V. Jagadish, </author> <title> ``Composition of Database Relations'', </title> <booktitle> Proc. IEEE 5th Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1989, </year> <pages> 102-109. </pages>
Reference-contexts: Graph-based algorithms are discussed in Section 5.3. In Section 5.4 we discuss hybrid algorithms which combine ideas from more than one of the other families. We should note that we have been involved in the design of the Direct algorithms, described in [ADJ90], the Single-Sided Composition algorithm, described in <ref> [ADJ89] </ref>, and the Spanning Tree algorithm, described in [DaJ92]. However, for the sake of uniformity, we do not discuss these works separately; rather, we present them as part of an overall survey of transitive closure algorithms for databases. Notation Let the input graph be G = (V,E). <p> Several variations on this basic iterative algorithm have been proposed in the literature <ref> [ADJ89, GKB87, Ioa86, Lu87, VaB86] </ref>, and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> Some systems (System R [Moh88] and Ingres [Sto88], for example) combine the first two steps and do projection at the same time as the join is being computed, but all the systems that we know of make a separate pass for removing duplicates. In <ref> [ADJ89] </ref>, Agrawal et al proposed an alternative composition method called single-sided composition, which performs join, projection, and duplicate elimination as one unified operation. The essential idea is as follows. Let R (A,B) and S (A,B) be the two relations to be composed. <p> The new tuples are guaranteed to fall into the T i bucket, and therefore duplicate elimination can be performed in memory. The tradeoff between the higher join cost and lower duplicate elimination cost is studied in <ref> [ADJ89] </ref>. Single-sided composition turns out to perform better than standard composition methods when the relations to be joined are such that the join result is many times larger than the source relations and many duplicates must be eliminated after projection over the non-join attributes.
Reference: [AgJ89] <author> R. Agrawal and H. V. Jagadish, </author> <title> ``Materialization and Incremental Update of Path Information'', </title> <booktitle> Proc. IEEE 5th Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [ABJ89] <author> R. Agrawal, A. Borgida and H. V. Jagadish, </author> <title> ``Efficient Management of Transitive Relationships in Large Data and Knowledge Bases'', </title> <booktitle> Proc. ACM-SIGMOD 1989 Int'l Conf. on Management of Data, </booktitle> <address> Portland, Oregon, </address> <month> May-June </month> <year> 1989. </year>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [ADJ90] <author> R. Agrawal, S. Dar and H. V. Jagadish, </author> <title> ``Direct Transitive Closure Algorithms: Design and Performance Evaluation'', </title> <journal> ACM Trans. Database Syst. </journal> <volume> 15, </volume> <month> 3 (Sep. </month> <year> 1990), </year> . <note> (Preliminary version appeared as: </note> <author> R. Agrawal and H.V. Jagadish, </author> <title> ``Direct Algorithms for Computing the Transitive Closure of Database Relations'', </title> <booktitle> Proc. 13th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brighton, England, </address> <month> Sept. </month> <year> 1987). </year>
Reference-contexts: Specific algorithms can be instantiated from algorithm 0 by choosing a specific priority policy. For example, the seminaive algorithm [Ban85] employs a BFS policy, the graph algorithms of [IRW] employ a DFS policy, and the direct algorithms of <ref> [ADJ90] </ref> employ a matrix ordering policy based on some numbering of the nodes in a graph. Algorithm 0 is meant to illustrate the optimization techniques that follow. Its generality is preserved in the refinements T, T pc , and T psc that are presented later in this chapter. <p> The refinements, and all optimizations discussed with respect to them, are equally applicable to all specific instantiations. In Section 4.4.4 we define two correctness criteria, completeness and irredundancy, for generalized transitive closure algorithms <ref> [ADJ90] </ref>. An algorithm is complete if it generates every path in the graph (implicitly or explicitly) at least once. An algorithm is irredundant if it generates every path in the graph at most once. <p> We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> Matrix-based algorithms are discussed in Section 5.2. Graph-based algorithms are discussed in Section 5.3. In Section 5.4 we discuss hybrid algorithms which combine ideas from more than one of the other families. We should note that we have been involved in the design of the Direct algorithms, described in <ref> [ADJ90] </ref>, the Single-Sided Composition algorithm, described in [ADJ89], and the Spanning Tree algorithm, described in [DaJ92]. However, for the sake of uniformity, we do not discuss these works separately; rather, we present them as part of an overall survey of transitive closure algorithms for databases. <p> This is typically the case when computing transitive closures of dense graphs. An implementation of Semi-naive based on single-sided composition was found to be better than the standard implementation for most input graphs in <ref> [ADJ90] </ref>. Implementations of the Semi-naive and logarithmic (Smart) algorithms, based on hash-join and single-sided compositions, were also explored in [KIC92]. <p> Yet, the locality of reference of the algorithm is still poor. A straightforward implementation of Warren's algorithm in [LM87] found that the algorithm did well (compared to iterative algorithms) only when the memory size was not much smaller than the final transitive closure size. 5.2.3 Warshall-Derived Algorithms In <ref> [ADJ90, AgJ87] </ref> the following observation was made. The order in which matrix elements are processed in Warshall's algorithm may be modified, provided that the following two constraints are satisfied: 1. For all i, j,k, processing of element (i,k) precedes processing of element (i, j) iff k &lt; j. 2. <p> The third constraint can be rewritten: (i, j) before (l,i) iff j &lt; i. But this constraint is the same as constraint 2 with appropriate substitution of variables. Therefore we need impose only the first two constraints. off-diagonal list diagonal lists Diagonal block Two Warshall-derived algorithms are presented in <ref> [ADJ90] </ref>. These are variations of the Warshall and Warren algorithms that use blocking to improve locality and reduce the I/O cost of computing the transitive closure. The basic idea is illustrated in Figure 5.1. <p> Figure 5.1 shows schematically an off-diagonal list that may be unioned with three diagonal lists. Thus, blocking allows several successor list unions to be performed at the cost of a single I/O. The performance studies in <ref> [ADJ90, KIC92] </ref> showed that the blocking algorithms generally performed much better than the iterative algorithms for the computation of the complete closure over a wide range of input graphs. __________________ 15. The case where j = k is not important since processing of ( j, j) does not affect anything. <p> The case where j = k is not important since processing of ( j, j) does not affect anything. As such, we have assumed jk in writing this constraint. 72 73 5.2.4 Partial Transitive Closure Matrix-based algorithms cannot handle selections on the source nodes efficiently <ref> [ADJ90, KIC92] </ref> since paths are extended at both ends. <p> Warshall-derived algorithms can be generalized in a similar fashion. A generalization of Warren's algorithm (in the relational form of [LM87]) is given in [CrN89], and generalizations of the blocking algorithms are given in <ref> [ADJ90] </ref>. 5.2.6 Completeness We establish the completeness of Warshall's algorithm using the sufficient condition given in the lemma below. <p> k = 1 to f * ; for j = 1 to f Ullman and Yannakakis show that, if the graph is dense, the closure computation incurs less I/O when the adjacency matrix is divided into squares than when it is divided into stripes, as in the blocking algorithms of <ref> [ADJ90] </ref>. However, with the Grid algorithm, the block sizes must all be equal, and dynamic block sizing is difficult [AgJ90]. The determination of the size of each submatrix is conservative, and unless the submatrices do fill up, memory is underutilized. <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> Page I/O [ADJ90, IRW, KIC92]. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly <ref> [ADJ90] </ref>, but it is sensitive to the workload of the system. Instead, the measured CPU time may be combined with an estimate of the I/O time given by the number of I/O's multiplied by the postulated cost of a single I/O [IRW, KIC92]. <p> In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor <ref> [ADJ90, IRW, KIC92] </ref>. Furthermore, a close correlation of the CPU and I/O curves was observed in [ADJ90]. This observation suggests that a large portion of the CPU cost was actually spent in processing the I/O subsystem calls, making the I/O cost even more pronouned. <p> In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor [ADJ90, IRW, KIC92]. Furthermore, a close correlation of the CPU and I/O curves was observed in <ref> [ADJ90] </ref>. This observation suggests that a large portion of the CPU cost was actually spent in processing the I/O subsystem calls, making the I/O cost even more pronouned. <p> We denote our implementation of the BTC algorithm by BTC. 6.3.2 The Hybrid Algorithm In the Hybrid algorithm [AgJ90], as in the Direct algorithms <ref> [ADJ90] </ref>, successor lists are processed in blocks in order to take advantage of locality and reduce I/O (see Figure 5.1). Block sizes are determined by a parameter called ILIMIT. <p> If the memory is filled up during expansion, the current block size is decreased by discarding one or more pages from the current block (this is called dynamic blocking in <ref> [AgJ90, ADJ90] </ref>.) With a block size of 1, the Hybrid algorithm is essentially identical to the BTC algorithm, in spite of their different representation. Thus, we wanted to see what effect the extra dimension of blocking had on the performance of the algorithm. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> fact, the algorithm performs best when no blocking is used, in which case it is identical to BTC. 0 10 20 30 40 50 Buffer Size 8000 10000 Total I/O BTC HYB-0.1 HYB-0.3 Blocking was found to be a useful technique for reducing I/O in the Direct algorithms presented in <ref> [ADJ90] </ref>. It is therefore surprising that blocking has a detrimental effect on the performance of the Hybrid algorithm. However, a closer look at the way that these algorithms utilize blocking explains the discrepancy. Consider Figure 5.1 again. <p> In Section 6.2 we reviewed many cost metrics that have been suggested in the literature for evaluating and comparing transitive closure algorithms. Since the computation of the transitive closure of a large graph is likely to be I/O bound (see e.g., <ref> [ADJ90, IRW, KIC92] </ref>), an important question to be asked is can cost metrics which count operations at the tuple or successor list level be used to estimate the I/O cost of a transitive closure computation? We believe that the results of Section 6.4 clearly demonstrate that such extrapolation is highly unreliable. <p> However, most previous performance investigations have involved a small set of algorithms and data sets, and only in a few studies were the algorithms actually implemented and the I/O cost directly measured. We review earlier performance studies below and briefly summarize their results. Agrawal et al <ref> [ADJ90, AgJ87] </ref> studied the Blocked Warshall (aka. Blocked Column) and Blocked Warren (aka. Blocked Row) Direct algorithms as well as an implementation of seminaive based on single-sided composition. They measured page I/O and elapsed time and found I/O to be the dominant cost factor. <p> They implemented the algorithms and measured page I/O and elapsed time. They found Seminaive to always outperform Smart. Blocked Warren was overall the best algorithm for CTC, but for PTC computation with less than 1/3 of the source nodes, Seminaive performed better. The results of <ref> [ADJ90, AgJ87, KIC92] </ref> demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm [UlY90] and a DFS algorithm based on [IoR88] <p> The results of [ADJ90, AgJ87, KIC92] demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm <ref> [ADJ90] </ref>, the Grid algorithm [UlY90] and a DFS algorithm based on [IoR88] and extended with caching of successor lists. Tuple I/O was the performance metric. Hybrid was found to be the best performer.
Reference: [AgJ87] <author> R. Agrawal and H. V. Jagadish, </author> <title> ``Direct Algorithms for Computing the Transitive Closure of Database Relations'', </title> <booktitle> Proc. 13th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brighton, England, </address> <month> Sept. </month> <year> 1987, </year> <pages> 255-266. </pages>
Reference-contexts: Yet, the locality of reference of the algorithm is still poor. A straightforward implementation of Warren's algorithm in [LM87] found that the algorithm did well (compared to iterative algorithms) only when the memory size was not much smaller than the final transitive closure size. 5.2.3 Warshall-Derived Algorithms In <ref> [ADJ90, AgJ87] </ref> the following observation was made. The order in which matrix elements are processed in Warshall's algorithm may be modified, provided that the following two constraints are satisfied: 1. For all i, j,k, processing of element (i,k) precedes processing of element (i, j) iff k &lt; j. 2. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> We experimented with boths DAGS and general (cyclic) graphs. For a DAG, arcs going out of a node are restricted to go to higher numbered nodes. Our usage of the locality parameter is similar to that of <ref> [AgJ87, IRW] </ref>. In a general graph, children of node i are in the range [i - l % n, i + l % n]. In a DAG, children of node i are in the range [i+1, min (i+l, n)]. <p> However, most previous performance investigations have involved a small set of algorithms and data sets, and only in a few studies were the algorithms actually implemented and the I/O cost directly measured. We review earlier performance studies below and briefly summarize their results. Agrawal et al <ref> [ADJ90, AgJ87] </ref> studied the Blocked Warshall (aka. Blocked Column) and Blocked Warren (aka. Blocked Row) Direct algorithms as well as an implementation of seminaive based on single-sided composition. They measured page I/O and elapsed time and found I/O to be the dominant cost factor. <p> They implemented the algorithms and measured page I/O and elapsed time. They found Seminaive to always outperform Smart. Blocked Warren was overall the best algorithm for CTC, but for PTC computation with less than 1/3 of the source nodes, Seminaive performed better. The results of <ref> [ADJ90, AgJ87, KIC92] </ref> demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm [UlY90] and a DFS algorithm based on [IoR88]
Reference: [AHU75] <author> A. V. Aho, E. Hopcroft and J. D. Ullman, </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1975. </year>
Reference-contexts: There exist binary functions BCON and BAGG such that for every path-set y, L ( y ) can be computed by BCON and BAGG, and BCON and BAGG form a path algebra (see Section 2.4, <ref> [AHU75] </ref>, [Car78]). 2. For every path-set y ( s , t ), the path-set label of y ( s , t ), can be computed as a function f of path-set labels L 1 , . . . , L n , which are all independently computable. Proof 1. <p> Proof 1. The proof of the first condition follows from <ref> [AHU75] </ref>. 2. Let y ( s , t ) and y ( t , w ) be two path-sets, and let y ( s , w ) = y ( s , t ) y ( t , w ). <p> Therefore, when expanding node i, node k will be considered before node j. This is the basis of the reduct and closure algorithm in [GoK79]. As shown in [GoK79, Jia90], the marking optimization on a topologically sorted graph is equivalent to a transitive reduction of the input graph <ref> [AHU75] </ref>. In other words, if we remove from the original graph all marked arcs, we end up with the minimal graph that has an identical closure to the original graph. <p> We assume that G has no duplicate arcs since such arcs are indistinguishable. Because G is a DAG, its transitive reduction is unique <ref> [AHU75] </ref>. This discussion motivates the following definition. Definitions (Redundant Arcs) Let G be a DAG, and let TR (G) be the transitive reduction of G. We say that an arc (i, j) G is redundant if (i, j) TR (G).
Reference: [AhU79] <author> A. V. Aho and J. D. Ullman, </author> <title> ``Universality of Data Retrieval Languages'', </title> <booktitle> Proc. 6th ACM Symp. Principles of Programming Languages, </booktitle> <address> San-Antonio, Texas, </address> <month> Jan. </month> <year> 1979, </year> <pages> 110-120. 117 118 </pages>
Reference-contexts: This definition guarantees that the final value obtained for each label L ( i , j ) does not take into account the same path multiple times. An example of a redundant algorithm is the naive algorithm <ref> [AhU79, Ban85] </ref>. In this algorithm, in each iteration, every path so far discovered is joined with the original relation, rather than using the paths newly discovered as in semi-naive (see Section 5.1.1 below). <p> For example, in a Datalog program for transitive closure, bindings may correspond to equality selections on the endpoints, on all arcs/nodes, or on consecutive arcs in the graph. For least fixed point recursions, Aho and Ullman <ref> [AhU79] </ref> gave a rule for moving selections into the iterative process of evaluating the solution. The types of selections that can be pushed into a recursion have been characterized by Kifer and Lozinskii [KiL86], by Beeri et al [BKB90] and by Agrawal and Devanbu [AgD89].
Reference: [AHB86] <author> P. M. G. Apers, M. A. W. Houtsma and F. Brandse, </author> <title> ``Extending a Relational Interface with Recursion'', </title> <booktitle> Proc. 6th Advanced Database Symposium, </booktitle> <address> Tokyo, Japan, </address> <month> Aug. </month> <year> 1986, </year> <pages> 159-166. </pages>
Reference: [BKM89] <author> I. Balbin, D. B. Kemp, K. Meenakshi and K. Ramamohanarao, </author> <title> ``Propagating Constraints in Recursive Deductive Databases'', </title> <booktitle> Proc. North American Conference on Logic Programming, </booktitle> <month> Oct. </month> <year> 1989, </year> <pages> 16-20. </pages>
Reference-contexts: In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see [RSS92, Ull89]). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. <ref> [BKM89, MFP90, SrRar] </ref>) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> C &lt;= 1000, and the recognition of monotonicity of derivations, e.g. that a fact path (x,y,c) where c &gt; 1000, cannot give rise, via rule QB2, to a new fact path (x ,y ,c ), such that c 1000. Constraint propagation has been studied, among others, in <ref> [BKM89, MFP90, SrRar] </ref>. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. <p> Constraint propagation has been studied, among others, in [BKM89, MFP90, SrRar]. Balbin et al <ref> [BKM89] </ref> push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm.
Reference: [BaR87] <author> I. Balbin and K. Ramamohanarao, </author> <title> ``A Generalization of the Differential Approach to Recursive Query Evaluation'', </title> <journal> Journal of Logic Programming 4, </journal> <month> 3 (Sep. </month> <year> 1987), </year> . 
Reference-contexts: In terms of the directed graph defined by R 0 , the Semi-naive algorithm <ref> [BaR87, Ban85, GKB87] </ref>, starting with paths of length one (i.e., length in number of arcs in the path), finds in each iteration new nodes that can be reached through paths that are one longer than in the previous iteration: R f R 0 ; while (R D f) - R D
Reference: [BaR] <author> F. Bancilhon and R. Ramakrishnan, </author> <title> ``Performance Evaluation of Data Intensive Logic Programs'', in Foundations of Deductive Databases and Logic Programming, </title> <editor> J. Minker (ed.), </editor> <publisher> Morgan Kaufman, . to appear. </publisher>
Reference-contexts: Since, for each path, the last arc is unique and the path obtained by removing the last arc is unique, each path is generated only once. This irredundant property has been proved for the Semi-naive algorithm in <ref> [BaR] </ref> under the name of optimality. 5.1.9 Error Handling Given an ill-defined problem, such as a bill-of-materials query on a cyclic graph or a shortest path query on a graph with negative weight cycles, the Semi-naive algorithm (and other iterative algorithms) may not terminate.
Reference: [Ban85] <author> F. Bancilhon, </author> <title> ``Naive Evaluation of Recursively Defined Relations'', in On Knowledge Base Management Systems Integrating Database and AI Systems, </title> <editor> M. Brodie and J. Mysopoulos (ed.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: In particular, we have left open the question of which path from OPEN should be extended next. Specific algorithms can be instantiated from algorithm 0 by choosing a specific priority policy. For example, the seminaive algorithm <ref> [Ban85] </ref> employs a BFS policy, the graph algorithms of [IRW] employ a DFS policy, and the direct algorithms of [ADJ90] employ a matrix ordering policy based on some numbering of the nodes in a graph. Algorithm 0 is meant to illustrate the optimization techniques that follow. <p> This definition guarantees that the final value obtained for each label L ( i , j ) does not take into account the same path multiple times. An example of a redundant algorithm is the naive algorithm <ref> [AhU79, Ban85] </ref>. In this algorithm, in each iteration, every path so far discovered is joined with the original relation, rather than using the paths newly discovered as in semi-naive (see Section 5.1.1 below). <p> In terms of the directed graph defined by R 0 , the Semi-naive algorithm <ref> [BaR87, Ban85, GKB87] </ref>, starting with paths of length one (i.e., length in number of arcs in the path), finds in each iteration new nodes that can be reached through paths that are one longer than in the previous iteration: R f R 0 ; while (R D f) - R D <p> Theorem 5.2 Warshall's algorithm is irredundant. __________________ 16. The touch-once property corresponds to duplicate free execution in <ref> [Ban85] </ref>. 74 75 Proof Suppose that Warshall's algorithm generates the same path P (i, j) twice. Assume k and l were the two generators. Clearly Warshall's algorithm has the touch-once property since each matrix element is processed exactly once. Therefore it must be the case that kl.
Reference: [BeR87] <author> C. Beeri and R. Ramakrishnan, </author> <title> ``On the Power of Magic'', </title> <booktitle> Proc. 6th Symp. Principles of Database Systems, </booktitle> <address> San Diego, California, </address> <month> March </month> <year> 1987, </year> <pages> 269-283. </pages>
Reference-contexts: However, the number of operations may also be measured on actual input graphs [Sch83]. In either case, this measure is most useful when the computation is memory resident since it does not take I/O into account. 2. Number of deductions <ref> [BeR87, Jak91, Jak92, NRS89] </ref>. This is a standard metric in recursive query processing. In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived [MuP91].
Reference: [BKB90] <author> C. Beeri, P. Kanellakis, F. Bancilhon and R. Ramakrishnan, </author> <title> ``Bounds on the Propagation of Selection into Logic Programs'', </title> <journal> J. Computer and System Sciences 41, </journal> <month> 2 (October </month> <year> 1990), </year> <pages> 157-180. </pages> <note> (Preliminary version appeared as: </note> <author> C. Beeri, P. Kanellakis, F. Bancilhon and R. </author> <title> Ramakrishnan ``Bounds on the Propagation of Selection into Logic Programs'', </title> <booktitle> Proc. 6th Symp. Principles of Database Systems, </booktitle> <address> San Diego, California, </address> <year> 1987). </year>
Reference-contexts: For least fixed point recursions, Aho and Ullman [AhU79] gave a rule for moving selections into the iterative process of evaluating the solution. The types of selections that can be pushed into a recursion have been characterized by Kifer and Lozinskii [KiL86], by Beeri et al <ref> [BKB90] </ref> and by Agrawal and Devanbu [AgD89]. A large body of knowledge was accumulated in recent years on general techniques for rewriting a collection of Datalog rules into an equivalent yet more efficient form.
Reference: [Bel58] <author> R. E. Bellman, </author> <title> ``On a Routing Problem'', </title> <journal> Quart. Appl. Math. </journal> <volume> 16, </volume> <year> (1958), </year> <pages> 87-90. </pages>
Reference-contexts: By Bellman's principle of optimality <ref> [Bel58] </ref>, the path P ( s ,... , t ) is a best path from s to t, and L ( s , w ) = BCON ( L ( s , t ) , L ( t , w ) ).
Reference: [Car78] <author> B. Carre, </author> <title> Graphs and Networks, </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1978. </year>
Reference-contexts: There exist binary functions BCON and BAGG such that for every path-set y, L ( y ) can be computed by BCON and BAGG, and BCON and BAGG form a path algebra (see Section 2.4, [AHU75], <ref> [Car78] </ref>). 2. For every path-set y ( s , t ), the path-set label of y ( s , t ), can be computed as a function f of path-set labels L 1 , . . . , L n , which are all independently computable. Proof 1.
Reference: [ChH91] <author> J. Cheiney and Y. Huang, </author> <title> ``Efficient Maintenance of Explicit Transitive Closures with Set-Oriented Update Propagation and Parallel Processing'', </title> <type> Tech. Report, </type> <institution> Ecole Nationale Superieure des Telecommunications, Paris, </institution> <year> 1991. </year>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [CoM90] <author> M. P. Consens and A. O. Mendelzon, </author> <title> ``GraphLog: a Visual Formalism for Real Life Recursion'', </title> <booktitle> Proc. 9th Symp. Principles of Database Systems, </booktitle> <year> 1990, </year> <pages> 404-416. </pages>
Reference: [CoW87] <author> D. Coopersmith and S. Winograd, </author> <title> ``Matrix Multiplication via Arithmetic Progressions'', </title> <booktitle> Proceedings of the 19th ACM Symposium on the Theory of Computing, </booktitle> <year> 1987, </year> <pages> 1-6. </pages>
Reference-contexts: It is evident that this algorithm does not examine every path and hence it is not complete. Consequently, Schnorr's transitive closure algorithm cannot be generalized to perform path computations. 56 Algorithms that are based on fast matrix-multiplication (e.g. <ref> [CoW87] </ref>) are also incomplete. An important class of incomplete algorithms that we describe in Section 5.2.3 are those algorithms that determine reachability by collapsing strongly connected components and computing the closure of the resulting condensation graph.
Reference: [CMW86] <author> I. F. Cruz, A. O. Mendelzon and P. T. Wood, </author> <title> ``A Graphical Query Language Supporting Recursion'', </title> <booktitle> Proc. ACM SIGMOD Conf. on Management of Data, </booktitle> <year> 1986, </year> <pages> 16-52. </pages>
Reference: [CMW88] <author> I. F. Cruz, A. O. Mendelzon and P. T. Wood, ``G+: </author> <title> Recursive Queries Without Recursion'', </title> <booktitle> Proc. 2nd Int'l Conf. Expert Database Systems, </booktitle> <year> 1988, </year> <pages> 355-368. </pages>
Reference-contexts: Yet, it seems that a graphical interface such as G+ <ref> [CMW88] </ref> would be more effective for that purpose.
Reference: [CrN89] <author> I. F. Cruz and T. S. Norvell, </author> <title> ``Aggregative Closure: An Extension of Transitive Closure'', </title> <booktitle> Proc. IEEE 5th Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1989, </year> <pages> 384-393. 118 119 </pages>
Reference-contexts: We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> Special optimizations for maximizing path algebras have been suggested in <ref> [CrN89, GGZ91, SuR91] </ref>. Cruz and Norvell [CrN89] gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. [GGZ91] presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan [SuR91] approached extremal aggregates using the notion of relevance. <p> Special optimizations for maximizing path algebras have been suggested in [CrN89, GGZ91, SuR91]. Cruz and Norvell <ref> [CrN89] </ref> gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. [GGZ91] presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan [SuR91] approached extremal aggregates using the notion of relevance. <p> not be able to fit even one successor list into memory, while if M n 2 , the computation of the transitive closure can be done completely in memory. 66 67 In the worst case, the Semi-naive algorithm requires d iterations, and therefore its complexity is O (n 3 d) <ref> [CrN89] </ref>. Several variations on this basic iterative algorithm have been proposed in the literature [ADJ89, GKB87, Ioa86, Lu87, VaB86], and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. <p> a set S of source nodes in by changing the initialization phase as follows: R f -t R 0 t. src S-; The resulting Semi-naive evaluation has also been called the d-Wavefront algorithm [QHK89]. 5.1.6 Generalized Transitive Closure To perform label computations, the Semi-naive algorithm can be generalized as follows <ref> [ADJ88b, CrN89] </ref>: 68 69 R D R 0 ; while (R f changes) - R D AGG (CON (R D ,R 0 ) ); - When the path problem is ordered, we can ignore a newly generated path when a better path has already been established and write [ADJ88b, CrN89]: R <p> as follows <ref> [ADJ88b, CrN89] </ref>: 68 69 R D R 0 ; while (R f changes) - R D AGG (CON (R D ,R 0 ) ); - When the path problem is ordered, we can ignore a newly generated path when a better path has already been established and write [ADJ88b, CrN89]: R f R 0 ; (* 2 *) while (R f changes) - R D AGG (CON (R D ,R 0 ) ) - R f ; - Where the subtraction is defined by S - T = -( x,y,L S ) S s. t. " / ( x,y,L <p> - R f ; - Where the subtraction is defined by S - T = -( x,y,L S ) S s. t. " / ( x,y,L T ) T L T L S - A generalization, similar to (* 1 *), of the logarithmic algorithm [Ioa86, VaB86] is given in <ref> [CrN89] </ref>. 5.1.7 Completeness The Semi-naive algorithm, as generalized in (* 1 *), is complete. Each arc in R 0 represents a path of length 1 and is included in R f . <p> Warshall-derived algorithms can be generalized in a similar fashion. A generalization of Warren's algorithm (in the relational form of [LM87]) is given in <ref> [CrN89] </ref>, and generalizations of the blocking algorithms are given in [ADJ90]. 5.2.6 Completeness We establish the completeness of Warshall's algorithm using the sufficient condition given in the lemma below.
Reference: [DaA] <author> S. Dar and R. Agrawal, </author> <title> ``Extending SQL with Generalized Transitive Closure'', </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> . <note> to appear. </note>
Reference: [DAJ91] <author> S. Dar, R. Agrawal and H. V. Jagadish, </author> <title> ``Optimization of Generalized Transitive Closure Queries'', </title> <booktitle> Proc. IEEE 7th Int'l Conf. Data Engineering, </booktitle> <address> Tokyo, Japan, </address> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Our notation preserves the spirit of SQL, and allows a declarative and concise formulation of transitive closure queries. 34 35 Chapter 4 Query Optimization In this chapter we develop a framework for optimization of generalized transitive closure queries <ref> [DAJ91] </ref>. The framework demonstrates, in an algorithm -independent fashion, how the various selections and label computations presented in Chapter 2 may be efficiently evaluated. The chapter is organized as follows.
Reference: [DaJ92] <author> S. Dar and H. V. Jagadish, </author> <title> ``A Spanning Tree Transitive Closure Algorithm'', </title> <booktitle> IEEE 8th Int'l Conf. on Data Engineering, </booktitle> <address> Phoenix, Arizona, </address> <month> Feb. </month> <year> 1992, </year> <pages> 2-11. </pages>
Reference-contexts: We should note that we have been involved in the design of the Direct algorithms, described in [ADJ90], the Single-Sided Composition algorithm, described in [ADJ89], and the Spanning Tree algorithm, described in <ref> [DaJ92] </ref>. However, for the sake of uniformity, we do not discuss these works separately; rather, we present them as part of an overall survey of transitive closure algorithms for databases. Notation Let the input graph be G = (V,E). <p> We describe the Hybrid algorithm in more detail in Chapter 6. 81 82 5.4.2 Tree-Based Algorithms All of the matrix and graph-based algorithms mentioned so far use the successor list of a node as the basic unit of storage and manipulation. Jakobsson [Jak91] and Dar and Jagadish <ref> [DaJ92] </ref> independently observed that the use of successor lists can result in redundant work and in unnecessary I/O, and that this extra work can be avoided if successor spanning trees are used instead of ``flat'' successor lists. <p> The use of successor trees is a general technique that may be applied to different algorithms. The Spanning Tree transitive closure algorithm presented in <ref> [DaJ92] </ref> is a modification of the hybrid algorithm of [AgJ90]. A modification of the Semi-naive algorithm is presented in [Jak91]. A modification of Warshall's algorithm is developed in [Jak92]. <p> 83 i a c x y z ii j investigate the performance of two spanning tree algorithms: an adaptation of the BTC algorithm of [IRW], and an algorithm using predecessor trees presented in [Jak92] and described in the next subsection. 5.4.3 Partial Transitive Closure The spanning tree algorithms presented in <ref> [DaJ92] </ref> and [Jak91] handle selections in the same fashion as the successor list algorithms that they are based on. In [Jak92], Jakobsson presents a spanning tree algorithm tailored to partial transitive closure. <p> to node k but not with respect to node j (assuming as we did that the arc (j,f) is processed before the arc (j,g)). a f e g b a a b k We will study the Compute_Tree algorithm in more detail in Chapter 6. 5.4.4 Generalized Transitive Closure In <ref> [DaJ92] </ref> Dar and Jagadish present a generalization of the Spanning Tree algorithm for path problems. <p> The candidate algorithms are the following: The BTC algorithm [IRW] (see Section 5.3.6). The Hybrid algorithm [AgJ90] (see Section 5.4.1). The BFS algorithm [Jia90] (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm <ref> [DaJ92] </ref> (see Section 5.4.2). The Compute_Tree algorithm [Jak92] (see Section 5.4.3). This chapter is organized as follows. In Section 6.1 we review the cost models that have been used in previous studies of transitive closure and recursion in databases, and motivate our choice of performance metrics. <p> The major difficulty with metrics using successor lists is that they are not uniform: successor lists of different nodes can have very different sizes, and the size of each successor list may change dramatically during the computation. 86 87 7. Tuple I/O <ref> [AgJ90, DaJ92] </ref>. <p> As in the preprocessing phase for the other algorithms, the buffer pool is managed using the LRU policy. We denote our implementation of the Search algorithm by SRCH. 6.3.5 The Spanning Tree Algorithm In <ref> [DaJ92] </ref>, a Spanning Tree algorithm was presented that was based on the Hybrid algorithm. But the idea of using successor spanning trees instead of flat successor lists is general, and can be applied to other algorithms as well. We have implemented the Spanning Tree algorithm as a modification of BTC. <p> But the idea of using successor spanning trees instead of flat successor lists is general, and can be applied to other algorithms as well. We have implemented the Spanning Tree algorithm as a modification of BTC. The implementation in <ref> [DaJ92] </ref> used an extra column to store the derivation information. Thus, a tuple of the form (x, y, z) would represent an arc from y to z in the spanning tree of x (we say that y is the parent of z). <p> Thus, a tuple of the form (x, y, z) would represent an arc from y to z in the spanning tree of x (we say that y is the parent of z). The extra column was reflected in the performance evaluation of <ref> [DaJ92] </ref>, which penalized the Spanning Tree algorithm by giving it 2/3 of the memory available to the other algorithms. With the restructuring of successor tuples into successor lists in memory, it is no longer necessary to store the value of x. <p> We present results of experiments involving acyclic graphs only, for the following reasons. First, several of the algorithms that we study are only applicable to acyclic graphs (e.g. <ref> [DaJ92, Jak92] </ref>). Second, for reachability queries, the closure of a cyclic graph can be computed using the Purdom algorithm [Pur70] by collapsing strongly connected components and computing the closure of the resulting acyclic condensation graph. <p> It performed better than DFS due to the use of blocking, and it did better than the Grid algorithm because in the latter the block sizes cannot be determined dynamically, and memory is thus underutilized. Dar and Jagadish <ref> [DaJ92] </ref> compared the Spanning Tree algorithm to the Hybrid algorithm. Tuple I/O was the performance metric. The Spanning Tree algorithm, although it was penalized via a 50% overhead for storing the tree structure, still outperformed Hybrid, since its selective union of successor trees avoids redundant tuple reads. <p> The main results were that BFS was better than DFS for computing multi-source queries, and that the use of the single-parent optimization reduces the cost of the algorithms by avoiding both reads and unions of single-parent successor lists. Taken together, the results reported in <ref> [AgJ90, DaJ92, IRW, Jia90] </ref> clearly demonstrate that the graph-based algorithms and their hybrid variants are superior to the iterative and matrix-based algorithms, both for the computation of CTC and for the computation of PTC with low selectivity (large number of source nodes).
Reference: [DaS85] <author> U. Dayal and J. M. Smith, </author> <title> ``PROBE: A Knowledge-Oriented Database Management System'', </title> <booktitle> Proc. Islamorada Workshop on Large Scale Knowledge Base and Reasoning Systems, </booktitle> <address> Islamorada, Florida, </address> <month> Feb. </month> <year> 1985, </year> <pages> 103-137. </pages>
Reference: [DKO84] <author> D. J. DeWitt, R. Katz, F. Olken, D. Shapiro, M. Stonebraker and D. Wood, </author> <title> ``Implementation Techniques for Main Memory Database Systems'', </title> <booktitle> Proc. ACM-SIGMOD 1984 Int'l Conf. on Management of Data, </booktitle> <address> Boston, Mass., </address> <month> June </month> <year> 1984, </year> <pages> 1-8. </pages>
Reference-contexts: In addition, the Semi-naive algorithm can handle selection on source nodes, which the logarithmic algorithms cannot handle efficiently. 5.1.3 Lu's Algorithm Lu's HYBRIDTC algorithm [Lu87] is essentially an implementation of the Semi-naive algorithm based on hash-join <ref> [DKO84] </ref>. The algorithm employs two optimizations: (a) at the end of each iteration, tuples in R 0 that will not be needed later on are deleted, and (b) new tuples that fall into the current hash bucket are processed immediately.
Reference: [Dij59] <author> E. W. Dijkstra, </author> <title> ``A Note on Two Problems in Connection with Graphs'', </title> <journal> Numer. Math. </journal> <volume> 1, </volume> <year> (1959), </year> <pages> 269-271. </pages>
Reference-contexts: Therefore, OPEN will only contain path-set condensations emanating from the source nodes in S. In particular, for the special case of single-source shortest path, algorithm T max is essentially Dijkstra's algorithm <ref> [Dij59] </ref>. 4.4.6 Path-Set Selection (d) Assume that associated with the label aggregation function AGG is a partitioning expression Z, and a path-set selection predicate d is used to select the desired partitions. Let the aggregate (path-set) label attribute defined by AGG be PSL. <p> For reachablity, search algorithms based on BFS and on DFS are given in [Jia90]. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next <ref> [Dij59] </ref>. Variations of this algorithm can be found, in [GGZ91, IRW, Jia92, SuR91]. 5.3.10 Generalized Transitive Closure Algorithms that compute transitive closure using the condensation graph are not complete, and cannot be directly adapted for generalized transitive closure computation.
Reference: [Ebe81] <author> J. Ebert, </author> <title> ``A Sensitive Transitive Closure Algorithm'', </title> <journal> Information Processing Letters 12, </journal> <year> (1981), </year> <pages> 255-258. </pages>
Reference-contexts: This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> When the successor list of the root is fully expanded, it can be distributed to all the members of the SCC. 5.3.3 The Ebert Algorithm Ebert <ref> [Ebe81] </ref> observed that sometimes there is no need to add to a node i the successors of its child j. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case. <p> The graph-based algorithms were superior over all input graphs, with an order of magnitude difference for cyclic graphs. Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert <ref> [Ebe81] </ref>, two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own [Jia90, Jia90]. The two performance metrics were the number of successor list reads and the number of successor list unions.
Reference: [Eng87] <author> R. W. Engles, </author> <title> ``Structured Tables'', ANSI X3H2-87-331, </title> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: We feel that this parameter is arbitrary and difficult to set intelligently. It will be better to limit the depth of the recursion, that is, the maximum length of any path. Indeed, <ref> [Eng87] </ref> proposes a current-depth (``current-level'') register for that purpose. Our approach does not require the introduction of any new constructs. It takes advantage of the fact that PATH is a relation, and its cardinality is the length of the corresponding path. <p> Such a TIMEOUT mechanism, however, should be available for any query and not limited just to CLOSURE queries. 3.4.1.2 Search Order In <ref> [Eng87] </ref> and [Sha88], a SEARCH clause is proposed that allows the user to specify the search order as either depth-first, breadth-first or user-defined. The presumed purpose of the search order specification is to allow the user to extract structural information about the underlying graph. <p> The presumed purpose of the search order specification is to allow the user to extract structural information about the underlying graph. This is done by introducing generated ``structural'' attributes `TREE', `NODE' and `LEVEL' in <ref> [Eng87] </ref>, and `PARENT' and `NODE' in [Sha88]. The `LEVEL' attribute specifies the distance, in number of arcs, between the given node and the root node for this query. Its value is independent of the search order. <p> Its value is independent of the search order. The `TREE', `PARENT' and `NODE' attributes assign numbers to nodes according to the search strategy indicated in the search clause. For example, a node can be identified as the 4th node in the 2nd tree in <ref> [Eng87] </ref>, or as node 12 with parent node 5 in [Sha88]. So-called ``structural'' information, by its nature, should presumably be independent of the order in which the underlying graph was traversed. But the above ``structural'' attributes have different values when different search orders are used. <p> In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view.
Reference: [EvK77] <author> J. Eve and R. Kurki-Suonio, </author> <title> ``On Computing the Transitive Closure of a Relation'', </title> <journal> Acta Informatica 8, </journal> <year> (1977), </year> <pages> 303-314. </pages>
Reference-contexts: This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio <ref> [EvK77] </ref> observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining Purdom's phases 1-2 with 3-4 and producing a single phase algorithm. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case. <p> The graph-based algorithms were superior over all input graphs, with an order of magnitude difference for cyclic graphs. Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio <ref> [EvK77] </ref>, Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own [Jia90, Jia90]. The two performance metrics were the number of successor list reads and the number of successor list unions.
Reference: [Flo62] <author> R. W. Floyd, </author> <title> ``Algorithm 97: Shortest Path'', </title> <journal> Commun. ACM 5, </journal> <volume> 6 (1962), </volume> <pages> 345. </pages>
Reference-contexts: Floyd's shortest path algorithm <ref> [Flo62] </ref> is a special case of the above generalization of Warshall's algorithm for the shortest path problem, with CON being addition and AGG being the min function. Warshall-derived algorithms can be generalized in a similar fashion.
Reference: [GKS91] <author> S. Ganguly, R. Krishnamurthy and A. Silberschatz, </author> <title> ``An Analysis Technique for Transitive Closure Algorithms: A Statistical Approach'', </title> <booktitle> Proc. IEEE 7th Int'l Conf. Data Engineering, </booktitle> <address> Tokyo, Japan, </address> <month> Feb. </month> <year> 1991, </year> <pages> 728-735. </pages>
Reference-contexts: A similar test for the distribution of the closure size in general graphs with respect to the average out degree is reported in <ref> [GKS91] </ref>. 6.4.3 Derived Graph Parameters Several statistics about the input graph (or, in case of selection, the magic graph) are collected as the graph is being scanned during the restructuring phase. Some of these statistics are trivial and need not be discussed in detail. <p> Second, for reachability queries, the closure of a cyclic graph can be computed using the Purdom algorithm [Pur70] by collapsing strongly connected components and computing the closure of the resulting acyclic condensation graph. This technique has been shown to be a strong optimization (see e.g. <ref> [GKS91] </ref>) and is used by all of the algorithms that we study except the Search algorithm. Third, random graphs generated with an out degree greater than 1 tend to have most nodes concentrated in one large strongly connected component (see [Kar90, SeN91]).
Reference: [GGZ91] <author> S. Ganguly, S. Greco and C. Zaniolo, </author> <title> ``Minimum and Maximum Predicates in Logic Programming'', </title> <booktitle> Proc. 10th Symp. Principles of Database Systems, </booktitle> <address> Denver, Colorado, </address> <month> May </month> <year> 1991, </year> <pages> 154-163. </pages>
Reference-contexts: More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. <ref> [GGZ91, MPR90, RoS92, SuR91] </ref>). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in <ref> [GGZ91, MPR90, RoS92, Sri93, SuR91] </ref>. In [MPR90] a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. <p> A program is monotonic if it comprises only monotonic rules. Ganguly et al. <ref> [GGZ91] </ref> generalized Datalog semantics for programs involving min or max aggregation by stipulating that each fact has an associated cost given by the value of the aggregated variable (in our terminology, its label). <p> They define a class of cost-monotonic min or max programs and provide semantics for it by transforming each subgoal involving aggregation into an equivalent one using negation. Ross and Sagiv [RoS92] provide a more general definition of monotonicity that combines the monotonicity of [MPR90] with the cost-monotonicity of <ref> [GGZ91] </ref>: a rule is monotonic if adding new facts to a subgoal, or increasing the cost of previously derived facts, can only add new facts to the head of the rule, or increase the cost of previously derived facts. <p> Yet it is possible to give semantics to program PC' based on monotonicity, as we discussed above <ref> [GGZ91, RoS92, SuR91] </ref>. 63 However, the idea behind the transformation from program PC to program PC' is applicable to more than just maximizing path problems. <p> Special optimizations for maximizing path algebras have been suggested in <ref> [CrN89, GGZ91, SuR91] </ref>. Cruz and Norvell [CrN89] gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. [GGZ91] presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan [SuR91] approached extremal aggregates using the notion of relevance. <p> Special optimizations for maximizing path algebras have been suggested in [CrN89, GGZ91, SuR91]. Cruz and Norvell [CrN89] gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. <ref> [GGZ91] </ref> presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan [SuR91] approached extremal aggregates using the notion of relevance. Essentially, facts that are non-maximal are not relevant (useful) to the evaluation of the query, and may be ignored. <p> For reachablity, search algorithms based on BFS and on DFS are given in [Jia90]. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. Variations of this algorithm can be found, in <ref> [GGZ91, IRW, Jia92, SuR91] </ref>. 5.3.10 Generalized Transitive Closure Algorithms that compute transitive closure using the condensation graph are not complete, and cannot be directly adapted for generalized transitive closure computation.
Reference: [Gel92] <author> A. V. Gelder, </author> <title> ``The Well-Founded Semantics of Aggregation'', </title> <booktitle> Proc. 11th Symp. Principles of Database Systems, </booktitle> <address> San Diego, California, </address> <month> June, </month> <year> 1992, </year> <pages> 127-138. </pages>
Reference-contexts: But, assuming that the underlying graph represented by relation assembly is acyclic, it is possible to give semantics to program PD' based on modular stratification (see e.g. <ref> [Gel92, Ros90, SSR93] </ref>) since the derivation of a specific fact for predicate contains will not depend on the same fact.
Reference: [GoK79] <author> A. Goralcikova and V. </author> <title> Koubek, ``A Reduct and Closure Algorithm for Graphs.'', </title> <booktitle> Proceedings of the Int'l Conf. on Mathematical Foundations of Computer Science, </booktitle> <year> 1979, </year> <pages> 301-307. </pages>
Reference-contexts: This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> For example, in Figure 5.2, i j k, as indicated by the topological sort rank next to each node. Therefore, when expanding node i, node k will be considered before node j. This is the basis of the reduct and closure algorithm in <ref> [GoK79] </ref>. As shown in [GoK79, Jia90], the marking optimization on a topologically sorted graph is equivalent to a transitive reduction of the input graph [AHU75]. <p> For example, in Figure 5.2, i j k, as indicated by the topological sort rank next to each node. Therefore, when expanding node i, node k will be considered before node j. This is the basis of the reduct and closure algorithm in [GoK79]. As shown in <ref> [GoK79, Jia90] </ref>, the marking optimization on a topologically sorted graph is equivalent to a transitive reduction of the input graph [AHU75]. In other words, if we remove from the original graph all marked arcs, we end up with the minimal graph that has an identical closure to the original graph.
Reference: [Gua90] <author> G. V. Guaardalben, </author> <title> ``The Transitive Closure and the Probabilistic Relational Data Model'', </title> <type> Unpublished Manuscript, </type> <year> 1990. </year>
Reference: [GuY] <author> K. Guh and C. T. Yu, </author> <title> ``Efficient Management of Materialized Transitive Closure in Centralized and Parallel Environments'', </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> . <note> to appear. 119 120 </note>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [GKB87] <author> U. Guntzer, W. Kiessling and R. Bayer, </author> <title> ``On the Evaluation of Recursion in Deductive Database Systems by Efficient Differential Fixpoint Iteration'', </title> <booktitle> Proc. IEEE 3rd Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1987, </year> <pages> 120-129. </pages>
Reference-contexts: In terms of the directed graph defined by R 0 , the Semi-naive algorithm <ref> [BaR87, Ban85, GKB87] </ref>, starting with paths of length one (i.e., length in number of arcs in the path), finds in each iteration new nodes that can be reached through paths that are one longer than in the previous iteration: R f R 0 ; while (R D f) - R D <p> Several variations on this basic iterative algorithm have been proposed in the literature <ref> [ADJ89, GKB87, Ioa86, Lu87, VaB86] </ref>, and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> These result tuples can be processed in the same iteration, instead of writing them to disk and then reading them again in the next iteration. This sort of ``pushy'' <ref> [GKB87] </ref> or ``immediate'' processing has been explored in [KIC92].
Reference: [HMM87] <author> T. Harder, K. Meyer-Wegener, P. B. Mitschang and A. Sikeler, </author> <title> ``PRIMA - a DBMS Prototype Supporting Engineering Applications'', </title> <booktitle> Proc. 13th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brighton, England, </address> <month> Sept. </month> <year> 1987, </year> <pages> 433-442. </pages>
Reference-contexts: Formulation of transitive closure queries is also possible in MQL, an extension of SQL to support the Molecule-Atom data model (MAD) <ref> [HMM87, Mit89] </ref>. The closure relationship is embedded in the data model, using the concept of association. Thus a recursive query looks like a regular query on a previously defined recursive structure.
Reference: [HSS87] <author> M. Hardwick, G. Samaras and D. L. Spooner, </author> <title> ``Evaluating Recursive Queries in CAD Using an Extended Projection Function.'', </title> <booktitle> Proc. IEEE 3rd Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1987, </year> <month> 138-149.. </month>
Reference-contexts: Queries against the path view utilize the special cursor functions FIRST, LAST, SOME and ALL-IN-BETWEEN to access the embedded path structure. Compared to this proposal, SQL/TC is a simpler extension to SQL and allows queries to be expressed more compactly. In <ref> [HSS87] </ref>, an extended projection operator was introduced. Its functionality is similar to transitive closure, but limited to traversal of a disjoint hierarchical structure with instantiated roots (selection on start nodes). A transitive closure operator was also needed to traverse a shared (overlapping) hierarchy of objects.
Reference: [HoK80] <author> J. Hong and H. Kung, </author> <title> ``The Red-Blue Pebble Game'', </title> <booktitle> Proceedings of the 13th ACM Symposium on the Theory of Computing, </booktitle> <year> 1980. </year>
Reference-contexts: Number of distinct tuples derived [MuP91]. For transitive closure, it corresponds to the number of distinct tuples generated, excluding duplicates. 4. I/O complexity [UlY90]. This metric is based on the Kung-Hong model <ref> [HoK80] </ref>. Essentially, Ullman and Yannakakis assume a main memory of size s ``values'' (e.g., nodes or tuples), where n &lt; s &lt; e. One I/O is performed whenever a value is moved between main memory and secondary storage.
Reference: [HuS93] <author> K. A. Hua and J. X. W. Su, </author> <title> ``Efficient Evaluation of Traversal Recursion Using Connectivity Index'', </title> <booktitle> Proceedings 9th Int'l Conf. on Data Engineering, </booktitle> <address> Vienna, Austria, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Similar definitions for node level were given in <ref> [HuS93, Jak93] </ref>. 97 98 As an example, Figure 6.7 shows the graph of Figure 6.1 (b), rearranged according to its node levels. <p> Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [IRW] <author> Y. E. Ioannidis, R. Ramakrishnan and L. Winger, </author> <title> ``Transitive Closure Algorithms Based on Depth-First Search'', </title> <journal> ACM Trans. Database Syst., </journal> . <note> to appear. </note>
Reference-contexts: In particular, we have left open the question of which path from OPEN should be extended next. Specific algorithms can be instantiated from algorithm 0 by choosing a specific priority policy. For example, the seminaive algorithm [Ban85] employs a BFS policy, the graph algorithms of <ref> [IRW] </ref> employ a DFS policy, and the direct algorithms of [ADJ90] employ a matrix ordering policy based on some numbering of the nodes in a graph. Algorithm 0 is meant to illustrate the optimization techniques that follow. <p> We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> The union of S j with S i is therefore redundant, and Ebert's algorithm avoids this union. This optimization was also utilized in [Sch83] and in several algorithms in <ref> [AgJ90, IRW] </ref>. <p> The combination of topological sort and the marking optimization was used, among others, in the Hybrid algorithm [AgJ90] and the BTC algorithm <ref> [IRW] </ref>. Both algorithms demonstrated that the redundant work avoided by the marking optimization far outweighed the extra cost of the topological sort. 5.3.5 The Schmitz Algorithm Schmitz [Sch83] noticed that the generation of (partial) successor lists for nodes other than the root node in an SCC is not necessary. <p> In general, when a successor list S j is added to another list S i where i is a predecessor of j, the list S j may or may not be complete. In <ref> [IRW] </ref> such a list union is called a closed addition if S j is complete, and an open addition otherwise. Ioannidis et al considered algorithms that use either closed or open additions, and they employed the marking optimization to reduce the cost of both types of algorithms. <p> Ioannidis et al considered algorithms that use either closed or open additions, and they employed the marking optimization to reduce the cost of both types of algorithms. Our definition of marking is more restrictive than that of <ref> [IRW] </ref> since we study algorithms that are based on Purdom's algorithm and hence use closed additions only. 78 79 generation of that list until the SCC is identified. <p> The SCC successor list contains the nodes of the SCC and the successors of children of the nodes of the SCC that are not members of the same SCC. This optimization was also utilized in [Jia90] and in several algorithms in <ref> [IRW] </ref>, where pointer manipulation was used to generate the successor list of the root of the SCC by merging partial successor lists of members of the SCC. We call this technique the root optimization [IRW]. 5.3.6 The BTC Algorithm Ioannidis et al [IRW, Win92] proposed a DFS algorithm called BTC (Basic <p> This optimization was also utilized in [Jia90] and in several algorithms in <ref> [IRW] </ref>, where pointer manipulation was used to generate the successor list of the root of the SCC by merging partial successor lists of members of the SCC. We call this technique the root optimization [IRW]. 5.3.6 The BTC Algorithm Ioannidis et al [IRW, Win92] proposed a DFS algorithm called BTC (Basic Transitive Closure) that incorporates most of the ideas presented in the previous subsections. In addition, they developed several implementation techniques to improve the efficiency of storing and expanding successor lists. <p> We call this technique the root optimization [IRW]. 5.3.6 The BTC Algorithm Ioannidis et al <ref> [IRW, Win92] </ref> proposed a DFS algorithm called BTC (Basic Transitive Closure) that incorporates most of the ideas presented in the previous subsections. In addition, they developed several implementation techniques to improve the efficiency of storing and expanding successor lists. <p> graph [Jak92] since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in <ref> [IRW, Jak92, Jia90] </ref>. 5.3.8 The Jiang Algorithm Jiang [Jia90] observed that for multi-source queries, a further reduction of the input graph is possible. <p> For reachablity, search algorithms based on BFS and on DFS are given in [Jia90]. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. Variations of this algorithm can be found, in <ref> [GGZ91, IRW, Jia92, SuR91] </ref>. 5.3.10 Generalized Transitive Closure Algorithms that compute transitive closure using the condensation graph are not complete, and cannot be directly adapted for generalized transitive closure computation. <p> However, it is possible to generalize graph-based algorithms for the special case of an acyclic graph, or to modify the algorithms to avoid collapsing strongly connected components in a cyclic graph. Ioannidis and Ramakrishnan present several such algorithms in <ref> [IRW] </ref> and prove their correctness, i.e. completeness and irredundancy. They also compare the performance of the algorithms for a set of shortest path queries. 5.4 Hybrid Algorithms In this section, we study algorithms that use a hybrid or mixed approach. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> A modification of the Semi-naive algorithm is presented in [Jak91]. A modification of Warshall's algorithm is developed in [Jak92]. In Chapter 6 we 82 83 i a c x y z ii j investigate the performance of two spanning tree algorithms: an adaptation of the BTC algorithm of <ref> [IRW] </ref>, and an algorithm using predecessor trees presented in [Jak92] and described in the next subsection. 5.4.3 Partial Transitive Closure The spanning tree algorithms presented in [DaJ92] and [Jak91] handle selections in the same fashion as the successor list algorithms that they are based on. <p> Although the original descriptions of the algorithms were quite dissimilar, we observed that the algorithms can all be restated in terms of successor list manipulation. This observation lead to a uniform implementation framework, which highlights the relationship between the algorithms. The candidate algorithms are the following: The BTC algorithm <ref> [IRW] </ref> (see Section 5.3.6). The Hybrid algorithm [AgJ90] (see Section 5.4.1). The BFS algorithm [Jia90] (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm [DaJ92] (see Section 5.4.2). The Compute_Tree algorithm [Jak92] (see Section 5.4.3). This chapter is organized as follows. <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. Instead, the measured CPU time may be combined with an estimate of the I/O time given by the number of I/O's multiplied by the postulated cost of a single I/O <ref> [IRW, KIC92] </ref>. In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor [ADJ90, IRW, KIC92]. Furthermore, a close correlation of the CPU and I/O curves was observed in [ADJ90]. <p> In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor <ref> [ADJ90, IRW, KIC92] </ref>. Furthermore, a close correlation of the CPU and I/O curves was observed in [ADJ90]. This observation suggests that a large portion of the CPU cost was actually spent in processing the I/O subsystem calls, making the I/O cost even more pronouned. <p> After the computation of the closure, the complete successor list of x is given by S x = - y (x,y) TC (G) -. Our implementations of the candidate algorithms are based for the most part on the implementation of BTC and other DFS algorithms in <ref> [IRW, Win92] </ref>. With the exception of the Search algorithm, all of the algorithms expand successor lists in reverse topological order and utilize the immediate successor and marking optimizations, as well as inter and intra-successor list clustering. <p> size was 15, while the average size of an expanded successor list was one or two orders of magnitude larger. node successor list page 0 8 -10 6 8 -9 3 4 -6 5 6 -8 3 -5 Both inter and intra-successor list clustering are utilized in the restructuring phase <ref> [IRW] </ref>, taking advantage of the topological sort order established during this phase. Inter-list clustering is accomplished by storing successor lists on a page in a way that matches the order in which they will be accessed, i.e., in reverse topological order. <p> When nodes 5 and 6 are processed, node 8 is marked by changing its value to 19 (8+11), and a later union of its successor list with the list of node 3 is thus avoided. 6.3 The Competing Algorithms 6.3.1 The BTC Algorithm Our implementation of the BTC algorithm follows <ref> [IRW] </ref>. In the acyclic case, nodes are topologically sorted, and then the successor lists are expanded in reverse topological order. The processing of a node involves reading the successor lists of its children and merging them with its own list (the immediate successor optimization). <p> algorithm by JKB and JKB2. 6.4 Experimental setup The parameters of each experiment in our study are described in the following subsections. 6.4.1 System Parameters The configuration of the system for each experiment is determined by the size of the buffer pool (M) and the list and page replacement policies <ref> [IRW] </ref>. The page size in our experiments is 2048 bytes. The input relation tuples are 8 bytes long (two integers). Hence, in the relation format (Figure 6.2), 256 tuples may be stored on a page. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> We experimented with boths DAGS and general (cyclic) graphs. For a DAG, arcs going out of a node are restricted to go to higher numbered nodes. Our usage of the locality parameter is similar to that of <ref> [AgJ87, IRW] </ref>. In a general graph, children of node i are in the range [i - l % n, i + l % n]. In a DAG, children of node i are in the range [i+1, min (i+l, n)]. <p> The choice of page replacement policy for the computation of the complete closure was investigated in <ref> [IRW] </ref>. Ioannidis et al suggested that LRU was the better policy for large and deep graphs, while LUND was better for shallow and small graphs. This may be explained as follows. <p> LUND is therefore the preferred policy for high-selectivity queries, and is less attractive for low selectivity queries with a small buffer. Considering list replacement policies, the TC policy, which was added to this study and was not used in <ref> [IRW] </ref>, was overall the best choice since it keeps the successor lists of parents and children clustered across page splits, allowing later unions of their lists to be performed with higher locality. <p> In Section 6.2 we reviewed many cost metrics that have been suggested in the literature for evaluating and comparing transitive closure algorithms. Since the computation of the transitive closure of a large graph is likely to be I/O bound (see e.g., <ref> [ADJ90, IRW, KIC92] </ref>), an important question to be asked is can cost metrics which count operations at the tuple or successor list level be used to estimate the I/O cost of a transitive closure computation? We believe that the results of Section 6.4 clearly demonstrate that such extrapolation is highly unreliable. <p> Tuple I/O was the performance metric. The Spanning Tree algorithm, although it was penalized via a 50% overhead for storing the tree structure, still outperformed Hybrid, since its selective union of successor trees avoids redundant tuple reads. Ioannidis et al <ref> [IRW] </ref> studied the performance of several graph-based algorithms including Schmitz [Sch83], BTC, and the more complex DFS algorithms presented in [IRW]. They measured page I/O and CPU time. Overall, BTC was found to be the best algorithm with regard to both I/O and CPU cost. <p> Ioannidis et al <ref> [IRW] </ref> studied the performance of several graph-based algorithms including Schmitz [Sch83], BTC, and the more complex DFS algorithms presented in [IRW]. They measured page I/O and CPU time. Overall, BTC was found to be the best algorithm with regard to both I/O and CPU cost. Ioannidis et al found that the algorithms were usually I/O bound. <p> The main results were that BFS was better than DFS for computing multi-source queries, and that the use of the single-parent optimization reduces the cost of the algorithms by avoiding both reads and unions of single-parent successor lists. Taken together, the results reported in <ref> [AgJ90, DaJ92, IRW, Jia90] </ref> clearly demonstrate that the graph-based algorithms and their hybrid variants are superior to the iterative and matrix-based algorithms, both for the computation of CTC and for the computation of PTC with low selectivity (large number of source nodes).
Reference: [Ioa86] <author> Y. E. Ioannidis, </author> <title> ``On the Computation of the Transitive Closure of Relational Operators'', </title> <booktitle> Proc. 12th Int'l Conf. Very Large Data Bases, </booktitle> <address> Kyoto, Japan, </address> <month> Aug. </month> <year> 1986, </year> <pages> 403-411. </pages>
Reference-contexts: Several variations on this basic iterative algorithm have been proposed in the literature <ref> [ADJ89, GKB87, Ioa86, Lu87, VaB86] </ref>, and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> Several variations on this basic iterative algorithm have been proposed in the literature [ADJ89, GKB87, Ioa86, Lu87, VaB86], and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis <ref> [Ioa86] </ref> independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. Ioannidis [Ioa86] developed algebraically a whole family of logarithmic algorithms, and suggested that the one based on powers of three, the so-called Smart algorithm, <p> [ADJ89, GKB87, Ioa86, Lu87, VaB86], and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis <ref> [Ioa86] </ref> independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. Ioannidis [Ioa86] developed algebraically a whole family of logarithmic algorithms, and suggested that the one based on powers of three, the so-called Smart algorithm, may be the best one. However, several performance studies indicate that the Semi-naive algorithm usually outperforms the logarithmic algorithms (see for example [KIC92]). <p> D ,R 0 ) ) - R f ; - Where the subtraction is defined by S - T = -( x,y,L S ) S s. t. " / ( x,y,L T ) T L T L S - A generalization, similar to (* 1 *), of the logarithmic algorithm <ref> [Ioa86, VaB86] </ref> is given in [CrN89]. 5.1.7 Completeness The Semi-naive algorithm, as generalized in (* 1 *), is complete. Each arc in R 0 represents a path of length 1 and is included in R f .
Reference: [IoR88] <author> Y. E. Ioannidis and R. Ramakrishnan, </author> <title> ``An Efficient Transitive Closure Algorithm'', </title> <booktitle> Proc. 14th Int'l Conf. Very Large Data Bases, </booktitle> <address> Los Angeles, California, Aug.-Sept. </address> <year> 1988. </year>
Reference-contexts: In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> We feel that this suggestion is quite simplistic: it does not take into account the memory management policy for pages, the distribution of values on pages (e.g. clustering), or the possibility of reorganization of values across pages. 5. Successor list I/O <ref> [IoR88, Jia90, Jia90] </ref>. This is the number of times a successor list is moved between main memory and secondary storage. In [IoR88], this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions [Jia90, Jia90]. <p> Successor list I/O [IoR88, Jia90, Jia90]. This is the number of times a successor list is moved between main memory and secondary storage. In <ref> [IoR88] </ref>, this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions [Jia90, Jia90]. This is the number of times a union of successor lists is performed. <p> [ADJ90, AgJ87, KIC92] demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm [UlY90] and a DFS algorithm based on <ref> [IoR88] </ref> and extended with caching of successor lists. Tuple I/O was the performance metric. Hybrid was found to be the best performer. It won over the Blocked Warren algorithm by employing the immediate successor and marking optimizations of graph-based algorithms. <p> Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from <ref> [IoR88] </ref>, and several algorithms of his own [Jia90, Jia90]. The two performance metrics were the number of successor list reads and the number of successor list unions.
Reference: [Jag90] <author> H. V. Jagadish, </author> <title> ``A Compression Technique to Materialize Transitive Closure'', </title> <journal> ACM Transactions on Database Systems 15, </journal> <month> 4 (Dec. </month> <year> 1990), </year> . <title> (Previously appeared as: ``A Compressed Transitive Closure Technique for Efficient Fixed-Point Query Processing'' in Proc. </title> <booktitle> 2nd Int'l Conf. on Expert Database Systems, </booktitle> <address> Tyson's Corner, VA, </address> <year> 1988). </year>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [Jak91] <author> H. Jakobsson, </author> <title> ``Mixed-Approach Algorithms for Transitive Closure'', </title> <booktitle> Proc. 10th Symp. Principles of Database Systems, </booktitle> <address> Denver, Colorado, </address> <year> 1991, </year> <pages> 199-205. </pages>
Reference-contexts: A simple search of the graph, starting from the source nodes and expanding only their successor lists, may be cheaper. We call such an algorithm a search algorithm (following <ref> [Jak91] </ref>). With a search algorithm, a multi-source query with k source nodes is essentially treated as k single-source queries. Given a single-source selection on node s, the successor list of s may be expanded using various graph search algorithms. <p> We describe the Hybrid algorithm in more detail in Chapter 6. 81 82 5.4.2 Tree-Based Algorithms All of the matrix and graph-based algorithms mentioned so far use the successor list of a node as the basic unit of storage and manipulation. Jakobsson <ref> [Jak91] </ref> and Dar and Jagadish [DaJ92] independently observed that the use of successor lists can result in redundant work and in unnecessary I/O, and that this extra work can be avoided if successor spanning trees are used instead of ``flat'' successor lists. <p> The use of successor trees is a general technique that may be applied to different algorithms. The Spanning Tree transitive closure algorithm presented in [DaJ92] is a modification of the hybrid algorithm of [AgJ90]. A modification of the Semi-naive algorithm is presented in <ref> [Jak91] </ref>. A modification of Warshall's algorithm is developed in [Jak92]. <p> a c x y z ii j investigate the performance of two spanning tree algorithms: an adaptation of the BTC algorithm of [IRW], and an algorithm using predecessor trees presented in [Jak92] and described in the next subsection. 5.4.3 Partial Transitive Closure The spanning tree algorithms presented in [DaJ92] and <ref> [Jak91] </ref> handle selections in the same fashion as the successor list algorithms that they are based on. In [Jak92], Jakobsson presents a spanning tree algorithm tailored to partial transitive closure. The algorithm, called Compute_Tree, differs from the complete closure algorithm of [Jak91] in two important ways: The spanning trees are built <p> Closure The spanning tree algorithms presented in [DaJ92] and <ref> [Jak91] </ref> handle selections in the same fashion as the successor list algorithms that they are based on. In [Jak92], Jakobsson presents a spanning tree algorithm tailored to partial transitive closure. The algorithm, called Compute_Tree, differs from the complete closure algorithm of [Jak91] in two important ways: The spanning trees are built with respect to the arc-reversed graph G r , i.e., the algorithm uses predecessor trees rather than successor trees. A predecessor tree for a node x contains only a subset of the predecessor nodes of x. <p> However, the number of operations may also be measured on actual input graphs [Sch83]. In either case, this measure is most useful when the computation is memory resident since it does not take I/O into account. 2. Number of deductions <ref> [BeR87, Jak91, Jak92, NRS89] </ref>. This is a standard metric in recursive query processing. In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived [MuP91].
Reference: [Jak92] <author> H. Jakobsson, </author> <title> ``On Tree-Based Techniques for Query Evaluation'', </title> <booktitle> Proc. 11th Symp. Principles of Database Systems, </booktitle> <year> 1992, </year> <pages> 380-392. </pages>
Reference-contexts: As before, we can use Tarjan's algorithm to compute the reachable strongly connected components of the graph by intializing it with the nodes in S. __________________ 18. We refer to this graph as the magic graph <ref> [Jak92] </ref> since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in [IRW, Jak92, <p> graph [Jak92] since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in <ref> [IRW, Jak92, Jia90] </ref>. 5.3.8 The Jiang Algorithm Jiang [Jia90] observed that for multi-source queries, a further reduction of the input graph is possible. <p> Once again, the subtree rooted at j is not read or processed. See Figure 5.6. The fact that the children of node j are searched in only one tree, namely the tree of node a, has been called the unique assignment property in <ref> [Jak92] </ref>. In addition to promoting sharing, a successor spanning tree implicitly records a path between the root of the tree and each of its leaves, and can be used to answer queries that require this path information. <p> The Spanning Tree transitive closure algorithm presented in [DaJ92] is a modification of the hybrid algorithm of [AgJ90]. A modification of the Semi-naive algorithm is presented in [Jak91]. A modification of Warshall's algorithm is developed in <ref> [Jak92] </ref>. In Chapter 6 we 82 83 i a c x y z ii j investigate the performance of two spanning tree algorithms: an adaptation of the BTC algorithm of [IRW], and an algorithm using predecessor trees presented in [Jak92] and described in the next subsection. 5.4.3 Partial Transitive Closure The <p> A modification of Warshall's algorithm is developed in <ref> [Jak92] </ref>. In Chapter 6 we 82 83 i a c x y z ii j investigate the performance of two spanning tree algorithms: an adaptation of the BTC algorithm of [IRW], and an algorithm using predecessor trees presented in [Jak92] and described in the next subsection. 5.4.3 Partial Transitive Closure The spanning tree algorithms presented in [DaJ92] and [Jak91] handle selections in the same fashion as the successor list algorithms that they are based on. In [Jak92], Jakobsson presents a spanning tree algorithm tailored to partial transitive closure. <p> the BTC algorithm of [IRW], and an algorithm using predecessor trees presented in <ref> [Jak92] </ref> and described in the next subsection. 5.4.3 Partial Transitive Closure The spanning tree algorithms presented in [DaJ92] and [Jak91] handle selections in the same fashion as the successor list algorithms that they are based on. In [Jak92], Jakobsson presents a spanning tree algorithm tailored to partial transitive closure. <p> The candidate algorithms are the following: The BTC algorithm [IRW] (see Section 5.3.6). The Hybrid algorithm [AgJ90] (see Section 5.4.1). The BFS algorithm [Jia90] (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm [DaJ92] (see Section 5.4.2). The Compute_Tree algorithm <ref> [Jak92] </ref> (see Section 5.4.3). This chapter is organized as follows. In Section 6.1 we review the cost models that have been used in previous studies of transitive closure and recursion in databases, and motivate our choice of performance metrics. <p> However, the number of operations may also be measured on actual input graphs [Sch83]. In either case, this measure is most useful when the computation is memory resident since it does not take I/O into account. 2. Number of deductions <ref> [BeR87, Jak91, Jak92, NRS89] </ref>. This is a standard metric in recursive query processing. In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived [MuP91]. <p> We present results of experiments involving acyclic graphs only, for the following reasons. First, several of the algorithms that we study are only applicable to acyclic graphs (e.g. <ref> [DaJ92, Jak92] </ref>). Second, for reachability queries, the closure of a cyclic graph can be computed using the Purdom algorithm [Pur70] by collapsing strongly connected components and computing the closure of the resulting acyclic condensation graph. <p> We therefore focused our performance study on graph-based and hybrid algorithms, including the algorithms that were the best performers in those earlier studies. As suggested in <ref> [Jak92, Jia90] </ref>, for PTC with high selectivity, a simple search from the source nodes may be the most efficient strategy. Hence, we also added the Search algorithm to our repertoire.
Reference: [Jak93] <author> H. Jakobsson, </author> <title> ``Mixed-Approach Algorithms for Transitive Closure'', </title> <type> Unpublished Manuscript, </type> <institution> Computer Science Dept., Stanford Univ., Stanford, California, </institution> <year> 1993. </year>
Reference-contexts: Similar definitions for node level were given in <ref> [HuS93, Jak93] </ref>. 97 98 As an example, Figure 6.7 shows the graph of Figure 6.1 (b), rearranged according to its node levels.
Reference: [Jia90] <author> B. Jiang, </author> <title> ``A Suitable Algorithm for Computing Partial Transitive Closures in Databases'', </title> <booktitle> Proc. IEEE 6th Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> We also discuss how the algorithms may be used to compute the most common type of selection, i.e. finding those nodes in the closure graph that are reachable from a specified set S of source nodes. Following <ref> [Jia90] </ref>, we refer to this problem as partial transitive closure (PTC). Given the plethora of transitive closure algorithms, we classify them into four families according to the data structure that underlies the computation in each algorithm. Iterative algorithms, which are based on a relational representation, are discussed in Section 5.1. <p> If S contains exactly one node, we say that the PTC is single-source. Otherwise we say that the PTC is multi-source. Following <ref> [Jia90] </ref>, we distinguish between weak and strong multi-source PTC computation. In a weak multi-source PTC query we wish to find all nodes in G reachable from some node in S, regardless of which particular node (s) in S they are reachable from. <p> This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> For example, in Figure 5.2, i j k, as indicated by the topological sort rank next to each node. Therefore, when expanding node i, node k will be considered before node j. This is the basis of the reduct and closure algorithm in [GoK79]. As shown in <ref> [GoK79, Jia90] </ref>, the marking optimization on a topologically sorted graph is equivalent to a transitive reduction of the input graph [AHU75]. In other words, if we remove from the original graph all marked arcs, we end up with the minimal graph that has an identical closure to the original graph. <p> The SCC successor list contains the nodes of the SCC and the successors of children of the nodes of the SCC that are not members of the same SCC. This optimization was also utilized in <ref> [Jia90] </ref> and in several algorithms in [IRW], where pointer manipulation was used to generate the successor list of the root of the SCC by merging partial successor lists of members of the SCC. <p> graph [Jak92] since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in <ref> [IRW, Jak92, Jia90] </ref>. 5.3.8 The Jiang Algorithm Jiang [Jia90] observed that for multi-source queries, a further reduction of the input graph is possible. <p> (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in [IRW, Jak92, Jia90]. 5.3.8 The Jiang Algorithm Jiang <ref> [Jia90] </ref> observed that for multi-source queries, a further reduction of the input graph is possible. If a node j has a single parent i and j is not in S, then there is no need to compute the successor list of j. (In [Jia90] j is called a single-input node, but <p> Jak92, Jia90]. 5.3.8 The Jiang Algorithm Jiang <ref> [Jia90] </ref> observed that for multi-source queries, a further reduction of the input graph is possible. If a node j has a single parent i and j is not in S, then there is no need to compute the successor list of j. (In [Jia90] j is called a single-input node, but we use the term single-parent instead.) Instead, node j can be reduced to a sink node by making its children (immediate successors) into children of i and deleting the outgoing arcs of node j. <p> Note that node e is not reduced since it is in S. a b i j k d 80 81 The application of this optimization to several graph-based algorithms, including those by Ebert and Schmitz, has been studied in detail in <ref> [Jia90] </ref>. 5.3.9 The Search Algorithm The main advantage of computing successor lists in reverse topological sort order is that the expanded successor list of a node can be used by the parents of this node when their successor lists are being expanded. <p> Given a single-source selection on node s, the successor list of s may be expanded using various graph search algorithms. For reachablity, search algorithms based on BFS and on DFS are given in <ref> [Jia90] </ref>. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> This observation lead to a uniform implementation framework, which highlights the relationship between the algorithms. The candidate algorithms are the following: The BTC algorithm [IRW] (see Section 5.3.6). The Hybrid algorithm [AgJ90] (see Section 5.4.1). The BFS algorithm <ref> [Jia90] </ref> (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm [DaJ92] (see Section 5.4.2). The Compute_Tree algorithm [Jak92] (see Section 5.4.3). This chapter is organized as follows. <p> We feel that this suggestion is quite simplistic: it does not take into account the memory management policy for pages, the distribution of values on pages (e.g. clustering), or the possibility of reorganization of values across pages. 5. Successor list I/O <ref> [IoR88, Jia90, Jia90] </ref>. This is the number of times a successor list is moved between main memory and secondary storage. In [IoR88], this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions [Jia90, Jia90]. <p> Successor list I/O [IoR88, Jia90, Jia90]. This is the number of times a successor list is moved between main memory and secondary storage. In [IoR88], this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions <ref> [Jia90, Jia90] </ref>. This is the number of times a union of successor lists is performed. <p> We avoid this problem by we making sure that the current block does not contain successor lists from more than one (non-trivial) SCC. We denote our implementation of the Hybrid algorithm by HYBRID. 6.3.3 The BFS Algorithm Jiang's BFS algorithm <ref> [Jia90] </ref> has been implemented by extending the BTC algorithm with the single-parent optimization. The successor lists of nodes with a single parent (incoming arc) are not expanded. Instead, the children of single-parent nodes are ``adopted'' by the parent, as though they were children of that parent node. <p> The successor lists of nodes with a single parent (incoming arc) are not expanded. Instead, the children of single-parent nodes are ``adopted'' by the parent, as though they were children of that parent node. Algorithms in <ref> [Jia90, Jia90] </ref> classify nodes as single-input or multi-input based on the input graph, regardless of the query at hand. In our implementation, we consider instead the magic subgraph reachable from the source nodes. <p> Hence, the magic graph usually contains more single-parent nodes. As an example, consider Figures 5.3 (a) and (b). In the original algorithm of <ref> [Jia90] </ref>, the original graph would be considered (Figure 5.3 (a)), and only node d would be classified as a single parent node and therefore reduced, resulting in the graph shown in Figure 5.4. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> The graph-based algorithms were superior over all input graphs, with an order of magnitude difference for cyclic graphs. Jiang <ref> [Jia90] </ref> investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own [Jia90, Jia90]. <p> Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own <ref> [Jia90, Jia90] </ref>. The two performance metrics were the number of successor list reads and the number of successor list unions. <p> The main results were that BFS was better than DFS for computing multi-source queries, and that the use of the single-parent optimization reduces the cost of the algorithms by avoiding both reads and unions of single-parent successor lists. Taken together, the results reported in <ref> [AgJ90, DaJ92, IRW, Jia90] </ref> clearly demonstrate that the graph-based algorithms and their hybrid variants are superior to the iterative and matrix-based algorithms, both for the computation of CTC and for the computation of PTC with low selectivity (large number of source nodes). <p> We therefore focused our performance study on graph-based and hybrid algorithms, including the algorithms that were the best performers in those earlier studies. As suggested in <ref> [Jak92, Jia90] </ref>, for PTC with high selectivity, a simple search from the source nodes may be the most efficient strategy. Hence, we also added the Search algorithm to our repertoire.
Reference: [Jia92] <author> B. Jiang, </author> <title> ``I/O Efficiency of Shortest Path Algorithms: An Analysis'', </title> <booktitle> IEEE 8th Int'l Conf. on Data Engineering., </booktitle> <address> Phoenix, Arizona, </address> <month> Feb. </month> <year> 1992. </year> <pages> 120 121 </pages>
Reference-contexts: For reachablity, search algorithms based on BFS and on DFS are given in [Jia90]. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. Variations of this algorithm can be found, in <ref> [GGZ91, IRW, Jia92, SuR91] </ref>. 5.3.10 Generalized Transitive Closure Algorithms that compute transitive closure using the condensation graph are not complete, and cannot be directly adapted for generalized transitive closure computation.
Reference: [Jia90] <author> B. Jiang, </author> <title> ``Design, Analysis, and Evaluation of Algorithms for Computing Partial Transitive in Databases'', </title> <institution> Computer Science Tech. </institution> <type> Rep., </type> <institution> ETH Zurich, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> We also discuss how the algorithms may be used to compute the most common type of selection, i.e. finding those nodes in the closure graph that are reachable from a specified set S of source nodes. Following <ref> [Jia90] </ref>, we refer to this problem as partial transitive closure (PTC). Given the plethora of transitive closure algorithms, we classify them into four families according to the data structure that underlies the computation in each algorithm. Iterative algorithms, which are based on a relational representation, are discussed in Section 5.1. <p> If S contains exactly one node, we say that the PTC is single-source. Otherwise we say that the PTC is multi-source. Following <ref> [Jia90] </ref>, we distinguish between weak and strong multi-source PTC computation. In a weak multi-source PTC query we wish to find all nodes in G reachable from some node in S, regardless of which particular node (s) in S they are reachable from. <p> This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> For example, in Figure 5.2, i j k, as indicated by the topological sort rank next to each node. Therefore, when expanding node i, node k will be considered before node j. This is the basis of the reduct and closure algorithm in [GoK79]. As shown in <ref> [GoK79, Jia90] </ref>, the marking optimization on a topologically sorted graph is equivalent to a transitive reduction of the input graph [AHU75]. In other words, if we remove from the original graph all marked arcs, we end up with the minimal graph that has an identical closure to the original graph. <p> The SCC successor list contains the nodes of the SCC and the successors of children of the nodes of the SCC that are not members of the same SCC. This optimization was also utilized in <ref> [Jia90] </ref> and in several algorithms in [IRW], where pointer manipulation was used to generate the successor list of the root of the SCC by merging partial successor lists of members of the SCC. <p> graph [Jak92] since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in <ref> [IRW, Jak92, Jia90] </ref>. 5.3.8 The Jiang Algorithm Jiang [Jia90] observed that for multi-source queries, a further reduction of the input graph is possible. <p> (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. [Ull89]). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in [IRW, Jak92, Jia90]. 5.3.8 The Jiang Algorithm Jiang <ref> [Jia90] </ref> observed that for multi-source queries, a further reduction of the input graph is possible. If a node j has a single parent i and j is not in S, then there is no need to compute the successor list of j. (In [Jia90] j is called a single-input node, but <p> Jak92, Jia90]. 5.3.8 The Jiang Algorithm Jiang <ref> [Jia90] </ref> observed that for multi-source queries, a further reduction of the input graph is possible. If a node j has a single parent i and j is not in S, then there is no need to compute the successor list of j. (In [Jia90] j is called a single-input node, but we use the term single-parent instead.) Instead, node j can be reduced to a sink node by making its children (immediate successors) into children of i and deleting the outgoing arcs of node j. <p> Note that node e is not reduced since it is in S. a b i j k d 80 81 The application of this optimization to several graph-based algorithms, including those by Ebert and Schmitz, has been studied in detail in <ref> [Jia90] </ref>. 5.3.9 The Search Algorithm The main advantage of computing successor lists in reverse topological sort order is that the expanded successor list of a node can be used by the parents of this node when their successor lists are being expanded. <p> Given a single-source selection on node s, the successor list of s may be expanded using various graph search algorithms. For reachablity, search algorithms based on BFS and on DFS are given in <ref> [Jia90] </ref>. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> This observation lead to a uniform implementation framework, which highlights the relationship between the algorithms. The candidate algorithms are the following: The BTC algorithm [IRW] (see Section 5.3.6). The Hybrid algorithm [AgJ90] (see Section 5.4.1). The BFS algorithm <ref> [Jia90] </ref> (see Section 5.3.8). The Search algorithm (see Section 5.4.3). The Spanning Tree algorithm [DaJ92] (see Section 5.4.2). The Compute_Tree algorithm [Jak92] (see Section 5.4.3). This chapter is organized as follows. <p> We feel that this suggestion is quite simplistic: it does not take into account the memory management policy for pages, the distribution of values on pages (e.g. clustering), or the possibility of reorganization of values across pages. 5. Successor list I/O <ref> [IoR88, Jia90, Jia90] </ref>. This is the number of times a successor list is moved between main memory and secondary storage. In [IoR88], this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions [Jia90, Jia90]. <p> Successor list I/O [IoR88, Jia90, Jia90]. This is the number of times a successor list is moved between main memory and secondary storage. In [IoR88], this metric was established analytically for the worst case, assuming main memory of size n. 6. Number of successor list unions <ref> [Jia90, Jia90] </ref>. This is the number of times a union of successor lists is performed. <p> We avoid this problem by we making sure that the current block does not contain successor lists from more than one (non-trivial) SCC. We denote our implementation of the Hybrid algorithm by HYBRID. 6.3.3 The BFS Algorithm Jiang's BFS algorithm <ref> [Jia90] </ref> has been implemented by extending the BTC algorithm with the single-parent optimization. The successor lists of nodes with a single parent (incoming arc) are not expanded. Instead, the children of single-parent nodes are ``adopted'' by the parent, as though they were children of that parent node. <p> The successor lists of nodes with a single parent (incoming arc) are not expanded. Instead, the children of single-parent nodes are ``adopted'' by the parent, as though they were children of that parent node. Algorithms in <ref> [Jia90, Jia90] </ref> classify nodes as single-input or multi-input based on the input graph, regardless of the query at hand. In our implementation, we consider instead the magic subgraph reachable from the source nodes. <p> Hence, the magic graph usually contains more single-parent nodes. As an example, consider Figures 5.3 (a) and (b). In the original algorithm of <ref> [Jia90] </ref>, the original graph would be considered (Figure 5.3 (a)), and only node d would be classified as a single parent node and therefore reduced, resulting in the graph shown in Figure 5.4. <p> System Parameters 6.4.2 Query Parameters Synthetic graphs with varying characteristics are used to explore the performance of the algorithms (see e.g. <ref> [AgJ90, ADJ90, AgJ87, IRW, Jia90, Jia90] </ref>). The parameters used to guide the graph generation process are the number of nodes in the graph (n), the average out-degree (F), and the graph locality (l). The actual out degree of each node is chosen using a uniform distribution between 0 and 2F. <p> The graph-based algorithms were superior over all input graphs, with an order of magnitude difference for cyclic graphs. Jiang <ref> [Jia90] </ref> investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own [Jia90, Jia90]. <p> Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz [Sch83], the DFTC algorithm from [IoR88], and several algorithms of his own <ref> [Jia90, Jia90] </ref>. The two performance metrics were the number of successor list reads and the number of successor list unions. <p> The main results were that BFS was better than DFS for computing multi-source queries, and that the use of the single-parent optimization reduces the cost of the algorithms by avoiding both reads and unions of single-parent successor lists. Taken together, the results reported in <ref> [AgJ90, DaJ92, IRW, Jia90] </ref> clearly demonstrate that the graph-based algorithms and their hybrid variants are superior to the iterative and matrix-based algorithms, both for the computation of CTC and for the computation of PTC with low selectivity (large number of source nodes). <p> We therefore focused our performance study on graph-based and hybrid algorithms, including the algorithms that were the best performers in those earlier studies. As suggested in <ref> [Jak92, Jia90] </ref>, for PTC with high selectivity, a simple search from the source nodes may be the most efficient strategy. Hence, we also added the Search algorithm to our repertoire.
Reference: [KIC92] <author> R. Kabler, Y. E. Ioannidis and M. Carey, </author> <title> ``Performance Evaluation of Algorithms for Transitive Closure'', </title> <booktitle> Information Systems 17, </booktitle> <month> 5 (Sep. </month> <year> 1992), </year> . 
Reference-contexts: Ioannidis [Ioa86] developed algebraically a whole family of logarithmic algorithms, and suggested that the one based on powers of three, the so-called Smart algorithm, may be the best one. However, several performance studies indicate that the Semi-naive algorithm usually outperforms the logarithmic algorithms (see for example <ref> [KIC92] </ref>). In addition, the Semi-naive algorithm can handle selection on source nodes, which the logarithmic algorithms cannot handle efficiently. 5.1.3 Lu's Algorithm Lu's HYBRIDTC algorithm [Lu87] is essentially an implementation of the Semi-naive algorithm based on hash-join [DKO84]. <p> An implementation of Semi-naive based on single-sided composition was found to be better than the standard implementation for most input graphs in [ADJ90]. Implementations of the Semi-naive and logarithmic (Smart) algorithms, based on hash-join and single-sided compositions, were also explored in <ref> [KIC92] </ref>. They found the hash-join implementations to perform generally better, though the single sided composition method employed was quite different duplicate elimination was done at the end of each iteration rather than being done on the fly. It is difficult to speculate regarding the performance tradeoff of these two schemes. <p> These result tuples can be processed in the same iteration, instead of writing them to disk and then reading them again in the next iteration. This sort of ``pushy'' [GKB87] or ``immediate'' processing has been explored in <ref> [KIC92] </ref>. <p> However, through some additional checking the iterative algorithms can be rendered terminating as well as discriminating <ref> [ADJ88a, KIC92] </ref>. If there is a (negative weight) cycle in a graph, than for every node on this cycle there must exist a non-null (negative weight) path to itself. <p> Figure 5.1 shows schematically an off-diagonal list that may be unioned with three diagonal lists. Thus, blocking allows several successor list unions to be performed at the cost of a single I/O. The performance studies in <ref> [ADJ90, KIC92] </ref> showed that the blocking algorithms generally performed much better than the iterative algorithms for the computation of the complete closure over a wide range of input graphs. __________________ 15. The case where j = k is not important since processing of ( j, j) does not affect anything. <p> The case where j = k is not important since processing of ( j, j) does not affect anything. As such, we have assumed jk in writing this constraint. 72 73 5.2.4 Partial Transitive Closure Matrix-based algorithms cannot handle selections on the source nodes efficiently <ref> [ADJ90, KIC92] </ref> since paths are extended at both ends. <p> A comparison of the Blocked Warren algorithm with the Seminaive algorithm for PTC computation in <ref> [KIC92] </ref> demonstrated that the performance of the Seminaive algorithm improved relative to Blocked Warren as the percentage of source nodes was decreased (i.e. the selectivity of the query was increased). <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> Page I/O <ref> [ADJ90, IRW, KIC92] </ref>. This is the number of times a page was moved between main memory and secondary storage. 9. I/O + CPU time [ADJ90, IRW, KIC92]. The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. <p> The total elapsed time may be used directly [ADJ90], but it is sensitive to the workload of the system. Instead, the measured CPU time may be combined with an estimate of the I/O time given by the number of I/O's multiplied by the postulated cost of a single I/O <ref> [IRW, KIC92] </ref>. In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor [ADJ90, IRW, KIC92]. Furthermore, a close correlation of the CPU and I/O curves was observed in [ADJ90]. <p> In studies that measured both I/O cost and CPU time, the I/O cost was clearly the dominant factor <ref> [ADJ90, IRW, KIC92] </ref>. Furthermore, a close correlation of the CPU and I/O curves was observed in [ADJ90]. This observation suggests that a large portion of the CPU cost was actually spent in processing the I/O subsystem calls, making the I/O cost even more pronouned. <p> In Section 6.2 we reviewed many cost metrics that have been suggested in the literature for evaluating and comparing transitive closure algorithms. Since the computation of the transitive closure of a large graph is likely to be I/O bound (see e.g., <ref> [ADJ90, IRW, KIC92] </ref>), an important question to be asked is can cost metrics which count operations at the tuple or successor list level be used to estimate the I/O cost of a transitive closure computation? We believe that the results of Section 6.4 clearly demonstrate that such extrapolation is highly unreliable. <p> They measured page I/O and elapsed time and found I/O to be the dominant cost factor. The Direct algorithms were found to perform much better for the computation of CTC over all input graphs. Kabler et al <ref> [KIC92] </ref> explored several implementations of the Seminaive, Smart and Blocked Warren algorithms using different join methods, duplicate elimination techniques, and buffer management policies. They implemented the algorithms and measured page I/O and elapsed time. They found Seminaive to always outperform Smart. <p> They implemented the algorithms and measured page I/O and elapsed time. They found Seminaive to always outperform Smart. Blocked Warren was overall the best algorithm for CTC, but for PTC computation with less than 1/3 of the source nodes, Seminaive performed better. The results of <ref> [ADJ90, AgJ87, KIC92] </ref> demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm [UlY90] and a DFS algorithm based on [IoR88] <p> The implementation of the algorithms for this study was based on the implementation of Ioannidis et al, as described in [Win92]. Ioannidis et al also compared the performance of the graph based algorithms to the performance of the Seminaive, Smart and Blocked Warren algorithms, using the results of <ref> [KIC92] </ref>, for similar graphs and buffer sizes. The graph-based algorithms were superior over all input graphs, with an order of magnitude difference for cyclic graphs. Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections.
Reference: [Kar90] <author> R. M. Karp, </author> <title> ``The Transitive Closure of a Random Graph'', Random Structures and Algorithms 1, </title> <booktitle> 1 (1990), </booktitle> <pages> 73-93. </pages>
Reference-contexts: Third, random graphs generated with an out degree greater than 1 tend to have most nodes concentrated in one large strongly connected component (see <ref> [Kar90, SeN91] </ref>). Hence, the condensation graph of these random graphs is quite small. __________________ 20. The reader may note that the number of arcs is often less than N F.
Reference: [KiL86] <author> M. Kifer and E. L. Lozinskii, </author> <title> ``A Framework for an Efficient Implementation of Deductive Database Systems'', </title> <booktitle> Proc. 6th Advanced Database Symposium, </booktitle> <address> Tokyo, Japan, </address> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: For least fixed point recursions, Aho and Ullman [AhU79] gave a rule for moving selections into the iterative process of evaluating the solution. The types of selections that can be pushed into a recursion have been characterized by Kifer and Lozinskii <ref> [KiL86] </ref>, by Beeri et al [BKB90] and by Agrawal and Devanbu [AgD89]. A large body of knowledge was accumulated in recent years on general techniques for rewriting a collection of Datalog rules into an equivalent yet more efficient form.
Reference: [Kle56] <author> S. C. Kleene, </author> <title> Representation of Events in Neural Nets and Finite Automata, </title> <publisher> Princeton University Press, </publisher> <year> 1956. </year>
Reference-contexts: all the graph studied. 5.2.5 Generalized Transitive Closure To perform label computations, the innermost step of Warshall's algorithm can be rewritten as: L i j = AGG (L i j ,CON (L ik ,L k j ) ) With a different notation, this is Kleene's algorithm for generalized transitive closure <ref> [Kle56] </ref>. Floyd's shortest path algorithm [Flo62] is a special case of the above generalization of Warshall's algorithm for the shortest path problem, with CON being addition and AGG being the min function. Warshall-derived algorithms can be generalized in a similar fashion.
Reference: [Knu73] <author> D. E. Knuth, </author> <title> The Art of Computer Programming: Sorting and Searching, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1973. </year>
Reference-contexts: A Template Transitive Closure Algorithm for Maximizing Path Algebras The template algorithm for path-set condensation, T psc of Section 4.2.2, can be modified to only extend optimal paths by extending paths in best-first order. This is achieved by using OPEN as a priority queue (see e.g. <ref> [Knu73] </ref>) which stores path-sets according to the ordering . The insertion of new path-sets to OPEN in steps 2 and 5 will maintain the priority queue ordering. Each concatenation in step 4 will extend the best path-set condensation y OPEN.
Reference: [KuP87] <author> S. M. Kuck and S. </author> <title> Pax, ``A Relational Calculus with Transitive Closure'', </title> <type> Technical Report, </type> <institution> Univ. Illinois, Urbana, Illinois, </institution> <year> 1987. </year>
Reference: [LaD89] <author> P. A. Larson and V. Deshpande, </author> <title> ``A File Structure Supporting Traversal Recursion,'', </title> <booktitle> Proc. ACM-SIGMOD 1989 Int'l Conf. Management of Data, </booktitle> <address> Portland, Oregon, </address> <month> May-June </month> <year> 1989, </year> <pages> 243-252. </pages>
Reference-contexts: The graph generation routines produce a graph relation that is clustered on the source attribute. In the case of a DAG, the resulting relation is also topologically clustered <ref> [LaD89] </ref>. That is, if node j is a successor of node i, then the immediate successor list of j is stored after the immediate successor list of i. This topological clustering biases the performance results, since it reduces the I/O cost of the preprocessing phase that scans the graph relation. <p> Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [Lin87] <author> V. Linnemann, </author> <title> ``Non First Normal Form Relations and Recursive Queries: An SQL Based Approach'', </title> <booktitle> Proc. IEEE 3rd Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1987, </year> <pages> 591-598. </pages>
Reference-contexts: Furthermore, since paths share arcs, unnesting PATH would create duplicates, and the semantics of handling these duplicates would be difficult to define. The formulation of recursive queries in an NF 2 SQL has been studied in <ref> [Lin87] </ref>. The proposed extension can express selection on end nodes, label concatenation, and retrieval of path information. However, we find the query formulation quite complicated. One reason is that type constructors for tuples, sets, and lists must be specified in the query, as in [PiA86]. <p> One reason is that type constructors for tuples, sets, and lists must be specified in the query, as in [PiA86]. Another reason is that the initial clause, iteration clause, selection on the start nodes and termination condition are specified separately. In the proposal of <ref> [Lin87] </ref> the user must specify termination conditions explicitly, for example, by including in the query a check for acyclicity. In [LZH90], the relational model is extended with a path structure, similar to our PATH relation.
Reference: [LiN89] <author> R. J. Lipton and J. F. Naughton, </author> <title> ``Estimating the Size of Generalized Transitive Closures'', </title> <booktitle> Proc. of the 15th Int'l Conf. on Very Large Databases, </booktitle> <address> Amsterdam, the Netherlands, </address> <month> Aug. </month> <year> 1989, </year> <pages> 165-172. </pages>
Reference: [LM87] <author> H. Lu, K. Mikkilineni and J. P. Richardson, </author> <title> ``Design and Evaluation of Algorithms to Compute the Transitive Closure of a Database Relation'', </title> <booktitle> Proc. IEEE 3rd Int'l Conf. Data Engineering, </booktitle> <address> Los Angeles, California, </address> <month> Feb. </month> <year> 1987, </year> <pages> 112-119. </pages>
Reference-contexts: As a result, it only requires successor lists there is no need to maintain predecessor lists as well. Yet, the locality of reference of the algorithm is still poor. A straightforward implementation of Warren's algorithm in <ref> [LM87] </ref> found that the algorithm did well (compared to iterative algorithms) only when the memory size was not much smaller than the final transitive closure size. 5.2.3 Warshall-Derived Algorithms In [ADJ90, AgJ87] the following observation was made. <p> Warshall-derived algorithms can be generalized in a similar fashion. A generalization of Warren's algorithm (in the relational form of <ref> [LM87] </ref>) is given in [CrN89], and generalizations of the blocking algorithms are given in [ADJ90]. 5.2.6 Completeness We establish the completeness of Warshall's algorithm using the sufficient condition given in the lemma below.
Reference: [Lu87] <author> H. Lu, </author> <title> ``New Strategies for Computing the Transitive Closure of a Database Relation'', </title> <booktitle> Proc. 13th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brighton, England, </address> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: Several variations on this basic iterative algorithm have been proposed in the literature <ref> [ADJ89, GKB87, Ioa86, Lu87, VaB86] </ref>, and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> However, several performance studies indicate that the Semi-naive algorithm usually outperforms the logarithmic algorithms (see for example [KIC92]). In addition, the Semi-naive algorithm can handle selection on source nodes, which the logarithmic algorithms cannot handle efficiently. 5.1.3 Lu's Algorithm Lu's HYBRIDTC algorithm <ref> [Lu87] </ref> is essentially an implementation of the Semi-naive algorithm based on hash-join [DKO84].
Reference: [LZH90] <author> W. S. Luk, W. Zhang and J. Han, </author> <title> ``Path: An Approach to Incorporate List Processing in a Relational Database'', </title> <booktitle> 2nd Int'l Conf. </booktitle> <institution> on Software Eng. and Knowledge Eng., Skokie, Illinois, </institution> <year> 1990. </year>
Reference-contexts: Another reason is that the initial clause, iteration clause, selection on the start nodes and termination condition are specified separately. In the proposal of [Lin87] the user must specify termination conditions explicitly, for example, by including in the query a check for acyclicity. In <ref> [LZH90] </ref>, the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. <p> As in [Eng87, MFP90, Sha88, Sha87, Sul87], this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view. To create a path view, <ref> [LZH90] </ref> introduce several new keywords (PATH-VIEW, PATH-STRUCTURE, EDGE, PATH) and built-in functions (CREATE-PATH (edge), APPEND (path, edge), CONCATENATE (path, path)). Equality ( ``='') is used in the WHERE clause to perform assignments, which is a significant deviation from normal (side-effect free) SQL semantics. <p> Corollary Path-set condensation can be used in the presence of selections on the source or destination nodes. 60 61 4.5 Related Work In the context of generalized transitive closure, optimization ideas have been suggested, among others, in <ref> [LZH90, RHD86] </ref>. Rosenthal et al [RHD86] have proposed the pushing of monotonic constraints and showed how monotonicity constraints on functions can be identified. Luk et al [LZH90] considered algorithms in which a path and an arc are joined to form new paths (sparse-standard algorithms, in the terminology of [UlY90]). <p> Rosenthal et al [RHD86] have proposed the pushing of monotonic constraints and showed how monotonicity constraints on functions can be identified. Luk et al <ref> [LZH90] </ref> considered algorithms in which a path and an arc are joined to form new paths (sparse-standard algorithms, in the terminology of [UlY90]). They identified different points in the closure computation where selections can be applied. Compared to these, our work is more general.
Reference: [Meh84] <author> K. Mehlhorn, </author> <title> Graphs Algorithms and NP Completeness, </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference: [Mel92] <editor> J. Melton, (ed.), </editor> <title> ``(ISO-ANSI Working Draft) Database Language SQL (SQL3)'', ANSI X3.135-1992, </title> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: Thus a recursive query looks like a regular query on a previously defined recursive structure. Conceivably, label computation could be added to the model as part of the definition of a recursive structure. 3.4.3 Generalized Transitive Closure vs. General Recursion The ANSI/SQL proposal <ref> [Mel92] </ref> and SBSQL [MFP90] are capable of expressing recursive queries that cannot be expressed in SQL/TC. However, the formulation of generalized transitive closure queries is more natural and direct in SQL/TC than it is in those proposals.
Reference: [MeW89] <author> A. O. Mendelzon and P. T. Wood, </author> <title> ``Finding Regular Simple Paths in Graph Databases'', </title> <booktitle> Proc. 15th Int'l Conf. Very Large Data Bases, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> Aug. </month> <year> 1989, </year> <pages> 185-194. 121 122 </pages>
Reference: [Mit89] <author> P. B. Mitschang, </author> <title> ``Extending the Relational Algebra to Capture Complex Objects'', </title> <booktitle> Proc. 15th Int'l Conf. Very Large Data Bases, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> Aug. </month> <year> 1989, </year> <pages> 297-305. </pages>
Reference-contexts: Formulation of transitive closure queries is also possible in MQL, an extension of SQL to support the Molecule-Atom data model (MAD) <ref> [HMM87, Mit89] </ref>. The closure relationship is embedded in the data model, using the concept of association. Thus a recursive query looks like a regular query on a previously defined recursive structure.
Reference: [Moh88] <author> C. Mohan, </author> <type> Personal Communication, </type> , <year> 1988. </year>
Reference-contexts: The performance study involved trees only, and duplicate elimination was not considered. 5.1.4 Single-Sided Composition Iterative algorithms are essentially a sequence of composition operations Each composition operation comprises 3 steps: i) join, ii) projection, and iii) duplicate elimination. Some systems (System R <ref> [Moh88] </ref> and Ingres [Sto88], for example) combine the first two steps and do projection at the same time as the join is being computed, but all the systems that we know of make a separate pass for removing duplicates.
Reference: [MFP90] <author> I. Mumick, S. Finkelstein, H. Pirahesh and R. Ramakrishnan, </author> <title> ``Magic Conditions'', </title> <booktitle> Proc. 9th Symp. Principles of Database Systems, </booktitle> <year> 1990, </year> <pages> 314-330. </pages>
Reference-contexts: This is because the input to the closure operation is referenced in both subqueries. 6. In the ANSI/SQL proposal it is not possible to retrieve the complete path (Query III). Another extension of SQL that supports recursive queries is SBSQL, developed in the Starburst project <ref> [MFP90] </ref>. The formulation of transitive closure queries in SBSQL is similar to the ANSI/SQL proposal, and in our opinion suffers from similar deficiencies. 3.4.1.1 Termination In [Sha87], cycle detection to avoid infinite recursion is an option that can be ``turned on'' by the user. <p> In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view. <p> Thus a recursive query looks like a regular query on a previously defined recursive structure. Conceivably, label computation could be added to the model as part of the definition of a recursive structure. 3.4.3 Generalized Transitive Closure vs. General Recursion The ANSI/SQL proposal [Mel92] and SBSQL <ref> [MFP90] </ref> are capable of expressing recursive queries that cannot be expressed in SQL/TC. However, the formulation of generalized transitive closure queries is more natural and direct in SQL/TC than it is in those proposals. <p> In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see [RSS92, Ull89]). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. <ref> [BKM89, MFP90, SrRar] </ref>) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> C &lt;= 1000, and the recognition of monotonicity of derivations, e.g. that a fact path (x,y,c) where c &gt; 1000, cannot give rise, via rule QB2, to a new fact path (x ,y ,c ), such that c 1000. Constraint propagation has been studied, among others, in <ref> [BKM89, MFP90, SrRar] </ref>. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. <p> Constraint propagation has been studied, among others, in [BKM89, MFP90, SrRar]. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. Mumick et al <ref> [MFP90] </ref> introduce the "c" (condition) adornment class, and develop an extension of the magic 61 62 templates algorithm [Ram88], called GMT (ground magic templates), which ensures that all rules are range-restricted.
Reference: [MPR90] <author> I. Mumick, H. Pirahesh and R. Ramakrishnan, </author> <title> ``The Magic of Duplicates and Aggregates'', </title> <booktitle> Proc. 16th Int'l Conf. Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: They can be applied to any SQL query involving aggregation, where a constraint is specified on the aggregated value. To the best of our knowledge, such optimization of aggregation queries is not employed in current SQL implementations (see also <ref> [MPR90] </ref>). 4.4 Representing Paths and Path-Sets In this section we consider the storage requirement for representing paths and path-sets in the transitive closure. <p> More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. <ref> [GGZ91, MPR90, RoS92, SuR91] </ref>). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in <ref> [GGZ91, MPR90, RoS92, Sri93, SuR91] </ref>. In [MPR90] a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. <p> Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in [GGZ91, MPR90, RoS92, Sri93, SuR91]. In <ref> [MPR90] </ref> a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. A program is monotonic if it comprises only monotonic rules. <p> They define a class of cost-monotonic min or max programs and provide semantics for it by transforming each subgoal involving aggregation into an equivalent one using negation. Ross and Sagiv [RoS92] provide a more general definition of monotonicity that combines the monotonicity of <ref> [MPR90] </ref> with the cost-monotonicity of [GGZ91]: a rule is monotonic if adding new facts to a subgoal, or increasing the cost of previously derived facts, can only add new facts to the head of the rule, or increase the cost of previously derived facts. <p> QC: s_path (X,?,MIN_C), MIN_C &lt;= 1000, X &gt; 5 As we suggested in Section 4.4.6, constraints on a group-by variable can be pushed without change through the grouping subgoal. In this example, the constraint X &gt; 5 can be pushed from rule PC3 to rule PC2 (see e.g <ref> [MPR90] </ref>). Constraints on the aggregate value may be used to derive constraints on the aggregated variable.
Reference: [MFP90] <author> I. Mumick, S. Finkelstein, H. Pirahesh and R. Ramakrishnan, </author> <title> ``Magic is Relevant'', </title> <booktitle> Proc. ACM-SIGMOD 1990 Int'l Conf. on Management of Data, </booktitle> <year> 1990, </year> <pages> 247-258. </pages>
Reference-contexts: This is because the input to the closure operation is referenced in both subqueries. 6. In the ANSI/SQL proposal it is not possible to retrieve the complete path (Query III). Another extension of SQL that supports recursive queries is SBSQL, developed in the Starburst project <ref> [MFP90] </ref>. The formulation of transitive closure queries in SBSQL is similar to the ANSI/SQL proposal, and in our opinion suffers from similar deficiencies. 3.4.1.1 Termination In [Sha87], cycle detection to avoid infinite recursion is an option that can be ``turned on'' by the user. <p> In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view. <p> Thus a recursive query looks like a regular query on a previously defined recursive structure. Conceivably, label computation could be added to the model as part of the definition of a recursive structure. 3.4.3 Generalized Transitive Closure vs. General Recursion The ANSI/SQL proposal [Mel92] and SBSQL <ref> [MFP90] </ref> are capable of expressing recursive queries that cannot be expressed in SQL/TC. However, the formulation of generalized transitive closure queries is more natural and direct in SQL/TC than it is in those proposals. <p> In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see [RSS92, Ull89]). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. <ref> [BKM89, MFP90, SrRar] </ref>) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> C &lt;= 1000, and the recognition of monotonicity of derivations, e.g. that a fact path (x,y,c) where c &gt; 1000, cannot give rise, via rule QB2, to a new fact path (x ,y ,c ), such that c 1000. Constraint propagation has been studied, among others, in <ref> [BKM89, MFP90, SrRar] </ref>. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. <p> Constraint propagation has been studied, among others, in [BKM89, MFP90, SrRar]. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. Mumick et al <ref> [MFP90] </ref> introduce the "c" (condition) adornment class, and develop an extension of the magic 61 62 templates algorithm [Ram88], called GMT (ground magic templates), which ensures that all rules are range-restricted.
Reference: [MuP91] <author> I. Mumick and H. Pirahesh, </author> <title> ``Overbound and Right-Linear Queries'', </title> <booktitle> Proc. 10th Symp. Principles of Database Systems, </booktitle> <address> Denver, Colorado, </address> <month> May </month> <year> 1991, </year> <pages> 127-141. </pages>
Reference-contexts: An alternative approach is to provide general recursion in the language and to attempt to recognize when a recursive query is actually a transitive closure of some kind. This approach was explored, among others, in <ref> [MuP91, NRS89, Sar89, ZYT90] </ref>. 3.5 Summary We have extended SQL to allow the expression of recursive queries based on the generalized transitive closure paradigm. The extension, SQL/TC, permits the user to pose queries that compute paths between two nodes and information associated with these paths. <p> Number of deductions [BeR87, Jak91, Jak92, NRS89]. This is a standard metric in recursive query processing. In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived <ref> [MuP91] </ref>. For transitive closure, it corresponds to the number of distinct tuples generated, excluding duplicates. 4. I/O complexity [UlY90]. This metric is based on the Kung-Hong model [HoK80]. Essentially, Ullman and Yannakakis assume a main memory of size s ``values'' (e.g., nodes or tuples), where n &lt; s &lt; e.
Reference: [NaT89] <author> S. Naqui and S. Tsur, </author> <title> ``A Logical Language for Data and Knowledge Bases'', </title> <booktitle> in Principles of Computer Science, </booktitle> <editor> A. V. Aho and J. D. Ullman (ed.), </editor> <publisher> Computer Science Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference: [NRS89] <author> J. F. Naughton, R. Ramakrishnan, Y. Sagiv and J. D. Ullman, </author> <title> ``Efficient Evaluation of Right-, Left-, and Multi-Linear Rules'', </title> <booktitle> Proc. ACM-SIGMOD 1989 Int'l Conf. Management of Data, </booktitle> <address> Portland, Oregon, </address> <month> May-June </month> <year> 1989, </year> <pages> 235-242. </pages>
Reference-contexts: An alternative approach is to provide general recursion in the language and to attempt to recognize when a recursive query is actually a transitive closure of some kind. This approach was explored, among others, in <ref> [MuP91, NRS89, Sar89, ZYT90] </ref>. 3.5 Summary We have extended SQL to allow the expression of recursive queries based on the generalized transitive closure paradigm. The extension, SQL/TC, permits the user to pose queries that compute paths between two nodes and information associated with these paths. <p> However, the number of operations may also be measured on actual input graphs [Sch83]. In either case, this measure is most useful when the computation is memory resident since it does not take I/O into account. 2. Number of deductions <ref> [BeR87, Jak91, Jak92, NRS89] </ref>. This is a standard metric in recursive query processing. In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived [MuP91].
Reference: [PiA86] <author> P. Pistor and F. Andersen, </author> <title> ``Designing A Generalized NF2 Model With an SQL-Type Interface'', </title> <booktitle> Proc. 12th Int'l Conf. on Very Large Databases, </booktitle> <address> Kyoto, Japan, </address> <month> Aug. </month> <year> 1986, </year> <pages> 278-285. </pages>
Reference-contexts: The generalization of the relational model to non-first normal form attributes has received wide attention (see, for example, [ScS86]). Extensions of SQL for a nested relation model have been presented, among others, in <ref> [PiA86, RKB87] </ref>. While it is true that in an SQL extended with non-first normal form relations, the implementation of PATH would be easier, this is not a necessary requirement. <p> The proposed extension can express selection on end nodes, label concatenation, and retrieval of path information. However, we find the query formulation quite complicated. One reason is that type constructors for tuples, sets, and lists must be specified in the query, as in <ref> [PiA86] </ref>. Another reason is that the initial clause, iteration clause, selection on the start nodes and termination condition are specified separately. In the proposal of [Lin87] the user must specify termination conditions explicitly, for example, by including in the query a check for acyclicity.
Reference: [Pur70] <author> P. Purdom, </author> <title> ``A Transitive Closure Algorithm'', </title> <type> BIT 10, </type> <year> (1970), </year> <pages> 76-94. </pages>
Reference-contexts: Definition (Topological Order) Given a directed acyclic graph G, a topological order on the nodes of G is an ordering , such that if (s, t) in G, then s t. 5.3.1 The Purdom Algorithm Purdom, in <ref> [Pur70] </ref>, made two key observations: 76 77 1. During the computation of transitive closure of a directed acyclic graph, if node s t, then additions to the successor list of node s cannot affect the successor list of node t. <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case. <p> We present results of experiments involving acyclic graphs only, for the following reasons. First, several of the algorithms that we study are only applicable to acyclic graphs (e.g. [DaJ92, Jak92]). Second, for reachability queries, the closure of a cyclic graph can be computed using the Purdom algorithm <ref> [Pur70] </ref> by collapsing strongly connected components and computing the closure of the resulting acyclic condensation graph. This technique has been shown to be a strong optimization (see e.g. [GKS91]) and is used by all of the algorithms that we study except the Search algorithm.
Reference: [QHK89] <author> G. Qadah, L. Henschen and J. Kim, </author> <title> ``The Efficient Processing of Instantiated Transitive Closure Queries'', </title> <institution> Northwestern University Technical Memorandum, Evanston, Illinois, </institution> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: iterations before convergence. 5.1.5 Partial Transitive Closure The Semi-naive algorithms can be adapted to handle selections on a set S of source nodes in by changing the initialization phase as follows: R f -t R 0 t. src S-; The resulting Semi-naive evaluation has also been called the d-Wavefront algorithm <ref> [QHK89] </ref>. 5.1.6 Generalized Transitive Closure To perform label computations, the Semi-naive algorithm can be generalized as follows [ADJ88b, CrN89]: 68 69 R D R 0 ; while (R f changes) - R D AGG (CON (R D ,R 0 ) ); - When the path problem is ordered, we can ignore
Reference: [RSS92] <author> R. Ramakrishnan, D. Srivastava and S. Sudarshan, </author> <title> ``Efficient Bottom-up Evaluation of Logic Programs'', </title> <booktitle> in The State of the Art in Computer Systems and Software Engineering, </booktitle> <editor> J. Vandewalle (ed.), </editor> <publisher> Kluwer Academic Publishers, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see <ref> [RSS92, Ull89] </ref>). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog.
Reference: [Ram88] <author> R. Ramakrishnan, </author> <title> ``Magic Templates: A Spellbinding Approach to Logic Programs'', </title> <booktitle> Proc. 5th Int'l Conference on Logic Programming, </booktitle> <address> Seatlle, Washington, </address> <month> Aug. </month> <year> 1988, </year> <pages> 140-159. </pages>
Reference-contexts: Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. Mumick et al [MFP90] introduce the "c" (condition) adornment class, and develop an extension of the magic 61 62 templates algorithm <ref> [Ram88] </ref>, called GMT (ground magic templates), which ensures that all rules are range-restricted. Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints.
Reference: [RHD86] <author> A. Rosenthal, S. Heiler, U. Dayal and F. Manola, </author> <title> ``Traversal Recursion: A Practical Approach to Supporting Recursive Applications'', </title> <booktitle> Proc. ACM-SIGMOD 1986 Int'l Conf. on Management of Data, </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1986, </year> <pages> 166-176. </pages>
Reference-contexts: Corollary Path-set condensation can be used in the presence of selections on the source or destination nodes. 60 61 4.5 Related Work In the context of generalized transitive closure, optimization ideas have been suggested, among others, in <ref> [LZH90, RHD86] </ref>. Rosenthal et al [RHD86] have proposed the pushing of monotonic constraints and showed how monotonicity constraints on functions can be identified. Luk et al [LZH90] considered algorithms in which a path and an arc are joined to form new paths (sparse-standard algorithms, in the terminology of [UlY90]). <p> Corollary Path-set condensation can be used in the presence of selections on the source or destination nodes. 60 61 4.5 Related Work In the context of generalized transitive closure, optimization ideas have been suggested, among others, in [LZH90, RHD86]. Rosenthal et al <ref> [RHD86] </ref> have proposed the pushing of monotonic constraints and showed how monotonicity constraints on functions can be identified. Luk et al [LZH90] considered algorithms in which a path and an arc are joined to form new paths (sparse-standard algorithms, in the terminology of [UlY90]).
Reference: [Ros90] <author> K. A. Ross, </author> <title> ``Modular Stratification and Magic Sets for DATALOG programs with negation'', </title> <booktitle> Proc. 9th Symp. Principles of Database Systems, </booktitle> <address> Nashville, Tennessee, </address> <month> April </month> <year> 1990, </year> <pages> 161-171. </pages>
Reference-contexts: But, assuming that the underlying graph represented by relation assembly is acyclic, it is possible to give semantics to program PD' based on modular stratification (see e.g. <ref> [Gel92, Ros90, SSR93] </ref>) since the derivation of a specific fact for predicate contains will not depend on the same fact.
Reference: [RoS92] <author> K. A. Ross and Y. Sagiv, </author> <title> ``Monotonic Aggregation in Deductive Databases'', </title> <booktitle> Proc. 11th Symp. Principles of Database Systems, </booktitle> <address> San Diego, California, </address> <month> June </month> <year> 1992, </year> <pages> 114-126. 122 123 </pages>
Reference-contexts: More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. <ref> [GGZ91, MPR90, RoS92, SuR91] </ref>). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in <ref> [GGZ91, MPR90, RoS92, Sri93, SuR91] </ref>. In [MPR90] a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. <p> They define a class of cost-monotonic min or max programs and provide semantics for it by transforming each subgoal involving aggregation into an equivalent one using negation. Ross and Sagiv <ref> [RoS92] </ref> provide a more general definition of monotonicity that combines the monotonicity of [MPR90] with the cost-monotonicity of [GGZ91]: a rule is monotonic if adding new facts to a subgoal, or increasing the cost of previously derived facts, can only add new facts to the head of the rule, or increase <p> Yet it is possible to give semantics to program PC' based on monotonicity, as we discussed above <ref> [GGZ91, RoS92, SuR91] </ref>. 63 However, the idea behind the transformation from program PC to program PC' is applicable to more than just maximizing path problems.
Reference: [RKB87] <author> M. A. Roth, H. F. Korth and D. S. Batory, ``SQL/NF: </author> <title> A Query Langage For 1NF Relational Databases'', </title> <booktitle> Information Systems 12, 1 (1987), </booktitle> <pages> 99-114. </pages>
Reference-contexts: The generalization of the relational model to non-first normal form attributes has received wide attention (see, for example, [ScS86]). Extensions of SQL for a nested relation model have been presented, among others, in <ref> [PiA86, RKB87] </ref>. While it is true that in an SQL extended with non-first normal form relations, the implementation of PATH would be easier, this is not a necessary requirement.
Reference: [Sar89] <author> Y. P. Saraiya, </author> <title> ``Linearizing Non-Linear Recursions in Polynomial Time'', </title> <booktitle> Proc. 8th Symp. Principles of Database Systems, </booktitle> <year> 1989. </year>
Reference-contexts: An alternative approach is to provide general recursion in the language and to attempt to recognize when a recursive query is actually a transitive closure of some kind. This approach was explored, among others, in <ref> [MuP91, NRS89, Sar89, ZYT90] </ref>. 3.5 Summary We have extended SQL to allow the expression of recursive queries based on the generalized transitive closure paradigm. The extension, SQL/TC, permits the user to pose queries that compute paths between two nodes and information associated with these paths.
Reference: [ScS86] <author> H. J. Schek and M. Scholl, </author> <title> ``The Relation Model with Relation-Valued Attributes'', </title> <booktitle> Information Systems 11, </booktitle> <month> 2 </month> <year> (1986), </year> . 
Reference-contexts: The generalization of the relational model to non-first normal form attributes has received wide attention (see, for example, <ref> [ScS86] </ref>). Extensions of SQL for a nested relation model have been presented, among others, in [PiA86, RKB87]. While it is true that in an SQL extended with non-first normal form relations, the implementation of PATH would be easier, this is not a necessary requirement.
Reference: [Sch83] <author> L. Schmitz, </author> <title> ``An Improved Transitive Closure Algorithm'', </title> <booktitle> Computing 30, </booktitle> <year> (1983), </year> <pages> 359-371. </pages>
Reference-contexts: This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. Embellishments on this basic algorithm have been suggested, among others, in <ref> [Ebe81, EvK77, GoK79, IRW, Jia90, Sch83] </ref> and are described in the following subsections. 5.3.2 The Eve and Kurki-Suonio Algorithm Eve and Kurki-Suonio [EvK77] observed that it was possible to modify Tarjan's algorithm so that the successor lists are also expanded as the strongly connected components were being determined, in effect combining <p> The union of S j with S i is therefore redundant, and Ebert's algorithm avoids this union. This optimization was also utilized in <ref> [Sch83] </ref> and in several algorithms in [AgJ90, IRW]. <p> The combination of topological sort and the marking optimization was used, among others, in the Hybrid algorithm [AgJ90] and the BTC algorithm [IRW]. Both algorithms demonstrated that the redundant work avoided by the marking optimization far outweighed the extra cost of the topological sort. 5.3.5 The Schmitz Algorithm Schmitz <ref> [Sch83] </ref> noticed that the generation of (partial) successor lists for nodes other than the root node in an SCC is not necessary. He proposed an algorithm that only generates one successor list per SCC, and delays the __________________ 17. <p> In fact, there is no need to read any successors of j in the successor spanning tree of b into memory. In transitive closure algorithms that treat the whole successor list as one unit (e.g. <ref> [AgJ90, Ebe81, EvK77, IRW, IoR88, Jia90, Sch83] </ref>) , the sucessor list of b would be read in its entirety and each of its elements examined for membership in the successor list of i, thereby performing redundant work. Finally, the spanning tree of c is merged with that of i. <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case. <p> When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case. However, the number of operations may also be measured on actual input graphs <ref> [Sch83] </ref>. In either case, this measure is most useful when the computation is memory resident since it does not take I/O into account. 2. Number of deductions [BeR87, Jak91, Jak92, NRS89]. This is a standard metric in recursive query processing. <p> The Spanning Tree algorithm, although it was penalized via a 50% overhead for storing the tree structure, still outperformed Hybrid, since its selective union of successor trees avoids redundant tuple reads. Ioannidis et al [IRW] studied the performance of several graph-based algorithms including Schmitz <ref> [Sch83] </ref>, BTC, and the more complex DFS algorithms presented in [IRW]. They measured page I/O and CPU time. Overall, BTC was found to be the best algorithm with regard to both I/O and CPU cost. Ioannidis et al found that the algorithms were usually I/O bound. <p> Jiang [Jia90] investigated the computation of PTC with varying selectivity, including single-source and strong multi-source selections. He compared many graph based algorithms, including those by Eve and Kurki-Sonio [EvK77], Ebert [Ebe81], two algorithms from Schmitz <ref> [Sch83] </ref>, the DFTC algorithm from [IoR88], and several algorithms of his own [Jia90, Jia90]. The two performance metrics were the number of successor list reads and the number of successor list unions.
Reference: [Sch78] <author> C. P. Schnorr, </author> <title> ``An Algorithm for Transitive Closure with Linear Expected Time'', </title> <journal> SIAM J. Computing 7, </journal> <month> 2 (May </month> <year> 1978), </year> <pages> 127-133. </pages>
Reference-contexts: Intuitively, a complete transitive closure algorithm never infers the existence of a path without actually constructing that path. An example of an algorithm that is not complete is the Schnorr algorithm <ref> [Sch78] </ref>. In this algorithm, a successor list is built for each node exactly until it includes half the nodes in the graph and no more. It is evident that this algorithm does not examine every path and hence it is not complete. <p> Then execute algorithm TC on G. Since the order of computation is the same, the computation should not consider any path in G that was not considered in G. Therefore tuple (i, j) will not be generated. In Section 4.4.4.1 we have given the Schnorr algorithm <ref> [Sch78] </ref> as an example of an algorithm that is not complete. Since the stopping condition in this algorithm depends on the number of successors found for a particular node, we see that the algorithm is also not order-invariant. Theorem 5.1 Warshall's algorithm is complete. Proof Warshall's algorithm is order-invariant. <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case.
Reference: [SeN91] <author> S. Seshadri and J. F. Naughton, </author> <title> ``On the Expected Size of Recursive Datalog Queries'', </title> <booktitle> Proc. 10th Symp. Principles of Database Systems, </booktitle> <address> Denver, Colorado, </address> <year> 1991, </year> <pages> 268-279. </pages>
Reference-contexts: Third, random graphs generated with an out degree greater than 1 tend to have most nodes concentrated in one large strongly connected component (see <ref> [Kar90, SeN91] </ref>). Hence, the condensation graph of these random graphs is quite small. __________________ 20. The reader may note that the number of arcs is often less than N F.
Reference: [Sha88] <author> P. Shaw, </author> <title> ``A Generalization of Recursive Expressions for Non-Linear Recursion of fixed Degree'', ANSI X3H2-88-93REV, </title> <month> April </month> <year> 1988. </year>
Reference-contexts: Such a TIMEOUT mechanism, however, should be available for any query and not limited just to CLOSURE queries. 3.4.1.2 Search Order In [Eng87] and <ref> [Sha88] </ref>, a SEARCH clause is proposed that allows the user to specify the search order as either depth-first, breadth-first or user-defined. The presumed purpose of the search order specification is to allow the user to extract structural information about the underlying graph. <p> The presumed purpose of the search order specification is to allow the user to extract structural information about the underlying graph. This is done by introducing generated ``structural'' attributes `TREE', `NODE' and `LEVEL' in [Eng87], and `PARENT' and `NODE' in <ref> [Sha88] </ref>. The `LEVEL' attribute specifies the distance, in number of arcs, between the given node and the root node for this query. Its value is independent of the search order. The `TREE', `PARENT' and `NODE' attributes assign numbers to nodes according to the search strategy indicated in the search clause. <p> The `TREE', `PARENT' and `NODE' attributes assign numbers to nodes according to the search strategy indicated in the search clause. For example, a node can be identified as the 4th node in the 2nd tree in [Eng87], or as node 12 with parent node 5 in <ref> [Sha88] </ref>. So-called ``structural'' information, by its nature, should presumably be independent of the order in which the underlying graph was traversed. But the above ``structural'' attributes have different values when different search orders are used. Therefore, we doubt the value of the `TREE', `PARENT', and `NODE' attributes. <p> Therefore, we doubt the value of the `TREE', `PARENT', and `NODE' attributes. In contrast, the structural information in the PATH relation is independent of the traversal order of the underlying graph. We believe that the choice of search order should be made by the implementation. <ref> [Sha88] </ref> suggests using a search-clause followed by an order-clause (sort) to allow the closure result to be presented in an ``indented'' way, e.g., print a type hierarchy in breadth-first order. Yet, it seems that a graphical interface such as G+ [CMW88] would be more effective for that purpose. <p> In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view.
Reference: [Sha87] <author> P. Shaw, </author> <title> ``CLOSURE Expressions'', ANSI X3H2-87-330, </title> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: Another extension of SQL that supports recursive queries is SBSQL, developed in the Starburst project [MFP90]. The formulation of transitive closure queries in SBSQL is similar to the ANSI/SQL proposal, and in our opinion suffers from similar deficiencies. 3.4.1.1 Termination In <ref> [Sha87] </ref>, cycle detection to avoid infinite recursion is an option that can be ``turned on'' by the user. If this option is turned off, then given a relation representing a cyclic graph, it is possible for a user to specify an ill-formed query whose evaluation results in infinite recursion. <p> If this option is turned off, then given a relation representing a cyclic graph, it is possible for a user to specify an ill-formed query whose evaluation results in infinite recursion. To remedy this problem, <ref> [Sha87] </ref> proposes a LIMIT clause to limit the number of tuples in the result. We feel that this parameter is arbitrary and difficult to set intelligently. It will be better to limit the depth of the recursion, that is, the maximum length of any path. <p> In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view.
Reference: [SiS88] <author> S. Sippu and E. Soisalon-Soininen, </author> <title> ``A Generalized Transitive Closure for Relational Queries'', </title> <booktitle> Proc. 7th Symp. Principles of Database Systems, </booktitle> <month> March </month> <year> 1988. </year>
Reference: [SHS87] <author> D. L. Spooner, M. Hardwick and G. Samaras, </author> <title> ``Some Conceptual Ideas For Extending SQL For Object-Oriented Engineering Database Systems'', </title> <booktitle> Proc. IEEE 1st Int'l Conf. on Data and Knowledge Systems for Manufacturing and Engineering, </booktitle> <month> Oct. </month> <year> 1987, </year> <pages> 163-169. </pages>
Reference-contexts: Its functionality is similar to transitive closure, but limited to traversal of a disjoint hierarchical structure with instantiated roots (selection on start nodes). A transitive closure operator was also needed to traverse a shared (overlapping) hierarchy of objects. A QUEL extension utilizing both operators was presented. A later paper, <ref> [SHS87] </ref>, generalized the transitive closure to an Alpha operator based on a [Agr87]. An SQL extension was illustrated by queries on different types of complex objects. However, neither the selections (r operator) nor the label computation capabilities (m list) of a are used.
Reference: [Sri93] <author> D. Srivastava, </author> <title> ``Representing and Querying Complex Information in the CORAL Deductive Database System'', </title> <institution> Univ. Wisconsin, Madison, Madison, Wisconsin, </institution> <year> 1993. </year> <type> Ph.D. Dissertation. </type>
Reference-contexts: Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in <ref> [GGZ91, MPR90, RoS92, Sri93, SuR91] </ref>. In [MPR90] a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. <p> Srivastava <ref> [Sri93] </ref> develops a general model of constraint projection that subsumes most of the previous work on monotonicity and constraint propagation. <p> Constraints on the aggregate value may be used to derive constraints on the aggregated variable. In this example, the constraint MIN_C &lt;= 1000 on rule PC3 may be used to derive the constraint C &lt;= 1000 for rule PC2 (see <ref> [Sri93] </ref>). 64 4.6 Summary We presented techniques for optimizing Generalized Transitive Closure queries. The following are the main results: 1.
Reference: [SrRar] <author> D. Srivastava and R. Ramakrishnan, </author> <title> ``Pushing Constraint Selections'', </title> <journal> Journal of Logic Programming, </journal> <note> to appear. (Preliminary version appeared as: </note> <author> D. Srivastava and R. Ramakrishnan, </author> <title> ``Pushing Constraint Selections'', </title> <booktitle> Proc. 11th Symp. Principles of Database Systems, </booktitle> <address> San Diego, California, </address> <month> June </month> <year> 1992). </year>
Reference-contexts: In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see [RSS92, Ull89]). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. <ref> [BKM89, MFP90, SrRar] </ref>) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> C &lt;= 1000, and the recognition of monotonicity of derivations, e.g. that a fact path (x,y,c) where c &gt; 1000, cannot give rise, via rule QB2, to a new fact path (x ,y ,c ), such that c 1000. Constraint propagation has been studied, among others, in <ref> [BKM89, MFP90, SrRar] </ref>. Balbin et al [BKM89] push conditions into recursive rules by adding a fold/unfold preprocessing phase to the magic set rewriting algorithm. <p> Mumick et al [MFP90] introduce the "c" (condition) adornment class, and develop an extension of the magic 61 62 templates algorithm [Ram88], called GMT (ground magic templates), which ensures that all rules are range-restricted. Srivastava and Ramakrishnan <ref> [SrRar] </ref> consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in [GGZ91, MPR90, RoS92, Sri93, SuR91].
Reference: [Sto88] <author> M. Stonebraker, </author> <type> Personal Communication, </type> , <year> 1988. </year>
Reference-contexts: The performance study involved trees only, and duplicate elimination was not considered. 5.1.4 Single-Sided Composition Iterative algorithms are essentially a sequence of composition operations Each composition operation comprises 3 steps: i) join, ii) projection, and iii) duplicate elimination. Some systems (System R [Moh88] and Ingres <ref> [Sto88] </ref>, for example) combine the first two steps and do projection at the same time as the join is being computed, but all the systems that we know of make a separate pass for removing duplicates.
Reference: [SSR93] <author> S. Sudarshan, D. Srivastava, R. Ramakrishnan and C. Beeri, </author> <title> ``Extending the Well-Founded and Valid Semantics for Aggregation'', </title> <booktitle> Proc. Int'l Logic Programming Symposium, </booktitle> <address> Vancouver, B.C., Canada, </address> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: But, assuming that the underlying graph represented by relation assembly is acyclic, it is possible to give semantics to program PD' based on modular stratification (see e.g. <ref> [Gel92, Ros90, SSR93] </ref>) since the derivation of a specific fact for predicate contains will not depend on the same fact.
Reference: [SuR91] <author> S. Sudarshan and R. Ramakrishnan, </author> <title> ``Aggregation and Relevance in Deductive Databases'', </title> <booktitle> Proc. of the 17th Int'l Conf. on Very Large Databases, </booktitle> <address> Barcelona, Spain, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. <ref> [GGZ91, MPR90, RoS92, SuR91] </ref>). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. As an example, consider program PB from Section 2.5, which computes paths in the graph and their associated length. <p> Srivastava and Ramakrishnan [SrRar] consider the propagation of arithmetic constraints, and develop a rewriting algorithm that computes the minimal set of facts necessary to answer the query given the constraints. Monotonicity has beed studied in <ref> [GGZ91, MPR90, RoS92, Sri93, SuR91] </ref>. In [MPR90] a rule is said to be monotonic if adding new instantiations to any subgoal in its body (in particular one involving aggregation), can only generate new facts for the head if the rule, but cannot invalidate previous derivations. <p> Yet it is possible to give semantics to program PC' based on monotonicity, as we discussed above <ref> [GGZ91, RoS92, SuR91] </ref>. 63 However, the idea behind the transformation from program PC to program PC' is applicable to more than just maximizing path problems. <p> Special optimizations for maximizing path algebras have been suggested in <ref> [CrN89, GGZ91, SuR91] </ref>. Cruz and Norvell [CrN89] gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. [GGZ91] presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan [SuR91] approached extremal aggregates using the notion of relevance. <p> Cruz and Norvell [CrN89] gave an algorithm for maximizing semirings based on best-first expansion (see Section 4.4.5). Ganguly et al. [GGZ91] presented a greedy fixpoint algorithm that propagates facts in increasing order of their cost. Sudarshan and Ramakrishnan <ref> [SuR91] </ref> approached extremal aggregates using the notion of relevance. Essentially, facts that are non-maximal are not relevant (useful) to the evaluation of the query, and may be ignored. They presented techniques to derive constraints on predicates that avoid generating facts when ``better'' facts are known. Finally, we consider path-set selection. <p> For reachablity, search algorithms based on BFS and on DFS are given in [Jia90]. For ordered path problems, such as shortest path, Dijkstra's algorithm achieves the optimal search order by expanding the best current successor next [Dij59]. Variations of this algorithm can be found, in <ref> [GGZ91, IRW, Jia92, SuR91] </ref>. 5.3.10 Generalized Transitive Closure Algorithms that compute transitive closure using the condensation graph are not complete, and cannot be directly adapted for generalized transitive closure computation.
Reference: [Sul87] <author> J. Sullivan, </author> <title> ``Tree Structured Traversal'', ANSI X3H2-87-306, </title> <month> Nov. </month> <year> 1987. </year> <pages> 123 124 </pages>
Reference-contexts: In [LZH90], the relational model is extended with a path structure, similar to our PATH relation. To express a generalized transitive closure query, a path view, similar to our transitive closure relation, must first be defined, using the CREATE PATH-VIEW statement. As in <ref> [Eng87, MFP90, Sha88, Sha87, Sul87] </ref>, this statement comprises an initial subquery and a recursive subquery. Queries with specific selection criteria can then be formulated against the path view.
Reference: [Tar72] <author> R. Tarjan, </author> <title> ``Depth-First Search and Linear Graph Algorithms'', </title> <journal> SIAM J. Computing 1, </journal> <year> (1972), </year> <pages> 146-160. </pages>
Reference-contexts: The complexity of Purdom's algorithm is O (nbn) = O (ne) [Yan90], since for each node, we process on average b arcs leading to its immediate successors, and each one of these may have O (n) successors. Tarjan <ref> [Tar72] </ref> independently developed an efficient algorithm for determining strongly connected components of a graph by means of a depth-first search. This algorithm also produces as a by-product a topological sort on the components. Thus it can be used to perform phases 1 and 2 of Purdom's algorithm. <p> An extended topological sort ordering of a cyclic graph such that the root of an SCC has the highest rank in the SCC may be established by the standard algorithm for topological sort and SCC recognition <ref> [Tar72] </ref>. The combined effect of numbering the nodes by an extended topological sort, expanding nodes in reverse topological order, and handling SCC nodes as described above is the root optimization only one successor list is built per SCC.
Reference: [Tri82] <author> K. S. Trivedi, </author> <title> Probability and Statistics With Reliability, Queuing, </title> <booktitle> and Computer Science Applications, </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: Query Parameters Unlike most previous studies, we used statistical methods to evaluate our graph generation routines. Specifically, we used the Kolmogorov-Smirnov test <ref> [Tri82] </ref> to verify that the generated graphs are approximately normally distributed with respect to both the closure size and the total number of I/O's spent in computing the closure (using the BTC algorithm).
Reference: [Ull89] <author> J. D. Ullman, </author> <title> Database and Knowledge-Base Systems (Volume 2), </title> <publisher> Computer Science Press, </publisher> <year> 1989. </year>
Reference-contexts: In the rewritten program, predicates are adorned, e.g. with "b or f" (bound or free) adornments, to indicate the binding of their arguments (see <ref> [RSS92, Ull89] </ref>). More recent work has extended magic optimization techniques to handle conditions other than equality (see e.g. [BKM89, MFP90, SrRar]) and aggregate functions (see e.g. [GGZ91, MPR90, RoS92, SuR91]). We describe this work in the remainder of this section. Let us first look at path enumeration in Datalog. <p> As an example, consider program PC from Section 2.5, which computes the all-pairs shortest path problem. PC1: path (X,Y,C) :- arc (X,Y,C) PC2: path (X,Y,C) :- path (X,Z,C1), arc (Z,Y,C2), C = C1 + C2 PC3: s_path (X,Y,min (&lt;C&gt;)) :- path (X,Y,C) The standard bottom-up evaluation <ref> [Ull89] </ref> of this program is similar to Algorithm 0 of Section 4.3.1 it first constructs all the paths in the graph, and then computes the shortest paths between pairs of nodes. <p> PC'1: path (X,Y,C) :- arc (X,Y,C) PC'2: path (X,Y,C) :- s_path (X,Z,C1), arc (Z,Y,C2), C = C1 + C2 PC'3: s_path (X,Y,min (&lt;C&gt;)) :- path (X,Y,C) Program PC' is no longer stratified <ref> [Ull89] </ref>: the evaluation of predicate path in rule PC'2, required for instantiating the set &lt;C&gt; and evaluating predicate s_path in rule PC'3, depends itself on the predicate s_path. <p> We refer to this graph as the magic graph [Jak92] since it includes exactly the arcs (facts) that would be deduced by magic optimization of the corresponding selection query (see e.g. <ref> [Ull89] </ref>). 79 80 e f g l h e f g l (b)(a) Graph algorithms that compute single-source or multi-source partial transtive closure have been presented in [IRW, Jak92, Jia90]. 5.3.8 The Jiang Algorithm Jiang [Jia90] observed that for multi-source queries, a further reduction of the input graph is possible.
Reference: [UlY90] <author> J. D. Ullman and M. Yannakakis, </author> <title> ``The Input/Output Complexity of Transitive Closure'', </title> <booktitle> Proc. ACM-SIGMOD 1990 Int'l Conf. on Management of Data, </booktitle> <address> Atlantic City. </address>
Reference-contexts: We refer to the modification of T to use path condensation as T pc . Implicitly, most existing generalized transitive closure algorithms (for example, <ref> [AgJ90, ADJ90, CrN89, IRW, Jia90, UlY90] </ref>) assume that paths can suitably be represented by their condensation. However, in general, path condensation may not be used for two reasons: 1. The label concatenation function CON may not be computable using the path condensation. 2. <p> However, it may in addition consider some cyclic paths.) Complete transitive closure algorithms have also been called standard algorithms in <ref> [UlY90] </ref>. Intuitively, a complete transitive closure algorithm never infers the existence of a path without actually constructing that path. An example of an algorithm that is not complete is the Schnorr algorithm [Sch78]. <p> Rosenthal et al [RHD86] have proposed the pushing of monotonic constraints and showed how monotonicity constraints on functions can be identified. Luk et al [LZH90] considered algorithms in which a path and an arc are joined to form new paths (sparse-standard algorithms, in the terminology of <ref> [UlY90] </ref>). They identified different points in the closure computation where selections can be applied. Compared to these, our work is more general. We suggest optimizations for arc, path, and path set selections, as well as path and path-set label computations. <p> additional processing can be done as a post-processing step after the algorithm has terminated, or it can be done on-the-fly as the transitive closure is being computed. 5.2.9 The Grid Algorithm Ullman and Yannakakis proposed an algorithm for dense graphs that processes the adjacency matrix in squares rather than stripes <ref> [UlY90] </ref>. The algorithm, referred to as the Grid algorithm in [AgJ90], proceeds as follows: 75 76 Partition the matrix into f f square sub-matrices. <p> In the case of transitive closure, it corresponds to the number of tuples generated by the algorithm, including duplicates. 3. Number of distinct tuples derived [MuP91]. For transitive closure, it corresponds to the number of distinct tuples generated, excluding duplicates. 4. I/O complexity <ref> [UlY90] </ref>. This metric is based on the Kung-Hong model [HoK80]. Essentially, Ullman and Yannakakis assume a main memory of size s ``values'' (e.g., nodes or tuples), where n &lt; s &lt; e. One I/O is performed whenever a value is moved between main memory and secondary storage. <p> Tuple I/O [AgJ90, DaJ92]. The tuple I/O metric is similar to the notion of I/O complexity <ref> [UlY90] </ref>, but it involves algorithm-specific assumptions about the way I/O is done, e.g., that successor lists are read and written as a unit. (Unlike the successor list I/O model, though, reading a successor list of size n counts as n ``tuple I/O's'' rather than one ``list I/O''.) 8. <p> The results of [ADJ90, AgJ87, KIC92] demonstrated that the matrix-based algorithms out-perform the iterative algorithms for the computation of the complete transitive closure by a wide margin. 113 114 Agrawal and Jagadish [AgJ90] compared the Hybrid algorithm to the Blocked Warren algorithm [ADJ90], the Grid algorithm <ref> [UlY90] </ref> and a DFS algorithm based on [IoR88] and extended with caching of successor lists. Tuple I/O was the performance metric. Hybrid was found to be the best performer. It won over the Blocked Warren algorithm by employing the immediate successor and marking optimizations of graph-based algorithms.
Reference: [VaB86] <author> P. Valduriez and H. Boral, </author> <title> ``Evaluation of Recursive Queries Using Join Indices'', </title> <booktitle> Proc. 1st Int'l Conf. Expert Database Systems, </booktitle> <address> Charleston, South Carolina, </address> <month> April </month> <year> 1986, </year> <pages> 197-208. </pages>
Reference-contexts: Several variations on this basic iterative algorithm have been proposed in the literature <ref> [ADJ89, GKB87, Ioa86, Lu87, VaB86] </ref>, and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral [VaB86] and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> Several variations on this basic iterative algorithm have been proposed in the literature [ADJ89, GKB87, Ioa86, Lu87, VaB86], and are described in the following subsections. 5.1.2 The Logarithmic Algorithm Valduriez and Boral <ref> [VaB86] </ref> and Ioannidis [Ioa86] independently suggested a logarithmic algorithm for transitive closure. The algorithm requires just ` `d + 1 iterations, but the relations processed at each iteration are larger. <p> D ,R 0 ) ) - R f ; - Where the subtraction is defined by S - T = -( x,y,L S ) S s. t. " / ( x,y,L T ) T L T L S - A generalization, similar to (* 1 *), of the logarithmic algorithm <ref> [Ioa86, VaB86] </ref> is given in [CrN89]. 5.1.7 Completeness The Semi-naive algorithm, as generalized in (* 1 *), is complete. Each arc in R 0 represents a path of length 1 and is included in R f . <p> Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [War75] <author> H. S. Warren, </author> <title> ``A Modification of Warshall's Algorithm for the Transitive Closure of Binary Relations'', </title> <journal> Commun. ACM 18, </journal> <month> 4 (April </month> <year> 1975), </year> <pages> 218-220. </pages>
Reference-contexts: This observation motivated the design of variations on Warshall's algorithm that reduce its I/O requirement by improving the locality of reference. The following subsections describe these variations. 5.2.2 Warren's Algorithm Warren <ref> [War75] </ref> observed that processing the matrix elements row-wise is desirable if the matrix is stored as bit vectors formed row-wise with each matrix element represented as a bit, and proposed the following modification to 70 71 Warshall's algorithm: " / i = 1 " / k = 1 " / j <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case.
Reference: [War62] <author> S. Warshall, </author> <title> ``A Theorem on Boolean Matrices'', </title> <journal> J. ACM 9, </journal> <month> 1 (Jan. </month> <year> 1962), </year> <pages> 11-12. </pages>
Reference-contexts: Definition (Adjacency Matrix) The adjacency matrix of a n-node graph G is an nn boolean matrix with element a i j being 1 if there is an arc from node i to node j, and 0 otherwise. 5.2.1 Warshall's Algorithm Given an initial nn adjacency matrix, Warshall's algorithm <ref> [War62] </ref> computes the transitive closure of the matrix as follows: For k=1 to n For j=1 to n In successor list terms, one can understand the algorithm as follows: For every node k For every predecessor i of k For every successor j of k Make j a successor of i <p> k=1 to n For j=1 to n In successor list terms, one can understand the algorithm as follows: For every node k For every predecessor i of k For every successor j of k Make j a successor of i The complexity of Warshall's Algorithm is O (k 3 ) <ref> [War62] </ref>. A straightforward implementation of Warshall's algorithm may proceed as follows: For each node k, first fetch its successor list. Then for each predecessor i of k, fetch the successor list of i, and add to the successor list of i the successor list of k (removing duplicates if any). <p> That is the topic of Section 6.7. The following cost models have been used in the literature: 1. Main memory operations <ref> [Ebe81, EvK77, Pur70, Sch83, Sch78, War75, War62] </ref>. This is the standard theoretical metric, assuming equal cost operations, e.g. testing or setting of a bit in the adjacency matrix. When established analytically, this metric corresponds to the complexity of the algorithm, and is usually given for the average or worst case.
Reference: [Win92] <author> L. Winger, </author> <title> ``Analysis of Depth-First Transitive Closure Algorithms'', </title> <institution> Univ. Wisconsin, Madison, Madison, Wisconsin, 1992. M.S. Dissertation. </institution>
Reference-contexts: We call this technique the root optimization [IRW]. 5.3.6 The BTC Algorithm Ioannidis et al <ref> [IRW, Win92] </ref> proposed a DFS algorithm called BTC (Basic Transitive Closure) that incorporates most of the ideas presented in the previous subsections. In addition, they developed several implementation techniques to improve the efficiency of storing and expanding successor lists. <p> After the computation of the closure, the complete successor list of x is given by S x = - y (x,y) TC (G) -. Our implementations of the candidate algorithms are based for the most part on the implementation of BTC and other DFS algorithms in <ref> [IRW, Win92] </ref>. With the exception of the Search algorithm, all of the algorithms expand successor lists in reverse topological order and utilize the immediate successor and marking optimizations, as well as inter and intra-successor list clustering. <p> Hence, in the relation format (Figure 6.2), 256 tuples may be stored on a page. After conversion to successor list format (Figure 6.3) 450 successor may be stored on each page. (A successor list page is divided into 30 blocks, each holding up to 15 successor nodes. See <ref> [Win92] </ref> for details). A list replacement policy is used when a successor list expands to the point where at least one of the other lists on the page must be moved to a new page (i.e., the page must be split). <p> The implementation of the algorithms for this study was based on the implementation of Ioannidis et al, as described in <ref> [Win92] </ref>. Ioannidis et al also compared the performance of the graph based algorithms to the performance of the Seminaive, Smart and Blocked Warren algorithms, using the results of [KIC92], for similar graphs and buffer sizes.
Reference: [Yan90] <author> M. Yannakakis, </author> <title> ``Graph-Theoretic Methods in Database Theory'', </title> <booktitle> Proc. 9th Symp. Principles of Database Systems, </booktitle> <address> Nashville, Tennessee, </address> <month> April </month> <year> 1990, </year> <pages> 230-242. </pages>
Reference-contexts: We denote by d the length of the longest acyclic path in G. A large number of transitive closure algorithms have been suggested in graph theory (see e.g., <ref> [Yan90] </ref>). Most of these algorithms implicitly assume that the transitive closure can be completely computed in memory. In the discussion below, we focus on the case where the computation does not fit in memory, and thus the I/O cost is a primary consideration. <p> The complexity of Purdom's algorithm is O (nbn) = O (ne) <ref> [Yan90] </ref>, since for each node, we process on average b arcs leading to its immediate successors, and each one of these may have O (n) successors. Tarjan [Tar72] independently developed an efficient algorithm for determining strongly connected components of a graph by means of a depth-first search. <p> Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [Yel88] <author> D. Yellin,, </author> <title> ``A Dynamic Transitive Closure Algorithm'', </title> <type> Technical Report, </type> <institution> IBM, Yorktown Heights, </institution> <note> Revised 6/20/88. </note>
Reference-contexts: Hence, we also added the Search algorithm to our repertoire. Materialization of transitive closure has been studied in many recent papers, and several of these papers investigate the performance of various schemes for encoding the transitive closure graph (see <ref> [AgK93, AgJ89, ABJ89, ChH91, GuY, HuS93, Jag90, LaD89, VaB86, Yan90, Yel88] </ref>).
Reference: [ZYT90] <author> W. Zhang, C. T. Yu and D. Troy, </author> <title> ``Necessary and Sufficient Conditions to Linearize Doubly Recursive Programs in Logic Databases'', </title> <journal> ACM Trans. Database Syst. </journal> <volume> 15, </volume> <month> 3 (Sep. </month> <year> 1990), </year> <pages> 459-482. 124 125 </pages>
Reference-contexts: An alternative approach is to provide general recursion in the language and to attempt to recognize when a recursive query is actually a transitive closure of some kind. This approach was explored, among others, in <ref> [MuP91, NRS89, Sar89, ZYT90] </ref>. 3.5 Summary We have extended SQL to allow the expression of recursive queries based on the generalized transitive closure paradigm. The extension, SQL/TC, permits the user to pose queries that compute paths between two nodes and information associated with these paths.
References-found: 117

