URL: ftp://ftp.cs.huji.ac.il/users/clag/aaai97W/wkshp.ps
Refering-URL: http://www.cs.huji.ac.il/~clag/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: clag@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Evolving Organizations of Agents  
Author: Claudia V. Goldman Jeffrey S. Rosenschein 
Keyword: organization of agents, evolutionary model, software agents  
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Institute of Computer Science The Hebrew University  
Abstract: We investigate how agents can learn to become experts, and eventually organize themselves appropriately for a range of tasks. Our aim is to look at evolutionary processes that lead to organizations of experts. The distributed artificial intelligence (DAI) community has dealt with multiagent systems that organize themselves in order to achieve a specific shared goal. Various organizations can arise that will effectively balance the load on the agents and improve their performance. We here look at the process of emergence of an organization as a step that takes place prior to the execution of a task, and as a general process related to a range of problems in a domain. To explore the ideas set forward, we designed and implemented a testbed based on the idea of the game of Life. We present experimental results that show different patterns of organizations that might evolve in a multiagent system. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Decker, K., and Lesser, V. </author> <year> 1994. </year> <title> Designing a family of coordination algorithms. </title> <type> Technical Report 94-14, </type> <institution> University of Massachusetts, Amherst. </institution>
Reference-contexts: Specific agents can be addressed to answer queries on the knowledge they have. For example, the organization can be approached by a user or another agent application to retrieve information related to a given query. Another example is to regard this organization as a library of reusable plans <ref> (Decker & Lesser 1994) </ref>. Moreover, these organizations serve as a preparing stage before the agents divide the tasks among themselves. Each agent can achieve goals that are more related to its expertise in a more efficient way.
Reference: <author> Gardner, M. </author> <year> 1983. </year> <title> Wheels, Life and other mathematical amusements. W.H. </title> <publisher> Freeman and Company. </publisher>
Reference-contexts: We have designed and implemented a testbed to experiment with evolving organizations of agents. The implementation of this testbed is along the lines of the Game of Life <ref> (Gardner 1983) </ref>. This game was invented by John Horton Conway in 1970. It takes place in a two dimensional grid (assumed to be an infinite plane). Each cell in this board has eight neighboring cells. <p> A set of parameters can be set by the user to test different scenarios, initial conditions of the system, and different thresholds needed by the rules that will influence the behavior of the agents. Experimental Results In the game of Life four main behaviors were reported and described <ref> (Gardner 1983) </ref>: stable, periodic or oscillating, fading, and ever growing patterns of organization. We will show similar results in our testbed, considering also the domain we choose. <p> Other behaviors analyzed in Life <ref> (Gardner 1983) </ref> concern distinct kinds of collisions among different patterns. This is also relevant in our scenario.
Reference: <author> Guichard, F., and Ayel, J. </author> <year> 1994. </year> <title> Logical reorganization of dai systems. </title> <booktitle> ECAI94 Workshop on Agents, Theories, Architectures and Languages LNAI. </booktitle>
Reference-contexts: The process by which agents reorganize themselves is by changing their current goals, i.e., refining their knowledge, or partitioning a goal into subgoals. Another model for self organization was presented by Guichard et al. <ref> (Guichard & Ayel 1994) </ref>. They introduced two primitives of reorganization: the composition (i.e., regrouping several agents into one), and the decomposition (i.e., the creation of several new agents).
Reference: <author> Huberman, B. A., and Hogg, T. </author> <year> 1995. </year> <title> Communities of practice: Performance and evolution. </title> <booktitle> Computational and Mathematical Organization Theory 1 </booktitle> <pages> 73-92. </pages>
Reference-contexts: They didn't explain formally any specific mechanism, but they mention several examples of it based on the number of tasks, the importance of tasks, or the required time for resolving the problem. Huberman and Hogg <ref> (Huberman & Hogg 1995) </ref> look into communities of practice, i.e., informal networks that generate their own norms and interaction patterns. They consider a group of individuals that are trying to solve a problem.
Reference: <author> Ishida, T. </author> <year> 1992. </year> <title> The tower of babel: Towards organization centered problem solving. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence. </booktitle>
Reference-contexts: A good organization will balance the load on the agents, and will cause the agents to improve their performance. Most work published on this topic considers the organization of the agents as a means that enables the agents to better adapt to their environment. Ishida <ref> (Ishida 1992) </ref> proposes a model in which agents organize themselves by decomposing the problem they have to solve to achieve a shared goal. He calls this approach organization centered problem solving.
Reference: <author> Nagendra Prasad, M.; Lesser, V.; and Lander, S. </author> <year> 1996. </year> <title> Learning organizational roles in a heterogeneous multi-agent system. </title> <booktitle> In Proceedings of the Second International Conference on Multiagent Systems. </booktitle> <address> Kyoto, Japan: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This requires each agent to learn about the hints it might get from other agents and to learn to use them effectively. Nagendra Prasad et al. <ref> (Nagendra Prasad, Lesser, & Lander 1996) </ref> investigated the usefulness of having heterogeneous agents learning their organizational role in a multiagent parametric design system. <p> In the learning study they considered only the first two roles. Each of these roles is defined as a set of tasks that the agent has to perform in a composite solution that solves a given problem. In <ref> (Nagendra Prasad, Lesser, & Lander 1996) </ref>, it is noted that the designer of the system cannot know beforehand the best assignments of roles to the agents because he lacks knowledge about the solution distribution in the space. <p> The agents are trained for all possible states of a search. In all the cases reviewed in this section, the reorganization of a group of agents is strictly related to a specific problem the agents are trying to solve. The study presented in <ref> (Nagendra Prasad, Lesser, & Lan-der 1996) </ref> is more general, in the sense that a still predefined number of agents is trained for all the possible states that could occur while searching for a solution for a multiparametric design.
Reference: <author> Salton, G., and McGill, M. </author> <year> 1983. </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw Hill International Books. </publisher>
Reference-contexts: each word that appears in the inverted index, and documents Doc i , and Doc j in which the word appears, the value of the cell [i; j] is incremented by an amount Incr [word; Doc i ; Doc j ] based on the Inverse Document Frequency (IDF) weight formula <ref> (Salton & McGill 1983) </ref>. The IDF formula assumes that the word's importance is proportional to the occurrence frequency of each word in each document and inversely proportional to the total number of documents in which the same word appears.
References-found: 7

