URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R206.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: darwiche@rpal.rockwell.com pearl@cs.ucla.edu  
Title: Symbolic Causal Networks for Reasoning about Actions and Plans  
Author: Adnan Darwiche Judea Pearl 
Address: Palo Alto, CA 94301 Los Angeles, CA 90024  
Affiliation: Rockwell Science Center Computer Science Department 444 High Street University of California  
Abstract: We present an approach for reasoning about actions and plans when domain knowledge is represented by a symbolic causal network, which is a principled, logical representation of a domain that explicates its perceived causal structure. The proposed approach shows that causal structures can play a key role in logical reasoning about actions given their effective role in dealing with some of the problems associated with such reasoning, including the frame, ramification, and concurrency problems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chitta Baral and Michael Gelfond. </author> <title> Representing concurrent actions in extended logic programs. </title> <booktitle> In Proceedings of International Joint Conference on Artifical Intelligence (IJCAI), </booktitle> <pages> pages 866-871, </pages> <year> 1993. </year>
Reference-contexts: allowing domain constraints in symbolic causal networks does not complicate the frame problem because frame axioms are not derived from effect axioms, but are inferred from the causal structure instead. 3.4 d-separation and concurrent actions The approach we presented so far does not require a special treatment of concurrent actions <ref> [1, 11] </ref>. That is, to predict the effect of a set of actions, one needs only to identify the mechanisms that they overrule and then compute the effects of such actions using the constraints imposed by the remaining mechanisms.
Reference: [2] <author> Adnan Darwiche. </author> <title> A Symbolic Generalization of Probability Theory. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1992. </year>
Reference-contexts: Specifically, proposition p follows from some assumptions precisely when these assumptions entail the argument for 4 Therefore, arguments are easier to compute than ATMS labels; the complexity of computing arguments in symbolic causal networks is symmetric to the complexity of computing probabilities in probabilistic causal networks <ref> [2, 3] </ref>. p. Moreover, the assumptions that are logically possi-ble given the observation O are those that do not entail the argument for :O [3]. Another important role of arguments in reasoning under uncertainty is in implementing Dempster-Shafer reasoning. <p> That is, the topology of a causal structure can be used to guide the decomposition of arguments into smaller arguments that can be computed in parallel <ref> [2, 5, 3] </ref>. <p> In fact, symbolic causal networks are only an instance of a more general class of networks, called abstract causal networks <ref> [2] </ref>, which also include probabilistic causal networks [14] and kappa causal networks [7]. The computational utility of the indepen-dences encoded by a causal structure is common to all instances of abstract causal networks as shown in [2], which also presents some formal algorithms and a Lisp implementation, called cnets [4], for <p> only an instance of a more general class of networks, called abstract causal networks <ref> [2] </ref>, which also include probabilistic causal networks [14] and kappa causal networks [7]. The computational utility of the indepen-dences encoded by a causal structure is common to all instances of abstract causal networks as shown in [2], which also presents some formal algorithms and a Lisp implementation, called cnets [4], for reasoning with abstract causal networks. Conclusion The basic contribution of this paper has been a proposal for updating propositional knowledge bases that are represented using symbolic causal networks.
Reference: [3] <author> Adnan Darwiche. </author> <title> Argument calculus and networks. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI), </booktitle> <pages> pages 420-427, </pages> <year> 1993. </year>
Reference-contexts: In particular, in the same way that probabilistic causal networks compute a probability for each proposition in the network, symbolic causal networks compute an argument for each proposition. Arguments are logically equivalent to ATMS labels, but they are not necessarily put in canonical form <ref> [3] </ref>. 4 Consider the network in Figure 3 for an example. Initially, the argument for any proposition is simply false, meaning that not any set of assumptions would be enough to entail any proposition. <p> Specifically, proposition p follows from some assumptions precisely when these assumptions entail the argument for 4 Therefore, arguments are easier to compute than ATMS labels; the complexity of computing arguments in symbolic causal networks is symmetric to the complexity of computing probabilities in probabilistic causal networks <ref> [2, 3] </ref>. p. Moreover, the assumptions that are logically possi-ble given the observation O are those that do not entail the argument for :O [3]. Another important role of arguments in reasoning under uncertainty is in implementing Dempster-Shafer reasoning. <p> Moreover, the assumptions that are logically possi-ble given the observation O are those that do not entail the argument for :O <ref> [3] </ref>. Another important role of arguments in reasoning under uncertainty is in implementing Dempster-Shafer reasoning. The basic idea here is to assign probabilities to assumption symbols while assuming their probabilistic independence. <p> That is, the topology of a causal structure can be used to guide the decomposition of arguments into smaller arguments that can be computed in parallel <ref> [2, 5, 3] </ref>. <p> [ Z, while XZ and Y Z are the subsets of XY Z over the propositions X [ Z and Y [ Z, respectively. 5 This decomposition is the basis for distributed algorithms that compute arguments and is analogous to the decomposition used when computing probabilities in probabilistic causal networks <ref> [3] </ref>. In fact, symbolic causal networks are only an instance of a more general class of networks, called abstract causal networks [2], which also include probabilistic causal networks [14] and kappa causal networks [7].
Reference: [4] <author> Adnan Darwiche. CNETS: </author> <title> A computational environment for generalized causal networks. </title> <type> Technical memorandum, </type> <institution> Rockwell International, Palo Alto Laboratory, </institution> <year> 1994. </year>
Reference-contexts: The computational utility of the indepen-dences encoded by a causal structure is common to all instances of abstract causal networks as shown in [2], which also presents some formal algorithms and a Lisp implementation, called cnets <ref> [4] </ref>, for reasoning with abstract causal networks. Conclusion The basic contribution of this paper has been a proposal for updating propositional knowledge bases that are represented using symbolic causal networks. The proposal guarantees the faithfulness of belief updates to a given causal structure in a precise sense.
Reference: [5] <author> Adnan Darwiche and Judea Pearl. </author> <title> Symbolic causal networks. </title> <booktitle> To appear in the Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <year> 1994. </year>
Reference-contexts: In the same way that a probabilistic causal network represents a probability distribution that is faithful to a given causal structure [14], a symbolic causal network represents a logical database that satisfies similar faithfulness conditions <ref> [5] </ref>. Causal faithfulness stands for two requirements, one concerns the dynamics of database revisions due to new observations, while the second concerns the dynamics of database updates due to external actions. <p> Symbolic causal networks offer similar guarantees with respect to logical databases, but the independence constraints encoded by these networks are logical rather than probabilistic. Revisional faithfulness and how it can be obtained using symbolic causal networks are treated elsewhere <ref> [5] </ref>. In this paper, we focus on the action part of faithfulness, ensuring that actions, their effects, their interactions with observations, and their interactions with fl This work has been partially supported by ARPA contract F30602-91-C-0031. other actions are consistent with the (perceived) causal structure of the world. <p> For example, one would never specify a relationship between the inputs to a digital gate in the process of specifying the relationship between its inputs and output. 3 Reasoning about action We observed elsewhere that causal structures impose independence constraints on belief changes that are triggered by observations (belief revisions) <ref> [5] </ref>. In particular, we characterized the conditional independences imposed by a causal structure on belief revisions: Given a state of the assumption symbols, observing the direct causes of a proposition p renders the belief in p independent of obser vations about its non-effects. <p> The direct effect of the action Do (p) is restricted to its effect on p; all its other effects are logical consequences of its effect on p. 2 Since the above proposal reduces actions to observations, the results reported in <ref> [5] </ref> for reasoning about observations become available for reasoning about actions. <p> That is, the topology of a causal structure can be used to guide the decomposition of arguments into smaller arguments that can be computed in parallel <ref> [2, 5, 3] </ref>.
Reference: [6] <author> Johan de Kleer. </author> <title> An assumption-based TMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 127-162, </pages> <year> 1986. </year>
Reference-contexts: There are many proposals for nonmonotonic reasoning. One of these proposals, called assumption-based reasoning, identifies a set of assumable propositions, assumes their truth values, and then retracts or reverses these assumptions when they prove to be wrong. An ATMS is the basic formalism for implementing this sort of reasoning <ref> [6] </ref>. In ATMSs, a label is attached to each proposition, which characterizes all assumptions under which the proposition holds. Symbolic causal networks support assumption-based reasoning.
Reference: [7] <author> Moises Goldszmidt and Adnan Darwiche. </author> <title> Action networks: A framework for reasoning about actions and change under uncertainty. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: In fact, symbolic causal networks are only an instance of a more general class of networks, called abstract causal networks [2], which also include probabilistic causal networks [14] and kappa causal networks <ref> [7] </ref>. The computational utility of the indepen-dences encoded by a causal structure is common to all instances of abstract causal networks as shown in [2], which also presents some formal algorithms and a Lisp implementation, called cnets [4], for reasoning with abstract causal networks.
Reference: [8] <author> Moises Goldszmidt and Judea Pearl. </author> <title> Rank-based systems: A simple approach to belief revision, belief update and reasoning about evidence and actions. </title> <booktitle> In Proceedings of the Third Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 661-672. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: This should not be surprising given the recent literature on belief update, which emphasizes the distinction between recording an observation about a static world (observing that C is ON) and recording an observation about a changing world (intervening to make C ON) <ref> [9, 8] </ref>. 2. The propositional database corresponding to the digital circuit does not contain enough information to predict the effect of an action that sets output C to ON. <p> Actions with uncertain effects can be modeled in the same framework, but are outside the scope of this paper. 2 We note here that actions with similar properties have been treated in probabilistic settings using a probabilistic analogue of the sufficient-cause principle <ref> [16, 8] </ref>. If we perform the same exercise with respect to the circuit in Figure 3, we obtain the symbolic causal network in Figure 5, which specifies a different database fl.
Reference: [9] <author> H. Katsuno and A. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> pages 387-394, </pages> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: We also showed that the database induced by a symbolic causal network satisfies all the independences encoded by its corresponding causal structure. But causal structures also impose constraints on belief changes that are triggered by external interventions (belief updates <ref> [9] </ref>). Therefore, our focus in this paper is on characterizing these constraints and on providing a formal proposal for belief update that respects them. To motivate the discussion in this section, consider the symbolic causal network in Figure 2. <p> This should not be surprising given the recent literature on belief update, which emphasizes the distinction between recording an observation about a static world (observing that C is ON) and recording an observation about a changing world (intervening to make C ON) <ref> [9, 8] </ref>. 2. The propositional database corresponding to the digital circuit does not contain enough information to predict the effect of an action that sets output C to ON.
Reference: [10] <author> K. B. Laskey and P. E. Lehner. </author> <title> Assumptions, beliefs, and probabilities. </title> <journal> Artificial Intelligence, </journal> <volume> 41(1) </volume> <pages> 65-77, </pages> <year> 1989. </year>
Reference-contexts: The basic idea here is to assign probabilities to assumption symbols while assuming their probabilistic independence. The probability of the argument for proposition p can then be shown to correspond to the Dempster-Shafer belief in p <ref> [10] </ref>. We have discussed earlier the role that causal structures play in treating the frame, ramification, and con-currency problems. These structures also play a significant computational role that will be elaborated on in the remainder of this section.
Reference: [11] <author> Fangzhen Lin and Yoav Shoham. </author> <title> Concurrent actions in the situation calculus. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI), </booktitle> <pages> pages 590-595, </pages> <year> 1992. </year>
Reference-contexts: allowing domain constraints in symbolic causal networks does not complicate the frame problem because frame axioms are not derived from effect axioms, but are inferred from the causal structure instead. 3.4 d-separation and concurrent actions The approach we presented so far does not require a special treatment of concurrent actions <ref> [1, 11] </ref>. That is, to predict the effect of a set of actions, one needs only to identify the mechanisms that they overrule and then compute the effects of such actions using the constraints imposed by the remaining mechanisms.
Reference: [12] <author> John McCarthy and Patrick Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <journal> Machine Intelligence, </journal> <volume> 4 </volume> <pages> 463-502, </pages> <year> 1969. </year>
Reference-contexts: For example, "Moving block A on the table does not change its color" is a frame axiom. The frame problem is that of succinctly summarizing the frame axioms <ref> [12] </ref>. A number of proposals for such summarization are discussed in [15]. Summarizing frame axioms is one of the key roles played by the causal structure of a symbolic causal network.
Reference: [13] <author> Judea Pearl. </author> <title> From imaging and stochastic control to a calculus of action. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: That is, neither of these actions will have an influence on c. The reader is referred to <ref> [13] </ref> for more details on the use of d-separation in making predictions about the effects of actions. 4 Reasoning about plans Reasoning about plans (sequences of actions) requires one to explicate the temporal order in which actions take place.
Reference: [14] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kauf-mann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: In the same way that a probabilistic causal network represents a probability distribution that is faithful to a given causal structure <ref> [14] </ref>, a symbolic causal network represents a logical database that satisfies similar faithfulness conditions [5]. Causal faithfulness stands for two requirements, one concerns the dynamics of database revisions due to new observations, while the second concerns the dynamics of database updates due to external actions. <p> In probabilistic causal networks, revisional faithfulness is encapsulated in conditional independence constraints, the satisfaction of which is guaranteed whenever the distribution is generated by processes configured according to the network's layout <ref> [14] </ref>. Symbolic causal networks offer similar guarantees with respect to logical databases, but the independence constraints encoded by these networks are logical rather than probabilistic. Revisional faithfulness and how it can be obtained using symbolic causal networks are treated elsewhere [5]. <p> Among the most important of these results are (1) a characterization of the independences imposed by a causal structure on beliefs, observations and actions; (2) the ability to read these independences and many of their implications directly from the topology of a causal structure using the criterion of d-separation <ref> [14] </ref>; (3) a proposal for reasoning about actions and observations that is guaranteed to satisfy these independences; and (4) a set of distributed algorithms for computing inferences that are symmetric in their complexity to the algorithms used in probabilistic causal networks. 3.1 An example Let us see how we can formally <p> That is, the topology of a causal structure can be used to guide the decomposition of arguments into smaller arguments that can be computed in parallel [2, 5, 3]. More precisely, whenever propositions X and Y are d-separated by Z in the causal structure <ref> [14] </ref>, we get the following key property: Argument ( XYZ ) Argument ( XZ )_Argument ( YZ ); where XY Z is a clause over propositions X [ Y [ Z, while XZ and Y Z are the subsets of XY Z over the propositions X [ Z and Y [ <p> In fact, symbolic causal networks are only an instance of a more general class of networks, called abstract causal networks [2], which also include probabilistic causal networks <ref> [14] </ref> and kappa causal networks [7]. The computational utility of the indepen-dences encoded by a causal structure is common to all instances of abstract causal networks as shown in [2], which also presents some formal algorithms and a Lisp implementation, called cnets [4], for reasoning with abstract causal networks.
Reference: [15] <author> Ray Reiter. </author> <title> The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression. </title> <editor> In Vladimir Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, </booktitle> <pages> pages 359-380. </pages> <publisher> Academic Press, </publisher> <address> San Diego, Ca, </address> <year> 1991. </year>
Reference-contexts: For example, "Moving block A on the table does not change its color" is a frame axiom. The frame problem is that of succinctly summarizing the frame axioms [12]. A number of proposals for such summarization are discussed in <ref> [15] </ref>. Summarizing frame axioms is one of the key roles played by the causal structure of a symbolic causal network. <p> This problem is most common in formalisms that solve the frame problem by deriving frame axioms from the completeness assumption of effect axioms <ref> [15] </ref>. In such a case, prohibiting domain constraints (e.g., the workings of a gate) seems to simplify the derivation of frame axioms because it allows such derivation through only local considerations of effect axioms.
Reference: [16] <author> P. Spirtes, C. Glymour, and R. Schienes. </author> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Actions with uncertain effects can be modeled in the same framework, but are outside the scope of this paper. 2 We note here that actions with similar properties have been treated in probabilistic settings using a probabilistic analogue of the sufficient-cause principle <ref> [16, 8] </ref>. If we perform the same exercise with respect to the circuit in Figure 3, we obtain the symbolic causal network in Figure 5, which specifies a different database fl.
References-found: 16

