URL: ftp://cs.aston.ac.uk/neural/willicki/bishop_nips8.ps.Z
Refering-URL: http://www.cs.cmu.edu/Web/Groups/NIPS/NIPS95/Papers.html
Root-URL: 
Email: c.m.bishop@aston.ac.uk svensjfm@aston.ac.uk c.k.i.williams@aston.ac.uk  
Title: In Advances in Neural Information Processing Systems 8  EM Optimization of Latent-Variable Density Models  
Author: eds. D. S. Touretzky, M. C. Mozer, M. E. Hasselmo, Christopher M Bishop, Markus Svensen and Christopher K I Williams 
Address: B4 7ET, UK  
Affiliation: Neural Computing Research Group Aston University, Birmingham,  
Note: MIT Press, 1996.  
Abstract: There is currently considerable interest in developing general nonlinear density models based on latent, or hidden, variables. Such models have the ability to discover the presence of a relatively small number of underlying `causes' which, acting in combination, give rise to the apparent complexity of the observed data set. Unfortunately, to train such models generally requires large computational effort. In this paper we introduce a novel latent variable algorithm which retains the general non-linear capabilities of previous models but which uses a training procedure based on the EM algorithm. We demonstrate the performance of the model on a toy problem and on data from flow diagnostics for a multi-phase oil pipeline.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bishop, C. M. </author> <year> (1995). </year> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford University Press. </publisher>
Reference: <author> Bishop, C. M. and G. D. </author> <title> James (1993). Analysis of multiphase flows using dual-energy gamma densitometry and neural networks. </title> <booktitle> Nuclear Instruments and Methods in Physics Research A327, </booktitle> <pages> 580-593. </pages>
Reference-contexts: demonstration of this algorithm, we consider data generated from a one-dimensional distribution embedded in two dimensions, as shown in Figure 2. 3.1 OIL FLOW DATA Our second example arises in the problem of determining the fraction of oil in a multi-phase pipeline carrying a mixture of oil, water and gas <ref> (Bishop and James, 1993) </ref>. Each data point consists of 12 measurements taken from dual-energy gamma densitometers measuring the attenuation of gamma beams passing through the pipe.
Reference: <author> Dayan, P., G. E. Hinton, R. M. Neal, and R. S. </author> <title> Zemel (1995). The Helmholtz machine. </title> <booktitle> Neural Computation 7 (5), </booktitle> <pages> 889-904. </pages>
Reference-contexts: There is therefore considerable interest in latent variable models in which the density function is expressed in terms of of hidden variables. These include density networks (MacKay, 1995) and Helmholtz machines <ref> (Dayan et al., 1995) </ref>. Much of this work has been concerned with predicting binary variables.
Reference: <author> Hinton, G. E., C. K. I. Williams, and M. D. </author> <month> Revow </month> <year> (1992). </year> <title> Adaptive elastic models for hand-printed character recognition. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <publisher> Morgan Kauffmann. </publisher>
Reference: <author> Kohonen, T. </author> <year> (1995). </year> <title> Self-Organizing Maps. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: We have already commented that factor analysis is a special case of this model, involving a linear mapping from latent space to data space. The Kohonen topographic map algorithm <ref> (Kohonen, 1995) </ref> can be regarded as an approximation to a latent variable density model of the kind outlined here. Finally, there are interesting similarities to a `soft' version of the `principal curves' algorithm (Tibshirani, 1992).
Reference: <author> Little, R. J. A. and D. B. </author> <title> Rubin (1987). Statistical Analysis with Missing Data. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference-contexts: Finally, there are interesting similarities to a `soft' version of the `principal curves' algorithm (Tibshirani, 1992). The model we have described can readily be extended to deal with the problem of missing data, provided we assume that the missing data is ignorable and missing at random <ref> (Little and Rubin, 1987) </ref>. This involves maximizing the likelihood function in which the missing values have been integrated out. For the model discussed here, the integrations can be performed analytically, leading to a modified form of the EM algorithm.
Reference: <author> MacKay, D. J. C. </author> <year> (1995). </year> <title> Bayesian neural networks and density networks. </title> <journal> Nuclear Instruments and Methods in Physics Research, </journal> <volume> A 354 (1), </volume> <pages> 73-80. </pages>
Reference-contexts: There is therefore considerable interest in latent variable models in which the density function is expressed in terms of of hidden variables. These include density networks <ref> (MacKay, 1995) </ref> and Helmholtz machines (Dayan et al., 1995). Much of this work has been concerned with predicting binary variables.
Reference: <author> Tibshirani, R. </author> <year> (1992). </year> <title> Principal curves revisited. </title> <journal> Statistics and Computing 2, </journal> <pages> 183-190. </pages>
Reference-contexts: The Kohonen topographic map algorithm (Kohonen, 1995) can be regarded as an approximation to a latent variable density model of the kind outlined here. Finally, there are interesting similarities to a `soft' version of the `principal curves' algorithm <ref> (Tibshirani, 1992) </ref>. The model we have described can readily be extended to deal with the problem of missing data, provided we assume that the missing data is ignorable and missing at random (Little and Rubin, 1987).
References-found: 8

