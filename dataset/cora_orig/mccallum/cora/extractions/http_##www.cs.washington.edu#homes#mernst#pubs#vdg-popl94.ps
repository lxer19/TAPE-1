URL: http://www.cs.washington.edu/homes/mernst/pubs/vdg-popl94.ps
Refering-URL: http://www.cs.washington.edu/homes/mernst/pubs/vdg-popl94-abstract.html
Root-URL: 
Title: Value Dependence Graphs: Representation Without Taxation  
Author: Daniel Weise Roger F. Crew Michael Ernst Bjarne Steensgaard 
Affiliation: Microsoft Research  
Abstract: The value dependence graph (VDG) is a sparse dataflow-like representation that simplifies program analysis and transformation. It is a functional representation that represents control flow as data flow and makes explicit all machine quantities, such as stores and I/O channels. We are developing a compiler that builds a VDG representing a program, analyzes and transforms the VDG, then produces a control flow graph (CFG) [ASU86] from the optimized VDG. This framework simplifies transformations and improves upon several published results. For example, it enables more powerful code motion than [CLZ86, FOW87], eliminates as many redundancies as [AWZ88, RWZ88] (except for redundant loops), and provides important information to the code sched-uler [BR91]. We exhibit a one-pass method for elimination of partial redundancies that never performs redundant code motion [KRS92, DS93] and is simpler than the classical [MR79, Dha91] or SSA [RWZ88] methods. These results accrue from eliminating the CFG from the analysis/transformation phases and using demand dependences in preference to control dependences. 
Abstract-found: 1
Intro-found: 1
Reference: [AN90] <author> Arvind and R. S. Nikhil. </author> <title> Executing a program on the MIT tagged-token dataflow architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(3) </volume> <pages> 300-318, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Switches are merge points for backwards program execution, so the DFG makes it as easy to perform backwards as forwards analyses. MIT dataflow graphs <ref> [AN90] </ref> differ from VDGs by including tokens for control and by not needing to represent machine state, such as stores. [BJP91] suggests a dataflow-like intermediate representation that shares many of our goals and concerns. However, it uses tokens to represent control, which keeps explicit control in the program representation.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. Computer Science Series. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: This algorithm uses the dPDG that was constructed for code generation. Section 6 compares our research to related work, and the last section discusses future research directions. 2 unlike those of <ref> [ASU86] </ref>, explicitly represent branches and joins. Dotted boxes enclose irreducible SESE regions (see Section 2.1). 2 Value Dependence Graphs The VDG is a functional representation that expresses the computation of a procedure solely as value flow. The lack of control flow has three immediate consequences. <p> The updated store is used to symbolically execute the program after the assignment, which makes the assigned value available to subsequent 4 We follow <ref> [ASU86] </ref> in defining two expressions to be common subexpressions if they compute the same value and one dominates the other. lookups. Symbolic execution performs no interprocedural analysis of a Call's effect on, or use of, the store; later passes perform that work.
Reference: [AWZ88] <author> Bowen Alpern, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Detecting equality of variables in programs. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-11. </pages> <publisher> ACM Press, </publisher> <month> Jan-uary </month> <year> 1988. </year>
Reference-contexts: During the last decade, new program representations have been proposed to alleviate these problems and make analysis simpler, faster, or more thorough. Static single assignment (SSA) form [CFR + 89] gives each value a distinct name, which improves the efficiency of constant propagation and other analyses <ref> [WZ85, AWZ88, RWZ88, WZ89] </ref>. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses [JP93]. These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG.
Reference: [BCT92] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> Rematerialization. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 311-321. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: We need to address this issue in the back end. Our representation raises many other issues for a code generator. For example, a computation that is demanded at two sites in the program with different demand dependences may be duplicated to reduce register pressure <ref> [BCT92] </ref>. Similarly, fl nodes with similar predicates but dissimilar demand dependences force a "precompute vs. register pressure vs. code size" engineering tradeoff. While these issues are not trivial, they are where they belong, in the back end.
Reference: [BH92] <author> Thomas Ball and Susan Horwitz. </author> <title> Slicing programs with arbitrary control flow. </title> <type> Technical Report 1128, </type> <institution> University of Wisconsin - Madison, </institution> <month> December 21, </month> <year> 1992. </year>
Reference-contexts: Other authors have noticed the efficacy of the PDG for slicing [HRB90] and addressed the problems of irreducible control flow <ref> [BH92] </ref>. Our algorithms are equally as precise as the best of these, simpler to state, and often more efficient [Ern93]. Because the VDG represents only value flow, we are able to slice only on values, not on particular program points, which notion does not make sense in the VDG framework.
Reference: [BJP91] <author> Micah Beck, Richard Johnson, and Keshav Pingali. </author> <title> From control flow to dataflow. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12 </volume> <pages> 118-129, </pages> <year> 1991. </year>
Reference-contexts: Switches are merge points for backwards program execution, so the DFG makes it as easy to perform backwards as forwards analyses. MIT dataflow graphs [AN90] differ from VDGs by including tokens for control and by not needing to represent machine state, such as stores. <ref> [BJP91] </ref> suggests a dataflow-like intermediate representation that shares many of our goals and concerns. However, it uses tokens to represent control, which keeps explicit control in the program representation. The authors of [BJP91] have since abandoned the dataflow model and are now investigating DFGs [JP93]. <p> from VDGs by including tokens for control and by not needing to represent machine state, such as stores. <ref> [BJP91] </ref> suggests a dataflow-like intermediate representation that shares many of our goals and concerns. However, it uses tokens to represent control, which keeps explicit control in the program representation. The authors of [BJP91] have since abandoned the dataflow model and are now investigating DFGs [JP93].
Reference: [BMO90] <author> Robert A. Ballance, Arthur B. Maccabe, and Karl J. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: The program dependence graph (PDG) eliminates some control artifacts by linking together operations with the same control dependence, and builds local data dependence graphs to simplify analysis and transformation [Ott78, FOW87]. The program dependence web (PDW) <ref> [BMO90, CKB93] </ref> makes value flow in the PDG more explicit by using gated single assignment (GSA) form. The next step in solving the problems of CFGs is to eliminate the CFG as the basis of analysis and transformation. <p> To simplify the exposition, we will consider the machine state to consist solely of a store. Second, operators that choose among control paths (e.g., if and switch statements) are represented by selectors that choose among possible values; these are essentially the fl nodes of <ref> [BMO90] </ref>. Third, looping is represented via function calls: the CFG backedge finds its analog in the VDG recursive call. A VDG consists of 1. A directed bipartite graph whose vertices are nodes representing computations and ports representing values. <p> However, it uses tokens to represent control, which keeps explicit control in the program representation. The authors of [BJP91] have since abandoned the dataflow model and are now investigating DFGs [JP93]. The gated single assignment (GSA) component of the program dependence web <ref> [BMO90, CKB93] </ref> is similar to the VDG, but transformation is hindered by the need to keep three different representations in sync, and it fails to handle irreducible programs. Thinned gated single assignment (TGSA) form [Hav93] is also similar to our representation.
Reference: [BR91] <author> David Bernstein and Michael Rodeh. </author> <title> Global instruction scheduling for superscalar machines. </title> <booktitle> In Proceedings of the SIG-PLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 241-255, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Analysis and transformation is simpler to implement, understand, and express formally, and frequently faster, when using a VDG rather than a CFG. While simple-minded code generation from the VDG may result in poor code, the representation provides important information to the code scheduler <ref> [BR91] </ref> which makes code movement and scheduling considerably easier.
Reference: [CCF91] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Procedings of the Eighteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 55-66. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1991. </year>
Reference-contexts: This work is similar to [CF89], which discusses the semantics of the program dependence graph (PDG) when considered as an executable dataflow program. Sparse evaluation graphs <ref> [CCF91] </ref> are a program representation for efficient solution of dataflow problems. For a given dataflow problem, a program is converted to a sparse evaluation graph which is used as the data structure for analysis.
Reference: [CF89] <author> Robert Cartwright and Matthias Felleisen. </author> <title> The semantics of program dependence. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 13-27, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Its rewrite rules are similar to VDG transformations, and similar techniques are used to extract values from stores, converting lookup operations into the values they would return. This work is similar to <ref> [CF89] </ref>, which discusses the semantics of the program dependence graph (PDG) when considered as an executable dataflow program. Sparse evaluation graphs [CCF91] are a program representation for efficient solution of dataflow problems.
Reference: [CFR + 89] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1989. </year>
Reference-contexts: During the last decade, new program representations have been proposed to alleviate these problems and make analysis simpler, faster, or more thorough. Static single assignment (SSA) form <ref> [CFR + 89] </ref> gives each value a distinct name, which improves the efficiency of constant propagation and other analyses [WZ85, AWZ88, RWZ88, WZ89]. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses [JP93]. <p> If both of the node's inputs are fl trees, the time is no worse than cubic. However, empirical results <ref> [CFR + 89] </ref> indicate that in practice Gtree (g) contains at most a few elements, which implies that in practice the depth of the demand dependence graph has a small bound. <p> The CDG is the novel contribution; it ties together elements of the program that execute under the same control conditions. CDGs provide information that enables and simplifies many transformations, such as code motion [CLZ86]. The theta graph [Cli93a, Cli93b] is a PDG for a program in SSA form <ref> [CFR + 89] </ref>. The theta graph is built directly from the CFG, without any need for an inlining step as in the VDG construction. Click suggests removing the control information from his program representation; if this occurs, the theta graph will probably end up very similar to the VDG.
Reference: [CKB93] <author> Philip L. Campbell, Ksheerabdhi Krishna, and Robert A. Ballance. </author> <title> Refining and defining the program dependence web. </title> <type> Technical Report CS93-6, </type> <institution> University of New Mexico, </institution> <address> Albuquerque, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: The program dependence graph (PDG) eliminates some control artifacts by linking together operations with the same control dependence, and builds local data dependence graphs to simplify analysis and transformation [Ott78, FOW87]. The program dependence web (PDW) <ref> [BMO90, CKB93] </ref> makes value flow in the PDG more explicit by using gated single assignment (GSA) form. The next step in solving the problems of CFGs is to eliminate the CFG as the basis of analysis and transformation. <p> However, it uses tokens to represent control, which keeps explicit control in the program representation. The authors of [BJP91] have since abandoned the dataflow model and are now investigating DFGs [JP93]. The gated single assignment (GSA) component of the program dependence web <ref> [BMO90, CKB93] </ref> is similar to the VDG, but transformation is hindered by the need to keep three different representations in sync, and it fails to handle irreducible programs. Thinned gated single assignment (TGSA) form [Hav93] is also similar to our representation.
Reference: [Cli93a] <author> Cliff Click. </author> <title> Combining analyses, combining optimizations. </title> <type> PhD thesis proposal, </type> <month> April </month> <year> 1993. </year>
Reference-contexts: The CDG is the novel contribution; it ties together elements of the program that execute under the same control conditions. CDGs provide information that enables and simplifies many transformations, such as code motion [CLZ86]. The theta graph <ref> [Cli93a, Cli93b] </ref> is a PDG for a program in SSA form [CFR + 89]. The theta graph is built directly from the CFG, without any need for an inlining step as in the VDG construction.
Reference: [Cli93b] <author> Cliff Click. </author> <title> From quads to graphs: An intermediate representation's journey. </title> <note> Submitted for publication, October 18, </note> <year> 1993. </year>
Reference-contexts: The CDG is the novel contribution; it ties together elements of the program that execute under the same control conditions. CDGs provide information that enables and simplifies many transformations, such as code motion [CLZ86]. The theta graph <ref> [Cli93a, Cli93b] </ref> is a PDG for a program in SSA form [CFR + 89]. The theta graph is built directly from the CFG, without any need for an inlining step as in the VDG construction.
Reference: [CLZ86] <author> Ron Cytron, Andy Lowry, and Kenneth Zadeck. </author> <title> Code motion of control structures in high-level languages. </title> <booktitle> In Proceedings of the Thirteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 70-85, </pages> <month> January </month> <year> 1986. </year> <month> 13 </month>
Reference-contexts: When the data dependences do not enforce a total ordering, the code generator is free to reorder computations and conditional constructs. For example, our system performs more strict (nonspeculative) code motion than <ref> [CLZ86] </ref>. In particular, for Figure 2 of that paper, our system would move the a.1 and a.5 assignments into the else clause of the if movable1 statement on the right side of the figure, 6 resulting in a clear improvement in the code. We extend the results of [CLZ86] in other <p> motion than <ref> [CLZ86] </ref>. In particular, for Figure 2 of that paper, our system would move the a.1 and a.5 assignments into the else clause of the if movable1 statement on the right side of the figure, 6 resulting in a clear improvement in the code. We extend the results of [CLZ86] in other ways: because of our redundancy detection, we find at least as many (structural) common subexpres-sions as their COMMON algorithm finds, and statements moved by our method don't have to have the same values on all iterations (our method handles the problem case of [CLZ86, Figure 11]). 5 Elimination <p> extend the results of [CLZ86] in other ways: because of our redundancy detection, we find at least as many (structural) common subexpres-sions as their COMMON algorithm finds, and statements moved by our method don't have to have the same values on all iterations (our method handles the problem case of <ref> [CLZ86, Figure 11] </ref>). 5 Elimination of Partial Redun dancies A computation is partially redundant at a program point if there is some path to the point that performed the same computation (the redundant path) and some path to the program point where the computation is not performed. <p> The CDG is the novel contribution; it ties together elements of the program that execute under the same control conditions. CDGs provide information that enables and simplifies many transformations, such as code motion <ref> [CLZ86] </ref>. The theta graph [Cli93a, Cli93b] is a PDG for a program in SSA form [CFR + 89]. The theta graph is built directly from the CFG, without any need for an inlining step as in the VDG construction.
Reference: [Coc70] <author> John Cocke. </author> <title> Global common subexpression elimination. </title> <journal> SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 20-24, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: Nodes are cached, so attempts to construct a node whose operation and operands match an existing node will merely retrieve that existing node. Caching, also known as global value numbering <ref> [Coc70, CS70] </ref>, implements common subexpression elimination (CSE) 4 by representing multiple (not necessarily identical) source expressions by a single node. Variable Update Given an assignment statement, update the location in the symbolic store to contain the value (VDG port) obtained by symbolically executing the expression part of the assignment statement.
Reference: [CS70] <author> John Cocke and Jacob T. Schwartz. </author> <title> Programming languages and their compilers. </title> <type> Technical report, </type> <institution> Courant Institute, NYU, </institution> <month> April </month> <year> 1970. </year> <note> Preliminary notes. </note>
Reference-contexts: Nodes are cached, so attempts to construct a node whose operation and operands match an existing node will merely retrieve that existing node. Caching, also known as global value numbering <ref> [Coc70, CS70] </ref>, implements common subexpression elimination (CSE) 4 by representing multiple (not necessarily identical) source expressions by a single node. Variable Update Given an assignment statement, update the location in the symbolic store to contain the value (VDG port) obtained by symbolically executing the expression part of the assignment statement.
Reference: [Dha91] <author> D. M. Dhamdhere. </author> <title> Practical adaptation of the global optimization algorithm of Morel and Renvoise. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 291-294, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Because our EPR method employs only a partial ordering of the computation as expressed by the dPDG, it is much simpler than methods that employ total order-ings expressed as a CFG. For example, as compared to the pure CFG methods <ref> [MR79, Dha91, DRZ92, KRS92, DS93] </ref>, it requires no availability or global (partial) an-ticipatibility analysis for every expression nor any basic block by basic block code motion. Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion.
Reference: [DRZ92] <author> Dhananjay M. Dhamdere, Barry K. Rosen, and F. Ken-neth Zadeck. </author> <title> How to analyze large programs efficiently and informatively. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 212-223, </pages> <address> San Francisco, California, June 17-19, 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Because our EPR method employs only a partial ordering of the computation as expressed by the dPDG, it is much simpler than methods that employ total order-ings expressed as a CFG. For example, as compared to the pure CFG methods <ref> [MR79, Dha91, DRZ92, KRS92, DS93] </ref>, it requires no availability or global (partial) an-ticipatibility analysis for every expression nor any basic block by basic block code motion. Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion.
Reference: [DS93] <author> Karl-Heinz Drechsler and Manfred P. Stadel. </author> <title> A variation of Knoop, Ruthing, and Steffen's lazy code motion. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(5) </volume> <pages> 29-38, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Because our EPR method employs only a partial ordering of the computation as expressed by the dPDG, it is much simpler than methods that employ total order-ings expressed as a CFG. For example, as compared to the pure CFG methods <ref> [MR79, Dha91, DRZ92, KRS92, DS93] </ref>, it requires no availability or global (partial) an-ticipatibility analysis for every expression nor any basic block by basic block code motion. Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion.
Reference: [Ern93] <author> Michael Ernst. </author> <title> Program slicing using the value dependence graph. </title> <note> In preparation, </note> <year> 1993. </year>
Reference-contexts: Figure 4 demonstrates the results of several transformations performed on the VDG. VDGs are the basis of powerful, precise, and efficient program slicing algorithms. Efficient algorithms for interprocedural slicing, slicing unstructured programs, and interactive slicing operate directly upon the VDG <ref> [Ern93] </ref>. The next section of this paper describes the VDG and the translation from CFGs into VDGs (the first three steps of Figure 1). Analyses and transformations are discussed in Section 3. <p> Other authors have noticed the efficacy of the PDG for slicing [HRB90] and addressed the problems of irreducible control flow [BH92]. Our algorithms are equally as precise as the best of these, simpler to state, and often more efficient <ref> [Ern93] </ref>. Because the VDG represents only value flow, we are able to slice only on values, not on particular program points, which notion does not make sense in the VDG framework. This does not appear to be a serious limitation.
Reference: [Fie92] <author> John Field. </author> <title> A simple rewriting semantics for realistic imperative programs and its application to program analysis (preliminary report). </title> <booktitle> In Proc. ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 98-107, </pages> <address> San Francisco, </address> <month> June </month> <year> 1992. </year> <note> Published as Yale University Technical Report YALEU/DCS/RR-909. </note>
Reference-contexts: Thinned gated single assignment (TGSA) form [Hav93] is also similar to our representation. The major difference between the VDG and TGSA form is that VDGs represent looping via procedure call and return, whereas TGSA, like PDW form, represents looping with special nodes (- and ). <ref> [Fie92] </ref> presents a framework for reasoning about and partially evaluating programs in graphical form, based on the idea of a guarded expression. Its rewrite rules are similar to VDG transformations, and similar techniques are used to extract values from stores, converting lookup operations into the values they would return.
Reference: [FKCX94] <author> Lawrence Feigen, David Klappholz, Robert Casazza, and Xing Xue. </author> <title> The revival transformation. </title> <booktitle> In Proceedings of the Twenty-first Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <address> Portland, OR, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: The control dependence is vacuous (i.e., "always execute"), but the demand dependence is "a &gt; d". The corresponding code motion into an arm of a conditional is called the revival transformation in <ref> [FKCX94] </ref>. The use of the dPDG enables more code motion and other transformations than representations based on control dependences. Motion out of loops occurs automatically, since the dPDG reflects only when a computation is used, not its location in the original program.
Reference: [FM85] <author> Jeanne Ferrante and Mary Mace. </author> <title> On linearizing parallel code. </title> <booktitle> In Proceedings of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 179-190, </pages> <month> Jan-uary </month> <year> 1985. </year>
Reference-contexts: PDG-based compilers simplify transformations by eliminating the CFG, at the cost of needing to reconstruct the CFG to produce serial code <ref> [FM85, FMS88, SAF90, SF93, Ste93a] </ref>. The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions.
Reference: [FMS88] <author> Jeanne Ferrante, Mary Mace, and Barbara Simons. </author> <title> Generating sequential code from parallel code. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 582-592, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: PDG-based compilers simplify transformations by eliminating the CFG, at the cost of needing to reconstruct the CFG to produce serial code <ref> [FM85, FMS88, SAF90, SF93, Ste93a] </ref>. The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions.
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG. The program dependence graph (PDG) eliminates some control artifacts by linking together operations with the same control dependence, and builds local data dependence graphs to simplify analysis and transformation <ref> [Ott78, FOW87] </ref>. The program dependence web (PDW) [BMO90, CKB93] makes value flow in the PDG more explicit by using gated single assignment (GSA) form. The next step in solving the problems of CFGs is to eliminate the CFG as the basis of analysis and transformation. <p> Code motion optimizations are decided when the demand dependence graph is constructed from the VDG. A demand dependence graph is similar in spirit to a control dependence graph (CDG) <ref> [FOW87] </ref>, except that the demand dependence graph is constructed using the predicates that lead to a computation contributing to the output of program, whereas the predicates in a CDG are those int example (int a, int b, int c, int d) - int acopy, bcopy, lp_inv1, lp_inv2; int down, cse, epr, <p> After local changes propagate, a scan determines if any enclosing formals may now be removed, or if return values are no longer computed within the . If so, the relevant Calls are updated, with local transformations proceeding outward. The same effect can be achieved with PDG methods <ref> [FOW87, Section 5.1] </ref>, but at higher cost in conceptual complexity, overhead, and analysis passes. the VDG of example (Figure 9). 4 Code Generation Generating code from the VDG is done in two stages. The first stage transforms the VDG into a demand-based program dependence graph (dPDG). <p> The first stage transforms the VDG into a demand-based program dependence graph (dPDG). A standard PDG <ref> [FOW87] </ref> consists of a data dependence graph and a control dependence graph (CDG). In the dPDG the VDG operand arcs provide the data dependences and the CDG is replaced by a demand dependence graph. The second stage transforms the dPDG into a CFG from which code may be generated directly. <p> The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions. The program dependence graph (PDG) <ref> [FOW87] </ref> consists of a control dependence graph (CDG) and a data dependence graph. The CDG is the novel contribution; it ties together elements of the program that execute under the same control conditions. CDGs provide information that enables and simplifies many transformations, such as code motion [CLZ86].
Reference: [Har85] <author> Dov Harel. </author> <title> A linear time algorithm for finding dominators in flow graphs and related problems. </title> <booktitle> In Proceedings of the Seventeenth ACM Symposium on Theory of Computing, </booktitle> <pages> pages 185-194, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: The branch-end for a non-SESE-bottom branch node n is its nearest postdominator that is either a join node or z. The join-end of a non-SESE-bottom join n is its nearest postdom-inator that is either a branch-end or z. End analysis depends only on postdominator trees and takes linear time <ref> [Har85] </ref>. The important property of this construction is that each CFG basic block and predicate appears exactly once within the resulting SDG, as a consequence of each CFG node being visited exactly once in the CFG traversal.
Reference: [Hav93] <author> Paul Havlak. </author> <title> Construction of thinned gated single-assignment form. Draft | Private distribution, </title> <month> February 20, </month> <year> 1993. </year>
Reference-contexts: While VDGs are slightly larger than CFGs, we do not anticipate that they will prove too large for practical use. Experiments with thinned gated single assignment (TGSA) form <ref> [Hav93] </ref> indicate that in practice, TGSA can be constructed in time and space linear in the number of variable references for programs "satisfying reasonable assumptions." We would be surprised if the same result did not hold for VDG form, which is similar to TGSA form. <p> This permits inlining without code duplication, after which Call and only model looping (and programmer-specified procedures and procedure calls). The result of this process is similar to thinned gated single assignment (TGSA) <ref> [Hav93] </ref> except that the fl trees take stores, rather than values, as inputs. (Later passes produce more TGSA-like structures in which the fl trees operate on values rather than upon stores.) Before the -fl transform, call loops are discovered, which identifies internal s that are loop entry points and identifies recursive <p> The -fl transform is illustrated by the two SDGs of Figure 7. The fl nodes introduced by this pass represent additional representational overhead of our form over SSA form. Experiments have shown that this overhead is a linear function of the size of programs in SSA form <ref> [Hav93] </ref>. 2.3 Symbolic Execution Symbolic execution expands the SDG's unevaluated basic blocks into VDG nodes. During the expansion, global value numbering, copy propagation, and constant propagation that can be performed without recourse to fixed point analysis are automatically performed. <p> The gated single assignment (GSA) component of the program dependence web [BMO90, CKB93] is similar to the VDG, but transformation is hindered by the need to keep three different representations in sync, and it fails to handle irreducible programs. Thinned gated single assignment (TGSA) form <ref> [Hav93] </ref> is also similar to our representation.
Reference: [HRB90] <author> Susan Horwitz, Thomas Reps, and David Binkley. </author> <title> In-terprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Other authors have noticed the efficacy of the PDG for slicing <ref> [HRB90] </ref> and addressed the problems of irreducible control flow [BH92]. Our algorithms are equally as precise as the best of these, simpler to state, and often more efficient [Ern93].
Reference: [JP93] <author> Richard Johnson and Keshav Pingali. </author> <title> Dependence-based program analysis. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 78-89, </pages> <address> Albuquerque, NM, June 23-25, 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Static single assignment (SSA) form [CFR + 89] gives each value a distinct name, which improves the efficiency of constant propagation and other analyses [WZ85, AWZ88, RWZ88, WZ89]. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses <ref> [JP93] </ref>. These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG. The program dependence graph (PDG) eliminates some control artifacts by linking together operations with the same control dependence, and builds local data dependence graphs to simplify analysis and transformation [Ott78, FOW87]. <p> Whether a particular join needs a corresponding internal and how to designate branch/join-ends are resolved by single-entry-single-exit (SESE) analysis <ref> [JP93] </ref>. A pair of distinct CFG nodes a; b encloses a SESE region iff there exist arcs ff ending at a and fi beginning at b such that ff dominates fi, fi postdomi-nates ff, and ff and fi are cycle-equivalent (i.e., every CFG graph cycle contains both or neither). <p> It would seem that more direct methods could be used for transforming the VDG, in particular, for determining the values demanded and modified by loops. Other sparse representations, such as dependence flow graphs <ref> [PBJ + 90, JP93] </ref> and SSA form, are constructed directly from the CFG. They can collect in one pass the variables used or modified within a loop. <p> Click suggests removing the control information from his program representation; if this occurs, the theta graph will probably end up very similar to the VDG. The dependence flow graph (DFG) <ref> [PBJ + 90, JP93] </ref> is an extension of the standard SSA form in which, in addition to the nodes inserted at merge points, switch nodes are inserted above branch points. <p> However, it uses tokens to represent control, which keeps explicit control in the program representation. The authors of [BJP91] have since abandoned the dataflow model and are now investigating DFGs <ref> [JP93] </ref>. The gated single assignment (GSA) component of the program dependence web [BMO90, CKB93] is similar to the VDG, but transformation is hindered by the need to keep three different representations in sync, and it fails to handle irreducible programs.
Reference: [JPP93] <author> Richard Johnson, David Pearson, and Keshav Pingali. </author> <title> Finding regions fast: Single entry single exit and control regions in linear time. </title> <type> Technical Report CTC93TR141, </type> <institution> Cornell University, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: A node d is a SESE-bottom if, for some node c, c and d enclose a SESE region. Finally, for each CFG node a, let bottom (a) be the postdomina-tor of the smallest SESE region containing a; bottom (a) can be found for all nodes in O (E) time <ref> [JPP93] </ref>. A join is symptomatic of looping or unstructured control iff it is not a SESE-bottom. End analysis associates with each branch (join) node a branch-end (join-end). The analysis depends on whether the node is a SESE-bottom or not.
Reference: [KRS92] <author> Jens Knoop, Oliver Ruthing, and Bernhard Steffen. </author> <title> Lazy code motion. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 224-234, </pages> <address> San Francisco, California, June 17-19, 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Because our EPR method employs only a partial ordering of the computation as expressed by the dPDG, it is much simpler than methods that employ total order-ings expressed as a CFG. For example, as compared to the pure CFG methods <ref> [MR79, Dha91, DRZ92, KRS92, DS93] </ref>, it requires no availability or global (partial) an-ticipatibility analysis for every expression nor any basic block by basic block code motion. Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion.
Reference: [MR79] <author> Etienne Morel and Claude Renvoise. </author> <title> Global optimization by suppression of partial redundancies. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> February </month> <year> 1979. </year>
Reference-contexts: Because our EPR method employs only a partial ordering of the computation as expressed by the dPDG, it is much simpler than methods that employ total order-ings expressed as a CFG. For example, as compared to the pure CFG methods <ref> [MR79, Dha91, DRZ92, KRS92, DS93] </ref>, it requires no availability or global (partial) an-ticipatibility analysis for every expression nor any basic block by basic block code motion. Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion.
Reference: [Ott78] <author> Karl Joseph Ottenstein. </author> <title> Data-flow graphs as an intermediate program form. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <month> August </month> <year> 1978. </year>
Reference-contexts: These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG. The program dependence graph (PDG) eliminates some control artifacts by linking together operations with the same control dependence, and builds local data dependence graphs to simplify analysis and transformation <ref> [Ott78, FOW87] </ref>. The program dependence web (PDW) [BMO90, CKB93] makes value flow in the PDG more explicit by using gated single assignment (GSA) form. The next step in solving the problems of CFGs is to eliminate the CFG as the basis of analysis and transformation.
Reference: [PBJ + 90] <author> Keshav Pingali, Micah Beck, Richard Johnson, Mayan Moudgill, and Paul Stodghill. </author> <title> Dependence flow graphs: An algebraic approach to program dependencies. </title> <type> Technical Report 90-1152, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY 14853, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: It would seem that more direct methods could be used for transforming the VDG, in particular, for determining the values demanded and modified by loops. Other sparse representations, such as dependence flow graphs <ref> [PBJ + 90, JP93] </ref> and SSA form, are constructed directly from the CFG. They can collect in one pass the variables used or modified within a loop. <p> Click suggests removing the control information from his program representation; if this occurs, the theta graph will probably end up very similar to the VDG. The dependence flow graph (DFG) <ref> [PBJ + 90, JP93] </ref> is an extension of the standard SSA form in which, in addition to the nodes inserted at merge points, switch nodes are inserted above branch points.
Reference: [RWZ88] <author> Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Global value numbers and redundant computations. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 12-27. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1988. </year>
Reference-contexts: CFGs overspecify a computation by totally ordering its operations, requiring the addition of extra nodes (such as entry pads and exit pads <ref> [RWZ88] </ref>) to a CFG before performing code motion. CFGs are statement-based and name all values; the names, usually provided by the programmer, get in the way of analyzing the underlying computation. <p> During the last decade, new program representations have been proposed to alleviate these problems and make analysis simpler, faster, or more thorough. Static single assignment (SSA) form [CFR + 89] gives each value a distinct name, which improves the efficiency of constant propagation and other analyses <ref> [WZ85, AWZ88, RWZ88, WZ89] </ref>. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses [JP93]. These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG. <p> Like more recent CFG based EPR methods, it does not perform re 11 dundant code motion. It is also simpler than the SSA method <ref> [RWZ88] </ref> with its CFG graph conditioning (e.g., adding landing pads), assignment of ranks or orders, LCT and MCT tables, etc. 6 Related Research Our graph structure is a direct descendant of the graph structure used in the Fuse partial evaluator [Wei90, WCRS91].
Reference: [SAF90] <author> Barbara Simons, David Alpern, and Jeanne Ferrante. </author> <title> A foundation for sequentializing parallel code | extended abstract. </title> <booktitle> In Proceedings of the 2nd ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 350-359, </pages> <year> 1990. </year>
Reference-contexts: PDG-based compilers simplify transformations by eliminating the CFG, at the cost of needing to reconstruct the CFG to produce serial code <ref> [FM85, FMS88, SAF90, SF93, Ste93a] </ref>. The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions.
Reference: [SF93] <author> Barbara Simons and Jeanne Ferrante. </author> <title> An efficient algorithm for constructing a control flow graph for parallel code. </title> <type> Technical Report TR 03.465, </type> <institution> IBM, Santa Teresa Laboratory, </institution> <address> San Jose, California, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: The second stage transforms the dPDG into a CFG from which code may be generated directly. This stage is described in [Ste93a], which extends earlier work on sequentializing PDGs <ref> [SF93] </ref>. The demand dependence of a VDG node is characterized by the fl nodes encountered on paths from a return node, much as the control dependence of a CFG node is characterized by branch nodes encountered on paths from an entry node. <p> PDG-based compilers simplify transformations by eliminating the CFG, at the cost of needing to reconstruct the CFG to produce serial code <ref> [FM85, FMS88, SAF90, SF93, Ste93a] </ref>. The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions.
Reference: [SHKN76] <author> T. A. Standish, D. C. Harriman, D. F. Kilber, and J. M. Neighbors. </author> <title> The Irvine program transformation catalogue. </title> <type> Technical Report 161, </type> <institution> University of California at Irvine, Department of Information and Computer Science, </institution> <month> January </month> <year> 1976. </year>
Reference-contexts: This transformation is equivalent to converting a op (p ? b : c) into p ? a op b : a op c, which is transformation rule 3.2.a of <ref> [SHKN76] </ref>. Our contribution is a program representation that allows this simple transformation to be the basis of efficient EPR. 6 We assume that "unmovable" expressions are unmovable due to loop carried dependences, and not because of semantic issues such as volatile variables in C.
Reference: [Ste93a] <author> Bjarne Steensgaard. </author> <title> Sequentializing program dependence graphs for irreducible programs. </title> <type> Technical Report MSR-TR-93-14, </type> <institution> Microsoft Research, </institution> <address> Redmond, WA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: In the dPDG the VDG operand arcs provide the data dependences and the CDG is replaced by a demand dependence graph. The second stage transforms the dPDG into a CFG from which code may be generated directly. This stage is described in <ref> [Ste93a] </ref>, which extends earlier work on sequentializing PDGs [SF93]. The demand dependence of a VDG node is characterized by the fl nodes encountered on paths from a return node, much as the control dependence of a CFG node is characterized by branch nodes encountered on paths from an entry node. <p> PDG-based compilers simplify transformations by eliminating the CFG, at the cost of needing to reconstruct the CFG to produce serial code <ref> [FM85, FMS88, SAF90, SF93, Ste93a] </ref>. The underlying representation is still statement-oriented, however (control dependences are attached to statements) so the PDG approach does not enable as many analysis and transformation simplifications as the VDG and the dPDG, which also eliminates the CFG but attaches demand dependences to expressions.
Reference: [Ste93b] <author> Bjarne Steensgaard. </author> <title> A store algebra for graphical program representations. </title> <note> In preparation, </note> <month> November </month> <year> 1993. </year>
Reference-contexts: If the location contains no explicit value, build a VDG lookup node representing the corresponding runtime load operation and return its result port. If the store is actually the result of a fl node, then 3 <ref> [Ste93b] </ref> describes our handling of store operations when the location being looked up or modified is not yet known due to pointer operations. 6 SDG (middle figure).
Reference: [Ven91] <author> G. A. Venkatesh. </author> <title> The semantic approach to program slicing. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 107-119, </pages> <address> Toronto, Ontario, Canada, </address> <month> June 26-28, </month> <year> 1991. </year>
Reference-contexts: Similarly, fl nodes with similar predicates but dissimilar demand dependences force a "precompute vs. register pressure vs. code size" engineering tradeoff. While these issues are not trivial, they are where they belong, in the back end. Program slicing <ref> [Wei84, Ven91] </ref> determines which elements of a program affect, or can be affected by, a given computation. This analysis can be useful in debugging and in distributing computations across processors.
Reference: [WCRS91] <author> Daniel Weise, Roland Conybeare, Erik Ruf, and Scott Seligman. </author> <title> Automatic online partial evaluation. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, number 523 in Lecture Notes in Computer Science, </booktitle> <pages> pages 165-191, </pages> <address> Cambridge, MA, </address> <month> August 26-30, </month> <year> 1991. </year> <title> ACM, </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: It is also simpler than the SSA method [RWZ88] with its CFG graph conditioning (e.g., adding landing pads), assignment of ranks or orders, LCT and MCT tables, etc. 6 Related Research Our graph structure is a direct descendant of the graph structure used in the Fuse partial evaluator <ref> [Wei90, WCRS91] </ref>. The graph structure was designed for reasoning about and transforming strict functional programs. The only accommodation made for imperative programs is the explicit presence of a store datatype (and other usually implicit machine quantities), and operations on stores.
Reference: [Wei84] <author> Mark Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: Similarly, fl nodes with similar predicates but dissimilar demand dependences force a "precompute vs. register pressure vs. code size" engineering tradeoff. While these issues are not trivial, they are where they belong, in the back end. Program slicing <ref> [Wei84, Ven91] </ref> determines which elements of a program affect, or can be affected by, a given computation. This analysis can be useful in debugging and in distributing computations across processors.
Reference: [Wei90] <author> Daniel Weise. </author> <title> Graphs as an intermediate representation for partial evaluation. </title> <type> Technical Report CSL-TR-90-421, </type> <institution> Stan-ford Computer Systems Laboratory, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: It is also simpler than the SSA method [RWZ88] with its CFG graph conditioning (e.g., adding landing pads), assignment of ranks or orders, LCT and MCT tables, etc. 6 Related Research Our graph structure is a direct descendant of the graph structure used in the Fuse partial evaluator <ref> [Wei90, WCRS91] </ref>. The graph structure was designed for reasoning about and transforming strict functional programs. The only accommodation made for imperative programs is the explicit presence of a store datatype (and other usually implicit machine quantities), and operations on stores.
Reference: [WZ85] <author> Mark N. Wegman and Frank Kenneth Zadeck. </author> <title> Constant propagation with condition branches. </title> <booktitle> In Proceedings of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 291-299, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: During the last decade, new program representations have been proposed to alleviate these problems and make analysis simpler, faster, or more thorough. Static single assignment (SSA) form [CFR + 89] gives each value a distinct name, which improves the efficiency of constant propagation and other analyses <ref> [WZ85, AWZ88, RWZ88, WZ89] </ref>. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses [JP93]. These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG.
Reference: [WZ89] <author> Mark N. Wegman and F. Kenneth Zadeck. </author> <title> Constant propagation with conditional branches. </title> <type> Technical Report CS-89-36, </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> May </month> <year> 1989. </year> <month> 14 </month>
Reference-contexts: During the last decade, new program representations have been proposed to alleviate these problems and make analysis simpler, faster, or more thorough. Static single assignment (SSA) form [CFR + 89] gives each value a distinct name, which improves the efficiency of constant propagation and other analyses <ref> [WZ85, AWZ88, RWZ88, WZ89] </ref>. The dependence flow graph (DFG) improves the efficiency of analyses by ignoring irrelevant sections of code and linking definitions to uses [JP93]. These representations can be viewed as augmentations to the CFG that allow more rapid traversal of the CFG.
References-found: 47

