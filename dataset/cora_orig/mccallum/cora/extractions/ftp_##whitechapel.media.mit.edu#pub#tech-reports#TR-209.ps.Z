URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-209.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Distributed Representation and Analysis of Visual Motion  
Author: by Eero P. Simoncelli 
Date: August 1993.  
Note: Reprinted with smaller type and spacing,  
Address: E15-385 20 Ames Street Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Abstract: Vision and Modeling Group Technical Report #209 January 1993 y 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. H. Adelson and J. R. Bergen. </author> <title> Spatiotemporal energy models for the perception of motion. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 2(2) </volume> <pages> 284-299, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section. <p> In this section, we will discuss a particular set of filter-based models that has received much attention from the computational biology community. These models are are based on the squared outputs of spatio-temporally oriented filters. We will refer to these as Spatio-Temporal Energy Models (STEM) <ref> [1, 40, 37] </ref>. We will show that the mixed-order differential solution discussed in the previous section may be interpreted as a spatio-temporal energy model. The importance of this observation is that it emphasizes the view of derivatives as filtering operations. <p> We will describe the basic one-dimensional STEM outlined by Adelson and Bergen here <ref> [1] </ref>. In order to eliminate the symmetry and contrast dependencies of the filter responses, they proposed the computation of "motion energy" measures from the sum of the square of even-and odd-symmetric filters tuned for the same orientation. <p> We will discuss the details of filter design in section 3.3. For now, we note only that derivatives of discretely sampled signals are typically computed as differences of neighboring sample values (that is, with the filter kernel <ref> [1; 1] </ref>), with a two-point average in the nonderivative directions (that is, a filter kernel of [0:5; 0:5]). But unless the imagery is bandlimited well below the Nyquist rate, these filters are not very good derivative approximations. <p> In other words, we could use a sum of squared responses of more than two basis functions as a local estimate of spectral energy. In the motion literature, several authors previously mentioned <ref> [1, 40, 29] </ref> have used quadrature pairs in the computation of motion. As we discussed in the previous section, this can be justified from a filtering point of view in terms of symmetry. <p> First we show that simple first order differences are likely to produce poor results for the optical flow problem when applied directly to the input imagery, especially in highly textured regions (i.e., regions with much high-frequency content). g 0 (n) = <ref> [1; 1] </ref>. On the same plot is shown the Fourier transform of the derivative of the two-point averaging operator g (n) = [0:5; 0:5], which is computed by multiplying its Fourier magnitude by the function j!j. <p> That is we would like j! x G (~!)j jG 0 (~!)j. 2. The prefilter should be a constant-phase filter, preferably even- or odd-symmetric (i.e., 66 are the magnitude of the Fourier transforms over the range &lt; ! of a) the derivative operator <ref> [1; 1] </ref> (dashed line), and b) the frequency-domain derivative of the two-point averaging operator [0:5; 0:5] (that is, its Fourier magnitude multiplied by j!j). If these were a perfect derivative/prefilter pair, the curves would coincide. phase of zero or =2 ). 3. <p> The directional derivative perpendicular to this line will have a zero response. This is illustrated in figure 4-1. Thus, the standard gradient algorithm may be termed a "null-steering" algorithm. This is counterintuitive in light of the intuition expressed by Adelson and Bergen <ref> [1] </ref>, and by other authors of spatio-temporal energy models. In these approaches, one searches for the oriented filter of maximal response. In the case of first derivatives, we can easily rewrite the solution as a maximization. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates. <p> The "complex cells" in area V1 have similar behavior to simple cells, except that they are not sensitive to the phase (or symmetry) of the stimulus. These cells have been modeled as a quadrature combination of simple cell responses, corresponding to equation (3.11) <ref> [70, 1, 72] </ref>. More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion [60, 66, 58, 7].
Reference: [2] <author> E. H. Adelson and J. R. Bergen. </author> <title> Perceptual dimensions of spatio-temporal vision. </title> <institution> Investigative Opthalmology and Visual Science Supplement (ARVO), 27:141, </institution> <year> 1986. </year>
Reference-contexts: They showed that their opponent STEM approach was closely related to the modified Reichardt correlation model of van Santen and Sperling [73, 96]. Adelson and Bergen also proposed a mechanism for computing a signal monotonically related to speed from these energies <ref> [2] </ref>: ^v ~ (R 2 e ) (L 2 e ) (S 2 e ) where R indicates the output of a linear filter sensitive to rightward motion (space-time orientation), L leftward motion, and S static (zero motion), and the subscripts e and o refer to even- and odd-symmetry of the
Reference: [3] <author> E. H. Adelson and J. A. Movshon. </author> <title> Phenomenal coherence of moving visual patterns. </title> <journal> Nature, </journal> <volume> 300(5892) </volume> <pages> 523-525, </pages> <year> 1982. </year>
Reference-contexts: A series of experiments have revealed that the parameters of such a two-grating stimulus stimulus may be adjusted to give either of these perceptions <ref> [3, 60, 52] </ref>. The general rule seems to be that when the gratings are "similar" (i.e., similar contrast, color, spatial-frequency, orientation, speed), they are perceived as a coherent plaid. Patterns in which the gratings are very different in one or more of these parameters tend to generate perceptions of transparency. <p> In this case, the perception is of a flickering stationary sinusoidal pattern (this stimulus is known as a "counterphase" grating). The original descriptions of plaid perception by Adelson and Movshon <ref> [3, 60] </ref> suggested that IOC might explain the perceived motion of coherent plaids, but later work [27, 90] clearly indicates that a strict interpretation of IOC as a model for human perception fails in many situations. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [4] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 4 </volume> <pages> 384-401, </pages> <year> 1985. </year>
Reference-contexts: These multiple-motion situations are prevalent, and cause problems for motion algorithms. Biological systems provide inspiration here: humans have no trouble distinguishing the motion of transparently moving sheets. Several authors have discussed the problem of multiple motions <ref> [26, 4, 29, 13] </ref>. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point.
Reference: [5] <author> J. K. Aggarwal and N. Nandhakumar. </author> <title> On the computation of motion from sequences of images | a review. </title> <journal> Proc. IEEE, </journal> <volume> 76 </volume> <pages> 917-935, </pages> <year> 1988. </year>
Reference-contexts: Neither will we attempt a thorough experimental comparison of the techniques we consider. It is very difficult to generate comparisons that are both fair and conclusive, although comparative reviews have begun to appear in the literature (eg, <ref> [5, 10] </ref>). Our second goal in this section is to sequentially construct a simple yet powerful general algorithm for extracting motion information from spatio-temporal imagery. In the course of considering various approaches to velocity estimation, we will find that many of the solutions are remarkably similar.
Reference: [6] <author> D. G. Albrecht and W. S. Geisler. </author> <title> Motion sensitivity and the contrast-response function of simple cells in the visual cortex. </title> <journal> Visual Neuroscience, </journal> <volume> 7 </volume> <pages> 531-546, </pages> <year> 1991. </year>
Reference-contexts: This computation is identical to that of equation (3.8), in which directional linear measurements are squared and divided by a sum of squared directional measurements plus the constant 2 . A similar model has been proposed by Albrecht and Geisler <ref> [6] </ref>. The "complex cells" in area V1 have similar behavior to simple cells, except that they are not sensitive to the phase (or symmetry) of the stimulus. These cells have been modeled as a quadrature combination of simple cell responses, corresponding to equation (3.11) [70, 1, 72].
Reference: [7] <author> T. D. Albright. </author> <title> Direction and orientation selectivity of neurons in visual area mt of the macaque. </title> <journal> J Neurophysiol, </journal> <volume> 52(6) </volume> <pages> 1106-1130, </pages> <month> December </month> <year> 1984. </year>
Reference-contexts: More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion <ref> [60, 66, 58, 7] </ref>. We propose a two-stage model based on the "donut mechanisms" developed in the previous chapter. The model computes a distributed representation of motion in two stages, as illustrated in figure 1-6.
Reference: [8] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: Choosing a vector to describe the motion in a blank region constitutes an overcommitment to a solution. Some researchers have advocated the use of "confidence" or "reliability" measures to indicate which optical flow vectors are to be trusted <ref> [63, 8, 29] </ref>. These are typically compared to a threshold value, and all flow vectors with confidences below the threshold are discarded. This approach does not take advantage of the full information present in the intensity signal. <p> Recently, some authors have developed approaches that compute two-dimensional covari-ance matrices which serve as a two-dimensional confidence measure. In particular, Heeger [40] 50 computed a Fischer information matrix by linearizing his regression model about the minimum. Anandan and others <ref> [8, 91, 86] </ref> have fitted quadratic functions to sum-of-squared-difference error surfaces to estimate confidence, although Barron et. al. [10] note that these confidence measures are often not very reliable. Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity [8, 36]. <p> Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity <ref> [8, 36] </ref>. Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear [74, 84, 82, 86]. <p> The warping procedure may be applied recursively to higher frequency subbands. This "coarse-to-fine" estimation process is illustrated in figure 3.2. This type of multi-scale "warping" approach has been suggested and used by a number of authors <ref> [54, 71, 23, 8, 12] </ref>. Coarse-to-Fine Algorithms As described above, in order to generate estimates at different scales, we can apply the differential algorithm to lowpass prefilters of different bandwidth.
Reference: [9] <author> H. B. Barlow. </author> <title> Single units and sensation: a neural doctrine for perceptual psychology? Perception I, </title> <address> pages 371-394, </address> <year> 1972. </year>
Reference: [10] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <type> Technical Report RPL-TR-9107, </type> <institution> Queen's University, Kingston, Ontario, Robotics and Perception Laboratory Technical Report, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Neither will we attempt a thorough experimental comparison of the techniques we consider. It is very difficult to generate comparisons that are both fair and conclusive, although comparative reviews have begun to appear in the literature (eg, <ref> [5, 10] </ref>). Our second goal in this section is to sequentially construct a simple yet powerful general algorithm for extracting motion information from spatio-temporal imagery. In the course of considering various approaches to velocity estimation, we will find that many of the solutions are remarkably similar. <p> In particular, Heeger [40] 50 computed a Fischer information matrix by linearizing his regression model about the minimum. Anandan and others [8, 91, 86] have fitted quadratic functions to sum-of-squared-difference error surfaces to estimate confidence, although Barron et. al. <ref> [10] </ref> note that these confidence measures are often not very reliable. Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity [8, 36]. <p> The remainder of the chapter discusses the implementation of the algorithms and provides examples of velocity field estimation and error analysis on synthetic and real image sequences. These results demonstrate an im 51 provement in performance when compared to those of a recent comparison study of optical flow techniques <ref> [10] </ref>. 3.1 Probabilistic Modeling Our goal is to compute an expression for the probability of the image velocity conditional on measurements made from the image sequence. We develop this representation by introducing an uncertainty model to characterize deviations from the standard gradient constraint equation. <p> The velocity surrounding the impulse is consistent with the image intensities: since the 76 Dots correspond to zero velocity vectors. image is zero everywhere except at the impulse, the motion is completely indeterminate. Next, we examined a sinusoidal plaid pattern, taken from Barron et. al. <ref> [10] </ref>. Two sinusoidal gratings with spatial frequency 6 pixels/cycle are additively combined. Their normal orientations are at 54 ffi and 27 ffi with speeds of 1.63 pixels/frame and 1.02 pixels/frame, respectively. The flow is computed using the multi-scale mixed-order algorithm. <p> One frame of the sequence, the estimated flow, and the error magnitude image are shown in figure 3-18. Also shown is a table of error statistics. The errors compare quite favorably with the mean angular errors reported by Barron et. al. <ref> [10] </ref>. Our mean angular error is an order of magnitude less than all the methods examined, except for that of Fleet and Jepson for which the value was 0:03 ffi . <p> We also note also that our mixed-order algorithm is significantly more efficient than most of the algorithms in <ref> [10] </ref>. For example, the Fleet and Jepson algorithm is implemented with a set of 46 kernels. These are implemented separably as 75 convolutions with one-dimensional 21-tap kernels. <p> Note that the error is concentrated at the boundaries, where derivative measurement is difficult. Error statistics for this computation are given in the table (see text for definitions). Realistic Synthetic Sequences We also estimated image velocity fields for the "Translating Tree" and "Diverging Tree" sequences used in <ref> [10] </ref>. These sequences were generated by warping an image of a tree to simulate translational camera motion with respect to the image plane. One frame from the sequence is shown in figure 3-19. <p> All parameters of the algorithm were the same as those used in the plaid sequence. "Translating Tree" sequence. Also given is a table of the error statistics. Figure 3-21 shows the same data for the "Diverging Tree" sequence. These results compare favorably to those reported in <ref> [10] </ref>. In particular, the best reported result in [10] for the translating sequence is the Fleet and Jepson algorithm which produced a mean angular error of 0:23 degrees. <p> Also given is a table of the error statistics. Figure 3-21 shows the same data for the "Diverging Tree" sequence. These results compare favorably to those reported in <ref> [10] </ref>. In particular, the best reported result in [10] for the translating sequence is the Fleet and Jepson algorithm which produced a mean angular error of 0:23 degrees. Note, however, that this result was for a flow field of 50% density (i.e., half of the velocity vectors were discarded as unreliable). <p> Upper right: the correct flow field. Lower right: estimated velocity field. Lower left: error magnitude image. Note that errors are concentrated near occlusion boundaries. 81 boundaries, since the support of the filters is much smaller. Furthermore, the error statistics compare quite favorably to those reported in <ref> [10] </ref>. In particular, the best result reported is that of Lucas and Kanade, with a mean angular error of 3:55 ffi and standard deviation of 7:09 ffi . This is almost identical to our result, but the flow vector density is only 8.8%. <p> We develop a probabilistic coarse-to-fine strategy a Kalman filter over scale for defeating temporal aliasing, and demonstrate the behavior of the algorithm on a number of synthetic and real image sequences. The results are shown to be superior to those published in a recent comparison of optical flow techniques <ref> [10] </ref>. We also demonstrate that the estimated covariance 123 matrices provide useful information about the quality of the velocity estimates. The most noticeable failure of the algorithm occurs at occlusion boundaries, as is to be expected.
Reference: [11] <author> M. Basseville, A. Benveniste, K. C. Chou, S. A. Golden, R. Nikoukhah, and A. S. Willsky. </author> <title> Modeling and estimation of multiresolution stochastic processes. </title> <type> Technical Report CICS-P-283, </type> <institution> MIT Center for Intelligent Control Systems, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: We assume that the ~n 0 (l) are independent, zero-mean, and normally distributed. Implicitly, we are imposing a sort of fractal model on the velocity field. This type of scale-to-scale Markov relationship has been explored in an estimation context in <ref> [20, 11] </ref>. We also define the measurement equation: f t (l) = ~ f s (l) ~v (l) + (n 2 + ~ f s (l) ~n 1 ) as in section 3.1. We will assume, as before, that the random variables are zero-mean, independent and normally distributed.
Reference: [12] <author> R. Battiti, E. Amaldi, and C. Koch. </author> <title> Computing optical flow across multiple scales: an adaptive coarse-to-fine strategy. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 6(2) </volume> <pages> 133-145, </pages> <year> 1991. </year> <month> 125 </month>
Reference-contexts: The warping procedure may be applied recursively to higher frequency subbands. This "coarse-to-fine" estimation process is illustrated in figure 3.2. This type of multi-scale "warping" approach has been suggested and used by a number of authors <ref> [54, 71, 23, 8, 12] </ref>. Coarse-to-Fine Algorithms As described above, in order to generate estimates at different scales, we can apply the differential algorithm to lowpass prefilters of different bandwidth.
Reference: [13] <author> J. R. Bergen, P. J. Burt, K. Hanna, R. Hingorani, P. Jeanne, and S. Peleg. </author> <title> Dynamic multiple-motion computation. </title> <editor> In Y. A. Feldman and A. Bruckstein, editors, </editor> <booktitle> Artificial Intelligence and Computer Vision, </booktitle> <pages> pages 147-156. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1991. </year>
Reference-contexts: These multiple-motion situations are prevalent, and cause problems for motion algorithms. Biological systems provide inspiration here: humans have no trouble distinguishing the motion of transparently moving sheets. Several authors have discussed the problem of multiple motions <ref> [26, 4, 29, 13] </ref>. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point. <p> Here we will instead consider representing more than one motion at each point. Shizawa and Mase [75, 76] have described algorithms for explicitly computing two motion vectors at each point in the scene. Bergen et. al. <ref> [13] </ref> have developed an algorithm for separating two transparently combined images moving according to an affine velocity field. We take a different approach here. In the previous section, we generated a quadratic error function over the space of all velocities ~v for each point in space and time.
Reference: [14] <author> M. Black and P. Anandan. </author> <title> Robust dynamic motion estimation over time. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 296-302, </pages> <address> Maui, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: An example of such a robust estimator was implemented by Black [15]. Some authors <ref> [61, 14] </ref> have proposed Markov Random Field models that represent dis-continuities with "line processes" [34]. As with the "edge detection" problem, this approach tends to be very sensitive to threshold parameters that determine whether a change in the estimate corresponds to a discontinuity or just a rapid variation.
Reference: [15] <author> M. J. Black. </author> <title> A robust gradient method for determiningn optical flow. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Champagne-Urbana, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: An example of such a robust estimator was implemented by Black <ref> [15] </ref>. Some authors [61, 14] have proposed Markov Random Field models that represent dis-continuities with "line processes" [34].
Reference: [16] <author> R. W. Brockett. Gramians, </author> <title> generalized inverses, and the least-squares approximation of optical flow. </title> <journal> J. Vis. Comm. and Image Rep., </journal> <volume> 1(1) </volume> <pages> 3-11, </pages> <month> Septemeber </month> <year> 1990. </year>
Reference-contexts: Poggio and Reichardt [68] have shown the equivalence of the time-averaged output of all two-input second-order motion detectors. Brockett <ref> [16] </ref> has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians.
Reference: [17] <author> P. J. Burt. </author> <title> Fast filter transforms for image processing. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 16 </volume> <pages> 20-51, </pages> <year> 1981. </year>
Reference-contexts: Conceptually, this approach operates by using prefilters of varying bandwidths. A more efficient technique for generating multi-scale representations is to construct an image pyramid <ref> [17] </ref>, by recursively applying lowpass filtering and subsampling operations. In this case, the images at different scales are also represented at different sampling rates. Assuming the lowpass filter prevents aliasing, the effect of the subsampling in the frequency domain is to stretch the spectrum out.
Reference: [18] <author> C. Cafforio and F. Rocca. </author> <title> Methods for measuring small displacements of television images. </title> <journal> IEEE Trans. Info. Theory, </journal> <volume> IT-22:573-579, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: Although much of the earliest work is due to television engineers <ref> [53, 18] </ref> and those working on biological modeling [35, 73], the field today is populated by a wide variety of researchers in Computer Vision and Robotics, Artificial Intelligence, Signal and Image Processing, Communications Engineering, Estimation and Decision Theory, and many other fields. <p> In many ways, this is both the simplest and the most elegant approach to motion estimation. Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in <ref> [53, 18, 26, 47, 54] </ref>. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time [46]. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc.
Reference: [19] <author> F. W. Campbell, G. F. Cooper, and C. Enroth-Cugell. </author> <title> The angular selectivity of visual cortical cells to moving gratings. </title> <journal> J. Physiology (London), </journal> <volume> 198 </volume> <pages> 237-250, </pages> <year> 1968. </year>
Reference-contexts: There is a very large literature on the behavior of so-called "simple cells" and "complex cells" in layer V1 of the visual cortex. The standard view of simple cells is that they behave like oriented linear filters <ref> [48, 19] </ref>. There are two noticeable departures from linearity. The first is that the cell responses are rectified: cell firing rates are by definition positive, and simple cells have a fairly low background firing rate.
Reference: [20] <author> K. C. Chou, A. S. Willsky, A. Benveniste, and M. Basseville. </author> <title> Recursive and iterative estimation algorithms for multi-resolution stochastic processes. </title> <type> Technical Report LIDS-P-1857, </type> <institution> MIT Laboratory for Information and Decision Sciences, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: As we have described, a "coarse-to-fine" algorithm can be used to handle problems of temporal aliasing. We noted that it also may be viewed as a technique for combining information from different spatial scales. It is also a technique for imposing a prior smoothness constraint (see, for example, <ref> [91, 20] </ref>). This basic technique does, however, have a serious drawback. If the coarse-scale estimates are incorrect, then the fine-scale estimates will have no chance of correcting the errors. To fix this, we must have knowledge of the error in the coarse-scale estimates. <p> We assume that the ~n 0 (l) are independent, zero-mean, and normally distributed. Implicitly, we are imposing a sort of fractal model on the velocity field. This type of scale-to-scale Markov relationship has been explored in an estimation context in <ref> [20, 11] </ref>. We also define the measurement equation: f t (l) = ~ f s (l) ~v (l) + (n 2 + ~ f s (l) ~n 1 ) as in section 3.1. We will assume, as before, that the random variables are zero-mean, independent and normally distributed.
Reference: [21] <author> T. Darrell and A. P. Pentland. </author> <title> Robust estimation of a multi-layer motion representation. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Simple flow-based algorithms would perform poorly at this task in the presence of multiple motions. We expect that the distributed representation should also prove useful for segmenting or grouping scenes according to coherency of motion <ref> [21] </ref>. 105 Chapter 5 Biological Modeling In this section, we discuss the relevance of the models developed in previous sections to biological vision. As discussed in the introduction, mammalian visual systems devote significant resources to the processing of visual motion.
Reference: [22] <author> J. G. Daugman. </author> <title> Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 2(7) </volume> <pages> 1160-1169, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Surfaces are rendered assuming a fixed point light source and a Lambertian reflectance function. the somewhat arbitrary choice of filters. Gabor filters are chosen because they minimize a joint space-frequency localization criterion [32], and because they have been suggested for use in biological modeling <ref> [22] </ref>. But this joint-localization constraint is not of primary importance in the velocity estimation problem, and many other choices of oriented bandpass filter serve equally well for purposes of physiological modeling. Consider the basic gradient algorithm in the Fourier domain.
Reference: [23] <author> W. Enkelmann and H. Nagel. </author> <title> Investigation of multigrid algorithms for estimation of optical flow fields in image sequences. </title> <journal> Comp. Vis. Graphics Image Proc., </journal> <volume> 43 </volume> <pages> 150-177, </pages> <year> 1988. </year>
Reference-contexts: The warping procedure may be applied recursively to higher frequency subbands. This "coarse-to-fine" estimation process is illustrated in figure 3.2. This type of multi-scale "warping" approach has been suggested and used by a number of authors <ref> [54, 71, 23, 8, 12] </ref>. Coarse-to-Fine Algorithms As described above, in order to generate estimates at different scales, we can apply the differential algorithm to lowpass prefilters of different bandwidth.
Reference: [24] <author> M. Fahle and T. Poggio. </author> <title> Visual hyperacuity: spatiotemporal interpolation in human vision. </title> <journal> Proceedings of the Royal Society of London, B, </journal> <volume> 213 </volume> <pages> 451-477, </pages> <year> 1981. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section.
Reference: [25] <author> M. Feder and E. Weinstein. </author> <title> Parameter estimation of superimposed signals using the EM algorithm. </title> <journal> IEEE Trans. Acoust. Speech Signal Proc., </journal> <volume> 36(4) </volume> <pages> 477-489, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: In practice, we are interested in local estimates of image velocity, and thus we need to use a local estimate of the power spectrum. We note that this type of approach for estimating orientation has been used in the array-processing literature for the problem of "direction-of-arrival" estimation <ref> [49, 25] </ref>. This concept was used by Heeger [39] to develop an algorithm for the computation of optical flow. He made local measurements of the power spectrum using a set of twelve Gabor filters 4 tuned for different spatio-temporal frequencies.
Reference: [26] <author> C. L. Fennema and W. Thompson. </author> <title> Velocity determination in scenes containing several moving objects. </title> <booktitle> In CGIP-9, </booktitle> <pages> pages 301-315, </pages> <year> 1979. </year>
Reference-contexts: In many ways, this is both the simplest and the most elegant approach to motion estimation. Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in <ref> [53, 18, 26, 47, 54] </ref>. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time [46]. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc. <p> These multiple-motion situations are prevalent, and cause problems for motion algorithms. Biological systems provide inspiration here: humans have no trouble distinguishing the motion of transparently moving sheets. Several authors have discussed the problem of multiple motions <ref> [26, 4, 29, 13] </ref>. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point.
Reference: [27] <author> V. P. Ferrara and H. R. Wilson. </author> <title> Perceived direction of moving two-dimensional patterns. Vis. </title> <journal> Res., </journal> <volume> 30(2) </volume> <pages> 273-287, </pages> <year> 1990. </year> <month> 126 </month>
Reference-contexts: In this case, the perception is of a flickering stationary sinusoidal pattern (this stimulus is known as a "counterphase" grating). The original descriptions of plaid perception by Adelson and Movshon [3, 60] suggested that IOC might explain the perceived motion of coherent plaids, but later work <ref> [27, 90] </ref> clearly indicates that a strict interpretation of IOC as a model for human perception fails in many situations. Some authors have proposed models that compute a sort of average of the IOC solution and a vector sum (i.e., the sum of the grating normal velocity vectors) [27]. <p> Some authors have proposed models that compute a sort of average of the IOC solution and a vector sum (i.e., the sum of the grating normal velocity vectors) <ref> [27] </ref>. It is, however, unnecessary to invoke a second calculation such as vector sum in order to explain the deviations of perceived velocity from the IOC velocity. <p> Again, the behavior of the model is quite similar to the human observers. Figure 5-5 does, however, contain another curve with substantial bias toward the lower contrast grating. We were unable to duplicate this behavior in any of our simulations. We have also modeled data by Ferrara and Wilson <ref> [27] </ref> on the perceived direction of coherent plaids. Perceived directions were measured by comparison with a one-dimensional grating. Measurements were only made for three types of plaid. Type I-S is a symmetric plaid: each grating has the same spatial and temporal frequency.
Reference: [28] <author> V. P. Ferrara and H. R. Wilson. </author> <title> Perceived speed of moving two-dimensional patterns. Vis. </title> <journal> Res., </journal> <volume> 31(5) </volume> <pages> 273-287, </pages> <year> 1990. </year>
Reference-contexts: In figure 5-6, we show a bar plot of the direction bias for subjects and for our model. Finally, we modeled data from another Ferrara and Wilson paper <ref> [28] </ref>, in which they mea 110 three curves correspond to different values of plaid angle. curves correspond to different values of average temporal frequency. curves correspond to different values of grating spatial frequency. 111 described in section 3.1.
Reference: [29] <author> D. Fleet and A. Jepson. </author> <title> Computation of component image velocity from local phase information. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 5(1) </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: In other words, we could use a sum of squared responses of more than two basis functions as a local estimate of spectral energy. In the motion literature, several authors previously mentioned <ref> [1, 40, 29] </ref> have used quadrature pairs in the computation of motion. As we discussed in the previous section, this can be justified from a filtering point of view in terms of symmetry. <p> The Phase-derivative Approach We discuss one more solution developed in the literature. Fleet and Jepson used quadrature pairs of Gabor filters to compute measures of local phase <ref> [29] </ref>. Rather than derive optical flow from the conservation of intensities (or prefiltered intensities), they choose to derive it from 46 the conservation of this local phase measurement. <p> Choosing a vector to describe the motion in a blank region constitutes an overcommitment to a solution. Some researchers have advocated the use of "confidence" or "reliability" measures to indicate which optical flow vectors are to be trusted <ref> [63, 8, 29] </ref>. These are typically compared to a threshold value, and all flow vectors with confidences below the threshold are discarded. This approach does not take advantage of the full information present in the intensity signal. <p> Errors in optical flow are sometimes reported as a ratio of the error magnitude to magnitude of the actual flow, but this is problematic when the actual flow vectors are small. Fleet and Jepson <ref> [29] </ref> used an error criterion based on the unit vector normal to the velocity plane in spatio-temporal frequency: E angular = arccos [^u (^v) ^u (~v)] ; where ^u () is a function producing a three-dimensional unit vector: ^u (~v) = p 0 @ ~v y 1 A ; and the <p> The examples were computed with a three-tap blurring kernel: [0:25; 0:5; 0:25]. The mixed derivative solution appears to be substantially more robust to non-motion changes in intensity, as suggested by Fleet and Jepson <ref> [29] </ref>. We note, however, that the behavior of the basic derivative solution improves when a larger blurring filter is used. To illustrate the spatial behavior of the algorithm, we estimated the velocity field of an impulse image moving at one pixel per frame. <p> These multiple-motion situations are prevalent, and cause problems for motion algorithms. Biological systems provide inspiration here: humans have no trouble distinguishing the motion of transparently moving sheets. Several authors have discussed the problem of multiple motions <ref> [26, 4, 29, 13] </ref>. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point.
Reference: [30] <author> D. J. Fleet and A. D. Jepson. </author> <title> A cascaded filter approach to the construction of velocity selective mechanisms. </title> <type> Technical Report RBCV-TR-84-6, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1984. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section.
Reference: [31] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: For now, we note that this property is not limited to the family of derivative functions. A general theory of such filters, known as "steerable" filters, has been developed by Freeman and Adelson <ref> [31] </ref>. Given the relationship of equation (2.16), we can start to make a connection between the gradient constraint equation and the oriented filtering concept of the STEM. <p> In section 2.3, we will see that there is an important reason for this particular combination. 3 The space of rotations of the directional derivative filter forms a linear subspace. There are many possible choices of linear basis that span this subspace (cf. <ref> [31] </ref>). 37 We can also show that the non-squared components of M and ~ b may be written as opponent combinations of expressions identical to the expression in equation (2.18). <p> Freeman and Adelson have elucidated an elegant theory of such functions, which they call "steerable" <ref> [31] </ref>. They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations. Similar concepts have been studied by other authors [51, 67].
Reference: [32] <author> D. </author> <title> Gabor. </title> <journal> Theory of communication. J. IEE, </journal> <volume> 93 </volume> <pages> 492-457, </pages> <year> 1946. </year>
Reference-contexts: The problem is illustrated in figure 2-7, and is due to 4 A Gabor function is a sinusoid multiplied by a Gaussian window <ref> [32] </ref>. 5 Grzywacz and Yuille state that their solution avoids this problem, but this is only true in the limit as the spatial bandwidth of the filters approaches zero, or as the number of filters grows toward infinity. 39 Shown are level surfaces of the power spectra of the filters in <p> The ! t axis is along the cylindrical axis of symmetry of the filter locations. Surfaces are rendered assuming a fixed point light source and a Lambertian reflectance function. the somewhat arbitrary choice of filters. Gabor filters are chosen because they minimize a joint space-frequency localization criterion <ref> [32] </ref>, and because they have been suggested for use in biological modeling [22]. But this joint-localization constraint is not of primary importance in the velocity estimation problem, and many other choices of oriented bandpass filter serve equally well for purposes of physiological modeling. <p> That is, the basis functions are formed as a product of cos (!x) and sin (!x) with the window function. An example that has been used often in the image processing literature is the Gabor basis set <ref> [32] </ref> which is composed of pairs of Gaussian-windowed sinusoids and cosinusoids. In both of these cases, local phase is defined as the arctangent of the ratio of responses of the pairs of filters, and local spectral energy is the squared sum of the these.
Reference: [33] <author> A. Gelb, </author> <title> editor. Applied Optimal Estimation. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: The solution is in the form of a standard Kalman filter <ref> [33] </ref>, but with the time variable replaced by the scale, l: ~v (l + 1) = E (l) ~v (l) + K (l + 1)-(l + 1) s (l + 1)fl 0 (l + 1) h s (l + 1) fl 0 (l + 1) + fl 1 ~ f s <p> In order to make the solution computationally feasible, we ignore the off-diagonal elements in fl 0 (l + 1) (i.e., the correlations between adjacent interpolated flow vectors). Now the Kalman solution may be put into the alternative "update" form by use of the following matrix identity <ref> [33] </ref>: h i 1 The left side corresponds to the inverse of the updated covariance matrix given in the Kalman equations above: fl (l + 1) = fl 0 (l + 1) 1 + ~ f s ( ~ f T s = 4 fl 0 (l + 1) 1 +
Reference: [34] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, gibbs distibutions, and bayesian restoration of images. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: An example of such a robust estimator was implemented by Black [15]. Some authors [61, 14] have proposed Markov Random Field models that represent dis-continuities with "line processes" <ref> [34] </ref>. As with the "edge detection" problem, this approach tends to be very sensitive to threshold parameters that determine whether a change in the estimate corresponds to a discontinuity or just a rapid variation. They also run into difficulties in producing extended contours by linking together "chains" of discontinuity segments.
Reference: [35] <author> J. J. Gibson. </author> <title> The Perception of the Visual World. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, MA, </address> <year> 1950. </year>
Reference-contexts: Although much of the earliest work is due to television engineers [53, 18] and those working on biological modeling <ref> [35, 73] </ref>, the field today is populated by a wide variety of researchers in Computer Vision and Robotics, Artificial Intelligence, Signal and Image Processing, Communications Engineering, Estimation and Decision Theory, and many other fields.
Reference: [36] <author> B. Girod and D. Kuo. </author> <title> Direct estimation of displacement histograms. </title> <booktitle> In OSA meeting on Image Understanding and Machine Vision, </booktitle> <address> Cape Code, Mass, </address> <year> 1989. </year>
Reference-contexts: Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity <ref> [8, 36] </ref>. Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear [74, 84, 82, 86].
Reference: [37] <author> N. M. Grzywacz and A. L. Yuille. </author> <title> A model for the estimate of local image velocity by cells in the visual cortex. </title> <journal> Proc. R. Soc. Lond. A, </journal> <volume> 239 </volume> <pages> 129-161, </pages> <year> 1990. </year>
Reference-contexts: In this section, we will discuss a particular set of filter-based models that has received much attention from the computational biology community. These models are are based on the squared outputs of spatio-temporally oriented filters. We will refer to these as Spatio-Temporal Energy Models (STEM) <ref> [1, 40, 37] </ref>. We will show that the mixed-order differential solution discussed in the previous section may be interpreted as a spatio-temporal energy model. The importance of this observation is that it emphasizes the view of derivatives as filtering operations. <p> The arrangement of the spectra of these filters is illustrated in figure 2-6. He then used a numerical optimization procedure to find the plane that best accounted for the measurements (the error criterion was least-squares regression on the filter energies). Grzywacz and Yuille <ref> [37] </ref> also constructed velocity estimators based on energies computed from Gabor filters. They developed both a least-squares solution similar to Heeger's, in addition to a correlational (or template-matching) solution. A fundamental problem with these approaches is that the resulting velocity estimates depend on the local spatial content of the signal. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [38] <author> R. M. Haralick and J. S. Lee. </author> <title> The facet approach to optic flow. </title> <editor> In L. Baumann, editor, </editor> <booktitle> Proceedings, Image Understanding Workshop, </booktitle> <pages> pages 84-93. </pages> <institution> Science Applications, Arlington, VA, </institution> <year> 1983. </year>
Reference-contexts: Some authors have suggested the use of an intensity derivative conservation assumption, in which one applies the gradient constraint equation (2.1) to the x, y and/or t first derivative sequences. 2 This leads to optical flow calculations that are based on second derivative measurements <ref> [38, 63, 94, 95, 69] </ref>. If one includes all three partial derivatives (as in [38]), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint. <p> If one includes all three partial derivatives (as in <ref> [38] </ref>), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint. We have left out the spatial and temporal location parameters in order to simplify notation. <p> It also reasonable to combine constraints arising from different order derivative operators, as suggested. For example, we can combine the second order constraint given above with the first derivative constraint (as was done in <ref> [38] </ref>): 0 B B f x f y f xy f yy 1 C C ~v + B B @ f xt f tt C C A As before, we can compute a least-squares solution, averaged over a small patch.
Reference: [39] <author> D. J. Heeger. </author> <title> Model for the extraction of image flow. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 4(8) </volume> <pages> 1455-1471, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: We note that this type of approach for estimating orientation has been used in the array-processing literature for the problem of "direction-of-arrival" estimation [49, 25]. This concept was used by Heeger <ref> [39] </ref> to develop an algorithm for the computation of optical flow. He made local measurements of the power spectrum using a set of twelve Gabor filters 4 tuned for different spatio-temporal frequencies. The arrangement of the spectra of these filters is illustrated in figure 2-6. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [40] <author> D. J. Heeger. </author> <title> Optical flow using spatiotemporal filters. </title> <journal> Intl. J. Comp. </journal> <volume> Vis., </volume> <pages> pages 279-302, </pages> <year> 1988. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section. <p> In this section, we will discuss a particular set of filter-based models that has received much attention from the computational biology community. These models are are based on the squared outputs of spatio-temporally oriented filters. We will refer to these as Spatio-Temporal Energy Models (STEM) <ref> [1, 40, 37] </ref>. We will show that the mixed-order differential solution discussed in the previous section may be interpreted as a spatio-temporal energy model. The importance of this observation is that it emphasizes the view of derivatives as filtering operations. <p> In other words, we could use a sum of squared responses of more than two basis functions as a local estimate of spectral energy. In the motion literature, several authors previously mentioned <ref> [1, 40, 29] </ref> have used quadrature pairs in the computation of motion. As we discussed in the previous section, this can be justified from a filtering point of view in terms of symmetry. <p> Thus, we want to represent the normal component of flow, and indicate uncertainty about the parallel component of flow. Recently, some authors have developed approaches that compute two-dimensional covari-ance matrices which serve as a two-dimensional confidence measure. In particular, Heeger <ref> [40] </ref> 50 computed a Fischer information matrix by linearizing his regression model about the minimum. Anandan and others [8, 91, 86] have fitted quadratic functions to sum-of-squared-difference error surfaces to estimate confidence, although Barron et. al. [10] note that these confidence measures are often not very reliable.
Reference: [41] <author> D. J. Heeger. </author> <title> Half-squaring in responses of cat simple cells. </title> <journal> Visual Neuroscience, </journal> <volume> 9, </volume> <year> 1992. </year> <note> In press. </note>
Reference-contexts: The second is that the outputs of the cells do not continue to grow linearly with input contrast. Rather, the response saturates at high contrasts. Several researchers have suggested that this saturation may be achieved by normalizing the responses with respect to stimulus contrast. Heeger <ref> [42, 41] </ref> has modeled an extensive amount of physiological data with a model based on squaring the cell outputs and dividing by the sum of the squares of a population of cells and a semi-saturation constant.
Reference: [42] <author> D. J. Heeger. </author> <title> Normalization of cell responses in cat striate cortex. </title> <journal> Visual Neuroscience, </journal> <volume> 9, </volume> <year> 1992. </year> <note> In press. </note>
Reference-contexts: The second is that the outputs of the cells do not continue to grow linearly with input contrast. Rather, the response saturates at high contrasts. Several researchers have suggested that this saturation may be achieved by normalizing the responses with respect to stimulus contrast. Heeger <ref> [42, 41] </ref> has modeled an extensive amount of physiological data with a model based on squaring the cell outputs and dividing by the sum of the squares of a population of cells and a semi-saturation constant.
Reference: [43] <author> D. J. Heeger, A. D. Jepson, and E. P. Simoncelli. </author> <title> Model of cell responses in visual area MT. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Some of this work has been published previously in <ref> [85, 43, 44, 83] </ref>. 5.1 Psychophysics Much of the recent work in motion psychophysics has been based on simple sinusoidal stimuli.
Reference: [44] <author> D. J. Heeger and E. P. Simoncelli. </author> <title> Model of visual motion sensing. </title> <editor> In L. Harris and M. Jenkin, editors, </editor> <title> Spatial Vision in Humans and Robots. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Note that there are now three constraints for the two unknown components of velocity. Thus, unlike equation (2.1), the formulation is no longer inherently underconstrained, but overconstrained. Note also that this idea can be taken further to make use of any order of derivative (for example, in <ref> [44] </ref>, we implement a set of third derivative measurements). It also reasonable to combine constraints arising from different order derivative operators, as suggested. <p> Some of this work has been published previously in <ref> [85, 43, 44, 83] </ref>. 5.1 Psychophysics Much of the recent work in motion psychophysics has been based on simple sinusoidal stimuli. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [45] <author> E. C. Hildreth. </author> <title> Computations underlying the measurement of visual motion. </title> <journal> Artificial Intelligence, </journal> <volume> 23(3) </volume> <pages> 309-355, </pages> <year> 1984. </year>
Reference-contexts: Typically, these operate by combining information spatially. Many of these regularization solutions operate by combining the local constraint given by equation (2.1) globally. For example, Horn and Schunck [47] used a constraint of global smoothness of the velocity field. Hildreth <ref> [45] </ref> used a constraint of smoothness along contours. Nagel [63, 62] used a global oriented smoothness 26 a line (illustrated with dashes) in the two-dimensional space of all velocities constraint, in which less smoothing is done in the direction of the gradient 1 .
Reference: [46] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: In doing this, one is assuming that these intensity patterns are preserved from frame to frame. As many authors have shown, the optical flow is not always the same as the motion field (eg, <ref> [46, 97] </ref>). What do we mean by the phrase "small pieces of image intensity pattern"? We cannot ask about the motion of an isolated point from one frame to the next without considering the context surrounding it. That is, we can only recognize the motion of patterns of intensity. <p> Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in [53, 18, 26, 47, 54]. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time <ref> [46] </ref>. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc. <p> As explained in the introduction, these two quantities often differ because variations in image intensities can be caused by overall changes in brightness, highlights, or changes in the three-dimensional orientation of surfaces <ref> [46] </ref>. We can make these idealizations explicit by introducing a set of additive random variables. We define ~v as the optical flow, and ~v as the actual velocity field.
Reference: [47] <author> B. K. P. Horn and B. G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: In many ways, this is both the simplest and the most elegant approach to motion estimation. Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in <ref> [53, 18, 26, 47, 54] </ref>. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time [46]. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc. <p> Typically, these operate by combining information spatially. Many of these regularization solutions operate by combining the local constraint given by equation (2.1) globally. For example, Horn and Schunck <ref> [47] </ref> used a constraint of global smoothness of the velocity field. Hildreth [45] used a constraint of smoothness along contours.
Reference: [48] <author> D. Hubel and T. Wiesel. </author> <title> Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex. </title> <journal> J. Physiology (London), </journal> <volume> 160 </volume> <pages> 106-154, </pages> <year> 1962. </year>
Reference-contexts: There is a very large literature on the behavior of so-called "simple cells" and "complex cells" in layer V1 of the visual cortex. The standard view of simple cells is that they behave like oriented linear filters <ref> [48, 19] </ref>. There are two noticeable departures from linearity. The first is that the cell responses are rectified: cell firing rates are by definition positive, and simple cells have a fairly low background firing rate.
Reference: [49] <author> D. H. Johnson. </author> <title> The application of spectral estimation methods to bearing estimation problems. </title> <journal> Proc. IEEE, </journal> <volume> 70 </volume> <pages> 1018-1028, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: In practice, we are interested in local estimates of image velocity, and thus we need to use a local estimate of the power spectrum. We note that this type of approach for estimating orientation has been used in the array-processing literature for the problem of "direction-of-arrival" estimation <ref> [49, 25] </ref>. This concept was used by Heeger [39] to develop an algorithm for the computation of optical flow. He made local measurements of the power spectrum using a set of twelve Gabor filters 4 tuned for different spatio-temporal frequencies.
Reference: [50] <author> J. K. Kearney, W. B. Thompson, and D. L. Boley. </author> <title> Optical flow estimation: An error analysis of gradient-based methods with local optimization. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 9(2) </volume> <pages> 229-244, </pages> <year> 1987. </year>
Reference-contexts: But unless the imagery is bandlimited well below the Nyquist rate, these filters are not very good derivative approximations. For example, Kearney et. al. <ref> [50] </ref> noted that gradient approaches often perform poorly in highly "textured" regions of an image. We believe that this is due only to the poor choice of prefilter. Examples shown in section 3.4 demonstrate that differential solutions perform very well on textured imagery.
Reference: [51] <author> H. Knutsson and G. H. Granlund. </author> <title> Texture analysis using two-dimensional quadrature filters. </title> <booktitle> In IEEE Computer Society Workshop on Computer Architecture for Pattern Analysis and Image Database Management, </booktitle> <pages> pages 206-213, </pages> <year> 1983. </year>
Reference-contexts: They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations. Similar concepts have been studied by other authors <ref> [51, 67] </ref>. We can take the interpolation in equation (4.6) one step further, and compute the value of the distribution P (v) at any v from its value at a set of fixed velocities. For simplicity, we demonstrate this result for the first derivative case.
Reference: [52] <author> F. L. Kooi, R. L. DeValois, and T. K. Wyman. </author> <title> Perceived direction of moving plaids. In Invest. </title> <journal> Opthalmol. and Vis. Sci. Suppl. (ARVO), </journal> <volume> volume 29, </volume> <year> 1989. </year>
Reference-contexts: A series of experiments have revealed that the parameters of such a two-grating stimulus stimulus may be adjusted to give either of these perceptions <ref> [3, 60, 52] </ref>. The general rule seems to be that when the gratings are "similar" (i.e., similar contrast, color, spatial-frequency, orientation, speed), they are perceived as a coherent plaid. Patterns in which the gratings are very different in one or more of these parameters tend to generate perceptions of transparency.
Reference: [53] <author> J. O. Limb and J. A. Murphy. </author> <title> Estimating the velocity of moving images in television signals. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 311-327, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: Although much of the earliest work is due to television engineers <ref> [53, 18] </ref> and those working on biological modeling [35, 73], the field today is populated by a wide variety of researchers in Computer Vision and Robotics, Artificial Intelligence, Signal and Image Processing, Communications Engineering, Estimation and Decision Theory, and many other fields. <p> In many ways, this is both the simplest and the most elegant approach to motion estimation. Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in <ref> [53, 18, 26, 47, 54] </ref>. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time [46]. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc.
Reference: [54] <author> B. D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Proceedings of the 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 674-679, </pages> <address> Vancouver, </address> <year> 1981. </year>
Reference-contexts: In many ways, this is both the simplest and the most elegant approach to motion estimation. Many authors have used differential formulations for motion analysis, with some of the earliest examples being found in <ref> [53, 18, 26, 47, 54] </ref>. The prototypical gradient formulation of the optical flow problem is based on an assumption of intensity conservation over time [46]. That is, changes in the image intensity are due only to translation of the local image intensity and not to changes in lighting, reflectance, etc. <p> This is the derivation used by Lucas and Kanade <ref> [54] </ref>, in the context of stereo vision. The resulting error function is identical to that of equation (2.4). 29 Higher-order Derivatives The gradient constraint is based on an assumption of image intensity conservation. <p> The warping procedure may be applied recursively to higher frequency subbands. This "coarse-to-fine" estimation process is illustrated in figure 3.2. This type of multi-scale "warping" approach has been suggested and used by a number of authors <ref> [54, 71, 23, 8, 12] </ref>. Coarse-to-Fine Algorithms As described above, in order to generate estimates at different scales, we can apply the differential algorithm to lowpass prefilters of different bandwidth.
Reference: [55] <author> M. Luettgen, W. Karl, and A. Willsky. </author> <title> Efficient multiscale regularization with applications to the computation of optical flow. </title> <type> Technical Report LIDS-P-2115, </type> <institution> MIT Laboratory for Information and Decision Systems, </institution> <year> 1992. </year> <note> Submitted, to IEEE Trans. Image Proc. </note>
Reference-contexts: These solutions perform quite well when their assumptions are met, but problems arise when they are applied to natural images which often do not have smooth velocity fields. Another common objection to these approaches is that they are computationally expensive, although several authors have developed more efficient versions (eg, <ref> [92, 74, 55] </ref>). For the purposes of this thesis we are interested in local combination of constraints.
Reference: [56] <author> D. Marr. </author> <title> Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> San Fransisco, </address> <year> 1982. </year>
Reference-contexts: This situation is illustrated in figure 1-4, and is known as "temporal aliasing". In the computer vision literature, the related problem of matching portions of an image or features occuring in two frames is known as the "correspondence problem" <ref> [56] </ref>. We will discuss this in detail in section 3.2. Non-translational Motions One last but very important problem arises from the assumption that motion of each patch of image is translational. <p> Given that image motion at a point is often not adequately described by a single translation, the vector representation is a violation of what Marr referred to as the "principle of least commitment" <ref> [56] </ref>. For example, in a region of the scene suffering from the brick-wall or aperture problem, describing the motion of the region with a single vector is necessarily arbitrary and misleading, since the motion is not uniquely constrained.
Reference: [57] <author> D. Marr and S. Ullman. </author> <title> Directional selectivity and its use in early visual processing. </title> <journal> Proc. Royal Society of London B, </journal> <volume> 211 </volume> <pages> 151-180, </pages> <year> 1981. </year>
Reference-contexts: If the pattern slides along the direction of the stripes, the image intensity pattern will not change. Again the pattern need only be striped within the region being considered. This problem is typically known in the literature as the "aperture" problem <ref> [57] </ref>. The "blank wall" and "aperture" singularities are illustrated in figure 1-3. We will address these problems in chapter 3. Non-motion Brightness Changes As we mentioned above, most algorithms for estimating image motion fields actually compute optical flow.
Reference: [58] <author> J. H. R. Maunsell and D. C. V. Essen. </author> <title> Functional properties of neurons in middle temporal visual area of the macaque monkey i. selectivity for stimulus direction, speed, and orientation. </title> <journal> Journal of Neurophysiology, </journal> <volume> 49(5) </volume> <pages> 1127-1147, </pages> <year> 1983. </year>
Reference-contexts: More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion <ref> [60, 66, 58, 7] </ref>. We propose a two-stage model based on the "donut mechanisms" developed in the previous chapter. The model computes a distributed representation of motion in two stages, as illustrated in figure 1-6. <p> Depicted are polar plots of the response as a function of the stimulus DOM. Figure 5-19 shows a comparison of the final stage of the model with data recorded in MT by Maunsell and van Essen <ref> [58] </ref>. Depicted is a plot of response versus the log of the stimulus speed, relative to the speed that produces maximal response. <p> The stimulus is a ninety degree sinusoidal plaid. Response of the cell is on the left, response of the model is shown on the right. 121 pattern cell data (replotted from Maunsell and Van Essen <ref> [58] </ref>). The stimulus is an oriented slit of light, moving in the cell's preferred direction. Plotted is the response as a function of log speed, relative to the optimal speed.
Reference: [59] <author> A. Mitche, Y. F. Yang, and J. K. Aggarwal. </author> <title> Experiments in computing optical flow with the gradient-based, multiconstraint method. </title> <journal> Pattern Recognition, </journal> <volume> 20(2) </volume> <pages> 173-179, </pages> <year> 1987. </year> <month> 128 </month>
Reference-contexts: Furthermore, one could imagine prefiltering the image with a spatially localized filter to extract some spatio-temporal subband and computing the derivatives on this subband (see, for example <ref> [59, 88, 87] </ref>). Since both operations are linear convolutions, the prefiltering operation can be combined associatively with the derivative operation. The resulting simplified operations is equivalent to convolving with the derivative of the prefiltering function.
Reference: [60] <author> J. A. Movshon. </author> <title> Processing of motion information by neurons in the striate and ex--trastriate visual cortex of the macaque. </title> <institution> Investigative Opthalmology and Visual Science Supplement (ARVO), 26:133, </institution> <year> 1985. </year>
Reference-contexts: A series of experiments have revealed that the parameters of such a two-grating stimulus stimulus may be adjusted to give either of these perceptions <ref> [3, 60, 52] </ref>. The general rule seems to be that when the gratings are "similar" (i.e., similar contrast, color, spatial-frequency, orientation, speed), they are perceived as a coherent plaid. Patterns in which the gratings are very different in one or more of these parameters tend to generate perceptions of transparency. <p> In this case, the perception is of a flickering stationary sinusoidal pattern (this stimulus is known as a "counterphase" grating). The original descriptions of plaid perception by Adelson and Movshon <ref> [3, 60] </ref> suggested that IOC might explain the perceived motion of coherent plaids, but later work [27, 90] clearly indicates that a strict interpretation of IOC as a model for human perception fails in many situations. <p> More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion <ref> [60, 66, 58, 7] </ref>. We propose a two-stage model based on the "donut mechanisms" developed in the previous chapter. The model computes a distributed representation of motion in two stages, as illustrated in figure 1-6. <p> More recent experiments, influenced by linear systems theory, map the response of simple cells with drifting sinusoids. Sinusoid plaids and fields of random dots have also been used. In a particularly influential set of experiments, Movshon et. al. <ref> [60] </ref> used gratings and plaids as stimuli for testing complex and MT cells. They found two populations of cells: one that responded to the motion of the individual gratings of the plaid, and the other that responded to the motion of the overall pattern. <p> of a prototypical velocity energy mechanism to the three different types of stimuli. that span the space of orientation and temporal frequency tunings. 118 a sinusoidal plaid, and a field of random dots. sinusoidal plaid, and a field of random dots. 119 orientation tuning data (replotted from Movshon et. al. <ref> [60] </ref>. The stimulus is a sinusoidal grating. Response of the cell is shown on the left in a polar plot as a function of stimulus orientation. Response of the model is shown on the right (note that this is simply a circular slice through the leftmost plot in 5-11). <p> DOM should start out bimodal and become unimodal. These predictions can easily be tested in single cell recording experiments. In figures 5-15 through 5-18, we show comparisons of the two stages of the model with data from Movshon et. al. <ref> [60] </ref>. Depicted are polar plots of the response as a function of the stimulus DOM. Figure 5-19 shows a comparison of the final stage of the model with data recorded in MT by Maunsell and van Essen [58]. <p> The simple probabilistic model of chapter 3 has been successfully used to quantitatively mimic psychophysical experiments on moving plaid perception. We have also shown qualitative consistency of the "donut mechanisms" with physiological data. 120 data (replotted from Movshon et. al. <ref> [60] </ref>. The stimulus is a ninety degree sinusoidal plaid. Response of the cell is on the left, response of the model is shown on the right. Response of the cell is on the left, response of the model is shown on the right. (replotted from Movshon et. al. [60]. <p> et. al. <ref> [60] </ref>. The stimulus is a ninety degree sinusoidal plaid. Response of the cell is on the left, response of the model is shown on the right. Response of the cell is on the left, response of the model is shown on the right. (replotted from Movshon et. al. [60]. The stimulus is a ninety degree sinusoidal plaid. Response of the cell is on the left, response of the model is shown on the right. 121 pattern cell data (replotted from Maunsell and Van Essen [58]).
Reference: [61] <author> D. W. Murray and B. F. Buxton. </author> <title> Scene segmentation from visual motion using global optimization. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 9 </volume> <pages> 220-228, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: An example of such a robust estimator was implemented by Black [15]. Some authors <ref> [61, 14] </ref> have proposed Markov Random Field models that represent dis-continuities with "line processes" [34]. As with the "edge detection" problem, this approach tends to be very sensitive to threshold parameters that determine whether a change in the estimate corresponds to a discontinuity or just a rapid variation.
Reference: [62] <author> H. Nagel and W. Enkelmann. </author> <title> An investigation of smoothness constraints for the estimation of displacement vector fields from image sequences. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 8 </volume> <pages> 565-593, </pages> <month> Septemeber </month> <year> 1986. </year>
Reference-contexts: Typically, these operate by combining information spatially. Many of these regularization solutions operate by combining the local constraint given by equation (2.1) globally. For example, Horn and Schunck [47] used a constraint of global smoothness of the velocity field. Hildreth [45] used a constraint of smoothness along contours. Nagel <ref> [63, 62] </ref> used a global oriented smoothness 26 a line (illustrated with dashes) in the two-dimensional space of all velocities constraint, in which less smoothing is done in the direction of the gradient 1 .
Reference: [63] <author> H. H. Nagel. </author> <title> Displacement vectors derived from second order intensity variations in image sequences. Computer Vision, </title> <journal> Pattern Recognition, and Image Processing, </journal> <volume> 21 </volume> <pages> 85-117, </pages> <year> 1983. </year>
Reference-contexts: Typically, these operate by combining information spatially. Many of these regularization solutions operate by combining the local constraint given by equation (2.1) globally. For example, Horn and Schunck [47] used a constraint of global smoothness of the velocity field. Hildreth [45] used a constraint of smoothness along contours. Nagel <ref> [63, 62] </ref> used a global oriented smoothness 26 a line (illustrated with dashes) in the two-dimensional space of all velocities constraint, in which less smoothing is done in the direction of the gradient 1 . <p> Some authors have suggested the use of an intensity derivative conservation assumption, in which one applies the gradient constraint equation (2.1) to the x, y and/or t first derivative sequences. 2 This leads to optical flow calculations that are based on second derivative measurements <ref> [38, 63, 94, 95, 69] </ref>. If one includes all three partial derivatives (as in [38]), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint. <p> Choosing a vector to describe the motion in a blank region constitutes an overcommitment to a solution. Some researchers have advocated the use of "confidence" or "reliability" measures to indicate which optical flow vectors are to be trusted <ref> [63, 8, 29] </ref>. These are typically compared to a threshold value, and all flow vectors with confidences below the threshold are discarded. This approach does not take advantage of the full information present in the intensity signal.
Reference: [64] <author> K. Nakayama. </author> <title> Biological image motion processing: A review. Vis. </title> <journal> Res., </journal> <volume> 25 </volume> <pages> 625-660, </pages> <year> 1985. </year>
Reference-contexts: We first discuss psychophysics of human motion perception. A large literature exists on the topic of motion psychophysics, starting at least as far back as the beginning of this century. A review of this topic may be found in <ref> [64] </ref>. We will demonstrate the use of a distributed model for quantitative prediction of psychophysical data on the perception of sinusoidal plaids. Then we will discuss mammalian physiology.
Reference: [65] <author> S. Negahdaripour, A. Shokrollahi, and M. A. Gennert. </author> <title> Relaxing the brightness constancy assumption in computing optical flow. </title> <booktitle> In Proc. IEEE Intern. Conf. Image Processing, </booktitle> <pages> pages 806-810, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: decreasing over time (eg, the sun goes behind a cloud), then all of the intensities in the image will decrease. 1 More complicated situations arise when the orientation of the surfaces in the world change 1 This particular global variation in image brightness has been addressed by some authors (eg. <ref> [65] </ref>). 17 movie are shown, the first below the second.
Reference: [66] <author> W. T. Newsome, M. S. Gizzi, and J. A. Movshon. </author> <title> Spatial and temporal properties of neurons in macaque mt. </title> <institution> Investigative Opthalmology and Visual Science Supplement (ARVO), 24:106, </institution> <year> 1983. </year>
Reference-contexts: More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion <ref> [60, 66, 58, 7] </ref>. We propose a two-stage model based on the "donut mechanisms" developed in the previous chapter. The model computes a distributed representation of motion in two stages, as illustrated in figure 1-6.
Reference: [67] <author> P. Perona. </author> <title> Deformable kernels for early vision. </title> <booktitle> In IEEE Comp. Soc. Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 222-227, </pages> <address> Maui, </address> <year> 1991. </year>
Reference-contexts: They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations. Similar concepts have been studied by other authors <ref> [51, 67] </ref>. We can take the interpolation in equation (4.6) one step further, and compute the value of the distribution P (v) at any v from its value at a set of fixed velocities. For simplicity, we demonstrate this result for the first derivative case.
Reference: [68] <author> T. Poggio and W. Reichardt. </author> <title> Considerations on models of movement detection. </title> <journal> Kybernet, </journal> <volume> 13 </volume> <pages> 223-227, </pages> <year> 1973. </year>
Reference-contexts: Perhaps it is not surprising that many of the approaches turn out to be based on quadratic combinations of linear measurements since the underlying error analysis is often a least-squares formulation. Poggio and Reichardt <ref> [68] </ref> have shown the equivalence of the time-averaged output of all two-input second-order motion detectors. Brockett [16] has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians. <p> In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section.
Reference: [69] <author> T. Poggio, W. Yang, and V. Torre. </author> <title> Optical flow: Computational properties and networks, biological and analog. </title> <editor> In R. Durbin, C. Miall, and G. Mitcheson, editors, </editor> <booktitle> The Computing Neuron, chapter 19, </booktitle> <pages> pages 355-370. </pages> <publisher> Addison-Wesley, </publisher> <address> Wokingham, England, </address> <year> 1988. </year>
Reference-contexts: Some authors have suggested the use of an intensity derivative conservation assumption, in which one applies the gradient constraint equation (2.1) to the x, y and/or t first derivative sequences. 2 This leads to optical flow calculations that are based on second derivative measurements <ref> [38, 63, 94, 95, 69] </ref>. If one includes all three partial derivatives (as in [38]), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint.
Reference: [70] <author> D. Pollen and S. Ronner. </author> <title> Visual cortical neurons as localized spatial-frequency filters. </title> <journal> IEEE Trans. Sys. Man Cyber., </journal> <volume> 13 </volume> <pages> 907-916, </pages> <year> 1983. </year>
Reference-contexts: The "complex cells" in area V1 have similar behavior to simple cells, except that they are not sensitive to the phase (or symmetry) of the stimulus. These cells have been modeled as a quadrature combination of simple cell responses, corresponding to equation (3.11) <ref> [70, 1, 72] </ref>. More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion [60, 66, 58, 7].
Reference: [71] <author> L. Quam. </author> <title> Hierarchical warp stereo. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop, </booktitle> <month> September </month> <year> 1984. </year>
Reference-contexts: The warping procedure may be applied recursively to higher frequency subbands. This "coarse-to-fine" estimation process is illustrated in figure 3.2. This type of multi-scale "warping" approach has been suggested and used by a number of authors <ref> [54, 71, 23, 8, 12] </ref>. Coarse-to-Fine Algorithms As described above, in order to generate estimates at different scales, we can apply the differential algorithm to lowpass prefilters of different bandwidth.
Reference: [72] <author> E. H. A. R C Emerson, J R Bergen. </author> <title> Directionally selective complex cells and the computation of motion energy in cat visual cortex. </title> <journal> Vision Research, </journal> <volume> 32(2) </volume> <pages> 203-218, </pages> <year> 1992. </year>
Reference-contexts: The "complex cells" in area V1 have similar behavior to simple cells, except that they are not sensitive to the phase (or symmetry) of the stimulus. These cells have been modeled as a quadrature combination of simple cell responses, corresponding to equation (3.11) <ref> [70, 1, 72] </ref>. More recently, authors have studied the behavior of cells in the cortical area known as V5 or "MT". There is growing evidence that some of the cells are tuned for speed and direction of motion [60, 66, 58, 7].
Reference: [73] <author> W. Reichardt. </author> <title> Autocorrelation, a principle for the evaluation of sensory information by the central nervous system. </title> <editor> In W. A. Rosenblith, editor, </editor> <title> Sensory Communication. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1961. </year> <month> 129 </month>
Reference-contexts: Although much of the earliest work is due to television engineers [53, 18] and those working on biological modeling <ref> [35, 73] </ref>, the field today is populated by a wide variety of researchers in Computer Vision and Robotics, Artificial Intelligence, Signal and Image Processing, Communications Engineering, Estimation and Decision Theory, and many other fields. <p> They suggested that these energy outputs should be combined in "opponent" fashion, subtracting the output of a mechanism tuned for leftward motion from one tuned for rightward motion. They showed that their opponent STEM approach was closely related to the modified Reichardt correlation model of van Santen and Sperling <ref> [73, 96] </ref>.
Reference: [74] <author> A. Rougee, B. C. Levy, and A. S. Willsky. </author> <title> An estimation-based approach to the recon-struction of optical flow. </title> <type> Technical Report LIDS-P-1663, </type> <institution> MIT Laboratory for Information and Decision Systems, </institution> <month> April </month> <year> 1987. </year>
Reference-contexts: These solutions perform quite well when their assumptions are met, but problems arise when they are applied to natural images which often do not have smooth velocity fields. Another common objection to these approaches is that they are computationally expensive, although several authors have developed more efficient versions (eg, <ref> [92, 74, 55] </ref>). For the purposes of this thesis we are interested in local combination of constraints. <p> Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear <ref> [74, 84, 82, 86] </ref>. The concepts of integrating prior information and providing directional uncertainty information suggests a Bayesian analysis of the problem. In this chapter, we will extend the basic and mixed-order algorithms of in the previous section to include uncertainty. Previous versions of this work appear in [82].
Reference: [75] <author> M. Shizawa and K. Mase. </author> <title> Simultaneous multiple optical flow estimation. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Atlantic City, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Several authors have discussed the problem of multiple motions [26, 4, 29, 13]. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point. Shizawa and Mase <ref> [75, 76] </ref> have described algorithms for explicitly computing two motion vectors at each point in the scene. Bergen et. al. [13] have developed an algorithm for separating two transparently combined images moving according to an affine velocity field. We take a different approach here. <p> Note that there are other forms of regression. For example, we could use the distance perpendicular to the line, as has been suggested by Shizawa and Mase <ref> [75, 76] </ref>. But this places undue emphasis on high frequency spectral content, and our preliminary tests indicate that it may perform poorly for optical flow estimation. Nulling versus Maximizing The value of the regression functions of the previous section will be minimized at the true velocity.
Reference: [76] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Maui, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Several authors have discussed the problem of multiple motions [26, 4, 29, 13]. Some authors have tried to handle the problem by using higher-order expansions of the motion field (eg, affine). Here we will instead consider representing more than one motion at each point. Shizawa and Mase <ref> [75, 76] </ref> have described algorithms for explicitly computing two motion vectors at each point in the scene. Bergen et. al. [13] have developed an algorithm for separating two transparently combined images moving according to an affine velocity field. We take a different approach here. <p> Note that there are other forms of regression. For example, we could use the distance perpendicular to the line, as has been suggested by Shizawa and Mase <ref> [75, 76] </ref>. But this places undue emphasis on high frequency spectral content, and our preliminary tests indicate that it may perform poorly for optical flow estimation. Nulling versus Maximizing The value of the regression functions of the previous section will be minimized at the true velocity.
Reference: [77] <author> E. P. Simoncelli. </author> <title> Computing optical flow from first and second order directional cosines. Vision and modeling technical report, </title> <publisher> MIT Media Laboratory, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: Brockett [16] has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians. Some of the work presented in this section has been described previously in <ref> [80, 79, 81, 77] </ref>. 2.1 Differential Techniques Since velocity is a differential quantity, it is natural to consider its estimation through the use of derivative measurements. In many ways, this is both the simplest and the most elegant approach to motion estimation.
Reference: [78] <author> E. P. Simoncelli. </author> <title> Distributed representations of image velocity. Vision and Modeling Technical Report 202, </title> <publisher> MIT Media Laboratory, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: A sampled representation is also more likely to be appropriate for biological modeling. We demonstrate the use of this sampled representation on simple synthetic examples containing occlusion boundaries and transparent surfaces. Preliminary versions of this work have appeared in <ref> [80, 78] </ref>. 4.1 One-Dimensional Case In this section, we develop the concept of distributed velocity representation. We will start by analyzing the one-dimensional gradient approach in the frequency domain.
Reference: [79] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Computation of optical flow: Relationship between several standard techniques. Vision and Modeling Technical Report 165, </title> <publisher> MIT Media Laboratory, </publisher> <month> November </month> <year> 1990. </year> <note> Revised, </note> <month> March </month> <year> 1991. </year>
Reference-contexts: Brockett [16] has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians. Some of the work presented in this section has been described previously in <ref> [80, 79, 81, 77] </ref>. 2.1 Differential Techniques Since velocity is a differential quantity, it is natural to consider its estimation through the use of derivative measurements. In many ways, this is both the simplest and the most elegant approach to motion estimation.
Reference: [80] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Optical flow distributions: gradient, energy and regression methods. </title> <booktitle> In Optical Society of America, Annual Meeting, </booktitle> <address> Boston, MA, </address> <month> Novem-ber </month> <year> 1990. </year>
Reference-contexts: Brockett [16] has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians. Some of the work presented in this section has been described previously in <ref> [80, 79, 81, 77] </ref>. 2.1 Differential Techniques Since velocity is a differential quantity, it is natural to consider its estimation through the use of derivative measurements. In many ways, this is both the simplest and the most elegant approach to motion estimation. <p> A sampled representation is also more likely to be appropriate for biological modeling. We demonstrate the use of this sampled representation on simple synthetic examples containing occlusion boundaries and transparent surfaces. Preliminary versions of this work have appeared in <ref> [80, 78] </ref>. 4.1 One-Dimensional Case In this section, we develop the concept of distributed velocity representation. We will start by analyzing the one-dimensional gradient approach in the frequency domain.
Reference: [81] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Relationship between gradient, spatio-temporal energy, and regression models for motion perception. </title> <booktitle> In Investigative Opthalmology and Visual Science Supplement (ARVO), </booktitle> <volume> volume 32, </volume> <year> 1991. </year>
Reference-contexts: Brockett [16] has shown that several motion extraction algorithms (although not those discussed here) may be described in a common least-squares framework based on Gramians. Some of the work presented in this section has been described previously in <ref> [80, 79, 81, 77] </ref>. 2.1 Differential Techniques Since velocity is a differential quantity, it is natural to consider its estimation through the use of derivative measurements. In many ways, this is both the simplest and the most elegant approach to motion estimation.
Reference: [82] <author> E. P. Simoncelli, E. H. Adelson, and D. J. Heeger. </author> <title> Probability distributions of optical flow. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, Mauii, Hawaii, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear <ref> [74, 84, 82, 86] </ref>. The concepts of integrating prior information and providing directional uncertainty information suggests a Bayesian analysis of the problem. In this chapter, we will extend the basic and mixed-order algorithms of in the previous section to include uncertainty. Previous versions of this work appear in [82]. <p> The concepts of integrating prior information and providing directional uncertainty information suggests a Bayesian analysis of the problem. In this chapter, we will extend the basic and mixed-order algorithms of in the previous section to include uncertainty. Previous versions of this work appear in <ref> [82] </ref>. In our view, this constitutes a fundamental shift in the representation of visual motion. Whereas we previously computed vector-field estimates of the image velocity, we will now compute probability distributions over the set of all possible image velocity vectors at a given spatio-temporal location.
Reference: [83] <author> E. P. Simoncelli and D. J. Heeger. </author> <title> A computational model for representation of image velocities. </title> <booktitle> In Investigative Opthalmology and Visual Science Supplement (ARVO), </booktitle> <volume> volume 34, </volume> <year> 1993. </year>
Reference-contexts: Some of this work has been published previously in <ref> [85, 43, 44, 83] </ref>. 5.1 Psychophysics Much of the recent work in motion psychophysics has been based on simple sinusoidal stimuli.
Reference: [84] <author> E. P. Simoncelli, D. J. Heeger, and E. H. Adelson. </author> <title> Perception of 3D motion in the presence of uncertainty. </title> <booktitle> In Investigative Opthalmology and Visual Science Supplement (ARVO), </booktitle> <volume> volume 31, </volume> <year> 1990. </year>
Reference-contexts: Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear <ref> [74, 84, 82, 86] </ref>. The concepts of integrating prior information and providing directional uncertainty information suggests a Bayesian analysis of the problem. In this chapter, we will extend the basic and mixed-order algorithms of in the previous section to include uncertainty. Previous versions of this work appear in [82].
Reference: [85] <author> E. P. Simoncelli, D. J. Heeger, and E. H. Adelson. </author> <title> A computational model for perception of two-dimensional pattern velocities. </title> <booktitle> In Investigative Opthalmology and Visual Science Supplement (ARVO), </booktitle> <volume> volume 33, </volume> <year> 1992. </year>
Reference-contexts: Some of this work has been published previously in <ref> [85, 43, 44, 83] </ref>. 5.1 Psychophysics Much of the recent work in motion psychophysics has been based on simple sinusoidal stimuli. <p> We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [86] <author> A. Singh. </author> <title> Incremental estimation of image-flow using a kalman filter. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Recently, some authors have developed approaches that compute two-dimensional covari-ance matrices which serve as a two-dimensional confidence measure. In particular, Heeger [40] 50 computed a Fischer information matrix by linearizing his regression model about the minimum. Anandan and others <ref> [8, 91, 86] </ref> have fitted quadratic functions to sum-of-squared-difference error surfaces to estimate confidence, although Barron et. al. [10] note that these confidence measures are often not very reliable. Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity [8, 36]. <p> Szeliski [91] has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear <ref> [74, 84, 82, 86] </ref>. The concepts of integrating prior information and providing directional uncertainty information suggests a Bayesian analysis of the problem. In this chapter, we will extend the basic and mixed-order algorithms of in the previous section to include uncertainty. Previous versions of this work appear in [82].
Reference: [87] <author> P. Sobey and M. V. Srinivasan. </author> <title> Measurement of optical flow by a generalized gradient scheme. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 8(9) </volume> <pages> 1488-1498, </pages> <month> September </month> <year> 1991. </year> <month> 130 </month>
Reference-contexts: Thus, we can apply the gradient constraint equation to a set of images prefiltered with different localized filters (see, for example <ref> [88, 87] </ref>). We will discuss the issues of prefilter design in section 3.3. 30 Note that without the summation, the solution is just the standard least-squares pseudo-inverse solution of the linear system in equation (2.11). At this point, this combination of constraints seems a bit arbitrary. <p> Furthermore, one could imagine prefiltering the image with a spatially localized filter to extract some spatio-temporal subband and computing the derivatives on this subband (see, for example <ref> [59, 88, 87] </ref>). Since both operations are linear convolutions, the prefiltering operation can be combined associatively with the derivative operation. The resulting simplified operations is equivalent to convolving with the derivative of the prefiltering function. <p> This is because, for example, the local phase estimates for a pattern of intensities does not vary if the contrast of the pattern is modified. Some related work has been done by other authors <ref> [100, 87] </ref>. We give a shortened derivation of the Fleet and Jepson estimator here. The basic algorithm is one-dimensional. Even- and odd-symmetric Gabor filters tuned for a particular orientation are applied to the image, producing responses f e and f o .
Reference: [88] <author> M. V. Srinivasan. </author> <title> Generalized gradient schemes for the measurement of two-dimensional image motion. </title> <journal> Biol. Cybern., </journal> <volume> 63 </volume> <pages> 421-431, </pages> <year> 1990. </year>
Reference-contexts: Thus, we can apply the gradient constraint equation to a set of images prefiltered with different localized filters (see, for example <ref> [88, 87] </ref>). We will discuss the issues of prefilter design in section 3.3. 30 Note that without the summation, the solution is just the standard least-squares pseudo-inverse solution of the linear system in equation (2.11). At this point, this combination of constraints seems a bit arbitrary. <p> Furthermore, one could imagine prefiltering the image with a spatially localized filter to extract some spatio-temporal subband and computing the derivatives on this subband (see, for example <ref> [59, 88, 87] </ref>). Since both operations are linear convolutions, the prefiltering operation can be combined associatively with the derivative operation. The resulting simplified operations is equivalent to convolving with the derivative of the prefiltering function.
Reference: [89] <author> L. S. Stone and P. Thompson. </author> <title> Human speed perception is contrast dependent. Vis. </title> <journal> Res., </journal> <volume> 32(8) </volume> <pages> 1535-1549, </pages> <year> 1992. </year>
Reference-contexts: The direction 106 reported is that normal to the stimulus orientation. 1 For high-contrast gratings, the perceived speed is the actual translation speed of the grating, although experiments by Thompson and Stone indicate that the perceived speed does vary with contrast <ref> [93, 89] </ref>. When two such gratings are superimposed, the perception becomes more complicated. We first note that more than one physical explanation can account for the stimulus.
Reference: [90] <author> L. S. Stone, A. B. Watson, and J. B. Mulligan. </author> <title> Effect of contrast on the perceived direction of a moving plaid. Vis. </title> <journal> Res., </journal> <volume> 30(7) </volume> <pages> 1049-1067, </pages> <year> 1990. </year>
Reference-contexts: In this case, the perception is of a flickering stationary sinusoidal pattern (this stimulus is known as a "counterphase" grating). The original descriptions of plaid perception by Adelson and Movshon [3, 60] suggested that IOC might explain the perceived motion of coherent plaids, but later work <ref> [27, 90] </ref> clearly indicates that a strict interpretation of IOC as a model for human perception fails in many situations. Some authors have proposed models that compute a sort of average of the IOC solution and a vector sum (i.e., the sum of the grating normal velocity vectors) [27]. <p> The parameter e is a semi-saturation constant for the energy normalization, and p is the prior probability variance. These were fitted to the data as described below. The prefilter used with the derivatives was a Gaussian. We consider an experiment by Stone et. al. <ref> [90] </ref>. The authors examined the effects of contrast ratio on the perception of coherent plaid motion direction. In general, they found that the perceived direction of motion of a plaid was biased away from the IOC solution toward the normal velocity of the higher contrast grating.
Reference: [91] <author> R. Szeliski. </author> <title> Bayesian modeling of uncertainty in low-level vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(3) </volume> <pages> 271-301, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Recently, some authors have developed approaches that compute two-dimensional covari-ance matrices which serve as a two-dimensional confidence measure. In particular, Heeger [40] 50 computed a Fischer information matrix by linearizing his regression model about the minimum. Anandan and others <ref> [8, 91, 86] </ref> have fitted quadratic functions to sum-of-squared-difference error surfaces to estimate confidence, although Barron et. al. [10] note that these confidence measures are often not very reliable. Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity [8, 36]. <p> Some authors have also considered autocorrelation or displacement histograms and used these as a sort of distribution over velocity [8, 36]. Szeliski <ref> [91] </ref> has discussed the use of Bayesian techniques for a variety of problems in low-level vision, including optical flow estimation. Estimation-theoretic approaches to optical flow are beginning to appear [74, 84, 82, 86]. <p> As we have described, a "coarse-to-fine" algorithm can be used to handle problems of temporal aliasing. We noted that it also may be viewed as a technique for combining information from different spatial scales. It is also a technique for imposing a prior smoothness constraint (see, for example, <ref> [91, 20] </ref>). This basic technique does, however, have a serious drawback. If the coarse-scale estimates are incorrect, then the fine-scale estimates will have no chance of correcting the errors. To fix this, we must have knowledge of the error in the coarse-scale estimates.
Reference: [92] <author> D. Terzopoulos. </author> <title> Image analysis using multigrid relaxation methods. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 8 </volume> <pages> 129-139, </pages> <year> 1986. </year>
Reference-contexts: These solutions perform quite well when their assumptions are met, but problems arise when they are applied to natural images which often do not have smooth velocity fields. Another common objection to these approaches is that they are computationally expensive, although several authors have developed more efficient versions (eg, <ref> [92, 74, 55] </ref>). For the purposes of this thesis we are interested in local combination of constraints.
Reference: [93] <author> P. Thompson. </author> <title> Perceived rate of movement depends on contrast. Vis. </title> <journal> Res., </journal> <volume> 22 </volume> <pages> 377-380, </pages> <year> 1982. </year>
Reference-contexts: The direction 106 reported is that normal to the stimulus orientation. 1 For high-contrast gratings, the perceived speed is the actual translation speed of the grating, although experiments by Thompson and Stone indicate that the perceived speed does vary with contrast <ref> [93, 89] </ref>. When two such gratings are superimposed, the perception becomes more complicated. We first note that more than one physical explanation can account for the stimulus.
Reference: [94] <author> O. Tretiak and L. </author> <title> Pastor. Velocity estimation from image sequences with second order differential operators. </title> <booktitle> In IEEE, </booktitle> <pages> pages 16-19, </pages> <year> 1984. </year>
Reference-contexts: Some authors have suggested the use of an intensity derivative conservation assumption, in which one applies the gradient constraint equation (2.1) to the x, y and/or t first derivative sequences. 2 This leads to optical flow calculations that are based on second derivative measurements <ref> [38, 63, 94, 95, 69] </ref>. If one includes all three partial derivatives (as in [38]), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint.
Reference: [95] <author> S. Uras, F. Girosi, A. Verri, and V. Torre. </author> <title> A computational approach to motion perception. </title> <journal> Biol. Cybern., </journal> <volume> 60 </volume> <pages> 79-87, </pages> <year> 1988. </year>
Reference-contexts: Some authors have suggested the use of an intensity derivative conservation assumption, in which one applies the gradient constraint equation (2.1) to the x, y and/or t first derivative sequences. 2 This leads to optical flow calculations that are based on second derivative measurements <ref> [38, 63, 94, 95, 69] </ref>. If one includes all three partial derivatives (as in [38]), the resulting constraint equations are written as: 0 @ f xy f yy 1 A ~v + B f xt f tt C As in equation (2.1), this is a pointwise constraint.
Reference: [96] <author> J. P. H. van Santen and G. Sperling. </author> <title> Temporal covariance model of human motion perception. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 1 </volume> <pages> 451-473, </pages> <year> 1984. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section. <p> They suggested that these energy outputs should be combined in "opponent" fashion, subtracting the output of a mechanism tuned for leftward motion from one tuned for rightward motion. They showed that their opponent STEM approach was closely related to the modified Reichardt correlation model of van Santen and Sperling <ref> [73, 96] </ref>.
Reference: [97] <author> A. Verri and T. Poggio. </author> <title> Motion field and optical flow: Qualitative properties. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <pages> pages 490-498, </pages> <year> 1989. </year>
Reference-contexts: In doing this, one is assuming that these intensity patterns are preserved from frame to frame. As many authors have shown, the optical flow is not always the same as the motion field (eg, <ref> [46, 97] </ref>). What do we mean by the phrase "small pieces of image intensity pattern"? We cannot ask about the motion of an isolated point from one frame to the next without considering the context surrounding it. That is, we can only recognize the motion of patterns of intensity.
Reference: [98] <author> A. B. Watson and A. J. Ahumada. </author> <title> A look at motion in the frequency domain. </title> <editor> In J. K. Tsotsos, editor, </editor> <booktitle> Motion: Perception and representation, </booktitle> <pages> pages 1-10. </pages> <year> 1983. </year>
Reference-contexts: This is illustrated in figure 2-5. The situation in two dimensions, while more difficult to illustrate, is analogous. A translating two-dimensional pattern has the appearance of oriented "bundles of fibers" in space-time (x; y; t). Watson and Ahumada <ref> [98] </ref> and others have noted that the Fourier transform spectrum of an image undergoing rigid translation lies in a plane in the spatio-temporal frequency domain. 38 " " the frequency domain. On the left is a translating fractal noise signal.
Reference: [99] <author> A. B. Watson and A. J. Ahumada. </author> <title> Model of human visual-motion sensing. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 2 </volume> <pages> 322-342, </pages> <year> 1985. </year>
Reference-contexts: In the next two sections, we will give stronger justifications for this "mixed-order" solution. 2.2 Spatio-temporal Filtering Techniques The previous section discussed differential approaches to estimating image velocity. Another view of motion analysis is based on the use of spatio-temporal filters <ref> [68, 24, 30, 96, 99, 1, 40] </ref>. Much of this work comes from the computational biology community and is physiologically motivated. These approaches are usually considered to be completely distinct from the differential approaches discussed in the previous section.
Reference: [100] <author> A. M. Waxman and K. Wohn. </author> <title> Contour evolution, neighbourhood deformation, and global image flow: Planar surfaces in motion. </title> <journal> Inter. J. Robotics Res., </journal> <volume> 4 </volume> <pages> 95-108, </pages> <year> 1985. </year>
Reference-contexts: This is because, for example, the local phase estimates for a pattern of intensities does not vary if the contrast of the pattern is modified. Some related work has been done by other authors <ref> [100, 87] </ref>. We give a shortened derivation of the Fleet and Jepson estimator here. The basic algorithm is one-dimensional. Even- and odd-symmetric Gabor filters tuned for a particular orientation are applied to the image, producing responses f e and f o . <p> e;x f o ) Fleet and Jepson extended this to two dimensions by fitting an affine model of the velocity field using a least squares combination of the one-dimensional normal constraints from different spatial orientations in a small region of space (a technique that was developed by Waxman and Wohn <ref> [100] </ref>). We can show that the solution of equation (2.27) corresponds spectrally to a quadrature energy solution like the mixed-order solution we have developed. First, we can see that the numerator (denominator) contains two terms.
Reference: [101] <author> L. Welch. </author> <title> The perception of moving plaids reveals two motion-processing stages. </title> <journal> Nature, </journal> <volume> 337 </volume> <pages> 734-736, </pages> <year> 1989. </year>
Reference-contexts: We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
Reference: [102] <author> H. R. Wilson, V. P. Ferrera, and C. Yo. </author> <title> A psychophysically motivated model for two-dimensional motion perception. </title> <journal> Visual Neuroscience, </journal> <volume> 9 </volume> <pages> 79-97, </pages> <year> 1992. </year> <month> 131 </month>
Reference-contexts: We will not model any details of the single-cell computation. Furthermore, we will model only the steady-state behavior of the system. A number of researchers have begun to converge on a two-stage model for the computation of motion information in visual cortex <ref> [3, 1, 39, 101, 37, 102, 44, 85] </ref>. As in the computer vision literature, these models all seem to have a similar flavor. Linear filters are used to extract particular subbands of spatio-temporal information. These outputs are quadratically combined to produce local Fourier energy estimates.
References-found: 102

