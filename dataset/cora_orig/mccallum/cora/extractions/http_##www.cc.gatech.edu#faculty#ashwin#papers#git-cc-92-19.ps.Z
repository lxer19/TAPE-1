URL: http://www.cc.gatech.edu/faculty/ashwin/papers/git-cc-92-19.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Email: ashwin@cc.gatech.edu and cox@cc.gatech.edu  
Title: Introspective reasoning using meta-explanations for multistrategy learning  
Author: Ashwin Ram and Michael T. Cox 
Note: Appears in R.S. Michalski and G. Tecuci (eds.), Machine Learning: A Multistrategy Approach, Vol. IV, pages 349-377, Morgan Kaufman Publishers,  
Address: Atlanta, Georgia 30332-0280  San Mateo, CA, 1994.  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: In order to learn effectively, a reasoner must not only possess knowledge about the world and be able to improve that knowledge, but it also must introspectively reason about how it performs a given task and what particular pieces of knowledge it needs to improve its performance at the current task. Introspection requires declarative representations of meta-knowledge of the reasoning performed by the system during the performance task, of the system's knowledge, and of the organization of this knowledge. This chapter presents a taxonomy of possible reasoning failures that can occur during a performance task, declarative representations of these failures, and associations between failures and particular learning strategies. The theory is based on Meta-XPs, which are explanation structures that help the system identify failure types, formulate learning goals, and choose appropriate learning strategies in order to avoid similar mistakes in the future. The theory is implemented in a computer model of an introspective reasoner that performs multistrategy learning during a story understanding task. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ahmad, A., Matwin, S., & Ould-Brahim, H. </author> <title> Acquiring the Second Tier: An Experiment in Learning Two-Tiered Concepts, </title> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning, </booktitle> <editor> R.S. Michalski & G. Tecuci (eds.), </editor> <booktitle> pp. </booktitle> <pages> 419-426, </pages> <address> Harpers Ferry, WV, </address> <year> 1991. </year>
Reference: <author> Alexander, J. Metacognition and Giftedness, </author> <note> Paper presented at the Southeast Cognitive Science Conference, </note> <institution> Georgia Institute of Technology, Atlanta, Georgia, </institution> <month> January </month> <year> 1992. </year>
Reference: <author> Alterman, R. </author> <title> A Dictionary based on Concept Coherence, </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 25, </volume> <pages> pp. 153-186, </pages> <year> 1985. </year>
Reference: <author> Barsalou, L. </author> <title> Deriving Categories to Achieve Goals, in The Psychology of Learning and Motivation: </title> <booktitle> Advances in Research and Theory, </booktitle> <volume> Volume 27, </volume> <editor> G.H. Bower (ed.), </editor> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference: <author> Bhatta, S., & Ram, A. </author> <title> Learning Indices for Schema Selection, </title> <booktitle> Proceedings of the Florida Artificial Intelligence Research Symposium, </booktitle> <address> M.B. </address> <publisher> Fishman (ed.), </publisher> <pages> pp. 226-231, </pages> <address> Cocoa Beach, FL, </address> <year> 1991. </year>
Reference: <author> Birnbaum, L., & Collins, G. </author> <title> Opportunistic Planning and Freudian Slips, </title> <booktitle> Proceedings of the Sixth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 124-127, </pages> <address> Boulder, CO, </address> <year> 1984. </year>
Reference: <author> Birnbaum, L., Collins, G., Freed, M., & Krulwich, B. </author> <title> Model-based Diagnosis of Planning Failures, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 318-323, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference: <author> Brazdil, P.B., & Konolige, K. </author> <title> Machine Learning, Meta-reasoning, and Logics, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference: <author> Carbonell, J.G. </author> <title> Derivational Analogy: A Theory of Reconstructive Problem Solving and Expertise Acquisition, Machine Learning II: An Artificial Intelligence Approach, R.S. </title> <editor> Michalski, J.G. Carbonell, & T. Mitchell (eds.), </editor> <booktitle> pp. </booktitle> <pages> 371-392, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1986. </year>
Reference: <author> Carr, M. </author> <title> Metacognitive Knowledge as a Predictor of Decomposition Strategy Use, </title> <booktitle> Paper presented at the Southeast Cognitive Science Conference, </booktitle> <institution> Georgia Institute of Technology, Atlanta, Georgia, </institution> <month> January </month> <year> 1992. </year>
Reference: <author> Chi, M.T.H., & VanLehn, K.A. </author> <title> The Content of Physics Self-explanations, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 69-105, </pages> <year> 1991. </year>
Reference: <author> Collins, G., & Birnbaum, L. </author> <title> Problem-Solver State Descriptions as Abstract Indices for Case Retrieval, </title> <booktitle> Working Notes of the AAAI Spring Symposium Series: Case-Based Reasoning, </booktitle> <address> Stanford, CA, </address> <year> 1990. </year> <note> 18 Cox, </note> <author> M., & Ram, A. </author> <title> Multistrategy Learning with Introspective Meta-Explanations, </title> <booktitle> Machine Learning: Proceedings of the Ninth International Conference, </booktitle> <editor> D. Sleeman & P. Edwards (eds.), </editor> <booktitle> ppp. </booktitle> <pages> 123-128, </pages> <address> Aberdeen, Scotland, </address> <year> 1992. </year>
Reference: <author> Davis, R. </author> <title> Meta-rules: Reasoning about control, </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 15, No. 3, </volume> <pages> pp. 179-222, </pages> <year> 1980. </year>
Reference: <author> DeJong, </author> <title> G.F., & Mooney, R.J. Explanation-based learning: An alternative view, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 145-176, </pages> <year> 1986. </year>
Reference: <author> Doyle, J. </author> <title> A Truth Maintenance System, </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 12, </volume> <pages> pp. 231-272, </pages> <year> 1979. </year>
Reference-contexts: To represent these conditions, Meta-AQUA uses standard non-monotonic logic values of in (in the current set of beliefs) and out (out of the current set of beliefs) <ref> (Doyle, 1979) </ref>, augmented with hypothesized-in (weakly assumed in), hypothesized-out (weakly assumed out), and hypothesized (unknown) (Ram, 1989). Thus, absolute retrieval failure is represented by A [truth = in] = E [truth = out].
Reference: <author> Falkenhainer, B. </author> <title> A Unified Approach to Explanation and Theory Formation, Computational Models of Scientific Discovery and Theory Formation, </title> <editor> J. Shrager & P. </editor> <booktitle> Langley (eds.), </booktitle> <pages> pp. 157-196, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Flann, N.S., & Dietterich, T.G. </author> <title> A Study of Explanation-based Methods for Inductive Learning, </title> <journal> Machine Learning, </journal> <volume> Vol. 4, </volume> <pages> pp. 187-226, </pages> <year> 1989. </year>
Reference: <author> Genest, J., Matwin, S., & Plante, B. </author> <title> Explanation-based Learning with Incomplete Theories: A Three-step Approach, </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, B.W. Porter & R.J. Mooney (eds.), </booktitle> <pages> pp. 286-294, </pages> <address> Austin, TX, </address> <year> 1990. </year>
Reference: <author> Hammond, K.J. </author> <title> Opportunistic Memory: Storing and Recalling Suspended Goals, </title> <booktitle> Proceedings of a Workshop on Case-based Reasoning, J.L. Kolodner (ed.), </booktitle> <pages> pp. 154-168, </pages> <address> Clearwater Beach, FL, </address> <year> 1988. </year>
Reference: <author> Hammond, K.J. </author> <title> Case-based Planning: Viewing Planning as a Memory Task, </title> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1989. </year>
Reference: <author> Hayes-Roth, B., and Hayes-Roth, F. </author> <title> A Cognitive Model of Planning, </title> <journal> Cognitive Science, </journal> <volume> Vol. 2, </volume> <pages> pp. 275-310, </pages> <year> 1979. </year>
Reference: <author> Hunter, L. </author> <title> Classifying for Prediction: A Multistrategy Approach to Predicting Protein Structure, Machine Learning: A Multi-strategy Approach, Vol. IV, R.S. </title> <editor> Michalski & G. Tecuci (eds.), </editor> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: <author> Hunter, L. </author> <title> Knowledge Acquisition Planning for Inference from Large Datasets, </title> <booktitle> Proceedings of the Twenty Third Annual Hawaii International Conference on System Sciences, B.D. Shriver (ed.), </booktitle> <pages> pp. 35-45, </pages> <address> Kona, HI, </address> <year> 1990a. </year>
Reference: <author> Hunter, L. </author> <title> Planning to Learn, </title> <booktitle> Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 26-34, </pages> <address> Boston, MA, </address> <year> 1990b. </year>
Reference: <author> Kass, A., Leake, D., and Owens, C. SWALE: </author> <title> A Program That Explains, Explanation Patterns: Understanding Mechanically and Creatively, R.C. </title> <booktitle> Schank, </booktitle> <pages> pp. 232-254, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference: <author> Kedar-Cabelli, S. </author> <title> Toward a Computational Model of Purpose-directed Analogy, </title> <editor> Analogica, A. Prieditis (ed.), </editor> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference: <author> Kolodner, J.L., and Simpson, </author> <title> R.L. A Case for Case-based Reasoning, </title> <booktitle> Proceedings of the Sixth Annual Conference of the Cognitive Science Society, </booktitle> <address> Boulder, CO, </address> <year> 1984. </year>
Reference: <author> Laird, J.E., Rosenbloom, P.S., and Newell, A. </author> <title> Chunking in Soar: The Anatomy of a General Learning Mechanism, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, </volume> <pages> pp. 11-46, </pages> <year> 1986. </year>
Reference: <author> Maes, P. </author> <title> Introspection in knowledge representation, </title> <booktitle> Advances in Artificial Intelligence II, </booktitle> <editor> B. Du Boulay, D. Hogg, and L. Steels (eds.), </editor> <publisher> Elsevier Science Publishers, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference: <author> Maes, P., and Nardi, D. </author> <title> Meta-Level Architectures and Reflection. </title> <publisher> Elsevier Science Publishers, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference: <author> Michalski, </author> <title> R.S. Inferential Theory of Learning: Developing Foundations for Multistrategy Learning, Machine Learning: A Multistrategy Approach, Vol. IV, R.S. </title> <editor> Michalski & G. Tecuci (eds.), </editor> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Learning in such situations is usually incremental, and involves strategies such as elaborative question asking (Ram, 1993) applied to the reasoning chain and abstraction, generalization and specialization techniques in conceptual memory <ref> (Michalski, 1993) </ref>. * Mis-indexed knowledge structure: The reasoner may have an applicable knowledge structure, but it may not be indexed in memory such that it can be retrieved using the particular cues provided by the context.
Reference: <author> Michalski, </author> <title> R.S. A Theory and Methodology of Inductive Learning, </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 20, </volume> <pages> pp. 111-161, </pages> <year> 1983. </year>
Reference-contexts: The situation is said to be anomalous with respect to the current knowledge in the system. In such a situation, the reasoner could use a variety of learning strategies, including explanation-based generalization (DeJong & Mooney, 1986; Mitchell, Keller, & Kedar-Cabelli, 1986), inductive generalization from input examples <ref> (Michalski, 1983) </ref>, and explanation-based refinement (Ram, 1993), coupled with index learning to place the new structures appropriately in memory. * Incorrect background knowledge: Even if the reasoner has knowledge structures that are applicable to the situation, these knowledge structures may be incomplete or incorrect.
Reference: <author> Minsky, M. </author> <title> Steps towards Artificial Intelligence, Computers and Thought, E.A. </title> <editor> Feigenbaum and J. Feldman (eds.), </editor> <booktitle> pp. </booktitle> <pages> 406-450, </pages> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1963. </year>
Reference: <author> Minsky, M. </author> <title> The Society of Mind, </title> <publisher> Simon and Schuster, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: Unlike successful processing where there may or may not be anything to learn, failure situations are guaranteed to provide a potential for learning; otherwise, the failure would not have occurred <ref> (Minsky, 1985) </ref>. 2 When a reasoning failure occurs, the system posts a knowledge goal which drives the reasoner to explain or otherwise resolve the gaps in its knowledge. Knowledge goals, often expressed as questions, represent the reasoner's goals to learn (Ram, 1989, 1991; Ram & Hunter, 1992).
Reference: <author> Mitchell, T.M., Keller, R., and Kedar-Cabelli, S. </author> <title> Explanation-based Generalization: A Unifying View, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 47-80, </pages> <year> 1986. </year>
Reference-contexts: The notion of a target concept used some learning systems <ref> (e.g., Mitchell, Keller, & Kedar-Cabelli, 1986) </ref>, again, is less flexible than the knowledge goals underlying the work presented here.
Reference: <author> Mitchell, T.M., Utgoff, P.E., and Banerji, R. </author> <title> Learning by Experimentation: Acquiring and Refining Problem-Solving Heuristics, Machine Learning: An Artificial Intelligence Approach, R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell (eds.), </editor> <booktitle> pp. </booktitle> <pages> 163-189, </pages> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1983. </year> <note> 19 Mooney, R.J., </note> <author> and Ourston, D. </author> <title> A Multistrategy Approach to Theory Refinement, Machine Learning: A Multistrategy Approach, Vol. IV, R.S. </title> <editor> Michalski & G. Tecuci (eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: <author> Ng, E., and Bereiter, C. </author> <title> Three Levels of Goal Orientation in Learning, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, Nos. 3 & 4, </volume> <pages> pp. 243-271, </pages> <year> 1991. </year>
Reference: <author> Ng, H., and Mooney, </author> <title> R.J. On the Role of Coherence in Abductive Explanation, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 337-342, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference: <author> Park, Y., and Wilkins, </author> <title> D.C. Establishing the Coherence of an Explanation to Improve Refinement of an Incomplete Knowledge Base, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 511-516, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference: <author> Pazzani, M.J. </author> <title> Learning to Predict and Explain: An Integration of Similarity-based, Theory-driven and Explanation-based Learning, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 153-199, </pages> <year> 1991. </year>
Reference: <author> Pirolli, P., and Bielaczyc, K. </author> <title> Empirical Analyses of Self-Explanation and Transfer in Learning to Program, </title> <booktitle> Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, </booktitle> <year> 1989. </year>
Reference: <author> Pollock, J.L. </author> <title> A General Theory of Rationality, </title> <journal> Journal of Theoretical and Experimental Artificial Intelligence, </journal> <volume> Vol. 1, </volume> <pages> pp. 209-226, </pages> <year> 1989. </year>
Reference: <author> Rajamoney, S. </author> <title> Explanation-basedtheory revision: An approach to the problems of incomplete and incorrect theories, </title> <type> Ph.D. thesis, </type> <institution> University of Illinois, Department of Computer Science, Urbana, IL, </institution> <year> 1989. </year>
Reference: <author> Ram, A. </author> <title> Question-driven Understanding: An Integrated Theory of Story Understanding, Memory and Learning, </title> <type> Ph.D. thesis, Research Report #710, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1989. </year>
Reference-contexts: The use of explicit Meta-XP structures allow direct inspection of the reasons by which knowledge goals are posted and processed, thus enabling a system to improve its ability to reason and learn. 3 Example: The Drug Bust To instantiate and test the theory, an introspective version of the AQUA system <ref> (Ram, 1989, 1991, 1993) </ref> called Meta-AQUA has been implemented. AQUA is a question-driven story understanding system that learns about Middle Eastern terrorist activities. <p> To represent these conditions, Meta-AQUA uses standard non-monotonic logic values of in (in the current set of beliefs) and out (out of the current set of beliefs) (Doyle, 1979), augmented with hypothesized-in (weakly assumed in), hypothesized-out (weakly assumed out), and hypothesized (unknown) <ref> (Ram, 1989) </ref>. Thus, absolute retrieval failure is represented by A [truth = in] = E [truth = out]. The relation that identifies the truth value of E as being out of the current set of beliefs mentally-initiates the assertion that a retrieval failure exists.
Reference: <author> Ram, A. </author> <title> Decision Models: A Theory of Volitional Explanation, </title> <booktitle> Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 198-205, </pages> <address> Cambridge, MA, </address> <year> 1990a. </year>
Reference-contexts: Further, it allows the system to pose knowledge goals about aspects of the reasoning process itself. 5 Representation of Trace Meta-XPs The AQUA system embodies a theory of motivational explanation based on decision models <ref> (Ram, 1990a, in press) </ref>, which represent the decision process that an agent goes through in deciding whether to perform an action. The agent considers its goals, goal priorities, and the expected outcome of performing the action, and then decides whether to perform the action.
Reference: <author> Ram, A. </author> <title> Knowledge Goals: A Theory of Interestingness, </title> <booktitle> Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 206-214, </pages> <address> Cambridge, MA, </address> <year> 1990b. </year>
Reference: <author> Ram, A. </author> <title> A Theory of Questions and Question Asking, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, Nos. 3 & 4, </volume> <pages> pp. 273-318, </pages> <year> 1991. </year>
Reference-contexts: The process of explanation generates 5 questions, or knowledge goals, representing what the system needs to know in order to be able to explain similar situations in the future, thus avoiding repeated similar failures <ref> (Ram, 1991, 1993) </ref>. Explanation patterns are similar to justification trees, linking antecedent conditions to their consequences. An XP is essentially a directed graph of concepts, connected with results, enables and initiates links. <p> When a hypothesis is generated, it is passed to the verification subsystem. Strategies for hypothesis verification include the devising of a test (currently not implemented; see, e.g., Rajamoney, 1989), comparison to known concepts, and suspension of the reasoning task until further information is available <ref> (Ram, 1991) </ref>. The system reviews the chain of reasoning after the verification phase is complete. The review process examines the Trace Meta-XP to check whether there was a reasoning failure. If a failure occurred, the review process searches for an introspective explanation. <p> The error is found by searching all hypothesis generation D-C-NODES on the path from the EXPLAINS node of A to the node E, performing elaborative question asking <ref> (Ram, 1991, 1993) </ref>. This case has not yet been represented declaratively. Meta-AQUA reasons about it using a general search heuristic for blame assignment. Meta-XP combines an XP-Novel-Situation, an XP-Mis-Indexed-Structure, and an XP-Incorrect-Background-Knowledge.
Reference: <author> Ram, A. </author> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases, </title> <journal> Machine Learning, </journal> <volume> Vol. 10, No. 3, </volume> <pages> pp. 201-248, </pages> <year> 1993. </year>
Reference-contexts: In such a situation, the reasoner could use a variety of learning strategies, including explanation-based generalization (DeJong & Mooney, 1986; Mitchell, Keller, & Kedar-Cabelli, 1986), inductive generalization from input examples (Michalski, 1983), and explanation-based refinement <ref> (Ram, 1993) </ref>, coupled with index learning to place the new structures appropriately in memory. * Incorrect background knowledge: Even if the reasoner has knowledge structures that are applicable to the situation, these knowledge structures may be incomplete or incorrect. <p> Learning in such situations is usually incremental, and involves strategies such as elaborative question asking <ref> (Ram, 1993) </ref> applied to the reasoning chain and abstraction, generalization and specialization techniques in conceptual memory (Michalski, 1993). * Mis-indexed knowledge structure: The reasoner may have an applicable knowledge structure, but it may not be indexed in memory such that it can be retrieved using the particular cues provided by the <p> Although AQUA is a general model of case-based learning with multiple learning methods <ref> (see Ram, 1993) </ref>, it falls short of being a general model of multistrategy learning, as defined in this chapter because the knowledge underlying the selection of appropriate learning methods in different situations is not explicitly represented in the system.
Reference: <author> Ram, A. </author> <title> AQUA: Questions that Drive the Explanation Process, to appear in Inside Computer Explanation, R.C. </title> <editor> Schank, A. Kass, & C.K. Riesbeck, </editor> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <publisher> in press. </publisher>
Reference: <author> Ram, A., and Hunter, L. </author> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning, </title> <journal> Applied Intelligence, </journal> <volume> Vol. 2, No. 1, </volume> <pages> pp. 47-73, </pages> <year> 1992. </year>
Reference: <author> Ram, A., and Leake, D. </author> <title> Goal-driven Learning: Fundamental Issues and Symposium Report, </title> <journal> to appear in AI Magazine, </journal> <volume> Vol. 14, No. 4, </volume> <year> 1993. </year>
Reference-contexts: In such a situation, the reasoner could use a variety of learning strategies, including explanation-based generalization (DeJong & Mooney, 1986; Mitchell, Keller, & Kedar-Cabelli, 1986), inductive generalization from input examples (Michalski, 1983), and explanation-based refinement <ref> (Ram, 1993) </ref>, coupled with index learning to place the new structures appropriately in memory. * Incorrect background knowledge: Even if the reasoner has knowledge structures that are applicable to the situation, these knowledge structures may be incomplete or incorrect. <p> Learning in such situations is usually incremental, and involves strategies such as elaborative question asking <ref> (Ram, 1993) </ref> applied to the reasoning chain and abstraction, generalization and specialization techniques in conceptual memory (Michalski, 1993). * Mis-indexed knowledge structure: The reasoner may have an applicable knowledge structure, but it may not be indexed in memory such that it can be retrieved using the particular cues provided by the <p> Although AQUA is a general model of case-based learning with multiple learning methods <ref> (see Ram, 1993) </ref>, it falls short of being a general model of multistrategy learning, as defined in this chapter because the knowledge underlying the selection of appropriate learning methods in different situations is not explicitly represented in the system.
Reference: <author> Reich, Y. </author> <title> Macro and Micro Perspectives of Multistrategy Learning, Machine Learning: A Multistrategy Approach, </title> <booktitle> Vol. IV, </booktitle> <pages> R.S. </pages>
Reference: <editor> Michalski & G. Tecuci (eds.), </editor> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Learning in such situations is usually incremental, and involves strategies such as elaborative question asking (Ram, 1993) applied to the reasoning chain and abstraction, generalization and specialization techniques in conceptual memory <ref> (Michalski, 1993) </ref>. * Mis-indexed knowledge structure: The reasoner may have an applicable knowledge structure, but it may not be indexed in memory such that it can be retrieved using the particular cues provided by the context.
Reference: <author> Scardamalia, M., and Bereiter, C. </author> <title> Higher Levels of Agency for Children in Knowledge Building: A Challenge for the Design of New Knowledge Media, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 37-68, </pages> <year> 1991. </year>
Reference-contexts: This view is consistent with psychological data on question asking in educational contexts <ref> (e.g., Scardamalia and Bereiter, 1991) </ref>, and on goal orientation in learning (e.g., Barsalou, 1991; Ng & Bereiter, 1991) and in focus of attention and inferencing (cf. Zukier's 1986 review).
Reference: <author> Schank, </author> <title> R.C., and Leake, D.B. Creativity and Learning in a Case-based Explainer, Machine Learning: Paradigms and Methods, </title> <editor> J.G. Carbonell (ed.), </editor> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: <author> Schank, </author> <title> R.C. Dynamic Memory: A Theory of Learning in Computers and People, </title> <publisher> Cambridge University Press, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference: <author> Schank, </author> <title> R.C. The Current State of AI: One Man's Opinion, </title> <journal> AI Magazine, </journal> <volume> Vol. 4, No. 1, </volume> <pages> pp. 3-8, </pages> <year> 1983. </year>
Reference-contexts: 1 Introduction It is generally accepted that learning is central to intelligent reasoning systems that perform realistic reasoning tasks, such as understanding natural language stories or solving non-trivial problems <ref> (e.g., Schank, 1983) </ref>. It is impossible to anticipate all possible situations in advance and to hand-program a machine with exactly the right knowledge to deal with all the situations it might be faced with.
Reference: <author> Schank, R.C.. </author> <title> Explanation Patterns: Understanding Mechanically and Creatively, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: A theory of content and representation of these meta-models is presented along with a computer model, Meta-AQUA, that implements this theory for a story understanding task. The theory focuses on failure-driven learning. The term failure includes not simply performance errors, but also expectation failures <ref> (Schank, 1986) </ref>, anomalous situations that the reasoner failed to predict, and other types of reasoning failures.
Reference: <author> Shavlik, J.W., and Towell, G.G. </author> <title> An Approach to Combining Explanation-based and Neural Learning Algorithms, </title> <journal> Connection Science, </journal> <volume> Vol. 1, No. 3, </volume> <year> 1989. </year> <title> 20 Stefik, </title> <journal> M.J. Planning and Meta-planning (MOLGEN: Part 2), Artificial Intelligence, </journal> <volume> Vol. 16, </volume> <pages> pp. 141-169, </pages> <year> 1981. </year>
Reference: <author> Thagard, P. </author> <title> Explanatory Coherence, </title> <journal> Behavioral and Brain Sciences, </journal> <volume> Vol. 12, No. 3, </volume> <pages> pp. 435-502, </pages> <year> 1989. </year>
Reference: <author> VanLehn, K.A, Jones, R.M., and Chi, M.T.H. </author> <title> A Model of the Self-explanation Effect, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 2, No. 1, </volume> <pages> pp. 1-60, </pages> <year> 1992. </year>
Reference: <author> Weintraub, M.A. </author> <title> An Explanation-based Approach to Assigning Credit, </title> <type> Ph.D. thesis, </type> <institution> Department of Information and Computer Science, The Ohio State University, Columbus, OH, </institution> <year> 1991. </year>
Reference: <author> Wilensky, R. Meta-planning: </author> <title> Representing and using Knowledge about Planning in Problem Solving and Natural Language Understanding, </title> <journal> Cognitive Science, </journal> <volume> Vol. 5, </volume> <pages> pp. 197-233, </pages> <year> 1981. </year>
Reference: <author> Winston, P.H. </author> <title> Learning Structural Descriptions from Examples, The Psychology of Computer Vision, </title> <publisher> P.H. Winston (ed.), </publisher> <pages> pp. 157-209, </pages> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1975. </year>
Reference: <author> Zukier, H. </author> <title> The Paradigmatic and Narrative Modes in Goal-guided Inference, Handbook of Motivation and Cognition: Foundations of Social Behavior, </title> <editor> R. Sorrentino and E. </editor> <booktitle> Higgins (eds.), </booktitle> <pages> pp. 465-502, </pages> <publisher> Guilford Press, </publisher> <address> Guilford, CT, </address> <year> 1986. </year> <month> 21 </month>
References-found: 65

