URL: ftp://ftp.cs.uchicago.edu/pub/publications/tech-reports/TR-95-07.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Title: Easy Sets Without Easy Small Subsets  
Author: Lance Fortnow 
Keyword: Classification: Computational Complexity  
Address: 1100 E. 58th Street Chicago, Illinois 60637  
Affiliation: Computer Science Department University of Chicago  
Abstract: We show the existence of relativized worlds relative to which there exist infinite polynomial-time computable sets without infinite polynomial-time computable sparse subsets or even non-deterministically polynomial-time computable sparse subsets. This result is tight since every infinite P set has an infinite sparse coNP subset.
Abstract-found: 1
Intro-found: 1
Reference: [BGS75] <author> T. Baker, J. Gill, and R. Solovay. </author> <title> Relativizations of the P = NP question. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(4) </volume> <pages> 431-442, </pages> <year> 1975. </year>
Reference-contexts: We also get the complementary relativized result to Theorem 2.5: Corollary 4.3 There exists a relativized world where every infinite polynomial-time computable set has an infinite polynomial-time computable sparse subset. Proof: Baker, Gill and Solovay <ref> [BGS75] </ref> create an oracle A where P A = NP A = coNP A .
Reference: [Edm65] <author> J. Edmonds. </author> <title> Paths, trees and flowers. </title> <journal> Canadian Journal of Mathematics, </journal> <volume> 17 </volume> <pages> 449-467, </pages> <year> 1965. </year>
Reference-contexts: 1 Introduction Back in 1965, Jack Edmonds <ref> [Edm65] </ref> gave a formal definition of efficient computation as those computations computable in time polynomial in the length of their input. In the three decades of computational complexity theory that followed, this definition has stood the test of time of the "right" theoretical notion of easily computable.
Reference: [FK95] <author> L. Fortnow and M. Kummer. </author> <title> Resource-bounded instance complexity. </title> <note> Theoretical Computer Science A, 1995. To appear. </note>
Reference-contexts: Email: fortnow@cs.uchicago.edu 1 In Section 2, we prove a relativizing failure of Conjecture 1.1 using Kolmogorov distinguishing complexity combining a result of Fortnow and Kummer <ref> [FK95] </ref> with a new result showing that every easy sparse set has only easily distinguishable elements. In Section 3, we prove Theorem 1.2 using a finite injury argument to delicately remove strings from an easy set that are accepted by small NP sets. <p> Although this result follows from Theorem 1.2, we feel the simpler proof of this result will help in understanding this problem. Fortnow and Kummer <ref> [FK95] </ref> prove the following result about relativized CD complexity: Theorem 2.1 There is an infinite set B such that for every polynomial p: CD (x) jxj=5 for almost all x 2 B: We will also use the following theorem that follows from Spielman's work on error correcting codes. <p> There exists a polynomial p and a constant c such that for every x in A, CND p (x) c log 2 n. One would then hope that the proof of Fortnow and Kummer <ref> [FK95] </ref> could generalize to show Conjecture 5.2 There is an infinite set B and a constant c such that for every polynomial p: CND p;B (x) jxj=c for almost all x 2 B: One could then conclude Theorem 1.2 from Theorem 5.1 and Conjecture 5.2 as in the proof of Theorem
Reference: [For94] <author> L. Fortnow. </author> <title> The role of relativization in complexity theory. </title> <journal> Bulletin of the European Association for Theoretical Computer Science, </journal> <volume> 52 </volume> <pages> 229-244, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Thus by showing that statements is true and false relative to various oracles implies that new techniques will likely be necessary to settle that question. For more details on the role of relativization see the survey by Fortnow <ref> [For94] </ref>. 1.2 Kolmogorov Complexity Many of the proofs in this paper rely on Kolmogorov complexity. We now discuss the definitions and facts needed for the Kolmogorov complexity arguments using the notation of Li and Vitanyi [LV93].
Reference: [HU79] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1979. </year>
Reference-contexts: 5, we discuss some open questions and an intriguing nondeterministic variation of the Kolmogorov distinguishing complexity. 1.1 Concepts Other than Kolmogorov complexity as discussed in Section 1.2 most of the concepts discussed in this paper are standard and can be found in an undergraduate textbook such as Hopcroft and Ullman <ref> [HU79] </ref>. Let = f0; 1g. Let n consist of all of the strings over of length n. For a finite set A we use jAj to represent the number of elements of A.
Reference: [LV93] <author> M. Li and P. Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and Its Applications. Texts and Monographs in Computer Science. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: For more details on the role of relativization see the survey by Fortnow [For94]. 1.2 Kolmogorov Complexity Many of the proofs in this paper rely on Kolmogorov complexity. We now discuss the definitions and facts needed for the Kolmogorov complexity arguments using the notation of Li and Vitanyi <ref> [LV93] </ref>. For more information about Kolmogorov complexity and for proofs of the facts we mention in this section, please see Li and Vitanyi [LV93]. Kolmogorov complexity tries measures the amount of randomness in a string. <p> We now discuss the definitions and facts needed for the Kolmogorov complexity arguments using the notation of Li and Vitanyi <ref> [LV93] </ref>. For more information about Kolmogorov complexity and for proofs of the facts we mention in this section, please see Li and Vitanyi [LV93]. Kolmogorov complexity tries measures the amount of randomness in a string. While no fixed string should not be any more "likely" than any other string, nevertheless some strings like 101010101010 seem less "random" then 011010110110.
Reference: [Spi95] <author> D. Spielman. </author> <title> Linear-time encodable and decodable error-correcting codes. </title> <booktitle> In Proceedings of the 27th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 388-397. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1995. </year> <month> 8 </month>
References-found: 7

