URL: ftp://ftp.imag.fr/pub/DRAKKAR/duda/ecmast98.ps.gz
Refering-URL: http://delos.imag.fr/publications.html
Root-URL: http://www.imag.fr
Title: An Execution Architecture for Synchronized Multimedia Presentations  
Author: Franck Rousseau ? and Andrzej Duda 
Address: 2 LSR-IMAG Grenoble, France  
Affiliation: 1 Open Group Research Institute  
Abstract: We have defined an execution architecture for playing back synchronized multimedia documents. We suppose that such documents are specified by means of several abstractions including hypertime links, time bases, and dynamic layout. Our architecture is based on three concepts: synchronization events, synchronization managers, and synchro-nizable media objects. It supports the notion of elastic time that adapts to available resources. We have prototyped the architecture using Java and experimented with playback of simple synchronized presentations. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> SMIL: </author> <title> Synchronized Multimedia Integration Language. WD-smil-971109, World Wide Web Consortium (W3C), </title> <month> November </month> <year> 1997. </year> <note> Latest version available at http://www.w3.org/TR/WD-smil. </note>
Reference-contexts: Second, even if such a standard exists, we need a flexible execution architecture to playback synchronized presentations on different platforms (something comparable to Mosaic that made WWW widely known). The WWW Consortium has initiated an activity to define a new standard for synchronized multimedia documents: SMIL <ref> [1] </ref>. SMIL adds to HTML some features related to time behavior: components of a SMIL document may be continuous multimedia. However, SMIL has some drawbacks: Temporal composition is based on a hybrid approach that mixes two different abstractions: intervals and time-points.
Reference: 2. <author> Rousseau, F., Duda, A.: </author> <title> Synchronized Multimedia for the WWW. 7th Intl. </title> <booktitle> World Wide Web Conf. </booktitle> <address> (WWW7), Brisbane, Australia, </address> <month> April 14-18, </month> <year> 1998. </year>
Reference-contexts: As a consequence, the layout is static | it cannot change in time. The static layout limits authoring possibilities, because temporal objects may require placement that varies in time. To overcome these problems, we have proposed temporal extensions to HTML based on three concepts <ref> [2] </ref>: - hypertime links for temporal composition, common time bases for close lip-sync synchronization between media objects, dynamic layout that can be seen as an extension of media objects. <p> It is based on XML and provides some basic functionalities for including continuous multimedia data such as video and audio in WWW documents. However, as stated in the introduction, it has several drawbacks. In a previous paper <ref> [2] </ref> we have proposed temporal extensions to HTML based on: hypertime links, time bases, and dynamic layout. 2.1 Hypertime Links for Temporal Composition We propose to use a simple functional paradigm derived from temporal point nets to specify temporal composition: a temporal link between an origin and a target. <p> Frames can include other layouts to specify nested layouts that provide nested coordinate spaces. Hypertime links define how the layout changes in time. This approach allows seamless integration of spatial and temporal dimensions into a multimedia document. The syntax of the temporal extensions, examples and discussion are given in <ref> [2] </ref>. 3 Execution Architecture for Synchronized Multimedia Documents To support the model presented above, we have defined an execution architecture for playing back documents specified using the proposed temporal extensions to HTML.
Reference: 3. <author> Papathomas, M.: </author> <title> ATOM: An Active Object Model for Enhancing Reuse in the Development of Concurrent Software. </title> <institution> RR 963-I-LSR-2, LSR - IMAG, Grenoble, France, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Active objects provide a nice basis for this goal, because they can guarantee flexibility and extensibility. We have begun with this approach in mind and after considering specific needs of multimedia synchronization, we have came up with an event based model similar to ATOM <ref> [3] </ref>, but much simpler and more specific. The architecture offers time management support to a collection of heterogeneous objects included in a multimedia document. Its only role is to guarantee a coherent playback of a document according to its temporal specification. <p> Our first tests with the MPEG decoder show performance gains around 25% when these checks are off. 5 Related Work This paper builds upon previous work done in the domain of multimedia synchronization, time representation, and temporal composition. Many proposed solutions are based on active objects such as ATOM <ref> [3] </ref>. We have not adopted this model, because it seems to us that handling time critical 3 http://www.mpeg.org/MSSG/ tasks with fine grain synchronization would be too costly.
Reference: 4. <author> Lu, G.: </author> <title> Communication and Computing for Distributed Multimedia Systems. </title> <publisher> Artech House, </publisher> <year> 1996. </year>
Reference-contexts: The architecture offers time management support to a collection of heterogeneous objects included in a multimedia document. Its only role is to guarantee a coherent playback of a document according to its temporal specification. Synchronization of media objects raises three kinds of problems that should be solved <ref> [4] </ref>: - Intramedia synchronization guarantees that a continuous media will be played at a requested rate.
Reference: 5. <author> Manohar, N.R., Prakash, A.: </author> <title> Dealing with Synchronization and Timing Variability in the Playback of Session Recordings. </title> <booktitle> Proc. of ACM Multimedia'95, </booktitle> <address> San Francisco, CA, </address> <pages> pages 45-56, </pages> <month> November 5-9, </month> <year> 1995. </year>
Reference-contexts: Event management is then much more simple and accurate, since it is performed by one entity. Communication delays between objects are shorter and we do not need associated locking mechanisms. A synchronization mechanism based on global events has been already proposed <ref> [5] </ref>. In this approach, events are global: all the streams to be synchronized contain the same events, so that they can be matched to enforce synchronization. In our model, events are provided by objects and synchronization is maintained by tight control of the distance between these events.
Reference: 6. <author> Gutfreund, Y.S., Diaz-Gonzalez, J., Sasnett, R., Phuah, V.: CircusTalk: </author> <title> An Orchestration Service for Distributed Multimedia. </title> <booktitle> Proc. of ACM Multimedia'93, </booktitle> <address> Anaheim, CA, </address> <pages> pages 351-358, </pages> <month> August 1-6, </month> <year> 1993. </year>
Reference-contexts: In our model, events are provided by objects and synchronization is maintained by tight control of the distance between these events. A distributed service for orchestration of multimedia has been proposed by Gutfreund et al. <ref> [6] </ref>. Flinn has proposed a mechanism for sound effect control [7]. In his solution, events are scheduled in a similar way to our architecture. A scheduler dispatches events or sequences of events as requested by independent applications. Such a framework is very flexible and is used to provide graceful degradation.
Reference: 7. <author> Flinn, S.: </author> <title> Coordinating Heterogeneous Time-Based Media Between Independent Applications. </title> <booktitle> Proc. of ACM Multimedia'95, </booktitle> <address> San Francisco, CA, </address> <pages> pages 435-444, </pages> <month> November 5-9, </month> <year> 1995. </year>
Reference-contexts: In our model, events are provided by objects and synchronization is maintained by tight control of the distance between these events. A distributed service for orchestration of multimedia has been proposed by Gutfreund et al. [6]. Flinn has proposed a mechanism for sound effect control <ref> [7] </ref>. In his solution, events are scheduled in a similar way to our architecture. A scheduler dispatches events or sequences of events as requested by independent applications. Such a framework is very flexible and is used to provide graceful degradation.
Reference: 8. <author> Orlarey, Y. and Lequay, H.: MidiShare: </author> <title> A Real Time Multi-tasks Software Module for MIDI Applications. </title> <booktitle> Proc. of the Int. Computer Music Conf., Computer Music Association, </booktitle> <address> San Francisco, CA, </address> <pages> pages 234-237, </pages> <year> 1989. </year>
Reference-contexts: Such a framework is very flexible and is used to provide graceful degradation. However, events are handled in a static way in the form of collections and the solutions proposed are more oriented toward rhythmic patterns and phase synchronization. Other work in this domain concerns systems supporting musical applications <ref> [8] </ref> and distributed multimedia systems [9]. 6 Conclusion and Future Work We have defined an execution architecture for playback of synchronized multimedia documents. We suppose that such documents are specified by means of several abstractions including hypertime links, time bases, and dynamic layout.
Reference: 9. <author> Steinmetz, R.: </author> <title> Synchronization Properties in Multimedia Systems. </title> <booktitle> JSAC, </booktitle> <pages> 8(3)401-412, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: However, events are handled in a static way in the form of collections and the solutions proposed are more oriented toward rhythmic patterns and phase synchronization. Other work in this domain concerns systems supporting musical applications [8] and distributed multimedia systems <ref> [9] </ref>. 6 Conclusion and Future Work We have defined an execution architecture for playback of synchronized multimedia documents. We suppose that such documents are specified by means of several abstractions including hypertime links, time bases, and dynamic layout.
Reference: 10. <author> Cen, S., Pu, C., Staehli, R., Cowan, C., Walpole, J.: </author> <title> Demonstrating the Effect of Software Feedback on a Distributed Real-Time MPEG Video Audio Player. </title> <booktitle> Proc. of ACM Multimedia'95, </booktitle> <address> San Francisco, CA, </address> <pages> pages 239-240, </pages> <month> November 5-9, </month> <year> 1995. </year>
Reference-contexts: We perform tests to increase performance, which would allow us to experiment with more complex documents. After performance tunning, we would like to investigate adaptive quality of service at the level of media processing and transport protocols. We will consider solutions such as software feedback <ref> [10, 11] </ref>, receiver-transmitter control [12], client-server negotiation to see how they can be integrated with our architecture.
Reference: 11. <author> Cen, S., Pu, C., Staehli, R., Cowan, C., Walpole, J.: </author> <title> A Distributed Real-Time MPEG Video Audio Player. </title> <booktitle> Proc. of the 5th Int. Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV'95), volume 1018 of Lecture Notes in Computer Science, </booktitle> <pages> pages 151-162, </pages> <address> Durham, NH, </address> <month> April 18-21, </month> <year> 1995. </year>
Reference-contexts: We perform tests to increase performance, which would allow us to experiment with more complex documents. After performance tunning, we would like to investigate adaptive quality of service at the level of media processing and transport protocols. We will consider solutions such as software feedback <ref> [10, 11] </ref>, receiver-transmitter control [12], client-server negotiation to see how they can be integrated with our architecture.
Reference: 12. <author> Correia, M., Pinto, P.: </author> <title> Low-Level Multimedia Synchronization Algorithms on Broadband Networks. </title> <booktitle> Proc. of ACM Multimedia'95, </booktitle> <address> San Francisco, CA, </address> <pages> pages 423-434, </pages> <month> November 5-9, </month> <year> 1995. </year>
Reference-contexts: We perform tests to increase performance, which would allow us to experiment with more complex documents. After performance tunning, we would like to investigate adaptive quality of service at the level of media processing and transport protocols. We will consider solutions such as software feedback [10, 11], receiver-transmitter control <ref> [12] </ref>, client-server negotiation to see how they can be integrated with our architecture.
References-found: 12

