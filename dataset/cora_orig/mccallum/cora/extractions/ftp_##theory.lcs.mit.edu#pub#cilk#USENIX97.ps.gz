URL: ftp://theory.lcs.mit.edu/pub/cilk/USENIX97.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~cilk/papers.html
Root-URL: 
Email: rdb@cs.utexas.edu  lisiecki@mit.edu  
Title: Adaptive and Reliable Parallel Computing on Networks of Workstations  
Author: Robert D. Blumofe Philip A. Lisiecki 
Date: October 21, 1996  
Address: Austin, Texas 78712  545 Technology Square Cambridge, Massachusetts 02139  
Affiliation: Department of Computer Sciences The University of Texas at Austin  MIT Laboratory for Computer Science  
Abstract: In this paper, we present the design of Cilk-NOW, a runtime system that adaptively and reliably executes functional Cilk programs in parallel on a network of UNIX workstations. Cilk (pronounced silk) is a parallel multithreaded extension of the C language, and all Cilk runtime systems employ a provably efficient thread-scheduling algorithm. Cilk-NOW is such a runtime system, and in addition, Cilk-NOW automatically delivers adaptive and reliable execution for a functional subset of Cilk programs. By adaptive execution, we mean that each Cilk program dynamically utilizes a changing set of otherwise-idle workstations. By reliable execution, we mean that the Cilk-NOW system as a whole and each executing Cilk program are able to tolerate machine and network faults. Cilk-NOW provides these features while programs remain fault oblivious, meaning that Cilk programmers need not code for fault tolerance. Throughout this paper, we focus on end-to-end design decisions, and we show how these decisions allow the design to exploit high-level algorithmic properties of the Cilk programming model in order to simplify and streamline the implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lorenzo Alvisi and Keith Marzullo. </author> <title> Message logging: Pessimistic, optimistic, causal and optimal. </title> <booktitle> In Proceedings of the 15th IEEE International Conference on Distributed Computing Systems, </booktitle> <pages> pages 229236, </pages> <address> Vancouver, Canada, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: We are currently working on this problem. The dag-consistency model was conceived with adaptive parallelism and fault tolerance in mind, and we are investigating the idea of coupling our current return transactions mechanism with a causal message-logging mechanism <ref> [1] </ref>. In other current research, we are investigating distributed macroscheduling algorithms. The goal of such an algorithm is to assign idle workstations to Cilk jobs so that each job gets a fair share and without requiring that users explicitly state their application's resource needs.
Reference: [2] <author> Cristiana Amza, Alan L. Cox, Sandhya Dwarkadas, Pete Keleher, Honghui Lu, Ramakrishnan Rajamony, Weimin Yu, and Willy Zwaenepoel. TreadMarks: </author> <title> Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2):1828, </volume> <month> February </month> <year> 1996. </year>
Reference-contexts: Each job should get its fair share of the idle machines, but no job should get more machines than it can efficiently utilize. 7 Related work Cilk-NOW is unique in delivering adaptive and reliable execution for parallel programs on networks of workstations. Traditionally, systems such as PVM [41], Tread-Marks <ref> [2] </ref>, and others [11, 16, 23, 29] that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [3] <author> Thomas E. Anderson, David E. Culler, and David A. Pat-terson. </author> <title> A case for NOW (networks of workstations. </title> <journal> IEEE Micro, </journal> <volume> 15(1):5464, </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: 1 Introduction A strong case argues for the use of networks of workstations (NOWs) as parallel-computation platforms <ref> [3] </ref>, and Cilk-NOW [6] is a software system that has been designed and implemented to run parallel programs easily and efficiently on networks of UNIX workstations.
Reference: [4] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cam-bridge University Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: The child procedures return values to the parent procedure by sending those values to the parent's waiting successor. Thus, a thread may wait to begin executing, but once it begins executing, it cannot suspend. This style of interaction among threads is called continuation-passing style <ref> [4] </ref>. Spawning successor and child threads is done with the spawn next and spawn keywords respectively. Sending a value to a waiting thread is done with the send argument statement. The Cilk runtime system implements these primitives using two basic data structures: closures and continuations.
Reference: [5] <author> Remzi H. Arpaci, Andrea C. Dusseau, Amin M. Vahdat, Lok T. Liu, Thomas E. Anderson, and David A. Patter-son. </author> <title> The interaction of parallel and sequential workloads on a network of workstations. </title> <booktitle> In Proceedings of the 1995 ACM SIGMETRICS Conference on the Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 267278, </pages> <month> May </month> <year> 1995. </year> <month> 13 </month>
Reference-contexts: These observations are consistent with those of others <ref> [5, 20, 27, 28, 31] </ref>. Cilk-NOW provides the following features for running Cilk programs on a network of workstations. Ease of use. A user can run a Cilk program in parallel on a NOW as if the program were only being run on the local workstation.
Reference: [6] <author> Robert D. Blumofe. </author> <title> Executing Multithreaded Programs Efficiently. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction A strong case argues for the use of networks of workstations (NOWs) as parallel-computation platforms [3], and Cilk-NOW <ref> [6] </ref> is a software system that has been designed and implemented to run parallel programs easily and efficiently on networks of UNIX workstations. <p> Implemented entirely in user-level software on top of UNIX, Cilk-NOW is a runtime system for a functional subset of the parallel Cilk language <ref> [6, 8, 26] </ref>, a mul-tithreaded extension of C. Applications written in Cilk This research was supported in part by the Advanced Research Projects Agency (ARPA) under Grants N00014-94-1-0985 and N00014-92-J-1310. Robert Blumofe was supported in part by an ARPA High-Performance Computing Graduate Fellowship. <p> Like all runtime systems for Cilk, Cilk-NOW schedules threads using a provably efficient algorithm based on the technique of random work stealing <ref> [6, 9] </ref> in which processors with no threads steal threads from victims chosen at random. With this algorithm, Cilk delivers performance that is guaranteed to be both efficient and predictable [6, 8]. In addition to thread scheduling, Cilk-NOW also performs macroscheduling [30]. <p> With this algorithm, Cilk delivers performance that is guaranteed to be both efficient and predictable <ref> [6, 8] </ref>. In addition to thread scheduling, Cilk-NOW also performs macroscheduling [30]. That is, Cilk-NOW automatically identifies idle workstations and assigns those idle workstations to help out with running Cilk programs. The Cilk-NOW runtime system is designed to execute Cilk programs efficiently in the highly dynamic environment of a NOW. <p> The user simply types the program's command line, and then the Cilk-NOW runtime system automatically schedules the execu tion of the program in parallel across the network. Adaptive parallelism. The Cilk-NOW system adaptively executes Cilk programs on a dynamically changing set of otherwise-idle workstations <ref> [6, 10] </ref>. When a given workstation is not being used by its owner, the workstation automatically joins in and helps out with the execution of a Cilk program. When the owner returns to work, the machine au tomatically retreats from the Cilk program. Fault tolerance. <p> When the owner returns to work, the machine au tomatically retreats from the Cilk program. Fault tolerance. The Cilk-NOW runtime system automatically performs checkpointing, detects failures, and performs recovery <ref> [6] </ref> while Cilk programs themselves remain fault oblivious. That is, Cilk-NOW provides fault tolerance without requiring that programmers code for fault tolerance. Flexibility. <p> The desired degree of security is that which a given system uses to authenticate its remote execution protocol. Guaranteed performance. The Cilk-NOW system executes Cilk programs using a work-stealing sched-uler. This scheduler delivers performance that can be predicted accurately with a simple abstract model <ref> [6, 8] </ref>. Moreover this simple model can be adapted to the case of heterogeneous processors and networks [32]. Recently, we ran a Cilk protein-folding application pfold [37] using Cilk-NOW on a network of about 50 Sun SPARCstations connected by shared 10-Mb/s Ethernet to solve a large-scale protein-folding problem. <p> The Cilk-2 language, work-stealing scheduler, MPP implementation, and guaranteed performance model have been covered at length in other papers <ref> [6, 8, 9, 26] </ref>. In this paper, we shall focus on adaptive parallelism and fault tolerance. <p> In Section 7 we compare the Cilk-NOW system to related work. Finally, in Section 8 we outline plans for future work, and we conclude. 2 The Cilk language and work stealing scheduler In this section we overview the Cilk parallel mul-tithreaded language and its runtime system's work-stealing scheduler <ref> [6, 8, 26] </ref>. For brevity, we shall not present the entire Cilk language, and we shall omit some details of the work-stealing algorithm. <p> If the victim has no ready closures, it informs the thief who then tries to steal from another random processor until a ready closure is found or program execution completes. This simple work-stealing scheduler has been shown, both analytically and empirically, to deliver efficient and predictable performance <ref> [6, 8, 9] </ref> for well structured computations. A well structured computation is one in which each procedure sends values (with send argument) only to its parent and only as the last action performed by its last thread. <p> In this section, we show how we can take advantage of Cilk's well structuring and the work-stealing scheduler to make this migration extremely simple and efficient. (Experimental results documenting the efficiency of Cilk-NOW's adaptive parallelism have been omitted for lack of space but can be found in <ref> [6] </ref>.) Our approach is to impose additional structure on the organization of closures and continuations, such that the structure is cheap to maintain while simplifying the migration of closures.
Reference: [7] <author> Robert D. Blumofe, Matteo Frigo, Christopher F. Jo-erg, Charles E. Leiserson, and Keith H. Randall. </author> <title> Dag-consistent distributed shared memory. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium (IPPS), </booktitle> <pages> pages 132141, </pages> <address> Honolulu, Hawaii, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: More recent incarnations of Cilk for MPPs and SMPs have support for a global address space using dag-consistent distributed shared memory <ref> [7] </ref>, and we are currently working on extensions for parallel I/O. With these additions to Cilk, preserving Cilk-NOW's adaptive and fault tolerant execution model remains a challenging open problem. We are currently working on this problem.
Reference: [8] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), pages 207216, </booktitle> <address> Santa Barbara, California, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Implemented entirely in user-level software on top of UNIX, Cilk-NOW is a runtime system for a functional subset of the parallel Cilk language <ref> [6, 8, 26] </ref>, a mul-tithreaded extension of C. Applications written in Cilk This research was supported in part by the Advanced Research Projects Agency (ARPA) under Grants N00014-94-1-0985 and N00014-92-J-1310. Robert Blumofe was supported in part by an ARPA High-Performance Computing Graduate Fellowship. <p> With this algorithm, Cilk delivers performance that is guaranteed to be both efficient and predictable <ref> [6, 8] </ref>. In addition to thread scheduling, Cilk-NOW also performs macroscheduling [30]. That is, Cilk-NOW automatically identifies idle workstations and assigns those idle workstations to help out with running Cilk programs. The Cilk-NOW runtime system is designed to execute Cilk programs efficiently in the highly dynamic environment of a NOW. <p> The desired degree of security is that which a given system uses to authenticate its remote execution protocol. Guaranteed performance. The Cilk-NOW system executes Cilk programs using a work-stealing sched-uler. This scheduler delivers performance that can be predicted accurately with a simple abstract model <ref> [6, 8] </ref>. Moreover this simple model can be adapted to the case of heterogeneous processors and networks [32]. Recently, we ran a Cilk protein-folding application pfold [37] using Cilk-NOW on a network of about 50 Sun SPARCstations connected by shared 10-Mb/s Ethernet to solve a large-scale protein-folding problem. <p> The Cilk-2 language, work-stealing scheduler, MPP implementation, and guaranteed performance model have been covered at length in other papers <ref> [6, 8, 9, 26] </ref>. In this paper, we shall focus on adaptive parallelism and fault tolerance. <p> The remainder of this paper is organized as follows. In Section 2 we review the Cilk-2 language and work-stealing scheduler as first introduced in <ref> [8] </ref>. In Section 3 we describe the architecture of a Cilk job executing under the Cilk-NOW runtime system. Then, in Section 4 we explain how Cilk-NOW implements adaptive parallelism, and in Section 5 we explain how Cilk-NOW performs checkpointing, fault detection, and fault recovery. <p> In Section 7 we compare the Cilk-NOW system to related work. Finally, in Section 8 we outline plans for future work, and we conclude. 2 The Cilk language and work stealing scheduler In this section we overview the Cilk parallel mul-tithreaded language and its runtime system's work-stealing scheduler <ref> [6, 8, 26] </ref>. For brevity, we shall not present the entire Cilk language, and we shall omit some details of the work-stealing algorithm. <p> If the victim has no ready closures, it informs the thief who then tries to steal from another random processor until a ready closure is found or program execution completes. This simple work-stealing scheduler has been shown, both analytically and empirically, to deliver efficient and predictable performance <ref> [6, 8, 9] </ref> for well structured computations. A well structured computation is one in which each procedure sends values (with send argument) only to its parent and only as the last action performed by its last thread.
Reference: [9] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling multithreaded computations by work stealing. </title> <booktitle> In Proceedings of the 35th Annual Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 356368, </pages> <address> Santa Fe, New Mexico, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Like all runtime systems for Cilk, Cilk-NOW schedules threads using a provably efficient algorithm based on the technique of random work stealing <ref> [6, 9] </ref> in which processors with no threads steal threads from victims chosen at random. With this algorithm, Cilk delivers performance that is guaranteed to be both efficient and predictable [6, 8]. In addition to thread scheduling, Cilk-NOW also performs macroscheduling [30]. <p> The Cilk-2 language, work-stealing scheduler, MPP implementation, and guaranteed performance model have been covered at length in other papers <ref> [6, 8, 9, 26] </ref>. In this paper, we shall focus on adaptive parallelism and fault tolerance. <p> If the victim has no ready closures, it informs the thief who then tries to steal from another random processor until a ready closure is found or program execution completes. This simple work-stealing scheduler has been shown, both analytically and empirically, to deliver efficient and predictable performance <ref> [6, 8, 9] </ref> for well structured computations. A well structured computation is one in which each procedure sends values (with send argument) only to its parent and only as the last action performed by its last thread.
Reference: [10] <author> Robert D. Blumofe and David S. Park. </author> <title> Scheduling large-scale parallel computations on networks of workstations. </title> <booktitle> In Proceedings of the Third International Symposium on High Performance Distributed Computing (HPDC), </booktitle> <pages> pages 96105, </pages> <address> San Francisco, California, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The user simply types the program's command line, and then the Cilk-NOW runtime system automatically schedules the execu tion of the program in parallel across the network. Adaptive parallelism. The Cilk-NOW system adaptively executes Cilk programs on a dynamically changing set of otherwise-idle workstations <ref> [6, 10] </ref>. When a given workstation is not being used by its owner, the workstation automatically joins in and helps out with the execution of a Cilk program. When the owner returns to work, the machine au tomatically retreats from the Cilk program. Fault tolerance.
Reference: [11] <author> Clemens H. Cap and Volker Strumpen. </author> <title> Efficient parallel computing in distributed workstation environments. </title> <booktitle> Parallel Computing, </booktitle> <address> 19:12211234, </address> <year> 1993. </year>
Reference-contexts: Traditionally, systems such as PVM [41], Tread-Marks [2], and others <ref> [11, 16, 23, 29] </ref> that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [12] <author> Nicholas Carriero and David Gelernter. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4):444458, </volume> <month> April </month> <year> 1989. </year>
Reference-contexts: Possibly the first adaptively parallel system is the Benevolent Bandit Laboratory (BBL) [22], and Cilk-NOW borrows some of its overall system architecture from BBL. The Pi ranha system [24, 27], which is based on the Linda programming model <ref> [12] </ref>, is also adaptively parallel. (In fact, the authors of Piranha appear to have coined the term adaptively parallel.) These systems support programming models that are quite different from Cilk's, but as with the Cilk-NOW design, both leverage properties of their programming model in order to implement adaptive parallelism.
Reference: [13] <author> Vint Cerf and Robert Kahn. </author> <title> A protocol for packet network intercommunication. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 22(5):637648, </volume> <month> May </month> <year> 1974. </year>
Reference-contexts: In later update messages, the clearinghouse informs the other workers of the crash, and the other workers take appropriate remedial action as described in Section 5. All communication between workers, and between workers and the clearinghouse, is implemented with UDP/IP <ref> [13, 40] </ref>. Knowing that UDP datagrams are unreliable, the Cilk-NOW protocols incorporate appropriate mechanisms, such as acknowledgments, retries, and timeouts, to ensure correct operation when messages get lost.
Reference: [14] <author> Rohit Chandra, Anoop Gupta, and John L. Hennessy. </author> <title> COOL: An object-based language for parallel programming. </title> <journal> IEEE Computer, </journal> <volume> 27(8):1326, </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: A runtime system for the programming language COOL <ref> [14] </ref> running on symmetric multiprocessors [44] and cache-coherent, distributed, shared-memory machines uses process control to support adaptive parallelism. This system relies on special-purpose operating system and hardware support. In contrast, Cilk-NOW supports adaptive parallelism entirely in user-level software on top of commercial hardware and operating systems.
Reference: [15] <author> John Chapin, Mendel Rosenblum, Scott Devine, Tirthankar Lahiri, Dan Teodosiu, and Anoop Gupta. Hive: </author> <title> Fault containment for shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <pages> pages 1225, </pages> <address> Copper Mountain Resort, Colorado, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Unlike Cilk-NOW, none of these systems are fault tolerant. A growing number of systems do provide fault tolerance, but unlike Cilk-NOW, none provide application fault tolerance in a high-level parallel programming environment. The Hive <ref> [15] </ref> distributed operating system provides system fault tolerance, meaning that a fault in one component does not bring down the entire system.
Reference: [16] <author> Jeffrey S. Chase, Franz G. Amador, Edward D. Lazowska, Henry M. Levy, and Richard J. Littlefield. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Operating Systems Principles (SOSP 12), </booktitle> <pages> pages 147 158, </pages> <address> Litchfield Park, Arizona, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: Traditionally, systems such as PVM [41], Tread-Marks [2], and others <ref> [11, 16, 23, 29] </ref> that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [17] <author> David R. Cheriton. </author> <title> The V distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 31(3):314333, </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems <ref> [17, 36, 43, 46] </ref> and remote execution facilities [18, 19, 31, 35, 47] provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [18] <author> Henry Clark and Bruce McMillin. </author> <title> DAWGSa distributed compute server utilizing idle workstations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14(2):175 186, </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities <ref> [18, 19, 31, 35, 47] </ref> provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [19] <author> P. Dasgupta, R. C. Chen, S. Menon, M. P. Pearson, R. Ananthanarayanan, U. Ramachandran, M. Ahamad, R. J. LeBlanc, W. F. Appelbe, J. M. Bernabeu-Auban, P. W. Hutto, M. Y. A. Khalidi, and C. J. Wilkenloh. </author> <title> The design and implementation of the Clouds distributed operating system. </title> <booktitle> Computing Systems, </booktitle> <address> 3(1):1146, </address> <year> 1990. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities <ref> [18, 19, 31, 35, 47] </ref> provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [20] <author> Fred Douglis and John Ousterhout. </author> <title> Transparent process migration: Design alternatives and the sprite implementation. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 21(8):757785, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: These observations are consistent with those of others <ref> [5, 20, 27, 28, 31] </ref>. Cilk-NOW provides the following features for running Cilk programs on a network of workstations. Ease of use. A user can run a Cilk program in parallel on a NOW as if the program were only being run on the local workstation.
Reference: [21] <author> Elmootazbellah N. Elnozahy and Willy Zwaenepoel. Manetho: </author> <title> Transparent rollback-recovery with low overhead, limited rollback and fast output commit. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-41(5):526531, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Hive does not, however, provide application fault tolerance, meaning that with Hive, if an application is using a failed component, then the entire application crashes (unless the application itself has taken care to be fault tolerant). Application fault tolerance is provided by the Manetho system <ref> [21] </ref> via the technique of message logging. The Sam system [39] uses message logging to implement a fault tolerant distributed shared memory. The Sam implementation leverages properties of its shared-memory consistency model in order to avoid logging certain messages.
Reference: [22] <author> Robert E. Felderman, Eve M. Schooler, and Leonard Kleinrock. </author> <title> The Benevolent Bandit Laboratory: A testbed for distributed algorithms. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(2):303311, </volume> <month> February </month> <year> 1989. </year>
Reference-contexts: A small number of parallel programming and runtime systems have been built that are adaptively parallel, but unlike Cilk-NOW, none are fault tolerant. Possibly the first adaptively parallel system is the Benevolent Bandit Laboratory (BBL) <ref> [22] </ref>, and Cilk-NOW borrows some of its overall system architecture from BBL.
Reference: [23] <author> Vincent W. Freeh, David K. Lowenthal, and Gregory R. Andrews. </author> <title> Distributed Filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, pages 201213, </booktitle> <address> Monterey, California, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Traditionally, systems such as PVM [41], Tread-Marks [2], and others <ref> [11, 16, 23, 29] </ref> that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [24] <author> David Gelernter and David Kaminsky. </author> <title> Supercomputing out of recycled garbage: Preliminary experience with Piranha. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <pages> pages 417427, </pages> <address> Wash-ington, D.C., </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Possibly the first adaptively parallel system is the Benevolent Bandit Laboratory (BBL) [22], and Cilk-NOW borrows some of its overall system architecture from BBL. The Pi ranha system <ref> [24, 27] </ref>, which is based on the Linda programming model [12], is also adaptively parallel. (In fact, the authors of Piranha appear to have coined the term adaptively parallel.) These systems support programming models that are quite different from Cilk's, but as with the Cilk-NOW design, both leverage properties of their
Reference: [25] <author> Chris Joerg and Bradley C. Kuszmaul. </author> <title> Massively parallel chess. </title> <booktitle> In Proceedings of the Third DIMACS Parallel Implementation Challenge, </booktitle> <institution> Rutgers University, </institution> <address> New Jersey, </address> <month> October </month> <year> 1994. </year> <note> Available as ftp://theory.lcs.mit.edu/ pub/cilk/dimacs94.ps.Z. </note>
Reference-contexts: Robert Blumofe was supported in part by an ARPA High-Performance Computing Graduate Fellowship. This paper appears in the Proceedings of the USENIX 1997 Annual Technical Symposium, Anaheim, California, January 610, 1997. include graphics rendering, backtrack search, protein folding [37], and the ?Socrates chess program <ref> [25] </ref> which won second prize at the 1995 ICCA World Computer Chess Championship running on the 1824-node In-tel Paragon at Sandia National Labs.
Reference: [26] <author> Christopher F. Joerg. </author> <title> The Cilk System for Parallel Mul-tithreaded Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: Implemented entirely in user-level software on top of UNIX, Cilk-NOW is a runtime system for a functional subset of the parallel Cilk language <ref> [6, 8, 26] </ref>, a mul-tithreaded extension of C. Applications written in Cilk This research was supported in part by the Advanced Research Projects Agency (ARPA) under Grants N00014-94-1-0985 and N00014-92-J-1310. Robert Blumofe was supported in part by an ARPA High-Performance Computing Graduate Fellowship. <p> The Cilk-2 language, work-stealing scheduler, MPP implementation, and guaranteed performance model have been covered at length in other papers <ref> [6, 8, 9, 26] </ref>. In this paper, we shall focus on adaptive parallelism and fault tolerance. <p> In Section 7 we compare the Cilk-NOW system to related work. Finally, in Section 8 we outline plans for future work, and we conclude. 2 The Cilk language and work stealing scheduler In this section we overview the Cilk parallel mul-tithreaded language and its runtime system's work-stealing scheduler <ref> [6, 8, 26] </ref>. For brevity, we shall not present the entire Cilk language, and we shall omit some details of the work-stealing algorithm.
Reference: [27] <author> David Louis Kaminsky. </author> <title> Adaptive Parallelism with Piranha. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: These observations are consistent with those of others <ref> [5, 20, 27, 28, 31] </ref>. Cilk-NOW provides the following features for running Cilk programs on a network of workstations. Ease of use. A user can run a Cilk program in parallel on a NOW as if the program were only being run on the local workstation. <p> Possibly the first adaptively parallel system is the Benevolent Bandit Laboratory (BBL) [22], and Cilk-NOW borrows some of its overall system architecture from BBL. The Pi ranha system <ref> [24, 27] </ref>, which is based on the Linda programming model [12], is also adaptively parallel. (In fact, the authors of Piranha appear to have coined the term adaptively parallel.) These systems support programming models that are quite different from Cilk's, but as with the Cilk-NOW design, both leverage properties of their
Reference: [28] <author> Phillip Krueger and Rohit Chawla. </author> <title> The Stealth distributed scheduler. </title> <booktitle> In Proceedings of the 11th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 336 343, </pages> <address> Arlington, Texas, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: These observations are consistent with those of others <ref> [5, 20, 27, 28, 31] </ref>. Cilk-NOW provides the following features for running Cilk programs on a network of workstations. Ease of use. A user can run a Cilk program in parallel on a NOW as if the program were only being run on the local workstation.
Reference: [29] <author> Kai Li. IVY: </author> <title> A shared virtual memory system for parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 94101, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Traditionally, systems such as PVM [41], Tread-Marks [2], and others <ref> [11, 16, 23, 29] </ref> that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [30] <author> Philip Andrew Lisiecki. </author> <title> Macro-level scheduling in the Cilk network of workstations environment. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: With this algorithm, Cilk delivers performance that is guaranteed to be both efficient and predictable [6, 8]. In addition to thread scheduling, Cilk-NOW also performs macroscheduling <ref> [30] </ref>. That is, Cilk-NOW automatically identifies idle workstations and assigns those idle workstations to help out with running Cilk programs. The Cilk-NOW runtime system is designed to execute Cilk programs efficiently in the highly dynamic environment of a NOW. <p> After recovering the root subcomputa-tion, then every other subcomputation can be recovered by recursively recovering the thief subcomputation for each of the root subcomputation's assigned closures. 6 Cilk-NOW macroscheduling The Cilk-NOW runtime system contains components that perform macroscheduling <ref> [30] </ref>. The macroscheduler identifies idle machines and determines which machines work on which jobs. In this section, we discuss each component of the macroscheduler, and we show how 2 We have not yet implemented any sort of distributed file system. <p> Furthermore, it is desirable for the macroscheduler's protocols to be secure against unauthorized messages. For these reasons, all of the macroscheduler's protocols are secured with an abstraction on top of UDP called secure active messages <ref> [30] </ref>. This abstraction maintains all of the semantics of the split-phase protocols mentioned earlier but adds a guarantee of the authenticity of messages to the receiver. Unlike a normal UDP message which is sent from one network address to another, a secure active message is sent between principals. <p> The switching decision is randomized and based only on information about the parallelism and size of the two jobs involved. Early simulation results indicate that such a scheme is very effective <ref> [30] </ref>, and we are currently working on analysis and implementation. More information about Cilk, including papers, documentation, and software releases, but not including Cilk-NOW software, can be found on the World-Wide Web at http://theory.lcs.mit.edu/cilk. Acknowledgments We wish to thank the entire Cilk project team at MIT.
Reference: [31] <author> Michael J. Litzkow, Miron Livny, and Matt W. </author> <title> Mutka. Condora hunter of idle workstations. </title> <booktitle> In Proceedings of the 8th International Conference on Distributed Comput 14 ing Systems, </booktitle> <pages> pages 104111, </pages> <address> San Jose, California, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: These observations are consistent with those of others <ref> [5, 20, 27, 28, 31] </ref>. Cilk-NOW provides the following features for running Cilk programs on a network of workstations. Ease of use. A user can run a Cilk program in parallel on a NOW as if the program were only being run on the local workstation. <p> Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities <ref> [18, 19, 31, 35, 47] </ref> provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [32] <author> Howard J. Lu. </author> <title> Heterogeneous multithreaded computing. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Guaranteed performance. The Cilk-NOW system executes Cilk programs using a work-stealing sched-uler. This scheduler delivers performance that can be predicted accurately with a simple abstract model [6, 8]. Moreover this simple model can be adapted to the case of heterogeneous processors and networks <ref> [32] </ref>. Recently, we ran a Cilk protein-folding application pfold [37] using Cilk-NOW on a network of about 50 Sun SPARCstations connected by shared 10-Mb/s Ethernet to solve a large-scale protein-folding problem.
Reference: [33] <author> Robert C. Miller. </author> <title> A type-checking preprocessor for Cilk 2, a multithreaded C language. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: The Cilk runtime system manipulates and schedules the threads. The runtime system is not aware of the grouping of threads into procedures. Cilk procedures are purely an abstraction supported by the cilk2c type-checking preprocessor <ref> [33] </ref>. Consider a program that uses double recursion to compute the Fibonacci function.
Reference: [34] <author> Steven P. Miller, B. Clifford Neuman, Jeffrey I. Schiller, and Jermoe H. Saltzer. </author> <title> Kerberos authentication and authorization system. </title> <type> Athena technical plan, </type> <institution> M.I.T. Project Athena, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: Each secure active message contains user data, the sending principal, and whatever additional data might be required by the underlying authentication protocol, whether that be the standard UNIX rsh protocol or a protocol like Kerberos <ref> [34] </ref>. The security layer is very simplistic, providing only enough functionality to allow the protocols to be secured in a manner independent of the authentication protocol.
Reference: [35] <author> David A. Nichols. </author> <title> Using idle workstations in a shared computing environment. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles (SOSP 11), </booktitle> <pages> pages 512, </pages> <address> Austin, Texas, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities <ref> [18, 19, 31, 35, 47] </ref> provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [36] <author> John K. Ousterhout, Andrew R. Cherenson, Freder-ick Douglis, Michael N. Nelson, and Brent B. Welch. </author> <title> The Sprite network operating system. </title> <journal> IEEE Computer, </journal> <volume> 21(2):2336, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems <ref> [17, 36, 43, 46] </ref> and remote execution facilities [18, 19, 31, 35, 47] provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [37] <author> Vijay S. Pande, Christopher F. Joerg, Alexander Yu Gros-berg, and Toyoichi Tanaka. </author> <title> Enumerations of the hamil-tonian walks on a cubic sublattice. </title> <journal> Journal of Physics A, </journal> <volume> 27, </volume> <year> 1994. </year>
Reference-contexts: Robert Blumofe was supported in part by an ARPA High-Performance Computing Graduate Fellowship. This paper appears in the Proceedings of the USENIX 1997 Annual Technical Symposium, Anaheim, California, January 610, 1997. include graphics rendering, backtrack search, protein folding <ref> [37] </ref>, and the ?Socrates chess program [25] which won second prize at the 1995 ICCA World Computer Chess Championship running on the 1824-node In-tel Paragon at Sandia National Labs. <p> This scheduler delivers performance that can be predicted accurately with a simple abstract model [6, 8]. Moreover this simple model can be adapted to the case of heterogeneous processors and networks [32]. Recently, we ran a Cilk protein-folding application pfold <ref> [37] </ref> using Cilk-NOW on a network of about 50 Sun SPARCstations connected by shared 10-Mb/s Ethernet to solve a large-scale protein-folding problem.
Reference: [38] <author> J. H. Saltzer, D. P. Reed, and D. D. Clark. </author> <title> End-to-end arguments in system design. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(4):277288, </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: The Cilk-2 language, work-stealing scheduler, MPP implementation, and guaranteed performance model have been covered at length in other papers [6, 8, 9, 26]. In this paper, we shall focus on adaptive parallelism and fault tolerance. Specifically, we will show how Cilk-NOW's end-to-end design <ref> [38] </ref> leverages algorithmic properties of the Cilk programming model and work-stealing scheduler in order to amortize all the overhead of adaptive parallelism and fault tolerance against the analytically and empirically bounded overhead of Cilk's work-stealing scheduler. The remainder of this paper is organized as follows. <p> We chose to build Cilk-NOW's communication protocols using an unreliable message-passing layer instead of a reliable one for two reasons, both based on end-to-end design arguments <ref> [38] </ref>. First, reliable layers such as TCP/IP [40] and PVM [41] perform implicit acknowledgments and retries to achieve reliability. Therefore, such layers either preclude the use of asynchronous communication or require extra buffering and copying. <p> In contrast, Cilk-NOW does provide support for parallel programs and it does provide adaptive parallelism and fault tolerance, but it does so only for the Cilk parallel programming model. Such specificity allows the Cilk-NOW design to take an end-to-end approach <ref> [38] </ref> that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities [18, 19, 31, 35, 47] provide services such as remote process execution and, in some cases, process migration.
Reference: [39] <author> Daniel J. Scales and Monica S. Lam. </author> <title> Transparent fault tolerance for parallel applications on networks of workstations. </title> <booktitle> In Proceedings of the USENIX 1996 Annual Winter Technical Conference, </booktitle> <address> San Diego, California, </address> <month> Jan-uary </month> <year> 1996. </year>
Reference-contexts: Application fault tolerance is provided by the Manetho system [21] via the technique of message logging. The Sam system <ref> [39] </ref> uses message logging to implement a fault tolerant distributed shared memory. The Sam implementation leverages properties of its shared-memory consistency model in order to avoid logging certain messages.
Reference: [40] <author> W. Richard Stevens. </author> <title> UNIX Network Programming. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1990. </year>
Reference-contexts: In later update messages, the clearinghouse informs the other workers of the crash, and the other workers take appropriate remedial action as described in Section 5. All communication between workers, and between workers and the clearinghouse, is implemented with UDP/IP <ref> [13, 40] </ref>. Knowing that UDP datagrams are unreliable, the Cilk-NOW protocols incorporate appropriate mechanisms, such as acknowledgments, retries, and timeouts, to ensure correct operation when messages get lost. <p> We chose to build Cilk-NOW's communication protocols using an unreliable message-passing layer instead of a reliable one for two reasons, both based on end-to-end design arguments [38]. First, reliable layers such as TCP/IP <ref> [40] </ref> and PVM [41] perform implicit acknowledgments and retries to achieve reliability. Therefore, such layers either preclude the use of asynchronous communication or require extra buffering and copying.
Reference: [41] <author> V. S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4):315339, </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: We chose to build Cilk-NOW's communication protocols using an unreliable message-passing layer instead of a reliable one for two reasons, both based on end-to-end design arguments [38]. First, reliable layers such as TCP/IP [40] and PVM <ref> [41] </ref> perform implicit acknowledgments and retries to achieve reliability. Therefore, such layers either preclude the use of asynchronous communication or require extra buffering and copying. A layer such as UDP which provides minimal service guarantees can be implemented with considerably less software overhead than a layer with more service features. <p> Each job should get its fair share of the idle machines, but no job should get more machines than it can efficiently utilize. 7 Related work Cilk-NOW is unique in delivering adaptive and reliable execution for parallel programs on networks of workstations. Traditionally, systems such as PVM <ref> [41] </ref>, Tread-Marks [2], and others [11, 16, 23, 29] that are designed to support parallel programs on networks of workstations have not provided adaptive parallelism or fault tolerance. On the other hand, most systems that do provide support for adaptive execution or fault tolerance take a process-centric approach.
Reference: [42] <author> Andrew S. Tanenbaum, Henri E. Bal, and M. Frans Kaashoek. </author> <title> Programming a distributed system using shared objects. </title> <booktitle> In Proceedings of the Second International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 512, </pages> <address> Spokane, Washington, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems. In fact, Orca <ref> [42] </ref>, which has been built on top of Amoeba, is such a system. These systems are process-centric in that they adapt only by remotely executing and/or migrating processes.
Reference: [43] <author> Andrew S. Tanenbaum, Robbert van Renesse, Hans van Staveren, Gregory J. Sharp, Sape J. Mullender, Jack Jansen, and Guido van Rossum. </author> <title> Experiences with the Amoeba distributed operating system. </title> <journal> Communications of the ACM, </journal> <volume> 33(12):4663, </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems <ref> [17, 36, 43, 46] </ref> and remote execution facilities [18, 19, 31, 35, 47] provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [44] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process control and scheduling issues for multiprogrammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Operating Systems Principles (SOSP 12), </booktitle> <pages> pages 159166, </pages> <address> Litchfield Park, Arizona, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: A runtime system for the programming language COOL [14] running on symmetric multiprocessors <ref> [44] </ref> and cache-coherent, distributed, shared-memory machines uses process control to support adaptive parallelism. This system relies on special-purpose operating system and hardware support. In contrast, Cilk-NOW supports adaptive parallelism entirely in user-level software on top of commercial hardware and operating systems.
Reference: [45] <author> Carl A. Waldspurger, Tad Hogg, Bernardo A. Huberman, Jeffrey O. Kephart, and W. Scott Stornetta. Spawn: </author> <title> A distributed computational economy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2):103117, </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: This system relies on special-purpose operating system and hardware support. In contrast, Cilk-NOW supports adaptive parallelism entirely in user-level software on top of commercial hardware and operating systems. The Spawn system <ref> [45] </ref> supports concurrent applications with dynamic and adaptive resource management policies based on microeconomic principles. Unlike Cilk-NOW, none of these systems are fault tolerant. A growing number of systems do provide fault tolerance, but unlike Cilk-NOW, none provide application fault tolerance in a high-level parallel programming environment.
Reference: [46] <author> Bruce Walker, Gerald Popek, Robert English, Charles Kline, and Greg Thiel. </author> <title> The LOCUS distributed operating system. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <pages> pages 4970, </pages> <address> Bretton Woods, New Hampshire, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems <ref> [17, 36, 43, 46] </ref> and remote execution facilities [18, 19, 31, 35, 47] provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
Reference: [47] <author> Songnian Zhou, Jingwen Wang, Xiaohu Zheng, and Pierre Delisle. </author> <title> Utopia: A load sharing facility for large, heterogeneous distributed computer systems. </title> <journal> Software Practice and Experience, </journal> <volume> 23(12):13051336, </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: Such specificity allows the Cilk-NOW design to take an end-to-end approach [38] that leverages properties of the Cilk programming model in order to implement adaptive parallelism and fault tolerance simply and efficiently. Distributed operating systems [17, 36, 43, 46] and remote execution facilities <ref> [18, 19, 31, 35, 47] </ref> provide services such as remote process execution and, in some cases, process migration. These systems are not intended to be parallel programming environments, though presumably a parallel programming environment could by built atop one of these systems.
References-found: 47

