URL: http://euler.mcs.utulsa.edu/~sandip/representation.ps
Refering-URL: http://euler.mcs.utulsa.edu/~sandip/GAGP.html
Root-URL: 
Email: e-mail: sandip@kolkata.mcs.utulsa.edu  
Title: A tale of two representations  
Author: Sandip Sen 
Address: 600 South College Avenue, Tulsa, OK 74104-3189, USA  
Affiliation: Department of Mathematical Computer Sciences University of Tulsa  
Abstract: Attribute based concept learning has been an active area of machine learning research over the past decade. A number of proposed concept learners are rule-based systems, whose efficiency depends largely on the representation of the rules. We analyze two attribute-value rule representations for the compactness of concept definition. A spectrum of concepts, with different numbers of conjuncts and disjuncts in their definition, is used to evaluate the effectiveness of the chosen representations. Our analysis shows that neither of the representations is dominant over the other, and it is beneficial to switch representations with varying concept complexity. Experimental verification of the predicted tradeoff is provided. The relatively novel of the two representations is found to be better, in general, at concisely representing concepts than the more commonly used representation. We present a formula to choose between these representations, which uses an estimate of the complexity of the concept to be learnt. 
Abstract-found: 1
Intro-found: 1
Reference: [Boo91] <editor> Lashon B. Booker. </editor> <title> Representing attribute-based concepts in a classifier system. </title> <editor> In Gregory J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 115-127, </pages> <year> 1991. </year>
Reference-contexts: We summarize our findings at the end of the paper (Section 8). Our research is complimentary to the work of Booker <ref> [Boo91] </ref>, Schuurmans and Schaeffer [SS89] and others, who are more concerned about the representational adequacy of the commonly used classifier language.
Reference: [BP91] <author> Pierre Bonelli and Alexander Parodi. </author> <title> An efficient classifier system and its experimental comparison with two representative learning methods on three medical domains. </title> <booktitle> In Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <pages> pages 288-295, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Mor-gan Kaufman. </publisher>
Reference-contexts: It is an improvement over the BOOLE [Wil87] system, and has been used successfully in a number of supervised classification problem domains <ref> [BP91, Sen93] </ref>. NEWBOOLE uses a population of classifiers (equivalent to bit-level zero order rules) which are evolved using genetic operators modeled after Darwinian principles. The rule representations used in this paper are as described previously.
Reference: [BPSW90] <author> Pierre Bonelli, Alexander Parodi, Sandip Sen, and Stewart W. Wilson. </author> <title> Newboole: A fast gbml system. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 153-159, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: We used speed of learning as a secondary metric to choose between the representations, when they fared equally well on the primary metric. In the following we present a brief description of NEWBOOLE, and then present our experimental results. 5 NEWBOOLE NEWBOOLE <ref> [BPSW90] </ref> is a simple stimulus-response classifier system in which receiving an input from the environment and reacting to it takes place in a single time step. It is an improvement over the BOOLE [Wil87] system, and has been used successfully in a number of supervised classification problem domains [BP91, Sen93].
Reference: [DS91] <author> Kenneth A. DeJong and William M. Spears. </author> <title> Learning concept classification rules using genetic algorithms. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 651-656, </pages> <year> 1991. </year>
Reference-contexts: We first noticed it in the work of De Jong and Spears <ref> [DS91] </ref>, where they called it a fixed-length representation. We have chosen to adopt another name because the rules in the other representation being discussed are also fixed length rules. As above, each rule is represented by a condition and a classification part, separated by the ":" symbol. <p> The idea of this problem set is largely borrowed from the work of De Jong and Spears <ref> [DS91] </ref>, but the exact concepts may or may not be different from theirs (they do not specify the exact concepts used). We chose a 4-attribute classification domain with each problem instance labeled as one of two possible classes (0 or 1).
Reference: [Gol89] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization & Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The discovery component uses a genetic algorithm <ref> [Gol89] </ref> to generate more useful classifiers over time. The parameter represents the number of offsprings produced per generation using the genetic algorithm.
Reference: [Hol86] <author> John H. Holland. </author> <title> Escaping brittleness: the possibilities of general-purpose learning algorithms applied to parallel rule-based systems. In R.S. </title> <editor> Michalski, J.G. Car-bonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, an artificial intelligence approach: Volume II. </booktitle> <publisher> Morgan Kaufman, </publisher> <address> Los Alamos, CA, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction Supervised concept learning from preclassified examples involves taking a set of input instances and trying to inductively infer the target concept. Approaches to solving classification problems are varied, including symbolic [Qui86], neural [RHW86], evolutionary <ref> [Hol86] </ref>, etc. A large number of automated classification approaches use pattern matching rules to represent the target concept. In these systems, the accuracy and speed of learning depends largely on the appropriateness of the representation chosen to describe rules and instances.
Reference: [MA92] <author> P.M. Murphy and D.W. Aha. </author> <title> Uci repository of machine learning databases [machine-readable data repository], </title> <year> 1992. </year>
Reference-contexts: In these systems, the accuracy and speed of learning depends largely on the appropriateness of the representation chosen to describe rules and instances. Since classification problems abound in real world practical applications including business, industry, scientific, and engineering domains <ref> [MA92] </ref>, analysis and development of representation schemes that allow for more accurate rule learning with relatively few training examples will have a significant commercial impact. fl With due apology to Charles Dickens.
Reference: [Qui86] <author> Ross J. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Supervised concept learning from preclassified examples involves taking a set of input instances and trying to inductively infer the target concept. Approaches to solving classification problems are varied, including symbolic <ref> [Qui86] </ref>, neural [RHW86], evolutionary [Hol86], etc. A large number of automated classification approaches use pattern matching rules to represent the target concept. In these systems, the accuracy and speed of learning depends largely on the appropriateness of the representation chosen to describe rules and instances.
Reference: [RHW86] <author> D.E. Rumelhart, G.E. Hinton, and R.J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D.E. Rumel-hart and J.L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction Supervised concept learning from preclassified examples involves taking a set of input instances and trying to inductively infer the target concept. Approaches to solving classification problems are varied, including symbolic [Qui86], neural <ref> [RHW86] </ref>, evolutionary [Hol86], etc. A large number of automated classification approaches use pattern matching rules to represent the target concept. In these systems, the accuracy and speed of learning depends largely on the appropriateness of the representation chosen to describe rules and instances.
Reference: [Sen93] <author> Sandip Sen. </author> <title> Improving classification accuracy through performance history. </title> <booktitle> In Proc. 5th Intl Conf on Genetic Algorithms, </booktitle> <year> 1993. </year>
Reference-contexts: It is an improvement over the BOOLE [Wil87] system, and has been used successfully in a number of supervised classification problem domains <ref> [BP91, Sen93] </ref>. NEWBOOLE uses a population of classifiers (equivalent to bit-level zero order rules) which are evolved using genetic operators modeled after Darwinian principles. The rule representations used in this paper are as described previously.
Reference: [SS89] <author> D. Schuurmans and J. Schaeffer. </author> <title> Representational difficulties with classifier systems. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 328-333, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: We summarize our findings at the end of the paper (Section 8). Our research is complimentary to the work of Booker [Boo91], Schuurmans and Schaeffer <ref> [SS89] </ref> and others, who are more concerned about the representational adequacy of the commonly used classifier language.

References-found: 11

