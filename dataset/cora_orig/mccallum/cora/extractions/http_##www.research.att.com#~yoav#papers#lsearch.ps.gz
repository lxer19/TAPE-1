URL: http://www.research.att.com/~yoav/papers/lsearch.ps.gz
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Email: yoav@research.att.com  
Title: Self bounding learning algorithms  
Author: Yoav Freund 
Address: 180 Park Avenue Florham Park, NJ 07932-0971 USA  
Affiliation: AT&T Labs  
Abstract: Most of the work which attempts to give bounds on the generalization error of the hypothesis generated by a learning algorithm is based on methods from the theory of uniform convergence. These bounds are a-priori bounds that hold for any distribution of examples and are calculated before any data is observed. In this paper we propose a different approach for bounding the generalization error after the data has been observed. A self-bounding learning algorithm is an algorithm which, in addition to the hypothesis that it outputs, outputs a reliable upper bound on the generalization error of this hypothesis. We first explore the idea in the statistical query learning framework of Kearns [10]. After that we give an explicit self bounding algorithm for learning algorithms that are based on local search.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Javed A. Aslam and Scott E. Decatur. </author> <title> On the sample complexity of noise-tolerant learning. </title> <journal> Information Processing Letters, </journal> <volume> 57(4) </volume> <pages> 189-195, </pages> <month> 26 February </month> <year> 1996. </year>
Reference-contexts: The oracle serves as an intermediary between the SQ learning algorithm and the 1 Our definition is essentially identical to the standard simulation of a PAC learning algorithm using an SQ algorithm as described in Kearns [10] and Aslam and Decatur <ref> [1] </ref>. However, as our emphasis here is on a different set of questions, we find it better to establish a slightly different terminology. training data. In order to be precise, we define the following setup. <p> The notation NEXT (A; s; a) represents the state which A reaches following s if the answer for the query (s) it issues in state s is a 2 <ref> [0; 1] </ref>. Theorem 1 Let A be an ESQ learning algorithm that re ceives a training sample S and outputs a final hypothesis h fl . Assume that S consists of m examples, drawn independently at random from the distribution D over X fi f0; 1g.
Reference: [2] <author> Gyora M. Benedek and Alon Itai. </author> <title> Learnability with respect to fixed distributions. </title> <journal> Theoretical Computer Science, </journal> <volume> 86(2) </volume> <pages> 377-389, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Other research that considers a-posteriori bounds include Shawe-Taylor and Williamson [16] and McAllester [12]. These analysis use as a starting point a prior distribution over the concept space. Learning for specific distributions has been studied quite extensively, for examples see Benedeck and Itai <ref> [2] </ref> and Haus-sler et. al [7]. However, these works derive bounds that depend explicitly on the input distribution. This makes them useless for problems of model selection, because the input distribution is not known and estimating it is usually a harder problem than approximating the input-output relationship.
Reference: [3] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24(6) </volume> <pages> 377-380, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Most of these bounds depend only on the complexity of the hypothesis class H. As we restrict ourselves here to finite hypotheses classes, we can use the simple application of Hoeffding's bounds [9] (see for instance Blumer et. al <ref> [3] </ref>) and get that P S~D m err (h fl ) c err (h fl ) &gt; * jHje 2m* 2 : (2) A different approach is used by Kearns in [10].
Reference: [4] <author> Leo Breiman. </author> <title> Bagging predictors. </title> <journal> Machine Learning, </journal> <volume> 24(2) </volume> <pages> 123-140, </pages> <year> 1996. </year>
Reference-contexts: For example, it seems likely that taking the majority vote over the hypotheses span of an algorithm can reduce the generalization error because it decreases the differences between the hypotheses in the span. This might provide a new way for analyzing ensemble methods such as Bagging C4.5 <ref> [4] </ref> and Randomized C4.5 [6] which can be seen as taking the majority vote over samples from the hypothesis span of C4.5. ACKNOWLEDGEMENTS Special thanks to David McAllester for inspiring discussions that led to this work. I thank Fernando Pereira and Rob Schapire for helpful comments and suggestions.
Reference: [5] <author> Leo Breiman, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <year> 1984. </year>
Reference-contexts: To see how this idea might be used consider the problem of bounding the generalization error of a decision tree generated by one of the practical learning algorithms for decision trees, such as C4.5 [13] or CART <ref> [5] </ref>. Bounds of this type can be used as part of a formally justified pruning method.
Reference: [6] <author> Thomas G. Dietterich. </author> <title> An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. </title> <type> Unpublished manuscript, </type> <year> 1998. </year>
Reference-contexts: This might provide a new way for analyzing ensemble methods such as Bagging C4.5 [4] and Randomized C4.5 <ref> [6] </ref> which can be seen as taking the majority vote over samples from the hypothesis span of C4.5. ACKNOWLEDGEMENTS Special thanks to David McAllester for inspiring discussions that led to this work. I thank Fernando Pereira and Rob Schapire for helpful comments and suggestions.
Reference: [7] <author> David Haussler, Michael Kearns, H. Sebastian Seung, and Naftali Tishby. </author> <title> Rigorous learning curve bounds from statistical mechanics. </title> <booktitle> Machine Learning, </booktitle> <address> 25:195--236, </address> <year> 1996. </year>
Reference-contexts: Other research that considers a-posteriori bounds include Shawe-Taylor and Williamson [16] and McAllester [12]. These analysis use as a starting point a prior distribution over the concept space. Learning for specific distributions has been studied quite extensively, for examples see Benedeck and Itai [2] and Haus-sler et. al <ref> [7] </ref>. However, these works derive bounds that depend explicitly on the input distribution. This makes them useless for problems of model selection, because the input distribution is not known and estimating it is usually a harder problem than approximating the input-output relationship. <p> We believe that in many real-world cases jC j t jCj for reasonably large values of . The analysis here is closely related to the distribution-specific analysis of Haussler et. al <ref> [7] </ref>. It extends their work in that it considers the bound that can be calculated when the distribution is unknown and only a sample from it is available.
Reference: [8] <author> D. Heckerman, D. Geiger, </author> <title> and D.M. Chickering. Learning bayesian networks: The combination of knowledge and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 197-243, </pages> <year> 1995. </year>
Reference-contexts: This is the family of local search algorithm. This family includes gradient-descent algorithms such as BackProp [14] and algorithms that work by iteratively altering their model, such as the work of Heckerman et. al. <ref> [8] </ref> on learning graphical models by repeated local changes. We describe a transforma tion of local-search learning algorithms into self-bounding algorithms.
Reference: [9] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> March </month> <year> 1963. </year>
Reference-contexts: Most of these bounds depend only on the complexity of the hypothesis class H. As we restrict ourselves here to finite hypotheses classes, we can use the simple application of Hoeffding's bounds <ref> [9] </ref> (see for instance Blumer et. al [3]) and get that P S~D m err (h fl ) c err (h fl ) &gt; * jHje 2m* 2 : (2) A different approach is used by Kearns in [10].
Reference: [10] <author> Michael Kearns. </author> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 392-401, </pages> <year> 1993. </year>
Reference-contexts: In the first part of the paper we explore the idea of self-bounding learning algorithms in the general context of the statistical query (SQ) learning model of Kearns <ref> [10] </ref>. We describe a general transformation of deterministic SQ learning algorithms into self-bounding algorithms. However, self bounding algorithms generated by this transformation would, in general, require exponentially more time and space than the original learning algorithm. <p> The advantage of our approach over cross validation is that the learning algorithm can use all of the training data. 2 ERROR BOUNDS FOR SQ ALGORITHMS Kearns <ref> [10] </ref> introduced the statistical query (SQ) model of learning. This model is a restriction of the PAC learning model. Most of the known concept learning algorithms can be analyzed within this framework. <p> The oracle serves as an intermediary between the SQ learning algorithm and the 1 Our definition is essentially identical to the standard simulation of a PAC learning algorithm using an SQ algorithm as described in Kearns <ref> [10] </ref> and Aslam and Decatur [1]. However, as our emphasis here is on a different set of questions, we find it better to establish a slightly different terminology. training data. In order to be precise, we define the following setup. <p> finite hypotheses classes, we can use the simple application of Hoeffding's bounds [9] (see for instance Blumer et. al [3]) and get that P S~D m err (h fl ) c err (h fl ) &gt; * jHje 2m* 2 : (2) A different approach is used by Kearns in <ref> [10] </ref>. There the assumption is made that if the answers to all the statistical queries are ff-accurate then the generalization error of the hypothesis output by the SQ learning algorithm is guaranteed to be smaller than *(ff).
Reference: [11] <author> Yishay Mansour. </author> <title> Pessimistic decision tree pruning based on tree size. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <pages> pages 195-201, </pages> <year> 1997. </year>
Reference-contexts: Bounds of this type can be used as part of a formally justified pruning method. If we base our analysis on structural risk minimization (see, for example, Mansour <ref> [11] </ref>), then we use the a-priori bound which is based on the number of all possible decision trees with a given number of nodes.
Reference: [12] <author> David A. McAllester. </author> <title> Some pac-bayesian theorems. </title> <booktitle> In Proceedings of the Eleventh Annual Conference on Computational Learning Theory, </booktitle> <year> 1998. </year>
Reference-contexts: Other research that considers a-posteriori bounds include Shawe-Taylor and Williamson [16] and McAllester <ref> [12] </ref>. These analysis use as a starting point a prior distribution over the concept space. Learning for specific distributions has been studied quite extensively, for examples see Benedeck and Itai [2] and Haus-sler et. al [7]. However, these works derive bounds that depend explicitly on the input distribution.
Reference: [13] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: To see how this idea might be used consider the problem of bounding the generalization error of a decision tree generated by one of the practical learning algorithms for decision trees, such as C4.5 <ref> [13] </ref> or CART [5]. Bounds of this type can be used as part of a formally justified pruning method.
Reference: [14] <editor> David E. Rumelhart and James L. McClelland, editors. </editor> <booktitle> Parallel Distributed Processing. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: In the second part of the paper we restrict our attention to one important subset of SQ learning algorithms. This is the family of local search algorithm. This family includes gradient-descent algorithms such as BackProp <ref> [14] </ref> and algorithms that work by iteratively altering their model, such as the work of Heckerman et. al. [8] on learning graphical models by repeated local changes. We describe a transforma tion of local-search learning algorithms into self-bounding algorithms. <p> It then replaces its hypothesis with the neighboring hypothesis that has the smallest estimated error and moves on to explore the neighbors of the new hypothesis. The popular BackProp learning algorithm for neural networks (see e.g. <ref> [14] </ref>), when run in batch mode, is a special case of this algorithm. In this case the local neighborhood is a small ball around the hypothesis in parameter space (weight space). Here we assume that the space of hypotheses is discretized.
Reference: [15] <author> John Shawe-Taylor, Peter L. Bartlett, Robert C. Williamson, and Martin Anthony. </author> <title> A framework for structural risk minimisation. </title> <booktitle> In Proceedings of the Ninth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 68-76, </pages> <year> 1996. </year>
Reference-contexts: This transformation produces a self bounding learning algorithm whose computational complexity is similar to the computational complexity of the learning algorithm on which it is based. 1.1 RELATION TO OTHER WORK A-posteriori error bounds of the type we consider here were previously considered by Shaw-Taylor et. al. <ref> [15] </ref>. In their work they expand Vapnik's SRM framework to allow for structures that depend on the training data. Their analysis yields bounds on the difference between the training error and the true error that can be quantified only after the data has been observed.
Reference: [16] <author> John Shawe-Taylor and Robert C. Williamson. </author> <title> A pac analysis of a bayesian estimator. </title> <booktitle> In Proceedings of the Tenth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 2-9, </pages> <year> 1997. </year>
Reference-contexts: The difference between this work and theirs is that our starting point is a given learning algorithm while theirs is a so-called luckiness function, which is, in the case of support vector machines, the size of the margin. Other research that considers a-posteriori bounds include Shawe-Taylor and Williamson <ref> [16] </ref> and McAllester [12]. These analysis use as a starting point a prior distribution over the concept space. Learning for specific distributions has been studied quite extensively, for examples see Benedeck and Itai [2] and Haus-sler et. al [7].
References-found: 16

