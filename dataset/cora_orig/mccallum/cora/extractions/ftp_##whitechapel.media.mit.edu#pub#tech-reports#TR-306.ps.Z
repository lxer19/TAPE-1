URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-306.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: E-mail: thad@media.mit.edu, sandy@media.mit.edu  
Title: Visual Recognition of American Sign Language Using Hidden Markov Models  
Author: Thad Starner and Alex Pentland 
Address: Room E15-383, 20 Ames Street, Cambridge MA 02139, USA  
Affiliation: The Media Laboratory, Massachusetts Institute of Technology  
Pubnum: Perceptual Computing Section,  
Abstract: Hidden Markov models (HMM's) have been used prominently and successfully in speech recognition and, more recently, in handwriting recognition. Consequently, they seem ideal for visual recognition of complex, structured hand gestures such as are found in sign language. We describe an HMM-based system for recognizing sentence level American Sign Language (ASL) which attains a word accuracy of 99.2% without explicitly modeling the fingers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation of probabilistic functions of markov processes. </title> <journal> Inequalities, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1972. </year>
Reference-contexts: However, this study shows the continuous gesture recognition capabilities of HMM's by recognizing gesture sequences. 4 Hidden Markov Modeling While a substantial body of literature exists on HMM technology <ref> [1, 7, 13, 22] </ref>, this section briefly outlines a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. <p> While the technique described only handles a single observation sequence, it is easy to extend to a set of observation sequences. A more formal discussion can be found in <ref> [1, 7, 22] </ref>. While the estimation and evaluation processes described above are sufficient for the development of an HMM system, the Viterbi algorithm provides a quick means of evaluating a set of HMM's in practice as well as providing a solution for the decoding problem.
Reference: [2] <author> C. Charayaphan and A. Marble. </author> <title> Image processing system for interpreting motion in American Sign Language. </title> <journal> Journal of Biomedical Engineering, </journal> <volume> 14 </volume> <pages> 419-425, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: However, these systems have generally concentrated on isolated signs and small training and test sets. Tamura and Kawasaki demonstrated an early image processing system which could recognize 20 Japanese signs based on matching cheremes [20]. Charayaphan and Marble <ref> [2] </ref> demonstrated a feature set that could distinguish between the 31 isolated ASL signs in their training set (which also acted as the test set).
Reference: [3] <author> B. Dorner. </author> <title> Hand shape identification and tracking for sign language interpretation. </title> <booktitle> In IJCAI Workshop on Looking at People, </booktitle> <year> 1993. </year>
Reference-contexts: To date, most work on sign language recognition has employed expensive wired "datagloves" which the user must wear [19]. In addition, these systems have mostly concentrated on finger signing, where the user spells each word with hand signs corresponding to the letters of the alphabet <ref> [3] </ref>. However, most signing does not involve finger spelling but, instead, gestures which represent whole words. This allows signed conversations to proceed at about the pace of spoken conversation. <p> used and only one mixture (Gaussian density) is being assumed, the algorithms above can proceed normally, incorporating these changes for the contin uous density case. 5 Recovering Hands from Video Previous systems have shown that, given some constraints, relatively detailed models of the hand can be recovered from video images <ref> [3, 14] </ref>. However, many of these constraints conflict with recognizing ASL in a natural context, either by requiring simple, unchanging backgrounds (unlike clothing), not allowing occlusion, requiring carefully labelled gloves, or being difficult to run in real time.
Reference: [4] <author> I. Essa, T. Darrell, and A. Pentland. </author> <title> Tracking facial motion. </title> <booktitle> IEEE Workshop on Nonrigid and articulated Motion, </booktitle> <address> Austin TX, </address> <month> Nov 94. </month>
Reference-contexts: For the purposes of this experiment, this aspect of ASL will be ignored. Furthermore, in ASL the eyebrows are raised for a question, held normal for a statement, and furrowed for a directive. While there has been work in recognizing facial gestures <ref> [4] </ref>, facial features will not be used to aid recognition in the task addressed. While the scope of this work is not to create a person independent, full lexicon system for recognizing ASL, a desired attribute of the system is extensibility towards this goal.
Reference: [5] <author> Y. He and A. Kundu. </author> <title> Planar shape classification using hidden markov models. </title> <booktitle> In Proc. 1991 IEEE Conf. on Comp. Vision and Pat. Rec., p. </booktitle> <pages> 10-15. </pages> <publisher> IEEE Press, </publisher> <year> 1991. </year>
Reference-contexts: Most early work was limited to handwriting recognition [10, 11]. More recently, He and Kundu <ref> [5] </ref> report using continuous density HMM's to classify planar shapes. Another early effort by Yamato et al. [21] uses discrete HMM's to successfully recognize image sequences of six different tennis strokes among three subjects.
Reference: [6] <author> B. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> NY, </address> <year> 1986. </year>
Reference-contexts: Z Z (y 0 ) 2 dx 0 dy 0 (x 0 and y 0 are the x and y coordinates normalized to the centroid) The axis of least inertia is then determined by the major axis of the bounding ellipse, which corresponds to the primary eigenvector of the matrix <ref> [6] </ref>. Note that this leaves a 180 degree ambiguity in the angle of the ellipses.
Reference: [7] <author> X. Huang, Y. Ariki, and M. Jack. </author> <title> Hidden Markov Models for Speech Recognition. </title> <publisher> Edin-burgh Univ. Press, Edinburgh, </publisher> <year> 1990. </year>
Reference-contexts: However, this study shows the continuous gesture recognition capabilities of HMM's by recognizing gesture sequences. 4 Hidden Markov Modeling While a substantial body of literature exists on HMM technology <ref> [1, 7, 13, 22] </ref>, this section briefly outlines a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. <p> After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. For broader discussion of the topic, <ref> [7, 17] </ref> are recommended. A time domain process demonstrates a Markov property if the conditional probability density of the current event, given all present and past events, depends only on the jth most recent events. <p> There are three key problems in HMM use. These are the evaluation, estimation, and the decoding problems. The evaluation problem is that given an observation sequence and a model, what is the probability that the observed sequence was generated by the model (P r (Oj)) (notational style from <ref> [7] </ref>)? If this can be evaluated for all competing models for an observation sequence, then the model with the highest probability can be chosen for recognition. P r (Oj) can be calculated several ways. <p> While the technique described only handles a single observation sequence, it is easy to extend to a set of observation sequences. A more formal discussion can be found in <ref> [1, 7, 22] </ref>. While the estimation and evaluation processes described above are sufficient for the development of an HMM system, the Viterbi algorithm provides a quick means of evaluating a set of HMM's in practice as well as providing a solution for the decoding problem. <p> While this is not strictly proper, the values are approximately equal in contiguous iterations <ref> [7] </ref> and seem not to make an empirical difference [22].
Reference: [8] <author> T. Humphries, C. Padden, and T. O'Rourke. </author> <title> A Basic Course in American Sign Language. </title> <editor> T. J. </editor> <publisher> Publ., Inc., </publisher> <address> Silver Spring, MD, </address> <year> 1980. </year>
Reference-contexts: Table 1 shows the words chosen for each class. Six personal pronouns, nine verbs, twenty nouns, and five adjectives are included making the total lexicon number forty words. The words were chosen by paging through Humphries et al. <ref> [8] </ref> and selecting those which would provide coherent sentences when generating random sentences.
Reference: [9] <author> B. Juang. </author> <title> Maximum likelihood estimation for mixture multivariate observations of markov chains. </title> <journal> AT&T Technical Journal, </journal> <volume> 64 </volume> <pages> 1235-1249, </pages> <year> 1985. </year>
Reference-contexts: So far the discussion has assumed some sort of quantization of feature vectors into classes. However, instead of using vector quantization, the actual probability densities for the features may be used. Baum-Welch, Viterbi, and the forward-backward algorithms can be modified to handle a variety of characteristic densities <ref> [9] </ref>. In this context, however, the densities will be assumed to be Gaussian.
Reference: [10] <author> A. Kundu, Y. He, and P. Bahl. </author> <title> Handwritten word recognition: a hidden markov model based approach. </title> <booktitle> 22: </booktitle> <pages> 283-297, </pages> <year> 1989. </year>
Reference-contexts: Most early work was limited to handwriting recognition <ref> [10, 11] </ref>. More recently, He and Kundu [5] report using continuous density HMM's to classify planar shapes. Another early effort by Yamato et al. [21] uses discrete HMM's to successfully recognize image sequences of six different tennis strokes among three subjects.
Reference: [11] <author> R. Nag, K. Wong, and F. Fallside. </author> <title> Script recognition using hidden markov models. </title> <booktitle> In ICASSP 86, </booktitle> <year> 1986. </year>
Reference-contexts: Most early work was limited to handwriting recognition <ref> [10, 11] </ref>. More recently, He and Kundu [5] report using continuous density HMM's to classify planar shapes. Another early effort by Yamato et al. [21] uses discrete HMM's to successfully recognize image sequences of six different tennis strokes among three subjects.
Reference: [12] <author> H. Poizner, U. Bellugi, and V. Lutes-Driscoll. </author> <title> Perception of american sign language in dynamic point-light displays. </title> <booktitle> 7: </booktitle> <pages> 430-440, </pages> <year> 1981. </year>
Reference-contexts: The hand tracking stage of the system does not attempt to produce a fine-grain description of hand shape; studies have shown that such detailed information may not be necessary for humans to interpret sign language <ref> [12, 16] </ref>. Instead, the tracking process produces only a coarse description of hand shape, orientation, and trajectory. Currently we require that the user wear inexpensive colored gloves to facilitate the hand tracking frame rate and stability.
Reference: [13] <author> L. Rabiner and B. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE ASSP Magazine, </journal> <volume> p. </volume> <pages> 4-16, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: However, this study shows the continuous gesture recognition capabilities of HMM's by recognizing gesture sequences. 4 Hidden Markov Modeling While a substantial body of literature exists on HMM technology <ref> [1, 7, 13, 22] </ref>, this section briefly outlines a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. <p> Note that since Viterbi only guarantees the maximum of P r (O; Sj) over all state sequences S (as a result of the first order Markov assumption) instead of the sum over all possible state sequences, the resultant scores are only an approximation. However, <ref> [13] </ref> shows that this is often sufficient. So far the discussion has assumed some sort of quantization of feature vectors into classes. However, instead of using vector quantization, the actual probability densities for the features may be used.
Reference: [14] <author> J. Rehg and T. Kanade. DigitEyes: </author> <title> vision-based human hand tracking. </title> <institution> School of Computer Science Technical Report CMU-CS-93-220, Carnegie Mellon Univ., </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: used and only one mixture (Gaussian density) is being assumed, the algorithms above can proceed normally, incorporating these changes for the contin uous density case. 5 Recovering Hands from Video Previous systems have shown that, given some constraints, relatively detailed models of the hand can be recovered from video images <ref> [3, 14] </ref>. However, many of these constraints conflict with recognizing ASL in a natural context, either by requiring simple, unchanging backgrounds (unlike clothing), not allowing occlusion, requiring carefully labelled gloves, or being difficult to run in real time.
Reference: [15] <author> J. Schlenzig, E. Hunter, and R. Jain. </author> <title> Recursive identification of gesture inputers using hidden markov models. </title> <booktitle> In Proc. of the Second Annual Conf.on Appl. of Comp. Vision, p. </booktitle> <pages> 187-194, </pages> <year> 1994. </year>
Reference-contexts: This experiment is significant because it used a 25x25 pixel quantized subsampled camera image as a feature vector. Even with such low-level information, the model could learn the set of motions to perform respectable recognition rates. Schlenzig et al <ref> [15] </ref> also use hidden Markov models for visual gesture recognition. The gestures are limited to "hello," "good-bye," and "rotate." The authors report "intuitively" defining the HMM associated with each gesture and imply that the normal Baum-Welch re-estimation method was not implemented.
Reference: [16] <author> G. Sperling, M. Landy, Y. Cohen, and M. Pavel. </author> <title> Intelligible encoding of ASL image sequences at extremely low information rates. </title> <journal> Comp. Vision, Graphics, and Image Proc., </journal> <volume> 31 </volume> <pages> 335-391, </pages> <year> 1985. </year>
Reference-contexts: The hand tracking stage of the system does not attempt to produce a fine-grain description of hand shape; studies have shown that such detailed information may not be necessary for humans to interpret sign language <ref> [12, 16] </ref>. Instead, the tracking process produces only a coarse description of hand shape, orientation, and trajectory. Currently we require that the user wear inexpensive colored gloves to facilitate the hand tracking frame rate and stability. <p> ASL consists of approximately 6000 gestures of common words with finger spelling used to communicate obscure words or proper nouns. Conversants in ASL may describe a person, place, or thing and then point to a place in space to temporarily store that object for later reference <ref> [16] </ref>. For the purposes of this experiment, this aspect of ASL will be ignored. Furthermore, in ASL the eyebrows are raised for a question, held normal for a statement, and furrowed for a directive.
Reference: [17] <author> T. Starner. </author> <title> Visual Recognition of American Sign Language Using Hidden Markov Models. </title> <type> Master's thesis, </type> <institution> MIT Media Laboratory, </institution> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. For broader discussion of the topic, <ref> [7, 17] </ref> are recommended. A time domain process demonstrates a Markov property if the conditional probability density of the current event, given all present and past events, depends only on the jth most recent events.
Reference: [18] <author> T. Starner, J. Makhoul, R. Schwartz, and G. Chou. </author> <title> On-line cursive handwriting recognition using speech recognition methods. </title> <booktitle> In ICASSP, </booktitle> <year> 1994. </year>
Reference-contexts: This shape, orientation, and trajectory information is then input to a HMM for recognition of the signed words. Hidden Markov models have intrinsic properties which make them very attractive for sign language recognition. Explicit segmentation on the word level is not necessary for either training or recognition <ref> [18] </ref>. Language and context models can be applied on several different levels, and much related development of this technology has already been done by the speech recognition community. <p> Given the resultant bitmap and centroid, second moment analysis is performed as described earlier. 6 Feature Extraction Previous experience has shown that it is often best to start simple and evolve a feature set <ref> [18] </ref>. Since finger spelling is not allowed and there are few ambiguities in the test vocabulary based on individual finger motion, a relatively coarse tracking system may be used.
Reference: [19] <author> T. Takahashi and F. Kishino. </author> <title> Hand gesture coding based on experiments using a hand gesture interface device. </title> <journal> SIGCHI Bulletin, </journal> <volume> 23(2) </volume> <pages> 67-73, </pages> <year> 1991. </year>
Reference-contexts: In sign language, each gesture already has assigned meaning, and strong rules of context and grammar may be applied to make recognition tractable. To date, most work on sign language recognition has employed expensive wired "datagloves" which the user must wear <ref> [19] </ref>. In addition, these systems have mostly concentrated on finger signing, where the user spells each word with hand signs corresponding to the letters of the alphabet [3]. However, most signing does not involve finger spelling but, instead, gestures which represent whole words. <p> Charayaphan and Marble [2] demonstrated a feature set that could distinguish between the 31 isolated ASL signs in their training set (which also acted as the test set). Takahashi and Kishino in <ref> [19] </ref> discuss a Dataglove-based system that could recognize 34 of the 46 Japanese kana alphabet gestures (user dependent) using a joint angle and hand orientation coding technique. The test user made each of the 46 gestures 10 times to provide data for principle component and cluster analysis.
Reference: [20] <author> S. Tamura and S. Kawasaki. </author> <title> Recognition of sign language motion images. </title> <booktitle> volume 21, p. </booktitle> <pages> 343-353, </pages> <year> 1988. </year>
Reference-contexts: However, these systems have generally concentrated on isolated signs and small training and test sets. Tamura and Kawasaki demonstrated an early image processing system which could recognize 20 Japanese signs based on matching cheremes <ref> [20] </ref>. Charayaphan and Marble [2] demonstrated a feature set that could distinguish between the 31 isolated ASL signs in their training set (which also acted as the test set).
Reference: [21] <author> J. Yamato, J. Ohya, and K. Ishii. </author> <title> Recognizing human action in time-sequetial images using hidden markov model. </title> <booktitle> In Proc. 1992 IEEE Conf. on Comp. Vision and Pat. Rec., p. </booktitle> <pages> 379-385. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: Most early work was limited to handwriting recognition [10, 11]. More recently, He and Kundu [5] report using continuous density HMM's to classify planar shapes. Another early effort by Yamato et al. <ref> [21] </ref> uses discrete HMM's to successfully recognize image sequences of six different tennis strokes among three subjects. This experiment is significant because it used a 25x25 pixel quantized subsampled camera image as a feature vector.
Reference: [22] <author> S. Young. </author> <title> HTK: Hidden Markov Model Toolkit V1.5. </title> <institution> Cambridge Univ. Eng. Dept. Speech Group and Entropic Research Lab. Inc., </institution> <address> Wash-ington DC, </address> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: However, this study shows the continuous gesture recognition capabilities of HMM's by recognizing gesture sequences. 4 Hidden Markov Modeling While a substantial body of literature exists on HMM technology <ref> [1, 7, 13, 22] </ref>, this section briefly outlines a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, this result is then generalized to the continuous density case used in the experiments. <p> While the technique described only handles a single observation sequence, it is easy to extend to a set of observation sequences. A more formal discussion can be found in <ref> [1, 7, 22] </ref>. While the estimation and evaluation processes described above are sufficient for the development of an HMM system, the Viterbi algorithm provides a quick means of evaluating a set of HMM's in practice as well as providing a solution for the decoding problem. <p> While this is not strictly proper, the values are approximately equal in contiguous iterations [7] and seem not to make an empirical difference <ref> [22] </ref>. <p> While initial training of the models might rely on manual segmentation or, in this case, evenly dividing the evidence amoung the models, embedded training trains the models in situ and allows boundaries to shift through a probabilistic entry into the initial states of each model <ref> [22] </ref>. Generally, a sign can be affected by both the sign in front of it and the sign behind it. In speech, this is called "co-articulation." While this can confuse systems trying to recognize isolated signs, the context information can be used to aid recognition.
References-found: 22

