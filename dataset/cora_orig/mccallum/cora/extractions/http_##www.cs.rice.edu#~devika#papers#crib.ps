URL: http://www.cs.rice.edu/~devika/papers/crib.ps
Refering-URL: http://www.cs.rice.edu/~devika/
Root-URL: 
Title: A THEORY OF JUSTIFIED REFORMULATIONS  
Author: Devika Subramanian 
Address: Ithaca, NY 14853  
Affiliation: Computer Science Department Cornell University  
Abstract: Present day systems, intelligent or otherwise, are limited by the conceptualizations of the world given to them by their designers. In this paper, we propose a novel, first-principles approach to performing incremental reformulations for computational efficiency. First, we define a reformulation to be a shift in conceptualization: a change in the basic objects, functions, and relations assumed in a formulation. We then analyze the requirements for automating reformulation and show the need for justifying shifts in conceptualization. Inefficient formulations make irrelevant distinctions. A new class of meta-theoretical justifications for a reformulation called irrelevance explanations, is presented. A logical irrelevance explanation demonstrates that certain distinctions made in the formulation are not necessary for the computation of a given class of problems. A computational irrelevance explanation shows that some distinctions are not useful with respect to a given problem solver for a given class of problems. We then present a meta-theoretical principle of ontological economy called the irrelevance principle. The irrelevance principle logically minimizes a formulation by removing all facts and distinctions that are either logically or computationally irrelevant to the specified goals. The automation of the irrelevance principle is demonstrated with an example from the world of kinship. We also describe the implementation of an irrelevance reformulator and outline preliminary experimental results that confirm our theory. fl This paper appears in Change of Representation and Inductive Bias, edited by P. Ben jamin, Kluwer Academic Press, pp 147-168, 1990. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [Ama68] <author> S. Amarel. </author> <title> On representation of problems of reasoning about actions, </title> <year> 1968. </year>
Reference-contexts: This paper investigates the complementary question of how to reduce or avoid search by changing representations automatically. This is the reformulation question first introduced in [New65] and studied in <ref> [Ama68, Kor80, Rid88, Low87, SG87, Sub89] </ref>. The chief barrier to building autonomously intelligent systems is that we build representations of the world into them; thus the adaptiveness of these agents is severely limited by the initial conceptualizations given to them. Working within a fixed conceptual framework causes two problems. <p> Working within a fixed conceptual framework causes two problems. In deductive contexts, an inappropriate choice of formulation has adverse effects on the computational efficiency of solution. Solving the missionaries and cannibals problem <ref> [Ama68] </ref> is much easier if we conceptualize the problem in terms of sets of missionaries and cannibals and not as individuals. In inductive contexts, an inadequate set of primitive concepts may make a target concept inexpressible and thus unlearnable.
Reference: [End72] <author> Herbert Enderton. </author> <title> Mathematical Logic. </title> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: We give a semantic account of reformulation as reconceptualization: a change in the basic objects, functions and relations assumed; i.e. an ontological shift. Since, both the new and old conceptualizations are about the same world, our definition of reformulation hinges on the concept of definabilty <ref> [End72] </ref>. Informally, a conceptualization is definable in terms of another if it can be constructed from the other along with some background knowledge in the form of another conceptualization .
Reference: [Har86] <author> G. Harman. </author> <title> Change in View. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The representational and computational principles are akin to Snell's law for computational systems: they propose taking the path of least resistance in the space of representations and computations. The representational irrelevance principle is a variation of Quine's principle of indiscernibility of identicals [Qui63]. It is re-echoed in Harman's <ref> [Har86] </ref> principle of clutter avoidance and Lenat's notion of cognitive economy [LHRK79]. Whereas the representational irrelevance principle outlaws making unnecessary distinctions, the computational irrelevance principle outlaws unneeded computation.
Reference: [Kor80] <author> R. E. Korf. </author> <title> Toward a model of representation changes. </title> <journal> Artificial Intelligence, </journal> <volume> 14(1) </volume> <pages> 41-78, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: This paper investigates the complementary question of how to reduce or avoid search by changing representations automatically. This is the reformulation question first introduced in [New65] and studied in <ref> [Ama68, Kor80, Rid88, Low87, SG87, Sub89] </ref>. The chief barrier to building autonomously intelligent systems is that we build representations of the world into them; thus the adaptiveness of these agents is severely limited by the initial conceptualizations given to them. Working within a fixed conceptual framework causes two problems.
Reference: [LHRK79] <author> D. Lenat, F. Hayes-Roth, and P. Klahr. </author> <title> Cognitive economy. </title> <type> Technical Report KSL-79-15, </type> <month> June </month> <year> 1979. </year>
Reference-contexts: The representational irrelevance principle is a variation of Quine's principle of indiscernibility of identicals [Qui63]. It is re-echoed in Harman's [Har86] principle of clutter avoidance and Lenat's notion of cognitive economy <ref> [LHRK79] </ref>. Whereas the representational irrelevance principle outlaws making unnecessary distinctions, the computational irrelevance principle outlaws unneeded computation. To apply the computational irrelevance principle we need to specify an encoding and a problem solver to determine the computations that are performed.
Reference: [Low87] <author> M.R. Lowry. </author> <title> The abstraction/implementation model of problem reformulation. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: This paper investigates the complementary question of how to reduce or avoid search by changing representations automatically. This is the reformulation question first introduced in [New65] and studied in <ref> [Ama68, Kor80, Rid88, Low87, SG87, Sub89] </ref>. The chief barrier to building autonomously intelligent systems is that we build representations of the world into them; thus the adaptiveness of these agents is severely limited by the initial conceptualizations given to them. Working within a fixed conceptual framework causes two problems.
Reference: [MTMB82] <author> Utgoff P. E. Mitchell Tom M. and Banerji R. B. </author> <title> Learning by experimentation: Acquiring and refining problem- solving heuristics. In Machine Learning. </title> <publisher> Tioga, </publisher> <year> 1982. </year>
Reference-contexts: Solving the missionaries and cannibals problem [Ama68] is much easier if we conceptualize the problem in terms of sets of missionaries and cannibals and not as individuals. In inductive contexts, an inadequate set of primitive concepts may make a target concept inexpressible and thus unlearnable. The LeX system <ref> [MTMB82] </ref> could not describe an integration heuristic involving odd powers of the cosine function, because its vocabulary did not include the concept odd integer. Additionally, with the right set of primitives, the simplest methods of induction suffice [Qui82].
Reference: [New65] <author> A. Newell. </author> <title> Limitation of the current stock of ideas about problem solving. </title> <editor> In Kent and Taulbee, editors, </editor> <booktitle> Conference on Electronic Information Handling. </booktitle> <publisher> Spartan Books, </publisher> <address> Washington, D.C., </address> <year> 1965. </year>
Reference-contexts: This paper investigates the complementary question of how to reduce or avoid search by changing representations automatically. This is the reformulation question first introduced in <ref> [New65] </ref> and studied in [Ama68, Kor80, Rid88, Low87, SG87, Sub89]. The chief barrier to building autonomously intelligent systems is that we build representations of the world into them; thus the adaptiveness of these agents is severely limited by the initial conceptualizations given to them.
Reference: [NS76] <author> A. Newell and H. A. Simon. </author> <title> Computer science as empirical inquiry: Symbols and search, the 1976 &lt;acm&gt; turing lecture. </title> <journal> Communications of ACM, </journal> <volume> 19(3):113 - 126, </volume> <year> 1976. </year>
Reference-contexts: INTRODUCTION One of the most important hypotheses in the field of artificial intelligence (AI) is the Physical Symbol System Hypothesis <ref> [NS76] </ref>: computation over symbolic representations is both necessary and sufficient for obtaining intelligent be-haviour. Over the last 30 years, research in AI in this paradigm has concentrated on developing sophisticated methods of controlling search in the space defined by a fixed representation provided by a human programmer.
References-found: 10

