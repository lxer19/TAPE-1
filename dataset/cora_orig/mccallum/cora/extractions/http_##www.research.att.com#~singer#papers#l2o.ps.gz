URL: http://www.research.att.com/~singer/papers/l2o.ps.gz
Refering-URL: http://www.research.att.com/~singer/pub.html
Root-URL: 
Email: fwcohen,schapire,singerg@research.att.com  
Title: Learning to Order Things  
Author: William W. Cohen Robert E. Schapire Yoram Singer 
Affiliation: AT&T Labs  
Abstract: There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order, given feedback in the form of preference judgments, i.e., statements to the effect that one instance should be ranked ahead of another. We outline a two-stage approach in which one first learns by conventional means a preference function, of the form PREF(u; v), which indicates whether it is advisable to rank u before v. New instances are then ordered so as to maximize agreements with the learned preference function. We show that the problem of finding the ordering that agrees best with a preference function is NP-complete, even under very restrictive assumptions. Nevertheless, we describe a simple greedy algorithm that is guaranteed to find a good approximation. We then discuss an on-line learning algorithm, based on the "Hedge" algorithm, for finding a good linear combination of ranking "experts." We use the ordering algorithm combined with the on-line learning algorithm to find a combination of "search experts," each of which is a domain-specific query expansion strategy for a WWW search engine, and present experimental results that demonstrate the merits of our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brian T. Bartell, Garrison W. Cottrell, and Richard K. Belew. </author> <title> Automatic combination of multiple ranked retrieval systems. </title> <booktitle> In Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1994. </year>
Reference-contexts: Finally, we discuss related work and conclude. 2 Preliminaries Let X be a set of instances (possibly infinite). A preference function PREF is a binary function PREF : X fi X ! <ref> [0; 1] </ref>. A value of PREF (u; v) which is close to 1 or 0 is interpreted as a strong recommendation that u should be ranked before v. A value close to 1=2 is interpreted as an abstention from making a recommendation. <p> a collection of N ordering functions f i : X ! S; and a preference function PREF defined as PREF (u; v) = N X w i R f i (u; v) where w = (w 1 ; : : : ; w N ) is a weight vector in <ref> [0; 1] </ref> N with P N Question: Does there exist a total order such that AGREE (; PREF) ? Proof sketch: The problem is clearly in NP since a non-deterministic algorithm can guess a total order and check the weighted number of agreements in polynomial time. <p> t , the loss for each preference function Loss (R t i ; F t ) is evaluated as in Eq. (2) and the weight vector w t is updated using the multiplicative rule w t+1 w t i fi Loss (R t i ;F t ) where fi 2 <ref> [0; 1] </ref> is a parameter, and Z t is a normalization constant, chosen so that the weights sum to one after the update. <p> Thus, based on the feedback, the weights of the ranking experts are adjusted so that experts producing preference functions with relatively large agreement with the feedback are promoted. 6 Allocate Weights for Ranking Experts Parameters: fi 2 <ref> [0; 1] </ref>, initial weight vector w 1 2 [0; 1] N with P N i = 1 N ranking experts, number of rounds T Do for t = 1; 2; : : :; T 1. <p> Thus, based on the feedback, the weights of the ranking experts are adjusted so that experts producing preference functions with relatively large agreement with the feedback are promoted. 6 Allocate Weights for Ranking Experts Parameters: fi 2 <ref> [0; 1] </ref>, initial weight vector w 1 2 [0; 1] N with P N i = 1 N ranking experts, number of rounds T Do for t = 1; 2; : : :; T 1. Receive a set of elements X t and preference functions R t 1 ; : : : ; R t 2. <p> General optimization methods have also been adopted to adjust parameters of an IR system so as improve agreement with a set of user-given preference judgments; for instance, Boyan, Freitag, and Joachims [2] use simulated annealing to improve agreement with "click data," and Bartell, Cottrell and Belew <ref> [1] </ref> use conjugate gradient descent to choose parameters for a linear combination of scoring functions, each associated with a different search expert. As is typical when such general methods are used, few guarantees of efficiency, optimality, or generalization performance can be made for such systems.
Reference: [2] <author> Justin Boyan, Dane Freitag, and Thorsten Joachims. </author> <title> A machine learning architecture for optimizing web search engines. Technical Report WS-96-05, </title> <journal> American Association of Artificial Intelligence, </journal> <year> 1994. </year>
Reference-contexts: Our methods are thus applicable to a broader class of ranking problems. General optimization methods have also been adopted to adjust parameters of an IR system so as improve agreement with a set of user-given preference judgments; for instance, Boyan, Freitag, and Joachims <ref> [2] </ref> use simulated annealing to improve agreement with "click data," and Bartell, Cottrell and Belew [1] use conjugate gradient descent to choose parameters for a linear combination of scoring functions, each associated with a different search expert.
Reference: [3] <author> O. Etzioni, S. Hanks, T. Jiang, R. M. Karp, O. Madani, and O. Waarts. </author> <title> Efficient information gathering on the internet. </title> <booktitle> In Proceedings of the 37th Annual Symposium on Foundations of Computer Science (FOCS-96), </booktitle> <address> Burlington, Vermont, 1996. </address> <publisher> IEEE Computer Society Press. </publisher> <pages> 11 </pages>
Reference-contexts: For instance, since it is impossible for two engines to give different relative orderings to the same pair of documents, combining the rankings can be done relatively easily. Etzioni et al <ref> [3] </ref> formally considered another aspect of metasearch|the task of optimally combining information sources with associated costs and time delays. Our formal results are disjoint from theirs, as they assume that every query has a single recognizable correct answer, rendering ordering issues are unimportant.
Reference: [4] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <note> To appear. An extended abstract appeared in Computational Learning Theory: Second European Conference, </note> <month> EuroCOLT '95, </month> <pages> pages 23-37, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm [9] and Winnow [8], and, more directly, Freund and Schapire's <ref> [4] </ref> "Hedge" algorithm. We then present some experimental results in which this algorithm is used to combine the results of several "search experts," each of which is a domain-specific query expansion strategy for a WWW search engine. <p> The algorithm we propose for this problem is based on the "weighted majority algorithm" of Littlestone and Warmuth [9] and, more directly, on Freund and Schapire's <ref> [4] </ref> "Hedge" algorithm. We define the loss of a preference function R with respect to the user's feedback F as Loss (R; F ) def P jF j This loss has a natural probabilistic interpretation. <p> Set the new weight vector w t+1 w t i fi Loss (R t i ;F t ) where Z t is a normalization constant, chosen so that P N i = 1. We briefly sketch the theoretical rationale behind this algorithm. Freund and Schapire <ref> [4] </ref> prove general results about Hedge which can be applied directly to this loss function.
Reference: [5] <author> Z. Galil and N. Megido. </author> <title> Cyclic ordering is NP-complete. </title> <journal> Theoretical Computer Science, </journal> <volume> 5 </volume> <pages> 179-182, </pages> <year> 1977. </year>
Reference: [6] <author> Michael R. Gary and David S. Johnson. </author> <title> Computers and Intractibility: A Guide to the Theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference: [7] <author> Paul B. Kantor. </author> <title> Decision level data fusion for routing of documents in the TREC3 context: a best case analysis of worste case results. </title> <booktitle> In Proceedings of the third text retrieval conference (TREC-3), </booktitle> <year> 1994. </year>
Reference-contexts: Many methods for this have been proposed by the information retrieval community, and many of these are adaptive, using relevance judgments to make an appropriate choice of parameters. However, generally rankings are combined by combining the scores that were used to rank documents <ref> [10, 7] </ref>; it is also frequently assumed that other properties of the objects (documents) to be ranked are available, such as word frequencies. In contrast, in our experiments, instances are atomic entities, with no associated properties except for their position in various rank-orderings.
Reference: [8] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4), </volume> <year> 1988. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm [9] and Winnow <ref> [8] </ref>, and, more directly, Freund and Schapire's [4] "Hedge" algorithm. We then present some experimental results in which this algorithm is used to combine the results of several "search experts," each of which is a domain-specific query expansion strategy for a WWW search engine. <p> The problem, then, is to learn a preference function of the form PREF (u; v) = P N i=1 w i R i (u; v). We adopt the on-line learning framework first studied by Littlestone <ref> [8] </ref> in which the weight w i assigned to each ranking expert R i is updated incrementally. Learning is assumed to take place in a sequence of rounds.
Reference: [9] <author> Nick Littlestone and Manfred Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm <ref> [9] </ref> and Winnow [8], and, more directly, Freund and Schapire's [4] "Hedge" algorithm. We then present some experimental results in which this algorithm is used to combine the results of several "search experts," each of which is a domain-specific query expansion strategy for a WWW search engine. <p> The algorithm we propose for this problem is based on the "weighted majority algorithm" of Littlestone and Warmuth <ref> [9] </ref> and, more directly, on Freund and Schapire's [4] "Hedge" algorithm. We define the loss of a preference function R with respect to the user's feedback F as Loss (R; F ) def P jF j This loss has a natural probabilistic interpretation.
Reference: [10] <author> Karen E. Lochbaum and Lynn A. Streeter. </author> <title> Comparing and combining the effectiveness of latent semantic indexing and the ordinary vector space model for information retrieval. </title> <booktitle> Information processing and management, </booktitle> <volume> 25(6) </volume> <pages> 665-676, </pages> <year> 1989. </year>
Reference-contexts: Many methods for this have been proposed by the information retrieval community, and many of these are adaptive, using relevance judgments to make an appropriate choice of parameters. However, generally rankings are combined by combining the scores that were used to rank documents <ref> [10, 7] </ref>; it is also frequently assumed that other properties of the objects (documents) to be ranked are available, such as word frequencies. In contrast, in our experiments, instances are atomic entities, with no associated properties except for their position in various rank-orderings.
Reference: [11] <author> Geoffrey Towell, Ellen Voorhees, Narendra Gupta, and Ben Johnson-Laird. </author> <title> Learning collection fusion strategies for information retrieval. </title> <booktitle> In Machine Learning: Proceedings of the Twelfth International Conference, </booktitle> <address> Lake Taho, California, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Another related task is collection fusion: here several searches are executed on disjoint subsets of a large collection, and the results are combined. Several approaches to this problem that do not rely on combining ranking scores have been described <ref> [11, 12] </ref>. However, although superficially the problem is similar to the one presented here, the assumption that the different search engines index disjoint sets of documents actually makes the problem quite different.
Reference: [12] <author> Ellen M. Voorhees, Narendra K. Gupta, and Ben Johnson-Laird. </author> <title> The collection fusion problem. </title> <booktitle> In Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Another related task is collection fusion: here several searches are executed on disjoint subsets of a large collection, and the results are combined. Several approaches to this problem that do not rely on combining ranking scores have been described <ref> [11, 12] </ref>. However, although superficially the problem is similar to the one presented here, the assumption that the different search engines index disjoint sets of documents actually makes the problem quite different.
References-found: 12

