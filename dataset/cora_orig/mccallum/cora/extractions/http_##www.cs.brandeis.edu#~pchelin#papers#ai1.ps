URL: http://www.cs.brandeis.edu/~pchelin/papers/ai1.ps
Refering-URL: http://www.cs.brandeis.edu/~pchelin/papers/
Root-URL: http://www.cs.brandeis.edu
Email: pchelin@cs.brandeis.edu  
Title: Knowledge Representation in Probabilistic Networks  
Author: Peter Pchelin 
Date: December 9, 1997  
Affiliation: Department of Computer Science, Brandeis University  
Abstract: This paper looks at several key issues facing the designers of a knowledge representation system and suggests how these issues might be addressed by a knowledge representation system that is based on both the symbolic and the connectivist model. Some weaknesses of such a system are put forth and several enhancements are furnished in light of this criticism. In particular, a probabilistic model of knowledge representation is advocated. One possible application of the resulting knowledge representation system in the area of natural language processing is also considered. 
Abstract-found: 1
Intro-found: 1
Reference: <author> John McCarthy [1968], </author> <title> "Programs with commonsense," </title> <editor> In M. Minsky (Ed.), </editor> <booktitle> Semantic Information Processing, </booktitle> <publisher> MIT Press, Cambridge, </publisher> <pages> 403-418. </pages>
Reference: <author> Geoffrey G. </author> <title> Towell [1991], "Symbolic Knowledge And Neural Networks: Insertion, Refinement, and Extraction," </title> <type> Thesis, </type> <institution> University of Wisconsin-Madison. </institution> <address> Eugene Charniak [1997], </address> <booktitle> "Statistical Techniques for Natural Language Parsing, </booktitle> <institution> Department of Computer Science," Brown University. </institution> <month> Gadi Pinkas, </month> <title> "Nonmonotonic Reasoning and Symmetric Networks-On Bridging the Gap Between Symbolic and Connectionist Knowledge Representation," in Neural Networks for Knowledge Representation And Inference, </title> <type> 175-203. </type>
Reference: <author> George E. Mobus, </author> <title> "Toward a Theory of Learning and Representating Causal Inferences in Neural Networks," in Neural Networks for Knowledge Representation And Inference, </title> <type> 339-374. </type>
Reference: <author> John Binder, Daphne Koller, Stuart Russell, </author> <title> Keiji Kanazawa [1997], "Adaptive Probabilistic Networks with Hiden Variables", </title> <publisher> Kluwer Academic Publishers, Boston. </publisher> <editor> James Pustejovsky, </editor> <title> "The Generative Lexicon", </title> <journal> Computational Linguistics, </journal> <volume> Volume 17, Number 4, </volume> <pages> 409-441. </pages>

Reference: <author> Radford M. </author> <title> Neal [1992], "Bayesian Training of Backpropagation Networks by the Hybrid Monte Carlo Method," </title> <type> Technical Report CRG-TR-92-1, </type> <institution> Connectionist Reserach Group, Department of Computer Science, University of Toronto. </institution>
Reference: <author> Eric Bauer, Daphne Koller, </author> <title> Yoram Singer [1997], "Update rules for parameter estimation in Bayesian networks," </title> <booktitle> in Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence (UAI-970, </booktitle> <address> Providence, Rhode Island, </address> <month> August 1-3, 3-13. </month> <title> Sabine Glesner and Daphne Koller, "Constructing Flexible Dynamic Belief Networks from First-Order Probabilistic Knowledge Bases," </title> <institution> Computer Science Division, University of California, Berkeley, </institution> <note> CA. </note> <author> Bryan Kramer and John Mylopoulos, </author> <title> "Knowledge Representation," in Knowledge Acquisition. </title>
Reference: <author> Daniel J. Simons, Frank C. </author> <title> Keil [1994], "An abstract to concrete shift in the development of biological thought: </title> <booktitle> the insides story," in Cognition 56 (1995), </booktitle> <pages> 129-163. </pages>
References-found: 7

