URL: http://robotics.stanford.edu/users/assembly/dBGH.ps.gz
Refering-URL: http://robotics.stanford.edu/users/assembly/pubs.html
Root-URL: http://www.cs.stanford.edu
Title: Vertical Decompositions  for Triangles in 3-Space  
Author: Mark de Berg Leonidas J. Guibas Dan Halperin 
Address: P.O.Box 80.089, 3508 TB Utrecht, the Netherlands.  Stanford, CA 94305.  Stanford, CA  
Affiliation: Department of Computer Science, Utrecht University,  Department of Computer Science, Stanford University,  Robotics Laboratory, Department of Computer Science, Stanford University,  
Date: February 22, 1995  94305.  
Note: Submitted to Discrete and Computational Geometry  
Abstract: We prove that, for any constant " &gt; 0, the complexity of the vertical decomposition of a set of n triangles in three-dimensional space is O(n 2+" + K), where K is the complexity of the arrangement of the triangles. For a single cell the complexity of the vertical decomposition is shown to be O(n 2+" ). These bounds are almost tight in the worst case. We also give a deterministic output-sensitive algorithm for computing the vertical decomposition that runs in O(n 2 log n + V log n) time, where V is the complexity of the decomposition. The algorithm is reasonably simple (in particular, it tries to perform as much of the computation in two-dimensional spaces as possible) and thus is a good candidate for efficient implementations. The algorithm is extended to compute the vertical decomposition of arrangements of n algebraic surface patches of constant maximum degree in three-dimensional space in time O(n q (n) log n + V log n), where V is the combinatorial complexity of the vertical decomposition, q (n) is a near-linear function related to Davenport-Schinzel sequences, and q is a constant that depends on the degree of the surface patches and their boundaries. We also present an algorithm with improved running time for the case of triangles which is, however, more complicated than the first algorithm. fl Mark de Berg was supported by the Dutch Organization for Scientific Research (N.W.O.), and by ESPRIT Basic Research Action No. 7141 (project ALCOM II:Algorithms and Complexity). Leonidas Guibas was supported by NSF grant CCR-9215219, by a grant from the Stanford SIMA Consortium, by NSF/ARPA Grant IRI-9306544, and by grants from the Digital Equipment, Mitsubishi, and Toshiba Corporations. Dan Halperin was supported by a Rothschild Postdoctoral Fellowship, by a grant from the Stanford Integrated Manufacturing Association (SIMA), by NSF/ARPA Grant IRI-9306544, and by NSF Grant CCR-9215219. A preliminary version of this paper appeared in Proc. 10th ACM Symposium on Computational Geometry, 1994, pp. 1-10. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal and J. Matousek. </author> <title> Ray shooting and parametric search. </title> <journal> SIAM J. Comput., </journal> <volume> 22(4) </volume> <pages> 794-806, </pages> <year> 1993. </year>
Reference: [2] <author> P. K. Agarwal and J. Matousek. </author> <title> On range searching with semialgebraic sets. </title> <journal> Discrete Comput. Geom., </journal> <volume> 11 </volume> <pages> 393-418, </pages> <year> 1994. </year>
Reference: [3] <author> P. K. Agarwal, M. Sharir, and P. Shor. </author> <title> Sharp upper and lower bounds on the length of general Davenport-Schinzel sequences. </title> <journal> J. Combin. Theory Ser. A, </journal> <volume> 52 </volume> <pages> 228-274, </pages> <year> 1989. </year>
Reference-contexts: Since fl is a convex curve, there are at most two such intersections. Hence, the complexity of the upper envelope of T fl 1 is at most 4 (n) = O (n2 ff (n) ) <ref> [3] </ref>. A similar argument holds for E (T 2 ). 2 Using this lemma we can prove an almost tight upper bound on b (n). A basic ingredient in the proof are efficient hierarchical cuttings [8, 29], which we define next.
Reference: [4] <author> B. Aronov and M. Sharir. </author> <title> Triangles in space or building (and analyzing) castles in the air. </title> <journal> Combinatorica, </journal> <volume> 10(2) </volume> <pages> 137-173, </pages> <year> 1990. </year>
Reference-contexts: In many applications, however, the actual complexity of the arrangement of triangles is much smaller. So the challenge is to obtain a decomposition whose size is sensitive to the complexity of the arrangement of the triangles. Such a complexity-sensitive decomposition was given by Aronov and Sharir <ref> [4] </ref>: their Slicing Theorem states that one can decompose an arrangement of n triangles in 3-space into O (n 2 ff (n)+K) tetrahedra, where K is the complexity of the arrangement. <p> Our proof uses an interesting combination of efficient hierarchical cuttings [8, 29], the counting scheme used in hereditary segment trees [11], the Slicing Theorem <ref> [4] </ref>, and random sampling [16, 26]. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity. <p> Let A (T ) denote the arrangement induced by T , namely, the subdivision of 3-space into cells of dimensions 0; 1; 2 and 3, induced by the triangles in T . We make the same general position assumption as Aronov and Sharir <ref> [4] </ref>: no two edges of distinct triangles intersect, no vertex of a triangle is contained in another triangle, and so on. In particular we assume that no triangle is vertical, that is, no triangle is parallel to the z-axis. (In the sequel "vertical" will always mean parallel to the z-axis. <p> There exists an O (log r=r)-cutting of size O (r 2 ff (r) + Kr 3 =n 3 ) for T . Proof: Let R T be a random sample of size r. By the Slicing Theorem <ref> [4] </ref> we can triangulate A (R) into O (r 2 ff (r) + jA (R)j) simplices. From "-net theory [26] it follows that with high probability each simplex in the triangulation will be intersected by O (n log r=r) triangles in T .
Reference: [5] <author> B. Aronov and M. Sharir. </author> <title> Castles in the air revisited. </title> <journal> Discrete Comput. Geom., </journal> <volume> 12 </volume> <pages> 119-150, </pages> <year> 1994. </year>
Reference-contexts: To prove an upper bound we note that a single cell in an arrangement of n triangles can be decomposed into O (n 2 log n) simplices; this follows from the Slicing Theorem and a bound on the complexity of a single cell <ref> [5] </ref>. We designate a single three-dimensional cell in the arrangement by a point in its interior.
Reference: [6] <author> J. L. Bentley and T. A. Ottmann. </author> <title> Algorithms for reporting and counting geometric intersections. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-28:643-647, </volume> <year> 1979. </year>
Reference-contexts: This is similar to a basic argument in the Bentley-Ottmann algorithm for detecting intersections of line segments <ref> [6] </ref>, [33, Section 7.2]. Once we handle a vertical visibility event it is easy to determine whether it is actual or false by checking whether the lower and upper chains involved in this event belong to the same face.
Reference: [7] <author> B. Chazelle. </author> <title> Convex partitions of polyhedra: a lower bound and worst-case optimal algorithm. </title> <journal> SIAM J. Comput., </journal> <volume> 13 </volume> <pages> 488-507, </pages> <year> 1984. </year>
Reference-contexts: This result is close to optimal: (K) is clearly a lower bound on any decomposition, and Chazelle <ref> [7] </ref> shows that there are arrangements of complexity O (n) such that any decomposition into convex cells has size (n 2 ). (The triangles in Chazelle's example form the boundary of a simple polytope.) The Slicing Theorem obtains a decomposition by adding vertical walls for each of the triangle boundary edges,
Reference: [8] <author> B. Chazelle. </author> <title> Cutting hyperplanes for divide-and-conquer. </title> <journal> Discrete Comput. Geom., </journal> <volume> 9 </volume> <pages> 145-158, </pages> <year> 1993. </year>
Reference-contexts: Our proof uses an interesting combination of efficient hierarchical cuttings <ref> [8, 29] </ref>, the counting scheme used in hereditary segment trees [11], the Slicing Theorem [4], and random sampling [16, 26]. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity. <p> A similar argument holds for E (T 2 ). 2 Using this lemma we can prove an almost tight upper bound on b (n). A basic ingredient in the proof are efficient hierarchical cuttings <ref> [8, 29] </ref>, which we define next. Let H be a set of n hyperplanes in IR d . A (1=r)-cutting for H is a subdivision of IR d 8 into disjoint simplices such that the interior of each simplex is intersected by at most n=r hyperplanes in H. <p> Notice that the last condition implies that k = fi (log r). We call the simplex in ffi i1 that contains a certain simplex s 2 ffi i the parent of s, denoted by parent (s). Chazelle <ref> [8] </ref> has shown (see also Matousek [29]) that for any given H and r there exists an efficient hierarchical cutting (for certain constants C; ). We are now ready to prove an upper bound on b (n). Lemma 3.2 b (n) = O (n 2 2 ff (n) log n).
Reference: [9] <author> B. Chazelle and H. Edelsbrunner. </author> <title> An optimal algorithm for intersecting line segments in the plane. </title> <journal> J. ACM, </journal> <volume> 39 </volume> <pages> 1-54, </pages> <year> 1992. </year>
Reference-contexts: A segment is a maximal portion of a line that appears in the arrangement, possibly intersected by other segments. An edge is a maximal portion of a segment not intersected by any other segment. 16 point one may use the optimal algorithm by Chazelle and Edelsbrunner <ref> [9] </ref>. However, due to other steps of the algorithm, this will not make a difference in the overall running time of the algorithm. Also, the sweep paradigm is more appropriate for the extension that we present below to handling arrangements of surface patches.
Reference: [10] <author> B. Chazelle, H. Edelsbrunner, L. Guibas, and M. Sharir. </author> <title> A singly-exponential stratification scheme for real semi-algebraic varieties and its applications. </title> <booktitle> In Proc. 16th Internat. Colloq. Automata Lang. Program., volume 372 of Lecture Notes in Computer Science, </booktitle> <pages> pages 179-192. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: For more general arrangements such refined decompositions are more difficult to find. For example, for algebraic hypersurfaces of constant maximum degree in d-dimensional space (d 3) the best decomposition technique known so far results in O (n 2d3 fi (n)) cells <ref> [10] </ref>, where fi (n) is an extremely slowly growing function, 1 whereas the complexity of the arrangement itself is only O (n d ). In this paper we study decompositions for arrangements of triangles in three-dimensional space.
Reference: [11] <author> B. Chazelle, H. Edelsbrunner, L. J. Guibas, and M. Sharir. </author> <title> Lines in space: </title> <booktitle> combinatorics, algorithms, and applications. In Proc. 21st Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 382-393, </pages> <year> 1989. </year>
Reference-contexts: Our proof uses an interesting combination of efficient hierarchical cuttings [8, 29], the counting scheme used in hereditary segment trees <ref> [11] </ref>, the Slicing Theorem [4], and random sampling [16, 26]. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity. <p> The observation implies that we only have to count for each simplex s 2 ffi the number of visibilities where all involved triangles are in T (s) and at least one of them is in T (s). (A similar observation is often made when one uses hereditary segment trees <ref> [11] </ref>: only long-long and long-short intersections need to be considered, not short-short intersections.) So let's count the number of such visibilities for a given simplex s. Let n s := jT (s)j. Consider some triangle t 2 T 1 (s).
Reference: [12] <author> B. Chazelle and J. Friedman. </author> <title> A deterministic view of random sampling and its use in geometry. </title> <journal> Combinatorica, </journal> <volume> 10(3) </volume> <pages> 229-249, </pages> <year> 1990. </year>
Reference-contexts: The Slicing Theorem decomposition has the unpleasant characteristic that it depends on the order in which triangle boundary edges are treated. Thus the tetrahedra in the decomposition are not defined "locally", and it is not canonical in the sense of Chazelle and Friedman <ref> [12] </ref>. This means that the decomposition is not very well suited for randomized incremental algorithms. It also makes it difficult to compute the decomposition efficiently. A decomposition which does not have this problem|and one which we think is more simple to compute|is the following [14, 30, 31].
Reference: [13] <author> B. Chazelle and L. J. Guibas. Fractional cascading: I. </author> <title> A data structuring technique. </title> <journal> Algorithmica, </journal> <volume> 1 </volume> <pages> 133-162, </pages> <year> 1986. </year>
Reference-contexts: Hence, the subdivisions must be propagated further. To avoid blowing up the complexity of our structure, the subdivisions must be properly coarsened during the propagation. So what we need is two-dimensional version of fractional cascading <ref> [13] </ref>. Currently we do not know how 23 to achieve this|we leave this is an open problem for further research. Another possible solution is to augment each arrangement B fl i with a point location structure [33].
Reference: [14] <author> K. Clarkson, H. Edelsbrunner, L. Guibas, M. Sharir, and E. Welzl. </author> <title> Combinatorial complexity bounds for arrangements of curves and spheres. </title> <journal> Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 99-160, </pages> <year> 1990. </year>
Reference-contexts: This means that the decomposition is not very well suited for randomized incremental algorithms. It also makes it difficult to compute the decomposition efficiently. A decomposition which does not have this problem|and one which we think is more simple to compute|is the following <ref> [14, 30, 31] </ref>. This decomposition is also obtained by erecting vertical walls. This time the wall for edge e simply consists of those points in H (e) that can be connected to e with a vertical segment that does not cross any of the triangles in T .
Reference: [15] <author> K. L. Clarkson. </author> <title> A randomized algorithm for closest-point queries. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 830-847, </pages> <year> 1988. </year>
Reference-contexts: Ideally, the number of cells after the refinement should be proportional to the overall complexity of the arrangement. For arrangements of hyperplanes the well-known bottom vertex triangulation <ref> [15] </ref> meets this criterion. For more general arrangements such refined decompositions are more difficult to find.
Reference: [16] <author> K. L. Clarkson and P. W. Shor. </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 387-421, </pages> <year> 1989. </year>
Reference-contexts: Our proof uses an interesting combination of efficient hierarchical cuttings [8, 29], the counting scheme used in hereditary segment trees [11], the Slicing Theorem [4], and random sampling <ref> [16, 26] </ref>. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity.
Reference: [17] <author> M. de Berg. </author> <title> Ray Shooting, Depth Orders and Hidden Surface Removal, </title> <booktitle> volume 703 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference: [18] <author> M. de Berg, K. Dobrindt, and O. Schwarzkopf. </author> <title> On lazy randomized incremental construction. </title> <booktitle> In Proc. 26th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 105-114, </pages> <year> 1994. </year>
Reference-contexts: Recently de Berg et al. <ref> [18] </ref> described a simple randomized incremental algorithm to compute a single cell in an arrangement of triangles. Their algorithm uses vertical decompositions, and its running time is O (g (n) log n), where g (n) is the maximum complexity of the vertical decomposition of a single cell.
Reference: [19] <author> M. de Berg, L. J. Guibas, and D. Halperin. </author> <title> Vertical decompostions for triangles in 3-space. </title> <type> Technical Report UU-CS-1994-29, </type> <institution> Utrecht University, </institution> <year> 1994. </year>
Reference-contexts: We have devised an algorithm that achieves a subquadratic overhead time. This algorithm is, however, substantially more complicated than the algorithm described above, and the savings are small. Therefore, we summarize the performance of the alternative algorithm in the following theorem, and refer the reader to a Technical Report <ref> [19] </ref> where a detailed description of the algorithm is given. Theorem 4.2 Let T be a collection of n triangles in general position in three dimensional space.
Reference: [20] <author> M. de Berg, D. Halperin, M. Overmars, J. Snoeyink, and M. van Kreveld. </author> <title> Efficient ray shooting and hidden surface removal. </title> <journal> Algorithmica, </journal> <volume> 12 </volume> <pages> 30-53, </pages> <year> 1994. </year>
Reference: [21] <author> H. Edelsbrunner. </author> <title> The upper envelope of piecewise linear functions: tight complexity bounds in higher dimensions. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 337-343, </pages> <year> 1989. </year>
Reference-contexts: The method of the proof of Lemma 3.2 can also be applied in other situations. As an example, consider the upper envelope of a set T of n (d 1)- simplices in IR d . The maximum complexity of this envelope is fi (n d1 ff (n)) <ref> [21] </ref>. Our proof technique does not give this optimal result, but an almost tight upper bound of O (n d1 log n).
Reference: [22] <author> M. Goodrich and R. Tamassia. </author> <title> Dynamic trees and dynamic point location. </title> <booktitle> In Proc. 23rd Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 523-533, </pages> <year> 1991. </year>
Reference-contexts: Our approach is related to a space sweep algorithm that has recently been developed to compute a decomposition of certain arrangements for motion planning problems [24], and to the space sweep methods used to construct point location data structures for monotone subdivisions <ref> [22, 34] </ref>. We then extend the algorithm to compute the vertical decomposition of arrangements of n algebraic surface patches of constant maximum degree in three-dimensional space. <p> Therefore, instead of handling each three-dimensional cell at a time we carry out a space sweep over the entire decomposition V 1 (T ). A similar approach has recently been used to obtain a decomposition of certain arrangements related to a motion planning problem [24]; see also <ref> [22, 34] </ref> for dynamic maintenance of a monotone subdivision in a space-sweep. Let P x 1 denote the plane x = x 1 .
Reference: [23] <author> L. J. Guibas and R. Sedgewick. </author> <title> A dichromatic framework for balanced trees. </title> <booktitle> In Proc. 19th Annu. IEEE Sympos. Found. Comput. Sci., Lecture Notes in Computer Science, </booktitle> <pages> pages 8-21, </pages> <year> 1978. </year>
Reference-contexts: All these operations (insertion, deletion, split and join) can be carried out in O (log n) time each, using, e.g., red-black trees <ref> [23] </ref>, [36, Chapter 4]. To detect vertical visibilities between vertices on the boundary of f we proceed as follows.
Reference: [24] <author> D. Halperin and M. Sharir. </author> <title> Near-quadratic bounds for the motion planning problem for a polygon in a polygonal environment. </title> <booktitle> In Proc. 34th Annu. Sympos. on Foundations of Computer Science, </booktitle> <pages> pages 382-391, </pages> <year> 1993. </year>
Reference-contexts: Our approach is related to a space sweep algorithm that has recently been developed to compute a decomposition of certain arrangements for motion planning problems <ref> [24] </ref>, and to the space sweep methods used to construct point location data structures for monotone subdivisions [22, 34]. We then extend the algorithm to compute the vertical decomposition of arrangements of n algebraic surface patches of constant maximum degree in three-dimensional space. <p> Therefore, instead of handling each three-dimensional cell at a time we carry out a space sweep over the entire decomposition V 1 (T ). A similar approach has recently been used to obtain a decomposition of certain arrangements related to a motion planning problem <ref> [24] </ref>; see also [22, 34] for dynamic maintenance of a monotone subdivision in a space-sweep. Let P x 1 denote the plane x = x 1 .
Reference: [25] <author> S. Hart and M. Sharir. </author> <title> Nonlinearity of Davenport-Schinzel sequences and of generalized path compression schemes. </title> <journal> Combinatorica, </journal> <volume> 6 </volume> <pages> 151-177, </pages> <year> 1986. </year>
Reference-contexts: See also Figure 1 (b). Since the complexity of the lower envelope of n segments in the plane is O (nff (n)) <ref> [25] </ref>, the part of W (e; T ) above e has O (nff (n)) complexity. A similar argument holds for the part of W (e; T ) below e. Hence, a single wall has complexity O (nff (n)).
Reference: [26] <author> D. Haussler and E. Welzl. </author> <title> Epsilon-nets and simplex range queries. </title> <journal> Discrete Comput. Geom., </journal> <volume> 2 </volume> <pages> 127-151, </pages> <year> 1987. </year>
Reference-contexts: Our proof uses an interesting combination of efficient hierarchical cuttings [8, 29], the counting scheme used in hereditary segment trees [11], the Slicing Theorem [4], and random sampling <ref> [16, 26] </ref>. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity. <p> Proof: Let R T be a random sample of size r. By the Slicing Theorem [4] we can triangulate A (R) into O (r 2 ff (r) + jA (R)j) simplices. From "-net theory <ref> [26] </ref> it follows that with high probability each simplex in the triangulation will be intersected by O (n log r=r) triangles in T . In other words, the triangulation will be an O (log r=r)- cutting for T with high probability.
Reference: [27] <author> J. Heintz, T. Recio, and M.-F. Roy. </author> <title> Algorithms in real algebraic geometry and applications to computational geometry. </title> <editor> In J.E. Goodman, R. Pollack, and W. Steiger, editors, </editor> <booktitle> Discrete and Computational Geometry: Papers from the DIMACS Special Year, volume 6 of DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <pages> pages 137-163. </pages> <publisher> Amer. Math. Soc., </publisher> <year> 1991. </year>
Reference-contexts: We need to assume here a model of computation where each elementary operation on the surface patches required by the algorithm is performed in constant time. We can assume the model used for algorithms in real algebraic geometry <ref> [27] </ref>, where each algebraic operation involving a constant number of polynomials of constant maximum degree can be performed exactly, using rational arithmetic, in constant time.
Reference: [28] <author> J. Hershberger. </author> <title> Finding the upper envelope of n line segments in O(n log n) time. </title> <journal> Inform. Process. Lett., </journal> <volume> 33 </volume> <pages> 169-174, </pages> <year> 1989. </year>
Reference-contexts: This fact also implies that we can compute a single wall in O (n log n) time <ref> [28] </ref>. Since there are 3n walls to compute, the time bound follows. 2 We define a pair of two-dimensional arrangements of segments for each triangle t i . <p> The time to compute each envelope is O ( q (n) log n) which can be done either by a straightforward divide and conquer, or, for a small 25 saving in the constant q above, by the algorithm of Hershberger mentioned earlier <ref> [28] </ref>. Computing all the O (n) walls, therefore, will take O (n q (n) log n) for some constant q. We also need to extend Lemma 4.3 to this more general setting.
Reference: [29] <author> J. Matousek. </author> <title> Range searching with efficient hierarchical cuttings. </title> <journal> Discrete Com-put. Geom., </journal> <volume> 10 </volume> <pages> 157-182, </pages> <year> 1993. </year>
Reference-contexts: Our proof uses an interesting combination of efficient hierarchical cuttings <ref> [8, 29] </ref>, the counting scheme used in hereditary segment trees [11], the Slicing Theorem [4], and random sampling [16, 26]. Our proof can be adapted to show that the vertical decomposition of a single cell in an arrangement of triangles has O (n 2+" ) complexity. <p> A similar argument holds for E (T 2 ). 2 Using this lemma we can prove an almost tight upper bound on b (n). A basic ingredient in the proof are efficient hierarchical cuttings <ref> [8, 29] </ref>, which we define next. Let H be a set of n hyperplanes in IR d . A (1=r)-cutting for H is a subdivision of IR d 8 into disjoint simplices such that the interior of each simplex is intersected by at most n=r hyperplanes in H. <p> Notice that the last condition implies that k = fi (log r). We call the simplex in ffi i1 that contains a certain simplex s 2 ffi i the parent of s, denoted by parent (s). Chazelle [8] has shown (see also Matousek <ref> [29] </ref>) that for any given H and r there exists an efficient hierarchical cutting (for certain constants C; ). We are now ready to prove an upper bound on b (n). Lemma 3.2 b (n) = O (n 2 2 ff (n) log n).
Reference: [30] <author> K. Mulmuley. </author> <title> Hidden surface removal with respect to a moving point. </title> <booktitle> In Proc. 23rd Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 512-522, </pages> <year> 1991. </year>
Reference-contexts: This means that the decomposition is not very well suited for randomized incremental algorithms. It also makes it difficult to compute the decomposition efficiently. A decomposition which does not have this problem|and one which we think is more simple to compute|is the following <ref> [14, 30, 31] </ref>. This decomposition is also obtained by erecting vertical walls. This time the wall for edge e simply consists of those points in H (e) that can be connected to e with a vertical segment that does not cross any of the triangles in T .
Reference: [31] <author> K. Mulmuley. </author> <title> Randomized multidimensional search trees: further results in dynamic sampling. </title> <booktitle> In Proc. 32nd Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 216-227, </pages> <year> 1991. </year>
Reference-contexts: This means that the decomposition is not very well suited for randomized incremental algorithms. It also makes it difficult to compute the decomposition efficiently. A decomposition which does not have this problem|and one which we think is more simple to compute|is the following <ref> [14, 30, 31] </ref>. This decomposition is also obtained by erecting vertical walls. This time the wall for edge e simply consists of those points in H (e) that can be connected to e with a vertical segment that does not cross any of the triangles in T . <p> We call the refined subdivision the full vertical decomposition 2 for T . In this paper we prove bounds on the maximum combinatorial complexity of vertical decompositions. Our bounds are sensitive to the complexity of the arrangement of 2 Mulmuley <ref> [31] </ref> calls V 3 (T ) the vertical decomposition, and he calls V 2 (T ) the cylindrical decomposition. 3 the triangles. <p> The total number of edges in E (T )|and thus the total number of walls|is O (n 2 ). It follows that the maximum complexity of V (T ) is O (n 3 ff (n)), as was noted by Mulmuley <ref> [31] </ref>. More precisely, it follows that jV (T )j = O ((n + N )nff (n))), where N is the number of pairwise intersections of triangles in the arrangement. However, it is not clear whether it is possible that all walls have fi (nff (n)) complexity.
Reference: [32] <author> M. Overmars and M. Sharir. </author> <title> Output-sensitive hidden surface removal. </title> <booktitle> In Proc. 30th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 598-603, </pages> <year> 1989. </year>
Reference: [33] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational Geometry: an Introduction. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year> <month> 29 </month>
Reference-contexts: The next step of the algorithm is to compute, for each side of each triangle t i 2 T , the arrangement induced by (t fl i ). To this end we use a standard plane sweep algorithm that detects all the intersection points between segments 4 <ref> [33] </ref>. (At this 4 From this point on, when discussing two-dimensional arrangements, we will distinguish between a segment and an edge. A segment is a maximal portion of a line that appears in the arrangement, possibly intersected by other segments. <p> Such a queue can be implemented so that the time for each operation is O (log m), where m is the maximum number of events held simultaneously in the queue <ref> [33] </ref>. To each event that we insert into the queue, we attach the local geometric and combinatorial information relevant to that event. Observe that we can insert all the events where 19 the structure of A x changes|the vertices of V 1 (T )|into Q before we start the sweep. <p> This is similar to a basic argument in the Bentley-Ottmann algorithm for detecting intersections of line segments [6], <ref> [33, Section 7.2] </ref>. Once we handle a vertical visibility event it is easy to determine whether it is actual or false by checking whether the lower and upper chains involved in this event belong to the same face. <p> So what we need is two-dimensional version of fractional cascading [13]. Currently we do not know how 23 to achieve this|we leave this is an open problem for further research. Another possible solution is to augment each arrangement B fl i with a point location structure <ref> [33] </ref>. This solution will not increase the preprocessing time of our structure asymptotically, but will cost O (log n) time per ceiling/floor crossing. A slight modification of our structure enables a certain "compromise" solution, with no increase in the asymptotic complexity of the structure or in the preprocessing time.
Reference: [34] <author> F. P. Preparata and R. Tamassia. </author> <title> Efficient point location in a convex spatial cell-complex. </title> <journal> SIAM J. Comput., </journal> <volume> 21 </volume> <pages> 267-280, </pages> <year> 1992. </year>
Reference-contexts: Our approach is related to a space sweep algorithm that has recently been developed to compute a decomposition of certain arrangements for motion planning problems [24], and to the space sweep methods used to construct point location data structures for monotone subdivisions <ref> [22, 34] </ref>. We then extend the algorithm to compute the vertical decomposition of arrangements of n algebraic surface patches of constant maximum degree in three-dimensional space. <p> Therefore, instead of handling each three-dimensional cell at a time we carry out a space sweep over the entire decomposition V 1 (T ). A similar approach has recently been used to obtain a decomposition of certain arrangements related to a motion planning problem [24]; see also <ref> [22, 34] </ref> for dynamic maintenance of a monotone subdivision in a space-sweep. Let P x 1 denote the plane x = x 1 .
Reference: [35] <author> M. Sharir. </author> <title> Almost tight upper bounds for lower envelopes in higher dimensions. </title> <journal> Discrete Comput. Geom., </journal> <volume> 12 </volume> <pages> 327-345, </pages> <year> 1994. </year>
Reference-contexts: When we are discussing arrangements on the xy-plane we will explicitly say "y-vertical" when we mean parallel to the y-axis.) By standard arguments <ref> [35] </ref> the combinatorial bound that we derive in Section 3 holds for degenerate arrangements as well. However, the algorithms described in Section 4 will have to undergo several technical adjustments (which we do not discuss in this paper) to accommodate for degenerate arrangements. <p> way of defining this is to require that the coefficients of the polynomials defining the surfaces and their boundaries are algebraically independent over the rationals (i.e., no multivariate polynomial with rational coefficients vanishes when substituting into it some of the given coefficients), thereby excluding all kinds of `degenerate' configurations; see <ref> [35] </ref> for more details. We need to assume here a model of computation where each elementary operation on the surface patches required by the algorithm is performed in constant time.
Reference: [36] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, PA, </address> <year> 1987. </year>
Reference-contexts: All these operations (insertion, deletion, split and join) can be carried out in O (log n) time each, using, e.g., red-black trees [23], <ref> [36, Chapter 4] </ref>. To detect vertical visibilities between vertices on the boundary of f we proceed as follows.
Reference: [37] <author> A. Wiernik and M. Sharir. </author> <title> Planar realizations of nonlinear Davenport-Schinzel sequences by segments. </title> <journal> Discrete Comput. Geom., </journal> <volume> 3 </volume> <pages> 15-47, </pages> <year> 1988. </year> <month> 30 </month>
Reference-contexts: Proof: Let S 0 be a set of bn=2c line segments in the yz-plane whose upper envelope has complexity fi (nff (n)) <ref> [37] </ref>, and such that S 0 lies completely below the plane z = 0. Extend each segment in the x-direction to obtain a set T 0 of infinitely long strips, that is, let T 0 := f [1 : 1] fi s : s 2 S 0 g.
References-found: 37

