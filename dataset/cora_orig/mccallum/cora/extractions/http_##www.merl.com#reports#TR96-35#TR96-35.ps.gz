URL: http://www.merl.com/reports/TR96-35/TR96-35.ps.gz
Refering-URL: http://www.merl.com/reports/TR96-35/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: freeman@merl.com  
Author: W. T. Freeman K. Tanaka J. Ohta and K. Kyuma 
Keyword: and Gesture Recognition,  
Date: October, 1996.  
Note: From: IEEE 2nd Intl. Conf. on Automatic Face  Killington, VT,  
Address: 201 Broadway Cambridge, MA 02139 USA  R&D Center 8-1-1, Tsukaguchi-Honmachi Amagasaki City, Hyogo 661, Japan  
Affiliation: MERL, a Mitsubishi Electric Research Lab.  Mitsubishi Electric Advanced Technology  
Abstract: We meet these constraints with algorithms tailored to particular hardware. We have developed a special detector, called the artificial retina chip, which allows for fast, on-chip image processing. We describe two algorithms, based on image moments and orientation histograms, which exploit the capabilities of the chip to provide interactive response to the player's hand or body positions at 10 msec frame time and at low-cost. We show several possible game interactions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. H. Ballard and C. M. Brown, </author> <title> editors. Computer Vision. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: Another uses orientation histograms to select the body pose from a menu of templates. The first exploits the image projection capabilities of the AR module; the second uses its ability to quickly calculate x and y derivatives. 3.1 Image Moments Image moments <ref> [9, 1] </ref> provide useful summaries of global image information, and have been applied to shape analysis or other tasks, often for binary images. The moments involve sums over all pixels, and so are robust against small pixel value changes.
Reference: [2] <author> D. Beymer and T. Poggio. </author> <title> Face recognition from one example view. </title> <booktitle> In Proc. 5th Intl. Conf. on Computer Vision, </booktitle> <pages> pages 500-507. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: The vision system may merely track the position of the visual center of mass of the player, but the game can turn that into running, jumping or crouching, depending on position and game context. There has been much recent work on computer vision analysis of faces and gestures (e.g. <ref> [3, 12, 4, 2] </ref>). The focus of this research has been on high performance algorithms, not cost optimization. While some systems perform at 10 or 30 Hz on workstation or Pentium systems, this is still too slow and far too expensive for the game requirements described above.
Reference: [3] <author> M. Bichsel. </author> <booktitle> International Workshop on Automatic Face- and Gesture- Recognition. IEEE Computer Society, </booktitle> <year> 1995. </year>
Reference-contexts: The vision system may merely track the position of the visual center of mass of the player, but the game can turn that into running, jumping or crouching, depending on position and game context. There has been much recent work on computer vision analysis of faces and gestures (e.g. <ref> [3, 12, 4, 2] </ref>). The focus of this research has been on high performance algorithms, not cost optimization. While some systems perform at 10 or 30 Hz on workstation or Pentium systems, this is still too slow and far too expensive for the game requirements described above.
Reference: [4] <author> M. J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion. </title> <booktitle> In Proc. 5th Intl. Conf. on Computer Vision, </booktitle> <pages> pages 374-381. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: The vision system may merely track the position of the visual center of mass of the player, but the game can turn that into running, jumping or crouching, depending on position and game context. There has been much recent work on computer vision analysis of faces and gestures (e.g. <ref> [3, 12, 4, 2] </ref>). The focus of this research has been on high performance algorithms, not cost optimization. While some systems perform at 10 or 30 Hz on workstation or Pentium systems, this is still too slow and far too expensive for the game requirements described above.
Reference: [5] <author> J. S. E. Hunter and R. Jain. </author> <title> Posture estimation in reduced-model gesture input systems. </title> <editor> In M. Bichsel, editor, </editor> <booktitle> Intl. Workshop on automatic face- and gesture-recognition, </booktitle> <pages> pages 290-295, </pages> <address> Zurich, Switzerland, </address> <year> 1995. </year> <institution> Dept. of Computer Science, </institution> <address> University of Zurich, </address> <booktitle> CH-8057. </booktitle> <volume> 0 5 10 15 20 25 30 35 5 15 25 0 5 10 15 20 25 30 35 5 15 25 0 5 10 15 20 25 30 35 5 15 25 eject which orientation histograms are calculated. </volume> <booktitle> Right: corresponding game action. </booktitle>
Reference-contexts: The horizontal and vertical projections can be performed on the artificial retina detector itself, approximately doubling the throughput. human figure, and present computation times for the AR module. Others have developed algorithms to identify the pose of a figure <ref> [8, 12, 5] </ref>, but those algorithms do not meet our speed and cost requirements. The orientation histogram algorithm has limitations: the arms should not cross the body, and we have not studied recognition choosing from among a very large set of possible poses.
Reference: [6] <author> W. T. Freeman and M. Roth. </author> <title> Orientation histograms for hand gesture recognition. </title> <editor> In M. Bichsel, editor, </editor> <booktitle> Intl. Workshop on automatic face- and gesture-recognition, </booktitle> <address> Zurich, Switzer-land, </address> <year> 1995. </year> <institution> Dept. of Computer Science, University of Zurich, CH-8057. </institution>
Reference-contexts: Histograms of local orientation can be used for fast pattern recognition <ref> [11, 6] </ref>. <p> We then divide orientation into bins (e.g. 10 ffi per bin) and calculate the orientation histogram over some region. Measuring the Euclidean distance <ref> [6] </ref>, or mutual information [11], between the orientation histograms of different images provides a measure of similarity which is contrast and position independent. A global orientation histogram of a figure would average too much spatial information to infer pose.
Reference: [7] <author> E. Funatsu, Y. Nitta, M. Miyake, T. Toyoda, K. Hara, H. Yagi, J. Ohta, and K. Kyuma. </author> <booktitle> SPIE, </booktitle> <volume> 2597(283), </volume> <year> 1995. </year>
Reference-contexts: Figure 1 shows the elements of the AR chip: a 2-D array of variable sensitivity photodetection cells (VSPC), a random access scanner for sensitivity control, and an output multiplexer <ref> [7] </ref>. The VSPC consists of a pn photo-diode and a differential amplifier which allows for high detection sensitivity of either positive or negative polarity. This structure also realizes nondestructive readout of the image, essential for the image processing.
Reference: [8] <author> D. M. Gavrila and L. S. Davis. </author> <title> Towards 3-d model-based tracking and recognition of human movement: a multi-view approach. </title> <editor> In M. Bich-sel, editor, </editor> <booktitle> Intl. Workshop on automatic face-and gesture-recognition, </booktitle> <pages> pages 272-277, </pages> <address> Zurich, Switzerland, </address> <year> 1995. </year> <institution> Dept. of Computer Science, University of Zurich, CH-8057. </institution>
Reference-contexts: The horizontal and vertical projections can be performed on the artificial retina detector itself, approximately doubling the throughput. human figure, and present computation times for the AR module. Others have developed algorithms to identify the pose of a figure <ref> [8, 12, 5] </ref>, but those algorithms do not meet our speed and cost requirements. The orientation histogram algorithm has limitations: the arms should not cross the body, and we have not studied recognition choosing from among a very large set of possible poses.
Reference: [9] <author> B. K. P. Horn. </author> <title> Robot vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Another uses orientation histograms to select the body pose from a menu of templates. The first exploits the image projection capabilities of the AR module; the second uses its ability to quickly calculate x and y derivatives. 3.1 Image Moments Image moments <ref> [9, 1] </ref> provide useful summaries of global image information, and have been applied to shape analysis or other tasks, often for binary images. The moments involve sums over all pixels, and so are robust against small pixel value changes. <p> = x y M 20 = x y X X y 2 I (x; y) We can find the position, x c , y c , orientation , and dimensions l 1 and l 2 of an equivalent rectangle which has the same moments as those measured in the image <ref> [9] </ref>. Those values give a measure of the hand's position, orientation, and aspect ratio. We have: x c = M 00 M 01 (2) and the equivalent rectangle having the same first and second order moments as those of the image. <p> Define the intermediate variables a, b, and c, a = M 00 c M 11 x c y c ) M 02 y 2 We have (c.f. <ref> [9] </ref>): = arctan (b; (a c)) 2 and r p 2 r p 2 The extracted parameters are independent of the overall image intensity. appear within a "playing area" of a game machine, and the corresponding equivalent rectangle calclu-ated for each image from the image moments. <p> Right: Possible game responses to hand inputs. Car orientation and position follow the hand; the hand's apparent width controls the throttle. 3.1.1 Fast Calculation of Image Moments The image moments can be calculated quickly from three projections of the image <ref> [9] </ref>, and we exploit that fact to speed up the processing with the AR chip. Let the vertical, horizontal, and diagonal projections be V (x) = y H (y) = x and X I ( p ; p ): (8) Then the image moments are [9]: M 00 = x V <p> three projections of the image <ref> [9] </ref>, and we exploit that fact to speed up the processing with the AR chip. Let the vertical, horizontal, and diagonal projections be V (x) = y H (y) = x and X I ( p ; p ): (8) Then the image moments are [9]: M 00 = x V (x) P 2 M 02 for each image (after background subtraction and clipping to positive values) with cross-hairs superimposed for reference. Right: Possible game response to rectangle states. Horizontal position determines right/left steering.
Reference: [10] <author> K. Kyuma, E. Lange, J. Ohta, A. Hermanns, B. Banish, and M. </author> <title> Oita. </title> <journal> Nature, </journal> <volume> 372(197), </volume> <year> 1994. </year>
Reference-contexts: By analogy with the fast, low-level processing that occurs in the eye, we call the detector the artificial retina (AR) chip <ref> [10] </ref>. Figure 1 shows the elements of the AR chip: a 2-D array of variable sensitivity photodetection cells (VSPC), a random access scanner for sensitivity control, and an output multiplexer [7].
Reference: [11] <author> R. K. McConnell. </author> <title> Method of and apparatus for pattern recognition. </title> <editor> U. S. </editor> <volume> Patent No. 4,567,610, </volume> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: Histograms of local orientation can be used for fast pattern recognition <ref> [11, 6] </ref>. <p> We then divide orientation into bins (e.g. 10 ffi per bin) and calculate the orientation histogram over some region. Measuring the Euclidean distance [6], or mutual information <ref> [11] </ref>, between the orientation histograms of different images provides a measure of similarity which is contrast and position independent. A global orientation histogram of a figure would average too much spatial information to infer pose.
Reference: [12] <author> A. P. Pentland. </author> <title> Smart rooms. </title> <journal> Scientific American, </journal> <volume> 274(4) </volume> <pages> 68-76, </pages> <year> 1996. </year> <title> image A. R. detector calculations micro-processor calculations orientation image 0 5 10 15 20 25 30 35 5 15 25 histogram algorithm. Top to bottom: Original image; x and y derivatives, calculated on the artificial retina detector; derivatives with the background image subtracted; orientation angle calculated for each pixel above a contrast threshold. Histograms of the orientations of the upper two 16x16 blocks of the orientation image were concatenated into one feature vector, which was compared with existing prototypes for recognition. </title>
Reference-contexts: The vision system may merely track the position of the visual center of mass of the player, but the game can turn that into running, jumping or crouching, depending on position and game context. There has been much recent work on computer vision analysis of faces and gestures (e.g. <ref> [3, 12, 4, 2] </ref>). The focus of this research has been on high performance algorithms, not cost optimization. While some systems perform at 10 or 30 Hz on workstation or Pentium systems, this is still too slow and far too expensive for the game requirements described above. <p> The horizontal and vertical projections can be performed on the artificial retina detector itself, approximately doubling the throughput. human figure, and present computation times for the AR module. Others have developed algorithms to identify the pose of a figure <ref> [8, 12, 5] </ref>, but those algorithms do not meet our speed and cost requirements. The orientation histogram algorithm has limitations: the arms should not cross the body, and we have not studied recognition choosing from among a very large set of possible poses.
References-found: 12

