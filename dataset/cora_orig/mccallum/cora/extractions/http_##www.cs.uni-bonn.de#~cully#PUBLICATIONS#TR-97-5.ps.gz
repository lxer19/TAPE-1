URL: http://www.cs.uni-bonn.de/~cully/PUBLICATIONS/TR-97-5.ps.gz
Refering-URL: http://www.cs.uni-bonn.de/~cully/research2.html
Root-URL: http://cs.uni-bonn.de
Email: fjw,cullyg@cs.uni-bonn.de  
Title: The MyView System: Tackling the Interface Problem  
Author: J.E. Wolff, J. Kalinski 
Keyword: information need, Boolean retrieval, query mapping, search optimization, distributed systems, bibliographic data repositories  
Address: Romerstr. 164, 53117 Bonn, Germany  
Affiliation: Institute of Computer Science III, University of Bonn,  
Abstract: The MyView system aims at gathering bibliographic information from a diversity of heterogeneous distributed Internet repositories like electronic journals, text archives, and traditional libraries. It maintains a personalized warehouse for bibliographic data in a unified scheme which is locally available for browsing, ad-hoc queries, rearrangements, and analysis. To specify a user's information need we suggest its definition in a simple and comfortable way, namely by just a set of terms and not by a complex query language. Traditional libraries, however, often exclusively offer a Boolean interface. To fill the warehouse a user's information need thus has to be translated into a sequence of Boolean queries. Furthermore, the additional restriction of limited storage resources has to be taken into account, when data are transferred into the warehouse. In this paper the mapping problem and optimal solutions are defined in exact terms. We additionally present two heuristically guided algorithms: The first one prefers highly ranked records, while the second algorithm tries to generate one query for every term of the information need, preferring equal-sized result sets. Furthermore we discuss some important implementation aspects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of the 1993 ACM SIGMOD Int. Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Tries offer efficient support for bit vector search and prefix search: 11 Let us mention that this idea has also been used in the mining of association rules (see <ref> [1] </ref>).
Reference: [2] <author> O. Balownew, T. Bode, A.B. Cremers, J. Kalinski, J.E. Wolff, and H. Rottmann. </author> <title> Maintaining Library Catalogues with an RDBMS | A Performance Study. </title> <type> Technical Report IAI-TR-96-13, </type> <institution> Institute of Computer Science III, University of Bonn, </institution> <address> Romerstr. 164, D-53117 Bonn, Germany, </address> <month> November </month> <year> 1996. </year> <note> &lt;URL: http://www.cs.bonn.edu/III/publikationen/tr/IAI-TR-96-13.abstract-en.html&gt; </note>
Reference-contexts: Based on the specification relevant information servers are queried and result sets are stored in the local warehouse. 5 http://lcweb.loc.gov/marc/ 6 http://www.hbz-nrw.de/ 7 Characteristics of the HBZ data and their influence on the performance of Boolean queries have been analyzed in [3]. A detailed version can be found in <ref> [2] </ref>. 4 As the specification itself should be user-friendly and simple we suggest its definition by means of sets of terms. Each term can be a keyword or a keyword phrase. These sets typically contain both some general terms as well as some more specific ones characterizing the desired topic.
Reference: [3] <author> O. Balownew, T. Bode, A.B. Cremers, J. Kalinski, J.E. Wolff, and H. Rottmann. </author> <title> A Library Application on Top of an RDBMS: Performance Aspects. </title> <booktitle> In DEXA97 [11], </booktitle> <pages> pages 488-497. </pages>
Reference-contexts: Based on the specification relevant information servers are queried and result sets are stored in the local warehouse. 5 http://lcweb.loc.gov/marc/ 6 http://www.hbz-nrw.de/ 7 Characteristics of the HBZ data and their influence on the performance of Boolean queries have been analyzed in <ref> [3] </ref>. A detailed version can be found in [2]. 4 As the specification itself should be user-friendly and simple we suggest its definition by means of sets of terms. Each term can be a keyword or a keyword phrase.
Reference: [4] <author> Nicholas J. Belkin and Bruce W. Croft. </author> <title> Retrieval techniques. </title> <journal> Annual Review of Information Science and Technology, </journal> <volume> 22 </volume> <pages> 109-145, </pages> <year> 1987. </year>
Reference-contexts: Although many functionalities are defined in the standard, only a few are actually provided by every Z39.50 server, typically linking query terms by Boolean operators and counting the result size of a query. It is generally accepted in the information retrieval community that Boolean retrieval is insufficient <ref> [4] </ref> and yields the worst retrieval quality in comparison with other retrieval models. Therefore MyView has to support functionality going beyond the existing services.
Reference: [5] <author> C. Blair, David. </author> <title> The data-document distinction in information retrieval. </title> <journal> Communications of the ACM, </journal> <volume> 27(4) </volume> <pages> 369-374, </pages> <year> 1984. </year>
Reference-contexts: can be stated as follows: Given an information need, data repositories R 1 ; : : : ; R r and a resource restriction N , how many documents should be transferred from each R i in order to maximize the total number of relevant documents received? Blair describes in <ref> [5] </ref> an approach where a set of weighted query terms entered by the user is automatically converted into a set of conjunctive Boolean queries. The use of weights is to reflect how successful the user believes them to be in the search as index terms.
Reference: [6] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, Michael F. Schwartz, and Duane P. Wessels. Harvest: </author> <title> A Scalable, Customizable Discovery and Access System. </title> <type> Technical Report CU-CS-732-94, </type> <institution> University of Colorado Boulder, </institution> <month> August </month> <year> 1994. </year> <note> &lt;URL: ftp://ftp.cs.colorado.edu/pub/cs/techreports/schwartz/Harvest.Jour.ps.Z&gt; </note>
Reference-contexts: In-between these two extremes meta search engines (MetaCrawler [25], SavvySearch 16 ) and networked literature collections (NCSTRL 17 ) overcome the latter interface diversity, but problems remain: predefined search space not configurable by the user, restricted retrieval capabilities. The Harvest system (see <ref> [6, 16] </ref>) is an integrated set of customizable tools for gathering information from diverse Internet repositories and their subsequent effective use. The architecture enables the construction of topic-specific content indexes, but the definition of a personalized view is not supported directly.
Reference: [7] <author> C. Mic Bowman, Peter B. Danzig, Udi Manber, and Michael F. Schwartz. </author> <title> Scalable Internet Resource Discovery: Research Problems and Approaches. </title> <journal> Communications of the ACM, </journal> <volume> 37(8) </volume> <pages> 98-114, </pages> <month> August </month> <year> 1994. </year> <note> &lt;URL: ftp://ftp.cs.colorado.edu/pub/cs/techreports/schwartz/RD.ResearchProblems.Jour.ps.Z&gt; </note>
Reference-contexts: So, the computation yields (01011000) representing fb; d; eg as the only element of C 0 . 8 Related Work Existing search engines (AltaVista 13 , InfoSeek 14 ) and resource discovery tools (see <ref> [7, 22] </ref>) are impressively powerful what concerns the keyword-driven discovery of Internet resources. But they do not integrate the millions of document descriptions of traditional library catalogues.
Reference: [8] <author> James P. Callan, Zhihong Lu, and Bruce W. Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proc. of the 18th Int. ACM SIGIR Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 21-28, </pages> <month> July </month> <year> 1995. </year> <note> &lt;URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/ir.html&gt; </note>
Reference-contexts: If all the repositories supported the same best-match query evaluation, the term set could be submitted as one single query to each of them and their results be merged (see <ref> [8] </ref>). However, this is the exception. What concerns traditional libraries we have to cope with exact-match query processing. Unfortunately, the probability of getting a hit decreases, the more terms are gathered in a conjunction. The conjunction of the entire information need will hardly yield any records at all.
Reference: [9] <author> Kevin Chen-Chuang Chang, Hector Garcia-Molina, and Andreas Paepcke. </author> <title> Boolean query mapping across heterogeneous information sources. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8(4) </volume> <pages> 515-521, </pages> <year> 1996. </year>
Reference-contexts: Each term can be a keyword or a keyword phrase. These sets typically contain both some general terms as well as some more specific ones characterizing the desired topic. This design decision was chosen in contrast to a complex query language to avoid the following drawbacks (but see <ref> [9, 10] </ref> for a different approach): * Learning just another query formalism to express the complex specifications. * Uncertainty in formulating the vague information need, particularly at the beginning of the work. * Deterioration of the query effectiveness caused by defective terms, e.g. typing errors. <p> The hard problem of modeling a user's information need is not tackled in GlOSS, because only Boolean "and" queries are considered. The generalized version gGlOSS (see [14]) also deals with vector-space databases and queries, but at the expense of additionally required statistical information about the databases. In <ref> [9, 10] </ref> Chang, Garcia-Molina and Paepcke study a translation problem which is in some way similar to ours. While we are discussing the gap between information needs as term sets and Boolean queries, the cited papers concentrate on exact-match queries in "rich" Boolean languages.
Reference: [10] <author> Kevin Chen-Chuang Chang, Hector Garcia-Molina, and Andreas Paepcke. </author> <title> Boolean query mapping across heterogeneous information sources (extended version). </title> <type> Technical Report CS-TR-97-1583, </type> <institution> Stanford University, </institution> <month> January </month> <year> 1997. </year> <note> &lt;URL: http://pub-db.stanford.edu/&gt; </note>
Reference-contexts: Each term can be a keyword or a keyword phrase. These sets typically contain both some general terms as well as some more specific ones characterizing the desired topic. This design decision was chosen in contrast to a complex query language to avoid the following drawbacks (but see <ref> [9, 10] </ref> for a different approach): * Learning just another query formalism to express the complex specifications. * Uncertainty in formulating the vague information need, particularly at the beginning of the work. * Deterioration of the query effectiveness caused by defective terms, e.g. typing errors. <p> The hard problem of modeling a user's information need is not tackled in GlOSS, because only Boolean "and" queries are considered. The generalized version gGlOSS (see [14]) also deals with vector-space databases and queries, but at the expense of additionally required statistical information about the databases. In <ref> [9, 10] </ref> Chang, Garcia-Molina and Paepcke study a translation problem which is in some way similar to ours. While we are discussing the gap between information needs as term sets and Boolean queries, the cited papers concentrate on exact-match queries in "rich" Boolean languages.
Reference: [11] <editor> Proc. </editor> <booktitle> of the 8th International Conference and Workshop on Database and Expert Systems Applications, </booktitle> <month> September </month> <year> 1997. </year> <month> 21 </month>
Reference: [12] <institution> European Research Consortium for Informatics and Mathematics. ERCIM News, </institution> <address> Number 27, </address> <month> October </month> <year> 1996. </year> <note> Special Issue: Digital Libraries. &lt;URL: http://www-ercim.inria.fr&gt; </note>
Reference-contexts: Beside traditional libraries offering their bibliographic data on the Web, many research projects in the USA (Digital Library Initiative 1 ), UK (eLib Project 2 ), Germany (Medoc 3 ), and other countries (see <ref> [12, 19] </ref>) have invested in digital library development. But whatever libraries will look like and whatever information they will provide in the end, the general problem for the user remains the same: how to query distributed repositories of knowledge efficiently and effectively with regard to their personal information needs.
Reference: [13] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability | A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1990. </year>
Reference-contexts: Notice that for the removal to be allowed all of docs R (T ) must fit into the warehouse. It is not hard to see that finding a query set which approaches N as close as possible includes the Knapsack problem (see <ref> [13, 17] </ref>). Algorithm BestLoad chooses single elements of P by random (line (5)). Other Knapsack algorithms can be used instead.
Reference: [14] <author> Luis Gravano and Hector Garcia-Molina. </author> <title> Generalizing GlOSS to vector-space databases and broker hierarchies. </title> <booktitle> In Proc. of the 21th Int. Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 78-89, </pages> <month> September </month> <year> 1995. </year> <note> &lt;URL: http://pub-db.stanford.edu/&gt; </note>
Reference-contexts: The hard problem of modeling a user's information need is not tackled in GlOSS, because only Boolean "and" queries are considered. The generalized version gGlOSS (see <ref> [14] </ref>) also deals with vector-space databases and queries, but at the expense of additionally required statistical information about the databases. In [9, 10] Chang, Garcia-Molina and Paepcke study a translation problem which is in some way similar to ours.
Reference: [15] <author> Luis Gravano, Hector Garcia-Molina, and Anthony Tomasic. </author> <title> The efficacy of GlOSS for the text database discovery problem. </title> <type> Technical Report STAN-CS-TN-93-2, </type> <institution> Stanford University, </institution> <year> 1993. </year> <note> &lt;URL: http://pub-db.stanford.edu/&gt; </note>
Reference-contexts: The architecture enables the construction of topic-specific content indexes, but the definition of a personalized view is not supported directly. Furthermore some sorts of information repositories cannot be handled, like e.g. traditional library catalogues. A system which aims at integrating distributed Internet resources and uses word-frequency information is GlOSS <ref> [15] </ref>. It focuses on the identification of relevant text databases for a given query and uses the word-frequencies to estimate the result sizes of the query. An estimation of this kind based on some probability distributions can also be used in our framework.
Reference: [16] <author> Darren R. Hardy, Michael F. Schwartz, and Duane Wessels. </author> <title> Harvest User's Manual. </title> <institution> University of Colorado, </institution> <month> January </month> <year> 1996. </year> <note> Version 1.4 patchlevel 2. &lt;URL: http://harvest.transarc.com/afs/transarc.com/public/trg/Harvest/user-manual.ps&gt; </note>
Reference-contexts: In-between these two extremes meta search engines (MetaCrawler [25], SavvySearch 16 ) and networked literature collections (NCSTRL 17 ) overcome the latter interface diversity, but problems remain: predefined search space not configurable by the user, restricted retrieval capabilities. The Harvest system (see <ref> [6, 16] </ref>) is an integrated set of customizable tools for gathering information from diverse Internet repositories and their subsequent effective use. The architecture enables the construction of topic-specific content indexes, but the definition of a personalized view is not supported directly.
Reference: [17] <author> Ellis Horowitz and Sartaj Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <year> 1978. </year>
Reference-contexts: Notice that for the removal to be allowed all of docs R (T ) must fit into the warehouse. It is not hard to see that finding a query set which approaches N as close as possible includes the Knapsack problem (see <ref> [13, 17] </ref>). Algorithm BestLoad chooses single elements of P by random (line (5)). Other Knapsack algorithms can be used instead.
Reference: [18] <author> R. Hull and G. Zhou. </author> <title> A framework for supporting data integration using the materialized and virtual approaches. </title> <booktitle> In Proc. of the 1996 ACM SIGMOD Int. Conference on Management of Data, </booktitle> <pages> pages 481-492, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: To support the above mentioned new functionalities MyView transforms the gathered bibliographic data records into a uniform scheme and stores them in a personal database. In the database community this approach has recently become popular as data warehousing (see <ref> [18, 29] </ref>). Efficient data retrieval and query post processing on the local warehouse can thus be realized.
Reference: [19] <institution> IEEE Computer, </institution> <month> May </month> <year> 1996. </year> <title> Theme: Digital Libraries. </title>
Reference-contexts: Beside traditional libraries offering their bibliographic data on the Web, many research projects in the USA (Digital Library Initiative 1 ), UK (eLib Project 2 ), Germany (Medoc 3 ), and other countries (see <ref> [12, 19] </ref>) have invested in digital library development. But whatever libraries will look like and whatever information they will provide in the end, the general problem for the user remains the same: how to query distributed repositories of knowledge efficiently and effectively with regard to their personal information needs.
Reference: [20] <author> M. Loffredo, M.B. Baldacci, and O. Signore. </author> <title> Tailoring Z39.50 on Existing Databases: the ARCA Project. </title> <booktitle> In DEXA97 [11], </booktitle> <pages> pages 332-338. </pages>
Reference-contexts: The standardized Z39.50 protocol [23], for instance, is widely used by traditional libraries and catalogue centers for supporting information retrieval services. Furthermore, Ludwig et al. [21] offer a Z39.50 interface for online bibliographic databases which have previously been accessible via Telnet only, and the ARCA Project <ref> [20] </ref> develops a library for making OPACs (Online Public Accessible Catalogues) a Z39.50 target. Although many functionalities are defined in the standard, only a few are actually provided by every Z39.50 server, typically linking query terms by Boolean operators and counting the result size of a query.
Reference: [21] <author> A. Ludwig, P. Becker, and U. Guntzer. </author> <title> Interfacing online bibliographic databases with Z39.50. </title> <booktitle> In Int. Database Engineering and Applications Symposium, </booktitle> <address> IDEAS'97, </address> <month> August </month> <year> 1997. </year> <note> &lt;URL: http://www.informatik.uni-tuebingen.de/forschung/papers/ludwig/ideas.ps&gt; </note>
Reference-contexts: Sophisticated query languages and best-match evaluation (vector space retrieval model) overcoming this lack are rarely supported by their interfaces. The standardized Z39.50 protocol [23], for instance, is widely used by traditional libraries and catalogue centers for supporting information retrieval services. Furthermore, Ludwig et al. <ref> [21] </ref> offer a Z39.50 interface for online bibliographic databases which have previously been accessible via Telnet only, and the ARCA Project [20] develops a library for making OPACs (Online Public Accessible Catalogues) a Z39.50 target.
Reference: [22] <author> Katia Obraczka, Peter B. Danzig, and Shih-Hao Li. </author> <title> Internet Resource Discovery Services. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 8-22, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: So, the computation yields (01011000) representing fb; d; eg as the only element of C 0 . 8 Related Work Existing search engines (AltaVista 13 , InfoSeek 14 ) and resource discovery tools (see <ref> [7, 22] </ref>) are impressively powerful what concerns the keyword-driven discovery of Internet resources. But they do not integrate the millions of document descriptions of traditional library catalogues.
Reference: [23] <author> National Information Standards Organization. </author> <title> Information Retrieval (Z39.50): Application Service Definition and Protocol Specification. </title> <publisher> NISO Press, </publisher> <year> 1995. </year> <note> &lt;URL: http://lcweb.loc.gov/z3950/agency/&gt; </note>
Reference-contexts: In general retrieval tools of traditional libraries support only restricted functionalities and simple exact-match queries (Boolean retrieval model). Sophisticated query languages and best-match evaluation (vector space retrieval model) overcoming this lack are rarely supported by their interfaces. The standardized Z39.50 protocol <ref> [23] </ref>, for instance, is widely used by traditional libraries and catalogue centers for supporting information retrieval services.
Reference: [24] <author> Robert Sedgewick. </author> <title> Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: The complete bit vectors are stored in the external nodes. For more details the reader may consult a text book about data structures (e.g. <ref> [24] </ref>), where he can also find optimized variations like Patricia tries. Example 7 The trie for the query set f fa; hg; fb; dg; fb; eg; fd; eg; fd; hg g is depicted in Fig. 11.
Reference: [25] <author> E. Selberg and O. Etzioni. </author> <title> Multi-Engine Search and Comparison using the MetaCrawler. </title> <booktitle> In Proc. of the Fourth Int'l WWW Conference, </booktitle> <pages> pages 195-208, </pages> <address> Boston, Massachusetts, USA, </address> <month> December </month> <year> 1995. </year> <note> &lt;URL: http://www.metacrawler.com/&gt; </note>
Reference-contexts: But they do not integrate the millions of document descriptions of traditional library catalogues. Web-based interfaces to libraries 15 on the other hand will in most cases support only simple queries and each offers a different user interface. In-between these two extremes meta search engines (MetaCrawler <ref> [25] </ref>, SavvySearch 16 ) and networked literature collections (NCSTRL 17 ) overcome the latter interface diversity, but problems remain: predefined search space not configurable by the user, restricted retrieval capabilities.
Reference: [26] <author> Ellen M. Voorhees. </author> <title> Siemens TREC-4 Report: Further Experiments with Database Merging. </title> <booktitle> In Proc. of the 1995 Text Retrieval Conference (TREC4), </booktitle> <month> November </month> <year> 1995. </year> <note> &lt;URL: http://www-nlpir.nist.gov/TREC/t4 proceedings.html&gt; </note>
Reference-contexts: Even mappings from one Boolean dialect into another are becoming non-trivial under these circumstances. Voorhees et al. examine how to merge ranked retrieval results from multiple independent repositories into a single result set (see <ref> [27, 26] </ref>).
Reference: [27] <author> Ellen M. Voorhees, Narenda K. Gupta, and Ben Johnson-Laird. </author> <title> The collection fusion problem. </title> <booktitle> In Proc. of the 1994 Text Retrieval Conference (TREC3), </booktitle> <year> 1994. </year> <note> &lt;URL: http://www-nlpir.nist.gov/TREC/t3 proceedings.html&gt; 22 </note>
Reference-contexts: Even mappings from one Boolean dialect into another are becoming non-trivial under these circumstances. Voorhees et al. examine how to merge ranked retrieval results from multiple independent repositories into a single result set (see <ref> [27, 26] </ref>).
Reference: [28] <author> Carolyn Watters and Michael A. Shepherd. </author> <title> Shifting the information paradigm from data--centered to user-centered. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 30(4) </volume> <pages> 455-471, </pages> <year> 1994. </year>
Reference-contexts: Its prospective user is a scientist gathering information for a scientific project or a consultant writing an industrial study. MyView thus represents the shift from data-centered to user-centered information access, as observed by Watters and Shepherd <ref> [28] </ref>. In the following we will focus our attention on traditional libraries as information repositories. 1 http://dli.grainger.uiuc.edu/national.htm 2 http://www.ukoln.ac.uk/services/elib/ 3 http://medoc.informatik.tu-muenchen.de/ 2 Identifying the personal information need as the central motivation behind MyView, support-ing its gratification efficiently is the logical consequence.
Reference: [29] <author> Jennifer Widom. </author> <title> Research problems in data warehousing. </title> <booktitle> In Proc. of the 4th International Conference on Information and Knowledge Management, </booktitle> <year> 1995. </year>
Reference-contexts: To support the above mentioned new functionalities MyView transforms the gathered bibliographic data records into a uniform scheme and stores them in a personal database. In the database community this approach has recently become popular as data warehousing (see <ref> [18, 29] </ref>). Efficient data retrieval and query post processing on the local warehouse can thus be realized.
Reference: [30] <author> J.E. Wolff and J. Kalinski. </author> <title> Mining library catalogues: Best-match retrieval based on exact-match interfaces. </title> <booktitle> In Proc. of the International Workshop on Issues and Applications of Database Technology (in print), </booktitle> <year> 1998. </year> <month> 23 </month>
Reference-contexts: Spoken in our terms, Blair performs a bottom-up traversal of the powerset lattice. As can be seen, his use of weights is significantly different from our ranking scheme. A generalization of algorithm BestLoad which takes into account weighted search terms is presented by Wolff and Kalinski in <ref> [30] </ref>. 9 Conclusion and Future Work Motivated by our MyView system we assume that all document repositories support at least a Boolean query language. Boolean query interfaces are in fact the workhorse of many commercial and high-performance applications like on-line library catalogues.
References-found: 30

