URL: ftp://ftp.cse.ucsc.edu/pub/protein/dirichlet/ismb93.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/compbio/sam.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: mpbrown@cse.ucsc.edu  rph@cse.ucsc.edu  krogh@nordig.ei.dth.dk  saira@fangio.ucsc.edu  kimmen@cse.ucsc.edu  haussler@cse.ucsc.edu  
Title: Using Dirichlet Mixture Priors to Derive Hidden Markov Models for Protein Families  
Author: Michael Brown Richard Hughey Anders Krogh I. Saira Mian Kimmen Sjolander David Haussler 
Address: Santa Cruz, CA 95064  Santa Cruz, CA 95064  2800 Lyngby, Denmark  Santa Cruz, CA 95064  Santa Cruz, CA 95064  Santa Cruz, CA 95064  
Affiliation: Computer Science University of California  Computer Engineering University of California  Electronics Institute, Build. 349 Technical University of Denmark  Sinsheimer Laboratories University of California  Computer Science University of California  Computer Science University of California  
Abstract: A Bayesian method for estimating the amino acid distributions in the states of a hidden Markov model (HMM) for a protein family or the columns of a multiple alignment of that family is introduced. This method uses Dirichlet mixture densities as priors over amino acid distributions. These mixture densities are determined from examination of previously constructed HMMs or multiple alignments. It is shown that this Bayesian method can improve the quality of HMMs produced from small training sets. Specific experiments on the EF-hand motif are reported, for which these priors are shown to produce HMMs with higher likelihood on unseen data, and fewer false positives and false negatives in a database search task. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Antoniak, C. </author> <year> 1974. </year> <title> Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. </title> <journal> Annals of Statistics 2 </journal> <pages> 1152-1174. </pages>
Reference-contexts: Additionally, databases can be searched with the model built from a small training data set to find new members of the family, increasing the size of the training set. In this paper, we introduce Dirichlet mixture densities <ref> ( Antoniak, 1974 ) </ref> as a means of representing prior information about typical amino acid distributions. A related use of mixture priors, in this case Gaussian mix ture priors used in the context of neural net training, was given in ( Nowlan and Hinton, 1992 ) .
Reference: <author> Baldi, P. and Chauvin, Y. </author> <year> 1994. </year> <title> Smooth on-line learning algorithms for hidden Markov models. </title> <booktitle> Neural Computation 6(2) </booktitle> <pages> 305-316. </pages>
Reference: <author> Baldi, P.; Chauvin, Y.; Hunkapiller, T.; and McClure, M. A. </author> <year> 1992. </year> <title> Adaptive algorithms for modeling and analysis of biological primary sequence information. </title> <type> Technical report, </type> <institution> Net-ID, Inc., </institution> <type> 8 Cathy Place, </type> <address> Menlo Park, CA 94305. </address>
Reference: <author> Barioch, A. and Boeckmann, B. </author> <year> 1991. </year> <journal> Nucleic Acids Research 19 </journal> <pages> 2247-2249. </pages>
Reference-contexts: M. Quinn ( 1991 ) . This set is biased towards sequences from vertebrates and higher eucaryotes but includes some from lower eucaryotes. There are only two kinases encoded by viral genomes. Training data for the globin alignment consisted of all globins from the SWISS-PROT database, release 22 <ref> ( Barioch and Boeckmann, 1991 ) </ref> . Elongation factor sequences were drawn from the SWISS-PROT database, releases 22 and 23. Multiple alignments for these sequences were produced by HMMs we built for these families, as described in ( Krogh et al., 1994; Hughey, 1993 ) .
Reference: <author> Barton, G. J. and Sternberg, M. J. </author> <year> 1990. </year> <title> Flexible protein sequence patterns: A sensitive method to detect weak structural similarities. </title> <journal> Journal of Molecular Biology 212(2) </journal> <pages> 389-402. </pages>
Reference: <author> Berger, J. </author> <year> 1985. </year> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Bowie, J. U.; Luthy, R.; and Eisenberg, D. </author> <year> 1991. </year> <title> A method to identify protein sequences that fold into a known three-dimensional structure. </title> <booktitle> Science 253 </booktitle> <pages> 164-170. </pages>
Reference-contexts: In several cases, the amino acid distributions we find are easily identified as typifying some commonly found distribution (e.g., a large non-polar), but we do not set out a priori to find distributions representing these structures. 1 In more recent work, they have used 18 different distributions <ref> ( Bowie et al., 1991 ) </ref> . For a review of the essentials of the HMM methodology we use, including architecture, parameter estimation, multiple alignments, and database searches, see ( Krogh et al., 1994 ) .
Reference: <author> Brown, M. P.; Hughey, R.; Krogh, A.; Mian, I. S.; Sjolander, K.; and Haussler, D. </author> <year> 1993. </year> <title> Dirichlet mixture priors for HMMs. </title> <note> In preparation. </note>
Reference-contexts: We have modified their procedure to estimate a mixture of Dirichlet rather than Gaussian densities. The mathematical details of this will be described in a separate paper <ref> ( Brown et al., 1993 ) </ref> . sity over the possible actual distributions ~p in the new protein family being modeled. <p> The latter estimates will differ from the maximum likelihood estimates, and should be much better when n is small. It is straightforward to derive the formulas for these Bayes estimates, assuming a Dirichlet mixture prior <ref> ( Brown et al., 1993 ) </ref> . In the first case, for each j between 1 and k, we want to calculate Prob (jj~n), the posterior probability that the underlying probability distribution ~p that produced the observed counts ~n was chosen from the j th component of the Dirichlet mixture.
Reference: <author> Churchill, G. A. </author> <year> 1989. </year> <title> Stochastic models for heterogeneous DNA sequences. </title> <journal> Bull Math Biol 51 </journal> <pages> 79-94. </pages>
Reference: <author> Dayhoff, M. O.; Schwartz, R. M.; and Orcutt, B. C. </author> <year> 1978. </year> <title> A model of evolutionary change in proteins. In Atlas of Protein Sequence and Structure. </title> <booktitle> National Biomedical Research Foundation, </booktitle> <address> Washington, D. C. </address> <note> chapter 22, 345-358. </note>
Reference-contexts: By combining these counts with prior information from the Dirichlet densities, better estimates of the p i parameters can be obtained. In this sense the Dirichlet mixture prior provides an alternative to the use of the Dayhoff matrix <ref> ( Dayhoff et al., 1978 ) </ref> , and other means of "smoothing" probability estimates based on a few occurrences of amino acids. Once we have estimated the parameters of a Dirich-let mixture, these issues can all be addressed in a purely statistical manner.
Reference: <author> Duda, R. O. and Hart, P. E. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Fasman, G. </author> <year> 1989. </year> <title> Prediction of protein structure and the principles of protein conformation. </title> <publisher> Plenum Press, </publisher> <address> New York. </address>
Reference: <author> Gribskov, M.; Luthy, R.; and Eisenberg, D. </author> <year> 1990. </year> <title> Profile analysis. </title> <booktitle> Methods in Enzymology 183 </booktitle> <pages> 146-159. </pages>
Reference: <author> Hanks, S. K. and Quinn, A. M. </author> <year> 1991. </year> <title> Protein kinase catalytic domain sequence database: identification of conserved features of primary structure and classification of family members. </title> <booktitle> Methods in Enzymology 200 </booktitle> <pages> 38-62. </pages>
Reference: <author> Haussler, D.; Krogh, A.; Mian, I. S.; and Sjolander, K. </author> <year> 1993. </year> <title> Protein modeling using hidden Markov models: Analysis of globins. </title> <booktitle> In Proceedings of the Hawaii International Conference on System Sciences, </booktitle> <volume> volume 1, </volume> <publisher> Los Alamitos, </publisher> <address> CA. </address> <publisher> IEEE Computer Society Press. </publisher> <pages> 792-802. </pages>
Reference: <author> Hughey, Richard 1993. </author> <title> Massively parallel biosequence analysis. </title> <type> Technical Report UCSC-CRL-93-14, </type> <institution> University of California, </institution> <address> Santa Cruz, CA. </address>
Reference: <author> Hunter, L. </author> <year> 1987. </year> <title> Representing Amino Acids with Bit-strings. </title> <publisher> Benjamin/Cummings Pub. Co., </publisher> <address> Menlo Park, Cal-ifornia. </address>
Reference-contexts: Each characteristic is defined by a numerical value for all residues, then these are averaged with respect to the distribution, and finally the background average is subtracted. Definitions of the numerical scores are taken from ( Fas-man, 1989 ) (Hydrophobicity, Standard-state accessibility, Average accessible area), <ref> ( Hunter, 1987 ) </ref> (Molecular Weight), and ( King and Sternberg, 1990 ) (Polar, Charged, Positively and Negatively Charged). demonstrate the ability of mixture-priors to compensate for limited sample sizes because the motif's small size allowed many experiments to be performed relatively rapidly.
Reference: <author> K. Asai and S. Hayamizu and K. Onizuka, </author> <year> 1993. </year> <title> HMM with protein structure grammar. </title> <booktitle> In Proceedings of the Hawaii International Conference on System Sciences, </booktitle> <address> Los Alamitos, CA. </address> <publisher> IEEE Computer Society Press. </publisher> <pages> 783-791. </pages>
Reference: <author> King, R. D. and Sternberg, M. J. </author> <year> 1990. </year> <title> Machine learning approach for the prediction of protein secondary structure. </title> <journal> Journal of Molecular Biology 216 </journal> <pages> 441-457. </pages>
Reference-contexts: Definitions of the numerical scores are taken from ( Fas-man, 1989 ) (Hydrophobicity, Standard-state accessibility, Average accessible area), ( Hunter, 1987 ) (Molecular Weight), and <ref> ( King and Sternberg, 1990 ) </ref> (Polar, Charged, Positively and Negatively Charged). demonstrate the ability of mixture-priors to compensate for limited sample sizes because the motif's small size allowed many experiments to be performed relatively rapidly. Furthermore, a large number of EF-hand motif sequences are available.
Reference: <author> Krogh, A.; Brown, M.; Mian, I. S.; Sjolander, K.; and Haussler, D. </author> <year> 1994. </year> <title> Hidden Markov models in computational biology: Applications to protein modeling. </title> <journal> Journal of Molecular Biology 235 </journal> <pages> 1501-1531. </pages>
Reference-contexts: For a review of the essentials of the HMM methodology we use, including architecture, parameter estimation, multiple alignments, and database searches, see <ref> ( Krogh et al., 1994 ) </ref> . Modeling amino acid distributions with Dirichlet mixtures Examining the columns in a large multiple alignment of a homologous set of protein sequences, we see a variety of distributions of amino acids. <p> For other sample sizes we performed five repetitions. separate test set containing EF-hand sequences not in the training set, yielding an average negative log likelihood (NLL) score over all test sequences for each model <ref> ( Krogh et al., 1994 ) </ref> . Lower scores represent more accurate models. For every combination of training sample size and prior used, we took the average test-set NLL-score across all models, and the standard deviation of the test-set NLL-scores. <p> For each sample size and prior, we built an HMM as above and then used it to search the SWISS-PROT database for sequences that contain the EF-hand motif, using the method described in <ref> ( Krogh et al., 1994 ) </ref> . The results are given in Figure 8. The results show again that HMM9 performs better than HMM1, which performs better than Add one.
Reference: <author> Luthy, R.; McLachlan, A. D.; and Eisenberg, D. </author> <year> 1991. </year> <title> Secondary structure-based profiles: Use of structure-conserving scoring table in searching protein sequence databases for structural similarities. PROTEINS: Structure, Function, </title> <booktitle> and Genetics 10 </booktitle> <pages> 229-239. </pages>
Reference-contexts: HMM9.9 greatly emphasizes large residues aswell as aromatic, hydrophobic and uncharged residues. In addition to the priors we obtained via maximum likelihood estimation, we tested the effectiveness of some additional priors: the standard uniform prior called Add One, 4 priors obtained directly from the nine-component LME distributions <ref> ( Luthy et al., 1991 ) </ref> and a 29-component EF-hand custom prior in which each component is derived from a column in our EF-hand multiple alignment.
Reference: <author> Moncrief, N. D.; Kretsinger, R. H.; and Goodman, M. </author> <year> 1990. </year> <title> Evolution of EF-hand calcium-modulated proteins. </title>
Reference: <author> I. </author> <title> relationships based on amino acid sequences. </title> <journal> Journal of Molecular Evolution 30 </journal> <pages> 522-562. </pages>
Reference: <author> Nakayama, S.; Moncrief, N. D.; and Kretsinger, R. H. </author> <year> 1992. </year> <title> Evolution of EF-hand calcium-modulated proteins. ii. domains of several subfamilies have diverse evolutionary histories. </title> <journal> Journal of Molecular Evolution 34 </journal> <pages> 416-448. </pages>
Reference-contexts: Furthermore, a large number of EF-hand motif sequences are available. For these experiments we used the June 1992 database of EF-hand sequences maintained by Kretsinger and co-workers <ref> ( Nakayama et al., 1992 ) </ref> . Sequences in this database are proteins containing two or more copies of the EF-hand motif. We extracted the EF-hand structures from each of the 242 sequences in the database, obtaining 885 EF-hand motifs having an average length of 29.
Reference: <author> Nowlan, S. J. and Hinton, G. E. </author> <year> 1992. </year> <title> Soft weight-sharing. </title> <editor> In Moody, ; Hanson, ; and Lippmann, , editors 1992, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <address> San Mateo, CA. </address> <publisher> Morgan Kauffmann Publishers. </publisher>
Reference-contexts: In this paper, we introduce Dirichlet mixture densities ( Antoniak, 1974 ) as a means of representing prior information about typical amino acid distributions. A related use of mixture priors, in this case Gaussian mix ture priors used in the context of neural net training, was given in <ref> ( Nowlan and Hinton, 1992 ) </ref> . The Dirich-let mixtures cluster amino acid distributions into prototypical classes of distributions. Using Bayes' rule, Dirichlet mixture densities can be combined with observed frequencies of amino acids to obtain posterior estimates of amino acid distributions.
Reference: <author> Persechini, A.; Moncrief, N. D.; and Kretsinger, R. H. </author> <year> 1989. </year> <title> The EF-hand family of calcium-modulated proteins. </title> <booktitle> Trends in Neurosciences 12(11) </booktitle> <pages> 462-467. </pages>
Reference: <author> Sander, C. and Schneider, R. </author> <year> 1991. </year> <title> Database of homology-derived protein structures and the structural meaning of sequence alignment. </title> <booktitle> Proteins 9(1) </booktitle> <pages> 56-68. </pages>
Reference-contexts: Here we describe the construction of several Dirichlet mixture priors and demonstrate the effectiveness of these priors in building accurate models for the EF-hand motif. We used two sources of multiple alignments for our raw count data: alignments from the HSSP database <ref> ( Sander and Schneider, 1991 ) </ref> (Figure 1), and multiple alignments we generated using HMMs to model the ki-nase, globin and elongation factor families ( Haussler et al., 1993; Krogh et al., 1994 ) (Figure 2). <p> The HSSP database contains multiple alignments of proteins obtained by taking a single protein whose three dimensional structure is known, and aligning to it other proteins that are deemed homologous above a certain threshold to this protein but whose structure is not known. In <ref> ( Sander and Schneider, 1991 ) </ref> , a representative set of HSSP multiple alignments is suggested that includes a variety of different protein types. We used all the multiple alignments in this representative set with 30 or more sequences to obtain our HSSP count data.
Reference: <author> Santner, T. J. and Duffy, D. E. </author> <year> 1989. </year> <title> The Statistical Analysis of Discrete Data. </title> <publisher> Springer Verlag, </publisher> <address> New York. </address>
Reference: <author> Stultz, C. M.; White, J. V.; and Smith, T. F. </author> <year> 1993. </year> <title> Structural analysis based on state-space modeling. </title> <booktitle> Protein Science 2 </booktitle> <pages> 305-315. </pages>
Reference: <author> Taylor, W. R. </author> <year> 1986. </year> <title> The classification of amino acid conservation. </title> <journal> Journal of Theoretical Biology 119 </journal> <pages> 205-218. </pages>
Reference: <author> Waterman, M. S. and Perlwitz, M. D. </author> <year> 1986. </year> <title> Line geometries for sequence comparisons. </title> <journal> Bull. Math. Biol. </journal> <volume> 46 </volume> <pages> 567-577. </pages>
Reference: <author> White, James V.; Stultz, Collin M.; and Smith, Temple F. </author> <year> 1994. </year> <title> Protein classification by stochastic modeling and optimal filtering of amino-acid sequences. </title> <booktitle> Mathematical Biosciences 119 </booktitle> <pages> 35-75. </pages>
References-found: 32

