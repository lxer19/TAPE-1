URL: http://www.cs.princeton.edu/prism/papers-ps/nbody-sched.ps
Refering-URL: http://www.cs.princeton.edu/prism/html/all-papers.html
Root-URL: http://www.cs.princeton.edu
Title: Load Balancing and Data Locality in Adaptive Hierarchical N-body Methods: Barnes-Hut, Fast Multipole, and Radiosity  
Author: Jaswinder Pal Singh, Chris Holt, Takashi Totsuka, Anoop Gupta and John L. Hennessy 
Address: Stanford, CA 94305  
Affiliation: Computer Systems Laboratory Stanford University  
Abstract: Hierarchical N-body methods, which are based on a fundamental insight into the nature of many physical processes, are increasingly being used to solve large-scale problems in a variety of scientific/engineering domains. Applications that use these methods are challenging to parallelize effectively, however, owing to their nonuniform, dynamically changing characteristics and their need for long-range communication. In this paper, we study the partitioning and scheduling techniques required to obtain effective parallel performance on applications that use a range of hierarchical N-body applications. To obtain representative coverage, we examine applications that use the three most promising methods used today. Two of these, the Barnes-Hut method and the Fast Multipole Method, are the best methods known for classical N-body problems (such as molecular or galactic simulations). The third is a recent hierarchical method for radiosity calculations in computer graphics, which applies the hierarchical N-body approach to a problem with very different characteristics. We find that straightforward decomposition techniques which an automatic scheduler might implement do not scale well, because they are unable to simultaneously provide load balancing and data locality. However, all the applications yield very good parallel performance if appropriate partitioning and scheduling techniques are implemented by the programmer. For the Barnes-Hut and Fast Multipole applications, we show that simple yet effective partitioning techniques can be developed by exploiting some key insights into both the solution methods and the classical problems that they solve. Using a novel partitioning technique, even relatively small problems achieve 45-fold speedups on a 48-processor Stanford DASH machine (a cache-coherent, shared address space multiprocessor) and 118-fold speedups on a 128-processor simulated architecture. The very different characteristics of the radiosity application require a different partitioning/scheduling approach to be used for it; however, it too yields very good parallel performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.J. Aarseth, M. Henon, and R. Wielen. </author> <title> Astronomy and Astrophysics, </title> <type> 37, </type> <year> 1974. </year>
Reference-contexts: The input distribution that we use in our experiments comprises two Plummer model <ref> [1] </ref> galaxies, slightly offset from each other in each of the three Cartesian directions. The Plummer model is an empirical model of galactic clusters. The density of a cluster is very large near the center and diminishes with distance from the center. 8.4.1 Speedups simulator with infinite caches.
Reference: [2] <author> Andrew A. Appel. </author> <title> An efficient program for many body simulation. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 6 </volume> <pages> 85-93, </pages> <year> 1985. </year>
Reference-contexts: For examples, if all pairwise interactions are computed directly, the complexity of computing interactions is O (n 2 ), which is prohibitive for large systems. Hierarchical tree-based methods have therefore been developed that reduce the complexity to O (n log n) for general distributions <ref> [2, 3] </ref>, or even O (n) for uniform distributions [15], without losing much accuracy in long-range interactions. <p> The hierarchical application Particle Large group not far enough away Small group far enough away Large group far enough away of this insight|first used by Appel <ref> [2] </ref> in 1985|implies that the farther away the particles, the larger the group that can be approximated by a single particle (see Figure 2). Although Newton arrived at his powerful insight in the context of gravitation, hierarchical N-body methods based on it have found increasing applicability in various problem domains. <p> The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2).
Reference: [3] <author> Joshua E. Barnes and Piet Hut. </author> <title> A hierarchical O(N log N) force calculation algorithm. </title> <journal> Nature, </journal> <volume> 324(4) </volume> <pages> 446-449, </pages> <year> 1986. </year>
Reference-contexts: In this paper, we study partitioning and scheduling issues in representative applications that use three important hierarchical N-body methods. Two of these methods|the Barnes-Hut method <ref> [3] </ref> and Greengard and Rokhlin's Fast Multipole Method (FMM) [15]|are the best methods known for classical N-body problems, such as those in astrophysics, electrostatics and molecular dynamics. <p> For examples, if all pairwise interactions are computed directly, the complexity of computing interactions is O (n 2 ), which is prohibitive for large systems. Hierarchical tree-based methods have therefore been developed that reduce the complexity to O (n log n) for general distributions <ref> [2, 3] </ref>, or even O (n) for uniform distributions [15], without losing much accuracy in long-range interactions. <p> The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2). <p> Several hierarchical methods have been proposed to solve classical N-body problems [2, 18, 3, 15, 29, 7]. The most widely used and promising among these are the Barnes-Hut method <ref> [3] </ref> and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2). By using these methods to solve our galactic problem, we therefore obtain good coverage of hierarchical methods for classical problems.
Reference: [4] <author> Richard P. Brent. </author> <title> Algorithms for Minimization Without Derivatives. </title> <publisher> Prentice-Hall, </publisher> <year> 1973. </year>
Reference-contexts: We experimented with different root finding algorithms for discrete functions, such as the bisection and Van Wijngaarden-Dekker-Brent algorithms described in <ref> [9, 4] </ref>. The best performance we obtained was from a decisection algorithm (similar to bisection, except that the currently guessed domain is split into 10 equal subdomains rather than 2 at every step in the root-finder).
Reference: [5] <author> Tony Chan. </author> <title> Hierarchical algorithms and architectures for parallel scientific computing. </title> <booktitle> In Proceedings of ACM Conference on Supercomputing, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Hierarchical algorithms exploit the range of spatial scales to efficiently propagate global information through the domain. Prominent 2 among these algorithms are N-body methods, multigrid methods, domain decomposition methods, multi-level preconditioners, adaptive mesh-refinement algorithms, and wavelet basis methods <ref> [5] </ref>. Our focus in this paper is on hierarchical N-body methods.
Reference: [6] <author> A. J. Chorin. </author> <title> Numerical study of slightly viscous flow. </title> <journal> Journal of Fluid Mechanics, </journal> <volume> 57 </volume> <pages> 785-796, </pages> <year> 1973. </year>
Reference-contexts: The simulation of polar fluids, however, introduces a Coulombic interaction term as well, so that long-range interactions must be considered to study some important properties (such as dielectric properties, for example). 4. Fluid Dynamics: The vortex blob method <ref> [6] </ref> for solving the Navier-Stokes equations requires the inter actions among N vortex blobs, where the long-range interaction law is Coulombic. 5.
Reference: [7] <author> K. Chua, A. Leonard, F. Pepin, and G. Winckelmans. </author> <title> Robust vortex methods for three-dimensional incompressible flows. </title> <booktitle> In Proceedings of Symposium on Recent Advances in Computational Fluid Dynamics, </booktitle> <year> 1988. </year>
Reference-contexts: The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2).
Reference: [8] <author> M.F. Cohen and D.P. Greenberg. </author> <title> The hemi-cube: A radiosity solution for complex environments. </title> <booktitle> In Proceedings of SIGGRAPH, </booktitle> <year> 1985. </year>
Reference-contexts: Clearly, both the Barnes-Hut and FMM applications afford abundant parallelism. 4.2 The Radiosity Application Computing the global illumination in a scene is a critical problem in computer graphics. The two dominant, and very different, approaches to solving this problem are the ray-tracing and radiosity methods. The radiosity method <ref> [8] </ref>, which is view-independent and based on the physics of light transport, has been most successful in producing realistic computer-generated images of complex scenes.
Reference: [9] <editor> William Press et al. Numerical Recipes in C. </editor> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: We experimented with different root finding algorithms for discrete functions, such as the bisection and Van Wijngaarden-Dekker-Brent algorithms described in <ref> [9, 4] </ref>. The best performance we obtained was from a decisection algorithm (similar to bisection, except that the currently guessed domain is split into 10 equal subdomains rather than 2 at every step in the root-finder).
Reference: [10] <author> Geoffrey C. Fox. </author> <title> Numerical Algorithms for Modern Parallel Computer Architectures, chapter A Graphical Approach to Load Balancing and Sparse Matrix Vector Multiplication on the Hypercube, </title> <address> pages 37-62. </address> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: use the work-counting mechanism of the previous subsection for load balancing, but they differ in the approach they take to providing physical locality. 8.3.1 Partitioning Space: Orthogonal Recursive Bisection Orthogonal Recursive Bisection (ORB) is a technique for providing physical locality in a problem domain by explicitly partitioning the domain space <ref> [10] </ref>. It was first used for hierarchical N-body problems in Salmon's message-passing Barnes-Hut implementation [23].
Reference: [11] <author> Henry Fuchs, Gregory D. Abram, and Eric D. Grant. </author> <title> Near real-time shaded display of rigid objects. </title> <booktitle> In Proceedings of SIGGRAPH, </booktitle> <year> 1983. </year>
Reference-contexts: The input polygons that comprise the scene are first inserted into a binary space partitioning (BSP) tree <ref> [11] </ref> to facilitate efficient visibility computation between a pair of patches. (The BSP tree and its use in visibility computation are described in Appendix A).
Reference: [12] <author> Aaron J. Goldberg and John L. Hennessy. </author> <title> Performance debugging shared memory multiprocessor programs with MTOOL. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <pages> pages 481-490, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: In addition to speedups, we also present results that separately compare the load balancing and communication behavior of different schemes. These results are obtained on the simulator, and we have corroborated their trends with the MTOOL <ref> [12] </ref> performance debugger on DASH. We compare load balancing behavior by measuring the time that processes spend waiting at synchronization points. <p> The scheme that incorporates patch stealing is called cost-estimates+patch-steal (C+PS) 20 . Figure 25 shows that the incorporation of patch stealing makes a dramatic difference to parallel performance and provides very good speedups. Measurements obtained with the MTOOL performance debugger <ref> [12] </ref> on DASH (Figure 27) show that the techniques used to maintain locality while stealing cause the stealing to contribute no appreciable increase in memory referencing overhead for these numbers of processors (16, in the figures).
Reference: [13] <author> Stephen R. Goldschmidt and Helen Davis. </author> <title> Tango introduction and tutorial. </title> <type> Technical Report CSL-TR-90-410, </type> <institution> Stanford University, </institution> <year> 1990. </year> <month> 35 </month>
Reference-contexts: To overcome these limitations, we also perform experiments on an event-driven simulator of an idealized shared-address-space multiprocessor <ref> [13] </ref>. The simulated multiprocessor looks exactly like that described in Figure 10, with the simple, three-level, nonuniform memory hierarchy. The timing of a simulated processor's instruction set is designed to match that of the MIPS R3000 CPU and R3010 floating point unit.
Reference: [14] <author> Leslie Greengard. </author> <title> The Rapid Evaluation of Potential Fields in Particle Systems. </title> <publisher> ACM Press, </publisher> <year> 1987. </year>
Reference-contexts: Although Newton arrived at his powerful insight in the context of gravitation, hierarchical N-body methods based on it have found increasing applicability in various problem domains. To demonstrate the wide-ranging applicability of these methods and their consequent importance for high-performance computing, we list some of the problem domains below <ref> [14] </ref>: 1. Astrophysics: The bodies in the system are stars or planets in a galaxy, and the governing interaction law is gravitational. 2. <p> We use the adaptive FMM in this paper. * While the mathematics of the Barnes-Hut algorithm are the same in three dimensions as they are in two, the FMM uses a different, more complex mathematical foundation in three dimensions <ref> [14] </ref>. The new mathematics substantially increases the constant factors in the time-complexity expression, so that the three-dimensional FMM is far more expensive than the two-dimensional FMM. The structures of the two-and three-dimensional algorithms are the same, however, as are the issues in parallelization. <p> The efficiency of the FMM is improved by allowing a larger maximum number of particles per leaf cell in the tree than the single particle allowed in the original Barnes-Hut method. We allow a maximum of 40 particles per leaf cell, as Greengard suggests <ref> [14] </ref>, unless otherwise mentioned. Thus, both the leaves and the internal nodes of the tree represent space cells in the FMM, with the leaves directly containing particles. <p> Interactions with these distant cells are accounted for by C's ancestors at higher levels of the tree. Details of the different types of interactions, beyond those indicated in Figure 7, are not important for our purposes and can be found in <ref> [14] </ref>. What is relevant is that the types of interactions computed with cells in different lists are different. c U U V V V V V W W W X X X U W List V (all cells): Children of the colleagues of C's parent that are well-separated from C. <p> As in the Barnes-Hut application, the complexities of the tree-building phase and the upward pass are O (n log n) and O (n), respectively. We show in [24] that the asymptotic complexity of the list interaction phases is not as simple as the O (m 3 n) claimed in <ref> [14] </ref>, where m is the number of terms used in the multipole and local expansions. If the analysis in [14] is performed correctly, the complexity is O (pm 2 n), where p is the number of levels in the tree. <p> We show in [24] that the asymptotic complexity of the list interaction phases is not as simple as the O (m 3 n) claimed in <ref> [14] </ref>, where m is the number of terms used in the multipole and local expansions. If the analysis in [14] is performed correctly, the complexity is O (pm 2 n), where p is the number of levels in the tree. <p> On the simulator, we were not able to run problems with more than 8K particles and a precision of 10 6 in a reasonable amount of time. With the 40 particles per leaf cell that we use on DASH and that Greengard recommends (see Section 4.1.2 and <ref> [14] </ref>), this leads to a very small number of cells and hence to large load imbalances. We therefore allow a maximum of 5 particles per leaf cell on the simulator, to obtain more cells and hence more concurrency.
Reference: [15] <author> Leslie Greengard and Vladimir Rokhlin. </author> <title> A fast algorithm for particle simulation. </title> <journal> Journal of Computational Physics, </journal> <volume> 73(325), </volume> <year> 1987. </year>
Reference-contexts: Hierarchical tree-based methods have therefore been developed that reduce the complexity to O (n log n) for general distributions [2, 3], or even O (n) for uniform distributions <ref> [15] </ref>, without losing much accuracy in long-range interactions. <p> The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2). <p> Several hierarchical methods have been proposed to solve classical N-body problems [2, 18, 3, 15, 29, 7]. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method <ref> [15] </ref>. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2). By using these methods to solve our galactic problem, we therefore obtain good coverage of hierarchical methods for classical problems.
Reference: [16] <author> P. Hanrahan, D. Salzman, and L. Aupperle. </author> <title> A rapid hierarchical radiosity algorithm. </title> <booktitle> In Proceedings of SIGGRAPH, </booktitle> <year> 1991. </year>
Reference-contexts: In addition to classical problems, the hierarchical 1 N-body approach has recently been applied with great success to many different domains, including a problem with very different characteristics: radiosity calculations for global illumination in computer graphics <ref> [16] </ref>. This constitutes our third application, and we believe the three together provide adequate coverage of the use of the hierarchical N-body approach today. <p> Computer Graphics: The dominant computation in solving global illumination problems with radiosity techniques has been the O (n 2 ) computation of the light transport between all pairs of elements that the scene is decomposed into. A recent algorithm <ref> [16] </ref>, which we study in this paper, uses a hierarchical N-body technique to compute these interactions in O (n) time. 3 Choice of Applications In this section, we discuss the problems and solution methods we choose to study in this paper, and the coverage of hierarchical N-body methods that they provide. <p> These differences are what cause very different partitioning/scheduling techniques to be required for the radiosity application, as we shall see. 4 We sometimes use the term patch to include leaf-level elements in our description of the algorithm. 10 4.2.1 The Sequential Algorithm The hierarchical radiosity <ref> [16] </ref> algorithm proceeds as follows. The input polygons that comprise the scene are first inserted into a binary space partitioning (BSP) tree [11] to facilitate efficient visibility computation between a pair of patches. (The BSP tree and its use in visibility computation are described in Appendix A). <p> Speedups for these schemes on the DASH multiprocessor (as well for several other schemes which we will describe) are shown in Figure 25. The input is a room scene used in the paper that presented the sequential algorithm <ref> [16] </ref>. The speedup with the static scheme saturates at about 4 processors, and with the single-queue-polygon scheme at about 10 processors. In the case of single-queue-polygon, the reason for the saturation is that the granularity of a task (a polygon-polygon interaction) is very large compared to the number of tasks.
Reference: [17] <author> Lars Hernquist. </author> <title> Hierarchical N-body methods. </title> <journal> Computer Physics Communications, </journal> <volume> 48 </volume> <pages> 107-115, </pages> <year> 1988. </year>
Reference-contexts: In this way, a particle traverses more levels of those parts of the tree which represent space that is physically close to it, and groups particles at a hierarchy of length scales. The complexity of the force-computation phase scales as 1 2 log n for realistic values of <ref> [17] </ref>. The Available Parallelism Each of the phases in a time-step can be executed internally in parallel.
Reference: [18] <author> J.G. Jernigan and D.H. Porter. </author> <title> A tree code with logarithmic reduction of force terms, hierarchical regularization of all variables and explicit accuracy controls. </title> <journal> Astrophysics Journal Supplement, </journal> <pages> page 871, </pages> <year> 1989. </year>
Reference-contexts: The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2).
Reference: [19] <author> Jacob Katzenelson. </author> <title> Computational structure of the N-body problem. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 10(4) </volume> <pages> 787-815, </pages> <year> 1989. </year>
Reference-contexts: Cell D is well-separated from cell C, but cell C is not well separated from cell D. In fact, both the FMM and the Barnes-Hut method have been shown to satisfy the same recursive set of equations, only using different elementary functions <ref> [19] </ref>. The primary differences between the two methods are: * While the Barnes-Hut method directly computes only particle-particle or particle-cell interactions, the FMM also computes interactions between internal cells directly.
Reference: [20] <author> Dan Lenoski, James Laudon, Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> The directory-based cache coherence protocol for the DASH multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Caches are kept coherent by a hardware mechanism. We use two instantiations of this generalized multiprocessor in our experiments: the Stanford DASH Multiprocessor|a high-performance research machine|and a simulated multiprocessor. Processor Interconnection Network Memory Cache Processor Memory Cache The Stanford DASH Multiprocessor The DASH machine <ref> [20] </ref> has 48 processors organized in 12 clusters. 6 A cluster comprises 4 MIPS R3000 processors connected by a shared bus, and clusters are connected together in a mesh network.
Reference: [21] <author> Vladimir Rokhlin. </author> <title> Rapid solution of integral equations of classical potential theory. </title> <journal> Journal of Computational Physics, </journal> <volume> 60 </volume> <pages> 187-207, </pages> <year> 1985. </year>
Reference-contexts: Boundary Value Problems: Integral equations resulting from boundary value problems can be solved rapidly by N-body methods, where N is the number of nodes in the discretization of the boundary <ref> [21] </ref>. 6. Numerical Complex Analysis: Many problems in this field can be reduced to computing a Cauchy integral, which can itself be viewed as equivalent to an electrostatic problem. 7.
Reference: [22] <author> Ed Rothberg, Jaswinder Pal Singh, and Anoop Gupta. </author> <title> Working sets, cache sizes and node granularity issues for large-scale multiprocessors. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Infinite caches do not capture this effect. However, this is not a very significant issue in our applications since the important working sets are small <ref> [22] </ref>. Besides, infinite caches are better at measuring inherent communication, which is what we want to compare using the simulator. 15 7.2 Organization of Experiments For each application, we first examine approaches that are conceptually obvious and very easy for a programmer to implement.
Reference: [23] <author> John K. Salmon. </author> <title> Parallel Hierarchical N-body Methods. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: However, all the applications can be made to yield excellent and scalable parallel performance if more sophisticated techniques are implemented by the programmer. The only other parallel version of a nonuniform hierarchical N-body application is a message-passing implementation of an astrophysical Barnes-Hut application <ref> [23] </ref>. It uses an orthogonal recursive bisection (ORB) partitioning technique to obtain both load balancing and data locality. (It is also substantially complicated by the lack of a shared-address-space programming model [28]). We propose a new partitioning technique called costzones for the classical applications. <p> The primary differences between the two methods are: * While the Barnes-Hut method directly computes only particle-particle or particle-cell interactions, the FMM also computes interactions between internal cells directly. This is one of the key distinguishing features among hierarchical N-body methods <ref> [23] </ref>, and it is the direct computation of cell-cell interactions that makes the force-computation phase in the FMM O (n) rather than O (n log n) for uniform particle distributions. 2 It is possible to exploit fine-grained dependence information and replace global inter-phase synchronization by finer-grained (cell- or particle-level) synchronization. <p> In the Barnes-Hut application, a good measure of a particle's cost is simply the number of interactions (with other particles or cells) required to compute the net force on that particle. This measure of cost is used by both Salmon <ref> [23] </ref> and us. The programming and runtime overheads of counting interactions are negligible: A process simply increments a per-particle counter every time it computes an interaction. As we shall see, this work-counting technique is very effective. <p> It was first used for hierarchical N-body problems in Salmon's message-passing Barnes-Hut implementation <ref> [23] </ref>. <p> A more detailed description of an ORB implementation for the Barnes-Hut problem can be found in <ref> [23] </ref>. High-level pseudocode describing the algorithm is shown in Figure 12. ORB introduces several new data structures, including a binary ORB tree that is distinct from the Barnes-Hut tree.
Reference: [24] <author> Jaswinder Pal Singh. </author> <title> Parallel Hierarchical N-body Methods and their Implications for Multiprocessors. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Building the tree and updating the particle properties take less than 1% of the time in sequential implementations. As in the Barnes-Hut application, the complexities of the tree-building phase and the upward pass are O (n log n) and O (n), respectively. We show in <ref> [24] </ref> that the asymptotic complexity of the list interaction phases is not as simple as the O (m 3 n) claimed in [14], where m is the number of terms used in the multipole and local expansions. <p> data appropriately in physically distributed main memory in this paper, primarily because this is both very difficult to do for these applications and because experiments we have performed show that the important form of locality is reuse or temporal locality, and that data distribution does not help performance very significantly <ref> [24] </ref>. Despite our focus on communication, however, we do make all reasonable efforts to exploit locality within a node effectively. Since there is often a tension between load balancing and data locality, effective partitioning and scheduling techniques must strive to find a good compromise between these goals. <p> This is particularly true since the number of particles is not expected to scale linearly with the number of processors <ref> [27, 24] </ref>. Besides performance benefits on large machines, physically contiguous partitions have other important advantages as well. They allow us to use a more efficient tree-building algorithm, as we shall see later in this section, which helps alleviate an important performance bottleneck as the number of processors grows. <p> A lack of physical contiguity also increases the working set size in the force computation phase, and has important implications for the programming complexity and sizes of problems that can be run on message-passing machines <ref> [28, 24] </ref>. The Spacelocality Scheme: Incorporating physical locality with a static notion of load balancing does indeed lead to dramatically better communication behavior in the spacelocality scheme (see Figure 18 (b)). <p> The result is that the hierarchical radiosity application also yields good parallel performance that is likely to scale to large numbers of processors. 21 If it knew the appropriate parallelism, which we believe would be impossible for today's compiler technology to find. 34 In another paper <ref> [28, 24] </ref>, we show that the nonuniform, dynamically changing nature of problems that hierarchical N-body methods are applied to, together with their need for long-range communication in the physical domain, cause multiprocessors that support a shared address space as the communication abstraction to have substantial advantages in design and programming complexity
Reference: [25] <author> Jaswinder Pal Singh and John L. Hennessy. </author> <title> High Performance Computing II, chapter Data Locality and Memory System Performance in the Parallel Simulation of Ocean Eddy Currents, </title> <address> pages 43-58. </address> <publisher> North-Holland, </publisher> <year> 1991. </year> <note> Also Stanford University Tech. Report No. CSL-TR-91-490. </note>
Reference-contexts: Both of these are schemes that a compiler or automatic scheduler might implement. Static approaches are appropriate for many scientific applications, in which the work per iteration in parallel loops is uniform and locality in iteration space translates naturally to the desired locality in the problem domain <ref> [25, 26] </ref>. 11 In our hierarchical N-body applications, however, the static scheme described above neither guarantees load balancing nor provides data locality. The load imbalance results from the fact that an equal number of particles does not imply an equal amount of work.
Reference: [26] <author> Jaswinder Pal Singh and John L. Hennessy. </author> <title> Parallelism, locality and scaling in a molecular dynamics simulation. </title> <note> To appear as Stanford University Technical Report, </note> <year> 1992. </year>
Reference-contexts: Both of these are schemes that a compiler or automatic scheduler might implement. Static approaches are appropriate for many scientific applications, in which the work per iteration in parallel loops is uniform and locality in iteration space translates naturally to the desired locality in the problem domain <ref> [25, 26] </ref>. 11 In our hierarchical N-body applications, however, the static scheme described above neither guarantees load balancing nor provides data locality. The load imbalance results from the fact that an equal number of particles does not imply an equal amount of work. <p> how we obtain load balancing by determining the work associated with a particle. 11 This is true of some uniform N-body applications as well, particularly those that use a fixed cutoff radius in computing interactions and a spatial directory to efficiently find the particles that are within the cutoff radius <ref> [26] </ref>. 16 There are three problems associated with load balancing in the Barnes-Hut application. First, the relative distribution of work among particles is not the same across the phases of computation (tree-building, force calculation, update, etc.). Different phases might therefore have different preferred partitions.
Reference: [27] <author> Jaswinder Pal Singh, John L. Hennessy, and Anoop Gupta. </author> <title> Scaling parallel programs for multiprocessors: Methodology and examples. </title> <journal> IEEE Computer. </journal> <note> To appear. Also available as Stanford Univeristy Tech. Report no. CSL-TR-92-541, </note> <year> 1992. </year>
Reference-contexts: This is particularly true since the number of particles is not expected to scale linearly with the number of processors <ref> [27, 24] </ref>. Besides performance benefits on large machines, physically contiguous partitions have other important advantages as well. They allow us to use a more efficient tree-building algorithm, as we shall see later in this section, which helps alleviate an important performance bottleneck as the number of processors grows.
Reference: [28] <author> Jaswinder Pal Singh, John L. Hennessy, and Anoop Gupta. </author> <title> Implications of hierarchical N-body techniques for multiprocessor architecture. </title> <type> Technical Report CSL-TR-92-506, </type> <institution> Stanford University, </institution> <year> 1992. </year>
Reference-contexts: It uses an orthogonal recursive bisection (ORB) partitioning technique to obtain both load balancing and data locality. (It is also substantially complicated by the lack of a shared-address-space programming model <ref> [28] </ref>). We propose a new partitioning technique called costzones for the classical applications. Costzones is much simpler to implement than ORB, and performs better on shared address space machines, particularly as the number of processors increases. <p> Thus, our measurement environment essentially eliminates all misses other than those due to inherent communication (other artifactual sources of communication in a multiprocessor, such as data placement in distributed main memory, are not significant either after the cold-start period with infinite caches in these applications <ref> [28] </ref>). Our metric for comparing inherent communication in this environment is the average number of cache misses per 1000 processor busy cycles. One implication of our use of infinite caches is that performance results obtained with the simulator may be biased in favor of partitioning schemes with poor locality characteristics. <p> A lack of physical contiguity also increases the working set size in the force computation phase, and has important implications for the programming complexity and sizes of problems that can be run on message-passing machines <ref> [28, 24] </ref>. The Spacelocality Scheme: Incorporating physical locality with a static notion of load balancing does indeed lead to dramatically better communication behavior in the spacelocality scheme (see Figure 18 (b)). <p> The result is that the hierarchical radiosity application also yields good parallel performance that is likely to scale to large numbers of processors. 21 If it knew the appropriate parallelism, which we believe would be impossible for today's compiler technology to find. 34 In another paper <ref> [28, 24] </ref>, we show that the nonuniform, dynamically changing nature of problems that hierarchical N-body methods are applied to, together with their need for long-range communication in the physical domain, cause multiprocessors that support a shared address space as the communication abstraction to have substantial advantages in design and programming complexity
Reference: [29] <author> Feng Zhao. </author> <title> An O(n) algorithm for three-dimensional N-body simulations. </title> <type> Technical Report 995, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1987. </year> <month> 36 </month>
Reference-contexts: The simulation of galaxies under gravitational force laws is the domain that hierarchical methods have been used most widely in so far, and we use it as being representative of nonuniform classical domains. Several hierarchical methods have been proposed to solve classical N-body problems <ref> [2, 18, 3, 15, 29, 7] </ref>. The most widely used and promising among these are the Barnes-Hut method [3] and the Fast Multipole Method [15]. Between them, these two methods also capture all the important characteristics of hierarchical methods for classical N-body problems (see Section 4.1.2).
References-found: 29

