URL: http://www.cs.umd.edu/users/franklin/papers/finegr.ps.gz
Refering-URL: http://www.cs.umd.edu/class/fall97/cmsc724-f97/readings.html
Root-URL: 
Email: carey@cs.wisc.edu franklin@cs.umd.edu markos@cs.wisc.edu  
Title: Fine-Grained Sharing in a Page Server OODBMS  
Author: Michael J. Carey Michael J. Franklin Markos Zaharioudakis 
Address: Madison, WI 53706 College Park, MD 20742 Madison WI 53706  
Affiliation: Computer Sciences Department Dept. of Computer Science Computer Sciences Department University of Wisconsin University of Maryland University of Wisconsin  
Abstract: For reasons of simplicity and communication efficiency, a number of existing object-oriented database management systems are based on page server architectures; data pages are their minimum unit of transfer and client caching. Despite their efficiency, page servers are often criticized as being too restrictive when it comes to concurrency, as existing systems use pages as the minimum locking unit as well. In this paper we show how to support object-level locking in a page server context. Several approaches are described, including an adaptive granularity approach that uses page-level locking for most pages but switches to object-level locking when finer-grained sharing is demanded. We study the performance of these approaches, comparing them to both a pure page server and a pure object server. For the range of workloads that we have examined, our results indicate that a page server is clearly preferable to an object server. Moreover, the adaptive page server is shown to provide very good performance, generally outperforming the pure page server, the pure object server, and the other alternatives as well. 
Abstract-found: 1
Intro-found: 1
Reference: [Astr76] <author> M. Astrahan, et al., </author> <title> System R: Relational Approach to Database Management, </title> <journal> ACM TODS 1(2), </journal> <year> 1976. </year>
Reference-contexts: For example, if two objects on a given page are increased in size by concurrent updaters, it is possible that a subsequent merging of the two updates will cause the page to overflow. Overflow can be handled using a standard forwarding technique a la <ref> [Astr76] </ref>, but this requires additional mechanism at the server and could entail extra disk I/Os to update the anchor pages of forwarded objects.
Reference: [Care91] <author> M. Carey, M. Franklin, M. Livny, E. Shekita, </author> <title> Data Caching Tradeoffs in Client-Server DBMS Architectures, </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> Denver, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Intertransaction caching requires the use of a cache consistency maintenance protocol to ensure that all clients see a consistent (serializable) view of the database. Despite the potential overhead associated with such a protocol, intertransaction caching has been shown to offer significant performance gains <ref> [Wilk90, Care91, Wang91, Fran92a, Fran93] </ref>. <p> We also developed a variant of the simulator that models an object server rather than a page server. In this section, we briefly describe these extended models; readers interested in more information about the basic model can find more complete descriptions in <ref> [Care91, Fran93] </ref>. 5 4.1 System Model The structure of the page server OODBMS model, which we built using the DeNet simulation language [Livn88], is depicted in Figure 2. <p> These results are discussed where appropriate in Section 5. To extend the page server model of <ref> [Care91] </ref> to model object-level processing, two parameters were added. The first new parameter is ObjectsPerPage, which specifies the number of objects per page in the database. <p> Other values for these parameters, particularly transaction size and page locality, have also been explored and will be discussed briefly later. The data sharing patterns inherent in the workloads of Table 2 were chosen due to their previously established effectiveness as performance discriminators for client caching alternatives <ref> [Care91, Fran93] </ref>. The HOTCOLD workload has a high degree of locality per client and a moderate amount of sharing and data contention among clients. <p> Though space prevents us from presenting those results in detail, we summarize them briefly here. Our other experiments included varying the number of client workstations a la <ref> [Care91, Fran92a] </ref>, using the clustered object access pattern, and reducing the network bandwidth by a factor of ten. In all cases, while the numbers were different, the qualititative results told the same basic story regarding the algorithm tradeoffs and the relative superiority of PS-AA.
Reference: [Care93] <author> M. Carey, D. DeWitt, J. Naughton. </author> <booktitle> The OO7 Benchmark ACM SIGMOD Conf., </booktitle> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: This wide variety of approaches is due, at least in part, to the lack of a common understanding of the performance tradeoffs between page servers and object servers. While benchmarks for OODBMS have been developed (e.g., 001 [Catt92] and 007 <ref> [Care93] </ref>), they do not isolate the effect of the transfer granularity from the effects of other system implementation decisions. In addition to transferring data efficiently, OODBMS try to improve performance by reducing the need to obtain data from the server in the first place.
Reference: [Care94] <author> M. Carey, et al. </author> <title> Shoring up Persistent Applications, </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> Minneapolis, </address> <month> May, </month> <year> 1994. </year>
Reference-contexts: These log records could be replayed at the server in order to update the pages at the server, obviating the need to merge already-updated pages that have been sent from clients. This redo-at-server scheme is simple to implement (and was thus chosen for the initial version of SHORE <ref> [Care94] </ref>). However, it has the drawback of shifting a significant burden to the server, as the server must repeat the updates performed by all clients. <p> Moreover, the adaptive page server was shown to provide very good performance; it outperformed the pure page server, the pure object server, and the other two alternatives. As a result, we plan to use this approach in the context of the SHORE system that we are now building <ref> [Care94] </ref>.
Reference: [Catt91] <author> R. Cattell, </author> <title> Object Data Management, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: One commonly voiced concern about page servers is the potential for increased data contention due to the use of page-level cache consistency protocols and the difficulty of implementing fine-grained concurrency control in the context of a page server (e.g., <ref> [DeWi90, Catt91] </ref>). In this paper we study the performance implications of ODDBMS granularity in a multiple client context. While virtually all existing page servers support cache consistency at only a page (or coarser) granularity, we demonstrate that this restriction is neither necessary nor desirable.
Reference: [Catt92] <author> R. Cattell, J. Skeen, </author> <title> Object Operations Benchmark, </title> <journal> ACM TODS, </journal> <volume> 17(1), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: This wide variety of approaches is due, at least in part, to the lack of a common understanding of the performance tradeoffs between page servers and object servers. While benchmarks for OODBMS have been developed (e.g., 001 <ref> [Catt92] </ref> and 007 [Care93]), they do not isolate the effect of the transfer granularity from the effects of other system implementation decisions. In addition to transferring data efficiently, OODBMS try to improve performance by reducing the need to obtain data from the server in the first place.
Reference: [Chu94] <author> S. Chu, M. Winslett, </author> <title> Minipage Locking Support for Page-Server Database Management Systems, </title> <note> submitted for publication, </note> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: 2 Transaction aborts are handled similarly, with affected objects being marked as unavailable in the aborting transaction's client cache if the page cannot be purged due to other active transactions at that client. 3 A related hybrid approach, based on hardware support for locking of minipages, was independently proposed in <ref> [Chu94] </ref>. Write-write conflicts in that proposal are always handled at the page level, however. 3.3.3 Adaptive Locking w/Adaptive Callbacks (PS-AA) The final approach that we describe is PS-AA, which performs both locking and callbacks in an adaptive fashion.
Reference: [DeWi90] <author> D. DeWitt, P. Futtersack, D. Maier, F. Velez, </author> <title> A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems, </title> <booktitle> 16th VLDB Conf., </booktitle> <address> Brisbane, Australia, </address> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: One commonly voiced concern about page servers is the potential for increased data contention due to the use of page-level cache consistency protocols and the difficulty of implementing fine-grained concurrency control in the context of a page server (e.g., <ref> [DeWi90, Catt91] </ref>). In this paper we study the performance implications of ODDBMS granularity in a multiple client context. While virtually all existing page servers support cache consistency at only a page (or coarser) granularity, we demonstrate that this restriction is neither necessary nor desirable. <p> Finally, Section 7 summarizes our results and discusses future work. 2 Related Work As implied in the Introduction, the current state of knowledge regarding the performance of alternative OODBMS architectures is rather primitive. The only previous study that has attempted to answer some of the relevant questions is <ref> [DeWi90] </ref>. That study compared the performance of an object server and a page server (and also an NFS-based file server), but only in the case of a single client and a single server. <p> The basic object server is the most obvious approach towards avoiding the potential communication, memory usage, and false sharing problems of the coarser-grained PS approach. This approach is similar to the object server that was studied in <ref> [DeWi90] </ref>, although consistency issues were not explicitly considered there. 3.3 Hybrid Approaches In contrast to PS and OS, the remaining approaches all remove the restriction of having to statically choose a single granularity to be used for all granularity decisions. <p> However, as has been noted elsewhere, the maintenance of cache consistency at a granularity finer than the transfer granularity increases the complexity of maintaining transaction semantics. For example, as discussed in <ref> [DeWi90] </ref>, if multiple clients simultaneously have permission to update different objects on the same page, then the resulting two copies of the page must be carefully merged to avoid losing one of the updates. <p> As mentioned there, two cases will be considered within each workload, one where the transaction page locality is relatively low and one where it is a factor of three higher; locality is a key factor in determining the tradeoffs between object servers and page servers <ref> [DeWi90] </ref>, and will also be seen to play a significant role in terms of determining the appropriate locking granularity. Within each case, the system size is fixed at 10 clients and the object update probability is varied to obtain different levels of contention and write-read data sharing. <p> In both cases, the communication cost saved by not sending a whole page to get a single object was the main reason for the improvement, a la <ref> [DeWi90] </ref>. 6 Other Granularity Issues In this section we discuss two additional granularity issues: concurrent page updates and grouped-object servers. 6.1 Concurrent Page Updates As discussed in Section 3.3, combining object-level locking with page-granularity data transfers raises the issue of managing concurrent updates to pages.
Reference: [Fran92a] <author> M. Franklin, M. Carey, </author> <title> Client-Server Caching Revisited, </title> <booktitle> Proc. Int'l Workshop on Distributed Object Mgmt., </booktitle> <address> Edmonton, Canada, </address> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Intertransaction caching requires the use of a cache consistency maintenance protocol to ensure that all clients see a consistent (serializable) view of the database. Despite the potential overhead associated with such a protocol, intertransaction caching has been shown to offer significant performance gains <ref> [Wilk90, Care91, Wang91, Fran92a, Fran93] </ref>. <p> The remaining techniques operate at multiple granularities. All five approaches are extensions of a pessimistic, locking-based cache consistency protocol known as Callback Locking [Howa88, Lamb91]. Transactional Callback Locking algorithms have previously been shown to have good performance over a wide range of system configurations and workload characteristics <ref> [Wang91, Fran92a] </ref> and are used by several OODBMSs, including ObjectStore and SHORE. In the approaches described here, we assume an underlying steal/no-force recovery scheme based on write-ahead logging and a purge-pages-at-client, undo-at-server approach to handling transaction aborts (a la [Fran92b]). <p> The PS approach uses a Callback Locking algorithm to maintain cache consistency; it uses the page-level Callback-Read (CB-Read) algorithm studied in <ref> [Fran92a, Fran93] </ref>. CB-Read guarantees 3 that copies of pages in client caches are always valid, so client transactions can safely read-lock and read cached pages without server intervention. <p> Though space prevents us from presenting those results in detail, we summarize them briefly here. Our other experiments included varying the number of client workstations a la <ref> [Care91, Fran92a] </ref>, using the clustered object access pattern, and reducing the network bandwidth by a factor of ten. In all cases, while the numbers were different, the qualititative results told the same basic story regarding the algorithm tradeoffs and the relative superiority of PS-AA.
Reference: [Fran92b] <author> M. Franklin, et al. </author> <title> Crash Recovery in Client-Server EXODUS, </title> <booktitle> ACM SIGMOD Conf. </booktitle> <address> San Diego, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: In the approaches described here, we assume an underlying steal/no-force recovery scheme based on write-ahead logging and a purge-pages-at-client, undo-at-server approach to handling transaction aborts (a la <ref> [Fran92b] </ref>). When a transaction commits, copies of all updated data pages that are still in the client's cache are sent back to the server that owns the data; this simplifies the server's job of ensuring durability for committed updates.
Reference: [Fran93] <author> M. Franklin, </author> <title> Caching and Memory Management in Client-Server Database Systems, </title> <type> Ph.D. Thesis, TR #1168, </type> <institution> Computer Sciences Dept., Univ. of WI, Madison, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Intertransaction caching requires the use of a cache consistency maintenance protocol to ensure that all clients see a consistent (serializable) view of the database. Despite the potential overhead associated with such a protocol, intertransaction caching has been shown to offer significant performance gains <ref> [Wilk90, Care91, Wang91, Fran92a, Fran93] </ref>. <p> The PS approach uses a Callback Locking algorithm to maintain cache consistency; it uses the page-level Callback-Read (CB-Read) algorithm studied in <ref> [Fran92a, Fran93] </ref>. CB-Read guarantees 3 that copies of pages in client caches are always valid, so client transactions can safely read-lock and read cached pages without server intervention. <p> We also developed a variant of the simulator that models an object server rather than a page server. In this section, we briefly describe these extended models; readers interested in more information about the basic model can find more complete descriptions in <ref> [Care91, Fran93] </ref>. 5 4.1 System Model The structure of the page server OODBMS model, which we built using the DeNet simulation language [Livn88], is depicted in Figure 2. <p> Other values for these parameters, particularly transaction size and page locality, have also been explored and will be discussed briefly later. The data sharing patterns inherent in the workloads of Table 2 were chosen due to their previously established effectiveness as performance discriminators for client caching alternatives <ref> [Care91, Fran93] </ref>. The HOTCOLD workload has a high degree of locality per client and a moderate amount of sharing and data contention among clients.
Reference: [Gray79] <author> J. </author> <title> Gray Notes on Database Operating Systems Operating Systems: An Advanced Course, </title> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: The most relevant, which inspired the best of the algorithms that we will be proposing, is the design of an adaptive locking algorithm for Rdb/VMS for use on VAXClusters [Josh91]. This algorithm uses a technique called lock de-escalation and works in the context of a hierarchy of lock granularities <ref> [Gray79] </ref>.
Reference: [Howa88] <author> J. Howard, et al, </author> <title> Scale and Performance in a Distributed File System, </title> <journal> ACM TOCS 6(1), </journal> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: First, we present two basic approaches in which the granularity chosen for all three functions is the same. The remaining techniques operate at multiple granularities. All five approaches are extensions of a pessimistic, locking-based cache consistency protocol known as Callback Locking <ref> [Howa88, Lamb91] </ref>. Transactional Callback Locking algorithms have previously been shown to have good performance over a wide range of system configurations and workload characteristics [Wang91, Fran92a] and are used by several OODBMSs, including ObjectStore and SHORE.
Reference: [Josh91] <author> A. Joshi, </author> <title> Adaptive Locking Strategies in a Multi-Node Data Sharing System, </title> <booktitle> 17th VLDB Conf., </booktitle> <address> Barcelona, </address> <year> 1991. </year>
Reference-contexts: The most relevant, which inspired the best of the algorithms that we will be proposing, is the design of an adaptive locking algorithm for Rdb/VMS for use on VAXClusters <ref> [Josh91] </ref>. This algorithm uses a technique called lock de-escalation and works in the context of a hierarchy of lock granularities [Gray79]. <p> Independently, an almost identical notion of lock de-escalation was proposed for use in the context of main memory database systems [Lehm89]. While <ref> [Josh91] </ref> presented some brief preliminary performance results, neither of these papers examined the performance of lock de-escalation in any detail. Related work on shared disk systems has also been done at IBM Almaden [Moha91].
Reference: [Lamb91] <author> C. Lamb, G. Landis, J. Orenstein, D. Weinreb, </author> <title> The ObjectStore Database System, </title> <type> CACM 34(10), </type> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: First, we present two basic approaches in which the granularity chosen for all three functions is the same. The remaining techniques operate at multiple granularities. All five approaches are extensions of a pessimistic, locking-based cache consistency protocol known as Callback Locking <ref> [Howa88, Lamb91] </ref>. Transactional Callback Locking algorithms have previously been shown to have good performance over a wide range of system configurations and workload characteristics [Wang91, Fran92a] and are used by several OODBMSs, including ObjectStore and SHORE.
Reference: [Lehm89] <author> T. Lehman, M. Carey, </author> <title> A Concurrency Control Algorithm for Memory-Resident Database Systems, </title> <booktitle> 3rd Int'l. FODO Conf., </booktitle> <address> Paris, France, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Independently, an almost identical notion of lock de-escalation was proposed for use in the context of main memory database systems <ref> [Lehm89] </ref>. While [Josh91] presented some brief preliminary performance results, neither of these papers examined the performance of lock de-escalation in any detail. Related work on shared disk systems has also been done at IBM Almaden [Moha91].
Reference: [Li89] <author> K. Li, P. Hudak, </author> <title> Memory Coherence in Shared Virtual Memory Systems, </title> <journal> ACM TOCS,7(4) Nov., </journal> <year> 1989. </year>
Reference-contexts: A way to avoid this problem is to disallow simultaneous updates by using a single write token per page <ref> [Li89] </ref>, as is proposed in [Moha91]. The write token approach can be communication-intensive, however the entire page must often be sent when the write token is transferred from one client to the other. For this reason, we have chosen to merge updates in the approaches studied here.
Reference: [Livn88] <author> M. Livny, </author> <note> DeNet User's Guide, Version 1.0, </note> <institution> Computer Sciences Dept., Univ. of WI-Madison, </institution> <year> 1988. </year>
Reference-contexts: In this section, we briefly describe these extended models; readers interested in more information about the basic model can find more complete descriptions in [Care91, Fran93]. 5 4.1 System Model The structure of the page server OODBMS model, which we built using the DeNet simulation language <ref> [Livn88] </ref>, is depicted in Figure 2. We model a system consisting of a single server plus a varying number of client workstations, all of which are connected via a local area network. The number of client machines in the system is a parameter of the model.
Reference: [Moha91] <author> C. Mohan, I. Narang, </author> <title> Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment, </title> <booktitle> 17th VLDB Conf., </booktitle> <address> Barcelona, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: While [Josh91] presented some brief preliminary performance results, neither of these papers examined the performance of lock de-escalation in any detail. Related work on shared disk systems has also been done at IBM Almaden <ref> [Moha91] </ref>. This paper proposed using strict two-phase locking on objects to ensure serializability, while using physical locks on pages to ensure cache consistency. These physical locks can either be released during a transaction or they can be held across transactions. <p> This approach was designed to exploit the relatively inexpensive inter-node communication paths usually found in tightly-coupled data sharing architectures, and several alternative algorithms (differing in their crash recovery implications) were proposed. The algorithms were ordered based on their designers' performance expectations <ref> [Moha91] </ref>, but no performance analysis was attempted. 3 Alternative Approaches The general architecture of a data-shipping OODBMS is shown in Figure 1; it consists of two types of processes that communicate via a local area network. <p> A way to avoid this problem is to disallow simultaneous updates by using a single write token per page [Li89], as is proposed in <ref> [Moha91] </ref>. The write token approach can be communication-intensive, however the entire page must often be sent when the write token is transferred from one client to the other. For this reason, we have chosen to merge updates in the approaches studied here.
Reference: [Tay85] <author> Y. Tay, N. Goodman, R. Suri, </author> <title> Locking Performance in Centralized Databases, </title> <journal> ACM TODS 10(4), </journal> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: As before, the performance of PS is now much better because the high locality significantly reduces data contention. As Tay has shown <ref> [Tay85] </ref>, contention grows as the square of transaction size, so reducing the transaction size for PS by a factor of three (in pages) implies a nine-fold decrease in inter-client page contention. <p> To reestablish similar operating conditions following this order of magnitude increase, we also scaled up the transaction size in pages. Since contention decreases linearly in the database size, but increases as the square of the transaction length <ref> [Tay85] </ref>, the transactions were scaled up by a factor of three. Figures 12-14 show the results of the scaled-up case for the low page locality. To make it easy to compare trends with the experiments with the small database and buffer pools, the results are shown in a normalized fashion.
Reference: [Wang91] <author> Y. Wang, L. Rowe, </author> <title> Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture, </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> Denver, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Intertransaction caching requires the use of a cache consistency maintenance protocol to ensure that all clients see a consistent (serializable) view of the database. Despite the potential overhead associated with such a protocol, intertransaction caching has been shown to offer significant performance gains <ref> [Wilk90, Care91, Wang91, Fran92a, Fran93] </ref>. <p> The remaining techniques operate at multiple granularities. All five approaches are extensions of a pessimistic, locking-based cache consistency protocol known as Callback Locking [Howa88, Lamb91]. Transactional Callback Locking algorithms have previously been shown to have good performance over a wide range of system configurations and workload characteristics <ref> [Wang91, Fran92a] </ref> and are used by several OODBMSs, including ObjectStore and SHORE. In the approaches described here, we assume an underlying steal/no-force recovery scheme based on write-ahead logging and a purge-pages-at-client, undo-at-server approach to handling transaction aborts (a la [Fran92b]).
Reference: [Wilk90] <author> W. Wilkinson, M. Neimat, </author> <title> Maintaining Consistency of Client Cached Data, </title> <booktitle> 16th VLDB Conf., </booktitle> <address> Brisbane, </address> <year> 1990. </year> <month> 12 </month>
Reference-contexts: Intertransaction caching requires the use of a cache consistency maintenance protocol to ensure that all clients see a consistent (serializable) view of the database. Despite the potential overhead associated with such a protocol, intertransaction caching has been shown to offer significant performance gains <ref> [Wilk90, Care91, Wang91, Fran92a, Fran93] </ref>.
References-found: 22

