URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/papers/slt96.ps
Refering-URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/index.html
Root-URL: http://www.cs.nyu.edu
Email: sekine,grishman@cs.nyu.edu  
Title: NYU Language Modeling Experiments for the 1995 CSR Evaluation  
Author: Satoshi Sekine and Ralph Grishman 
Address: New York University 715 Broadway, 7th floor New York, NY 10003, USA  
Affiliation: Computer Science Department  
Abstract: This paper describesNYU's effort toward improving recognition accuracy for the 1995 ARPA Large Vocabulary Continuous Speech Recognition evaluation. We are trying to develop language models which includes longer-range language models and linguistic motivated model. For the system described here, we used as a starting point the scores produced by SRI's acoustic and language models. These are linearly combined with the scores produced by the NYU language models. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R Kuhn: </author> <title> Speech Recognition and the Frequency of Recently Used Words: A Modified Markov Model for Natural Language 12th International Conference on Computational Linguistic (1988) </title>
Reference: 2. <author> F Jelinek, B Merialdo, S Roukos, and M Strauss: </author> <title> A Dynamic Language Model for Speech Recognition Proceedings DARPA Speech and Natural Language Workshop (1991) </title>
Reference-contexts: Topic Coherence Model There have been several attempts in the last few years to make use of topic coherence properties in order to improve recognition accuracy <ref> [2] </ref>, [3], [8]. These are, in other words, dynamic language models which utilize the partially dictated document (cache) in order to predict the next word. Some of these methods also use a large corpus to identify and predict words closely related to those in the cache.
Reference: 3. <author> Ronald Rosenfeld and Xuedong Huang: </author> <booktitle> Improvements in Stochastic Language Modeling Proceedings DARPA Speech and Natural Language Workshop (1992) </booktitle>
Reference-contexts: Topic Coherence Model There have been several attempts in the last few years to make use of topic coherence properties in order to improve recognition accuracy [2], <ref> [3] </ref>, [8]. These are, in other words, dynamic language models which utilize the partially dictated document (cache) in order to predict the next word. Some of these methods also use a large corpus to identify and predict words closely related to those in the cache.
Reference: 4. <author> Kevin Knight, </author> <note> Ishwar Chander Automated Postediting of Documents AAAI-94 (1994) </note>
Reference-contexts: In particular, this year we considered two of the problems, determiner selection and the tense of verbs. 2.1. Determiner selection Although we found a number of determiner mistakes in the recognition errors, finding the correct determiner is not an easy task (even for a human). Knight and Chander <ref> [4] </ref> described a decision tree method for choosing the determiner (`a' or `the'). They report an accuracy of 81% for choosing a determiner at a point where you know some determiner must be present.
Reference: 5. <author> Satoshi Sekine: </author> <title> A New Direction for Sublanguage NLP International Conference on New Methods in Language Processing (1994) </title>
Reference-contexts: With regard to the size of sublanguage set, a constant size may not be optimal. Sekine <ref> [5] </ref> reported on an experiment which selects the size automatically by seeking the minimum ratio of the document set perplexity to the estimated perplexity of randomly selected document sets of that size. This approach can be applicable to our system.
Reference: 6. <author> K.Sparck-Jones: </author> <title> Index Term Weighting Information Storage and Retrieval, </title> <address> Vol.9, </address> <month> p619-633 </month> <year> (1973) </year>
Reference-contexts: This is a standard metric of information retrieval based on the assumption that the higher frequency words provide less information about topics <ref> [6] </ref>. Article scores (AScore) for all articles in the large corpus are computed as the sum of the weighted scores of the selected keywords in each article, and are normalized by the log of the size of each article.
Reference: 7. <author> Vassilios Digalakis, Mitch Weintraub, Ananth Sankar, Hora-cio Franco, Leonardo Neumeyer, </author> <title> and Hy Murveit Continuous Speech Dictation on ARPA's North Business News Domain Proceedings of the ARPA Spoken Language Systems Technology Workshop, </title> <month> p88-93 </month> <year> (1995) </year>
Reference: 8. <author> Satoshi Sekine, </author> <booktitle> John Sterling and Ralph Grishman NYU/BBN 1994 CSR evaluation Proceedings of the ARPA Spoken Language Systems Technology Workshop (1995) </booktitle>
Reference-contexts: This year, we started the project by classifying the recognition errors in terms of their linguistic properties. Then, we considered how some of these errors might be reduced by specifically-targeted linguistic models. We also improved the topic coherence model, which we explored last year <ref> [8] </ref>. We are working jointly with SRI this year. For the system described here, we used as a starting point the scores produced by SRI's acoustic and language models. <p> Topic Coherence Model There have been several attempts in the last few years to make use of topic coherence properties in order to improve recognition accuracy [2], [3], <ref> [8] </ref>. These are, in other words, dynamic language models which utilize the partially dictated document (cache) in order to predict the next word. Some of these methods also use a large corpus to identify and predict words closely related to those in the cache.
Reference: 9. <author> Satoshi Sekine, </author> <booktitle> Ralph Grishman A Corpus-based Probabilistic Grammar with Only Two Non-terminals Proceedings of the Fourth International Workshop on Parsing Technologies (1995) </booktitle>
Reference-contexts: Also, as we have achieved similar improvements in different evaluations, as well as 1994 CSR evaluation, we believe that the technique is consistently beneficial. For the future, we would like to continue seeking natural language techniques which can improve recognition accuracy. We are developing a corpus-based statistical parser <ref> [9] </ref>; The approach has the potential for producing a very accurate parser, and it has already demonstrated better performance than conventional parsers (using hand-coded grammars).
References-found: 9

