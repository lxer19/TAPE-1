URL: http://www.is.cs.cmu.edu/papers/multimodal/96.ieee_gaze.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.multimodal.publications.html
Root-URL: 
Email: stiefel@ira.uka.de, yang+@cs.cmu.edu, waibel@cs.cmu.edu  
Title: A Model-Based Gaze Tracking System  
Author: Rainer Stiefelhagen, Jie Yang, Alex Waibel 
Address: Karlsruhe  
Affiliation: Interactive System Laboratories Carnegie Mellon University University of  
Abstract: In this paper we present a non-intrusive model-based gaze tracking system. The system estimates the 3-D pose of a user's head by tracking as few as six facial feature points. The system locates a human face using a statistical color model without any mark on the face and then finds and tracks the facial features, such as eyes, nostrils and lip corners. A full perspective model is employed to map these feature points onto the 3D pose. Several techniques have been developed to track the features points and recover from failure. We currently achieve a frame rate of 15+ frames per second using an HP 9000 workstation with a framegrabber and a Canon VC-C1 camera. The application of the system has been demonstrated by a gaze-driven panorama image viewer. The potential applications of the system include multimodal interfaces, virtual reality and video-teleconferencing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. F. DeMenthon and L. S. Davis. </author> <title> Model based object pose in 25 lines of code. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Computer Vision - ECCV 92, Proceedings Second European Conference on Computer Vision, </booktitle> <address> Santa Margherita Ligure, </address> <month> May </month> <year> 1992, </year> <pages> pages 335 - 343. </pages> <publisher> Springer Verlag, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: The system is also able to recover from tracking failures. The system then finds and tracks the facial features, such as eyes, nostrils and lip corners. To compute the pose we use the POSIT-algorithm, recently proposed by DeMenthon <ref> [1] </ref>. This algorithm iteratively approximates a full perspective solution of the pose, given at least four 3D to 2D correspondences. The remainder of this paper is organized as follows: In section 2 we describe the search for the face, the eyes, nostrils and lip-corners. <p> Using the second method, the subset that leads to the pose that implies the smoothest motion is chosen as the best subset. To compute the pose using the POSIT-algorithm we need at least four correspondences, and the object points should preferably be non-coplanar <ref> [1] </ref>. We chose the considered subsets as follows: * In case, we only found one nostril, only the two subsets are considered, where the left or the right nostril is missing, respectively.
Reference: [2] <author> R. Brunelli, T. Poggio. </author> <title> Face Recognition: Features versus Templates. </title> <journal> IEEE Transaction on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 15, No. 10, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: The vertical positions of the left and right lip corners can be found by searching for the darkest pixel along the columns at the left and right estimated boundaries of the lips in that search-region. The use of integral projections to extract facial features is for example described in <ref> [2] </ref> or in Kanade's work on face recognition [5]. found lip-corners. The small rectangles mark the predicted positions of the lip-corners. 2.4. Searching the Nostrils Similar to searching the eyes, the nostrils can be found by searching for two dark regions, that satisfy certain geometric constraints.
Reference: [3] <author> Andrew Gee and Robert Cipolla. </author> <title> Non-Intrusive Gaze Tracking for Human-Computer Interaction. </title> <booktitle> Proc. Mechatronics and Machine Vision in Practise, p. </booktitle> <pages> 112-117, </pages> <address> Toowoomba, Australia, </address> <year> 1994 </year>
Reference-contexts: Gee & Cipolla developed a system to track the rotation and position of the head by finding correspondences between facial feature points and corresponding points in a model of the head, using a weak perspective projection <ref> [3] </ref>. However, the system has to be initialized manually because the system cannot locate the face and the facial feature points automatically. We present a software-based system in this paper. The system estimates the 3-D pose of a user's head by tracking as few as six facial feature points.
Reference: [4] <author> A. H. Gee and R. Cipolla, </author> <title> Fast Visual Tracking by Temporal Consensus. </title> <type> Technical Report CUED/F-INFENG/TR-207, </type> <institution> University of Cambridge, </institution> <month> February </month> <year> 1995 </year>
Reference-contexts: At the same time, we use a most consistent subset of 2D to 3D point-correspondences to compute the pose, instead of using all found points. To find a best subset we investigated two methods proposed by Cipolla <ref> [4] </ref>: Sample consensus tracking and temporal continuity tracking. Using the first method, that subset is chosen that leads to the best back-projection of model-points into the image-plane. Using the second method, the subset that leads to the pose that implies the smoothest motion is chosen as the best subset.
Reference: [5] <author> T. Kanade, </author> <title> Picture processing by computer complex and recognition of human faces. </title> <type> Tech. Rep., </type> <institution> Kyoto Univ., Dept. Inform. Sci., </institution> <year> 1973. </year>
Reference-contexts: The use of integral projections to extract facial features is for example described in [2] or in Kanade's work on face recognition <ref> [5] </ref>. found lip-corners. The small rectangles mark the predicted positions of the lip-corners. 2.4. Searching the Nostrils Similar to searching the eyes, the nostrils can be found by searching for two dark regions, that satisfy certain geometric constraints.
Reference: [6] <author> S. Baluja, D. Pomerleau. </author> <title> Non-Intrusive Gaze Tracking Using Artificial Neural Networks. </title> <type> CMU Tech. Report CMU-CS-94-102, </type> <year> 1994. </year>
Reference-contexts: Recently, there have been proposed nonintrusive gaze trackers using mainly software. Baluja and Pomerleau proposed a method to estimate the eye-gaze onto a computer monitor <ref> [6] </ref>. In their approach however, the user has to stay in an almost fixed position and is not allowed to turn his head, and special lighting is needed.
Reference: [7] <author> J. Yang, A. Waibel. </author> <title> Tracking Human Faces in Real-Time. </title> <type> CMU Tech. Report CMU-CS-95-210, </type> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: The color distribution is initialized so as to find a variety of face colors and is gradually adapted to the actual found face. A description of the use of the color model to find and track faces can be found in <ref> [7] </ref>. input image (color!) face-colored regions sample input image. The face is marked in the input image 2.2. <p> Tracking the Face In order order to beeing able to adjust parameters for the search windows of facial features to changing sizes of the face and to adjust parameters for the color model (see <ref> [7] </ref>), it is necessary to track the face in the image. Therefore, the face is searched in a search window around the last position of the face (see Figure 8).
Reference: [8] <author> D. A. Simon, M. Hebert, T. Kanade. </author> <title> Real-time 3-D Pose Esti mation Using a High-Speed Range Sensor. </title> <booktitle> International Conference of Robotics and Automation Proceedings, </booktitle> <address> May '94, San Diego. </address>
Reference-contexts: There have been several approaches to compute the gaze of a person. First to mention, hardware-intensive and/or intrusive methods, where the user has to wear special headgear, or methods that use expensive hardware like radar range finder <ref> [8] </ref>. Recently, there have been proposed nonintrusive gaze trackers using mainly software. Baluja and Pomerleau proposed a method to estimate the eye-gaze onto a computer monitor [6].
References-found: 8

