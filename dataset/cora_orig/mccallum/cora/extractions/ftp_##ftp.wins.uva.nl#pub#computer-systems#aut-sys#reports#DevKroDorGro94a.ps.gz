URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/DevKroDorGro94a.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Observer Curve and Object Detection from the Optic Flow  
Author: Anuj Dev, Ben J.A. Krose Leo Dorst, Frans C.A. Groen 
Abstract-found: 0
Intro-found: 1
Reference: [Div84] <author> Adiv, G. </author> <year> 1985. </year> <title> Determining Three-Dimensional Motion and Structure from Optical Flow Generated by Several Moving Objects. </title> <journal> IEEE transactions on PAMI 7-4: </journal> <pages> 384-401. </pages>
Reference-contexts: Gibson [Gibson66] argued that the direction of translation is the most important information gained from the optic flow. In computer vision Adiv <ref> [Div84] </ref>, among others, has shown methods to estimate the direction of translation.
Reference: [Gibson66] <author> Gibson, J.J. </author> <year> 1966. </year> <title> The senses considered as perceptual systems. </title> <publisher> Houghto Mi*in. </publisher>
Reference-contexts: The observer curve equals: fi (s) = (st x ; st y ; st z ) This type of motion has been very popular in psychophysical and computer vision communities. Gibson <ref> [Gibson66] </ref> argued that the direction of translation is the most important information gained from the optic flow. In computer vision Adiv [Div84], among others, has shown methods to estimate the direction of translation.
Reference: [Girossi89] <author> Girosi F., Verri A. and Torre V. </author> <year> 1989. </year> <title> Constraints for the computation of optic flow. </title> <booktitle> In DARPA Image understanding workshop. </booktitle> <pages> pp. 116-124. </pages>
Reference-contexts: The extraction of the optic flow field from the time varying images has attracted a lot of attention in the computer vision community. We will not give an overview but refer the reader to papers from <ref> [Girossi89] </ref> [Heeger92] [Horn81] [Nagel83] [Singh91]. Instead we start from the optic flow and give the relation of the motion of the environment to the optic flow. 3.1 Motion of the environment Consider the observer moving relative to a environment that consists of static bodies.
Reference: [Heeger92] <author> Heeger D.J. and Jepson A.D. </author> <year> 1992. </year> <title> Subspace Methods for Recovering Rigid Motion 1: Algorithm and Implementation. </title> <journal> International journal of Computer Vision 7-2: </journal> <pages> 95-117. </pages>
Reference-contexts: We will consider an observer with a single camera as its sensor. It has been shown in the literature <ref> [Heeger92] </ref> [Koenderink87b] [Prazdny80] that, up to a scaling factor, a model of the environment and the motion of the observer can be computed from the time varying images. This is certainly not a trivial problem. <p> The extraction of the optic flow field from the time varying images has attracted a lot of attention in the computer vision community. We will not give an overview but refer the reader to papers from [Girossi89] <ref> [Heeger92] </ref> [Horn81] [Nagel83] [Singh91]. Instead we start from the optic flow and give the relation of the motion of the environment to the optic flow. 3.1 Motion of the environment Consider the observer moving relative to a environment that consists of static bodies.
Reference: [Horn81] <author> Horn B.K.P. and Schunck B.G. </author> <year> 1981. </year> <title> Determining optical flow. </title> <booktitle> Artificial Intelligence 17: </booktitle> <pages> 185-203. </pages>
Reference-contexts: The extraction of the optic flow field from the time varying images has attracted a lot of attention in the computer vision community. We will not give an overview but refer the reader to papers from [Girossi89] [Heeger92] <ref> [Horn81] </ref> [Nagel83] [Singh91]. Instead we start from the optic flow and give the relation of the motion of the environment to the optic flow. 3.1 Motion of the environment Consider the observer moving relative to a environment that consists of static bodies.
Reference: [Koenderink86] <author> Koenderink J.J. </author> <year> 1986. </year> <title> Optic Flow. </title> <booktitle> Vision Research 26-1: </booktitle> <pages> 161-180. </pages>
Reference-contexts: The time to collision s p to a collision point p which lies on the object equals (s p ) 1 = (t p t z = @x @ _r y Proof The spatial derivatives of the optic flow equal _r <ref> [Koenderink86] </ref> [Nelson91] @ _ r = p z _r x @p z p z @y _r y @p z t y _r y @p z The only projected collision point lies in the focus of expansion.
Reference: [Koenderink87b] <author> Koenderink J.J. and van Doorn A.J. </author> <year> 1987. </year> <title> Facts on Optic Flow. </title> <booktitle> Biological Cybernetics 56: </booktitle> <pages> 247-254. </pages>
Reference-contexts: We will consider an observer with a single camera as its sensor. It has been shown in the literature [Heeger92] <ref> [Koenderink87b] </ref> [Prazdny80] that, up to a scaling factor, a model of the environment and the motion of the observer can be computed from the time varying images. This is certainly not a trivial problem.
Reference: [Lee80] <author> Lee D.N. </author> <year> 1980. </year> <title> The optic flow field: the foundation of vision. </title> <journal> Philosophical transactions of the Royal Society of London 290: </journal> <pages> 169-179. </pages>
Reference-contexts: The observer moves on a curve: fi (s) = st x + 2 a y s 2 ; st z + 2 (5) Following Lee <ref> [Lee80] </ref>, Rieger [Rieger83] has shown that the projected collision points can be computed from the time derivatives of the velocity scaled depth. Since the velocity scaled depth entails 7 information about the instantaneous motion, intuitively one can imagine that these derivatives contain information about the acceleration.
Reference: [Long80] <author> Longuet-Higgins H. and Prazdny K. </author> <year> 1980. </year> <title> The interpretation of a moving retinal image. </title> <journal> Proceedings of the Royal Society of London 208: </journal> <pages> 385-387 </pages>
Reference: [Nagel83] <author> Nagel H.H. </author> <year> 1983. </year> <title> Displacement vectors derived from 2nd order Intensity variations in Image sequences. </title> <booktitle> Computer vision, graphics and image processing 21: </booktitle> <pages> 85-117. </pages>
Reference-contexts: The extraction of the optic flow field from the time varying images has attracted a lot of attention in the computer vision community. We will not give an overview but refer the reader to papers from [Girossi89] [Heeger92] [Horn81] <ref> [Nagel83] </ref> [Singh91]. Instead we start from the optic flow and give the relation of the motion of the environment to the optic flow. 3.1 Motion of the environment Consider the observer moving relative to a environment that consists of static bodies.
Reference: [Nelson91] <author> Nelson R.C. and Aloimonos J. </author> <year> 1991. </year> <title> Using flow field divergence for obstacle avoidance. </title> <booktitle> DARPA image understanding workshop: </booktitle> <pages> 548-564 </pages>
Reference-contexts: The time to collision s p to a collision point p which lies on the object equals (s p ) 1 = (t p t z = @x @ _r y Proof The spatial derivatives of the optic flow equal _r [Koenderink86] <ref> [Nelson91] </ref> @ _ r = p z _r x @p z p z @y _r y @p z t y _r y @p z The only projected collision point lies in the focus of expansion.
Reference: [Prazdny80] <author> Prazdny K. </author> <year> 1980. </year> <title> Egomotion and Relative Depth Map from Optical Flow. </title> <booktitle> Biological Cybernetics 36: </booktitle> <pages> 87-102. </pages>
Reference-contexts: We will consider an observer with a single camera as its sensor. It has been shown in the literature [Heeger92] [Koenderink87b] <ref> [Prazdny80] </ref> that, up to a scaling factor, a model of the environment and the motion of the observer can be computed from the time varying images. This is certainly not a trivial problem.
Reference: [Rieger83] <author> Rieger J.H. </author> <year> 1983. </year> <title> Information in optical flows induced by curved paths of observation. </title> <journal> Journal of the Optical Society of America 73-3: </journal> <pages> 339-344. </pages>
Reference-contexts: The observer moves on a curve: fi (s) = st x + 2 a y s 2 ; st z + 2 (5) Following Lee [Lee80], Rieger <ref> [Rieger83] </ref> has shown that the projected collision points can be computed from the time derivatives of the velocity scaled depth. Since the velocity scaled depth entails 7 information about the instantaneous motion, intuitively one can imagine that these derivatives contain information about the acceleration.
Reference: [Singh91] <author> A. Singh A. </author> <year> 1991. </year> <title> Robust computation of image-motion and scene-depth. </title> <booktitle> In Proceedings of the IEEE conference on Robotics and Automation pp. </booktitle> <pages> 2730-2737. </pages>
Reference-contexts: The extraction of the optic flow field from the time varying images has attracted a lot of attention in the computer vision community. We will not give an overview but refer the reader to papers from [Girossi89] [Heeger92] [Horn81] [Nagel83] <ref> [Singh91] </ref>. Instead we start from the optic flow and give the relation of the motion of the environment to the optic flow. 3.1 Motion of the environment Consider the observer moving relative to a environment that consists of static bodies.
Reference: [Warren91] <editor> Warren W.H. et al. </editor> <year> 1991. </year> <title> On the sufficiency if the velocity field for the perception of heading. </title> <booktitle> Biological Cybernetics 65: </booktitle> <pages> 311-320. </pages>
Reference: [Wells89] <author> Wells III W.M. </author> <year> 1989. </year> <title> Visual Estimation of 3D Line Segments from Motion A Mobile Robot. </title> <journal> IEEE transactions on Robotics and Automation 5-6: </journal> <pages> 820-825. </pages>
Reference-contexts: The time to collision for that point then equals s p of this equation. Proof The theorem follows from the time derivative of the foe, lemma 3and equation (7) 5 Coupled Rotational and Translational motion The remainder of this chapter will be devoted to navigation of mobile robots <ref> [Wells89] </ref>. The construction usually constrains the motion of the mobile robots to a lower dimension then the dimension of the possible configurations in the workspace. For example, a mobile robot can reach each point in the workspace under any orientation which thus spans a three space.
References-found: 16

