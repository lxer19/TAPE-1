URL: http://www.cs.colostate.edu/~draper/papers/draper_mlcv93.ps.gz
Refering-URL: http://www.cs.colostate.edu/~vision/html/publications.html
Root-URL: 
Email: bdraper@cs.umass.edu  
Title: Learning from the Schema Learning System  
Author: Bruce A. Draper 
Address: Box 34610 Amherst, MA., 01003-4610  
Affiliation: Dept. of Computer Science University of Massachusetts  
Abstract: A major problem that confronts developers of knowledge-based vision systems is how the information in the knowledge base (both object-specific knowledge and the control strategies for applying the knowledge) is acquired. Hand construction of knowledge bases is an onerous, time-consuming and errorful process, and is inadequate for systems requiring more than a few object models, especially if the domain within which the system operates changes. Over the past four years we have addressed this problem by developing the Schema Learning System (SLS) to learn strategies for applying object-specific knowledge in complex domains. The goal is build a system that can learn (under supervision) to recognize a new object or object class without any direct human intervention. This paper will not describe SLS in any detail; that has been done elsewhere. (See Draper et al. [9] for a preliminary presentation, or Draper [10] for a more recent and complete description). Instead, this paper summarizes some of our conclusions from four years of machine learning and computer vision research, emphasizing our representation of recognition strategies, our syntactic approach to integrating visual modules, and the implications of SLS for goal-directed, as opposed to recon-structionist, theories of vision. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aloimonos and D. Shulman. </author> <title> Integration of Visual Modules: An Extension of the Marr Paradigm. </title> <publisher> Academic Press, Inc., </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: Syntactic Approach to Integration In terms of the integration of visual modules, SLS is on the opposite end of a spectrum from the approach taken by Aloimonos and Shulman <ref> [1] </ref>. Aloi-monos and Shulman recommend analyzing the semantics of each visual operator closely, and integrating them by merging their mathematical con straints. Although such an approach is very powerful in theory, it is difficult, if not impossible, in practice.
Reference: [2] <author> J. Aloimonos. </author> <title> "Purposive and Qualitative Active Vision," </title> <booktitle> Proc. of the DARPA Image Understanding Workshop, </booktitle> <address> Pittsburgh, PA., </address> <month> Sept. </month> <year> 1990. </year> <pages> pp. 816-828. </pages>
Reference-contexts: Several years later, Brooks proposed a layered approach with each layer integrating perception and action as a solution to problems of real-time robotics [8]. Similar ideas surfaced again in the work of Aloimonos, who was trying to circumvent the practical difficulties of reconstructionist vision <ref> [2] </ref>, and Ballard, who, like Arbib, was modeling biological vision [6]. Partly as a result of this repeated convergence, the notion of vision as a collection of concurrent, special-purpose strategies is once again gaining popularity. We believe SLS gives a boost to theories of goal-directed (a.k.a. purposive) vision.
Reference: [3] <author> M.A. Arbib. </author> <title> The Metaphorical Brain: An Introduction to Cybernetics as Artificial Intelligence and Brain Theory. </title> <address> New York: </address> <publisher> Wiley In-terscience, </publisher> <year> 1972. </year>
Reference-contexts: It first appeared in the early 1970's in the work of Arbib, who modeled perception in terms of action-oriented schemas <ref> [3, 4] </ref>. Several years later, Brooks proposed a layered approach with each layer integrating perception and action as a solution to problems of real-time robotics [8].
Reference: [4] <author> M.A. Arbib. </author> <title> "Segmentation, Schemas, </title> <booktitle> and Cooperative Computation," Studies in Mathematical Biology, </booktitle> <volume> pt. 1. </volume> <editor> S. Levin (ed.). </editor> <booktitle> MAA Studies in Mathematics, </booktitle> <volume> vol. 15, </volume> <year> 1978, </year> <pages> pp. 118-155. </pages>
Reference-contexts: It first appeared in the early 1970's in the work of Arbib, who modeled perception in terms of action-oriented schemas <ref> [3, 4] </ref>. Several years later, Brooks proposed a layered approach with each layer integrating perception and action as a solution to problems of real-time robotics [8].
Reference: [5] <author> M.A. Arbib. </author> <title> "Schema Theory," </title> <booktitle> in The Encyclopedia of Artificial Intelligence, 2nd ed., </booktitle> <address> S.C. Shaprio (ed.) New York: </address> <publisher> Wiley and Sons, </publisher> <year> 1992, </year> <pages> pp. 1427-1443. </pages>
Reference-contexts: This goal-directed approach has roots in the psychology literature of the 1960's and 1 Although the citation is to the original source, we discovered this quotation in the introductory paragraph of Dana Ballard's article on animate vision [6]. 3 the cybernetics literature of the 1940's and '50s. (See Arbib <ref> [5] </ref> for a review.) What is particularly compelling about this approach, however, is that it keeps resurfacing in the computer vision literature with different motivations. It first appeared in the early 1970's in the work of Arbib, who modeled perception in terms of action-oriented schemas [3, 4].
Reference: [6] <author> D.H. Ballard. </author> <title> "Animate Vision," </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <month> 57-86 </month> <year> (1991). </year>
Reference-contexts: This goal-directed approach has roots in the psychology literature of the 1960's and 1 Although the citation is to the original source, we discovered this quotation in the introductory paragraph of Dana Ballard's article on animate vision <ref> [6] </ref>. 3 the cybernetics literature of the 1940's and '50s. (See Arbib [5] for a review.) What is particularly compelling about this approach, however, is that it keeps resurfacing in the computer vision literature with different motivations. <p> Similar ideas surfaced again in the work of Aloimonos, who was trying to circumvent the practical difficulties of reconstructionist vision [2], and Ballard, who, like Arbib, was modeling biological vision <ref> [6] </ref>. Partly as a result of this repeated convergence, the notion of vision as a collection of concurrent, special-purpose strategies is once again gaining popularity. We believe SLS gives a boost to theories of goal-directed (a.k.a. purposive) vision.
Reference: [7] <author> C.E. Brodley. </author> <title> "Addressing the Selective Superiority Problem: Automatic Algorithm/Model Class Selection," </title> <booktitle> Proc. of Tenth International Machine Learning Conference, </booktitle> <address> June 27-29, Amherst, MA., </address> <pages> pp. 17-24. </pages>
Reference-contexts: Any two-class classifier can be used, and we are currently developing recognition graphs that use artificial neural networks and multivariate decision trees instead. (One could also build a hybrid system that selected the best classification induction algorithm for each level of abstraction, a la Brodley <ref> [7] </ref>.) It is important, however, that the classifier have a very low false negative rate. At all but the highest level of abstraction, if a classifier verifies a false instance the mistake will most likely be corrected when the instance is transformed to the next level of representation.
Reference: [8] <author> R.A. Brooks. </author> <title> "Intelligence without Representation." </title> <booktitle> Proc. of the Workshop on the Foundations of Artificial Intelligence, </booktitle> <address> Cambridge, MA.: </address> <publisher> MIT Press, </publisher> <year> 1987. </year> <month> 4 </month>
Reference-contexts: It first appeared in the early 1970's in the work of Arbib, who modeled perception in terms of action-oriented schemas [3, 4]. Several years later, Brooks proposed a layered approach with each layer integrating perception and action as a solution to problems of real-time robotics <ref> [8] </ref>. Similar ideas surfaced again in the work of Aloimonos, who was trying to circumvent the practical difficulties of reconstructionist vision [2], and Ballard, who, like Arbib, was modeling biological vision [6].
Reference: [9] <author> B. Draper, A. Hanson and E. Riseman. </author> <title> "Learning Blackboard-based Scheduling Algorithms for Computer Vision," </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 7(2), </volume> <year> 1993. </year>
Reference: [10] <author> B. Draper. </author> <title> Learning Object Recognition Strategies. </title> <type> Ph.D. dissertation, </type> <institution> Univ. of Mas-sachusetts, </institution> <year> 1993. </year> <note> Available as tech. report 93-50 from the Dept. </note> <institution> of Computer Science. </institution>
Reference-contexts: From the problem statements, a set of training images, and a library of visual operators, it learns executable recognition strategies that satisfy the goal by invoking controlled sequences of known operators <ref> [10] </ref>. Figures 1 and 2, for example, show the result of looking for the pose of a specific building and the image location of a tree by reprojecting the hypotheses returned by learned strategies back onto a test image. <p> The pose was recovered by a special-purpose strategy learned by SLS for deter mining the position and orientation of the LGRC. We will not describe the learning algorithms used by SLS here; interested readers are refered to my dissertation <ref> [10] </ref>. Instead, we will present informal conclusions drawn from our experience with SLS, focusing on items that may be of interest to other researchers in the area of machine learning and vision.
Reference: [11] <author> D.C. Marr. </author> <title> Vision. </title> <address> San Francisco: </address> <publisher> W.H. Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: Theory of Vision According to the Encyclopedia of Artificial Intelligence, "the goal of an image understanding system is to transform two dimensional data into a description of the three dimensional spatiotemporal world." [13, pg. 389] 1 Such definitions reflect the influence of Marr and the reconstructionist school of computer vision <ref> [11] </ref>, which holds that vision is the process of reconstructing the three dimensional geometry of a scene from two dimensional images, essentially by inverting the geometry and physics of optical perspective projection. Symbolic recognition is viewed as a secondary process that follows and is dependent upon geometric reconstruction.
Reference: [12] <author> C. McGlone and J. Shufelt. </author> <title> "Incorporating Vanishing Point Geometry Into a Building Extraction System," </title> <booktitle> Proc. of the ARPA Image Understanding Workshop, </booktitle> <address> Washington, D.C., </address> <month> April </month> <year> 1993. </year> <pages> pp. 437-448. </pages>
Reference-contexts: Introduction Computer vision research often involves searching for sequences of visual operators that can achieve a desired goal. For example, McGlone and Shufelt <ref> [12] </ref> recently presented a paper in which they sequenced four simple operators line extraction, corner detection, linking and matching to find roofs in aerial images.
Reference: [13] <author> J.K. Tsotsos. </author> <title> "Image Understanding," </title> <booktitle> in The Encyclopedia of Artificial Intelligence, first edition, </booktitle> <pages> pp. 389-409. </pages> <year> 1987. </year> <month> 5 </month>
Reference-contexts: A Theory of Vision According to the Encyclopedia of Artificial Intelligence, "the goal of an image understanding system is to transform two dimensional data into a description of the three dimensional spatiotemporal world." <ref> [13, pg. 389] </ref> 1 Such definitions reflect the influence of Marr and the reconstructionist school of computer vision [11], which holds that vision is the process of reconstructing the three dimensional geometry of a scene from two dimensional images, essentially by inverting the geometry and physics of optical perspective projection.
References-found: 13

