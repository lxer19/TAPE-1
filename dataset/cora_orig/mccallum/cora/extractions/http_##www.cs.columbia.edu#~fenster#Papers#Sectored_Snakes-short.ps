URL: http://www.cs.columbia.edu/~fenster/Papers/Sectored_Snakes-short.ps
Refering-URL: http://www.cs.columbia.edu/~fenster/Papers/
Root-URL: http://www.cs.columbia.edu
Email: fenster j kender ]@cs.columbia.edu  
Title: Sectored Snakes: Evaluating Learned-Energy Segmentations  
Author: Samuel D. Fenster and John R. Kender 
Address: New York, NY 10027, USA  
Affiliation: Dept. of Computer Science, Columbia University,  
Abstract: We describe how to teach deformable models to maximize image segmentation correctness based on user-specified criteria, and we present a method for evaluating which criteria work best. We present sectored snakes, a formulation that demonstrably improves upon regular snakes. A traditional deformable model (snake in 2D) fails to find an object's boundary when the strongest nearby image edges are not the ones sought. But models can be trained to respond to other image features instead, by learning their probability distributions. The implementor must then decide on which of many image qualities to teach the model. To this end, we show how to evaluate the efficacy of any resulting deformable model, given a sampling of ground truth, a model of the range of shapes tried during optimization, and a measure of shape closeness. In the domain of abdominal CT images, we demonstrate such evaluation on a simple sectoring of a snake, in which intensity and perpendicular gradient are observed over equal-length segments. This specific set of qualities shows a measured improvement over an objective function that is uniform around the shape, and it follows naturally from examination of the latter's failures due to images variations around the organ boundary. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Kass, A. Witkin, and D. Terzopoulos, Snakes: </author> <title> Active contour models, </title> <booktitle> in Proc. ICCV, </booktitle> <pages> pp. 259268, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction In <ref> [1] </ref>, the authors introduced a flexible shape model that moved until it maximized some combination (energy) of its smoothness and the cumulative strength and proximity of nearby image edges. <p> Best is measured by an arbitrary real-valued objective function, or energy. The process of minimizing this energy is sometimes called a force. In the case of a contour in a 2D image, the model is called a snake <ref> [1] </ref>. There are domains in which traditional snakes, attracted to strongest or closest image edges, fail. The strongest edges are often not the edges of the object we seek. <p> Since blurring seems to often prevent energy functions from being able to distinguish right and wrong boundaries, and yet blurring may be necessary for gradient descent optimization, gradual deblurring is indicated a standard robust optimization technique recommended in <ref> [1] </ref>. In addition, there may be domains where correct contours are actually more distinguished at coarse scales. 7 Conclusion and Future Plans We have presented a systematized framework for the training of deformable models based on any chosen shape and image features and objective function model.
Reference: [2] <author> T. E. Boult, S. D. Fenster, and T. O'Donnell, </author> <booktitle> Reinterpreting physically-motivated modeling, in Proc. ARPA Image Understanding Workshop, </booktitle> <address> (Monterey, CA, USA), </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In [1], the authors introduced a flexible shape model that moved until it maximized some combination (energy) of its smoothness and the cumulative strength and proximity of nearby image edges. But there was no right way to set the parameters of this combination <ref> [2] </ref>. 1 Furthermore, it was not established how effective an objective function based on those particular quantities was in the first place.
Reference: [3] <author> K. Lai and R. Chin, </author> <title> Deformable contours: Modeling and extraction, </title> <journal> PAMI, </journal> <volume> vol. 17, </volume> <pages> pp. 10841090, </pages> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: matching intensity profiles at feature points [4], matching multiscale intensity and gradient at feature points [5], and centering within a region of classi fl This work was supported in part by DOD/ONR MURI Grant N00014-95-1-0601, by the New York State Science and Technology Foundation, and by ARPA Contract DACA-76-92-C-007. 1 <ref> [3] </ref> used a minimax criterion to balance shape and image components of their objective function in a manner that had nothing to do with what object was sought in the domain. fied pixels [6]. But few, if any, comparative studies within a domain have been done. <p> Once they are known, the desired object may be found in a new image by finding the shape whose relationship to the image is likeliest, according to the known probability distributions. Although there has been plenty of work on learning the prior probability of a shape, e.g. <ref> [8, 3] </ref>, there has been little on learning a model of shape likelihood given an image. 3.1 Formalizing how to learn Here, we formalize the notion of learning a general deformable model objective function based on arbitrary shape and image features.
Reference: [4] <author> T. Cootes, A. Hill, C. Taylor, and J. Haslam, </author> <title> Building and using flexible models incorporating grey-level information, </title> <booktitle> in Proc. ICCV, </booktitle> <pages> pp. 242246, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Since then, specific other features have been tried in various domains, e.g. matching intensity profiles at feature points <ref> [4] </ref>, matching multiscale intensity and gradient at feature points [5], and centering within a region of classi fl This work was supported in part by DOD/ONR MURI Grant N00014-95-1-0601, by the New York State Science and Technology Foundation, and by ARPA Contract DACA-76-92-C-007. 1 [3] used a minimax criterion to balance <p> This requires a ground truth training set, which is a collection of images, each with the desired contour correctly specified. Such training on image features has been done in <ref> [4] </ref>, whose model learned a knD Gaussian of intensities perpendicular to a shape boundary at k feature points along line segments of n pixels. Within a similar framework, [5] used a Gaussian distribution of multiscale intensity and gradient at a few points around many organs simultaneously in a human cross-section. <p> This calls for a spatially varying objective function. Furthermore, they may have differing degrees of variability at different places, so the function's sensitivity should vary, providing robustness where wide variation is expected. The approach of individually modeling feature points <ref> [4] </ref> would ignore most contour information. We will present sectored snakes, which address these needs within the training framework. 1.3 Measuring effectiveness With such a choice of objective functions, we must be able to compare and evaluate their performance, which is domain-specific. <p> Since these spatial boundary variations are often consistent across images of a particular domain object (Fig. 2), it made sense to formulate a snake that learned what to seek separately on separate portions of its length. In this, we followed <ref> [4] </ref>, although they trained a small number of preselected feature points. We seek an accurate boundary everywhere, so we wish to respond to image data everywhere along the contour, rather than just at a few points.
Reference: [5] <author> B. Baldwin, </author> <title> Multiscale Snakes. </title> <type> PhD thesis, </type> <institution> Courant Institute of New York University, </institution> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Since then, specific other features have been tried in various domains, e.g. matching intensity profiles at feature points [4], matching multiscale intensity and gradient at feature points <ref> [5] </ref>, and centering within a region of classi fl This work was supported in part by DOD/ONR MURI Grant N00014-95-1-0601, by the New York State Science and Technology Foundation, and by ARPA Contract DACA-76-92-C-007. 1 [3] used a minimax criterion to balance shape and image components of their objective function in <p> Such training on image features has been done in [4], whose model learned a knD Gaussian of intensities perpendicular to a shape boundary at k feature points along line segments of n pixels. Within a similar framework, <ref> [5] </ref> used a Gaussian distribution of multiscale intensity and gradient at a few points around many organs simultaneously in a human cross-section. Finally, [7] uses a 3D model incorporating the observed likelihood of nearby edges belonging to the liver or not. Here we formalize the general training framework.
Reference: [6] <author> C. A. Davatzikos and J. L. Prince, </author> <title> An active contour model for mapping the cortex, </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> vol. 14, </volume> <pages> pp. 6580, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Grant N00014-95-1-0601, by the New York State Science and Technology Foundation, and by ARPA Contract DACA-76-92-C-007. 1 [3] used a minimax criterion to balance shape and image components of their objective function in a manner that had nothing to do with what object was sought in the domain. fied pixels <ref> [6] </ref>. But few, if any, comparative studies within a domain have been done. Let us consider what quantity should be optimized when seeking a shape in an image.
Reference: [7] <author> J. L. Boes, C. R. Meyer, and T. E. Weymouth, </author> <title> Liver definition in CT using a population-based shape model, </title> <booktitle> in Proc. 1st Int. Conf. on Computer Vision, Virtual Reality, and Robotics in Medicine (CVRMed '95), </booktitle> <pages> pp. 506512, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Within a similar framework, [5] used a Gaussian distribution of multiscale intensity and gradient at a few points around many organs simultaneously in a human cross-section. Finally, <ref> [7] </ref> uses a 3D model incorporating the observed likelihood of nearby edges belonging to the liver or not. Here we formalize the general training framework. It easily incorporates prior shape probability, though that is not our focus.
Reference: [8] <author> C. Kervrann and F. Heitz, </author> <title> A hierarchical statistical framework for the segmentation of deformable objects in image sequences, </title> <booktitle> in Proc. CVPR, </booktitle> <pages> pp. 724728, </pages> <year> 1994. </year>
Reference-contexts: Once they are known, the desired object may be found in a new image by finding the shape whose relationship to the image is likeliest, according to the known probability distributions. Although there has been plenty of work on learning the prior probability of a shape, e.g. <ref> [8, 3] </ref>, there has been little on learning a model of shape likelihood given an image. 3.1 Formalizing how to learn Here, we formalize the notion of learning a general deformable model objective function based on arbitrary shape and image features.
Reference: [9] <author> G. Borgefors, </author> <title> Hierarchical chamfer matching: A parametric edge matching algorithm, </title> <journal> PAMI, </journal> <volume> vol. 10, </volume> <pages> pp. 849865, </pages> <month> Nov. </month> <year> 1988. </year> <month> 7 </month>
Reference-contexts: We chose the chamfer distance between two boundaries <ref> [9] </ref>, which is the average over one shape of distance to the closest point on the other. To calculate this, one does a distance transform on an image containing one shape, then averages the distance values intersected by the other.
References-found: 9

