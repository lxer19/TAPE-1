URL: ftp://psyche.mit.edu/pub/lksaul/interpolate.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/jordan.html
Root-URL: 
Email: flksaul,jordang@psyche.mit.edu  
Title: A variational principle for model-based interpolation  
Author: Lawrence K. Saul and Michael I. Jordan 
Note: MIT CBCL preprint 1996  
Address: 79 Amherst Street, E10-243 Cambridge, MA 02139  
Affiliation: Center for Biological and Computational Learning Massachusetts Institute of Technology  
Abstract: Given a multidimensional data set and a model of its density, we consider how to define the optimal interpolation between two points. This is done by assigning a cost to each path through space, based on two competing goals|one to interpolate through regions of high density, the other to minimize arc length. From this path functional, we derive the Euler-Lagrange equations for extremal motion; given two points, the desired interpolation is found by solving a boundary value problem. We show that this interpolation can be done efficiently, in high dimensions, for Gaussian, Dirichlet, and mixture models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <booktitle> Proc. of IEEE, vol 78:9 (1990). </booktitle>
Reference-contexts: 1 Introduction The problem of non-linear interpolation arises frequently in image, speech, and signal processing. Consider the following two examples: (i) given two profiles of the same face, connect them by a smooth animation of intermediate poses <ref> [1] </ref>; (ii) given a telephone signal masked by intermittent noise, fill in the missing speech. Both these examples may be viewed as instances of the same abstract problem. <p> Thus our paper will be organized along these lines: in section 2, we consider the problem of intracluster interpolation; in section 3, the problem of intercluster interpolation. Previous approaches to non-linear interpolation have exploited the properties of radial basis function (RBF) networks <ref> [1] </ref> and locally linear models [2]. We have been influenced by both these works, especially in the abstract formulation of the problem. <p> : : :; w N ) 2 R N ; w ff &gt; 0 for all ff; and ff The elements of these vectors have many interpretations, as (i) probability "masses" for an event with N possible outcomes, (ii) hidden unit activations in a normalized radial basis function (RBF) network <ref> [1] </ref>, or (iii) coordinates over the interior of an N -dimensional simplex. Clearly, the multivariate Gaussian is not suited to data of this form, since no matter what the mean and covariance matrix, it cannot assign zero probability to vectors outside the simplex.
Reference: [2] <author> C. Bregler and S. Omohundro. </author> <title> Nonlinear image interpolation using manifold learning. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen (eds.). </editor> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> 973-980. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA (1995). </address>
Reference-contexts: Both these examples may be viewed as instances of the same abstract problem. In qualitative terms, we can state the problem as follows <ref> [2] </ref>: given a multidimensional data set, and two points from this set, find a smooth adjoining path that is consistent with available models of the data. We will refer to this as the problem of model-based interpolation. <p> Thus our paper will be organized along these lines: in section 2, we consider the problem of intracluster interpolation; in section 3, the problem of intercluster interpolation. Previous approaches to non-linear interpolation have exploited the properties of radial basis function (RBF) networks [1] and locally linear models <ref> [2] </ref>. We have been influenced by both these works, especially in the abstract formulation of the problem. <p> (i) from eqs. (24) and (25), express the unknowns ff and K ff in terms of t , w (1) (2) (ii) substitute these expressions into eq. (26) to obtain a one-dimensional equation for t ; (iii) locate (numerically) the root of this equation by searching the interval t 2 <ref> [0; 2] </ref>; (iv) compute numerical values for ff and K ff from the value obtained for t . <p> At n = 0, the path is initialized as a straight line; subsequently, it converges to the circle of means. to the path that traverses the circle of means. The effect is similar, but not identical, to the manifold-snake algorithm of Bregler and Omohundro <ref> [2] </ref>. The main difference lies in the nature of the intermediate solutions. In our case, the interpolant starts out with a pronounced segmentation, then becomes smoother as the boundary crossings adapt according to eq. (31).
Reference: [3] <author> T. Ezzat. </author> <title> Example based analysis and synthesis for images of faces. </title> <institution> MIT EECS M.S. </institution> <note> thesis (1996). 15 </note>
Reference-contexts: Non-linear interpolation is an example of such an operation, one that has important applications to video email <ref> [3] </ref>, low-bandwidth teleconferencing [4], and audiovisual speech recognition [5]. Our approach to this problem is based on a variational principle that assigns a value to each path through space. The modeled density plays a fundamental role in inducing the metric and geometry of this space.
Reference: [4] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Example based image analysis and synthesis. AI Memo 1161, </title> <publisher> MIT (1993). </publisher>
Reference-contexts: Non-linear interpolation is an example of such an operation, one that has important applications to video email [3], low-bandwidth teleconferencing <ref> [4] </ref>, and audiovisual speech recognition [5]. Our approach to this problem is based on a variational principle that assigns a value to each path through space. The modeled density plays a fundamental role in inducing the metric and geometry of this space.
Reference: [5] <author> C. Bregler and S. Omohundro. </author> <title> Nonlinear manifold learning for visual speech recognition. </title> <editor> In E. Grimson (ed.), </editor> <booktitle> Proc. of the 5th Intl. Conf. on Computer Vision, </booktitle> <pages> 494-499. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA (1995). </address>
Reference-contexts: Non-linear interpolation is an example of such an operation, one that has important applications to video email [3], low-bandwidth teleconferencing [4], and audiovisual speech recognition <ref> [5] </ref>. Our approach to this problem is based on a variational principle that assigns a value to each path through space. The modeled density plays a fundamental role in inducing the metric and geometry of this space.
Reference: [6] <author> H. Goldstein. </author> <title> Classical Mechanics. </title> <publisher> Addison-Wesley, </publisher> <address> London (1980). </address>
Reference-contexts: The optimal interpolation between two points is then defined as the path which minimizes this functional. This path (or an approximation to it) is found by deriving the Euler-Lagrange equations <ref> [6] </ref> and solving the associated boundary value problem. We show that this interpolation can be done efficiently, in high dimensions, for Gaussian, Dirichlet, and mixture models [7]. In fact, our framework is especially geared to mixture models, which represent the data as a collection of two or more clusters. <p> Then the path which minimizes this functional obeys the Euler-Lagrange equations: d @ _ q = @q The function L (q; _ q) is known as the Lagrangian. Note, however, that the form of the Lagrangian in eq. (5) is quite different than its counterpart in classical mechanics <ref> [6] </ref>. In our case, the terms in the Euler-Lagrange equations depend on the modeled density, P (q), and the line tension, `. We define the model-based interpolant between two points as the path which minimizes this functional; it is found by solving the associated boundary value problem. <p> For example, one can imagine encoding a sequence of images by the parameters of this equation and a set of initial conditions. Future work will concentrate along these lines. 14 A Calculus of variations In this appendix, we summarize some key results from the calculus of variations <ref> [6] </ref>.
Reference: [7] <author> G. McLachlan and K. Basford. </author> <title> Mixture models: inference and applications to clustering. </title> <publisher> Marcel Dekker (1988). </publisher>
Reference-contexts: This path (or an approximation to it) is found by deriving the Euler-Lagrange equations [6] and solving the associated boundary value problem. We show that this interpolation can be done efficiently, in high dimensions, for Gaussian, Dirichlet, and mixture models <ref> [7] </ref>. In fact, our framework is especially geared to mixture models, which represent the data as a collection of two or more clusters. These models, quite popular in practice, are well-suited to handling complicated (multimodal) data sets.
Reference: [8] <author> W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </author> <title> Numerical Recipes. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge (1986). </address>
Reference-contexts: Suppose we are given two endpoints, a and b, and asked to provide the nonlinear interpolation based on eq. (9). The crux of the boundary value problem <ref> [8] </ref> is to find the initial "shooting" direction at x = a such that the path passes through x = b at some later time.
Reference: [9] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons, </publisher> <address> New York (1991). </address> <month> 16 </month>
Reference-contexts: Then, making a change of variables 3 from w to ln w, we have: P (ln w) = Z where Z is a normalization factor that depends on ff (but not w), and the quantity in the exponent is times the Kullback-Leibler (KL) divergence <ref> [9] </ref>, KL (w fl jjw) = ff ff ln w fl w ff : (13) The KL divergence is a non-negative measure of the mismatch between w and w fl , with KL (w fl jjw) = 0 if and only if w = w fl .
References-found: 9

