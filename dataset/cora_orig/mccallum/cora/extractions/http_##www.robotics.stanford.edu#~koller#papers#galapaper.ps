URL: http://www.robotics.stanford.edu/~koller/papers/galapaper.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/galapaper.html
Root-URL: http://www.robotics.stanford.edu
Email: fkoller,avig@cs.stanford.edu  
Title: Representations and Solutions for Game-Theoretic Problems  
Author: Daphne Koller Avi Pfeffer 
Address: Gates Building 1A  Stanford, CA 94305-9010  
Affiliation: Computer Science Department  Stanford University  
Date: 94(1), July 1997, pages 167-215  April 16, 1997  
Note: In Artificial Intelligence  
Abstract: A system with multiple interacting agents (whether artificial or human) is often best analyzed using game-theoretic tools. Unfortunately, while the formal foundations are well-established, standard computational techniques for game-theoretic reasoning are inadequate for dealing with realistic games. This paper describes the Gala system, an implemented system that allows the specification and efficient solution of large imperfect information games. The system contains the first implementation of a recent algorithm, due to Koller, Megiddo, and von Stengel. Experimental results from the system demonstrate that the algorithm is exponentially faster than the standard algorithm in practice, not just in theory. It therefore allows the solution of games that are orders of magnitude larger than were previously possible. The system also provides a new declarative language for compactly and naturally representing games by their rules. As a whole, the Gala system provides the capability for automated game-theoretic analysis of complex real-world situations.
Abstract-found: 1
Intro-found: 1
Reference: [ Aumann and Hart, 1992 ] <author> R. J. Aumann and S. Hart, </author> <title> editors. </title> <booktitle> Handbook of Game Theory, </booktitle> <volume> Vol. 1. </volume> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1992. </year> <month> 41 </month>
Reference-contexts: Since real life contains many situations involving multiple interactive agents with incompatible goals, game theory has played a role in a variety of different areas. Game theory has been fundamental in economics <ref> [ Aumann and Hart, 1992 ] </ref> , both in the theoretical foundations of microe-conomic theory and in more practical examples (such as the design of the 1995/6 FCC auction of wavelengths [ Norton, 1995 ] ).
Reference: [ Avenhaus et al., 1995 ] <author> R. Avenhaus, B. von Stengel, and S. Zamir. </author> <title> Inspection games. </title> <editor> In R. J. Aumann and S. Hart, editors, </editor> <booktitle> Handbook of Game Theory, </booktitle> <volume> Vol. </volume> <pages> 3, </pages> <note> to appear. </note> <editor> North-Holland, </editor> <address> Amsterdam, </address> <year> 1995. </year>
Reference-contexts: As an example, Figure 6 shows a complete listing of a simple inspection game, which has received significant attention in the game theory community as a model of on-site inspections for arms control treaties <ref> [ Avenhaus et al., 1995 ] </ref> . The inspection game involves two players: a violator, who wants to commit some treaty-violating act (such as nuclear testing), and an inspector who wants to prevent the act. The game takes place over n stages.
Reference: [ Blair et al., 1993 ] <author> J. R. S. Blair, D. Mutchler, and C. Liu. </author> <title> Games with imperfect information. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <year> 1993. </year>
Reference: [ Cottle et al., 1992 ] <author> R. W. Cottle, J.-S. Pang, and R. E. Stone. </author> <title> The Linear Complementarity Problem. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Other standard LP solution algorithms, while slower in practice, can be used to guarantee a worst-case polynomial time for the solution. A different, but related, transformation allows the reformulation of the equilibrium problem for general two-player games as a linear complementarity problem (see <ref> [ Cottle et al., 1992 ] </ref> for a definition): Theorem 5.2: The normal form of a general two-player game defines a linear complementarity problem (LCP) whose solutions are the equilibria of the game. <p> This algorithm resembles the simplex algorithm both in its general operation and in the fact that, while requiring exponential time in the worst case, it is fast in practice. If a comprehensive list of equilibria is required, a general exhaustive enumeration scheme can be used (as in <ref> [ Cottle et al., 1992, p.17 ] </ref> ). This, of course, requires exponential time. At this point, one might think that the problem of solving games is essentially solved, at least in the two-player case.
Reference: [ Dantzig, 1963 ] <author> G. B. Dantzig. </author> <title> Linear Programming and Extensions. </title> <publisher> Princeton University Press, </publisher> <year> 1963. </year>
Reference-contexts: For the zero-sum case, the problem (?) described above can be written as: Find x which achieves: max x min y x T Ay subject to P m P n x; y 0: This problem can be reformulated, by an appropriate use of linear programming duality <ref> [ Dantzig, 1963 ] </ref> , as a simple linear programming problem, resulting in the following theorem [ von Neumann and Morgenstern, 1947 ] : Theorem 5.1: [von Neumann, 1947] The normal form of a zero-sum game defines a linear program (LP) whose solutions are the equilibria (maximin strategies) of the game.
Reference: [ Fagin et al., 1995 ] <author> R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1995. </year>
Reference-contexts: Each node in the execution tree is a possible state that can occur in the game, with the root corresponding to the initial state of the program, and the children of each node corresponding to those states that can follow the state encoded by that node. As in <ref> [ Fagin et al., 1995 ] </ref> , a global state describes both the "external" state of the game and the internal states of the different players. <p> Similarly, nodes that neither player considers possible, but that one player thinks the other player considers possible, can also have an effect on a player's strategy. The only nodes that can be completely eliminated from consideration are those for which it is common knowledge <ref> [ Fagin et al., 1995 ] </ref> that they cannot be reached. 21 It might be possible to develop a solution approach, analogous to the one described above, where we only eliminate such nodes. The resulting algorithm may be useful in some games.
Reference: [ Franklin et al., 1993 ] <author> M. Franklin, Z. Galil, and M. Yung. </author> <title> Eavesdropping games: A graph-theoretic approach to privacy in distributed systems. </title> <booktitle> In Proceedings of the 34th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 670-679, </pages> <year> 1993. </year>
Reference: [ Gordon, 1993 ] <author> S. Gordon. </author> <title> A comparison between probabilistic search and weighted heuristics in a game with incomplete information. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <year> 1993. </year>
Reference: [ Howard et al., 1977 ] <author> R. A. Howard, J. E. Matheson, and K. L. Miller, </author> <title> editors. </title> <booktitle> Readings on the Principles and Applications of Decision Analysis. </booktitle> <institution> Stanford Research Institute, Strategic Decisions Group, </institution> <address> Menlo Park, CA, </address> <year> 1977. </year>
Reference-contexts: In such games, the elimination of unreachable nodes may not significantly reduce the size of the game tree. Some other method of pruning the tree is needed, perhaps one based on the value of information metric (see, e.g., <ref> [ Howard et al., 1977 ] </ref> ). We believe that developing an algorithm that prunes the tree in a principled manner presents an interesting research problem.
Reference: [ Kaelbling et al., 1996 ] <author> L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. </author> <title> Planning and acting in partially observable stochastic domains. </title> <note> Submitted for publication. Can be obtained from http://www.cs.duke.edu/~mlittman/topics/pomdp-page.html, 1996. </note>
Reference-contexts: See <ref> [ Kaelbling et al., 1996 ] </ref> for a survey. 2 by experts. Therefore, the tools provided by game theory are only available to the general public via specialized consultants. * The lack of practical game-theoretic algorithms has prevented the use of game-theoretic de cision making directly by autonomous artificial agents.
Reference: [ Koller and Megiddo, 1992 ] <author> D. Koller and N. Megiddo. </author> <title> The complexity of two-person zero-sum games in extensive form. </title> <journal> Games and Economic Behavior, </journal> <volume> 4 </volume> <pages> 528-552, </pages> <year> 1992. </year>
Reference-contexts: First, in order to substitute a search over realization plans for a search over randomized strategies, we must provide a correspondence between the two spaces. Clearly, not every vector of numbers (of the right length) actually represents some randomized strategy. Lemma 5.4: <ref> [ Koller and Megiddo, 1992 ] </ref> If player k has perfect recall, then there exists a matrix E and a vector e such that a non-negative vector x of dimension m k represents a randomized strategy for player k if and only if Ex = e.
Reference: [ Koller et al., 1994 ] <author> D. Koller, N. Megiddo, and B. von Stengel. </author> <title> Fast algorithms for finding randomized strategies in game trees. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 750-759, </pages> <year> 1994. </year>
Reference-contexts: In Section 5 we survey both the standard game-theoretic solution algorithms based on the normal form of the game, as well as the more recent sequence form algorithms of <ref> [ Koller et al., 1994 ] </ref> . In Section 6, we show how these different ideas come together to form the Gala system, and present the first experimental results comparing the sequence form and the normal form algorithms. <p> We now survey the two main frameworks for solving games in extensive form. In Section 5.1 we survey the traditional normal form algorithms, and in Section 5.2 we review the more recent approach of <ref> [ Koller et al., 1994 ] </ref> . 5.1 Normal form The representation of a game in extensive form is rather complex, requiring many different components (nodes, edges, information sets, chance moves, . . . ) for representing the dynamics of the game and of the players' information state. <p> We can now solve (?) using realization weights as our strategic variables. The similarity between the normal form and sequence form formulations of (?) allow the use of very similar techniques to those used in the proofs of Theorems 5.1 and 5.2, resulting in the following theorems: Theorem 5.5: <ref> [ Koller et al., 1994 ] </ref> The sequence form of a zero-sum game defines a linear program (LP) whose solutions are the equilibria (maximin strategies) of the game. As before, standard LP solution algorithms provide us with polynomial time algorithms for solving such games. <p> As before, standard LP solution algorithms provide us with polynomial time algorithms for solving such games. In the more general case: Theorem 5.6: <ref> [ Koller et al., 1994 ] </ref> The sequence form of a general two-player game defines a linear complementarity problem (LCP) whose solutions are the equilibria of the game. One of these solutions (each of which corresponds to an equilibrium) can be found by Lemke's algorithm [ Lemke, 1965 ] .
Reference: [ Koller et al., 1996 ] <author> D. Koller, N. Megiddo, and B. von Stengel. </author> <title> Efficient solutions of extensive two-person games. </title> <journal> Games and Economic Behavior, </journal> <volume> 14 </volume> <pages> 247-259, </pages> <year> 1996. </year>
Reference: [ Kuhn, 1950 ] <author> H. W. Kuhn. </author> <title> A simplified two-person poker. </title> <editor> In H. W. Kuhn and A. W. Tucker, editors, </editor> <booktitle> Contributions to the Theory of Games I, </booktitle> <pages> pages 97-103. </pages> <publisher> Princeton University Press, </publisher> <year> 1950. </year>
Reference: [ Kuhn, 1953 ] <author> H. W. Kuhn. </author> <title> Extensive games and the problem of information. </title> <editor> In H. W. Kuhn and A. W. Tucker, editors, </editor> <booktitle> Contributions to the Theory of Games II, </booktitle> <pages> pages 193-216. </pages> <publisher> Princeton University Press, </publisher> <year> 1953. </year>
Reference-contexts: Such a distribution is known as a mixed strategy in the game theory literature. Clearly, any randomized strategy generates such a distribution. For games of perfect recall, it is also the case that any such distribution (mixed strategy) is equivalent to a randomized strategy <ref> [ Kuhn, 1953 ] </ref> . This representation of strategies allows us to construct a simple formulation of the problem of finding equilibrium strategies. The advantages are most tangible in the case of two-player games, so we will focus on those for the remainder of the section.
Reference: [ Lemke and Howson, 1964 ] <author> C. E. Lemke and J. T. Howson, Jr. </author> <title> Equilibrium points in bimatrix games. </title> <journal> Journal of the Society for Industrial and Applied Mathematics, </journal> <volume> 12 </volume> <pages> 413-423, </pages> <year> 1964. </year> <month> 42 </month>
Reference-contexts: One of the solutions to this LCP (each of which corresponds to an equilibrium) can be found by the Lemke-Howson algorithm <ref> [ Lemke and Howson, 1964 ] </ref> . This algorithm resembles the simplex algorithm both in its general operation and in the fact that, while requiring exponential time in the worst case, it is fast in practice.
Reference: [ Lemke, 1965 ] <author> C. E. Lemke. </author> <title> Bimatrix equilibrium points and mathematical programming. </title> <journal> Man--agement Science, </journal> <volume> 11 </volume> <pages> 681-689, </pages> <year> 1965. </year>
Reference-contexts: One of these solutions (each of which corresponds to an equilibrium) can be found by Lemke's algorithm <ref> [ Lemke, 1965 ] </ref> . Lemke's algorithm is a simple variant of the Lemke-Howson algorithm, with the same general characteristics. At first glance, these results seem very similar to the normal-form results, so it might not be clear what we have gained.
Reference: [ Lucas, 1972 ] <author> W. F. Lucas. </author> <title> An overview of the mathematical theory of games. </title> <booktitle> Management Science, 15, Appendix P:3-19, </booktitle> <year> 1972. </year>
Reference: [ McKelvey and McLennan, 1996 ] <author> R. D. McKelvey and A. McLennan. </author> <title> Computation of equilibria in finite games. </title> <booktitle> In Handbook of Computational Economics. </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: The ability of the Gala language to capture regularities in the game may be particularly useful in this context, since the high-level description of a game state can provide features for the learning algorithm. 19 <ref> [ McKelvey and McLennan, 1996 ] </ref> also contains an extensive survey of computational methods for finding equilibria of non-zero-sum games. 38 7.2 Scaling up While we can now solve games with tens of thousands of nodes, we are nowhere close to being able to solve huge games such as full-scale poker,
Reference: [ McKelvey, 1992 ] <author> R. D. McKelvey. </author> <title> gambit: Interactive Extensive Form Game Program. </title> <institution> California Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: Gala provides access to these normal-form solution algorithms by interfacing with a state-of-the-art game-theoretic solving system called gambit <ref> [ McKelvey, 1992 ] </ref> . Unfortunately, the normal-form conversion process incurs exponential blowup in the size of the representation, rendering this approach impractical for large games. Gala therefore implements an 4 alternative approach, due to Koller, Megiddo and von Stengel [ 1994 ] , for solving games in extensive form. <p> We are currently working on the implementation of the case of general two-player games. The Gala system is the first to provide an implementation of any of the sequence form algorithms. The other solution method is via an interface to the gambit system <ref> [ McKelvey, 1992 ] </ref> , a state-of-the-art game theory software package which provides a number of game-theoretic solution algorithms (primarily for the normal form). Gala outputs the extensive form of a game in a format readable by gambit, and calls the appropriate gambit routines over the result.
Reference: [ Nash, 1951 ] <author> J. F. Nash. </author> <title> Non-cooperative games. </title> <journal> Annals of Mathematics, </journal> <volume> 54 </volume> <pages> 286-295, </pages> <year> 1951. </year>
Reference-contexts: The basic insight is that deterministic strategies can be predictable, allowing the opponent (s) to gain additional information about the state of the game. Once randomized strategies are allowed, the existence of "optimal strategies" in imperfect information games can be proved <ref> [ Nash, 1951 ] </ref> . In particular, this means that there exists an optimal randomized strategy for poker, in much the same way as there exists an optimal deterministic strategy for chess. <p> In Section 4, we review the basic solution concepts in imperfect information games, including the definition of the Nash equilibrium <ref> [ Nash, 1951 ] </ref> . In Section 5 we survey both the standard game-theoretic solution algorithms based on the normal form of the game, as well as the more recent sequence form algorithms of [ Koller et al., 1994 ] . <p> However, it is far from clear that an equilibrium necessarily exists in complex games involving many moves. In his Nobel-prize winning theorem, Nash [ 1951 ] showed that the use of randomized strategies allows us to guarantee the existence of an equilibrium for imperfect information games. 11 Theorem 4.4: <ref> [ Nash, 1951 ] </ref> Any extensive-form game with perfect recall has an equilibrium solution in randomized strategies. Just as in the case of perfect information games, the equilibrium strategies are particularly compelling when the game is zero-sum.
Reference: [ Norton, 1995 ] <author> R. Norton. </author> <title> Winning the game of business. </title> <journal> Fortune Magazine, </journal> <volume> 131(2):36, </volume> <year> 1995. </year>
Reference-contexts: Game theory has been fundamental in economics [ Aumann and Hart, 1992 ] , both in the theoretical foundations of microe-conomic theory and in more practical examples (such as the design of the 1995/6 FCC auction of wavelengths <ref> [ Norton, 1995 ] </ref> ). Game theory has also been applied in the realm of government policy, law, politics, military analysis (both strategic and tactical), biology, and more. Clearly, situations involving multiple agents also arise in computer science applications.
Reference: [ Parikh, 1992 ] <author> P. Parikh. </author> <title> A game-theoretic account of implicature. </title> <booktitle> In Proceedings of the Fourth Conference on Theoretical Aspects of Reasoning about Knowledge (TARK). </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference: [ Pell, 1992 ] <author> B. Pell. </author> <title> Metagame in symmetric, chess-like games. </title> <editor> In H. van der Herik and L. Allis, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 3 | The Third Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference: [ Rasmusen, 1989 ] <author> E. Rasmusen. </author> <title> Games and Information: An Introduction to Game Theory. </title> <publisher> Basil Blackwell, Oxford, </publisher> <address> U.K. and Cambridge, Mass., </address> <year> 1989. </year>
Reference: [ Romanovsky, 1962 ] <author> J. V. Romanovsky. </author> <title> Reduction of a game with perfect recall to a constrained matrix game (in russian). </title> <journal> Doklady Akademii Nauk SSSR, </journal> <volume> 144 </volume> <pages> 62-64, </pages> <year> 1962. </year>
Reference: [ Rosenschein and Zlotkin, 1994 ] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Consenting agents: Designing conventions for automated negotiation. </title> <journal> AI Magazine, </journal> <volume> 15(3) </volume> <pages> 29-46, </pages> <year> 1994. </year>
Reference-contexts: In artificial intelligence, more and more researchers are turning to game theory for the theoretical foundations of multi-agent systems (see, for example, <ref> [ Rosenschein and Zlotkin, 1994 ] </ref> and the references therein). Despite the growing popularity of game theory as an analytic tool, there has been little work on providing effective automated tools for game-theoretic analysis.
Reference: [ Shenker, 1995 ] <author> S. J. Shenker. </author> <title> Making greed work in networks: A game-theoretic analysis of switch service disciplines. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(6) </volume> <pages> 819-831, </pages> <year> 1995. </year>
Reference: [ Smith and Nau, 1993 ] <author> S. J. J. Smith and D. S. Nau. </author> <title> Strategic planning for imperfect-information games. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <year> 1993. </year>
Reference: [ van Damme, 1983 ] <author> E. van Damme. </author> <title> Refinements of the Nash Equilibrium Concept. </title> <booktitle> Lecture Notes in Economics and Mathematical Systems. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin and New York, </address> <year> 1983. </year>
Reference-contexts: These difficulties are well-known, and have led to the development of an extensive suite of alternative (more refined) solution concepts. The discussion of the different options is beyond the scope of this paper; see <ref> [ van Damme, 1983 ] </ref> for a survey. Currently, there seems to be no consensus as to the "right solution" to this problem. Nevertheless, it would be useful to incorporate one or more of the alternative solutions into the Gala system.
Reference: [ van den Elzen et al., 1996 ] <author> A. van den Elzen, B. von Stengel, and D. Talman. </author> <title> Tracing equilibria in extensive games by complementary pivoting. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference: [ von Neumann and Morgenstern, 1947 ] <author> J. von Neumann and O. Morgenstern. </author> <title> The Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <address> 2nd edition, </address> <year> 1947. </year>
Reference-contexts: Just as in the case of perfect information games, the equilibrium strategies are particularly compelling when the game is zero-sum. Then, as shown by von Neumann <ref> [ von Neumann and Morgenstern, 1947 ] </ref> , any equilibrium strategy is optimal against a rational player. More precisely, 11 Nash's result actually applies to mixed strategies and normal form games, both of which are described in the next section. <p> as: Find x which achieves: max x min y x T Ay subject to P m P n x; y 0: This problem can be reformulated, by an appropriate use of linear programming duality [ Dantzig, 1963 ] , as a simple linear programming problem, resulting in the following theorem <ref> [ von Neumann and Morgenstern, 1947 ] </ref> : Theorem 5.1: [von Neumann, 1947] The normal form of a zero-sum game defines a linear program (LP) whose solutions are the equilibria (maximin strategies) of the game.
Reference: [ von Stengel, 1996 ] <author> B. von Stengel. </author> <title> Efficient computation of behavior strategies. </title> <journal> Games and Economic Behavior, </journal> <volume> 14 </volume> <pages> 220-246, </pages> <year> 1996. </year>
Reference-contexts: Alternative conversions into a reduced normal form also exist. While the reduced normal form is smaller than the normal form, it is still exponential in the size of the game tree. See <ref> [ von Stengel, 1996 ] </ref> for details. 28 Management Science [ 1972 ] 5.2 Sequence form The exponential blowup associated with the normal form makes the standard solution algorithms an unrealistic option for many games.
Reference: [ Zermelo, 1913 ] <author> E. Zermelo. </author> <title> Uber eine Anwendung der Mengenlehre auf die Theorie des Schachspiels. </title> <editor> In E. W. Hobson and A. E. H. Love, editors, </editor> <booktitle> Proceedings of the Fifth International Congress of Mathematicians II, </booktitle> <pages> pages 501-504. </pages> <publisher> Cambridge University Press, </publisher> <year> 1913. </year> <month> 43 </month>
References-found: 34

