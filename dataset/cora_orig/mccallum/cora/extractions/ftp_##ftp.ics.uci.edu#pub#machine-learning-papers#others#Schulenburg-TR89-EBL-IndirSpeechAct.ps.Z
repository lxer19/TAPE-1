URL: ftp://ftp.ics.uci.edu/pub/machine-learning-papers/others/Schulenburg-TR89-EBL-IndirSpeechAct.ps.Z
Refering-URL: http://www.ics.uci.edu/AI/ML/MLAbstracts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (schulenb@ics.uci.edu)  (pazzani@ics.uci.edu)  
Title: Explanation-Based Learning of Indirect Speech Act Interpretation Rules  
Author: David Schulenburg Michael J. Pazzani 
Note: copyright c 1989  
Address: Irvine, CA 92717 USA  
Affiliation: Department of Information Computer Science University of California,  University of California, Irvine  
Abstract: Technical Report - 89 - 11 10 May 1989 Abstract We describe an approach to deriving efficient rules for interpreting the intended meaning of indirect speech acts. We have constructed a system called sally that starts with a few, very general principles for understanding the intention of the speaker of an utterance. After inferring the intended meaning of a particular utterance, sally creates a specialized rule to understand directly similar utterances in the future. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. & Perrault, C. </author> <year> (1980). </year> <title> Analyzing intention in utterances. </title> <journal> Artificial Intelligence, </journal> <volume> 15, </volume> <pages> 143-178. </pages>
Reference-contexts: Finally, as a cognitive model, the approach does not specify how the interpretation rules might be acquired or extended as new plans are learned. The interpretation of an indirect speech act is a function of the plans that the speaker believes the listener is capable of executing (or understanding) <ref> (Perrault and Allen, 1980) </ref>. When an additional plan is acquired, it may be necessary for the knowledge-intensive approach to acquire additional interpretation rules.
Reference: <author> Austin, J. </author> <year> (1962). </year> <title> How to do things with words. </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference-contexts: However, in most contexts, this question should be interpreted as a request for the listener to give the speaker a match. This is a kind of speech act <ref> (Austin, 1962) </ref> called an indirect speech act (Searle, 1975), in which the intent of the speaker differs from the direct, literal meaning of the speaker's utterance. For a computer to take part in a conversation, it is essential that it have the ability to understand indirect speech acts.
Reference: <author> Cohen, P. & Perrault, C. </author> <year> (1979). </year> <title> Elements of a plan-based theory of speech acts. </title> <journal> Cognitive Science, </journal> <volume> 3, </volume> <pages> 177-212. </pages>
Reference: <author> DeJong, G. & Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: An alternate view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 145-176. </pages>
Reference: <author> Fikes, R. & Nilsson, N. </author> <year> (1971). </year> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2, </volume> <pages> 189-208. </pages>
Reference: <author> Gibbs, R. </author> <year> (1983). </year> <title> Do people always process the literal meaning of indirect requests? Journal of Experimental Psychology: Learning, Memory, </title> <journal> and Cognition, </journal> <volume> 3, </volume> <pages> 524-533. </pages>
Reference-contexts: Psycholinguistic studies have shown that in many circumstances, it takes no longer for a person to recognize an indirect speech act than to find the direct meaning of an utterance. For example, in one experiment <ref> (Gibbs, 1983) </ref>, subjects found it no more difficult to find the indirect interpretation of a request such as "Can't you be friendly?" than the literal interpretation. The approach that we take is a hybrid between the specific, knowledge-intensive approach and the general, plan-based approach.
Reference: <author> Gibbs, R. </author> <year> (1984). </year> <title> Literal meaning and psychological theory. </title> <journal> Cognitive Science, </journal> <volume> 8, </volume> <pages> 275-305. </pages>
Reference: <author> Grosz, B. & Sidner, C. </author> <year> (1986). </year> <title> Attention, intentions and the structure of discourse. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 12, </volume> <pages> 175-204. </pages>
Reference: <author> Hinkleman, E. & Allen, J. </author> <year> (1988). </year> <title> How to do things with words, </title> <type> computationally speaking (Technical Report). </type> <institution> Rochester, NY: Computer Science Department, University of Rochester. </institution>
Reference-contexts: Plan-based approaches such as ours ignore the linguistic information associated with the literal meaning of the utterance <ref> (Hinkleman, 1988) </ref>. One solution to this problem, which is more faithful to the psycholinguistic data, is to have rules that map phrases to interpretations without having an intermediate representation of the literal meaning.
Reference: <author> Keller, R. </author> <year> (1987). </year> <title> Defining operationality for explanation-based learning. </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence (482-487). </booktitle> <address> Seattle, WA: </address> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: Next, the example is generalized by retaining only those features of the example which were necessary to produce the explanation. This generalization characterizes the class of problems that will have the same solution for the same reason as the training example. EBL explicates (or operationalizes <ref> (Keller, 1987) </ref>) information that is implicitly represented in a system. For example, aces (Pazzani, 1987) is a system that learns diagnosis heuristics (i.e., efficient heuristics that associate faults with symptoms) from a functional device description.
Reference: <author> Lehnert, W. </author> <year> (1978). </year> <title> The process of question answering. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: However, in most contexts, the intent of the speaker is not to ask for a verification. Rather, the speaker is requesting some action of the hearer, e.g., to give the match to the speaker. The ATRANS-Request Conversion rule <ref> (Lehnert, 1978) </ref> states that given a verification request of a possession state of some object which has little value, a possible target interpretation is a request of the hearer to give the speaker that object. We address here the issue of learning this rule.
Reference: <author> Litman, D. & Allen, J. </author> <year> (1987). </year> <title> A plan recognition model for subdialogues in conversation. </title> <journal> Cognitive Science, </journal> <volume> 11, </volume> <pages> 163-200. </pages> <note> 7 Mitchell, </note> <author> T., Kedar-Cabelli, S., & Keller, R. </author> <year> (1986). </year> <title> Explanation-based learning: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 47-80. </pages>
Reference: <author> Mooney, R. & Bennett, S. </author> <year> (1986). </year> <title> A domain independent explanation-based generalizer. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence (551-555). </booktitle> <address> Philadel-phia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, aces (Pazzani, 1987) is a system that learns diagnosis heuristics (i.e., efficient heuristics that associate faults with symptoms) from a functional device description. In this work, we are using a modified version of the eggs <ref> (Mooney and Bennett, 1986) </ref> explanation-based learning algorithm to explicate conditions under which an indirect interpretation of a speech act can be inferred. 3 If the effect of act is e [Action-Effect Rule] and actor wants e then actor wants act.
Reference: <author> Pazzani, M. </author> <year> (1987). </year> <title> Explanation-based learning for knowledge-based systems. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 26, </volume> <pages> 413-433. </pages>
Reference-contexts: This generalization characterizes the class of problems that will have the same solution for the same reason as the training example. EBL explicates (or operationalizes (Keller, 1987)) information that is implicitly represented in a system. For example, aces <ref> (Pazzani, 1987) </ref> is a system that learns diagnosis heuristics (i.e., efficient heuristics that associate faults with symptoms) from a functional device description.
Reference: <author> Perrault, C. & Allen, J. </author> <year> (1980). </year> <title> A plan-based analysis of indirect speech acts. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 6, </volume> <pages> 167-182. </pages>
Reference-contexts: Finally, as a cognitive model, the approach does not specify how the interpretation rules might be acquired or extended as new plans are learned. The interpretation of an indirect speech act is a function of the plans that the speaker believes the listener is capable of executing (or understanding) <ref> (Perrault and Allen, 1980) </ref>. When an additional plan is acquired, it may be necessary for the knowledge-intensive approach to acquire additional interpretation rules.
Reference: <author> Searle, J. R. </author> <year> (1975). </year> <title> Indirect speech acts. </title> <editor> In P. Cole & J. L. Morgan (Eds.), </editor> <title> Syntax and Semantics, Vol. 3, Speech Acts. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: However, in most contexts, this question should be interpreted as a request for the listener to give the speaker a match. This is a kind of speech act (Austin, 1962) called an indirect speech act <ref> (Searle, 1975) </ref>, in which the intent of the speaker differs from the direct, literal meaning of the speaker's utterance. For a computer to take part in a conversation, it is essential that it have the ability to understand indirect speech acts.
Reference: <author> Wilensky, R. </author> <year> (1983). </year> <title> Planning and understanding. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher> <pages> 8 </pages>
References-found: 17

