URL: http://arti.vub.ac.be/www/krest/robot/sab94.ps
Refering-URL: http://www.cs.brandeis.edu/~zippy/alife-library.html
Root-URL: 
Email: E-mail: steels@arti.vub.ac.be  
Title: A case study in the behavior-oriented design of autonomous agents.  
Author: Luc Steels 
Address: Pleinlaan 2, B-1050 Brussels, Belgium  
Affiliation: Artificial Intelligence Laboratory Vrije Universiteit Brussel  
Abstract: The paper documents a case study in the design and implementation of a robotic multi-agent system. It illustrates known design guidelines, namely that the physics of the environment must be exploited, that behavior is the result from the interaction dynamics between the agent and the environment, and that emergent behavior can and must be utilised whenever possible. But the case study also challenges certain views, such as the subsumption architecture, the need for an action selection mechanism, the goal-oriented design methodology dominating the literature on planning, and the algorithmic style of writing control programs. Alternatives are explored in the form of a cooperative, parallel, behavior-oriented de sign.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arkin, R. </author> <title> (1989) Motor Schema based mobile robot navigation. </title> <journal> Int. Journal of Robotics Research. </journal> <volume> Vol 8, 4 p. </volume> <pages> 92-112. </pages>
Reference-contexts: The first two characteristics of the experiment center around a single agent operating in an environment in which it can gather energy but also benefits from weakening competition for the same energy. The remaining characteristics have been chosen to bring in a multi-agent perspective. <ref> [1] </ref> An agent can recharge itself. The primary goal of an autonomous agent is to sustain itself. This implies at least that the agent has at all times enough energy to keep on functioning. Each agent has therefore a set of batteries and the capability to recharge itself. <p> left back bumper touched fl = AddV alue (LeftSpeed; Jump fl LeftBackBumper); AddV alue (RightSpeed; (Jump + DeltaJump) j fl Lef tBackBumper); = fl 4: W hen right back bumper touched fl = AddV alue (LeftSpeed; (Jump + DeltaJump) j fl RightBackBumper); AddV alue (RightSpeed; Jump fl RightBackBumper); Side effects: <ref> [1] </ref> The inverse translation progressively decreases because the forward movement behavior system brings the speed back to the default. [2] When the robot is touched in the front and the back simultaneously, it will not make any change in movement because the influences cancel each other out. is indeed backward movement <p> A lamp is mounted on the robot and the trace is produced by filtering the images coming from the camera in real time. 3.4 Smooth Obstacle Avoidance. Smooth obstacle avoidance is implemented by the creation of a repelling force field, similar to a potential field <ref> [1] </ref>, based on the measured infrared reflection. <p> AddV alue (RightSpeed; P hotoF actor fl j (value (BlueP hotoLeft) value (BlueP hotoRight)); AddV alue (LeftSpeed; P hotoF actor fl j (value (BlueP hotoRight) value (BlueP hotoLeft)); Side effects: <ref> [1] </ref> A regular zig-zag behavior is typically observed (see figure 3.7). <p> We therefore need an additional influence on the motor speed related to the availability of energy determined by testing whether there is a positive rate of change in the battery charge. AddV alue (RightSpeed; j (DefaultRightSpeed fl EnergyAvailability); AddV alue (LeftSpeed; j (DefaultLef tSpeed fl EnergyAvailability); Side effects: <ref> [1] </ref> As the robot is charging, the batteries will become fuller and less energy will be drawn from the charging station. EnergyInflow will decrease and the default forward movement influence on the motor speeds will take over. <p> the tendency for going towards the boxes and dim out the lights: AddV alue (RightSpeed; P hotoF actor fl j (value (Y ellowP hotoLeft) value (Y ellowP hotoRight)) j =EnergyDrain); AddV alue (LeftSpeed; P hotoF actor fl j (value (Y ellowP hotoRight) value (Y ellowP hotoLeft)) j =EnergyDrain); Side effects: <ref> [1] </ref> As the robot is attracted to the yellow light, there is enough momentum that it will bump into the box, thus causing the light to be dimmed. <p> For example, there is no explicit parking behavior. It emerges from the interaction between blue phototaxis and obstacle avoidance. The case study also explores some novel design prin ciples: <ref> [1] </ref> We use a cooperative as opposed to a subsumption architecture. Our approach has been to progressively consider different behaviors, each time adding more 6 mechanisms to achieve more competence. This method-ology has been recommended by several researchers, in particular Brooks [2].
Reference: [2] <author> Brooks, R. </author> <title> (1991) Intelligence without reason. </title> <booktitle> Proceedings of IJCAI-91. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo Ca. p. </address> <pages> 569-595. </pages>
Reference-contexts: McFarland [7] has defined the biological background and motivation for the experiment. Designing autonomous agents and multi-agent systems is notoriously difficult. The paper intends to illustrate a set of design guidelines about which there seems to be a consensus in the field <ref> [2] </ref>: (a) exploit the physics, (b) exploit the interaction dynamics between the agent and the environment, and (c) use emergent behavior when possible. <p> When these charging rods make contact with the disks, current is drawn and the battery starts charging. There is a continuous supply of energy to the The main processor is a pocket PC computer inserted in the robot body. whole system. <ref> [2] </ref> There is competition for energy in the form of additional lights. There are lamps which are in competition for the overall energy available in the ecosystem. The lamps are mounted in boxes installed in the environment (figure 2). <p> fl Lef tBackBumper); = fl 4: W hen right back bumper touched fl = AddV alue (LeftSpeed; (Jump + DeltaJump) j fl RightBackBumper); AddV alue (RightSpeed; Jump fl RightBackBumper); Side effects: [1] The inverse translation progressively decreases because the forward movement behavior system brings the speed back to the default. <ref> [2] </ref> When the robot is touched in the front and the back simultaneously, it will not make any change in movement because the influences cancel each other out. is indeed backward movement and a turning away to the left. <p> that there must be for a while forward movement then left turn to a certain angle, then again forward movement, etc.) but follows from the interaction between the agent's internal dynamics and those of the environment, in particular the changing position of the agent with respect to the charging station. <ref> [2] </ref> The robot will end up between the walls of the charging station (and thus ready for charging) due to the interaction between the obstacle avoidance and pho-totaxis behaviors (figure 3.7). As the robot is attracted to the light, it moves in on the charging station. <p> EnergyInflow will decrease and the default forward movement influence on the motor speeds will take over. Consequently the robot will leave the charging station. <ref> [2] </ref> If the available current is reduced as a result of competition from the box-lights, EnergyAvailability decreases. If competition for the energy from the lights increases, less current will be available from the charging station and EnergyInflow decreases. <p> The bumping causes touch-based obstacle avoidance and therefore retraction, but because the is still causing phototaxis, a second approach takes place, etc. <ref> [2] </ref> Bumping stops when there is no longer yellow light emmitted by the lamp associated with the box. <p> This leads to a more efficient exploitation of the available energy. These extensions will be discussed in another paper. The case study illustrates some of the design guidelines published earlier <ref> [2] </ref>: * The physics of the agent and the ecosystem is exploited. For example, the momentum from forward movement enforced by yellow phototaxis causes the robot to bump into a box and thus dim the light. <p> Our approach has been to progressively consider different behaviors, each time adding more 6 mechanisms to achieve more competence. This method-ology has been recommended by several researchers, in particular Brooks <ref> [2] </ref>. But we see additional behavior systems cooperating rather than subsuming existing behavior systems. A particular behavior system may never inhibit the in- or outflow of information to another behavior system and the effects of different behavior systems are always summed. <p> A particular behavior system may never inhibit the in- or outflow of information to another behavior system and the effects of different behavior systems are always summed. In this sense, the architecture is a cooperative as opposed to a subsumption architecture. <ref> [2] </ref> We use parallelism as opposed to action selection.
Reference: [3] <author> Jones, J.L. </author> <title> and A.M. Flynn (1993) Mobile Robots. Inspiration to implementation. A.K. </title> <publisher> Peters, </publisher> <address> Wellesley Ma. </address>
Reference-contexts: Prototypes of the agents have been built using Lego TM - technology (figure 1) (as in [4] or <ref> [3] </ref>). A more robust version of the agents, which can operate for days in a row, is currently under construction. <p> The charging station emits blue light and the boxes emit yellow light. The agent performs phototaxis using photosensors mounted on the left and right sides of the body. They are covered with filters to be only sensitive to yellow or blue light. <ref> [3] </ref> There is an opportunity for cooperation between agents. Obviously it would be beneficial for the agent which is recharging, if there were another agent weakening the competition for the available energy. So there is an opportunity for cooperation. <p> However, the action of doing obstacle avoidance is never explicitly selected. It is always there. The same is true for all the other `actions' observable in the experiment. <ref> [3] </ref> We perform a behavior-oriented as opposed to a goal-oriented design. There is a long tradition in AI to perform design by identifying goals, identifying actions that can satisfy those goals, and by then refining the analysis in terms of preconditions and postconditions.
Reference: [4] <author> Donnett, J. and T. </author> <title> Smithers (1990) Lego Vehicles: A Technology for studying intelligent systems. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 540-569. </pages>
Reference-contexts: Prototypes of the agents have been built using Lego TM - technology (figure 1) (as in <ref> [4] </ref> or [3]). A more robust version of the agents, which can operate for days in a row, is currently under construction. <p> So there is an opportunity for cooperation. While one agent recharges, the other one seeks out boxes and pushes against them to dim the lights. In a first series of experiments we use two agents, but a larger group is planned. <ref> [4] </ref> One agent cannot survive. more agents, obstacles, a charging station and boxes with lamps mounted in them. The agents can cooperate but they are also in competition and can potentially exploit each other. <p> For some behaviors, a behavior system is developed which establishes the desired behavior in continuous interaction with the environment. This behavior system is integrated with already existing behavior systems (to ensure that the mutual influences are compatible) and it is always active. <ref> [4] </ref> Control programs are based on dynamical systems as opposed to algorithms. There are no sequential steps, control flow in the form of goto's, conditional statements, timers, etc. Instead each behavior system establishes a continuous link between a set of quantities and a set of other quantities.
Reference: [5] <author> Maes, P. </author> <title> (1989) The Dynamics of Action Selection. </title> <booktitle> In: Proceedings of the 11th International Joint Conference on AI (IJCAI 89) Morgan Kauf-mann, </booktitle> <publisher> Pub. </publisher> <address> Los Altos. p. </address> <pages> 991-997. </pages>
Reference-contexts: Consequently it is in its own interest to let the other agent occasionally get on the charging station. Each agent has the capability to emit sound and to perceive sound through a microphone. Using this capability an agent can indicate that it needs to be on the charging station. <ref> [5] </ref> A balance must be sought between egoism and altruism. An agent can help another agent get to the charging station by turning additional light on, so that the other agent has better chances to reach the charging station through phototaxis. <p> Many researchers assume that the overall activity of the agent has to be split up into different, mutually exclusive actions and that consequently there is an action selection mechanism necessary which selects what action is the most appropriate at a particular point in time <ref> [5] </ref>. Instead, we work from the hypothesis that behavior systems exert a continuous influence on the actuators by a large set of parallel processes. The influences are summed. As observers we sometimes see only one action and not others but this is the consequence of properties in the environment.
Reference: [6] <author> McFarland, D. </author> <title> (1990) Animal behaviour. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference-contexts: There is in addition the kind of cooperation we find between individual animals, such as between two birds that are keeping eggs warm on a nest and occasionally have to go out for food <ref> [6] </ref>. These situations have been well studied in ethology and part of the case study is to make explicit 2 sensors, 6 infrared sensors, 4 bumper sensors, a loudspeaker, and a sensor measuring the energy level in the battery.
Reference: [7] <author> McFarland, D. </author> <title> (1994) Towards Robot Cooperation. </title> <note> [submitted to SAB1994]. </note>
Reference-contexts: Instead of taking a knowledge-oriented approach, in which the agents make models of each other and negotiate through explicit natural language-like communication, we explore a behavior-oriented approach [11] in which cooperation is forced upon the agents by the environment and emerges from the activities of individual agents. McFarland <ref> [7] </ref> has defined the biological background and motivation for the experiment. Designing autonomous agents and multi-agent systems is notoriously difficult. <p> The actuators are a left and right motor and a loudspeaker. comparisons with known properties of animal behavior <ref> [7] </ref>. 3 The behavior systems The robot used for the experiment has the hardware characteristics outlined in figure 3. We use a dynamical systems approach to the programming of the behavior systems using a programming language PDL designed for this purpose [9]. The C-based implementation of PDL is used.
Reference: [8] <author> Nilsson, N. </author> <title> (1994) Teleo-reactive programs for robot control. In: </title> <journal> Journal of AI Research. </journal> <note> [to appear] </note>
Reference-contexts: Existing planning systems all operate with this abstraction. Also in more recent work on reactive agents, a goal-oriented analysis has been proposed <ref> [8] </ref>. Instead we use a behavior-oriented design approach. The different needed observable behaviors are identified. These behaviors have as a side effect that certain goals will be achieved (if one insists on a goal-oriented analysis).
Reference: [9] <author> Steels, L. </author> <title> (1992b) The PDL reference manual. </title> <booktitle> VUB AI Lab memo. </booktitle> <pages> 92-5. 7 </pages>
Reference-contexts: We use a dynamical systems approach to the programming of the behavior systems using a programming language PDL designed for this purpose <ref> [9] </ref>. The C-based implementation of PDL is used. PDL supports a set of quantities (such as Right-FrontIR for the measured reflection of infrared reflection or WeakenCompetitor for the `drive' to seek out competitors). The quantities are frozen at the beginning of a time cycle.
Reference: [10] <author> Steels, L. </author> <title> (1993) Building Agents with Au--tonomous Behavior Systems. </title> <editor> In: Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: It also illustrates some novel principles (see <ref> [10] </ref> for a more extensive discussion): (a) use a cooperative as opposed to a subsumption architecture, (b) use parallelism as opposed to action selection, (c) perform a behavior-oriented as opposed to goal-oriented design, and (d) view control programs as dynamical systems. <p> The rest of this section documents the different behavior systems. For some behavior systems, minor details have been left out due to space limitations. 3.2 Forward movement Forward movement is implemented through a stabiliser <ref> [10] </ref> which adds or subtracts part of the difference between the current speed and the default speed. As a 3 result speed always moves progressively back to the de-fault. The default speed may be different for the left and right motors because motors are not necessarily equal. <p> Obstacles sensed in the back should also be avoided because occasionally the robot may bump into obstacles as it is moving backwards or it may have to move away when another object hits the back. Touch-based obstacle avoidance is accomplished through a disturber <ref> [10] </ref> which increases speed in the opposite direction and causes a rotation away from the touch location (to the left when touched left and to the right when touched right).
Reference: [11] <editor> Steels, L. </editor> <booktitle> (1994) The artificial life roots of artificial intelligence. Artificial Life Journal, Vol 1,1. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge. </address> <month> 8 </month>
Reference-contexts: Instead of taking a knowledge-oriented approach, in which the agents make models of each other and negotiate through explicit natural language-like communication, we explore a behavior-oriented approach <ref> [11] </ref> in which cooperation is forced upon the agents by the environment and emerges from the activities of individual agents. McFarland [7] has defined the biological background and motivation for the experiment. Designing autonomous agents and multi-agent systems is notoriously difficult.
References-found: 11

