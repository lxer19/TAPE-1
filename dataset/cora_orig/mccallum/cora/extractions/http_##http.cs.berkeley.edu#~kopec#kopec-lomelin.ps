URL: http://http.cs.berkeley.edu/~kopec/kopec-lomelin.ps
Refering-URL: http://elib.cs.berkeley.edu:8080/admin/quarterly_reports/report.95.html
Root-URL: 
Title: Document Image Decoding Approach to Character Template Estimation 1  
Author: Gary E. Kopec Mauricio Lomelin 
Keyword: Index Terms: document image decoding, Markov models, template estimation, character recognition  
Date: November 29, 1995  
Affiliation: Xerox Palo Alto Research Center  Microsoft Corp.  
Abstract: This paper develops an approach to supervised training of character templates from page images and unaligned transcriptions. The template estimation problem is formulated as one of constrained maximum likelihood parameter estimation within the document image decoding framework. This leads to a two-phase iterative training algorithm consisting of transcription alignment and aligned template estimation (ATE) steps. The maximum likelihood ATE problem is shown to be NP-complete and thus a number of simple suboptimal solutions are developed. The training procedure is illustrated by its use in creating a document-specific decoder for high-accuracy transcription of a large (400 page) text document. Depending on the language model used, the decoder character error rate is a factor of 7-20 less than that of a commercial omni-font OCR program; the best case error rate is 0.036%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Baird and G. Nagy, </author> <title> A self-correcting 100-font classifier, in Document Recognition, </title> <editor> L. Vincent and T. Pavlidis, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2181, </volume> <pages> pp. 106-115, </pages> <year> 1994. </year>
Reference-contexts: The focus on document-specific models is motivated by the observation that the error rate of a font-specific recognizer can be significantly less than that of a multi-font system <ref> [1] </ref>. Thus, in many cases the cost of constructing specialized templates will be more than offset by a reduced need for post-recognition proofreading and error correction. The traditional approach to creating character templates is to average and threshold a set of aligned sample images for each character.
Reference: [2] <author> D. Bloomberg and L. Vincent, </author> <title> Blur hit-miss transform and its use in document image pattern detection, in Document Recognition II, </title> <editor> L. Vincent and H. Baird, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2422, </volume> <pages> pp. 84-97, </pages> <year> 1995. </year>
Reference-contexts: Templates with both *** Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 9 write-black and write-white levels are similar to the hit-miss transforms used for morphological shape recognition <ref> [2] </ref>. Fig. 19 shows a set of multilevel templates for 212 characters in four fonts of the Times family, created as described in section 6. The level parameters are ff 0 = :95, ff 1 = :999 and ff 2 = :001. The background level is rendered as middle gray.
Reference: [3] <author> California Dept. </author> <title> of Water Resources, General Comparison of Water District Acts, </title> <journal> Bulletin 155-94, </journal> <month> March, </month> <year> 1994. </year>
Reference-contexts: Fig. 4 shows a collection of glyph image regions for the Times-Roman character a drawn from a set of scanned pages <ref> [3] </ref>. As the figure illustrates, a glyph image region typically contains glyphs and/or parts of glyphs in addition to the glyph located at the canvas origin. Similarly, it is clear that there can be significant overlap between the glyph image regions at adjacent glyph positions. <p> Many of these documents are relatively long (100-600 pages) and contain statistical information that is useful only if accuractely transcribed. We will use one of the Berkeley documents to illustrate the training algorithms and the use of document-specific templates in image decoding. Bulletin 155 (B155) <ref> [3] </ref> is a report by the California Department of Water Resources (DWR) that summarizes the provisions of 157 state water district acts. The information about each act is presented as a two column table that spans one to five pages. Fig. 10 shows a portion of one table.
Reference: [4] <author> F. Chen, D. Bloomberg and L. Wilcox, </author> <title> Spotting phrases in lines of imaged text, Document Recognition II, </title> <editor> L. Vincent and H. Baird, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2422, </volume> <pages> pp. 256-269, </pages> <year> 1995. </year> *** <note> Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 33 </note>
Reference-contexts: However, it can be very expensive, even with powerful interactive tools such as those described in [7]. The success of automatic speech recognition systems based on hidden Markov models (HMMs) has motivated recent attempts to develop HMM-based methods for printed text recognition <ref> [12, 4] </ref>. One of the main advantages of the HMM approach is that optimal estimation of character model parameters can be carried out using whole word or text line images with unaligned transcriptions. This eliminates the need for segmentation of the training data into individual glyph images prior to training.
Reference: [5] <author> P. Chou, </author> <title> Recognition of equations using a two-dimensional stochastic context-free grammar, </title> <booktitle> SPIE Conf. on Visual Communications and Image Processing, </booktitle> <address> Philadelphia, PA, </address> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: The training procedure is applicable to a class of multilevel character shape models that generalizes the bilevel models defined in [11]. The principles underlying the method apply to a general class of layout models based on stochastic context-free attribute grammars <ref> [5, 6] </ref>. For simplicity, however, we will develop the method for the important specific case of Markov image sources [11]. The rest of this paper is organized as follows. Section 2 briefly reviews Markov image sources and formulates the supervised maximum likelihood template estimation problem.
Reference: [6] <author> P. Chou and G. Kopec, </author> <title> A stochastic attribute grammar model of document production and its use in document image decoding, Document Recognition II, </title> <editor> L. Vincent and H. Baird, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2422, </volume> <pages> pp. 66-73, </pages> <year> 1995. </year>
Reference-contexts: The training procedure is applicable to a class of multilevel character shape models that generalizes the bilevel models defined in [11]. The principles underlying the method apply to a general class of layout models based on stochastic context-free attribute grammars <ref> [5, 6] </ref>. For simplicity, however, we will develop the method for the important specific case of Markov image sources [11]. The rest of this paper is organized as follows. Section 2 briefly reviews Markov image sources and formulates the supervised maximum likelihood template estimation problem.
Reference: [7] <author> T. Fruchterman, DAFS: </author> <title> a standard for document and image understanding, </title> <booktitle> Proc. 1995 Symposium on Document Image Understanding Technology, </booktitle> <address> Bowie, MD, </address> <month> Oct. </month> <pages> 24-25, </pages> <year> 1995, </year> <pages> pp. 94-100. </pages>
Reference-contexts: Manual segmentation and labeling is a simple and reliable approach to data preparation that is applicable to a wide variety of document types. However, it can be very expensive, even with powerful interactive tools such as those described in <ref> [7] </ref>. The success of automatic speech recognition systems based on hidden Markov models (HMMs) has motivated recent attempts to develop HMM-based methods for printed text recognition [12, 4]. <p> A simple way to obtain initial templates is to excise a sample of each required character from the training images using an interactive tool <ref> [7] </ref>. Alterna *** Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 18 write-white space character template. Right: Support of write-black printing character template. tively, initial templates can be derived from an existing bitmap or outline font.
Reference: [8] <author> J. Hopcroft and J. Ullman, </author> <title> Introduction to Automata Theory, </title> <booktitle> Languages and Computation, 1979, </booktitle> <address> Reading: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The resulting complete path defines an alignment between M and Z. The transcription image source can be constructed using a straightforward extension to the *** Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 17 standard algorithm for intersecting two finite-state automata <ref> [8] </ref>. This construction is applicable to any Markov image source and transcription that can be described using regular grammars. Thus, for example, templates for the yellow page model discussed in [11] could be trained using the two-dimensional source models and LaTeX-like transcriptions presented therein.
Reference: [9] <author> A. Kam and G. Kopec, </author> <title> Separable source models for document image decoding, Document Recognition II, </title> <editor> L. Vincent and H. Baird, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2422, </volume> <pages> pp. 84-97, </pages> <year> 1995. </year>
Reference-contexts: Thus, for example, templates for the yellow page model discussed in [11] could be trained using the two-dimensional source models and LaTeX-like transcriptions presented therein. In practice, however, we anticipate that applications of template estimation will primarily involve one-dimensional horizontal source models, such as those described in <ref> [9] </ref>, applied to images of individual text lines. The reason is that full two-dimensional decoding is significantly more expensive computationally than line decoding and is unnecessary if the lines can be extracted reliably through simpler means. <p> The error calculation included space characters and ignored differences in font. The character unigram language model allows any of the 212 characters to follow any other and exactly corresponds to the simple text column model described in <ref> [11, 9] </ref>. The unigram model imposes no constraints on character sequencing and thus places the entire recognition burden on the templates. As table 3 shows, the unigram error rate of 0.11% is about a factor of seven less than that of the omni-font system.
Reference: [10] <author> G. Kopec and P. Chou, </author> <title> Automatic generation of custom document image decoders, </title> <booktitle> Proc. Second Intl. Conf. on Document Analysis and Recognition, </booktitle> <address> Tsukuba Science City, Japan, </address> <month> Oct. </month> <pages> 20-22, </pages> <year> 1993. </year>
Reference-contexts: A major issue in applying DID to a particular recognition problem is developing explicit models of the character shapes and positioning in the documents to be recognized <ref> [10] </ref>. Unlike most approaches to character recognition, DID emphasizes the use of document-specific bitmap templates as character models, rather than omni-font feature-based models.
Reference: [11] <author> G. Kopec and P. Chou, </author> <title> Document image decoding using Markov source models, </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 16, no. 6, </volume> <month> June, </month> <year> 1994, </year> <pages> pp. 602-617. </pages>
Reference-contexts: 1 Introduction Document image decoding (DID) is an approach to document recognition that is based on a communication theory view of the processes of document creation, transmission and recognition <ref> [11] </ref>. A major issue in applying DID to a particular recognition problem is developing explicit models of the character shapes and positioning in the documents to be recognized [10]. <p> The iteration can be started in either phase, i.e., by providing either a set of initial glyph positions or a set of initial templates. The training procedure is applicable to a class of multilevel character shape models that generalizes the bilevel models defined in <ref> [11] </ref>. The principles underlying the method apply to a general class of layout models based on stochastic context-free attribute grammars [5, 6]. For simplicity, however, we will develop the method for the important specific case of Markov image sources [11]. The rest of this paper is organized as follows. <p> multilevel character shape models that generalizes the bilevel models defined in <ref> [11] </ref>. The principles underlying the method apply to a general class of layout models based on stochastic context-free attribute grammars [5, 6]. For simplicity, however, we will develop the method for the important specific case of Markov image sources [11]. The rest of this paper is organized as follows. Section 2 briefly reviews Markov image sources and formulates the supervised maximum likelihood template estimation problem. Section 3 defines the multilevel source and channel models. Section 4 discusses aligned template estimation for multilevel models. <p> In <ref> [11] </ref> the ideal and observed images are taken to be bilevel bitmaps, with pixel values of 0 and 1 corresponding to background (normally white) and foreground (normally black), respectively, and U is the bitwise inclusive or operator. <p> A valid fi is required to satisfy the template disjointness constraint, which can be informally stated as the requirement that the shifted templates Q t i [~x i ] on the right hand side of (1) have disjoint support <ref> [11] </ref>. The disjointness constraint is motivated by the observation that typefaces are normally designed so that adjacent characters in a line of printed text do not overlap. The template disjointness constraint is formalized as follows. <p> where the subscripts on Q ;fi reflect dependence on both the *** Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 6 path and the template parameters, and thus (4) becomes ^ fi = arg max X Pr fZ j Q ;fi g Pr fg : (5) As discussed in <ref> [11] </ref>, it is usual to approximate the sum in (5) by its largest term, in which case ^ fi = arg max max Pr fZ j Q ;fi g Pr fg : (6) Finally, following [11] we note that (6) remains valid if the right hand side is divided by Pr <p> max X Pr fZ j Q ;fi g Pr fg : (5) As discussed in <ref> [11] </ref>, it is usual to approximate the sum in (5) by its largest term, in which case ^ fi = arg max max Pr fZ j Q ;fi g Pr fg : (6) Finally, following [11] we note that (6) remains valid if the right hand side is divided by Pr fZ j Q 0 g, where Q 0 is the all-background image, and the logarithm is taken. <p> and channel models and derives the corresponding likelihood function. 3 Multilevel Image Source and Channel Models Previous published work in DID was based on bilevel image models in which Q and Z are binary images and pixel values of 0 and 1 correspond to background (white) and foreground (black), respectively <ref> [11] </ref>. The standard bilevel channel is the memoryless asymmetric bit-flip channel characterized by two parameters, ff 0 = Pr fz (~x) = 0 j q (~x) = 0g and ff 1 = Pr fz (~x) = 1 j q (~x) = 1g. <p> For the printing characters, the write-black (ff 1 ) and write-white (ff 2 ) levels are rendered in black and white, respectively. The four space templates (e.g. upper left corner) have a single foreground level (ff 2 ) that is rendered in black. The derivation of (11) presented in <ref> [11] </ref> can be generalized to multilevel models by treating each foreground level as a separate bilevel template. <p> This construction is applicable to any Markov image source and transcription that can be described using regular grammars. Thus, for example, templates for the yellow page model discussed in <ref> [11] </ref> could be trained using the two-dimensional source models and LaTeX-like transcriptions presented therein. In practice, however, we anticipate that applications of template estimation will primarily involve one-dimensional horizontal source models, such as those described in [9], applied to images of individual text lines. <p> The model consists of a chain of transitions for the characters of the string plus unit displacement self-transitions for horizontal spacing adjustment. Image decoding using Markov source models with bilevel templates is described in <ref> [11] </ref>. The only change introduced by multilevel templates is in the computation of the template match scores L (Z j Q t [~x]). <p> The error calculation included space characters and ignored differences in font. The character unigram language model allows any of the 212 characters to follow any other and exactly corresponds to the simple text column model described in <ref> [11, 9] </ref>. The unigram model imposes no constraints on character sequencing and thus places the entire recognition burden on the templates. As table 3 shows, the unigram error rate of 0.11% is about a factor of seven less than that of the omni-font system.
Reference: [12] <author> S. Kuo and O. Agazzi, </author> <title> Keyword spotting in poorly printed documents using pseudo 2-d hidden Markov models, </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 16, no. 8, </volume> <month> Aug., </month> <year> 1994, </year> <pages> pp. 842-848. </pages>
Reference-contexts: However, it can be very expensive, even with powerful interactive tools such as those described in [7]. The success of automatic speech recognition systems based on hidden Markov models (HMMs) has motivated recent attempts to develop HMM-based methods for printed text recognition <ref> [12, 4] </ref>. One of the main advantages of the HMM approach is that optimal estimation of character model parameters can be carried out using whole word or text line images with unaligned transcriptions. This eliminates the need for segmentation of the training data into individual glyph images prior to training.
Reference: [13] <author> C. Papadimitriou and K. Steiglitz, </author> <title> Combinatorial Optimization, </title> <booktitle> 1982, </booktitle> <address> Englewood Cliffs: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: We establish the NP-completeness of ATE by showing that any algorithm that solves ATE exactly can be used to solve the independent set problem, which is known to be NP-complete <ref> [13] </ref>. Let G be an undirected graph consisting of a finite set of vertices V = fv 1 : : : v V g and a finite set of edges E = f (v l i ; v r i ); i = 1 : : : Eg. <p> If the template disjointness constraint is removed, a similar construction can be used to show that a solution to the (uncontrained) ATE problem implies a solution to the NP-complete minimum cover <ref> [13] </ref> problem.
Reference: [14] <author> L. Rabiner and B.-H. Juang, </author> <title> Fundamentals of Speech Recognition, </title> <booktitle> 1993, </booktitle> <address> Englewood Cliffs: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: HMM text recognizers typically are based on a simple 1-dimensional typsetting model in which a line of text can be partitioned into individual glyphs by vertical cuts. Thus, although HMM training procedures such as the Baum-Welch (forward-backward) algorithm <ref> [14] </ref> do not require segmented input, they do assume that the input is segmentable into disjoint rectangular regions representing individual glyphs. *** Kopec and Lomelin; CTE... (DRAFT, do not distibute) *** 2 Complex graphical notations such as music and equations are not well described in terms of non-overlapping rectangular components. <p> This is a constrained decoding problem that is analogous to the speech recognition problem of training hidden Markov models using sentence-level transcriptions <ref> [14] </ref>. By analogy with the speech case, constrained decoding can be carried out in two steps. First, the image source model and transcription are combined into a transcription image source model.
Reference: [15] <author> R. Rubenstein, Digital Typography, </author> <year> 1988, </year> <title> Reading: </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: This paper presents an approach to supervised maximum likelihood template estimation, similar in spirit to current HMM methods, that is applicable to the general sidebearing model of character shape and positioning that is widely used in digital typography <ref> [15] </ref>. The inputs to the training procedure are images of whole pages or text lines plus the corresponding unaligned transcriptions. The method does not assume that the training data can be segmented into individual glyphs by rectangular subdivision.
Reference: [16] <author> R. Wilensky, </author> <title> Toward work-centered digital information services, </title> <note> to appear in IEEE Computer, special issue on Building Large-scale Digital Libraries, </note> <month> May, </month> <year> 1996. </year>
Reference-contexts: The most extensive application has been to create document-specific templates for decoding scanned reports in the Environmental Digital Library at the Univ. of California at Berkeley <ref> [16] </ref>. Many of these documents are relatively long (100-600 pages) and contain statistical information that is useful only if accuractely transcribed. We will use one of the Berkeley documents to illustrate the training algorithms and the use of document-specific templates in image decoding.
References-found: 16

