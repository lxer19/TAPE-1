URL: ftp://ftp.idsia.ch/pub/juergen/heat.ps.gz
Refering-URL: http://www.idsia.ch/~juergen/topics.html
Root-URL: 
Email: juergen@idsia.ch  
Title: The Neural Heat Exchanger "Invited Talk" at ICONIP'96  
Author: Jurgen Schmidhuber 
Web: http://www.idsia.ch/~juergen  
Address: Corso Elvezia 36 6900 Lugano, Switzerland  
Affiliation: IDSIA,  
Abstract: The "Neural Heat Exchanger" is an alternative, supervised learning method for multi-layer neural nets. It is inspired by the physical heat exchanger. Unlike backprop, it is entirely local. This makes its parallel implementation trivial. It was first presented during occasional talks since 1990, and is closely related to Hinton et. al.'s recent Helmholtz Machine (1995). For the first time, this paper presents the basic ideas in written form. To fully understand the Neural Heat Exchanger's advantages and limitations, however, much theoretical and empirical work remains to be done. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Dayan and G. E. Hinton. </author> <title> Varieties of Helmholtz machine. Neural Networks, </title> <publisher> in press, </publisher> <year> 1996. </year>
Reference-contexts: No global control mechanism is required. Exchanger is essentially a supervised variant of the recent Helmholtz Machine [3, 2]. Or, depending on the point of view, the Helmholtz Machine is an unsupervised variant of the Neural Heat Exchanger. According to Peter Dayan and Geoff Hinton <ref> [1] </ref>, a trouble with the Neural Heat Exchanger is that in non-deterministic domains, there is no reason why B's output should match F 's input. Dayan and Hinton's algorithm overcomes this problem by using completely separate learning phases for top-down and bottom-up weights.
Reference: [2] <author> P. Dayan, G. E. Hinton, R. M. Neal, and R. S. Zemel. </author> <title> The Helmholtz machine. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 889-904, </pages> <year> 1995. </year>
Reference-contexts: Inputs entering the upper net slowly "heat up" to become like the targets. Targets entering the lower net slowly "cool down" to become like the inputs. No global control mechanism is required. Exchanger is essentially a supervised variant of the recent Helmholtz Machine <ref> [3, 2] </ref>. Or, depending on the point of view, the Helmholtz Machine is an unsupervised variant of the Neural Heat Exchanger.
Reference: [3] <author> G. E. Hinton, P. Dayan, B. J. Frey, and R. M. Neal. </author> <title> The wake-sleep algorithm for unsupervised neural networks. </title> <journal> Science, </journal> <volume> 268 </volume> <pages> 1158-1160, </pages> <year> 1995. </year>
Reference-contexts: Inputs entering the upper net slowly "heat up" to become like the targets. Targets entering the lower net slowly "cool down" to become like the inputs. No global control mechanism is required. Exchanger is essentially a supervised variant of the recent Helmholtz Machine <ref> [3, 2] </ref>. Or, depending on the point of view, the Helmholtz Machine is an unsupervised variant of the Neural Heat Exchanger.
Reference: [4] <author> J. H. Schmidhuber. </author> <title> The Neural Bucket Brigade: A local learning algorithm for dynamic feedforward and recurrent networks. </title> <journal> Connection Science, </journal> <volume> 1(4) </volume> <pages> 403-412, </pages> <year> 1989. </year>
Reference-contexts: One advantage of truly local algorithms is that their parallel implementation is trivial. The method to be described below is designed to be entirely local while still being able to deal with hidden units and non-linearities [5]. See <ref> [4] </ref> for another local alternative. 2 The Neural Heat Exchanger First consider a conventional, physical heat exchanger. See Figure 1 (C). There are two touching water pipes with opposite flow direction. Cold water enters the first pipe. Hot water enters the second pipe.
Reference: [5] <author> J. H. Schmidhuber. </author> <title> The Neural Heat Exchanger, </title> <note> 1990. Talk presented at Technische Universitat Munchen. The same talk was given at University of Colorado at Boulder (1992), at various other institutions, and at Zhaoping Li's NIPS*94 workshop on unsupervised learning. </note>
Reference-contexts: Many suspect, however, that the brain does use an entirely local algorithm. One advantage of truly local algorithms is that their parallel implementation is trivial. The method to be described below is designed to be entirely local while still being able to deal with hidden units and non-linearities <ref> [5] </ref>. See [4] for another local alternative. 2 The Neural Heat Exchanger First consider a conventional, physical heat exchanger. See Figure 1 (C). There are two touching water pipes with opposite flow direction. Cold water enters the first pipe. Hot water enters the second pipe.
References-found: 5

