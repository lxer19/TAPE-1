URL: http://www.icsi.berkeley.edu/ftp/global/pub/ai/lzero/narayanan_proposal.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/ai/lzero/
Root-URL: http://www.icsi.berkeley.edu
Title: THESIS PROPOSAL One more step: An on-line model of metaphoric interpretation  
Author: by Srini Narayanan 
Degree: Professor Jerome A. Feldman, Advisor  
Date: January 30, 1995  
Affiliation: University of California at Berkeley  
Abstract: On-line narrative interpretation can be viewed as the simultaneous satisfaction of two sets of constraints. First, the linguistic structure of the input governs how linguistic constructions are accessed and selected. Second, the agent's mental model of plausible world situations constrains the set of allowable interpretations. My work proposes a uniform processing model where both types of constraints can be represented and their joint effects on interpretation studied. In the model, constructions and conventional metaphors are integrated if this best reduces the uncertainty of the resulting interpretation. Initially, the agent makes a selection choice between competing interpretations based on the degree to which they activate an existing mental model. Once activated the executing mental model sets up a dynamic context which conditions future interpretations of the linguistic input. Preliminary results indicate that the approach proposed here shows promise in solving some well known problems in disambiguation and automatic inference. 
Abstract-found: 1
Intro-found: 1
Reference: [Allen1995] <author> J. A. Allen, </author> <year> 1995. </year> <title> Natural Language Understanding. </title> <publisher> The Benjamin Cummings Publishing Company, </publisher> <year> 1995. </year>
Reference: [Arbib1992] <author> M.A. Arbib, </author> <year> 1992. </year> <title> The Metaphorical Brain: 2. </title> <publisher> Oxford University Press. </publisher>
Reference-contexts: Extending metaphoric interpretation to generate dynamic context and source domain inferences is entirely new and is the significant open computational and linguistic problem addressed in this thesis. In designing the representation of schemas, I intend to borrow methods and techniques from robotics [Brooks1986], [Drescher1991], from computational neuroscience <ref> [Arbib1992] </ref>, and from research in situated automata [Rosenshein1985]. The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis [Jurafsky1992] in several areas. Jurafsky's thesis used the theory of Construction Grammars [Fillmore1989].
Reference: [Brooks1986] <author> R. A. Brooks, </author> <year> 1986. </year> <title> A Robust-layered controlled system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-23. </pages>
Reference-contexts: Extending metaphoric interpretation to generate dynamic context and source domain inferences is entirely new and is the significant open computational and linguistic problem addressed in this thesis. In designing the representation of schemas, I intend to borrow methods and techniques from robotics <ref> [Brooks1986] </ref>, [Drescher1991], from computational neuroscience [Arbib1992], and from research in situated automata [Rosenshein1985]. The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis [Jurafsky1992] in several areas. Jurafsky's thesis used the theory of Construction Grammars [Fillmore1989].
Reference: [Burs1983] <author> M.H. Burstein, </author> <year> 1983. </year> <title> A model of learning by incremental analogical reasoning and debugging. </title> <booktitle> Proceedings of AAAI 83, </booktitle> <year> 1983. </year>
Reference-contexts: So the only possible binding is one that results after the application of the metaphor. If this condition is true for all the predicates in a target domain, then we could conclude that the target is completely structured by the source domain. Some of Burstein's <ref> [Burs1983] </ref> examples exhibit this character and may be good test examples for our hypothesis. * Case 3: M U M = BEL (M jM:t) Interpretation: Target Domain and Source Domain may fill role with equal felicity. In this case we have the following relations.
Reference: [Carberry1991] <author> S. Carberry, </author> <year> 1991. </year> <title> Plan Recognition in Natural Language Dialog. </title> <publisher> Cambridge, MA:MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Scripts illustrate one kind of inference source domain schema execution provides. However, as is well recognized in the plan recognition community <ref> [Carberry1991] </ref>, the process of indexing to world knowledge requires much finer-grained representation and dynamic assemblages than is provided by Scripts. My own study modeling aspectual inferences confirms this hypothesis in metaphoric interpretation, and suggests requirements for schema representation. The topic is discussed in detail in Section 6.
Reference: [Carbonell1982] <author> J. Carbonell, </author> <year> 1982. </year> <title> Metaphor Comrehension. </title> <booktitle> Strategies for natural language processing, </booktitle> <pages> pp 413-433, </pages> <publisher> Lawrence Earlbaum:1982. </publisher>
Reference-contexts: My hypothesis is based on analysis of about 2000 newspaper stories. These predictions are considerably more specific (and hence testable) than those of Carbonell <ref> [Carbonell1982] </ref> who also attempts to categorize the inferential structure provided by the source domain of a metaphoric map. * Aspectual inferences (has fallen versus was falling versus fell versus used to fall, etc.) are preserved.
Reference: [Charniak1976] <author> E. Charniak, </author> <year> 1976. </year> <title> Computational Semantics. </title>
Reference-contexts: In the presence of ambiguity, the interpretation that generated the most number of inferences was selected. While his proposal showed the close connection between world knowledge and interpretation, the uncontrolled nature of forward inferences led to severe intractability and counter-intuitive results <ref> [Charniak1976] </ref>. Later, Schank's group scaled back the effort and used the idea of Scripts [Schank1977], where inferences were limited to narrow domains and text interpretation relied exclusively on stereotyped scenarios.
Reference: [Charniak1988] <author> E. Charniak and R. Goldman, </author> <year> 1988. </year> <title> A logic for semantic interpretation. </title> <booktitle> ACL 1988. </booktitle>
Reference-contexts: There are several other differences in our approaches, and I will point them out in the appropriate sections. Probabilistic network techniques to model the interpretation process have been proposed by Dekai Wu [Wu1993] and Charniak <ref> [Charniak1988] </ref> [Charniak1989]. My proposal is different from these efforts in that I show how conventional metaphors and dynamic context can be brought to bear during interpretation. <p> Return the bindings r i ffi f i with the highest value. 4.1.3 Discussion Steps 1 to 4 of the network construction process similar in spirit to the work of Charniak and his students <ref> [Charniak1988] </ref>, [Charniak1993], [Charniak1994] in dynamic belief net based story understanding. However, the addition of metaphors and constructions, and the use of the decision net make the algorithm quite different from these attempts.
Reference: [Charniak1989] <author> E. Charniak and R. Goldman, </author> <year> 1989. </year> <title> A semantics for probabilistic, quantifier-free, first order languages, with particular emphasis to story understanding. </title> <booktitle> Proceedings of IJCAI, </booktitle> <year> 1989. </year>
Reference-contexts: There are several other differences in our approaches, and I will point them out in the appropriate sections. Probabilistic network techniques to model the interpretation process have been proposed by Dekai Wu [Wu1993] and Charniak [Charniak1988] <ref> [Charniak1989] </ref>. My proposal is different from these efforts in that I show how conventional metaphors and dynamic context can be brought to bear during interpretation. Also, as Norvig and Wilensky observe, [Norvig1990], the proposals of Char-niak and his students did not take into account linguistic usage patterns (such as constructions).
Reference: [Charniak1993] <author> E. Charniak and R. Goldman, </author> <year> 1993. </year> <title> A Bayesian Model of Plan Recognition Artificial Intelligence (64), </title> <booktitle> 1993: </booktitle> <pages> 53-79. </pages>
Reference-contexts: Return the bindings r i ffi f i with the highest value. 4.1.3 Discussion Steps 1 to 4 of the network construction process similar in spirit to the work of Charniak and his students [Charniak1988], <ref> [Charniak1993] </ref>, [Charniak1994] in dynamic belief net based story understanding. However, the addition of metaphors and constructions, and the use of the decision net make the algorithm quite different from these attempts.
Reference: [Charniak1994] <author> E. Cherniak and R. Shimony, </author> <year> 1994. </year> <title> CBA and MAP Explanation. </title> <journal> AI Journal, </journal> <month> Apr. </month> <year> 1994 </year>
Reference-contexts: Return the bindings r i ffi f i with the highest value. 4.1.3 Discussion Steps 1 to 4 of the network construction process similar in spirit to the work of Charniak and his students [Charniak1988], [Charniak1993], <ref> [Charniak1994] </ref> in dynamic belief net based story understanding. However, the addition of metaphors and constructions, and the use of the decision net make the algorithm quite different from these attempts. <p> As I argued earlier, searching for the best explanation given the input is an in instance of abduction. The correspondence between weighted abduction and probabilistic inference was shown by Charniak and Shimony <ref> [Charniak1994] </ref>. In this thesis, I take the view that interpretation is a combination of abduction and prediction. Binding to schemas is primarily an abductive process, while schema execution is a mainly a predictive process.
Reference: [Comrie1976] <author> B. Comrie, </author> <year> 1976. </year> <title> Aspect. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Also implicit at the end of the narrative is the implication France is out of recession. This comes 2 IMPLEMENTATION APPROACH 9 about because of the use of the perfective aspect <ref> [Comrie1976] </ref> in the narrative. 4 Schema name/type pull out Schema instance pullout1 Trajector1 Germany:person2 Tr1.location Trajector2 France:person1 Tr2.location Lm.bottom Landmark Recession:hole1 Rate Status Active Manner Aspect Perfective Tense Past The binding structure shown when the second utterance comes in.
Reference: [Cover1991] <author> T. Cover and J.A. Thomas, </author> <year> 1991. </year> <title> Elements Of Information Theory. </title> <publisher> Wiley Inter-science Publications, </publisher> <year> 1991. </year>
Reference-contexts: In this work, I propose to use a measure based on computing the additional information that different role-filler pairs provide about the situation being described. Mutual information is a standard measure used to model this idea <ref> [Cover1991] </ref>. A variant of the mutual information measure was used by Resnick [Resnick1993] to quantify the selectivity of different predicates for the type of their arguments. He used his technique to predict possible arguments given the occurrence of a specific predicate.
Reference: [Drescher1991] <author> G.L. Drescher, </author> <year> 1991. </year> <title> Made-up minds: A constructivist approach to AI. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Extending metaphoric interpretation to generate dynamic context and source domain inferences is entirely new and is the significant open computational and linguistic problem addressed in this thesis. In designing the representation of schemas, I intend to borrow methods and techniques from robotics [Brooks1986], <ref> [Drescher1991] </ref>, from computational neuroscience [Arbib1992], and from research in situated automata [Rosenshein1985]. The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis [Jurafsky1992] in several areas. Jurafsky's thesis used the theory of Construction Grammars [Fillmore1989].
Reference: [Feldman1989] <author> J. A. Feldman, </author> <year> 1989. </year> <title> Neural Representation Of Conceptual Knowledge. Neural Connections, Mental Computation. </title> <publisher> MIT Press 1989. </publisher>
Reference: [Feldman1994 etal] <author> Feldman, Lakoff, Bailey, Narayanan, Regier, Stolcke, </author> <year> 1994. </year> <title> Lzero: The first four years. To be published in AI Review Journal, </title> <publisher> Kluwer Press, </publisher> <year> 1995. </year>
Reference: [Fillmore1989] <author> Charles Fillmore, </author> <year> 1989. </year> <title> On Grammatical Constructions. </title> <note> Course notes draft. </note>
Reference-contexts: Constructions, metaphors and other knowledge sources are brought to bear on the input to converge onto a schema-binding. Binding to a schema involves selection of the schema and supplying fillers to specific slots in the schema. Schema-slots are a superset of the theta-roles <ref> [Fillmore1989] </ref> in construction grammar or frame-semantics. This schema-specific role-filler representation is called the binding structure of the relevant schema. The problem of disambiguation is a problem of binding at two levels. First, the interpreter has to be able to recognize the linguistic input as referring to a schema. <p> The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis [Jurafsky1992] in several areas. Jurafsky's thesis used the theory of Construction Grammars <ref> [Fillmore1989] </ref>. The basic idea behind this theory is that knowledge of language is represented as a collection of uniform structures or constructions which contain lexical, syntactic, and semantic usage information. Interpretation was divided into the three processes of access, integration and selection.
Reference: [Fauconnier1985] <author> G. Fauconnier, </author> <year> 1985. </year> <title> Mental Spaces. </title> <publisher> MIT Press, </publisher> <year> 1985. </year> <note> REFERENCES 68 </note>
Reference-contexts: The standard belief net inference algorithms will work for this case as well. The exact details of the construction algorithm in the presence of metaphor hierarchies is still to be worked out. 8 DISCUSSION 58 8.5 Other connectors Consider the sentence The mushroom omelet left a large tip <ref> [Fauconnier1985] </ref>. In this case a domain specific metonymy maps the input mushroom omelet to the customer who ordered the eggs. This helps the overall convergence to the schema customer leaves tip. Such connectors can also be felicitously handled in the proposed framework.
Reference: [Gibbs1993] <author> R. Gibbs, </author> <title> 1993 Why idioms are not dead metaphors Idioms: processing, Structure and Interpretation. </title> <publisher> Lawrence Earlbaum and Associates, </publisher> <pages> pp. 55-77, </pages> <year> 1993. </year>
Reference-contexts: While we have narrowed our domain considerably by using metaphoric mappings, we are left with simulating the source domain at multiple levels of resolution. We expect the answer here will come from cognitive constraints and their computational implications. Whenever there are timing studies of metaphor processing such as <ref> [Gibbs1993] </ref>, we can include them. For the vast majority of the stories in our database, metaphoric mappings are used mainly for disambiguation and for fairly shallow inferences (mainly aspectual and context setting inferences for anaphora resolution).
Reference: [GL1990] <author> R.V. Guha, and D.B.Lenat, </author> <year> 1990. </year> <title> Cyc: a mid-term report. </title> <journal> AI Magazine, </journal> <volume> 11 3 (1990), </volume> <pages> 32-59. </pages>
Reference-contexts: While incorporation of such linguistic knowledge is a necessary component of any interpreter, it tends to underconstrain the set of possible interpretations, especially those that require a world model for disambiguation. On the other hand, researchers who have focussed solely on "real-world knowledge" representation <ref> [GL1990] </ref> have yet to demonstrate a system capable of tractably expressing the linguistic richness and regularity observed in human language. The model of interpretation proposed here attempts to provide a uniform processing model where both types of constraints can be represented and their joint effects on interpretation studied.
Reference: [Girard1987] <author> Jean-Yves Girard, </author> <note> 1987 Linear Logic. Theoretical Computer Science 50 (1987) 1-102. </note>
Reference-contexts: One of our interests in this project is to stick as closely as possible to a structured connectionist implementation while retaining a formal specification and analysis process. While the exact correspondence between Petri Nets and Connectionist Networks is yet to be worked out (though Linear Logic <ref> [Girard1987] </ref> may prove to be a unifying semantics), the connection between places and nodes, markings and activation, arc weights and connection weights, token flow and activation flow is obvious.
Reference: [Hobbs1985] <author> J. Hobbs and B. Moore, </author> <year> 1985. </year> <title> Formal Theories Of The Commonsense World. </title> <publisher> Ablex Publishing Corporation, </publisher> <address> NJ. </address>
Reference: [Hobbs1990] <author> J. Hobbs et al., </author> <year> 1990. </year> <title> Interpretation as Abduction. </title> <type> SRI Tech. Note 499, </type> <institution> SRI International, </institution> <address> Menlo Park, Ca, </address> <year> 1990. </year>
Reference-contexts: However, the addition of metaphors and constructions, and the use of the decision net make the algorithm quite different from these attempts. Our interpretation algorithm also takes a step toward formalizing the concept of interpretation as abduction that has characterized much of Jerry Hobbs's work <ref> [Hobbs1990] </ref>. Our algorithm has been implemented for the non-metaphoric case representing bindings as a belief node and not as a decision node. <p> In their argument an utterance is relevant to the extent that it allows easy inferences in the current context. In the presence of ambiguity, the best interpretation is that which is most relevant. In other work, Hobbs <ref> [Hobbs1990] </ref> and others have argued for a backward chaining mode of inference called abduction. As I argued earlier, searching for the best explanation given the input is an in instance of abduction. The correspondence between weighted abduction and probabilistic inference was shown by Charniak and Shimony [Charniak1994].
Reference: [Hobbs1993] <author> J. Hobbs, M. Stickel, D. Appelt, and P. </author> <title> Martin 1993. Interpretation as Abduction. </title> <journal> AI Journal 63, 1-2:69-142. </journal>
Reference: [Howard1981] <author> R.A. Howard and J.E. Matheson, </author> <year> 1981. </year> <title> Influence Diagrams, Strategic Decisions Group, </title> <type> 37, </type> <year> 1981. </year>
Reference-contexts: The access process retrieves constructions from long-term store, and the selection process integrates the accessed constructions dynamically where roles are bound to fillers if the result reduces the uncertainty in explaining the input sentence. 2. The current implementation of the interpretation algorithm dynamically constructs and evaluates an Influence diagram <ref> [Howard1981] </ref>. The orthographic input is the evidence, explanatory constructions are modeled as belief nodes, and potential role-filler binding sites are modeled as decision nodes in the developing network. 3. The decision to bind two constituents is determined by a value function. <p> This makes them an attractive representation for modeling narrative interpretation. Our technique of combining external constraints (such as resource constraints and the role-filler SA measure) with standard belief updating (such as revision of beliefs in the presence of new evidence) uses decision networks <ref> [Howard1981] </ref>. The main intuition is that the interpreter considers all the input evidence as well as its own SA measure and any resource constraints in making a decision to bind to a schema. <p> This results in the most informative binding given the input and the background context (set of unintegrated constructions). 3 METAPHORIC UNIFICATION 21 3.6 Decision networks As mentioned above, the proposed approach to the dynamic construction and evaluation of interpretations involves the use of Influence Diagrams <ref> [Howard1981] </ref>, [Schacter1990]. Influence diagrams are also called Decision networks [Russell1995]. I will be using the terms interchangeably. A decision net is a directed acyclic graph with three types of nodes: namely chance nodes, decision nodes, and value nodes, drawn as circles, squares and diamonds respectively.
Reference: [Jurafsky1992] <author> D. J. </author> <title> Jurafsky 1992. An On-line Computational Model Of Human Sentence Interpretation. </title> <type> UCB Ph.D. thesis 1992. </type>
Reference-contexts: The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis <ref> [Jurafsky1992] </ref> in several areas. Jurafsky's thesis used the theory of Construction Grammars [Fillmore1989]. The basic idea behind this theory is that knowledge of language is represented as a collection of uniform structures or constructions which contain lexical, syntactic, and semantic usage information. <p> This includes schema activation and extraction. Section 7 discusses the proposed approach. This is the main area of current research. 3 METAPHORIC UNIFICATION 17 3 Metaphoric Unification 3.1 Introduction Modeling the access and selection of grammatical constructions formed the nucleus of Dan Juraf-sky's <ref> [Jurafsky1992] </ref> Ph.D. thesis work. While incorporation of such linguistic knowledge is a necessary component of any interpreter, it tends to underconstrain the set of possible interpretations, especially those that require a world model for disambiguation. <p> A class of metaphors (which we will refer to as basic metaphors) map static constructions to dynamic schemas. 3 METAPHORIC UNIFICATION 18 The model we will be using is a probabilistic version of the construction grammar interpreter. The interpreter is described in detail in <ref> [Jurafsky1992] </ref>. The probabilistic version is described in [JN1995]. The basic ideas that carry over to the current discussion are outlined below. 1. Constructions are accessed, integrated and selected probabilistically.
Reference: [JN1995] <author> D. J. Jurafsky and S. Narayanan, </author> <year> 1994. </year> <title> Probabilistic Unification. </title> <type> ICSI TR, </type> <note> In Preparation. </note>
Reference-contexts: However, the solution I propose should deal well with other kinds of ambiguity, such as syntactic ambiguity, lexical ambiguity and semantic ambiguity. In fact the general approach has already shown promise in solving these other disambiguation problems. A detailed exposition of this work can be found in <ref> [JN1995] </ref>. 2.3 Background Modeling online metaphoric interpretation is not new. [Martin1990] studied this problem in his thesis, and in many respects the work proposed here draws on his effort. However, there are many points of difference between the two efforts. <p> Also, as Norvig and Wilensky observe, [Norvig1990], the proposals of Char-niak and his students did not take into account linguistic usage patterns (such as constructions). In more recent work <ref> [JN1995] </ref>, we have demonstrated the utility of incorporating such knowledge. This allows us to study the problem of disambiguation in greater detail than was previously possible. Apriori probabilities of constructions are less important for disambiguation than conditional probabilities, given a context. <p> Details of the various parts of the project can be found in subsequent sections. 2.4 Input/Output * Input. I will assume that input sentences are parsed using a probabilistic Construction Grammar Interpreter (such as SAL+ <ref> [JN1995] </ref>). I propose to enhance the grammar to include metaphoric knowledge. The proposed system will also include a lexicon of the relevant action constructions and the associated theta-role constraints. <p> The model of interpretation proposed here attempts to provide a uniform processing model where both types of constraints can be represented and their joint effects on interpretation studied. In recent work on modeling construction access and selection <ref> [JN1995] </ref>, we viewed the human interpreter as a decision maker who decides to unify a constituent (filler value) to a role or site (a slot in an instantiated construction) if the binding results in a reduction in uncertainty of the resulting interpretation. <p> The interpreter is described in detail in [Jurafsky1992]. The probabilistic version is described in <ref> [JN1995] </ref>. The basic ideas that carry over to the current discussion are outlined below. 1. Constructions are accessed, integrated and selected probabilistically.
Reference: [Kolodner1984] <author> J. </author> <title> Kolodner 1984. Retrieval and Organization Strategies in Conceptual Memory: A computational model. </title> <address> Hillsdale, </address> <month> NJ:Erlbaum </month> <year> 1984. </year>
Reference-contexts: This limitation proved too severe, and led to extensions that pertained to recognizing and using goal-based strategies [Wilensky1983], and dynamic memory assemblages <ref> [Kolodner1984] </ref>. In more recent philosophical work, Sperber and Wilson [Sperber1986] have made an argument in many ways similar to that of Rieger. They argue that the contextual implication of a new utterance is the conclusion that can be drawn from the currently active background knowledge and the input information.
Reference: [LJ1980] <author> G. Lakoff and M. </author> <title> Johnson 1980. Metaphors we live by. </title> <publisher> Chicago, University Of Chicago Press. </publisher>
Reference-contexts: While the overfitting problem is severe where trying to characterize selectional restrictions for a role, it could still be used to rank different possible bindings in a specific context. 2. Several of the possible predicates or arguments to predicates are linked by conventional metaphors [Lakoff1987], <ref> [LJ1980] </ref>. For instance, there are conventional metaphors that link the start of a process to the opening of a container [Martin1990]. Once these metaphors (or static correspondences) are accessed, the common inference, namely, allow access, can apply to both situations.
Reference: [Lakoff1987] <author> G. </author> <title> Lakoff 1987. Women, Fire and Dangerous Things. </title> <publisher> Chicago, University Of Chicago Press, </publisher> <year> 1987. </year>
Reference-contexts: While the overfitting problem is severe where trying to characterize selectional restrictions for a role, it could still be used to rank different possible bindings in a specific context. 2. Several of the possible predicates or arguments to predicates are linked by conventional metaphors <ref> [Lakoff1987] </ref>, [LJ1980]. For instance, there are conventional metaphors that link the start of a process to the opening of a container [Martin1990]. Once these metaphors (or static correspondences) are accessed, the common inference, namely, allow access, can apply to both situations.
Reference: [Lakoff1992] <author> G. Lakoff, </author> <year> 1992. </year> <title> What is Metaphor?. Advances in Connectionist Theory. V2 : Analogical Connections, </title> <publisher> V2. </publisher>
Reference-contexts: This involves the use of a special interface structure called the Binding structure. Finally, I develop a set of computational requirements for schemas and a possible schema representation scheme. 6.1 Cognitive Semantic Results In Cognitive semantics, Lakoff <ref> [Lakoff1992] </ref> has hypothesized that the structure of events is understood metaphorically through mappings to the force dynamic and spatio-temporal domain. The general name for this mapping is the Event Structure Metaphor. The Event Structure Metaphor consists of the following mappings 1. Abstract States are mapped to Locations. 2.
Reference: [Langacker1987] <author> R. Langacker, </author> <year> 1987. </year> <title> Foundations Of Cognitive grammar. </title> <publisher> Stanford University Press. </publisher>
Reference-contexts: Now that we can perform such mappings, this chapter explores the additional benefits to be obtained by simulating the spatio-temporal domain. The Event Structure has as its source domain, agent motions in space. There are other domains that researchers in cognitive science <ref> [Langacker1987] </ref> have identified as basic domains. These include color, orientational and configuration domains, and also basic social behaviors. While the general process of mapping and inference proposed here could be extended to model some of these domains, this discussion will focus mainly on the spatio-temporal domain.
Reference: [Martin1990] <author> J. </author> <title> Martin 1990. An A Computational Model of Metaphor Interpretation. </title> <publisher> Academic Press, </publisher> <address> NY, </address> <year> 1990. </year>
Reference-contexts: A first cut proposal can be found in Section 6.3. In general, the both the target domain and the source domain of a metaphor map generate inferences. The example McEnroe killed Connors <ref> [Martin1990] </ref> illustrates this. The proposed schema representation can potentially model both target and source domain inferences. In this case, we have parallel contexts being maintained, one in the source and another in the target domain. The resulting interpretation is a blending of the two simultaneous inference processes. <p> In fact the general approach has already shown promise in solving these other disambiguation problems. A detailed exposition of this work can be found in [JN1995]. 2.3 Background Modeling online metaphoric interpretation is not new. <ref> [Martin1990] </ref> studied this problem in his thesis, and in many respects the work proposed here draws on his effort. However, there are many points of difference between the two efforts. <p> Several of the possible predicates or arguments to predicates are linked by conventional metaphors [Lakoff1987], [LJ1980]. For instance, there are conventional metaphors that link the start of a process to the opening of a container <ref> [Martin1990] </ref>. Once these metaphors (or static correspondences) are accessed, the common inference, namely, allow access, can apply to both situations. Including such metaphors would reduce the number of possible word sense clusters and thereby impact the overfitting problem. The work outlined in this report attempts to implement these solutions. <p> Tennis:kill ISA Kill, 2. Victor ISA Killer, 3. Defeated ISA Killed. This results in a lower valued binding since each probability 1: 8 Taken from <ref> [Martin1990] </ref>. 9 We have not yet seen how the two different senses of kill become active given the domain and the argument types of the kill schema. <p> Even if the SA measure for both predicates are the same, the target domain schema would be a much more likely candidate for selection. 8.4 Metaphors are structured objects <ref> [Martin1990] </ref> makes a convincing case that metaphors are structured objects that can be arranged in dominance hierarchies.
Reference: [Mcdermott1982] <author> D. </author> <title> Mcdermott 1982. </title> <booktitle> A Temporal Logic For Reasoning About Processes and Plans In Cognitive Science 6: </booktitle> <pages> pp. 101-155 </pages> . 
Reference: [Molloy1982] <editor> M.K. Molloy, et al. </editor> <year> 1982. </year> <title> Performance Analysis Using Stochastic Petri Nets. </title> <journal> IEEE Transactions on Computers, </journal> <note> C-31, No.9, pp.913-917 . REFERENCES 69 </note>
Reference-contexts: Stochastic Transitions are associated with an exponentially distributed random variable that expresses the delay between enabling and firing. Due to the memoryless feature of 6 SCHEMAS 45 the exponential transition, PN's with stochastic transitions are isomorphic to Markov Chains <ref> [Molloy1982] </ref>. 3. Hierarchical Transitions correspond to the activation and execution of a subnet. Hier archical transitions are instantaneous. 6.9 Why Petri Nets? There are several reasons for choosing Petri Nets are our schema representation language. They are outlined below. 1.
Reference: [Murata1988] <author> T. Murata. </author> <year> 1989. </year> <title> Petri Nets: Properties, Analysis, </title> <booktitle> and Applications. In Proc. IEEE-89, V77, </booktitle> <volume> Number 4, </volume> <month> April </month> <year> 1989, </year> <pages> pp. 541-576 </pages> . 
Reference-contexts: The extension to individual tokens preserves the liveness and reachability properties of the underlying ordinary net. Any net with a finite number of types can always be unrolled into an ordinary net by adding special places for type combinations. A general treatment of such nets can be found in <ref> [Murata1988] </ref>. * Transition Types A Process Net consists of three types of transitions, namely deterministic transitions, stochas tic transitions, and hierarchical transitions. 1. Deterministic Transitions fire with a fixed delay after being enabled. The actual delay is an integer which varies depending on the nature of the transition.
Reference: [Narayanan1995] <author> S. Narayanan, </author> <year> 1995. </year> <title> A computational semantics of Aspect. </title> <note> In Preparation. </note>
Reference-contexts: The requirements outlined above suggest a net based model of process semantics. The current model uses a variant of high-level Petri Nets [Nielsen1981]). I have done preliminary investigation of such a model to model aspectual distinctions made by different languages. The work on modeling aspect can be found in <ref> [Narayanan1995] </ref>. Schemas are discussed in Section 6 along with a proposed model. Section 7 discusses the modeling capabilities of Schemas. * The Schema Communication. This includes schema activation and extraction. Section 7 discusses the proposed approach. <p> The overall algorithm or the argu ments here do not depend on this fact. 2. The fall construction has additional slots that pertain to the Aspect and Tense of the input. These features affect the dynamic inferencing process. A detailed model of Aspect can be found in <ref> [Narayanan1995] </ref>. For our purposes in this section, we will simply assume that these are static features that are bound to the values indicated. 3. The inputs "Brazil", "into", and "recession" unambiguously access the country, spatial rela tion and economic state concepts. 12 4. Constructions access conventional metaphors. <p> Since more that one schema may be active, more that one controller needs to be active as well. The use of the causal graph in making aspectual inferences in different languages has been studied in detail in <ref> [Narayanan1995] </ref>. <p> Place a token at the result stage of the schema controller. * TR: b1: create an individual token of type person for the TR. * LM: hole1: create an individual token of type hole1 for the LM. 17 The overall schema allows for other inferences, and can be found in <ref> [Narayanan1995] </ref>. 7 MEETING THE MODELING REQUIREMENTS 54 7.6 Extracting from Schemas When a schema executes, it modifies the binding structure by creating new bindings. We saw how in the example, the slots for the location, goal and destination became bound as a result of schema execution.
Reference: [Nakhimovsky1988] <author> A. Nakhimovsky. </author> <year> 1988. </year> <title> Aspect, Aspectual Class, and the Temporal Structure Of Narrative. </title> <booktitle> In Proc. ACL-88, V4, </booktitle> <volume> Number 2, </volume> <month> June </month> <year> 1988, </year> <pages> pp. 29-44 </pages> . 
Reference: [Nielsen1981] <author> M. Nielsen and G. Plotkin and G. Winskel, </author> <year> 1981. </year> <title> Petri Nets, Event Structures, and Domains, Part I". </title> <booktitle> Theoretical Computer Science, </booktitle> <address> V13, </address> <year> 1981. </year>
Reference-contexts: Should be implementable as a connectionist style of computation (ie. should be based on finite state machines, and should use a generalized spreading activation mechanism for inference). The requirements outlined above suggest a net based model of process semantics. The current model uses a variant of high-level Petri Nets <ref> [Nielsen1981] </ref>). I have done preliminary investigation of such a model to model aspectual distinctions made by different languages. The work on modeling aspect can be found in [Narayanan1995]. Schemas are discussed in Section 6 along with a proposed model. <p> Having established the general characteristics of schemas, we now turn to our working model of their representation. 6.7 Representation Of Schemas We represent schemas as a modified class of Petri Nets <ref> [Nielsen1981] </ref>, where the modifications allow for the representation of stochastic transitions, as well as special compositional states and transitions (decomposable to a an ordered collection of primitive states and transitions). A hierarchical network structures that represent an active schema by simulating execution of the component actions.
Reference: [Norvig1990] <author> P. Norvig and R. Wilensky, </author> <year> 1990. </year> <title> A critical evaluation of commensurable abduction models for semantic interpretation. </title> <booktitle> Proceedings of the Thirteenth Internation Conference on Computational Linguistics, </booktitle> <volume> 3, </volume> <publisher> Helsinki, Finland(1990), </publisher> <pages> 225-230. </pages>
Reference-contexts: Probabilistic network techniques to model the interpretation process have been proposed by Dekai Wu [Wu1993] and Charniak [Charniak1988] [Charniak1989]. My proposal is different from these efforts in that I show how conventional metaphors and dynamic context can be brought to bear during interpretation. Also, as Norvig and Wilensky observe, <ref> [Norvig1990] </ref>, the proposals of Char-niak and his students did not take into account linguistic usage patterns (such as constructions). In more recent work [JN1995], we have demonstrated the utility of incorporating such knowledge. This allows us to study the problem of disambiguation in greater detail than was previously possible.
Reference: [Pear1988] <author> J. Pearl, </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> CA, </address> <year> 1988. </year>
Reference-contexts: One is much more probable than the other, and given the various constraints, the verb construction is selected as the better cause that explains the presence of the input evidence. This formulation allows us to investigate the use of belief network construction and inference techniques <ref> [Pear1988] </ref> to model disambiguation. In the current formulation, as the input utterance comes in, a belief net is constructed where competing constructions accessed by the input are parents of the equivalent input node in the belief net. <p> This allows the selection measure to depend on the overall interpretation, rather than be statically computed and set for a predicate. This requires us to construct a joint probability distribution of several variables. A compact way of representing such a joint distribution is to use belief networks <ref> [Pear1988] </ref>. Belief networks are compact because their topology reflects the independence relationships amongst the different variables. Belief networks also allow distributed inference and an asynchronous control. This makes them an attractive representation for modeling narrative interpretation. <p> Given the state of information at the time of a decision, the alternatives selected maximize a utility function normally associated with a value node. Influence diagrams without value nodes or decision nodes are called Belief Nets <ref> [Pear1988] </ref>. Belief nets are used for probabilistic inference in the presence of changes in information. <p> (when to update the dynamic net construction algorithm) are yet to be worked out and any serious model of timing details with metaphoric integration awaits psycholinguistic research on on-line access and selection of metaphoric knowledge. 11 In the evaluation phase, we use standard belief net inference algorithms for step 2 <ref> [Pear1988] </ref>. Note that once the decision nodes are instantiated, all cycles are blocked, leaving a virtually singly connected network. This allows for the inference algorithms to be local, and linear in the size of the network. <p> In the example, I will concentrate on the qualitative aspects of the construction and evaluation process, since the process of updating CPT entries and the inference algorithm used can be found in <ref> [Pear1988] </ref>. 5.1 Input algorithm. As mentioned earlier, we will assume that the entire phrase has been accessed before selection starts. This may not be the case and the exact timing details of the access and selection process are not modeled. 5 AN EXAMPLE OF THE INTERPRETATION PROCESS 30 1. <p> Thus the product of the 3 belief measures yields the value of the overall conjunctive constraint. Note that in the evidence propagation step <ref> [Pear1988] </ref>, the impact of each instantiation (the messages) are transmitted only to the variables included in the query. For the example, we had three bindings. Figure 11 shows how the schemas are indexed by the predicate fall into. Each such schema executes when a specific set of parameters get instantiated.
Reference: [Pear1994] <author> J. Pearl, </author> <year> 1994. </year> <title> A Probabilistic calculus of actions. </title> <booktitle> Uncertainty in AI, </booktitle> <year> 1994. </year>
Reference: [Resnick1993] <author> P. S. Resnick, </author> <year> 1993. </year> <title> Selection and Information: A class based approach to lexical relationships (Ph.D. </title> <type> Dissertation). </type> <institution> Computer and Information Science, University Of Pennsyl-vania, </institution> <year> 1993. </year>
Reference-contexts: Fillers to theta roles in constructions are selected based on how well a role construction associates with the filler. The measure used here is a variant of an information measure called Selection Association (SA) used by <ref> [Resnick1993] </ref> to quantify how a type of role selects for a filler. This allows us to use standard belief net inference algorithms combined with the SA measure to generate the best interpretation for the input. <p> In this work, I propose to use a measure based on computing the additional information that different role-filler pairs provide about the situation being described. Mutual information is a standard measure used to model this idea [Cover1991]. A variant of the mutual information measure was used by Resnick <ref> [Resnick1993] </ref> to quantify the selectivity of different predicates for the type of their arguments. He used his technique to predict possible arguments given the occurrence of a specific predicate. <p> y) and marginal probability mass functions p (x) and p (y) is the relative entropy between the joint distribution and the product distribution p (x)p (y). 3 METAPHORIC UNIFICATION 19 I (X ; Y ) = x2X y2Y p (x; y) (1) Definition : 2: Selectional Association The Selectional Association <ref> [Resnick1993] </ref>, A (p i ; c) between a predicate p i and an element of the class c is the conditional mutual information provided about the class c by the occurrence of the predicate p i .
Reference: [Rieger1975] <author> C. Rieger, </author> <year> 1975. </year> <title> Language Comprehension. </title> <note> Readings in KR,1975. </note>
Reference-contexts: Having a single underlying domain may allow hardwiring the various combinations. 8 DISCUSSION 56 8 Discussion 8.1 Inference in NLP: Using World Knowledge Using world knowledge in discourse interpretation was first studied extensively by Chuck Rieger <ref> [Rieger1975] </ref> under Roger Schank. In this seminal work, Rieger implemented a system where sentences were mapped to a semantic representation that generated inferences. All possible inferences that could be drawn were drawn. In the presence of ambiguity, the interpretation that generated the most number of inferences was selected.
Reference: [Rosenshein1985] <author> J.S. Rosenschein, </author> <year> 1985. </year> <title> Formal theories of knowledge in AI and Robotics. </title> <booktitle> New Generation Computing 3(4) </booktitle> <pages> 345-357. </pages>
Reference-contexts: In designing the representation of schemas, I intend to borrow methods and techniques from robotics [Brooks1986], [Drescher1991], from computational neuroscience [Arbib1992], and from research in situated automata <ref> [Rosenshein1985] </ref>. The proposed implementation approach also relies on previous work in on-line interpretation, and can be viewed as an extension of Dan Jurafsky's thesis [Jurafsky1992] in several areas. Jurafsky's thesis used the theory of Construction Grammars [Fillmore1989].
Reference: [Russell1994] <author> S.J. Russell, J. Binder, and D. Koller, </author> <year> 1994. </year> <title> Adaptive Probabilistic Networks. </title> <type> UCB Tech Report, </type> <institution> CSD-94-824, </institution> <year> 1994. </year>
Reference-contexts: In fact, one of the potential contributions of the research proposed here would be to spur attempts to tag corpora with metaphoric information. Regarding correct estimates, preliminary results indicate that exact numerical values are not required for the disambiguation problem that we are trying to solve. Also, <ref> [Russell1994] </ref> has recently shown how gradient descent can be used in combination with the standard probabilistic inference algorithms to update the CPT adaptively. Such a scheme has several advantages including localized learning and ability to use prior knowledge in the learning process.
Reference: [Russell1995] <author> S.J. Russell and P. Norvig, </author> <year> 1994. </year> <title> AI: A Modern Approach. </title> <publisher> Prentice Hall Series in AI, </publisher> <year> 1995. </year>
Reference-contexts: Influence diagrams are also called Decision networks <ref> [Russell1995] </ref>. I will be using the terms interchangeably. A decision net is a directed acyclic graph with three types of nodes: namely chance nodes, decision nodes, and value nodes, drawn as circles, squares and diamonds respectively. Nodes correspond to propositions and arcs correspond to interaction between nodes.
Reference: [Schacter1990] <author> R. </author> <month> Schacter </month> <year> 1990. </year> <title> Evaluating Influence Diagrams. Readings in Uncertain Reasoning, </title> <publisher> Morgan Kaufmann, </publisher> <address> CA, </address> <year> 1990, </year> <note> 79 -90. </note>
Reference-contexts: This results in the most informative binding given the input and the background context (set of unintegrated constructions). 3 METAPHORIC UNIFICATION 21 3.6 Decision networks As mentioned above, the proposed approach to the dynamic construction and evaluation of interpretations involves the use of Influence Diagrams [Howard1981], <ref> [Schacter1990] </ref>. Influence diagrams are also called Decision networks [Russell1995]. I will be using the terms interchangeably. A decision net is a directed acyclic graph with three types of nodes: namely chance nodes, decision nodes, and value nodes, drawn as circles, squares and diamonds respectively.
Reference: [Schank1977] <author> R. C. Schank and R.P. </author> <title> Abelson 1977. Script, Plans, Goals, and Understanding: An inquiry into human knowledge structures. </title> <address> Hillsdale, </address> <month> NJ:Erlbaum </month> <year> 1977. </year>
Reference-contexts: When the rest of the input comes in, the pullout1 schema is bound and ready to execute. In fact, once the source domain mapping has been accomplished, the binding structures could be a part of a large Script <ref> [Schank1977] </ref> where the anaphor resolution involves no search. One common Script is: 1. Person1 is moving ahead. 2. Person1 falls into hole. 3. Person1 is pulled out by Person2 out of the hole. 4. Person1 is moving ahead again. <p> While his proposal showed the close connection between world knowledge and interpretation, the uncontrolled nature of forward inferences led to severe intractability and counter-intuitive results [Charniak1976]. Later, Schank's group scaled back the effort and used the idea of Scripts <ref> [Schank1977] </ref>, where inferences were limited to narrow domains and text interpretation relied exclusively on stereotyped scenarios. This limitation proved too severe, and led to extensions that pertained to recognizing and using goal-based strategies [Wilensky1983], and dynamic memory assemblages [Kolodner1984].
Reference: [Shastri1990] <author> L. Shastri and V. Ajjanagadde, </author> <year> 1990. </year> <title> From Structured Associations to Systematic Reasoning. </title> <type> Tech Report 90-05, </type> <institution> CIS, </institution> <month> U.Penn </month> <year> 1990. </year>
Reference-contexts: We also note that in the presence of multiple binding nodes, the number of polytrees is exponential in the number of bindings (each binding node is a cutset). This suggests that accumulating unbound slots makes the evaluation phase intractable. Such a result is compatible with research in reflexive reasoning <ref> [Shastri1990] </ref>, and provides an intriguing avenue for further exploration. While returning the maximum valued interpretation requires us to exactly evaluate all possible interpretations, preliminary results suggest that evaluating a few of the most promising interpretations and setting fairly loose tolerances for the actual probability estimation is sufficient.
Reference: [Sowa1984] <author> John Sowa, </author> <year> 1984. </year> <title> Conceptual Structures: Information Processing in Mind and Machine. </title> <publisher> Addison-Wesley 1984. </publisher>
Reference-contexts: This makes it of potential use in semantic network research. The earliest attempts to use Petri nets to model semantic networks seems 6 SCHEMAS 46 to have been done by Sowa <ref> [Sowa1984] </ref> who modeled data flow in conceptual graphs using a variant of Petri nets. Petri nets also show promise in formalizing aspects of marker passing architectures. 5. <p> Define a new kind of marker that moves backward on the net. Then standard reachability analysis can determine the required action sequences. The second possibility will make the current representation resemble very closely the dataflow graph representation using in Conceptual Graphs <ref> [Sowa1984] </ref>. In Sowa's representation scheme, actor nodes attached to a conceptual graph are also joined to form a dataflow graph. These dataflow graphs resemble Petri nets with two kinds of tokens, namely assertion marks which resemble the forward propagating Petri net tokens, and request marks which are propagated backwards.
Reference: [Sperber1986] <author> D. Sperber and D. Wilson, </author> <year> 1986. </year> <title> Relevance: Communication and Cognition. </title> <publisher> Harvard University Press, </publisher> <year> 1986. </year>
Reference-contexts: This limitation proved too severe, and led to extensions that pertained to recognizing and using goal-based strategies [Wilensky1983], and dynamic memory assemblages [Kolodner1984]. In more recent philosophical work, Sperber and Wilson <ref> [Sperber1986] </ref> have made an argument in many ways similar to that of Rieger. They argue that the contextual implication of a new utterance is the conclusion that can be drawn from the currently active background knowledge and the input information.
Reference: [Talmy1985] <author> Len Talmy, </author> <year> 1985. </year> <title> Lexicalization Patterns:semantic structure in lexical forms In Language Typology and Syntactic Description, </title> <booktitle> V 3, </booktitle> <pages> pp. </pages> <address> 59-138 Cambridge University Press. REFERENCES 70 </address>
Reference-contexts: The selection process can be modeled by formal probabilistic inference techniques. In short, 2 Schemas have the verb and path collapsed, whereas traditionally constructions are indexed by root verb with a path as a parameter. This schema design is currently to ease implementation of schemas. However, as <ref> [Talmy1985] </ref> points out, many languages only allow constructions where the path is a suffix to the root verb, so there is some linguistic justification for this choice. 3 I will denote the metaphoric binding France is interpreted as a person by France:person, where the colon stands for the the Metaphor Country
Reference: [Wilensky1983] <author> R. Wilensky, </author> <year> 1983. </year> <title> Planning and Natural Language Understanding. </title> <publisher> Adddison Wesley, </publisher> <year> 1983. </year>
Reference-contexts: Hence, cetirus paribus, the model gives more weight to the target domain and if a target domain interpretation is felicitous, it will be selected. This extends the Specificity principle <ref> [Wilensky1983] </ref> (which states that all other things being equal, select the more specific interpretation) to metaphoric unification as well. <p> Later, Schank's group scaled back the effort and used the idea of Scripts [Schank1977], where inferences were limited to narrow domains and text interpretation relied exclusively on stereotyped scenarios. This limitation proved too severe, and led to extensions that pertained to recognizing and using goal-based strategies <ref> [Wilensky1983] </ref>, and dynamic memory assemblages [Kolodner1984]. In more recent philosophical work, Sperber and Wilson [Sperber1986] have made an argument in many ways similar to that of Rieger.
Reference: [Wilensky1991] <author> R. Wilensky, </author> <year> 1991. </year> <title> Etending the lexicon by exploring subregularities. IJCAI Workshop on Computational Approaches to Non-literal language, </title> <type> Tech Report CU-CS-550-91, </type> <institution> University of Colorado at Boulder: </institution> <month> 161-169. </month>
Reference: [Wilks1978] <author> Y. Wilks, </author> <year> 1978. </year> <title> Making Preferences more active. </title> <journal> AI Journal 11, </journal> <year> 1978. </year>
Reference-contexts: India had high import tariffs. 3. This kept goods from flowing in to India's markets. 4. India removed import tariffs. 5. This allowed Japanese goods to flow into the market. 6. Unrestricted and fast flow of goods resulted in flooding the market. 1 taken from Wilks <ref> [Wilks1978] </ref> 2 IMPLEMENTATION APPROACH 5 The interpreter uses background knowledge that treats import tariffs as if they were barriers that keep inflow to a minimum. Removing import tariffs is thus viewed as removing an inflow barrier.
Reference: [Word] <author> Miller et al, </author> <year> 1990. </year> <title> Wordnet: An on-line lexical database. </title> <journal> International Journal of lexicography 3, </journal> <month> 4 </month> <year> (1990) </year> <month> 235-245. </month>
Reference-contexts: A variant of the mutual information measure was used by Resnick [Resnick1993] to quantify the selectivity of different predicates for the type of their arguments. He used his technique to predict possible arguments given the occurrence of a specific predicate. Using Wordnet <ref> [Word] </ref>, Resnick demonstrated how this idea could be used to quantify the idea of Selectional Restrictions by measuring the degree of fit between predicates and their arguments from predefined Wordnet groups. Resnick called his measure the Selectional Association (SA) between a predicate and its argument.
Reference: [Wu1992] <author> D. Wu, </author> <year> 1992. </year> <title> A Probablistic basis for Natural Language Interpretation. </title> <type> Ph.D. </type> <institution> Dissertation Dept. Of Computer Science, UCB, </institution> <year> 1992. </year>
Reference: [Wu1993] <author> D. Wu, </author> <year> 1993. </year> <title> Estimating Probability Distributions over Hypothesis with Variable Unification. </title> <booktitle> IJCAI-93 procedings 1993, </booktitle> <pages> pp. 790-795. </pages>
Reference-contexts: There are several other differences in our approaches, and I will point them out in the appropriate sections. Probabilistic network techniques to model the interpretation process have been proposed by Dekai Wu <ref> [Wu1993] </ref> and Charniak [Charniak1988] [Charniak1989]. My proposal is different from these efforts in that I show how conventional metaphors and dynamic context can be brought to bear during interpretation.
References-found: 59

