URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/atal-95.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Email: singh@ncsu.edu  
Title: Semantical Considerations on Some Primitives for Agent Specification  
Author: Munindar P. Singh 
Address: Raleigh, NC 27695-8206 USA  
Affiliation: Department of Computer Science North Carolina State University  
Abstract: Intelligent agents, invented in artificial intelligence (AI), are finding application in a number of traditional areas. Classical AI notions such as knowledge and intentions can serve as natural primitives for the specification of agents. However, in order for them to live up to their promise, these notions must be given rigorous definitions. We propose formal definitions for intentions, knowledge, and know-how in a general model of actions and time. Our definitions are conceptually simple and are designed to be modular, in the sense of being orthogonal to one another. Using these definitions, we are able to prove a success result for agents that is akin to the notion of liveness in traditional computing. Others have been able to prove similar results only with the support of rather strong additional assumptions. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Michael E. Bratman. </author> <title> Intention, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Of these, (a) and (b) are jointly termed the asymmetry thesis by Bratman <ref> [1, p. 38] </ref>. He argues that they are among the more basic constraints on the intentions and beliefs of rational agents. Intentions have an obvious connection with actionsagents act to satisfy their intentions. However, intentions do not ensure success. Example 11. Consider Figure 2.
Reference: 2. <author> K. M. Chandy and Jayadev Misra. </author> <title> How processes learn. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 40-52, </pages> <year> 1986. </year>
Reference-contexts: Our work seeks to enhance both traditional and AI approaches. Our enhancements to the traditional distributed computing approaches are chiefly in adding the concepts of know-how and intentions, because know-that and time are well-studied there <ref> [2, 5] </ref>. Know-How and intentions prove crucial because they enable the separation of what an agent might perform from what the agent will perform given certain intentions, knowledge, and abilities. Temporal logic has been used for several years in reasoning about distributed systems [5]. <p> Knowledge, understood as know-that, was extensively studied in the AI and distributed computing literatures. Three main classes of approaches can be identified. The simplest are the modal approaches, on which our present framework is based <ref> [2, 9, 6, 15] </ref>. These approaches are simple, but incorrectly predict that agents know the logical consequences of their knowledge. Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge.
Reference: 3. <author> Brian F. Chellas. </author> <title> Modal Logic. </title> <publisher> Cambridge University Press, </publisher> <address> New York, NY, </address> <year> 1980. </year>
Reference-contexts: This is used in the formal semantics for know-that in the traditional manner. For simplicity, we assume that B is an equivalence relation, resulting in K t being an S5 modal logic operator <ref> [3] </ref>, which grants both positive and negative introspection. For most purposes, an S4 operator would suffice, which only has positive introspection [15]. I assigns to each agent at each moment the scenarios that the agent prefers.
Reference: 4. <author> Philip R. Cohen and Hector J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261, </pages> <year> 1990. </year>
Reference-contexts: For example, we might require our agents to intend to keep their promises even if they cannot guarantee successthis is a reasonable communication constraint in the sense of [22]. Under temporal logic, intended and unintended failures are equally unacceptable. Our enhancements to past AI approaches, notably, <ref> [15, 4, 20] </ref> are chiefly in (a) formalizing know-how, which has typically been ignored and (b) obtaining results similar to the liveness and safety properties in a framework based on intentions and know-how. We have pursued this program of research for several years. <p> Technically, two main ingredients are missing. The agent must know-how to achieve the intended condition and must act on his intentions. We include this here to point out that in the theory of <ref> [4] </ref>, persistence is sufficient for success (p. 233). This is a major conceptual weakness, since it violates the usual understanding that intentions do not entail know-how [21]. <p> The above classes of research would extend naturally into intentions. However, most work on intentions has been on modal approachesthe few exceptions include [12, 25]. The formal literature on intentions includes reference to time and beliefs or know-that <ref> [4, 20] </ref>. However, know-how is not considered. The above approaches consequently cannot prove success results such as we exhibited here. They require additional and, in our view spurious assumptions [21]. A common assumption is that agents will necessarily drop their intentions.
Reference: 5. <author> E. A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: There is a well-known tension in assigning cognitive properties to physical systems. By assuming our models to be weakly deterministic, we can capture the notion of state just as in traditional logics of program approaches <ref> [5] </ref>, and yet give a nonvacuous semantics for our primitives. Like previous approaches, we make knowledge a primitive of our approach. But, whereas traditional approaches consider know-that or the knowledge of facts solely, we also formalize know-how or the knowledge of actions to achieve different conditions. <p> Our work seeks to enhance both traditional and AI approaches. Our enhancements to the traditional distributed computing approaches are chiefly in adding the concepts of know-how and intentions, because know-that and time are well-studied there <ref> [2, 5] </ref>. Know-How and intentions prove crucial because they enable the separation of what an agent might perform from what the agent will perform given certain intentions, knowledge, and abilities. Temporal logic has been used for several years in reasoning about distributed systems [5]. <p> Know-How and intentions prove crucial because they enable the separation of what an agent might perform from what the agent will perform given certain intentions, knowledge, and abilities. Temporal logic has been used for several years in reasoning about distributed systems <ref> [5] </ref>. It enables us to distinguish between the conditions that are or are not attained in the computations of a distributed system. Linear time temporal logic considers specific computations; branching time temporal logic considers all possible computations. <p> If our robot turns on high heat, then the room becomes warm irrespective of the other agent's actions, whereas if he turns on medium heat, it becomes warm quickly only if the window is not opened. 2.1 The Formal Language We use a qualitative temporal language, L, based on CTL* <ref> [5] </ref>. This captures the essential properties of actions and time that are of interest in specifying intelligent agents. Formally, L is the minimal set closed under the rules given below. <p> We say p is satisfiable iff for some M and t, M j= t p. The satisfaction conditions for the temporal operators are adapted from those in <ref> [5] </ref>. For simplicity, we assume that each action symbol is quantified over at most once in any formula. Below, pj a b is the formula resulting from the substitution of all occurrences of a in p by b.
Reference: 6. <author> Ronald Fagin, Joseph Y. Halpern, and Moshe Y. Vardi. </author> <title> What can machines know? on the epistemic properties of machines. </title> <booktitle> In AAAI, </booktitle> <pages> pages 428-434, </pages> <year> 1986. </year>
Reference-contexts: Knowledge, understood as know-that, was extensively studied in the AI and distributed computing literatures. Three main classes of approaches can be identified. The simplest are the modal approaches, on which our present framework is based <ref> [2, 9, 6, 15] </ref>. These approaches are simple, but incorrectly predict that agents know the logical consequences of their knowledge. Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge.
Reference: 7. <author> Ronald Fagin, Joseph Y. Halpern, and Moshe Y. Vardi. </author> <title> A nonstandard approach to the logical omniscience problem. </title> <booktitle> In Proceedings of the Third Conference on Theoretical Aspects of Reasoning About Knowledge. </booktitle> <publisher> Morgan Kaufmann Inc., </publisher> <year> 1990. </year>
Reference-contexts: Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge. The third kind are hybrid approaches, which seek to avoid both extremes but at the price of a greater technical and conceptual complexity <ref> [7, 25] </ref>. In our present work, we have not taken advantage of our previous research [25] primarily because we wish to highlight orthogonal issues in the simplest possible framework. The above classes of research would extend naturally into intentions.
Reference: 8. <author> R. Gotzhein and F. H. Vogt. </author> <title> The design of a temporal logic for open distributed systems. </title> <booktitle> In Proceedings of the International Conference on Open Distributed Processing. </booktitle> <publisher> Elsevier Science Publishers B. V., </publisher> <year> 1992. </year>
Reference-contexts: One way to capture this requirement would be to state that when a customer inserts a card, the card is found valid, and the ATM has enough money, then the ATM gives out money (the desired amount). The above kind of a constraint is naturally captured in temporal logic <ref> [8, 18] </ref>. However, it conflates the issues of whether the ATM intends to give the money and whether it can given the money.
Reference: 9. <author> Joseph Y. Halpern. </author> <title> Reasoning about knowledge. </title> <editor> In Joseph Y. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 1-26, </pages> <year> 1986. </year>
Reference-contexts: Knowledge, understood as know-that, was extensively studied in the AI and distributed computing literatures. Three main classes of approaches can be identified. The simplest are the modal approaches, on which our present framework is based <ref> [2, 9, 6, 15] </ref>. These approaches are simple, but incorrectly predict that agents know the logical consequences of their knowledge. Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge.
Reference: 10. <author> Carl Hewitt, C. Manning, Jeff Inman, and Gul Agha, </author> <title> editors. Toward Open Information Systems Science. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: The autonomy of agents is captured in the fact that they are the loci of actions. Agents can in addition be mobile [27], reflective <ref> [10] </ref>, and lightweight threads [28]. The above is a useful definition for agents in general. However, in many cases of interest, the agent metaphor is the most applicable when the agents are given high-level cognitive specifications.
Reference: 11. <author> Kurt Konolige. </author> <title> A Deduction Model of Belief. </title> <publisher> Morgan Kaufmann, Inc., </publisher> <year> 1986. </year>
Reference-contexts: Three main classes of approaches can be identified. The simplest are the modal approaches, on which our present framework is based [2, 9, 6, 15]. These approaches are simple, but incorrectly predict that agents know the logical consequences of their knowledge. Another class of approaches are the sentential ones <ref> [11] </ref>, which avoid the above problem, but do not facilitate many positive inferences involving knowledge. The third kind are hybrid approaches, which seek to avoid both extremes but at the price of a greater technical and conceptual complexity [7, 25].
Reference: 12. <author> Kurt G. Konolige and Martha E. Pollack. </author> <title> A representationalist theory of intentions. </title> <booktitle> In IJCAI, </booktitle> <year> 1989. </year>
Reference-contexts: The above classes of research would extend naturally into intentions. However, most work on intentions has been on modal approachesthe few exceptions include <ref> [12, 25] </ref>. The formal literature on intentions includes reference to time and beliefs or know-that [4, 20]. However, know-how is not considered. The above approaches consequently cannot prove success results such as we exhibited here. They require additional and, in our view spurious assumptions [21].
Reference: 13. <author> Dexter Kozen and Jerzy Tiurzyn. </author> <title> Logics of program. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Example 7. In Figure 1, RFq holds at t 0 , since q holds on some moment on the real scenario identified at t 0 . L also contains operators on actions. These are adapted and generalized from dynamic logic <ref> [13] </ref>, in which the action operators behave essentially like state-formulas. Our operators can capture the traditional operators.
Reference: 14. <author> John McCarthy. </author> <title> Ascribing mental qualities to machines. </title> <editor> In Martin Ringle, editor, </editor> <booktitle> Philosophical Perspectives in Artificial Intelligence. </booktitle> <publisher> Harvester Press, </publisher> <year> 1979. </year> <note> Page nos. from a revised version, issued as a report in 1987. </note>
Reference-contexts: The above is a useful definition for agents in general. However, in many cases of interest, the agent metaphor is the most applicable when the agents are given high-level cognitive specifications. This is described as taking an intentional stance toward agents <ref> [14] </ref> or viewing them at the knowledge level [17]. The high-level cognitive specifications take the form of concepts such as beliefs, knowledge, desires, and intentions.
Reference: 15. <author> Robert C. Moore. </author> <title> A formal theory of knowledge and action. </title> <editor> In Jerry R. Hobbs and Robert C. Moore, editors, </editor> <booktitle> Formal Theories of the Commonsense World, </booktitle> <pages> pages 319-358. </pages> <publisher> Ablex Publishing Company, </publisher> <address> Norwood, NJ, </address> <year> 1984. </year>
Reference-contexts: For example, we might require our agents to intend to keep their promises even if they cannot guarantee successthis is a reasonable communication constraint in the sense of [22]. Under temporal logic, intended and unintended failures are equally unacceptable. Our enhancements to past AI approaches, notably, <ref> [15, 4, 20] </ref> are chiefly in (a) formalizing know-how, which has typically been ignored and (b) obtaining results similar to the liveness and safety properties in a framework based on intentions and know-how. We have pursued this program of research for several years. <p> For simplicity, we assume that B is an equivalence relation, resulting in K t being an S5 modal logic operator [3], which grants both positive and negative introspection. For most purposes, an S4 operator would suffice, which only has positive introspection <ref> [15] </ref>. I assigns to each agent at each moment the scenarios that the agent prefers. This is explained further in section 3, where it is used to give a formal meaning to intentions. For p 2 L, M j= t p expresses M satisfies p at t. <p> Knowledge, understood as know-that, was extensively studied in the AI and distributed computing literatures. Three main classes of approaches can be identified. The simplest are the modal approaches, on which our present framework is based <ref> [2, 9, 6, 15] </ref>. These approaches are simple, but incorrectly predict that agents know the logical consequences of their knowledge. Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge. <p> Curiously, there has been little work on know-how, although knowledge preconditions for actions and plans were studied in <ref> [15, 16] </ref>. The recent STIT (for seeing to it that) approaches [29] appear to embody similar intuitions, although they also mingle intentions and know-how, as we have identified those concepts.
Reference: 16. <author> Leora Morgenstern. </author> <title> A theory of knowledge and planning. </title> <booktitle> In IJCAI, </booktitle> <year> 1987. </year>
Reference-contexts: Curiously, there has been little work on know-how, although knowledge preconditions for actions and plans were studied in <ref> [15, 16] </ref>. The recent STIT (for seeing to it that) approaches [29] appear to embody similar intuitions, although they also mingle intentions and know-how, as we have identified those concepts.
Reference: 17. <author> Allen Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18(1) </volume> <pages> 87-127, </pages> <year> 1982. </year>
Reference-contexts: The above is a useful definition for agents in general. However, in many cases of interest, the agent metaphor is the most applicable when the agents are given high-level cognitive specifications. This is described as taking an intentional stance toward agents [14] or viewing them at the knowledge level <ref> [17] </ref>. The high-level cognitive specifications take the form of concepts such as beliefs, knowledge, desires, and intentions.
Reference: 18. <author> A. H. H. Ngu, R. Meersman, and H. Weigand. </author> <title> Specification and verification of communication constraints for interoperable transactions. </title> <booktitle> In Proceedings of the 2nd International Conference on Cooperative Information Systems (CoopIS), </booktitle> <year> 1994. </year>
Reference-contexts: One way to capture this requirement would be to state that when a customer inserts a card, the card is found valid, and the ATM has enough money, then the ATM gives out money (the desired amount). The above kind of a constraint is naturally captured in temporal logic <ref> [8, 18] </ref>. However, it conflates the issues of whether the ATM intends to give the money and whether it can given the money.
Reference: 19. <author> Anand S. Rao. </author> <title> Decision procedures for propositional linear-time belief-desire-intention logics. </title> <booktitle> In IJCAI Workshop on Agent Theories, Architectures, and Languages, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: We believe that the primitives developed herein will pay off when they begin to be incorporated into tools for reasoning about agents. Some useful results have been obtained by <ref> [19, 23, 29] </ref>. Complexity issues remain a challenge. This research area has been focused on conceptual issues in terms of the expressiveness to capture various cases, to obtain useful and avoid pernicious inferences.
Reference: 20. <author> Anand S. Rao and Michael P. Georgeff. </author> <title> Asymmetry thesis and side-effect problems in linear-time and branching-time intention logics. </title> <booktitle> In IJCAI, </booktitle> <year> 1991. </year>
Reference-contexts: For example, we might require our agents to intend to keep their promises even if they cannot guarantee successthis is a reasonable communication constraint in the sense of [22]. Under temporal logic, intended and unintended failures are equally unacceptable. Our enhancements to past AI approaches, notably, <ref> [15, 4, 20] </ref> are chiefly in (a) formalizing know-how, which has typically been ignored and (b) obtaining results similar to the liveness and safety properties in a framework based on intentions and know-how. We have pursued this program of research for several years. <p> The above classes of research would extend naturally into intentions. However, most work on intentions has been on modal approachesthe few exceptions include [12, 25]. The formal literature on intentions includes reference to time and beliefs or know-that <ref> [4, 20] </ref>. However, know-how is not considered. The above approaches consequently cannot prove success results such as we exhibited here. They require additional and, in our view spurious assumptions [21]. A common assumption is that agents will necessarily drop their intentions. <p> A common assumption is that agents will necessarily drop their intentions. Since agents are additionally assumed to do so only upon success, success is guaranteed. Many approaches also end up constraining the formal models so that the various primitives are extraneously tied to each other. <ref> [20] </ref> have shown how to remove some of these restrictions; we believe we have additional results, but lack the space to elaborate here. Curiously, there has been little work on know-how, although knowledge preconditions for actions and plans were studied in [15, 16].
Reference: 21. <author> Munindar P. Singh. </author> <title> A critical examination of the Cohen-Levesque theory of intentions. </title> <booktitle> In 10th European Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Consequently, success is achieved trivially for any intentionthis is clearly unintuitive and reduces the concept of intentions to something quite meaningless for real-life agents. Details of this argument were presented in <ref> [21] </ref>. Further, traditional theories do not provide any means to capture the distinction between what an agent will do given his intentions and what he might have done. The formal models are unconstrained, so that certain inferences that are clearly valid are not captured by these theories. <p> We include this here to point out that in the theory of [4], persistence is sufficient for success (p. 233). This is a major conceptual weakness, since it violates the usual understanding that intentions do not entail know-how <ref> [21] </ref>. The need to state the conditions under which an agent can succeed with his intentions is one of the motivations for the concept of know-how. IC4. Persist while succeeding: This constraint is a possible restriction on the architectures of agents. <p> The formal literature on intentions includes reference to time and beliefs or know-that [4, 20]. However, know-how is not considered. The above approaches consequently cannot prove success results such as we exhibited here. They require additional and, in our view spurious assumptions <ref> [21] </ref>. A common assumption is that agents will necessarily drop their intentions. Since agents are additionally assumed to do so only upon success, success is guaranteed.
Reference: 22. <author> Munindar P. Singh. </author> <title> A semantics for speech acts. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 8(I-II):47-71, </volume> <year> 1993. </year>
Reference-contexts: Indeed, the intentions adopted by different agents can be a part of the specification of correct behavior. For example, we might require our agents to intend to keep their promises even if they cannot guarantee successthis is a reasonable communication constraint in the sense of <ref> [22] </ref>. Under temporal logic, intended and unintended failures are equally unacceptable.
Reference: 23. <author> Munindar P. Singh. </author> <title> Maintenance and prevention: Formalization and fixpoint characterization. </title> <booktitle> In ECAI Workshop on Logic and Change, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: We believe that the primitives developed herein will pay off when they begin to be incorporated into tools for reasoning about agents. Some useful results have been obtained by <ref> [19, 23, 29] </ref>. Complexity issues remain a challenge. This research area has been focused on conceptual issues in terms of the expressiveness to capture various cases, to obtain useful and avoid pernicious inferences.
Reference: 24. <author> Munindar P. Singh. </author> <title> Multiagent Systems: A Theoretical Framework for Intentions, KnowHow, and Communications. </title> <publisher> Springer Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1994. </year>
Reference-contexts: We have pursued this program of research for several years. A more leisurely description of our greater motivations is presented in <ref> [24] </ref>. The technical framework of branching time and the formalization of know-how are shared with our previous work. The present paper has a new formalization of intentions, of the constraints on models, and of the key results. <p> Some of the literature is reviewed in <ref> [24, chap. 3] </ref>. However, existing approaches do not validate some of the properties that are crucial to the kinds of reasoning that we must perform about agents in general.
Reference: 25. <author> Munindar P. Singh and Nicholas M. Asher. </author> <title> A logic of intentions and beliefs. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 22 </volume> <pages> 513-544, </pages> <year> 1993. </year>
Reference-contexts: Another class of approaches are the sentential ones [11], which avoid the above problem, but do not facilitate many positive inferences involving knowledge. The third kind are hybrid approaches, which seek to avoid both extremes but at the price of a greater technical and conceptual complexity <ref> [7, 25] </ref>. In our present work, we have not taken advantage of our previous research [25] primarily because we wish to highlight orthogonal issues in the simplest possible framework. The above classes of research would extend naturally into intentions. <p> The third kind are hybrid approaches, which seek to avoid both extremes but at the price of a greater technical and conceptual complexity [7, 25]. In our present work, we have not taken advantage of our previous research <ref> [25] </ref> primarily because we wish to highlight orthogonal issues in the simplest possible framework. The above classes of research would extend naturally into intentions. However, most work on intentions has been on modal approachesthe few exceptions include [12, 25]. <p> The above classes of research would extend naturally into intentions. However, most work on intentions has been on modal approachesthe few exceptions include <ref> [12, 25] </ref>. The formal literature on intentions includes reference to time and beliefs or know-that [4, 20]. However, know-how is not considered. The above approaches consequently cannot prove success results such as we exhibited here. They require additional and, in our view spurious assumptions [21].
Reference: 26. <author> Munindar P. Singh and Michael N. </author> <title> Huhns. </title> <booktitle> Cooperative information systems: Tutorial notes, 1995. Tutorial given at the International Conference on Distributed Computing Systems and at the International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: While numerous definitions of agents have been proposed. We like to use the following operational definition that includes their essential properties: agents are entities with a persistent identity that are the loci of perception and behavior (actions and communications) <ref> [26] </ref>. The autonomy of agents is captured in the fact that they are the loci of actions. Agents can in addition be mobile [27], reflective [10], and lightweight threads [28]. The above is a useful definition for agents in general.
Reference: 27. <author> James White. </author> <title> TeleScript technology: The foundation for the electronic marketplace, </title> <note> 1994. White paper. </note>
Reference-contexts: The autonomy of agents is captured in the fact that they are the loci of actions. Agents can in addition be mobile <ref> [27] </ref>, reflective [10], and lightweight threads [28]. The above is a useful definition for agents in general. However, in many cases of interest, the agent metaphor is the most applicable when the agents are given high-level cognitive specifications.
Reference: 28. <author> Darrell Woelk and Christine Tomlinson. </author> <title> The InfoSleuth project white-paper. </title> <type> Technical Report InfoSleuth-95-01, </type> <institution> Microelectronics and Computer Technology Corporation, Austin, TX, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: The autonomy of agents is captured in the fact that they are the loci of actions. Agents can in addition be mobile [27], reflective [10], and lightweight threads <ref> [28] </ref>. The above is a useful definition for agents in general. However, in many cases of interest, the agent metaphor is the most applicable when the agents are given high-level cognitive specifications.
Reference: 29. <author> Michael Wooldridge. </author> <title> Time, knowledge, and choice. </title> <booktitle> In IJCAI Workshop on Agent Theories, Architectures, and Languages, </booktitle> <month> August </month> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Curiously, there has been little work on know-how, although knowledge preconditions for actions and plans were studied in [15, 16]. The recent STIT (for seeing to it that) approaches <ref> [29] </ref> appear to embody similar intuitions, although they also mingle intentions and know-how, as we have identified those concepts. We believe that the primitives developed herein will pay off when they begin to be incorporated into tools for reasoning about agents. <p> We believe that the primitives developed herein will pay off when they begin to be incorporated into tools for reasoning about agents. Some useful results have been obtained by <ref> [19, 23, 29] </ref>. Complexity issues remain a challenge. This research area has been focused on conceptual issues in terms of the expressiveness to capture various cases, to obtain useful and avoid pernicious inferences.
References-found: 29

