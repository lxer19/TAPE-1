URL: http://cobar.cs.umass.edu/pubfiles/callansigir96a.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: callan@cs.umass.edu  
Title: Document Filtering With Inference Networks  
Author: Jamie Callan 
Address: Amherst, MA 01003-4610, USA  
Affiliation: Computer Science Department University of Massachusetts  
Abstract: Although statistical retrieval models are now accepted widely, there has been little research on how to adapt them to the demands of high speed document filtering. The problems of document retrieval and document filtering are similar at an abstract level, but the architectures required, the optimizations that are possible, and the quality of the information available, are all different. This paper describes a new statistical document filtering system called InRoute, the problems of filtering effectiveness and efficiency that arise with such a system, and experiments with various solutions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Allan, L. Ballesteros, J. P. Callan, W. B. Croft, and Z. Lu. </author> <title> Recent experiments with inquery. </title> <editor> In D. Har-man, editor, </editor> <booktitle> Proceedings of the Fourth Text REtrieval Conference (TREC-4). </booktitle> <institution> National Institute of Standards and Technology Special Publication, </institution> <note> (to appear). </note>
Reference-contexts: This approach is effective, but it may be impractical in practice. Obtaining idfs from a retrospective corpus can be expensive, particularly if queries include large numbers of proximity operators, as in <ref> [1] </ref>. Idfs for unindexed query fragments 4 bytes. in this experiment. Document length is represented in bytes. (e.g., proximity operators) can only be obtained by running queries against the retrospective collection. <p> These met-rics were chosen because they were used in the TREC Routing track. InRoute was run twice on the TREC-4 corpus (935 MB, 329,780 documents) and INQ203 Routing queries (50 queries, 50 terms and 200 proximity pairs each) <ref> [1] </ref>. In one run, corpus statistics were available a priori ("perfect" statistics). In the other, estimates were updated as each document was encountered ("learned" statistics). The experiment required dissemination thresholds that would disseminate at least 1,000 documents for each query.
Reference: [2] <author> N. J. Belkin and W. B. Croft. </author> <title> Information filtering and information retrieval: </title> <journal> Two sides of the same coin? Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 29-38, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Retrieval of documents from an archival collection (retrospective retrieval) and filtering documents from an incoming stream of documents (document filtering or selective dissemination of information) have been described as two sides of the same coin <ref> [2] </ref>. Both tasks consist of determining quickly how well a document matches an information need. <p> This paper describes some of the issues that arose while developing the InRoute document filtering system from parts of the INQUERY retrospective retrieval system [5]. The two systems are based on the inference network model of information retrieval <ref> [11, 12, 2] </ref>, share a common query language, and started out sharing much of the code that matches information needs to documents. However, there are as many differences as similarities between the two systems. The differences are the subject of this paper. <p> SIFT also incorporates relevance feedback algorithms that enable a user to refine a profile based upon relevant and nonrelevant documents. 3 The InRoute Architecture The InRoute document filtering system is based upon the inference network model of information retrieval and filtering <ref> [11, 2] </ref>. The major tasks performed by InRoute are creation of query networks, creation of the document network, and use of the networks to filter documents. The document network is created automatically by mapping documents onto content representation nodes, which are implemented with traditional inverted lists. <p> Profile indexing is less effective with the structured queries that characterize inference network systems, because scores for structured queries cannot be computed when profile inverted lists are merged ("...we cannot simply turn the inference network `upside down'..." <ref> [2] </ref>). In this case, profile indexing can be used only to identify profiles that are candidates for evaluation.
Reference: [3] <author> Chris Buckley and Alan F. Lewit. </author> <title> Optimization of inverted vector searches. </title> <booktitle> In Proceedings of the Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 97-110, </pages> <address> New York, NY, 1985. </address> <publisher> ACM. </publisher>
Reference-contexts: This information is stored in the profile index, and used during filtering. The profile is selected only if it matches a sufficient number of document terms. The MinTerm estimate is obtained with an algorithm similar to algorithms that reorder and/or optimize unstructured queries (e.g., <ref> [3] </ref>) and Boolean queries (e.g., [15]). Reordering by optimal belief is perhaps a more general technique, because it applies to both unstructured queries and queries structured with a wide range of Boolean and probabilistic operators.
Reference: [4] <author> J. P. Callan, W. B. Croft, and J. Broglio. </author> <title> TREC and TIPSTER experiments with INQUERY. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 31(3) </volume> <pages> 327-343, </pages> <year> 1995. </year>
Reference-contexts: A common approach has been to simulate document filtering with an existing vector-space or probabilistic document retrieval system on a collection of new or recent documents (e.g., Pasadena [13], LSI SDI [6], INQUERY <ref> [4] </ref>, Okapi [9], most TREC systems [7]). This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf . <p> Figure 1 shows the major components of the InRoute system, and how information flows between them. The following sections discuss each component in more detail. 3.1 Parsing Profiles into Query Nets As with INQUERY <ref> [5, 4] </ref>, InRoute information needs may be specified in either a query language or natural language. InRoute shares INQUERY's rich query language, which includes probabilistic AND, OR, and NOT operators, proximity operators, probabilistic phrase and passage operators, and a weighted sum operator for user-specified weights. <p> For each query term that occurs in the document, InRoute must locate the appropriate inverted list, lookup the belief associated with the term, and then combine the belief with the beliefs from other terms, according to the probabilistic operators being used <ref> [4] </ref>. If proximity operators are used, InRoute must also lookup the locations where the term occurs, intersect those with the locations of other proximate terms, and then compute the belief for the proximity operator dynamically, using the same tf:idf formulas described above.
Reference: [5] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The IN-QUERY retrieval system. </title> <booktitle> In Proceedings of the Third International Conference on Database and Expert Systems Applications, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: These issues are important, because they determine how efficient and effective statistical document filtering systems will be in "real world" environments. This paper describes some of the issues that arose while developing the InRoute document filtering system from parts of the INQUERY retrospective retrieval system <ref> [5] </ref>. The two systems are based on the inference network model of information retrieval [11, 12, 2], share a common query language, and started out sharing much of the code that matches information needs to documents. However, there are as many differences as similarities between the two systems. <p> Figure 1 shows the major components of the InRoute system, and how information flows between them. The following sections discuss each component in more detail. 3.1 Parsing Profiles into Query Nets As with INQUERY <ref> [5, 4] </ref>, InRoute information needs may be specified in either a query language or natural language. InRoute shares INQUERY's rich query language, which includes probabilistic AND, OR, and NOT operators, proximity operators, probabilistic phrase and passage operators, and a weighted sum operator for user-specified weights.
Reference: [6] <author> P. W. Foltz and S. T. Dumais. </author> <title> Personalized information delivery: An analysis of information filtering methods. </title> <journal> Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 51-60, </pages> <year> 1992. </year>
Reference-contexts: A common approach has been to simulate document filtering with an existing vector-space or probabilistic document retrieval system on a collection of new or recent documents (e.g., Pasadena [13], LSI SDI <ref> [6] </ref>, INQUERY [4], Okapi [9], most TREC systems [7]). This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf .
Reference: [7] <editor> D. Harman, editor. </editor> <booktitle> Proceedings of the Fourth Text REtrieval Conference (TREC-4). National Institute of Standards and Technology Special Publication, </booktitle> <address> Gaithersburg, MD, </address> <note> (to appear). </note>
Reference-contexts: Neither track requires that a filtering system be used. Indeed, many participants index the set of Routing documents and then search the index with a retrospective retrieval system <ref> [7] </ref>. <p> A common approach has been to simulate document filtering with an existing vector-space or probabilistic document retrieval system on a collection of new or recent documents (e.g., Pasadena [13], LSI SDI [6], INQUERY [4], Okapi [9], most TREC systems <ref> [7] </ref>). This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf . However, it is not well-suited to immediate dissemination of new information, and it adds index creation, storage, and maintenance to the cost of document filtering.
Reference: [8] <author> K.H. Packer and D. Soergel. </author> <title> The importance of SDI for current awareness in fields with severe scatter of information. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 30(3) </volume> <pages> 125-135, </pages> <year> 1979. </year>
Reference-contexts: Section 5 discusses the problem of filtering quickly with complex profiles (queries), and presents experiments with some possible solutions. Section 6 concludes. 2 Document Filtering Document filtering, also known as selective dissemination of information (SDI), has a long history, most of it based on the unranked Boolean retrieval model <ref> [8] </ref>. A user's information need is expressed by a query, also called a profile, in a query language. (Sometimes a profile is actually a set of queries for one user; in this paper, query and profile are considered synonymous.) Queries are expressed with Boolean logic.
Reference: [9] <author> S. E. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford. </author> <note> Okapi at TREC-3. </note> <editor> In D. K. Harman, editor, </editor> <booktitle> The Third Text REtrieval Conference (TREC-3), </booktitle> <address> Gaithersburg, MD, </address> <year> 1995. </year> <institution> National Institute of Standards and Technology, </institution> <note> Special Publication 500-225. </note>
Reference-contexts: A common approach has been to simulate document filtering with an existing vector-space or probabilistic document retrieval system on a collection of new or recent documents (e.g., Pasadena [13], LSI SDI [6], INQUERY [4], Okapi <ref> [9] </ref>, most TREC systems [7]). This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf . However, it is not well-suited to immediate dissemination of new information, and it adds index creation, storage, and maintenance to the cost of document filtering.
Reference: [10] <author> Gerard Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: However, it is not well-suited to immediate dissemination of new information, and it adds index creation, storage, and maintenance to the cost of document filtering. SIFT [14] is a document filtering system based on the well-known vector-space retrieval model <ref> [10] </ref>. SIFT queries are unstructured (i.e., no query operators), so they can be indexed with inverted lists. A document "retrieves" a set of inverted lists that indicate which profiles to evaluate for the document. The document's score for a profile is determined with a vector-space algorithm.
Reference: [11] <author> H. R. Turtle and W. B. Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <year> 1991. </year>
Reference-contexts: This paper describes some of the issues that arose while developing the InRoute document filtering system from parts of the INQUERY retrospective retrieval system [5]. The two systems are based on the inference network model of information retrieval <ref> [11, 12, 2] </ref>, share a common query language, and started out sharing much of the code that matches information needs to documents. However, there are as many differences as similarities between the two systems. The differences are the subject of this paper. <p> SIFT also incorporates relevance feedback algorithms that enable a user to refine a profile based upon relevant and nonrelevant documents. 3 The InRoute Architecture The InRoute document filtering system is based upon the inference network model of information retrieval and filtering <ref> [11, 2] </ref>. The major tasks performed by InRoute are creation of query networks, creation of the document network, and use of the networks to filter documents. The document network is created automatically by mapping documents onto content representation nodes, which are implemented with traditional inverted lists.
Reference: [12] <author> Howard R. Turtle and W. Bruce Croft. </author> <title> Efficient probabilistic inference for text retrieval. </title> <booktitle> In RIAO 3 Conference Proceedings, </booktitle> <pages> pages 644-661, </pages> <address> Barcelona, Spain, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: This paper describes some of the issues that arose while developing the InRoute document filtering system from parts of the INQUERY retrospective retrieval system [5]. The two systems are based on the inference network model of information retrieval <ref> [11, 12, 2] </ref>, share a common query language, and started out sharing much of the code that matches information needs to documents. However, there are as many differences as similarities between the two systems. The differences are the subject of this paper.
Reference: [13] <author> M. F. Wyle and H. P. Frei. </author> <title> Retrieving highly dynamic, widely distributed information. </title> <booktitle> In Proceedings of the ACM SIGIR International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 108-115, </pages> <address> Boston, MA, </address> <year> 1989. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The growing power of computer hardware has made statistical systems increasingly practical for even large scale document filtering environments. A common approach has been to simulate document filtering with an existing vector-space or probabilistic document retrieval system on a collection of new or recent documents (e.g., Pasadena <ref> [13] </ref>, LSI SDI [6], INQUERY [4], Okapi [9], most TREC systems [7]). This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf .
Reference: [14] <author> T. Yan and H. Garcia-Molina. </author> <title> SIFT A tool for wide-area information dissemination. </title> <booktitle> In Proc. USENIX Winter 1995 Technical Conference, </booktitle> <address> New Orleans, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: This approach is simple, effective, and has the advantage of a corpus from which to gather statistics like idf . However, it is not well-suited to immediate dissemination of new information, and it adds index creation, storage, and maintenance to the cost of document filtering. SIFT <ref> [14] </ref> is a document filtering system based on the well-known vector-space retrieval model [10]. SIFT queries are unstructured (i.e., no query operators), so they can be indexed with inverted lists. A document "retrieves" a set of inverted lists that indicate which profiles to evaluate for the document. <p> Both can be optimized, but we restrict our attention here to profile selection. For each document, the goal is to spend either no time or nearly no time on most of the profiles. One approach, used for example in SIFT <ref> [14] </ref>, is to index profiles with inverted lists. The terms in a document "retrieve" profiles during filtering. This approach works particularly well with the unstructured queries that characterize vector-space systems, because profile scores can be computed when inverted lists are merged.
Reference: [15] <author> J. A. Yochum. </author> <title> A high-speed text scanning algorithm utilizing least frequent trigraphs. </title> <booktitle> In Proceedings of the IEEE International Symposium on New Directions in Computing, </booktitle> <pages> pages 114-121, </pages> <address> Trondheim, Norway, 1985. </address> <publisher> IEEE. </publisher>
Reference-contexts: There is no ability to partially satisfy a query, or to determine how well a document matches or satisfies a query. Instead, the emphasis is on speed, and on indexing methods that enable very fast processing of documents against profiles. LMDS <ref> [15] </ref> is an example of this class of systems. Each Boolean profile is analyzed to identify the least frequent trigram (LFT) that must occur whenever the profile matches a document (a necessary, but not sufficient, condition for matching). <p> This information is stored in the profile index, and used during filtering. The profile is selected only if it matches a sufficient number of document terms. The MinTerm estimate is obtained with an algorithm similar to algorithms that reorder and/or optimize unstructured queries (e.g., [3]) and Boolean queries (e.g., <ref> [15] </ref>). Reordering by optimal belief is perhaps a more general technique, because it applies to both unstructured queries and queries structured with a wide range of Boolean and probabilistic operators.
Reference: [16] <author> G. K. Zipf. </author> <title> Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1949. </year> <month> 8 </month>
Reference-contexts: As more profiles are added, the vocabulary grows larger. Fortunately, adding a large num ber of profiles causes only a small increase in the size of the term dictionary <ref> [16] </ref>, and therefore only a small decrease in document parsing speed. 3.4 Comparing a Document to Profiles After a document is indexed, it can be compared to a clipset.
References-found: 16

