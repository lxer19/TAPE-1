URL: http://http.cs.berkeley.edu/~miyamoto/classes/spring98/cs265/expert/papers/ASPLOS96-cdpc.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~miyamoto/classes/spring98/cs265/expert/index.html
Root-URL: http://www.cs.berkeley.edu
Title: Abstract  
Abstract: This paper presents a new technique, compiler-directed page coloring, that eliminates conict misses in multiprocessor applications. It enables applications to make better use of the increased aggregate cache size available in a multiprocessor. This technique uses the compilers knowledge of the access patterns of the parallelized applications to direct the operating systems virtual memory page mapping strategy. We demonstrate that this technique can lead to significant performance improvements over two commonly used page mapping strategies for machines with either direct-mapped or two-way set-associative caches. We also show that it is complementary to latency-hiding techniques such as prefetching. We implemented compiler-directed page coloring in the SUIF parallelizing compiler and on two commercial operating systems. We applied the technique to the SPEC95fp benchmark suite, a representative set of numeric programs. We used the SimOS machine simulator to analyze the applications and isolate their performance bottlenecks. We also validated these results on a real machine, an eight-processor 350MHz Digital AlphaServer. Compiler-directed page coloring leads to significant performance improvements for several applications. Overall, our technique improves the SPEC95fp rating for eight processors by 8% over Digital UNIXs page mapping policy and by 20% over a page coloring, a standard page mapping policy. The SUIF compiler achieves a SPEC95fp ratio of 57.4, the highest ratio to date. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Saman P. Amarasinghe, Jennifer M. Anderson, Christopher S. Wilson, Shih-Wei Liao, Robert S. French, Mary W. Hall, Brian R. Murphy and Monica S. Lam. </author> <title> The Multiprocessor as a General-Purpose Processor: A Software Perspective. </title> <journal> IEEE Micro, </journal> <volume> 16(3), </volume> <month> Jun. </month> <year> 1996. </year>
Reference-contexts: The SUIF compiler also includes several advanced optimizations that have been described and evaluated in <ref> [1] </ref> and [12]. The compiler performs inter-procedural analysis to parallelize large regions of code that may span multiple procedures. It performs reduction recognition and privatization analysis on arrays. SUIF also contains a suite of locality optimization techniques to make the multiprocessor caches more effective.
Reference: [2] <author> Jennifer M. Anderson, Saman P. Amarasinghe and Monica S. Lam, </author> <title> Data and Computation Transformations for Multiprocessors, </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, Jul.1995, </booktitle> <pages> pp. 166-178. </pages>
Reference-contexts: Transformations that make data elements accessed by the same processor contiguous in the shared address space have been shown to be useful for enhancing spatial locality and minimizing false sharing <ref> [2] </ref>. These transformations make the data accessed by each processor contiguous within an individual data structure. Techniques that merge data structures in the virtual address space have also been proposed to make data accessed by each processor contiguous across data structures [14]. <p> It also takes advantage of several properties of compiler-parallelized codes. First the compiler uses optimizations to assign the computation and restructure the arrays so that the data within each individual data structure accessed by one processor is contiguous in the virtual address space when possible <ref> [2] </ref>. Second, to optimize for locality and minimize parallelization overhead, the compiler statically schedules the parallel computation across the processors. The access patterns of individual processors are therefore predictable. The compiler extracts three kinds of information from the program: Array Partitioning.
Reference: [3] <author> Jennifer M. Anderson and Monica S. Lam, </author> <title> Global Optimizations for Parallelism and Locality on Scalable Parallel Machines, </title> <booktitle> In Proceedings of the ACM SIGPLAN93 Conference on Programming Language Design and Implementation, </booktitle> <month> Jun. </month> <year> 1993, </year> <pages> pp. 112-125. </pages>
Reference: [4] <author> Brian N. Bershad, Dennis Lee, Theodore H. Romer, and J. Bradley Chen, </author> <title> Avoiding Conict Misses Dynamically in Large Direct-Mapped Caches, </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Oct. </month> <year> 1994, </year> <pages> pp. 158-170. </pages>
Reference-contexts: Recently dynamic policies have also been proposed that recolor a page by copying its contents to a newly allocated page of a different color and simultaneously changing the virtual-to-physical mapping of the page. The operating system uses either some custom hardware in the form of a cache-miss lookaside buffer <ref> [4] </ref> or a combination of TLB state information and cache miss counters to detect conicts [20]. When such a conict is detected, one of the pages involved in the conict is recolored. To our knowledge, the performance of dynamic policies for multiprocessors has not been studied.
Reference: [5] <author> David F. Bacon, Susan L. Graham and Oliver J. Sharp, </author> <title> Compiler Transformations for High-Performance Computing, </title> <journal> In Computing Surveys, </journal> <volume> 26 (4), </volume> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: However, such transformations are not applicable to all programs. In contrast, compiler-directed page coloring achieves a similar effect but is completely transparent to the application. Padding <ref> [5] </ref> is a simple, commonly-used technique for eliminating cache conicts. With padding, the compiler or loader offsets the starting locations of data locations and increases the dimensions of arrays, usually by a small number of cache lines, to avoid cache conicts.
Reference: [6] <author> David Callahan, Ken Kennedy and Allan Porterfield, </author> <title> Software Prefetching, </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Apr. </month> <year> 1991, </year> <pages> pp. 40-52. </pages>
Reference: [7] <author> Steve Carr, Kathryn S. McKinley and Chau-Wen Tseng, </author> <title> Compiler Optimizations for Improving Data Locality, </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Oct. </month> <year> 1994, </year> <pages> pp. 252-262. </pages>
Reference: [8] <author> Michel Dubois, Jonas Skeppstedt, Livio Ricciulli, Krishnan Ramamurthy and Per Stenstrom, </author> <title> The Detection and Elimination of Useless Misses in Multiprocessors, </title> <booktitle> In Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 88-97. </pages>
Reference-contexts: The graph separates the stall time due to on-chip cache misses from off-chip cache misses and classifies the latter. Our classification separates replacement misses from communication misses. Communication misses are classified according to <ref> [8] </ref>. The memory system behavior graph shows that the memory stall time of most applications is dominated by replacement misses caused by the limited size (capacity misses) and associativity (conict misses) of the cache. <p> The memory system behavior graph quantifies and classifies the memory system behavior. The memory system behavior is only reported for the useful execution of each processor. We use the definition of true and false sharing based on inter-processor word communication from Dubois et al. <ref> [8] </ref>. The last graph shows the occupancy of the bus. The results were generated with a 1MB direct-mapped cache. The operating system is IRIX and uses a page coloring policy for page mapping.
Reference: [9] <author> Susan J. Eggers and Randy H. Katz, </author> <title> The effect of sharing on cache and bus performance of parallel programs, </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, Apr.1989, </booktitle> <pages> pp. 257-270. </pages>
Reference: [10] <author> Dawson R. Engler, M. Frans Kaashoek and James OToole Jr. Exokernel: </author> <title> An Operating System Architecture for Application-Level Resource Managment, </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating System Principles, </booktitle> <month> Dec. </month> <year> 1995, </year> <pages> pp 251-266. </pages>
Reference-contexts: The page mapping policies, and more generally the memory management policies, of an operating system can lead to poor performance for applications with non-standard requirements. To overcome these limitations, operating systems such as V++ [13] and Exokernel <ref> [10] </ref> allow sophisticated applications to manage their allocated portions of physical memory. These applications can implement their own customized page replacement and page mapping policies. In contrast to these approaches, CDPC is fully automatic and does not require applications to manipulate physical addresses directly.
Reference: [11] <author> Manish Gupta and Prith Banerjee, </author> <title> Demonstration of Automatic Data Partitioning Techniques for Parallelizing Compilers on Multicomputers. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2), </volume> <month> Mar. </month> <year> 1992, </year> <pages> pp. 179-193. </pages>
Reference: [12] <author> Mary W. Hall, Saman P. Amarasinghe, Brian R. Murphy, Shih-Wei Liao and Monica S. Lam, </author> <title> Detecting Coarse-Grain Parallelism Using an Interprocedural Parallelizing Compiler, </title> <booktitle> In Proceedings of Supercomputing 95, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: The SUIF compiler also includes several advanced optimizations that have been described and evaluated in [1] and <ref> [12] </ref>. The compiler performs inter-procedural analysis to parallelize large regions of code that may span multiple procedures. It performs reduction recognition and privatization analysis on arrays. SUIF also contains a suite of locality optimization techniques to make the multiprocessor caches more effective.
Reference: [13] <author> Kieran Harty and David R. Cheriton, </author> <title> Application-controlled Physical Memory using External Page-Cache Management, </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems , Apr. </booktitle> <year> 1991. </year>
Reference-contexts: The page mapping policies, and more generally the memory management policies, of an operating system can lead to poor performance for applications with non-standard requirements. To overcome these limitations, operating systems such as V++ <ref> [13] </ref> and Exokernel [10] allow sophisticated applications to manage their allocated portions of physical memory. These applications can implement their own customized page replacement and page mapping policies. In contrast to these approaches, CDPC is fully automatic and does not require applications to manipulate physical addresses directly.
Reference: [14] <author> Tor E. Jeremiassen and Susan J. Eggers, </author> <title> Reducing False Sharing on Shared Memory Multiprocessors through Compile Time Data Transformations, </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> Jul. </month> <year> 1995, </year> <pages> pp. 179-188. </pages>
Reference-contexts: These transformations make the data accessed by each processor contiguous within an individual data structure. Techniques that merge data structures in the virtual address space have also been proposed to make data accessed by each processor contiguous across data structures <ref> [14] </ref>. However, such transformations are not applicable to all programs. In contrast, compiler-directed page coloring achieves a similar effect but is completely transparent to the application. Padding [5] is a simple, commonly-used technique for eliminating cache conicts.
Reference: [15] <author> Ken Kennedy and Ulrich Kremer, </author> <title> Automatic Data Layout for High Performance Fortran, </title> <booktitle> In Proceedings of Supercomputing 95, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference: [16] <author> Richard E. Kessler and Mark D. Hill, </author> <title> Page Placement Algorithms for Large Real-indexed Caches, </title> <journal> In ACM Transactions on Computer Systems, </journal> <volume> 10(4), </volume> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: The operating system uses a page mapping policy to determine a preferred color and attempts to allocate a page of that color. Most current operating systems support one of two page mapping policies, page coloring and bin hopping <ref> [16] </ref>. Page coloring maps consecutive virtual pages to consecutive colors. Page coloring exploits spatial locality by ensuring that conicts only occur between pages whose virtual addresses differ by a multiple of the cache set size.
Reference: [17] <author> Butler W. Lampson, </author> <title> Hints for Computer System Design, </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <year> 1983, </year> <pages> pp. 33-48. </pages>
Reference-contexts: CDPC is fully automatic as it uses information available within the compiler to predict the access patterns of a compiler-parallelized application. This information is used to customize the applications page mapping strategy. The suggested page mapping is then treated as a hint by the operating system <ref> [17] </ref>. We show the importance of page mapping policies to the performance of a set of compiler-parallelized workloads. We then compare our compiler-directed page coloring technique with two existing page mapping policies used by commercial operating systems. We show that neither existing page mapping policy dominates the other.
Reference: [18] <author> Todd C. Mowry, Monica S. Lam and Anoop Gupta, </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching, </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Oct. </month> <year> 1992, </year> <pages> pp. 62-73. </pages>
Reference: [19] <author> Todd C. Mowry, </author> <title> Tolerating Latency through Software-controlled Data Prefetching, </title> <type> Ph.D. thesis, Technical Report CSL-TR-94-626, </type> <institution> Stanford University, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: Prefetch instructions are supported in many recent processors (e.g., the MIPS R10000, the DEC Alpha 21164). Previous studies have demonstrated the effectiveness of automatic compiler-inserted prefetching on sequential and hand-parallelized applications <ref> [19] </ref>. In this paper, we present the first results where automatic prefetching is combined with automatic parallelization. 3 Experimental Setup 3.1 The Workloads We used the ten programs of the SPEC95fp benchmark suite for our experiments. <p> To hide the latency of the misses that remain after CDPC, we used the SUIF compiler to automatically insert prefetch instructions into the compiler-parallelized code. Our algorithm uses locality analysis to insert prefetches only for those references that are likely to suffer misses <ref> [19] </ref>. Although the MIPS R4400 processors do not support prefetching, the SimOS CPU simulators model the prefetch instruction of the MIPS R10000.
Reference: [20] <author> Theodore H. Romer, Dennis Lee, Brian N. Bershad and J. Bradley Chen, </author> <title> Dynamic Page Mapping Policies for Cache Conict Resolution on Standard Hardware, </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <month> Nov. </month> <year> 1994, </year> <pages> pp. 255-266. </pages>
Reference-contexts: The operating system uses either some custom hardware in the form of a cache-miss lookaside buffer [4] or a combination of TLB state information and cache miss counters to detect conicts <ref> [20] </ref>. When such a conict is detected, one of the pages involved in the conict is recolored. To our knowledge, the performance of dynamic policies for multiprocessors has not been studied.
Reference: [21] <author> Mendel Rosenblum, Stephen A. Herrod, Emmett Witchel and Anoop Gupta, </author> <title> Complete Computer Simulation: The SimOS Approach, </title> <booktitle> In IEEE Parallel and Distributed Technology, </booktitle> <volume> 3(4), </volume> <month> Fall </month> <year> 1995. </year>
Reference-contexts: This technology has the promise of making parallel processing accessible to a much broader range of users. However, the performance of the parallel codes is highly sensitive to its memory subsystem behavior. We used the SimOS machine simulation environment <ref> [21] </ref> to study the performance of the SPEC95fp benchmark suite [22] parallelized by the SUIF compiler [24]. A close look at the behavior of the applications shows that the compiler is good at making use of the additional processors and at eliminating unnecessary communication between processors. <p> The feedback mechanism uses the training data sets of the benchmarks to determine which loops should be suppressed. 3.3 Simulation Methodology The simulation platform is SimOS <ref> [21] </ref>. We used SimOS to study the performance of the workloads in detail and to analyze the Benchmark Data set size (MB) 101.tomcatv 14 102.swim 14 103.su2cor 23 104.hydro2d 8 107.mgrid 7 110.applu 31 125.turb3d 24 141.apsi 9 145.fpppp &lt; 1 146.wave5 40 Table 1.
Reference: [22] <institution> Standard Performance Evaluation Corporation, </institution> <note> The SPEC95fp benchmark suite. http://www.spechbench.org. </note>
Reference-contexts: This technology has the promise of making parallel processing accessible to a much broader range of users. However, the performance of the parallel codes is highly sensitive to its memory subsystem behavior. We used the SimOS machine simulation environment [21] to study the performance of the SPEC95fp benchmark suite <ref> [22] </ref> parallelized by the SUIF compiler [24]. A close look at the behavior of the applications shows that the compiler is good at making use of the additional processors and at eliminating unnecessary communication between processors.
Reference: [23] <author> Ben Verghese, Scott Devine, Anoop Gupta and Mendel Rosenblum, </author> <title> Operating System Support for Improving Locality on CC-NUMA Compute Servers, </title> <booktitle> In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: However, detecting conict misses in a multiprocessor is harder than on a uniprocessor as one must be able to differentiate conict misses from coherence misses. The overheads of a recoloring operation are also likely to be significantly larger than on uniprocessors <ref> [23] </ref>. The TLB state of each processor must be individually ushed and the recoloring operation may generate significant inter-processor communication. The page mapping policies, and more generally the memory management policies, of an operating system can lead to poor performance for applications with non-standard requirements.
Reference: [24] <author> Robert P. Wilson, Robert S. French, Christopher S. Wilson, Saman P. Amarasinghe, Jennifer M. Anderson, Steven W.K. Tjiang, Shi-Wei Liao, Chau-Wen Tseng, Mary W. Hall, Monica S. Lam and John L. Hennessy, </author> <title> SUIF: An Infrastructure for Research on Parallelizing and Optimizing Compilers, </title> <journal> In ACM SIGPLAN Notices, </journal> <volume> 29(12), </volume> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: However, the performance of the parallel codes is highly sensitive to its memory subsystem behavior. We used the SimOS machine simulation environment [21] to study the performance of the SPEC95fp benchmark suite [22] parallelized by the SUIF compiler <ref> [24] </ref>. A close look at the behavior of the applications shows that the compiler is good at making use of the additional processors and at eliminating unnecessary communication between processors. However, the parallelized codes are not taking advantage of the increase in aggregate cache size available to the parallel computation.
Reference: [25] <author> Emmett Witchel and Mendel Rosenblum, Embra: </author> <title> Fast and Flexible Machine Simulation, </title> <booktitle> In Proceedings of the ACM SIGMETRICS 96 Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 68-79. </pages>
Reference-contexts: The execution of the application consists of a sequence of sequential and parallel regions. Master Slaves state of the workload. The representative execution window is a part of the steady state that contains each phase at least once. We used SimOSs high-speed simulator <ref> [25] </ref>, configured to model a large external cache, to execute the sequential benchmarks to completion. For each benchmark, we analyze the variation in execution behavior between different occurrences of each phase.
Reference: [26] <author> Michael E. Wolf and Monica S. Lam, </author> <title> A Data Locality Optimizing Algorithm, </title> <booktitle> In Proceedings of the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991, </year> <pages> pp. 30-44. </pages>
References-found: 26

