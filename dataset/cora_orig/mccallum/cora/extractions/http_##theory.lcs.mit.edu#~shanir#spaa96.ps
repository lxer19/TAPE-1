URL: http://theory.lcs.mit.edu/~shanir/spaa96.ps
Refering-URL: http://theory.lcs.mit.edu/tds/reflist.html
Root-URL: 
Title: A Steady State Analysis of Diffracting Trees (Extended Abstract)  
Author: Nir Shavit Eli Upfal Asaph Zemach 
Abstract: Diffracting trees are an effective and highly scalable distributed-parallel technique for shared counting and load balancing. This paper presents the first steady-state combinatorial model and analysis for diffracting trees, and uses it to answer several critical algorithmic design questions. Our model is simple and sufficiently high level to overcome many implementation specific details, and yet as we will show it is rich enough to accurately predict empirically observed behaviors. As a result of our analysis we were able to identify starvation problems in the original diffracting tree algorithm and modify it to a create a more stable version. We are also able to identify the range in which the diffracting tree performs most efficiently, and the ranges in which its performance degrades. We believe our model and modeling approach open the way to steady-state analysis of other distributed-parallel structures such as counting networks and elimination trees. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal and M. Cherian. </author> <title> Adaptive Backoff Synchronization Techniques. </title> <booktitle> In Proceedings of the 16th International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1989. </year>
Reference: [2] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <note> An extended version of this paper has been submitted for publication, and appears as MIT/LCS Memo TM-454, </note> <year> 1991. </year>
Reference-contexts: It is these and similar questions that our work attempts to address. 2.2 The New Algorithm We begin by modifying the diffracting tree algorithm of [12]. Touitou [18] reports the following when running a benchmark on the prototype MIT Alewife machine <ref> [2] </ref>. In his benchmark, processes repeatedly attempt to increment a diffracting tree based counter until some fixed number of increments has been performed. During sufficiently long runs, some processors end up performing all the increments, while all others remain "starving" in the tree. <p> the full diffracting tree should feed a binary tree of depth dlog 2 `e with ` counters in the leaves. 4 Experimental Results In order to verify the validity of our theoretical analysis we ran a set of benchmarks on a simulated distributed-shared-memory multiprocessor similar to the MIT Alewife machine <ref> [2] </ref>. Our simulations were performed using Proteus 1 , a multiprocessor simulator developed by Brewer et. al. [7] (see Appendix B for details). In our benchmarks we measured the average latency of processors accessing a distributed Fetch&Increment counter implemented as a diffracting tree with hardware Fetch&Increment counters at its leaves.
Reference: [3] <author> B. Aiello, R. Venkatesan and M. Yung. </author> <title> Optimal Depth Counting Networks. </title> <type> personal communication. </type>
Reference-contexts: The closest modeling work related to ours is the amortized contention model of Dwork, Herlihy, and Waarts [9] used in the analysis of counting networks [9] and of the randomized counting networks by Aiello, Venkatesan, Yung <ref> [3] </ref>. However, unlike our work, that analysis is directed at mod eling and quantifying contention in the face of a worst case adversary, not the steady state behaviors of the algorithms in normal (i.e. common case) executions.
Reference: [4] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <title> Counting Networks. </title> <journal> Journal of the ACM, </journal> <volume> Vol. 41, No. </volume> <month> 5 (September </month> <year> 1994), </year> <pages> pp. 1020-1048. </pages>
Reference-contexts: 1 Introduction Diffracting trees [12] are among the most effective and scalable distributed-parallel techniques for shared counting, with a variety of applications to load balancing and concurrent data structure design. Diffracting trees are a special form of the counting networks of Aspnes, Herlihy, and Shavit <ref> [4] </ref>. They are constructed from simple one-input two-output computing elements called balancers that are connected to one another by wires to form a balanced binary tree. Tokens (processes) arrive on the balancer's input wire at arbitrary times, and are output on its output wires. <p> To illustrate this property, consider an execution in which tokens traverse the tree sequentially, one completely after the other. Figure 1 shows such an execution on a Binary <ref> [4] </ref> counting tree which we define formally in the appendix. As can be seen, the tree moves input tokens to output wires in increasing order modulo w. <p> The constant hid den by the O notation is small and depends on a particular machine's ability to handle multiple accesses to the same memory location. This is an expected result and fits well with the saturation model of Aspnes, Herlihy, and Shavit for counting networks <ref> [4] </ref>. 1 Version 3.00, dated February 18, 1993. The following figures show how our model accurately pre-dicts the experimental results. Figure 2 shows the latency of diffracting trees five and six levels deep.
Reference: [5] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <title> Counting Networks and Multi-Processor Coordination. </title> <booktitle> In Proceedings of the 23rd Annual Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: structures such as counting networks and other diffracting tree based data structures such as elimination trees [13], pools [13], priority queues, and so on. 2 Counting Trees and Diffraction Diffracting trees [12] are counting trees, a special form of the counting network data structures introduced by Aspnes, Herlihy and Shavit <ref> [5] </ref>. They are binary trees of nodes called balancers. A balancer is a computing element with one input wire and two output wires. Tokens arrive on the balancer's input wire at arbitrary times, and are output on its output wires.
Reference: [6] <author> E.A. Brewer, C.N. Dellarocas. </author> <title> Proteus User Documentation. MIT, 545 Technology Square, </title> <address> Cambridge, MA 02139, 0.5 edition, </address> <month> December </month> <year> 1992. </year>
Reference: [7] <author> E.A. Brewer, C.N. Dellarocas, A. Colbrook and W.E. Weihl. Proteus: </author> <title> A High-Performance Parallel-Architecture Simulator. </title> <type> MIT Technical Report /MIT/LCS/TR-561, </type> <month> September </month> <year> 1991. </year>
Reference-contexts: Our simulations were performed using Proteus 1 , a multiprocessor simulator developed by Brewer et. al. <ref> [7] </ref> (see Appendix B for details). In our benchmarks we measured the average latency of processors accessing a distributed Fetch&Increment counter implemented as a diffracting tree with hardware Fetch&Increment counters at its leaves. The average latency is the number of cycles it takes the counter to deliver an index.
Reference: [8] <author> D.G. </author> <title> Carta Two Fast Implementations of the "Minimal Standard" Random Number Generator. </title> <journal> CACM, </journal> <volume> 33(1), </volume> <month> January </month> <year> 1990. </year>
Reference: [9] <author> C. Dwork, M. P. Herlihy, and O. Waarts. </author> <title> Contention in shared memory algorithms. </title> <booktitle> In Proceedings of the 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 174-183, </pages> <month> May </month> <year> 1993. </year> <note> Expanded version: Digital Equipment Corporation Technical Report CRL 93/12. </note>
Reference-contexts: In the final section of this paper we provide a collection of experimental benchmarks that show how accurately our model fits with actual diffracting tree performance. The closest modeling work related to ours is the amortized contention model of Dwork, Herlihy, and Waarts <ref> [9] </ref> used in the analysis of counting networks [9] and of the randomized counting networks by Aiello, Venkatesan, Yung [3]. <p> The closest modeling work related to ours is the amortized contention model of Dwork, Herlihy, and Waarts <ref> [9] </ref> used in the analysis of counting networks [9] and of the randomized counting networks by Aiello, Venkatesan, Yung [3]. However, unlike our work, that analysis is directed at mod eling and quantifying contention in the face of a worst case adversary, not the steady state behaviors of the algorithms in normal (i.e. common case) executions.
Reference: [10] <author> J.R. Goodman, M.K. Vernon, and P.J. Woest. </author> <title> Efficient Synchronization Primitives for Large-Scale Cache-Coherent multiprocessors. </title> <booktitle> In Proceedings of the 3rd AS-PLOS, </booktitle> <pages> pages 64-75. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1989. </year>
Reference-contexts: Note that the calibration of our graphs, and hence the phenomena we are modeling, are very fine relative to the changes in latency for other types of data structures. For example, in [12], combining trees <ref> [10] </ref> are shown to have a latency increase by 2500 units over the tested concurrency range, and so the 300 unit change in latency of diffracting trees would be considered almost constant. See [12] for details. keeping the other parameters constant.
Reference: [11] <author> V.F. Kolchin, B.A. Senast'yanov, </author> <title> and V.P. Chistyakov. Random Allocation. </title> <publisher> V.H. Winston & Sons, </publisher> <address> Washington D.C. </address> <year> 1978. </year>
Reference-contexts: Let (p; b) = 1 (1 1 b (1 1 b ) p1 ; then E [M (p; b)] = b (p; b). Furthermore, if p; b ! 1 such that p b = (1), then with high probability M (p; b) is concentrated around its mean value <ref> [11] </ref>. The diffracting process distributes the processors evenly between balancers in the same level.
Reference: [12] <author> N. Shavit and A. Zemach. </author> <title> Diffracting Trees. </title> <booktitle> In Proceedings of the 6th Annual Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Diffracting trees <ref> [12] </ref> are among the most effective and scalable distributed-parallel techniques for shared counting, with a variety of applications to load balancing and concurrent data structure design. Diffracting trees are a special form of the counting networks of Aspnes, Herlihy, and Shavit [4]. <p> Our model is simple and sufficiently high level to overcome many implementation specific details, and yet as we will show it is rich enough to accurately predict empirically observed behaviors. As a result of our analysis we were able to identify starvation problems in the algorithm of <ref> [12] </ref> and thus introduce a more stable diffracting balancer algorithm (see section 2.2). We were also able to identify the range (as a function of P , work, d and L) in which the diffracting tree performs most efficiently, and the ranges in which its performance degrades. <p> We strongly believe our model and modeling approach pave the way to steady-state combinatorial analysis of other distributed-parallel data structures such as counting networks and other diffracting tree based data structures such as elimination trees [13], pools [13], priority queues, and so on. 2 Counting Trees and Diffraction Diffracting trees <ref> [12] </ref> are counting trees, a special form of the counting network data structures introduced by Aspnes, Herlihy and Shavit [5]. They are binary trees of nodes called balancers. A balancer is a computing element with one input wire and two output wires. <p> However, there is a large range of concurrency levels where there are moderate numbers of processors, and yet it is far from clear what level of diffraction is achieved. Furthermore, it was observed by <ref> [12, 13] </ref> that too many concurrent processors can also cause performance degradation. This brings us to the questions most often asked by practitioners implementing diffracting trees [17]. <p> It is these and similar questions that our work attempts to address. 2.2 The New Algorithm We begin by modifying the diffracting tree algorithm of <ref> [12] </ref>. Touitou [18] reports the following when running a benchmark on the prototype MIT Alewife machine [2]. In his benchmark, processes repeatedly attempt to increment a diffracting tree based counter until some fixed number of increments has been performed. <p> Nevertheless, we will show that it is rich enough to accurately model the empirically observed behavior. Unlike the new algorithm we analyze here, in the old algorithm of <ref> [12] </ref>, a processor that reached a new balancer tried diffracting in its prism once, and if it failed to diffract, moved to being queued on the toggle till it acquired it and proceeded to the next balancer. 3.1 Analysis Label the nodes of the tree 1; :::; 2 d+1 1 in <p> Note that the calibration of our graphs, and hence the phenomena we are modeling, are very fine relative to the changes in latency for other types of data structures. For example, in <ref> [12] </ref>, combining trees [10] are shown to have a latency increase by 2500 units over the tested concurrency range, and so the 300 unit change in latency of diffracting trees would be considered almost constant. See [12] for details. keeping the other parameters constant. <p> For example, in <ref> [12] </ref>, combining trees [10] are shown to have a latency increase by 2500 units over the tested concurrency range, and so the 300 unit change in latency of diffracting trees would be considered almost constant. See [12] for details. keeping the other parameters constant. Here we used a tree of depth 3 and 64 processors, with almost no work. The number of counters in the tree does not change, it remains 2 d = 8.
Reference: [13] <author> N. Shavit, and D. </author> <title> Touitou. </title> <booktitle> Elimination Trees and the Construction of Pools and Stacks In Proceedings of the 7th Annual Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 54-63, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: We strongly believe our model and modeling approach pave the way to steady-state combinatorial analysis of other distributed-parallel data structures such as counting networks and other diffracting tree based data structures such as elimination trees <ref> [13] </ref>, pools [13], priority queues, and so on. 2 Counting Trees and Diffraction Diffracting trees [12] are counting trees, a special form of the counting network data structures introduced by Aspnes, Herlihy and Shavit [5]. They are binary trees of nodes called balancers. <p> We strongly believe our model and modeling approach pave the way to steady-state combinatorial analysis of other distributed-parallel data structures such as counting networks and other diffracting tree based data structures such as elimination trees <ref> [13] </ref>, pools [13], priority queues, and so on. 2 Counting Trees and Diffraction Diffracting trees [12] are counting trees, a special form of the counting network data structures introduced by Aspnes, Herlihy and Shavit [5]. They are binary trees of nodes called balancers. <p> However, there is a large range of concurrency levels where there are moderate numbers of processors, and yet it is far from clear what level of diffraction is achieved. Furthermore, it was observed by <ref> [12, 13] </ref> that too many concurrent processors can also cause performance degradation. This brings us to the questions most often asked by practitioners implementing diffracting trees [17]. <p> The solution was to add a second layer prism between the first layer and the toggle bit, a method which empirically exhibits more stability at the price of slightly increased latency <ref> [13] </ref>. The combinatorial model of the next section shows that this form of starvation is an inherent phenomena in the old code due to the fact that processors that do not diffract can leave the balancer only by toggling the shared bit, that is, by passing through a sequential bottleneck. <p> Our analysis shows that in sufficiently long runs one will reach a permanent global state in which processors are piled up at the toggle bits. This would also be true of the method of <ref> [13] </ref> unless many levels of prisms are used, resulting in poor latency. The improved algorithm presented in this article solves this problem by allowing processors to repeatedly return to attempt diffractions on the prism after failing to acquire the toggle bit. <p> The improved algorithm presented in this article solves this problem by allowing processors to repeatedly return to attempt diffractions on the prism after failing to acquire the toggle bit. It is a dynamic form of the method used by <ref> [13] </ref>, but does not suffer from the same latency increase since it always uses the right number of prisms.
Reference: [14] <author> J.M. Mellor-Crummey and M.L. Scott. </author> <title> Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. </title> <type> Technical Report 342, </type> <institution> University of Rochester, Rochester, </institution> <address> NY 14627, </address> <month> April </month> <year> 1990. </year>
Reference: [15] <author> S.K. Park and K.W. Miller. </author> <title> Random number genera tors: Good ones are hard to find. </title> <journal> CACM, </journal> <month> 31(10),Octo-ber </month> <year> 1988. </year>
Reference: [16] <author> L. Rudolph, </author> <title> Decentralized cache scheme for an MIMD parallel processor. </title> <booktitle> In 11th Annual Computing Architecture Conference, </booktitle> <year> 1983, </year> <pages> pp. 340-347. </pages>
Reference: [17] <author> S. </author> <title> Kahan - TERA Computer Company. </title> <type> Personal com munication, </type> <month> May </month> <year> 1995. </year>
Reference-contexts: The processors need simply agree between themselves which one would have gotten the "0" bit, and which the "1". The diffraction mechanism uses randomization to ensure high collision/diffraction rates on the prism, and the tree structure guarantees correctness of the output values. When implementing diffracting trees <ref> [17] </ref>, the following type of questions are of critical importance. <p> Furthermore, it was observed by [12, 13] that too many concurrent processors can also cause performance degradation. This brings us to the questions most often asked by practitioners implementing diffracting trees <ref> [17] </ref>.
Reference: [18] <author> D. </author> <title> Touitou - Tel-Aviv University. </title> <type> Personal communication, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: It is these and similar questions that our work attempts to address. 2.2 The New Algorithm We begin by modifying the diffracting tree algorithm of [12]. Touitou <ref> [18] </ref> reports the following when running a benchmark on the prototype MIT Alewife machine [2]. In his benchmark, processes repeatedly attempt to increment a diffracting tree based counter until some fixed number of increments has been performed.
References-found: 18

