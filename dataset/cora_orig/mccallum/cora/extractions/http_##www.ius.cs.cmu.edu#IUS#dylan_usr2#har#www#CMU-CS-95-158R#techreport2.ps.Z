URL: http://www.ius.cs.cmu.edu/IUS/dylan_usr2/har/www/CMU-CS-95-158R/techreport2.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/baluja/www/techreps.html
Root-URL: 
Title: Human Face Detection in Visual Scenes  
Author: Henry A. Rowley Shumeet Baluja Takeo Kanade 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: November 1995  
Pubnum: CMU-CS-95-158R  
Abstract: We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates. This work was partially supported by a grant from Siemens Corporate Research, Inc., by the Department of the Army, Army Research Office under grant number DAAH04-94-G-0006, and by the Office of Naval Research under grant number N00014-95-1-0591. This work was started while Shumeet Baluja was supported by a National Science Foundation Graduate Fellowship. He is currently supported by a graduate student fellowship from the National Aeronautics and Space Administration, administered by the Lyndon B. Johnson Space Center. The views and conclusions contained in this document are those of the authors, and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the sponsoring agencies. 
Abstract-found: 1
Intro-found: 1
Reference: [ Baluja and Pomerleau, 1995a ] <author> Shumeet Baluja and Dean Pomerleau. </author> <title> Encouraging distributed input reliance in spatially constrained artificial neural networks: Applications to visual scene analysis and control. </title> <note> Submitted, </note> <year> 1995. </year>
Reference-contexts: using to detect faces, then present the error rates of the system over three large test sets. 3.1 Sensitivity Analysis In order to determine which part of the input image the network uses to decide whether the input is a face, we performed a sensitivity analysis using the method of <ref> [ Baluja and Pomerleau, 1995a ] </ref> . We collected a positive test set based on the training database of face images, but with different randomized scales, translations, and rotations than were used for training.
Reference: [ Baluja and Pomerleau, 1995b ] <author> Shumeet Baluja and Dean Pomerleau. </author> <title> Using a saliency map for active spatial selective attention: Implementation & initial results. </title> <editor> In G. Tesauro, D. S. Touretzky, and T. K. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems (NIPS) 7. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: When an image sequence is available, temporal coherence can focus attention on particular portions of the images. As a face moves about, its location in one frame is a strong predictor of its location in next frame. Standard tracking methods, as well as expectation-based methods <ref> [ Baluja and Pomerleau, 1995b ] </ref> , can be applied to focus the detector's attention. Other methods of improving system performance include obtaining more positive examples for training, or applying more sophisticated image preprocessing and normalization techniques.
Reference: [ Baluja, 1994 ] <author> Shumeet Baluja. </author> <title> Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning. </title> <institution> CMU-CS-94-163, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: Simple arbitration strategies, such as ANDing, can be used to combine the outputs of two verification networks. 4 After trying to arrange these images compactly by hand, we decided to use a more systematic approach. These images were laid out automatically by the PBIL optimization algorithm <ref> [ Baluja, 1994 ] </ref> . The objective function tries to pack images as closely as possible, by maximizing the amount of space left over at the bottom of each page. 16 the number of faces in the image, the number of faces detected correctly, and the number of false detections.
Reference: [ Hunke, 1994 ] <author> H. Martin Hunke. </author> <title> Locating and tracking of human faces with neural networks. </title> <type> Master's thesis, </type> <institution> University of Karlsruhe, </institution> <year> 1994. </year>
Reference-contexts: Other methods of improving system performance include obtaining more positive examples for training, or applying more sophisticated image preprocessing and normalization techniques. For instance, the color segmentation method used in <ref> [ Hunke, 1994 ] </ref> for color-based face tracking could be used to filter images. The face detector would then be applied only to portions of the image which contain skin color, which would speed up the algorithm as well as eliminating false detections.
Reference: [ Le Cun et al., 1989 ] <author> Y. Le Cun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hub-bard, and L. D. Jackel. </author> <title> Backpropogation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551, </pages> <year> 1989. </year>
Reference-contexts: For the experiments which are described later, we use networks with two and three sets of these hidden units. Similar input connection patterns are commonly used in speech and character recognition tasks <ref> [ Waibel et al., 1989, Le Cun et al., 1989 ] </ref> . The network has a single, real-valued output, which indicates whether or not the window contains a face. Examples of output from a single network are shown in Figure 3.
Reference: [ Pentland et al., 1994 ] <author> Alex Pentland, Baback Moghaddam, and Thad Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 84-91, </pages> <year> 1994. </year>
Reference-contexts: It may be possible to make the detectors more robust using the bootstrap technique described here and in [ Sung and Poggio, 1994 ] . Another related system is described in <ref> [ Pentland et al., 1994 ] </ref> . This system uses PCA to describe face patterns (as well as smaller patterns like eyes) with a lower-dimensional space than the image space.
Reference: [ Sung and Poggio, 1994 ] <author> Kah-Kay Sung and Tomaso Poggio. </author> <title> Example-based learning for view-based human face detection. </title> <journal> A.I. </journal> <note> Memo 1521, CBCL Paper 112, </note> <institution> MIT, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: The size of the training set for the second class can grow very quickly. We avoid the problem of using a huge training set for non-faces by selectively adding images to the training set as training progresses <ref> [ Sung and Poggio, 1994 ] </ref> . This bootstrap method reduces the size of the training set needed. Detailed descriptions of this training method, along with the network architecture are given in Section 2. In Section 3, the performance of the system is examined. <p> For the work presented here, we apply the filter at every pixel position in the image, and scale the image down by a factor of 1.2 for each step in the pyramid. The filtering algorithm is shown in Figure 1. First, a preprocessing step, adapted from <ref> [ Sung and Poggio, 1994 ] </ref> , is applied to a window of the image. <p> However, collecting a representative set of non-faces is difficult. Instead of collecting the images before training is started, the images are collected during training, in the following manner, adapted from <ref> [ Sung and Poggio, 1994 ] </ref> : 1. Create an initial set of non-face images by generating 1000 images with random pixel intensities. Apply the preprocessing steps to each of these images. 2 Dr. <p> These images contain 169 frontal views of faces, and require the networks to examine 22,053,124 20x20 pixel windows. Test Set B consists of 23 images containing 155 faces (9,678,084 windows); it was used in <ref> [ Sung and Poggio, 1994 ] </ref> to measure the accuracy of their system. Test Set C is similar to Test Set A, but contains many images with more complex backgrounds and without any faces, to more accurately measure the false detection rate. <p> These techniques, taken together, have proved useful in building an almost real-time version of the system suitable for demonstration purposes. 5 Comparison to Other Systems <ref> [ Sung and Poggio, 1994 ] </ref> reports a face detection system based on clustering techniques. Their system, like ours, passes a small window over all portions of the image, and determines whether a face exists in each window. <p> The second distance metric is the Euclidean distance between the test pattern and its projection in the 75 dimensional subspace. These distance measures have close ties with Principal Components Analysis (PCA), as described in <ref> [ Sung and Poggio, 1994 ] </ref> . The last step in their system is to use either a perceptron or a neural network with a hidden layer, trained to classify points using the two distances to each of the clusters (a total of 24 inputs). <p> In comparison, our system uses approximately 16000 positive examples and 9000 negative examples. Table 3 shows the accuracy of their system on Test Set B, along with the results of our system using the heuristics employed by Systems 10, 11, and 12 in Table 1. In <ref> [ Sung and Poggio, 1994 ] </ref> , 149 faces were labelled in the test set, while we labelled 155. Some of these faces are difficult for either system to detect. Based on the assumption that [ Sung and Poggio, 1994 ] were unable to detect any of the six additional faces <p> In <ref> [ Sung and Poggio, 1994 ] </ref> , 149 faces were labelled in the test set, while we labelled 155. Some of these faces are difficult for either system to detect. Based on the assumption that [ Sung and Poggio, 1994 ] were unable to detect any of the six additional faces we labelled, the number of missed faces is six more than the values listed in their paper. It should be noted that because of implementation details, [ Sung and Poggio, 1994 ] process a slightly <p> Based on the assumption that <ref> [ Sung and Poggio, 1994 ] </ref> were unable to detect any of the six additional faces we labelled, the number of missed faces is six more than the values listed in their paper. It should be noted that because of implementation details, [ Sung and Poggio, 1994 ] process a slightly smaller number of windows over the entire test set; this is taken into account when computing the false detection rates. Table 3 shows that for equal numbers of false detections, we can achieve higher detection rates. <p> <ref> [ Sung and Poggio, 1994 ] </ref> process a slightly smaller number of windows over the entire test set; this is taken into account when computing the false detection rates. Table 3 shows that for equal numbers of false detections, we can achieve higher detection rates. The main computational cost in [ Sung and Poggio, 1994 ] is in computing the two distance measures from each new window to 12 clusters. <p> We estimate that this computation requires fifty 21 times as many floating point operations as are needed to classify a window in our system, where the main costs are in preprocessing and applying neural networks to the window. Table 3: Comparison of <ref> [ Sung and Poggio, 1994 ] </ref> and Our System on Test Set B Missed Detect False False detect System faces rate detects rate Networks 1 and 2 ! AND (0) ! threshold (2,3) ! overlap elimination 34 78.1% 3 1 in 3226028 Networks 1 and 2 ! threshold (2,2) ! overlap <p> ! threshold (2,3) ! overlap elimination 34 78.1% 3 1 in 3226028 Networks 1 and 2 ! threshold (2,2) ! overlap elimination ! AND (2) Networks 1 and 2 ! threshold (2,2) ! overlap elimination ! OR (2) ! threshold (2,1) ! overlap elimination 11 92.9% 64 1 in 151220 <ref> [ Sung and Poggio, 1994 ] </ref> (Multi-layer network) 36 76.8% 5 1 in 1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1 in 742175 The candidate verification process used to speed up our system, described in Section 4, is similar to the detection technique used by [ Vaillant <p> and 2 ! threshold (2,2) ! overlap elimination ! AND (2) Networks 1 and 2 ! threshold (2,2) ! overlap elimination ! OR (2) ! threshold (2,1) ! overlap elimination 11 92.9% 64 1 in 151220 <ref> [ Sung and Poggio, 1994 ] </ref> (Multi-layer network) 36 76.8% 5 1 in 1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1 in 742175 The candidate verification process used to speed up our system, described in Section 4, is similar to the detection technique used by [ Vaillant et al., 1994 ] . In that work, two networks were used. <p> One possible problem with this work is that the negative training examples are selected manually from a small set of images (indoor scenes, similar to those used for testing the system). It may be possible to make the detectors more robust using the bootstrap technique described here and in <ref> [ Sung and Poggio, 1994 ] </ref> . Another related system is described in [ Pentland et al., 1994 ] . This system uses PCA to describe face patterns (as well as smaller patterns like eyes) with a lower-dimensional space than the image space. <p> The difference between the original and reconstructed images is a measure of how close the image is to being a face. Although the results reported are quite good, it is unlikely that this system is as robust as <ref> [ Sung and Poggio, 1994 ] </ref> , because Pentland's classifier is a special case of Sung and Poggio's system, using a single positive cluster rather than six positive and six negative clusters. [ Yang and Huang, 1994 ] used an approach quite different from the ones presented above. 22 Rather than
Reference: [ Umezaki, 1995 ] <author> Tazio Umezaki. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: Recall that the amount of position invariance in the pattern recognition component of our system determines how many windows must be processed. In the related task of license plate detection, <ref> [ Umezaki, 1995 ] </ref> decreased the number of windows that must be processed. The key idea was to have the neural-network be invariant to translations of about 25% of the size of a license plate.
Reference: [ Vaillant et al., 1994 ] <author> R. Vaillant, C. Monrocq, and Y. Le Cun. </author> <title> Original approach for the locali-sation of objects in images. </title> <booktitle> IEE Proceedings on Vision, Image, and Signal Processing, </booktitle> <volume> 141(4), </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: 151220 [ Sung and Poggio, 1994 ] (Multi-layer network) 36 76.8% 5 1 in 1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1 in 742175 The candidate verification process used to speed up our system, described in Section 4, is similar to the detection technique used by <ref> [ Vaillant et al., 1994 ] </ref> . In that work, two networks were used. The first network has a single output, and like our system it is trained to produce a maximal positive value for centered faces, and a maximal negative value for non-faces.
Reference: [ Waibel et al., 1989 ] <author> Alex Waibel, Toshiyuki Hanazawa, Geoffrey Hinton, Kiyohiro Shikano, and Kevin J. Lang. </author> <title> Phoneme recognition using time-delay neural networks. </title> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 393-404, </pages> <year> 1989. </year>
Reference-contexts: For the experiments which are described later, we use networks with two and three sets of these hidden units. Similar input connection patterns are commonly used in speech and character recognition tasks <ref> [ Waibel et al., 1989, Le Cun et al., 1989 ] </ref> . The network has a single, real-valued output, which indicates whether or not the window contains a face. Examples of output from a single network are shown in Figure 3.
Reference: [ Yang and Huang, 1994 ] <author> Gaungzheng Yang and Thomas S. Huang. </author> <title> Human face detection in a complex background. </title> <journal> Pattern Recognition, </journal> <volume> 27(1) </volume> <pages> 53-63, </pages> <year> 1994. </year> <month> 24 </month>
Reference-contexts: Although the results reported are quite good, it is unlikely that this system is as robust as [ Sung and Poggio, 1994 ] , because Pentland's classifier is a special case of Sung and Poggio's system, using a single positive cluster rather than six positive and six negative clusters. <ref> [ Yang and Huang, 1994 ] </ref> used an approach quite different from the ones presented above. 22 Rather than having the computer learn the face patterns to be detected, the authors manually coded rules and feature detectors for face detection.
References-found: 11

