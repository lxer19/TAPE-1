URL: http://choices.cs.uiuc.edu/~f-kon/multimedia/internet_music.ps.gz
Refering-URL: http://choices.cs.uiuc.edu/~f-kon/computer.music.html
Root-URL: http://www.cs.uiuc.edu
Email: f-kon@cs.uiuc.edu  iazzetta@exatas.pucsp.br  
Title: Internet Music: Dream or (virtual) Reality?  
Author: FABIO KON FERNANDO IAZZETTA Laboratorio de Linguagens Sonoras Comunica~c~ao e Semiotica PUC-SP R. Ministro Godoy, sala B- S~ao Paulo SP - Brasil 
Address: 1304 W. Springfield Avenue. Urbana, IL 61801 USA  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign  
Abstract: The recent explosive growth of the Internet and the fact that personal computers with multimedia capabilities are now a commonplace have raised the interest in distributed multimedia systems. Among all multimedia applications, the ones that relate to interactive music are the ones which present the tightest timing constraints. Traditional operating systems and networking infrastructure does not provide enough support for the quality of service these applications require. This paper describes a number of problems concerning distributed musical applications on the Internet and discusses possible solutions for each of them. We, then, consider a variety of situations in which Internet Music systems could be used and suggest that the Internet is a viable environment for musical activities even when using existing technologies. 
Abstract-found: 1
Intro-found: 1
Reference: [Casey and Smaragdis, 1996] <author> Casey, M. and Smaragdis, P. </author> <year> (1996). </year> <title> NetSound. </title> <booktitle> In Proceedings of the 1996 International Computer Music Conference, </booktitle> <address> Hong Kong. </address>
Reference-contexts: However, the recent explosion in the growth of the Internet and the fact that inexpensive personal computers are now capable of offering high-quality multimedia make this scenario likely to change. NetSound <ref> [Casey and Smaragdis, 1996] </ref> is a sound and music description system that is capable of streaming Csound [Vercoe, 1997] specifications in real-time. The main advantage of this approach is an enormous economy in network bandwidth.
Reference: [Chen et al., 1996] <author> Chen, Z., Tan, S. M., Sane, A., Li, Y., Campbell, R., and Xie, D. </author> <year> (1996). </year> <note> Video and Audio: Organization and Retrieval in the WWW. White Paper. Available at http://vosaic.com/corp/papers/www5.html. </note>
Reference-contexts: 1 Introduction In 1995, our research group at the University of Illinois developed Vosaic, an extension to the Mosaic Web Browser that is capable of streaming compressed video and audio in real time over the Internet using adaptive algorithms <ref> [Chen et al., 1996, Tan et al., 1996] </ref>. This pioneering work demonstrated that it was possible to send complex multimedia data over the Internet in real-time. However, it also showed that the complete unpredictability of the Internet behavior would pose very significant obstacles to the development of interactive distributed applications.
Reference: [Danks, 1997] <author> Danks, M. </author> <year> (1997). </year> <title> Real-time Image and Video Processing in GEM. </title> <booktitle> In Proceedings of the 1997 International Computer Music Conference, </booktitle> <pages> pages 220-223, </pages> <month> Thessa-loniki. </month>
Reference-contexts: The Global Visual-Music Project [Puckette et al., 1998] is developing an infrastructure for real-time, networked multimedia for multi-site, improvisatory performance. This group has developed PD, a programming language for real-time audio and graphics applications. By using this language and a set of extensions called GEM <ref> [Danks, 1997] </ref>, the group has composed Lemma 1 for percussion and trombone. It was performed on September 1997 in a Jazz club during the International Computer Music Conference. This performance was the first phase of a series called Global Visual-Music Jam Session.
Reference: [Deering and Hinden, 1997] <author> Deering, S. and Hinden, R. </author> <year> (1997). </year> <title> Internet Protocol, Version 6 (IPv6) Specification. draft-ietf-ipngwg-ipng-spec-v2-01.txt. Internet Draft. </title>
Reference-contexts: Therefore, the network provides the user some guarantees regarding bandwidth, latency, and jitter. A new and much more powerful version of the Internet Protocol, called IPv6, provides the underlying support for implementing systems capable of streaming real-time data guaranteeing that bandwidth, latency, and jitter requirements are met <ref> [Deering and Hinden, 1997] </ref>. A large number of operating system vendors and research groups are currently implementing IPv6 on their systems. It promises to be the next standard for wide-area inter-networking.
Reference: [Golombek et al., 1997] <author> Golombek, M. P., Cook, R. A., Economou, T., Folkner, W. M., Haldemann, A. F., Kallemeyn, P. H., Knudsen, J. M., Manning, R. M., Moore, H. J., Parker, T. J., Rieder, R., Schofield, J. T., Smith, P. H., and Vaughan, R. M. </author> <year> (1997). </year> <title> Overview of the Mars Pathfinder Mission and Assessment of Landing Site Predictions. </title> <journal> Science, </journal> <volume> 278(5344) </volume> <pages> 1734-42. </pages>
Reference-contexts: Using this framework, we were able to build large distribution networks that could potentially serve 3,000 simultaneous clients with low-bandwidth video and audio. Our technology was chosen to broadcast, live over the Internet, the coverage of the NASA JPL Mars Pathfinder mission <ref> [Golombek et al., 1997] </ref>. A network of more than 30 Reflectors spread across five continents was able to deliver live video and audio from the NASA Jet Propulsion Laboratory to more than one million clients in dozens of different countries.
Reference: [Iazzetta and Kon, 1995] <author> Iazzetta, F. and Kon, F. </author> <year> (1995). </year> <title> MaxAnnealing: A Tool for Algorithmic Composition Based on Simulated Annealing. </title> <booktitle> In Proceedings of the Second Brazilian Symposium on Computer Music. </booktitle>
Reference-contexts: A supercomputer today has the computational power of personal computers of five to ten years in the future. Musical applications of supercomputing include real-time synthesis [Kriese and Tipei, 1992], and computationally intensive algorithmic composition tools such as MaxAnnealing <ref> [Iazzetta and Kon, 1995] </ref>. Supercomputers are, by definition, scarce resources to which very few people have access. They are usually shared by a large number of researchers and they have very little mobility.
Reference: [Kon et al., 1998] <author> Kon, F., Campbell, R. H., Tan, S., Valdez, M., Chen, Z., and Wong, J. </author> <year> (1998). </year> <title> A Component-Based Architecture for Scalable Distributed Multimedia. </title> <booktitle> In Proceedings of the 14th International Conference on Advanced Science and Technology (ICAST'98), </booktitle> <pages> pages 121-135, </pages> <institution> Lucent Technologies, Naperville. </institution> <month> 9 </month>
Reference-contexts: In this section, we discuss some scenarios in which the topics discussed previously can be deployed. 4.1 Concert Broadcasts At the University of Illinois, we have been developing a scalable distribution framework for real-time multimedia streaming <ref> [Kon et al., 1998] </ref>. Using this framework, we were able to build large distribution networks that could potentially serve 3,000 simultaneous clients with low-bandwidth video and audio. Our technology was chosen to broadcast, live over the Internet, the coverage of the NASA JPL Mars Pathfinder mission [Golombek et al., 1997].
Reference: [Kriese and Tipei, 1992] <author> Kriese, C. and Tipei, S. </author> <year> (1992). </year> <title> A Compositional Approach to Additive Synthesis on Supercomputers. </title> <booktitle> In Proceedings of the 1992 International Computer Music Conference, </booktitle> <pages> pages 394-395, </pages> <address> San Jose, CA. </address>
Reference-contexts: A supercomputer today has the computational power of personal computers of five to ten years in the future. Musical applications of supercomputing include real-time synthesis <ref> [Kriese and Tipei, 1992] </ref>, and computationally intensive algorithmic composition tools such as MaxAnnealing [Iazzetta and Kon, 1995]. Supercomputers are, by definition, scarce resources to which very few people have access. They are usually shared by a large number of researchers and they have very little mobility.
Reference: [Leslie et al., 1996] <author> Leslie, I., McAuley, D., Black, R., Roscoe, T., Barham, P., Evers, D., Fairbairns, R., and Hyden, E. </author> <year> (1996). </year> <title> The Design and Implementation of an Operating System to Support Distributed Multimedia Applications. </title> <journal> IEEE Journal on Selected Areas in Communication, </journal> <volume> 14(7) </volume> <pages> 1280-1297. </pages>
Reference-contexts: Experimental systems such as Nemesis <ref> [Leslie et al., 1996] </ref> controls the admission of new tasks and provide support for resource allocation and real-time scheduling based on application requirements. With these facilities, a system can offer guarantees that the multimedia streams will be processed with the required quality of service.
Reference: [Loy, 1985] <author> Loy, C. </author> <year> (1985). </year> <title> Musicians Make a Standard: The MIDI Phenomenon. </title> <journal> Computer Music Journal, </journal> <volume> 9(4) </volume> <pages> 9-26. </pages>
Reference-contexts: can be avoided by using alternative data representations rather than dealing with the digitized wave form. 1 The higher the data rate is, the higher is the sound quality. 4 The most commonly known alternative representation is the MIDI format that stores information about musical notes rather than sound waves <ref> [Loy, 1985] </ref>. The MIDI standard produces very low data rates typically in the order of 0.1 to 5kbps. The codified notes are received by the MIDI player which produces the output sound wave.
Reference: [Moore, 1987] <author> Moore, F. R. </author> <year> (1987). </year> <booktitle> The Dysfunctions of MIDI. In Proceedings of the 1987 International Computer Music Conference, </booktitle> <pages> pages 256-263, </pages> <address> San Francisco. </address>
Reference-contexts: This can be done either by manipulating wave tables or by synthesizing the wave forms from mathematical models. This process can be done both in software and using special hardware such as sound cards or other sound devices. MIDI presents a series of limitations <ref> [Moore, 1987, Puckette, 1994] </ref> including the fact that the data stream does not contain a description of the wave form but, simply, pitch, intensity, and the "instrument" that plays each note. Each MIDI player is free to give its own interpretation of how the instrument will sound.
Reference: [MPEG.ORG, 1998] <institution> MPEG.ORG (1998). </institution> <note> MPEG-Audio layer 3 resources. URL: http: //www.mpeg.org/index.html/mp3.html. </note>
Reference-contexts: The GSM algorithm [Vary and et al, 1988], for example, is used in audioconfer-encing and telephony applications and produces a data rate of 11.3kbps. But its quality is far from being enough for professional musical applications. The MPEG layer 3 standard <ref> [MPEG.ORG, 1998] </ref> uses a psychoacoustic model to capture the information that is more relevant to the human ear and ignores what cannot be perceived [Sporer et al., 1992].
Reference: [Puckette, 1994] <author> Puckette, M. </author> <year> (1994). </year> <booktitle> Is there life after midi? In Proceedings of the 1994 International Computer Music Conference, </booktitle> <pages> page 2, </pages> <address> Aarhus, Denmark. </address>
Reference-contexts: This can be done either by manipulating wave tables or by synthesizing the wave forms from mathematical models. This process can be done both in software and using special hardware such as sound cards or other sound devices. MIDI presents a series of limitations <ref> [Moore, 1987, Puckette, 1994] </ref> including the fact that the data stream does not contain a description of the wave form but, simply, pitch, intensity, and the "instrument" that plays each note. Each MIDI player is free to give its own interpretation of how the instrument will sound.
Reference: [Puckette et al., 1998] <author> Puckette, M., Sorensen, V., and Steiger, R. </author> <year> (1998). </year> <title> The Global Visual Music Project. Project Home Page: </title> <address> http://www.earunit.org/gvm.htm. </address>
Reference-contexts: Although this approach solves the bandwidth problem, it does not address latency and jitter issues (see section 3.3). Actually, it might increase these problems since intensive computation is performed in the target machine. The Global Visual-Music Project <ref> [Puckette et al., 1998] </ref> is developing an infrastructure for real-time, networked multimedia for multi-site, improvisatory performance. This group has developed PD, a programming language for real-time audio and graphics applications.
Reference: [Sporer et al., 1992] <author> Sporer, T., Brandenburg, K., and Edler, B. </author> <year> (1992). </year> <title> The use of multirate filter banks for coding of high quality digital audio. </title> <booktitle> In Proceedings of the 6th European Signal Processing Conference, </booktitle> <pages> pages 211-214. </pages>
Reference-contexts: But its quality is far from being enough for professional musical applications. The MPEG layer 3 standard [MPEG.ORG, 1998] uses a psychoacoustic model to capture the information that is more relevant to the human ear and ignores what cannot be perceived <ref> [Sporer et al., 1992] </ref>. By applying filter banks, quantizations, entropy compression, and by exploiting redundancy of both channels, MPEG is capable of encoding high-quality audio at data rates ranging from 8kbps to 128kbps 1 .
Reference: [Steinmetz and Nahrstedt, 1995] <author> Steinmetz, R. and Nahrstedt, K. </author> <year> (1995). </year> <title> Multimedia: Computing, Communications, and Applications. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey. </address>
Reference-contexts: Commonly used Ethernet connections and the Internet Protocol does not provide any kind of guarantee regarding the transmission of data 5 packets. One cannot know, a priori, what the available bandwidth is and the latency can vary from a few microseconds to several seconds. ATM and FDDI networks <ref> [Steinmetz and Nahrstedt, 1995] </ref>, on the other hand, provide the basis for resource reservation and admission control. On these networks it is possible to reserve a certain fraction of the network time to specific data streams. Therefore, the network provides the user some guarantees regarding bandwidth, latency, and jitter. <p> Multimedia and real-time applications have completely different requirements that have been addressed by recent research <ref> [Steinmetz and Nahrstedt, 1995] </ref>. Traditional operating systems manage hardware resources such as CPU, disk, memory, and network using best-effort strategies. They usually accept any number of tasks without paying attention to the quality of service that will be offered to their users.
Reference: [Tan et al., 1996] <author> Tan, S., Campbell, R., Chen, Z., Liao, W., Raila, D. K., Kon, F., and Valdez, M. </author> <year> (1996). </year> <title> Adaptation and Synchronization in Low-Bandwidth Internet Video. In World Wide Web Consortium Workshop on Real Time Multimedia and the Web (RTMW '96), </title> <institution> INRIA Sophia Antipolis, France. </institution>
Reference-contexts: 1 Introduction In 1995, our research group at the University of Illinois developed Vosaic, an extension to the Mosaic Web Browser that is capable of streaming compressed video and audio in real time over the Internet using adaptive algorithms <ref> [Chen et al., 1996, Tan et al., 1996] </ref>. This pioneering work demonstrated that it was possible to send complex multimedia data over the Internet in real-time. However, it also showed that the complete unpredictability of the Internet behavior would pose very significant obstacles to the development of interactive distributed applications.
Reference: [University Corporation for Advanced Internet Development, 1998] <institution> University Corporation for Advanced Internet Development (1998). Internet2 Project Home Page. </institution> <address> http://www. internet2.edu. </address>
Reference-contexts: The bandwidth of existing wide-area networks has been increasing very rapidly in the last few years. According to Richard Palmer, a marketing director at Cisco Systems, Inc., new gigabit switch routers will scale from 622Mbps to 2.4Gbps in 1998 and to 9.6Gbps in 1999. Internet2 <ref> [University Corporation for Advanced Internet Development, 1998] </ref> will connect more than one hundred research universities in the United States at 2.4Gbps by the year 2000. The same trend can be observed in other countries and in non-academic Internet systems.
Reference: [Vary and et al, 1988] <editor> Vary, P. and et al (1988). </editor> <title> A speech codec for the European mobile radio system. </title> <booktitle> In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 227-230. </pages>
Reference-contexts: Audio-specific compression algorithms have been developed as a means to utilize the knowledge about the characteristics of the audio data in order to achieve a better compression ratio. The GSM algorithm <ref> [Vary and et al, 1988] </ref>, for example, is used in audioconfer-encing and telephony applications and produces a data rate of 11.3kbps. But its quality is far from being enough for professional musical applications.
Reference: [Vercoe, 1997] <author> Vercoe, B. </author> <year> (1997). </year> <title> Csound Manual. Media Lab, MIT. Edited by Jean Piche. Acknowledgments The authors gratefully acknowledge the support provided by CAPES and FAPESP. Fabio Kon is supported by a grant from CAPES, proc.# 1405/95-2 and Fernando Iazzetta is supported by FAPESP, </title> <booktitle> proc.# </booktitle> <pages> 97/01688-1. 10 </pages>
Reference-contexts: However, the recent explosion in the growth of the Internet and the fact that inexpensive personal computers are now capable of offering high-quality multimedia make this scenario likely to change. NetSound [Casey and Smaragdis, 1996] is a sound and music description system that is capable of streaming Csound <ref> [Vercoe, 1997] </ref> specifications in real-time. The main advantage of this approach is an enormous economy in network bandwidth. Instead of sending a digitized audio wave through the network, NetSound sends a mathematical description of the sound wave which is then generated at the target machine.
References-found: 20

