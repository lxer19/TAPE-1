URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3278/3278.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: perlis@cs.umd.edu  
Title: LOGIC FOR A LIFETIME  
Author: Don Perlis AV Williams Bldg 
Note: This research was supported in part by NSF grant IRI9311988.  
Address: College Park, MD 20742  
Affiliation: Institute for Advanced Computer Studies Computer Science Department  University of Maryland  
Date: May 26, 1994  
Pubnum: CS-TR-3278  UMIACS-TR94-62  
Abstract: There has been an explosion of formal work in commonsense reasoning in the past fifteen years, but almost no significant connection with work in building commonsense reasoning systems (cognitive or otherwise). We explore the reasons, and especially the ideal formal assumption of omniscience, reviewing and extending arguments that this is irreparably out of line with the needs of any real reasoning agent. On the other hand, this exploration reveals some desiderata that might still be given useful formal treatment, but with a somewhat altered set of aims from what has motivated most formal work. The discussion is motivated by several examples of commonsense reasoning, involving change of belief in addition to the more usual arguments concerning resource limitations. Key to the entire discussion is the notion that real reasoners do not usually have the luxury of isolated problems with well-defined beginnings and endings, but rather must deal with evolving and ongoing problems and situations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Arruda. </author> <title> A survey of paraconsistent logic. </title> <editor> In A. Arruda, R. Chuaqui, and N.C.A. da Costa, editors, </editor> <booktitle> Mathematical Logic ni Latin America, </booktitle> <pages> pages 1-41. </pages> <publisher> North-Holland, </publisher> <year> 1980. </year>
Reference-contexts: Some, such as the paraconsistent logics surveyed in <ref> [1] </ref>, aim to extract a trustworthy core of inferences while avoiding the contradictions. Others, such as [5, 15, 26], aim to detect and resolve contradictions. The latter are closer in spirit to the needs we are addressing here.
Reference: [2] <author> J. Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(3) </volume> <pages> 231-272, </pages> <year> 1979. </year> <month> 10 </month>
Reference-contexts: view that evolved in the early 1980s, but to my knowledge has never been carefully expressed in writing), commonsense reasoning consists of an ongoing alternation of two kinds of symbolic manipulation: the CSR phase, during which defeasible theorems are proven from given commonsense axioms (beliefs), and truth-maintenance phase (TMS, see <ref> [2] </ref>), during which the axiom set is updated based on new incoming information (and theorems are retracted as needed). Then follows another round of CSR, then (if more data comes in) more TMS, etc.
Reference: [3] <author> J. Elgot-Drapkin. Step-logic: </author> <title> Reasoning Situated in Time. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, College Park, Maryland, </institution> <year> 1988. </year>
Reference-contexts: Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR [21, 24, 22, 23] as well as active (step) logics <ref> [4, 3, 5, 16, 9] </ref> are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [4] <author> J. Elgot-Drapkin. </author> <title> Step-logic and the three-wise-men problem. </title> <booktitle> In Proceedings of the 9th National Conference on Artificial Intelligence, </booktitle> <pages> pages 412-417, </pages> <year> 1991. </year>
Reference-contexts: Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR [21, 24, 22, 23] as well as active (step) logics <ref> [4, 3, 5, 16, 9] </ref> are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [5] <author> J. Elgot-Drapkin and D. Perlis. </author> <title> Reasoning situated in time I: Basic concepts. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2(1) </volume> <pages> 75-98, </pages> <year> 1990. </year>
Reference-contexts: Some, such as the paraconsistent logics surveyed in [1], aim to extract a trustworthy core of inferences while avoiding the contradictions. Others, such as <ref> [5, 15, 26] </ref>, aim to detect and resolve contradictions. The latter are closer in spirit to the needs we are addressing here. <p> Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR [21, 24, 22, 23] as well as active (step) logics <ref> [4, 3, 5, 16, 9] </ref> are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [6] <editor> M. Ginsberg, editor. </editor> <booktitle> Readings in Nonmonotonic Reasoning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: At a very high level (a more prosaic and more revealing description is given later) it is this: omniscient formalisms have the major advantage of being simpler and easier to study, and can be taken as modeling 1 E.g., witness the collections <ref> [6] </ref> and [8], the recurrent international NMR and KRR workshops, and in particular the many beautiful discoveries by McCarthy, Reiter, Moore, Konolige, Levesque, Pearl, Halpern, and Lifschitz, among others. 2 ideal reasoners against which real (human or robotic) reasoners can be measured as approx-imations.
Reference: [7] <author> R. Guha and D. Lenat. </author> <title> Cyc: a midterm report. </title> <journal> AI Magazine, </journal> <volume> 11(3) </volume> <pages> 32-59, </pages> <year> 1990. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms.
Reference: [8] <author> Jerry Hobbs and Robert Moore, </author> <title> editors. Formal Theories of the Commonsense World. </title> <publisher> Ablex, </publisher> <year> 1985. </year>
Reference-contexts: At a very high level (a more prosaic and more revealing description is given later) it is this: omniscient formalisms have the major advantage of being simpler and easier to study, and can be taken as modeling 1 E.g., witness the collections [6] and <ref> [8] </ref>, the recurrent international NMR and KRR workshops, and in particular the many beautiful discoveries by McCarthy, Reiter, Moore, Konolige, Levesque, Pearl, Halpern, and Lifschitz, among others. 2 ideal reasoners against which real (human or robotic) reasoners can be measured as approx-imations. <p> The reasoner must be able to reason about these changes, to incorporate them into her usage intelligently; and this involves noting tension (contradictions!) between usages. Noting that "John is tall" contradicts the personal 5 As I myself have done; see [20]. Also see the introduction to <ref> [8] </ref>. 8 observation that John is short, she starts to wonder whether these might be two different persons named "John" (see [15]). Interpreting orders Your boss tells you (a personnel manager) never to hire high-school dropouts. One day a job candidate comes to your office.
Reference: [9] <author> S. Kraus, M. Nirkhe, and D. Perlis. </author> <title> Planning and acting in deadline situations. </title> <booktitle> Presented at the AAAI-90 Workshop on Planning in Complex Domains, </booktitle> <year> 1990. </year>
Reference-contexts: Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR [21, 24, 22, 23] as well as active (step) logics <ref> [4, 3, 5, 16, 9] </ref> are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [10] <author> J. Laird, A. Newell, and P. Rosenbloom. </author> <title> Soar: an architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms.
Reference: [11] <author> J. McCarthy. </author> <title> Programs with common sense. </title> <booktitle> In Proceedings of the Symposium on the Mechanization of Thought Processes, </booktitle> <address> Teddington, England, </address> <year> 1958. </year> <institution> National Physical Laboratory. </institution>
Reference-contexts: Do you hire him or not? Commonsense says this not what your boss meant by "HS dropout". But you are a little nervous because you realize that there is a clash of meanings, and you want to check it out with your boss. Taking advice Advice taking <ref> [11] </ref> involves trusting what others say. But they may contradict what you believe, and you need to realize this even of you do trust them, so you can remove the contradicted beliefs. This is not necessarily straightforward, since it may take some reasoning to find out the contradictions.
Reference: [12] <author> J. McCarthy. </author> <title> Circumscription: A form of non-monotonic reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):27-39, </volume> <year> 1980. </year>
Reference-contexts: We may now be in need of yet another revolution. 3 or robot) commonsense reasoning. By 1980 at least three distinct formalisms for NMR had been developed <ref> [12, 25, 14] </ref>, and the standard model began to emerge. To present this model, we first restate the examples in chronological terms: at first we know Tweety is a bird and so conclude Tweety can fly; later we learn Tweety is an ostrich, and so then retract our earlier conclusion.
Reference: [13] <author> J. McCarthy and V. Lifschitz. </author> <title> Commentary on McDermott. </title> <journal> Computational Intelligence, </journal> <volume> 3(3) </volume> <pages> 196-197, </pages> <year> 1987. </year>
Reference-contexts: Language change It has been argued before <ref> [13, 19] </ref> that unlike the case of customary fixed formal languages, commonsense (or natural) language changes: new terms are coined or learned, old terms change meanings, etc.
Reference: [14] <author> D. McDermott and J. Doyle. </author> <title> Non-monotonic logic I. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):4172, </volume> <year> 1980. </year>
Reference-contexts: We may now be in need of yet another revolution. 3 or robot) commonsense reasoning. By 1980 at least three distinct formalisms for NMR had been developed <ref> [12, 25, 14] </ref>, and the standard model began to emerge. To present this model, we first restate the examples in chronological terms: at first we know Tweety is a bird and so conclude Tweety can fly; later we learn Tweety is an ostrich, and so then retract our earlier conclusion.
Reference: [15] <author> M. Miller. </author> <title> A view of one's past and other aspects of reasoned change in belief. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, College Park, Maryland, </institution> <year> 1993. </year>
Reference-contexts: Some, such as the paraconsistent logics surveyed in [1], aim to extract a trustworthy core of inferences while avoiding the contradictions. Others, such as <ref> [5, 15, 26] </ref>, aim to detect and resolve contradictions. The latter are closer in spirit to the needs we are addressing here. <p> Noting that "John is tall" contradicts the personal 5 As I myself have done; see [20]. Also see the introduction to [8]. 8 observation that John is short, she starts to wonder whether these might be two different persons named "John" (see <ref> [15] </ref>). Interpreting orders Your boss tells you (a personnel manager) never to hire high-school dropouts. One day a job candidate comes to your office. The interview goes fine and you note that he has a PhD.
Reference: [16] <author> M. Miller and D. Perlis. </author> <title> Presentations and this and that: </title> <booktitle> logic in action. In Proceedings of the 15th Annual Conference of the Cognitive Science Society, </booktitle> <address> Boulder, Colorado, </address> <year> 1993. </year>
Reference-contexts: Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR [21, 24, 22, 23] as well as active (step) logics <ref> [4, 3, 5, 16, 9] </ref> are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [17] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <editor> In P. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: 1 Introduction There has been an explosion of formal work in commonsense reasoning in the past fifteen years, largely in the specific area of nonmonotonic reasoning (NMR). 1 This resulted in part from the observation <ref> [17] </ref> that human commonsense reasoning (CSR) often does not obey traditional modes of logical inference. But Minsky may have misdiagnosed the source of the problem. <p> of aims from what has motivated much existing formal work. 3 To a considerable extent, the paradigm suggested by Nilsson [18] of a robot with a lifetime of its own serves as an underlying motivational theme. 2 The standard model We begin with Minsky's (by now famous and overworked) examples <ref> [17] </ref> of two commonsense human inferences: from the information that Tweety is a bird, one may well infer that Tweety can fly; and yet if instead the reasoner had originally had the additional information that Tweety is an ostrich, the former inference would likely not have occurred and indeed instead one
Reference: [18] <author> N. J. Nilsson. </author> <title> Artificial intelligence prepares for 2001. </title> <journal> AI Magazine, </journal> <volume> 4(4) </volume> <pages> 7-14, </pages> <year> 1983. </year>
Reference-contexts: well as their possible significance for future formal directions, since this exploration also suggests desiderata that may very well be given useful formal treatment, but with a somewhat different set of aims from what has motivated much existing formal work. 3 To a considerable extent, the paradigm suggested by Nilsson <ref> [18] </ref> of a robot with a lifetime of its own serves as an underlying motivational theme. 2 The standard model We begin with Minsky's (by now famous and overworked) examples [17] of two commonsense human inferences: from the information that Tweety is a bird, one may well infer that Tweety can
Reference: [19] <author> D. Perlis. </author> <title> Language, Computation, and Reality. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1981. </year>
Reference-contexts: Language change It has been argued before <ref> [13, 19] </ref> that unlike the case of customary fixed formal languages, commonsense (or natural) language changes: new terms are coined or learned, old terms change meanings, etc.
Reference: [20] <author> D. Perlis. </author> <title> Languages with self reference I: </title> <booktitle> Foundations. Artificial Intelligence, </booktitle> <address> 25:301322, </address> <year> 1985. </year>
Reference-contexts: The reasoner must be able to reason about these changes, to incorporate them into her usage intelligently; and this involves noting tension (contradictions!) between usages. Noting that "John is tall" contradicts the personal 5 As I myself have done; see <ref> [20] </ref>. Also see the introduction to [8]. 8 observation that John is short, she starts to wonder whether these might be two different persons named "John" (see [15]). Interpreting orders Your boss tells you (a personnel manager) never to hire high-school dropouts.
Reference: [21] <author> J. L. Pollock. </author> <title> Defeasible reasoning. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 481-518, </pages> <year> 1987. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms. <p> Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR <ref> [21, 24, 22, 23] </ref> as well as active (step) logics [4, 3, 5, 16, 9] are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [22] <author> John Pollock. </author> <title> How to build a person. </title> <publisher> MIT, </publisher> <year> 1989. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms. <p> Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR <ref> [21, 24, 22, 23] </ref> as well as active (step) logics [4, 3, 5, 16, 9] are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [23] <author> John Pollock. Oscar: </author> <title> a general theory of rationality. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 1(3) </volume> <pages> 209-226, </pages> <year> 1989. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms. <p> Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR <ref> [21, 24, 22, 23] </ref> as well as active (step) logics [4, 3, 5, 16, 9] are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [24] <author> John Pollock. </author> <title> How to reason defeasibly. </title> <journal> Artificial Intelligence, </journal> <volume> 57(1) </volume> <pages> 1-42, </pages> <year> 1992. </year>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms. <p> Thus self-adjusting logics of confusion seem to be the order of the day. What form such logics may eventually take is far from clear. I note that OSCAR <ref> [21, 24, 22, 23] </ref> as well as active (step) logics [4, 3, 5, 16, 9] are beginnings. It is clear that human commonsense reasoning involves many conflict-driven changes of belief, and that this is in need of being better understood for both cognitive and robotic purposes.
Reference: [25] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):81-132, </volume> <year> 1980. </year>
Reference-contexts: We may now be in need of yet another revolution. 3 or robot) commonsense reasoning. By 1980 at least three distinct formalisms for NMR had been developed <ref> [12, 25, 14] </ref>, and the standard model began to emerge. To present this model, we first restate the examples in chronological terms: at first we know Tweety is a bird and so conclude Tweety can fly; later we learn Tweety is an ostrich, and so then retract our earlier conclusion.
Reference: [26] <author> N. Roos. </author> <title> A logic for reasoning with inconsistent knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 69-103, </pages> <year> 1992. </year>
Reference-contexts: Some, such as the paraconsistent logics surveyed in [1], aim to extract a trustworthy core of inferences while avoiding the contradictions. Others, such as <ref> [5, 15, 26] </ref>, aim to detect and resolve contradictions. The latter are closer in spirit to the needs we are addressing here.
Reference: [27] <author> P. Rosenbloom, J. Laird, A. Newell, and R. McCarl. </author> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 289-325, </pages> <year> 1991. </year> <month> 12 </month>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms.
Reference: [28] <author> S. Vere and T. Bickmore. </author> <title> A basic agent. </title> <journal> Computational Intelligence, </journal> <volume> 6(1) </volume> <pages> 41-60, </pages> <year> 1990. </year> <month> 13 </month>
Reference-contexts: But the clear conclusion is that traditional monotonic logic is not the proper vehicle for much of (human 2 This may account for the fact that those building commonsense reasoning systems (e.g., <ref> [21, 24, 22, 23, 10, 27, 28, 7] </ref>) have availed themselves of only modest borrowings from traditional NMR formalisms. 3 Thus this is not at all an anti-logicist essay, but rather a call for yet further improved formalisms.
References-found: 28

