URL: http://www.dcs.ex.ac.uk/research/neural/pub/paper15.ps
Refering-URL: http://www.dcs.ex.ac.uk/research/neural/pub/pub.htm
Root-URL: http://www.dcs.ex.ac.uk
Title: An Experimental Evaluation of Methodological Diversity in Multiversion Software Reliability  
Author: Derek Partridge Niall Griffith Dan Tallis and Phillis Jones 
Date: June 30, 1997  
Address: Exeter EX4 4PT, UK  
Affiliation: Department of Computer Science University of Exeter  
Abstract: N-version programming has long been mooted as a method of improving software reliability. Earlier studies, which generated apparently discouraging results, offered pessimistic prognostications for this general strategy. However, further study of the problem has both refined the evaluation procedure and revealed new opportunities for improvement. In particular, exploitation of methodological diversity has proved to be productive. In this paper, we continue such studies by introducing a methodological extreme, an inductive computing technology, neural computing, to extend an earlier study of Modula2 and Prolog versions of the Launch Interceptor problem. In addition, we examine several diversity measures which are presented as more reliable indicators of potential reliability enhancement than the earlier measures of independence of failure and, subsequently, of probability of two-version joint failure. We also examine several strategies for diversity exploitation in multiversion systems. With the caveat that neural computing technology is far from well-understood, the conclusion is that it does offer a methodologically diverse approach, but perhaps no more so than the diversity potential of imperative versus declarative languages. But as an inductive computing technology, within which versions are both cheap to produce and specification independent, neural computing opens several new possibilities for enhancing N-version system reliability. Finally, we conclude that the apparent mismatch between pessimistic predictions and optimistic results in previous multiversion studies is founded on a failure to properly appreciate both the full complexity of the general strategy and the full scope of the options available.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. M. Adams and A. Taha, </author> <title> "An experiment in software redundancy with diverse methodologies," </title> <booktitle> Proc. 25th Hawaii Internat. Conf. on System Sciences, </booktitle> <pages> pp. 83-90, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The primary aim of this paper is to present the results of an experiment with multiversion programming. The experiment reported significantly extends a previous study of "method ological diversity" <ref> [1] </ref> and provides a further empirical exploration of the conceptual model of Littlewood and Miller [13]. <p> By "diversity of version behavior" they mean "low probability of simultaneous version failure" (p. 1609) which they propose might be forced by the use of diverse methodologies. The experiment that we extend in this paper is one performed by Adams and Taha <ref> [1] </ref> specifically to explore Littlewood and Miller's conceptual model. The Littlewood and Miller diversity indicator, the probability of simultaneous version failure, is E ( 2 ) which is the probability that two versions, selected at random (from the set of N ), will both fail on a random input. <p> The particular problem studied was the Launch Interceptor problem. 3.1 The Launch Interceptor problem The Launch Interceptor (LI) problem has been used for a variety of software engineering experiments (e.g. [14,6]) and more importantly in multiversion experiments <ref> [11, 5, 1] </ref>. It was chosen in the past "in order to make the experiment realistic" as "an application that would normally be a candidate for the inclusion of fault tolerance". <p> Firstly, we note that despite concerted efforts to eliminate ambiguity and imprecision, each new experimentor finds new problems with the specification. [11] rewrote "the requirements specification [that] had been carefully `debugged' prior to use in this experiment" (p. 98). Subsequently, <ref> [1] </ref> were forced to neglect 122 of their test cases because "there is some ambiguity about the input data in the requirement specifications of the program" (p. 86). <p> We believe it is a more fundamental problem enmeshed in the (confused) nature of specification [17]. This general problem further undermines the comparability of results from one experiment to another. 3.2 Description of the previous experiment Two sets of versions of the Launch Interceptor program were previously developed <ref> [1] </ref>. One set of six versions were all implemented in the imperative language Modula2 by six students in a junior-level software engineering class at New Mexico State University. <p> decision strategies (except under majority voting, which is inconclusive). 6 Conclusion The primary goal of this study has been reached: we have assessed neural computing as a methodological novelty in the context of a multiversion software system, as first explored conceptually by [13] and put to a practical test by <ref> [1] </ref>. However, two important caveats must be stated explicitly: 1. The nature of the LI problem seriously confounds results on the problem as a whole. We first consider such results because they are the only route to comparability with a number of earlier studies.
Reference: 2. <author> C. M. Bishop, </author> <title> "Neural Networks for Pattern Recognition," </title> <publisher> Oxford University Press: Oxford, </publisher> <year> 1995. </year>
Reference-contexts: We can, for example, average across the individual versions, which leads to a notion of `random scatter' diversity (e.g. see analysis of averaging across "committees" of neural networks in <ref> [2] </ref>). Estimation of the potential reliability of an N-version system is a complex process that, as yet, we do not fully understand. Previous pessimistic estimates have relied on limited (and sometimes inaccurate [18]) estimators and have failed to consider the full scope of possibilities.
Reference: 3. <author> P. G. Bishop, D. G. Esp, M. Barnes, P. Humphreys, G. Dahll and J. Lahti, </author> <title> "PODS | a project on diverse software," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-12, no. 9, </volume> <pages> pp. 929-940, </pages> <month> Sept. </month> <year> 1986. </year>
Reference: 4. <author> S. S. Brilliant, J. C. Knight and N. G. Leveson, </author> <title> "The consistent comparison problem in N-version software," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 15, no. 11, </volume> <pages> pp. 1481-1485, </pages> <month> Nov. </month> <year> 1989. </year>
Reference: 5. <author> S. S. Brilliant, J. C. Knight and N. G. Leveson, </author> <title> "Analysis of faults in an N-version software experiment," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 238-247, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Initial studies aimed to properly define the notion of `independence' [7,8] and to empirically determine if independence of failure actually occurred [11]. Some empirical studies found a lack of independence of failure, and good reasons for it, which led to pessimistic prognostications for the future of N-version programming <ref> [5] </ref>. As part of a comprehensive conceptual model of coincident failures in multiversion programming [13] questioned the pivotal significance of independent failure behavior, and proposed that the important idea is `diversity'. <p> The particular problem studied was the Launch Interceptor problem. 3.1 The Launch Interceptor problem The Launch Interceptor (LI) problem has been used for a variety of software engineering experiments (e.g. [14,6]) and more importantly in multiversion experiments <ref> [11, 5, 1] </ref>. It was chosen in the past "in order to make the experiment realistic" as "an application that would normally be a candidate for the inclusion of fault tolerance".
Reference: 6. <author> J. R. Dunham, </author> <title> "Experiments in software reliability: </title> <journal> life-critical applications," IEEE Trans. Software Eng., </journal> <volume> vol. SE-12, no. 1, </volume> <pages> pp. 110-123, </pages> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: Subsequently, [1] were forced to neglect 122 of their test cases because "there is some ambiguity about the input data in the requirement specifications of the program" <ref> (p. 86) </ref>. Essentially, the ambiguity is whether the "specified range" of input data items "is completely determined by the declarations given in the specification, or if additional restrictions contained in the specification of the fifteen LICs should be considered"(p. 86). We also uncovered problems.
Reference: 7. <author> D. E. Eckhardt and L. D. Lee, </author> <title> "A theoretical basis for the analysis of redundant software subject to coincident errors," </title> <type> NASA Tech. Memo 86369, </type> <month> Jan. </month> <year> 1985. </year>
Reference: 8. <author> D. E. Eckhardt and L. D. Lee, </author> <title> "A theoretical basis for the analysis of multiversion software subject to coincident errors," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-11, no. 12, </volume> <pages> pp. 1511-1517, </pages> <month> Dec. </month> <year> 1985. </year>
Reference: 9. <author> N. Griffith and D. Partridge, </author> <title> "Self-organizing experts," </title> <journal> Res. Rep. </journal> <volume> no. </volume> <pages> 349, </pages> <institution> Dept. Computer Science, University of Exeter, sec@dcs.exeter.ac.uk, </institution> <year> 1996. </year>
Reference: 10. <author> J. P. J. Kelly and S. C. Murphy, </author> <title> "Achieving dependability throughout the development process: a distributed software experiment," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 153-165, </pages> <month> Feb. </month> <year> 1990. </year>
Reference: 11. <author> J. C. Knight and N. G. Leveson, </author> <title> "An experimental evaluation of the assumption of independence in multiversion programming," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-12, no. 1, </volume> <pages> pp. 96-109, </pages> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: Initial studies aimed to properly define the notion of `independence' [7,8] and to empirically determine if independence of failure actually occurred <ref> [11] </ref>. Some empirical studies found a lack of independence of failure, and good reasons for it, which led to pessimistic prognostications for the future of N-version programming [5]. <p> The particular problem studied was the Launch Interceptor problem. 3.1 The Launch Interceptor problem The Launch Interceptor (LI) problem has been used for a variety of software engineering experiments (e.g. [14,6]) and more importantly in multiversion experiments <ref> [11, 5, 1] </ref>. It was chosen in the past "in order to make the experiment realistic" as "an application that would normally be a candidate for the inclusion of fault tolerance". <p> originally from an aerospace company" (<ref> [11] </ref>, p. 98). 3 The problem is to examine a series of radar reflections and determine if they indicate a hostile missile that should be intercepted, or not | a simple Launch or No-Launch signal is the final result. The full specification is given in [11], pages 103 to 109. The input to the computation is specified as a list of 2 to 100 x-y coordinate data points, and 19 real-valued parameters. <p> Then if, and only if, all fifteen values in the FUV are true is the output Launch, otherwise it is No-Launch. Firstly, we note that despite concerted efforts to eliminate ambiguity and imprecision, each new experimentor finds new problems with the specification. <ref> [11] </ref> rewrote "the requirements specification [that] had been carefully `debugged' prior to use in this experiment" (p. 98). Subsequently, [1] were forced to neglect 122 of their test cases because "there is some ambiguity about the input data in the requirement specifications of the program" (p. 86). <p> returns false on all the specific applications that should return true! This feature of the LI problem significantly confounds the data analysis; we return to it when we consider the detailed results. 4 One important manifestation of ambiguity in these experiments concerns the idea of ran-dom data, and random testing. <ref> [11] </ref> used "one million randomly generated test cases"(p. 98). We, as did Adams and Taha, tried to obtain information about the nature of the randomness employed by Knight and Leveson, but were similarly unsuccessful. <p> The versions in both sets passed an acceptance test which consisted of 200 randomly generated test cases. As in the Knight and Leveson experiment <ref> [11] </ref>, each version was executed on a different set of acceptance test cases to prevent a "general filtering of common faults"(p. 98).
Reference: 12. <author> T. Kohonen, </author> <title> "The self-organizing map," </title> <publisher> Springer: </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference: 13. <author> B. Littlewood and D. R. Miller, </author> <title> "Conceptual modeling of coincident failures in multi-version software," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 15, no. 12, </volume> <pages> pp. 1596-1614, </pages> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: 1 Introduction The primary aim of this paper is to present the results of an experiment with multiversion programming. The experiment reported significantly extends a previous study of "method ological diversity" [1] and provides a further empirical exploration of the conceptual model of Littlewood and Miller <ref> [13] </ref>. <p> Some empirical studies found a lack of independence of failure, and good reasons for it, which led to pessimistic prognostications for the future of N-version programming [5]. As part of a comprehensive conceptual model of coincident failures in multiversion programming <ref> [13] </ref> questioned the pivotal significance of independent failure behavior, and proposed that the important idea is `diversity'. By "diversity of version behavior" they mean "low probability of simultaneous version failure" (p. 1609) which they propose might be forced by the use of diverse methodologies. <p> The probability estimate p (1) = E () = P N n the probability that two versions selected at random without replacement will both fail on a random input, is estimated as N X n (n 1) p n In order to follow the theoretical analysis of Littlewood and Miller <ref> [13] </ref>, a variety of systems and associated reliabilities have been tabulated. Two architectural options are compared: `diverse' and `homogeneous'. In a diverse system (prefixed "Div"), the versions are divided into disjoint subsets, and selection is random within a subset. <p> are preferable, over their diverse counterparts, under all decision strategies (except under majority voting, which is inconclusive). 6 Conclusion The primary goal of this study has been reached: we have assessed neural computing as a methodological novelty in the context of a multiversion software system, as first explored conceptually by <ref> [13] </ref> and put to a practical test by [1]. However, two important caveats must be stated explicitly: 1. The nature of the LI problem seriously confounds results on the problem as a whole. <p> We found this surprising, although an example of a three-methodology system approximating independence of failure was found. In terms of general observations, we note, firstly, that system reliability is crucially dependent on the organization of the N-versions and on the decision strategy applied (as <ref> [13] </ref> first revealed). An important part of the software engineering task must be to make these two choices in such a way that the available versions deliver an optimal performance within whatever constraints a particular problem contains. Littlewood and Miller [13] discuss some of these choices within their conceptual model but <p> of the N-versions and on the decision strategy applied (as <ref> [13] </ref> first revealed). An important part of the software engineering task must be to make these two choices in such a way that the available versions deliver an optimal performance within whatever constraints a particular problem contains. Littlewood and Miller [13] discuss some of these choices within their conceptual model but no previous empirical study appears to have explored these issues. <p> Estimation of the potential reliability of an N-version system is a complex process that, as yet, we do not fully understand. Previous pessimistic estimates have relied on limited (and sometimes inaccurate [18]) estimators and have failed to consider the full scope of possibilities. Littlewood and Miller <ref> [13] </ref> showed the potential benefits of forced diversity | a situation achieved by pursuing diversity of process to yield diversity of product.
Reference: 14. <author> P. M. Nagel and J. A. Skrivan, </author> <title> "Software reliability: repetitive run experimentation and modeling," </title> <type> NASA Contractor Rep. </type> <institution> CR-165836, </institution> <month> Feb. </month> <year> 1982. </year> <month> 22 </month>
Reference: 15. <author> D. Partridge, </author> <title> "On the difficulty of really considering a radical novelty," </title> <journal> Minds and Machines, </journal> <volume> vol. 5, </volume> <pages> pp. 391-410, </pages> <year> 1995. </year>
Reference-contexts: values produced by that version and those produced by the gold program, or if the version caused an exception during execution on the test case. 3.3 Neural computing and the LI problem Neural networks (of the type that we employ) compute in an entirely different way from conventional programs (see <ref> [15] </ref> for a full discussion of this claim). It is of particular relevance that they are statistical approximators, not conventional symbol-manipulation devices that compute to a well-understood explicit numerical precision. After the initial training phase, they are, however, deterministic implementations of functions.
Reference: 16. <author> D. Partridge, </author> <title> "The case for inductive programming," </title> <booktitle> IEEE Computer, </booktitle> <month> January, </month> <pages> pp. 36-41, </pages> <year> 1997. </year>
Reference-contexts: A subsidiary goal of this paper is to provide further evidence of this contention. Another subsidiary goal is to demonstrate the potential of inductive computing technology (in this case neural computing) in practical software engineering. This novel computational paradigm is virtually unexplored by the software engineering community <ref> [16] </ref> and will reward proper study.
Reference: 17. <author> D. Partridge and A. Galton, </author> <title> "The specification of `specification'," </title> <journal> Minds and Machines, </journal> <volume> vol. 5, no. 2, </volume> <pages> pp. 243-255, </pages> <year> 1995. </year>
Reference-contexts: This is generally known as the "consistent comparison problem"[4] and is attributed to a lack of specificity in the specification. We believe it is a more fundamental problem enmeshed in the (confused) nature of specification <ref> [17] </ref>. This general problem further undermines the comparability of results from one experiment to another. 3.2 Description of the previous experiment Two sets of versions of the Launch Interceptor program were previously developed [1].
Reference: 18. <author> D. Partridge and W. J. Krzanowski, </author> <title> "Distinct failure diversity in multiversion software," Res. </title> <type> Rep. 348, </type> <institution> Dept. Computer Science, University of Exeter, sec@dcs.exeter.ac.uk. </institution>
Reference-contexts: But because of the novel computing technology used (neural computing), and because of the new measures and extensions to the basic model now available <ref> [19, 18] </ref>, a number of other issues are examined and presented. fl corresponding author, address as above and derek@dcs.exeter.ac.uk; tel: 01392 264069; fax: 01392 264067 y current address: Department of Computer Science, University of Limerick, Ireland 1 One long-studied approach to software reliability through fault tolerance is multiversion, or N-version, programming. <p> This method depends for its reliability enhancement (i.e. that the N versions together with a suitable decision strategy are more reliable than any of the component versions individually) on a property called `diversity' which, contrary to earlier assumptions, is now known to be a non-simple property <ref> [18] </ref>. A subsidiary goal of this paper is to provide further evidence of this contention. Another subsidiary goal is to demonstrate the potential of inductive computing technology (in this case neural computing) in practical software engineering. <p> The Littlewood and Miller model, although comprehensive, was constructed as a theoretical exercise. It assumes, for example, infinite sets of versions and of inputs. In any real N-version system, neither will be infinite and the number of versions is likely to be very small. A subsequent model <ref> [18] </ref> has made adjustments to the Littlewood and Miller model to make it more applicable to practical experimental data. <p> Secondly, and closely related to the first point, software diversity | if taken to mean that property which makes N versions more reliable as a whole than individually | is itself not a single, simple property <ref> [18] </ref>. This is partly because different decision strategies exploit different properties of the version set. It is also partly because it is not simply independence of failure nor lack of coincidence of failure as had been assumed. <p> Estimation of the potential reliability of an N-version system is a complex process that, as yet, we do not fully understand. Previous pessimistic estimates have relied on limited (and sometimes inaccurate <ref> [18] </ref>) estimators and have failed to consider the full scope of possibilities. Littlewood and Miller [13] showed the potential benefits of forced diversity | a situation achieved by pursuing diversity of process to yield diversity of product. <p> But when most versions are to be evaluated then the `freedom' offered by the homogeneous systems favours them over the diverse (Table 11). In an earlier study <ref> [18] </ref> we proved and demonstrated the potential value of distinct-failure diversity as a source of potential reliability enhancement orthogonal to the usual coincident-failure diversity. In this paper, the experiment performed provides further empirical evidence for the practical scope for N-version system reliability enhancement that distinct-failure diversity may offer.
Reference: 19. <author> D. Partridge and W. J. Krzanowski, </author> <title> "Software diversity: practical statistics for its measurement and exploitation," Res. </title> <type> Rep. 324, </type> <institution> Dept. Computer Science, University of Exeter, (accepted for Information and Software Technology). </institution>
Reference-contexts: But because of the novel computing technology used (neural computing), and because of the new measures and extensions to the basic model now available <ref> [19, 18] </ref>, a number of other issues are examined and presented. fl corresponding author, address as above and derek@dcs.exeter.ac.uk; tel: 01392 264069; fax: 01392 264067 y current address: Department of Computer Science, University of Limerick, Ireland 1 One long-studied approach to software reliability through fault tolerance is multiversion, or N-version, programming. <p> Adams and Taha did not compute t n values for they are part of our <ref> [19] </ref> extension to the Littlewood and Miller model. They are used to compute a measure of distinct-failure diversity, DFD. For the same test set applied to the four Prolog versions we have the simple test results (Table 3) and the coincident and identical failure results (Table 4). <p> In a homogeneous system (prefixed "Hom"), there are no subdivisions and selection is unconstrained within the total version set. The CF D diversity measure, which is defined on a homogeneous set, is extended (see <ref> [19] </ref> for details) to a CF B measure of coincident-failure diversity between sets of versions. <p> Notice that of the four diverse-three-methodology systems, the highest performance is indicated by the lowest average (of the three pairwise values) of Littlewood and Miller's error correlation coefficient, . This system (DivProModExp) does not exhibit the highest between-set diversity, CF B <ref> [19] </ref>, but the system with the slightly higher CF B value (DivProModMvs) also exhibits the greatest performance increase over the average of its component versions. It is disadvantaged by starting from a lower average level of performance, 85.72%, rather than the 89.42% in the overall better system.
Reference: 20. <author> D. Partridge and W. B. Yates, </author> <title> "Engineering multiversion neural-net systems," </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 4, </volume> <pages> pp. 869-893, </pages> <year> 1996. </year>
Reference-contexts: In order to combat the approximating nature of the technology and the general difficulty of ensuring that an inductive process converges on the desired target function, we used a multiversion approach to implement each neural-net LIC. We explored a variety of strategies for engineering multiversion neural-net systems <ref> [20] </ref>. For the purposes of this experiment we will test two, rather different types of systems, in the neural-net implementations of the 14 LICs. <p> In particular, we might prefer a 2-out-of-3 decision strategy in which the 3 are each selected from a methodologically different set as opposed to total selection indifference across all three sets, as Table 11 illustrates. We have empirically explored some of these choice options <ref> [20] </ref> and shown that the optimal choice is dependent upon both the specific decision strategy used and the diversity, both within and between sets, exhibited by the versions available.
Reference: 21. <author> D. Partridge and W. B. Yates, </author> <title> "Data-defined problems and multiversion neural-net systems," </title> <journal> Journal of Intelligent Systems, </journal> <volume> vol. 7, </volume> <pages> nos. 1-2, pp. 19-32, </pages> <year> 1997. </year>
Reference-contexts: Within the fast-growing field of data mining, for example, the data does `define' the problem, and in such cases a data-driven inductive technique may be required (see <ref> [21] </ref> for an example). As the conclusion to their comprehensive conceptual model of the multiversion programming paradigm, Littlewood and Miller state that despite their work on the identification and elucidation of many important issues "the picture is not yet totally clear" ([13], p. 1609).
Reference: 22. <author> D. E. Rumelhart and J. L. McClelland, </author> <title> "Parallel distributed processing: explorations in the microstructure of cognition," 2 vols., </title> <publisher> MIT Press: </publisher> <address> Cambridge, Mass., </address> <year> 1986. </year>
Reference-contexts: Because of the way the LI problem is specified (discussed earlier) these two levels of testing give significantly different results. 3.6 Multiversion versions Because the neural-net implementations are automatically generated (using the backpropagation algorithm with multilayer perceptron nets <ref> [22] </ref>), a neural net version can be generated relatively cheaply. In order to combat the approximating nature of the technology and the general difficulty of ensuring that an inductive process converges on the desired target function, we used a multiversion approach to implement each neural-net LIC.
Reference: 23. <author> W. B. Yates and D. Partridge, </author> <title> "Use of methodological diversity to improve neural network generalization," </title> <journal> Neural Computing & Applications, </journal> <volume> vol. 4, no. 2, </volume> <pages> pp. 114-128, </pages> <year> 1996. </year>
References-found: 23

