URL: http://www.cs.rice.edu/CS/PLT/Publications/lfp92-sf.ps.gz
Refering-URL: http://www.cs.rice.edu/CS/PLT/Publications/
Root-URL: 
Title: Reasoning about Programs in Continuation-Passing Style  
Author: Amr Sabry Matthias Felleisen 
Address: Houston, TX 77251-1892  
Affiliation: Department of Computer Science Rice University  
Abstract: Plotkin's -value calculus is sound but incomplete for reasoning about fi-transformations on programs in continuation-passing style (CPS). To find a complete extension, we define a new, compactifying CPS transformation and an "inverse" mapping, un-CPS, both of which are interesting in their own right. Using the new CPS transformation, we can determine the precise language of CPS terms closed under fi-transformations. Using the un-CPS transformation, we can derive a set of axioms such that every equation between source programs is provable if and only if fi can prove the corresponding equation between CPS programs. The extended calculus is equivalent to an untyped variant of Moggi's computational -calculus. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Appel, A. and T. Jim. </author> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Proc. 16th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1982, </year> <pages> 293-302. </pages>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages <ref> [1, 13, 19, 20] </ref> utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation [10, 18]. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. <p> For example, Plotkin [17] finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. Hence, "practical" CPS transformations <ref> [1, 5, 13, 19, 20] </ref> use special algorithms to minimize the size of their outputs.
Reference: 2. <author> Barendregt, </author> <title> H.P. The Lambda Calculus: Its Syntax and Semantics. Revised Edition. </title> <booktitle> Studies in Logic and the Foundations of Mathematics 103. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1984. </year> <month> 10 </month>
Reference-contexts: Due to space limitations, we only indicate the ideas behind major proof steps. For details, we refer the reader to our extended technical report (Rice TR 92-180 ). 2 fl: Calculi & Semantics The language of the pure lambda calculus, fl <ref> [2] </ref>, consists of variables, -abstractions, and applications. <p> Lemma 3.7 Let P and Q be in fi-normal form. If fi ` F [[M ]] !! P and fi ` F [[M ]] !! Q, then P Q. Proof. The proof is a consequence of the Church-Rosser theorem for fi <ref> [2] </ref>. The output of F2 k is extremely compact. <p> Next, we turn to the definition of our universe of discourse, the set of CPS terms. It must include all terms that contribute to the proofs of equations of the form: fi ` C k [[M ]] = C k [[N ]]: Since fi is CR <ref> [2] </ref>, it is sufficient to consider equations of the form: fi ` C k [[M ]] !! P: Hence, the interesting set of CPS terms is: S fP j 9M 2 fl:fi ` C k [[M ]] !! P g: The definition of the transformation C k provides some insight about
Reference: 3. <author> Danvy, O. </author> <title> Back to direct style. </title> <booktitle> In 4th Proc. Euro--pean Symposium on Programming. Springer Lecture Notes in Computer Science, </booktitle> <volume> 582. </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1992, </year> <pages> 130-150. </pages>
Reference-contexts: The new transformation also produces the smallest possible output of all known CPS transformations, without reducing any of the original (source) redexes. 2. Second, we develop an un-CPS transformation that maps canonical CPS programs and their derivations back to the original language. As Danvy and Lawall <ref> [3, 6] </ref> convincingly argue, this translation from CPS to direct terms is useful in its own right. 3. Finally, by studying the connection between the CPS and un-CPS transformations, we systematically derive A. The extended -value calculus is equivalent to an untyped variant of Moggi's [16] computational -calculus. <p> Values consist of variables, drawn from the set Vars, and - abstractions. We adopt Barendregt's <ref> [2: ch 2, 3] </ref> notation and terminology for this syntax. Thus, in the abstraction (x:M ), the variable x is bound in M . Variables that are not bound by a -abstraction are free; the set of free variables in a term M is F V (M ). <p> The definition of the function C k shows that, in two cases, different inputs are indeed mapped to the same output. 3 Danvy and Lawall <ref> [3, 6] </ref> define a direct style transformation that maps CPS terms into source terms. To get an inverse of the Danvy/Filinski CPS [5], they have to restrict the domain of their direct style transformation to images of fl terms.
Reference: 4. <author> Danvy, O. </author> <title> Three steps for the CPS transformation. </title> <type> Tech. Rep. </type> <institution> CIS-92-2. Kansas State University, </institution> <year> 1992. </year>
Reference-contexts: According to folklore in the functional compiler-building community <ref> [4] </ref>, the first aspect of a CPS transformation is to give the value of every application a name.
Reference: 5. <author> Danvy, O. and A. Filinski. </author> <title> Representing control: A study of the CPS transformation. </title> <type> Tech. </type> <institution> Rpt. CIS-91-2. Kansas State University, </institution> <year> 1991. </year>
Reference-contexts: For example, Plotkin [17] finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. Hence, "practical" CPS transformations <ref> [1, 5, 13, 19, 20] </ref> use special algorithms to minimize the size of their outputs. <p> Definition 3.3. (Modified Fischer CPS ) Let k; m; n 2 Vars be as in Definition 3.1. F [[V ]] = k:k [[V ]] [[x]] = x 1 See also Danvy and Filinski's development of these ideas <ref> [5] </ref>. An overline decorates -abstractions that were not present in the original term. <p> The output of F2 k is extremely compact. For example, applying F 2 k to (((x:y:x) a) b) yields the term: M ((x:((y:kx) b)) a) For the same example, both Steele's Rabbit transfor mation [20] and the Danvy/Filinski transformation <ref> [5] </ref> 4 yield the term: 2 N ((k 1 x:(k 1 k 2 y:k 2 x)) (m:mkb) a): In the term N , every procedure accepts its continuation at the same time it accepts its argument. Therefore, the management of all continuations in the term N must occur at run-time. <p> The definition of the function C k shows that, in two cases, different inputs are indeed mapped to the same output. 3 Danvy and Lawall [3, 6] define a direct style transformation that maps CPS terms into source terms. To get an inverse of the Danvy/Filinski CPS <ref> [5] </ref>, they have to restrict the domain of their direct style transformation to images of fl terms.
Reference: 6. <author> Danvy, O. and J. Lawall. </author> <title> Back to direct style II: First-class continuations. </title> <booktitle> In Proc. 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1992, </year> <note> this volume. </note>
Reference-contexts: The new transformation also produces the smallest possible output of all known CPS transformations, without reducing any of the original (source) redexes. 2. Second, we develop an un-CPS transformation that maps canonical CPS programs and their derivations back to the original language. As Danvy and Lawall <ref> [3, 6] </ref> convincingly argue, this translation from CPS to direct terms is useful in its own right. 3. Finally, by studying the connection between the CPS and un-CPS transformations, we systematically derive A. The extended -value calculus is equivalent to an untyped variant of Moggi's [16] computational -calculus. <p> The definition of the function C k shows that, in two cases, different inputs are indeed mapped to the same output. 3 Danvy and Lawall <ref> [3, 6] </ref> define a direct style transformation that maps CPS terms into source terms. To get an inverse of the Danvy/Filinski CPS [5], they have to restrict the domain of their direct style transformation to images of fl terms.
Reference: 7. <author> Felleisen, M. and D.P. Friedman. </author> <title> Control operators, the SECD-machine, and the -calculus. In Formal Description of Programming Concepts III , edited by M. Wirsing. </title> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1986, </year> <pages> 193-217. </pages>
Reference-contexts: Typically, Eval is defined via an abstract machine that manipulates abstract counterparts to machine stacks, stores, registers, etc. Examples are the SECD machine [14] and the CEK machine <ref> [7] </ref>. An equivalent method for specifying the semantics is based on the Curry-Feys Standard Reduction theorem [7, 17]. The Standard Reduction theorem defines a partial function, 7!, from programs to programs that corresponds to a single evaluation step of an abstract machine for fl. <p> Typically, Eval is defined via an abstract machine that manipulates abstract counterparts to machine stacks, stores, registers, etc. Examples are the SECD machine [14] and the CEK machine [7]. An equivalent method for specifying the semantics is based on the Curry-Feys Standard Reduction theorem <ref> [7, 17] </ref>. The Standard Reduction theorem defines a partial function, 7!, from programs to programs that corresponds to a single evaluation step of an abstract machine for fl. <p> The special contexts, E, are evaluation contexts and have the following definition for the call-by-value and call-by-name variants of fl, respectively <ref> [7] </ref>: E v ::= [ ] j E v [(V [ ])] j E v [([ ] M )] Conceptually, the hole of an evaluation context, [ ], points to the current instruction, which must be a fi v or fi redex. <p> The decomposition of M into E [(V N )] where (V N ) is a redex means that the current instruction is (V N ) and that the rest of the computation (the continuation! <ref> [7] </ref>) is E. Since, a call-by-name language never evaluates arguments, evaluation contexts do not include contexts of the shape E n [(V [ ])]. <p> For the source terms, this means that the body of an abstraction in application position absorbs the syntactic representation of the continuation, which is the evaluation context <ref> [7] </ref>. Thus, a program of the shape E [((x:M ) V )] where E represents K, must be translated as if it had been written as ((x:E [M ]) V ). Put differently, our CPS transformation "symbolically" evaluates redexes by lifting them to the root of the program.
Reference: 8. <author> Felleisen, M. and R. Hieb. </author> <title> The revised report on the syntactic theories of sequential control and state. </title> <type> Technical Report 100, </type> <institution> Rice University, </institution> <month> June </month> <year> 1989. </year> <institution> Theor. Comput. Sci., </institution> <year> 1991, </year> <note> to appear. </note>
Reference-contexts: However, the correspondence theorem fails since operators like call/cc manipulate their continuation in non-standard ways. To re-establish the correspondence theorem for such languages, we need to find an extension for the -control calculus <ref> [8, 9] </ref> that corresponds to fi on CPS terms.
Reference: 9. <author> Felleisen, M., D. Friedman, E. Kohlbecker, and B. Duba. </author> <title> A syntactic theory of sequential control. </title> <journal> Theor. Comput. Sci. </journal> <volume> 52(3), </volume> <year> 1987, </year> <pages> 205-237. </pages> <note> Preliminary version in: Proc. Symposium on Logic in Computer Science, </note> <year> 1986, </year> <pages> 131-141. </pages>
Reference-contexts: However, the correspondence theorem fails since operators like call/cc manipulate their continuation in non-standard ways. To re-establish the correspondence theorem for such languages, we need to find an extension for the -control calculus <ref> [8, 9] </ref> that corresponds to fi on CPS terms.
Reference: 10. <author> Fischer, M.J. </author> <title> Lambda calculus schemata. </title> <booktitle> In Proc. ACM Conference on Proving Assertions About Programs, SIGPLAN Notices 7(1), </booktitle> <year> 1972, </year> <pages> 104-109. </pages>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages [1, 13, 19, 20] utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation <ref> [10, 18] </ref>. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. In the terminology of the -calculus, optimizations generally correspond to (sequences of) fi- and - reductions. <p> For a few years, the transformation remained part of the folklore of computer science until Fischer and Reynolds codified it in 1972. Fischer <ref> [10] </ref> studied two implementation strategies for fl: a heap-based retention strategy, in which all variable bindings are retained until no longer needed, and a stack-based deletion strategy, in which variable bind ings are destroyed when control leaves the procedure (or block) in which they were created.
Reference: 11. <author> Gateley, J. </author> <title> and B.F. Duba. Call-by-value com-binatory logic and the lambda-value calculus. </title> <booktitle> In Proc. 1991 Workshop on Mathematical Foundations of Programming Semantics. Lecture Notes in Computer Science 517, to appear. </booktitle>
Reference-contexts: extend the call-by-value -calculus such that: v A ` M = N iff fi ` cps (M ) = cps (N ): Such a correspondence theorem would be similar to the correspondence theorems for the -calculus and combinatory logic [2: ch 7], and the v -calculus and by-value combinatory logic <ref> [11] </ref>. In analogy to model theory, we call the left-to-right direction soundness and the right-to-left direction completeness since the CPS transformation is often taken as the definition of a call-by-value semantics. To derive A, we proceed in three steps: 1.
Reference: 12. <author> Hieb R., R. K. Dybvig, and C. Bruggeman. </author> <title> Representing control in the presence of first-class continuations. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1990, </year> <pages> 66-77. </pages>
Reference-contexts: If so, optimizations of CPS programs could be understood and reported in terms of the original program as opposed to its rather complicated CPS version. In particular, compilers that do not use the CPS transformation, e.g., Chez Scheme <ref> [12] </ref> or Zinc [15], could benefit by implementing fl Both authors were supported in part by NSF grant CCR 89-17022 and by a Texas ATP grant 92-003604014.
Reference: 13. <author> Kranz, D., et al. </author> <title> ORBIT: An optimizing compiler for Scheme. </title> <booktitle> In Proc. SIGPLAN 1986 Symposium on Compiler Construction, SIGPLAN Notices 21(7), </booktitle> <year> 1986, </year> <pages> 219-233. </pages>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages <ref> [1, 13, 19, 20] </ref> utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation [10, 18]. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. <p> For example, Plotkin [17] finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. Hence, "practical" CPS transformations <ref> [1, 5, 13, 19, 20] </ref> use special algorithms to minimize the size of their outputs.
Reference: 14. <author> Landin, P.J. </author> <title> The mechanical evaluation of expressions. </title> <journal> Comput. J. </journal> <volume> 6(4), </volume> <year> 1964, </year> <pages> 308-320. </pages>
Reference-contexts: A program is a term with no free variables and, in practical languages, an answer is a member of the syntactic category of values. Typically, Eval is defined via an abstract machine that manipulates abstract counterparts to machine stacks, stores, registers, etc. Examples are the SECD machine <ref> [14] </ref> and the CEK machine [7]. An equivalent method for specifying the semantics is based on the Curry-Feys Standard Reduction theorem [7, 17]. The Standard Reduction theorem defines a partial function, 7!, from programs to programs that corresponds to a single evaluation step of an abstract machine for fl.
Reference: 15. <author> Leroy, X. </author> <title> The Zinc experiement. </title> <type> Technical Report 117. </type> <institution> INRIA, </institution> <year> 1990. </year>
Reference-contexts: If so, optimizations of CPS programs could be understood and reported in terms of the original program as opposed to its rather complicated CPS version. In particular, compilers that do not use the CPS transformation, e.g., Chez Scheme [12] or Zinc <ref> [15] </ref>, could benefit by implementing fl Both authors were supported in part by NSF grant CCR 89-17022 and by a Texas ATP grant 92-003604014.
Reference: 16. <author> Moggi, E. </author> <title> Computational lambda-calculus and monads. </title> <booktitle> In Proc. Symposium on Logic in Computer Science, </booktitle> <year> 1989, </year> <pages> 14-23. </pages> <note> Also appeared as: </note> <institution> LFCS Report ECS-LFCS-88-66, University of Edinburgh, </institution> <year> 1988. </year>
Reference-contexts: As Danvy and Lawall [3, 6] convincingly argue, this translation from CPS to direct terms is useful in its own right. 3. Finally, by studying the connection between the CPS and un-CPS transformations, we systematically derive A. The extended -value calculus is equivalent to an untyped variant of Moggi's <ref> [16] </ref> computational -calculus. The next section introduces the basic terminology and notation of the -calculus and its semantics. The third section is a short history of CPS transformations. In 1 Section 4, we formalize the problem and outline our approach to the solution. <p> Rather the result is valid for any CPS transformation cps that satisfies the following condition for M 2 fl: 7.4 The computational -calculus The calculus v A is equivalent to an untyped variant of Moggi's computational -calculus c <ref> [16] </ref>. Specifically, we ignore the types of expressions, eliminate product and computational expressions, re-interpret Moggi's let-expression as the usual abbreviation for a -application, and apply his let-axioms to the expanded expressions. <p> Therefore, the natural question is whether our extension is sound with respect to the call-by-value observational equivalence relation. Moggi <ref> [16] </ref> proves the result in a typed setting. It follows that our extension is sound for reasoning about typed CPS programs, for example in a language like (full) ML.
Reference: 17. <author> Plotkin, G.D. </author> <title> Call-by-name, call-by-value, and the -calculus. </title> <journal> Theor. Comput. Sci. </journal> <volume> 1, </volume> <year> 1975, </year> <pages> 125-159. </pages>
Reference-contexts: Technically speaking, we are addressing the following question: which calculus can prove M = N for by-value expressions M and N , if cps (M ) = cps (N ) is provable in the (by-value or by-name) -calculus? As Plotkin <ref> [17] </ref> showed in 1974, the v -calculus does not suffice. <p> Typically, Eval is defined via an abstract machine that manipulates abstract counterparts to machine stacks, stores, registers, etc. Examples are the SECD machine [14] and the CEK machine [7]. An equivalent method for specifying the semantics is based on the Curry-Feys Standard Reduction theorem <ref> [7, 17] </ref>. The Standard Reduction theorem defines a partial function, 7!, from programs to programs that corresponds to a single evaluation step of an abstract machine for fl. <p> He developed a constructive (but informal) method to transform an interpreter such that it becomes indifferent to whether the underlying parameter passing technique is call-by-value or call-by-name. His transformation is essentially the same transformation as Fischer's F . Plotkin <ref> [17] </ref> later proved Reynolds' ideas correct. Theorem 3.2 (Plotkin [17]) Let M 2 fl. 3 Simulation: [[Eval v (M )]] = Eval n (F [[M ]] (x:x)) Indifference: Eval n (F [[M ]] (x:x)) = Eval v (F [[M ]] (x:x)) The Simulation theorem shows that the evaluation of the CPS <p> He developed a constructive (but informal) method to transform an interpreter such that it becomes indifferent to whether the underlying parameter passing technique is call-by-value or call-by-name. His transformation is essentially the same transformation as Fischer's F . Plotkin <ref> [17] </ref> later proved Reynolds' ideas correct. Theorem 3.2 (Plotkin [17]) Let M 2 fl. 3 Simulation: [[Eval v (M )]] = Eval n (F [[M ]] (x:x)) Indifference: Eval n (F [[M ]] (x:x)) = Eval v (F [[M ]] (x:x)) The Simulation theorem shows that the evaluation of the CPS program produces correct outputs. <p> For example, F [[((x:x) (y y))]] = (m:((k:((k:ky) m:k:ky n:(m k) n)) Although the original term contains one -abstraction and no fi v -redexes, its CPS counterpart contains a large number of both. Plotkin <ref> [17] </ref> referred to the new redexes as administrative redexes because an evaluator must always reduce them before re-establishing fi v -redexes that were present in the source term. From both a theoretical and a practical perspective, the presence of the administrative redexes is undesirable. <p> From both a theoretical and a practical perspective, the presence of the administrative redexes is undesirable. On the theoretical side, they complicate reasoning about CPS programs. For example, Plotkin <ref> [17] </ref> finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. <p> Plotkin <ref> [17] </ref> was the first to offer some insights about the relation between reductions on source terms and CPS terms. In a comparative study of equational theories for call-by-value languages and call-by-name lan guages, he proved the following theorem. Theorem 4.1 (Plotkin [17]) Let M; N 2 fl. 1. v ` M <p> Plotkin <ref> [17] </ref> was the first to offer some insights about the relation between reductions on source terms and CPS terms. In a comparative study of equational theories for call-by-value languages and call-by-name lan guages, he proved the following theorem. Theorem 4.1 (Plotkin [17]) Let M; N 2 fl. 1. v ` M = N implies v ` F [[M ]] = F [[N ]]; 2. v ` F [[M ]] = F [[N ]] does not imply v ` M = N ; 3. v ` F [[M ]] = F [[N ]]
Reference: 18. <author> Reynolds, </author> <title> J.C. Definitional interpreters for higher-order programming languages. </title> <booktitle> In Proc. ACM Annual Conference, </booktitle> <year> 1972, </year> <pages> 717-740. </pages>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages [1, 13, 19, 20] utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation <ref> [10, 18] </ref>. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. In the terminology of the -calculus, optimizations generally correspond to (sequences of) fi- and - reductions. <p> F : fl ! fl F [[M N ]] = k:F [[M ]] (m:F [[N ]] n:(m k) n) [[x:M ]] = k:x:F [[M ]] k Reynolds <ref> [18] </ref> investigated definitional interpreters for higher-order languages. Among his goals was the desire to liberate the definition of a language from the parameter-passing technique of the defining language.
Reference: 19. <author> Shivers, O. </author> <title> Control-flow Analysis of Higher-Order Languages or Taming Lambda. </title> <type> Ph.D. dissertation, </type> <institution> Carnegie-Mellon University, </institution> <year> 1991. </year>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages <ref> [1, 13, 19, 20] </ref> utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation [10, 18]. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. <p> For example, Plotkin [17] finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. Hence, "practical" CPS transformations <ref> [1, 5, 13, 19, 20] </ref> use special algorithms to minimize the size of their outputs.
Reference: 20. <author> Steele, G.L., Jr. RABBIT: </author> <title> A compiler for SCHEME. </title> <type> Memo 474, </type> <institution> MIT AI Lab, </institution> <year> 1978. </year> <month> 11 </month>
Reference-contexts: 1 Compiling with CPS Many modern compilers for higher-order functional languages <ref> [1, 13, 19, 20] </ref> utilize some variant of the Fischer-Reynolds continuation-passing style (CPS) transformation [10, 18]. Once a program is in continuation-passing style, these compilers usually perform code optimizations via local transformations. Typical examples of such optimizations are loop unrolling, procedure inlin-ing, and partial evaluation. <p> For example, Plotkin [17] finds it necessary to define an improved CPS transformation exclusively for the proof of Theorem 3.2 above. On the practical side, code generation phases in compilers favor smaller, i.e., more manageable, programs. Hence, "practical" CPS transformations <ref> [1, 5, 13, 19, 20] </ref> use special algorithms to minimize the size of their outputs. <p> Proof. The proof is a consequence of the Church-Rosser theorem for fi [2]. The output of F2 k is extremely compact. For example, applying F 2 k to (((x:y:x) a) b) yields the term: M ((x:((y:kx) b)) a) For the same example, both Steele's Rabbit transfor mation <ref> [20] </ref> and the Danvy/Filinski transformation [5] 4 yield the term: 2 N ((k 1 x:(k 1 k 2 y:k 2 x)) (m:mkb) a): In the term N , every procedure accepts its continuation at the same time it accepts its argument.
References-found: 20

