URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/Cosco/NEULA:_A_hybrid_neural-symbolic_expert_system_shell.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~tirri/publications.html
Root-URL: 
Title: NEULA: A hybrid neural-symbolic expert system shell  
Author: Patrik Floreen, Petri Myllymaki, Pekka Orponen, Henry Tirri 
Address: Teollisuuskatu 23, 00510 Helsinki, Finland  
Affiliation: University of Helsinki, Department of Computer Science  
Date: 3 (November 1992) 11  
Note: Tietojenkasittelytiede  
Abstract: Current expert systems cannot properly handle imprecise and incomplete information. On the other hand, neural networks can perform pattern recognition operations even in noisy environments. Against this background, we have implemented a neural expert system shell NEULA, whose computational mechanism processes imprecisely or incompletely given information by means of approximate probabilistic reasoning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Aarts and J. Korst, </author> <title> Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing. </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1989. </year>
Reference-contexts: On the other hand, instead of simulating the neural network model in a conventional computer, the computation may be performed in a special parallel environment (neural net emulator or chip), which enables enormous speed-ups in performance. The second model, described in [17], uses the simulated annealing scheme (see e.g. <ref> [1] </ref>). The simulated annealing technique forces the network to eventually settle down to the "maximum entropy" state, which is the most proba ble state of the network consistent with the given input query.
Reference: [2] <author> J. Alspector, T. Zeppenfeld, S. Luna, </author> <title> A volatility measure for annealing in feedback neural networks. </title> <booktitle> Neural Computation 4 (1992), </booktitle> <pages> 191-195. </pages>
Reference-contexts: A parallel implementation of the NEULA simulator is currently under construction for the 100-transputer Hathi-2 system at Abo Akademi [3]. On the algorithmic front, we are also studying more sophisticated annealing techniques, such as self-adjusting annealing schedules <ref> [2] </ref> and the mean field annealing algorithm [23]. NEULA: A hybrid neural-symbolic expert system shell 17
Reference: [3] <author> M.Aspnas, R.J.R.Back, T.-E. Malen, </author> <title> The Hathi-2 Multiprocessor System. </title> <type> Report A-80-1989, </type> <institution> Departments of Computer Science and Mathematics, Abo Akademi. </institution>
Reference-contexts: A parallel implementation of the NEULA simulator is currently under construction for the 100-transputer Hathi-2 system at Abo Akademi <ref> [3] </ref>. On the algorithmic front, we are also studying more sophisticated annealing techniques, such as self-adjusting annealing schedules [2] and the mean field annealing algorithm [23]. NEULA: A hybrid neural-symbolic expert system shell 17
Reference: [4] <author> J. A. Barnden and J. B. Pollack (eds.), </author> <title> Advances in Connectionist and Neural Computation Theory, Vol. I: High Level Neural Models. </title> <publisher> Ablex Publ. Co., </publisher> <address> Norwood, NJ, </address> <year> 1991. </year>
Reference-contexts: We fl Email: Firstname.Lastname@Helsinki.FI have therefore investigated the interesting question of whether the robustness problem of traditional artificial intelligence applications can be attacked by neurally inspired techniques for knowledge representation. Inspired by the general idea of hybrid neural-symbolic systems (e.g. <ref> [4] </ref>), we have introduced in the NEULOG 1 project a knowledge representation scheme for robust storing of hierarchically related concepts. The scheme is based on a neural representation structure, which bears resemblance to a semantic network. <p> The neural network model behind the NEULA system is structurally simple and uniform. This is a clear advantage over many other hybrid knowledge representation schemes (see e.g. <ref> [4, 9, 24] </ref>), which require fairly complicated computing elements and control regimes. Consequently, the NEULA system would be much easier to implement in a real neural system.
Reference: [5] <author> G. F. Cooper, </author> <title> Probabilistic Inference Using Belief Networks is NP-hard. </title> <type> Report KSL-87-27. </type> <institution> Knowledge Systems Laboratory, Stanford University. </institution>
Reference-contexts: The Bayesian framework is an attractive theoretical model for reasoning with uncertainties, but so far it has had one major drawback: in general, it seems to be impossible to calculate the conditional probabilities exactly in reasonable time <ref> [5] </ref>, so in practice some kind of approximation is needed. The new sampling methods developed offer powerful tools for this kind of approximation. As neural nets allow parallelization of such models, they are a natural choice as the implementation platform.
Reference: [6] <author> P.Floreen, P.Myllymaki, P.Orponen, H.Tirri, </author> <title> Neural representation of concepts for robust inference. </title> <booktitle> Proceedings of the International Symposium Computational Intelligence II (Milano, </booktitle> <address> Italy, </address> <month> September </month> <year> 1989, </year> <editor> F. Gardin and G. Mauri, eds.), </editor> <address> 89-98. </address> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference-contexts: But we still need some kind of "goodness of fit" measure for the different states of the network, some kind of a mathematical model for the calculations. In earlier versions of the system <ref> [6, 7] </ref>, we used a heuristic computational scheme. This scheme was not satisfactory, however, as we wanted to have an exact interpretation of the truth values given to the user.
Reference: [7] <author> P.Floreen, P.Myllymaki, P.Orponen, H.Tirri, </author> <title> Compiling object declarations into connectionist networks. </title> <booktitle> AI Communications 3 (1990), </booktitle> <pages> 172-183. </pages>
Reference-contexts: But we still need some kind of "goodness of fit" measure for the different states of the network, some kind of a mathematical model for the calculations. In earlier versions of the system <ref> [6, 7] </ref>, we used a heuristic computational scheme. This scheme was not satisfactory, however, as we wanted to have an exact interpretation of the truth values given to the user.
Reference: [8] <author> S. Geman and D. Geman, </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 6 (1984), </journal> <pages> 721-741. </pages>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields <ref> [8, 13] </ref>, and their close relationships to Bayesian networks, as discussed in [12, 14, 15, 26]. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query. <p> According to Pearl [22] and Ge-man&Geman <ref> [8] </ref>, the estimates given by the network converge to the correct probability as the simulation continues. Consequently, the accuracy of the answer becomes better and better with increased running time.
Reference: [9] <author> G. E. Hinton (ed.), </author> <title> Special issue on connectionist symbol processing. </title> <booktitle> Artificial Intelligence 46 (1990): </booktitle> <pages> 1-2. </pages>
Reference-contexts: The neural network model behind the NEULA system is structurally simple and uniform. This is a clear advantage over many other hybrid knowledge representation schemes (see e.g. <ref> [4, 9, 24] </ref>), which require fairly complicated computing elements and control regimes. Consequently, the NEULA system would be much easier to implement in a real neural system.
Reference: [10] <author> G. E. Hinton and T. J. Sejnowski, </author> <title> Optimal perceptual inference. </title> <booktitle> Proc. of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Washington DC, </booktitle> <month> June </month> <year> 1983), </year> <pages> 448-453. </pages> <publisher> IEEE, </publisher> <address> New York, NY, </address> <year> 1983. </year>
Reference-contexts: A typical plot of the state 1 occurrence frequencies of the nodes during the "dolphin query" processing is shown in figure 2. The neural network model used in the second model is the harmony network [25], which is a kind of a generalization of the Boltzmann machine model <ref> [10, 11] </ref>. In this scheme, the user is given as output only either of the judgements "true" or "false" for each of the variables.
Reference: [11] <author> G. E. Hinton and T. J. Sejnowski, </author> <title> Learning and relearning in Boltzmann machines. Parallel Distributed Processing (D. </title> <editor> E. Rumelhart and J. L. McClelland, eds.). </editor> <volume> Vol. I, </volume> <pages> 282-317. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: A typical plot of the state 1 occurrence frequencies of the nodes during the "dolphin query" processing is shown in figure 2. The neural network model used in the second model is the harmony network [25], which is a kind of a generalization of the Boltzmann machine model <ref> [10, 11] </ref>. In this scheme, the user is given as output only either of the judgements "true" or "false" for each of the variables.
Reference: [12] <author> T.Hrycej, </author> <title> Gibbs sampling in Bayesian networks. </title> <booktitle> Artificial Intelligence 46 (1990), </booktitle> <pages> 351-363. </pages>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields [8, 13], and their close relationships to Bayesian networks, as discussed in <ref> [12, 14, 15, 26] </ref>. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query.
Reference: [13] <author> R. Kinderman and J. L. Snell, </author> <title> Markov Random Fields and Their Applications. </title> <publisher> American Mathematical Society, </publisher> <address> Providence, RI, </address> <year> 1980. </year>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields <ref> [8, 13] </ref>, and their close relationships to Bayesian networks, as discussed in [12, 14, 15, 26]. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query.
Reference: [14] <author> K. B. Laskey, </author> <title> Adapting neural learning to Bayesian networks. </title> <booktitle> Int. J. of Approximate Reasoning 4 (1990), </booktitle> <pages> 261-282. </pages>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields [8, 13], and their close relationships to Bayesian networks, as discussed in <ref> [12, 14, 15, 26] </ref>. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query.
Reference: [15] <author> S.L.Lauritzen and D.J.Spiegelhalter, </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Royal Stat. Soc., Ser. B 1989. </journal> <note> Reprinted as pp. 415-448 in: Readings in Uncertain Reasoning (G. </note> <editor> Shafer and J. Pearl, eds.). </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1990. </year>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields [8, 13], and their close relationships to Bayesian networks, as discussed in <ref> [12, 14, 15, 26] </ref>. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query.
Reference: [16] <author> R. J. T. Morris, L. D. Rubin, H. Tirri, </author> <title> Neural network techniques for object 18 Floreen, Myllymaki, Orponen, Tirri orientation detection: solution by optimal feedforward network and learning vector quantization approaches. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 12 (1990) 11 (November), </journal> <pages> 1107-1115. </pages>
Reference-contexts: One possible technique for this kind of data discretization was studied in cooperation with AT&T Bell Laboratories by implementing a program for object orientation detection <ref> [16] </ref>. Another approach using instance-based reasoning techniques is described in [19]. The main problems with the current system concern its efficiency: simulated annealing techniques require a lot of iterative processing, and consequently their implementations on conventional serial computers can be excruciatingly slow.
Reference: [17] <editor> P.Myllymaki and P.Orponen, </editor> <booktitle> Programming the Harmonium. Proc. of the International Joint Conf. on Neural Networks (Singapore, Nov. 1991), </booktitle> <volume> Vol. 1, </volume> <pages> 671-677. </pages> <publisher> IEEE, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: On the other hand, instead of simulating the neural network model in a conventional computer, the computation may be performed in a special parallel environment (neural net emulator or chip), which enables enormous speed-ups in performance. The second model, described in <ref> [17] </ref>, uses the simulated annealing scheme (see e.g. [1]). The simulated annealing technique forces the network to eventually settle down to the "maximum entropy" state, which is the most proba ble state of the network consistent with the given input query.
Reference: [18] <author> P. Myllymaki, P. Orponen, T. Silan-der, </author> <title> Integrating symbolic reasoning with neurally represented background knowledge. </title> <booktitle> Proc. of STeP-92, the Finnish Artificial Intelligence Conference (Otaniemi, </booktitle> <address> Finland, </address> <month> June </month> <year> 1992), </year> <title> Vol. </title> <booktitle> II, </booktitle> <pages> 231-240. </pages> <booktitle> Finnish Artificial Intelligence Society, </booktitle> <address> Helsinki, </address> <year> 1992. </year> <title> Also: </title> <booktitle> Workshop notes of the AAAI-92 workshop on Integrating Neural and Symbolic Processes, </booktitle> <pages> 168-172. </pages>
Reference-contexts: Section 4 demonstrates how our system can be used as a stand-alone expert system. However, after the NEULA code has been compiled, it is also possible to extract the generated network module, and integrate it with other software. As an example, we have implemented a system <ref> [18] </ref>, where the NEULA module is integrated with a Prolog inference engine. This kind of system allows the user to mix probabilistic and logical reasoning. The current NEULA system is able to handle only discrete values of the attributes.
Reference: [19] <author> P. Myllymaki and H. Tirri, </author> <title> Bayesian case-based reasoning with neural networks. </title> <note> Manuscript submitted for publication (Oct. </note> <year> 1992), </year> <pages> 7 pp. </pages>
Reference-contexts: One possible technique for this kind of data discretization was studied in cooperation with AT&T Bell Laboratories by implementing a program for object orientation detection [16]. Another approach using instance-based reasoning techniques is described in <ref> [19] </ref>. The main problems with the current system concern its efficiency: simulated annealing techniques require a lot of iterative processing, and consequently their implementations on conventional serial computers can be excruciatingly slow.
Reference: [20] <author> M.Oksalahti, T.Pasonen, T.Saarikivi, M.Seppanen, M.Silvonen, NeulaTool-Neuraaliverkkojen ohjelmointiympa-riston kayttoliittyma. </author> <type> Report C-1992-33, </type> <institution> University of Helsinki, Department of Computer Science (in Finnish). </institution>
Reference-contexts: The user states a query to the network by perma nently setting ("clamping") the activity values of a selected set of nodes. In the NEULA system, this can be accomplished by using a graphical point-and-click interface called NeulaTool <ref> [20] </ref>.
Reference: [21] <author> P. Orponen, P. Floreen, P. Myllymaki, H. Tirri, </author> <title> A neural implementation of conceptual hierarchies with Bayesian reasoning. </title> <booktitle> Proc. of the International Joint Conf. on Neural Networks (San Diego, </booktitle> <address> CA, </address> <month> June </month> <year> 1990), </year> <journal> Vol. </journal> <volume> I, </volume> <pages> 297-303. </pages> <publisher> IEEE, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: However, the fact that a NEULA description consists of a hierarchy of concepts enables us to reduce the number of hidden units to grow just linearly in the size of the description (see e.g. <ref> [21] </ref>). 4 Query processing The neural network created from the compilation can be seen as a model of the world described in the NEULA code. <p> In both our models, all the nodes are actually binary, being at any iteration step either in state 1 (representing the value "true"), or 0 ("false"). In the first technique, described in <ref> [21] </ref>, we are able to approximate the probability of each of the variables by the frequency NEULA: A hybrid neural-symbolic expert system shell 15 of the corresponding node having been in the state 1, resulting in an estimate of the conditional Bayesian probabilities for each of the objects and (attribute:value) pairs,
Reference: [22] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The compiler first creates a de NEULA: A hybrid neural-symbolic expert system shell 13 scription of the code as a belief network representation <ref> [22] </ref>, which consists of a set of random variables and probabilistic dependencies between these variables. In our scheme, each concept and (attribute:value) pair in the NEULA code is regarded as one variable in the belief network. <p> According to Pearl <ref> [22] </ref> and Ge-man&Geman [8], the estimates given by the network converge to the correct probability as the simulation continues. Consequently, the accuracy of the answer becomes better and better with increased running time.
Reference: [23] <author> C. Peterson, J. R. Anderson, </author> <title> A mean field theory learning algorithm for neural networks. </title> <booktitle> Complex Systems 1 (1987), </booktitle> <pages> 995-1019. </pages>
Reference-contexts: A parallel implementation of the NEULA simulator is currently under construction for the 100-transputer Hathi-2 system at Abo Akademi [3]. On the algorithmic front, we are also studying more sophisticated annealing techniques, such as self-adjusting annealing schedules [2] and the mean field annealing algorithm <ref> [23] </ref>. NEULA: A hybrid neural-symbolic expert system shell 17
Reference: [24] <author> L. Shastri, </author> <title> Semantic Networks: An Evidential Formalization and Its Connectionist Realization. </title> <publisher> Pitman, </publisher> <address> Lon-don, </address> <year> 1988. </year>
Reference-contexts: The neural network model behind the NEULA system is structurally simple and uniform. This is a clear advantage over many other hybrid knowledge representation schemes (see e.g. <ref> [4, 9, 24] </ref>), which require fairly complicated computing elements and control regimes. Consequently, the NEULA system would be much easier to implement in a real neural system.
Reference: [25] <author> P. Smolensky, </author> <booktitle> Information processing in dynamical systems: Foundations of Harmony Theory. Parallel Distributed Processing (D. </booktitle> <editor> E. Rumelhart and J. L. McClelland, eds.). </editor> <volume> Vol. I, </volume> <pages> 194-281. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: In our scheme, each concept and (attribute:value) pair in the NEULA code is regarded as one variable in the belief network. The conditional probabilities attached to the dependencies are calculated from the numbers given in the code. The belief network is then transformed to a harmonium-type neural network <ref> [25] </ref>. The interconnection weights in the neural network are calculated from the conditional probabilities in the belief network. For each variable in the belief network, there will be a corresponding node in the neural network: these are called visible units. <p> A typical plot of the state 1 occurrence frequencies of the nodes during the "dolphin query" processing is shown in figure 2. The neural network model used in the second model is the harmony network <ref> [25] </ref>, which is a kind of a generalization of the Boltzmann machine model [10, 11]. In this scheme, the user is given as output only either of the judgements "true" or "false" for each of the variables.
Reference: [26] <author> D. J. Spiegelhalter, </author> <title> Probabilistic reasoning in predictive expert systems. </title> <booktitle> Uncertainty in Artificial Intelligence (L. </booktitle> <editor> N. Kanal and J. F. Lemmer, eds.). </editor> <address> 47-67. Elsevier-North-Holland, Ams-terdam, </address> <year> 1986. </year>
Reference-contexts: We have developed two different techniques for implementing efficient approximations of this kind of reasoning by our neural network models. The methods are based on the theory of Markov random fields [8, 13], and their close relationships to Bayesian networks, as discussed in <ref> [12, 14, 15, 26] </ref>. The techniques developed provide a sound basis for the probabilistic interpretation of the truth values given as the result of a query.
References-found: 26

