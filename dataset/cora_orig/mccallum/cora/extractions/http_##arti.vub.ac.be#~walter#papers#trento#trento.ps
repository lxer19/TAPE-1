URL: http://arti.vub.ac.be/~walter/papers/trento/trento.ps
Refering-URL: http://arti.vub.ac.be/~walter/papers/welcome.html
Root-URL: 
Title: Cognitive Architectures From Knowledge Level To Structural Coupling  
Author: Walter Van de Velde 
Address: Pleinlaan 2, B-1050 Brussels, Belgium  
Affiliation: Vrije Universiteit Brussel, AI-Lab  
Abstract: This chapter 1 investigates the relation between the two key aspects of intelligent agents: intelligence and agent-hood. Efforts for building general architectures for intelligent agents have typically focussed on one of these aspects. The chapter first reviews some work on cognitive architectures for intelligence and illustrates how these are being applied to physical agents. Secondly, this chapter puts forward a series of hypotheses on the relationship between cognition and agent-hood. These hypotheses are aimed at a unified treatment of behavior and cognition. Central to this discussion in the notion of coordination. In particular the nature and role of representations, internal and external, are explained in relation to their coordinating role. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.R. Anderson. </author> <title> The Architecture of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1983 </year>
Reference-contexts: Many of the more traditional theories of intelligent agents (see [22] for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures. Systems like ACT* <ref> [1] </ref>, SOAR [7, 14], THEO [12] and ICARUS [9] and there are many more -, all provide for symbolic representations and for mechanisms to manipulate and construct these representations.
Reference: 2. <author> J. Blythe and T. Mitchell. </author> <title> On becoming reactive. </title> <booktitle> In Proceedings 6th International Conference on Machine Learning, </booktitle> <pages> pp. 255-257. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989 </year>
Reference-contexts: Architectural commitments in three cognitive architectures Of the three architectures, SOAR and THEO have originally been designed for cognitive tasks alone, i.e., tasks not involving ongoing interac tion with an environment. Nevertheless, both SOAR and THEO have subse-quently been applied in a robotic context. Robo-SOAR [8] and Theo-Agent <ref> [2] </ref> are the resulting systems. In any case, and this is important, the applications respect the architectural commitments that are made by the basic architectures. ICARUS is less publicized and was never actually finished as a complete system. <p> However, it has been applied to a problem of autonomous agents, called THEO-Agent <ref> [2] </ref>. THEO-Agent adds an agent architecture on top of THEO (Figure 8). The architecture repeatedly assesses the situation, selects a goal, creates a plan for that goal and then performs the first action of that plan. <p> However the form of explanation-based learning in THEO may lead to interesting generalization which, in effect shortcut part of or all of the reasoning in THEO-Agent. Examples have been reported where THEO-Agent learns to directly connect percepts with motor actions, without going through the goal selection and planning processes <ref> [2] </ref>. Fig. 8. The THEO-Agent architecture on top of THEO. THEO-Agent asks itself 'what do I do next' and computes the answer by lazy evaluation.
Reference: 3. <author> P. Brazdil, M. Gams, S. Sian, L. Torgo, and W. Van de Velde. </author> <title> Learning in distributed systems and multi-agent environments. </title> <editor> In Y. Kodratoff (ed.), </editor> <booktitle> Machine Learning-EWSL-91, </booktitle> <pages> pp. 412-423, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag </publisher>
Reference-contexts: Knowledge level coupling occurs in many situations. For example a good soccer team coordinates the different players in a rationalisable way. Also the coordination between the two teams is an example of knowledge level coupling (see <ref> [3] </ref> for more on this example). In a more traditional context phenomena of performance and explanation are knowledge level coupled: Fig. 13. Two forms of realizing coordinated behavior. In symbol level cou-pling, to the left, agents share or exchange representations.
Reference: 4. <author> W. J. Clancey. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27: </volume> <pages> 289-350, </pages> <year> 1985 </year>
Reference-contexts: Doing is not a goal in itself but brings the environment in such a state as to make reasoning work. As it turns out there is finally not much going on in the method. If we think of the case model, then its shape (e.g., the heuristic classification horse-shoe <ref> [4] </ref>) is actually determined by the problem solving method that is underlying the reasoning. However, its role in reasoning is, in a sense, minimal. All that is required is some appropriate coordination between the different handlers that are working on it.
Reference: 5. <author> W. J. Clancey. </author> <title> Model construction operators. </title> <journal> Artificial Intelligence, </journal> <volume> 53(1): </volume> <pages> 1-115, </pages> <year> 1992 </year>
Reference-contexts: The goal of reasoning is to select one of the possible actions. More recently a different view is being explored, namely the view of problem solving as modelling. The idea is that problem solving is the construction of a situation specific model <ref> [5] </ref> or case model [15]. My interpretation of this was previously explained in [19] and [21]. From a knowledge level perspective the agent's perception of the world is through knowledge alone. A goal therefore must correspond to a desired state of one's knowledge about the world. <p> How the processes actually get triggered is unclear but it does seem to rely on external clues or cues (Figure 14). 6 This is a slight re-interpretation of Clancey's argument <ref> [5] </ref> for the usefulness of the metaphor of blackboard: it holds the external representation that regulates the coordination between multiple experts (knowledge sources). The hypothesis is that here cognition comes in. The coordinated behavior is as if mediated by representation, but it is achieved without representation.
Reference: 6. <author> J.H. Gennari, P. Langley, and D. Fisher. </author> <title> Models of incremental concept formation. </title> <journal> Artificial Intelligence, </journal> <volume> (40): </volume> <pages> 11-61, </pages> <year> 1989 </year>
Reference-contexts: In some cases ICARUS' learning mechanism may even consider a more drastic reorganization of the concept hier archy. Classification and concept formation in ICARUS are based on Classit <ref> [6] </ref>. Fig. 10. A simplified view of the heuristic classification processes in three interleaved hierarchies for object recognition, planning and motor control in ICARUS. The concept formation capability in ICARUS is a step toward solving the problem of symbol grounding.
Reference: 7. <author> J. E. Laird, A. Newell, and P. S. Rosenbloom. </author> <title> SOAR: an architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33: </volume> <pages> 1-64, </pages> <year> 1987 </year>
Reference-contexts: Many of the more traditional theories of intelligent agents (see [22] for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures. Systems like ACT* [1], SOAR <ref> [7, 14] </ref>, THEO [12] and ICARUS [9] and there are many more -, all provide for symbolic representations and for mechanisms to manipulate and construct these representations. <p> Such mediating processes enable a behavior which, under the right circumstances (clues), leads to cognitive effects but is, in fact, itself representation-less. 2 General Architectures The concept of an architecture of intelligence is illustrated by the abstract of a seminal paper on SOAR <ref> [7] </ref>, which is probably the most well-known such architecture: "The ultimate goal of work in cognitive architectures is to provide for a system capable of general intelligent behavior. <p> The work culminated into an integrated theory of intelligence in [14]. The main reference for this section is <ref> [7] </ref>. The architectural commitments in SOAR are summarized in Table 2. With respect to representation SOAR embodies the commitment of representing all long-term memory as productions, all short term memory as objects and any task environment as problem spaces. Especially the latter is significant.
Reference: 8. <author> J. E. Laird, E. S. Yager, M. Hucka, and C. M. Tuck. Robo-Soar: </author> <title> An integration of external interaction, planning, and learning using Soar. </title> <editor> In W. Van de Velde (ed.), </editor> <booktitle> Toward Learning Robots, </booktitle> <pages> pp. 113-130. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993 </year>
Reference-contexts: For example, in Robo-SOAR the SOAR architecture has been applied to a task that involves robotic interaction with an external environment. The abstract of a paper describing that work <ref> [8] </ref> reads as follows: "This chapter reports on progress in extending the SOAR architecture to tasks that involve interaction with external environments. The tasks are performed using a Puma arm and camera in a system called Robo-SOAR. <p> Architectural commitments in three cognitive architectures Of the three architectures, SOAR and THEO have originally been designed for cognitive tasks alone, i.e., tasks not involving ongoing interac tion with an environment. Nevertheless, both SOAR and THEO have subse-quently been applied in a robotic context. Robo-SOAR <ref> [8] </ref> and Theo-Agent [2] are the resulting systems. In any case, and this is important, the applications respect the architectural commitments that are made by the basic architectures. ICARUS is less publicized and was never actually finished as a complete system.
Reference: 9. <author> Pat Langley, Kevin Thompson, Wayne Iba, John Gennari, and John Allen. </author> <title> An integrated cognitive architecture for autonomous agents. </title> <type> Technical report, </type> <institution> Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA, </address> <year> 1991 </year>
Reference-contexts: Many of the more traditional theories of intelligent agents (see [22] for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures. Systems like ACT* [1], SOAR [7, 14], THEO [12] and ICARUS <ref> [9] </ref> and there are many more -, all provide for symbolic representations and for mechanisms to manipulate and construct these representations.
Reference: 10. <author> H. Maturana. </author> <title> Biology of cognition. </title> <editor> In F. Varela and H. Maturana (eds.), Au-topoiesis and Cognition. </editor> <publisher> Reidel, </publisher> <address> London, </address> <year> 1980 </year>
Reference-contexts: This circular view on knowledge and behavior is reminiscent of Maturana's view of autonomous systems <ref> [10] </ref>. In what follows we will push a little further in this direction. 4.2 Representation for Coordination In [19] an architecture is described that implements the above model of problem solving. It makes different commitments by distinguishing between 'reasoning' and 'doing', which are implemented by methods and handlers.
Reference: 11. <author> H.R. Maturana and F. J. Varela. </author> <title> The Tree of Knowledge: The biological roots of human understanding. </title> <address> Shambala, Boston and London, </address> <note> revised edition, </note> <year> 1992 </year>
Reference-contexts: The traditional way, I call it symbol level cou-pling, is to enforce a link between the representations that are involved in each of the processes, for example by a mechanism of consistency maintenance. An alternative, called structural coupling <ref> [11] </ref>, occurs when processes are mutually adapted to eachother and to the environment that they both interact with. In this case their behavior is coordinated but there is no direct link between them. <p> of the structures that re-occurs over the variety of systems that realize the wider class of behaviors. 2 But abstraction is only half of the story: An architecture must also provide guidance in creating (or, designing) a particular instance. 2 The terminology of structure and organization is used as in <ref> [11] </ref>. Fig. 3. Variations of intelligence. What is left if we abstract away from all these differences? Architecture of intelligence are more or less ambitious in covering areas of variation. They are common abstractions that can be systematically instantiated to any meaningful variation. Fig. 4. <p> Structural coupling: whenever two systems coordinate without exchange of representation, but by being mutually adapted to the influences that they experience through their common environment we call them struc turally coupled <ref> [11] </ref>. As extensively argued by Maturana and Varela (e.g. [11]) structural cou pling can explain a variety of biological, cognitive and social phenomena. 4.4 External coordination In a previous section we have explained the role of representation for coordination. <p> Structural coupling: whenever two systems coordinate without exchange of representation, but by being mutually adapted to the influences that they experience through their common environment we call them struc turally coupled <ref> [11] </ref>. As extensively argued by Maturana and Varela (e.g. [11]) structural cou pling can explain a variety of biological, cognitive and social phenomena. 4.4 External coordination In a previous section we have explained the role of representation for coordination. To explain the nature of these representations, we first need to distinguish between internal and external representations (Figure 14). <p> Moreover, it could be that the structural elements start playing a completely different role in another situation (which is a feature of structural coupling, as argued by Maturana and Varela <ref> [11] </ref>). Thus, the representation looses its character of having an intrinsic meaning. Rather it acquires its meaning only when it is effectively used. 5 Conclusion This chapter has investigated the relationship between intelligence and the agent-hood of an intelligent agent.
Reference: 12. <author> T. Mitchell, J. Allen, P. Chalasani, J. Cheng, O. Etzioni, M. Ringuette, and J. Schlimmer. Theo: </author> <title> A framework for self-improving systems. </title> <editor> In K. VanLehn, editor, </editor> <booktitle> Architectures for Intelligence. </booktitle> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1990 </year>
Reference-contexts: Many of the more traditional theories of intelligent agents (see [22] for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures. Systems like ACT* [1], SOAR [7, 14], THEO <ref> [12] </ref> and ICARUS [9] and there are many more -, all provide for symbolic representations and for mechanisms to manipulate and construct these representations.
Reference: 13. <author> A. Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18: </volume> <pages> 87-127, </pages> <year> 1982 </year>
Reference-contexts: The concept of intelligence is more tricky. One traditional view holds that intelligence is basically cognition, i.e., the capacity to construct and manipulate symbolic representations that are somehow related to the environment (i.e., represent aspects of that environment) and that are used to determine appropriate actions (e.g. <ref> [13] </ref>). In another view intelligence relies on self-sufficiency: a behavior is intelligent to the extent that it can be justified as being aimed at sustained behavior in an environment (see Steels, this 1 Originally published as Walter Van de Velde (1995) Cognitive Architectures - From Knowledge Level to Structural Coupling. <p> For example, the knowledge-oriented paradigm uses knowledge as a way to describe behavior: an agent is viewed as acting according to a body of knowledge that is ascribed to it (e.g., <ref> [13] </ref>). Early rule-based models assumed that the representation of that knowledge in terms of production rules would, upon manipulation by a general inference mechanism, lead to the appropriate behavior. This would fit our notion of systematic instantia-tion. <p> The knowledge level rationalizes behaviour in terms of the reasons that an agent has to believe that certain actions will lead to achieving certain goals. In this sense knowledge is a means to an end, a resource for behaviour <ref> [13] </ref>. The goal of reasoning is to select one of the possible actions. More recently a different view is being explored, namely the view of problem solving as modelling. The idea is that problem solving is the construction of a situation specific model [5] or case model [15]. <p> This model let us call it the case model at every moment during problem solving summarizes the agent's understanding of the problem, and allows it to eventually conclude that the goal has been reached. The actions are the means that the agent has for interacting with the world <ref> [13] </ref>. Again, since at the knowledge level the agent's perception is through knowledge an action must be viewed as a way of obtaining knowledge about the reality. Actions of perception naturally fit in this scheme but also genuine acts of interaction do [19]. <p> The important twist is that, in this view problem solving is no longer an input-output process, neither a means to select actions (as in Newell's knowledge level theory <ref> [13] </ref>). Rather it is a process of organizing knowledge (obtained through actions) by making assumptions (i.e., constructing a model) that allow one to conclude (in effect, only assume [21]) that a goal is achieved. Successful problem solving is a matter of making the right assumptions and exploring their consequences.
Reference: 14. <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990 </year>
Reference-contexts: Many of the more traditional theories of intelligent agents (see [22] for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures. Systems like ACT* [1], SOAR <ref> [7, 14] </ref>, THEO [12] and ICARUS [9] and there are many more -, all provide for symbolic representations and for mechanisms to manipulate and construct these representations. <p> The specificity of ICARUS is that, to some extend, it takes the issue of interaction into account from the start. 3.1 SOAR The history of SOAR goes back to work on GPS and OPS5. The work culminated into an integrated theory of intelligence in <ref> [14] </ref>. The main reference for this section is [7]. The architectural commitments in SOAR are summarized in Table 2. With respect to representation SOAR embodies the commitment of representing all long-term memory as productions, all short term memory as objects and any task environment as problem spaces. <p> The experiment with Robo-SOAR had two purposes. The first one was to demonstrate the application of SOAR to a robotics problem. The second one is to show how SOAR could be used as an instructable system with human guidance to build up the robot's skills. In <ref> [14] </ref> Allen Newell has described a way of extending SOAR into a full cognitive system for an integrated agent. He proposes productions that do the coding and decoding for action and perception, i.e., transduction between the cognitive level and the low-level interaction mechanisms (Figure 7).
Reference: 15. <author> L. Steels. </author> <title> Components of Expertise. </title> <journal> AI Magazine, </journal> <volume> 11(2): </volume> <pages> 29-49, </pages> <year> 1990 </year>
Reference-contexts: The goal of reasoning is to select one of the possible actions. More recently a different view is being explored, namely the view of problem solving as modelling. The idea is that problem solving is the construction of a situation specific model [5] or case model <ref> [15] </ref>. My interpretation of this was previously explained in [19] and [21]. From a knowledge level perspective the agent's perception of the world is through knowledge alone. A goal therefore must correspond to a desired state of one's knowledge about the world.
Reference: 16. <author> M. Tan. </author> <title> Learing cost-sensitive decision trees. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1992 </year>
Reference-contexts: So our next hypothesis is that representation is a means for coordination. An experiment by Ming Tan on cost-sensitive decision trees <ref> [17, 16] </ref> illustrates the same idea in a robotic context (Figure 12). Ming has developed a system for an approach and recognize task.
Reference: 17. <author> M. Tan and J. Schlimmer. </author> <title> Cost sensitive concept learning of sensor use in approach and recognition. </title> <booktitle> In Proceedings of the 6th International Machine Learning Workshop, </booktitle> <year> 1989 </year>
Reference-contexts: So our next hypothesis is that representation is a means for coordination. An experiment by Ming Tan on cost-sensitive decision trees <ref> [17, 16] </ref> illustrates the same idea in a robotic context (Figure 12). Ming has developed a system for an approach and recognize task.
Reference: 18. <author> W. Van de Velde. </author> <title> Inference stucture as a basis for problem solving. </title> <editor> In Y. Kodratoff (ed.), </editor> <booktitle> Proceedings of the 8th European Conference on Artificial Intelligence, </booktitle> <pages> pp. 202-207, </pages> <address> London, 1988. </address> <publisher> Pitman </publisher>
Reference-contexts: All that is required is some appropriate coordination between the different handlers that are working on it. If we take the bold step of viewing the problem solving method as the representation (which is not so bold in light of the notion of inference structure as used in <ref> [18] </ref>) then we can state that the role of representation is the coordination of behaviors. So our next hypothesis is that representation is a means for coordination. An experiment by Ming Tan on cost-sensitive decision trees [17, 16] illustrates the same idea in a robotic context (Figure 12).
Reference: 19. <author> W. Van de Velde. </author> <title> Reasoning, behavior and learning: a knowledge level perspective. </title> <booktitle> In Proceedings of Cognitiva 90, </booktitle> <pages> pp. 451-463, </pages> <month> November </month> <year> 1990 </year>
Reference-contexts: More recently a different view is being explored, namely the view of problem solving as modelling. The idea is that problem solving is the construction of a situation specific model [5] or case model [15]. My interpretation of this was previously explained in <ref> [19] </ref> and [21]. From a knowledge level perspective the agent's perception of the world is through knowledge alone. A goal therefore must correspond to a desired state of one's knowledge about the world. Consequently this knowledge must refer to the specific systems that the goal is about. <p> Again, since at the knowledge level the agent's perception is through knowledge an action must be viewed as a way of obtaining knowledge about the reality. Actions of perception naturally fit in this scheme but also genuine acts of interaction do <ref> [19] </ref>. For example when a spray-painting robot paints some part then it will assume that the part probably has paint on it afterwards. <p> This circular view on knowledge and behavior is reminiscent of Maturana's view of autonomous systems [10]. In what follows we will push a little further in this direction. 4.2 Representation for Coordination In <ref> [19] </ref> an architecture is described that implements the above model of problem solving. It makes different commitments by distinguishing between 'reasoning' and 'doing', which are implemented by methods and handlers. The methods are, as usual, for reasoning. The handlers are for "doing", i.e., for provoquing side-effects.
Reference: 20. <author> W. Van de Velde. </author> <title> Tractable rationality at the knowledge-level. </title> <editor> In L. Steels and B. Smith (eds.), </editor> <booktitle> Proceedings AISB'91: Artificial Intelligence and Simulation of Behaviour, </booktitle> <pages> pp. 196-207, </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1991 </year>
Reference-contexts: Problem solving is thus viewed as the `creation' of a suitable case model and the interaction only creates the context for this, by side-effect setting the boundary conditions for the process of maintaining an internal organization and identity <ref> [20] </ref>. The cognitive agent can be considered a closed and self-contained process. It is subject to influences from the outside that change its state, but all it aims at is to come to terms with its understanding of the world (Figure 11). Fig. 11.
Reference: 21. <author> W. Van de Velde. </author> <title> Issues in knowledge level modelling. </title> <editor> In J-M. David, J-M Krivine, and R. Simmons (eds.), </editor> <booktitle> Second Generation Expert Systems, </booktitle> <pages> pp. 211 - 231. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1993 </year>
Reference-contexts: More recently a different view is being explored, namely the view of problem solving as modelling. The idea is that problem solving is the construction of a situation specific model [5] or case model [15]. My interpretation of this was previously explained in [19] and <ref> [21] </ref>. From a knowledge level perspective the agent's perception of the world is through knowledge alone. A goal therefore must correspond to a desired state of one's knowledge about the world. Consequently this knowledge must refer to the specific systems that the goal is about. <p> Rather it is a process of organizing knowledge (obtained through actions) by making assumptions (i.e., constructing a model) that allow one to conclude (in effect, only assume <ref> [21] </ref>) that a goal is achieved. Successful problem solving is a matter of making the right assumptions and exploring their consequences.
Reference: 22. <author> K. VanLehn. </author> <title> Architectures for Intelligence. </title> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1989 </year>
Reference-contexts: The aim of this chapter is to investigate into the connection between the intelligence and the agent-hood of an intelligent agent. Many of the more traditional theories of intelligent agents (see <ref> [22] </ref> for a number of these) have focussed on the cognitive aspects of intelligence. They are therefore called cognitive architectures.
References-found: 22

