URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/nonmonotone.ps
Refering-URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/fsqp.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: high end AVOIDING THE MARATOS EFFECT BY MEANS OF A NONMONOTONE LINE SEARCH II. INEQUALITY
Author: J. FR ED ERIC BONNANSy, ELIANE R. PANIERz, ANDR E L. TITS AND JIAN ZHOU 
Keyword: Key words. constrained optimization, sequential quadratic programming, Maratos effect, superlinear convergence, feasibility  
Date: 1187-1202, August 1992 018  
Note: SIAM J. NUM. ANAL. c fl1992 Society for Industrial and Applied Mathematics Vol. 29, No. 4, pp.  AMS(MOS) subject classifications. 90C30, 65K10  
Abstract: When solving inequality constrained optimization problems via Sequential Quadratic Programming (SQP), it is potentially advantageous to generate iterates that all satisfy the constraints: all quadratic programs encountered are then feasible and there is no need for a surrogate merit function. (Feasibility of the successive iterates is in fact required in many contexts such as in real-time applications or when the objective function is not defined outside the feasible set.) It has recently been shown that this is indeed possible, by means of a suitable perturbation of the original SQP iteration, without losing superlinear convergence. In this context, the well known Maratos effect is compounded by the possible infeasibility of the full step of one even close to a solution. These difficulties have been accommodated by making use of a suitable modification of a "bending" technique proposed by Mayne and Polak, requiring evaluation of the constraints function at an auxiliary point at each iteration. In part I of this two-part paper, it was shown that, when feasibility of the successive iterates is not required, the Maratos effect can be avoided by combining Mayne and Polak's technique with a nonmonotone line search proposed by Grippo, Lampariello and Lucidi in the context of unconstrained optimization, in such a way that, except possibly at a few early iterations, function evaluations are no longer performed at auxiliary points. In this second part, we show that feasibility can be restored without resorting to additional constraint evaluations, by adaptively estimating a bound on the second derivatives of the active constraints. Extension to constrained minimax problems is briefly discussed.
Abstract-found: 1
Intro-found: 1
Reference: <author> 14 j. fr ed eric bonnans, eliane r. panier, andr e l. </author> <title> tits and jian zhou </title>
Reference-contexts: The appropriate amount of bending is determined via evaluation of the constraints at an auxiliary point at each iteration. In part I of this two-part paper <ref> [14] </ref>, it was shown that, when feasibility of the successive iterates is not required, the "Maratos effect" can be avoided by combining Mayne and Polak's technique with a nonmonotone line search proposed by Grippo, Lampariello and Lucidi in the context of unconstrained optimization, in such a way that, except possibly at <p> Proposition 3.3. The entire sequence fx k g converges to x fl . Proof. The proof is similar to the one of Proposition 3.4 in <ref> [14] </ref>. Proposition 3.4. There exists C &gt; 0 such that C k C; 8k: Proof. <p> Proof. Similarly to what is done in the proof of Proposition 3.6 in Part I of this two-part paper <ref> [14] </ref>, it can be proven that (i) holds. <p> Proof of Theorem 3.8 We first show that, for k large enough, (A:3) f (x k + d ` k ) ffhrf (x k ); d 0 k i f (x k3 ) : While this proof has similarities with that of Theorem 3.8 in <ref> [14] </ref>, it is given here for the reader's convenience.
Reference: [1] <author> R. M. CHAMBERLAIN, M. J. D. POWELL, C. LEMARECHAL, and H. C. PEDERSEN, </author> <title> The Watchdog Technique for Forcing Convergence in Algorithms for Constrained Optimization, </title> <journal> Math. Programming Stud., </journal> <volume> 16 (1982), </volume> <pages> pp. 1-17. </pages>
Reference-contexts: step of one is eventually taken, an imperative requirement if superlinear convergence is to take place. (The possible undesirable truncation of the step due to failure of the merit function to decrease when a full step is taken was first pointed out by Maratos [11].) In particular the watchdog technique <ref> [1] </ref>, by which the full step of one is tentatively accepted if sufficient decrease was obtained in recent iterations, is of no help here. In [13], [15], the issue is resolved by making use of a "bending" technique employed by Mayne and Polak [12], suitably adapted for restoring feasibility. <p> k+1 ) = g j (x k ) + hrg j (x k ); d ` 1 hd ` @ 2 g j k )d ` Ckd 0 1 kd ` @ 2 g j k )k; j = 1; : : : ; m for some ~ j;k 2 <ref> [0; 1] </ref>. <p> Next, it is easily checked that if C k remains bounded as k ! 1 (which will be shown to be true) and d ` k is constructed according to d ` k )d 0 k d 1 (x k ); with ` k 2 <ref> [0; 1] </ref> as small as possible subject to satisfaction of (1:5), the requirement (1.4) will be satisfied. Away from x fl however it may be impossible to satisfy (1:5) with ` k 2 [0; 1]. A suitable choice in such case would be ` k = 1. <p> according to d ` k )d 0 k d 1 (x k ); with ` k 2 <ref> [0; 1] </ref> as small as possible subject to satisfaction of (1:5), the requirement (1.4) will be satisfied. Away from x fl however it may be impossible to satisfy (1:5) with ` k 2 [0; 1]. A suitable choice in such case would be ` k = 1. <p> = minfC k kd 0 k k 2 ; kd 0 k kg and define values k;j for j = 1; : : : ; m by k;j equal to zero if g j (x k ) + hrg j (x k ); d 0 or equal the maximum in <ref> [0; 1] </ref> such that g j (x k ) + hrg j (x k ); (1 )d 0 k i v k otherwise. Finally, let ` k = max j=1;:::;m f k;j g: 6 j. fr ed eric bonnans, eliane r. panier, andr e l. tits and jian zhou iii. <p> It then follows from Theorem 3.7 that f (x k + d ` k ) ffhrf (x k ); d 0 k i = f (x fl ) + o (kx k3 x fl k 2 ) : Equation (A.3) then follows from the easily checked fact <ref> [1, Lemma 1 ] </ref> that there exists a positive scalar C such that for x feasible close enough to x fl , f (x) f (x fl ) + Ckx x fl k 2 : The theorem follows from (A.3) and the fact that, in view of Proposition 3.6, for k
Reference: [2] <author> C. CHARALAMBOUS AND A. R. CONN, </author> <title> An Efficient Method to Solve the Minimax Problem Directly, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 15 (1978), </volume> <pages> pp. 162-187. </pages>
Reference-contexts: No significant difference is observed in the number of objective function evaluations. Results obtained on selected minimax problems are summarized in Table 2. Problems BARD, DAVD2, F&R, HETTICH, and WATS are from [18]; CB2, CB3, R-S, WONG and COLV are from <ref> [2; Examples 5.1-5] </ref>; MAD1 to MAD8 are from [10, Examples 1-8]. Some of these test problems allow one to freely select the number of variables; problems WATS-6 and WATS-20 correspond to 6 and 20 variables, respectively, and MAD8-10, MAD8-30 and MAD8-50 to 10, 30 and 50 variables respectively.
Reference: [3] <author> A. R. CONN AND Y. LI, </author> <title> An Efficient Algorithm for Nonlinear Minimax Problems, </title> <institution> University of Waterloo, Research Report CS-88-41, Waterloo, </institution> <address> Ontario, N2L 3G1 Canada, </address> <month> November, </month> <year> 1989 </year> . 
Reference-contexts: In Table 2, the performance of FSQP is also compared with that of the algorithms proposed in <ref> [3] </ref> (NM) and [10] (MS). To make such comparison meaningful, we attempted to best approximate the stopping rule used in each of the references.
Reference: [4] <author> J. M. DANIEL, </author> <title> Stability of the Solution of Definite Quadratic Programs, </title> <journal> Math. Programming, </journal> <volume> 5 (1970), </volume> <pages> pp. 41-53. </pages>
Reference-contexts: In view of (2:1), we may also assume, without loss of generality, that the subsequence fH k g k2K converges to some symmetric positive definite matrix H fl . In that case, in view of the work in <ref> [4] </ref> (see also [6, Lemma 3.2]), the subsequence fd 0 k g k2K converges to a vector d 0fl . In order to conclude, we show that d 0fl = 0, so that, the feasible point x fl (limit of feasible iterates) is a KKT point for (P ).
Reference: [5] <author> L. GRIPPO, F. LAMPARIELLO, and S. LUCIDI, </author> <title> A Nonmonotone Line Search Technique for Newton's Method, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 23 (1986), </volume> <pages> pp. 707-716. </pages>
Reference-contexts: Again, locally around x fl , evaluation of the constraints at auxiliary points would not be necessary. Global convergence of a corresponding scheme was proved in part I based on a result in <ref> [5] </ref>. 1 In the present case however, a major difficulty remains: the full step of one will likely be rejected due to infeasibility. 1 The fact that d 0 k is a direction of descent for f is crucial. avoiding the maratos effect part ii 3 It turns out (see Theorem <p> Appendix Proof of Proposition 3.1. Showing that fx k g is bounded can be done similarly to the proof of the Theorem in <ref> [5] </ref>, using Assumption A2 and the monotonical decrease on f . For the remainder of the proof, the only difference with what is done in [5] consists in showing that if t k hrf (x k ); d 0 k i converges to zero on a subsequence, then, on that same <p> Appendix Proof of Proposition 3.1. Showing that fx k g is bounded can be done similarly to the proof of the Theorem in <ref> [5] </ref>, using Assumption A2 and the monotonical decrease on f . For the remainder of the proof, the only difference with what is done in [5] consists in showing that if t k hrf (x k ); d 0 k i converges to zero on a subsequence, then, on that same subsequence, (i) t k d 0 k and (ii) kx k+1 x k k also converge to zero. (i) obviously holds in view of (3:1),
Reference: [6] <author> S. P. HAN, </author> <title> A Globally Convergent Method for Nonlinear Programming, </title> <journal> J. Op-tim. Theory Appl., </journal> <volume> 22 (1977), </volume> <pages> pp. </pages> <month> 297-309. </month> <title> [7] , Superlinear Convergence of a Minimax Method, </title> <institution> Department of Computer Science, Cornell University, TR78-336, </institution> <year> 1978. </year> <title> [8] , Variable Metric Methods for Minimizing a Class of Nondifferentiable Functions, </title> <journal> Math. Prog., </journal> <volume> 20 (1981), </volume> <pages> pp. 1-13. </pages>
Reference-contexts: In view of (2:1), we may also assume, without loss of generality, that the subsequence fH k g k2K converges to some symmetric positive definite matrix H fl . In that case, in view of the work in [4] (see also <ref> [6, Lemma 3.2] </ref>), the subsequence fd 0 k g k2K converges to a vector d 0fl . In order to conclude, we show that d 0fl = 0, so that, the feasible point x fl (limit of feasible iterates) is a KKT point for (P ).
Reference: [9] <author> W. HOCK AND K. SCHITTKOWSKI, </author> <title> Test Examples for Nonlinear Programming Codes, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems (187), </booktitle> <publisher> Springer Verlag, </publisher> <year> 1981. </year>
Reference-contexts: For the first set of problems, gradients were computed analytically; for the second set, they were computed by finite differences (for the ith component, the perturbation parameter was 10 7 maxf1; jx i k jg). Table 1 contains results obtained on test problems from <ref> [9] </ref>. The new algorithm (FSQP-NL) is compared to the algorithm analyzed in [15] (FSQP-AL), to the authors knowledge the best available "feasible iterate" algorithm. y It is observed that on all problems the number of nonlinear constraint evaluations is lower in FSQP-NL, often dramatically so. <p> Problems BARD down to MAD8 are unconstrained or linearly constrained minimax problems. Unable to find nonlinearly constrained minimax test problems in the literature, we constructed problems P43M through P117M from problems 43, 84, 113 and 117 in <ref> [9] </ref> by removing certain constraints and including instead additional objectives of the form f i (x) = f (x) + ff i g j (x) where the ff i 's are positive scalars and g j (x) 0: Specifically, P43M is constructed from problem 43 by taking out the first two
Reference: [10] <author> K. MADSEN AND H. SCHJR-JACOBSEN, </author> <title> Linearly Constrained Minimax Optimization, </title> <journal> Mathematical Programming, </journal> <volume> 14 (1978), </volume> <pages> pp. 208-223. </pages>
Reference-contexts: No significant difference is observed in the number of objective function evaluations. Results obtained on selected minimax problems are summarized in Table 2. Problems BARD, DAVD2, F&R, HETTICH, and WATS are from [18]; CB2, CB3, R-S, WONG and COLV are from [2; Examples 5.1-5]; MAD1 to MAD8 are from <ref> [10, Examples 1-8] </ref>. Some of these test problems allow one to freely select the number of variables; problems WATS-6 and WATS-20 correspond to 6 and 20 variables, respectively, and MAD8-10, MAD8-30 and MAD8-50 to 10, 30 and 50 variables respectively. <p> In Table 2, the performance of FSQP is also compared with that of the algorithms proposed in [3] (NM) and <ref> [10] </ref> (MS). To make such comparison meaningful, we attempted to best approximate the stopping rule used in each of the references.
Reference: [11] <author> N. MARATOS, </author> <title> Exact Penalty Function Algorithms for Finite Dimensional and Optimization Problems, </title> <type> Ph.D. Thesis, </type> <institution> Imperial College of Science and Technology, </institution> <address> London, U.K., </address> <year> 1978. </year>
Reference-contexts: mechanism to ensure that the full step of one is eventually taken, an imperative requirement if superlinear convergence is to take place. (The possible undesirable truncation of the step due to failure of the merit function to decrease when a full step is taken was first pointed out by Maratos <ref> [11] </ref>.) In particular the watchdog technique [1], by which the full step of one is tentatively accepted if sufficient decrease was obtained in recent iterations, is of no help here.
Reference: [12] <author> D. Q. MAYNE AND E. POLAK, </author> <title> A Superlinearly Convergent Algorithm for Constrained Optimization Problems, </title> <journal> Math. Programming Stud., </journal> <volume> 16 (1982), </volume> <pages> pp. 45-61. </pages>
Reference-contexts: In [13], [15], the issue is resolved by making use of a "bending" technique employed by Mayne and Polak <ref> [12] </ref>, suitably adapted for restoring feasibility. The appropriate amount of bending is determined via evaluation of the constraints at an auxiliary point at each iteration.

Reference: [17] <author> M. J. D. POWELL, </author> <title> A Fast Algorithm for Nonlinearly Constrained Optimization Calculations, in Numerical Analysis, </title> <note> Dundee, 1977, Lecture Notes in Mathematics 630, </note> <editor> G. A. Watson, ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1978, </year> <pages> pp. 144-157. </pages>
Reference-contexts: The initial Hessian approximation H 0 is taken to be the identity. H k is updated by means of the BFGS formula with Powell's modification <ref> [17] </ref>.
Reference: [18] <author> G. A. WATSON, </author> <title> The Minimax Solution of an Overdetermined System of Nonlinear Equations, </title> <journal> J. Inst. Math. Appl., </journal> <volume> 23 (1979), </volume> <pages> pp. </pages> <month> 167-180. </month> <title> avoiding the maratos effect part ii 15 </title>
Reference-contexts: No significant difference is observed in the number of objective function evaluations. Results obtained on selected minimax problems are summarized in Table 2. Problems BARD, DAVD2, F&R, HETTICH, and WATS are from <ref> [18] </ref>; CB2, CB3, R-S, WONG and COLV are from [2; Examples 5.1-5]; MAD1 to MAD8 are from [10, Examples 1-8].
Reference: [19] <author> J. ZHOU AND A. L. </author> <title> TITS, User's Guide for FSQP Version 2.0 A Fortran Code for Solving Optimization Problems, Possibly Minimax, with General Inequality Constraints and Linear Equality Constraints, Generating Feasible Iterates, </title> <institution> Systems Research Center, University of Maryland, SRC TR-90-60, College Park, MD 20742, </institution> <year> 1990. </year>
Reference-contexts: Numerical experiments. An efficient implementation of the algorithm de scribed in this paper has been completed (FSQP Version 2.0 <ref> [19] </ref>). In this implementation, given x, the direction d 1 (x) is defined to be the value of d 1 at which min d 2 is achieved, with = 3:0. <p> The FSQP code includes special provisions for efficient handling of affine constraints and it also accepts affine equality constraints. Such extensions are straightforward (see <ref> [19] </ref> for details). The extension to constrained minimax problems suggested in x4 is also implemented. avoiding the maratos effect part ii 11 Results on two sets of experiments are presented in Tables 1 and 2. All computations were performed on a Sun 4/SPARCstation 1. <p> This is especially true for the four nonlinearly constrained minimax problem (P43M to P117M) where the number of objective function evaluations and the number of constraint evaluations are both significantly lower with FSQP-NL. Second, y FSQP Version 2.0 <ref> [19] </ref> gives the user the option to select either FSQP-AL or FSQP-NL. 12 j. fr ed eric bonnans, eliane r. panier, andr e l. tits and jian zhou while our algorithm was not specifically designed for minimax problems, it compares well with pure minimax algorithms proposed by others. 6.
References-found: 14

