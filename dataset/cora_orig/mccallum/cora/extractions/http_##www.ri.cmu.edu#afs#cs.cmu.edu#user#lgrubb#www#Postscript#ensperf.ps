URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/lgrubb/www/Postscript/ensperf.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/lgrubb/www/useful.htm
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [Baird et. al., 1993] <author> B. Baird, D. Blevins, and N. Zahler. </author> <title> Artificial intelligence and music: implementing an interactive computer performer. </title> <journal> Computer Music Journal 17(2): </journal> <pages> 73-9, </pages> <year> 1993. </year>
Reference: [Bilmes, 1992] <author> J. Bilmes. </author> <title> A model for musical rhythm. </title> <booktitle> In Proceedings of the 1992 International Computer Music Conference, </booktitle> <pages> 207-10, </pages> <year> 1992. </year>
Reference-contexts: If the time difference is less than a pre-determined noise threshold, then only the accompaniment tempo is modified to agree with the ensemble tempo. The noise threshold prevents excessive jumping and tempo alterations, since performers do make subtle alterations in note placement <ref> [Bilmes, 1992] </ref>. If the performer is ahead of the accompaniment by a difference at least as great as the noise threshold, the accompaniment will either jump to the ensemble score position or play at an abnormally fast tempo to catch up.
Reference: [Bloch and Dannenberg, 1985] <author> J. Bloch and R. Dannenberg. </author> <title> Real-time computer accompaniment of keyboard performances. </title> <booktitle> In Proceedings of the 1985 International Computer Music Conference, </booktitle> <pages> 279-90, </pages> <year> 1985. </year>
Reference-contexts: By using a window centered around the expected score location, the work per performed note is further reduced to a constant. A more detailed presentation of the matchers algorithm can be found in <ref> [Bloch and Dannenberg, 1985] </ref>, which also shows how to modify this algorithm to handle polyphonic performance input (e.g., chord sequences played on a keyboard). A score position is posited for each performer on every note input received from that performer.
Reference: [Dannenberg, 1984] <author> R. Dannenberg. </author> <title> An on-line algorithm for real-time accompaniment. </title> <booktitle> In Proceedings of the 1984 International Computer Music Conference, </booktitle> <pages> 193-8, </pages> <year> 1984. </year>
Reference-contexts: It is based upon a system for accompanying solo performers previously described in <ref> [Dannenberg, 1984] </ref>. It assumes the availability of a score that has all parts explicitly and completely written out for all performers. The system extracts musical parameters from a per-formance represented by a sequence of MIDI messages.
Reference: [Dannenberg, 1993] <author> R. Dannenberg. </author> <title> The CMU MIDI Toolkit. </title> <institution> Pittsburgh, Carnegie Mellon University, </institution> <year> 1993. </year>
Reference-contexts: To prevent the accompaniment from continuing too far ahead of the performers, an input expectation point is maintained. If this point is passed without additional input from any performer, the accompaniment system pauses until additional input arrives. The ensemble performer is implemented using the CMU MIDI Toolkit <ref> [Dannenberg, 1993] </ref> which provides MIDI message handling, real-time scheduling, and performance of MIDI sequences. It is possible to adjust the position and tempo of a sequence (score) performance on-the-y as part of processing input or generating output.
Reference: [Dannenberg and Bookstein, 1991] <author> R. Dannenberg and K. Bookstein. </author> <title> Practical aspects of a MIDI conducting program. </title> <booktitle> In Proceedings of the 1991 International Computer Music Conference, </booktitle> <pages> 537-40, </pages> <year> 1991. </year>
Reference-contexts: Pre-performance analysis of the score may help the ensemble performer to develop appropriate performance expectations. Annotations in scores can provide useful performance hints to the scheduler <ref> [Dannenberg and Bookstein, 1991] </ref>. As a simple consideration, for example, if it is clear from the score that a particular per former should be inactive at present, then perhaps that performers estimates should be ignored.
Reference: [Desain and Honing, 1992] <author> P. Desain and H. Honing. </author> <title> Tempo curves considered harmful. In Music, Mind, and Machine: Studies in Computer Music, Music Cognition, </title> <booktitle> and Artificial Intelligence, </booktitle> <address> Amsterdam, </address> <publisher> Thesis Publishers, </publisher> <pages> 25-40, </pages> <year> 1992. </year>
Reference-contexts: This is accomplished by comparing actual time differences between performed events and expected time differences between corresponding score events. Since it is well-known that performers alter durations of notes for expressive purposes <ref> [Desain and Honing, 1992] </ref>, accompaniment systems must apply some method of averaging successive time difference comparisons to avoid sudden, drastic tempo changes. Conversely, this averaging must not be so extreme as to hinder the system from reacting to actual, expressive tempo changes initiated by the performers.
Reference: [Inoue et al., 1993] <author> W. Inoue, S. Hashimoto, and S. Ohteru. </author> <title> A computer music system for human singing. </title> <booktitle> In Proceedings of the 1993 International Computer Music Conference, </booktitle> <pages> 150-3, </pages> <year> 1993. </year>
Reference-contexts: For performances from different instruments, the system may need to track different parameters. In the case of tracking vocal performances, information about phonemes can be useful, as might syllables or words if they can be reliably recognized <ref> [Inoue et al., 1993] </ref>. The performance detection and representation task is common to all accompaniment systems, whether they accompany soloists or ensembles, either by playing from a pre-composed score or by improvising. The second task of an accompaniment system is tracking the score position of performers in real-time.
Reference: [Kashino and Tanaka, 1993] <author> K. Kashino and H. Tanaka. </author> <title> A sound source separation system with the ability of automatic tone modeling. </title> <booktitle> In Proceedings of the 1993 International Computer Music Conference, </booktitle> <pages> 248-55, </pages> <year> 1993. </year>
Reference-contexts: A yet more difficult case is to distinguish multiple instruments recorded with a single microphone <ref> [Kashino and Tanaka, 1993] </ref>. For performances from different instruments, the system may need to track different parameters. In the case of tracking vocal performances, information about phonemes can be useful, as might syllables or words if they can be reliably recognized [Inoue et al., 1993].
Reference: [Mecca, 1993] <author> M. Mecca. </author> <title> Tempo following behavior in musical accompaniment. </title> <type> Masters thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference-contexts: Once the ensemble player has calculated ensemble score position and tempo estimates, it applies a set of accompaniment rules to adjust the accompaniment performance. These rules correspond to studies of how live accompanists react to similar situations encountered during a performance <ref> [Mecca, 1993] </ref>. The rules con-sider the time difference between the ensemble score position and the current accompaniment score position. If the time difference is less than a pre-determined noise threshold, then only the accompaniment tempo is modified to agree with the ensemble tempo.
Reference: [Vercoe, 1984] <author> B. Vercoe. </author> <title> The synthetic performer in the context of live performance. </title> <booktitle> In Proceedings of the 1984 International Computer Music Conference, </booktitle> <pages> 199-200, </pages> <year> 1984. </year>
Reference: [Vercoe and Puckette, 1985] <author> B. Vercoe and M. Puckette. </author> <title> Synthetic rehearsal: training the synthetic performer. </title> <booktitle> In Proceedings of the 1985 International Computer Music Conference, </booktitle> <pages> 275-78, </pages> <year> 1985. </year>
Reference-contexts: Automating this type of analysis process would, however, require significant musical knowledge pertinent to interpreting scores and performer actions. Alternatively, we are also interested in experimenting with learning through rehearsal, possibly by using techniques similar in philosophy to those presented in <ref> [Vercoe and Puckette, 1985] </ref>. Ideally, an accompaniment system should be able to improve by practicing a piece with an ensemble and noting where to expect consistent tempo changes, embellishment, or performer error.
References-found: 12

