URL: http://www.cs.umd.edu/users/bultan/papers/jpdc92.ps
Refering-URL: http://www.cs.umd.edu/users/bultan/publications-abstracts.html
Root-URL: 
Title: A NEW MAPPING HEURISTIC BASED ON MEAN FIELD ANNEALING 1  
Author: Tevfik Bultan and Cevdet Aykanat 
Note: 1 This work is partially supported by Intel Supercomputer Systems Division under Grant SSD100791-2 and Turkish Science and Research Council under Grant EEEAG-5.  
Address: 06533 Bilkent, Ankara, Turkey  
Affiliation: Department of Computer Engineering and Information Science, Bilkent University,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Arora, R. K., and Rana, S. P., </author> <title> Heuristic algorithms for process assignment in distributed computing systems. </title> <journal> Information Processing Letters, </journal> <volume> vol. 11, no. </volume> <pages> 4-5, pp. 199-203, </pages> <year> 1980. </year>
Reference-contexts: The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer.
Reference: [2] <author> Aykanat, C., Ozguner, F., Er~cal, F., and Sadayappan, P. </author> <title> Iterative algorithms for solution of large sparse systems of linear equations on hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 37, no. 12, </volume> <pages> pp. 1554-1567, </pages> <year> 1988. </year>
Reference-contexts: However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications <ref> [2, 20] </ref> and power system simulations [3, 16], and VLSI simulation programs [22] are represented by TIGs. In this paper, problems which can be represented by the TIG model are addressed.
Reference: [3] <author> Behnam-Guilani, K. </author> <title> Fast decoupled load flow: the hybrid model. </title> <journal> IEEE Transactions on Power Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 734-739, </pages> <year> 1988. </year> <month> 30 </month>
Reference-contexts: However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications [2, 20] and power system simulations <ref> [3, 16] </ref>, and VLSI simulation programs [22] are represented by TIGs. In this paper, problems which can be represented by the TIG model are addressed. In order to solve the mapping problem, parallel architecture must also be modeled in a way that represents its architectural features.
Reference: [4] <author> Bokhari, S. H. </author> <title> On the mapping problem. </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. 30, no. 3, </volume> <pages> pp. 207-214, </pages> <year> 1981. </year>
Reference-contexts: Second step is mapping each one of these tasks to an individual processor of the parallel architecture in such a way that the total execution time is minimized. The second step, named as the mapping problem <ref> [4] </ref>, is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem [1, 4, 7, 12, 13, 21]. <p> The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer.
Reference: [5] <author> Bultan, T., and Aykanat, C. </author> <title> Parallel mean field algorithms for the solution of combinatorial optimization problems. </title> <booktitle> Proc. ICANN-91, </booktitle> <volume> vol. 1, </volume> <pages> pp. 591-596, </pages> <year> 1991. </year>
Reference-contexts: It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> This method was first proposed for solving the traveling salesperson problem [23] and then it is applied to the graph partitioning problem <ref> [5, 6, 17, 25] </ref>. Here, general formulation of the MFA algorithm [25] is given for the sake of completeness.
Reference: [6] <author> Bultan, T., and Aykanat, C. </author> <title> Circuit Partitioning Using Parallel Mean Field Annealing Algorithms. </title> <booktitle> Proc. 3rd IEEE Symposium on Parallel Processing, </booktitle> <year> 1991. </year>
Reference-contexts: It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> This method was first proposed for solving the traveling salesperson problem [23] and then it is applied to the graph partitioning problem <ref> [5, 6, 17, 25] </ref>. Here, general formulation of the MFA algorithm [25] is given for the sake of completeness.
Reference: [7] <author> Er~cal, F., Ramanujam, J., and Sadayappan, P. </author> <title> Task allocation onto a hypercube by recursive mincut bipartitioning. </title> <journal> J. Parallel Distrib. Comput. </journal> <volume> vol. 10, </volume> <pages> pp. 35-44, </pages> <year> 1990. </year>
Reference-contexts: The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer. <p> In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem [1, 4, 7, 12, 13, 21]. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase <ref> [7] </ref>. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer. In two phase approaches, clustering phase is followed by one-to-one mapping phase. <p> In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem <ref> [7, 19, 21, 22] </ref>. Heuristics proposed to solve the mapping problem are compute intensive. Solving the mapping problem can be considered as a preprocessing performed before the execution of the parallel program on the parallel computer.
Reference: [8] <author> Fiduccia, C. M., and Mattheyses, R. M. </author> <title> A linear heuristic for improving network partitions. </title> <booktitle> Proc. Design Automat. Conf., </booktitle> <pages> pp. 175-181, </pages> <year> 1982. </year>
Reference-contexts: The problem solved in the clustering phase is identical to the multi-way graph partitioning problem. In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) <ref> [8, 14] </ref> and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem [7, 19, 21, 22]. Heuristics proposed to solve the mapping problem are compute intensive. <p> These K clusters are then mapped to PCG using a one-to-one mapping heuristic in the second phase. One-to-one mapping heuristic used in this work is a variant of the KL heuristic. For the clustering phase, Kernighan-Lin heuristic is implemented efficiently as described by Fiduccia and Mattheyses <ref> [8] </ref>. Two different schemes are utilized to apply KL to K-way graph partitioning. First scheme, partitioning by recursive bisection (KL-RB), recursively partitions the initial graph into two partitions until K partitions are obtained.
Reference: [9] <author> Hopfield, J. J., and Tank, D. W. </author> <title> `Neural' Computation of Decisions in Optimization Problems. </title> <journal> Biolog. Cybern., </journal> <volume> vol. 52, </volume> <pages> pp. 141-152, </pages> <year> 1985. </year>
Reference-contexts: Computational loads of the processors are CL p = 3 for 1 p 4. Hence, perfect load balance is achieved, since ( i=1 w i )=4 = 3. 3 Mean Field Annealing Mean Field Annealing (MFA) merges collective computation and annealing properties of Hop-field Neural Networks (HNN) <ref> [9, 10, 11] </ref> and Simulated Annealing (SA) [15], respectively, to obtain a general algorithm for solving combinatorial optimization problems. HNN is used for 8 solving various optimization problems and reasonable results are obtained for small size prob-lems [9]. <p> HNN is used for 8 solving various optimization problems and reasonable results are obtained for small size prob-lems <ref> [9] </ref>. However, simulations of this network reveals the fact that it is hard to obtain feasible solutions for large problem sizes. Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN [18, 23, 24, 25]. In the MFA algorithm, problem representation is identical to HNN <ref> [9, 23, 24] </ref>, but iterative scheme used to relax the system is different. MFA can be used for solving a combinatorial optimization problem by choosing a representation scheme in which the final states of the spins can be decoded as a solution to the target problem.
Reference: [10] <author> Hopfield, J. J., and Tank, D. W. </author> <title> Computing with neural circuits: a model. </title> <journal> Science, </journal> <volume> Vol. 233, </volume> <pages> pp. 625-633, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Computational loads of the processors are CL p = 3 for 1 p 4. Hence, perfect load balance is achieved, since ( i=1 w i )=4 = 3. 3 Mean Field Annealing Mean Field Annealing (MFA) merges collective computation and annealing properties of Hop-field Neural Networks (HNN) <ref> [9, 10, 11] </ref> and Simulated Annealing (SA) [15], respectively, to obtain a general algorithm for solving combinatorial optimization problems. HNN is used for 8 solving various optimization problems and reasonable results are obtained for small size prob-lems [9].
Reference: [11] <author> Hopfield, J. J., and Tank, D. W. </author> <title> Collective computation in neuronlike circuits, </title> <journal> Scientific American, </journal> <volume> vol. 257, no. 6, </volume> <pages> pp. 104-114, </pages> <year> 1987. </year>
Reference-contexts: Computational loads of the processors are CL p = 3 for 1 p 4. Hence, perfect load balance is achieved, since ( i=1 w i )=4 = 3. 3 Mean Field Annealing Mean Field Annealing (MFA) merges collective computation and annealing properties of Hop-field Neural Networks (HNN) <ref> [9, 10, 11] </ref> and Simulated Annealing (SA) [15], respectively, to obtain a general algorithm for solving combinatorial optimization problems. HNN is used for 8 solving various optimization problems and reasonable results are obtained for small size prob-lems [9].
Reference: [12] <author> Indurkhya, B., Stone H. S., and Xi-Cheng, L. </author> <title> Optimal partitioning of randomly generated distributed programs. </title> <journal> IEEE Trans. Software Engrg., </journal> <volume> vol. 12, no. 3, </volume> <pages> pp. 483-495, </pages> <year> 1986. </year>
Reference-contexts: The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard <ref> [12, 13] </ref>. Hence, heuristics giving sub-optimal solutions are used to solve the problem [1, 4, 7, 12, 13, 21]. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. <p> The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer.
Reference: [13] <author> Kasahara, H., and Narita, S. </author> <title> Practical multiprocessor scheduling algorithms for efficient parallel processing. </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. 33, no. 11, </volume> <pages> pp. 1023-1029, </pages> <year> 1984. </year>
Reference-contexts: The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard <ref> [12, 13] </ref>. Hence, heuristics giving sub-optimal solutions are used to solve the problem [1, 4, 7, 12, 13, 21]. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. <p> The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer. <p> Hence, weights can be associated with the vertices in order to denote the computational costs of the corresponding tasks. Two different models, Task Precedence Graph (TPG) and Task Interaction Graph (TIG), are used for modeling static task interaction patterns <ref> [13, 20] </ref>. TPG is a directed graph where directed edges represent execution dependencies. Each edge denotes a pair of tasks; source and destination. The destination task can only be executed after the completion of the execution of the source task.
Reference: [14] <author> Kernighan, B. W., and Lin, S. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell Syst. Tech. J., </journal> <volume> vol. 49, </volume> <pages> pp. 291-307, </pages> <year> 1970. </year>
Reference-contexts: The problem solved in the clustering phase is identical to the multi-way graph partitioning problem. In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) <ref> [8, 14] </ref> and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem [7, 19, 21, 22]. Heuristics proposed to solve the mapping problem are compute intensive.
Reference: [15] <author> Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> vol. 220, </volume> <pages> pp. 671-680, </pages> <year> 1983. </year>
Reference-contexts: The problem solved in the clustering phase is identical to the multi-way graph partitioning problem. In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) <ref> [15] </ref> heuristics are two attractive algorithms widely used for solving the mapping problem [7, 19, 21, 22]. Heuristics proposed to solve the mapping problem are compute intensive. Solving the mapping problem can be considered as a preprocessing performed before the execution of the parallel program on the parallel computer. <p> Hence, perfect load balance is achieved, since ( i=1 w i )=4 = 3. 3 Mean Field Annealing Mean Field Annealing (MFA) merges collective computation and annealing properties of Hop-field Neural Networks (HNN) [9, 10, 11] and Simulated Annealing (SA) <ref> [15] </ref>, respectively, to obtain a general algorithm for solving combinatorial optimization problems. HNN is used for 8 solving various optimization problems and reasonable results are obtained for small size prob-lems [9].
Reference: [16] <author> Lee, S. Y., Chiang, H. D., Lee, K. G., and Ku, B. Y. </author> <title> Parallel power system transient stability analysis on hypercube multiprocessors. </title> <journal> IEEE Transactions on Power Systems, </journal> <volume> vol. 6, no. 3, </volume> <pages> pp. 1337-1343. 31 </pages>
Reference-contexts: However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications [2, 20] and power system simulations <ref> [3, 16] </ref>, and VLSI simulation programs [22] are represented by TIGs. In this paper, problems which can be represented by the TIG model are addressed. In order to solve the mapping problem, parallel architecture must also be modeled in a way that represents its architectural features.
Reference: [17] <author> Peterson, C., and Anderson, J. R. </author> <title> Neural networks and NP-complete optimization prob-lems; a performance study on the graph bisection problem. </title> <journal> Complex Syst. </journal> <volume> vol. 2, </volume> <pages> pp. 59-89, </pages> <year> 1988. </year>
Reference-contexts: It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> This method was first proposed for solving the traveling salesperson problem [23] and then it is applied to the graph partitioning problem <ref> [5, 6, 17, 25] </ref>. Here, general formulation of the MFA algorithm [25] is given for the sake of completeness.
Reference: [18] <author> Peterson, C., and Soderberg, B. </author> <title> A new method for mapping optimization problems onto neural networks. </title> <journal> Int. J. Neural Syst., </journal> <volume> vol. 1, no. 3, </volume> <year> 1989. </year>
Reference-contexts: Efficient parallel mapping heuristics are needed in such cases. The KL and SA heuristics are inherently sequential, hence hard to parallelize. Efficient parallelizations of these algorithms remain as important issues in parallel processing research. In this work, a recently proposed algorithm, called Mean Field Annealing (MFA) <ref> [18, 24, 25] </ref> is formulated for the many-to-one mapping problem. MFA combines the collective computation property of Hopfield Neural Networks (HNN) with the annealing notion of SA. It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. <p> It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN <ref> [18, 23, 24, 25] </ref>. In the MFA algorithm, problem representation is identical to HNN [9, 23, 24], but iterative scheme used to relax the system is different. <p> At each temperature, iterations continue until H &lt; * for L consecutive iterations where L = N initially. Parameter * is chosen to be 0:5. Cooling process is realized in two phases; slow cooling followed by fast cooling, similar to the cooling schedules used for SA <ref> [18] </ref>. In the slow cooling phase, temperature is decreased using ff = 0:9 until T is less than T 0 =1:5. Then, in the fast cooling phase, L is set to L=4 and ff is set to 0:5 and cooling is continued until T is less then T 0 =5:0. <p> Acceptance probabilities of the moves that increase the cost are controlled with a temperature parameter T which is decreased using an annealing schedule. Hence, as the annealing proceeds acceptance probabilities of uphill moves decrease. An automatic cooling schedule is used in the implementation of the SA algorithm <ref> [18] </ref>. 5.4 Experimental Results In this section, performance of the MFA algorithm is discussed in comparison with the SA and KL algorithms. These heuristics are experimented by mapping randomly generated TIGs onto mesh and hypercube connected multicomputers. Six test TIGs are generated with N = 200 and 400 vertices.
Reference: [19] <author> Ramanujam, J., Er~cal, F., and Sadayappan, P. </author> <title> Task allocation by simulated annealing. </title> <booktitle> Proc. International Conference on Supercomputing. </booktitle> <address> Boston, MA, </address> <month> May </month> <year> 1988, </year> <title> vol. </title> <booktitle> III, Hardware & Software, </booktitle> <pages> pp. 475-497. </pages>
Reference-contexts: In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem <ref> [7, 19, 21, 22] </ref>. Heuristics proposed to solve the mapping problem are compute intensive. Solving the mapping problem can be considered as a preprocessing performed before the execution of the parallel program on the parallel computer.
Reference: [20] <author> Sadayappan, P., and Er~cal, </author> <title> F.Nearest-neighbour mapping of finite element graphs onto processor meshes. </title> <journal> IEEE Trans. Comput. </journal> <volume> vol. 36, no. 12, </volume> <pages> pp. 1408-1424, </pages> <year> 1987. </year>
Reference-contexts: Hence, weights can be associated with the vertices in order to denote the computational costs of the corresponding tasks. Two different models, Task Precedence Graph (TPG) and Task Interaction Graph (TIG), are used for modeling static task interaction patterns <ref> [13, 20] </ref>. TPG is a directed graph where directed edges represent execution dependencies. Each edge denotes a pair of tasks; source and destination. The destination task can only be executed after the completion of the execution of the source task. <p> TIG usually represents the repeated execution of the tasks with intervening task interactions denoted by the edges. The TIG model may seem to be unrealistic for general applications since it does not consider the temporal interaction dependencies among the tasks <ref> [20] </ref>. However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications [2, 20] and power system simulations [3, 16], and VLSI simulation programs [22] are represented by TIGs. <p> However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications <ref> [2, 20] </ref> and power system simulations [3, 16], and VLSI simulation programs [22] are represented by TIGs. In this paper, problems which can be represented by the TIG model are addressed.
Reference: [21] <author> Sadayappan, P.,Er~cal, F., and Ramanujam, J. </author> <title> Cluster partitioning approaches to mapping parallel programs onto a hypercube. </title> <journal> Parallel Computing. </journal> <volume> vol. 13, </volume> <pages> pp. 1-16, </pages> <year> 1990. </year>
Reference-contexts: The second step, named as the mapping problem [4], is very crucial in designing efficient parallel programs. In general, the mapping problem is known to be NP-hard [12, 13]. Hence, heuristics giving sub-optimal solutions are used to solve the problem <ref> [1, 4, 7, 12, 13, 21] </ref>. Two distinct approaches have been considered in the context of mapping heuristics; one phase and two phase [7]. In one phase approaches, referred as many-to-one mapping, tasks of the parallel program are directly mapped onto the processors of the multicomputer. <p> In two phase approaches, clustering phase is followed by one-to-one mapping phase. In the clustering phase, tasks of the parallel program are partitioned into as many equal weighted clusters as the number of processors of the multicomputer, while minimizing the total weight of the interactions 3 among clusters <ref> [21] </ref>. The problem solved in the clustering phase is identical to the multi-way graph partitioning problem. In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. <p> minimizing the total weight of the interactions 3 among clusters <ref> [21] </ref>. The problem solved in the clustering phase is identical to the multi-way graph partitioning problem. In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem [7, 19, 21, 22]. Heuristics proposed to solve the mapping problem are compute intensive. <p> In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem <ref> [7, 19, 21, 22] </ref>. Heuristics proposed to solve the mapping problem are compute intensive. Solving the mapping problem can be considered as a preprocessing performed before the execution of the parallel program on the parallel computer.
Reference: [22] <author> Shield, J. </author> <title> Partitioning concurrent VLSI simulation programs onto a multiprocessor by simulated annealing. </title> <booktitle> IEEE Proc. Part G, </booktitle> <volume> vol. 134, no. 1, </volume> <pages> pp. 24-28, </pages> <year> 1987. </year>
Reference-contexts: In the one-to-one mapping phase, each cluster is assigned to an individual processor of the multicomputer such that the total inter-processor communication is minimized [21]. Kernighan-Lin (KL) [8, 14] and Simulated Annealing (SA) [15] heuristics are two attractive algorithms widely used for solving the mapping problem <ref> [7, 19, 21, 22] </ref>. Heuristics proposed to solve the mapping problem are compute intensive. Solving the mapping problem can be considered as a preprocessing performed before the execution of the parallel program on the parallel computer. <p> However, there are various classes of problems which can be successfully modeled with the TIG model. For example, iterative solution of systems of equations arising in finite element applications [2, 20] and power system simulations [3, 16], and VLSI simulation programs <ref> [22] </ref> are represented by TIGs. In this paper, problems which can be represented by the TIG model are addressed. In order to solve the mapping problem, parallel architecture must also be modeled in a way that represents its architectural features.
Reference: [23] <author> Van den Bout, D. E., and Miller, T. K. </author> <title> A Traveling Salesman Objective Function That Works. </title> <booktitle> IEEE Int. Conf. Neural Nets, </booktitle> <volume> vol. 2, </volume> <pages> pp. 299-303, </pages> <year> 1988. </year>
Reference-contexts: MFA combines the collective computation property of Hopfield Neural Networks (HNN) with the annealing notion of SA. It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN <ref> [23] </ref>. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA [5, 6, 17, 18, 24, 25] show that it can be successfully applied to various combinatorial optimization problems. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN <ref> [18, 23, 24, 25] </ref>. In the MFA algorithm, problem representation is identical to HNN [9, 23, 24], but iterative scheme used to relax the system is different. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN [18, 23, 24, 25]. In the MFA algorithm, problem representation is identical to HNN <ref> [9, 23, 24] </ref>, but iterative scheme used to relax the system is different. MFA can be used for solving a combinatorial optimization problem by choosing a representation scheme in which the final states of the spins can be decoded as a solution to the target problem. <p> The MFA algorithm is derived by making an analogy to Ising spin model which is used to estimate the state of a system of particles or spins in thermal equilibrium. This method was first proposed for solving the traveling salesperson problem <ref> [23] </ref> and then it is applied to the graph partitioning problem [5, 6, 17, 25]. Here, general formulation of the MFA algorithm [25] is given for the sake of completeness. <p> It is assumed that fi kl = fi lk and fi kk = 0 for 1 k; l; S. At thermal equilibrium, spin average hs k i of spin k can be calculated using Boltzmann distribution as follows <ref> [23] </ref> hs k i = 1 + e k =T (4) Here, k = hH (s)ij s k =0 hH (s)ij s k =1 represents the mean field effecting on spin k, where the energy average hH (s)i of the system is hH (s)i = k=1 l6=k S X h k
Reference: [24] <author> Van den Bout, D. E., and Miller, T. K. </author> <title> Improving the performance of the Hopfield-Tank neural network through normalization and annealing. </title> <journal> Biolog. Cybern., </journal> <volume> vol. 62, </volume> <pages> pp. 129-139, </pages> <year> 1989. </year>
Reference-contexts: Efficient parallel mapping heuristics are needed in such cases. The KL and SA heuristics are inherently sequential, hence hard to parallelize. Efficient parallelizations of these algorithms remain as important issues in parallel processing research. In this work, a recently proposed algorithm, called Mean Field Annealing (MFA) <ref> [18, 24, 25] </ref> is formulated for the many-to-one mapping problem. MFA combines the collective computation property of Hopfield Neural Networks (HNN) with the annealing notion of SA. It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. <p> It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN <ref> [18, 23, 24, 25] </ref>. In the MFA algorithm, problem representation is identical to HNN [9, 23, 24], but iterative scheme used to relax the system is different. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN [18, 23, 24, 25]. In the MFA algorithm, problem representation is identical to HNN <ref> [9, 23, 24] </ref>, but iterative scheme used to relax the system is different. MFA can be used for solving a combinatorial optimization problem by choosing a representation scheme in which the final states of the spins can be decoded as a solution to the target problem. <p> HNN and SA have a major difference; SA is an algorithm implemented in software, whereas HNN is derived with a possible hardware implementation in mind. MFA is somewhere in between, it is an algorithm implemented in software, having potential for hardware realization <ref> [24, 25] </ref>. In this work MFA is treated as a software algorithm. <p> Each row update of the spin matrix is referred as a single iteration of the algorithm. The system is observed after each spin-row update in order to detect the convergence to an equilibrium state for a given temperature <ref> [24] </ref>. If energy function H does not decrease after a certain number of consecutive spin-row updates, this means that the system is stabilized for that temperature [24]. Then, T is decreased according to the cooling schedule, and iteration process is re-initiated. <p> The system is observed after each spin-row update in order to detect the convergence to an equilibrium state for a given temperature <ref> [24] </ref>. If energy function H does not decrease after a certain number of consecutive spin-row updates, this means that the system is stabilized for that temperature [24]. Then, T is decreased according to the cooling schedule, and iteration process is re-initiated. Note that, the computation of the energy difference H necessitates the computation of H (Eq. (8)) at each iteration.
Reference: [25] <author> Van den Bout, D. E., and Miller, T. K. </author> <title> Graph partitioning using annealed neural networks. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 192-203, </pages> <year> 1990. </year> <month> 32 </month>
Reference-contexts: Efficient parallel mapping heuristics are needed in such cases. The KL and SA heuristics are inherently sequential, hence hard to parallelize. Efficient parallelizations of these algorithms remain as important issues in parallel processing research. In this work, a recently proposed algorithm, called Mean Field Annealing (MFA) <ref> [18, 24, 25] </ref> is formulated for the many-to-one mapping problem. MFA combines the collective computation property of Hopfield Neural Networks (HNN) with the annealing notion of SA. It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. <p> It is originally proposed for solving traveling salesperson problem, as a working alternative to HNN [23]. MFA is also a general strategy as SA, and can be applied to different problems with suitable formulations. Previous works on MFA <ref> [5, 6, 17, 18, 24, 25] </ref> show that it can be successfully applied to various combinatorial optimization problems. MFA has the inherent parallelism that exists in most of the neural network algorithms. Section 2 presents a formal definition of the mapping problem by modeling parallel program design process. <p> Hence, the algorithm does not have a good scaling property, which is a very important performance criterion for heuristic optimization algorithms. MFA is proposed as a successful alternative to HNN <ref> [18, 23, 24, 25] </ref>. In the MFA algorithm, problem representation is identical to HNN [9, 23, 24], but iterative scheme used to relax the system is different. <p> This method was first proposed for solving the traveling salesperson problem [23] and then it is applied to the graph partitioning problem <ref> [5, 6, 17, 25] </ref>. Here, general formulation of the MFA algorithm [25] is given for the sake of completeness. <p> This method was first proposed for solving the traveling salesperson problem [23] and then it is applied to the graph partitioning problem [5, 6, 17, 25]. Here, general formulation of the MFA algorithm <ref> [25] </ref> is given for the sake of completeness. <p> (s)ij s k =0 hH (s)ij s k =1 represents the mean field effecting on spin k, where the energy average hH (s)i of the system is hH (s)i = k=1 l6=k S X h k hs k i (5) The complexity of computing k using Eq. (5) is exponential <ref> [25] </ref>. However, for large number 9 1. Get the initial temperature T 0 , and set T = T 0 2. Initialize the spin averages hsi = [hs 1 i; : : : ; hs k i; : : : ; hs S i] 3. <p> HNN and SA have a major difference; SA is an algorithm implemented in software, whereas HNN is derived with a possible hardware implementation in mind. MFA is somewhere in between, it is an algorithm implemented in software, having potential for hardware realization <ref> [24, 25] </ref>. In this work MFA is treated as a software algorithm.
References-found: 25

