URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/kluwer.ps
Refering-URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/fsqp.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: FEASIBLE SEQUENTIAL QUADRATIC PROGRAMMING FOR FINELY DISCRETIZED PROBLEMS FROM SIP  
Author: Craig T. Lawrence and Andre L. Tits 
Address: College Park College Park, Maryland 20742 USA  
Affiliation: Department of Electrical Engineering and Institute for Systems Research University of Maryland,  
Abstract: A Sequential Quadratic Programming algorithm designed to efficiently solve nonlinear optimization problems with many inequality constraints, e.g. problems arising from finely discretized Semi-Infinite Programming, is described and analyzed. The key features of the algorithm are (i) that only a few of the constraints are used in the QP sub-problems at each iteration, and (ii) that every iterate satisfies all constraints. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. C. Biggs. </author> <title> Constrained minimization using recursive equality quadratic programming. </title> <editor> In F. A. Lootsma, editor, </editor> <booktitle> Numerical Methods for NonLinear Optimization, </booktitle> <pages> pages 411-428. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: 1 INTRODUCTION Consider the Semi-Infinite Programming (SIP) problem minimize f (x) subject to (x) 0; (SI) where f : IR n ! IR is continuously differentiable, and : IR n ! IR is defined by ~2 [0;1] with : IR n fi <ref> [0; 1] </ref> ! IR continuously differentiable in the first argument. For an excellent survey of the theory behind the problem (SI), in addition to some algorithms and applications, see [9] as well as the other papers in the present volume. <p> Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of <ref> [0; 1] </ref> (see, e.g. [5, 7, 8, 16, 18, 19, 20, 23]). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set. <p> 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of <ref> [0; 1] </ref> (see, e.g. [5, 7, 8, 16, 18, 19, 20, 23]). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set. For example, given q 2 IN, one could use the uniform discretization ffi = 0; q q 1 ; 1 : Clearly these algorithms are crucially dependent upon being able to efficiently solve problem (DSI). <p> For an excellent recent survey of SQP algorithms, see [2]. A number of attempts at applying the SQP scheme to problems with a large number of constraints, e.g. our discretized problem from SIP, have been documented in the literature. In <ref> [1] </ref>, Biggs treats all active inequality constraints as equality constraints in the QP sub-problem, while ignoring all constraints which are not active. Polak and Tits [20], and Mine et al. [14], apply to the SQP framework an *-active scheme similar to that used in [19]. <p> iterates are to remain in the feasible set, following [17], an essentially arbitrary feasible descent direction d 1 k is computed and the search direction is taken to be the convex combination d k = (1 k )d 0 k : The coefficient k = (d 0 k ) 2 <ref> [0; 1] </ref> goes to zero fast enough, as x k approaches a solution, to ensure the fast convergence rate of the standard SQP scheme is preserved. An Armijo-type line search is then performed along the direction d k , yielding a step-size t k 2 (0; 1]. <p> Thus, at iteration k, the search direction d k is taken as a convex combination of d 0 k , i.e. d k = (1 k )d 0 k , k 2 <ref> [0; 1] </ref>. In order to guarantee a fast local rate of convergence while providing a suitably feasible search direction, we require the coefficient of the convex combination k = (d 0 k ) to satisfy certain properties. Namely, () : IR n ! [0; 1] must satisfy 8 Chapter 1 (d <p> k )d 0 k , k 2 <ref> [0; 1] </ref>. In order to guarantee a fast local rate of convergence while providing a suitably feasible search direction, we require the coefficient of the convex combination k = (d 0 k ) to satisfy certain properties. Namely, () : IR n ! [0; 1] must satisfy 8 Chapter 1 (d 0 ) is bounded away from zero outside every neighborhood of zero, and (d 0 ) = O (kd 0 k 2 ): For example, we could take (d 0 ) = minf1; kd 0 k - g, where - 2. <p> Since QP 1 (x; ^ ffi) is convex, (d 1 ; fl) is also its unique KKT point. Boundedness of d 1 (x; ^ ffi) over bounded subsets of X follows from the first equation of the optimality conditions (1.3), noting that the QP multipliers must all lie in <ref> [0; 1] </ref>. Now suppose d 1 = 0. Since x 2 X, it is clear that fl = 0. Substitute d 1 = 0 and fl = 0 into (1.3) and let 1 2 IR and 1 2 IR j ^ ffij be the corresponding multipliers. <p> Boundedness of fd 1 k g follows from Lemma 2 and boundedness of fx k g. Since k 2 <ref> [0; 1] </ref>, fd k g is bounded as well. Finally, suppose ft k d k g 6! 0. Then there exists an infinite index set K IN such that t k d k is bounded away from zero on K. <p> Furthermore, since t k d k is bounded away from zero on K, there exists t &gt; 0 such that t k t for all k 2 K, and since ft k g is bounded (t k 2 <ref> [0; 1] </ref>), it follows that either d 0;fl 6= 0 or d 1;fl 6= 0. Applying Lemmas 1 and 2 in both directions shows that x fl is not a KKT point for (DSI) and both d 0;fl 6= 0 and d 1;fl 6= 0.
Reference: [2] <author> P. T. Boggs and J. W. Tolle. </author> <title> Sequential quadratic programming. </title> <journal> Acta Numerica, </journal> <pages> pages 1-51, </pages> <year> 1995. </year>
Reference-contexts: In such algorithms, quadratic programs (QPs) are used as models to construct the search direction. For an excellent recent survey of SQP algorithms, see <ref> [2] </ref>. A number of attempts at applying the SQP scheme to problems with a large number of constraints, e.g. our discretized problem from SIP, have been documented in the literature.
Reference: [3] <author> I. D. Coope and G. A. Watson. </author> <title> A projected lagrangian algorithm for semi-infinite programming. </title> <journal> Math. Programming, </journal> <volume> 32 </volume> <pages> 337-356, </pages> <year> 1985. </year>
Reference-contexts: We report the numerical results for 13 discretized SIP test problems with dis-cretization levels of 101 and 501. A uniform discretization was used in all cases. Problems cw 3, cw 5, and cw 6 are borrowed from <ref> [3] </ref>. Problems oet 1 through oet 7 are from [15]. Finally, hz 1 is from [10] and sch 3 is from [26].
Reference: [4] <author> J. W. Daniel. </author> <title> Stability of the solution of definite quadratic programs. </title> <journal> Math. Programming, </journal> <volume> 5 </volume> <pages> 41-53, </pages> <year> 1973. </year>
Reference-contexts: It follows that the solution d 0 is well-defined and the unique KKT point for the QP. As the set H is uniformly positive definite, continuity in x and H for fixed ^ ffi is a direct consequence of Theorem 4.4 in <ref> [4] </ref>. Now suppose d 0 is 0 and let f 0 ~ j ~ 2 ^ ffi g be the QP multipliers.
Reference: [5] <author> C. Gonzaga and E. Polak. </author> <title> On constraint dropping schemes and optimality functions for a class of outer approximation algorithms. </title> <journal> SIAM J. Control Optim., </journal> <volume> 17 </volume> <pages> 477-493, </pages> <year> 1979. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set.
Reference: [6] <author> C. Gonzaga, E. Polak, and R. Trahan. </author> <title> An improved algorithm for optimization problems with functional inequality constraints. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-25:49-54, </volume> <year> 1980. </year>
Reference-contexts: In the implementation, heuristics are applied to add potentially useful elements to ffi k (see, e.g. [26] for a discussion of such heuristics). In the case of discretized SIP, one may wish to exploit the knowledge that adjacent discretization points are likely to be closely related. Following <ref> [27, 16, 6] </ref>, for some * &gt; 0, the cfsqp implementation includes in ffi k the set ffi ``m * (x k ) of *-active "left local maximizers" at x k .
Reference: [7] <author> S. A. Gustafson. </author> <title> A three-phase algorithm for semi-infinite programs. </title> <editor> In A. V. Fiacco and K. O. Kortanek, editors, </editor> <booktitle> Semi-Infinite Programming FSQP for Finely Discretized SIP 29 and Applications, Lecture Notes in Control and Information Sciences 215, </booktitle> <pages> pages 138-157. </pages> <publisher> Springer Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set.
Reference: [8] <author> R. Hettich. </author> <title> An implementation of a discretization method for semi-infinite programming. </title> <journal> Math. Programming, </journal> <volume> 34 </volume> <pages> 354-361, </pages> <year> 1986. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set.
Reference: [9] <author> R. Hettich and K. O. Kortanek. </author> <title> Semi-infinite programming: theory, methods, </title> <journal> and applications. SIAM Rev., </journal> <volume> 35 </volume> <pages> 380-429, </pages> <year> 1993. </year>
Reference-contexts: For an excellent survey of the theory behind the problem (SI), in addition to some algorithms and applications, see <ref> [9] </ref> as well as the other papers in the present volume. Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. [5, 7, 8, 16, 18, 19, 20, 23]).
Reference: [10] <author> R. Hettich and P. Zencke. </author> <title> Numerische Methoden der Approximation und Semi-Infiniten Optimierung. </title> <publisher> Teubner Studienbucher Mathematik, </publisher> <address> Stuttgart, Germany, </address> <year> 1982. </year>
Reference-contexts: A uniform discretization was used in all cases. Problems cw 3, cw 5, and cw 6 are borrowed from [3]. Problems oet 1 through oet 7 are from [15]. Finally, hz 1 is from <ref> [10] </ref> and sch 3 is from [26]. In all cases except for oet 7, the initial guess x 0 is the same as that given 5 In the numerical experiments reported here, t k remained bounded away from 0.
Reference: [11] <author> K. C. Kiwiel. </author> <title> Methods of Descent in Nondifferentiable Optimization, </title> <booktitle> Lecture Notes in Mathematics No. </booktitle> <volume> 1183. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: However, if the discretization is very fine, such an approach may still produce sub-problems with an unduly large number of constraints. It was shown in [16] that, by means of a scheme inspired by the bundle-type methods of nondifferentiable optimization (see, e.g. <ref> [11, 13] </ref>), the number of constraints used in the sub-problems can be further reduced without jeopardizing global convergence. Specifically, in [16], the constraints to be used in the computation of the search direction d k+1 at iteration k + 1 are chosen as follows.
Reference: [12] <author> C. T. Lawrence, J. L. Zhou, and A. L. </author> <title> Tits. User's Guide for CFSQP Version 2.4: A C Code for Solving (Large Scale) Constrained Nonlinear (Minimax) Optimization Problems, Generating Iterates Satisfying All Inequality Constraints, 1996. </title> <institution> ISR TR-94-16r1, Institute for Systems Research, University of Maryland (College Park, MD). </institution>
Reference-contexts: Otherwise, obtain a new symmetric positive definite estimate H k+1 to the Hessian of the Lagrangian. (v). Set k k + 1 and go back to Step 1. 22 Chapter 1 5 IMPLEMENTATION AND NUMERICAL RESULTS Algorithm FSQP-MOC has been implemented as part of the code cfsqp 3 <ref> [12] </ref>. The numerical test results reported in this section were obtained with a modified copy of cfsqp Version 2.4 (the relevant changes will be included in subsequent releases, beginning with Version 2.5). All test problems we consider here are instances of (DSI).
Reference: [13] <author> C. </author> <title> Lemarechal. Nondifferentiable optimization. </title> <editor> In G. Nemhauser, A. Rinooy-Kan, and M. Todd, editors, </editor> <booktitle> Optimization, Handbooks in Operations Research and Management Science. </booktitle> <publisher> Elsevier Science, North Holland, </publisher> <year> 1989. </year>
Reference-contexts: However, if the discretization is very fine, such an approach may still produce sub-problems with an unduly large number of constraints. It was shown in [16] that, by means of a scheme inspired by the bundle-type methods of nondifferentiable optimization (see, e.g. <ref> [11, 13] </ref>), the number of constraints used in the sub-problems can be further reduced without jeopardizing global convergence. Specifically, in [16], the constraints to be used in the computation of the search direction d k+1 at iteration k + 1 are chosen as follows.
Reference: [14] <author> H. Mine, M. Fukushima, and Y. Tanaka. </author> <title> On the use of *-most active constraints in an exact penalty function method for nonlinear optimization. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-29:1040-1042, </volume> <year> 1984. </year>
Reference-contexts: In [1], Biggs treats all active inequality constraints as equality constraints in the QP sub-problem, while ignoring all constraints which are not active. Polak and Tits [20], and Mine et al. <ref> [14] </ref>, apply to the SQP framework an *-active scheme similar to that used in [19]. Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in [22].
Reference: [15] <author> K. Oettershagen. </author> <title> Ein Superlinear Konvergenter Algorithmus zur Losung Semi-Infiniter Optimierungsprobleme. </title> <type> PhD thesis, </type> <institution> Bonn University, </institution> <year> 1982. </year>
Reference-contexts: We report the numerical results for 13 discretized SIP test problems with dis-cretization levels of 101 and 501. A uniform discretization was used in all cases. Problems cw 3, cw 5, and cw 6 are borrowed from [3]. Problems oet 1 through oet 7 are from <ref> [15] </ref>. Finally, hz 1 is from [10] and sch 3 is from [26]. In all cases except for oet 7, the initial guess x 0 is the same as that given 5 In the numerical experiments reported here, t k remained bounded away from 0.
Reference: [16] <author> E. R. Panier and A. L. </author> <title> Tits. A globally convergent algorithm with adaptively refined discretization for semi-infinite optimization problems arising in engineering design. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-34(8):903-908, </volume> <year> 1989. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set. <p> A scheme which exploits this fact by cleverly using an appropriate small subset of the constraints at each step should, in most cases, enjoy substantial savings in computational effort without sacrificing global and local convergence properties. Early efforts at employing such a scheme appear in <ref> [19, 16] </ref> in the context of first order methods of feasible directions. In [19], at iteration k, a search direction is computed based on the method of Zoutendijk [28] using only the gradients of those constraints satisfying (x k ; ~) *, where * &gt; 0 is small. <p> Clearly, close to a solution, such "*-active" constraints are sufficient to ensure convergence. However, if the discretization is very fine, such an approach may still produce sub-problems with an unduly large number of constraints. It was shown in <ref> [16] </ref> that, by means of a scheme inspired by the bundle-type methods of nondifferentiable optimization (see, e.g. [11, 13]), the number of constraints used in the sub-problems can be further reduced without jeopardizing global convergence. Specifically, in [16], the constraints to be used in the computation of the search direction d <p> It was shown in <ref> [16] </ref> that, by means of a scheme inspired by the bundle-type methods of nondifferentiable optimization (see, e.g. [11, 13]), the number of constraints used in the sub-problems can be further reduced without jeopardizing global convergence. Specifically, in [16], the constraints to be used in the computation of the search direction d k+1 at iteration k + 1 are chosen as follows. Let ffi k ffi be the set of constraints used to compute the search direction d k , and let x k+1 be the next iterate. <p> While the former is obviously needed to ensure that d k is a feasible direction, it is argued in <ref> [16] </ref> that the latter two are necessary to avoid zig-zagging or other jamming phenomena. The number of constraints required to compute the search direction is thus typically small compared to jffij, hence each iteration of such a method is com-putationally less costly. <p> The number of constraints required to compute the search direction is thus typically small compared to jffij, hence each iteration of such a method is com-putationally less costly. Unfortunately, for a fixed level of discretization, the algorithms in <ref> [19, 16] </ref> converge at best at a linear rate. Sequential Quadratic Programming (SQP)-type algorithms exhibit fast local convergence and are well-suited for problems in which the number of variables is not too large but the evaluation of objective/constraint functions and their gradients is costly. <p> In practice, the algorithm in [26] may or may not converge, dependent upon the heuristics applied to choose the constraints for the QP sub-problem. In this paper, the scheme introduced in <ref> [16] </ref> in the context of first-order feasible direction methods is extended to the SQP framework, specifically, the Feasible SQP (FSQP) framework introduced in [17] (the qualifier "feasible" signifies that all iterates x k satisfy the constraints, i.e. (x k ; ~) 0; for all ~ 2 ffi). <p> The next iterate is taken to be x k+1 = x k + t k d k . Finally, H k is updated yielding H k+1 , and a new constraint index set ffi k+1 is constructed following the ideas of <ref> [16] </ref>. As is pointed out in [27], the construction of [16] cannot be used meaningfully in the SQP framework without modifying the update rule for the new metric H k+1 . The reason is as follows. As noted above, following [16], if t k &lt; 1, ffi k+1 is to include, <p> Finally, H k is updated yielding H k+1 , and a new constraint index set ffi k+1 is constructed following the ideas of <ref> [16] </ref>. As is pointed out in [27], the construction of [16] cannot be used meaningfully in the SQP framework without modifying the update rule for the new metric H k+1 . The reason is as follows. As noted above, following [16], if t k &lt; 1, ffi k+1 is to include, among others, the index ~ 2 ffi of a constraint <p> index set ffi k+1 is constructed following the ideas of <ref> [16] </ref>. As is pointed out in [27], the construction of [16] cannot be used meaningfully in the SQP framework without modifying the update rule for the new metric H k+1 . The reason is as follows. As noted above, following [16], if t k &lt; 1, ffi k+1 is to include, among others, the index ~ 2 ffi of a constraint which was infeasible for the last trial point in the line search. 1 The rationale for including ~ in ffi k+1 is that if ~ had been in ffi k <p> Such reasoning is clearly justified in the context of first-order search directions as is used in <ref> [16] </ref>, but it is not clear that ~ is the right constraint to include under the new metric H k+1 . <p> If this is not done, convergence is not ensured and a "zig zagging" phenomenon as discussed in <ref> [16] </ref> could result. As a final matter on the update rule for ffi k , following [27], we allow for additional constraint indices to be added to the set ffi k . While not necessary for global convergence, cleverly choosing additional constraints can significantly improve performance, especially in early iterations. <p> It remains to explicitly specify the key feature of the proposed algorithm: the update rule for ffi k . As discussed above, following <ref> [16] </ref>, ffi k+1 will include (in addition to possible heuristics) three crucial components. The first one is the set ffi act (x k+1 ) of indices of active constraints at the new iterate. <p> The price to be paid is the introduction of Assumption 5 below for proving Theorem 1. The proof of the following result is inspired by that of Theorem T in <ref> [16] </ref>. Proposition 1 lim inf k 16 Chapter 1 Corollary 1 There exists an accumulation point x fl of fx k g which is a KKT point for (DSI). <p> In the implementation, heuristics are applied to add potentially useful elements to ffi k (see, e.g. [26] for a discussion of such heuristics). In the case of discretized SIP, one may wish to exploit the knowledge that adjacent discretization points are likely to be closely related. Following <ref> [27, 16, 6] </ref>, for some * &gt; 0, the cfsqp implementation includes in ffi k the set ffi ``m * (x k ) of *-active "left local maximizers" at x k .
Reference: [17] <author> E. R. Panier and A. L. </author> <title> Tits. On combining feasibility, descent and super-linear convergence in inequality constrained optimization. </title> <journal> Math. Programming, </journal> <volume> 59 </volume> <pages> 261-276, </pages> <year> 1993. </year>
Reference-contexts: In this paper, the scheme introduced in [16] in the context of first-order feasible direction methods is extended to the SQP framework, specifically, the Feasible SQP (FSQP) framework introduced in <ref> [17] </ref> (the qualifier "feasible" signifies that all iterates x k satisfy the constraints, i.e. (x k ; ~) 0; for all ~ 2 ffi). Our presentation and analysis significantly borrow from [27], where an important special case of (DSI) is considered, the unconstrained minimax problem. <p> Note that d 0 k may not be a feasible search direction, as required in the FSQP context, but that at worst it is tangent to the feasible set. Since all iterates are to remain in the feasible set, following <ref> [17] </ref>, an essentially arbitrary feasible descent direction d 1 k is computed and the search direction is taken to be the convex combination d k = (1 k )d 0 k : The coefficient k = (d 0 k ) 2 [0; 1] goes to zero fast enough, as x k <p> It is well-known in the SQP context that the line search could truncate the step size arbitrarily close to a solution (the so-called Maratos effect), thus preventing superlinear convergence. Various schemes have been devised to overcome such a situation. We will argue that a second-order correction, as used in <ref> [17] </ref>, will overcome the Maratos effect without sacrificing global convergence. The balance of the paper is organized as follows. In Section 2 we introduce the algorithm and present some preliminary material. Next, in Section 3, we give a complete convergence analysis of the algorithm proposed in Section 2. <p> In the subsequent analysis we assume that d 1 is chosen specifically as the solution of QP 1 (x; ^ ffi), though it can be shown that the results still hold if some minor variation is used. To be precise, following <ref> [17] </ref>, we require that d 1 = d 1 (x; ^ ffi) satisfy: d 1 (x; ^ ffi) = 0 if x is a KKT point, hrf (x); d 1 (x; ^ ffi)i &lt; 0 if x is not a KKT point, hr x (x; ~); d 1 (x; ^ ffi)i <p> Finally, since ffi act (x) ^ ffi, (1.7) and (1.8) follow from Proposition 3.1 in <ref> [17] </ref>. 2 FSQP for Finely Discretized SIP 11 Lemma 2 For all x 2 X, and ^ ffi ffi such that ffi act (x) ^ ffi, the direction d 1 = d 1 (x; ^ ffi) is well-defined and the pair (d 1 ; fl), where fl = fl (x; ^ <p> Several techniques have been introduced to avoid the so-called Maratos effect. We chose to include a second order correction such as that used in <ref> [17] </ref>. <p> Hence, it is established that for k large enough, the modified algorithm FSQP-MC behaves identically to that given in <ref> [17] </ref>, applied to (P fl ). Assumption 1 is now further strengthened and a new assumption concerning the Hessian approximations H k is given. These assumptions allow us to use the local convergence rate result from [17]. <p> for k large enough, the modified algorithm FSQP-MC behaves identically to that given in <ref> [17] </ref>, applied to (P fl ). Assumption 1 is now further strengthened and a new assumption concerning the Hessian approximations H k is given. These assumptions allow us to use the local convergence rate result from [17]. Assumption 1 00 : The functions f : IR n ! IR, and (; ~) : IR n ! IR, ~ 2 ffi, are three times continuously differentiable. <p> In the tables, the implementation of FSQP-MOC just discussed is denoted NEW. A simple *-active strategy was employed in the algorithm we call *-ACT, i.e. we set ffi k = ffi * (x k ) for all k, where * = 0:1. The standard FSQP scheme of <ref> [17] </ref> was applied in algorithm FULL by simply setting ffi k = ffi, for all k. All three algorithms were set to stop when kd 0 k k 1 fi 10 4 .
Reference: [18] <author> E. Polak and L. </author> <title> He. Rate preserving discretization strategies for semi-infinite programming and optimal control. </title> <booktitle> In Proceedings of the 29th Conference on Decision and Control, </booktitle> <month> December </month> <year> 1990. </year> <note> 30 Chapter 1 </note>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set.
Reference: [19] <author> E. Polak and D. Q. Mayne. </author> <title> An algorithm for optimization problems with functional inequality constraints. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-21:184-193, </volume> <year> 1976. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set. <p> A scheme which exploits this fact by cleverly using an appropriate small subset of the constraints at each step should, in most cases, enjoy substantial savings in computational effort without sacrificing global and local convergence properties. Early efforts at employing such a scheme appear in <ref> [19, 16] </ref> in the context of first order methods of feasible directions. In [19], at iteration k, a search direction is computed based on the method of Zoutendijk [28] using only the gradients of those constraints satisfying (x k ; ~) *, where * &gt; 0 is small. <p> Early efforts at employing such a scheme appear in [19, 16] in the context of first order methods of feasible directions. In <ref> [19] </ref>, at iteration k, a search direction is computed based on the method of Zoutendijk [28] using only the gradients of those constraints satisfying (x k ; ~) *, where * &gt; 0 is small. Clearly, close to a solution, such "*-active" constraints are sufficient to ensure convergence. <p> The number of constraints required to compute the search direction is thus typically small compared to jffij, hence each iteration of such a method is com-putationally less costly. Unfortunately, for a fixed level of discretization, the algorithms in <ref> [19, 16] </ref> converge at best at a linear rate. Sequential Quadratic Programming (SQP)-type algorithms exhibit fast local convergence and are well-suited for problems in which the number of variables is not too large but the evaluation of objective/constraint functions and their gradients is costly. <p> In [1], Biggs treats all active inequality constraints as equality constraints in the QP sub-problem, while ignoring all constraints which are not active. Polak and Tits [20], and Mine et al. [14], apply to the SQP framework an *-active scheme similar to that used in <ref> [19] </ref>. Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in [22]. Finally, in [26], Schittkowski proposes another modification of the SQP scheme for problems with many constraints, but does not prove convergence.
Reference: [20] <author> E. Polak and A. L. </author> <title> Tits. A recursive quadratic programming algorithm for semi-infinite optimization problems. </title> <journal> Appl. Math. Optim., </journal> <volume> 8 </volume> <pages> 325-349, </pages> <year> 1982. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set. <p> In [1], Biggs treats all active inequality constraints as equality constraints in the QP sub-problem, while ignoring all constraints which are not active. Polak and Tits <ref> [20] </ref>, and Mine et al. [14], apply to the SQP framework an *-active scheme similar to that used in [19]. Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in [22].
Reference: [21] <author> M. J. D. Powell. </author> <title> A fast algorithm for nonlinearly constrained optimization calculations. </title> <editor> In G. A. Watson, editor, </editor> <title> Numerical Analysis, Dundee, </title> <booktitle> 1977, Lecture Notes in Mathematics 630, </booktitle> <pages> pages 144-157. </pages> <publisher> Springer Verlag, </publisher> <year> 1978. </year>
Reference-contexts: The matrices H k are updated using the BFGS formula with Powell's modification <ref> [21] </ref>. The multiplier estimates used for the updates are those obtained from QP 0 (x k ; H k ; ffi k ), with all multipliers corresponding to discretization points outside of ffi k set to zero.
Reference: [22] <author> M. J. D. Powell. </author> <title> A tolerant algorithm for linearly constrained optimization calculations. </title> <journal> Math. Programming, </journal> <volume> 45 </volume> <pages> 547-566, </pages> <year> 1989. </year>
Reference-contexts: Polak and Tits [20], and Mine et al. [14], apply to the SQP framework an *-active scheme similar to that used in [19]. Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in <ref> [22] </ref>. Finally, in [26], Schittkowski proposes another modification of the SQP scheme for problems with many constraints, but does not prove convergence. In practice, the algorithm in [26] may or may not converge, dependent upon the heuristics applied to choose the constraints for the QP sub-problem.
Reference: [23] <author> R. Reemtsen. </author> <title> Discretization methods for the solution of semi-infinite programming problems. </title> <journal> J. Optim. Theory Appl., </journal> <volume> 71 </volume> <pages> 85-103, </pages> <year> 1991. </year>
Reference-contexts: Many globally convergent algorithms designed to solve (SI) 1 2 Chapter 1 rely on approximating (x) by using progressively finer discretizations of [0; 1] (see, e.g. <ref> [5, 7, 8, 16, 18, 19, 20, 23] </ref>). Specifically, such algorithms generate a sequence of problems of the form minimize f (x) subject to (x; ~) 0; 8~ 2 ffi; (DSI) where ffi [0; 1] is a (presumably large) finite set.
Reference: [24] <author> S. M. Robinson. </author> <title> Perturbed Kuhn-Tucker points and rates of convergence for a class of nonlinear-programming algorithms. </title> <journal> Math. Programming, </journal> <volume> 7 </volume> <pages> 1-16, </pages> <year> 1974. </year>
Reference: [25] <author> K. Schittkowski. </author> <title> QLD: A Fortran Code for Quadratic Programming, User's Guide. </title> <institution> Mathematisches Institut, Universitat Bayreuth, Germany, </institution> <year> 1986. </year>
Reference-contexts: The QP sub-problems were solved using the routine QLD due to Powell and Schittkowski <ref> [25] </ref>. Finally, the following parameter values were used for all numerical testing: ff = 0:1, fi = 0:5, * = 1, and ffi was set to the square root of the machine precision.
Reference: [26] <author> K. Schittkowski. </author> <title> Solving nonlinear programming problems with very many constraints. </title> <type> Technical Report No. 294, </type> <institution> Mathematisches Institut, Univer-sitat Bayreuth, Germany, </institution> <year> 1991. </year>
Reference-contexts: Polak and Tits [20], and Mine et al. [14], apply to the SQP framework an *-active scheme similar to that used in [19]. Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in [22]. Finally, in <ref> [26] </ref>, Schittkowski proposes another modification of the SQP scheme for problems with many constraints, but does not prove convergence. In practice, the algorithm in [26] may or may not converge, dependent upon the heuristics applied to choose the constraints for the QP sub-problem. <p> Similar to the *-active idea, Powell proposes a "tolerant" algorithm for linearly constrained problems in [22]. Finally, in <ref> [26] </ref>, Schittkowski proposes another modification of the SQP scheme for problems with many constraints, but does not prove convergence. In practice, the algorithm in [26] may or may not converge, dependent upon the heuristics applied to choose the constraints for the QP sub-problem. <p> Of course, there is a trade-off between speeding up initial convergence and increasing (i) the number of gradient evaluations and (ii) the size of the QPs. In the implementation, heuristics are applied to add potentially useful elements to ffi k (see, e.g. <ref> [26] </ref> for a discussion of such heuristics). In the case of discretized SIP, one may wish to exploit the knowledge that adjacent discretization points are likely to be closely related. <p> A uniform discretization was used in all cases. Problems cw 3, cw 5, and cw 6 are borrowed from [3]. Problems oet 1 through oet 7 are from [15]. Finally, hz 1 is from [10] and sch 3 is from <ref> [26] </ref>. In all cases except for oet 7, the initial guess x 0 is the same as that given 5 In the numerical experiments reported here, t k remained bounded away from 0. FSQP for Finely Discretized SIP 25 in the reference from which the problem was taken.
Reference: [27] <author> J. L. Zhou and A. L. </author> <title> Tits. An SQP algorithm for finely discretized continuous minimax problems and other minimax problems with many objective functions. </title> <journal> SIAM J. on Optimization, </journal> <pages> pages 461-487, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Our presentation and analysis significantly borrow from <ref> [27] </ref>, where an important special case of (DSI) is considered, the unconstrained minimax problem. <p> The next iterate is taken to be x k+1 = x k + t k d k . Finally, H k is updated yielding H k+1 , and a new constraint index set ffi k+1 is constructed following the ideas of [16]. As is pointed out in <ref> [27] </ref>, the construction of [16] cannot be used meaningfully in the SQP framework without modifying the update rule for the new metric H k+1 . The reason is as follows. <p> Such reasoning is clearly justified in the context of first-order search directions as is used in [16], but it is not clear that ~ is the right constraint to include under the new metric H k+1 . To overcome this difficulty, it is proposed in <ref> [27] </ref> that H k not be updated whenever t k &lt; ffi, ffi a prescribed small positive number, and ~ 62 ffi k . We will show in Section 3 that, as is the case for the minimax algorithm of [27], for k large enough, ~ will always be in ffi <p> To overcome this difficulty, it is proposed in <ref> [27] </ref> that H k not be updated whenever t k &lt; ffi, ffi a prescribed small positive number, and ~ 62 ffi k . We will show in Section 3 that, as is the case for the minimax algorithm of [27], for k large enough, ~ will always be in ffi k , thus normal updating will take place eventually, preserving the local convergence rate properties of the SQP scheme. <p> There is an important additional complication, with the update of ffi k , which was not present in the minimax case considered in <ref> [27] </ref>. As just pointed out, any ~ 2 ffi k which affected the search direction is to be included in ffi k+1 . In [27] (unconstrained minimax problem) this is accomplished by including those objectives whose multipliers are non-zero in the QP used to compute the search 1 Assuming that it <p> There is an important additional complication, with the update of ffi k , which was not present in the minimax case considered in <ref> [27] </ref>. As just pointed out, any ~ 2 ffi k which affected the search direction is to be included in ffi k+1 . In [27] (unconstrained minimax problem) this is accomplished by including those objectives whose multipliers are non-zero in the QP used to compute the search 1 Assuming that it was a constraint, and not the objective function, which caused a failure in the line search. <p> If this is not done, convergence is not ensured and a "zig zagging" phenomenon as discussed in [16] could result. As a final matter on the update rule for ffi k , following <ref> [27] </ref>, we allow for additional constraint indices to be added to the set ffi k . While not necessary for global convergence, cleverly choosing additional constraints can significantly improve performance, especially in early iterations. <p> Otherwise, obtain a new symmetric positive definite estimate H k+1 to the Hessian of the Lagrangian. (v). Set k k + 1 and go back to Step 1. 3 CONVERGENCE ANALYSIS While there are some critical differences, the analysis in this section closely parallels that of <ref> [27] </ref>. We begin by establishing that, under a few additional assumptions, algorithm FSQP-MC generates a sequence which converges to a KKT point for (DSI). <p> This result is, in fact, weaker than that obtained in <ref> [27] </ref> for the unconstrained minimax case, where under similar assumptions, but with a more involved argument, it is shown that all accumu lation points are KKT. The price to be paid is the introduction of Assumption 5 below for proving Theorem 1. <p> Further, the sequence fx k g converges to x fl 2-step superlinearly, i.e. lim kx k+2 x fl k = 0: 4 EXTENSION TO CONSTRAINED MINIMAX The algorithm we have discussed may be extended following the scheme of <ref> [27] </ref> to handle problems with many objective functions, i.e. large-scale constrained minimax. <p> In order to describe the update rules for k , following <ref> [27] </ref>, we define a few index sets for the objectives (in direct analogy with the index sets for the constraints as introduced in Section 2). <p> Accordingly, in <ref> [27] </ref>, b k is defined based on a single set of multipliers. <p> In the implementation, heuristics are applied to add potentially useful elements to ffi k (see, e.g. [26] for a discussion of such heuristics). In the case of discretized SIP, one may wish to exploit the knowledge that adjacent discretization points are likely to be closely related. Following <ref> [27, 16, 6] </ref>, for some * &gt; 0, the cfsqp implementation includes in ffi k the set ffi ``m * (x k ) of *-active "left local maximizers" at x k .

References-found: 27

