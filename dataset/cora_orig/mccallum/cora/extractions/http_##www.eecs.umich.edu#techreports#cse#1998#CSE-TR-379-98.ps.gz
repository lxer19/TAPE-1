URL: http://www.eecs.umich.edu/techreports/cse/1998/CSE-TR-379-98.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse98.html
Root-URL: http://www.eecs.umich.edu
Title: Ensuring Reasoning Consistency in Hierarchical Architectures  
Author: by Robert E. Wray, III Associate Professor Edmund H. Durfee Randolph M. Jones 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science and Engineering) in The  Doctoral Committee: Associate Professor John E. Laird, Chair  Associate Professor Robert K. Lindsay  
Note: Assistant Research Scientist  
Date: 1998  
Affiliation: University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agre, P. E. and Chapman, D. </author> <year> (1987). </year> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 196-201, </pages> <address> Seattle, Washington. </address>
Reference: <author> Agre, P. E. and Horswill, I. </author> <year> (1997). </year> <title> Lifeworld analysis. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 6 </volume> <pages> 111-145. </pages>
Reference-contexts: If Theo needed to put out a fire in the kitchen and went into the basement to get a fire extinguisher, it would forget about the fire because it no longer sensed the fire. Although there has been some research in structuring the external environment to provide persistent memory <ref> (Agre and Horswill, 1997) </ref>, internal, persistent memory is necessary for many agent domains. Consider three reasons. First, as we saw above, agents sometimes need to "remember" an external situation or stimulus, even when that perception is no longer available. Second, some assertions may need to reflect hypothetical states.
Reference: <author> Almasi, G. S. and Gottlieb, A. </author> <year> (1989). </year> <title> Highly Parallel Computing. </title> <address> Benjamin/Cummings, Redwood City, California. </address>
Reference: <author> Anderson, J. R. </author> <year> (1987). </year> <title> Skill acquisition: Compilation of weak-method problem solutions. </title> <journal> Psychological Review, </journal> <volume> 94(2) </volume> <pages> 192-210. </pages>
Reference: <author> Bonasso, R. P., Firby, R. J., Gat, E., Kortenkamp, D., Miller, D. P., and Slack, M. G. </author> <year> (1997). </year> <title> Experiences with an architecture for intelligent, reactive agents. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 9(1). </volume>
Reference-contexts: There are currently many different implemented agent architectures and certainly more unexplored ways of building them. The 3T architecture is one instance of these many architectures, having been used primarily in mobile robot domains <ref> (Bonasso et al., 1997) </ref>. The 3T architecture consists of three layers or "tiers," with a specific planner (Elsaesser and Slack, 1994), scheduler (Firby, 1987), and controller (Yu et al., 1994) comprising each tier.
Reference: <author> Bresina, J., Drummond, M., and Kedar, S. </author> <year> (1993). </year> <title> Reactive, integrated systems pose new problems for machine learning. </title> <editor> In Minton, S., editor, </editor> <title> Machine Learning Methods for Planning, </title> <booktitle> chapter 6, </booktitle> <pages> pages 159-195. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Hierarchical task decomposition has been used in a great number of execution systems, including the Adaptive Intelligent Systems architecture (Hayes-Roth, 1990), ATLANTIS (Gat, 1991), Cypress (Wilkins et al., 1995), the Entropy Reduction Engine <ref> (Bresina et al., 1993) </ref>, the New Millennium Remote Agent (Pell et al., 1996), the Procedural Reasoning System (Georgeff and Lansky, 1987; Lee et al., 1994), RAPS (Firby, 1987), Soar (Laird et al., 1987; Laird and Rosenbloom, 1990), and Theo (Mitchell, 1990; Mitchell et al., 1991), among others. <p> The same approach can be used to ensure reasoning consistency in a hierarchical agent by formulating explicit domain knowledge that recognizes potential inconsistencies and responds by removing assumptions. We call this approach knowledge-based assumption consistency (KBAC). For example, the Entropy Reduction Engine (ERE) <ref> (Bresina et al., 1993) </ref> relies on knowledge-based assumption consistency. ERE requires domain constraints, or knowledge that describes the physics of the task domain. Domain constraints identify impossible conditions. For instance, a domain constraint could indicate that an agent cannot occupy two different physical locations simultaneously. <p> Domain constraints identify impossible conditions. For instance, a domain constraint could indicate that an agent cannot occupy two different physical locations simultaneously. In ERE, domain constraints are specifically used "to maintain consistency in the current world model state during execution" <ref> (Bresina et al., 1993, pp. 166) </ref>. However, we believe that many other architectures use KBAC as well (either solely, or in conjunction with other methods we describe below). The use of KBAC explains why this problem 32 has not been previously examined. <p> Because the compilation of non-contemporaneous constraints arises from inconsistency due to persistence, we expect that any of the approaches we described in Chapter 3 will avoid the problem (including, of course, Dynamic Hierarchical Justification). For example, neither Theo (Mitchell et al., 1991) nor ERE <ref> (Bresina et al., 1993) </ref> suffer from non-contemporaneous constraints in learned rules. Theo never creates persistent assumptions. Thus, the hierarchy never contains assertions derived in a context nonmonotonic to the current one and compilation is not problematic.
Reference: <author> Brooks, F. P. </author> <year> (1995). </year> <title> The Mythical Man-Month; Essays on Software Engineering, Anniversary Edition. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: This curve is based solely on intuitions provided by the advantages we outlined above and we will not try to empirically validate this hypothesis in the dissertation. In general, metrics used in software engineering provide only rough approximations of engineering effort, (e.g., person hours, source lines of code <ref> (Brooks, 1995) </ref>) and the complexity of tasks usually varies along many dimensions, as we described above. However, the important point from this diagram is that as the complexity of a task increases, so does the engineering effort necessary to implement a task.
Reference: <author> Brooks, R. A. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal on Robotics and Automation, RA-2(1):14-22. </journal>
Reference: <author> Byrne, M. D. and Bovair, S. </author> <year> (1997). </year> <title> A working memory model of a common procedural error. </title> <journal> Cognitive Science, </journal> <volume> 21 </volume> <pages> 31-61. </pages>
Reference-contexts: The information and biases in the knowledge would be the strong determiners of behavior, rather than the underlying manipulation processes. However, some details of the architecture have changed under GOHHC and may have some implication for psychological modeling. As one example, consider post-completion 123 errors <ref> (Byrne and Bovair, 1997) </ref>. Post-completion errors are errors in behavior that arise when a goal is completed but some cleanup is necessary following the achievement of the goal. For example, when making a photocopy, one might forget to retrieve the original along with the copy.
Reference: <author> Carbonell, J. G., Knoblock, C. A., and Minton, S. </author> <year> (1991). </year> <title> PRODIGY: An integrated architecture for planning and learning. </title> <editor> In VanLehn, K., editor, </editor> <booktitle> Architectures for Intelligence, chapter 9, </booktitle> <pages> pages 241-278. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Explanation-based learning (EBL) approaches have used this goal regression technique to operationalize problem solving knowledge in a number of domain classes including concept formation (DeJong and Mooney, 1986; Mitchell et al., 1986), planning (Fikes et al., 1972; Minton, 1988) and scheduling <ref> (Carbonell et al., 1991) </ref>. EBL uses a domain theory to generate an explanation of why some training instance is an example of a goal concept according to some operationality criterion (DeJong and Mooney, 1986).
Reference: <author> Chapman, D. </author> <year> (1987). </year> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32(3) </volume> <pages> 333-377. </pages>
Reference-contexts: This example is based on the Blocks World domain familiar from planning <ref> (Chapman, 1987) </ref>. 5 Rather than form a plan about how blocks should be moved, in this example an agent must actually move blocks in a simulated world to build towers, walls, etc.
Reference: <author> Chien, S. A., Gervasio, M. T., and DeJong, G. F. </author> <year> (1991). </year> <title> On becoming decreasingly reactive: Learning to deliberate minimally. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 288-292, </pages> <address> Evanston, Illinois. </address> <note> 132 Cox, </note> <author> B. J. </author> <year> (1986). </year> <title> Object-Oriented Programming: An Evolutionary Approach. </title> <publisher> Addison--Wesley. </publisher>
Reference: <author> Dechter, R. </author> <year> (1990). </year> <title> Enhancement schemes for constraint processing: Backjumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> 41 </volume> <pages> 273-312. </pages>
Reference-contexts: For instance, in constraint satisfaction problems, the backjumping algorithm identifies which variable assignments are related to other variable assignments via the constraints specified in the problem definition. When a violation is discovered, the algorithm backtracks to the most recent, related variable <ref> (Dechter, 1990) </ref>. Intervening variable assignments are discarded. In DHJ, when an assertion in the hierarchy changes, the system "backjumps" to the highest level in the hierarchy for which the changed assertion is not dependent.
Reference: <author> DeJong, G. and Bennett, S. </author> <year> (1995). </year> <title> Extending classical planning to real-world execution with machine learning. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1153-1159, </pages> <address> Montreal, Canada. </address>
Reference: <author> DeJong, G. and Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176. </pages>
Reference-contexts: EBL uses a domain theory to generate an explanation of why some training instance is an example of a goal concept according to some operationality criterion <ref> (DeJong and Mooney, 1986) </ref>. In execution domains, the goal concepts for EBL are the situations in which each primitive operation should be generated in the current external state, where the current external state is defined by the available percepts and task goals.
Reference: <author> Doorenbos, R. B. </author> <year> (1993). </year> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 290-296. </pages>
Reference-contexts: The addition of new knowledge, especially by an automatic process such as compilation, can increase the cost of knowledge search for individual pieces of knowledge such that knowledge search is more expensive than problem search (i.e., the decomposition) in a smaller knowledge base. This average growth effect <ref> (Doorenbos, 1993) </ref> is a specialized case of the well-known utility problem (Minton, 1988). We require that the agent's reasoning not slow down significantly as the number of rules in the agent increases. <p> For example, the conditions from Rule 2 are included in the compiled rule because the pick-up goal contributed to the execution of the step-right primitive. Of course, there is a non-zero "bookkeeping" cost for mapping conditions to productions when creating new production instantiations. However, <ref> (Doorenbos, 1993) </ref> shows that for RETE (and thus Soar), the number of compiled productions must grow several orders of magnitude to see appreciable utility problems from this effect.
Reference: <author> Doorenbos, R. B. </author> <year> (1994). </year> <title> Combining left and right unlinking for matching a large number of learned rules. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, WA. </address>
Reference-contexts: The RETE algorithm, which we have discussed in previous chapters, provides one example of current rule matching that technology can support such a requirement <ref> (Doorenbos, 1994) </ref>. Preserves Correctness: Execution during and after compilation on a given task must be as proficient as the same system without learning. This goal requires a com-putationally inexpensive compilation algorithm, as discussed above, and a compilation process that preserves correctness.
Reference: <author> Doyle, J. </author> <year> (1979). </year> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 231-272. </pages>
Reference-contexts: Chapter 3 describes our approach to inconsistency due to persistence. We argue that previous approaches all fail along at least one of the key dimensions we have outlined here: knowledge design cost, efficiency, and responsiveness. Our approach extends truth maintenance techniques <ref> (Doyle, 1979) </ref> to capture the logical dependencies between local knowledge and the higher level context. However, efficiency concerns lead us to consider heuristic solutions to the determination of dependencies. Our heuristic guarantees reasoning consistency but may retract some assertions unnecessarily. <p> operator were interrupted, the empty 7 We consider this computation in more detail in Section 2.2.4 and in Figure 2.6, page 19. 14 Agent Memories Hierarchy Maintenance memories. calculation could be automatically removed as well, without the overhead of a dependency calculation such as those used in truth maintenance systems <ref> (Doyle, 1979) </ref>. We will have more to say about the capabilities and limitations of these processes in later chapters.
Reference: <author> Durfee, E. H. </author> <year> (1998). </year> <type> Personal Communication. </type>
Reference-contexts: Subtask-limited Reasoning avoids expensive computation of dependencies between assertions by sequencing the reasoning between subtasks. This process is similar to the "washing" mechanism used in PRS <ref> (Durfee, 1998) </ref>. Reasoning across subtasks is serialized, progressing from the top of the hierarchy to the lowest level of the hierarchy.
Reference: <author> Elsaesser, C. and Slack, M. G. </author> <year> (1994). </year> <title> Integrating deliberative planning in a robot architecture. </title> <booktitle> In Proceedings of the AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS '94). </booktitle>
Reference-contexts: The 3T architecture is one instance of these many architectures, having been used primarily in mobile robot domains (Bonasso et al., 1997). The 3T architecture consists of three layers or "tiers," with a specific planner <ref> (Elsaesser and Slack, 1994) </ref>, scheduler (Firby, 1987), and controller (Yu et al., 1994) comprising each tier.
Reference: <author> Erol, K., Hendler, J., and Nau, D. S. </author> <year> (1994). </year> <title> HTN planning: Complexity and expressivity. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1123-1128, </pages> <address> Seattle, Washington. </address>
Reference: <author> Fikes, R. E., Hart, P. E., and Nilsson, N. J. </author> <year> (1972). </year> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288. </pages>
Reference-contexts: We also hypothesize that agent performance can improve with experience by using knowledge compilation (Goel, 1991). Knowledge compilation has been used successfully in static domains and in dynamic domains in which the learning occurs "off-line" from the execution. For example, STRIPS <ref> (Fikes et al., 1972) </ref> compiled macro-operators over a static planning space even though these operators were then used to direct a robot in the external world. <p> For example, STRIPS <ref> (Fikes et al., 1972) </ref> compiled macro-operators over a static planning space even though these operators were then used to direct a robot in the external world. However, EBL has been applied to external domains in only limited cases (e.g., (Bresina et al., 1993; Laird and Rosenbloom, 1990; Mitchell, 1990)).
Reference: <author> Firby, R. J. </author> <year> (1987). </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 202-206, </pages> <address> Seattle, Washington. </address>
Reference-contexts: The 3T architecture is one instance of these many architectures, having been used primarily in mobile robot domains (Bonasso et al., 1997). The 3T architecture consists of three layers or "tiers," with a specific planner (Elsaesser and Slack, 1994), scheduler <ref> (Firby, 1987) </ref>, and controller (Yu et al., 1994) comprising each tier. However, the tiers of the 3T architecture have also been discussed as a general functional decomposition of the capabilities necessary for building interactive agents, independent of the specific choice of implementation in each tier (Pryor, 1996). <p> number of execution systems, including the Adaptive Intelligent Systems architecture (Hayes-Roth, 1990), ATLANTIS (Gat, 1991), Cypress (Wilkins et al., 1995), the Entropy Reduction Engine (Bresina et al., 1993), the New Millennium Remote Agent (Pell et al., 1996), the Procedural Reasoning System (Georgeff and Lansky, 1987; Lee et al., 1994), RAPS <ref> (Firby, 1987) </ref>, Soar (Laird et al., 1987; Laird and Rosenbloom, 1990), and Theo (Mitchell, 1990; Mitchell et al., 1991), among others. We will examine some of the advantages of hierarchical task decomposition and a more concrete example in the following section.
Reference: <author> Forbus, K. D. and deKleer, J. </author> <year> (1993). </year> <title> Building Problem Solvers. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Forgy, C. L. </author> <year> (1979). </year> <title> On the Efficient Implementation of Production Systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University. </institution>
Reference-contexts: The RETE algorithm <ref> (Forgy, 1979) </ref> shares condition elements across different productions. Thus, the removal of productions only decreases the total search if the removed productions contain condition elements not appearing in the retained productions.
Reference: <author> Forgy, C. L. </author> <year> (1981). </year> <title> OPS5 reference manual. </title> <type> Technical Report CMU-CS-81-135, </type> <institution> Computer Science Department, Carnegie-Mellon University, Pittsburgh, Pennsylvania. </institution>
Reference-contexts: Without parallelism, when these rules match simultaneously, the agent will have to choose one of the two rules to apply. The process of deciding which one of many rules that can apply is known as conflict resolution (McDermott and Forgy, 1978). For example, in the OPS5 production system <ref> (Forgy, 1981) </ref>, conflict resolution strategies include choosing the production that is most specific to the current situation, or choosing a production that matches against more recently instantiated elements, etc. In the example, if the most specific strategy had been chosen, Rule 2 would be selected and applied.
Reference: <author> Gaschnig, J. </author> <year> (1979). </year> <title> Performance measurement and analysis of certain search algorithms. </title> <type> Technical Report CMU-CS-79-124, </type> <institution> Computer Science Department, Carnegie-Mellon University, Pittsburgh, Pennsylvania. </institution>
Reference-contexts: With Dynamic Hierarchical Justification, the agent retracts all reasoning in the dependent subtask (and all lower levels in the hierarchy). Therefore, some assertions not dependent on the change in the context will be withdrawn. DHJ is thus similar to back-jumping <ref> (Gaschnig, 1979) </ref>. Backjumping uses heuristics to determine to where in a search space a current search should backtrack or "backjump." The heuristics used by backjump-ing are based on syntactic features of the problem.
Reference: <author> Gat, E. </author> <year> (1991). </year> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for mobile robots. </title> <journal> SIGART BULLETIN 2, </journal> <pages> pages 71-74. </pages> <note> 133 Georgeff, </note> <author> M. and Lansky, A. L. </author> <year> (1987). </year> <title> Reactive reasoning and planning. </title> <booktitle> In Proceed--ings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 677-682, </pages> <address> Seattle, Washington. </address>
Reference-contexts: Hierarchical task decomposition has been used in a great number of execution systems, including the Adaptive Intelligent Systems architecture (Hayes-Roth, 1990), ATLANTIS <ref> (Gat, 1991) </ref>, Cypress (Wilkins et al., 1995), the Entropy Reduction Engine (Bresina et al., 1993), the New Millennium Remote Agent (Pell et al., 1996), the Procedural Reasoning System (Georgeff and Lansky, 1987; Lee et al., 1994), RAPS (Firby, 1987), Soar (Laird et al., 1987; Laird and Rosenbloom, 1990), and Theo (Mitchell,
Reference: <author> Goel, A. K. </author> <year> (1991). </year> <title> Knowledge compilation: A symposium. </title> <journal> IEEE Expert, </journal> <volume> 6(2) </volume> <pages> 71-93. </pages>
Reference-contexts: Further, overall performance often improves under Goal-Oriented Heuristic Hierarchical Consistency because embedding general consistency knowledge in the architecture is less expensive than applying task-specific consistency knowledge. We also hypothesize that agent performance can improve with experience by using knowledge compilation <ref> (Goel, 1991) </ref>. Knowledge compilation has been used successfully in static domains and in dynamic domains in which the learning occurs "off-line" from the execution.
Reference: <author> Gupta, A. </author> <year> (1986). </year> <title> Parallelism in Production Systems. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University. </institution> <note> (Also published as Technical Report CMU-CS-86-122, </note> <institution> Computer Science Department, Carnegie Mellon University.). </institution>
Reference: <author> Hanks, S., Pollack, M., and Cohen, P. R. </author> <year> (1993). </year> <title> Benchmarks, test beds, controlled experimentation and the design of agent architectures. </title> <journal> AI Magazine, </journal> <volume> 14 </volume> <pages> 17-42. </pages>
Reference-contexts: Therefore, we will pursue an empirical characterization of hierarchical decomposition and limit these investigations to simulation domains where the engineering effort for the interface is more easily controlled. Support for this assumption includes <ref> (Hanks et al., 1993) </ref>, which suggests that simulated "test beds" are a good choice for empirical studies because the experimenter has control over the underlying domain. As a further control, we will use simulation tasks designed independently of this research. 4 Assumption 2: Focus on the execution level. <p> The choice of only a few tasks or domains is a considerable drawback of benchmarks, in both Artificial Intelligence <ref> (Hanks et al., 1993) </ref> and, more generally, in Computer Science (Hennessey and Patterson, 1990). Further, based on the commitments we described above, the domains we will investigate must also have independently-developed Soar 7 agents. <p> Therefore, we will pursue an empirical characterization of hierarchical decomposition and limit these investigations to simulation domains where the engineering effort for the interface is more easily controlled. Support for this assumption includes <ref> (Hanks et al., 1993) </ref>, which suggests that simulated "test beds" are a good choice for empirical studies because the experimenter has control over the underlying domain. As a further control, we will use simulation tasks designed independently of this research. 1 Assumption 2: Focus on the execution level.
Reference: <author> Hayes-Roth, B. </author> <year> (1990). </year> <title> An architecture for adaptive intelligent systems. In Workshop on Innovative Approaches to Planning, </title> <journal> Scheduling and Control, </journal> <pages> pages 422-432, </pages> <address> San Diego, CA. </address>
Reference: <author> Hayes-Roth, B., Pfleger, K., Lalanda, P., Morignot, P., and Balabanovic, M. </author> <year> (1995). </year> <title> A domain-specific software architecture for adaptive intelligent systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(4) </volume> <pages> 288-301. </pages>
Reference: <author> Hennessey, J. L. and Patterson, D. A. </author> <year> (1990). </year> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: The choice of only a few tasks or domains is a considerable drawback of benchmarks, in both Artificial Intelligence (Hanks et al., 1993) and, more generally, in Computer Science <ref> (Hennessey and Patterson, 1990) </ref>. Further, based on the commitments we described above, the domains we will investigate must also have independently-developed Soar 7 agents. We chose to examine agents in the Blocks World and in a reduced-knowledge version of TacAir-Soar ("micro-TacAir-Soar").
Reference: <author> Kim, J. and Rosenbloom, P. S. </author> <year> (1995). </year> <title> Transformational analyses of learning in Soar. </title> <type> Technical Report ISI/RR-95-4221, </type> <institution> Information Sciences Institute, Marina del Rey, </institution> <address> CA 90292. </address>
Reference-contexts: We did not make eliminating over-specific learning a priority. Recent work has shown that chunking can be modified to use more typical explanation-based learning generalization techniques and thus avoid the limitations of the variabilization process in chunking that leads to over-specific rules <ref> (Kim and Rosenbloom, 1995) </ref>. However, the occurrence of over-specific rules in our results does impact the learning rate, as we observed above, and means that our estimate of the changes necessary to address over-specific learning is low for the current implementation of chunking in Soar.
Reference: <author> Knoblock, C. A. </author> <year> (1991). </year> <title> Search reduction in hierarchical problem solving. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 686-691, </pages> <address> Anaheim, California. </address>
Reference: <author> Korf, R. E. </author> <year> (1987). </year> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 65-88. </pages> <note> (Also published in Readings in Planning, </note> <editor> James Allen and James Hendler and Austin Tate, editors, </editor> <address> pages 566-578, </address> <publisher> Morgan Kaufmann, 1990.). </publisher>
Reference-contexts: Based on these characteristics, we will use these non-hierarchical agents as a potential alternative to hierarchical agents. Hierarchical decomposition reduces the complexity of planning from exponential to 15 linear in the size of the problem <ref> (Korf, 1987) </ref>. This advantage has made hierarchical decomposition a well-researched and frequently-used technique in classical planning (Sac-erdoti, 1974; Tate, 1976; Erol et al., 1994). We argue in this section that hierarchical task decomposition simplifies knowledge design in execution domains, in comparison to a flat representation.
Reference: <author> Kuhn, H. T. and Padua, D. A., </author> <title> editors (1981). </title> <booktitle> Tutorial on Parallel Processing. IEEE. </booktitle>
Reference: <author> Kuokka, D. R. </author> <year> (1991). </year> <title> MAX: A meta-reasoning architecture for X. </title> <journal> SIGART BULLETIN 2, </journal> <pages> pages 93-97. </pages>
Reference-contexts: Because the additional required knowledge concerns agent processing, rather than the domain, we describe this solution as the "Meta-Level Consistency Knowledge" (MLCK) solution. MLCK requires that an agent be able to reason about its own processes. Many architectures do not support this requirement. An exception is MAX <ref> (Kuokka, 1991) </ref>, an extension of Prodigy research for execution domains. The reasoning language used by MAX, lframes, is both executable and declarative, allowing the agent to reason about its processing.
Reference: <author> Laird, J. E. </author> <year> (1998). </year> <type> Personal Communication. </type>
Reference-contexts: Chapter 5 provides empirical evidence that shows dynamic hierarchical justification contributes to a reduction in engineering effort and improvements in performance in comparison to knowledge-based techniques. 1 These solutions are also described in <ref> (Wray and Laird, 1998) </ref>. 24 Inference Rules Prior Assertions New Assertion (s) A ^ B ! D A; B D no contradiction (consistent) A; C :D no contradiction (consistent) C ! :D B; C :D no contradiction (consistent) A; B; C :D; D contradiction (inconsistent) Table 3.1: A simple example of <p> This work provides a theoretical explanation for the costs associated with Assumption Justification. An actual implementation of assumption support in Soar was completed by members of the Soar research group at the University of Michigan other than the author <ref> (Laird, 1998) </ref>. Experiments using assumption justification in Soar, using Air-Soar, a flight simulator domain (Pearson et al., 1993), showed the overhead of maintaining all prior assumptions in a level negatively impacted agent performance, a result not surprising given the analysis presented here.
Reference: <author> Laird, J. E., Newell, A., and Rosenbloom, P. S. </author> <year> (1987). </year> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64. </pages>
Reference-contexts: Again, too, the solution ensures consistency but sometimes sequences reasoning unnecessarily. In Chapter 5, we evaluate Goal-Oriented Heuristic Hierarchical Consistency (GO-HHC), our total solution to the inconsistency problems. Having added this solution to the Soar architecture <ref> (Laird et al., 1987) </ref>, we evaluate our solution along two critical dimensions. First, we compare the knowledge requirements for GOHHC agents to the knowledge requirements for agents using knowledge-based solutions for consistency. <p> Assumption 3: Focus on a particular implementation. Although we are interested in the general characteristics of hierarchical task decomposition, we will focus our empirical experimentation in one plan execution system: the Soar architecture <ref> (Laird et al., 1987) </ref>. We originally became interested in the characteristics and problems of hierarchical task decomposition through the use of Soar in a number of different plan execution environments constrained by Assumption 2 (Laird and Rosenbloom, 1990; Pearson et al., 1993; Tambe et al., 1995)). <p> These support sets, in effect, form justifications for levels in the hierarchy. When an assertion in a support set is removed (e.g., a 22 ), the agent responds by removing the level (Level 3 ). Architectures such as the Procedural Reasoning System (PRS) (Georgeff and Lansky, 1987) and Soar <ref> (Laird et al., 1987) </ref> use architectural mechanisms to retract complete levels of the hierarchy when the support set no longer holds. PRS checks the continuing applicability of each active subtask ("knowledge area") prior to continuing reasoning in that level. <p> Assumption 3: Focus on a particular implementation. Although we are interested in the general characteristics of hierarchical task decomposition, we will focus our empirical experimentation in one plan execution system: the Soar architecture <ref> (Laird et al., 1987) </ref>. We originally became interested in the characteristics and problems of hierarchical task decomposition through the use of Soar in a number of different plan execution environments constrained by Assumption 2 (Laird and Rosenbloom, 1990; Pearson et al., 1993; Tambe et al., 1995)).
Reference: <author> Laird, J. E., Pearson, D. J., Jones, R. M., and Wray, R. E. </author> <year> (1996). </year> <title> Dynamic knowledge integration during plan execution. </title> <booktitle> In Papers from the 1996 AAAI Fall Symposium on Plan Execution: Problems and Issues, </booktitle> <pages> pages 92-98, </pages> <address> Cambridge, Massachusetts. </address> <publisher> AAAI. </publisher>
Reference-contexts: Thus, the agent pays the time-price for the decomposition to a primitive in a specific circumstance only one time. Assumption 7: The world has regularities that make learning useful. We assume that the world has goal-relevant regularities <ref> (Laird et al., 1996) </ref>. A block stacking robot regularly encounters situations in which it must stack blocks. The can-collecting robot regularly encounters situations in which it must move, search, and grasp cans. <p> Thus, the effort necessary for developing a general solution can be amortized over the development of all the agents using the architectural solution. Assumption 7: The world has regularities that make learning useful. We assume that the world has goal-relevant regularities <ref> (Laird et al., 1996) </ref>. A block stacking robot regularly encounters situations in which it must stack blocks. The can-collecting robot regularly encounters situations in which it must move, search, and grasp cans.
Reference: <author> Laird, J. E. and Rosenbloom, P. S. </author> <year> (1990). </year> <title> Integrating execution, planning, and learning in Soar for external environments. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1022-1029, </pages> <address> Boston, Massachusetts. </address> <note> 134 Laird, </note> <author> J. E. and Rosenbloom, P. S. </author> <year> (1995). </year> <title> The evolution of the Soar cognitive architecture. </title> <editor> In Steier, D. and Mitchell, T., editors, </editor> <title> Mind Matters: Contributions to Cognitive and Computer Science in Honor of Allen Newell. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Laird, J. E., Rosenbloom, P. S., and Newell, A. </author> <year> (1986a). </year> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46. </pages>
Reference-contexts: The training example is the specific current situation. Therefore, the object of EBL in execution environments is to operationalize appropriately the generation of a primitive output command. EBL algorithms such as EBG (Mitchell et al., 1986) and chunking <ref> (Laird et al., 1986a) </ref> also use generalization schemes that result in compiled rules more general than Rule 5. 6.2.1 Requirements for Knowledge Compilation in Execution Domains The compilation process we have described above is sufficient for the general goal of caching the results of hierarchical decomposition in particular situations. <p> While some EBL system's "re-prove" the explanation to create a generalized explanation, several systems use architecture-specific techniques to improve efficiency. Examples include Prodigy's EBS algorithm (Minton, 1988) and Soar's chunking mechanism <ref> (Laird et al., 1986a) </ref>. Agent knowledge bases may grow significantly as compiled experience increases the number of rules.
Reference: <author> Laird, J. E., Rosenbloom, P. S., and Newell, A. </author> <year> (1986b). </year> <title> Overgeneralization during knowledge compilation in Soar. </title> <editor> In Dietterich, T. G., editor, </editor> <booktitle> Proceedings of the Workshop on Knowledge Compilation. </booktitle>
Reference-contexts: Although this requirement is important for the compilation algorithm, it also makes demands on the execution system. For instance, the target language of compilation must be sufficient for describing the necessary computations in the subtask <ref> (Laird et al., 1986b) </ref>. 6.3 Problems in Knowledge Compilation Knowledge compilation has been used successfully in static domains and in dynamic domains in which the learning occurs "off line" from the execution.
Reference: <author> Lallement, Y. and John, B. E. </author> <year> (1998). </year> <title> Cognitive architecture and modeling idiom: an examination of three models of the Wickens's task. </title> <booktitle> In Twentieth Annual Conference of the Cognitive Science Society, </booktitle> <address> Madison, Wisconsin. </address>
Reference-contexts: Thus, we expect these systems can be converted with much less expense. For example, although we do not report the results directly in this thesis, we have developed additional Blocks World agents for two representational conventions, or modeling idioms <ref> (Lallement and John, 1998) </ref>, that make learning unproblematic. The emphasis of the modeling idioms is psychological rather than functional, although both do provide knowledge-based solutions to inconsistency (Lehman et al., 1995; Rieman et al., 1996). The Blocks World agents using these conventions were developed for Soar 7. <p> As another example, models of dual-task performance implemented in Soar 7 (using a particular modeling idiom) and in Soar 8 have both been shown to match human performance data closely <ref> (Lallement and John, 1998) </ref>. In general, most psychological phenomena modeled with Soar will not intersect with the changes necessary for Goal-Oriented Heuristic Hierarchical Consistency.
Reference: <author> Lee, J., Huber, M. L., Durfee, E., and Kenny, P. G. </author> <year> (1994). </year> <title> UM-PRS: An implementation of the Procedural Reasoning System for multirobot applications. </title> <booktitle> In Proceedings of the AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS '94). </booktitle>
Reference: <author> Lehman, J. F., Dyke, J. V., and Rubinoff, R. </author> <year> (1995). </year> <title> Natural language processing for IFORs: Comprehension and generation in the air combat domain. </title> <booktitle> In Proceedings of the Fifth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <address> Orlando, Florida. </address> <institution> Institute for Simulation and Training. </institution>
Reference: <author> Martin, J. </author> <year> (1993). </year> <title> Principles of Object-Oriented Analysis and Design. </title> <publisher> Prentice-Hall. </publisher>
Reference: <author> McCarthy, J. and Hayes, P. J. </author> <year> (1969). </year> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In Meltzer, B. and Mitchie, D., editors, </editor> <booktitle> Machine Intelligence 4. </booktitle> <publisher> Edinburgh University Press. </publisher>
Reference-contexts: However, this additional knowledge can be difficult (and thus expensive) to develop. First, this knowledge is not a natural part of the task representation. For example, this knowledge is motivated by the frame problem <ref> (McCarthy and Hayes, 1969) </ref>. That is, it describes how to change previous assumptions as the world changes. In general, this knowledge is necessary in both flat and hierarchical systems.
Reference: <author> McDermott, D. </author> <year> (1991). </year> <title> A general framework for reason maintenance. </title> <journal> Artificial Intelligence, </journal> <volume> 50 </volume> <pages> 289-329. </pages>
Reference: <author> McDermott, J. and Forgy, C. </author> <year> (1978). </year> <title> Production system conflict resolution strategies. </title> <editor> In Waterman, D. A. and Hayes-Roth, F., editors, </editor> <booktitle> Pattern-directed Inference Systems, </booktitle> <pages> pages 177-199. </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Without parallelism, when these rules match simultaneously, the agent will have to choose one of the two rules to apply. The process of deciding which one of many rules that can apply is known as conflict resolution <ref> (McDermott and Forgy, 1978) </ref>. For example, in the OPS5 production system (Forgy, 1981), conflict resolution strategies include choosing the production that is most specific to the current situation, or choosing a production that matches against more recently instantiated elements, etc.
Reference: <author> McGregor, J. D. and Sykes, D. A. </author> <year> (1992). </year> <title> Object-Oriented Software Development: Engineering Software for Reuse. </title> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: Consistency knowledge makes the knowledge base less hierarchical and more "flat" because the agent has to know and reason about the interactions between different levels in the hierarchy. A lack of modularity makes the maintainability of software more difficult <ref> (McGregor and Sykes, 1992) </ref>. Indeed, a number of presentations at a recent meeting of researchers using the Soar architecture (Schwamb, 1998) stressed that, for large systems, maintainability and re-use were difficult to achieve, even though Soar systems are organized around modular problem spaces.
Reference: <author> Minton, S. </author> <year> (1988). </year> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: While some EBL system's "re-prove" the explanation to create a generalized explanation, several systems use architecture-specific techniques to improve efficiency. Examples include Prodigy's EBS algorithm <ref> (Minton, 1988) </ref> and Soar's chunking mechanism (Laird et al., 1986a). Agent knowledge bases may grow significantly as compiled experience increases the number of rules. <p> This average growth effect (Doorenbos, 1993) is a specialized case of the well-known utility problem <ref> (Minton, 1988) </ref>. We require that the agent's reasoning not slow down significantly as the number of rules in the agent increases.
Reference: <author> Mitchell, T. M. </author> <year> (1990). </year> <title> Becoming increasingly reactive. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1051-1058, </pages> <address> Boston, Massachusetts. </address>
Reference: <author> Mitchell, T. M., Allen, J., Chalasani, P., Cheng, J., Etzioni, O., Ringuette, M., and Schlimmer, J. C. </author> <year> (1991). </year> <title> Theo: A framework for self-improving systems. </title> <editor> In Van-Lehn, K., editor, </editor> <booktitle> Architectures for Intelligence, chapter 12, </booktitle> <pages> pages 323-355. </pages> <publisher> Lawrence Erlbaum Associates. 135 Mitchell, </publisher> <editor> T. M., Kellar, R. M., and Kedar-Cabelli, S. T. </editor> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80. </pages>
Reference-contexts: Indeed, Theo <ref> (Mitchell et al., 1991) </ref>, a hierarchical plan execution system, does not experience the problem we describe in this chapter. However, Theo can only reason and act about what it can directly sense. The persistence of its internal inferences is limited by its sensors. <p> Because the compilation of non-contemporaneous constraints arises from inconsistency due to persistence, we expect that any of the approaches we described in Chapter 3 will avoid the problem (including, of course, Dynamic Hierarchical Justification). For example, neither Theo <ref> (Mitchell et al., 1991) </ref> nor ERE (Bresina et al., 1993) suffer from non-contemporaneous constraints in learned rules. Theo never creates persistent assumptions. Thus, the hierarchy never contains assertions derived in a context nonmonotonic to the current one and compilation is not problematic.
Reference: <author> Newell, A. </author> <year> (1980). </year> <title> Reasoning, problem solving, and decision processes: The problem space as a fundamental category. </title> <editor> In Nickerson, R., editor, </editor> <title> Attention and Performance VIII. </title> <publisher> Erlbaum. </publisher>
Reference-contexts: At this point, other rules would fire to close the gripper over the block and execution of the task would continue. Each level of the decomposition in a hierarchical system corresponds to a problem space <ref> (Newell, 1980) </ref>. A problem space is simply a space that the agent creates to search for a solution. Three different problem spaces are represented in this example. Each problem space represents a body of knowledge insulated from the others. For example, 13 1.
Reference: <author> Newell, A. </author> <year> (1990). </year> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: Thus, knowledge engineering cost does not increase with the addition of compilation. Finally, Chapter 7 summarizes the results of this work and outlines some potential directions for future research. Because the Soar architecture has also been used as a model of human cognition <ref> (Newell, 1990) </ref>, we also briefly survey the impact Goal-Oriented Heuristic Hierarchical Consistency may have on this aspect of Soar. 6 1.3 Contributions The primary contributions of this thesis are to: * Provide an understanding of how inconsistency can arise due to persistence in hierarchical architectures. <p> Instead, its chief responsibility is responding to the current situation by activating the knowledge most appropriate to the current situation. In other words, the execution system attempts to optimize knowledge search rather than problem search <ref> (Newell, 1990, pp. 98) </ref>. Thus, the motivations for using hierarchical task decomposition in the execution layer are different than for using it in the planning layer. We outline some of these motivations below. Natural Representation A hierarchical decomposition of knowledge is a very natural way to represent the task. <p> In execution agents, decomposition leads to the eventual execution of a primitive action. In Soar, the interface to the external environment is part of the top state or base level space <ref> (Newell, 1990) </ref>. Therefore, the initiation of an external action requires returning a motor command to the top state as a result, and chunking compiles the decomposition that led to the result. Thus, we can use chunking as it exists, using existing agent knowledge. <p> the conversion to Soar 8 for systems designed for learning in Soar 7 will be not be as extensive as required by the examples in this thesis. 7.2.2 Effect on Psychological Theory Soar has been used to model psychological phenomena and has been proposed as a unified theory of cognition <ref> (Newell, 1990) </ref>. We now briefly consider the potential impact of GOHHC on Soar as a psychological theory and tool for psychological modeling. The basic commitments of the Soar architecture associative retrieval of knowledge, problem spaces, impasse-driven subgoaling, and chunking are unchanged in Soar 8.
Reference: <author> Pearson, D. J., Huffman, S. B., Willis, M. B., Laird, J. E., and Jones, R. M. </author> <year> (1993). </year> <title> A symbolic solution to intelligent real-time control. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11 </volume> <pages> 279-291. </pages>
Reference-contexts: An actual implementation of assumption support in Soar was completed by members of the Soar research group at the University of Michigan other than the author (Laird, 1998). Experiments using assumption justification in Soar, using Air-Soar, a flight simulator domain <ref> (Pearson et al., 1993) </ref>, showed the overhead of maintaining all prior assumptions in a level negatively impacted agent performance, a result not surprising given the analysis presented here.
Reference: <author> Pell, B., Gat, E., Keesing, R., Muscettola, N., and Smith, B. </author> <year> (1996). </year> <title> Plan execution for autonomous spacecraft. </title> <booktitle> In Papers from the 1996 AAAI Fall Symposium on Plan Execution: Problems and Issues, </booktitle> <pages> pages 109-116, </pages> <address> Cambridge, Massachusetts. </address> <publisher> AAAI. </publisher>
Reference-contexts: Hierarchical task decomposition has been used in a great number of execution systems, including the Adaptive Intelligent Systems architecture (Hayes-Roth, 1990), ATLANTIS (Gat, 1991), Cypress (Wilkins et al., 1995), the Entropy Reduction Engine (Bresina et al., 1993), the New Millennium Remote Agent <ref> (Pell et al., 1996) </ref>, the Procedural Reasoning System (Georgeff and Lansky, 1987; Lee et al., 1994), RAPS (Firby, 1987), Soar (Laird et al., 1987; Laird and Rosenbloom, 1990), and Theo (Mitchell, 1990; Mitchell et al., 1991), among others.
Reference: <author> Prieto-Diaz, R. and Arango, G., </author> <title> editors (1991). Domain Analysis and Software Systems Modeling. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA. </address>
Reference: <author> Pryor, L., </author> <title> editor (1996). Plan Execution: Problems and Issues: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address> <note> Technical Report FS-96-01. </note>
Reference-contexts: However, the tiers of the 3T architecture have also been discussed as a general functional decomposition of the capabilities necessary for building interactive agents, independent of the specific choice of implementation in each tier <ref> (Pryor, 1996) </ref>. Throughout the dissertation, we adopt this abstract notion of an agent with three layers of processing as a general framework and explore the specific 3T agent framework below. 2.1.1 Three-tiered Agents lowest tier, the agent uses reactive skills to act in the external environment.
Reference: <author> Rieman, J., Young, R. M., and Howes, A. </author> <year> (1996). </year> <title> A dual-space model of iteratively deepening exploratory learning. </title> <journal> International Journal of Human-Computer Studies, </journal> <volume> 44 </volume> <pages> 743-775. </pages>
Reference: <author> Rosenbloom, P. and Laird, J. </author> <year> (1986). </year> <title> Mapping explanation-based generalization onto Soar. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 561-567, </pages> <address> Philadelphia, Pennsylvania. </address>
Reference: <author> Rosenbloom, P. S., Laird, J. E., and Newell, A. </author> <year> (1988). </year> <title> The chunking of skill and knowledge. </title> <editor> In Bouma, H. and Elsendorn, A., editors, </editor> <booktitle> Working Models of Human Perception. </booktitle> <publisher> Academic Press, </publisher> <address> London, England. </address>
Reference-contexts: Non-problematic, on-line compilation also facilitates the inductive use of learning in execution environments. For example, chunking can be used to compile inductive problem solving, resulting in inductive learning <ref> (Rosenbloom et al., 1988) </ref>. Importantly, compilation provides the potential for knowledge-rich, computationally efficient inductive learning that can occur in conjunction with behavior. Inductive learning could be used to modify behavior with changing domains, self-correct errors in execution knowledge, etc.
Reference: <author> Sacerdoti, E. D. </author> <year> (1974). </year> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135. </pages>
Reference: <author> Schoppers, M. J. </author> <year> (1986). </year> <title> Universal plans for reactive robots in unpredictable environments. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Schwamb, K., </author> <title> editor (1998). </title> <booktitle> Soar Workshop 18. Explore Reasoning Systems, </booktitle> <address> Vienna, Virginia. </address>
Reference-contexts: A lack of modularity makes the maintainability of software more difficult (McGregor and Sykes, 1992). Indeed, a number of presentations at a recent meeting of researchers using the Soar architecture <ref> (Schwamb, 1998) </ref> stressed that, for large systems, maintainability and re-use were difficult to achieve, even though Soar systems are organized around modular problem spaces.
Reference: <author> Simon, H. A. </author> <year> (1969). </year> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Stallman, R. M. and Sussman, G. J. </author> <year> (1977). </year> <title> Forward reasoning and dependency-directed backtracking in a system for computer aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196. </pages>
Reference: <author> Tambe, M. </author> <year> (1991). </year> <title> Eliminating Combinatorics from Production Match. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University. </institution> <note> (Also published as Technical Report CMU-CS-91-150, </note> <institution> Computer Science Department, Carnegie Mellon University.). </institution> <note> 136 Tambe, </note> <author> M., Johnson, W. L., Jones, R. M., Koss, F., Laird, J. E., Rosenbloom, P. S., and Schwamb, K. </author> <year> (1995). </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <volume> 16(1) </volume> <pages> 15-39. </pages>
Reference-contexts: Different productions take different amounts of time to match and fire in Soar; production matching, especially, is not a constant time operation. In general, the match cost of a production grows linearly with the number of partial instantiations of the production <ref> (Tambe, 1991) </ref>. These partial instantiations are called tokens. Each token indicates what conditions in the production have matched and the variable bindings for those conditions. In effect, each token represents a node in a search over the agent's memory for matching instantiation (s) of the production.
Reference: <author> Tambe, M., Newell, A., and Rosenbloom, P. S. </author> <year> (1990). </year> <title> The problem of expensive chunks and its solution by restricting expressiveness. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 299-348. </pages>
Reference: <author> Tate, A. </author> <year> (1976). </year> <title> NONLIN: A hierarchical non-linear planner. </title> <type> Technical report, </type> <institution> Department of Artificial Intelligence, University of Edinburgh. </institution>
Reference: <author> Tversky, A. and Kahneman, D. </author> <year> (1982). </year> <title> Judgement under uncertainty: Heuristics and biases. </title> <editor> In Kahneman, D., Slovic, P., and Tversky, A., editors, </editor> <title> Judgement under Uncertainty: Heuristics and Biases. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Wilkins, D. E., Myers, K. L., Lowrance, J. D., and Wesley, L. P. </author> <year> (1995). </year> <title> Planning and reacting in uncertain and dynamic environments. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 7. </volume>
Reference-contexts: Hierarchical task decomposition has been used in a great number of execution systems, including the Adaptive Intelligent Systems architecture (Hayes-Roth, 1990), ATLANTIS (Gat, 1991), Cypress <ref> (Wilkins et al., 1995) </ref>, the Entropy Reduction Engine (Bresina et al., 1993), the New Millennium Remote Agent (Pell et al., 1996), the Procedural Reasoning System (Georgeff and Lansky, 1987; Lee et al., 1994), RAPS (Firby, 1987), Soar (Laird et al., 1987; Laird and Rosenbloom, 1990), and Theo (Mitchell, 1990; Mitchell et
Reference: <author> Wray, R. and Laird, J. </author> <year> (1998). </year> <title> Maintaining consistency in hierarchical reasoning. </title> <booktitle> In Proceedings of the Fifteenth National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Chapter 5 provides empirical evidence that shows dynamic hierarchical justification contributes to a reduction in engineering effort and improvements in performance in comparison to knowledge-based techniques. 1 These solutions are also described in <ref> (Wray and Laird, 1998) </ref>. 24 Inference Rules Prior Assertions New Assertion (s) A ^ B ! D A; B D no contradiction (consistent) A; C :D no contradiction (consistent) C ! :D B; C :D no contradiction (consistent) A; B; C :D; D contradiction (inconsistent) Table 3.1: A simple example of
Reference: <author> Wray, R., Laird, J., and Jones, R. M. </author> <year> (1996). </year> <title> Compilation of non-contemporaneous constraints. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 771-778, </pages> <address> Portland, OR. </address>
Reference-contexts: A few systems with on-line, analytic learning have been developed; however, these have been dependent upon specific representation schemes to avoid problems resulting from using knowledge compilation in a dynamic environment. These 5 problems include generating rules that include features that never co-occur (the non--contemporaneous constraints problem <ref> (Wray et al., 1996) </ref>) and conflicts between compiled and original task knowledge (the knowledge contention problem). In Chapter 6, we show that Goal-Oriented Heuristic Hierarchical Consistency provides solutions to these learning problems, leading to agents whose performance improves with domain experience. <p> However, close-gripper requires that the gripper be immediately above block-3, meaning it is no longer clear. Regressing through these conditions for compilation leads to the conditions clear (block-3) and immediately-above (gripper,block-3), which do not occur simultaneously in this domain. 6.3.1 The Problem of Non-Contemporaneous Constraints Non-contemporaneous constraints <ref> (Wray et al., 1996) </ref> occur in the conditions of a learned rule when two or more conditions match against features which never occur simultaneously in the domain. A rule with non-contemporaneous constraints can never apply.
Reference: <author> Yu, S., Slack, M. G., and Miller, D. </author> <year> (1994). </year> <title> A streamlined software environment for situated skills. </title> <booktitle> In Proceedings of the AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS '94). </booktitle> <pages> 137 </pages>
Reference-contexts: The 3T architecture is one instance of these many architectures, having been used primarily in mobile robot domains (Bonasso et al., 1997). The 3T architecture consists of three layers or "tiers," with a specific planner (Elsaesser and Slack, 1994), scheduler (Firby, 1987), and controller <ref> (Yu et al., 1994) </ref> comprising each tier. However, the tiers of the 3T architecture have also been discussed as a general functional decomposition of the capabilities necessary for building interactive agents, independent of the specific choice of implementation in each tier (Pryor, 1996).
References-found: 78

