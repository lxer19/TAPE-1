URL: http://www.research.att.com/~schapire/papers/CohenScSi98.ps.Z
Refering-URL: http://www.research.att.com/~schapire/publist.html
Root-URL: 
Email: fwcohen,schapire,singerg@research.att.com  
Title: Learning to Order Things  
Author: William W. Cohen Robert E. Schapire Yoram Singer 
Address: 180 Park Ave., Florham Park, NJ 07932  
Affiliation: AT&T Labs,  
Note: Advances in Neural Information Processing Systems 10, Morgan Kaufmann, 1998.  
Abstract: There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order, given feedback in the form of preference judgments, i.e., statements to the effect that one instance should be ranked ahead of another. We outline a two-stage approach in which one first learns by conventional means a preference function, of the form PREF(u; v), which indicates whether it is advisable to rank u before v. New instances are then ordered so as to maximize agreements with the learned preference function. We show that the problem of finding the ordering that agrees best with a preference function is NP-complete, even under very restrictive assumptions. Nevertheless, we describe a simple greedy algorithm that is guaranteed to find a good approximation. We then discuss an on-line learning algorithm, based on the Hedge algorithm, for finding a good linear combination of ranking experts. We use the ordering algorithm combined with the on-line learning algorithm to find a combination of search experts, each of which is a domain-specific query expansion strategy for a WWW search engine, and present experimental results that demonstrate the merits of our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.S. Hochbaum (Ed.). </author> <title> Approximation Algorithms for NP-hard problems. </title> <publisher> PWS Publishing Company, </publisher> <year> 1997. </year>
Reference-contexts: This general approach is novel; for related work in various fields see, for instance, references <ref> [2, 3, 1, 7, 10] </ref>. As we will see, given an appropriate feature set, learning a preference function can be reduced to a fairly conventional classification learning problem. On the other hand, finding a total order that agrees best with a preference function is NP-complete. <p> A preference function PREF is a binary function PREF : X fi X ! <ref> [0; 1] </ref>. A value of PREF (u; v) which is close to 1 or 0 is interpreted as a strong recommendation that u should be ranked before v. A value close to 1=2 is interpreted as an abstention from making a recommendation. <p> collection of N ordering functions f i : X ! S; and a preference function PREF defined as PREF (u; v) = P N i=1 w i R f i (u; v) where w = (w 1 ; : : : ; w N ) is a weight vector in <ref> [0; 1] </ref> N with P N Question: Does there exist a total order such that AGREE (; PREF) ? The proof (omitted) is by reduction from CYCLIC-ORDERING [5, 6]. <p> The algorithm we propose for this problem is based on the weighted majority algorithm [9] and, more directly, on the Hedge algorithm [4]. We define the loss of a preference function Allocate Weights for Ranking Experts Parameters: fi 2 <ref> [0; 1] </ref>, initial weight vector w 1 2 [0; 1] N with P N i = 1 N ranking experts, number of rounds T Do for t = 1; 2; : : : ; T 1. <p> The algorithm we propose for this problem is based on the weighted majority algorithm [9] and, more directly, on the Hedge algorithm [4]. We define the loss of a preference function Allocate Weights for Ranking Experts Parameters: fi 2 <ref> [0; 1] </ref>, initial weight vector w 1 2 [0; 1] N with P N i = 1 N ranking experts, number of rounds T Do for t = 1; 2; : : : ; T 1. Receive a set of elements X t and preference functions R t 1 ; : : : ; R t 2. <p> for each preference function Loss (R t i ; F t ) is evaluated as in Eq. (2) and the weight vector w t is updated using the multiplicative rule w t+1 i = w t i fi Loss (R t i ;F t ) =Z t where fi 2 <ref> [0; 1] </ref> is a parameter, and Z t is a normalization constant, chosen so that the weights sum to one after the update.
Reference: [2] <author> O. Etzioni, S. Hanks, T. Jiang, R. M. Karp, O. Madani, and O. Waarts. </author> <title> Efficient information gathering on the internet. </title> <booktitle> In 37th Ann. Symp. on Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: This general approach is novel; for related work in various fields see, for instance, references <ref> [2, 3, 1, 7, 10] </ref>. As we will see, given an appropriate feature set, learning a preference function can be reduced to a fairly conventional classification learning problem. On the other hand, finding a total order that agrees best with a preference function is NP-complete.
Reference: [3] <author> P.C Fishburn. </author> <title> The Theory of Social Choice. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1973. </year>
Reference-contexts: This general approach is novel; for related work in various fields see, for instance, references <ref> [2, 3, 1, 7, 10] </ref>. As we will see, given an appropriate feature set, learning a preference function can be reduced to a fairly conventional classification learning problem. On the other hand, finding a total order that agrees best with a preference function is NP-complete.
Reference: [4] <author> Y. Freund and R.E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <year> 1997. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm [9] and Winnow [8], and, more directly, Freund and Schapire's <ref> [4] </ref> Hedge algorithm. We then present some experimental results in which this algorithm is used to combine the results of several search experts, each of which is a domain-specific query expansion strategy for a WWW search engine. 2 Preliminaries Let X be a set of instances (possibly infinite). <p> That is, formally we regard the feedback on the t-th round as a set F t of pairs (u; v) indicating such preferences. The algorithm we propose for this problem is based on the weighted majority algorithm [9] and, more directly, on the Hedge algorithm <ref> [4] </ref>. <p> Thus, based on the feedback, the weights of the ranking experts are adjusted so that experts producing preference functions with relatively large agreement with the feedback are promoted. We will briefly sketch the theoretical rationale behind this algorithm. Freund and Schapire <ref> [4] </ref> prove general results about Hedge which can be applied directly to this loss function.
Reference: [5] <author> Z. Galil and N. Megido. </author> <title> Cyclic ordering is NP-complete. </title> <journal> Theor. Comp. Sci., </journal> <volume> 5 </volume> <pages> 179-182, </pages> <year> 1977. </year>
Reference-contexts: R f i (u; v) where w = (w 1 ; : : : ; w N ) is a weight vector in [0; 1] N with P N Question: Does there exist a total order such that AGREE (; PREF) ? The proof (omitted) is by reduction from CYCLIC-ORDERING <ref> [5, 6] </ref>. Although this problem is hard when jSj 3, it becomes tractable for linear combinations of rank orderings into a set S of size two.
Reference: [6] <author> M.R. Gary and D.S. Johnson. </author> <title> Computers and Intractibility: A Guide to the Theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: R f i (u; v) where w = (w 1 ; : : : ; w N ) is a weight vector in [0; 1] N with P N Question: Does there exist a total order such that AGREE (; PREF) ? The proof (omitted) is by reduction from CYCLIC-ORDERING <ref> [5, 6] </ref>. Although this problem is hard when jSj 3, it becomes tractable for linear combinations of rank orderings into a set S of size two.
Reference: [7] <author> P.B. Kantor. </author> <title> Decision level data fusion for routing of documents in the TREC3 context: a best case analysis of worste case results. </title> <booktitle> In TREC-3, </booktitle> <year> 1994. </year>
Reference-contexts: This general approach is novel; for related work in various fields see, for instance, references <ref> [2, 3, 1, 7, 10] </ref>. As we will see, given an appropriate feature set, learning a preference function can be reduced to a fairly conventional classification learning problem. On the other hand, finding a total order that agrees best with a preference function is NP-complete.
Reference: [8] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4), </volume> <year> 1988. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm [9] and Winnow <ref> [8] </ref>, and, more directly, Freund and Schapire's [4] Hedge algorithm. <p> The problem, then, is to learn a preference function of the form PREF (u; v) = P N i=1 w i R i (u; v). We adopt the on-line learning framework first studied by Littlestone <ref> [8] </ref> in which the weight w i assigned to each ranking expert R i is updated incrementally. Learning is assumed to take place in a sequence of rounds.
Reference: [9] <author> N. Littlestone and M.K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: After presenting these results on the complexity of ordering instances using a preference function, we then describe a specific algorithm for learning a preference function. The algorithm is an on-line weight allocation algorithm, much like the weighted majority algorithm <ref> [9] </ref> and Winnow [8], and, more directly, Freund and Schapire's [4] Hedge algorithm. <p> That is, formally we regard the feedback on the t-th round as a set F t of pairs (u; v) indicating such preferences. The algorithm we propose for this problem is based on the weighted majority algorithm <ref> [9] </ref> and, more directly, on the Hedge algorithm [4].
Reference: [10] <author> K.E. Lochbaum and L.A. Streeter. </author> <title> Comparing and combining the effectiveness of latent semantic indexing and the ordinary vector space model for information retrieval. </title> <booktitle> Information processing and management, </booktitle> <volume> 25(6) </volume> <pages> 665-676, </pages> <year> 1989. </year>
Reference-contexts: This general approach is novel; for related work in various fields see, for instance, references <ref> [2, 3, 1, 7, 10] </ref>. As we will see, given an appropriate feature set, learning a preference function can be reduced to a fairly conventional classification learning problem. On the other hand, finding a total order that agrees best with a preference function is NP-complete.
References-found: 10

