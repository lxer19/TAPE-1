URL: ftp://ftp.cs.rochester.edu/pub/u/michael/IPPS97.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/michael/
Root-URL: 
Email: fmichael,scottg@cs.rochester.edu  
Title: Relative Performance of Preemption-Safe Locking and Non-Blocking Synchronization on Multiprogrammed Shared Memory Multiprocessors  
Author: Maged M. Michael Michael L. Scott 
Address: Rochester, NY 14627-0226  
Affiliation: University of Rochester Department of Computer Science  
Abstract: We present a comparison of the two alternative strategies, focusing on four simple but important concurrent data structures stacks, FIFO queues, priority queues and countersin micro-benchmarks and real applications on a 12-processor SGI Challenge multiprocessor. Our results indicate that data-structure-specific non-blocking algorithms, which exist for stacks, FIFO queues and counters, can work extremely well: not only do they outperform preemption-safe lock-based algorithms on multipro-grammed machines, they also outperform ordinary locks on dedicated machines. At the same time, since general-purpose non-blocking techniques do not yet appear to be practical, preemption-safe locks remain the preferred alternative for complex data structures: they outperform conventional locks by significant margins on multiprogrammed systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Alemany and E. W. Felten. </author> <title> Performance Issues in Non-blocking Synchronization on Shared-Memory Multiprocessors. </title> <booktitle> In Proc. of the 11th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 125-134, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: The basic methodology requires copying the whole data structure on every update. Herlihy also proposed an optimization by which the programmer can avoid some fraction of the copying for certain data structures; he illustrated this optimization in a non-blocking implementation of a skew-heap. Alemany and Felten <ref> [1] </ref> and LaMarca [11] proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes.
Reference: [2] <author> R. J. Anderson and H. Woll. </author> <title> Wait-Free Parallel Algorithms for the Union-Find Problem. </title> <booktitle> In Proc. of the 23rd ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 370-380, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists. Anderson and Woll <ref> [2] </ref> proposed a non-blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented using a fetch and add atomic primitive (if supported by hardware), or a read-modify-check-write cycle using CAS or LL/SC. Performance results were reported for only a few of these algorithms [17, 19, 30].
Reference: [3] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Black's work on Mach [5] employs a recovery technique: a process may suggest to the kernel that it be descheduled in favor of some specific other process (presumably the one that is holding a desired lock). The scheduler activations of Anderson et al. <ref> [3] </ref> also support recovery: when a processor is taken from an application, another processor belonging to the same application is informed via software interrupt.
Reference: [4] <author> G. Barnes. </author> <title> A Method for Implementing Lock-Free Data Structures. </title> <booktitle> In Proc. of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June - July </month> <year> 1993. </year>
Reference-contexts: Alemany and Felten [1] and LaMarca [11] proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes. Barnes <ref> [4] </ref> presented a similar general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou [20] presented software transactional memory, which implements a k-word CAS using LL/SC.
Reference: [5] <author> D. L. Black. </author> <title> Scheduling Support for Concurrency and Parallelism in the Mach Operating System. </title> <journal> Computer, </journal> <volume> 23(5) </volume> <pages> 35-43, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: If a process verifies that it has not been warned of preemption before entering a critical section (and if critical sections are short), then it is guaranteed to be able to complete its operation in the current quantum. Otherwise, it can yield the processor voluntarily. Black's work on Mach <ref> [5] </ref> employs a recovery technique: a process may suggest to the kernel that it be descheduled in favor of some specific other process (presumably the one that is holding a desired lock).
Reference: [6] <author> J. Edler, J. Lipkis, and E. Schonberg. </author> <title> Process Management for Highly Parallel UNIX Systems. </title> <booktitle> In Proc. of the USENIX Workshop on Unix and Supercomputers, </booktitle> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: We summarize our conclusions and recommendations in section 5. 2 Preemption-Safe Locking For simple mutual exclusion locks (e.g. test and set), preemption-safe locking techniques allow the system either to avoid or to recover from the preemption of processes holding locks. Edler et al.'s Symunix system <ref> [6] </ref> employs an avoidance technique: a process may request that the kernel not preempt it because it is holding a lock, and the kernel will honor the request up to a pre-defined time limit.
Reference: [7] <author> M. P. Herlihy and J. M. Wing. </author> <title> Axions for Concurrent Objects. </title> <booktitle> In Proc. of the 14th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 13-26, </pages> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Massalin and Pu [13] presented non-blocking algorithms for array-based stacks, FIFO queues, and linked lists, using a double compare and swap (DCAS) primitive that operates on two arbitrary memory locations simultaneously. Unfortunately, this primitive is available only on the Motorola 68020 processor and its direct successors. Herlihy and Wing <ref> [7] </ref> proposed a non-blocking array-based queue algorithm that requires infinite arrays. Val-ois [23] presented a non-blocking array-based queue algorithm that requires either a non-aligned CAS (not supported on any architecture) or a Motorola-like DCAS. No practical non-blocking implementations for array-based stacks or circular queues have been proposed. <p> For the designers of future systems, we recommend (1) that hardware always include a universal atomic primitive, and (2) that kernel interfaces provide a mechanism for preemption-safe locking. For small-scale machines, the Synunix interface appears to work well <ref> [7] </ref>. For larger machines, a more elaborate interface may be appropriate [10].
Reference: [8] <author> M. Herlihy. </author> <title> Wait-Free Synchronization. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: While mutual exclusion locks can be implemented using comparatively weak atomic primitives (e.g. test and set, fetch and increment, or fetch and store), non-blocking algorithms generally require a universal <ref> [8] </ref> primitive such as compare and swap (CAS) or the pair load linked and store conditional (LL/SC). Our contribution is to evaluate the relative performance of preemption-safe and non-blocking atomic update on multipro-grammed (time-sliced) systems. We focus on four simple but important data structures: counters, queues, stacks, and priority queues.
Reference: [9] <author> M. Herlihy. </author> <title> A Methodology for Implementing Highly Concurrent Data Objects. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 15(5) </volume> <pages> 745-770, </pages> <month> Nov. </month> <year> 1993. </year> <title> Quicksort stack system, with multiprogramming levels of 1 (left), 2 (middle), and 3 (right). TSP stack and counters on a multiprogrammed system, with multiprogramming levels of 1 (left), 2 (middle), and 3 (right). </title>
Reference-contexts: Herlihy <ref> [9] </ref> presented a general methodology for transforming sequential implementations of data structures to concurrent non-blocking implementations using CAS or LL/SC. The basic methodology requires copying the whole data structure on every update. <p> Turek et al. [22] and Prakash et al. [18] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations <ref> [9, 11, 20] </ref>. Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists. <p> of the best available non-blocking algo rithms on simple data structures, we use the following in our experiments: the non-blocking link-based queues of Michael and Scott [17] and Prakash et al. [19], the non-blocking link-based stack of Treiber [21], an optimized version of a stack resulting from applying Herlihy's methodology <ref> [9] </ref>, a skew heap implementation due to Herlihy using his general methodology with optimized copying [9], and a LL/SC implementation of counters. 4 Experimental Results We use an SGI Challenge multiprocessor with twelve 100 MHz MIPS R4400 processors to compare the performance of the best non-blocking, ordinary lock-based, and preemption-safe lock-based <p> in our experiments: the non-blocking link-based queues of Michael and Scott [17] and Prakash et al. [19], the non-blocking link-based stack of Treiber [21], an optimized version of a stack resulting from applying Herlihy's methodology <ref> [9] </ref>, a skew heap implementation due to Herlihy using his general methodology with optimized copying [9], and a LL/SC implementation of counters. 4 Experimental Results We use an SGI Challenge multiprocessor with twelve 100 MHz MIPS R4400 processors to compare the performance of the best non-blocking, ordinary lock-based, and preemption-safe lock-based implementations of counters and of link-based queues, stacks, and skew heaps. <p> Stacks programming levels of 1 (left), 2 (middle), and 3 (right). preemption-safe locks, a non-blocking implementation due to Treiber [21], and an optimized non-blocking implementation based on Herlihy's general methodology <ref> [9] </ref>. Treiber's non-blocking algorithm represents the stack as a singly-linked list with a Top pointer. It uses CAS to modify the value of Top atomically. The optimized implementation based on Herlihy's methodology also uses a singly-linked list to represent the stack with a Top pointer. <p> Accordingly, Treiber's implementation yields the best performance even with no contention. 4.3 Heaps and preemption-safe locks, and an optimized non-blocking implementation due to Herlihy <ref> [9] </ref>. The latter uses a binary tree to represent the heap with a Root pointer. Every process has its own copy of Root.
Reference: [10] <author> L. I. Kontothanassis, R. W. Wisniewski, and M. L. Scott. </author> <title> Scheduler-Conscious Synchronization. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 15(1), </volume> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: Preempting and scheduling processes in an order inconsistent with their order in the lock's queue can degrade performance dramatically. Kontothanassis et al. <ref> [10] </ref> present scheduler-conscious versions of the MCS queue lock [14] and other scalable locks. These algorithms detect the descheduling of critical processes using handshaking and/or a widened kernel-user interface. <p> For the designers of future systems, we recommend (1) that hardware always include a universal atomic primitive, and (2) that kernel interfaces provide a mechanism for preemption-safe locking. For small-scale machines, the Synunix interface appears to work well [7]. For larger machines, a more elaborate interface may be appropriate <ref> [10] </ref>.
Reference: [11] <author> A. LaMarca. </author> <title> A Performance Evaluation of Lock-free Synchronization Protocols. </title> <booktitle> In Proc. of the 13th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: The basic methodology requires copying the whole data structure on every update. Herlihy also proposed an optimization by which the programmer can avoid some fraction of the copying for certain data structures; he illustrated this optimization in a non-blocking implementation of a skew-heap. Alemany and Felten [1] and LaMarca <ref> [11] </ref> proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes. Barnes [4] presented a similar general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. <p> Turek et al. [22] and Prakash et al. [18] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations <ref> [9, 11, 20] </ref>. Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists.
Reference: [12] <author> B. D. Marsh, M. L. Scott, T. J. LeBlanc, and E. P. Markatos. </author> <title> First-Class User-Level Threads. </title> <booktitle> In Proc. of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Edler et al.'s Symunix system [6] employs an avoidance technique: a process may request that the kernel not preempt it because it is holding a lock, and the kernel will honor the request up to a pre-defined time limit. The first-class threads of Marsh et al.'s Psyche system <ref> [12] </ref> require the kernel to warn an application process a fixed amount of time in advance of preemption.
Reference: [13] <author> H. Massalin and C. Pu. </author> <title> A Lock-Free Multiprocessor OS Kernel. </title> <type> Tech. Report CUCS-005-91, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: However, Treiber's stack is very simple and can be expected to be quite efficient. We also observe that a stack derived from Herlihy's general methodology, with unnecessary copying removed, seems to be simple enough to compete with lock-based implementations. Massalin and Pu <ref> [13] </ref> presented non-blocking algorithms for array-based stacks, FIFO queues, and linked lists, using a double compare and swap (DCAS) primitive that operates on two arbitrary memory locations simultaneously. Unfortunately, this primitive is available only on the Motorola 68020 processor and its direct successors.
Reference: [14] <author> J. Mellor-Crummey and M. L. Scott. </author> <title> Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Preempting and scheduling processes in an order inconsistent with their order in the lock's queue can degrade performance dramatically. Kontothanassis et al. [10] present scheduler-conscious versions of the MCS queue lock <ref> [14] </ref> and other scalable locks. These algorithms detect the descheduling of critical processes using handshaking and/or a widened kernel-user interface. The proposals of Black and of Anderson et al. require the application to recognize the preemption of lock-holding processes and to deal with the problem.
Reference: [15] <author> M. M. Michael and M. L. Scott. </author> <title> Implementation of Atomic Primitives on Distributed Shared-Memory Multiprocessors. </title> <booktitle> In Proc. of the First International Symposium on High Performance Computer Architecture, </booktitle> <pages> pp. 222-231, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: The results are similar to those observed for queues and stacks, but are even more pronounced. The non-blocking implementation outperforms the preemption-safe lock-based counter by more than 55% on 11 processors with levels of multiprogramming. The performance of a fetch and add atomic primitive would be even better <ref> [15] </ref>. 4.5 Quicksort Application We performed experiments on two versions of a parallel quick-sort application, one that uses a link-based queue, and another that uses a link-based stack for distributing items to be sorted among the cooperating processes.
Reference: [16] <author> M. M. Michael and M. L. Scott. </author> <title> Concurrent Update on Multiprogrammed Shared Memory Multiprocessors. </title> <type> Tech. Report 614, </type> <institution> Computer Science Dept., Univ. of Rochester, </institution> <month> April </month> <year> 1996. </year>
Reference-contexts: We also use two versions of a parallel quick-sort application, together with a parallel solution to the traveling salesman problem, to compare the performance of the implementations when used in a real application. 1 More detailed results are available in a technical report version of this paper <ref> [16] </ref>. Our results were obtained on a dedicated machine with application processes pinned to 11 processors and with one processor dedicated to running a pseudo-scheduler. Whenever a process is due for preemption, the pseudo-scheduler interrupts it, forcing it into a signal handler.
Reference: [17] <author> M. M. Michael and M. L. Scott. </author> <title> Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms. </title> <booktitle> In Proc. of the Fifteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 267-275, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations [9, 11, 20]. Prakash et al. [19], Valois [30], and Michael and Scott <ref> [17] </ref> proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists. Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. <p> Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented using a fetch and add atomic primitive (if supported by hardware), or a read-modify-check-write cycle using CAS or LL/SC. Performance results were reported for only a few of these algorithms <ref> [17, 19, 30] </ref>. The results of Michael and Scott indicate that their non-blocking implementation of link-based queues outperforms all other non-blocking and lock-based implementations, on both multiprogrammed and dedicated multiprocessors. The queue of Prakash et al. outperforms lock-based implementations in the case of multiprogramming. <p> For these data structures lock-based implementations seem to be the only option. As representatives of the best available non-blocking algo rithms on simple data structures, we use the following in our experiments: the non-blocking link-based queues of Michael and Scott <ref> [17] </ref> and Prakash et al. [19], the non-blocking link-based stack of Treiber [21], an optimized version of a stack resulting from applying Herlihy's methodology [9], a skew heap implementation due to Herlihy using his general methodology with optimized copying [9], and a LL/SC implementation of counters. 4 Experimental Results We use <p> (the right graph in each figure) represents a system with a process from each of three different applications on each processor. 4.1 Queues implementations are: the usual single-lock implementation using both ordinary and preemption-safe locks (single ordinary lock and single preemption-safe lock); a two-lock implementation due to Michael and Scott <ref> [17] </ref>, again using both ordinary and preemption-safe locks (two ordinary locks and two preemption-safe locks); and non-blocking implementations due to Michael and Scott [17] (MS non-blocking) and Prakash et al. [19] (PLJ non-blocking). <p> implementations are: the usual single-lock implementation using both ordinary and preemption-safe locks (single ordinary lock and single preemption-safe lock); a two-lock implementation due to Michael and Scott <ref> [17] </ref>, again using both ordinary and preemption-safe locks (two ordinary locks and two preemption-safe locks); and non-blocking implementations due to Michael and Scott [17] (MS non-blocking) and Prakash et al. [19] (PLJ non-blocking).
Reference: [18] <author> S. Prakash, Y. H. Lee, and T. Johnson. </author> <title> Non-Blocking Algorithms for Concurrent Data Structures. </title> <type> Tech. Report 91-002, </type> <institution> University of Florida, </institution> <year> 1991. </year>
Reference-contexts: Barnes [4] presented a similar general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou [20] presented software transactional memory, which implements a k-word CAS using LL/SC. Turek et al. [22] and Prakash et al. <ref> [18] </ref> presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations [9, 11, 20].
Reference: [19] <author> S. Prakash, Y. H. Lee, and T. Johnson. </author> <title> A Nonblocking Algorithm for Shared Queues Using Compare-and-Swap. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 43(5) </volume> <pages> 548-559, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations [9, 11, 20]. Prakash et al. <ref> [19] </ref>, Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists. Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. <p> Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented using a fetch and add atomic primitive (if supported by hardware), or a read-modify-check-write cycle using CAS or LL/SC. Performance results were reported for only a few of these algorithms <ref> [17, 19, 30] </ref>. The results of Michael and Scott indicate that their non-blocking implementation of link-based queues outperforms all other non-blocking and lock-based implementations, on both multiprogrammed and dedicated multiprocessors. The queue of Prakash et al. outperforms lock-based implementations in the case of multiprogramming. <p> For these data structures lock-based implementations seem to be the only option. As representatives of the best available non-blocking algo rithms on simple data structures, we use the following in our experiments: the non-blocking link-based queues of Michael and Scott [17] and Prakash et al. <ref> [19] </ref>, the non-blocking link-based stack of Treiber [21], an optimized version of a stack resulting from applying Herlihy's methodology [9], a skew heap implementation due to Herlihy using his general methodology with optimized copying [9], and a LL/SC implementation of counters. 4 Experimental Results We use an SGI Challenge multiprocessor with <p> both ordinary and preemption-safe locks (single ordinary lock and single preemption-safe lock); a two-lock implementation due to Michael and Scott [17], again using both ordinary and preemption-safe locks (two ordinary locks and two preemption-safe locks); and non-blocking implementations due to Michael and Scott [17] (MS non-blocking) and Prakash et al. <ref> [19] </ref> (PLJ non-blocking).
Reference: [20] <author> N. Shavit and D. Touitou. </author> <title> Software Transactional Memory. </title> <booktitle> In Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Barnes [4] presented a similar general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou <ref> [20] </ref> presented software transactional memory, which implements a k-word CAS using LL/SC. Turek et al. [22] and Prakash et al. [18] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. <p> Turek et al. [22] and Prakash et al. [18] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations <ref> [9, 11, 20] </ref>. Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists.
Reference: [21] <author> R. K. Treiber. </author> <title> Systems Programming: Coping with Parallelism. In RJ 5118, </title> <institution> IBM Almaden Res. Center, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations [9, 11, 20]. Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber <ref> [21] </ref> proposed a non-blocking implementation of concurrent link-based stacks. Valois [24] proposed a non-blocking implementation of linked lists. Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. <p> As representatives of the best available non-blocking algo rithms on simple data structures, we use the following in our experiments: the non-blocking link-based queues of Michael and Scott [17] and Prakash et al. [19], the non-blocking link-based stack of Treiber <ref> [21] </ref>, an optimized version of a stack resulting from applying Herlihy's methodology [9], a skew heap implementation due to Herlihy using his general methodology with optimized copying [9], and a LL/SC implementation of counters. 4 Experimental Results We use an SGI Challenge multiprocessor with twelve 100 MHz MIPS R4400 processors to <p> In the case of no contention, it is essentially tied with the single ordinary lock. 4.2 Stacks Queues multiprogramming levels of 1 (left), 2 (middle), and 3 (right). Stacks programming levels of 1 (left), 2 (middle), and 3 (right). preemption-safe locks, a non-blocking implementation due to Treiber <ref> [21] </ref>, and an optimized non-blocking implementation based on Herlihy's general methodology [9]. Treiber's non-blocking algorithm represents the stack as a singly-linked list with a Top pointer. It uses CAS to modify the value of Top atomically.
Reference: [22] <author> J. Turek, D. Shasha, and S. Prakash. </author> <title> Locking without Blocking: Making Lock Based Concurrent Data Structure Algorithms Nonblocking. </title> <booktitle> In Proc. of the 11th ACM Symposium on Principles of Database Systems, </booktitle> <pages> pp. 212-222, </pages> <year> 1992. </year>
Reference-contexts: Barnes [4] presented a similar general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou [20] presented software transactional memory, which implements a k-word CAS using LL/SC. Turek et al. <ref> [22] </ref> and Prakash et al. [18] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based implementations [9, 11, 20].
Reference: [23] <author> J. D. Valois. </author> <title> Implementing Lock-Free Queues. </title> <booktitle> In Proc. of the Seventh International Conference on Parallel and Distributed Computing Systems, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Unfortunately, this primitive is available only on the Motorola 68020 processor and its direct successors. Herlihy and Wing [7] proposed a non-blocking array-based queue algorithm that requires infinite arrays. Val-ois <ref> [23] </ref> presented a non-blocking array-based queue algorithm that requires either a non-aligned CAS (not supported on any architecture) or a Motorola-like DCAS. No practical non-blocking implementations for array-based stacks or circular queues have been proposed. The general methodologies can be used, but the resulting implementations would be very inefficient.
Reference: [24] <author> J. D. Valois. </author> <title> Lock-free Linked Lists using Compare-and-swap. </title> <booktitle> In Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Prakash et al. [19], Valois [30], and Michael and Scott [17] proposed non-blocking implementations of concurrent link-based queues. Treiber [21] proposed a non-blocking implementation of concurrent link-based stacks. Valois <ref> [24] </ref> proposed a non-blocking implementation of linked lists. Anderson and Woll [2] proposed a non-blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented using a fetch and add atomic primitive (if supported by hardware), or a read-modify-check-write cycle using CAS or LL/SC.
Reference: [25] <author> J. Zahorjan, E. D. Lazowska, and D. L. Eager. </author> <title> The Effect of Scheduling Discipline on Spin Overhead in Shared Memory Parallel Systems. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(2) </volume> <pages> 180-198, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: At the same time, most multiprocessors are preemptively multiprogrammed, for the sake of response time and processor utilization. Unfortunately, preemption of a process holding a lock can degrade application performance dramatically <ref> [25] </ref>; any other process busy-waiting on the lock is unable to perform useful work until the preempted process is rescheduled and subsequently releases the lock. fl This work was supported in part by NSF grants nos. CDA-94-01142 and CCR-93-19445, and by ONR research grant no.
References-found: 25

