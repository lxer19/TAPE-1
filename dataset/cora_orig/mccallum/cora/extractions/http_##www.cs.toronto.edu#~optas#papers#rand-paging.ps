URL: http://www.cs.toronto.edu/~optas/papers/rand-paging.ps
Refering-URL: http://www.cs.toronto.edu/~optas/work.html
Root-URL: 
Title: Competitive Analysis of Randomized Paging Algorithms  
Author: Dimitris Achlioptas Marek Chrobak John Noga 
Keyword: on-line algorithms, analysis of algorithms, competitive analysis, paging, random ized algorithms.  
Affiliation: Computer Science  
Note: To appear in Theoretical  
Abstract: The paging problem is defined as follows: we are given a two-level memory system, in which one level is a fast memory, called cache, capable of holding k items, and the second level is an unbounded but slow memory. At each given time step, a request to an item is issued. Given a request to an item p, a miss occurs if p is not present in the fast memory. In response to a miss, we need to choose an item q in the cache and replace it by p. The choice of q needs to be made on-line, without the knowledge of future requests. The objective is to design a replacement strategy with a small number of misses. In this paper we use competitive analysis to study the performance of randomized on-line paging algorithms. Our goal is to show how the concept of work functions, used previously mostly for the analysis of deterministic algorithms, can also be applied, in a systematic fashion, to the randomized case. We present two results: we first show that the competitive ratio of the marking algorithm is exactly 2H k 1. Previously, it was known to be between H k and 2H k . Then we provide a new, H k -competitive algorithm for paging. Our algorithm, as well as its analysis, is simpler than the known algorithm by McGeoch and Sleator. Another advantage of our algorithm is that it can be implemented with complexity bounds independent of the number of past requests: O(k 2 log k) memory and O(k 2 ) time per request. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Borodin, S. Irani, P. Raghavan, and B. Schieber. </author> <title> Competitive paging with locality of reference. </title> <booktitle> In Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <pages> pages 249-259, </pages> <year> 1991. </year>
Reference-contexts: In [21, 22] both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated. Several results about the so-called loose competitiveness of these problems are proven. In <ref> [1, 2] </ref> and [8] the paging problem is addressed with the assumption that after any particular request the next request is likely to be from a small set of nearby items.
Reference: [2] <author> A. Borodin, S. Irani, P. Raghavan, and B. Schieber. </author> <title> Competitive paging with locality of reference. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 50(2) </volume> <pages> 244-258, </pages> <year> 1995. </year>
Reference-contexts: In [21, 22] both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated. Several results about the so-called loose competitiveness of these problems are proven. In <ref> [1, 2] </ref> and [8] the paging problem is addressed with the assumption that after any particular request the next request is likely to be from a small set of nearby items.
Reference: [3] <author> M. Chrobak and L. L. Larmore. </author> <title> An optimal online algorithm for k servers on trees. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20 </volume> <pages> 144-148, </pages> <year> 1991. </year>
Reference-contexts: Paging is a classical on-line problem and has been extensively studied in the literature on competitive on-line algorithms. It can be viewed as a special case of the k-server problem (see, for example, <ref> [12, 13, 17, 3] </ref>), in which all distances are equal to one. For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see [20]).
Reference: [4] <author> M. Chrobak and L. L. Larmore. </author> <title> Metrical service systems: Randomized strategies. </title> <type> manuscript, </type> <year> 1992. </year>
Reference-contexts: We call this a distribution-based algorithm. The cost of a move can be defined by a so-called transport distance between the distributions. It can be shown that this approach is equivalent to the other two (see <ref> [4, 6] </ref>). Algorithm Mark is defined as a behavior algorithm, while our H k -competitive algorithm Equitable is easier to define using the distribution-based approach. However, for the sake of completeness and for cost estimation, we also show how to "implement" Equitable as a behavior algorithm.
Reference: [5] <author> M. Chrobak and L. L. Larmore. </author> <title> Generosity helps or an 11-competitive algorithm for three servers. </title> <journal> Journal of Algorithms, </journal> <volume> 16 </volume> <pages> 234-263, </pages> <year> 1994. </year> <booktitle> Also in Proceedings of ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1992, </year> <pages> 196-202. </pages>
Reference-contexts: The offset function is raised by at most max ( X !) k 1, so it is sufficient to set opt = k + 1. We refer to it as a forgiveness step, since on some configurations the overall optimal cost can actually decrease. (See <ref> [6, 5] </ref> for other examples of the forgiveness method.) The proof that B remains H k -competitive uses a more subtle potential argument.
Reference: [6] <author> M. Chrobak, L. L. Larmore, N. Reingold, and J. Westbrook. </author> <title> Page migration algorithms using work functions. </title> <type> Technical Report YALE/DCS/RR-910, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1992. </year> <note> To appear in Journal of Algorithms. </note>
Reference-contexts: Work functions have played an important role in the analysis of on-line problems. However, in the past, work functions have been used mostly in the analysis of deterministic algorithms, and only recently they have been applied to the randomized case (see <ref> [6, 15, 16, 9] </ref>). For example, in [6], some optimal randomized algorithms for the page migration problem were developed based on this technique. One of our goals is to show how work functions can also be applied in the competitive analysis of randomized algorithms for the paging problem. <p> Work functions have played an important role in the analysis of on-line problems. However, in the past, work functions have been used mostly in the analysis of deterministic algorithms, and only recently they have been applied to the randomized case (see [6, 15, 16, 9]). For example, in <ref> [6] </ref>, some optimal randomized algorithms for the page migration problem were developed based on this technique. One of our goals is to show how work functions can also be applied in the competitive analysis of randomized algorithms for the paging problem. <p> We call this a distribution-based algorithm. The cost of a move can be defined by a so-called transport distance between the distributions. It can be shown that this approach is equivalent to the other two (see <ref> [4, 6] </ref>). Algorithm Mark is defined as a behavior algorithm, while our H k -competitive algorithm Equitable is easier to define using the distribution-based approach. However, for the sake of completeness and for cost estimation, we also show how to "implement" Equitable as a behavior algorithm. <p> The offset function is raised by at most max ( X !) k 1, so it is sufficient to set opt = k + 1. We refer to it as a forgiveness step, since on some configurations the overall optimal cost can actually decrease. (See <ref> [6, 5] </ref> for other examples of the forgiveness method.) The proof that B remains H k -competitive uses a more subtle potential argument.
Reference: [7] <author> A. Fiat, R. Karp, M. Luby, L. A. McGeoch, D. Sleator, and N.E. Young. </author> <title> Competitive paging algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 12 </volume> <pages> 685-699, </pages> <year> 1991. </year>
Reference-contexts: For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see [20]). In this paper we concentrate on the randomized version of the paging problem. It is relatively easy to show (see <ref> [7] </ref>) that no randomized on-line algorithm can be better than H k -competitive, where H k = P k i=1 1=i is the k-th harmonic number. Two algorithms have been proposed for this problem in the past. Fiat et al [7] gave a simple marking algorithm, called Mark, and proved that <p> It is relatively easy to show (see <ref> [7] </ref>) that no randomized on-line algorithm can be better than H k -competitive, where H k = P k i=1 1=i is the k-th harmonic number. Two algorithms have been proposed for this problem in the past. Fiat et al [7] gave a simple marking algorithm, called Mark, and proved that it is 2H k -competitive. Subsequently, McGeoch and Sleator [18] presented another algorithm, called Partition, and proved that it is H k -competitive, and thus optimal. Work functions have played an important role in the analysis of on-line problems. <p> Koutsoupias and Papadimitriou [11] presented a simple, elegant characterization of work functions for paging. In an earlier work, McGeoch and Sleator in [18] gave an equivalent characterization of the behavior of an optimal algorithm, although their formulation did not explicitly involve work functions. Analysis of Mark. Algorithm Mark of <ref> [7] </ref>, even though not optimal, is of independent interest. It is simpler, faster and more space-efficient than Partition. Mark can be implemented using O (k) memory and O (1) time per request, while Partition may need as much as (n) memory, where n is the number of past requests. <p> It is simpler, faster and more space-efficient than Partition. Mark can be implemented using O (k) memory and O (1) time per request, while Partition may need as much as (n) memory, where n is the number of past requests. Fiat et al <ref> [7] </ref> provided an upper bound of 2H k on the 2 competitive ratio of Mark. The general lower bound is H k . Thus it would be interesting to know the exact competitiveness of this algorithm.
Reference: [8] <author> S. Irani, A. Karlin, and S. Phillips. </author> <title> Strongly competitive algorithms for paging with locality of reference. </title> <booktitle> In 3rd Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 228-236, </pages> <year> 1992. </year>
Reference-contexts: In [21, 22] both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated. Several results about the so-called loose competitiveness of these problems are proven. In [1, 2] and <ref> [8] </ref> the paging problem is addressed with the assumption that after any particular request the next request is likely to be from a small set of nearby items.
Reference: [9] <author> Sandy Irani and S. Seiden. </author> <title> Randomized algorithms for metrical task systems. </title> <booktitle> In WADS, </booktitle> <pages> pages 159-170, </pages> <year> 1995. </year>
Reference-contexts: Work functions have played an important role in the analysis of on-line problems. However, in the past, work functions have been used mostly in the analysis of deterministic algorithms, and only recently they have been applied to the randomized case (see <ref> [6, 15, 16, 9] </ref>). For example, in [6], some optimal randomized algorithms for the page migration problem were developed based on this technique. One of our goals is to show how work functions can also be applied in the competitive analysis of randomized algorithms for the paging problem.
Reference: [10] <author> A. Karlin, S. Phillips, and P. Raghavan. </author> <title> Markov paging. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 208-217, </pages> <year> 1992. </year>
Reference-contexts: There is also some recent research in this direction that does not involve work functions. In <ref> [10] </ref> the paging problem is considered in the case where the requests come from a Markov process. In [21, 22] both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated.
Reference: [11] <author> E. Koutsoupias and C. Papadimitriou. </author> <title> Beyond competitive analysis. </title> <booktitle> In Proc. 35th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 394-400, </pages> <year> 1994. </year> <month> 15 </month>
Reference-contexts: A work function approach usually starts with some characterization of work functions for a given problem. Then, the properties of work functions are used to design and analyze an on-line algorithm. Koutsoupias and Papadimitriou <ref> [11] </ref> presented a simple, elegant characterization of work functions for paging. In an earlier work, McGeoch and Sleator in [18] gave an equivalent characterization of the behavior of an optimal algorithm, although their formulation did not explicitly involve work functions. Analysis of Mark. <p> This method works for randomized algorithms as well, the only difference being that the potential now depends on the current offset function and the distribution of A, while cost A is the expected cost of A in the given move. Characterization of work functions. Koutsoupias and Papadimitriou <ref> [11] </ref> gave the following elegant characterization of the work functions for the paging problem with the cache of size k. Lemma 1 Every offset function is coned up from the set of configurations for which its value is zero. <p> We can assume that an optimal algorithm has all revealed items in the cache, since any optimal algorithm can be modified to one with this property without raising its cost. By N (!) we denote the set of non-revealed items in S (!). 5 Koutsoupias and Papadimitriou <ref> [11] </ref> also give a method for updating the layers after a request. Let ! = (L 1 j : : : jL k ). Suppose that r is a new request. <p> The competitive analysis has been criticized for being overly pessimistic. Addressing this problem, the most recent work on the competitive analysis of paging moves towards relaxing the definition of competitiveness. Koutsoupias and Papadimitriou <ref> [11] </ref> used work functions to analyze paging under two refined notions of competitiveness. The first one restricts the adversary to using a distribution chosen from a given set of distributions.
Reference: [12] <author> E. Koutsoupias and C. Papadimitriou. </author> <title> On the k-server conjecture. </title> <booktitle> In Proc. 26th Symposium on Theory of Computing, </booktitle> <pages> pages 507-511, </pages> <year> 1994. </year>
Reference-contexts: Paging is a classical on-line problem and has been extensively studied in the literature on competitive on-line algorithms. It can be viewed as a special case of the k-server problem (see, for example, <ref> [12, 13, 17, 3] </ref>), in which all distances are equal to one. For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see [20]).
Reference: [13] <author> E. Koutsoupias and C. Papadimitriou. </author> <title> On the k-server conjecture. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 42(5) </volume> <pages> 971-983, </pages> <year> 1995. </year>
Reference-contexts: Paging is a classical on-line problem and has been extensively studied in the literature on competitive on-line algorithms. It can be viewed as a special case of the k-server problem (see, for example, <ref> [12, 13, 17, 3] </ref>), in which all distances are equal to one. For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see [20]).
Reference: [14] <author> H. Kuhn. </author> <title> Extensive games and the problem of information. </title> <editor> In H. Kuhn and A. Tucker, editors, </editor> <booktitle> Contributions to the Theory of Games, </booktitle> <pages> pages 193-216. </pages> <publisher> Princeton University Press, </publisher> <year> 1953. </year>
Reference-contexts: In the theory of multi-stage games these two approaches are sometimes called, respectively, mixed strategies and behavior strategies (see, for example, <ref> [14] </ref>). The definitions of cost and competitiveness extend naturally to randomized algorithms, independently of which of the two above definitions is being used. If A is a randomized algorithm then cost A (%) denotes the expected cost of A on %, and inequality (1) remains unchanged.
Reference: [15] <author> C. Lund and N. Reingold. </author> <title> Linear programs for randomized on-line algorithms. </title> <booktitle> In Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year> <pages> 382-391. </pages>
Reference-contexts: Work functions have played an important role in the analysis of on-line problems. However, in the past, work functions have been used mostly in the analysis of deterministic algorithms, and only recently they have been applied to the randomized case (see <ref> [6, 15, 16, 9] </ref>). For example, in [6], some optimal randomized algorithms for the page migration problem were developed based on this technique. One of our goals is to show how work functions can also be applied in the competitive analysis of randomized algorithms for the paging problem.
Reference: [16] <author> C. Lund, N. Reingold, J. Westbrook, and D. Yan. </author> <title> On-line distributed data management. </title> <booktitle> In Proc. European Symposium on Algorithms, </booktitle> <year> 1994. </year> <pages> 202-214. </pages>
Reference-contexts: Work functions have played an important role in the analysis of on-line problems. However, in the past, work functions have been used mostly in the analysis of deterministic algorithms, and only recently they have been applied to the randomized case (see <ref> [6, 15, 16, 9] </ref>). For example, in [6], some optimal randomized algorithms for the page migration problem were developed based on this technique. One of our goals is to show how work functions can also be applied in the competitive analysis of randomized algorithms for the paging problem.
Reference: [17] <author> M. Manasse, L. A. McGeoch, and D. Sleator. </author> <title> Competitive algorithms for server problems. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 208-230, </pages> <year> 1990. </year>
Reference-contexts: Paging is a classical on-line problem and has been extensively studied in the literature on competitive on-line algorithms. It can be viewed as a special case of the k-server problem (see, for example, <ref> [12, 13, 17, 3] </ref>), in which all distances are equal to one. For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see [20]).
Reference: [18] <author> L. McGeoch and D. Sleator. </author> <title> A strongly competitive randomized paging algorithm. </title> <journal> J. Algorithms, </journal> <volume> 6 </volume> <pages> 816-825, </pages> <year> 1991. </year>
Reference-contexts: Two algorithms have been proposed for this problem in the past. Fiat et al [7] gave a simple marking algorithm, called Mark, and proved that it is 2H k -competitive. Subsequently, McGeoch and Sleator <ref> [18] </ref> presented another algorithm, called Partition, and proved that it is H k -competitive, and thus optimal. Work functions have played an important role in the analysis of on-line problems. <p> Then, the properties of work functions are used to design and analyze an on-line algorithm. Koutsoupias and Papadimitriou [11] presented a simple, elegant characterization of work functions for paging. In an earlier work, McGeoch and Sleator in <ref> [18] </ref> gave an equivalent characterization of the behavior of an optimal algorithm, although their formulation did not explicitly involve work functions. Analysis of Mark. Algorithm Mark of [7], even though not optimal, is of independent interest. It is simpler, faster and more space-efficient than Partition. <p> The general lower bound is H k . Thus it would be interesting to know the exact competitiveness of this algorithm. Our first result is a proof that the competitive ratio of Mark is 2H k 1. A new optimal algorithm. The result of McGeoch and Sleator <ref> [18] </ref> gives a tight bound on the optimal competitive ratio in the randomized case. However, the algorithm Partition from [18] is somewhat counter-intuitive, and both the correctness and competitiveness proofs are rather difficult. <p> Our first result is a proof that the competitive ratio of Mark is 2H k 1. A new optimal algorithm. The result of McGeoch and Sleator <ref> [18] </ref> gives a tight bound on the optimal competitive ratio in the randomized case. However, the algorithm Partition from [18] is somewhat counter-intuitive, and both the correctness and competitiveness proofs are rather difficult. In the second part of the paper, we present an alternative H k -competitive algorithm for paging, called Equitable, that we believe is simpler and more natural. <p> Thus, a stable algorithm can be described as a function A (!) giving the distribution of A if the current offset function is !. Naturally, for stable randomized algorithms the potential function will depend only on the current offset function. Partition, the algorithm proposed by McGeoch and Sleator in <ref> [18] </ref>, can be classified as distribution-based and stable. Its probability distribution is defined by the following k-round tournament: Initially, each x 2 L i is given rank i + 1. <p> We conclude this section with the following theorem. Theorem 3 Algorithm Equitable can be implemented in O (k 2 log k) memory and O (k 2 ) time per request. 5 Final Comments Both Partition from <ref> [18] </ref>, and the naive implementation of Equitable are very time and space consuming. They both use O (n) space, where n is the number of past requests.
Reference: [19] <author> P. Raghavan and M. Snir. </author> <title> Memory versus randomization in online algorithms. </title> <booktitle> In 16th International Colloquium on Automata, Languages, and Programming, Lecture Notes in Computer Science vol. </booktitle> <volume> 372, </volume> <pages> pages 687-703. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Algorithm Mark, although not optimally competitive, uses only O (k) memory and O (1) time for each request. One problem that we leave open is whether there is a simple H k -competitive algorithm for paging which requires only O (k) memory. Raghavan and Snir in <ref> [19] </ref> investigated a memory versus randomization trade-off in on-line algorithms. Is there also a trade-off between memory and competitiveness? It would also be interesting to extend the applications of work functions to other approaches to competitive analysis. The competitive analysis has been criticized for being overly pessimistic.
Reference: [20] <author> D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 202-208, </pages> <year> 1985. </year>
Reference-contexts: For the deterministic case, it has been established that the well-known Lru (least recently used) strategy is k-competitive, and that no better competitiveness is possible (see <ref> [20] </ref>). In this paper we concentrate on the randomized version of the paging problem. It is relatively easy to show (see [7]) that no randomized on-line algorithm can be better than H k -competitive, where H k = P k i=1 1=i is the k-th harmonic number.
Reference: [21] <author> N. Young. </author> <title> On-line caching as cache size varies. </title> <booktitle> In Proc. 2nd Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 241-250, </pages> <year> 1991. </year>
Reference-contexts: There is also some recent research in this direction that does not involve work functions. In [10] the paging problem is considered in the case where the requests come from a Markov process. In <ref> [21, 22] </ref> both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated. Several results about the so-called loose competitiveness of these problems are proven.
Reference: [22] <author> N. Young. </author> <title> The k-server dual and loose competitiveness for paging. </title> <journal> Algorithmica, </journal> <volume> 11(6) </volume> <pages> 525-541, </pages> <year> 1994. </year>
Reference-contexts: There is also some recent research in this direction that does not involve work functions. In [10] the paging problem is considered in the case where the requests come from a Markov process. In <ref> [21, 22] </ref> both the paging and weighted cache problems are considered as linear programming problems and the resulting dual problem is investigated. Several results about the so-called loose competitiveness of these problems are proven.
References-found: 22

