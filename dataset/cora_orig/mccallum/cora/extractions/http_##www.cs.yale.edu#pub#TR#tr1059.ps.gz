URL: http://www.cs.yale.edu/pub/TR/tr1059.ps.gz
Refering-URL: http://www.cs.yale.edu/pub/TR/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: toyama@cs.yale.edu, hager@cs.yale.edu  
Title: Keeping One's Eye on the Ball: Tracking Occluding Contours of Unfamiliar Objects without Distraction  
Author: Kentaro Toyama and Gregory D. Hager 
Address: Box 208285, New Haven, CT, 06520.  
Date: December 6, 1994  
Affiliation: Department of Computer Science Yale University  P.O.  
Abstract: Visual tracking is prone to distractions, where features similar to the target features guide the tracker away from its intended object. Global shape models and dynamic models are necessary for completely distraction-free contour tracking, but there are many cases when component feature trackers alone can be expected to avoid distraction. We define the tracking problem in general and devise a method for local, window-based, feature trackers to track accurately in spite of background distractions. The algorithm is applied to a generic line tracker and a snake-like contour tracker which are then experimentally analyzed with respect to previous contour-trackers. We discuss the advantages and disadvantages of our approach and suggest that existing model-based trackers can be improved by incorporating similar techniques at the local level. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. A. Amini, S. Tehrani, T. E. Weymouth. </author> <title> Using dynamic programming for minimizing 28 the energy of active contours in the presence of hard constraints. </title> <booktitle> In Proceedings, 2nd Int'l Conf. on Comp. Vision, </booktitle> <pages> pages 95-99, </pages> <year> 1988. </year>
Reference-contexts: In the sequel, a state space for a feature x is denoted F x : The notation F n is shorthand for Q n i=1 F i where 3 F i ; 1 i n, are arbitrary feature state spaces. The variable t 2 <ref> [0; 1] </ref> represents time. The notation f i (t) denotes the state of feature i at time t. Systems evolve continuously, but are sampled at a fixed but arbitrary time increment (which we normalize to 1). <p> The only geometric constraint is that the tracked object is a simple, closed loop. Our snake-like tracker takes elements of many previous contour trackers <ref> [1, 3, 8, 12, 14] </ref>. To determine the position of new search windows, we compute a weighted combination of predicted positions and spatially interpolated positions to calculate the parameters, w, of the search window for the lowest level.
Reference: [2] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> Affine-invariant contour tracking with automatic control of spatiotemporal scale. </title> <booktitle> In Proceedings, Int'l Conf. on Comp. Vision, </booktitle> <address> Berlin, Germany, </address> <month> May 11-14, </month> <year> 1993, </year> <pages> pp. 421-430. </pages>
Reference-contexts: At the other end of the spectrum lie simple edge detection methods <ref> [2, 4, 6] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> Even when dynamic information is known, it may not be precise enough to prevent distraction. In constraint-based tracking, no explicit model is used. However, the feature states are forced to respect one or more constraints C : F m ! &lt;: An example is found in <ref> [2] </ref>. Their work supposes constant velocity motion and an affine motion constraint on the set of features being tracked. Kalman filters applied both to the motion and the affine model allow temporary distactions to be eventually disregarded as noise. <p> Distraction occurs because individual components are simply high-gradient edge finders, and depend upon high-level models to correct them in the case that they stray. While many model- or template-based contour trackers, such as those described in <ref> [2] </ref>, might not be distracted by the high-contrast edges in Figures (a) and (b), they would still fail in cases (c) and (d), where the change in the shape of the contour is small and/or gradual. Figures 11 and 12 illustrate distraction-free tracking.
Reference: [3] <author> L. D. Cohen. </author> <title> On active contour models and balloons. </title> <booktitle> In CVGIP: Image Understanding, </booktitle> <volume> 53(2) </volume> <pages> 211-218, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: The only geometric constraint is that the tracked object is a simple, closed loop. Our snake-like tracker takes elements of many previous contour trackers <ref> [1, 3, 8, 12, 14] </ref>. To determine the position of new search windows, we compute a weighted combination of predicted positions and spatially interpolated positions to calculate the parameters, w, of the search window for the lowest level.
Reference: [4] <author> E. D. Dickmanns, and V. Graefe. </author> <title> Dynamic monocular machine vision. </title> <booktitle> In Machine Vision and Applications, </booktitle> <volume> 1 </volume> <pages> 223-240, </pages> <year> 1988. </year>
Reference-contexts: At the other end of the spectrum lie simple edge detection methods <ref> [2, 4, 6] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> In unstructured situations, we do not have prior information about the object, so strong model-based constraints usually cannot be used. Likewise, when information about the object dynamics is available, temporal constraints can be used localize the search for features <ref> [4, 5, 11] </ref>. The object dynamics can be expressed in terms of the image features [5], or in terms of a model [11]. Again, in unstructured situations, it is unlikely that highly reliable dynamic information is available, except on the camera system itself.
Reference: [5] <author> O. D. Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In unstructured situations, we do not have prior information about the object, so strong model-based constraints usually cannot be used. Likewise, when information about the object dynamics is available, temporal constraints can be used localize the search for features <ref> [4, 5, 11] </ref>. The object dynamics can be expressed in terms of the image features [5], or in terms of a model [11]. Again, in unstructured situations, it is unlikely that highly reliable dynamic information is available, except on the camera system itself. <p> Likewise, when information about the object dynamics is available, temporal constraints can be used localize the search for features [4, 5, 11]. The object dynamics can be expressed in terms of the image features <ref> [5] </ref>, or in terms of a model [11]. Again, in unstructured situations, it is unlikely that highly reliable dynamic information is available, except on the camera system itself. Even when dynamic information is known, it may not be precise enough to prevent distraction.
Reference: [6] <author> G. Hager, S. Puri, and K. Toyama. </author> <title> A framework for real-time window-based tracking using off-the-shelf hardware. </title> <type> Yale Tech Report: </type> <institution> Yale-TR-988, </institution> <year> 1993. </year>
Reference-contexts: At the other end of the spectrum lie simple edge detection methods <ref> [2, 4, 6] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> These applications are separated into two levels, where the lower level deals with local tracking and feature matching, and the upper level directs window placement and computes the state of the entire object. See <ref> [6] </ref> for more information on layered feature tracking. 5.1 Low Level Tracking The algorithm chosen above is incorporated into a 1-dimensional edge detector. Each window is simply a single line of pixels which monitors a part of the contour. <p> Equation 4 is implemented in a straight-forward manner. Edges are found by convolving a 1-dimensional discrete derivative mask with the line of pixels in a window and looking for points with gray-scale gradient above a threshold (See <ref> [6] </ref>). Regions between edges and window boundaries are identified by computing the mode of gray-scale values for each region 14 to within 2 percent of the range of possible values.
Reference: [7] <author> J. Huang and G. Hager. </author> <title> Tracking tools for vision-based navigation. </title> <note> Submitted to Int'l Conf. on Intel. Robot and Sys., </note> <year> 1995. </year>
Reference-contexts: Small changes, for example, in the local brightness or contrast can easily ruin or bias the match. We have begun to use visual tracking in a variety of applications where the environment is unstructured <ref> [7] </ref>, implying that specific geometric and dynamic information is not available. Hence, our tracking algorithms must rely on local feature detection to perform properly. In this article, we address the question of what can be tracked locally in a distraction-free fashion.
Reference: [8] <author> M. Kass, A. Witkin, and D. Terzopoulos. Snakes: </author> <title> active contour models. </title> <journal> In Int'l J. of Comp. Vision, </journal> <volume> 1 </volume> <pages> 321-331, </pages> <year> 1987. </year>
Reference-contexts: The only geometric constraint is that the tracked object is a simple, closed loop. Our snake-like tracker takes elements of many previous contour trackers <ref> [1, 3, 8, 12, 14] </ref>. To determine the position of new search windows, we compute a weighted combination of predicted positions and spatially interpolated positions to calculate the parameters, w, of the search window for the lowest level.
Reference: [9] <author> D. G. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> In Int'l J. of Comp. Vision, </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <year> 1992. </year>
Reference-contexts: Unless the feature tracker finds more than one minimum, distraction occurs only when the objective function is not accurately defined. 2.2 High-Level Constraints Three other types of information are commonly used in tracking applications. In model-based tracking, information about the geometry of features is supplied, as in <ref> [9] </ref>. Here, the configurations of physical features are expected to fit some shape model of the object, and visual tracking of those features is enough to track the state of the modeled object.
Reference: [10] <author> N. P. Papanikolopoulos, P. K. Khosla, T. Kanade. </author> <title> Visual tracking of a moving target by a camera mounted on a robot: a combination of control and vision. </title> <journal> In IEEE Trans. on Robotics and Automaton, </journal> <volume> 9(1) </volume> <pages> 14-35, </pages> <month> February, </month> <year> 1993. </year>
Reference-contexts: Temporally dependent objective functions are usually variations on auto-correlation methods. In particular, sum-of-squared-difference (SSD) methods have become quite popular <ref> [10, 13] </ref>. Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations.
Reference: [11] <author> A. A. Rizzi and D. E. Koditschek. </author> <title> An active visual estimator for dexterous manipulation. </title> <booktitle> In IEEE Int'l Conf. on Robotics and Automaton, </booktitle> <year> 1994. </year> <month> 29 </month>
Reference-contexts: In unstructured situations, we do not have prior information about the object, so strong model-based constraints usually cannot be used. Likewise, when information about the object dynamics is available, temporal constraints can be used localize the search for features <ref> [4, 5, 11] </ref>. The object dynamics can be expressed in terms of the image features [5], or in terms of a model [11]. Again, in unstructured situations, it is unlikely that highly reliable dynamic information is available, except on the camera system itself. <p> Likewise, when information about the object dynamics is available, temporal constraints can be used localize the search for features [4, 5, 11]. The object dynamics can be expressed in terms of the image features [5], or in terms of a model <ref> [11] </ref>. Again, in unstructured situations, it is unlikely that highly reliable dynamic information is available, except on the camera system itself. Even when dynamic information is known, it may not be precise enough to prevent distraction. In constraint-based tracking, no explicit model is used.
Reference: [12] <author> D. Terzopoulos and Szeliski. </author> <title> Tracking with Kalman snakes In Active Vision, </title> <editor> ed. A. Blake and A. Yuille. </editor> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The only geometric constraint is that the tracked object is a simple, closed loop. Our snake-like tracker takes elements of many previous contour trackers <ref> [1, 3, 8, 12, 14] </ref>. To determine the position of new search windows, we compute a weighted combination of predicted positions and spatially interpolated positions to calculate the parameters, w, of the search window for the lowest level.
Reference: [13] <author> C. Tomasi and T. Kanade. </author> <title> Detection and tracking of point features. </title> <type> Carnegie-Mellon Tech Report, </type> <institution> CMU-CS-91-132, </institution> <month> April, </month> <year> 1991. </year>
Reference-contexts: Temporally dependent objective functions are usually variations on auto-correlation methods. In particular, sum-of-squared-difference (SSD) methods have become quite popular <ref> [10, 13] </ref>. Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations.
Reference: [14] <author> D. J. Williams and M. Shah. </author> <title> A fast algorithm for active contours and curvature estimation. </title> <booktitle> In CVGIP: Image Understanding, </booktitle> <volume> 55(1) </volume> <pages> 14-26, </pages> <month> January </month> <year> 1992. </year> <month> 30 </month>
Reference-contexts: The only geometric constraint is that the tracked object is a simple, closed loop. Our snake-like tracker takes elements of many previous contour trackers <ref> [1, 3, 8, 12, 14] </ref>. To determine the position of new search windows, we compute a weighted combination of predicted positions and spatially interpolated positions to calculate the parameters, w, of the search window for the lowest level.
References-found: 14

