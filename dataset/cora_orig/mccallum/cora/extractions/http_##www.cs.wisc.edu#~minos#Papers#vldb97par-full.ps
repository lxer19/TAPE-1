URL: http://www.cs.wisc.edu/~minos/Papers/vldb97par-full.ps
Refering-URL: 
Root-URL: 
Title: Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources  
Note: Partially supported by the National Science Foundation under Grants IRI-9113736 and IRI-9157368 (PYI Award), and by grants from IBM, DEC, HP, AT&T, Informix, and Oracle.  
Abstract: Minos N. Garofalakis Yannis E. Ioannidis fl Computer Sciences Department University of Wisconsin Madison, WI 53706 fminos,yannisg@cs.wisc.edu A shorter version of this paper appears in the Proceedings of the 1997 VLDB Conference, pp. 296-305, Athens, Greece, August 1997. Abstract Scheduling query execution plans is a particularly complex problem in hierarchical parallel systems, where each site consists of a collection of local time-shared (e.g., CPU(s) or disk(s)) and space-shared (e.g., memory) resources and communicates with remote sites by message-passing. Earlier work on the problem employs either one-dimensional models of parallel task scheduling, effectively ignoring the potential benefits of resource sharing, or models of globally accessible resource units, ignoring the affinity of system resources to sites. In this paper, we develop a general approach capturing the full complexity of scheduling distributed multi-dimensional resource units for all forms of parallelism within and across queries and operators. We present a level-based list scheduling heuristic algorithm for independent query tasks (i.e., operator pipelines) that is provably near-optimal for given degrees of partitioned parallelism (with a worst-case performance ratio that depends on the number of time-shared and space-shared resources per site and the granularity of the clones). We also provide extensions to handle precedence constraints in bushy query plans as well as on-line task arrivals (e.g., in a dynamic or multi-query execution environment). Preliminary experimental results confirm the effectiveness of our scheduling algorithm compared to the optimal solution. Based on our analytical and experimental results, we revisit the open problem of designing efficient cost models for parallel query optimization and propose a solution that captures all the important parameters of parallel execution. 
Abstract-found: 1
Intro-found: 1
Reference: [BB90] <author> Krishna P. Belkhale and Prithviraj Banerjee. </author> <title> "Approximate Algorithms for the Partitionable Independent Task Scheduling Problem". </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages I72-I75, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field.
Reference: [BB91] <author> Krishna P. Belkhale and Prithviraj Banerjee. </author> <title> "A Scheduling Algorithm for Parallelizable Dependent Tasks". </title> <booktitle> In Proceedings of the Fifth International Parallel Processing Symposium, </booktitle> <pages> pages 500-506, </pages> <year> 1991. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field.
Reference: [BFG + 95] <author> C.K. Baru, G. Fecteau, A. Goyal, H. Hsiao, A. Jhingran, S. Padmanabhan, </author> <title> G.P. Copeland, and W.G. Wilson. "DB2 Parallel Edition". </title> <journal> IBM Systems Journal, </journal> <volume> 34(2) </volume> <pages> 292-322, </pages> <year> 1995. </year>
Reference-contexts: This suggests that it may not be a good idea to ignore resource scheduling during the optimization process. Prior work has demonstrated that divorcing the two will often result in a clearly suboptimal plan <ref> [JPS93, BFG + 95] </ref>. For example, using the traditional work (i.e., total resource consumption) metric can often result in plans that are inherently sequential and, consequently, unable to exploit the available parallelism. <p> Prior work has demonstrated that a two-phase approach [HS91, Hon92] using the traditional work metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism <ref> [JPS93, BFG + 95] </ref>. On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach [SE93, JPS93, LVZ93]) can have a tremendous impact on optimizer complexity and optimization cost.
Reference: [BFV96] <author> Luc Bouganim, Daniela Florescu, and Patrick Valduriez. </author> <title> "Dynamic Load Balancing in Hierarchical Parallel Database Systems". </title> <booktitle> In Proceedings of the 22nd International Conference on Very Large Data Bases, </booktitle> <pages> pages 436-447, </pages> <address> Mumbai(Bombay), India, </address> <month> September </month> <year> 1996. </year> <month> 25 </month>
Reference-contexts: 1 Introduction Parallelism has been recognized as a powerful and cost-effective means of handling the projected increases in data size and query complexity in future database applications. Among all proposals, the shared-nothing [DG92] and, recently, the more general hierarchical (or, hybrid) <ref> [NZT96, BFV96] </ref> multiprocessor architectures have emerged as the most scalable to support very large database management. In these systems, each site consists of its own set of local resources and communicates with other sites only by message-passing. <p> Both of these papers avoid dealing with complex query scheduling issues by assuming workloads consisting of simple binary joins and/or OLTP transactions. Bouganim et al. <ref> [BFV96] </ref> propose methods for optimizing load-balancing on each site of a hierarchical architecture at run-time so that inter-site data transfers are minimized. In their model, the optimizer still has to determine the assignment of operators to sites and the run-time environment has to make up for optimizer inaccuracies. <p> However, the general problem of scheduling operator graphs with both types of resources has not been addressed in prior work on databases or deterministic scheduling theory. 3 Problem Formulation 3.1 Definitions We consider hierarchical parallel systems <ref> [BFV96] </ref> with identical multiprogrammed resource sites connected by an interconnection network. Each site is a collection of d ts resources (e.g., CPU (s), disk (s), and network interface (s) or communication processor (s)) and s ss resources (e.g., memory).
Reference: [Bro94] <author> Kurt Brown. "PRPL: </author> <title> A Database Workload Specification Language (Version 1.4)". </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1994. </year>
Reference-contexts: Our effort suggests several directions for future research. First, we are in the process of performing an experimental evaluation of the algorithms we have devised to compare them with the worst case bound and lower bound that we have derived. We are using ZetaSim <ref> [Bro94] </ref> for this purpose and we hope to be able to report on the results in the near future. Second, the assumptions of Section 3.3 may occasionally be not reflective of reality. Extending our model and algorithms to remove (some of) these is a challenging issue.
Reference: [BS83] <author> Brenda S. Baker and Jerald S. Schwarz. </author> <title> "Shelf Algorithms for Two-Dimensional Packing Problems". </title> <journal> SIAM Journal on Computing, </journal> <volume> 12(3) </volume> <pages> 508-525, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: This bound gives us a feeling for the performance of the algorithm when the optimal response time is much larger that the longest execution time of all clones and is a better measure of performance when jSj is large <ref> [CGJT80, BS83] </ref>. Note that our scheduling algorithm combines the list scheduling method of Graham [Gra69] with the Next-Fit Decreasing Height (NFDH) shelf-based algorithm of Coffman et al. [CGJT80].
Reference: [CGJ84] <author> E.G. Coffman, Jr., M.R. Garey, and D.S. Johnson. </author> <title> "Approximation Algorithms for Bin-Packing An Updated Survey". </title> <booktitle> In "Algorithm Design for Computing System Design", </booktitle> <pages> pages 49-106. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: We will see that this new parameter plays an important role in our analytical and experimental results. The basic idea of our heuristic scheduling algorithm, termed OpSched, is to construct the partition of clones into compatible subsets incrementally, using a Next-Fit rule <ref> [CGJ84, CGJT80] </ref>. Specifically, OpSched scans the list of clones in non-increasing order of execution time. At each step, the clone selected is placed in the site B i of minimal height T site (B i ) (see Equation 1). This placement is done as follows. <p> Given a collection of operator clones in a pipeline, the schedulability question poses an N P-hard decision problem that essentially corresponds to the decision problem of s-dimensional vector packing <ref> [CGJ84] </ref>. Thus, it is highly unlikely that efficient (i.e., polynomial time) necessary and sufficient conditions for pipeline schedulability exist. Note that no such problems were raised in the previous section, since the clones were assumed to be feasible (i.e., 1-granular) and executing independently of each other.
Reference: [CGJT80] <author> E.G. Coffman, Jr., M.R. Garey, D.S. Johnson, and R.E. Tarjan. </author> <title> "Performance Bounds for Level-Oriented Two-Dimensional Packing Algorithms". </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(4) </volume> <pages> 808-826, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: We then extend our approach to multiple independent pipelines, using a level-based scheduling algorithm <ref> [CGJT80, TWPY92] </ref> that treats PipeSched as a subroutine within each level. The resulting algorithm, termed LevelSched, is analytically shown to be near-optimal for given degrees of operator parallelism. <p> We will see that this new parameter plays an important role in our analytical and experimental results. The basic idea of our heuristic scheduling algorithm, termed OpSched, is to construct the partition of clones into compatible subsets incrementally, using a Next-Fit rule <ref> [CGJ84, CGJT80] </ref>. Specifically, OpSched scans the list of clones in non-increasing order of execution time. At each step, the clone selected is placed in the site B i of minimal height T site (B i ) (see Equation 1). This placement is done as follows. <p> This bound gives us a feeling for the performance of the algorithm when the optimal response time is much larger that the longest execution time of all clones and is a better measure of performance when jSj is large <ref> [CGJT80, BS83] </ref>. Note that our scheduling algorithm combines the list scheduling method of Graham [Gra69] with the Next-Fit Decreasing Height (NFDH) shelf-based algorithm of Coffman et al. [CGJT80]. <p> Note that our scheduling algorithm combines the list scheduling method of Graham [Gra69] with the Next-Fit Decreasing Height (NFDH) shelf-based algorithm of Coffman et al. <ref> [CGJT80] </ref>. <p> Our algorithm for scheduling multiple independent pipelines uses a Next-Fit Decreasing Height (NFDH) policy <ref> [CGJT80] </ref> in conjunction with Lemma 5.2 to identify pipelines that can be scheduled to execute concurrently on P sites (i.e., in one layer of execution). PipeSched is then used for determining the execution schedule within each layer. The overall algorithm, LevelSched, is formally outlined in Figure 5.
Reference: [CHM95] <author> Chandra Chekuri, Waqar Hasan, and Rajeev Motwani. </author> <title> "Scheduling Problems in Parallel Query Optimization". </title> <booktitle> In Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 255-265, </pages> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like "work" or "time" <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. <p> Hasan and Motwani [HM94] study the tradeoff between pipelined parallelism and its communication overhead and develop near-optimal heuristics for scheduling a star or a path of pipelined relational operators on a multiprocessor architecture. Chekuri et al. <ref> [CHM95] </ref> extend these results to arbitrary pipelined operator trees. The heuristics proposed in these papers ignore both independent and partitioned parallelism. Ganguly and Wang [GW93] describe the design of a parallelizing scheduler for a tree of coarse grain operators.
Reference: [CLYY92] <author> Ming-Syan Chen, Ming-Ling Lo, Philip S. Yu, and Honesty C. Young. </author> <title> "Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins". </title> <booktitle> In Proceedings of the Eighteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 15-26, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In addition, many proposals have simplified the scheduling issues by ignoring independent (bushy tree) parallelism; these include the right-deep trees of 3 Schneider [Sch90] and the segmented right-deep trees of Chen et al. <ref> [CLYY92] </ref>. Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research [CYW92].
Reference: [CM96] <author> Soumen Chakrabarti and S. Muthukrishnan. </author> <title> "Resource Scheduling for Parallel Database and Scientific Applications". </title> <booktitle> In Proceedings of the Eighth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Padua, Italy, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: With respect to ss resources, all previous work has concentrated on simplified models, assuming that the capacity of all such resources is infinite or that they are all globally accessible to all tasks <ref> [GG75, ST94, NSHL95, CM96] </ref>. Clearly, such models do not account for the physical distribution of resource units or the possibilities of ss resource fragmentation. This limits the usefulness of these models to a shared-everything [DG92] context. <p> However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field. <p> Perhaps most importantly, even the very recent results of Shachnai and Turek [ST94] and Chakrabarti and Muthukrishnan <ref> [CM96] </ref> on multi-resource scheduling are based on the assumption that all resources are globally accessible to all tasks. <p> Given an operator clone with a (stand-alone) execution time of T and a ss demand of V , we define the vol ume vector of the clone as the product T V , i.e., the resource-time product 2 for the clone's execution <ref> [CM96] </ref>. S W , S V , and S T V are used to denote the set of work, demand, and volume vectors (respectively) for the set S of all the clones to be scheduled.
Reference: [CYW92] <author> Ming-Syan Chen, Philip S. Yu, and Kun-Lung Wu. </author> <title> "Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries". </title> <booktitle> In Proceedings of the Eighth International Conference on Data Engineering, </booktitle> <pages> pages 58-67, </pages> <address> Phoenix, Arizona, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research <ref> [CYW92] </ref>. Tan and Lu [TL93] and Niccum et al. [NSHL95] consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins.
Reference: [DG92] <author> David J. DeWitt and Jim Gray. </author> <title> "Parallel Database Systems: The Future of High Performance Database Database Systems". </title> <journal> Communications of the ACM, </journal> <volume> 35(6) </volume> <pages> 85-98, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Parallelism has been recognized as a powerful and cost-effective means of handling the projected increases in data size and query complexity in future database applications. Among all proposals, the shared-nothing <ref> [DG92] </ref> and, recently, the more general hierarchical (or, hybrid) [NZT96, BFV96] multiprocessor architectures have emerged as the most scalable to support very large database management. In these systems, each site consists of its own set of local resources and communicates with other sites only by message-passing. <p> Clearly, such models do not account for the physical distribution of resource units or the possibilities of ss resource fragmentation. This limits the usefulness of these models to a shared-everything <ref> [DG92] </ref> context. In this paper, we extend our previous formulation to present a general framework for multi-dimensional ts and ss resource scheduling in hierarchical parallel database systems. We represent query operator costs as pairs of work and demand vectors with one dimension per ts and ss resource, respectively. <p> to obtain better execution schedules. response times obtained by LevelSched. (f = 0:6, * = 0:5) 7 Parallel Query Optimization In this section, we study the implications of the analytical and experimental results presented in this paper for the open problem of designing efficient cost models for parallel query optimization <ref> [DG92] </ref>. 23 As noted in Section 1, the use of response time as optimization metric implies that a parallel query optimizer cannot afford to ignore resource scheduling during the optimization process.
Reference: [DGS + 90] <author> David J. DeWitt, Shahram Ghandeharizadeh, Donovan A. Schneider, Allan Bricker, Hui-I Hsiao, and Rick Rasmussen. </author> <title> "The Gamma Database Machine Project". </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 44-62, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: in our future work. 4.2 Quantifying the Granularity of Parallel Execution As is well known, increasing the parallelism of an operator reduces its execution time until a saturation point is reached, beyond which additional parallelism causes a speed-down, due to excessive communication startup and coordination overhead over too many sites <ref> [DGS + 90] </ref>. To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse [GGS96, GI96]. <p> Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures [GMSY93, WFA92, GI96] and validated on the Gamma research prototype <ref> [DGS + 90] </ref>. 10 Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [GI96].
Reference: [DL89] <author> Jianzhong Du and Joseph Y-T. Leung. </author> <title> "Complexity of Scheduling Parallel Task Systems". </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 2(4) </volume> <pages> 473-487, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: Moving away from the database field, there is a significant body of work on parallel task scheduling in the field of deterministic scheduling theory. Since the problem is N P-hard in the strong sense <ref> [DL89] </ref>, research efforts have concentrated on providing fast heuristics with provable worst case bounds on the suboptimality of the solution.
Reference: [GG75] <author> M.R. Garey and R.L. Graham. </author> <title> "Bounds for Multiprocessor Scheduling with Resource Constraints". </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(2) </volume> <pages> 187-200, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: With respect to ss resources, all previous work has concentrated on simplified models, assuming that the capacity of all such resources is infinite or that they are all globally accessible to all tasks <ref> [GG75, ST94, NSHL95, CM96] </ref>. Clearly, such models do not account for the physical distribution of resource units or the possibilities of ss resource fragmentation. This limits the usefulness of these models to a shared-everything [DG92] context. <p> However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical <ref> [Gra66, GG75, GLLRK79] </ref> or even more recent [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] efforts in that field.
Reference: [GGS96] <author> Sumit Ganguly, Akshay Goel, and Avi Silberschatz. </author> <title> "Efficient and Accurate Cost Models for Parallel Query Optimization". </title> <booktitle> In Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Smaller degrees result in reduced communication overhead and, therefore, increased total work (i.e., ts resource requirements) for the operator execution (i.e., coarse grain parallel executions <ref> [GW93, GGS96, GI96] </ref>). On the other hand, larger degrees of parallelism in general imply smaller ss requirements for each operator clone, thus allowing for better load balancing opportunities and tighter schedulability conditions. <p> Finally, we revisit the open problem of designing efficient cost models for parallel query optimization. In recent work, Ganguly et al. <ref> [GGS96] </ref> identified two important "bulk parameters" of a parallel query execution plan, namely average work and critical path length, that 2 are crucial to characterizing its expected response time. <p> Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both ts and ss resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [GW93, GGS96, GI96] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to ts resource use. <p> To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse <ref> [GGS96, GI96] </ref>. <p> The goal is to devise cost metrics that are more realistic than total resource consumption, in the sense that they are cognizant of the available parallelism, and at the same time are sufficiently efficient to keep the optimization process tractable. In recent work, Ganguly et al. <ref> [GGS96] </ref> suggested the use of a novel scalar cost metric for parallel query optimization. Their metric was defined as the maximum of two "bulk parameters" of a parallel query plan, namely the critical path length of the plan tree and the average work per site. <p> Consequently, we feel that these three components can provide the basis for an efficient and accurate cost model for parallel query optimizers. Finally, note that although Ganguly et al. <ref> [GGS96] </ref> suggested combining the plan parameters through a maxfg function to produce a scalar metric, the way these parameters are used should depend on the optimization strategy.
Reference: [GGW95] <author> Sumit Ganguly, Apostolos Gerasoulis, and Weining Wang. </author> <title> "Partitioning Pipelines with Communication Costs". </title> <booktitle> In Proceedings of the 6th International Conference on Information Systems and Data Management (CISMOD'95), </booktitle> <pages> pages 302-320, </pages> <address> Bombay, India, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Based on a one-dimensional model of query operator costs, the authors show their scheduler to be near-optimal for a limited space of query plans (i.e., left-deep join trees with a single materialization point in any right subtree). Ganguly et al. <ref> [GGW95] </ref> obtain similar results for the problem of partitioning independent pipelines without the coarse granularity restriction. The benefits of resource sharing and the multi-dimensionality of query operators are not addressed in these papers. Furthermore, no experimental results are reported.
Reference: [GHK92] <author> Sumit Ganguly, Waqar Hasan, and Ravi Krishnamurthy. </author> <title> "Query Optimization for Parallel Execution". </title> <booktitle> In Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 9-18, </pages> <address> San Diego, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: In these systems, each site consists of its own set of local resources and communicates with other sites only by message-passing. Despite the popularity of these architectures, the development of effective and efficient query processing and optimization techniques to exploit their full potential still remains an issue of concern <ref> [GHK92, Val93] </ref>. Perhaps the major difference between parallel query optimization and its well-understood centralized counterpart lies in the choice of response time as a more appropriate optimization metric. <p> Moreover, system resources can be categorized into two radically different classes with respect to their mode of usage by query plan operators: * Time-Shared (ts) (or, preemptable) resources (e.g., CPUs, disks, network interfaces), that can be sliced between operators at very low overhead <ref> [GHK92, GI96] </ref>. For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (ss) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads [GHK92]. <p> For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (ss) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads <ref> [GHK92] </ref>. For such resources, operators typically specify rigid capacity requirements that must be satisfied throughout their execution. 1 Most previous work on parallel query scheduling has typically ignored the multi-dimensional nature of database queries. <p> Finally, it is worth noting that the two resource classes described in Section 1 have been identified in prior work, e.g., the "stretchable" and "non-stretchable" resources of Pirahesh et al. [PMC + 90] and Ganguly et al. <ref> [GHK92] </ref>. However, the general problem of scheduling operator graphs with both types of resources has not been addressed in prior work on databases or deterministic scheduling theory. 3 Problem Formulation 3.1 Definitions We consider hierarchical parallel systems [BFV96] with identical multiprogrammed resource sites connected by an interconnection network. <p> An obvious advantage of this general formulation is that it allows us the flexibility to "draw the line" between ts and ss resources at any boundary, depending on factors such as application requirements or user view of resources. An operator tree <ref> [GHK92, Hon92, Sch90] </ref> is created as a "macro-expansion" of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> No Time-Sharing Overhead for ts Resources. Following Ganguly et al. <ref> [GHK92] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A2. Uniform ts Resource Usage. Following Ganguly et al. [GHK92], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A3. Constant ss Resource Demand. <p> No Time-Sharing Overhead for ts Resources. Following Ganguly et al. <ref> [GHK92] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A2. Uniform ts Resource Usage. Following Ganguly et al. [GHK92], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A3. Constant ss Resource Demand. The total ss requirements of an operator are constant and independent of its degree of parallelism. <p> attributes of pipelined joins are different, the degrees of partitioned parallelism differ, or different declustering schemes must be used for load balancing. 4 Quantifying Partitioned Parallelism 4.1 A Resource Usage Model Our treatment of ts resource usage is based on the model of preemptable resources proposed by Ganguly et al. <ref> [GHK92] </ref>, which we briefly describe here. <p> Although this abstraction can model the true utilization of a system resource, it does not allow us to predict exactly when the busy periods are. Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing <ref> [GHK92] </ref>. In our previous work [GI96] we presented a multi-dimensional version of the model of Ganguly et al. [GHK92] that can quantify the effects of sharing sites with ts resources among query operators. <p> Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing <ref> [GHK92] </ref>. In our previous work [GI96] we presented a multi-dimensional version of the model of Ganguly et al. [GHK92] that can quantify the effects of sharing sites with ts resources among query operators. <p> ts resources and s ss resources by the triple (T seq ; W ; V ), where: * T seq is the (stand-alone) sequential execution time of the operator, * W is a d-dimensional work vector whose components denote the work done on individual ts resources, i.e., the effective time <ref> [GHK92, GI96] </ref> for which each resource is used by the operator; and * V is an s-dimensional demand vector whose components denote the ss resource requirements of the operator throughout its execution. <p> extensions account for all forms of parallelism and quantify the effects of sharing ts and ss resources on the response time of a parallel execution. 5.2.1 Partitioned and Independent Parallelism In partitioned parallelism, the work and demand vectors of an operator are partitioned among a set of independent operator clones <ref> [GHK92] </ref>. Each clone executes on a single site and works on a portion of the operator's data. The partitioning of W op i and V op i into work and demand vectors for operator clones is determined based on statistical information kept in the DBMS catalogs. <p> For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources <ref> [GHK92, LVZ93] </ref>. This leads to a combinatorial explosion in the state that must be maintained while building the DP tree, rendering the algorithm impractical even for small query sizes. <p> For example, a DP-based parallel optimizer should use our three "bulk parameters" as a 3-dimensional vector and use a 3-dimensional "less than" to prune the search space <ref> [GHK92] </ref>. Clearly, using only three dimensions turns the Partial Order DP (PODP) approach of Ganguly et al. [GHK92] into a feasible and efficient paradigm for DP-based parallel query optimization. 24 8 Conclusions The problem of scheduling complex queries in hierarchical parallel database systems of multiple time-shared and space-shared resources has been <p> For example, a DP-based parallel optimizer should use our three "bulk parameters" as a 3-dimensional vector and use a 3-dimensional "less than" to prune the search space <ref> [GHK92] </ref>. Clearly, using only three dimensions turns the Partial Order DP (PODP) approach of Ganguly et al. [GHK92] into a feasible and efficient paradigm for DP-based parallel query optimization. 24 8 Conclusions The problem of scheduling complex queries in hierarchical parallel database systems of multiple time-shared and space-shared resources has been open for a long time both within the database field and the deterministic scheduling theory field.
Reference: [GI96] <author> Minos N. Garofalakis and Yannis E. Ioannidis. </author> <title> "Multi-dimensional Resource Scheduling for Parallel Queries". </title> <booktitle> In Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 365-376, </pages> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> Moreover, system resources can be categorized into two radically different classes with respect to their mode of usage by query plan operators: * Time-Shared (ts) (or, preemptable) resources (e.g., CPUs, disks, network interfaces), that can be sliced between operators at very low overhead <ref> [GHK92, GI96] </ref>. For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (ss) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads [GHK92]. <p> This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. In our earlier work <ref> [GI96] </ref>, we presented a multi-dimensional framework for complex query scheduling in shared-nothing parallel systems with only ts resources and developed a provably near-optimal list scheduling approach for time-sharing system resources among concurrent operators. <p> Smaller degrees result in reduced communication overhead and, therefore, increased total work (i.e., ts resource requirements) for the operator execution (i.e., coarse grain parallel executions <ref> [GW93, GGS96, GI96] </ref>). On the other hand, larger degrees of parallelism in general imply smaller ss requirements for each operator clone, thus allowing for better load balancing opportunities and tighter schedulability conditions. <p> Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both ts and ss resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [GW93, GGS96, GI96] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to ts resource use. <p> Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing [GHK92]. In our previous work <ref> [GI96] </ref> we presented a multi-dimensional version of the model of Ganguly et al. [GHK92] that can quantify the effects of sharing sites with ts resources among query operators. <p> ts resources and s ss resources by the triple (T seq ; W ; V ), where: * T seq is the (stand-alone) sequential execution time of the operator, * W is a d-dimensional work vector whose components denote the work done on individual ts resources, i.e., the effective time <ref> [GHK92, GI96] </ref> for which each resource is used by the operator; and * V is an s-dimensional demand vector whose components denote the ss resource requirements of the operator throughout its execution. <p> Time T seq is actually a function of the operator's individual resource requirements, i.e., its work vector W (sometimes emphasized by using T seq (W ) instead of T seq ), and the amount of overlap that can be achieved between processing at different resources <ref> [GI96] </ref>. This overlap is a system parameter that depends on the hardware and software architecture of the resource sites (e.g., buffering architecture for disk I/O) as well as the algorithm implementing the operator. <p> To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse <ref> [GGS96, GI96] </ref>. <p> Definition 4.1 A parallel execution of an operator op with degree of partitioned parallelism equal to N is -granular if V (op; N ) , where 1. The following quantification of coarse grain parallelism extends our earlier formulation <ref> [GI96] </ref>. <p> Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures <ref> [GMSY93, WFA92, GI96] </ref> and validated on the Gamma research prototype [DGS + 90]. 10 Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [GI96]. <p> [GMSY93, WFA92, GI96] and validated on the Gamma research prototype [DGS + 90]. 10 Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters <ref> [GI96] </ref>. The following proposition is an immediate consequence of Definition 4.3 and our communication cost model. <p> Compared to our earlier results <ref> [GI96] </ref>, the lower bound in Lemma 5.1 introduces a third term containing l (S T V ), i.e., the total volume of the parallel execution. We will see that this new parameter plays an important role in our analytical and experimental results. <p> Thus, our layer-based approach provides a uniform scheduling framework for handling intra-query as well as inter-query parallelism. As we have already indicated in our earlier work <ref> [GI96] </ref>, deriving performance bounds in the presence of data dependencies is a very difficult problem that continues to elude our efforts. The difficulty stems from the interdependencies between different execution layers: scheduling decisions made at earlier layers can impose data placement and operator execution constraints on the layers that follow. <p> Since the effects of f and * on scheduler performance were also studied in our prior work <ref> [GI96] </ref>, the experiments discussed in this paper mostly concentrate on the new parameter . (The results presented in the next section are indicative of the results 20 obtained for all values of f and *.) In all experiments, we assumed system nodes consisting of d = 3 ts resources (one CPU, <p> Note that our algorithm is consistently within a small constant factor (i.e., less than 2) of the lower bound on the optimal schedule length. Although the distance from the lower bound has certainly increased compared to our results for only ts resources (see <ref> [GI96] </ref>), the results clearly demonstrate that the worst-case multiplicative factors derived in our analytical bounds are overly pessimistic as far as average performance is concerned. Observing Figure 6 (a), it appears that TreeSched performs better for larger values of the memory granularity parameter .
Reference: [GJ79] <author> M.R. Garey and D.S. Johnson. </author> <title> "Computers and Intractability: A Guide to the Theory of NP-Completeness". W.H. </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: All the scheduling problems addressed in this paper are non-trivial generalizations of traditional multiprocessor scheduling <ref> [GJ79] </ref> and, thus, they are clearly N P-hard. Given the intractability of the problems, we develop polynomial time heuristics that are provably near-optimal , i.e., with a constant bound on the performance ratio.
Reference: [GLLRK79] <author> R.L. Graham, E.L. Lawler, J.K. Lenstra, and A.H.G. Rinnooy Kan. </author> <title> "Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey". </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 5 </volume> <pages> 287-326, </pages> <year> 1979. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical <ref> [Gra66, GG75, GLLRK79] </ref> or even more recent [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] efforts in that field.
Reference: [GMSY93] <author> Shahram Ghandeharizadeh, Robert R. Meyer, Gary L. Schultz, and Jonathan Yackel. </author> <title> "Optimal Balanced Assignments and a Parallel Database Application". </title> <journal> ORSA Journal on Computing, </journal> <volume> 5(2) </volume> <pages> 151-167, </pages> <month> Spring </month> <year> 1993. </year>
Reference-contexts: Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures <ref> [GMSY93, WFA92, GI96] </ref> and validated on the Gamma research prototype [DGS + 90]. 10 Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [GI96].
Reference: [Gra66] <author> R.L. Graham. </author> <title> "Bounds for Certain Multiprocessing Anomalies". </title> <journal> The Bell System Technical Journal, </journal> <volume> 45 </volume> <pages> 1563-1581, </pages> <month> November </month> <year> 1966. </year>
Reference-contexts: The importance of such tradeoffs for parallel query processing and optimization has been stressed earlier [HFV96] and is addressed in this work. Based on our framework, we develop a fast resource scheduling algorithm for operator pipelines called PipeSched that belongs to the class of list scheduling algorithms <ref> [Gra66] </ref>. <p> However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical <ref> [Gra66, GG75, GLLRK79] </ref> or even more recent [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] efforts in that field.
Reference: [Gra69] <author> R.L. Graham. </author> <title> "Bounds on Multiprocessing Timing Anomalies". </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year> <month> 26 </month>
Reference-contexts: We then demonstrate that a heuristic based on Graham's LPT (Largest Processing Time) list scheduling method <ref> [Gra69] </ref> can guarantee near-optimal schedules for such operators. Lemma 5.1 Let fop i ; i = 1; : : : M g be a collection of independent operators with respective degrees of partitioned parallelism N = (N 1 ; N 2 ; : : : ; N M ). <p> Note that our scheduling algorithm combines the list scheduling method of Graham <ref> [Gra69] </ref> with the Next-Fit Decreasing Height (NFDH) shelf-based algorithm of Coffman et al. [CGJT80]. <p> Lemma 5.2 The number of sites required to schedule a -granular pipeline C ( &lt; 1) is always less than or equal to l (S V 1 . Furthermore, this bound is tight. Our heuristic, PipeSched, belongs to the family of list scheduling algorithms <ref> [Gra69] </ref>. PipeSched assumes that it is given a number of sites P C that is sufficient for the scheduling of C, according to the condition of Lemma 5.2. The algorithm considers the clones in S C in non-increasing order of their work density ratio l (W i ) .
Reference: [Gra93] <author> Goetz Graefe. </author> <title> "Query Evaluation Techniques for Large Databases". </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2):73--170, </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: The problems with load-balancing a pipelined execution have been identified in previous work <ref> [Gra93] </ref>. Compared to our model of a schedule for partitioned and independent parallelism (Definition 5.1), pipelined execution constrains the placement and execution of compatible clone subsets to ensure that all the clones in a pipe run concurrently they all start and terminate at the same time [HM94].
Reference: [GW93] <author> Sumit Ganguly and Weining Wang. </author> <title> "Optimizing Queries for Coarse Grain Parallelism". </title> <type> Technical Report LCSR-TR-218, </type> <institution> Department of Computer Sciences, Rutgers University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like "work" or "time" <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. <p> Smaller degrees result in reduced communication overhead and, therefore, increased total work (i.e., ts resource requirements) for the operator execution (i.e., coarse grain parallel executions <ref> [GW93, GGS96, GI96] </ref>). On the other hand, larger degrees of parallelism in general imply smaller ss requirements for each operator clone, thus allowing for better load balancing opportunities and tighter schedulability conditions. <p> Chekuri et al. [CHM95] extend these results to arbitrary pipelined operator trees. The heuristics proposed in these papers ignore both independent and partitioned parallelism. Ganguly and Wang <ref> [GW93] </ref> describe the design of a parallelizing scheduler for a tree of coarse grain operators. <p> Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both ts and ss resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [GW93, GGS96, GI96] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to ts resource use. <p> W p (op) W c (op;N) and V (op; N ), where * W p (op) denotes the total amount of work performed during the execution of op on a single site, when 9 all its operands are locally resident (i.e., zero communication cost); it corresponds to the processing area <ref> [GW93] </ref> of op and is constant for all possible executions of op; * W c (op; N ) denotes the total communication overhead incurred when the execution of op is partitioned among N clones; it corresponds to the communication area of the partitioned execution of op and is a non-decreasing function <p> The memory requirement of hash-join operators was estimated as F times the size of the inner join relation, where F is a "fudge factor" capturing the hash table overheads [Sha86]. The values of the cost model parameters were obtained from the literature <ref> [HCY94, GW93, WFA92] </ref> and are summarized in Table 2.
Reference: [HCY94] <author> Hui-I Hsiao, Ming-Syan Chen, and Philip S. Yu. </author> <title> "On Parallel Execution of Multiple Pipelined Hash Joins". </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 185-196, </pages> <address> Minneapolis, Minnesota, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like "work" or "time" <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. <p> Tan and Lu [TL93] and Niccum et al. [NSHL95] consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins. For the same problem, Hsiao et al. <ref> [HCY94] </ref> propose a processor allocation scheme based on the concept of synchronous execution time: the set of processors allotted to a parent join pipeline are recursively partitioned among its subtrees in such a way that those subtrees can be completed at approximately the same time. <p> We have devised an algorithm for scheduling bushy execution plan trees that consists of the following steps: 1. Construct the corresponding operator and task trees, and for each operator, determine its individual resource requirements using hardware parameters, DBMS statistics, and conventional optimizer cost models (e.g., <ref> [SAC + 79, HCY94] </ref>). 2. For each floating operator, determine the degree of parallelism based on the ts vs. ss resource tradeoffs discussed above (partitioned parallelism). 3. Place the tasks corresponding to the leaf nodes of the task tree in the ready list L of the scheduler. <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. <ref> [HCY94] </ref>. The communication costs were calculated using the model described in Section 4. The memory requirement of hash-join operators was estimated as F times the size of the inner join relation, where F is a "fudge factor" capturing the hash table overheads [Sha86]. <p> The memory requirement of hash-join operators was estimated as F times the size of the inner join relation, where F is a "fudge factor" capturing the hash table overheads [Sha86]. The values of the cost model parameters were obtained from the literature <ref> [HCY94, GW93, WFA92] </ref> and are summarized in Table 2.
Reference: [HFV96] <author> Waqar Hasan, Daniela Florescu, and Patrick Valduriez. </author> <title> "Open Issues in Parallel Query Optimization". </title> <journal> ACM SIGMOD Record, </journal> <volume> 25(3) </volume> <pages> 28-33, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: On the other hand, larger degrees of parallelism in general imply smaller ss requirements for each operator clone, thus allowing for better load balancing opportunities and tighter schedulability conditions. The importance of such tradeoffs for parallel query processing and optimization has been stressed earlier <ref> [HFV96] </ref> and is addressed in this work. Based on our framework, we develop a fast resource scheduling algorithm for operator pipelines called PipeSched that belongs to the class of list scheduling algorithms [Gra66]. <p> On the other hand, it also increases the total amount of work l (S W C ) because of the overhead of parallelism. The importance of such work-space tradeoffs for parallel query processing and optimization has been stressed in recent work <ref> [HFV96] </ref>. 5.4.2 Scheduling Multiple Independent -granular Pipelines The basic observation here is that the PipeSched algorithm presented in the previous section can be used to schedule any collection of independent pipelines as long as schedulability is guaranteed by Lemma 5.2.
Reference: [HM94] <author> Waqar Hasan and Rajeev Motwani. </author> <title> "Optimization Algorithms for Exploiting the Parallelism-Communication Tradeoff in Pipelined Parallelism". </title> <booktitle> In Proceedings of the 20th International Conference on Very Large Data Bases, </booktitle> <pages> pages 36-47, </pages> <address> Santiago, Chile, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like "work" or "time" <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. <p> Proofs of theoretical results presented in this paper can be found in Appendix A. 2 Related Work The problem of scheduling complex query plans on parallel machines has recently attracted a lot of attention from the database research community. Hasan and Motwani <ref> [HM94] </ref> study the tradeoff between pipelined parallelism and its communication overhead and develop near-optimal heuristics for scheduling a star or a path of pipelined relational operators on a multiprocessor architecture. Chekuri et al. [CHM95] extend these results to arbitrary pipelined operator trees. <p> Compared to our model of a schedule for partitioned and independent parallelism (Definition 5.1), pipelined execution constrains the placement and execution of compatible clone subsets to ensure that all the clones in a pipe run concurrently they all start and terminate at the same time <ref> [HM94] </ref>. This means that it is no longer possible to schedule resources at one site independent of the others, as we suggested in the previous section. Compatible subsets containing clones from the same pipeline must run concurrently.
Reference: [Hon92] <author> Wei Hong. </author> <title> "Exploiting Inter-Operation Parallelism in XPRS". </title> <booktitle> In Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 19-28, </pages> <address> San Diego, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> This has the serious drawback that some obvious, critical co-scheduling may be lost. For example, although it may be highly desirable to combine CPU-bound and IO-bound tasks from different plans <ref> [Hon92] </ref>, this may not be possible after the collapse. Wilschut et al. [WFA95] present a comparative performance evaluation of various multi-join execution strategies on the PRISMA/DB parallel main-memory database system. <p> Perhaps the only exception is Hong's method for exploiting independent parallelism in the XPRS shared-memory database system <ref> [Hon92] </ref>. His approach is based on dynamically balancing resource use between one I/O-bound and one CPU-bound operator pipeline to ensure that the system always executes at its IO-CPU balance point. However, the substantial cost of communication renders such a scheduling method impractical for shared-nothing or hierarchical systems. <p> An obvious advantage of this general formulation is that it allows us the flexibility to "draw the line" between ts and ss resources at any boundary, depending on factors such as application requirements or user view of resources. An operator tree <ref> [GHK92, Hon92, Sch90] </ref> is created as a "macro-expansion" of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> Prior work has demonstrated that a two-phase approach <ref> [HS91, Hon92] </ref> using the traditional work metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism [JPS93, BFG + 95].
Reference: [HS91] <author> Wei Hong and Michael Stonebraker. </author> <title> "Optimization of Parallel Query Execution Plans in XPRS". </title> <booktitle> In Proceedings of the First International Conference on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, Florida, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: Prior work has demonstrated that a two-phase approach <ref> [HS91, Hon92] </ref> using the traditional work metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism [JPS93, BFG + 95].
Reference: [Ioa93] <author> Yannis E. Ioannidis. </author> <title> "Universality of Serial Histograms". </title> <booktitle> In Proceedings of the Nineteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 256-267, </pages> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Similarly, the ss grain size V (op; N ) can be estimated using traditional optimizer cost models and statistics kept in the database catalogs on the distribution of attribute values <ref> [Ioa93, PI96] </ref>.
Reference: [JPS93] <author> Anant Jhingran, Sriram Padmanabhan, and Ambuj Shatdal. </author> <title> "Join Query Optimization in Parallel Database Systems". </title> <booktitle> In Proceedings of the IEEE Workshop on Advances in Parallel and Distributed Systems, </booktitle> <year> 1993. </year>
Reference-contexts: This suggests that it may not be a good idea to ignore resource scheduling during the optimization process. Prior work has demonstrated that divorcing the two will often result in a clearly suboptimal plan <ref> [JPS93, BFG + 95] </ref>. For example, using the traditional work (i.e., total resource consumption) metric can often result in plans that are inherently sequential and, consequently, unable to exploit the available parallelism. <p> Prior work has demonstrated that a two-phase approach [HS91, Hon92] using the traditional work metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism <ref> [JPS93, BFG + 95] </ref>. On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach [SE93, JPS93, LVZ93]) can have a tremendous impact on optimizer complexity and optimization cost. <p> On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach <ref> [SE93, JPS93, LVZ93] </ref>) can have a tremendous impact on optimizer complexity and optimization cost. For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources [GHK92, LVZ93].
Reference: [KM92] <author> Ramesh Krishnamurti and Eva Ma. </author> <title> "An Approximation Algorithm for Scheduling Tasks on Varying Partition Sizes in Partitionable Multiprocessor Systems". </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(12) </volume> <pages> 1572-1579, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field.
Reference: [LCRY93] <author> Ming-Ling Lo, Ming-Syan Chen, C.V. Ravishankar, and Philip S. Yu. </author> <title> "On Optimal Processor Allocation to Support Pipelined Hash Joins". </title> <booktitle> In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 69-78, </pages> <address> Washington, D.C., </address> <month> June </month> <year> 1993. </year>
Reference-contexts: As a result, significant research effort has concentrated on the problem of minimizing the response time of a single query through parallelization of an execution plan, i.e., scheduling of the plan's operators on the system's sites <ref> [CHM95, GW93, GI96, HM94, Hon92, HCY94, LCRY93] </ref>. Most of these efforts, however, are based on simplifying assumptions that limit their applicability. <p> It has simplified the allocation of resources to a mere allocation of processors, hiding the multi-dimensionality of query operators under a scalar cost metric like "work" or "time" <ref> [CHM95, GW93, HM94, HCY94, LCRY93] </ref>. This one-dimensional model of scheduling is inadequate for database operations that impose a significant load on multiple system resources. <p> Ganguly et al. [GGW95] obtain similar results for the problem of partitioning independent pipelines without the coarse granularity restriction. The benefits of resource sharing and the multi-dimensionality of query operators are not addressed in these papers. Furthermore, no experimental results are reported. Lo et al. <ref> [LCRY93] </ref> develop optimal schemes for assigning processors to the stages of a pipeline of hash-joins in a shared-disk environment. Their schemes are based on a two-phase minimax formulation of the problem that ignores communication costs and prevents processor sharing among stages.
Reference: [LVZ93] <author> Rosana S.G. Lanzelotte, Patrick Valduriez, and Mohamed Za it. </author> <title> "On the Effectiveness of Optimization Search Strategies for Parallel Execution Spaces". </title> <booktitle> In Proceedings of the Nineteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 493-504, </pages> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach <ref> [SE93, JPS93, LVZ93] </ref>) can have a tremendous impact on optimizer complexity and optimization cost. For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources [GHK92, LVZ93]. <p> For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources <ref> [GHK92, LVZ93] </ref>. This leads to a combinatorial explosion in the state that must be maintained while building the DP tree, rendering the algorithm impractical even for small query sizes.
Reference: [MD95] <author> Manish Mehta and David J. DeWitt. </author> <title> "Managing Intra-operator Parallelism in Parallel Database Systems". </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases, </booktitle> <pages> pages 382-394, </pages> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Wilschut et al. [WFA95] present a comparative performance evaluation of various multi-join execution strategies on the PRISMA/DB parallel main-memory database system. Mehta and DeWitt <ref> [MD95] </ref> and Rahm and Marek [RM95] present experimental evaluations of various heuristic strategies for determining the degree of intra-operation parallelism and assigning processors in shared-nothing DBMSs. Both of these papers avoid dealing with complex query scheduling issues by assuming workloads consisting of simple binary joins and/or OLTP transactions.
Reference: [NSHL95] <author> Thomas M. Niccum, Jaideep Srivastava, Bhaskar Himatsingka, and Jianzhong Li. </author> <title> "Query Optimization and Processing in Parallel Databases". </title> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <volume> 22 </volume> <pages> 259-287, </pages> <year> 1995. </year>
Reference-contexts: With respect to ss resources, all previous work has concentrated on simplified models, assuming that the capacity of all such resources is infinite or that they are all globally accessible to all tasks <ref> [GG75, ST94, NSHL95, CM96] </ref>. Clearly, such models do not account for the physical distribution of resource units or the possibilities of ss resource fragmentation. This limits the usefulness of these models to a shared-everything [DG92] context. <p> Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research [CYW92]. Tan and Lu [TL93] and Niccum et al. <ref> [NSHL95] </ref> consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins.
Reference: [NZT96] <author> Michael G. Norman, Thomas Zurek, and Peter Thanisch. </author> <title> "Much Ado About Shared-Nothing". </title> <journal> ACM SIGMOD Record, </journal> <volume> 25(3) </volume> <pages> 16-21, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Parallelism has been recognized as a powerful and cost-effective means of handling the projected increases in data size and query complexity in future database applications. Among all proposals, the shared-nothing [DG92] and, recently, the more general hierarchical (or, hybrid) <ref> [NZT96, BFV96] </ref> multiprocessor architectures have emerged as the most scalable to support very large database management. In these systems, each site consists of its own set of local resources and communicates with other sites only by message-passing.
Reference: [PI96] <author> Viswanath Poosala and Yannis E. Ioannidis. </author> <title> "Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing". </title> <booktitle> In Proceedings of the 22nd International Conference on Very Large Data Bases, </booktitle> <pages> pages 448-459, </pages> <address> Mumbai(Bombay), India, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: Similarly, the ss grain size V (op; N ) can be estimated using traditional optimizer cost models and statistics kept in the database catalogs on the distribution of attribute values <ref> [Ioa93, PI96] </ref>.
Reference: [PMC + 90] <author> Hamid Pirahesh, C. Mohan, Josephine Cheng, T.S. Liu, and Pat Selinger. </author> <title> "Parallelism in Relational Data Base Systems: </title> <booktitle> Architectural Issues and Design Approaches". In Proceedings of the Second International Symposium on Databases in Parallel and Distributed Systems, </booktitle> <pages> pages 4-29, </pages> <address> Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: To the best of our knowledge, there are no previous theoretical results on multi-resource scheduling in this context. Finally, it is worth noting that the two resource classes described in Section 1 have been identified in prior work, e.g., the "stretchable" and "non-stretchable" resources of Pirahesh et al. <ref> [PMC + 90] </ref> and Ganguly et al. [GHK92].
Reference: [RM95] <author> Erhard Rahm and Robert Marek. </author> <title> "Dynamic Multi-Resource Load Balancing in Parallel Database Systems". </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases, </booktitle> <pages> pages 395-406, </pages> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Wilschut et al. [WFA95] present a comparative performance evaluation of various multi-join execution strategies on the PRISMA/DB parallel main-memory database system. Mehta and DeWitt [MD95] and Rahm and Marek <ref> [RM95] </ref> present experimental evaluations of various heuristic strategies for determining the degree of intra-operation parallelism and assigning processors in shared-nothing DBMSs. Both of these papers avoid dealing with complex query scheduling issues by assuming workloads consisting of simple binary joins and/or OLTP transactions.
Reference: [SAC + 79] <author> P. Selinger, M.M. Astrahan, D.D. Chamberlin, R.A. Lorie, and T.G. Price. </author> <title> "Access Path Selection in a Relational Database Management System". </title> <booktitle> In Proceedings of the 1979 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34, </pages> <address> Boston, Massachusetts, </address> <month> June </month> <year> 1979. </year>
Reference-contexts: We have devised an algorithm for scheduling bushy execution plan trees that consists of the following steps: 1. Construct the corresponding operator and task trees, and for each operator, determine its individual resource requirements using hardware parameters, DBMS statistics, and conventional optimizer cost models (e.g., <ref> [SAC + 79, HCY94] </ref>). 2. For each floating operator, determine the degree of parallelism based on the ts vs. ss resource tradeoffs discussed above (partitioned parallelism). 3. Place the tasks corresponding to the leaf nodes of the task tree in the ready list L of the scheduler. <p> graphically demonstrated in Figure 3. 4.3 Degree of Partitioned Parallelism Assuming zero communication costs, the ts and ss resource requirements of an operator are described by a d-dimensional work vector W and an s-dimensional demand vector V whose components can be derived from system parameters and traditional optimizer cost models <ref> [SAC + 79] </ref>. By definition, the processing area of the operator W p (op) is simply the sum of W 's components, i.e., W p (op) = P d i=1 W [i].
Reference: [Sch90] <author> Donovan A. Schneider. </author> <title> "Complex Query Processing in Multiprocessor Database Machines". </title> <type> PhD thesis, </type> <institution> University of Wisconsin-Madison, </institution> <month> September </month> <year> 1990. </year> <month> 27 </month>
Reference-contexts: With the exception of the papers mentioned above, most efforts are experimental in nature and offer no theoretical justification for the algorithms that they propose. In addition, many proposals have simplified the scheduling issues by ignoring independent (bushy tree) parallelism; these include the right-deep trees of 3 Schneider <ref> [Sch90] </ref> and the segmented right-deep trees of Chen et al. [CLYY92]. Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research [CYW92]. <p> An obvious advantage of this general formulation is that it allows us the flexibility to "draw the line" between ts and ss resources at any boundary, depending on factors such as application requirements or user view of resources. An operator tree <ref> [GHK92, Hon92, Sch90] </ref> is created as a "macro-expansion" of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> This means that intermediate disk I/O has to be performed at one or more pipeline stages, essentially modifying the original plan with the addition of extra blocking and data dependencies. Various multi-pass schemes for pipelined hash-join execution under limited memory were studied in the work of Schneider <ref> [Sch90] </ref>. As part of our future work, we plan to investigate the effects of such memory limitations on our scheduling methodology and results.
Reference: [SE93] <author> Jaideep Srivastava and Gary Elsesser. </author> <title> "Optimizing Multi-Join Queries in Parallel Relational Databases". </title> <booktitle> In Proceedings of the Second International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 84-92, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach <ref> [SE93, JPS93, LVZ93] </ref>) can have a tremendous impact on optimizer complexity and optimization cost. For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources [GHK92, LVZ93].
Reference: [Sha86] <author> Leonard D. Shapiro. </author> <title> "Join Processing in Database Systems with Large Main Memories". </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(3) </volume> <pages> 239-264, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Note that even though it is possible to execute a hash-join with less memory <ref> [Sha86] </ref>, such memory limitations complicate the processing of multi-join pipelines since probe operators cannot keep their entire data sets (i.e., inner hash tables) in memory, it is no longer possible to execute the probe pipeline in one pass. <p> The communication costs were calculated using the model described in Section 4. The memory requirement of hash-join operators was estimated as F times the size of the inner join relation, where F is a "fudge factor" capturing the hash table overheads <ref> [Sha86] </ref>. The values of the cost model parameters were obtained from the literature [HCY94, GW93, WFA92] and are summarized in Table 2.
Reference: [ST94] <author> Hadas Shachnai and John J. Turek. </author> <title> "Multiresource Malleable Task Scheduling". </title> <note> Submitted for publication, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: With respect to ss resources, all previous work has concentrated on simplified models, assuming that the capacity of all such resources is infinite or that they are all globally accessible to all tasks <ref> [GG75, ST94, NSHL95, CM96] </ref>. Clearly, such models do not account for the physical distribution of resource units or the possibilities of ss resource fragmentation. This limits the usefulness of these models to a shared-everything [DG92] context. <p> However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field. <p> Perhaps most importantly, even the very recent results of Shachnai and Turek <ref> [ST94] </ref> and Chakrabarti and Muthukrishnan [CM96] on multi-resource scheduling are based on the assumption that all resources are globally accessible to all tasks.
Reference: [TL93] <author> Kian-Lee Tan and Hongjun Lu. </author> <title> "On Resource Scheduling of Multi-join Queries in Parallel Database Systems". </title> <journal> Information Processing Letters, </journal> <volume> 48 </volume> <pages> 189-195, </pages> <year> 1993. </year>
Reference-contexts: Nevertheless, the advantages offered by such parallelism, especially for large queries, have been demonstrated in prior research [CYW92]. Tan and Lu <ref> [TL93] </ref> and Niccum et al. [NSHL95] consider the general problem of scheduling bushy join plans on parallel machines exploiting all forms of intra-query parallelism and suggest heuristic methods of splitting the bushy plan into non-overlapping shelves of concurrent joins.
Reference: [TWPY92] <author> John Turek, Joel L. Wolf, Krishna R. Pattipati, and Philip S. Yu. </author> <title> "Scheduling Parallelizable Tasks: Putting it All on the Shelf". </title> <booktitle> In Proceedings of the 1992 ACM SIGMETRICS Conference on Measurement & Modeling of Computer Systems, </booktitle> <pages> pages 225-236, </pages> <address> Newport, Rhode Island, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: We then extend our approach to multiple independent pipelines, using a level-based scheduling algorithm <ref> [CGJT80, TWPY92] </ref> that treats PipeSched as a subroutine within each level. The resulting algorithm, termed LevelSched, is analytically shown to be near-optimal for given degrees of operator parallelism.
Reference: [TWY92] <author> John Turek, Joel L. Wolf, and Philip S. Yu. </author> <title> "Approximate Algorithms for Scheduling Parallelizable Tasks". </title> <booktitle> In Proceedings of the Fourth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 323-332, </pages> <address> San Diego, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field.
Reference: [Val93] <author> Patrick Valduriez. </author> <title> "Parallel Database Systems: Open Problems and New Issues". </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 1 </volume> <pages> 137-165, </pages> <year> 1993. </year>
Reference-contexts: In these systems, each site consists of its own set of local resources and communicates with other sites only by message-passing. Despite the popularity of these architectures, the development of effective and efficient query processing and optimization techniques to exploit their full potential still remains an issue of concern <ref> [GHK92, Val93] </ref>. Perhaps the major difference between parallel query optimization and its well-understood centralized counterpart lies in the choice of response time as a more appropriate optimization metric.
Reference: [WC92] <author> Qingzhou Wang and Kam Hoi Cheng. </author> <title> "A Heuristic of Scheduling Parallel Tasks and its Analysis". </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(2) </volume> <pages> 281-294, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: However, scheduling query plans on shared-nothing or hierarchical architectures requires a significantly richer model of parallelization than what is assumed in the classical [Gra66, GG75, GLLRK79] or even more recent <ref> [BB90, BB91, KM92, TWY92, WC92, ST94, CM96] </ref> efforts in that field.
Reference: [WFA92] <author> Annita N. Wilschut, Jan Flokstra, and Peter M.G. Apers. </author> <title> "Parallelism in a Main-Memory DBMS: </title> <booktitle> The Performance of PRISMA/DB". In Proceedings of the Eighteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 521-532, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures <ref> [GMSY93, WFA92, GI96] </ref> and validated on the Gamma research prototype [DGS + 90]. 10 Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [GI96]. <p> The memory requirement of hash-join operators was estimated as F times the size of the inner join relation, where F is a "fudge factor" capturing the hash table overheads [Sha86]. The values of the cost model parameters were obtained from the literature <ref> [HCY94, GW93, WFA92] </ref> and are summarized in Table 2.
Reference: [WFA95] <author> Annita N. Wilschut, Jan Flokstra, and Peter M.G. Apers. </author> <title> "Parallel Evaluation of Multi-join Queries". </title> <booktitle> In Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 115-126, </pages> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: This has the serious drawback that some obvious, critical co-scheduling may be lost. For example, although it may be highly desirable to combine CPU-bound and IO-bound tasks from different plans [Hon92], this may not be possible after the collapse. Wilschut et al. <ref> [WFA95] </ref> present a comparative performance evaluation of various multi-join execution strategies on the PRISMA/DB parallel main-memory database system. Mehta and DeWitt [MD95] and Rahm and Marek [RM95] present experimental evaluations of various heuristic strategies for determining the degree of intra-operation parallelism and assigning processors in shared-nothing DBMSs.
Reference: [WTCY94] <author> Joel L. Wolf, John Turek, Ming-Syan Chen, and Philip S. Yu. </author> <title> "Scheduling Multiple Queries on a Parallel Machine". </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement & Modeling of Computer Systems, </booktitle> <pages> pages 45-55, </pages> <address> Nashville, Tennessee, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: For deep execution plans, there exists a point beyond which further partitioning is detrimental or even impossible, and serialization must be employed for better performance. Wolf et al. <ref> [WTCY94] </ref> present a (one-dimensional) hierarchical algorithm for scheduling multiple parallel queries. Their main idea is to collapse each query plan to a single "large" parallel job and then apply the known results for independent jobs. This has the serious drawback that some obvious, critical co-scheduling may be lost.
References-found: 56

