URL: http://www.cs.berkeley.edu/~alanm/CP/schauser.ipps9.95.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Email: fschauser,chrissg@cs.ucsb.edu  
Title: Active Messages Implementations for the Meiko CS-2  
Author: Klaus E. Schauser and Chris J. Scheiman 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: Active messages provide a low latency communication architecture which on modern parallel machines achieves more than an order of magnitude performance improvement over more traditional communication libraries. It is used by library and compiler writers to obtain the utmost performance and has been used to implement the novel parallel language Split-C. This paper discusses the experience we gained while implementing active messages on the Meiko CS-2, and discusses implementations for similar architectures. The CS-2 is an interesting experimental platform, as it resembles a cluster of Sparc workstations, each equipped with a dedicated communication co-processor. During our work we have identified two mismatches between the requirements of active message and the Meiko CS-2 architecture. First, architectures which only support efficient remote write operations (or DMA transfers as in the case of the CS-2) make it difficult to transfer both data and control as required by active messages. Traditional network interfaces avoid this problem because they have a single point of entry which essentially acts as a queue. To efficiently support active messages on modern network communication co-processors, hardware primitives are required which support this queue behavior. We overcame this problem by producing specialized code which runs on the communications co-processor and supports the active messages protocol. We also identify hardware primitives which are required to efficiently support active messages. The second mismatch is that active messages do not provide a non-blocking form of send, which is required to achieve the highest possible bandwidth while allowing the overlap of communication and computation when a communications co-processor is present. We propose to extend the current active message definition to include a non-blocking form of send. Our implementation of active messages results in a one-way latency of 12:3s and achieves up to 39 MB/s for bulk transfers. Both numbers are close to optimal for the current Meiko hardware and are competitive with performance of active messages on other hardware platforms.
Abstract-found: 1
Intro-found: 1
Reference: [BLA + 94] <author> M. A. Blumrich, K. Li, R. Alpert, C. Dubnicki, and E. W. Felten. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> In Proc. of the 21st Int'l Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: The next generation goes a step further and allows fully protected user-level remote memory accesses without the involvement of main processor and the operating system (e.g., Cray T3D, Shrimp project <ref> [BLA + 94] </ref>). It is difficult to implement active messages efficiently on these architectures since remote writes alone are not sufficient. It is easier on architectures which provide a freely programmable co-processor to handle communication (e.g., Meiko CS-2, *T [NPA92]).
Reference: [CDG + 93] <author> D. E. Culler, A. Dusseau, S. C. Golstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: The small overhead and low latency facilitates building more complicated communication layers [TM94] and makes it a desirable target for high-level language compilers <ref> [CGSvE93, CDG + 93] </ref>. Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 [vECGS92], Paragon, as well as clusters of workstations connected by FDDI [Mar94] and ATM [vEABB94]. <p> Such is the case for the parallel language Split-C <ref> [CDG + 93] </ref>. Split-C is a C-like language with a number of communication primitives; among them are the data transfer primitives get, put, read, write, and store. Split-C data transfers are kept track of using counters, and Split-C uses active messages to increment and decrement these counters.
Reference: [CGSvE93] <author> D. E. Culler, S. C. Goldstein, K. E. Schauser, and T. von Eicken. </author> <title> TAM A Compiler Controlled Threaded Abstract Machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: The small overhead and low latency facilitates building more complicated communication layers [TM94] and makes it a desirable target for high-level language compilers <ref> [CGSvE93, CDG + 93] </ref>. Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 [vECGS92], Paragon, as well as clusters of workstations connected by FDDI [Mar94] and ATM [vEABB94]. <p> From Figure 1, we see that bulk puts, via the active message implementation, achieve a bandwidth of up to 39 MB/second. 7 Related Work Active messages originated out of the Berkeley TAM group which was looking for efficient communication primitives required for fine-grained parallel languages <ref> [CGSvE93] </ref>. The first active message implementation was developed for the Ncube/2 and CM-5 and resulted in more than an order of magnitude performance improvement over more traditional communication architectures [vECGS92].
Reference: [CKL + 94] <author> D. Culler, K. Keeton, L. T. Liu, A. Mainwaring, R. Martin, S. Rodrigues, and K. Wright. </author> <title> Generic Active Message Interface Specification. </title> <institution> UC Berkeley, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: The programmer could then continue on with other work, as long as the data being transferred is not touched until the send is complete. To alleviate this mismatch future versions of active messages, particularly the Generic Active Messages definition <ref> [CKL + 94] </ref>, include non-blocking sends for bulk transfers. Of course this also requires introducing a new synchronization primitive into active messages which allows to test for the completion of a bulk transfer.
Reference: [CKP + 93] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Table 2 summarizes the results, which are discussed in more detail below. The performance is presented in terms of the parameters of the LogP model <ref> [CKP + 93] </ref>. L : is the latency, or time for a message to travel from a source to a destination processor, disregarding overhead. o s : is the sending overhead. This is the time the main processor is involved in sending a message.
Reference: [HM93] <author> M. Homewood and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <booktitle> In Proc. of Hot Interconnects, </booktitle> <month> August </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: The CS-2, the most recent MPP built by Meiko, consists of Sparc based nodes connected via a fat tree communication network <ref> [HM93] </ref>. The CS-2 is an interesting architecture as it closely resembles a cluster of workstations, which is widely accepted as the future of parallel processing. <p> Section 7 discusses related work. Finally, Section 8 summarizes our experiences and concludes. 2 The Meiko CS-2 Architecture The CS-2 is the most recent machine built by Meiko. It consists of Sparc based nodes connected via a fat tree communication network <ref> [HM93] </ref>. Running a slightly enhanced version of the Solaris 2.3 operating system on every node, it closely resembles a cluster of workstations connected by a fast network. For maximum floating point performance each node can optionally be equipped with vector units. <p> The main processor and the thread processor can set, clear, and wait on events. The DMA engine and input processors can also set events. The most common use of an event is as a flag to indicate the completion of a DMA transfer. As reported in <ref> [HM93] </ref>, the highest obtainable performance at the user level with DMAs is a 9s one-way latency for small messages, and a peak sustained bandwidth of 44 MB/s for long messages.
Reference: [Kea94] <author> J. Kuskin and et. al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proc. of the 21st Int'l Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: It is easier on architectures which provide a freely programmable co-processor to handle communication (e.g., Meiko CS-2, *T [NPA92]). Modern shared memory machines such as the Flash architecture also integrate a fully programmable communications co-processor, but allow only system code to run on it to facilitate protection <ref> [Kea94] </ref>. 8 Conclusions This paper reports on our experience with implementing active messages on the Meiko CS-2. Active messages provide an extremely simple but efficient communication architecture. They are universal; with active messages one can support any protocol.
Reference: [Mar94] <author> R. P. Martin. HPAM: </author> <title> An Active Message Layer for a Network of HP Workstations. </title> <booktitle> In Proc. of Hot Interconnects II, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 [vECGS92], Paragon, as well as clusters of workstations connected by FDDI <ref> [Mar94] </ref> and ATM [vEABB94]. In most, if not all, of these cases, active messages are a natural solution for obtaining low latency communication. In most of these systems the main processor is involved in both the sending and receiving of messages. <p> This is either ensured by involving the operating system on every message (Ncube/2 [vE93], SparcStation cluster [vEABB94]), using gang scheduling (CM-5 [vE93]), or combining gang scheduling with some hardware support (HP cluster <ref> [Mar94] </ref>). Protection on the Meiko CS-2 is trivial since it is done completely by the Elan processor in hardware. 3 3.2 Reliability To provide reliability, we must ensure that each message is delivered to the destination once and only once. <p> Thus, only a single message can be outstanding for any pair of processors. It is easy to extend this using k message deep input buffers <ref> [Mar94] </ref>. Now it is possible to overlap several communication operations to the same processor and it is possible to combine the acknowledgment of multiple messages. Unfortunately, as we have found out, using many buffers leads to a larger working set and therefore to a higher cache miss rate. <p> As a consequence, active messages were embraced by applications and systems programmers and were integrated into the CM-5 message library [TM94]. Since then active messages have been implemented on several other hardware platforms, including the Paragon, a cluster of HP workstations connected by FDDI <ref> [Mar94] </ref>, and a cluster of SparcStations connected by ATM [vEABB94]. The last two implementations were especially challenging, since they had to solve the problem of unreliable message delivery. As previously mentioned, active messages are essentially a very limited form of RPC.
Reference: [NPA92] <author> R. S. Nikhil, G. M. Papadopoulos, and Arvind. </author> <title> *T: A Multithreaded Massively Parallel Architecture. </title> <booktitle> In Proc. 19th. Annual Intl. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: It is difficult to implement active messages efficiently on these architectures since remote writes alone are not sufficient. It is easier on architectures which provide a freely programmable co-processor to handle communication (e.g., Meiko CS-2, *T <ref> [NPA92] </ref>). Modern shared memory machines such as the Flash architecture also integrate a fully programmable communications co-processor, but allow only system code to run on it to facilitate protection [Kea94]. 8 Conclusions This paper reports on our experience with implementing active messages on the Meiko CS-2.
Reference: [TLL93] <author> C. A. Thekkath, H. M. Levy, and E. D. Lazowska. </author> <title> Efficient Support for Multicomputing on ATM Networks. </title> <type> Technical Report TR 93-04-03, </type> <institution> Dep. of Computer Science and Engineering, Univ. of Washington, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Like active messages, RPCs require the transfer of both data and control. Unlike active messages, the control transfer is much more expensive because no limitations are placed on what an RPC may contain. As 16 pointed out by <ref> [TLL93] </ref>, the control transfer of RPC is often unnecessary. These researchers have shown that advances in operating systems research and more modern network interfaces facilitate efficient fully protected remote memory accesses, achieving a communication performance which is competitive with that found on parallel computers [TLL93]. <p> As 16 pointed out by <ref> [TLL93] </ref>, the control transfer of RPC is often unnecessary. These researchers have shown that advances in operating systems research and more modern network interfaces facilitate efficient fully protected remote memory accesses, achieving a communication performance which is competitive with that found on parallel computers [TLL93]. As a consequence they advocate separating the data and control transfer present in RPC [TLL94]. The research of efficient communication architectures is very much driven by the advances in network interface technology.
Reference: [TLL94] <author> C. A. Thekkath, H. M. Levy, and E. D. Lazowska. </author> <title> Separating Data and Control Transfer in Distributed Operating Systems. </title> <booktitle> In ASPLOS, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: As a consequence they advocate separating the data and control transfer present in RPC <ref> [TLL94] </ref>. The research of efficient communication architectures is very much driven by the advances in network interface technology. The first generation of network interfaces were pure slave devices and required some involvement of the operating system (on every message or by gang scheduling) to ensure protection.
Reference: [TM94] <author> L. W. Tucker and A. Mainwaring. </author> <title> CMMD: Active messages on the CM-5. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: As a result, active messages achieve an order of magnitude performance improvement over more traditional communication mechanisms. 1 Although they are quite primitive, active messages have become an important communication layer because of their efficiency. The small overhead and low latency facilitates building more complicated communication layers <ref> [TM94] </ref> and makes it a desirable target for high-level language compilers [CGSvE93, CDG + 93]. Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 [vECGS92], Paragon, as well as clusters of workstations connected by FDDI [Mar94] and ATM [vEABB94]. <p> The first active message implementation was developed for the Ncube/2 and CM-5 and resulted in more than an order of magnitude performance improvement over more traditional communication architectures [vECGS92]. As a consequence, active messages were embraced by applications and systems programmers and were integrated into the CM-5 message library <ref> [TM94] </ref>. Since then active messages have been implemented on several other hardware platforms, including the Paragon, a cluster of HP workstations connected by FDDI [Mar94], and a cluster of SparcStations connected by ATM [vEABB94]. <p> Active messages provide an extremely simple but efficient communication architecture. They are universal; with active messages one can support any protocol. As pointed out in <ref> [TM94] </ref>, using a single underlying mechanism such as active messages to implement higher level communication protocols is useful, as it naturally allows for multiple co-existing communication primitives without the danger of deadlock or conflicting resource requirements. Many communication protocols (e.g., tagged messages) require a basic functionality similar to active messages.
Reference: [vE93] <author> T. von Eicken. </author> <title> Active Messages: an Efficient Communications Architecture for Multiprocessors. </title> <type> PhD thesis, </type> <institution> Computer Science Division EECS, U.C. Berkeley, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: This is either ensured by involving the operating system on every message (Ncube/2 <ref> [vE93] </ref>, SparcStation cluster [vEABB94]), using gang scheduling (CM-5 [vE93]), or combining gang scheduling with some hardware support (HP cluster [Mar94]). <p> This is either ensured by involving the operating system on every message (Ncube/2 <ref> [vE93] </ref>, SparcStation cluster [vEABB94]), using gang scheduling (CM-5 [vE93]), or combining gang scheduling with some hardware support (HP cluster [Mar94]).
Reference: [vEABB94] <author> T. von Eicken, V. Avula, A. Basu, and V. </author> <title> Buch. Low-Latency Communication over ATM Networks using Active Messages. </title> <booktitle> In Proc. of Hot Interconnects II, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 [vECGS92], Paragon, as well as clusters of workstations connected by FDDI [Mar94] and ATM <ref> [vEABB94] </ref>. In most, if not all, of these cases, active messages are a natural solution for obtaining low latency communication. In most of these systems the main processor is involved in both the sending and receiving of messages. <p> This is either ensured by involving the operating system on every message (Ncube/2 [vE93], SparcStation cluster <ref> [vEABB94] </ref>), using gang scheduling (CM-5 [vE93]), or combining gang scheduling with some hardware support (HP cluster [Mar94]). <p> Since then active messages have been implemented on several other hardware platforms, including the Paragon, a cluster of HP workstations connected by FDDI [Mar94], and a cluster of SparcStations connected by ATM <ref> [vEABB94] </ref>. The last two implementations were especially challenging, since they had to solve the problem of unreliable message delivery. As previously mentioned, active messages are essentially a very limited form of RPC. Thus one would expect the large body of work on RPC to be directly related to active messages.
Reference: [vECGS92] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: 1 Introduction Active messages provide an efficient communication architecture which exposes the raw capabilities of the underlying hardware <ref> [vECGS92] </ref>. Although usable by application programmers, it is mainly targeted at compiler and library writers who want to obtain the utmost in performance. Active messages associate with each message a handler function which is executed on the receiving processor upon arrival of the message. <p> The small overhead and low latency facilitates building more complicated communication layers [TM94] and makes it a desirable target for high-level language compilers [CGSvE93, CDG + 93]. Over the past several years active messages have been implemented on many different hardware platforms, including the CM-5 and Ncube/2 <ref> [vECGS92] </ref>, Paragon, as well as clusters of workstations connected by FDDI [Mar94] and ATM [vEABB94]. In most, if not all, of these cases, active messages are a natural solution for obtaining low latency communication. <p> When requests and replies do not share resources, it is easy to ensure that no communication deadlock can occur. In the case where a send inside a request handler fails, all that need to be done is to process incoming replies <ref> [vECGS92] </ref>. To simplify the description, we will limit our discussion throughout this paper to a single incoming buffer. The reader should keep in mind that in reality we always have two incoming buffers. 5 The scheme described so far only uses one incoming buffer for every other processor. <p> The first active message implementation was developed for the Ncube/2 and CM-5 and resulted in more than an order of magnitude performance improvement over more traditional communication architectures <ref> [vECGS92] </ref>. As a consequence, active messages were embraced by applications and systems programmers and were integrated into the CM-5 message library [TM94].
References-found: 15

