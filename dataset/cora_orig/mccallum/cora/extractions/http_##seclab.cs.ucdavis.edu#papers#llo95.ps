URL: http://seclab.cs.ucdavis.edu/papers/llo95.ps
Refering-URL: http://seclab.cs.ucdavis.edu/papers.html
Root-URL: http://www.cs.ucdavis.edu
Email: &lt;lo@cs.ucdavis.edu&gt;  &lt;levitt@cs.ucdavis.edu&gt;  &lt;olsson@cs.ucdavis.edu&gt;  
Phone: Phone: (916) 752-7004 Fax: (916) 752-4767  
Title: MCF: A Malicious Code Filter  
Author: Raymond W. Lo Karl N. Levitt Ronald A. Olsson Raymond W. Lo, 
Date: 94039-7311.  
Note: This work is supported by the United States Department of Defense, Lawrence Livermore National Laboratory, and Deloitte Touche. Current address:  
Address: Davis, CA 95616-8562  2011 N. Shoreline Blvd., P.O. Box 7311, M/S 10U-178, Mountain View, CA  
Affiliation: Department of Computer Science University of California, Davis  Silicon Graphics, Inc.,  
Abstract: Address editorial correspondence regarding this paper to Olsson.] 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Robert W. Baldwin, Kuang: </author> <title> Rule-Based Security Checking, </title> <booktitle> Kuang.man in comp.sources.unix/volume21/cops, </booktitle> <month> (Mar. </month> <year> 1990). </year>
Reference-contexts: ow modification: The main procedure modifies its return address by overowing the array x and replacing the return address in the stack with the address of unreachable (). unreachable () is executed when main () returns. */ unreachable () - puts ("virus"); exit (); - main () - int x <ref> [1] </ref>; /* the offset of the return address from x, 2 * sizeof (int), is system dependent */ x [2] = unreachable; - Stealth programming using data execution: This program executes on a Sun 3 workstation. data [] contains a machine code program to print out the string "virus". */ data <p> The direct holes may be closed by carefully examining the protection mode of security-related system files. The indirect holes are harder to close because a thorough understanding of the interaction of various components in the system is required. The COPS package [8] detects direct holes, and the Kuang <ref> [1] </ref> package iden tifies some of the indirect holes. (3) Wait for the proper condition or look for certain patterns. A malicious code starts when certain conditions are met. For example, a PC EXE virus only infects EXE files in the system. <p> to cause the autologin protocol; 116 * -h is used by other servers to pass the name of the 117 * remote host to login so that it may be placed in utmp and wtmp - 19 - 118 */ 119 while (argc &gt; 1) - 120 if (strcmp (argv <ref> [1] </ref>, "-r") == 0) - 121 if (rag || hag) - 122 printf ("Only one of -r and -h allowed"n"); 123 exit (1); 124 - 125 if (argv [2] == 0) 126 exit (1); 127 rag = 1; 128 usererr = doremotelogin (argv [2]); 129 SCPYN (utmp.ut_host, argv [2]); 130 argc <p> of -r and -h allowed"n"); 123 exit (1); 124 - 125 if (argv [2] == 0) 126 exit (1); 127 rag = 1; 128 usererr = doremotelogin (argv [2]); 129 SCPYN (utmp.ut_host, argv [2]); 130 argc -= 2; 131 argv += 2; 132 continue; 133 - 134 if (strcmp (argv <ref> [1] </ref>, "-h") == 0 && getuid () == 0) - 135 if (rag || hag) - 136 printf ("Only one of -r and -h allowed"n"); 137 exit (1); 138 - 140 SCPYN (utmp.ut_host, argv [2]); 141 argc -= 2; 142 argv += 2; 143 continue; 144 - 145 if (strcmp (argv <p> "-h") == 0 && getuid () == 0) - 135 if (rag || hag) - 136 printf ("Only one of -r and -h allowed"n"); 137 exit (1); 138 - 140 SCPYN (utmp.ut_host, argv [2]); 141 argc -= 2; 142 argv += 2; 143 continue; 144 - 145 if (strcmp (argv <ref> [1] </ref>, "-p") == 0) - 146 argc; 147 argv++; 148 pag = 1; 149 continue; 150 - 151 break; 152 - 153 ioctl (0, TIOCLSET, &zero); 154 ioctl (0, TIOCNXCL, 0); 155 ioctl (0, FIONBIO, &zero); 156 ioctl (0, FIOASYNC, &zero); 157 ioctl (0, TIOCGETP, &ttyb); 158 /* 159 * If <p> tty++; 180 openlog ("login", LOG_ODELAY, LOG_AUTH); 181 t = 0; 182 invalid = FALSE; 183 do - 184 ldisc = 0; 185 ioctl (0, TIOCSETD, &ldisc); 186 SCPYN (utmp.ut_name, ""); 187 /* 188 * Name specified, take it. 189 */ 190 if (argc &gt; 1) - 191 SCPYN (utmp.ut_name, argv <ref> [1] </ref>); 192 argc = 0; 193 - 195 * If remote login take giv en name, 196 * otherwise prompt user for something. 197 */ 198 if (rag && !invalid) 199 SCPYN (utmp.ut_name, lusername); 200 else - 201 getloginname (&utmp); 202 if (utmp.ut_name [0] == '-') - 203 puts ("login names
Reference: 2. <author> Robert S. Boyer, Bernard Elspas, Karl N. Levitt, </author> <title> SELECTA Formal System for Testing and Debugging Programs by Symbolic Execution, </title> <booktitle> Proceedings of International Conference on Reliable Software, </booktitle> <pages> pp. </pages> <month> 234-245 </month> <year> (1975). </year>
Reference-contexts: This analysis will investigate the exact nature of the previously identified suspicious property, determine its triggering conditions, and possibly discover additional suspicious properties. So far, MCF operates only in the first mode. Techniques such as symbolic evaluation <ref> [2] </ref>, dynamic analysis [11,12], and testing [9] will be very useful in building the second mode. - 15 - Appendix A: Examples of Bad-behaved Programs /* Stealth programming using pointer overow: The pointer p is overowed to point the string "siruv". <p> in the stack with the address of unreachable (). unreachable () is executed when main () returns. */ unreachable () - puts ("virus"); exit (); - main () - int x [1]; /* the offset of the return address from x, 2 * sizeof (int), is system dependent */ x <ref> [2] </ref> = unreachable; - Stealth programming using data execution: This program executes on a Sun 3 workstation. data [] contains a machine code program to print out the string "virus". */ data [] = - 0x4e560000, 0xdffc0000, 0x48d7, 0x4878, 0x6487a, 0x1c4878, 0x161ff, 0xc, 0x4fef000c, 0x4e5e4e75, 0x48780004, 0x4e404e75, 0x76697275, 0x730a0000, 0 main <p> may be placed in utmp and wtmp - 19 - 118 */ 119 while (argc &gt; 1) - 120 if (strcmp (argv [1], "-r") == 0) - 121 if (rag || hag) - 122 printf ("Only one of -r and -h allowed"n"); 123 exit (1); 124 - 125 if (argv <ref> [2] </ref> == 0) 126 exit (1); 127 rag = 1; 128 usererr = doremotelogin (argv [2]); 129 SCPYN (utmp.ut_host, argv [2]); 130 argc -= 2; 131 argv += 2; 132 continue; 133 - 134 if (strcmp (argv [1], "-h") == 0 && getuid () == 0) - 135 if (rag || <p> &gt; 1) - 120 if (strcmp (argv [1], "-r") == 0) - 121 if (rag || hag) - 122 printf ("Only one of -r and -h allowed"n"); 123 exit (1); 124 - 125 if (argv <ref> [2] </ref> == 0) 126 exit (1); 127 rag = 1; 128 usererr = doremotelogin (argv [2]); 129 SCPYN (utmp.ut_host, argv [2]); 130 argc -= 2; 131 argv += 2; 132 continue; 133 - 134 if (strcmp (argv [1], "-h") == 0 && getuid () == 0) - 135 if (rag || hag) - 136 printf ("Only one of -r and -h allowed"n"); 137 exit (1); 138 <p> (strcmp (argv [1], "-r") == 0) - 121 if (rag || hag) - 122 printf ("Only one of -r and -h allowed"n"); 123 exit (1); 124 - 125 if (argv <ref> [2] </ref> == 0) 126 exit (1); 127 rag = 1; 128 usererr = doremotelogin (argv [2]); 129 SCPYN (utmp.ut_host, argv [2]); 130 argc -= 2; 131 argv += 2; 132 continue; 133 - 134 if (strcmp (argv [1], "-h") == 0 && getuid () == 0) - 135 if (rag || hag) - 136 printf ("Only one of -r and -h allowed"n"); 137 exit (1); 138 - 140 SCPYN (utmp.ut_host, argv <p> 130 argc -= 2; 131 argv += 2; 132 continue; 133 - 134 if (strcmp (argv [1], "-h") == 0 && getuid () == 0) - 135 if (rag || hag) - 136 printf ("Only one of -r and -h allowed"n"); 137 exit (1); 138 - 140 SCPYN (utmp.ut_host, argv <ref> [2] </ref>); 141 argc -= 2; 142 argv += 2; 143 continue; 144 - 145 if (strcmp (argv [1], "-p") == 0) - 146 argc; 147 argv++; 148 pag = 1; 149 continue; 150 - 151 break; 152 - 153 ioctl (0, TIOCLSET, &zero); 154 ioctl (0, TIOCNXCL, 0); 155 ioctl (0, <p> short st_dev; 33 short st_ino; 34 short st_mode; 35 short st_nlink; 36 short st_uid; 37 short st_gid; 38 short st_rdev; 39 int st_size; 40 int st_atime; 41 int st_spare1; 42 int st_mtime; 43 int st_spare2; 44 int st_ctime; 45 int st_spare3; 46 long st_blksize; 47 long st_blocks; 48 long st_spare4 <ref> [2] </ref>; 49 - sbuf; 50 51 int Guessed [26]; 52 53 char Word [1024], 54 Known [1024], 55 *Noose_pict [] = - 56 " ______", 58 " |", 60 " |", 62 " __|_____", 64 " |_________|", 66 -; 68 int Errors, 69 Wordnum = 0; 70 71 oat Av erage
Reference: 3. <author> Ralf Burger, </author> <title> Computer Viruses: A High-tech Disease, </title> <booktitle> Abacus (1988). </booktitle>
Reference-contexts: Anomalous file accesses. The virus opens and writes to executable files, normally only done by compilers and linkers. These tell-tale signs do not identify only the W virus, but also others. For example, we can detect the RUSH HOUR virus <ref> [3] </ref>, which was developed and published for virus demonstration, using the fourth tell-tale sign. The RUSH HOUR virus is intended to harmlessly show the danger of viruses to computer systems. The virus only lodges itself in the MS-DOS German keyboard driver KEYBGR.COM.
Reference: 4. <author> Fred Cohen, </author> <title> Computer Viruses: Theory and Experiments, Computer Security: A Global Challenge, </title> <year> (1984). </year>
Reference-contexts: 1. Introduction Malicious programs can cause loss of confidentiality and integrity, or cause denial of resources. Common classes of malicious programs include computer viruses <ref> [4] </ref>, computer worms [13], Trojan horses, and programs that exploit security holes, covert channels, and administrative aws to achieve malicious purposes. Some program properties allow us to discern malicious programs from benign programs easily with very high accuracy without the need to give a specification of the program. <p> Details can be found in [10] Nevertheless, the checker can verify most array accesses automatically, but there are some cases that the tool cannot handle. 8. Conclusion Tell-tale signs are useful in discriminating malicious from benign programs. Since no discrimination method is perfect, as shown by Cohen <ref> [4] </ref>, we identify a larger class of program called suspicious programs. Suspicious programs are those that carry code that might perform malicious action. Tell-tale signs can identify such programs.
Reference: 5. <author> Fred Cohen, </author> <title> A Cryptographic Checksum for Integrity Protection, Computers and Security 6 pp. </title> <month> 505-510 </month> <year> (1987). </year>
Reference-contexts: Therefore, they do not have the problems associated with run-time approaches. However, static analysis is harder to implement. Current static methods are comparison-based. They fall into the following three general categories according to whether the program is 1) compared with a clean copy of the program <ref> [5] </ref>, 2) compared with known malicious code (used by virus scanners), or 3) compared against a formal specification [7]. Unfortunately, a clean program is not easily obtained, the most dangerous malicious code are the unknown ones. Also the formal specification and verification of programs is at best difficult.
Reference: 6. <author> R. Crawford, R. Lo, J. Crossley, G. F ink, P. Kerchen, W. Ho, K. Levitt, R. Olsson, M. Archer, </author> <title> A Testbed for Malicious Code Detection: A Synthesis of Static and Dynamic Analysis Techniques, </title> <booktitle> Proceedings of the Department of Energy Computer Security Group Conference, </booktitle> <pages> pp. 17 </pages> <month> 1-23 (May </month> <year> 1991). </year>
Reference-contexts: Unfortunately, a clean program is not easily obtained, the most dangerous malicious code are the unknown ones. Also the formal specification and verification of programs is at best difficult. Commonly used programs often have no specifications and are very unlikely to be verified. Dynamic analysis <ref> [6] </ref> combines the concept of testing and debugging to detect malicious activities by running a program in a clean-room environment. The execution is typically monitored (e.g., by a programmable debugger [11] ) for suspicious behavior.
Reference: 7. <author> Steve Crocker, M aria M. Pozzo, </author> <title> A Proposal for a Verification-Based Virus Filter, </title> <booktitle> Proceedings of the IEEE Computer Society Symposium on Security and Privacy, </booktitle> <pages> pp. </pages> <month> 319-324 (May </month> <year> 1989). </year>
Reference-contexts: Current static methods are comparison-based. They fall into the following three general categories according to whether the program is 1) compared with a clean copy of the program [5], 2) compared with known malicious code (used by virus scanners), or 3) compared against a formal specification <ref> [7] </ref>. Unfortunately, a clean program is not easily obtained, the most dangerous malicious code are the unknown ones. Also the formal specification and verification of programs is at best difficult. Commonly used programs often have no specifications and are very unlikely to be verified. <p> in hangman.c */ 2 4 #include &lt;stdio.h&gt; 5 #include &lt;sys/types.h&gt; 6 #include &lt;sys/stat.h&gt; 7 #include &lt;ctype.h&gt; 8 10 # define MINLEN 6 11 # define MAXERRS 7 12 # define BUFSIZ 1024 13 # define DICT "/usr/dict/words" 14 16 struct ERR_POS - 17 int y; 19 char ch; 20 Err_pos <ref> [7] </ref> = - 22 - 3, 10, '|' -, 24 - 5, 9, '/' -, 26 - 3, 11, '"' -, 28 -; 30 struct stat 31 - 32 short st_dev; 33 short st_ino; 34 short st_mode; 35 short st_nlink; 36 short st_uid; 37 short st_gid; 38 short st_rdev; 39 int
Reference: 8. <author> Dan Farmer, COPS and Robbers: </author> <title> UN*X System Security, </title> <booktitle> COPS.report in comp.sources.unix/volume21/cops, </booktitle> <month> (Mar. </month> <year> 1990). </year>
Reference-contexts: The direct holes may be closed by carefully examining the protection mode of security-related system files. The indirect holes are harder to close because a thorough understanding of the interaction of various components in the system is required. The COPS package <ref> [8] </ref> detects direct holes, and the Kuang [1] package iden tifies some of the indirect holes. (3) Wait for the proper condition or look for certain patterns. A malicious code starts when certain conditions are met. For example, a PC EXE virus only infects EXE files in the system.
Reference: 9. <author> Richard Hamlet, </author> <title> Testing Programs to Detect Malicious Faults, </title> <booktitle> Proceedings of the IFIP Working Conference on Dependable Computing, </booktitle> <pages> pp. </pages> <month> 162-169 (Feb. </month> <year> 1991). </year>
Reference-contexts: The execution is typically monitored (e.g., by a programmable debugger [11] ) for suspicious behavior. The analysis is in general more reliable than run-time approaches because data are generated systematically to test the program <ref> [9] </ref>. Test coverage analysis will also reveal parts of programs not covered by the analysis. Compared with static analysis, dynamic analysis is less reliable because testing can never be exhaustive. - 4 - Malicious code can be detected by a human analyst screening the program. <p> This analysis will investigate the exact nature of the previously identified suspicious property, determine its triggering conditions, and possibly discover additional suspicious properties. So far, MCF operates only in the first mode. Techniques such as symbolic evaluation [2], dynamic analysis [11,12], and testing <ref> [9] </ref> will be very useful in building the second mode. - 15 - Appendix A: Examples of Bad-behaved Programs /* Stealth programming using pointer overow: The pointer p is overowed to point the string "siruv". By dereferencing p, we can actually change the string "siruv" to "virus".
Reference: 10. <author> Raymond W. Lo, </author> <title> Static Analysis of Programs with Application to Malicious Code Detection, </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Computer Science, University of California at Davis, </institution> <month> (Sep. </month> <year> 1992). </year>
Reference-contexts: Section 6 contains the analysis of one user program and one system program. Section 7 describes how MCF can be defeated and introduces the well-behaved property. Section 9 concludes the paper. This paper summarizes our approach; complete details appear in <ref> [10] </ref>. 2. Related Work The simplest approach to detect malicious code is to run the program to see whether it shows any viral activities. Despite its simplicity, run-time approaches have sev eral major drawbacks. First, they expose a system to potential damages by running a potential malicious program. <p> We hav e included a Trojan login program and multistage malicious code here. More examples including a salami attack program, a sniffer, a ferret program, and a program that overloads a system can be found in <ref> [10] </ref>. Although these programs are not real malicious code, they are based on realistic examples and are used to illustrate how tell-tale signs are useful towards detecting real malicious code. - 6 - 4.1.1. <p> UNIX Vulnerabilities and Their Detection In this section, we examine how the tell-tale sign approach is useful for identifying some known system vulnerabilities. More examples including the rdist bug and the sendmail bug can be found in <ref> [10] </ref>. 4.2.1. Finger Daemon (fingerd) The finger daemon (fingerd) has a bug that allows an intruder to read protected files without proper privilege. fingerd, running as root, prints the content of the .plan file of the person being fingered. <p> The function of the well-behavedness checker is to verify these properties. We hav e developed a well-behaved checker that applies both ow analysis and verification techniques to show that pointers do not overow and array accesses are within bounds. Details can be found in <ref> [10] </ref> Nevertheless, the checker can verify most array accesses automatically, but there are some cases that the tool cannot handle. 8. Conclusion Tell-tale signs are useful in discriminating malicious from benign programs.
Reference: 11. <author> Ronald A. Olsson, Richard H. Crawford, W. Wilson Ho, Dalek: </author> <title> a GNU, improved programmable debugger, pp. </title> <booktitle> 221-231 in USENIX Conference Proceedings, USENIX, </booktitle> <address> Anaheim, CA (June 1990). </address>
Reference-contexts: Commonly used programs often have no specifications and are very unlikely to be verified. Dynamic analysis [6] combines the concept of testing and debugging to detect malicious activities by running a program in a clean-room environment. The execution is typically monitored (e.g., by a programmable debugger <ref> [11] </ref> ) for suspicious behavior. The analysis is in general more reliable than run-time approaches because data are generated systematically to test the program [9]. Test coverage analysis will also reveal parts of programs not covered by the analysis.
Reference: 12. <author> Ronald A. Olsson, Richard H. Crawford, W. Wilson Ho, </author> <title> A Dataow Approach to Event-Based Debugging, </title> <journal> SoftwarePractice and Experience 21(2) pp. </journal> <month> 209-229 (Feb. </month> <year> 1991). </year>
Reference: 13. <author> John F. Shoch, Jon A. Hupp, </author> <title> The Worm ProgramsEarly Experience with a Distributed Computation, </title> <journal> Communications of the ACM 25(3) pp. </journal> <month> 172-180 (Mar. </month> <year> 1982). </year>
Reference-contexts: 1. Introduction Malicious programs can cause loss of confidentiality and integrity, or cause denial of resources. Common classes of malicious programs include computer viruses [4], computer worms <ref> [13] </ref>, Trojan horses, and programs that exploit security holes, covert channels, and administrative aws to achieve malicious purposes. Some program properties allow us to discern malicious programs from benign programs easily with very high accuracy without the need to give a specification of the program.
Reference: 14. <author> Alan Solomon, </author> <title> Mechanisms of Stealth, </title> <booktitle> International Computer Virus and Security Conference, </booktitle> <pages> pp. </pages> <month> 374-383 </month> <year> (1992). </year>
Reference-contexts: For example, virus scanners are found to be useless against polymorphic viruses. A toolkit that converts existing PC viruses to polymorphic viruses has been developed and exchanged among virus writers <ref> [14] </ref>. Furthermore, the detection tool should also identify cases in which its result might be unreliable.
Reference: 15. <author> Eugene H. Spafford, </author> <title> Common System Vulnerabilities, Future Directions in Intrusion and Misuses Detection, </title> <year> (1992). </year>
Reference-contexts: As a virus, it may attach itself to a user's diskette when the user accesses an infected machine. To a lesser extent, an outsider who does not have direct access to the system can install malicious programs through known OS bugs or aws <ref> [15] </ref> in pro tection settings (protection states). (2) Obtain higher privilege/Retain current privilege. Once a program is installed in the system, it may belong to a particular user in the system, but it may not have sufficient privilege to perform the malicious action.
Reference: 16. <author> Mark Weiser, </author> <title> Program Slicing, </title> <booktitle> Proceedings of the Fifth International Conference on Software Engineering, </booktitle> <pages> pp. </pages> <month> 439-449 (Mar. </month> <year> 1981). </year>
Reference-contexts: The comsat problem is revealed by the "File Read" sign, which indicates that the file written to comes from the /etc/utmp directly. Further analysis on the access of /etc/utmp shows that its content is not validated. 5. Mechanizing Malicious Code Detection Program slicing <ref> [16] </ref> produces a bona-fide programa subset of the original program that behaves exactly the same with respect to the computation of a designated property. The concept of breaking down a large program into smaller modules for analysis dates back to 1975 [17]. <p> The concept of breaking down a large program into smaller modules for analysis dates back to 1975 [17]. Zislis uses busy variables (variables that will be used later in the program) as the criteria to group related program statements together and form a slice. Weiser <ref> [16] </ref> uses a more accurate criteriadata dependenceto group statements together. These criteria are not the only ways of grouping relevant and eliminating irrelevant statements. <p> 53 char nolog [] = "/etc/nologin"; 54 char qlog [] = ".hushlogin"; 55 char maildir [30] = "/usr/spool/mail/"; 56 char lastlog [] = "/usr/adm/lastlog"; 57 struct passwd nouser = -"", "nope", -1, -1, -1, "", "", "", "" -; 58 struct sgttyb ttyb; 59 struct utmp utmp; 60 char minusnam <ref> [16] </ref> = "-"; 61 char *envinit [] = - 0 -; /* now set by setenv calls */ 62 /* 63 * This bounds the time given to login.
Reference: 17. <author> Paul M. Zislis, </author> <title> Semantic Decomposition of Computer Programs: An Aid to Program Testing, </title> <journal> Acta Informat-ica, </journal> <pages> pp. </pages> <month> 245-269 </month> <year> (1975). </year> <month> - 27 </month> - 
Reference-contexts: Mechanizing Malicious Code Detection Program slicing [16] produces a bona-fide programa subset of the original program that behaves exactly the same with respect to the computation of a designated property. The concept of breaking down a large program into smaller modules for analysis dates back to 1975 <ref> [17] </ref>. Zislis uses busy variables (variables that will be used later in the program) as the criteria to group related program statements together and form a slice. Weiser [16] uses a more accurate criteriadata dependenceto group statements together.
References-found: 17

