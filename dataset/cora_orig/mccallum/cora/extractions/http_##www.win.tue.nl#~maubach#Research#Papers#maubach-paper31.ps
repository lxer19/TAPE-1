URL: http://www.win.tue.nl/~maubach/Research/Papers/maubach-paper31.ps
Refering-URL: http://www.win.tue.nl/~maubach/Research/papers.html
Root-URL: http://www.win.tue.nl
Title: Boundary-Hibrid Finite Element A Posteriori Error Estimation  
Author: Joseph M. Maubach and Patrick J. Rabier 
Abstract: Finite element methods that calculate the normal derivative of the solution along the mesh interfaces and recover the solution via local Neumann problems were introduced about two decades ago by I. Babu ff ska, J.T. Oden and J.K. Lee for the treatment of the homogeneous Laplace equation and called boundary-hybrid method. We revisit this approach for general symmetric and positive definite elliptic equations with homogeneous boundary conditions. The resulting approximation is nonconforming, and the corresponding error is orthogonal to all the conforming finite element subspaces. This crucial property shows immediately how to derive an a posteriori error estimator for conforming finite element approximations via Pythagoras' theorem. The investigation of this idea leads to a sound strategy for a posteriori error analysis which gives conservative, yet accurate, estimates, is cheap for good conforming approximations, and otherwise produces an enhanced solution at not significantly more than the cost normally expected for such a result. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ainsworth and J.T. Oden, </author> <title> A unified approach to a posteriori error estimation using element residual methods, </title> <journal> Numerische Mathematik, </journal> <volume> 65(1993), </volume> <pages> 23-50 </pages>
Reference-contexts: : 3: 20 Incidentally, the choice (3.20) corresponds to ~ being the projection of (@ ^u K =@n A K ) onto fl relative to the orthogonal splitting L 2 ( ~ I ) = fl + fl : 3: 21 Other weighted averages are suggested in Ainsworth and Oden <ref> [1] </ref>. The step consisting in substituting ~ as given in (3.20) into (3.19) involves only solving local problems (specifically, (3.9) and (3.11)), which can be done in parallel and with high accuracy, yet at a nominal cost.
Reference: [2] <author> O. Axelsson, </author> <title> A generalized conjugate gradient, least square method, </title> <journal> Numerische Math-ematik, </journal> <volume> 51(1987), </volume> <pages> 209-227 </pages>
Reference-contexts: This nonsymmetric formulation is only positive semidefinite, and hence the use of well-established iterative methods (GMRES [9], CGS [10], GCGLS <ref> [2] </ref>) seems not to be fully justified.
Reference: [3] <author> I. Babu ff ska and M. Suri, </author> <title> The h p version of the finite element method with quasiuniform meshes, </title> <journal> Math. Mod. Num. Anal., </journal> <volume> 21(1987), </volume> <pages> 199-238 </pages>
Reference-contexts: 1 Introduction In the second part of their paper Mixed-Hybrid Finite Element Approximations of Second-Order Elliptic Boundary Value Problems, Babu ff ska, Oden and Lee <ref> [3] </ref>, [4] discuss an original finite element procedure, coined as boundary hybrid method, to solve the homogeneous Laplace equation ( u = g on @; where ae R 2 is a polygonal domain. <p> To complete with, we need an estimate for each infimum appearing in the right-hand side of (5.14). The following special case of Lemma 4.5 in Babu ff ska and Suri <ref> [3] </ref> will suffice: Lemma 5.5 Let s 0 be a real number. <p> There is a constant C &gt; 0 depending only upon s such that for every integer m 0 and every v 2 H s ( KL ), we have inffjv wj 0; KL : w 2 P m ( KL )g C h KL Actually, in <ref> [3] </ref> Lemma 5.5 is proved in the two-dimensional case when KL is replaced by a nondegenerate triangle or parallelogram. The one-dimensional case considered in Lemma 5.5 is of course simpler (though not considerably). Also, curiously, the case m = 0 in (5.20) is not considered in [3] although it does not <p> h KL Actually, in <ref> [3] </ref> Lemma 5.5 is proved in the two-dimensional case when KL is replaced by a nondegenerate triangle or parallelogram. The one-dimensional case considered in Lemma 5.5 is of course simpler (though not considerably). Also, curiously, the case m = 0 in (5.20) is not considered in [3] although it does not present any particular additional difficulty. Since is a polygon, the relation u 2 H r () should not be expected to hold with r 3 irrespective of the smoothness of f .
Reference: [4] <author> R. Jeurissen and W. Layton, </author> <title> Load balancing via graph coloring: an algorithm, </title> <note> to appear, Computers and Mathematics with Applications, </note> <year> 1993 </year>
Reference-contexts: 1 Introduction In the second part of their paper Mixed-Hybrid Finite Element Approximations of Second-Order Elliptic Boundary Value Problems, Babu ff ska, Oden and Lee [3], <ref> [4] </ref> discuss an original finite element procedure, coined as boundary hybrid method, to solve the homogeneous Laplace equation ( u = g on @; where ae R 2 is a polygonal domain. Roughly, the procedure can be described as follows: Consider a partition P of the domain into polygonal elements. <p> If the normal derivative @u=@n of the solution is known across all the element interfaces, then the solution u can (obviously) be recovered by solving the corresponding Neumann problem for the homogeneous Laplace equation over each element separately. A variational characterization of the normal derivative @u=@n is obtained in <ref> [4, Theorem 3.3] </ref>. Then, approximations of @u=@n, e.g. by functions which are polynomials in each interface can be found by restricting the variational formulation to an ? Department of Mathematics, Thackeray Hall 301, University of Pittsburgh PA. 15260, U.S.A.. <p> To obtain u numerically, it suffices to solve the Neumann problem over each element with @u=@n being replaced by its piecewise polynomial approximation. Of course, the local Neumann problems need not be solved exactly, and in <ref> [4] </ref> this is exploited by using higher degree harmonic polynomials within each element. <p> In practice, this means that adequate care should be given to the definition of its domain. One available option is to use the characterization of @u=@n A towards the numerical approximation of u, as was done in <ref> [4] </ref> for the problem (1.1). However, a fuller application can be found to the a posteriori estimation of u ^u when ^u 2 H 1 0 () is any approximation of u. It is this second and less standard aspect that we have chosen to emphasize here. <p> Such a coloring is involved in the parallel algorithms described in Layton and Rabier [6], Layton, Maubach and Rabier [5], used in our experiments. In theory, a checkerboard coloring of the mesh is always possible with patches of at most two triangular elements (Jeurissen and Layton <ref> [4] </ref>), but a faster algorithm with patches of at most four elements due to Maubach (unpublished) was found more convenient. The grid refinement used is that by cite Maubach [7] and [8].
Reference: [5] <author> W. Layton, J.M. Maubach and P. Rabier, </author> <title> Parallel algorithms for maximal monotone operators of local type, </title> <journal> Numerische Mathematik, </journal> <pages> 71(1995) 29-58 </pages>
Reference-contexts: This nonsymmetric formulation is only positive semidefinite, and hence the use of well-established iterative methods (GMRES [9], CGS [10], GCGLS [2]) seems not to be fully justified. On the other hand, the constraints (6.11) have a form that allows for the use of the new parallel procedure in <ref> [5] </ref>. (Although not of local type in the sense of that paper, the constraints (6.11) retain just enough properties to justify the method.) Theorem 5.1 continues to hold provided that, now k 2 fl k is the solution of the discretized constrained minimization problem. <p> Such a coloring is involved in the parallel algorithms described in Layton and Rabier [6], Layton, Maubach and Rabier <ref> [5] </ref>, used in our experiments. In theory, a checkerboard coloring of the mesh is always possible with patches of at most two triangular elements (Jeurissen and Layton [4]), but a faster algorithm with patches of at most four elements due to Maubach (unpublished) was found more convenient. <p> Such methods performed well or adequately on the coarse uniform mesh, but exhibited very slow convergence on locally refined meshes (residuals as large as 10 3 or 10 2 after 3000 iterations; not surprisingly, preconditioners of ILU (0) type didn't help). The new algorithms in <ref> [5] </ref> and [6] consistently produced 10 9 residuals in 3000 or fewer iterations and therefore were used in all the tests presented here. As usual, the quality of the error estimator is expressed in terms of the efficiency index, i.e. the ratio (estimated error)/(actual error). <p> Storage limitations have prevented us from considering the finer grid of previously is needed to implement conveniently (but not optimally) the procedure described in Section 6. As mentioned there, we have handled the resulting constrained minimization problem via the fully parallelizable algorithm of Layton, Maubach and Rabier <ref> [5] </ref> (or, more precisely, a variant of it whose convergence can also be fully justified mathematically). Table 7.3 below is the analog of Table 7.1 for Problem (7.3).
Reference: [6] <author> W.J. Layton and P. Rabier, </author> <title> Peaceman-Rachford procedure and domain decomposition for finite element problems, Journal on Numerical Linear Algebra with Applications, </title> <type> 2(1995), </type> <institution> p363-394 </institution>
Reference-contexts: The results of Section 5 have the form of a priori estimates and show that both the error estimator and the enhanced solution have optimal orders of accuracy. No saturation assumption ([1], <ref> [6] </ref>) is 4 Boundary-Hibrid Finite Element A Posteriori needed. <p> Patching up elements is needed to comply with the requirement that no interface KL contains a vertex of (see Section 5), and is also required to obtain a checkerboard coloring of the mesh. Such a coloring is involved in the parallel algorithms described in Layton and Rabier <ref> [6] </ref>, Layton, Maubach and Rabier [5], used in our experiments. <p> Such methods performed well or adequately on the coarse uniform mesh, but exhibited very slow convergence on locally refined meshes (residuals as large as 10 3 or 10 2 after 3000 iterations; not surprisingly, preconditioners of ILU (0) type didn't help). The new algorithms in [5] and <ref> [6] </ref> consistently produced 10 9 residuals in 3000 or fewer iterations and therefore were used in all the tests presented here. As usual, the quality of the error estimator is expressed in terms of the efficiency index, i.e. the ratio (estimated error)/(actual error).
Reference: [7] <author> J. Maubach, </author> <title> Local bisection refinement for n-simplicial grids generated by reflections, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 16(1995), </volume> <pages> 210-227 </pages>
Reference-contexts: The grid refinement used is that by cite Maubach <ref> [7] </ref> and [8].
Reference: [8] <author> J. Maubach, </author> <title> The amount of similarity classes created by local n-simplicial bisectionre-finement, </title> <note> submitted (preprint available), </note> <institution> Pittsburgh, </institution> <address> PA., USA, </address> <year> 1996 </year> <month> (37 pages) </month>
Reference-contexts: of a continuous extension of @v K =@n A K as an element of V ? K for v K 2 H A ( K ) follows from (2.26) and the denseness of C 1 ( K ) in H A ( K ). (For the latter point, see Grisvard <ref> [8, p. 59] </ref> when A = I; the proof in the general case is similar.) Next, (2.23) is just the extension of (2.25) by denseness and continuity. <p> The first remark is that since is a polygon, the solution u possesses the better regularity u 2 H s () for some s &gt; 3=2 (s 2 if is convex). For this, we refer to Grisvard <ref> [8, Chapter 5] </ref>. As a result, the derivative @u K =@n A K is defined in H s3=2 ( K ) and hence in L 2 ( KL ); (K; L) 2 I. As we also know from Section 3, ~ 2 fl . <p> The grid refinement used is that by cite Maubach [7] and <ref> [8] </ref>.
Reference: [9] <author> Y. Saad and M.H. Schultz, </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM Journal on Scientific and Statistical Computations, </journal> <volume> 7(1986), </volume> <pages> 856-869 </pages>
Reference-contexts: If the constraints (6.11) are written in the form C = ', one option is to solve the system C 0 ' ; where ffi appears as a Lagrange multiplier. This nonsymmetric formulation is only positive semidefinite, and hence the use of well-established iterative methods (GMRES <ref> [9] </ref>, CGS [10], GCGLS [2]) seems not to be fully justified.
Reference: [10] <author> P. Sonneveld, </author> <title> CGS, a fast Lanczos-type solver for non-symmetric linear systems, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 10(1989), </volume> <pages> 36-52 </pages>
Reference-contexts: Not only this step is evidently fully parallelizable, but even the minimization of Q lends itself perfectly to elementwise parallel processing by the method recently introduced in <ref> [10] </ref> and [11]. Section 2 is devoted to some preliminaries including a definition of a space fl which, later (Section 4), will be shown canonically isomorphic to the space fl mentioned earlier. <p> If the constraints (6.11) are written in the form C = ', one option is to solve the system C 0 ' ; where ffi appears as a Lagrange multiplier. This nonsymmetric formulation is only positive semidefinite, and hence the use of well-established iterative methods (GMRES [9], CGS <ref> [10] </ref>, GCGLS [2]) seems not to be fully justified.
References-found: 10

