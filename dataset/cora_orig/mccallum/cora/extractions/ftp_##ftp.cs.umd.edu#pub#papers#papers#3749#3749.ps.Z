URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3749/3749.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: fladan,richg@cs.umd.edu  
Title: Multi-Platform Simulation of Video Playout Performance  
Author: Ladan Gharai and Richard Gerber 
Address: College Park, MD 20742  
Affiliation: Institute for Advanced Computer Studies Department of Computer Science University of Maryland  
Abstract: We describe a video playout and simulation package, including (1) a multi-threaded player, which maximizes performance via asynchronous streaming and selective IO-prefetching; (2) a compositional simulator, which predicts playout performance for multiple platforms via eleven key deterministic and stochastic time-generating functions; and (3) a set of profiling tools, which allows one to extend the range of target platforms by benchmarking new components, and converting the results into distribution functions that the simulator can access. Using this system, a developer can quickly estimate a video's performance on a wide spectrum of target platforms without ever having to actually assemble them. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Navin Chaddha, Gerard A.Wall, and Brian Schmidt. </author> <title> An End to End Software Only Scalable Video Delivery System. </title> <booktitle> In Proceedings of the Workshop on Network and Operating Systems for Digital Audio and Video (NOSSDAV 95), </booktitle> <year> 1995. </year>
Reference-contexts: In this manner, a rough backward playback is simply a matter of displaying a series of I frames. The system described in <ref> [1] </ref> scales not only the rate, but also the spatial resolution of a video stream. This is done by packaging three versions of every frame, with each offering a monotonic improvement over the previous one. <p> We summarize the two methods here: Pure stochastic variable: In this case the time-sample list is sorted as a histogram divided into either 10 3 or 10 4 buckets (depending on the range and variation of the recorded process). Then, the histogram is normalized to the interval <ref> [0; 1] </ref>, which yields a (synthesized) discrete probability distribution function (or pdf) f (t) for the variable, where we now assume that a given outcome is made as a simple Bernoulli decision. I.e., f (t) returns the probability of a sample time t being realized during playback on the device. <p> I.e., f (t) returns the probability of a sample time t being realized during playback on the device. Next, f 's cumulative distribution function F (t) is produced, and the output of the entire process is F 1 (u), the CDF's inverse transform, where u is uniformly distributed in <ref> [0; 1] </ref>. The simulator uses this function to generate random response times, in concert with a dedicated random number generator. <p> Finally, at simulation time, we get our IO time variable as follows: T io = L (size) + R 1 (u) where "size" is the number of bytes requested by the simulated IO thread, and u 2 <ref> [0; 1] </ref> is obtained via a random-number generator. (2) CPU Profiling: The CPU-based playout software itself is modeled by the variables T ply , T pre , T IOc , T iocb , T snd , T sch , T sndcb and T cnts , which represent execution times for the
Reference: [2] <author> Ming-Syan Chen and Dilip D.Kandlur. </author> <title> Downloading and Stream Conversion: Supporting Interactive Playout of Videos in a Client Station. </title> <booktitle> In Proceedings of the International Conference on Multimedia Computing and Systems, </booktitle> <pages> pages 73-80, </pages> <year> 1995. </year>
Reference-contexts: As we show in the following section, these techniques are similar to our system's feedback loop however, since we concentrate on single-client streams, the rate adjustments can obviously be made faster. Chen and Kandlur describe a player in <ref> [2] </ref>, which, like ours, is a stand alone client station player. However their emphasis is on supporting VCR playback capabilities, such as forward and backward playback for an MPEG encoded video stream.
Reference: [3] <institution> Apple Computer Corporation. Inside Machintosh: </institution> <address> Quicktime. </address> <publisher> Addison Wesley, </publisher> <year> 1994. </year>
Reference-contexts: In this paper we present a cheap, fast alternative to this process, which uses discrete-event simulation, in concert with an abstract model of the playout platform. The model characterizes the datapath of our QuickTime <ref> [3] </ref> playout software (described in [6]), and its operation on specific CPU/IO configurations. The simulator's inputs are (1) a specific CPU workstation type, (2) a SCSI device model, and (3) a Quicktime video header file.
Reference: [4] <author> Kevin Fall and Joseph Pasquale. </author> <title> Improving Continuous-Media Playback Performance with In-Kernel Data Paths. </title> <booktitle> In Proceedings of the First International IEEE Conference on Multimedia Computing and Systems, </booktitle> <pages> pages 100-109, </pages> <year> 1994. </year>
Reference-contexts: At any point in the process the codec can stop improving the current frame, and proceed to the next. Of course, this flexibility is achieved by using a custom codec, which was designed specifically for this purpose. Our focus on IO and data paths is echoed in <ref> [4] </ref>, which proposes a means of optimizing the transmission of compressed videos.
Reference: [5] <author> D.James Gemmell, Harrick M.Vin, Dilip D.Kandlur, P.Venkat Rangan, and Lawrence A.Rowe. </author> <title> Multimedia Storage Servers: A tutorial. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 40-49, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: For single video streams, decent performance was shown to be realized by both CSCAN and SCAN-EDF ahybrid of the traditional SCAN technique, and the "earliest-deadline-first" strategy used in real-time thread schedulers. Another technique, the Group Sweeping Scheme <ref> [5] </ref>, is a hybrid of round-robin and SCAN. A number of "groups" are scheduled via round-robin, whereas within each group the SCAN algorithm is used.
Reference: [6] <author> Richard Gerber and Ladan Gharai. </author> <title> Experiments with Digital Video Playout. </title> <booktitle> In ACM Sig-metrics, </booktitle> <pages> pages 210-221, </pages> <year> 1996. </year>
Reference-contexts: In this paper we present a cheap, fast alternative to this process, which uses discrete-event simulation, in concert with an abstract model of the playout platform. The model characterizes the datapath of our QuickTime [3] playout software (described in <ref> [6] </ref>), and its operation on specific CPU/IO configurations. The simulator's inputs are (1) a specific CPU workstation type, (2) a SCSI device model, and (3) a Quicktime video header file. <p> On one hand, commercial APIs like those provided by QuickTime can simplify a program's interaction with the underlying codec software. But on the other, their long, multi-layered call-paths tend to cause an enormous amount of jitter and bursty frame-dropping at display time. In <ref> [6] </ref> we describe our alternative implementation, which bypasses all high-level API functions and only interacts with QuickTime's codec support. Hence, our architecture manages all system-level details involved in video playback, such as IO transfers, memory management, buffering, flow control and audio/video synchronization.
Reference: [7] <author> Howard P. Katseff and Bethany S.Robinson. </author> <title> Predictive Prefetch in the Nemesis Multimedia Information Service. </title> <booktitle> In ACM Multimedia Proceedings, </booktitle> <pages> pages 201-209, </pages> <year> 1993. </year>
Reference-contexts: A related issue is achieving graceful degradation of service in the event of network congestion. One approach to this problem is for the client to adaptively scale the playback rate by deterministically dropping some of its frames. This is the approach taken in the the Nemesis <ref> [7] </ref> project, which uses a predictive prefetch algorithm to scale a client's input streams. This is also the approach taken in Vosaic [11], which uses its own specialized a real time variant of UDP, and allows the server to scale its transmission by the feedback it receives from the client.
Reference: [8] <author> A.L. Narasimha Reddy and James C.Wyllie. </author> <title> IO Issues in a Multimedia System. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 69-74, </pages> <month> March </month> <year> 1994. </year> <month> 16 </month>
Reference-contexts: Alternatively, other researchers have constructed detailed models of certain key components, and then subjected them to simulated video workloads. In particular, IO subsystems have often been studied in this manner. For example, the results in <ref> [8] </ref> illustrate the performance of various disk-scheduling algorithms, when tested with synthetic video simulations. For single video streams, decent performance was shown to be realized by both CSCAN and SCAN-EDF ahybrid of the traditional SCAN technique, and the "earliest-deadline-first" strategy used in real-time thread schedulers.
Reference: [9] <author> Ralf Steinmetz. </author> <title> Compression Techniques in Multimedia Systems. </title> <type> Technical Report 43.9307, </type> <institution> IBM European Networking Center, </institution> <address> Vangerowstrabe 18, 69020 Heidelberg, Germany, </address> <year> 1993. </year>
Reference-contexts: This means the Display thread should never have to wait for a frame the IO should always have prefetched it ahead of time, while the Display thread was processing a previous frame. Keyframes. Our scheme is complicated by the existence of keyframes (which are analogous to I-Frames in MPEG <ref> [9] </ref>); e.g., if a keyframe is dropped, then the the interpolated sequence following has to be discarded. Thus, while PR (t) is the current predicted rate, the Predict thread cannot simply fetch frames at a constant frequency. First a decision is made whether an entire sequence will be avoided.
Reference: [10] <author> Donald L. Stone and Kevin Jeffay. </author> <title> An Empirical Study of Delay Jitter Management Policies. </title> <journal> Multimedia Systems, </journal> <volume> 2(6) </volume> <pages> 267-279, </pages> <year> 1995. </year>
Reference-contexts: As we show in the sequel, for our purposes an IO device can be sufficiently modeled by its rate and latency distributions. Although described in the context of networked video, Stone and Jeffay's <ref> [10] </ref> queue monitoring method is quite similar to the way our playout loop manages jitter. As they have found with networked traffic and as we have found in dealing with IO and compression software a balance must be found between a stream's jitter and its delivery rate.
Reference: [11] <author> Roy H. Campbell Zhigang Chen, See-Mong Tan and Yongcheng Li. </author> <title> Real Time Video and Audio in the World Wide Web. </title> <booktitle> In Proceedings of the Fourth International World Wide Web Conference, </booktitle> <year> 1995. </year> <month> 17 </month>
Reference-contexts: This is the approach taken in the the Nemesis [7] project, which uses a predictive prefetch algorithm to scale a client's input streams. This is also the approach taken in Vosaic <ref> [11] </ref>, which uses its own specialized a real time variant of UDP, and allows the server to scale its transmission by the feedback it receives from the client.
References-found: 11

