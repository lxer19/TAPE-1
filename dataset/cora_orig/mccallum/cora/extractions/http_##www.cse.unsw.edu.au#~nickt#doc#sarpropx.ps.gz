URL: http://www.cse.unsw.edu.au/~nickt/doc/sarpropx.ps.gz
Refering-URL: http://www.cse.unsw.edu.au/~nickt/index.html
Root-URL: http://www.cse.unsw.edu.au
Email: -@cse.unsw.edu.au  
Title: THE SARPROP ALGORITHM: A SIMULATED ANNEALING ENHANCEMENT TO RESILIENT BACK PROPAGATION  
Author: N.K. Treadgold and T.D. Gedeon nickt tom 
Address: Sydney N.S.W. 2052 AUSTRALIA  
Affiliation: School of Computer Science Engineering The University of New South Wales  
Abstract: Back Propagation and its variations are widely used as methods for training artificial neural networks. One such variation, Resilient Back Propagation (RPROP), has proven to be one of the best in terms of speed of convergence. Our SARPROP enhancement, based on Simulated Annealing, is described in this paper and is shown to increase the rate of convergence for some problems. The extension involves two complementary modifications: weight constraints early in training combine with noise to force the network to perform a more thorough search of the initial weight space, before allowing the network to refine its solutions as training continues. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Burton, R.M. and Mpitsos, G.J. </author> <title> (1992) Event-Dependent Control of Noise Enhances Learning in Neural Networks. </title> <booktitle> Neural Networks 5, </booktitle> <pages> 627-637. </pages>
Reference-contexts: SARPROP attempts to address this problem by using the method of Simulated Annealing (SA). SA methods are a well known technique in training artificial neural networks, and have been applied to the Back Propagation algorithm <ref> (Burton and Mpitsos, 1992) </ref> with good results in terms of speed of converge. SA, in general, involves the addition of a random noise factor during weight updates. The amount of noise added is often associated with a temperature value which decreases the effect of the noise as training progresses.
Reference: <author> Fahlman, </author> <title> S.E. (1988) An Empirical Study of Learning Speed in BackPropagation Networks (CMU-CS-88-162), </title> <type> Technical Report, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: For classification problems the 40-20-40 threshold and margin criterion was used <ref> (Fahlman, 1988) </ref>. In using the 40-20-40 criterion, a class has been learnt correctly if the neurons output is in the correct upper or lower 40% of its output range. For regression problems, a RMS error value was specified to indicate convergence.
Reference: <author> Jacobs, R.A. </author> <title> (1988) Increased Rates of Convergence Through Learning Rate Adaption. </title> <booktitle> Neural Networks 1, </booktitle> <pages> 295-307. </pages>
Reference: <author> Riedmiller, M. </author> <title> (1994) Rprop - Description and Implementation Details, </title> <type> Technical Report, </type> <institution> University of Karlsruhe. </institution>
Reference: <author> Riedmiller, M. and Braun, H. </author> <title> (1993) A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm. </title> <editor> In: Ruspini, H., (Ed.) </editor> <booktitle> Proc. of the ICNN 93, </booktitle> <address> San Francisco, </address> <pages> pp. 586-591. </pages>
Reference-contexts: This allows the step size to be adapted without having the size of the gradient interfere with the adaptation process <ref> (Riedmiller, 1993) </ref>. In a number of previous BP variants, the learning parameter, h, was varied adaptively (Tollenaere, 1990; Jacobs, 1988). There was, however, no account taken of the current gradient magnitude (which is combined with the learning parameter to give the step size). <p> Since the two algorithms have a number of parameters in common, these were all set to the same values in both algorithms. The standard settings for these parameters are <ref> (Braun and Riedmiller, 1993) </ref>: h + - 1x10 . These values remained constant throughout the comparisons. The initial update value, D 0 , was set to 0.1 for all problems in both RPROP and SARPROP. <p> The initial update value, D 0 , was set to 0.1 for all problems in both RPROP and SARPROP. The value chosen for D 0 has been shown to be of little significance in regards to the performance of RPROP since it is quickly adapted <ref> (Braun and Riedmiller 1993) </ref>. There are a number of parameters introduced by SARPROP which need to be set before training commences. After some experimentation good values for the parameters k 1 , k 2 , and k 3 were found: 0.01, 0.1, and 3 respectively.
Reference: <author> Rumelhart, D.E., Hinton, G.E. and Williams, </author> <title> R.J. (1986) Learning internal representations by error propagation. </title> <editor> In: Rumelhart, D.E. and McClelland, J.L., (Ed.) </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition. </booktitle> <volume> vol 1. </volume> <booktitle> Foundations, </booktitle> <pages> pp. 318-362. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
References-found: 6

