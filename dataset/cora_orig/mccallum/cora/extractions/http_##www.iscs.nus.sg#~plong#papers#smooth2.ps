URL: http://www.iscs.nus.sg/~plong/papers/smooth2.ps
Refering-URL: 
Root-URL: 
Title: Improved Bounds about On-line Learning of Smooth Functions of a Single Variable  
Author: Philip M. Long 
Note: log m); and that opt(F 2 m) p 2 O(1).  
Address: Singapore 119260, Republic of Singapore  
Affiliation: ISCS Department National University of Singapore  
Abstract: We consider the complexity of learning classes of smooth functions formed by bounding different norms of a function's derivative. The learning model is the generalization of the mistake-bound model to continuous-valued functions. Suppose F q is the set of all absolutely continuous functions f from [0; 1] to R such that jjf 0 jj q 1, and opt(F q ; m) is the best possible bound on the worst-case sum of absolute prediction errors over sequences of m trials. We show that for all q 2, opt(F q ; m) = fi(
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction In this paper, we continue a line of research investigating the complexity of learning, in the on-line model, classes of functions intended to capture the idea of similar inputs tending to yield similar outputs. In the model that we will consider here <ref> [6, 1, 7] </ref>, an algorithm is trying to learn a real-valued function f, given the a priori knowledge that f comes from some class F . <p> In the model that we will consider here [6, 1, 7], an algorithm is trying to learn a real-valued function f, given the a priori knowledge that f comes from some class F . Learning proceeds in trials, where, in the tth trial, the algorithm gets x t 2 <ref> [0; 1] </ref>, outputs a prediction ^y t of f (x t ), and discovers f (x t ). An algorithm A is evaluated by the worst-case sum of its absolute prediction errors, i.e. 1 by its worst-case value of P m t=1 j^y t f (x t )j. <p> For this reason, for various q, we will study the set F q of all absolutely continuous functions f from <ref> [0; 1] </ref> to R such that R 1 We number our trials from 0, but, as in [4], we start counting errors on trial number 1. This is for technical reasons: we could obtain similar results without this if we set the range to be [0; 1], or required that f <p> absolutely continuous functions f from <ref> [0; 1] </ref> to R such that R 1 We number our trials from 0, but, as in [4], we start counting errors on trial number 1. This is for technical reasons: we could obtain similar results without this if we set the range to be [0; 1], or required that f (0) = 0. The set F 1 is defined analogously using the large-q limit. <p> The set F 1 is defined analogously using the large-q limit. This set can be defined in a simpler way (see [8]) as the set of functions with a Lipschitz bound of 1, i.e. the set of functions f for which for all a; b 2 <ref> [0; 1] </ref>, jf (a) f (b)j ja bj. Informally, this is the set of functions for which the outputs are never more dissimilar than the inputs. <p> In the model considered in this paper [6, 7], learning proceeds in trials. The algorithm is trying to learn a function f : <ref> [0; 1] </ref> ! R. In each trial t = 0; 1; 2; ::: an algorithm is given x t 2 [0; 1], outputs^y t 2 R, and receives f (x t ) 2 R. <p> In the model considered in this paper [6, 7], learning proceeds in trials. The algorithm is trying to learn a function f : <ref> [0; 1] </ref> ! R. In each trial t = 0; 1; 2; ::: an algorithm is given x t 2 [0; 1], outputs^y t 2 R, and receives f (x t ) 2 R. <p> We then define opt (F; m) = inf L (A; F; m) where the infimum ranges over learning algorithms. Choose q 1. Define F q to be the set of all absolutely continuous functions f : <ref> [0; 1] </ref> ! R such that Z jf 0 (x)j q dx 1: Since any absolutely continuous function is differentiable almost everywhere, the LHS is always well-defined for such functions. The following is the first of this paper's main results. Theorem 1. <p> Theorem 2. opt (F 2 ; m) = log m O (1): 3 The upper bound Suppose S = f (u i ; v i ) : 1 i mg is a finite subset of <ref> [0; 1] </ref> fi R such that u 1 &lt; u 2 &lt; &lt; u m : Define f S : [0; 1] ! R to be the function which linearly interpolates the points in S and extrapolates with the constants v 1 and v m respectively. <p> ; m) = log m O (1): 3 The upper bound Suppose S = f (u i ; v i ) : 1 i mg is a finite subset of <ref> [0; 1] </ref> fi R such that u 1 &lt; u 2 &lt; &lt; u m : Define f S : [0; 1] ! R to be the function which linearly interpolates the points in S and extrapolates with the constants v 1 and v m respectively. <p> That is, for all x; f ; (x) = 0, and 8 &gt; : v i + u i+1 u i if x 2 (u i ; u i+1 ] if jSj 1. For f : <ref> [0; 1] </ref> ! R, define the action of f, denoted by J [f ], to be J [f] = 0 Note that F 2 is the set of absolutely continuous functions whose action is at most 1. <p> Lemma 3. Choose m 2 N. Choose (u 1 ; v 1 ); :::; (u m ; v m ) 2 <ref> [0; 1] </ref> fi R such that the u i 's are distinct. Let S = f (u i ; v i ) : 1 i mg. <p> Let S = f (u i ; v i ) : 1 i mg and let U = fu i : 1 i mg. Choose an example (x; y) 2 <ref> [0; 1] </ref> fi R such that x 62 U . <p> Specifically, algorithm A, on the tth trial, gets x t from the environment, outputs f f (x i ;f (x i )):i&lt;tg (x t ), and gets f (x t ). Choose x 0 ; :::; x m 2 <ref> [0; 1] </ref>; f 2 F 2 . Let ^y 1 ; :::; ^y m be the predictions generated from these by A in the obvious way. Assume without loss of generality that the x t 's are distinct. <p> ) ^y t ) 2 minfjx t uj : u 2 X t g 1: (8) Since for each t 2 OUT, max X t+1 min X t+1 (max X t min X t ) + minfjx t uj : u 2 X t g; the fact that X m+1 <ref> [0; 1] </ref> implies that X minfjx t uj : u 2 X t g 1: Putting this together with (8) and Lemma 5, we have X jf (x t ) ^y t j 1: Putting this together with (7) completes the proof. ut 4 The lower bound To prove Theorem 1,
Reference: 2. <author> N. Cesa-Bianchi, </author> <title> P.M. Long, and M.K. Warmuth. Worst-case quadratic loss bounds for prediction using linear functions and gradient descent. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7(3) </volume> <pages> 604-619, </pages> <year> 1996. </year>
Reference-contexts: In addition to the work from [4] described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski [3] and in [4]. Cesa-Bianchi, Long, and Warmuth <ref> [2] </ref> extended this work to the noisy case. As mentioned in [4], these results can be trivially generalized using scaling tricks. 2 Definitions Denote the reals by R.
Reference: 3. <author> V. Faber and J. Mycielski. </author> <title> Applications of learning theorems. </title> <journal> Fundamenta Infor-maticae, </journal> <volume> 15(2) </volume> <pages> 145-167, </pages> <year> 1991. </year>
Reference-contexts: All previous results are due to Kimber and Long [4]. In addition to the work from [4] described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski <ref> [3] </ref> and in [4]. Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. As mentioned in [4], these results can be trivially generalized using scaling tricks. 2 Definitions Denote the reals by R.
Reference: 4. <author> D. Kimber and P.M. </author> <title> Long. On-line learning of smooth functions of a single variable. </title> <journal> Theoretical Computer Science, </journal> <volume> 148(1) </volume> <pages> 141-156, </pages> <year> 1995. </year>
Reference-contexts: For this reason, for various q, we will study the set F q of all absolutely continuous functions f from [0; 1] to R such that R 1 We number our trials from 0, but, as in <ref> [4] </ref>, we start counting errors on trial number 1. This is for technical reasons: we could obtain similar results without this if we set the range to be [0; 1], or required that f (0) = 0. The set F 1 is defined analogously using the large-q limit. <p> Upper and lower bounds on opt (F 1 ; m) and opt (F 2 ; m) were implicit 2 in the work of Kimber and Long <ref> [4] </ref>. The state of knowledge about these classes before and after this paper is summarized in Table 1. <p> Comparison between the current and previous state of knowledge about opt (F 1 ; m) and opt (F 2 ; m). All previous results are due to Kimber and Long <ref> [4] </ref>. In addition to the work from [4] described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski [3] and in [4]. Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. <p> Comparison between the current and previous state of knowledge about opt (F 1 ; m) and opt (F 2 ; m). All previous results are due to Kimber and Long <ref> [4] </ref>. In addition to the work from [4] described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski [3] and in [4]. Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. As mentioned in [4], these results can be <p> All previous results are due to Kimber and Long <ref> [4] </ref>. In addition to the work from [4] described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski [3] and in [4]. Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. As mentioned in [4], these results can be trivially generalized using scaling tricks. 2 Definitions Denote the reals by R. <p> to the work from <ref> [4] </ref> described above, F 2 was studied in an analogous model using the quadratic loss ((^y t f (x t )) 2 ) by Faber and Mycielski [3] and in [4]. Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. As mentioned in [4], these results can be trivially generalized using scaling tricks. 2 Definitions Denote the reals by R. <p> The following is the first of this paper's main results. Theorem 1. For all q 2, opt (F q ; m) = fi ( log m): Putting our upper bound on opt (F 2 ; m) (Theorem 7) together with <ref> [4, Theorem 21] </ref>, we obtain the other main result. <p> If f is an absolutely continuous function such that for all i m, f (u i ) = v i , then J [f] J [f S ]: Proof: In Appendix A. ut Next, we record a lemma implicit in the analysis of <ref> [4] </ref> that describes the change in the action of f S when a pair is added to S. Lemma 4 [4]. Choose m 2 N. <p> f (u i ) = v i , then J [f] J [f S ]: Proof: In Appendix A. ut Next, we record a lemma implicit in the analysis of <ref> [4] </ref> that describes the change in the action of f S when a pair is added to S. Lemma 4 [4]. Choose m 2 N. Let (u 1 ; v 1 ); :::; (u m ; v m ) be a sample with 0 u 1 &lt; u 2 &lt; &lt; u m 1.
Reference: 5. <author> G. Leitmann. </author> <title> The Calculus of Variations and Optimal Control. </title> <publisher> Plenum Press, </publisher> <year> 1981. </year>
Reference-contexts: For f : [0; 1] ! R, define the action of f, denoted by J [f ], to be J [f] = 0 Note that F 2 is the set of absolutely continuous functions whose action is at most 1. Statements similar to the following lemma are known (see <ref> [5] </ref>), but we include a proof in an appendix since we do not know a reference for precisely this statement. Lemma 3. Choose m 2 N.
Reference: 6. <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction In this paper, we continue a line of research investigating the complexity of learning, in the on-line model, classes of functions intended to capture the idea of similar inputs tending to yield similar outputs. In the model that we will consider here <ref> [6, 1, 7] </ref>, an algorithm is trying to learn a real-valued function f, given the a priori knowledge that f comes from some class F . <p> In the model considered in this paper <ref> [6, 7] </ref>, learning proceeds in trials. The algorithm is trying to learn a function f : [0; 1] ! R. In each trial t = 0; 1; 2; ::: an algorithm is given x t 2 [0; 1], outputs^y t 2 R, and receives f (x t ) 2 R.
Reference: 7. <author> J. Mycielski. </author> <title> A learning algorithm for linear operators. </title> <journal> Proceedings of the American Mathematical Society, </journal> <volume> 103(2) </volume> <pages> 547-550, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction In this paper, we continue a line of research investigating the complexity of learning, in the on-line model, classes of functions intended to capture the idea of similar inputs tending to yield similar outputs. In the model that we will consider here <ref> [6, 1, 7] </ref>, an algorithm is trying to learn a real-valued function f, given the a priori knowledge that f comes from some class F . <p> In the model considered in this paper <ref> [6, 7] </ref>, learning proceeds in trials. The algorithm is trying to learn a function f : [0; 1] ! R. In each trial t = 0; 1; 2; ::: an algorithm is given x t 2 [0; 1], outputs^y t 2 R, and receives f (x t ) 2 R.
Reference: 8. <author> H.L. Royden. </author> <title> Real Analysis. </title> <publisher> Macmillan, </publisher> <year> 1963. </year>
Reference-contexts: This is for technical reasons: we could obtain similar results without this if we set the range to be [0; 1], or required that f (0) = 0. The set F 1 is defined analogously using the large-q limit. This set can be defined in a simpler way (see <ref> [8] </ref>) as the set of functions with a Lipschitz bound of 1, i.e. the set of functions f for which for all a; b 2 [0; 1], jf (a) f (b)j ja bj. <p> Cesa-Bianchi, Long, and Warmuth [2] extended this work to the noisy case. As mentioned in [4], these results can be trivially generalized using scaling tricks. 2 Definitions Denote the reals by R. We refer the reader to <ref> [8] </ref> for the definitions and facts from elementary real analysis used here. 2 For their proof of the upper bounds, they used slightly stronger assumptions than that the functions were absolutely continuous.
References-found: 8

