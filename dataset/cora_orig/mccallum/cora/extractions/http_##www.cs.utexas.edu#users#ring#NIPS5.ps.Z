URL: http://www.cs.utexas.edu/users/ring/NIPS5.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ring/
Root-URL: 
Email: (ring@cs.utexas.edu)  
Title: Learning Sequential Tasks by Incrementally Adding Higher Orders  
Author: Mark Ring 
Address: Taylor 2.124  Austin, Texas 78712  
Affiliation: Department of Computer Sciences,  University of Texas at Austin  
Abstract: An incremental, higher-order, non-recurrent network combines two properties found to be useful for learning sequential tasks: higher-order connections and incremental introduction of new units. The network adds higher orders when needed by adding new units that dynamically modify connection weights. Since the new units modify the weights at the next time-step with information from the previous step, temporal tasks can be learned without the use of feedback, thereby greatly simplifying training. Furthermore, a theoretically unlimited number of units can be added to reach into the arbitrarily distant past. Experiments with the Reber grammar have demonstrated speedups of two orders of magnitude over recurrent networks.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jonathan Richard Bachrach. </author> <title> Connectionist Modeling and Control of Finite State Environments. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Sciences, University of Massachusetts, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: 1 INTRODUCTION Second-order recurrent networks have proven to be very powerful [8], especially when trained using complete back propagation through time <ref> [1, 6, 14] </ref>. It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks [2, 4, 11, 12, 15].
Reference: [2] <author> Axel Cleeremans, David Servan-Schreiber, and James L. McClelland. </author> <title> Finite state automata and simple recurrent networks. </title> <journal> Neural Computation, </journal> <volume> 1(3) </volume> <pages> 372-381, </pages> <year> 1989. </year>
Reference-contexts: It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks <ref> [2, 4, 11, 12, 15] </ref>. The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in [9]), adds higher orders when they are needed by the system to solve its task. <p> The results for the recurrent networks are quoted from other sources <ref> [2, 5] </ref>. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm [15]. the arc that will be traversed next. <p> Note that the current state cannot be determined from the current input alone. An Elman-type recurrent network was able to learn this task after 20,000 string presentations using 15 hidden units <ref> [2] </ref>. (The correctness criteria for the Elman net was slightly more stringent than that described in the previous paragraph.) Recurrent Cascade-Correlation (RCC) was able to learn this task using only two or three hidden units in an average of 25,000 string presentations [5].
Reference: [3] <author> Richard Dawkins. </author> <title> Hierarchical organisation: a candidate principle for ethology. </title> <editor> In P. P. G. Bateson and R. A. Hinde, editors, </editor> <booktitle> Growing Points in Ethology, </booktitle> <pages> pages 7-54, </pages> <address> Cambridge, 1976. </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: If the needed information is not available at the previous time-step, then new units may be built to look for the information at still earlier steps. This method concentrating on unexpected events is similar to the "hierarchy of decisions" of Dawkins <ref> [3] </ref>, and the "history compression" of Schmidhuber [13]. 3 WHEN TO ADD NEW UNITS A unit is added whenever a weight is being pulled strongly in opposite directions (i.e. when learning is forcing the weight to increase and to decrease at the same time).
Reference: [4] <author> Jeffrey L. Elman. </author> <title> Finding structure in time. </title> <type> CRL Technical Report 8801, </type> <institution> University of California, San Diego, Center for Research in Language, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks <ref> [2, 4, 11, 12, 15] </ref>. The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in [9]), adds higher orders when they are needed by the system to solve its task.
Reference: [5] <author> Scott E. Fahlman. </author> <title> The recurrent cascade-correlation architecture. </title> <editor> In R. P. Lippmann, J. E. Moody, and D. S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <pages> pages 190-196, </pages> <address> San Mateo, California, 1991. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The results for the recurrent networks are quoted from other sources <ref> [2, 5] </ref>. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm [15]. the arc that will be traversed next. <p> after 20,000 string presentations using 15 hidden units [2]. (The correctness criteria for the Elman net was slightly more stringent than that described in the previous paragraph.) Recurrent Cascade-Correlation (RCC) was able to learn this task using only two or three hidden units in an average of 25,000 string presentations <ref> [5] </ref>. The incremental, higher-order network was trained on a continuous stream of input: the network was not reset before beginning a new string. Training was considered to be complete only after the network had correctly classified 100 strings in a row.
Reference: [6] <author> C. L. Giles, C. B. Miller, D. Chen, G. Z. Sun, H. H. Chen, and Y. C. Lee. </author> <title> Extracting and learning an unknown grammar with recurrent neural networks. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 317-324, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: 1 INTRODUCTION Second-order recurrent networks have proven to be very powerful [8], especially when trained using complete back propagation through time <ref> [1, 6, 14] </ref>. It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks [2, 4, 11, 12, 15].
Reference: [7] <author> Michael C. Mozer. </author> <title> Induction of multiscale temporal structure. </title> <editor> In John E. Moody, Steven J. Hanson, and Richard P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 275-282, </pages> <address> San Mateo, Califor-nia, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The parameter settings were: = 0:04; = 0:08; fi = 1:0; * = 0:1 and Bias = 0:0. (The network seemed to perform better with no bias unit.) The network has also been tested on the "variable gap" tasks introduced by Mozer <ref> [7] </ref>, as shown in figure 1. These tasks were intended to test performance of networks over long time-delays. Two sequences are alternately presented to the network. <p> The length of the gap can be increased in order to create tasks of greater difficulty. Results of the "gap" tasks are given in table 2. The values for the standard recurrent network and for Mozer's own variation are quoted from Mozer's paper <ref> [7] </ref>. The incremental higher-order net had no difficulty with gaps up to 24, which was the largest gap I tested. <p> Gap Standard Mozer Incremental Units Recurrent Net Network Higher-Order Net Created 2 468 328 4 10 6 9830 992 8 19 10 &gt; 10000 1630 12 27 Table 2: A comparison on the "gap" tasks of a standard recurrent-network and a network devised specifically for long time-delays (quoted from Mozer <ref> [7] </ref>, who reported results for gaps up to ten) against an incremental higher-order network. The last column is the number of units created by the incremental higher-order net. 5 CONCLUSIONS The incremental higher-order network performed much better than the networks that it was compared against on these tiny tests.
Reference: [8] <author> Jordan B. Pollack. </author> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 227-252, </pages> <year> 1991. </year>
Reference-contexts: 1 INTRODUCTION Second-order recurrent networks have proven to be very powerful <ref> [8] </ref>, especially when trained using complete back propagation through time [1, 6, 14]. It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks [2, 4, 11, 12, 15].
Reference: [9] <author> Mark B. </author> <title> Ring. Incremental development of complex behaviors through automatic construction of sensory-motor hierarchies. </title> <editor> In Lawrence A. Birnbaum and Gregg C. Collins, editors, </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (ML91), </booktitle> <pages> pages 343-347. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in <ref> [9] </ref>), adds higher orders when they are needed by the system to solve its task. This is done by adding new units that dynamically modify connection weights.
Reference: [10] <author> Mark B. </author> <title> Ring. Sequence learning with incremental higher-order neural networks. </title> <type> Technical Report AI 93-193, </type> <institution> Artificial Intelligence Laboratory, University of Texas at Austin, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: It therefore also specifies how many time-steps it takes for a change in unit i's activation to affect the network's output. Due to space limitations, the derivation of the gradient is not shown, but is given elsewhere <ref> [10] </ref>. The resulting weight change rule, however, is: w ij (t) = I j (t t i ) T i (t) O i (t) If U i O i xy The weights are changed after error values for the output units have been collected.
Reference: [11] <author> A. J. Robinson and F. Fallside. </author> <title> The utility driven dynamic error propagation network. </title> <type> Technical Report CUED/F-INFENG/TR.1, </type> <institution> Cambridge University Engineering Department, </institution> <year> 1987. </year>
Reference-contexts: It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks <ref> [2, 4, 11, 12, 15] </ref>. The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in [9]), adds higher orders when they are needed by the system to solve its task.
Reference: [12] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. V1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks <ref> [2, 4, 11, 12, 15] </ref>. The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in [9]), adds higher orders when they are needed by the system to solve its task.
Reference: [13] <author> Jurgen Schmidhuber. </author> <title> Learning unambiguous reduced sequence descriptions. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 291-298, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: If the needed information is not available at the previous time-step, then new units may be built to look for the information at still earlier steps. This method concentrating on unexpected events is similar to the "hierarchy of decisions" of Dawkins [3], and the "history compression" of Schmidhuber <ref> [13] </ref>. 3 WHEN TO ADD NEW UNITS A unit is added whenever a weight is being pulled strongly in opposite directions (i.e. when learning is forcing the weight to increase and to decrease at the same time).
Reference: [14] <author> Raymond L. Watrous and Gary M. Kuhn. </author> <title> Induction of finite-state languages using second-order recurrent networks. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 309-316, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: 1 INTRODUCTION Second-order recurrent networks have proven to be very powerful [8], especially when trained using complete back propagation through time <ref> [1, 6, 14] </ref>. It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks [2, 4, 11, 12, 15].
Reference: [15] <author> Ronald J. Williams and David Zipser. </author> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 270-280, </pages> <year> 1989. </year>
Reference-contexts: It has also been demonstrated by Fahlman that a recurrent network that incrementally adds nodes during training|his Recurrent Cascade-Correlation algorithm [5]|can be superior to non-incremental, recurrent networks <ref> [2, 4, 11, 12, 15] </ref>. The incremental, higher-order network presented here combines advantages of both of these approaches in a non-recurrent network. This network (a simplified, con tinuous version of that introduced in [9]), adds higher orders when they are needed by the system to solve its task. <p> The results for the recurrent networks are quoted from other sources [2, 5]. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm <ref> [15] </ref>. the arc that will be traversed next. A training sequence, or string, is generated by starting with a B transition and then randomly choosing an arc leading away from the current state until the final state is reached.
Reference: [16] <author> Mike Wynn-Jones. </author> <title> Node splitting: A constructive algorithm for feed-forward neural networks. </title> <journal> Neural Computing and Applications, </journal> <volume> 1(1) </volume> <pages> 17-22, </pages> <year> 1993. </year>
Reference-contexts: A related method for adding new units in feed-forward networks was introduced by Wynne-Jones <ref> [16] </ref>. When a new unit is added, its incoming weights are initially zero. It has no output weights but simply learns to anticipate and reduce the error at each time-step of the weight it modifies.
References-found: 16

