URL: http://www.cs.wustl.edu/~sg/wucs-98-28.ps.Z
Refering-URL: http://www.cs.wustl.edu/~sg/
Root-URL: http://www.cs.wustl.edu
Email: sg@cs.wustl.edu  kwek@eecs.wsu.edu  sscott@cse.unl.edu  
Title: Learning From Examples With Unspecified Attribute Values  
Author: Sally A. Goldman Stephen S. Kwek Stephen D. Scott 
Note: An earlier version appears in the Tenth Annual ACM Conference on Computational Learn ing Theory, 1997 Supported in part by NSF NYI Grant CCR-9357707 with matching funds provided by Xerox PARC and WUTA.  
Date: December 1998  
Address: St. Louis, MO 63130-4899  Pullman, WA 99164-1035  Lincoln, NE 68588-0115  
Affiliation: Dept. of Computer Science Washington University  School of Electrical Engineering and Computer Science Washington State University  Dept. of Computer Science and Engineering University of Nebraska  
Pubnum: WUCS-98-28  
Abstract: We introduce the UAV learning model in which some of the attributes in the examples are unspecified. In our model, an example x is classified positive (resp., negative) if all possible assignments for the unspecified attributes result in a positive (resp., negative) classification. Otherwise the classification given to x is "?" (for unknown). Given an example x in which some attributes are unspecified, the oracle UAV-MQ responds with the classification of x. Given a hypothesis h, the oracle UAV-EQ returns 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Aizenstein and L. Pitt. </author> <title> Exact learning of read-twice DNF formulas. </title> <booktitle> In Proc. 32th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 170-179. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 18, 16], read-twice DNF formulas <ref> [1] </ref>, k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [2] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Inform. Comput., </journal> <volume> 75(2) </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata <ref> [2] </ref>, Horn sentences [4], read-once formulas [5, 18, 16], read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [3] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The attributes could be provided by the output of feature extractors which sometimes are unable to determine whether or not a given feature is present. In this paper we introduce a variant of Angluin's exact learning model <ref> [3] </ref> in which some of the attribute values are left unspecified. When first defining the PAC model, Valiant [43] also suggested a variation in which some attribute values are unspecified but he did not study this variation in detail (see Section 3). <p> We study the relationship between the UAV and RUAV models, and then prove that the class of DNF formulas is learnable under the RUAV model using RUAV-MQ and RUAV-EQ oracles (no evaluation oracle is needed). 2 OUR LEARNING MODEL We first briefly review the exact learning model introduced by Angluin <ref> [3] </ref>. The learner's goal is to exactly learn (using various types of queries) how an unknown (boolean) target function f, taken from some known concept class C, classifies (from f+; g) all instances from the domain. Many different types of queries have been studied. <p> For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 32, 41, 29] </ref> and when there is attribute noise [40, 23, 33]. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12]. <p> They presented lower bound results on the number of UAV-EQs and UAV-MQs required to learn a concept class in terms of its Vapnik Chervonenkis dimension. Further, they extended Angluin's <ref> [3] </ref> sunflower lemma (which is useful in proving lower bound results in the exact model) to the UAV setting. In doing so, they establish exponentially large lower bounds on the number of UAV-MQs needed to learn monotone DNF, read-once DNF, O (n)-DNF, read-twice DNF and 2-decision lists. <p> Since the class of singletons can be represented by trees in T with O (n) nodes and the class of singletons cannot be learned with standard membership queries <ref> [3] </ref>, T cannot be learned using standard membership queries. This provides a second example (along with read-once formulas, see Section 3) demonstrating that the UAV-MQ oracle is more powerful than standard MQ oracle. We denote the size of a tree T by jT j. <p> x i 2L t and hence we will reach a "?" example and go to Line 2. 21 Finally, since PositiveCompletion and ExtractTerm make O (n 2 ) and O (n) membership queries respectively, we have the desired result. 7 CONCLUSION In this paper, we introduced a variant of Angluin's <ref> [3] </ref> exact learning model where some of the attributes in the examples are unspecified. While we gave some initial results for this model, many interesting questions have been raised.
Reference: [4] <author> D. Angluin, M. Frazier, and L. Pitt. </author> <title> Learning conjunctions of Horn clauses. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 147-164, </pages> <year> 1992. </year> <month> 22 </month>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences <ref> [4] </ref>, read-once formulas [5, 18, 16], read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [5] <author> D. Angluin, L. Hellerstein, and M. Karpinski. </author> <title> Learning read-once formulas with queries. </title> <journal> J. ACM, </journal> <volume> 40 </volume> <pages> 185-210, </pages> <year> 1993. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 18, 16] </ref>, read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries [26] or using these restricted projective equivalence queries [27]. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known <ref> [5] </ref> that a polynomial number of calls to the MQ oracle is not sufficient. This demonstrates (as one would expect) that the UAV-MQ oracle is more powerful than the MQ oracle.
Reference: [6] <author> D. Angluin and M. Krikis. </author> <title> Learning with malicious membership queries and exceptions. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 57-66. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [37, 7, 42, 6, 12] </ref>.
Reference: [7] <author> Dana Angluin and Donna K. </author> <title> Slonim. Randomly fallible teachers: Learning monotone DNF with an incomplete membership oracle. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 7-26, </pages> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [37, 7, 42, 6, 12] </ref>.
Reference: [8] <author> R. Bareiss B. W. Porter and R. Holte. </author> <title> Concept learning and heuristic classifcation in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 229-263, </pages> <year> 1990. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 35, 15] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [38, 39] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> They investigate, under various conditions, whether the strategies <ref> [8, 35, 15] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [9] <author> S. Ben-David and E. Dichterman. </author> <title> Learning with restricted focus of attention. </title> <booktitle> In Proc. 6th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 287-296. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: A learning model that has very similar motivations to the UAV model is 6 the model of RFA (restricted focus of attention) learnability <ref> [9, 10] </ref>. The k-RFA model is a variant of the PAC model in which for each example only k attributes (of the n attributes), as selected by the learner, are specified.
Reference: [10] <author> Andreas Birkendorf, Eli Dichterman, Jeffrey Jackson, Norbert Klasner, and Hans Ulrich Simon. </author> <title> On restricted-focus-of-attention learnability of Boolean functions. </title> <journal> Machine Learning, </journal> <volume> 30 </volume> <pages> 89-123, </pages> <year> 1998. </year>
Reference-contexts: A learning model that has very similar motivations to the UAV model is 6 the model of RFA (restricted focus of attention) learnability <ref> [9, 10] </ref>. The k-RFA model is a variant of the PAC model in which for each example only k attributes (of the n attributes), as selected by the learner, are specified.
Reference: [11] <author> Andreas Birkendorf, Eli Dichterman, Norbert Klasner, and Hans Ulrich Simon. </author> <title> Structural results about exact learning with unspecified attribute values. </title> <booktitle> In Proc. 11th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 144-153, </pages> <year> 1998. </year>
Reference-contexts: However, we believe that the UAV-MQ oracle cannot simulate subset and superset query oracles with the hypothesis class of depth-3 ^-_-^ formulas as would be needed to use the algorithm of Bshouty et. al to learn DNF formulas with only a UAV-MQ oracle. Recently, Birkendorf, Klasner, Kuhlman and Simon <ref> [11] </ref> investigated the UAV model further and answered a number of open problems posted in an earlier (conference) version of this paper [24]. They presented lower bound results on the number of UAV-EQs and UAV-MQs required to learn a concept class in terms of its Vapnik Chervonenkis dimension.
Reference: [12] <author> Avrim Blum, Prasad Chalasani, Sally A. Goldman, and Donna K. </author> <title> Slonim. Learning with unreliable boundary queries. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 98-107. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [37, 7, 42, 6, 12] </ref>.
Reference: [13] <author> Avrim Blum and Stephen Rudich. </author> <title> Fast learning of k-term DNF formulas with queries. </title> <journal> J. of Comput. Syst. Sci., </journal> <volume> 51(3) </volume> <pages> 367-373, </pages> <year> 1995. </year>
Reference-contexts: can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 18, 16], read-twice DNF formulas [1], k-term DNF formulas <ref> [13, 20] </ref>, etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [14] <author> M. Blum, A. Chandra, and M. Wegman. </author> <title> Equivalence of free Boolean graphs can be decided probabilistically in polynomial time. </title> <journal> Information Processing Letters, </journal> <volume> 10 </volume> <pages> 80-82, </pages> <year> 1980. </year>
Reference-contexts: First, for a projection closed class 1 if we can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs <ref> [14, 21] </ref>, read-once boolean formulas [28] and read-twice DNF [34]. Also, if the number of unspecified attributes is O (log n), then evaluation can be done in polynomial time by simply considering all completions of x. <p> Finally, for a projection closed class for whichwe can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs <ref> [14, 21] </ref>, read-once boolean formulas [28] and read-twice DNF [34].
Reference: [15] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <year> 1984. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 35, 15] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [38, 39] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> They investigate, under various conditions, whether the strategies <ref> [8, 35, 15] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [16] <author> N. Bshouty, T. Hancock, L. Hellerstein, and M. Karpinski. </author> <title> An algorithm to learn read-once threshold formulas, and transformations between learning models. </title> <journal> Computational Complexity, </journal> <volume> 4 </volume> <pages> 37-61, </pages> <year> 1994. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 18, 16] </ref>, read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [17] <author> N. H. Bshouty, R. Cleve, S. Kannan, and C. Tamon. </author> <title> Oracles and queries that are sufficient for exact learning. </title> <journal> J. of Comput. Syst. Sci., </journal> <volume> 52(3) </volume> <pages> 421-433, </pages> <year> 1996. </year>
Reference-contexts: Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient. This demonstrates (as one would expect) that the UAV-MQ oracle is more powerful than the MQ oracle. Bshouty, Cleve, Kannan and Tamon <ref> [17] </ref> show that DNF formulas can be learned by a randomized algorithm in expected polynomial time with equivalence queries and the aid of an NP oracle. Using this result, they also show that DNF formulas can be learned using subset and superset queries.
Reference: [18] <author> N. H. Bshouty, T. R. Hancock, and L. Hellerstein. </author> <title> Learning arithmetic read-once formulas. </title> <journal> SIAM J. Comput., </journal> <volume> 24(4) </volume> <pages> 706-735, </pages> <year> 1995. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 18, 16] </ref>, read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [19] <author> Nader H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <journal> Inform. Com-put., </journal> <volume> 123(1) </volume> <pages> 146-153, </pages> <year> 1995. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees <ref> [19] </ref>, deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 18, 16], read-twice DNF formulas [1], k-term DNF formulas [13, 20], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. <p> in polynomial time in the UAV model using only the UAV-EQ oracle, then C is exactly learnable in the standard model in polynomial time using only the EQ oracle. 5 LEARNING ORDERED DECISION TREES WITH A UAV-MQ ORACLE Combining our results from the last section with Bshouty's decision tree algorithm <ref> [19] </ref>, we can learn the class of decision trees in the UAV model using the UAV-MQ, UAV-EQ, and EV oracles.
Reference: [20] <author> Nader H. Bshouty. </author> <title> Simple learning algorithms using divide and conquer. </title> <journal> Computational Complexity, </journal> <volume> 6(2) </volume> <pages> 174-194, </pages> <year> 1997. </year>
Reference-contexts: can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [19], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 18, 16], read-twice DNF formulas [1], k-term DNF formulas <ref> [13, 20] </ref>, etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [21] <author> S. Fortune, J. Hopcroft, and E. Schmidt. </author> <title> The complexity of equivalence and containment for free single variable program schemes. </title> <booktitle> In Lecture Notes in Computer Science 62: Proceedings of Automata, Languages and Programming, </booktitle> <pages> pages 227-240. </pages> <publisher> Springer-Verlag, </publisher> <year> 1978. </year>
Reference-contexts: First, for a projection closed class 1 if we can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs <ref> [14, 21] </ref>, read-once boolean formulas [28] and read-twice DNF [34]. Also, if the number of unspecified attributes is O (log n), then evaluation can be done in polynomial time by simply considering all completions of x. <p> Finally, for a projection closed class for whichwe can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs <ref> [14, 21] </ref>, read-once boolean formulas [28] and read-twice DNF [34].
Reference: [22] <author> M. Frazier, S. Goldman, N. Mishra, and L. Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <journal> J. of Comput. Syst. Sci., </journal> <volume> 52(3) </volume> <pages> 472-492, </pages> <year> 1996. </year> <note> Special Issue on COLT '94. </note>
Reference-contexts: In other related work, Frazier, Goldman, Mishra, and Pitt <ref> [22] </ref> introduce a learning model that captures the idea that teachers may have gaps in their knowledge.
Reference: [23] <author> S. A. Goldman and R. H. Sloan. </author> <title> Can PAC learning algorithms tolerate random attribute noise? Algorithmica, </title> <booktitle> 14 </booktitle> <pages> 70-84, </pages> <year> 1995. </year>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 32, 41, 29] and when there is attribute noise <ref> [40, 23, 33] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [24] <author> Sally A. Goldman, Stephen S. Kwek, and Stephen D. Scott. </author> <title> Learning from examples with unspecified attribute values. </title> <booktitle> In Proc. 10th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 231-242. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: Recently, Birkendorf, Klasner, Kuhlman and Simon [11] investigated the UAV model further and answered a number of open problems posted in an earlier (conference) version of this paper <ref> [24] </ref>. They presented lower bound results on the number of UAV-EQs and UAV-MQs required to learn a concept class in terms of its Vapnik Chervonenkis dimension. Further, they extended Angluin's [3] sunflower lemma (which is useful in proving lower bound results in the exact model) to the UAV setting.
Reference: [25] <author> Russell Greiner, Adam J. Grove, and Dan Roth. </author> <title> Learning active classifiers. </title> <booktitle> In Proc. 13th International Conference on Machine Learning, </booktitle> <pages> pages 207-215. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: There has been some research in this direction (such as the work of Greiner, Grove and Roth <ref> [25] </ref>). By allowing the cost to possibly be infinite this could model the situation in which some unspecified attributes could be obtained (at some given cost), yet the values of some unspecified attributes are just not available.
Reference: [26] <author> T. Hancock. </author> <title> Identifying -decision trees and -formulas with constrained instance queries. </title> <type> Manuscript, </type> <institution> Harvard University, </institution> <year> 1989. </year>
Reference-contexts: Finally, there have been two oracles studied that are similar to the UAV-MQ oracle: the constrained instance oracle <ref> [26] </ref> and the projective equivalence oracle [27]. We use CIQ to denote a constrained instance query, and PEQ to denote a projective equivalence query. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries <ref> [26] </ref> or using these restricted projective equivalence queries [27]. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient.
Reference: [27] <author> L. Hellerstein and M. Karpinski. </author> <title> Learning read-once formulas using membership queries. </title> <booktitle> In Proc. of the Second Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 146-161. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Finally, there have been two oracles studied that are similar to the UAV-MQ oracle: the constrained instance oracle [26] and the projective equivalence oracle <ref> [27] </ref>. We use CIQ to denote a constrained instance query, and PEQ to denote a projective equivalence query. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries [26] or using these restricted projective equivalence queries <ref> [27] </ref>. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient.
Reference: [28] <author> H. Hunt and R. Stearns. </author> <title> Monotone Boolean formulas, distributive lattices, and the complexity of logics, algebraic structures, and comutation structures. </title> <booktitle> In Lecture Notes in Computer Science: Proceedings of 3rd Annual Symposium on Theoretical Aspects of Computer Science, </booktitle> <pages> pages 277-287. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: First, for a projection closed class 1 if we can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs [14, 21], read-once boolean formulas <ref> [28] </ref> and read-twice DNF [34]. Also, if the number of unspecified attributes is O (log n), then evaluation can be done in polynomial time by simply considering all completions of x. <p> Finally, for a projection closed class for whichwe can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs [14, 21], read-once boolean formulas <ref> [28] </ref> and read-twice DNF [34].
Reference: [29] <author> M. Kearns and M. Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 807-837, </pages> <year> 1993. </year>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 32, 41, 29] </ref> and when there is attribute noise [40, 23, 33]. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [30] <author> M. Kearns and R. Schapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 48(3) </volume> <pages> 464-497, </pages> <year> 1994. </year>
Reference-contexts: Using this observation, Valiant constructs an efficient PAC learning algorithm, with the aid of a membership query oracle, for learning monotone DNF under the universal interpretation. Some work that has similar motivations is the p-concepts model of Kearns and Schapire <ref> [30] </ref>.
Reference: [31] <author> Roni Khardon and Dan Roth. </author> <title> Learning to reason with a restricted view. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 301-310. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: Thus we feel it is important for algorithms in our model to classify examples that have unspecified attributes. This requirement led us to have a three-valued (versus binary) output. In the different "learning to reason" framework, Khardon and Roth <ref> [31] </ref> investigate the construction of a knowledge base for representing "the world", i.e. some boolean function f. This knowledge base is then used to deduce (i.e. reason) if f logically implies ff where ff is a propositional query capturing the situation at hand.
Reference: [32] <author> P.D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 32, 41, 29] </ref> and when there is attribute noise [40, 23, 33]. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [33] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Com-put. Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 32, 41, 29] and when there is attribute noise <ref> [40, 23, 33] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [34] <author> K. Pillaipakkamnatt and V. Raghavan. </author> <title> Read-twice DNF formulas are properly learnable. </title> <journal> Inform. Comput., </journal> <volume> 122(2) </volume> <pages> 236-267, </pages> <year> 1995. </year>
Reference-contexts: Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs [14, 21], read-once boolean formulas [28] and read-twice DNF <ref> [34] </ref>. Also, if the number of unspecified attributes is O (log n), then evaluation can be done in polynomial time by simply considering all completions of x. <p> Such equivalence tests exist for monotone DNF, read-once branching programs [36], Horn-sentences, free-branching programs [14, 21], read-once boolean formulas [28] and read-twice DNF <ref> [34] </ref>.
Reference: [35] <author> J. R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In Proceedings of the 6th International Machine Learning Workshop, </booktitle> <pages> pages 164-168, </pages> <year> 1989. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 35, 15] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [38, 39] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> They investigate, under various conditions, whether the strategies <ref> [8, 35, 15] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [36] <author> V. Raghhavan and D. Wilkins. </author> <title> A nearly-linear time equivalence test and characterization of -branching programs. </title> <journal> Mathematical Systems Theory, </journal> <volume> 30 </volume> <pages> 249-283, </pages> <year> 1997. </year>
Reference-contexts: First, for a projection closed class 1 if we can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs <ref> [36] </ref>, Horn-sentences, free-branching programs [14, 21], read-once boolean formulas [28] and read-twice DNF [34]. Also, if the number of unspecified attributes is O (log n), then evaluation can be done in polynomial time by simply considering all completions of x. <p> Finally, for a projection closed class for whichwe can efficiently determine whether two different representations of a concept class are functionally equivalent then an EV oracle is not needed. Such equivalence tests exist for monotone DNF, read-once branching programs <ref> [36] </ref>, Horn-sentences, free-branching programs [14, 21], read-once boolean formulas [28] and read-twice DNF [34].
Reference: [37] <author> Y. Sakakibara. </author> <title> On learning from queries and counterexamples in the presence of noise. </title> <journal> Inform. Proc. Lett., </journal> <volume> 37(5) </volume> <pages> 279-284, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [37, 7, 42, 6, 12] </ref>.
Reference: [38] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning default concepts. </title> <booktitle> In Proceedings of the Tenth Canadian Conference on Artificial Intelligence, </booktitle> <pages> pages 519-523, </pages> <year> 1994. </year>
Reference-contexts: There has been some empirical work studying the task of learning from incomplete data [8, 35, 15]. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner <ref> [38, 39] </ref> studied the problem of learning accurate default concepts to be used when working with incomplete data.
Reference: [39] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning to Classify Incomplete Examples. </title> <booktitle> In Computational Learning Theory and Natural Learning Systems, Volume IV: Making Learning Systems Practical, chapter 6, </booktitle> <pages> pages 87-105. </pages> <publisher> MIT Press, </publisher> <year> 1997. </year>
Reference-contexts: There has been some empirical work studying the task of learning from incomplete data [8, 35, 15]. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner <ref> [38, 39] </ref> studied the problem of learning accurate default concepts to be used when working with incomplete data.
Reference: [40] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proc. 1st Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 32, 41, 29] and when there is attribute noise <ref> [40, 23, 33] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [41] <author> R. H. Sloan. </author> <title> Four types of noise in data for PAC learning. </title> <journal> Information Processing Letters, </journal> <volume> 54 </volume> <pages> 157-162, </pages> <year> 1995. </year>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 32, 41, 29] </ref> and when there is attribute noise [40, 23, 33]. There has also been some work in which the answers to membership queries are noisy or missing [37, 7, 42, 6, 12].
Reference: [42] <author> R. H. Sloan and G. Turan. </author> <title> Learning with queries but incomplete information. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 237-245. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [37, 7, 42, 6, 12] </ref>.
Reference: [43] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year> <month> 25 </month>
Reference-contexts: In this paper we introduce a variant of Angluin's exact learning model [3] in which some of the attribute values are left unspecified. When first defining the PAC model, Valiant <ref> [43] </ref> also suggested a variation in which some attribute values are unspecified but he did not study this variation in detail (see Section 3). In our new model, the examples are drawn from f0; 1; flg n where "fl" denotes unspecified. <p> As suggested by Valiant <ref> [43] </ref>, we consider when the target concept is defined over n boolean variables x 1 ; : : : ; x n with an instance space X n = f0; 1; flg n , where "fl" indicates that the corresponding variable is unspecified. <p> The membership and equivalence query oracles under these two interpretations are clearly less informative than their UAV counterparts. The universal interpretation was introduced earlier when Valiant <ref> [43] </ref> first defined the PAC model. 7 Clearly, if the target concept is monotone, then both the universal and abbrevi-ated interpretations are equivalent. Using this observation, Valiant constructs an efficient PAC learning algorithm, with the aid of a membership query oracle, for learning monotone DNF under the universal interpretation.
References-found: 43

