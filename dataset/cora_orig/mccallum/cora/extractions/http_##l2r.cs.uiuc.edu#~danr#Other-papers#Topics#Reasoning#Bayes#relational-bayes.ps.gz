URL: http://l2r.cs.uiuc.edu/~danr/Other-papers/Topics/Reasoning/Bayes/relational-bayes.ps.gz
Refering-URL: http://l2r.cs.uiuc.edu/~danr/Teaching/CS491-98/491-list.html
Root-URL: http://www.cs.uiuc.edu
Email: jaeger@robotics.stanford.edu  
Title: Relational Bayesian Networks  
Author: Manfred Jaeger 
Address: Stanford CA 94305  
Affiliation: Computer Science Department, Stanford University,  
Abstract: A new method is developed to represent probabilistic relations on multiple random events. Where previously knowledge bases containing probabilistic rules were used for this purpose, here a probability distribution over the relations is directly represented by a Bayesian network. By using a powerful way of specifying conditional probability distributions in these networks, the resulting formalism is more expressive than the previous ones. Particularly, it provides for constraints on equalities of events, and it allows to define complex, nested combination functions.
Abstract-found: 1
Intro-found: 1
Reference: <author> Breese, J. S. </author> <year> (1992), </year> <title> Construction of belief and decision networks, </title> <journal> Computational Intelligence. </journal>
Reference-contexts: One way of expressing such laws, which has been explored in the past ( <ref> (Breese 1992) </ref>,(Poole 1993),(Haddawy 1994)), is to use probabilistic rules such as stronger (u; v) 0:8 quake (u) ^ quake (v) ^alarm (u) ^ :alarm (v): (1) The intended meaning here is: for all states of the world ! 1 and ! 2 , given that quake (! 1 ) ^ :
Reference: <author> Glesner, S. & Koller, D. </author> <year> (1995), </year> <title> Constructing flexible dynamic belief networks from first-order probabilistic knowledge bases, </title> <booktitle> in Proceedings of ECSQARU, Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer Ver-lag. </publisher>
Reference-contexts: In <ref> (Glesner & Koller 1995) </ref> and (Ngo, Haddawy & Helwig 1995) therefore a combination rule is added to the rule-base, which defines how the conditional probabilities arising from different in-stantiations, or rules, are to be combined. <p> There are other interesting things that we are not able to model so far. Among them are random functions (the main concern of (Haddawy 1994)), and a recursive temporal dependence of a relation on itself (addressed both in (Ngo et al. 1995) and <ref> (Glesner & Koller 1995) </ref>). In this section we define a straightforward generalization of relational Bayesian networks that allows us to treat all these issues in a uniform way. We can identify a recursive dependence of a relation on itself as the general underlying mechanism we have to model.
Reference: <author> Haddawy, P. </author> <year> (1994), </year> <title> Generating bayesian networks from probability logic knowledge bases, </title> <booktitle> in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: There are other interesting things that we are not able to model so far. Among them are random functions (the main concern of <ref> (Haddawy 1994) </ref>), and a recursive temporal dependence of a relation on itself (addressed both in (Ngo et al. 1995) and (Glesner & Koller 1995)). In this section we define a straightforward generalization of relational Bayesian networks that allows us to treat all these issues in a uniform way.
Reference: <author> Halpern, J. </author> <year> (1990), </year> <title> An analysis of first-order logics of probability, </title> <journal> Artificial Intelligence 46, </journal> <volume> 311350. </volume>
Reference: <author> Koller, D. & Halpern, J. Y. </author> <year> (1996), </year> <title> Irrelevance and conditioning in first-order probabilistic logic, </title> <booktitle> in Pro-ceedins of the 13th National Conference on Artificial Intelligence (AAAI), </booktitle> <pages> pp. 569576. </pages>
Reference: <author> Ngo, L., Haddawy, P. & Helwig, J. </author> <year> (1995), </year> <title> A theoretical framework for context-sensitive temporal probability model construction with application to plan projection, </title> <booktitle> in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 419426. </pages>
Reference-contexts: In (Glesner & Koller 1995) and <ref> (Ngo, Haddawy & Helwig 1995) </ref> therefore a combination rule is added to the rule-base, which defines how the conditional probabilities arising from different in-stantiations, or rules, are to be combined. <p> There are other interesting things that we are not able to model so far. Among them are random functions (the main concern of (Haddawy 1994)), and a recursive temporal dependence of a relation on itself (addressed both in <ref> (Ngo et al. 1995) </ref> and (Glesner & Koller 1995)). In this section we define a straightforward generalization of relational Bayesian networks that allows us to treat all these issues in a uniform way.
Reference: <author> Poole, D. </author> <year> (1993), </year> <title> Probabilistic horn abduction and bayesian networks, </title> <journal> Artificial Intelligence 64, </journal> <volume> 81 129. </volume>
References-found: 7

