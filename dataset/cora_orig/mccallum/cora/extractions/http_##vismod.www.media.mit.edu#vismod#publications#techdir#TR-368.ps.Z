URL: http://vismod.www.media.mit.edu/vismod/publications/techdir/TR-368.ps.Z
Refering-URL: http://vismod.www.media.mit.edu/vismod/demos/facerec/index.html
Root-URL: 
Title: Generalized Image Matching: Statistical Learning of Physically-Based Deformations  
Author: Chahab Nastar, Baback Moghaddam and Alex Pentland 
Address: 20 Ames Street, Cambridge MA 02139, U.S.A.  
Affiliation: The Media Laboratory, Massachusetts Institute of Technology  
Pubnum: Perceptual Computing Section,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 368 Appears in: Fourth European Conference on Computer Vision, Cambridge, UK, April 1996. Abstract We describe a novel approach for image matching based on deformable intensity surfaces. In this approach, the intensity surface of the image is modeled as a deformable 3D mesh in the (x; y; I(x; y)) space. Each surface point has 3 degrees of freedom, thus capturing fine surface changes. A set of representative deformations within a class of objects (e.g. faces) are statistically learned through a Principal Components Analysis, thus providing a priori knowledge about object-specific deformations. We demonstrate the power of the approach by examples such as image matching and interpolation of missing data. Moreover this approach dramatically reduces the computational cost of solving the governing equation for the physically based system by approximately three orders of magni tude.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. J. Bathe. </author> <title> Finite Element Procedures in Engineering Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: We do not make that assumption here. The vibration modes (i) of the previous deformable surface are the vector solutions of the eigenproblem <ref> [1] </ref> : K = ! 2 M (2) where !(i) is the i-th eigenfrequency of the system.
Reference: [2] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> In Proceedings of the Third European Conference on Computer Vision 1994 (ECCV'94), </booktitle> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [20, 17] and parametric descriptions of shape <ref> [7, 2, 11] </ref>. On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition [21, 19]. In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation.
Reference: [3] <author> David Beymer. </author> <title> Vectorizing face images by interleaving shape and texture computations. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1537, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Furthermore, we seek to unify the shape and texture components of an image in a single compact mathematical framework. Current work in the area of image-based object modeling deals with the shape (2D) and texture (grayscale) components of an image in an independant manner <ref> [3, 5] </ref>. Our novel representation combines both the spatial (XY) and grayscale (I) components of the image into a 3D surface (or manifold) and then efficiently solves for a dense correspondance map in the XY I space.
Reference: [4] <author> T. Boult. </author> <title> Physics in a fantasy world vs. robust statistical estimation. </title> <booktitle> In NSF/ARPA workshop on 3D Object Representation in Computer Vision, </booktitle> <address> New York, USA, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation. In view of some recent critiques of physical modeling (e.g. <ref> [4] </ref>) our motivation here is to ground physically-based models in actual real-world statistics in order to obtain a more realistic and data-driven model for the underlying phenomenon [13, 6]. Furthermore, we seek to unify the shape and texture components of an image in a single compact mathematical framework.
Reference: [5] <author> T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham. </author> <title> Active Shape Models Their Training and Application. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 61(1) </volume> <pages> 38-59, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Furthermore, we seek to unify the shape and texture components of an image in a single compact mathematical framework. Current work in the area of image-based object modeling deals with the shape (2D) and texture (grayscale) components of an image in an independant manner <ref> [3, 5] </ref>. Our novel representation combines both the spatial (XY) and grayscale (I) components of the image into a 3D surface (or manifold) and then efficiently solves for a dense correspondance map in the XY I space.
Reference: [6] <author> T.F. Cootes and C.J. Taylor. </author> <title> Combining point distribution models with shape models based on finite element analysis. </title> <journal> Image and Vision Computing, </journal> <volume> 13(5), </volume> <year> 1995. </year>
Reference-contexts: In view of some recent critiques of physical modeling (e.g. [4]) our motivation here is to ground physically-based models in actual real-world statistics in order to obtain a more realistic and data-driven model for the underlying phenomenon <ref> [13, 6] </ref>. Furthermore, we seek to unify the shape and texture components of an image in a single compact mathematical framework. Current work in the area of image-based object modeling deals with the shape (2D) and texture (grayscale) components of an image in an independant manner [3, 5].
Reference: [7] <author> T.F. Cootes, C.J. Taylor, D.H. Cooper, and J. Graham. </author> <title> Training models of shape from sets of examples. </title> <booktitle> 5 In Proceedings of the British Machine Vision Confer--ence, </booktitle> <address> Leeds, </address> <year> 1992. </year>
Reference-contexts: The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [20, 17] and parametric descriptions of shape <ref> [7, 2, 11] </ref>. On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition [21, 19]. In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation.
Reference: [8] <author> P. E. Danielsson. </author> <title> Euclidean distance mapping. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 14 </volume> <pages> 227-248, </pages> <year> 1980. </year>
Reference-contexts: Initialize the deformable surface S as a subsampling of the intensity surface of image1. 3. Convert image2 to its 3D binary representation, image3. 4. Compute Euclidean distance maps at each voxel of image3 <ref> [8, 22] </ref>. 5. Let S deform dynamically in image3 with the external force derived from the distance maps created at step 2. Note that steps 1 to 4 are pre-processing steps. Steps 1 and 2 provide respectively intensity and spatial smoothing 1 of the image.
Reference: [9] <author> B.K.P. Horn and G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: The elasticity of the surface provides an intrinsic smoothness constraint for computing the final displacement field. Note that our formulation provides an interesting alternative to optical flow methods, without the classical brightness constraint <ref> [9] </ref>. Indeed, the brightness constraint corresponds to a particular case of our formulation 1 where the closest point P i has to have the same intensity as M i ( M i P i is parallel to the XY plane). We do not make that assumption here.
Reference: [10] <author> I.T. Jolliffe. </author> <title> Principal Component Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: These characteristic deformations (or "principal warps") are learned through a statistical Principal Components Analysis (PCA) <ref> [10] </ref> which identifies the principal subspace in which the final correspondance field must lie.
Reference: [11] <author> C. Kervrann and F. Heitz. </author> <title> Learning structure and deformation modes of nonrigid objects in long image sequences. </title> <booktitle> In Proceedings of the International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [20, 17] and parametric descriptions of shape <ref> [7, 2, 11] </ref>. On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition [21, 19]. In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation.
Reference: [12] <editor> M.M. Loeve. </editor> <title> Probability Theory. </title> <publisher> Van Nostrand, Princeton, </publisher> <year> 1955. </year>
Reference-contexts: These characteristic deformations (or "principal warps") are learned through a statistical Principal Components Analysis (PCA) [10] which identifies the principal subspace in which the final correspondance field must lie. Since the Karhunen-Loeve Transform (KLT) <ref> [12] </ref> in PCA corresponds to a unitary linear change of basis, which can be appended to the modal transform used in solving the physical system, we can ultimately derive a compact reduced-order form of the governing equation which combines both the dynamics of the physical system and the "learned" deformations which
Reference: [13] <author> J. Martin, A. Pentland, and R. Kikinis. </author> <title> Shape analysis of brain structures using physical and experimental modes. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, USA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: In view of some recent critiques of physical modeling (e.g. [4]) our motivation here is to ground physically-based models in actual real-world statistics in order to obtain a more realistic and data-driven model for the underlying phenomenon <ref> [13, 6] </ref>. Furthermore, we seek to unify the shape and texture components of an image in a single compact mathematical framework. Current work in the area of image-based object modeling deals with the shape (2D) and texture (grayscale) components of an image in an independant manner [3, 5].
Reference: [14] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <booktitle> In IEEE Proceedings of the Fifth International Conference on Computer Vision, </booktitle> <address> Cambridge, USA, </address> <month> june </month> <year> 1995. </year>
Reference-contexts: This approach is actually part of a more complete statistical formulation for estimating the probability density function of these warps in the high-dimensional vector space ~ U 2 R P (see <ref> [14] </ref>). The estimated class-conditional density P ( ~ Uj) can be ultimately used in a Bayesian framework for a variety of tasks such as regression, interpolation, inference and classification. <p> In our experiments, this alignment was obtained using an automatic face-processing system which extracts faces from the input image and normalizes for translation, scale and slight rotations (both in-plane and out-of-plane). This system is described in detail in <ref> [14] </ref>. For the learning phase of our technique, we choose a set of 50 faces to be warped into a reference face.
Reference: [15] <author> H. Murase and S. K. Nayar. </author> <title> Visual learning and recognition of 3D objects from appearance. </title> <journal> International Journal of Computer Vision, </journal> <volume> 14(5), </volume> <year> 1995. </year>
Reference-contexts: 1 Introduction In recent years, computer vision research has witnessed a growing interest in eigenvector analysis and subspace decomposition methods <ref> [15] </ref>. This general analysis framework lends itself to several closely related formulations in object modeling and recognition which employ the principal modes or characteristic degrees-of-freedom for description.
Reference: [16] <author> C. Nastar. </author> <title> Vibration modes for nonrigid motion analysis in 3D images. </title> <booktitle> In Proceedings of the Third Eu-ropean Conference on Computer Vision (ECCV '94), </booktitle> <address> Stockholm, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The modal superposition equation (4) can be seen as a Fourier expansion with high-frequencies neglected <ref> [16] </ref>. We make use of the analytic expressions of the modes which are known sine and cosine functions for specific surface topologies. For quadrilateral surface meshes that have plane topology (which is the case of the intensity surfaces), the eigenfrequencies of the system are [16] : ! (p; p ) = <p> a Fourier expansion with high-frequencies neglected <ref> [16] </ref>. We make use of the analytic expressions of the modes which are known sine and cosine functions for specific surface topologies. For quadrilateral surface meshes that have plane topology (which is the case of the intensity surfaces), the eigenfrequencies of the system are [16] : ! (p; p ) = 4K=M (sin 2n 2 p 0 K is the stiffness of each spring, M the mass of each node, p and p 0 are the mode parameters.
Reference: [17] <author> C. Nastar and N. Ayache. </author> <title> Fast segmentation, tracking, and analysis of deformable objects. </title> <booktitle> In Proceedings of the Fourth International Conference on Computer Vision (ICCV '93), </booktitle> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling <ref> [20, 17] </ref> and parametric descriptions of shape [7, 2, 11]. On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition [21, 19]. <p> Note that steps 1 to 4 are pre-processing steps. Steps 1 and 2 provide respectively intensity and spatial smoothing 1 of the image. The dynamic process of step 5 is described in <ref> [17] </ref> ; to sum up, the intensity surface S is modeled as a deformable mesh of size N = n fi n 0 nodes, ruled by Lagrangian dynamics : M U + C _ U + KU = F (t) (1) where U = [: : : ; x i ; <p> The above equation is of order 3N . At each node M i of the mesh, the image force points to the closest point P i in the 3D binary image image3 <ref> [17] </ref>. Figure 1 shows a representation of the deformation process. Note that the external forces (dashed arrows) do not necessarily correspond to the final displacement field of the surface since the closest point P i is updated at each time iteration.
Reference: [18] <author> C. Nastar and A. Pentland. </author> <title> Matching and recognition using deformable intensity surfaces. </title> <booktitle> In IEEE International Symposium on Computer Vision, Coral Gables, </booktitle> <address> USA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Our system focuses on matching and recognition in the 3D space defined by (x; y; I (x; y)), that we will call the XY I space (see <ref> [18] </ref> for details). In our formulation, deforming the intensity surface of image1 into the one of image2 in XY I takes place in 5 steps : 1. <p> Each of these faces has a N = 128fi128 resolution, and the manifolds are matched in a modal subspace whose dimension is suitably chosen P = 3 fi 128 2 =4 2 = 3072 <ref> [18] </ref>. We then perform a Principal Components Analysis on the spectra of these warps. KL-eigenvectors extracted from the learning set. For example, we can see that ! E 1 represents change in global headshape (as well as the size of the eyes).
Reference: [19] <author> A. Pentland, B. Moghaddam, T. Starner, and M. Turk. </author> <title> View based and modular eigenspaces for face recognition. </title> <booktitle> In IEEE Proceedings of Computer Vision and Pattern Recognition, </booktitle> <year> 1994. </year>
Reference-contexts: On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition <ref> [21, 19] </ref>. In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation.
Reference: [20] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modelling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-13(7):715-729, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling <ref> [20, 17] </ref> and parametric descriptions of shape [7, 2, 11]. On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition [21, 19].
Reference: [21] <author> M. Turk and A. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In IEEE Proceedings of Computer Vision and Pattern Recognition, </booktitle> <pages> pages 586-591, </pages> <year> 1991. </year>
Reference-contexts: On the other hand, view-based eigentechniques have recently provided some of the best results in object recognition <ref> [21, 19] </ref>. In this paper, we propose a new method which combines both the physically-based modes of vibration and the statistically-based modes of variation.
Reference: [22] <author> Q.Z. Ye. </author> <title> The signed euclidean distance transform and its applications. </title> <booktitle> In International Conference on Pattern Recognition, </booktitle> <pages> pages 495-499, </pages> <year> 1988. </year> <month> 6 </month>
Reference-contexts: Initialize the deformable surface S as a subsampling of the intensity surface of image1. 3. Convert image2 to its 3D binary representation, image3. 4. Compute Euclidean distance maps at each voxel of image3 <ref> [8, 22] </ref>. 5. Let S deform dynamically in image3 with the external force derived from the distance maps created at step 2. Note that steps 1 to 4 are pre-processing steps. Steps 1 and 2 provide respectively intensity and spatial smoothing 1 of the image.
References-found: 22

