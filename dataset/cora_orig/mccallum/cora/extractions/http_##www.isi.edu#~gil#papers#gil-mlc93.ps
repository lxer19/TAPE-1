URL: http://www.isi.edu/~gil/papers/gil-mlc93.ps
Refering-URL: http://www.isi.edu/~gil/papers/papers-ml.html
Root-URL: 
Email: gil@isi.edu  
Title: Efficient Domain-Independent Experimentation  
Author: Yolanda Gil 
Note: In Proceedings of the Tenth International Conference on Machine  
Date: July 19, 1996  June 1993.  
Address: 4676 Admiralty Way Marina del Rey, CA 90292  Amherst, MA,  
Affiliation: Information Sciences Institute, USC  Learning,  
Abstract: Planning systems often make the assumption that omniscient world knowledge is available. Our approach makes the more realistic assumption that the initial knowledge about the actions is incomplete, and uses experimentation as a learning mechanism when the missing knowledge causes an execution failure. Previous work on learning by experimentation has not addressed the issue of how to choose good experiments, and much research on learning from failure has relied on background knowledge to build explanations that pinpoint directly the causes of failures. We want to investigate the potential of a system for efficient learning by experimentation without such background knowledge. This paper describes domain-independent heuristics that compare possible hypotheses and choose the ones most likely to cause the failure. These heuristics extract information solely from the domain operators initially available for planning (incapable of producing such explanations) and the planner's experiences in interacting with the environment. Our approach has been implemented in EXPO, a system that uses prodigy as a baseline planner and improves its domain knowledge in several domains. The empirical results presented show that EXPO's heuristics dramatically reduce the number of experiments needed to refine incomplete operators. 
Abstract-found: 1
Intro-found: 1
Reference: [ Carbonell and Gil, 1990 ] <author> Jaime G. Carbonell and Yolanda Gil. </author> <title> Learning by experimentation: The operator refinement method. </title> <editor> In Y. Kodratoff and R. S. Michalski, editors, </editor> <booktitle> Machine Learning, An Artificial Intelligence Approach, Volume III. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: EXPO learns new preconditions through the Operator Refinement Method <ref> [ Carbonell and Gil, 1990 ] </ref> , that we summarize here briefly. Suppose that the system has build a plan to grind a part to make its length smaller. Before grinding the part, the system checks that the preconditions are true in the external world.
Reference: [ Carbonell et al., 1990 ] <author> J. G. Carbonell, Y. Gil, R. L. Joseph, C. A. Knoblock, S. Minton, and M. M. Veloso. </author> <title> Designing an integrated architecture: The prodigy view. </title> <booktitle> In Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: The paper also shows the performance of these heuristics in their implementation in EXPO, a learning by experimentation capability within the prodigy system <ref> [ Carbonell et al., 1990 ] </ref> that improves the planner's knowledge in several domains. We begin with a brief description of our previous work. 2 Learning by Experimentation Suppose that a planner is given a process planning domain with the incomplete operator shown in Figure 1.
Reference: [ Gil, 1991 ] <author> Yolanda Gil. </author> <title> A domain-independent framework for effective experimentation in planning. </title> <booktitle> In Proceedings of the Eight International Workshop on Machine Leaning, </booktitle> <address> Evanston, IL, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This section briefly describes these heuristics, summarized in Table 1. Their implementation in EXPO follows. For more details see <ref> [ Gil, 1991, Gil, 1992 ] </ref> . One heuristic is locality of actions. The idea behind it is the following. The fact that there is a steel part lying somewhere else in the machine shop is not likely to affect our grinding operation.
Reference: [ Gil, 1992 ] <author> Yolanda Gil. </author> <title> Acquiring Domain Knowledge for Planning by Experimentation. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: This may be because the known effect that specifies the new surface finish is wrong, or because the operator is missing a necessary precondition. This method addresses the failure by considering the latter possibility as the working hypothesis first (see <ref> [ Gil, 1992 ] </ref> for a discussion on the first possibility): that some unknown precondition is not true in the state and thus the grinding action is not working as the given operator specifies. <p> Among the things that were true in that state, which may be many, is the fact that the grinder had fluid when the operation worked in the past 1 . Experimentation 1 For a discussion on the case when the missing condition is not present, see <ref> [ Gil, 1992 ] </ref> . 2 heuristic description locality of actions objects affected by the action are likely to be present in the operator's parameters structural similarity similar operators are likely to have similar preconditions generalization of experience necessary conditions have been present in all past successful executions of the action <p> for simplicity consider the following subset: (size-of &lt;part&gt; WIDTH 3) (size-of &lt;part&gt; LENGTH 7) (size-of &lt;part&gt; HEIGHT 2.5) (material-of &lt;part&gt; BRASS) (has-fluid &lt;machine&gt;) (surface-finish part26 &lt;side&gt; SAWCUT) (holding drill1 vise2 part26 &lt;side&gt;) (material-of part26 STEEL) (is-a drill1 DRILL) (is-a drill-bit1 DRILL-BIT) (material-of part37 COPPER) (has-hole part37 &lt;side&gt;) As described in <ref> [ Gil, 1992 ] </ref> , it is important to minimize the number of experiments and their requirements. For each experiment the planner has to build a plan to set the environment in a state that satisfies that many predicates. <p> This section briefly describes these heuristics, summarized in Table 1. Their implementation in EXPO follows. For more details see <ref> [ Gil, 1991, Gil, 1992 ] </ref> . One heuristic is locality of actions. The idea behind it is the following. The fact that there is a steel part lying somewhere else in the machine shop is not likely to affect our grinding operation. <p> This new subset of the hypotheses is then ranked by the heuristic of structural similarity as we explain now. All the domain operators are organized by EXPO in a hierarchy using a simple clustering algorithm <ref> [ Gil, 1992 ] </ref> . The root node contains all the operators in the hierarchy. For every node, the operators that are not in any of its children yet are examined to build a child node. <p> If this is not the case, then the missing condition may be something else, e.g., a disjunction of some of those conditions, a quantified expression over some predicate, or an unobserved fact (see <ref> [ Gil, 1992 ] </ref> for more details). EXPO does not learn these types of conditions. <p> The effectiveness of s improves as new knowledge is added to the domain. As we mentioned above, even though DC needs few experiments, the planner must achieve n 1 additional goals for each failure (see <ref> [ Gil, 1992 ] </ref> for more details). <p> The details of this simulation are described in <ref> [ Gil, 1992 ] </ref> . 6 necessary with all the combinations of the three hypotheses-selection heuristics: generalization of experience (g), locality (l), and structural similarity (s). The number of experiments needed is greatly reduced when the three of them are used.
Reference: [ Hammond, 1986 ] <author> Chris J. Hammond. </author> <title> Case-based Planning: An Integrated Theory of Planning, Learning, and Memory. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CN, </address> <year> 1986. </year>
Reference-contexts: Others have tried to reduce or eliminate the need for experimentation by relying on causal theories or other types of background knowledge to build explanations for the failures that determine what is to be learned <ref> [ Rajamoney, 1988, Kedar et al., 1991, Hammond, 1986 ] </ref> . Learning only seems feasible when detailed knowledge of the domain at hand is available. The central issue of the acquisition and refinement of additional and necessarily complex background knowledge is still far from resolved.
Reference: [ Hume and Sammut, 1991 ] <author> David Hume and Claude Sammut. </author> <title> Using inverse resolution to learn relations from experiments. </title> <booktitle> In Proceedings of the Eighth Machine Learning Workshop, </booktitle> <address> Evanston, IL, </address> <year> 1991. </year>
Reference-contexts: Experimentation is a powerful tool for gathering additional information from the environment that helps determine the appropriate correction. Previous work on learning from the environment has not addressed the issue of how to choose good hypotheses for efficient experimentation <ref> [ Shen, 1989, Hume and Sammut, 1991 ] </ref> .
Reference: [ Kedar et al., 1991 ] <author> Smadar T. Kedar, John L. Bresina, and C. Lisa Dent. </author> <title> The blind leading the blind: Mutual refinement of approximate theories. </title> <booktitle> In Proceedings of the Eight Machine Learning Workshop, </booktitle> <address> Evanston, IL, </address> <year> 1991. </year> <month> 9 </month>
Reference-contexts: Others have tried to reduce or eliminate the need for experimentation by relying on causal theories or other types of background knowledge to build explanations for the failures that determine what is to be learned <ref> [ Rajamoney, 1988, Kedar et al., 1991, Hammond, 1986 ] </ref> . Learning only seems feasible when detailed knowledge of the domain at hand is available. The central issue of the acquisition and refinement of additional and necessarily complex background knowledge is still far from resolved.
Reference: [ Langley et al., In press ] <author> Pat Langley, Ken Thompson, Wayne Iba, John H. Gennari, and John A. Allen. </author> <title> An integrated cognitive architecture for autonomous agents. </title> <editor> In Walter Van De Velde, editor, </editor> <booktitle> Representation and Learning in Autonomous Agents. </booktitle> <publisher> North Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <publisher> In press. </publisher>
Reference: [ Langley, 1987 ] <author> Pat Langley. </author> <title> A general theory of discrimination learning. In Production System Models of Learning and Development. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference: [ Mitchell et al., 1983 ] <author> Tom Mitchell, Paul Utgoff, and Ranan Banerji. </author> <title> Learning by experimentation: Acquiring and refining problem-solving heuristics. In Machine Learning, An Artificial Intelligence Approach, Volume I. </title> <publisher> Tioga Press, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference: [ Mitchell, 1978 ] <author> Tom M. Mitchell. </author> <title> Version Spaces: An Approach to Concept Learning. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <year> 1978. </year>
Reference-contexts: The situations are used to maintain the current description of each operator's preconditions as a version space <ref> [ Mitchell, 1978 ] </ref> . The algorithm is biased to produce conjunctive descriptions of the concept. This bias is appropriate for this application. The large majority of the precondition expressions in operators are conjunctions of predicates (or negations of predicates).
Reference: [ Rajamoney, 1988 ] <author> Shankar A. Rajamoney. </author> <title> Explanation-Based Theory Revision: An Approach to the Problems of Incomplete and Incorrect Theories. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, IL, </institution> <year> 1988. </year>
Reference-contexts: Others have tried to reduce or eliminate the need for experimentation by relying on causal theories or other types of background knowledge to build explanations for the failures that determine what is to be learned <ref> [ Rajamoney, 1988, Kedar et al., 1991, Hammond, 1986 ] </ref> . Learning only seems feasible when detailed knowledge of the domain at hand is available. The central issue of the acquisition and refinement of additional and necessarily complex background knowledge is still far from resolved.
Reference: [ Shen, 1989 ] <author> Wei-Min Shen. </author> <title> Learning from the Environment Based on Percepts and Actions. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1989. </year>
Reference-contexts: Experimentation is a powerful tool for gathering additional information from the environment that helps determine the appropriate correction. Previous work on learning from the environment has not addressed the issue of how to choose good hypotheses for efficient experimentation <ref> [ Shen, 1989, Hume and Sammut, 1991 ] </ref> .
References-found: 13

