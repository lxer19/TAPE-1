URL: http://data.cs.washington.edu/papers/ifflw_sigmod99.ps
Refering-URL: http://data.cs.washington.edu/integration/tukwila/
Root-URL: http://www.cs.washington.edu
Email: zives@cs.washington.edu  Daniela.Florescu@inria.fr  friedman@cs.washington.edu  alon@cs.washington.edu  weld@cs.washington.edu  
Title: An Adaptive Query Execution System for Data Integration  
Author: Zachary G. Ives Daniela Florescu Marc Friedman Alon Levy Daniel S. Weld 
Address: Washington  Washington  Washington  Washington  
Affiliation: University of  INRIA Roquencourt  University of  University of  University of  
Abstract: Query processing in data integration occurs over network-bound, autonomous data sources. This requires extensions to traditional optimization and execution techniques for three reasons: there is an absence of quality statistics about the data, data transfer rates are unpredictable and bursty, and slow or unavailable data sources can often be replaced by overlapping or mirrored sources. This paper presents the Tukwila data integration system, designed to support adaptivity at its core using a two-pronged approach. Interleaved planning and execution with partial optimization allows Tuk-wila to quickly recover from decisions based on inaccurate estimates. During execution, Tukwila uses adaptive query operators such as the double pipelined hash join, which produces answers quickly, and the dynamic collector, which robustly and efficiently computes unions across overlapping data sources. We demonstrate that the Tukwila architecture extends previous innovations in adaptive execution (such as query scrambling, mid-execution re-optimization, and choose nodes), and we present experimental evidence that our techniques result in behavior desirable for a data integration system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Adali, K. Candan, Y. Papakonstantinou, and V. Sub-rahmanian. </author> <title> Query caching and optimization in distributed mediator systems. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <address> Montreal, Canada, </address> <year> 1996. </year>
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems. <p> The Garlic system [13] optimizes over sources that can perform joins. The work on fusion queries [27] optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible. Systems such as TSIMMIS [10], the Information Manifold [17], Hermes <ref> [1] </ref>, and Razor [9] have focused on the query reformulation component. Our research complements these projects by providing a general query execution engine. 8 Conclusions This paper represents the first step in a larger research effort concerning query optimization and execution for data integration.
Reference: [2] <author> G. Antoshenkov and M. Ziauddin. </author> <title> Query processing and optmization in Oracle Rdb. </title> <journal> VLDB Journal, </journal> <volume> 5(4) </volume> <pages> 229-237, </pages> <year> 1996. </year>
Reference-contexts: Graefe and Ward's choose nodes allow the execution system to choose from a set of precompiled sub-plans based on runtime variables [12]. Oracle's Rdb <ref> [2] </ref> used a "dynamic optimization" strategy to deal with uncertainty by running alternative query plan subtrees in parallel competition. Although our query plans have a different structure, they can express similar choices over a set of fragments. Tukwila provides dynamic collectors to organize access to redundant and overlapping information sources.
Reference: [3] <author> Y. Arens, C. A. Knoblock, and W.-M. Shen. </author> <title> Query reformulation for dynamic information integration. </title> <journal> International Journal on Intelligent and Cooperative Information Systems, </journal> <volume> (6) </volume> 2/3:99-130, June 1996. 
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems.
Reference: [4] <author> J. A. Blakeley. </author> <title> Data access for the masses through OLE DB. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 161-172, </pages> <address> Montreal, Canada, </address> <year> 1996. </year>
Reference: [5] <author> L. Bouganim, O. Kapitskaia, and P. Valduriez. </author> <title> Memory-adaptive scheduling for large query execution. </title> <booktitle> In Seventh International Conference on Information and Knowledge Management, </booktitle> <address> Bethesda, MD, </address> <month> Nov. </month> <year> 1998. </year>
Reference-contexts: Each node in the tree is a physical operator specifying: (1) the algebraic operator at the node (e.g., selection, join), (2) the chosen physical implementation of the operator (e.g., hash join, double pipelined join), (3) the children of the node, (4) the memory allocated to the operator, as discussed in <ref> [5, 18] </ref>, and (5) an estimate of result cardinality. 3.1.2 Rules Rules are the key mechanism for implementing several kinds of adaptive behavior in Tukwila: * Re-optimization: At the end of a fragment, if the optimizer's cardinality estimate for the fragment's result is significantly different from the actual size, the optimizer <p> Tukwila is the first data integration system to incorporate these techniques into a query processor. Other researchers have investigated double pipelined joins (e.g., [14, 24]), but in the context of parallel database systems as opposed to data integration. Bouganim et al. <ref> [5] </ref> consider adaptive scheduling techniques aimed at large queries, and Nag and DeWitt [18] investigate memory allocation strategies in the context of decision support queries. The data integration context provides performance challenges unfamiliar in database systems.
Reference: [6] <author> W. Cohen. </author> <title> Integration of heterogeneous databases without common domains using queries based on textual similarity. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <address> Seattle, WA, </address> <year> 1998. </year>
Reference: [7] <author> C. Evrendilek, A. Dogac, S. Nural, and F. Ozcan. </author> <title> Mul-tidatabase query optimization. </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 5(1) </volume> <pages> 77-114, </pages> <year> 1997. </year>
Reference-contexts: If the optimizer concludes that it does not have enough metadata with which to reliably compare candidate query execution plans, it may choose to send only a partial plan to the execution engine, and decide how to proceed after the partial plan has been completed, as in <ref> [7] </ref>.
Reference: [8] <author> D. Florescu, D. Koller, and A. Levy. </author> <title> Using probabilistic information in data integration. </title> <booktitle> In Proc. of the Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <pages> pages 216-225, </pages> <address> Athens, Greece, </address> <year> 1997. </year>
Reference-contexts: Second is overlap information about pairs of data sources (that is, the probability that a data value d appears in source S 1 if d is known to appear in source S 2 ) for use by collector operators, as in <ref> [8] </ref>. In the extreme case, overlap information can indicate that two sites are mirrors of each other. Finally, the catalog may contain key statistics about the data, such as the cost of accessing each source, the sizes of the relations in the sources, and selectivity information. <p> In this section, we highlight Tukwila's adaptive operators: the dynamic collector and the double pipelined join operator. 4.1 Dynamic collectors A common task in data integration is to perform a union over a large number of overlapping sources <ref> [27, 8] </ref>. Common examples of such sources include those providing bibliographic references, movie reviews and product information. In some cases different sites are deliberately created as mirrors. For these reasons, the Tukwila query reformulator will output queries using disjunction at the leaves. <p> discussion we assume that exploiting additional capabilities of the wrappers is done within the refor-mulator, and hence Tukwila submits atomic fetch queries to the wrappers. the order in which data sources should be accessed, and potential fallback sources to use when a particular source is unavailable or slow (as in <ref> [8] </ref>). This guidance is given in the form of a policy. The query execution engine implements the policy by contacting data sources in parallel, monitoring the state of each connection, and adding or dropping connections as required by error and latency conditions. <p> Tukwila provides dynamic collectors to organize access to redundant and overlapping information sources. Local completeness reasoning [9] can be used to generate policies for collectors when there are covering relationships between the sources. Probabilistic reasoning can be used whenever there is partial overlap, and completeness is not required <ref> [8] </ref>. Tukwila is the first data integration system to incorporate these techniques into a query processor. Other researchers have investigated double pipelined joins (e.g., [14, 24]), but in the context of parallel database systems as opposed to data integration.
Reference: [9] <author> M. Friedman and D. Weld. </author> <title> Efficient execution of information gathering plans. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <address> Nagoya, Japan, </address> <year> 1997. </year>
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems. <p> Although our query plans have a different structure, they can express similar choices over a set of fragments. Tukwila provides dynamic collectors to organize access to redundant and overlapping information sources. Local completeness reasoning <ref> [9] </ref> can be used to generate policies for collectors when there are covering relationships between the sources. Probabilistic reasoning can be used whenever there is partial overlap, and completeness is not required [8]. Tukwila is the first data integration system to incorporate these techniques into a query processor. <p> The Garlic system [13] optimizes over sources that can perform joins. The work on fusion queries [27] optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible. Systems such as TSIMMIS [10], the Information Manifold [17], Hermes [1], and Razor <ref> [9] </ref> have focused on the query reformulation component. Our research complements these projects by providing a general query execution engine. 8 Conclusions This paper represents the first step in a larger research effort concerning query optimization and execution for data integration.
Reference: [10] <author> H. Garcia-Molina, Y. Papakonstantinou, D. Quass, A. Rajaraman, Y. Sagiv, J. Ullman, and J. Widom. </author> <title> The TSIMMIS project: Integration of heterogeneous information sources. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 8(2) </volume> <pages> 117-132, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems. <p> The Garlic system [13] optimizes over sources that can perform joins. The work on fusion queries [27] optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible. Systems such as TSIMMIS <ref> [10] </ref>, the Information Manifold [17], Hermes [1], and Razor [9] have focused on the query reformulation component. Our research complements these projects by providing a general query execution engine. 8 Conclusions This paper represents the first step in a larger research effort concerning query optimization and execution for data integration.
Reference: [11] <author> G. Graefe. </author> <title> Query evaluation techniques for large databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The system takes a query execution plan from the optimizer and sends its rules to the event handler (Section 3.3). Then each plan fragment is processed in turn, as a single, pipelined execution unit. The operator tree is executed using the top-down "iterator" model <ref> [11] </ref>. (Note that our implementation of the double pipelined join is an iterator-based adaptation, as described in Section 4.2). Control flows from the root node and makes its way down the tree. <p> Then one tuple at a time is read from the outer relation and is used to probe the hash table; all matching tuples will be joined with the current tuple and returned <ref> [11] </ref>. If the entire inner relation fits into memory, hash join requires only as many I/O operations as are required to load both relations. If the inner relation is too large, however, the data must be partitioned into smaller units that are small enough to fit into memory. <p> The outer relation is then read and partitioned along the same boundaries. Now the hash join procedure is recursively performed on matching pairs of overflow files. Hybrid hashing <ref> [11] </ref> uses a similar mechanism, but takes a "lazy" approach to creating overflow files: each time the operation runs out of memory, only a subset of the hash buckets are written to disk. After the entire inner relation is scanned, some buckets will probably remain in memory.
Reference: [12] <author> G. Graefe and R. Cole. </author> <title> Optimization of dynamic query evaluation plans. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <address> Minneapolis, MN, </address> <year> 1994. </year>
Reference-contexts: This is particularly true since a query optimizer is unlikely to produce good plans from bad metadata, and even a plan that may be good on average should be abandoned if unexpected situations arise. While runtime adaptivity has been shown to speed up performance even in traditional systems <ref> [15, 12] </ref>, it becomes critical to performance in the data integration context (e.g., [22]). 1.2 Adaptive Features of Tukwila This paper describes the Tukwila 1 data integration system, designed with adaptivity built into its core. <p> In addition, the Tukwila execution engine includes a collector operator whose task is to efficiently union data from a large set of possibly overlapping or redundant sources. Finally, Tukwila query execution plans can contain conditional nodes in the spirit of <ref> [12] </ref> in order to adapt to conditions that can be anticipated at optimization time. Adaptive behavior in Tukwila is coordinated in a uniform fashion by a set of event-condition-action rules. <p> the fragment's result is significantly different from the actual size, the optimizer will be reinvoked (in the same spirit as [15]). * Contingent planning: At the end of a fragment the execution engine can check properties of the result in order to select the next fragment (thus implementing choose nodes <ref> [12] </ref>). * Adaptive operators: The policy for memory over flow resolution in the double pipelined join (Section 4.2) is guided by a rule. <p> Graefe and Ward's choose nodes allow the execution system to choose from a set of precompiled sub-plans based on runtime variables <ref> [12] </ref>. Oracle's Rdb [2] used a "dynamic optimization" strategy to deal with uncertainty by running alternative query plan subtrees in parallel competition. Although our query plans have a different structure, they can express similar choices over a set of fragments. <p> The key contribution is that adaptivity is designed into its core to facilitate interleaving of planning and execution. Furthermore, Tuk-wila provides a platform for incorporating hybrid optimization [19, p181] and important query optimization techniques that have been developed previously in isolation (e.g., query scrambling [22], choose nodes <ref> [12] </ref>, runtime re-optimization [15], optimization of fusion queries [27]). * We describe the design and implementation of query operators that are especially suited for adaptive behavior | the double pipelined join and the dynamic collector.
Reference: [13] <author> L. Haas, D. Kossmann, E. Wimmers, and J. Yang. </author> <title> Optimizing queries across diverse data sources. </title> <booktitle> In Proc. of the Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <address> Athens, Greece, </address> <year> 1997. </year>
Reference-contexts: Our framework incorporates their adaptive algorithms. Data integration also involves extending the query-answering problem to handle sources with varying capabilities. In contrast to our paper, much of this work has focused on either query optimization or query reformulation. The Garlic system <ref> [13] </ref> optimizes over sources that can perform joins. The work on fusion queries [27] optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible.
Reference: [14] <author> W. Hong and M. Stonebraker. </author> <title> Optimization of parallel query execution plans in XPRS. </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 1(1) </volume> <pages> 9-32, </pages> <year> 1993. </year>
Reference-contexts: The global rules encode conditional execution policies, such as choosing among a set of alternative fragments after one completes. Fragments unrelated in the partial order may execute in parallel. For example, we may execute one CPU-bound fragment in parallel with other network-bound fragments as in <ref> [14] </ref>. 3.1.1 Fragments and Operators A fragment consists of a fully pipelined tree of physical operators, and a set of local rules. <p> Probabilistic reasoning can be used whenever there is partial overlap, and completeness is not required [8]. Tukwila is the first data integration system to incorporate these techniques into a query processor. Other researchers have investigated double pipelined joins (e.g., <ref> [14, 24] </ref>), but in the context of parallel database systems as opposed to data integration. Bouganim et al. [5] consider adaptive scheduling techniques aimed at large queries, and Nag and DeWitt [18] investigate memory allocation strategies in the context of decision support queries.
Reference: [15] <author> N. Kabra and D. J. DeWitt. </author> <title> Efficient mid-query re-optimization of sub-optimal query execution plans. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 106-117, </pages> <address> Seattle, WA, </address> <year> 1998. </year>
Reference-contexts: This is particularly true since a query optimizer is unlikely to produce good plans from bad metadata, and even a plan that may be good on average should be abandoned if unexpected situations arise. While runtime adaptivity has been shown to speed up performance even in traditional systems <ref> [15, 12] </ref>, it becomes critical to performance in the data integration context (e.g., [22]). 1.2 Adaptive Features of Tukwila This paper describes the Tukwila 1 data integration system, designed with adaptivity built into its core. <p> Should that time out as well, the optimizer is called with that information to produce a plan reordered to use the non-blocked sources first. * Re-optimization: After the AB join completes and materializes, Tukwila compares the actual cardinality with the optimizer's estimate. As in <ref> [15] </ref>, if this value significantly differs from the optimizer's estimate, the optimizer is awakened to find a cheaper plan (perhaps the one in Figure 1c) given more accurate information. The paper is organized as follows. Section 2 provides an overview of the architecture of Tukwila. <p> 3.1.2 Rules Rules are the key mechanism for implementing several kinds of adaptive behavior in Tukwila: * Re-optimization: At the end of a fragment, if the optimizer's cardinality estimate for the fragment's result is significantly different from the actual size, the optimizer will be reinvoked (in the same spirit as <ref> [15] </ref>). * Contingent planning: At the end of a fragment the execution engine can check properties of the result in order to select the next fragment (thus implementing choose nodes [12]). * Adaptive operators: The policy for memory over flow resolution in the double pipelined join (Section 4.2) is guided by <p> However, their approach was largely eclipsed by less flexible System-R style optimiz-ers. Only recently have Kabra and DeWitt demonstrated the utility of runtime re-optimization for conventional database queries using a System-R style optimizer <ref> [15] </ref>. The Tukwila rule mechanism enables re-optimization as in [15] with two important advantages: (1) we do not necessarily create complete plans in advance, and (2) our optimizer was built to support efficient re-optimization while [15] used the standard Paradise optimizer. <p> However, their approach was largely eclipsed by less flexible System-R style optimiz-ers. Only recently have Kabra and DeWitt demonstrated the utility of runtime re-optimization for conventional database queries using a System-R style optimizer <ref> [15] </ref>. The Tukwila rule mechanism enables re-optimization as in [15] with two important advantages: (1) we do not necessarily create complete plans in advance, and (2) our optimizer was built to support efficient re-optimization while [15] used the standard Paradise optimizer. <p> demonstrated the utility of runtime re-optimization for conventional database queries using a System-R style optimizer <ref> [15] </ref>. The Tukwila rule mechanism enables re-optimization as in [15] with two important advantages: (1) we do not necessarily create complete plans in advance, and (2) our optimizer was built to support efficient re-optimization while [15] used the standard Paradise optimizer. Graefe and Ward's choose nodes allow the execution system to choose from a set of precompiled sub-plans based on runtime variables [12]. Oracle's Rdb [2] used a "dynamic optimization" strategy to deal with uncertainty by running alternative query plan subtrees in parallel competition. <p> Furthermore, Tuk-wila provides a platform for incorporating hybrid optimization [19, p181] and important query optimization techniques that have been developed previously in isolation (e.g., query scrambling [22], choose nodes [12], runtime re-optimization <ref> [15] </ref>, optimization of fusion queries [27]). * We describe the design and implementation of query operators that are especially suited for adaptive behavior | the double pipelined join and the dynamic collector.
Reference: [16] <author> N. Kushmerick, R. Doorenbos, and D. Weld. </author> <title> Wrapper induction for information extraction. </title> <booktitle> In Proceedings of the 15th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1997. </year>
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems.
Reference: [17] <author> A. Y. Levy, A. Rajaraman, and J. J. Ordille. </author> <title> Querying heterogeneous information sources using source descriptions. </title> <booktitle> In Proc. of the Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <address> Bombay, India, </address> <year> 1996. </year>
Reference-contexts: While the problems of reformulation and rapid wrapper development have been the focus of previous work (e.g., <ref> [10, 17, 1, 9, 16, 3] </ref>), relatively little attention has been given to the development of query optimization algorithms and efficient query execution engines for data integration systems. <p> Query reformulation: The query over the mediated schema is fed into the Tukwila query reformulation component, which is based on an enhanced version of the algorithm described in <ref> [17] </ref>. In general, a query refor-mulator converts the user's query into a union of conjunctive queries referring to the data source schemata. This paper focuses on a limited form in which we have a single query that may include disjunction at the leaves. <p> The Garlic system [13] optimizes over sources that can perform joins. The work on fusion queries [27] optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible. Systems such as TSIMMIS [10], the Information Manifold <ref> [17] </ref>, Hermes [1], and Razor [9] have focused on the query reformulation component. Our research complements these projects by providing a general query execution engine. 8 Conclusions This paper represents the first step in a larger research effort concerning query optimization and execution for data integration.
Reference: [18] <author> B. Nag and D. J. DeWitt. </author> <title> Memory allocation strategies for complex decision support queries. </title> <booktitle> In Seventh International Conference on Information and Knowledge Management, </booktitle> <address> Bethesda, MD, </address> <month> Nov. </month> <year> 1998. </year>
Reference-contexts: Each node in the tree is a physical operator specifying: (1) the algebraic operator at the node (e.g., selection, join), (2) the chosen physical implementation of the operator (e.g., hash join, double pipelined join), (3) the children of the node, (4) the memory allocated to the operator, as discussed in <ref> [5, 18] </ref>, and (5) an estimate of result cardinality. 3.1.2 Rules Rules are the key mechanism for implementing several kinds of adaptive behavior in Tukwila: * Re-optimization: At the end of a fragment, if the optimizer's cardinality estimate for the fragment's result is significantly different from the actual size, the optimizer <p> Other researchers have investigated double pipelined joins (e.g., [14, 24]), but in the context of parallel database systems as opposed to data integration. Bouganim et al. [5] consider adaptive scheduling techniques aimed at large queries, and Nag and DeWitt <ref> [18] </ref> investigate memory allocation strategies in the context of decision support queries. The data integration context provides performance challenges unfamiliar in database systems. Urhan et al. explored replanning and rescheduling options for dealing with long source transmission delays [22] that may occur when sources are remotely located and autonomous.
Reference: [19] <author> M. T. Ozsu and P. Valduriez. </author> <title> Principles of Distributed Database Systems. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Engle-wood Cliffs, NJ, 2nd edition, </address> <year> 1999. </year>
Reference-contexts: In particular, we make the following contributions: * We describe the architecture of the implemented Tuk-wila query processor. The key contribution is that adaptivity is designed into its core to facilitate interleaving of planning and execution. Furthermore, Tuk-wila provides a platform for incorporating hybrid optimization <ref> [19, p181] </ref> and important query optimization techniques that have been developed previously in isolation (e.g., query scrambling [22], choose nodes [12], runtime re-optimization [15], optimization of fusion queries [27]). * We describe the design and implementation of query operators that are especially suited for adaptive behavior | the double pipelined join
Reference: [20] <author> M. Stonebraker, P. M. Aoki, W. Litwin, A. Pfeffer, A. Sah, J. Sidell, C. Staelin, and A. Yu. Mariposa: </author> <title> A wide-area distributed database system. </title> <journal> VLDB Journal, </journal> <volume> 5(1) </volume> <pages> 48-63, </pages> <year> 1996. </year>
Reference: [21] <author> A. Tomasic, L. Raschid, and P. Valduriez. </author> <title> Scaling access to distributed heterogeneous data sources with Disco. </title> <journal> IEEE Transactions On Knowledge and Data Engineering, </journal> <year> 1998. </year>
Reference: [22] <author> T. Urhan, M. J. Franklin, and L. Amsaleg. </author> <title> Cost based query scrambling for initial delays. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 130-141, </pages> <address> Seattle, WA, </address> <year> 1998. </year>
Reference-contexts: Hence, even if the query optimizer is able to determine the best plan based on total work, the data arrival characteristics may cause it to be inefficient in practice <ref> [22] </ref>. * Overlap and redundancy among sources: as a result of the heterogeneity of the data sources, there is often significant overlap or redundancy among them. <p> While runtime adaptivity has been shown to speed up performance even in traditional systems [15, 12], it becomes critical to performance in the data integration context (e.g., <ref> [22] </ref>). 1.2 Adaptive Features of Tukwila This paper describes the Tukwila 1 data integration system, designed with adaptivity built into its core. <p> Should some sources respond slowly, however, Tukwila can reschedule as with query scrambling <ref> [22] </ref>. If the connection to data source A times out, join DE will be executed preemptively. <p> Collectors (Section 4.1) are also implemented using rules. * Rescheduling: Rules are used for specifying when a plan should be rescheduled if a source times out (as in query scrambling <ref> [22] </ref>). Tukwila rules have the form when event if condition then actions. <p> The data integration context provides performance challenges unfamiliar in database systems. Urhan et al. explored replanning and rescheduling options for dealing with long source transmission delays <ref> [22] </ref> that may occur when sources are remotely located and autonomous. Our framework incorporates their adaptive algorithms. Data integration also involves extending the query-answering problem to handle sources with varying capabilities. In contrast to our paper, much of this work has focused on either query optimization or query reformulation. <p> The key contribution is that adaptivity is designed into its core to facilitate interleaving of planning and execution. Furthermore, Tuk-wila provides a platform for incorporating hybrid optimization [19, p181] and important query optimization techniques that have been developed previously in isolation (e.g., query scrambling <ref> [22] </ref>, choose nodes [12], runtime re-optimization [15], optimization of fusion queries [27]). * We describe the design and implementation of query operators that are especially suited for adaptive behavior | the double pipelined join and the dynamic collector.
Reference: [23] <author> S. Venkataraman and T. Zhang. </author> <title> Heterogeneous database query optimization in DB2 Universal DataJoiner. </title> <booktitle> In Proc. of the Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <pages> pages 685-689, </pages> <month> Aug. </month> <year> 1998. </year>
Reference-contexts: The problem of data integration has received significant attention in the research community as evidenced by numerous research projects (e.g., [10, 20, 25, 17, 9, 3, 6, 1, 25, 21, 4, 13]) and the emergence of several commercial products (e.g., DataJoiner <ref> [23] </ref> and jango.excite.com). Three main challenges distinguish the design of a data integration system from that of a traditional database system: query reformulation, the construction of wrapper programs, and the design of new query processing techniques for this more unpredictable environment.
Reference: [24] <author> A. N. Wilschut and P. M. G. Apers. </author> <title> Dataflow query execution in a parallel main-memory environment. </title> <booktitle> In Proc. of the Int. Conf. on Parallel and Distributed Information Systems (PDIS), </booktitle> <pages> pages 68-77, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Specifically, it employs an enhanced version of the double pipelined hash join <ref> [24] </ref> (a join implementation which executes in a symmetric, data-driven manner) and techniques for adapting its execution when there is insufficient memory. In addition, the Tukwila execution engine includes a collector operator whose task is to efficiently union data from a large set of possibly overlapping or redundant sources. <p> Likewise, for the hash join, we must load the entire inner relation into a hash table before we can pipeline. We now contrast these models with the double pipelined join (also known as the pipelined hash join), which was originally proposed in <ref> [24] </ref> for parallel database systems. 4.2.1 Conventional Hash Join As was previously mentioned, in a standard hash join, the database system creates a hash table from the inner relation, keyed by the join attributes of the operation. <p> Probabilistic reasoning can be used whenever there is partial overlap, and completeness is not required [8]. Tukwila is the first data integration system to incorporate these techniques into a query processor. Other researchers have investigated double pipelined joins (e.g., <ref> [14, 24] </ref>), but in the context of parallel database systems as opposed to data integration. Bouganim et al. [5] consider adaptive scheduling techniques aimed at large queries, and Nag and DeWitt [18] investigate memory allocation strategies in the context of decision support queries.
Reference: [25] <author> D. Woelk, B. Bohrer, N. Jacobs, K. Ong, C. Tomlinson, and C. Unnikrishnan. </author> <title> Carnot and InfoSleuth: Database technology and the world wide web. </title> <booktitle> In Proc. of ACM SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 443-444, </pages> <address> San Jose, CA, </address> <year> 1995. </year>
Reference: [26] <author> E. Wong and K. Youssefi. </author> <title> Decomposition: A strategy for query processing. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 1(3):223, </volume> <year> 1976. </year>
Reference-contexts: In separate experiments (not shown) we compare re-optimization using saved state without usage pointers and the resulting performance is worse than replanning from scratch. 7 Related work The INGRES query optimization algorithm originally interleaved steps of constructing a query execution plan and executing it <ref> [26] </ref>. However, their approach was largely eclipsed by less flexible System-R style optimiz-ers. Only recently have Kabra and DeWitt demonstrated the utility of runtime re-optimization for conventional database queries using a System-R style optimizer [15].
Reference: [27] <author> R. Yerneni, Y. Papakonstantinou, S. Abiteboul, and H. Garcia-Molina. </author> <title> Fusion queries over internet databases. </title> <booktitle> In Proc. of the Conf. on Extending Database Technology (EDBT), </booktitle> <pages> pages 57-71, </pages> <address> Valencia, Spain, </address> <year> 1998. </year>
Reference-contexts: In this section, we highlight Tukwila's adaptive operators: the dynamic collector and the double pipelined join operator. 4.1 Dynamic collectors A common task in data integration is to perform a union over a large number of overlapping sources <ref> [27, 8] </ref>. Common examples of such sources include those providing bibliographic references, movie reviews and product information. In some cases different sites are deliberately created as mirrors. For these reasons, the Tukwila query reformulator will output queries using disjunction at the leaves. <p> Data integration also involves extending the query-answering problem to handle sources with varying capabilities. In contrast to our paper, much of this work has focused on either query optimization or query reformulation. The Garlic system [13] optimizes over sources that can perform joins. The work on fusion queries <ref> [27] </ref> optimizes queries for data that occur in multiple sources, while utilizing semijoins at the sources if possible. Systems such as TSIMMIS [10], the Information Manifold [17], Hermes [1], and Razor [9] have focused on the query reformulation component. <p> Furthermore, Tuk-wila provides a platform for incorporating hybrid optimization [19, p181] and important query optimization techniques that have been developed previously in isolation (e.g., query scrambling [22], choose nodes [12], runtime re-optimization [15], optimization of fusion queries <ref> [27] </ref>). * We describe the design and implementation of query operators that are especially suited for adaptive behavior | the double pipelined join and the dynamic collector.
References-found: 27

