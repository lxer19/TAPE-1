URL: http://www.eecs.umich.edu/~qstout/pap/JPDC90.ps.Z
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.eecs.umich.edu
Title: Intensive Hypercube Communication: Prearranged Communication in Link-Bound Machines 1 2  
Author: Quentin F. Stout and Bruce Wagar 
Date: September 7, 1988  
Address: Ann Arbor, MI 48109-2122 USA  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan  
Note: In J. of Parallel and Distributed Computing 10 (1990), pp. 167-181.  
Abstract: 1 A preliminary condensed version of this paper appeared as "Passing messages in link-bound hypercubes", Hypercube Mutiprocessors 1987, M. Heath, ed., pp. 251-257. 2 This research was partially supported by National Science Foundation grant DCR-8507851 and an Incentives for Excellence award from Digital Equipment Corp. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Baru, C. K., and Frieder, O. </author> <title> Implementing relational database operations in a cube-connected multicomputer system. </title> <booktitle> Proc. 3rd Int'l. Conf. on Data Engineering, </booktitle> <year> 1987. </year>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [2] <author> Cybenko, G. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <institution> Tufts Univ. Dept. of Computer Science Tech. </institution> <type> Report 87-1, </type> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [3] <author> Gustafson, J. L., Hawkinson, S., and Scott, K. </author> <title> The architecture of a homogeneous vector supercomputer. </title> <booktitle> Proc. 1986 Int'l. Conf. on Parallel Proc., IEEE, </booktitle> <year> 1986, </year> <pages> pp. 649-652. </pages>
Reference-contexts: While no hypercube can currently use all of its communication links simultaneously, several manufacturers are trying to attain such ability. The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time <ref> [3] </ref>.
Reference: [4] <author> Hayes, J., Mudge,T., Stout, Q. F., Coley, S., and Palmer, J. </author> <title> A microprocessor-based hypercube supercomputer. </title> <booktitle> IEEE Micro 6 (1986), </booktitle> <pages> pp. 6-17. </pages>
Reference-contexts: While no hypercube can currently use all of its communication links simultaneously, several manufacturers are trying to attain such ability. The NCUBE machines apparently come the closest <ref> [4] </ref>, and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3].
Reference: [5] <author> Ho, C.-T., and Johnsson, S. L. </author> <title> Distributed routing algorithms for broadcasting and personalized communications in hypercubes. </title> <booktitle> Proc. 1986 Int'l. Conf. on Parallel Proc., IEEE, </booktitle> <year> 1986, </year> <pages> pp. 640-648. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Also note that the total internal I/O bandwidth of the computer is 2 d do . In general, o and fi are treated as constants and the algorithms are analyzed as functions of d and m. As in <ref> [5, 6, 7, 8, 11] </ref>, we ignore the effects of rounding or truncating. Furthermore, because special cases arise for various relative values of the parameters, the exact formulas will be given only for m sufficiently large. <p> Because we are most interested in processing long messages, the term containing the highest power of m will be called the highest-order term. Some of the problems studied in this paper, such as broadcasting a message from one node to all others, have been previously considered by <ref> [5, 9, 11] </ref>. These papers use a similar model to the link-bound model, but give slightly slower algorithms. <p> This problem has been previously examined in <ref> [5, 11] </ref>, but our algorithms are somewhat faster. It is interesting to note that the NCUBE machine has special hardware instructions to allow a node to simultaneously broadcast to all of its neighbors, though the current operating system does not make use of these instructions. <p> shown that this time is minimized when g = &gt; &gt; &lt; 1 d = 1 (d1)o m 1=2 d 2 which produces a final time of 8 &gt; &gt; : o m + 2 (d1)fio m 1=2 + (d1)fi d 2 For purposes of comparison, the best broadcast in <ref> [5] </ref> has a running time of o m + 2 fio m 1=2 + dfi: One last observation. BROADCAST 4 is absolutely optimal if all sends have to use fixed-size packets. To see this, suppose the packet size is s. <p> This operation has no standard name (it was referred to as "scatter" in [11] and "personalized communications" in <ref> [5] </ref>), so we will call it distributing. Its dual operation, collecting, where one node has to receive a message from each of the other nodes, is exactly the same operation, only run in reverse. Hence, it suffices to design and analyze distributing algorithms. <p> algorithm is d1 X " d d # " d1 X k o m + dfi (2 d 1)o m + dfi : The distribute algorithm in [11] had a time of (2 d 1)o m + dfi and <ref> [5] </ref>'s had a time strictly greater than ours. The time in [5] is dificult to represent, but has the property that for fixed d &gt; 1, the coefficient of m is strictly greater than (2 d 1)=d, but it tends to (2 d 1)=d as d approaches 1. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [6] <author> Ho, C.-T., and Johnsson, S. L. </author> <title> Algorithms for matrix transposition on boolean n-cube configured ensemble architectures, </title> <booktitle> Proc. 1987 Int'l. Conf. on Parallel Proc., IEEE, </booktitle> <year> 1987, </year> <pages> pp. 621-629. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Also note that the total internal I/O bandwidth of the computer is 2 d do . In general, o and fi are treated as constants and the algorithms are analyzed as functions of d and m. As in <ref> [5, 6, 7, 8, 11] </ref>, we ignore the effects of rounding or truncating. Furthermore, because special cases arise for various relative values of the parameters, the exact formulas will be given only for m sufficiently large. <p> Since the initial announcement of our results in [14] and the submission of this paper, additional papers have appeared which pursue the use of such techniques for matrix problems <ref> [6, 8, 9] </ref>. These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission. Though our algorithms are deterministic, this paper has ties to Valiant's work on randomized routing [12, 13]. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [7] <author> Ho, C.-T., and Johnsson, S. L. </author> <title> Optimal algorithms for stable dimension permutations on boolean cubes, </title> <booktitle> Proc. 3rd Conf. on Hypercube Concurrent Computers and Applic., ACM, </booktitle> <year> 1988, </year> <pages> pp. 725-736. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Also note that the total internal I/O bandwidth of the computer is 2 d do . In general, o and fi are treated as constants and the algorithms are analyzed as functions of d and m. As in <ref> [5, 6, 7, 8, 11] </ref>, we ignore the effects of rounding or truncating. Furthermore, because special cases arise for various relative values of the parameters, the exact formulas will be given only for m sufficiently large. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [8] <author> Ho, C.-T., and Johnsson, S. L. </author> <title> Expressing boolean cube matrix algorithms in shared memory primitives. </title> <booktitle> Proc. 3rd Conf. on Hypercube Concurrent Computers and Applic., ACM, </booktitle> <year> 1988, </year> <pages> pp. 1599-1609. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Also note that the total internal I/O bandwidth of the computer is 2 d do . In general, o and fi are treated as constants and the algorithms are analyzed as functions of d and m. As in <ref> [5, 6, 7, 8, 11] </ref>, we ignore the effects of rounding or truncating. Furthermore, because special cases arise for various relative values of the parameters, the exact formulas will be given only for m sufficiently large. <p> There are 2 d ! such permutations, so determining the most efficient algorithm for each one seems neither possible nor practical, though recently some papers have appeared ana lyzing specific permutations <ref> [8, 10] </ref>. For arbitrary permutatations, however, a deterministic 16 analogue of Valiant's randomized routing [12, 13] can be employed. It consists of two com-plete exchanges: one to disperse all the data evenly throughout the cube and another to collect it all up at the appropriate destinations. <p> Since the initial announcement of our results in [14] and the submission of this paper, additional papers have appeared which pursue the use of such techniques for matrix problems <ref> [6, 8, 9] </ref>. These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission. Though our algorithms are deterministic, this paper has ties to Valiant's work on randomized routing [12, 13]. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [9] <author> Johnsson, S. L. </author> <title> Communication efficient basic linear algebra computations on hypercube architectures. </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing 4 (1987), </booktitle> <pages> pp. 133-172. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Because we are most interested in processing long messages, the term containing the highest power of m will be called the highest-order term. Some of the problems studied in this paper, such as broadcasting a message from one node to all others, have been previously considered by <ref> [5, 9, 11] </ref>. These papers use a similar model to the link-bound model, but give slightly slower algorithms. <p> It has been previously considered in <ref> [9, 11] </ref>, but faster algorithms will be developed here. Suppose you want to transpose an N fi N matrix M stored in a d-dimensional hypercube, with each node containing N 2 =2 d entries. <p> This is approximately half of the o time required by <ref> [9] </ref>, where it is assumed that fi is zero. 8 Histogramming The same techniques used previously can be applied to the problem of histogramming. <p> Since the initial announcement of our results in [14] and the submission of this paper, additional papers have appeared which pursue the use of such techniques for matrix problems <ref> [6, 8, 9] </ref>. These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission. Though our algorithms are deterministic, this paper has ties to Valiant's work on randomized routing [12, 13]. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [10] <author> Livingston, M. and Stout, Q. F. </author> <title> Good permutations for hypercube communication, </title> <note> in preparation. </note>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> There are 2 d ! such permutations, so determining the most efficient algorithm for each one seems neither possible nor practical, though recently some papers have appeared ana lyzing specific permutations <ref> [8, 10] </ref>. For arbitrary permutatations, however, a deterministic 16 analogue of Valiant's randomized routing [12, 13] can be employed. It consists of two com-plete exchanges: one to disperse all the data evenly throughout the cube and another to collect it all up at the appropriate destinations. <p> might guess that all fixed-point free permutations require the same highest-order term. (If permutations with fixed points are considered, then the identity can be completed in zero time.) However, it has been shown that some fixed-point free permutations can be routed with a highest-order term smaller than that of reflection <ref> [10] </ref>, and therefore PERMUTED SEND is only worst-case optimal among fixed-point free permutations. Beyond the highest-order term, we believe that some of the algorithms herein are absolutely optimal. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [11] <author> Saad, Y. and Schultz, M. H. </author> <title> Data communications in hypercubes, </title> <institution> Yale Univ. Dept. of Computer Science Research Report YALEU/DCS/RR-428, </institution> <year> 1985. </year>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> Also note that the total internal I/O bandwidth of the computer is 2 d do . In general, o and fi are treated as constants and the algorithms are analyzed as functions of d and m. As in <ref> [5, 6, 7, 8, 11] </ref>, we ignore the effects of rounding or truncating. Furthermore, because special cases arise for various relative values of the parameters, the exact formulas will be given only for m sufficiently large. <p> Because we are most interested in processing long messages, the term containing the highest power of m will be called the highest-order term. Some of the problems studied in this paper, such as broadcasting a message from one node to all others, have been previously considered by <ref> [5, 9, 11] </ref>. These papers use a similar model to the link-bound model, but give slightly slower algorithms. <p> Some of the problems studied in this paper, such as broadcasting a message from one node to all others, have been previously considered by [5, 9, 11]. These papers use a similar model to the link-bound model, but give slightly slower algorithms. In particular, <ref> [11] </ref> considered a model where communication between nodes can only take place one direction at a time, so where this made a difference, the times of their algorithms have been divided by two so that they can be fairly compared with ours. <p> This problem has been previously examined in <ref> [5, 11] </ref>, but our algorithms are somewhat faster. It is interesting to note that the NCUBE machine has special hardware instructions to allow a node to simultaneously broadcast to all of its neighbors, though the current operating system does not make use of these instructions. <p> : o m + 2 (n+K n1 )fio m 1=2 + (n+1)fi 1 n 4 and n d1 d s d : This compares to the 8 &gt; &gt; &gt; &gt; &gt; : d s d o m + 2 (d1)fio m 1=2 + (d1)fi n = d needed by <ref> [11] </ref>. As was the case with O.C. SEND 4, ARBITRARY SEND 3 is only a slight improvement over broadcasting. <p> This operation has no standard name (it was referred to as "scatter" in <ref> [11] </ref> and "personalized communications" in [5]), so we will call it distributing. Its dual operation, collecting, where one node has to receive a message from each of the other nodes, is exactly the same operation, only run in reverse. Hence, it suffices to design and analyze distributing algorithms. <p> spent by node 0 during each stage is longer than nodes in any other C j , so the total time for the algorithm is d1 X " d d # " d1 X k o m + dfi (2 d 1)o m + dfi : The distribute algorithm in <ref> [11] </ref> had a time of (2 d 1)o m + dfi and [5]'s had a time strictly greater than ours. <p> Therefore, the time for the algorithm is d1 X 2 k m + fi = d For purposes of comparison, <ref> [11] </ref> produced an "optimal" complete broadcast (which they referred to as a "total exchange") with a running time of (2 d +d 2 )o m + dfi: The next operation to be completed will be the o.c. send. <p> In other words, it's the same thing as completing the distributing or collecting operations. The complete exchange turns out to be useful for matrix transpositions as well as random communication patterns (both to be discussed later). In <ref> [11] </ref>, complete exchange was called multigather/scatter. Algorithm: COMPLETE EXCHANGE Just complete DISTRIBUTE in the same manner that O.C. SEND 1 was completed to produce INVERSION. There are still d stages, numbered 0; 1; : : :; d1. <p> It has been previously considered in <ref> [9, 11] </ref>, but faster algorithms will be developed here. Suppose you want to transpose an N fi N matrix M stored in a d-dimensional hypercube, with each node containing N 2 =2 d entries. <p> In other words, a complete exchange has to be performed with a message length of N 2 =2 2d . This takes time 2 d1 o 2 2d + dfi = 2 d+1 N 2 + dfi ; as compared to do 17 needed by <ref> [11] </ref>. 7.2 Storage by Submatrices When stored as submatrices, it is convenient to assume that d is even, say d = 2c, and that N is evenly divisible by 2 c . <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [12] <author> Valiant, L. G. </author> <title> Experiments with a parallel communication scheme, </title> <booktitle> Proc. 18th Allerton Conf. on Communication, Control, and Computing, </booktitle> <year> 1980, </year> <pages> pp. 802-811. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> There are 2 d ! such permutations, so determining the most efficient algorithm for each one seems neither possible nor practical, though recently some papers have appeared ana lyzing specific permutations [8, 10]. For arbitrary permutatations, however, a deterministic 16 analogue of Valiant's randomized routing <ref> [12, 13] </ref> can be employed. It consists of two com-plete exchanges: one to disperse all the data evenly throughout the cube and another to collect it all up at the appropriate destinations. <p> These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission. Though our algorithms are deterministic, this paper has ties to Valiant's work on randomized routing <ref> [12, 13] </ref>. He showed that indivisible unit-length messages in a link-bound hypercube could be routed in fi (d) expected time, no matter what the permutation, by routing each message to a random intermediate destination and then on to its original destination. <p> For long divisible messages and a known permutation (so that header information need not be attached), PERMUTED SEND eliminates the random destination by sending a portion of the message to every processor. Further, in <ref> [12] </ref> he used four "bad" examples to empirically show the usefulness of randomization. One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [13] <author> Valiant, L. G. </author> <title> A scheme for parallel communication. </title> <journal> SIAM J. Computing 11 (1982), </journal> <pages> pp. 350-361. </pages>
Reference-contexts: The NCUBE machines apparently come the closest [4], and the FPS T-Series machines have nodes capable of 4 bi-directional communications at the same time [3]. The link-bound model has been studied in <ref> [1, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>. 1 j d = 0 i j 1 j 00 i j 10 i d = 2 i j 001 i j 011 i j 101 i j 111 1.3 Message-Passing Problems Throughout the paper, various hypercube communication patterns will be <p> There are 2 d ! such permutations, so determining the most efficient algorithm for each one seems neither possible nor practical, though recently some papers have appeared ana lyzing specific permutations [8, 10]. For arbitrary permutatations, however, a deterministic 16 analogue of Valiant's randomized routing <ref> [12, 13] </ref> can be employed. It consists of two com-plete exchanges: one to disperse all the data evenly throughout the cube and another to collect it all up at the appropriate destinations. <p> These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission. Though our algorithms are deterministic, this paper has ties to Valiant's work on randomized routing <ref> [12, 13] </ref>. He showed that indivisible unit-length messages in a link-bound hypercube could be routed in fi (d) expected time, no matter what the permutation, by routing each message to a random intermediate destination and then on to its original destination. <p> One of these is equivalent to matrix transposition for a matrix stored as submatrices, and the worst one was inversion. MATRIX TRANSPOSITION and INVERSION show that there are efficient deterministic routing schemes for these permutations. Finally, despite the intense interest in hypercube communication <ref> [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13] </ref>, still little is known about optimal hypercube performance on communication-intensive tasks such as sorting, routing, data balancing, database operations, and image warping.
Reference: [14] <author> Wagar, B., and Stout, Q. F. </author> <title> Passing messages in link-bound hypercubes. Hypercube Multiprocessors 1987, </title> <publisher> SIAM, </publisher> <pages> pp. 251-257. 24 </pages>
Reference-contexts: If a matrix is stored via submatrices, and the G function used in the assignment is either the identity or a reflexive Gray code, then rotation via quarter-turns or half-turns can be accomplished by algorithms closely related to MATRIX TRANSPOSITION. Since the initial announcement of our results in <ref> [14] </ref> and the submission of this paper, additional papers have appeared which pursue the use of such techniques for matrix problems [6, 8, 9]. These papers include experimental results on Intel and Thinking Machines hypercubes, showing that our techniques do indeed result in faster message transmission.
References-found: 14

