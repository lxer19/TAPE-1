URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R192.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: judea@cs.ucla.edu  
Title: A Calculus of Pragmatic Obligation  Content Areas: Commonsense Reasoning, Probabilistic Reasoning, Reasoning about Action  
Author: Judea Pearl 
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory University of California,  
Abstract: We present a qualitative, decision-theoretic account for statements of the form: "You ought to do A, if C". We show that adding a qualitative causal theory (in the form of a graph) as part of an epistemic state is sufficient to facilitate the analysis of action sequences, their consequences, their interaction with observations, their expected utilities and, hence, the assertability of conditional "ought" statements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adams, </author> <title> E.W., "Prior probabilities and counter-factual conditionals," </title> <editor> in W.L. Harper and C.A. Hooker (Eds.), </editor> <title> Foundations of Probability Theory, Statistical Inference, and Statistical Theories of Science, Volume I, </title> <address> D. </address> <publisher> Reidel, Dordrecht, Holland, </publisher> <pages> 1-21, </pages> <year> 1976. </year>
Reference-contexts: The bulb can be made to light by other means, e.g., by short-circuiting the switch.) Our account also explains (see Example 2) why the assertability of counterfactual conditionals is often dependent upon previous observations, a point noted by Adams <ref> [1] </ref> and explained by Skyrms [19] in terms of probabilities of propensities. Such propensities are now given a concrete embodiment in the form of the causal network .
Reference: [2] <author> Alchourron, C., Gardenfors, P., and Makinson, D., </author> <title> "On the logic of theory change: Partial meet contraction and revision functions," </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50, </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: It ignores subsequent ac 2 The difference between P (!j') and P ' (!) is precisely the difference between belief revision and belief update <ref> [2, 10, 8] </ref> and also accounts for the difference between indicative and subjunctive conditionals a topic of much philosophical discussion [9]. 3 tions which the agent might be able to take so as to change this probability.
Reference: [3] <author> Boutilier, C., </author> <title> "Conditional goals: The influence of knowledge and ability on obligations," </title> <note> submitted. </note>
Reference-contexts: Example 1: To demonstrate the use of Eq. (15), let us examine the assertability of "If it is cloudy you ought to take an umbrella" <ref> [3] </ref>. We assume three atomic propositions, c - "Cloudy", r - "Rain", and u - "Having an Umbrella", which form eight worlds, each corresponding to a complete truth assignment to c; r; and u. <p> Additionally, Poole's is a calculus of incremental improvements of utility, while ours is concerned with substantial improvements, as is typical of obligation statements. Boutilier <ref> [3] </ref> has developed a modal logic account of obligations which embodies considerations similar to 9 ours. It remains to be seen whether causal relation-ships such as those governing the interplay among actions and observations can easily be encoded into his formalism.
Reference: [4] <author> Dean, T., and Kanazawa, K., </author> <title> "A model for reasoning about persistence and causation," </title> <journal> Computational Intelligence, </journal> <volume> 5, </volume> <pages> 142-150, </pages> <year> 1989. </year>
Reference-contexts: First, when we deal with actions and consequences, we must resort to causal knowledge of the domain and we must decide how such knowledge is to be encoded, organized, and utilized. Second, while theories of actions are normally formulated as theories of temporal changes <ref> [18, 4] </ref>, deontic statements invariably suppress explicit references to time, strongly suggesting that temporal information is redundant, namely, it can be reconstructed if required, but glossed over otherwise. <p> Eq. (18) specifies the conditional rank (Xjpa X ) for every variable X in the combined networks and, hence, it provides a complete specification of the joint rank (!; ! 0 ). 7 The desired expression for the 6 This is essentially the persistence model used by Dean and Kanazawa <ref> [4] </ref>, in which s i represents the sur vival function of X i . <p> Long streams of observations and actions could therefore be processed as a sequence of updates on some initial state, without requiring analysis of long chains of temporally indexed networks, as in Dean and Kanazawa <ref> [4] </ref>.
Reference: [5] <author> Gibbard, A., </author> <title> "Two recent theories of conditionals," </title> <booktitle> in [9], </booktitle> <pages> 211-247. </pages>
Reference-contexts: For example, the Stalnaker-Lewis logic of counterfactuals, which promised to capture some aspects of causation (causal relationships invariably invite counterfactuations), ended up as a faint version of the logic of indicative conditionals <ref> [5] </ref>, hiding rather than revealing the rich structure of causation. of A. 9 We also saw that this likelihood depends critically on how C is confirmed, by observation or by action.
Reference: [6] <author> Gibbard, A., and Harper, L., </author> <title> "Counterfactuals and two kinds of expected utility," </title> <booktitle> in [9], </booktitle> <pages> 153-190. </pages>
Reference-contexts: call Decision Making Conditionals (DMC), avoids the CS and CSO paradoxes of conditional logics (see [13]) by ratifying only those conditionals A &gt; B that reflect a causal rather than an accidental connection between A and B and by insisting that causal connections are antisymmetric. 11 10 Gibbard and Harper <ref> [6] </ref> develop a quantitative theory of rational decisions that is based on Stalnaker's suggestion and explicitly attributes causal character to counterfactual conditionals.
Reference: [7] <author> Goldszmidt, M., </author> <title> "Qualitative probabilities: A normative framework for commonsense reasoning," </title> <type> Technical Report (R-190), </type> <institution> UCLA, Cognitive Systems Laboratory, </institution> <type> Ph.D. Dissertation, </type> <month> October </month> <year> 1992. </year>
Reference-contexts: The longer sentence combines several modalities that have been the subjects of AI investigations: observation, belief, knowledge, probability ("expected"), desirability ("utility"), causation ("resulting from"), and, of course, action ("doing A"). With the exception of utility, these modalities have been formulated recently using qualitative, order-of-magnitude abstractions of probability theory <ref> [8, 7] </ref>. Utility preferences themselves, we know from decision theory, can be fairly unstructured, save for obeying asymmetry and transitivity.
Reference: [8] <author> Goldszmidt, M., and Pearl, J., </author> <title> "Rank-based systems: A simple approach to belief revision, belief update, and reasoning about evidence and actions," </title> <booktitle> in Proceedings of the Third International Conference on Knowledge Representation and Reasoning, </booktitle> <address> Cambridge, MA, 661-672, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The longer sentence combines several modalities that have been the subjects of AI investigations: observation, belief, knowledge, probability ("expected"), desirability ("utility"), causation ("resulting from"), and, of course, action ("doing A"). With the exception of utility, these modalities have been formulated recently using qualitative, order-of-magnitude abstractions of probability theory <ref> [8, 7] </ref>. Utility preferences themselves, we know from decision theory, can be fairly unstructured, save for obeying asymmetry and transitivity. <p> This utility rating, when combined with the infinitesimal rating of probabilistic beliefs <ref> [8] </ref>, should permit us to rate actions by the expected utility of their consequences, and an obligation to do A would then be asserted iff the rating of doing A is substantially (i.e., a factor of 1=*) higher than that of not doing A. <p> = C* (!) (1) Treating * as an infinitesimal quantity induces a conditional ranking function ('j ) on propositions which is governed by Spohn's calculus [20]: (') = min ! (!) for ! j= ' ('j ) = (' ^ ) ( ) (2) 2. (Stratified Rankings and Causal Networks <ref> [8] </ref>). A causal network is a directed acyclic graph (dag) in which each node corresponds to an atomic variable and each edge X i ! X j asserts that X i has a direct causal influence on X j . <p> It ignores subsequent ac 2 The difference between P (!j') and P ' (!) is precisely the difference between belief revision and belief update <ref> [2, 10, 8] </ref> and also accounts for the difference between indicative and subjunctive conditionals a topic of much philosophical discussion [9]. 3 tions which the agent might be able to take so as to change this probability. <p> First we note that this update cannot be obtained by simply applying the update formula developed in <ref> [8, Eq. (2.2)] </ref>, A (!) = (!) (Ajpa A (!)) ! j= A 1 ! j= :A where pa A (!) are the parents (or immediate causes) of A in the causal network evaluated at !. <p> In such a case, the inequality X i (!) 6= X 0 i (! 0 ) contributes s i units of surprise to the normal relation between X i and its parents. 6 The unique feature of this model, unlike the one proposed in <ref> [8] </ref>, is that persistence defaults can be violated by causal factors without forcing us to conclude that such factors are abnormal. <p> To handle disjunctive actions such as "Paint the wall either red or blue" one must decide between two interpretations: "Paint the wall red or blue regardless of its current color" or "Paint the wall either red or blue but, if possible, do not change its current color" (see [10] and <ref> [8] </ref>). We will adopt the former interpretation, according to which "do (A _ B)" is merely a shorthand for "do (A) _ do (B)". <p> To the best of my knowledge, there has been no attempt to translate causal sentences into specifications of the Stalnaker-Lewis selection function. 10 Such specifications were partially provided in <ref> [8] </ref>, through the imaging function ! fl , and are further refined in this paper by invoking the persistence model (Eq. (20)).
Reference: [9] <editor> Harper, L., Stalnaker, R., and Pearce, G. (Eds.), Ifs, D. </editor> <publisher> Reidel Dordrecht, Holland, </publisher> <year> 1980. </year>
Reference-contexts: It ignores subsequent ac 2 The difference between P (!j') and P ' (!) is precisely the difference between belief revision and belief update [2, 10, 8] and also accounts for the difference between indicative and subjunctive conditionals a topic of much philosophical discussion <ref> [9] </ref>. 3 tions which the agent might be able to take so as to change this probability. For example, event ' might provide the agent with the option of conducting further tests so as to determine with greater certainty which world would eventually be realized.
Reference: [10] <author> Katsuno, H., and Mendelzon, </author> <title> A.O., "On the difference between updating a knowledge base and revising it," </title> <booktitle> in Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <address> Boston, MA, 387-394, </address> <year> 1991. </year>
Reference-contexts: It ignores subsequent ac 2 The difference between P (!j') and P ' (!) is precisely the difference between belief revision and belief update <ref> [2, 10, 8] </ref> and also accounts for the difference between indicative and subjunctive conditionals a topic of much philosophical discussion [9]. 3 tions which the agent might be able to take so as to change this probability. <p> To handle disjunctive actions such as "Paint the wall either red or blue" one must decide between two interpretations: "Paint the wall red or blue regardless of its current color" or "Paint the wall either red or blue but, if possible, do not change its current color" (see <ref> [10] </ref> and [8]). We will adopt the former interpretation, according to which "do (A _ B)" is merely a shorthand for "do (A) _ do (B)".
Reference: [11] <author> Levi, I., </author> <title> "Iteration of conditionals and the Ram-sey test," </title> <type> Synthese 76, </type> <pages> 49-81, </pages> <year> 1988. </year>
Reference-contexts: Intuitively, (!) represents the degree of surprise associated with finding a world ! realized, and worlds assigned = 0 are considered serious possibilities <ref> [11] </ref>. (!) can be considered an order-of-magnitude approximation of a probability function P (!) by writing P (!) as a polynomial of some small quantity * and taking the most significant term of that polynomial, i.e., P (!) ~ = C* (!) (1) Treating * as an infinitesimal quantity induces a
Reference: [12] <author> Lewis, D., </author> <title> Counterfactuals, </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1973. </year>
Reference-contexts: Surprisingly, despite an intense effort to establish a satisfactory account of "ought" statements <ref> [23, 22, 12] </ref>, the literature of both logics is loaded with paradoxes and voids of principle. This raises the question of whether "ought" statements are destined to forever elude formalization or that the approach taken by deontic logicians has been misdirected. I believe the answer involves a combination of both.
Reference: [13] <author> Nute, D., </author> <title> "Logic, conditional," </title> <editor> in Stuart C. Shapiro (Ed.), </editor> <booktitle> Encyclopedia of Artificial Intelligence, Second Edition, </booktitle> <publisher> John Wiley, </publisher> <address> New York, 854-860, </address> <year> 1992. </year>
Reference-contexts: This account, which we call Decision Making Conditionals (DMC), avoids the CS and CSO paradoxes of conditional logics (see <ref> [13] </ref>) by ratifying only those conditionals A &gt; B that reflect a causal rather than an accidental connection between A and B and by insisting that causal connections are antisymmetric. 11 10 Gibbard and Harper [6] develop a quantitative theory of rational decisions that is based on Stalnaker's suggestion and explicitly <p> other propositions, is not provided. 11 CS stands for A^B =) (A &gt; B); according to which reading the outcome of past US presidential elections would lead us to conclude "If Nixon had been elected president in 1972, then Betty Ford would have lived in the White House in 1974" <ref> [13, p. 856] </ref>. CS is not valid in our account because it does not satisfy Eq. (34) for all epistemic states, e.g., if is empty. <p> While transitivity is a characteristic feature of causation, the transitive rule [(A &gt; B) ^ (B &gt; C)] =) (A &gt; C) (35) is certainly not supported unconditionally by all causal models. For example <ref> [13] </ref>, George's health would improve (C) if he stopped smoking (B), and George would stop smoking (B) if he contracted em-phesyma (A), but surely George's health is not improved if he contracts emphesyma.
Reference: [14] <author> Mullen, J.D., </author> <title> "Does the logic of preference rest on a mistake?", </title> <journal> Metaphilosophy, </journal> <volume> 10, </volume> <pages> 247-255, </pages> <year> 1979. </year>
Reference-contexts: Since this information cannot be obtained from the logical content of A and C, it is not surprising that "almost every principle which has been proposed as fundamental to a preference logic has been rejected by some other source" <ref> [14] </ref>. In fact, the decision theoretic account embodied in Eq. (15) can be used to generate counterexamples to most of the principles suggested in the literature, simply by selecting a combination of ; , and that defies the proposed principle.
Reference: [15] <author> Pearl, J., </author> <title> Probabilistic Reasoning in Intelligent Systems, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: while deontic statements of the type "You ought to do A" are presumed applicable to any arbitrary proposition A. 1 Finally, decision theoretic methods, especially those based on static influence diagrams, treat both the informational relationships between observations and actions and the causal relationships between actions and consequences as instantaneous <ref> [17, 15, Chapter 6] </ref>. In reality, the effect of our next action might be to invalidate currently observed properties, hence any non-temporal criterion for obligation must carefully distinguish properties that are influenced by the action from those that will persist despite the action. <p> Given a ranking function (!), any edge-minimal dag satisfying Eq. (3), is called a Bayesian network of (!) <ref> [15] </ref>. <p> The utility of every chance event is evaluated as the expectation over the utilities of its immediate consequences, and the utility of every choice situation is computed as the maximum over the utilities of the available choices <ref> [15, Chapter 6] </ref>. This computation is rather exhaustive and is often governed by some form of myopic approximation. For example, assuming at some stage that the current action A is the last one permitted, after which a world ! will be chosen at random, with probability P A (!). <p> Once we are given it will be convenient to encode both (!) and (!) using integer-valued labels on the links of . Moreover, it is straightforward to apply Eqs. (14) and (15) to the usual decision theoretic tasks of selecting an optimal action or an optimal information-gathering strategy <ref> [15, Chapter 6] </ref>. Example 1: To demonstrate the use of Eq. (15), let us examine the assertability of "If it is cloudy you ought to take an umbrella" [3].
Reference: [16] <author> Poole, D., </author> <title> "Decision-theoretic defaults," </title> <booktitle> Ninth Canadian Conference on AI, </booktitle> <address> Vancouver, Canada, 190-197, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: It states that every dependence must have a causal explanation, either direct or indirect (via some common cause). 6.3 Other Decision Theoretic Accounts Poole <ref> [16] </ref> has proposed a quantitative decision-theoretic account of defaults, taking the utility of A, given evidence e, to be (Aje) = ! (!; A)P (!je) (37) This requires a specification of an action-dependent preference function for each (!; A) pair.
Reference: [17] <author> Shachter, R.D., </author> <title> "Evaluating influence diagrams," </title> <journal> Operations Research, </journal> <volume> 34, </volume> <pages> 871-882, </pages> <year> 1986. </year>
Reference-contexts: while deontic statements of the type "You ought to do A" are presumed applicable to any arbitrary proposition A. 1 Finally, decision theoretic methods, especially those based on static influence diagrams, treat both the informational relationships between observations and actions and the causal relationships between actions and consequences as instantaneous <ref> [17, 15, Chapter 6] </ref>. In reality, the effect of our next action might be to invalidate currently observed properties, hence any non-temporal criterion for obligation must carefully distinguish properties that are influenced by the action from those that will persist despite the action.
Reference: [18] <author> Shoham, Y., </author> <title> Reasoning About Change: Time and Causation from the Standpoint of Artificial Intelligence, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: First, when we deal with actions and consequences, we must resort to causal knowledge of the domain and we must decide how such knowledge is to be encoded, organized, and utilized. Second, while theories of actions are normally formulated as theories of temporal changes <ref> [18, 4] </ref>, deontic statements invariably suppress explicit references to time, strongly suggesting that temporal information is redundant, namely, it can be reconstructed if required, but glossed over otherwise.
Reference: [19] <author> Skyrms, B., </author> <title> "The prior propensity account of subjunctive conditionals," </title> <booktitle> in [9], </booktitle> <pages> 259-265. </pages>
Reference-contexts: The bulb can be made to light by other means, e.g., by short-circuiting the switch.) Our account also explains (see Example 2) why the assertability of counterfactual conditionals is often dependent upon previous observations, a point noted by Adams [1] and explained by Skyrms <ref> [19] </ref> in terms of probabilities of propensities. Such propensities are now given a concrete embodiment in the form of the causal network .
Reference: [20] <author> Spohn, W., </author> <title> "Ordinal conditional functions: A dynamic theory of epistemic states," </title> <editor> in W.L. Harper and B. Skyrms (Eds.), </editor> <title> Causation in Decision, Belief Change, and Statistics, </title> <address> D. </address> <publisher> Reidel, Dordrecht, Holland, </publisher> <pages> 105-134, </pages> <year> 1988. </year>
Reference-contexts: by writing P (!) as a polynomial of some small quantity * and taking the most significant term of that polynomial, i.e., P (!) ~ = C* (!) (1) Treating * as an infinitesimal quantity induces a conditional ranking function ('j ) on propositions which is governed by Spohn's calculus <ref> [20] </ref>: (') = min ! (!) for ! j= ' ('j ) = (' ^ ) ( ) (2) 2. (Stratified Rankings and Causal Networks [8]).
Reference: [21] <author> Stalnaker, R., </author> <title> "Letter to David Lewis" in [9], </title> <type> 151-152. </type>
Reference-contexts: But one begins to wonder about the value of assembling a logic from a sparse collection of such impoverished survivors when, in practice, a full specification of ; , and would be required. 6.2 Counterfactual Conditionals Stalnaker <ref> [21] </ref> was the first to make the connection between actions and counterfactual statements, and he proposed using the probability of the counter-factual conditional (as opposed to the conditional probability, which is more appropriate for indicative conditionals) in the calculation of expected utilities. <p> Our proposal (in line with <ref> [21] </ref>) attributes the dependence of on A to beliefs about the possible consequences of A, thereby keeping the utility of each consequence constant. In this way, we see more clearly how the structure of causal theories should affect obligations.
Reference: [22] <author> Van Fraassen, </author> <title> B.C., "The logic of conditional obligation," </title> <editor> in M. Bunge (Ed.), Exact Philosophy, D. </editor> <publisher> Reidel, Dordrecht, Holland, </publisher> <pages> 151-172, </pages> <year> 1973. </year>
Reference-contexts: Surprisingly, despite an intense effort to establish a satisfactory account of "ought" statements <ref> [23, 22, 12] </ref>, the literature of both logics is loaded with paradoxes and voids of principle. This raises the question of whether "ought" statements are destined to forever elude formalization or that the approach taken by deontic logicians has been misdirected. I believe the answer involves a combination of both. <p> He fails to notice that three out of his five axioms either stand in outright violation of decision theory or make strong commitments to a particular assignment of probabilities to the possible outcomes. Van Fraassen <ref> [22] </ref>, likewise, acknowledges the importance of likelihood, stating "But does this not ignore the problem of likelihood? Is gambling the most moral of pursuits if breaking the bank makes possible unrivalled philanthropy? I don't mean that of course. <p> Abandoning this relation yields a breakdown of almost all of van Fraassen's axioms, especially RC 2 (see the critique of H. Beatty, following <ref> [22] </ref>). 8 be thought of as a generalization of, and a surrogate for, causal knowledge, it is too general, as it is not constrained by the basic features of causal relationships such as asymmetry, transitivity, and complicity with temporal order.
Reference: [23] <author> Von Wright, </author> <title> G.H., The Logic of Preference, </title> <publisher> University of Edinburgh Press, Edinburgh, </publisher> <address> Scotland, </address> <year> 1963. </year> <month> 10 </month>
Reference-contexts: Deontics: From Utilities and Beliefs to Goals and Obligations Given a proposition ' that describes some condition or event in the world, what information is needed before we can evaluate the merit of obtaining ', or, at the least, whether ' 1 is "preferred" to ' 2 ? Preference logics <ref> [23] </ref> have assumed that regardless of the reasons for our preferences, there are some basic logical constraints that tie preferences among propositions to preferences among their constituents. <p> Surprisingly, despite an intense effort to establish a satisfactory account of "ought" statements <ref> [23, 22, 12] </ref>, the literature of both logics is loaded with paradoxes and voids of principle. This raises the question of whether "ought" statements are destined to forever elude formalization or that the approach taken by deontic logicians has been misdirected. I believe the answer involves a combination of both. <p> Stalnaker's theory does not provide an explicit connection between subjunctive conditionals and causation, however. Although the selection function used in the Stalnaker-Lewis nearest-world semantics can 9 The developers of deontic logic were not oblivious to the importance of likelihoods and/or control. Von Wright <ref> [23] </ref>, for example, mentions decision theory as an exercise in the definition of subjective (numerical) probabilities and utilities, hence, lying outside the province of logical analysis.
References-found: 23

