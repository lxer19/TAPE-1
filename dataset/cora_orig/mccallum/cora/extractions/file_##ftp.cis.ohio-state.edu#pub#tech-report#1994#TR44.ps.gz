URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1994/TR44.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: fspiro,pipping@cis.ohio-state.edu.  
Phone: Voice: +1 (614) 292 6377 FAX: +1 (614) 292 2911  
Title: Optimizing Compilation of Linear Arithmetic in a Class of Constraint Logic Programs  
Author: Spiro Michaylov Bill Pippin 
Date: August 31, 1994  
Address: 2015 Neil Avenue Mall, Columbus, OH 43210-1277, U.S.A.,  
Affiliation: Department of Computer and Information Science, The Ohio State University, 395 Dreese Lab,  
Pubnum: Technical Report OSU-CISRC-8/94-TR44  
Abstract: A central issue in the optimizing compilation of Constraint Logic Programming (CLP) languages is how to compile away as much general constraint solving as possible. Most such work relies on obtaining mode and type information by global analysis, and uses it to generate specialized code for individual constraints and calls, often with the aid of multiple specialization. Some recent work has augmented these techniques with procedure-level analysis of the inter-relationships between constraints, to detect constraints that subsume other constraints, and variables that cease to be reachable at some point in a computation. In combination, these techniques have been shown to dramatically improve performance for a number of programs. Here we continue this line of investigation by considering a class of programs that accumulate and simplify systems of linear arithmetic constraints. The programs contain procedures that relate their parameters by an affine transform. For some calling patterns, the procedures repeatedly compose and simplify affine transforms, using virtually the full power of the linear arithmetic constraint solver, and incurring considerable expense. We describe source to source translations that make this composition of transforms explicit, replacing constraint solving with ground (imperative) arithmetic. We demonstrate the translations and present experimental data showing substantial improvements in execution speed and space utilization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alain Colmerauer. </author> <title> An introduction to PROLOG-III. </title> <journal> Communications of the ACM, </journal> <volume> 33(7) </volume> <pages> 69-90, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Many Constraint Logic Programming (CLP) [7] languages incorporate solving of linear arithmetic equations as a basic operational step. These include CLP (R) [8], Prolog III <ref> [1] </ref>, CHIP [4] and ECL i PS e [6]. Programs that frequently require simultaneous linear equations to be checked for satisfiability can cause the solver to use a large amount of space, and may execute slowly.
Reference: [2] <author> M. J. Garca de la Banda and M. Hermenegildo. </author> <title> A practical approach to the global analysis of constraint logic programs. </title> <type> Technical Report UPM/DIA/CLIP/PRINCE-1/92.1.1, </type> <institution> Facultad de Informatica, Universidad Politecnica de Madrid, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Global analysis techniques for Constraint Logic Programming have been discussed by Dumortier et al [5], Garca de la Banda and Hermenegildo <ref> [2] </ref>, Jtrgensen [9], Marriott and Stndergaard [12], and others. Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov [15], MacDonald et al [11], Marriott and Stuckey [13], and others.
Reference: [3] <author> M. J. Garca de la Banda, M. Hermenegildo, and K. Marriott. </author> <title> Independence in constraint logic programs. </title> <type> Technical Report UPM/DIA/CLIP/PRINCE-1/92.2.1, </type> <institution> Facultad de Informatica, Universidad Politecnica de Madrid, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al <ref> [3] </ref>, Jtrgensen et al [10], Michaylov [15], MacDonald et al [11], Marriott and Stuckey [13], and others.
Reference: [4] <author> M. Dincbas, P. van Hentenryck, H. Simonis, A. Aggoun, T. Graf, and F. Berthier. </author> <title> The Constraint Logic Programming Language CHIP. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems FGCS-88, </booktitle> <pages> pages 693-702, </pages> <address> Tokyo, Japan, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Many Constraint Logic Programming (CLP) [7] languages incorporate solving of linear arithmetic equations as a basic operational step. These include CLP (R) [8], Prolog III [1], CHIP <ref> [4] </ref> and ECL i PS e [6]. Programs that frequently require simultaneous linear equations to be checked for satisfiability can cause the solver to use a large amount of space, and may execute slowly.
Reference: [5] <author> Veroniek Dumortier, Gerda Janssens, and Maurice Bruynooghe. </author> <title> Detection of free variables in the presence of numeric constraints by means of abstract interpretation. </title> <type> Technical Report CW 145, </type> <institution> Derpartment of Computer Science, Katholieke Universiteit Leuven, Celestijnenlaan 200A - B-3001 Leuven, Belgium, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Thus, much effort has recently been put into global program analysis, in the hope that detailed mode and type information can be used to improve performance by reducing the use of the constraint solver. Global analysis techniques for Constraint Logic Programming have been discussed by Dumortier et al <ref> [5] </ref>, Garca de la Banda and Hermenegildo [2], Jtrgensen [9], Marriott and Stndergaard [12], and others.
Reference: [6] <author> ECRC. </author> <title> ECL i PS e users manual. </title> <year> 1993. </year>
Reference-contexts: 1 Introduction Many Constraint Logic Programming (CLP) [7] languages incorporate solving of linear arithmetic equations as a basic operational step. These include CLP (R) [8], Prolog III [1], CHIP [4] and ECL i PS e <ref> [6] </ref>. Programs that frequently require simultaneous linear equations to be checked for satisfiability can cause the solver to use a large amount of space, and may execute slowly.
Reference: [7] <author> Joxan Jaffar and Jean-Louis Lassez. </author> <title> Constraint logic programming. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Principles of Programming Languages (POPL), </booktitle> <address> Munich, Germany, </address> <pages> pages 111-119. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Many Constraint Logic Programming (CLP) <ref> [7] </ref> languages incorporate solving of linear arithmetic equations as a basic operational step. These include CLP (R) [8], Prolog III [1], CHIP [4] and ECL i PS e [6].
Reference: [8] <author> Joxan Jaffar, Spiro Michaylov, Peter J. Stuckey, and Roland H. C. Yap. </author> <title> The CLP(R) language and system. </title> <journal> ACM Transactions on Programming Languages and Systems (TOPLAS), </journal> <volume> 14(3) </volume> <pages> 339-395, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Many Constraint Logic Programming (CLP) [7] languages incorporate solving of linear arithmetic equations as a basic operational step. These include CLP (R) <ref> [8] </ref>, Prolog III [1], CHIP [4] and ECL i PS e [6]. Programs that frequently require simultaneous linear equations to be checked for satisfiability can cause the solver to use a large amount of space, and may execute slowly.
Reference: [9] <author> Niels Jtrgensen. </author> <title> Abstract Interpretation of Constraint Logic Programs. </title> <type> PhD thesis, </type> <institution> Roskilde University Center, Denmark, </institution> <year> 1992. </year>
Reference-contexts: Global analysis techniques for Constraint Logic Programming have been discussed by Dumortier et al [5], Garca de la Banda and Hermenegildo [2], Jtrgensen <ref> [9] </ref>, Marriott and Stndergaard [12], and others. Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov [15], MacDonald et al [11], Marriott and Stuckey [13], and others. <p> One relevant area of practical global compilation that is just barely beginning to be investigated is the relationship with programming methodology and program development tools. The optimizations in this paper, like a number of others <ref> [9, 11, 13, 15] </ref> were developed by either explicitly or implicitly considering the rationale behind the way some class of real programs is structured. That is, they stem from an understanding of programming methodology.
Reference: [10] <author> Niels Jtrgensen, Kim Marriott, and Spiro Michaylov. </author> <title> Some global compile-time optimizations for CLP(R). </title> <editor> In Vijay Saraswat and Kazunori Ueda, editors, </editor> <booktitle> Logic Programming: Proceedings of the 1991 International Symposium, </booktitle> <pages> pages 420-434, </pages> <address> San Diego, CA, October 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al <ref> [10] </ref>, Michaylov [15], MacDonald et al [11], Marriott and Stuckey [13], and others. Most attempts at optimizing CLP programs depend on a small number of techniques applied at the level of individual procedures in addition to basic global analysis: * Multiple specialization Various calling patterns enable different optimizations. <p> Some examples include future redundancy <ref> [10, 15] </ref>, dead variable elimination [11] and constraint removal [13]. Many CLP programs dealing with arithmetic, for some classes of queries, establish a network of linear constraints one at a time, calling the equation solver to simplify the network and check its satisfiability at each operational step. <p> The transformed programs can then be further optimized using the "solver bypass" techniques described in <ref> [10] </ref>. Furthermore, these optimizations are intended for use with other optimizations, such as the reordering of subgoals within rules [14], and future redundancy [10, 15]. <p> The transformed programs can then be further optimized using the "solver bypass" techniques described in [10]. Furthermore, these optimizations are intended for use with other optimizations, such as the reordering of subgoals within rules [14], and future redundancy <ref> [10, 15] </ref>. In fact, applicability of the optimizations described here is a good criterion for those reordering translations, as many programs will need reordering before these are applicable. 5 In this section, we describe progressively more general versions formally.
Reference: [11] <author> Andrew D. Macdonald, Peter J. Stuckey, and Roland H. C. Yap. </author> <title> Redundancy of variables in CLP(R). </title> <booktitle> In Logic Programming: Proceedings of the 1993 International Symposium, </booktitle> <pages> pages 75-93, </pages> <address> Vancouver, October 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov [15], MacDonald et al <ref> [11] </ref>, Marriott and Stuckey [13], and others. Most attempts at optimizing CLP programs depend on a small number of techniques applied at the level of individual procedures in addition to basic global analysis: * Multiple specialization Various calling patterns enable different optimizations. <p> Some examples include future redundancy [10, 15], dead variable elimination <ref> [11] </ref> and constraint removal [13]. Many CLP programs dealing with arithmetic, for some classes of queries, establish a network of linear constraints one at a time, calling the equation solver to simplify the network and check its satisfiability at each operational step. <p> One relevant area of practical global compilation that is just barely beginning to be investigated is the relationship with programming methodology and program development tools. The optimizations in this paper, like a number of others <ref> [9, 11, 13, 15] </ref> were developed by either explicitly or implicitly considering the rationale behind the way some class of real programs is structured. That is, they stem from an understanding of programming methodology.
Reference: [12] <author> Kim Marriott and Harald Stndergaard. </author> <title> Analysis of constraint logic programs. </title> <editor> In Saumya Debray and Manuel Hermenegildo, editors, </editor> <booktitle> Proc. of the 1990 North American Conference on Logic Programming, </booktitle> <pages> pages 521-540, </pages> <address> Austin, TX, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Global analysis techniques for Constraint Logic Programming have been discussed by Dumortier et al [5], Garca de la Banda and Hermenegildo [2], Jtrgensen [9], Marriott and Stndergaard <ref> [12] </ref>, and others. Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov [15], MacDonald et al [11], Marriott and Stuckey [13], and others.
Reference: [13] <author> Kimbal G. Marriott and Peter J. Stuckey. </author> <title> The 3 R's of optimizing constraint logic programs: Refinement, removal and reordering. </title> <booktitle> In Proc. ACM SIGPLAN Symposium on Principles of Programming Languages (POPL), </booktitle> <address> Charleston, NC, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov [15], MacDonald et al [11], Marriott and Stuckey <ref> [13] </ref>, and others. Most attempts at optimizing CLP programs depend on a small number of techniques applied at the level of individual procedures in addition to basic global analysis: * Multiple specialization Various calling patterns enable different optimizations. <p> This is most fully described by Winsborough in [20]. * Subgoal reordering Different orders of constraints in the body of a rule may be appropriate for different calling patterns. This was first described for CLP by Marriott and Stuckey in <ref> [13] </ref>, and studied systematically by Michaylov [14]. * Fold/Unfold transformations These can enable optimizations based on procedures of certain restricted forms. * Constraint interactions across rule instances Some of the most useful optimizations rely on observing how various constraint instances throughout the execution of a procedure interact. <p> Some examples include future redundancy [10, 15], dead variable elimination [11] and constraint removal <ref> [13] </ref>. Many CLP programs dealing with arithmetic, for some classes of queries, establish a network of linear constraints one at a time, calling the equation solver to simplify the network and check its satisfiability at each operational step. <p> One relevant area of practical global compilation that is just barely beginning to be investigated is the relationship with programming methodology and program development tools. The optimizations in this paper, like a number of others <ref> [9, 11, 13, 15] </ref> were developed by either explicitly or implicitly considering the rationale behind the way some class of real programs is structured. That is, they stem from an understanding of programming methodology.
Reference: [14] <author> Spiro Michaylov. </author> <title> Optimizing CLP(R) programs by reordering subgoals. </title> <type> Technical report, </type> <institution> Department of Computer and Information Science, The Ohio State University, </institution> <month> forthcoming </month> <year> 1994. </year>
Reference-contexts: This is most fully described by Winsborough in [20]. * Subgoal reordering Different orders of constraints in the body of a rule may be appropriate for different calling patterns. This was first described for CLP by Marriott and Stuckey in [13], and studied systematically by Michaylov <ref> [14] </ref>. * Fold/Unfold transformations These can enable optimizations based on procedures of certain restricted forms. * Constraint interactions across rule instances Some of the most useful optimizations rely on observing how various constraint instances throughout the execution of a procedure interact. <p> Consider the following examples: * 1 : ?- solve (num, num, num, num, free). Requires only simple arithmetic evaluation and testing. * 2 : ?- solve (num, free, num, num, num). After suitable re-ordering of constraints, as described in <ref> [14] </ref>, this also requires only simple arithmetic evaluation and testing. * 3 : ?- solve (num, free, num, num, free). Establishes a chain of linear equations linking the two free arguments. <p> The transformed programs can then be further optimized using the "solver bypass" techniques described in [10]. Furthermore, these optimizations are intended for use with other optimizations, such as the reordering of subgoals within rules <ref> [14] </ref>, and future redundancy [10, 15]. In fact, applicability of the optimizations described here is a good criterion for those reordering translations, as many programs will need reordering before these are applicable. 5 In this section, we describe progressively more general versions formally.
Reference: [15] <author> Spiro Michaylov. </author> <title> Repeated redundant inequalities in constraint logic programming. </title> <booktitle> In First International Conference on Constraints in Computational Logics, </booktitle> <address> Munich, </address> <month> September </month> <year> 1994. </year> <note> Also appears as Technical Report OSU-CISRC-6/94-TR31, </note> <institution> Department of Computer and Information Science, The Ohio State University. </institution>
Reference-contexts: Based on such analysis, considerable work has been done on actual optimizing compilation of CLP languages, by Garca de la Banda et al [3], Jtrgensen et al [10], Michaylov <ref> [15] </ref>, MacDonald et al [11], Marriott and Stuckey [13], and others. Most attempts at optimizing CLP programs depend on a small number of techniques applied at the level of individual procedures in addition to basic global analysis: * Multiple specialization Various calling patterns enable different optimizations. <p> Some examples include future redundancy <ref> [10, 15] </ref>, dead variable elimination [11] and constraint removal [13]. Many CLP programs dealing with arithmetic, for some classes of queries, establish a network of linear constraints one at a time, calling the equation solver to simplify the network and check its satisfiability at each operational step. <p> The transformed programs can then be further optimized using the "solver bypass" techniques described in [10]. Furthermore, these optimizations are intended for use with other optimizations, such as the reordering of subgoals within rules [14], and future redundancy <ref> [10, 15] </ref>. In fact, applicability of the optimizations described here is a good criterion for those reordering translations, as many programs will need reordering before these are applicable. 5 In this section, we describe progressively more general versions formally. <p> However, the program can still be optimized. The inequality Y &gt; 0 is partially future redundant in the sense of <ref> [15] </ref>, and hence need only be tested at each iteration, with only the last one being added to the constraint solver. Furthermore, for the given allowed query pattern, that inequality cannot cause failure at any stage of the recursion, and hence need not even be checked. <p> 0 ) ^ U n ( ~ X n ) &gt; 0: Thus a procedure containing an inequality linked to a variable in a transformation chain can be optimized as before, with the final inequality moved to the wrapper, the others deleted, and some other administrative modifications, as described in <ref> [15] </ref>. Now, we also consider the problem of early detection of failure. The above translation results in procedures with the same solutions as the original ones. <p> One relevant area of practical global compilation that is just barely beginning to be investigated is the relationship with programming methodology and program development tools. The optimizations in this paper, like a number of others <ref> [9, 11, 13, 15] </ref> were developed by either explicitly or implicitly considering the rationale behind the way some class of real programs is structured. That is, they stem from an understanding of programming methodology.
Reference: [16] <author> Spiro Michaylov. </author> <title> Skeletons and techniques for the systematic development of constraint logic programs. </title> <booktitle> In 6th IEEE International Conference on Tools with Artificial Intelligence, </booktitle> <address> New Orleans, </address> <month> November </month> <year> 1994. </year> <note> Also appears as Technical Report OSU-CISRC-6/94-TR30, </note> <institution> Department of Computer and Information Science, The Ohio State University. </institution>
Reference-contexts: That is, they stem from an understanding of programming methodology. Some of the recent work on program development using skeletons and techniques <ref> [19, 16, 17] </ref> has speculated about the possibility of a well-defined program construction methodology being used to guide optimizing compilation, by associating optimizations with individual skeletons and techniques.
Reference: [17] <author> Spiro Michaylov and Bill Pippin. </author> <title> Optimizing compilation of linear arithmetic in a class of constraint logic programs. </title> <booktitle> In International Logic Programming Symposium, </booktitle> <address> Ithaca, NY, </address> <month> November </month> <year> 1994. </year> <note> Also appears as Technical Report OSU-CISRC-8/94-TR44, </note> <institution> Department of Computer and Information Science, The Ohio State University. </institution>
Reference-contexts: That is, they stem from an understanding of programming methodology. Some of the recent work on program development using skeletons and techniques <ref> [19, 16, 17] </ref> has speculated about the possibility of a well-defined program construction methodology being used to guide optimizing compilation, by associating optimizations with individual skeletons and techniques.
Reference: [18] <author> Reinhard Skuppin. </author> <title> Treating ordinary differential equations in clp. </title> <type> Technical Report FAW-TR-93004, </type> <institution> FAW Ulm, </institution> <year> 1993. </year>
Reference-contexts: The techniques described are applicable to any system of linear ODEs, that is systems with each member of the form dy dt = f 0 (t)y + f 1 (t), where f 0 and f 1 are arbitrary functions in t. Skuppin <ref> [18] </ref> demonstrates the use of ODE solvers written in CLP (R) and Prolog III, and shows the value of unusual query patterns in practical applications. A solver such as eulers/5 can be used to solve both initial value and two-point boundary value problems.
Reference: [19] <author> Leon Sterling and Marc Kirschenbaum. </author> <title> Applying techniques to skeletons. </title> <editor> In J.-M. Jacquet, editor, </editor> <booktitle> Constructing Logic Programs, </booktitle> <pages> pages 127-140. </pages> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: That is, they stem from an understanding of programming methodology. Some of the recent work on program development using skeletons and techniques <ref> [19, 16, 17] </ref> has speculated about the possibility of a well-defined program construction methodology being used to guide optimizing compilation, by associating optimizations with individual skeletons and techniques.
Reference: [20] <author> William H. Winsborough. </author> <title> Path-dependent reachability analysis for multiple specialization. </title> <booktitle> In Logic Programming: Proceedings of the North American Conference, </booktitle> <pages> pages 133-153, </pages> <address> Cleveland, OH, USA, November 1989. </address> <publisher> MIT Press. </publisher> <pages> 31 </pages>
Reference-contexts: Most attempts at optimizing CLP programs depend on a small number of techniques applied at the level of individual procedures in addition to basic global analysis: * Multiple specialization Various calling patterns enable different optimizations. This is most fully described by Winsborough in <ref> [20] </ref>. * Subgoal reordering Different orders of constraints in the body of a rule may be appropriate for different calling patterns.
References-found: 20

