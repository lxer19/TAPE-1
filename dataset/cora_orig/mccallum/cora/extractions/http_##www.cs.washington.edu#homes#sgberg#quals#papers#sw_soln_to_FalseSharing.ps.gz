URL: http://www.cs.washington.edu/homes/sgberg/quals/papers/sw_soln_to_FalseSharing.ps.gz
Refering-URL: http://www.cs.washington.edu/homes/sgberg/quals/index.html
Root-URL: 
Title: Simple Compiler Algorithms to Reduce Ownership Overhead in Cache Coherence Protocols  
Author: Jonas Skeppstedt and Per Stenstrom 
Address: P.O. Box 118, S-221 00 Lund, SWEDEN  
Affiliation: Department of Computer Engineering, Lund University  
Abstract: We study in this paper the design and efficiency of compiler algorithms that remove ownership overhead in shared- memory multiprocessors with write-invalidate protocols. These algorithms detect loads followed by stores to the same address. Such loads are marked and constitute a hint to the cache to obtain an exclusive copy of the block. We consider three algorithms where the first one focuses on load-store sequences within each basic block of code and the other two analyse the existence of load-store sequences across basic blocks at the intra-procedural level. Since the dataflow analysis we adopt is a trivial variation of live-variable analysis, the algorithms are easily incorporated into a compiler. Through detailed simulations of a cache-coherent NUMA architecture using five scientific parallel benchmark programs, we find that the algorithms are capable of removing over 95% of the separate ownership acquisitions. Moreover, we also find that even the simplest algorithm is comparable in efficiency with previously proposed hardware-based adaptive cache coherence protocols to attack the same problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred Aho, Ravi Sethi, and Jeffrey Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year> <note> ISBN: 0-201-10088-6. </note>
Reference-contexts: Note that marking of loads is strictly a performance issueexcessive marking does not compromise correctness. 3.2 Definitions and Overview of the Algorithms Conceptually, our algorithms detect load-store sequences by using a dataflow analysis similar to live-variable analysis <ref> [1] </ref>. Loosely speaking, our algorithms decide whether a store reaches a certain load by propagating stores backwards in the flow graph taking conditions (1) and (2) into account. We have implemented the algorithms as an optimisation pass on the intermediate code level. <p> The above operations applied to each basic block are repeated until no changes occur as in other iterative dataflow analyses <ref> [1] </ref>. Global Analysis The last step in Conservative and Speculative marks loads whose associated store classes belong to the OU T set of the basic block and are not killed locally. <p> Even though our compiler performs many standard optimisations <ref> [1, 5] </ref>, it becomes important to understand how the results in the next section compare to code compiled with public- domain optimising compilers. Therefore, we have compared some key parameters with gcc (version 2.1) with optimisa- tion level O2.
Reference: [2] <author> James Boyle et al. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <year> 1987. </year>
Reference-contexts: FLC, SLC, and local memory access times are 1, 6, and 30 pclocks, respectively. 4.2 Compiler and Benchmarks We have incorporated the compiler algorithms into an opti- mising C compiler [17] which compiles parallel applications using the ANL macros <ref> [2] </ref> and generates code for shared- memory multiprocessors based on SPARC processors. Even though our compiler performs many standard optimisations [1, 5], it becomes important to understand how the results in the next section compare to code compiled with public- domain optimising compilers.
Reference: [3] <author> Mats Brorsson, Fredrik Dahlgren, Hakan Nilsson, and Per Stenstrom. </author> <title> The CacheMire Test Bench A Flexible and Effective Approach for Simulation of Multiprocessors. </title> <booktitle> In Proc. of the 26th IEEE Annual Simulation Symposium, </booktitle> <pages> pages 41-49, </pages> <month> March </month> <year> 1993. </year>
Reference: [4] <author> Lucien Censier and Paul Feautrier. </author> <title> A New Solution to Coherence Problems in Multicache Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 27(12) </volume> <pages> 1112-1118, </pages> <year> 1978. </year>
Reference-contexts: Each processing node contains a processor with a two-level cache hierarchy and a part of the shared memory. In order to maintain consistency among the private caches in the processing nodes, a full-map write-invalidate protocol due to Censier and Feautrier <ref> [4] </ref> is assumed. In a write- invalidate protocol, acquisition of ownership is needed before a processor can modify a block. In addition to the time the processors are stalled due to cache misses, the processors also incur penalties in handling ownership requests.
Reference: [5] <author> Fred Chow and John Hennessy. </author> <title> The Priority-Based Coloring Approach to Register Allocation. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 12(4) </volume> <pages> 590-536, </pages> <year> 1990. </year>
Reference-contexts: Even though our compiler performs many standard optimisations <ref> [1, 5] </ref>, it becomes important to understand how the results in the next section compare to code compiled with public- domain optimising compilers. Therefore, we have compared some key parameters with gcc (version 2.1) with optimisa- tion level O2.
Reference: [6] <author> Allan Cox and Robert Fowler. </author> <title> Adaptive Cache Coherency for Detecting Migratory Shared Data. </title> <booktitle> In 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 98-108, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Previous studies have focused on hardware-based as well as software-based approaches to remove explicit ownership requests. Starting with hardware-based methods, Cox and Fowler <ref> [6] </ref> and Stenstrom et al. [18] have studied adaptive cache coherence protocols that detect non-overlapping load- store sequences by different processors to the same block called migratory sharing. Detection is done by augmenting the cache coherence protocol with extra functionality to detect cache-miss requests followed by ownership requests. <p> This is the key idea of previously proposed adaptive cache coherence protocols which we consider next. 2.2 Adaptive Cache Coherence Protocols Cox and Fowler <ref> [6] </ref> and Stenstrom et al. [18] have proposed extensions to basic write-invalidate protocols which dynamically detect migratory sharing and for blocks deemed migratory, merge ownership requests with cache-miss requests. <p> Note that the cache hierarchy mechanisms needed in this case include a SLWB. In our simulations we assume that the FLWB and the SLWB contain 8 and 16 entries, respectively. Adaptive Cache Coherence Protocol Extensions The adaptive cache coherence protocol we evaluate, according to <ref> [18, 6] </ref>, extend the baseline write-invalidate protocol with a pointer of size log 2 16 = 4 bits per memory block and an extra cache state. We have evaluated two variants of the adaptive cache coherence protocols. <p> The topmost three applications (Water, Cholesky, and MP3D) are all characterised by having a fair amount of migratory sharing as observed in previous studies <ref> [6, 10, 18] </ref>. The write stall-times for B range from 2% in Water, 18% in Cholesky, and 36% in MP3D. When considering the compiler algorithms (L, C, and S) and the adaptive cache coherence protocols (DS and DM) we see that the write stall-times are almost completely eliminated. <p> However, if we were to consider more aggressive processors than we have assumed in this study such as the DEC Alpha, the impact of ownership overhead reduction on the execution time would be more dramatic than our numbers suggest. Cox and Fowler <ref> [6] </ref> studied the effect of cache parameters on the effectiveness of the adaptive techniques. Overall they found that if false sharing becomes dominant when the block size increases, the effectiveness of the detection goes down. <p> Con- sidering limited caches, replacements can reduce the latency of each individual cache operation because blocks are more often uncached in the home node. Cox and Fowler <ref> [6] </ref> found that the relative efficiency of the adaptive techniques was smaller for limited caches and we expect this to hold for our compiler algorithms as well.
Reference: [7] <author> Michel Dubois, Jonas Skeppstedt, Livio Ricciulli, Krishnan Ramamurthy, and Per Stenstrom. </author> <title> The Detection and Elimination of Useless Misses in Multiprocessors. </title> <booktitle> In Proc.of 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 88-97, </pages> <year> 1993. </year>
Reference-contexts: In that trace, P2 first issues a load that results in a cold miss. Because of the load-store sequence of P1, the load at T1 is marked (Load+) and results in an invalidation of the block in P2's cache. As a result, P2 will experience a useless miss <ref> [7] </ref> at T2. An interesting Ref. P1 P2 Comment T0: Load Cold miss T1: Load+ INV Miss and invalidation T2: Load Useless miss T3: Store same data item.
Reference: [8] <author> Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> Performance Evaluation of Memory Consistency Models for Shared-Memory Multiprocessors. </title> <booktitle> In Proc. of ASPLOS-IV, </booktitle> <pages> pages 245-257, </pages> <year> 1991. </year>
Reference-contexts: In addition to the time the processors are stalled due to cache misses, the processors also incur penalties in handling ownership requests. Under sequential consistency, which we especially focus on in this study, the processors must stall at store requests until ownership has been granted <ref> [8] </ref>. Moreover, the separate ownership requests that are triggered by stores also increase network traffic due to the ownership request itself, invalidations, and acknowledgement messages. This extra traffic may, as a secondary effect, increase the read and synchroni- sation penalties because of memory-system contention also under relaxed memory consistency models. <p> To start with, if a relaxed memory consistency model would have been used, the gains of the algorithms seem at first glance nullified because the write latency can be then completely hidden <ref> [8] </ref>. However, Stenstrom et al. showed in [18] that the adaptive techniques were able to cut the network traffic by more than 20% for MP3D, Cholesky, and Water which we have used in this study.
Reference: [9] <author> Kourosh Gharachorloo, Daniel Lenoski, James Laudon, Philip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors. </title> <booktitle> In Proc. of 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <year> 1990. </year>
Reference-contexts: Unfortunately, such ownership acquisitions may stall the processor and result in substantial penalties under sequential consistency [18]. Moreover, even though the memory model is relaxed <ref> [9] </ref> the additional traffic caused by ownership acquisitions can result in memory-system contention which as a secondary effect can increase read and synchronisation penalties. Previous studies have focused on hardware-based as well as software-based approaches to remove explicit ownership requests. <p> Data races show up if two processors issue accesses to the same address and at least one of them is a store. For example, in the trace of race. However, properly-labeled programs <ref> [9] </ref> do not have any data races because competing accesses are separated by a synchronisation. Thus, if a load-store sequence is not separated by a synchronisation in between and the program is properly labeled, extra invalidations and misses are not introduced given that there is no false sharing.
Reference: [10] <author> Anoop Gupta and Wolf-Dietrich Weber. </author> <title> Cache Invalidation Patterns in Shared-Memory Multiprocesors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(7) </volume> <pages> 794-810, </pages> <year> 1992. </year>
Reference-contexts: This extra traffic may, as a secondary effect, increase the read and synchroni- sation penalties because of memory-system contention also under relaxed memory consistency models. A common data-sharing pattern in which ownership overhead is especially pronounced is migratory sharing <ref> [10] </ref> where a memory block migrates between different processing nodes and each processor issues read-write sequences to the block. A typical example of when such a behaviour occurs is when a data structure is read and modified in a critical section. <p> The topmost three applications (Water, Cholesky, and MP3D) are all characterised by having a fair amount of migratory sharing as observed in previous studies <ref> [6, 10, 18] </ref>. The write stall-times for B range from 2% in Water, 18% in Cholesky, and 36% in MP3D. When considering the compiler algorithms (L, C, and S) and the adaptive cache coherence protocols (DS and DM) we see that the write stall-times are almost completely eliminated.
Reference: [11] <author> Mark Hill, James Larus, Steven Reinhardt, and David Wood. </author> <title> Cooperative Shared Memory: </title> <booktitle> Software and Hardware Support for Scalable Shared Memory . In Proc. of ASPLOS V, </booktitle> <pages> pages 262-273, </pages> <year> 1992. </year>
Reference-contexts: Stenstrom et al. [18] found that for applications with substantial migratory sharing, most of the ownership requests were removed which reduced the execution time by as much as 35% under sequential consistency. Continuing with software-based approaches, Hill et al. have proposed a programming notation called CICO (Check- In/Check-Out) <ref> [11] </ref>. With CICO, the programmer provides information about when a data structure is exclusively used. This information can be used by the compiler to insert instructions that prefetch an exclusive copy of the block into the cache. Mowry and Gupta have studied the use of such exclusive-prefetch instructions [14]. <p> Since we have used parallel applications that are not annotated with primitives that reveal expected use of data, we feel that annotations such as those proposed in Cooperative shared memory <ref> [11] </ref>, are not needed to reduce ownership overhead effectively using static analysis. Mowry et al. [15] have developed a compiler algorithm for non-binding prefetching based on locality analysis, and extended it for shared-memory multiprocessors by taking synchronisations into account when computing the localised iteration space of a loop [13].
Reference: [12] <author> Daniel Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Continuing with the effect of varying the memory-system latencies, we first note that the latency assumptions in this study are similar to those found in machines such as the DASH <ref> [12] </ref>, although DASH services cache misses in three node-to-node traversals in situations where our protocol handles them in four.
Reference: [13] <author> Todd Mowry. </author> <title> Tolerating Latency Through SoftwareControlled Data Prefetching. </title> <type> PhD thesis, </type> <institution> Stanford University, Computer Systems Laboratory, Stanford, </institution> <address> CA 94305, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: They have found that explicit ownership requests associated with the stores can be effectively removed if inserted far ahead of the stores. To be feasible, such instructions have to be inserted by the compilerand not by the programmer. In a follow-up study, Mowry et al. <ref> [15, 13] </ref> have designed and evaluated compiler algorithms for the automatic insertion of prefetch instructions in general, and exclusive-prefetch instructions in particular. Their algorithms predict statically which load instructions cause cache misses and insert exclusive prefetch instructions if such loads are followed by a store to the same block. <p> This may prevent insertion of exclusive prefetches or cause an intolerable instruction overhead if too many exclusive-prefetch instructions are inserted. We have designed compiler algorithms that can detect and cut the ownership overhead significantly. Like the approach taken by Mowry <ref> [13] </ref>, our algorithms detect load-store sequences in the program code. Unlike their approach, however, loads followed by stores to the same address are marked and act as a hint to the cache system. <p> Mowry et al. [15] have developed a compiler algorithm for non-binding prefetching based on locality analysis, and extended it for shared-memory multiprocessors by taking synchronisations into account when computing the localised iteration space of a loop <ref> [13] </ref>. Their algorithm does nonbinding prefetching in read-only or read-exclusive mode.
Reference: [14] <author> Todd Mowry and Anoop Gupta. </author> <title> Tolerating Latency through Software-Controlled Prefetching in Scalable Shared-Memory Multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 2(4) </volume> <pages> 87-106, </pages> <year> 1991. </year>
Reference-contexts: With CICO, the programmer provides information about when a data structure is exclusively used. This information can be used by the compiler to insert instructions that prefetch an exclusive copy of the block into the cache. Mowry and Gupta have studied the use of such exclusive-prefetch instructions <ref> [14] </ref>. They have found that explicit ownership requests associated with the stores can be effectively removed if inserted far ahead of the stores. To be feasible, such instructions have to be inserted by the compilerand not by the programmer. <p> The actions taken by the cache hierarchy when a load- exclusive request is issued are as follows. If the block is present in the FLC, the data is returned to the processor and an ownership request is buffered in the FLWB. Since ownership acquisition is non-binding <ref> [14] </ref>, the processor may proceed until the next store and does not have to await ownership to be granted. If the block is not present in the FLC, however, the processor has to stall and a load-exclusive request is buffered in the FLWB.
Reference: [15] <author> Todd Mowry, Monica Lam, and Anoop Gupta. </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching. </title> <booktitle> In Proc. of ASPLOS V, </booktitle> <pages> pages 62-73, </pages> <year> 1992. </year>
Reference-contexts: They have found that explicit ownership requests associated with the stores can be effectively removed if inserted far ahead of the stores. To be feasible, such instructions have to be inserted by the compilerand not by the programmer. In a follow-up study, Mowry et al. <ref> [15, 13] </ref> have designed and evaluated compiler algorithms for the automatic insertion of prefetch instructions in general, and exclusive-prefetch instructions in particular. Their algorithms predict statically which load instructions cause cache misses and insert exclusive prefetch instructions if such loads are followed by a store to the same block. <p> Since we have used parallel applications that are not annotated with primitives that reveal expected use of data, we feel that annotations such as those proposed in Cooperative shared memory [11], are not needed to reduce ownership overhead effectively using static analysis. Mowry et al. <ref> [15] </ref> have developed a compiler algorithm for non-binding prefetching based on locality analysis, and extended it for shared-memory multiprocessors by taking synchronisations into account when computing the localised iteration space of a loop [13]. Their algorithm does nonbinding prefetching in read-only or read-exclusive mode.
Reference: [16] <author> Jaswinder Pal Singh, Wolf-Dietrich Weber, and Anoop Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <year> 1992. </year>
Reference-contexts: We have used a set of five applications developed at Stan- ford University, three of which are part of the SPLASH suite <ref> [16] </ref> (MP3D, Water, and Cholesky). We used the standard data set sizes according to the SPLASH report and that Table 1: Benchmark programs and data set sizes used.
Reference: [17] <author> Jonas Skeppstedt. </author> <title> The Design and Implementation of an Optimizing ANSI C Compiler for SPARC. </title> <type> Technical report, </type> <institution> Department of Computer Science, Lund University, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: We model a 4 Kbyte FLC and an infinite SLC, both with a block size of 32 bytes. FLC, SLC, and local memory access times are 1, 6, and 30 pclocks, respectively. 4.2 Compiler and Benchmarks We have incorporated the compiler algorithms into an opti- mising C compiler <ref> [17] </ref> which compiles parallel applications using the ANL macros [2] and generates code for shared- memory multiprocessors based on SPARC processors.
Reference: [18] <author> Per Stenstrom, Mats Brorsson, and Lars Sandberg. </author> <title> An Adaptive Cache Coherence Protocol Optimized for Migratory Sharing. </title> <booktitle> In Proc. of 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 109-118, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Unfortunately, such ownership acquisitions may stall the processor and result in substantial penalties under sequential consistency <ref> [18] </ref>. Moreover, even though the memory model is relaxed [9] the additional traffic caused by ownership acquisitions can result in memory-system contention which as a secondary effect can increase read and synchronisation penalties. Previous studies have focused on hardware-based as well as software-based approaches to remove explicit ownership requests. <p> Previous studies have focused on hardware-based as well as software-based approaches to remove explicit ownership requests. Starting with hardware-based methods, Cox and Fowler [6] and Stenstrom et al. <ref> [18] </ref> have studied adaptive cache coherence protocols that detect non-overlapping load- store sequences by different processors to the same block called migratory sharing. Detection is done by augmenting the cache coherence protocol with extra functionality to detect cache-miss requests followed by ownership requests. <p> When such sequences are detected, the block is deemed migratory. Subsequent cache-miss requests for migratory blocks will then obtain an exclusive copy of the block that eliminates explicit ownership acquisitions for the stores. Stenstrom et al. <ref> [18] </ref> found that for applications with substantial migratory sharing, most of the ownership requests were removed which reduced the execution time by as much as 35% under sequential consistency. Continuing with software-based approaches, Hill et al. have proposed a programming notation called CICO (Check- In/Check-Out) [11]. <p> This is the key idea of previously proposed adaptive cache coherence protocols which we consider next. 2.2 Adaptive Cache Coherence Protocols Cox and Fowler [6] and Stenstrom et al. <ref> [18] </ref> have proposed extensions to basic write-invalidate protocols which dynamically detect migratory sharing and for blocks deemed migratory, merge ownership requests with cache-miss requests. <p> The reduction of the execution time by removing explicit ownership requests has been evaluated by Stenstrom et al. <ref> [18] </ref>, assuming an architecture similar to the one in applications exhibiting migratory sharing and that the traffic was reduced by more than 20%. <p> Note that the cache hierarchy mechanisms needed in this case include a SLWB. In our simulations we assume that the FLWB and the SLWB contain 8 and 16 entries, respectively. Adaptive Cache Coherence Protocol Extensions The adaptive cache coherence protocol we evaluate, according to <ref> [18, 6] </ref>, extend the baseline write-invalidate protocol with a pointer of size log 2 16 = 4 bits per memory block and an extra cache state. We have evaluated two variants of the adaptive cache coherence protocols. <p> The topmost three applications (Water, Cholesky, and MP3D) are all characterised by having a fair amount of migratory sharing as observed in previous studies <ref> [6, 10, 18] </ref>. The write stall-times for B range from 2% in Water, 18% in Cholesky, and 36% in MP3D. When considering the compiler algorithms (L, C, and S) and the adaptive cache coherence protocols (DS and DM) we see that the write stall-times are almost completely eliminated. <p> Overall, the adaptive cache coherence protocols manage to cut at least 83% (Cholesky) of the write stall-time resulting in an execution-time improvement of as much as 37% in MP3D. These results conform qualitatively with those presented in <ref> [18] </ref>. Continuing with the effectiveness of the compiler algorithms, L and C are as effective in cutting the write stall-times in Water and Cholesky as DMthe adaptive cache coherence protocol that performs best. <p> To start with, if a relaxed memory consistency model would have been used, the gains of the algorithms seem at first glance nullified because the write latency can be then completely hidden [8]. However, Stenstrom et al. showed in <ref> [18] </ref> that the adaptive techniques were able to cut the network traffic by more than 20% for MP3D, Cholesky, and Water which we have used in this study.
References-found: 18

