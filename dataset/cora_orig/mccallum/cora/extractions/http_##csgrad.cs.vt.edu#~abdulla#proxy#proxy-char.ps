URL: http://csgrad.cs.vt.edu/~abdulla/proxy/proxy-char.ps
Refering-URL: http://www.cs.vt.edu/~nrg/work.html
Root-URL: http://www.cs.vt.edu
Title: WWW Proxy Traffic Characterization with Application to Caching  
Author: Ghaleb Abdulla, Edward A. Fox, Marc Abrams, Stephen Williams 
Abstract: Characterizing World Wide Web proxy traffic helps identify parameters that affect caching, capacity planning and simulation studies. In this paper we identify invariants that hold across a collection of ten traces representing traffic seen by caching-proxy servers. The traces were collected from governmental, industry, university, high school, and an online service provider environment, with request rates that range from a few accesses to millions of accesses per hour. We also show that the examined traffic is self-similar. We explore sources of Web self-similarity and we conclude that a strong source is the periodicity in the users behavior. The tests revealed that their is a strong connection between access rate from hour to hour. We also report the hit rate and weighted hit rate obtained by running a trace driven simulation on the workloads to simulate a proxy with infinite cache. similarly, accesses to unique servers and URLs are a small portion of the total. By considering these characteristics of traffic we can improve the utility of caching for WWW clients. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. F. Arlitt and C. L. Williamson. </author> <title> Web server workload characterization: The search for invariants. </title> <booktitle> In Proc. SIGMETRICS, </booktitle> <address> Philadelphia, PA, </address> <month> April </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: 1 Introduction Research to reduce network latency, enhance response time and conserve network bandwidth when accessing a World Wide Web document is very active. Simulations using server traffic <ref> [1, 2, 3] </ref> and proxy traffic [4, 5] have shown that caching will reduce latency and network usage. Understanding Web traffic is essential for performing and generalizing results of such simulations and experiments. It is important to look for workload characteristics that will hold true between different workloads. <p> Change in user behavior over a period of time may affect the Web dynamics too. 1.1 Related work Their were several studies to characterize client workload [6, 7] and server workload <ref> [1] </ref>. However, their was no study to characterize proxy traffic. This is due to the difficulty of collecting proxy log files from different sources due to the sensitivity of such logs. In [1] the authors used six different log files to characterize accesses to WWW servers. <p> dynamics too. 1.1 Related work Their were several studies to characterize client workload [6, 7] and server workload <ref> [1] </ref>. However, their was no study to characterize proxy traffic. This is due to the difficulty of collecting proxy log files from different sources due to the sensitivity of such logs. In [1] the authors used six different log files to characterize accesses to WWW servers. From the used logs the authors identified ten different invariants for web server workload. The invariants are important since they represent universal truths for all Internet Web servers. <p> a trace driven simulation for all workloads and report the hit rate and weighted hit rate for each workload. 2 Objectives In this paper we test the following hypotheses: * Hypothesis 1: We can identify invariants across proxy workloads collected from different communities, as was done for server workloads in <ref> [1] </ref>. * Hypothesis 2: Some of the identified invariants hold true over time. * Hypothesis 3: The traffic seen by a proxy is self-similar. * Hypothesis 4: A major source for the traffic self-similarity is the cyclic behavior of users over time. <p> The Korea log file was collected using a proxy server installed as the gateway to South Korea. Therefore, the logs contain all trans-Pacific traffic. 4 Proxy Workload Invariants In this section we identify invariants that hold true across the workloads studied. We follow closely the work done in <ref> [1] </ref> in establishing the invariants. However, since our workloads are for a different class of HTTP traffic, namely traffic seen at a caching-proxy server, we expect that though our invariants will overlap with the ones identified in [1], they will not be the same. <p> We follow closely the work done in <ref> [1] </ref> in establishing the invariants. However, since our workloads are for a different class of HTTP traffic, namely traffic seen at a caching-proxy server, we expect that though our invariants will overlap with the ones identified in [1], they will not be the same. Workload invariants for proxy-server traffic are listed in Table 2. These invariants are discussed in detail below. <p> This appears in table 2 as an invariant. The mean file size ranges between 7K to 27K; this is consistent with the invariant for average server file size found in <ref> [1] </ref>. This is our second invariant and also appears in Table 2. The value for third quantile is less than the average file size and the maximum file size is large when compared to the median and mean file sizes, this implies that the file size distribution is heavy tailed. <p> Graphics Files are the most accessed type in all workloads. However HTML and graphics do not represent 90% of the total accesses which is different from the servers invariants in <ref> [1] </ref>. By comparing the results from the different workloads we notice that BU (G), BU (U) and Korea follow the results reported in [1]. However, in the other workloads HTML and graphics represent less than 89%. This is especially in the DEC data which has a no type category. <p> However HTML and graphics do not represent 90% of the total accesses which is different from the servers invariants in <ref> [1] </ref>. By comparing the results from the different workloads we notice that BU (G), BU (U) and Korea follow the results reported in [1]. However, in the other workloads HTML and graphics represent less than 89%. This is especially in the DEC data which has a no type category. <p> However servers get hits from all over the world and the cyclic or periodic behavior will be weaker. This could be the reason why self-similarity was not identified as one of the invariants for the server workload in <ref> [1] </ref>. The method we have used to examine the hypothesis in [6] is not formal, and our 16 intention is not to falsify their hypothesis. We only try to show that there might be other sources for self-similarity and that it is user dependent.
Reference: [2] <author> H. Braun and K. Claffy. </author> <title> Web traffic characterization: An assessment of the impact of caching documents from NCSA's Web server. </title> <booktitle> In Proc. 2nd Int. WWW Conference, </booktitle> <address> Chicago, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Research to reduce network latency, enhance response time and conserve network bandwidth when accessing a World Wide Web document is very active. Simulations using server traffic <ref> [1, 2, 3] </ref> and proxy traffic [4, 5] have shown that caching will reduce latency and network usage. Understanding Web traffic is essential for performing and generalizing results of such simulations and experiments. It is important to look for workload characteristics that will hold true between different workloads.
Reference: [3] <author> T. Kwan, R. McGrath, and D. Reed. </author> <title> NCSA's World Wide Web server: Design and performance. </title> <journal> IEEE Computer, </journal> <volume> 28(11) </volume> <pages> 68-74, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Research to reduce network latency, enhance response time and conserve network bandwidth when accessing a World Wide Web document is very active. Simulations using server traffic <ref> [1, 2, 3] </ref> and proxy traffic [4, 5] have shown that caching will reduce latency and network usage. Understanding Web traffic is essential for performing and generalizing results of such simulations and experiments. It is important to look for workload characteristics that will hold true between different workloads.
Reference: [4] <author> M. Abrams, C. R. Standridge, G. Abdulla, S. Williams, and E. A. Fox. </author> <title> Caching proxies: Limitations and potentials. </title> <booktitle> In 4th International World-wide Web Conference, </booktitle> <pages> pages 119-133, </pages> <address> Boston, </address> <month> December </month> <year> 1995. </year> <note> &lt;URL: http://ei.cs.vt.edu/- ~succeed/WWW4/WWW4.html&gt;. </note>
Reference-contexts: 1 Introduction Research to reduce network latency, enhance response time and conserve network bandwidth when accessing a World Wide Web document is very active. Simulations using server traffic [1, 2, 3] and proxy traffic <ref> [4, 5] </ref> have shown that caching will reduce latency and network usage. Understanding Web traffic is essential for performing and generalizing results of such simulations and experiments. It is important to look for workload characteristics that will hold true between different workloads.
Reference: [5] <author> S. Williams, M. Abrams, C. R. Standridge, G. Abdulla, and E. A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <booktitle> In ACM SIGCOMM'96 Conference, </booktitle> <pages> pages 293-305, </pages> <institution> Stanford University, California, </institution> <month> August </month> <year> 1996. </year> <note> &lt;URL: http://ei.cs.vt.edu/~succeed/96sigcomm/96sigcomm.html&gt;. </note>
Reference-contexts: 1 Introduction Research to reduce network latency, enhance response time and conserve network bandwidth when accessing a World Wide Web document is very active. Simulations using server traffic [1, 2, 3] and proxy traffic <ref> [4, 5] </ref> have shown that caching will reduce latency and network usage. Understanding Web traffic is essential for performing and generalizing results of such simulations and experiments. It is important to look for workload characteristics that will hold true between different workloads. <p> The files of type compressed include files that has the name extension ZIP, GZIP, Z, etc.. This implies that for groups of clients which access these types more frequently, caching should be task or type dependent, since this will maximize weighted hit rate <ref> [5] </ref>. 6 %of accesses % of servers % of accesses % of URLs to unique accessed one to unique accessed one Workload servers time URLs time DEC1 11.2 4.9 59.2 51.0 BU (G) 1.3 0.2 1.8 0.5 Korea 1.3 0.3 2.8 1.2 VT-Lib 8.8 3.1 13.4 8.4 VT-Han 2.4 0.3 6.4
Reference: [6] <author> Mark E. Crovella and Azer Bestavros. </author> <title> Self-similarity in world wide web traffic evidence and possible causes. </title> <booktitle> In Proc. SIGMETRICS, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: Therefore, it is reasonable to assume that Web users behave differently 1 from those who use other network resources. Change in user behavior over a period of time may affect the Web dynamics too. 1.1 Related work Their were several studies to characterize client workload <ref> [6, 7] </ref> and server workload [1]. However, their was no study to characterize proxy traffic. This is due to the difficulty of collecting proxy log files from different sources due to the sensitivity of such logs. <p> The invariants in the study were used to identify two strategies for cache design and to determine the bounds on performance improvement due to each strategy. A study to test if those invariants hold true over time is necessary. In <ref> [6] </ref> and [7] the data was collected from a group of clients accessing the Web. The authors [7] in showed that many characteristics of the WWW can be modeled using power-law distributions. In [6] the authors have shown that the Web traffic have characteristics that is consistent with self-similarity. <p> A study to test if those invariants hold true over time is necessary. In <ref> [6] </ref> and [7] the data was collected from a group of clients accessing the Web. The authors [7] in showed that many characteristics of the WWW can be modeled using power-law distributions. In [6] the authors have shown that the Web traffic have characteristics that is consistent with self-similarity. They traced the reasons for Web self-similarity to the basic characteristics of information organization and retrieval. <p> Access rate, is defined as the number of accesses that a proxy gets per unit time. Bytes rate is defined as the number of bytes that a proxy sends per unit time. We used the R/S statistics and the normalized variance tests to estimate the H value <ref> [6] </ref>. For self-similar traffic H should be between 0.5 and 1. The closer H is to one, the stronger self-similarity in the tested traffic. <p> The closer H is to one, the stronger self-similarity in the tested traffic. The Boston traffic 10 ACC/Min Bytes/Min Workload R/S Var R/S Var VT-Lib 0.93 0.93 0.81 0.86 AUB 0.94 0.85 0.82 0.81 Table 8: Values for the Hurst parameter has been proven to be self-similar <ref> [6] </ref>. Self-similarity is an invariant and it is listed in Table 2. 4.7 Invariants Table 2 shows a list of the identified invariants across the workloads. Thus we establish Hypothesis 1 and 2, given in section 2. <p> We then generated a time series and plotted the autocorrelation function with different lags. Figure 6, which is the ACF plot for accesses/hour, shows that the correlation is strong and cyclic. The daily cycle is very clear in the figure; every 24 hours we get a peak. In <ref> [6] </ref> the authors tried to identify sources of self-similarity in the Web traffic by showing that transmission times may be heavy-tailed, primarily due to the distribution of Web file sizes. The transmission times correspond to the on times and user think time corresponds to the off time. <p> Multiplexing on/off times will generate a self-similar traffic. Table 8 shows that self-similarity appeared in the tested data sets to be stronger with access rate than with bytes rate; this made us question the assumption in <ref> [6] </ref>. The file sizes might not be the major cause for self-similarity. <p> However servers get hits from all over the world and the cyclic or periodic behavior will be weaker. This could be the reason why self-similarity was not identified as one of the invariants for the server workload in [1]. The method we have used to examine the hypothesis in <ref> [6] </ref> is not formal, and our 16 intention is not to falsify their hypothesis. We only try to show that there might be other sources for self-similarity and that it is user dependent. Figure 6 shows that there is a significant correlation between hourly access rate.
Reference: [7] <author> Carlos R. Cunha, Azer Bestavros, and Mark E. Crovella. </author> <title> Characteristics of www client-based traces. </title> <type> Technical Report BT-CS-95-010, </type> <institution> Dept. of Comp. Sci., Boston Univ., </institution> <address> 11 Cummington St, Boston, MA 02215, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Therefore, it is reasonable to assume that Web users behave differently 1 from those who use other network resources. Change in user behavior over a period of time may affect the Web dynamics too. 1.1 Related work Their were several studies to characterize client workload <ref> [6, 7] </ref> and server workload [1]. However, their was no study to characterize proxy traffic. This is due to the difficulty of collecting proxy log files from different sources due to the sensitivity of such logs. <p> The invariants in the study were used to identify two strategies for cache design and to determine the bounds on performance improvement due to each strategy. A study to test if those invariants hold true over time is necessary. In [6] and <ref> [7] </ref> the data was collected from a group of clients accessing the Web. The authors [7] in showed that many characteristics of the WWW can be modeled using power-law distributions. In [6] the authors have shown that the Web traffic have characteristics that is consistent with self-similarity. <p> A study to test if those invariants hold true over time is necessary. In [6] and <ref> [7] </ref> the data was collected from a group of clients accessing the Web. The authors [7] in showed that many characteristics of the WWW can be modeled using power-law distributions. In [6] the authors have shown that the Web traffic have characteristics that is consistent with self-similarity. They traced the reasons for Web self-similarity to the basic characteristics of information organization and retrieval.
Reference: [8] <author> M. Abrams and Stephen Williams. </author> <title> Complementing surveying and demographics with automated network monitoring. World Wide Web, </title> <booktitle> 1(3) </booktitle> <pages> 101-119, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: For each workload we have collected a log file that contains users' accesses to the WWW. Collection procedures differ between workloads. Workloads from Virginia Tech, Computer Science (VT-CS), Hancock Hall (VT-Han), and Library (VT-Lib) and Auburn (AUB) high school were collected using a tool called httpfilt <ref> [8] </ref>. Since the tool records all accesses from the clients to servers inside and outside the school, we used a filter to exclude accesses to local servers. This way we only examine accesses to servers outside the school which is what a caching-proxy would see.
Reference: [9] <author> G. Abdulla. </author> <title> Characterizing and Modeling World Wide Web Objects. </title> <type> PhD thesis, </type> <institution> Computer Sci. Dept., Virginia Tech, </institution> <year> 1997. </year> <title> Dissertation in Progress. </title> <type> 19 </type>
Reference-contexts: The variability in file size is due to the different file types; video and audio file sizes are typically huge compared to text files. A detailed study to characterize file sizes with statistical distributions is in progress <ref> [9] </ref>. 4.2 File types Table 4 shows the percentage of accesses for each file type in each workload. Graphics Files are the most accessed type in all workloads. However HTML and graphics do not represent 90% of the total accesses which is different from the servers invariants in [1]. <p> Invariants 5, 6, 7 and 8 should be good predictors for cache performance. Future studies to identify statistical distributions for file sizes, access rate, bytes rate, and inter-arrival time is in progress <ref> [9] </ref>. The initial results reveal that we can model some of these distributions using Weibull distribution with 0:5 &lt;= ff &lt;= 0:8. A Pareto distribution also can be used to model such distributions.
Reference: [10] <author> Jan Beran. </author> <title> Statistics for Long-Memory Process. </title> <publisher> Chapman and Hall, </publisher> <address> NewYork, NY 10119, </address> <year> 1994. </year>
Reference-contexts: These graphs can be used to test for the existence of self-similarity in the data, however it does not prove that the data has this property. The tests for self-similarity in the collected data showed that these workloads are self-similar. Table 8 shows the estimated Hurst or H parameter <ref> [10] </ref> for tested work-loads. We have generated two time series for each workload. The first one is access rate and the second is bytes rate. Access rate, is defined as the number of accesses that a proxy gets per unit time. <p> The value obtained for the Hurst parameter from the R/S plot was 0.86 and from the normalized variance plot was 0.82. For 0:5 H 1 the correlation decays to zero slowly so that 1 X (k) = 1 and the process has long memory <ref> [10] </ref>. As a result we expect that the access rate for the VT-CS data will have a strong correlation. To test for this we extracted accesses/minute, accesses/hour, accesses/day, and accesses/week. We then generated a time series and plotted the autocorrelation function with different lags.
References-found: 10

