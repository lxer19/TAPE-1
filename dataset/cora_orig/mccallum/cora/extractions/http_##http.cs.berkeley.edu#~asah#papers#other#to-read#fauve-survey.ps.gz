URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/fauve-survey.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: A Classification of Update Methods for Replicated Databases  
Author: Stefano Ceri Maurice A.W. Houtsma Arthur M. Keller Pierangela Samarati 
Date: May 5, 1994  
Affiliation: Computer Science Department Stanford University  
Abstract: In this paper we present a classification of the methods for updating replicated databases. The main contribution of this paper is to present the various methods in the context of a structured taxonomy, which accommodates very heterogeneous methods. Classes of update methods are presented through their general properties, such as the invariants that hold for them. Methods are reviewed both in their normal and abnormal behaviour (i.e., after a network partition). We show that several methods presented in the literature, sometimes in independent papers with no cross-reference, are indeed very much related, for instance because they share the same basic technique. We also show in what sense they diverge from the basic technique. This classification can serve as a basis for choosing the method that is most suitable to a specific application. It can also be used as a guideline to researchers who aim at developing new mechanisms.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Agrawal and A. </author> <title> El Abbadi "The tree quorum protocol: an efficient approach for managing replicated data," </title> <booktitle> in Proc. 16th Int. Conf. on VLDB, </booktitle> <address> Brisbane, </address> <month> Aug. </month> <year> 1990, </year> <pages> pp. 243-254. </pages>
Reference-contexts: This algorithm assumes that it is possible to determine the `recentness' of an item, for instance, by having a timestamp associated to each item. Note that the quorum is formed dynamically for each transaction. TQP Tree Quorum Protocol <ref> [1, 2] </ref>. For each item, a logical tree is defined on its copies. For each data item a read/write quorum is defined in the following way.
Reference: [2] <author> D. Agrawal and A. El Abbadi, </author> <title> "Efficient techniques for replicated data management," </title> <booktitle> Proc. of the Workshop on Management of Replicated Data, </booktitle> <address> Houston, TX, </address> <month> Nov. </month> <year> 1990, </year> <pages> pp. 48-52. </pages>
Reference-contexts: This algorithm assumes that it is possible to determine the `recentness' of an item, for instance, by having a timestamp associated to each item. Note that the quorum is formed dynamically for each transaction. TQP Tree Quorum Protocol <ref> [1, 2] </ref>. For each item, a logical tree is defined on its copies. For each data item a read/write quorum is defined in the following way.
Reference: [3] <author> R. Alonso, D. Barbara. H. Garcia Molina, S. Abad, "Quasi-copies: </author> <title> efficient data sharing for information retrieval systems," </title> <booktitle> Proc. of the Int. Conf. on Extending Data Base Technology, </booktitle> <address> EDBT'88. </address>
Reference-contexts: Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., <ref> [3, 18, 24, 25, 29] </ref>). These protocols have very different origins; some of them were designed in academic or research environments, but many others were designed by engineers while developing advanced applications. This paper presents a critical overview of protocols for updating replicated databases. <p> ASAP As Soon As Possible [7]. Write operations are executed on the primary copy. Committed writes are collected and sent to all other copies as independent transactions. QUC Quasi Copies <ref> [3] </ref>. Information is controlled at a single central site, but the methods can also be applied in case of multiple central sites. Coherency conditions associated with a copy define the allowable deviations between an object and the copy. Coherency conditions can be related to time, version, or value.
Reference: [4] <author> D. Barbara, H. Garcia-Molina, </author> <title> The demarcation protocol: a technique for maintaining arithmetic constraints in distributed database systems, </title> <institution> CS-TR-320-91, Princeton University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: In practice, several algorithms are used for this. One-copy serializability should be guaranteed by the reconciliation algorithm, which brings the database into a single consistent state. A particular example of such an algorithm is the demarcation protocol <ref> [4] </ref>. It does not treat copies as true replicas anymore, but as independent copies. Local constraints are then formulated on each copy, which ensures that the independent copies can be merged again into a single logical copy later on.
Reference: [5] <author> D. Barbara, H. Garcia-Molina, </author> <title> "The case for controlled inconsistency in replicated data," </title> <booktitle> Proc. of the Workshop on Management of Replicated Data, </booktitle> <address> Houston, TX, </address> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: supported by the LOGIDATA+ project of CNR Italy. y The research of Maurice Houtsma has been made possible by a fellowship of the Royal Netherlands Academy of Arts and Sciences. z On leave from the University of Milan, supported by a scholarship from the Rotary Foundation 1 the applications' semantics <ref> [5] </ref>. Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., [3, 18, 24, 25, 29]). <p> Contrary to QC and TQP, VP works with a fixed quorum assignment; the quorum can, therefore, not be adapted in case of failures. MAR Multi-Airline Reservation Updates are executed independently on different copies and conflicts have to be resolved later <ref> [5] </ref>. In practice, several algorithms are used for this. One-copy serializability should be guaranteed by the reconciliation algorithm, which brings the database into a single consistent state. A particular example of such an algorithm is the demarcation protocol [4].
Reference: [6] <author> P.A. Bernstein, N. Goodman, </author> <title> "An algorithm for concurrency control and recovery in replicated distributed databases," </title> <journal> ACM TODS, </journal> <volume> 9(4), </volume> <month> Dec. </month> <year> 1984, </year> <pages> pp. 596-615. 15 </pages>
Reference-contexts: Also, all primary/backup methods are order preserving and 1-safe. To some extend all methods are recoverable, we will go into this in Sec. 4. ROWA Read One Write All <ref> [6] </ref>. A read operation may be executed on an arbitrary copy.
Reference: [7] <author> P.A. Bernstein, V. Hadzilacos, N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: This has consequences, e.g., for the implementation of commit; each transaction has to check that its view of the system is still correct, to avoid one transaction updating an item inaccessible to another transaction and vice versa. DOAC Directory-Oriented Available Copies <ref> [7] </ref>. A directory of a data item consists of the references to the set of copies of that data item. Like a data item, a directory may be replicated to increase availability. <p> Thereby, updating an `old' value is avoided. After updating the data item at the site of the transaction, the update is executed as a separate transaction at the other sites. ASAP As Soon As Possible <ref> [7] </ref>. Write operations are executed on the primary copy. Committed writes are collected and sent to all other copies as independent transactions. QUC Quasi Copies [3]. Information is controlled at a single central site, but the methods can also be applied in case of multiple central sites.
Reference: [8] <author> S. Ceri, M.A.W. Houtsma, A.M. Keller, and P. Samarati, </author> <title> "A theory of independent updates and recovery," </title> <note> in preparation. </note>
Reference: [9] <author> S. Ceri and G. Pelegatti, </author> <title> Distributed database systems, </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: Protocols are analyzed in their normal operation, when the distributed database is functioning correctly, and in their abnormal operation, when failures occur. In particular, the most significant kind of failure that can affect a replicated database is a network partitioning <ref> [9] </ref>. It occurs when some nodes of the database are disconnected, though operational, and can perform conflicting updates. Strategies for dealing with network partitions are, therefore, analyzed.
Reference: [10] <author> A. Chan, D. Skeen, </author> <title> The reliability subsystem of a distributed database manager, </title> <type> Tech. Rep. </type> <institution> CCA-85-02, Computer Corporation of America, </institution> <year> 1986. </year>
Reference-contexts: any in snapshot read any in snapshot read any in snapshot read any in snapshot read any after recover ing consistency partially inconsistent N/A read any read any read any read any read any Table 1: Read action in order to achieve answers' properties ROWAA Read One Write All Available <ref> [10, 17] </ref>. A read operation may be executed on an arbitrary copy. A write operation does not write all copies of the item: it ignores any copies that are down. Thereby, the problem of not-up-to-date copies is introduced.
Reference: [11] <author> D.L. Eager, </author> <title> Robust concurrency control in distributed databases, </title> <type> Tech. Rep. </type> <institution> CSRG #135, Computer System Research Group, University of Toronto, </institution> <month> Oct. </month> <year> 1981. </year>
Reference-contexts: Execution of the actual read and write operations is as described for Quorum Consensus. Note that also here a quorum is formed dynamically. MW Missing Writes <ref> [11, 12] </ref>. The assumption is made that a system knows reliable and failure periods of operation. During a reliable period, i.e., the system functions without any failure, Read One Write All is used. When a failure occurs, a switch is made to using Quorum Consensus.
Reference: [12] <author> D.L. Eager, K.C. Sevcik, </author> <title> "Achieving robustness in distributed database systems," </title> <journal> ACM-TODS, </journal> <volume> 8(3), </volume> <month> Sept. </month> <year> 1983, </year> <pages> pp. 354-381. </pages>
Reference-contexts: Execution of the actual read and write operations is as described for Quorum Consensus. Note that also here a quorum is formed dynamically. MW Missing Writes <ref> [11, 12] </ref>. The assumption is made that a system knows reliable and failure periods of operation. During a reliable period, i.e., the system functions without any failure, Read One Write All is used. When a failure occurs, a switch is made to using Quorum Consensus.
Reference: [13] <author> A. El Abbadi, D. Skeen, F. Christian, </author> <title> "An efficient fault-tolerant protocol for replicated data management," </title> <booktitle> Proc. 4th ACM SIGACT-SIGMOD Symp. on Principles of Database Systems, </booktitle> <address> Portland, OR, </address> <month> March </month> <year> 1985, </year> <pages> pp. 215-228. </pages>
Reference-contexts: VP Virtual Partition <ref> [13, 14] </ref>. Each site maintains a view consisting of the sites it believes it can communicate with. Within each view Read One Write All is used. A transaction is initiated at a given site.
Reference: [14] <author> A. El Abbadi, S. Toueg, </author> <title> "Availability in partitioned replicated databases," </title> <booktitle> Proc 5th ACM SIGACT-SIGMOD Symp. on Principles of Database Systems, </booktitle> <address> Cambridge, MA, </address> <month> March </month> <year> 1986, </year> <pages> pp. 240-251. </pages>
Reference-contexts: VP Virtual Partition <ref> [13, 14] </ref>. Each site maintains a view consisting of the sites it believes it can communicate with. Within each view Read One Write All is used. A transaction is initiated at a given site.
Reference: [15] <author> H. Garcia-Molian and K. </author> <booktitle> Salem "Sagas" Proc. ACM Sigmod, </booktitle> <year> 1987, </year> <pages> pp. 249-259 </pages>
Reference-contexts: Strategies for dealing with network partitions are, therefore, analyzed. We concentrate here on update methods, and do not study the related problem of executing corrective actions when constraints do not hold anymore after temporary failures <ref> [15, 26] </ref>. This paper is organized as follows. In Section 2 we classify the update strategies, and describe the properties (also called invariants) that hold for each class of update strategy.
Reference: [16] <author> D.K. Gifford, </author> <title> "Weighted voting for replicated data," </title> <booktitle> Proc. 7th ACM-SIGOPS Symp. on Operating Systems Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Dec. </month> <year> 1979, </year> <pages> pp. 150-159. </pages>
Reference-contexts: Note that this last step ensures one-copy serializability, as it guarantees that logical conflicts are reflected on physical copies. Also in this algorithm, all sites need to agree on the status table reflecting the sites that are up. QC Quorum Consensus <ref> [16, 20] </ref>. A non-negative weight is assigned to each copy of a data item.
Reference: [17] <author> N. Goodman, D. Skeen, A. Chan, U. Dayal, S. Fox, D. Ries, </author> <title> "A recovery algorithm for a distributed database system," </title> <booktitle> Proc. 2nd ACM SIGACT-SIGMOD, Symp. Database System Atlanta, </booktitle> <address> GA, </address> <month> March </month> <year> 1983, </year> <pages> pp. 8-15. </pages>
Reference-contexts: any in snapshot read any in snapshot read any in snapshot read any in snapshot read any after recover ing consistency partially inconsistent N/A read any read any read any read any read any Table 1: Read action in order to achieve answers' properties ROWAA Read One Write All Available <ref> [10, 17] </ref>. A read operation may be executed on an arbitrary copy. A write operation does not write all copies of the item: it ignores any copies that are down. Thereby, the problem of not-up-to-date copies is introduced.
Reference: [18] <author> J.N. Gray, M. Anderton, </author> <title> "Distributed computer systems: four case studies", </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 75, No. 5, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., <ref> [3, 18, 24, 25, 29] </ref>). These protocols have very different origins; some of them were designed in academic or research environments, but many others were designed by engineers while developing advanced applications. This paper presents a critical overview of protocols for updating replicated databases. <p> The main difference between RBP and RDF is the parallelism that may be introduced by not enforcing commits at the backup site to be in proper ticket order. DIP Disaster protection <ref> [18] </ref> All data items are fully replicated over all sites. Duplexed disks are used on each site to protect against disk crashes. Local updates are executed after checking the timestamp of the data item with time stamps of the copies of the data item on other sites.
Reference: [19] <author> R.P. King, N. Halim, H. Garcia-Molina, </author> <title> C.A. Polyzois, "Management of a remote backup copy for disaster recovery", </title> <journal> ACM-TODS, </journal> <volume> 16(2), </volume> <month> June </month> <year> 1991, </year> <pages> pp. 338-368. </pages>
Reference-contexts: It is not 2-safe but only 1-safe. If the primary site fails and some of its messages regarding committed transactions are lost, the backup site is not aware of these committed transactions and they are not executed. RBP Remote Backup Procedure <ref> [19] </ref> The database system is assumed to consist of a primary site and a backup site. Each site is composed of many stores, among which the data are partitioned. At the primary site two-phase commit is used, and each transaction is assigned a ticket upon its completion.
Reference: [20] <author> A. Kumar and A. </author> <title> Segev "Optimizing voting-type algorithms for replicated data," </title> <booktitle> in Advances in Database Technology-EDBT'88, </booktitle> <editor> J.W. Schmidt, S. Ceri, and M. Missikoff (Eds.), </editor> <volume> LNCS 303, </volume> <year> 1988, </year> <pages> pp. 428-442. </pages>
Reference-contexts: Note that this last step ensures one-copy serializability, as it guarantees that logical conflicts are reflected on physical copies. Also in this algorithm, all sites need to agree on the status table reflecting the sites that are up. QC Quorum Consensus <ref> [16, 20] </ref>. A non-negative weight is assigned to each copy of a data item.
Reference: [21] <author> B. Lindsay, L. Haas, C. Mohan, H. Pirahesh, and P. Wilms, </author> <title> "A snapshot differential refresh algorithm," </title> <booktitle> Proc. ACM Sigmod, </booktitle> <year> 1986, </year> <pages> pp. 53-60. </pages>
Reference-contexts: The time of update depends on the algorithm, for instance, it can be on time of access of replica, on user demand, or periodically. DR Differential refresh <ref> [21] </ref> A timestamp is associated with tuples at the base table. To each copy, a snaptime is associated, which reflects the time when it was last refreshed. To each tuple in the copy an address is associated stating where the corresponding base tuple is stored.
Reference: [22] <author> T. Minoura and G. Wiederhold. </author> <title> "Resilient extended true-copy token scheme for a distributed database," </title> <journal> IEEE TSE, </journal> <volume> Vol. 8, No. 3, </volume> <pages> pp. 173-189. </pages>
Reference-contexts: The address space between the current address and the previous tuple is guaranteed to be empty. This information can be used when updating the copy. 8 CT Copy token <ref> [22] </ref> Each item is associated a logical copy and a set of physical copies. Writes are enforced on the logical copy and buffered until commit time, only then are they actually executed on the physical copies.
Reference: [23] <author> C. Pu, A. Leff, </author> <title> "Replica control in distributed systems: an asynchronous approach,", </title> <booktitle> Proc. </booktitle> <address> ACM-SIGMOD'91, Denver, CO, </address> <month> May </month> <year> 1991. </year> <month> 16 </month>
Reference-contexts: However, all these features are compromised if all the copies are written atomically, because the write protocol requires all copies to be available at each write operation <ref> [23] </ref>. Requirements of applications accessing replicated data seldom insist that all copies be updated atomically.
Reference: [24] <author> C. Pu and A. Leff, </author> <title> "Replica control in distributed systems: an asynchronous approach," </title> <type> Technical report No. </type> <institution> CUCS-053-90, Columbia University, </institution> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., <ref> [3, 18, 24, 25, 29] </ref>). These protocols have very different origins; some of them were designed in academic or research environments, but many others were designed by engineers while developing advanced applications. This paper presents a critical overview of protocols for updating replicated databases.
Reference: [25] <author> C. Pu and A. Leff, "Epsilon-Serializability," </author> <type> Technical report No. </type> <institution> CUCS-054-90, Columbia University, </institution> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., <ref> [3, 18, 24, 25, 29] </ref>). These protocols have very different origins; some of them were designed in academic or research environments, but many others were designed by engineers while developing advanced applications. This paper presents a critical overview of protocols for updating replicated databases.
Reference: [26] <author> A. Reuter and H. Wachter, </author> <title> "The contract model," </title> <journal> IEEE Database Engineering bulletin Vol. </journal> <volume> 14, No. 1, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: Strategies for dealing with network partitions are, therefore, analyzed. We concentrate here on update methods, and do not study the related problem of executing corrective actions when constraints do not hold anymore after temporary failures <ref> [15, 26] </ref>. This paper is organized as follows. In Section 2 we classify the update strategies, and describe the properties (also called invariants) that hold for each class of update strategy.
Reference: [27] <author> S.K. Sarin, C.W. Kaufman, and J.E. Somers, </author> <title> "Using history information to process delayed database updates," </title> <booktitle> Proc. 12th Int. Conf. on Very Large Data Bases, </booktitle> <address> Kyoto, Japan, </address> <year> 1986. </year>
Reference: [28] <author> D.G. Severance, G. Lohman, </author> <title> "Differential files: their application to the maintenance of large databases," </title> <journal> ACM-TODS, </journal> <volume> 1(3), </volume> <month> Sept. </month> <year> 1976. </year>
Reference-contexts: The values are installed when convenient. DF Differential File <ref> [28] </ref> A differential file is used to record the changes made on the primary copy, this differential file is then used to update the copies. The time of update depends on the algorithm, for instance, it can be on time of access of replica, on user demand, or periodically.
Reference: [29] <author> Tandem Computers. </author> <title> Remote Duplicate Database Facility (RDF) System Management Manual, </title> <month> March </month> <year> 1987. </year> <month> 17 </month>
Reference-contexts: Therefore, several protocols have been developed in distributed databases for updating replicated data without strictly requiring that all copies be atomically and synchronously updated (see, e.g., <ref> [3, 18, 24, 25, 29] </ref>). These protocols have very different origins; some of them were designed in academic or research environments, but many others were designed by engineers while developing advanced applications. This paper presents a critical overview of protocols for updating replicated databases. <p> Copies can exchange information about their updates, thereby integrating update information from other sites. In this way the database may be brought to a fully consistent and up-to-date state. Hence, again it is the reconciliation algorithm that should guarantee one-copy serializability. RDF Remote Duplicate Database Facility. <ref> [29] </ref> The database system is assumed to consist of a primary site and a backup site. At the primary site, undo/redo log entries are written in a master log for every transaction. As this log is written, a copy is sent to a control process at the backup site.
References-found: 29

