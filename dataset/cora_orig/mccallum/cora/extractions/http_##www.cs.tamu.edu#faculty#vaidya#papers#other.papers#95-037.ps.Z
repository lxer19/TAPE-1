URL: http://www.cs.tamu.edu/faculty/vaidya/papers/other.papers/95-037.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/Vaidya-other.html
Root-URL: http://www.cs.tamu.edu
Email: E-mail: fjhkim,vaidyag@cs.tamu.edu  
Title: Towards an Adaptive Distributed Shared Memory (Preliminary Version 2 Web: http://www.cs.tamu.edu/faculty/vaidya/ Index Terms: distributed shared
Author: Jai-Hoon Kim Nitin H. Vaidya 
Date: September 1995  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Pubnum: Technical Report 95-037  
Abstract: The focus of this report is on software implementations of Distributed Shared Memory (DSM). In the recent years, many protocols for implementing DSM have been proposed. The protocols can be broadly divided into two classes: invalidation-based schemes and update-based schemes. Performance of these protocols depends on the memory access behavior of the applications. Some researchers have proposed DSMs that provide a family of consistency protocols or application specific protocols, and the programmer is allowed to choose any one of them for each shared memory object (or page) or each stage of an application. While such implementations have a potential for achieving optimal performance, they impose undue burden on the programmer. An adaptive implementation that automatically chooses the appropriate protocol for each shared memory page (at run-time) will ease the task of programming for DSM. This report presents a simple approach for implementing adaptive DSMs. The approach is illustrated with the example of an adaptive DSM based on the competitive update protocol. The objective of the adaptive scheme is to minimize a pre-defined "cost" function. The cost functions considered here are number of messages and size of messages. (Other cost functions can also be used similarly.) The proposed scheme allows each node to independently choose (at run-time) a different protocol for each page. The report presents preliminary evaluation of the adaptive DSM. Preliminary results shows that the performance is improved by dynamically selecting the appropriate protocol. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Karlin et al., </author> <title> "Competitive snoopy caching," </title> <booktitle> in Proc. of the 27'th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 244-254, </pages> <year> 1986. </year>
Reference-contexts: Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol <ref> [1, 9, 14, 10] </ref>. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. <p> Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. The preliminary experiments show that our approach can indeed reduce the cost, thus motivating further work. This report is organized as follows. Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple <p> Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple implementation of a write-update protocol is likely to be inefficient, because many copies of a page may be updated, even if some of them are not going to be accessed in the near future. <p> Munin [7] incorporates a time-out mechanism to invalidate those copies of a page which have not been accessed by a node for a long time. <ref> [1, 9, 14, 10] </ref> present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many times" without an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to [7], is as follows: the <p> Quarks [16] also incorporates a mechanism similar to that presented in <ref> [1, 9, 14, 10] </ref>. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. This section presents details of the implementation, and 3 also discusses some generalizations of the basic competitive update protocol. The adaptive scheme uses these generalizations of the original protocol. <p> Thus, the competitive update protocol invalidates those pages that are accessed "less frequently" the protocol can be tuned to a given application by a proper choice of limit L <ref> [1, 9, 14, 10] </ref>. 6 In case of write-sharing, a local copy of a page should not be invalidated if local copy has been modified (the modification needs to be sent to the other nodes). 5 As discussed later, the limit can also be changed dynamically (at run-time) to adapt to <p> Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 [7] to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes <ref> [2, 1, 9, 14, 10] </ref>, implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). The basic competitive protocol can be generalized in four ways, as summarized below.
Reference: [2] <author> J. Archibald, </author> <title> "A cache coherence approach for large multiprocessor systems," </title> <booktitle> in International Conference on Supercomputing, </booktitle> <pages> pp. 337-345, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 [7] to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes <ref> [2, 1, 9, 14, 10] </ref>, implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). The basic competitive protocol can be generalized in four ways, as summarized below. <p> The scheme in [26] makes use of such information to determine whether a copy of the page should be updated or invalidated. * Dynamic cache coherence approach presented by Archibald <ref> [2] </ref> dynamically chooses to update or invalidate copies of a shared data object. If there are three writes by a single processor without intervening references by any other processor, all other cached copies are invalidated. * Optimizations for migratory sharing have also been proposed [8, 29, 9, 22].
Reference: [3] <author> B. Falsafi et al., </author> <title> "Application-specific protocols for user-level shared memory," </title> <booktitle> in International Conference on Supercomputing, </booktitle> <pages> pp. 380-389, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: not seem to decrease once it has increased. 30 The adaptive protocol proposed in this report can detect all relevant 13 local accesses (read as well as write), and the limit is changed based on access patterns in the previous sampling period (the limit may decrease or increase). * Tempest <ref> [27, 3] </ref> allows programmers and compilers to use user-level mechanism to implement shared memory "policies" that are appropriate to a particular program or data structure.
Reference: [4] <author> J. Bennett, J. Carter, and W. Zwaenepoel, </author> <title> "Adaptive software cache management for distributed shared memory architectures," </title> <booktitle> in Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 125-134, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: For simplicity, in the present discussion, we do not consider the messages required to perform an acquire. 9 Segment is a sequence of remote updates between two consecutive local accesses. Write-run [13] and no-synch run <ref> [4] </ref> models are introduced by others. A write-run is a sequence of local writes between two consecutive remote accesses. no-synch run is a sequence of accesses to a single object by any thread between two synchronization points in a particular thread.
Reference: [5] <author> R. Bianchini and T. LeBlanc, </author> <title> "Software caching on cache-coherent multiprocessors," </title> <booktitle> in Proceedings of International Conference on Parallel and Distributed Processing, </booktitle> <pages> pp. 521-526, </pages> <year> 1992. </year>
Reference-contexts: the shared pages are updated with the local images by invoking the define global system call. * Bianchini and LeBlanc address software caching which can adapt to changes in memory reference behavior by making a new copy of data and repartitioning the data as needed for each phase of execution <ref> [5] </ref>. * [21] presents a flexible communication mechanism. Their scheme uses a programmable node controller, called MAGIC.
Reference: [6] <author> J. Carter, D. Khandekar, and L. Kamb, </author> <title> "Distributed shared memory: Where we are and where we should be headed," </title> <booktitle> in Proc. of the Fifth Workshop on Hot Topics in Operating Systems, </booktitle> <pages> pp. 119-122, </pages> <month> May </month> <year> 1995. </year> <month> 34 </month>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> We implemented the protocol by modifying another DSM, Quarks (Beta release 0.8) <ref> [16, 6] </ref>. The performance evaluation is in progress. This section presents some preliminary results. Methodology We executed a synthetic application qtest with the adaptive DSM. (Other benchmark applications will also be evaluated.) qtest is a simple shared memory access application: all nodes access the shared data concurrently.
Reference: [7] <author> J. B. Carter, </author> <title> Efficient Distributed Shared Memory Based On Multi-Protocol Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> Many approaches have been proposed to implement distributed shared memory [7, 12, 19, 30, 16, 6, 15, 26, 9, 27]. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency <ref> [7] </ref>. As no single protocol is optimal for all applications, researchers have proposed DSM implementations that provide a choice of multiple consistency protocols (e.g. [7]). The programmer may specify the appropriate protocol to be used for each shared memory object (or page). <p> The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency <ref> [7] </ref>. As no single protocol is optimal for all applications, researchers have proposed DSM implementations that provide a choice of multiple consistency protocols (e.g. [7]). The programmer may specify the appropriate protocol to be used for each shared memory object (or page). While this approach has the potential for achieving good performance, it imposes undue burden on the programmer. <p> Munin <ref> [7] </ref> incorporates a time-out mechanism to invalidate those copies of a page which have not been accessed by a node for a long time. [1, 9, 14, 10] present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many <p> for a long time. [1, 9, 14, 10] present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many times" without an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to <ref> [7] </ref>, is as follows: the decision mechanism used in this approach (to determine when to invalidate a page) is dependent only on the application's access pattern, instead of real time as in Munin [7]. Quarks [16] also incorporates a mechanism similar to that presented in [1, 9, 14, 10]. <p> an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to <ref> [7] </ref>, is as follows: the decision mechanism used in this approach (to determine when to invalidate a page) is dependent only on the application's access pattern, instead of real time as in Munin [7]. Quarks [16] also incorporates a mechanism similar to that presented in [1, 9, 14, 10]. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. <p> Information Structure We assume an implementation that is similar to Munin <ref> [7] </ref> and Quarks [16], with a few modifications to facilitate competitive updates. Each node maintains an information structure for each page resident in its memory. <p> In general, a node 4 A simple optimization can avoid clearing the counter on every local access. 5 Quarks Beta release 0.8. 4 may not know exactly which other nodes have a copy of the page <ref> [7] </ref>. However, when a node updates remote copies of a page (when it does a release ), at the end of the update procedure, that node knows precisely the set of nodes, that hold the copies of the page, that were updated. <p> The "updater" node collects this information by means of acknowledgment messages sent as a part of the update procedure. * probOwner: Points towards the "owner" of the page <ref> [7] </ref>. On a page fault, a node requests the page from the probOwner. If the probOwner does not have a copy of the page, it forwards the request to its probOwner. The request is thus forwarded until a node having a copy of the page is reached. <p> Subsequently, node 0 performs two acquire-write-release sequences, at the end of which, the update-counter at node 1 becomes 3 (column 23). Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 <ref> [7] </ref> to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes [2, 1, 9, 14, 10], implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). <p> By setting the limit to 1, the competitive update protocol becomes similar to the invalidate protocol, while the protocol is equivalent to the traditional update protocol when limit is infinity (or large). Thus, the generalized competitive update protocol can effectively be used as a "multiple" consistency protocol <ref> [7] </ref>, simply by using a different limit for each page. * If the access pattern to the same page is different for different nodes, a "hybrid" protocol [24] is more appropriate than a "pure" protocol. <p> Algorithms (i) and (ii) are similar to multiple protocols in <ref> [7, 16] </ref>, and (iii) is similar to our adaptive protocols which can choose the appropriate protocol at run-time. <p> Tempest consists of four types of mechanisms (low-overhead messaging, bulk data transfer, virtual memory management, and fine-grained memory access control). * Munin <ref> [7] </ref> incorporates an update timeout mechanism. The main idea of this mechanism is to invalidate local copy of a page that has not been accessed for a certain period of time, freeze time, after it was last updated. <p> Whereas the time limit, freeze time, is fixed in Munin, our adaptive protocol can adapt to time-varying memory access patterns by changing the update limit at run-time. * Multiple consistency protocol was proposed in <ref> [7, 16] </ref>. Several categories of shared data objects are identified: conventional, read-only, migratory, write-shared, and synchronization. They developed many memory coherence techniques that perform efficiently for these categories of shared data objects.
Reference: [8] <author> A. Cox and R. Fowler, </author> <title> "Adaptive cache coherency for detecting migratory shared data," </title> <booktitle> in Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 98-108, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: If there are three writes by a single processor without intervening references by any other processor, all other cached copies are invalidated. * Optimizations for migratory sharing have also been proposed <ref> [8, 29, 9, 22] </ref>. <p> These protocols dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. <ref> [8, 29] </ref> are based on invalidate protocol, and [22, 9] are based on competitive update protocol. * Quarks [16] limits the number of updates independently for each page and each copy. If a copy of the page is updated more than limit times without local access, the copy is invalidated.
Reference: [9] <author> F. Dahlgren, M. Dubois, and P. Stenstrom, </author> <title> "Combined performance gains of simple cache protocol extentions," </title> <booktitle> in Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 187-197, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol <ref> [1, 9, 14, 10] </ref>. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. <p> Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. The preliminary experiments show that our approach can indeed reduce the cost, thus motivating further work. This report is organized as follows. Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple <p> Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple implementation of a write-update protocol is likely to be inefficient, because many copies of a page may be updated, even if some of them are not going to be accessed in the near future. <p> Munin [7] incorporates a time-out mechanism to invalidate those copies of a page which have not been accessed by a node for a long time. <ref> [1, 9, 14, 10] </ref> present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many times" without an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to [7], is as follows: the <p> Quarks [16] also incorporates a mechanism similar to that presented in <ref> [1, 9, 14, 10] </ref>. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. This section presents details of the implementation, and 3 also discusses some generalizations of the basic competitive update protocol. The adaptive scheme uses these generalizations of the original protocol. <p> Thus, the competitive update protocol invalidates those pages that are accessed "less frequently" the protocol can be tuned to a given application by a proper choice of limit L <ref> [1, 9, 14, 10] </ref>. 6 In case of write-sharing, a local copy of a page should not be invalidated if local copy has been modified (the modification needs to be sent to the other nodes). 5 As discussed later, the limit can also be changed dynamically (at run-time) to adapt to <p> Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 [7] to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes <ref> [2, 1, 9, 14, 10] </ref>, implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). The basic competitive protocol can be generalized in four ways, as summarized below. <p> If there are three writes by a single processor without intervening references by any other processor, all other cached copies are invalidated. * Optimizations for migratory sharing have also been proposed <ref> [8, 29, 9, 22] </ref>. <p> These protocols dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [8, 29] are based on invalidate protocol, and <ref> [22, 9] </ref> are based on competitive update protocol. * Quarks [16] limits the number of updates independently for each page and each copy. If a copy of the page is updated more than limit times without local access, the copy is invalidated.
Reference: [10] <author> F. Dahlgren and P. Stenstrom, </author> <title> "Using write caches to improve performance of cache coherence protocols in shared-memory multiprocessors," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 26, </volume> <pages> pp. 193-210, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol <ref> [1, 9, 14, 10] </ref>. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. <p> Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. The preliminary experiments show that our approach can indeed reduce the cost, thus motivating further work. This report is organized as follows. Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple <p> Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple implementation of a write-update protocol is likely to be inefficient, because many copies of a page may be updated, even if some of them are not going to be accessed in the near future. <p> Munin [7] incorporates a time-out mechanism to invalidate those copies of a page which have not been accessed by a node for a long time. <ref> [1, 9, 14, 10] </ref> present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many times" without an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to [7], is as follows: the <p> Quarks [16] also incorporates a mechanism similar to that presented in <ref> [1, 9, 14, 10] </ref>. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. This section presents details of the implementation, and 3 also discusses some generalizations of the basic competitive update protocol. The adaptive scheme uses these generalizations of the original protocol. <p> Thus, the competitive update protocol invalidates those pages that are accessed "less frequently" the protocol can be tuned to a given application by a proper choice of limit L <ref> [1, 9, 14, 10] </ref>. 6 In case of write-sharing, a local copy of a page should not be invalidated if local copy has been modified (the modification needs to be sent to the other nodes). 5 As discussed later, the limit can also be changed dynamically (at run-time) to adapt to <p> Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 [7] to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes <ref> [2, 1, 9, 14, 10] </ref>, implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). The basic competitive protocol can be generalized in four ways, as summarized below.
Reference: [11] <author> C. Dubnicki and T. LeBlanc, </author> <title> "Adjustable block size coherent caches," </title> <booktitle> in Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 170-180, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Their protocol allows multiple copies of a shared data block in a hierarchical network with minimum cache coherence overhead by dynamically partitioning the network into sharing and nonsharing regions based on program behavior. * Adjustable block size coherent caching scheme is proposed by C. Dubnicki and T. LeBlanc <ref> [11] </ref>. Their cache structure dynamically adjusts the cache block size according to recently observed reference behavior.
Reference: [12] <author> S. Eggers and R. Katz, </author> <title> "A characterization of sharing in parallel prograns and its application to coherency protocol evaluation," </title> <booktitle> in Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 373-382, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7].
Reference: [13] <author> S. J. Eggers, </author> <title> "Simplicity versus accuracy in a model of cache coherency overhead," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 40, </volume> <pages> pp. 893-906, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: Three possibilities for the cost metric are: * The number of messages. * The amount of data transferred. * Execution time. The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 <ref> [30, 13, 31] </ref> present similar cost analysis for coherency overhead. [30] is based on read to write ratio and fault ratio, and [13] is based on the write-run model. [31] associates different costs with different events (such as cache hit, invalidate, update, and cache load). <p> The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 [30, 13, 31] present similar cost analysis for coherency overhead. [30] is based on read to write ratio and fault ratio, and <ref> [13] </ref> is based on the write-run model. [31] associates different costs with different events (such as cache hit, invalidate, update, and cache load). Our approach is based on the number of updates by other nodes between consecutive local accesses. <p> For simplicity, in the present discussion, we do not consider the messages required to perform an acquire. 9 Segment is a sequence of remote updates between two consecutive local accesses. Write-run <ref> [13] </ref> and no-synch run [4] models are introduced by others. A write-run is a sequence of local writes between two consecutive remote accesses. no-synch run is a sequence of accesses to a single object by any thread between two synchronization points in a particular thread. <p> A write-run is a sequence of local writes between two consecutive remote accesses. no-synch run is a sequence of accesses to a single object by any thread between two synchronization points in a particular thread. The write-run model was presented by Eggers <ref> [13] </ref> to predict the cache coherency overhead for a bus based multiprocessor system.
Reference: [14] <author> H. Grahn, P. Stenstrom, and M. Dubois, </author> <title> "Implementation and evaluation of update-based cache protocols under relaxed memory consistency models," </title> <journal> Future Generation Computer Systems, </journal> <volume> vol. 11, </volume> <pages> pp. 247-271, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol <ref> [1, 9, 14, 10] </ref>. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. <p> Our goal is to determine the appropriate value of the limit so as to minimize a pre-defined "cost" metric. The preliminary experiments show that our approach can indeed reduce the cost, thus motivating further work. This report is organized as follows. Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple <p> Section 2 summarizes the competitive update protocol <ref> [1, 9, 14, 10] </ref> and its generalizations. The proposed adaptive protocol is presented in Section 3. Section 4 shows the performance evaluation of the proposed scheme. Related work is discussed in Section 6. Section 7 concludes the report. 2 Competitive Update Protocol [1, 9, 14, 10] and Its Generalizations A simple implementation of a write-update protocol is likely to be inefficient, because many copies of a page may be updated, even if some of them are not going to be accessed in the near future. <p> Munin [7] incorporates a time-out mechanism to invalidate those copies of a page which have not been accessed by a node for a long time. <ref> [1, 9, 14, 10] </ref> present competitive-update mechanisms to invalidate a copy of a page at a node, if the copy is updated by other nodes "too many times" without an intervening local access. ([2] presents a similar scheme.) The advantage of this approach, as compared to [7], is as follows: the <p> Quarks [16] also incorporates a mechanism similar to that presented in <ref> [1, 9, 14, 10] </ref>. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. This section presents details of the implementation, and 3 also discusses some generalizations of the basic competitive update protocol. The adaptive scheme uses these generalizations of the original protocol. <p> Thus, the competitive update protocol invalidates those pages that are accessed "less frequently" the protocol can be tuned to a given application by a proper choice of limit L <ref> [1, 9, 14, 10] </ref>. 6 In case of write-sharing, a local copy of a page should not be invalidated if local copy has been modified (the modification needs to be sent to the other nodes). 5 As discussed later, the limit can also be changed dynamically (at run-time) to adapt to <p> Therefore, the page copy at node 1 is also invalidated. At the end, only node 0 has a copy of the page, with update-counter 0 (column 23). 2 [7] to implement its time-out mechanism. 7 2.1 Generalization of the Competitive Update Protocol Unlike other similar schemes <ref> [2, 1, 9, 14, 10] </ref>, implemented in hardware caches, the software implementation can be more flexible and complex (without affecting the performance adversely). The basic competitive protocol can be generalized in four ways, as summarized below.
Reference: [15] <author> P. Keleher, </author> <title> Lazy Release Consistency for Distributed Shared Memory. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7].
Reference: [16] <author> D. Khandekar, </author> <title> "Quarks: Portable dsm on unix," </title> <type> tech. rep., </type> <institution> University of Utah. </institution>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> Quarks <ref> [16] </ref> also incorporates a mechanism similar to that presented in [1, 9, 14, 10]. We consider a software implementation of the competitive update protocol for a DSM that uses release consistency. This section presents details of the implementation, and 3 also discusses some generalizations of the basic competitive update protocol. <p> Information Structure We assume an implementation that is similar to Munin [7] and Quarks <ref> [16] </ref>, with a few modifications to facilitate competitive updates. Each node maintains an information structure for each page resident in its memory. <p> The limit for each page determines the performance of the competitive update protocol. (As discussed later, we allow a different limit for each copy of each page.) Quarks 5 <ref> [16] </ref> also maintains information similar to our update counter and limit. <p> We implemented the protocol by modifying another DSM, Quarks (Beta release 0.8) <ref> [16, 6] </ref>. The performance evaluation is in progress. This section presents some preliminary results. Methodology We executed a synthetic application qtest with the adaptive DSM. (Other benchmark applications will also be evaluated.) qtest is a simple shared memory access application: all nodes access the shared data concurrently. <p> Algorithms (i) and (ii) are similar to multiple protocols in <ref> [7, 16] </ref>, and (iii) is similar to our adaptive protocols which can choose the appropriate protocol at run-time. <p> These protocols dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [8, 29] are based on invalidate protocol, and [22, 9] are based on competitive update protocol. * Quarks <ref> [16] </ref> limits the number of updates independently for each page and each copy. If a copy of the page is updated more than limit times without local access, the copy is invalidated. <p> Whereas the time limit, freeze time, is fixed in Munin, our adaptive protocol can adapt to time-varying memory access patterns by changing the update limit at run-time. * Multiple consistency protocol was proposed in <ref> [7, 16] </ref>. Several categories of shared data objects are identified: conventional, read-only, migratory, write-shared, and synchronization. They developed many memory coherence techniques that perform efficiently for these categories of shared data objects. <p> As yet, we have not explored this possibility. Acknowledgements We thank John Carter and D. Khandekar at the University of Utah for making Quarks <ref> [16] </ref> source code available in public domain.
Reference: [17] <author> J.-H. Kim and N. H. Vaidya, </author> <title> "Distributed shared memory: Recoverable and non-recoverable limited update protocols," </title> <type> Tech. Rep. 95-025, </type> <institution> Texas A&M University, College Station, </institution> <year> 1995. </year> <note> To appear in Proc. of 1995 Pacific Rim International Symposium on Fault-Tolerant Systems. </note>
Reference-contexts: The main idea of this mechanism is to invalidate local copy of a page that has not been accessed for a certain period of time, freeze time, after it was last updated. Although the two approaches (limit and timeout ) have similar goals, they do not behave identically <ref> [17] </ref>. Whereas the time limit, freeze time, is fixed in Munin, our adaptive protocol can adapt to time-varying memory access patterns by changing the update limit at run-time. * Multiple consistency protocol was proposed in [7, 16].
Reference: [18] <author> A. Lebeck and D. Wood, </author> <title> "Dynamic self-invalidation: Reducing coherence overhead in shared-memory multiprocessors," </title> <booktitle> in Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: They developed many memory coherence techniques that perform efficiently for these categories of shared data objects. But programmer should know the memory access behaviors on each shared variable to specify a protocol used for the variable. * Lebeck and Wood <ref> [18] </ref> introduce dynamic self-invalidation (DSI) scheme to reduce overhead in directory-based write-invalidate cache coherence protocol. The directory identifies blocks for self-invalidation. The directory conveys the self-invalidation information to the cache when responding to a cache miss.
Reference: [19] <author> K. Li and P. Hudak, </author> <title> "Memory coherence in shared virtual memory systems," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 7, </volume> <pages> pp. 321-359, </pages> <month> Nov. </month> <year> 1989. </year> <month> 35 </month>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> Note that F varies according to memory access patterns and the number of nodes. Although F can be estimated at run time, previous work <ref> [19] </ref> suggests that F is less than 3 up to 32 nodes. For this discussion, we assume F = 2 (future work will consider estimating F at run-time). Then, U critical = F +3 2 = 2 = 2:5.
Reference: [20] <author> C. Lindemann and F. Schon, </author> <title> "Performance evaluation of consistency models for mul--ticomputers with virtually shared memory," </title> <booktitle> in System Science, 1993 Annual Hawaii International Conf., </booktitle> <volume> vol. II, </volume> <pages> pp. 154-163, </pages> <year> 1993. </year>
Reference-contexts: The directory identifies blocks for self-invalidation. The directory conveys the self-invalidation information to the cache when responding to a cache miss. The cache controller self invalidates the blocks. * Lindemann and Schon <ref> [20] </ref> add LOCAL state, to SHARED, INVALID, and EXCLUSIVE states, to relax the consistency model.
Reference: [21] <author> M. Heinrich et al., </author> <title> "The performance impact of flexibility in the stanford flash multiprocessor," </title> <booktitle> in Proc. of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 274-285, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: pages are updated with the local images by invoking the define global system call. * Bianchini and LeBlanc address software caching which can adapt to changes in memory reference behavior by making a new copy of data and repartitioning the data as needed for each phase of execution [5]. * <ref> [21] </ref> presents a flexible communication mechanism. Their scheme uses a programmable node controller, called MAGIC.
Reference: [22] <author> H. Nilson and P. Stenstrom, </author> <title> "An adaptive update-based cache coherence protocol for reduction of miss rate and traffic," </title> <type> tech. rep., </type> <institution> Lund University. </institution> <note> To appear in Parallel Architectures and Languages Europe, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: If there are three writes by a single processor without intervening references by any other processor, all other cached copies are invalidated. * Optimizations for migratory sharing have also been proposed <ref> [8, 29, 9, 22] </ref>. <p> These protocols dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [8, 29] are based on invalidate protocol, and <ref> [22, 9] </ref> are based on competitive update protocol. * Quarks [16] limits the number of updates independently for each page and each copy. If a copy of the page is updated more than limit times without local access, the copy is invalidated.
Reference: [23] <author> B. Nitzberg and V. Lo, </author> <title> "Distributed shared memory: A survey of issues and algorithms," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, </volume> <pages> pp. 52-60, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems have many advantages over message passing systems <ref> [30, 23] </ref>. Since DSM provides a user a simple shared memory abstraction, the user does not have to be concerned with data movement between hosts. Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications.
Reference: [24] <author> N. Oba, A. Moriwaki, and S. Shimizu, "Top-1: </author> <title> A snoop-cache-based multiprocessor," </title> <booktitle> in Proc. 1990 International Phoenix Conference on Computers and Communication, </booktitle> <pages> pp. 101-108, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Thus, the generalized competitive update protocol can effectively be used as a "multiple" consistency protocol [7], simply by using a different limit for each page. * If the access pattern to the same page is different for different nodes, a "hybrid" protocol <ref> [24] </ref> is more appropriate than a "pure" protocol. <p> Their scheme uses a programmable node controller, called MAGIC. MAGIC is responsible for implementing the cache coherence and message-passing protocols. * Hybrid protocol is more appropriate than a "pure" protocol for a DSM, if the access pattern for the same page is different in each node. TOP-1 <ref> [24] </ref>, a tightly coupled snoop-cache-based multiprocessor, has a hybrid coherence protocol which allows an update protocol and an invalidate protocol, which can be dynamically changed, to coexist simultaneously.
Reference: [25] <author> J. Peterson and A. Silberschatz, </author> <booktitle> Operating System Concepts, </booktitle> <pages> pp. 105-108. </pages> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1983. </year>
Reference-contexts: This prediction should 3 For example, to predict the next CPU burst of a task, a Shortest-Job-First CPU scheduling algorithm may use an exponential average of the measured lengths of previous CPU bursts <ref> [25] </ref>. 2 be accurate, provided that the memory access patterns change relatively infrequently. (The research presented in [26, 31] is closely related to that presented in this report.
Reference: [26] <author> U. Ramachandran, G. Shah, A. Sivasubramaniam, A. Singla, and I. Yanasak, </author> <title> "Architectural mechanisms for explicit communication in shared memory multiproccessors," </title> <type> Tech. Rep. </type> <institution> GIT-CC-94-59, Georgia Institute of Technology, </institution> <month> Dec. </month> <year> 1994. </year> <note> To appear in Proc. of International Conference on Supercomputing 1995. </note>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> This prediction should 3 For example, to predict the next CPU burst of a task, a Shortest-Job-First CPU scheduling algorithm may use an exponential average of the measured lengths of previous CPU bursts [25]. 2 be accurate, provided that the memory access patterns change relatively infrequently. (The research presented in <ref> [26, 31] </ref> is closely related to that presented in this report. Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol [1, 9, 14, 10]. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). <p> task, a Shortest-Job-First CPU scheduling algorithm may use an exponential average of the measured lengths of previous CPU bursts [25]. 2 be accurate, provided that the memory access patterns change relatively infrequently. (The research presented in <ref> [26, 31] </ref> is closely related to that presented in this report. Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol [1, 9, 14, 10]. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. <p> The results shows that the hybrid protocols outperform any single pure protocol in most applications. * Ramachandran et al. <ref> [26, 28] </ref> present new mechanisms for explicit communication in shared memory multiprocessors. They propose explicit communication primitives which allows selectively updating a set of processors, or requesting a stream of data ahead of its intended use (prefetch). <p> Their scheme can also adapt to time-varying sharing pattern by dynamically changing the set of nodes to be updated (or invalidated). The basic difference between our approach and <ref> [26] </ref> is that our scheme does not need to know whether a particular synchronization controls access to a given shared memory page or not. The scheme in [26] makes use of such information to determine whether a copy of the page should be updated or invalidated. * Dynamic cache coherence approach <p> The basic difference between our approach and <ref> [26] </ref> is that our scheme does not need to know whether a particular synchronization controls access to a given shared memory page or not. The scheme in [26] makes use of such information to determine whether a copy of the page should be updated or invalidated. * Dynamic cache coherence approach presented by Archibald [2] dynamically chooses to update or invalidate copies of a shared data object. <p> heuristic for choosing between one of these, at run-time, needs to be developed to implement more efficient DSMs. * Comparison of the proposed approach with previously proposed adaptive schemes. * The adaptive approach (based on collection of statistics) presented here can be combined with ideas developed by other researchers (e.g., <ref> [26] </ref>) to obtain further improve ment in DSM performance. As yet, we have not explored this possibility. Acknowledgements We thank John Carter and D. Khandekar at the University of Utah for making Quarks [16] source code available in public domain.
Reference: [27] <author> S. Reinhardt, J. Larus, and D. Wood, "Tempest and typoon: </author> <title> User-level shared memory," </title> <booktitle> in Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 325-336, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> not seem to decrease once it has increased. 30 The adaptive protocol proposed in this report can detect all relevant 13 local accesses (read as well as write), and the limit is changed based on access patterns in the previous sampling period (the limit may decrease or increase). * Tempest <ref> [27, 3] </ref> allows programmers and compilers to use user-level mechanism to implement shared memory "policies" that are appropriate to a particular program or data structure.
Reference: [28] <author> G. Shah, A. Singla, and U. Ramachandran, </author> <title> "The quest for a zero overhead shared memory parallel machine," </title> <booktitle> in Proceedings of International Conference on Parallel Procesing, </booktitle> <volume> vol. I, </volume> <year> 1995. </year>
Reference-contexts: The results shows that the hybrid protocols outperform any single pure protocol in most applications. * Ramachandran et al. <ref> [26, 28] </ref> present new mechanisms for explicit communication in shared memory multiprocessors. They propose explicit communication primitives which allows selectively updating a set of processors, or requesting a stream of data ahead of its intended use (prefetch).
Reference: [29] <author> P. Stenstrom, M. Brorsson, and L. Sandberg, </author> <title> "An adaptive cache coherence protocol optimized for migratory sharing," </title> <booktitle> in Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 109-118, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: If there are three writes by a single processor without intervening references by any other processor, all other cached copies are invalidated. * Optimizations for migratory sharing have also been proposed <ref> [8, 29, 9, 22] </ref>. <p> These protocols dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. <ref> [8, 29] </ref> are based on invalidate protocol, and [22, 9] are based on competitive update protocol. * Quarks [16] limits the number of updates independently for each page and each copy. If a copy of the page is updated more than limit times without local access, the copy is invalidated.
Reference: [30] <author> M. Stumm and S. Zhou, </author> <title> "Algorithms implementing distributed shared memory," </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 54-64, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems have many advantages over message passing systems <ref> [30, 23] </ref>. Since DSM provides a user a simple shared memory abstraction, the user does not have to be concerned with data movement between hosts. Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. <p> Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [7, 12, 19, 30, 16, 6, 15, 26, 9, 27] </ref>. The DSM implementations are based on variations of write-invalidate and/or write-update protocols. Recent implementations of DSM use relaxed memory consistency models such as release consistency [7]. <p> Three possibilities for the cost metric are: * The number of messages. * The amount of data transferred. * Execution time. The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 <ref> [30, 13, 31] </ref> present similar cost analysis for coherency overhead. [30] is based on read to write ratio and fault ratio, and [13] is based on the write-run model. [31] associates different costs with different events (such as cache hit, invalidate, update, and cache load). <p> Three possibilities for the cost metric are: * The number of messages. * The amount of data transferred. * Execution time. The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 [30, 13, 31] present similar cost analysis for coherency overhead. <ref> [30] </ref> is based on read to write ratio and fault ratio, and [13] is based on the write-run model. [31] associates different costs with different events (such as cache hit, invalidate, update, and cache load).
Reference: [31] <author> J. Veenstra and R. Fowler, </author> <title> "A performance evaluation of optimal hybrid cache coherency protocols," </title> <booktitle> in Proc. of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 149-160, </pages> <month> Oct. </month> <year> 1992. </year> <month> 36 </month>
Reference-contexts: This prediction should 3 For example, to predict the next CPU burst of a task, a Shortest-Job-First CPU scheduling algorithm may use an exponential average of the measured lengths of previous CPU bursts [25]. 2 be accurate, provided that the memory access patterns change relatively infrequently. (The research presented in <ref> [26, 31] </ref> is closely related to that presented in this report. Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol [1, 9, 14, 10]. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). <p> task, a Shortest-Job-First CPU scheduling algorithm may use an exponential average of the measured lengths of previous CPU bursts [25]. 2 be accurate, provided that the memory access patterns change relatively infrequently. (The research presented in <ref> [26, 31] </ref> is closely related to that presented in this report. Section 6 discusses [26, 31] and other related research.) To demonstrate our approach, we choose the competitive update protocol [1, 9, 14, 10]. This protocol is defined by a "threshold" parameter (we will rename the threshold as the "limit"). Different choices of the limit parameter yield different consistency protocols. <p> Three possibilities for the cost metric are: * The number of messages. * The amount of data transferred. * Execution time. The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 <ref> [30, 13, 31] </ref> present similar cost analysis for coherency overhead. [30] is based on read to write ratio and fault ratio, and [13] is based on the write-run model. [31] associates different costs with different events (such as cache hit, invalidate, update, and cache load). <p> The objectives of minimizing these cost are inter-related. This report deals with the first two metrics. 9 [30, 13, 31] present similar cost analysis for coherency overhead. [30] is based on read to write ratio and fault ratio, and [13] is based on the write-run model. <ref> [31] </ref> associates different costs with different events (such as cache hit, invalidate, update, and cache load). Our approach is based on the number of updates by other nodes between consecutive local accesses. <p> Many schemes have been proposed to reduce overhead by adapting to memory access patterns [2, 33, 11, 8, 29, 24, 9, 1, 14, 10, 4, 7, 20, 5, 26, 27, 3, 21, 16, 6]: * The approach proposed in this paper is related to the work by Veenstra and Fowler <ref> [31] </ref>. [31] evaluates the performance of three types of off-line algorithms: (i) an algorithm that chooses statically, at the beginning of the program, either invalidate or update protocols on a per-page basis, (ii) an algorithm that chooses statically either invalidate or update protocols for each cache block, and (iii) an algorithm <p> schemes have been proposed to reduce overhead by adapting to memory access patterns [2, 33, 11, 8, 29, 24, 9, 1, 14, 10, 4, 7, 20, 5, 26, 27, 3, 21, 16, 6]: * The approach proposed in this paper is related to the work by Veenstra and Fowler <ref> [31] </ref>. [31] evaluates the performance of three types of off-line algorithms: (i) an algorithm that chooses statically, at the beginning of the program, either invalidate or update protocols on a per-page basis, (ii) an algorithm that chooses statically either invalidate or update protocols for each cache block, and (iii) an algorithm that <p> Algorithms (i) and (ii) are similar to multiple protocols in [7, 16], and (iii) is similar to our adaptive protocols which can choose the appropriate protocol at run-time. However, in <ref> [31] </ref>, the chosen protocol is applicable to all copies of a cache block, whereas in our scheme, the protocol used for each copy of a page may be different. [31] considers off-line algorithms, for a bus-based system. <p> However, in <ref> [31] </ref>, the chosen protocol is applicable to all copies of a cache block, whereas in our scheme, the protocol used for each copy of a page may be different. [31] considers off-line algorithms, for a bus-based system.
Reference: [32] <author> J. Veenstra and R. Fowler, </author> <title> "The prospects for on-line hybrid coherency protocols on bus-based multiprocessors," </title> <type> Tech. Rep. 490, </type> <institution> The University of Rochester, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: On the other hand, this report considers adaptive (on-line) algorithms that are applicable to distributed systems. * <ref> [32] </ref> examines the performance of on-line hybrid protocols that combine the best aspects of several protocols (invalidate protocol, update protocol, migratory protocol, etc.), on 29 bus-based cache-coherent multiprocessors.
Reference: [33] <author> Q. Yang, G. Thangadurai, and L. Bhuyan, </author> <title> "Design of an adaptive cache coherence protocol for large scale multiprocessors," </title> <journal> IEEE Transaction on Parallel and Distributed Systems, </journal> <volume> vol. 3, </volume> <pages> pp. 281-293, </pages> <month> May </month> <year> 1992. </year> <month> 37 </month>
Reference-contexts: However, TOP-1 needs additional hardware design, cache mode register (to specify a cache mode: update mode and invalidate mode) and CH (Cache Hit) bus line (to indicate a snoop hit). * An adaptive cache coherence protocol is presented by Yang, Thangadurai, and Bhuyan <ref> [33] </ref>. This scheme is based on a hardware approach that handles multiple shared reads efficiently.
References-found: 33

