URL: ftp://ftp.cs.huji.ac.il/users/transis/thesis/roman-msc.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/transis/Abstracts/roman-msc.html
Root-URL: http://www.cs.huji.ac.il
Title: Properties of Distributed Group Communication and Their Utilization  
Author: Roman Vitenberg supervised by Prof. Danny Dolev 
Degree: A thesis submitted in fulfillment of the requirements for the degree of Master of Science by  
Date: January 28, 1998  
Address: Jerusalem, Israel.  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract-found: 0
Intro-found: 1
Reference: [AAD93] <author> O. Amir, Y. Amir, and D. Dolev. </author> <title> A Highly Available Application in the Transis Environment. In Proceedings of the Hardware and Software Architectures for Fault Tolerance Workshop, </title> <institution> at Le Mont Saint-Michel, France (LNCS 774), </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: The State Transfer Problem deals with bringing such replicas to a consistent state when they re-connect. This work presents an efficient implementation of the State Transfer Module that may serve as a building block in object replication protocols. Replication is the focus of traditional distributed database applications <ref> [KD96, ADMSM94, AAD93, ABCD96] </ref> as well as of Computer Supported Cooperative Work [Rod91] applications. The latter includes multimedia and desktop conferencing systems, interactive distributed games and simulations, distributed applications with shared workspace, etc.
Reference: [ABCD96] <author> Y. Amir, D. Breitgand, G. Chockler, and D. Dolev. </author> <title> Group Communication as an Infrastructure for Distributed System Management. </title> <booktitle> In International Workshop on Services in Distributed and Networked Environment, number 3rd, </booktitle> <month> June </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> The State Transfer Problem deals with bringing such replicas to a consistent state when they re-connect. This work presents an efficient implementation of the State Transfer Module that may serve as a building block in object replication protocols. Replication is the focus of traditional distributed database applications <ref> [KD96, ADMSM94, AAD93, ABCD96] </ref> as well as of Computer Supported Cooperative Work [Rod91] applications. The latter includes multimedia and desktop conferencing systems, interactive distributed games and simulations, distributed applications with shared workspace, etc.
Reference: [ACBMT95] <author> E. Anceaume, B. Charron-Bost, P. Minet, and S. Toueg. </author> <title> On the formal specification of group membership services. </title> <type> TR 95-1534, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Papers describing GCSs typically enumerate the services provided, but often do not rigorously formalize the service semantics. Many suggested specifications are complicated and difficult to understand, and some were shown to be ambiguous <ref> [ACBMT95] </ref>. This makes it difficult to analyze and compare the different systems. Furthermore, it is often unclear whether a given specification is necessary or sufficient for a certain application [FLS97]. <p> Therefore, many of the suggested specifications turned out to be too trivial, and in particular, solvable by weaker algorithms than the actual implementations, or even by trivial algorithms <ref> [ACBMT95] </ref>. Other specifications turned out to be too strong to implement [CHTCB96]. In this work, we address the non-triviality issues and suggest ways to circumvent the impossibility results using external failure 6 detectors or by reasoning about liveness guarantees at stability periods. <p> Many formal specifications of group communication systems do not capture this notion of "best effort". This results in specifications that can in fact be implemented by algorithms weaker than the actual implementations (or even by trivial algorithms) <ref> [ACBMT95] </ref>. However, since the "best effort" principle is an important consideration of every system builder, actual systems provide more than their specifications require. For example, the Internet Protocol (IP) [Pos81] is an unreliable datagram protocol that does not guarantee to deliver any message. <p> The first attempts at non-trivial membership specifications [DMS94] ruled out only those classes of trivial algorithms which, despite changes in the actual network situation, might at some point cease reporting view changes. These attempts were criticized as too trivial in <ref> [ACBMT95] </ref>. Later specifications explicitly linked the behavior of the GCS to the output of an external failure detector module. The output of a failure detector is a list of suspects, i.e., processes which are suspected to be faulty. <p> Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment [FLP85, CHTCB96], since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable <ref> [ACBMT95] </ref>. This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate.
Reference: [ACDV97] <author> Y. Amir, G. V. Chokler, D. Dolev, and R. Vitenberg. </author> <title> Efficient state transfer in parti-tionable environments. </title> <booktitle> In 2nd European Research Seminar on Advances in Distributed Syste ms (ERSADS'97), </booktitle> <pages> pages 183-192. </pages> <institution> BROADCAST (ESPRIT WG 22455), Operating Systems Laboratory, Swiss Federal Institute of Technolo gy, Lausanne, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. Such applications change their state when they receive application messages and membership changes <ref> [HS95, FV97, ACDV97] </ref>. However, we are aware of only few distributed applications that explicitly base their operation on Virtual Synchrony, since Virtual Synchrony is an "external observer" requirement, formulated in terms of two processes that proceed together through the same two consecutive views. <p> In order to overcome this difficulty we define a transitional set (Requirement 5.1.6). Transitional set is an addition to the membership view that, informally speaking, allows a process to know which members of its previous view proceed along with it to the next view <ref> [ACDV97] </ref>. The scenario depicted in Figure 9.1 (a,b), illustrates this point. In Figure 9.1 (a) the communication subsystem delivers regular views only, and in Figure 9.1 (b) views also contain a transitional set. p and q start as one connected component (both install &lt; 1; fp; qg &gt;).
Reference: [ACK + 97] <author> T. Anker, G. Chockler, I. Keidar, M. Rozman, and J. </author> <title> Wexler. Exploiting Group Communication for Highly Available Video-On-Demand Services. </title> <booktitle> In Proceedings of the IEEE 13th International Conference on Advanced Science and Technology (ICAST 97) and the 2nd International Conference on Multimedia Information Systems (ICMIS 97), </booktitle> <pages> pages 265-270, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications.
Reference: [ADKM92a] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. </author> <title> Membership Algorithms for Multicast Communication Groups. </title> <booktitle> In 6th Intl. Workshop on Distributed Algorithms proceedings (WDAG-6), (LCNS, </booktitle> <volume> 647), </volume> <pages> pages 292-312, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis <ref> [ADKM92a] </ref>, have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems [DMS96, EMS95, BDM97, FLS97].
Reference: [ADKM92b] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. Transis: </author> <title> A Communication Sub-System for High Availability. </title> <booktitle> In 22nd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 76-84, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This implementation of an additional service by a GCS does not require extra communication, beyond that already required for the implementation of the Virtual Synchrony model. The State Transfer Module proposed in this paper has been implemented on top of the Tran-sis <ref> [ADKM92b] </ref> and Totem [AMMS + 95] group communication toolkits and is used by various distributed applications developed by members of the Transis project. 1.1 Distributed Group Communication and the Motivation to Spec ify its Properties Group communication systems (GCSs) provide reliable multicast and group membership services. <p> The transitional membership notification, which complements the regular membership notification, enables each replica to locally determine the set of other members that have the same state. Our proposed State Transfer Module may be implemented on top of any group communication layer that provides specifications defined in Chapter 5. Transis <ref> [ADKM92b] </ref> and Totem [AMMS + 95] are examples of such systems, in which the transitional set is implemented at no additional cost, beyond that required by virtually synchronous group communication. <p> We show that the proper combination of services and semantics provided by GCSs and described in Part I allows the State Transfer problem to be tackled and solved in an elegant and efficient manner. The State Transfer Module has been implemented and exploited by applications in the Tran-sis <ref> [ADKM92b] </ref> and Totem [AMMS + 95] environments. 1.3 Overview of the Thesis The rest of this work is divided into two parts. In Part I we deal with specifications of GCSs. <p> Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis <ref> [ADKM92b] </ref>. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to different applications, which require different semantics and qualities of service. <p> Another benefit of modularity is its flexibility to incorporate a variety of QoS options. Recently, several emerging projects addressed the challenge of incorporating QoS communication into the framework of group communication. For example, the MMTS [CHKD96] extends the Tran-sis <ref> [ADKM92b, DM96] </ref> GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications. 3.2 <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis <ref> [ADKM92b] </ref> and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages and that all delivered messages are guaranteed to be uncorrupted. <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> For example, in RMP, the unreliable QoS level provides the guarantees of the underlying communication. Similarly, the MMTS [CHKD96] extends Transis <ref> [ADKM92b, DM96] </ref> by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications. <p> This requirement is less trivial than Delivery Integrity, because the underlying network usually may duplicate messages. Most GCSs eliminate duplication <ref> [BDM95, EMS95, ADKM92b] </ref>. However, when a GCS 48 directly provides QoS of the underlying communication layer, duplication is not eliminated, e.g., in the Unreliable and Unordered QoS levels of RMP [WMK95]. Unfortunately, there is no general way to guarantee a certain latency of delivery in asynchronous systems. <p> In similar requirements of [FvR95] and [BDM95] this next view installed at p excludes q. However, this refinement contradicts to the "best-effort accuracy" principle (see a more detailed discussion of the transitional set below). In Transis <ref> [ADKM92b] </ref> it could also happen that q detached from p, installed another view and now reconnected again (in Horus [FvR95] this scenario is impossible due to Agreement on Successors property). In this case, q cannot deliver the message because it would violate Requirement 5.2.4, which is discussed next. <p> It is exactly the View-Synchronous Communication Service M2 requirement of [BDM95]. This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis <ref> [ADKM92b] </ref>, Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis [BJ87], Horus [FvR95] and Totem [AMMS + 95]. Virtual Synchrony (Requirement 5.2.5) is perhaps the most well known property of GCSs, to the extent that it engendered the whole Virtual Synchrony model. <p> Hence, the previous decision value of q is different from that of p and the transitional set delivered along with &lt;3; fp; qg&gt; on p, does not include q. The transitional set is contained in the transitional view , introduced in Extended Virtual Synchrony [MAMSA94] and implemented in Transis <ref> [ADKM92b] </ref> and Totem [AMMS + 95]. Other systems develop similar approaches: In Relacs [BDM97] every change in connectivity causes two views to be installed: first, a transitional set is installed as a regular view, and then a normal membership view is installed. <p> Isis [BJ87] gives weak incorporated semantics between messages sent by AB-CAST and CBCAST multicast primitives. However, this system has another total order multicast primitive, GBCAST, so that messages sent by GBCAST and CBCAST primitives are ordered according to strong incorporated semantics. Transis <ref> [ADKM92b] </ref> may be configured to use one of several protocols providing agreed delivery. More efficient ARTOP protocol [Cho97] guarantees only weak incorporated semantics between a reliable causal message and a strongly agreed message. <p> However, some systems provide a QoS level, corresponding to this message stability and some do not. The implementations we are aware of are the Safe messages of Totem [AMMS + 95, MAMSA94] and Transis <ref> [ADKM92b] </ref>, the Totally Resilient QoS level of RMP [WMK95], the atomic, tight and delta QoS levels of xAMp [RV92] and the Uniform multicast of Phoenix [MFSW95]. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. <p> An important consequence of Requirement 5.4.1, is that if an agreed message is indicated as safe, it also satisfies the Reliable Agreed Delivery property (Requirement 5.3.7). This property is exploited by the applications in [ADMSM94], [KD96] and [FLS97]. It is supported by Totem [AMMS + 95] and Transis <ref> [ADKM92b] </ref> that do not provide Reliable Agreed Delivery (Requirement 5.3.7). A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception. Usually such acknowledgements are given by a GC system of the process that receives the message. <p> We show that the combination of the specifications of the traditional Virtual Synchrony model with these additional services allows tackling the State Transfer problem elegantly and efficiently. Currently, the protocol is implemented as part of the group membership of Transis <ref> [ADKM92b] </ref> communication system. 58 Chapter 8 The State Transfer Problem In this section we present the definition of the State Transfer problem. The definition is similar to the one given in [BBD96].
Reference: [ADMSM94] <author> Y. Amir, D. Dolev, P. M. Melliar-Smith, and L. E. Moser. </author> <title> Robust and Efficient Replication Using Group Communication. </title> <type> TR CS94-20, </type> <institution> Institute of computer science, The Hebrew University of Jerusalem, </institution> <year> 1994. </year> <month> 73 </month>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> The State Transfer Problem deals with bringing such replicas to a consistent state when they re-connect. This work presents an efficient implementation of the State Transfer Module that may serve as a building block in object replication protocols. Replication is the focus of traditional distributed database applications <ref> [KD96, ADMSM94, AAD93, ABCD96] </ref> as well as of Computer Supported Cooperative Work [Rod91] applications. The latter includes multimedia and desktop conferencing systems, interactive distributed games and simulations, distributed applications with shared workspace, etc. <p> When two processes reconnect, they can exploit this property to find out which process is more updated, i.e. was a member of a later primary partition in the global history. This information is useful for the implementation of a consistent replication service <ref> [ADMSM94, KD96] </ref>. However, in order to fulfill Requirement 5.1.7 a process p must be aware of possible view installations at other processes of views that include p. The latter circumstance renders the membership protocol more complicated and less efficient, because it demands at least two rounds of communication. <p> Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. However, there are applications implementing a consistent replication paradigm, which re 51 quire that processes agree upon the order of messages even in case they disconnect from each other <ref> [ADMSM94, KD96] </ref>. This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix [MFSW95], Horus [vRHB94], Transis [Cho97] and RMP [WMK95]. <p> An important consequence of Requirement 5.4.1, is that if an agreed message is indicated as safe, it also satisfies the Reliable Agreed Delivery property (Requirement 5.3.7). This property is exploited by the applications in <ref> [ADMSM94] </ref>, [KD96] and [FLS97]. It is supported by Totem [AMMS + 95] and Transis [ADKM92b] that do not provide Reliable Agreed Delivery (Requirement 5.3.7). A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception. <p> Currently, the protocol is implemented as part of the group membership of Transis communication system. In future we intend to build a generic State Transfer layer and to incorporate its services into the existing object replication protocols, e.g. [KD96] and <ref> [ADMSM94] </ref>. We will examine other known problems faced by distributed applications operating on top of GCSs. We are going to investigate how utilizing additional services and semantics may give rise to new, more efficient solutions to these problems. 72
Reference: [Ahu93] <author> M. Ahuja. </author> <title> Assertions about Past and Future in Highways: Global Flush Broadcast and Flush-vector-time. </title> <journal> Information Processing Letters, </journal> <volume> 48(1) </volume> <pages> 21-28, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: ) ^ content (e) = content (e 0 )) _ pid (e) = pid (e 0 ) ^ time (e) time (e 0 )) * event causality relation definition e ! e 0 def dir dir * causal cone function definition It is called "Past of an event" function in <ref> [Ahu93] </ref> cone (h; e) def * extension predicate definition extension (h; E; e) def 9h 0 [cone (h 0 ; e) = cone (h; e) ^ E = h 0 "cone (h; e)] * mute extension predicate definition mute ext (h; E; e) def = extension (h; E; e) ^ 8e <p> In particular, we will discuss Consul [MPS91b], Highways <ref> [Ahu93] </ref> Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption <p> More efficient ARTOP protocol [Cho97] guarantees only weak incorporated semantics between a reliable causal message and a strongly agreed message. On the other hand, the "all-ack" protocol [DM95, CHD] guarantees strong incorporated semantics between messages of these two types, but it incurs longer delivery latency. Highways <ref> [Ahu93] </ref> defines different types of causal delivery and shows how they can be efficiently combined in a GCS. 6.5 Message Stability Distributed applications often require "all or nothing" semantics, i.e., they require that either all the processes will deliver a message or none of the processes will.
Reference: [Ami95] <author> Y. Amir. </author> <title> Replication Using Group Communication Over a Partitioned Network. </title> <type> PhD thesis, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Israel, </institution> <year> 1995. </year>
Reference-contexts: Requirement 5.1.3 has another significant consequence: if two processes install the same two views, they install these views in the same order. The importance of view ordering properties is noted and emphasized in several works, for example in [HS95, FV97]. This feature is exploited by numerous applications, e.g. [KD96], <ref> [Ami95] </ref> and [FV97]. Requirement 5.1.4 (Termination of Membership) guarantees that if a process p installs a view V , then either all members of V install V or p installs a next view (unless it crashes). Usually, when several processes install the same new view, they exchange messages.
Reference: [AMMS + 95] <author> Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, and P. Ciarfella. </author> <title> The totem single-ring ordering and membership protocol. </title> <journal> ACM Trans. on Comp. Syst., </journal> <volume> 13(4), </volume> <month> November </month> <year> 1995. </year>
Reference-contexts: This implementation of an additional service by a GCS does not require extra communication, beyond that already required for the implementation of the Virtual Synchrony model. The State Transfer Module proposed in this paper has been implemented on top of the Tran-sis [ADKM92b] and Totem <ref> [AMMS + 95] </ref> group communication toolkits and is used by various distributed applications developed by members of the Transis project. 1.1 Distributed Group Communication and the Motivation to Spec ify its Properties Group communication systems (GCSs) provide reliable multicast and group membership services. <p> Our proposed State Transfer Module may be implemented on top of any group communication layer that provides specifications defined in Chapter 5. Transis [ADKM92b] and Totem <ref> [AMMS + 95] </ref> are examples of such systems, in which the transitional set is implemented at no additional cost, beyond that required by virtually synchronous group communication. <p> The State Transfer Module has been implemented and exploited by applications in the Tran-sis [ADKM92b] and Totem <ref> [AMMS + 95] </ref> environments. 1.3 Overview of the Thesis The rest of this work is divided into two parts. In Part I we deal with specifications of GCSs. In Chapter 3 we first informally describe the typical services provided by GCSs as well as new trends in modern GCSs. <p> Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem <ref> [AMMS + 95] </ref> and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to different applications, which require different semantics and qualities <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem <ref> [AMMS + 95] </ref>, Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages and that all delivered messages are <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> This local counter is incremented by a process upon each installation. The counters in [FLS97] and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. In Phoenix [MS95], Totem <ref> [AMMS + 95] </ref>, Horus [FvR95], Relacs [BDM97] and in the specifications of [CS95] a view is a set of pairs &lt; p i ; c i &gt; where p i is a process identifier and c i is a value of a local counter on p i . <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> It is possible in principle to overcome this problem by saving information on a disk before each view installation. However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, Horus [FvR95], Relacs [BDM97] or above a group communication system conforming with the specifications of [Nei96] or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. <p> However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis [BJ87], Horus [FvR95] and Totem <ref> [AMMS + 95] </ref>. Virtual Synchrony (Requirement 5.2.5) is perhaps the most well known property of GCSs, to the extent that it engendered the whole Virtual Synchrony model. It states that if two processes install the same two consecutive views, then they receive the same set of messages in the former. <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, Newtop [EMS95], Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. <p> The transitional set is contained in the transitional view , introduced in Extended Virtual Synchrony [MAMSA94] and implemented in Transis [ADKM92b] and Totem <ref> [AMMS + 95] </ref>. Other systems develop similar approaches: In Relacs [BDM97] every change in connectivity causes two views to be installed: first, a transitional set is installed as a regular view, and then a normal membership view is installed. <p> This requirement thus incurs extra latency for message delivery. Among the group communication systems that support strong virtual synchrony are Isis [BJ87] and Totem <ref> [AMMS + 95] </ref>. In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications [MAMSA94, FLS97, HS95]. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. <p> It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis [BJ87], Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, Horus [FvR95] and Newtop [EMS95]. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. <p> They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. <p> As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem <ref> [AMMS + 95] </ref>, Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). In particular, this work defines strong and weak total order in the context of a primary partition membership service. <p> The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem <ref> [AMMS + 95] </ref>) provide only higher QoS levels extending Weak Agreed Delivery. However, there are applications implementing a consistent replication paradigm, which re 51 quire that processes agree upon the order of messages even in case they disconnect from each other [ADMSM94, KD96]. <p> However, there are applications implementing a consistent replication paradigm, which re 51 quire that processes agree upon the order of messages even in case they disconnect from each other [ADMSM94, KD96]. This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem <ref> [AMMS + 95] </ref>, Phoenix [MFSW95], Horus [vRHB94], Transis [Cho97] and RMP [WMK95]. Since processes do not know they are going to disconnect before they actually do, messages delivered under weak agreed semantics also comply with Strong Agreed Delivery until the moment of a link failure. <p> Horus [FvR95] and RMP [WMK95] provide this service. Isis [BJ87], Transis [DMS96], Totem <ref> [AMMS + 95] </ref>, New-top [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92]. Totem <ref> [AMMS + 95] </ref>, Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery. <p> However, some systems provide a QoS level, corresponding to this message stability and some do not. The implementations we are aware of are the Safe messages of Totem <ref> [AMMS + 95, MAMSA94] </ref> and Transis [ADKM92b], the Totally Resilient QoS level of RMP [WMK95], the atomic, tight and delta QoS levels of xAMp [RV92] and the Uniform multicast of Phoenix [MFSW95]. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. <p> An important consequence of Requirement 5.4.1, is that if an agreed message is indicated as safe, it also satisfies the Reliable Agreed Delivery property (Requirement 5.3.7). This property is exploited by the applications in [ADMSM94], [KD96] and [FLS97]. It is supported by Totem <ref> [AMMS + 95] </ref> and Transis [ADKM92b] that do not provide Reliable Agreed Delivery (Requirement 5.3.7). A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception.
Reference: [Avr98] <author> U. Avraham. </author> <title> Models for concurrency. </title> <publisher> Gordon and Breach, </publisher> <year> 1998. </year> <note> In preparation. </note>
Reference-contexts: In this work we formulate a comprehensive set of specification "building blocks" which may be combined to represent the guarantees of most existing GCSs. We specify clear and rigorous requirements formalized as trace properties of I/O automata [LT89, Lyn96] using a first order logic modeling technique <ref> [Avr98] </ref>. In light of these requirements, we survey and analyze over thirty published specifications which cover a dozen leading GCSs. We correlate the terminology used in different papers to our terminology. This yields a semantic comparison of the guarantees of existing systems. <p> of the length n + 1 can be expressed as an execution of length n followed by a single transition of the automaton. 2.3 First Order Logic Methodology In order to formally describe system specifications we will be using sentences of a certain first-order theory that satisfy a finiteness demand <ref> [Avr98] </ref>. First we define a first order language and its interpretation, then we deal with formulas, their truth values and models 2 , and finally we discusses axioms and theories. This section introduces some of the elementary notions from model theory that are needed. <p> For example, a function symbol of arity two is interpreted by a two-place function. The notion of an interpretation is quite intuitive, so we do not formally define it here. Such a formal definition can be found in <ref> [Avr98] </ref> or in any logic textbook. We use here multi-sorted structures rather that structures with a single universe. The universe of a multi-sorted structure consists of pairwise disjoint sorts (also called types) corresponding intuitively to the different types objects we deal with.
Reference: [BBD96] <author> O. Babaoglu, A. Bartoli, and G. Dini. </author> <title> On Programming with View Synchrony. </title> <booktitle> In Intl. Conference on Distributed Computing Systems, number 16th, </booktitle> <pages> pages 3-10, </pages> <month> May </month> <year> 1996. </year> <note> Also available as technical report UBLCS95-15, </note> <institution> Department of Computer Science, University of Bologna, </institution> <year> 1995. </year>
Reference-contexts: The state transfer tool of Isis [BCJ + 90] was, perhaps, the first to provide a generic solution to the State Transfer problem, It did this, though, within the framework of a primary partition model. Other work tackling the state transfer problem can be found in <ref> [Cri96, BBD96, HK94] </ref>. The approach presented in [BBD96] is the closest to ours. This work defines the shared state problem in a partitionable environment and contains a detailed survey of its different aspects. <p> Other work tackling the state transfer problem can be found in [Cri96, BBD96, HK94]. The approach presented in <ref> [BBD96] </ref> is the closest to ours. This work defines the shared state problem in a partitionable environment and contains a detailed survey of its different aspects. <p> It also introduces an extension of the view synchrony model, called enriched view synchrony . However, the authors are less concerned with the subtleties of the underlying communication model that would 8 allow efficient and simple implementation: the main contribution of <ref> [BBD96] </ref> is a new high level paradigm for building distributed applications, operating in group communication framework. Our work, by contrast, focuses on the specifications of the underlying communication model, with the aim of rendering feasible the efficient identification of the set of processes with the same state. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of <ref> [MAMSA94, FLS97, BBD96, CS95, JFR93] </ref>. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. <p> Unfortunately, this implies an overhead of processing an extra view by the application and more complicated GCS semantics. The developers of Relacs have recently suggested an appealing programming paradigm, called enriched view synchrony <ref> [BBD96] </ref>. Instead of regular views the membership service provides enriched views, which contain more useful information. Among other things, an enriched view relays information regarding the previous view of each of its members. Thus, the transitional set can be deduced from the enriched view. <p> Currently, the protocol is implemented as part of the group membership of Transis [ADKM92b] communication system. 58 Chapter 8 The State Transfer Problem In this section we present the definition of the State Transfer problem. The definition is similar to the one given in <ref> [BBD96] </ref>. However, [BBD96] specifies three instances of the problem, namely: * Processes joining an operational group. * Recovery from scratch (such as after a total crash). * Merging of two or more network components. In contrast, we offer a single problem definition which covers all of these instances. <p> Currently, the protocol is implemented as part of the group membership of Transis [ADKM92b] communication system. 58 Chapter 8 The State Transfer Problem In this section we present the definition of the State Transfer problem. The definition is similar to the one given in <ref> [BBD96] </ref>. However, [BBD96] specifies three instances of the problem, namely: * Processes joining an operational group. * Recovery from scratch (such as after a total crash). * Merging of two or more network components. In contrast, we offer a single problem definition which covers all of these instances. <p> In contrast, we offer a single problem definition which covers all of these instances. Furthermore, we approach the definition of the problem from a more formal perspective than does <ref> [BBD96] </ref>. 8.1 Object's State Each instance of the application maintains a replica of the distributed object. Although the definition of an actual object is application dependent, the following structure is generic: An object consists of a state (a set of variables) and a collection of methods to manipulate these variables.
Reference: [BCJ + 90] <author> K. P. Birman, R. Cooper, T. A. Joseph, K. Marzullo, M. Makpangou, K. Kane, F. Schmuck, and M. Wood. </author> <title> The ISIS System Manual. </title> <institution> Dept of Computer Science, Cornell University, </institution> <month> Sep 90. </month>
Reference-contexts: Transis [ADKM92b] and Totem [AMMS + 95] are examples of such systems, in which the transitional set is implemented at no additional cost, beyond that required by virtually synchronous group communication. The state transfer tool of Isis <ref> [BCJ + 90] </ref> was, perhaps, the first to provide a generic solution to the State Transfer problem, It did this, though, within the framework of a primary partition model. Other work tackling the state transfer problem can be found in [Cri96, BBD96, HK94].
Reference: [BDGB94] <author> O. Babaoglu, R. Davoli, L. Giachini, and M. Baker. RELACS: </author> <title> A Communication Infrastructure for Constructing Reliable Applications in Large-Scale Distributed Systems. </title> <type> TR UBLCS94-15, </type> <institution> Laboratory of Computer Science, University of Bologna, </institution> <year> 1994. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs <ref> [BDGB94] </ref>, RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to different applications, which require <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs <ref> [BDGB94] </ref>, RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages and that <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs <ref> [BDGB94, BDM95, BDM97] </ref> and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one.
Reference: [BDM95] <author> O. Babaoglu, R. Davoli, and A. Montresor. </author> <title> Failure detectors, group membership and view-synchronous communication in partitionable asynchronous systems. </title> <type> TR UBLCS95-18, </type> <institution> Department of Conmputer Science, University of Bologna, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: Such modular GCSs easily adapt to a variety of application needs. Traditionally, GCS developers concentrated primarily on system performance, in order to make their systems useful for real-world distributed applications. Only recently, the challenging task of specifying the semantics and services of GCSs has become an active research area <ref> [MAMSA94, FvR95, BDM95, FLS97] </ref>, but as of yet, no commonly accepted specifications have been established. The guarantees of different GCSs are stated using different terminologies and modeling techniques, and the specifications vary greatly in their rigor. <p> The output of a failure detector is a list of suspects, i.e., processes which are suspected to be faulty. For example, [FvR95, DMS96] require that a process not be removed from the view unless it is a suspect. Other specifications <ref> [MS95, BDM95] </ref> take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. An eventual perfect failure detector eventually suspects all faulty processes and also eventually permanently stops suspecting non-faulty ones. The specifications in [MS95, BDM95] guarantee that if the external failure detector is an eventual <p> Other specifications <ref> [MS95, BDM95] </ref> take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. An eventual perfect failure detector eventually suspects all faulty processes and also eventually permanently stops suspecting non-faulty ones. The specifications in [MS95, BDM95] guarantee that if the external failure detector is an eventual perfect one then the membership service will at some point begin to correctly reflect the network situation. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs <ref> [BDGB94, BDM95, BDM97] </ref> and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Since a membership of a view reflects the ability to communicate with the process and a process is always able to communicate with itself, this requirement is trivial and holds in all group communication systems and specifications, as explicitly specified in <ref> [DMS96, FvR95, EMS95, BDM95] </ref>. Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. <p> This time bound is a protocol parameter suited for the underlying network. An interesting research direction would be to show how membership protocol capriciousness could be restricted even further. Unlike <ref> [BDM95] </ref>, we do not assume symmetry and transitivity of the underlying network communication. It should be emphasized that these two properties are only preconditions of the precise 47 ness requirement; when they are not fulfilled accuracy is not guaranteed but no other requirements are affected. <p> Since the underlying network does not spontaneously generate messages (assumption 4.3.1) neither does the communication service. This requirement can be trivially implemented, so all GCSs support it, as explicitly specified in <ref> [BDM95] </ref> and [RV92]. 6.3.1 Quality of Service GCSs typically provide various types of multicast services. Traditionally, GCSs provide reliable multicast services with different ordering guarantees. We call these paradigms reliable quality of service options. However, this type of multicast is not appropriate for all applications. <p> This requirement is less trivial than Delivery Integrity, because the underlying network usually may duplicate messages. Most GCSs eliminate duplication <ref> [BDM95, EMS95, ADKM92b] </ref>. However, when a GCS 48 directly provides QoS of the underlying communication layer, duplication is not eliminated, e.g., in the Unreliable and Unordered QoS levels of RMP [WMK95]. Unfortunately, there is no general way to guarantee a certain latency of delivery in asynchronous systems. <p> According to Requirement 5.2.3 (Termination of Delivery) processes within a connected component eventually deliver each other's messages. This requirement precludes trivial protocols that never deliver messages or that deliver messages only before view changes. Similar termination requirements can be found in [DMS96], [FvR95] and <ref> [BDM95] </ref>. This requirement is not fulfilled by Unreliable QoS levels (e.g. in RMP [WMK95]). According to Requirement 5.2.3 if p installs a view V and sends a message in this view, then either each member q of V delivers this message, or p installs a next view (unless p crashes). <p> According to Requirement 5.2.3 if p installs a view V and sends a message in this view, then either each member q of V delivers this message, or p installs a next view (unless p crashes). In similar requirements of [FvR95] and <ref> [BDM95] </ref> this next view installed at p excludes q. However, this refinement contradicts to the "best-effort accuracy" principle (see a more detailed discussion of the transitional set below). <p> Thus, there is no reason for p to exclude q from the next view. Requirement 5.2.4 states that a message is delivered in the same view at every process that delivers it. It is exactly the View-Synchronous Communication Service M2 requirement of <ref> [BDM95] </ref>. This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. <p> It is exactly the View-Synchronous Communication Service M2 requirement of <ref> [BDM95] </ref>. This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis [BJ87], Horus [FvR95] and Totem [AMMS + 95]. Virtual Synchrony (Requirement 5.2.5) is perhaps the most well known property of GCSs, to the extent that it engendered the whole Virtual Synchrony model. <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service <ref> [FvR95, DMS96, EMS95, MAMSA94, BDM95] </ref>. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and [FV97] it was called "failure atomicity", and in <ref> [BDM95] </ref> it was called "view synchrony".
Reference: [BDM97] <author> O. Babaoglu, R. Davoli, and A. Montresor. </author> <title> Partitionalbe Group Membership: Specification and Algorithms. </title> <type> TR UBLCS97-1, </type> <institution> Department of Conmputer Science, University of Bologna, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: Note that this assumption does not restrict the network to delivering messages at most once, so message duplication is still possible. While Assumption 4.3.1 is highly reasonable and realistic <ref> [RV92, BDM97, WMK95] </ref>, some group communication systems do not assume it. Instead, they cope with the problem of such messages by using a checksum algorithm, even though this imposes an execution penalty. <p> This local counter is incremented by a process upon each installation. The counters in [FLS97] and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. In Phoenix [MS95], Totem [AMMS + 95], Horus [FvR95], Relacs <ref> [BDM97] </ref> and in the specifications of [CS95] a view is a set of pairs &lt; p i ; c i &gt; where p i is a process identifier and c i is a value of a local counter on p i . <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs <ref> [BDGB94, BDM95, BDM97] </ref> and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> It is possible in principle to overcome this problem by saving information on a disk before each view installation. However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], Relacs <ref> [BDM97] </ref> or above a group communication system conforming with the specifications of [Nei96] or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. In Phoenix [MS95] a view contains local counter values along with process identifiers. <p> The latter circumstance renders the membership protocol more complicated and less efficient, because it demands at least two rounds of communication. Thus, only a few GCSs (e.g. Transis [DMS96] and Relacs <ref> [BDM97] </ref>) support this requirement, even in the absence of crashes. [YLKD97] is also concerned with this requirement implementation. 6.2.6 Non-triviality of membership Preciseness (Requirement 5.1.5) is one of the most fundamental properties of a membership service. <p> A group communication system is useless if its membership service is not precise at least to some extent. In order to be precise, a membership service should be complete, i.e. eventually exclude crashed and detached processes, and it should be accurate, i.e. eventually permanently include reachable processes <ref> [HS95, BG93, BDM97] </ref>. Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment [FLP85, CHTCB96], since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. <p> This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems <ref> [DMS96, EMS95, BDM97, FLS97] </ref>. Our approach is to guarantee that the the membership service will eventually be precise, provided that some well-defined conditions on the underlying network hold, as explained below. <p> Unfortunately, as we show in Section 3.2, such a desirable membership service is not implementable in purely asynchronous environments. In order to circumvent this impossibility result we augment the model with an external failure detector. A similar approach was taken in <ref> [SR93, MS95, BDM97, HS95] </ref>. We assume that each process is equipped with an external failure detector module (or oracle), which reports to the local process which of the other processes are suspected to have failed. <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95], Phoenix [SS93] and Relacs <ref> [BDM97] </ref>) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. <p> The transitional set is contained in the transitional view , introduced in Extended Virtual Synchrony [MAMSA94] and implemented in Transis [ADKM92b] and Totem [AMMS + 95]. Other systems develop similar approaches: In Relacs <ref> [BDM97] </ref> every change in connectivity causes two views to be installed: first, a transitional set is installed as a regular view, and then a normal membership view is installed. Unfortunately, this implies an overhead of processing an extra view by the application and more complicated GCS semantics.
Reference: [BFHR98] <author> K. Birman, R. Friedman, M. Hayden, and I. Rhee. </author> <title> Middleware Support for Distributed Multimedia and Collaborative Computing. </title> <booktitle> In Multimedia Computing and Networking (MMCN98), </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Recently, several emerging projects addressed the challenge of incorporating QoS communication into the framework of group communication. For example, the MMTS [CHKD96] extends the Tran-sis [ADKM92b, DM96] GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro <ref> [BFHR98] </ref> extends the Ensemble [HvR96] group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications. 3.2 On the Formal Specifications of Group Communication Sys tems In this section we discuss the difficulties <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro <ref> [BFHR98] </ref>, Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may <p> For example, in RMP, the unreliable QoS level provides the guarantees of the underlying communication. Similarly, the MMTS [CHKD96] extends Transis [ADKM92b, DM96] by providing a framework for synchronization of messages with different QoS requirements; Maestro <ref> [BFHR98] </ref> extends the Ensemble [HvR96] GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications.
Reference: [BG93] <author> K. P. Birman and B. Glade. </author> <title> Consistent failure reporting in reliable communication systems. </title> <type> TR 93-1349, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: A group communication system is useless if its membership service is not precise at least to some extent. In order to be precise, a membership service should be complete, i.e. eventually exclude crashed and detached processes, and it should be accurate, i.e. eventually permanently include reachable processes <ref> [HS95, BG93, BDM97] </ref>. Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment [FLP85, CHTCB96], since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95].
Reference: [Bir93] <author> K. P. Birman. </author> <title> The Process Group Approach to Reliable Distributed Computing. </title> <journal> Communications of the ACM, </journal> <volume> 36(12), </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: It states that if two processes install the same two consecutive views, then they receive the same set of messages in the former. This requirement was first introduced in the Isis literature <ref> [BJ87, Bir94, BSS91, Bir93] </ref> in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony".
Reference: [Bir94] <author> K. P. Birman. </author> <title> Reliable Distributed Computing with the Isis Toolkit, chapter Virtual Synchrony Model. </title> <publisher> IEEE Press, </publisher> <year> 1994. </year> <month> 74 </month>
Reference-contexts: It states that if two processes install the same two consecutive views, then they receive the same set of messages in the former. This requirement was first introduced in the Isis literature <ref> [BJ87, Bir94, BSS91, Bir93] </ref> in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony".
Reference: [Bir96] <author> K. Birman. </author> <title> Building Secure and Reliable Network Applications, </title> <type> chapter 18. Manning, </type> <year> 1996. </year>
Reference-contexts: Nonetheless, not all the specifications are useful for all the applications. Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications <ref> [Bir96] </ref>: different GCSs were tailored for different applications, which require different semantics and QoS options. <p> Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications <ref> [Bir96] </ref>: different GCSs are tailored to different applications, which require different semantics and qualities of service. The Horus [vRBM96] system tackled this problem with a new paradigm: modularity. Horus and its successor Ensemble [HvR96] are flexible GCSs comprised of independent protocol layers that implement different service levels and semantics.
Reference: [BJ87] <author> K. P. Birman and T. Joseph. </author> <title> Exploiting Virtual Synchrony in Distributed Systems. </title> <booktitle> In 11th Ann. Symp. Operating Systems Principles, </booktitle> <pages> pages 123-138, </pages> <month> Nov 87. </month>
Reference-contexts: In such environments, the GCS simulates a "benign" world in which message delivery is reliable within the set of reachable (live and connected) processes. Furthermore, several GCSs provide semantic models such as Virtual Synchrony <ref> [BJ87] </ref>, Strong Virtual Synchrony [FvR95] and Extended Virtual Synchrony [MAMSA94]. Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis <ref> [BJ87] </ref>, Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis <ref> [BJ87] </ref>, Horus [FvR95] and Totem [AMMS + 95]. Virtual Synchrony (Requirement 5.2.5) is perhaps the most well known property of GCSs, to the extent that it engendered the whole Virtual Synchrony model. <p> It states that if two processes install the same two consecutive views, then they receive the same set of messages in the former. This requirement was first introduced in the Isis literature <ref> [BJ87, Bir94, BSS91, Bir93] </ref> in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis <ref> [BJ87] </ref>, Horus [FvR95], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95], Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. <p> This requirement thus incurs extra latency for message delivery. Among the group communication systems that support strong virtual synchrony are Isis <ref> [BJ87] </ref> and Totem [AMMS + 95]. In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications [MAMSA94, FLS97, HS95]. <p> It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis <ref> [BJ87] </ref>, Transis [DMS96], Totem [AMMS + 95], Horus [FvR95] and Newtop [EMS95]. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. <p> They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis <ref> [BJ87] </ref>, Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. <p> Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. This order extends the fifo order by requiring that a response m 0 to a message m is always delivered after the delivery of m. The CBCAST primitive of Isis <ref> [BJ87] </ref> was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. <p> The CBCAST primitive of Isis <ref> [BJ87] </ref> was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). <p> This requirement is meaningful only if Requirement 5.2.4 (Same View Delivery) holds. In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis <ref> [BJ87] </ref> was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis <ref> [BJ87] </ref> was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> According to Requirement 5.3.5 (Reliable fifo), if a process p delivers a message m that was sent by process q in view V , then p delivers every message that q sent before m in V . Horus [FvR95] and RMP [WMK95] provide this service. Isis <ref> [BJ87] </ref>, Transis [DMS96], Totem [AMMS + 95], New-top [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery. <p> Requirement 5.3.6 (Reliable Causal) states that if two messages m 1 and m 2 were sent in view V , m 1 causally precedes m 2 and m 2 was delivered at some process p, then p also delivered m 1 . An appropriate QoS level exists in Isis <ref> [BJ87] </ref>, Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92]. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery. <p> Isis <ref> [BJ87] </ref> gives weak incorporated semantics between messages sent by AB-CAST and CBCAST multicast primitives. However, this system has another total order multicast primitive, GBCAST, so that messages sent by GBCAST and CBCAST primitives are ordered according to strong incorporated semantics.
Reference: [BSS91] <author> K. P. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight Causal and Atomic Group Multicast. </title> <journal> ACM Trans. on Comp. Syst., </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <year> 1991. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS <ref> [BSS91] </ref>, New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are <p> Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis <ref> [BSS91] </ref>, Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems [DMS96, EMS95, BDM97, FLS97]. <p> It states that if two processes install the same two consecutive views, then they receive the same set of messages in the former. This requirement was first introduced in the Isis literature <ref> [BJ87, Bir94, BSS91, Bir93] </ref> in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony".
Reference: [CAB + 86] <author> Robert L. Constable, Stuart F. Allen, H.M. Bromley, W.R. Cleaveland, J.F. Cre-mer, R.W. Harper, Douglas J. Howe, T.B. Knoblock, N.P. Mendler, P. Panangaden, James T. Sasaki, and Scott F. Smith. </author> <title> Implementing Mathematics with the Nuprl Development System. </title> <publisher> Prentice-Hall, </publisher> <year> 1986. </year>
Reference-contexts: If the protocol solving the problem is also presented as a set of sentences describing its execution, then the problem specifications should be derived from the axioms and the protocol description using first logic proofs. Automatic proof tools (e.g. Nuprl <ref> [CAB + 86] </ref>) can be employed for this purpose. However, the description of implementations often contains not first order properties and hence the proofs cannot be turned directly into first order proofs.
Reference: [CHD] <author> G. Chockler, N. Huleihel, and D. Dolev. ARTOP: </author> <title> An Adaptive Randomized Total Ordering Protocol. </title> <note> Submitted for publication. </note>
Reference-contexts: Transis [ADKM92b] may be configured to use one of several protocols providing agreed delivery. More efficient ARTOP protocol [Cho97] guarantees only weak incorporated semantics between a reliable causal message and a strongly agreed message. On the other hand, the "all-ack" protocol <ref> [DM95, CHD] </ref> guarantees strong incorporated semantics between messages of these two types, but it incurs longer delivery latency.
Reference: [CHKD96] <author> G. Chockler, N. Huleihel, I. Keidar, and D. Dolev. </author> <title> Multimedia Multicast Transport Service for Groupware. </title> <booktitle> In TINA Conference on the Convergence of Telecommunications and Distributed Computing Technologies, </booktitle> <month> September </month> <year> 1996. </year> <note> Full version available as Technical Report CS96-3, </note> <institution> The Hebrew University, Jerusalem, Israel. </institution>
Reference-contexts: Another benefit of modularity is its flexibility to incorporate a variety of QoS options. Recently, several emerging projects addressed the challenge of incorporating QoS communication into the framework of group communication. For example, the MMTS <ref> [CHKD96] </ref> extends the Tran-sis [ADKM92b, DM96] GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed <p> For example, in RMP, the unreliable QoS level provides the guarantees of the underlying communication. Similarly, the MMTS <ref> [CHKD96] </ref> extends Transis [ADKM92b, DM96] by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications.
Reference: [Cho97] <author> G. V. Chockler. </author> <title> An Adaptive Totally Ordered Multicast Protocol that Tolerates Partitions. </title> <type> Master's thesis, </type> <institution> Inst. of Computer Science, The Hebrew University of Jerusalem, </institution> <year> 1997. </year>
Reference-contexts: Modular design has another important advantage: it is possible to separately reason about the guarantees of each layer and the correctness of its implementation. Recently, the I/O automata formalism was exploited for specification and reasoning about GCSs <ref> [FLS97, Cho97] </ref>. The modular "layered" design nicely maps into compositions of I/O automata. This approach uncovers the subtleties of the interaction between the GCS and its applications, as well as among the layers of the GCS. Another benefit of modularity is its flexibility to incorporate a variety of QoS options. <p> It is exactly the View-Synchronous Communication Service M2 requirement of [BDM95]. This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like <ref> [Cho97] </ref>. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis [BJ87], Horus [FvR95] and Totem [AMMS + 95]. <p> This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix [MFSW95], Horus [vRHB94], Transis <ref> [Cho97] </ref> and RMP [WMK95]. Since processes do not know they are going to disconnect before they actually do, messages delivered under weak agreed semantics also comply with Strong Agreed Delivery until the moment of a link failure. <p> However, this system has another total order multicast primitive, GBCAST, so that messages sent by GBCAST and CBCAST primitives are ordered according to strong incorporated semantics. Transis [ADKM92b] may be configured to use one of several protocols providing agreed delivery. More efficient ARTOP protocol <ref> [Cho97] </ref> guarantees only weak incorporated semantics between a reliable causal message and a strongly agreed message. On the other hand, the "all-ack" protocol [DM95, CHD] guarantees strong incorporated semantics between messages of these two types, but it incurs longer delivery latency.
Reference: [CHTCB96] <author> T. D. Chandra, V. Hadzilacos, S. Toueg, and B. Charron-Bost. </author> <title> On the Impossibility of Group Membership. </title> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 322-330, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Therefore, many of the suggested specifications turned out to be too trivial, and in particular, solvable by weaker algorithms than the actual implementations, or even by trivial algorithms [ACBMT95]. Other specifications turned out to be too strong to implement <ref> [CHTCB96] </ref>. In this work, we address the non-triviality issues and suggest ways to circumvent the impossibility results using external failure 6 detectors or by reasoning about liveness guarantees at stability periods. <p> Therefore, when restricted to the fail-stop model, our desired membership service is as strong as an eventual perfect failure detector [CT96], which is not implementable in asynchronous fail-stop environments. In fact, it has been proven by <ref> [CHTCB96] </ref> that even a very weak version of the group membership problem is not solvable in asynchronous environments. 3.2.2 The "Best Effort" Principle Practical systems cannot do the impossible, they can only make their "best-effort". <p> In order to be precise, a membership service should be complete, i.e. eventually exclude crashed and detached processes, and it should be accurate, i.e. eventually permanently include reachable processes [HS95, BG93, BDM97]. Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment <ref> [FLP85, CHTCB96] </ref>, since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. <p> In particular, if there was only one class, no messages would need to be sent. Unfortunately, an accurate membership service in an asynchronous environment is impossible <ref> [FLP85, CHTCB96] </ref>. Therefore, there is no way for a process to know the precise membership of its class.
Reference: [Cri91] <author> Flaviu Cristian. </author> <title> Reaching agreement on processor group membership in synchronous distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 4(4) </volume> <pages> 175-187, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], <ref> [Cri91] </ref> and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], <ref> [Cri91] </ref> and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition.
Reference: [Cri96] <author> Flaviu Cristian. </author> <title> Group, majority, and strict agreement in timed asynchronous distributed systems. </title> <booktitle> In International Symposium on Fault-Tolerant Computing, number 26th, </booktitle> <year> 1996. </year>
Reference-contexts: The state transfer tool of Isis [BCJ + 90] was, perhaps, the first to provide a generic solution to the State Transfer problem, It did this, though, within the framework of a primary partition model. Other work tackling the state transfer problem can be found in <ref> [Cri96, BBD96, HK94] </ref>. The approach presented in [BBD96] is the closest to ours. This work defines the shared state problem in a partitionable environment and contains a detailed survey of its different aspects.
Reference: [CS95] <author> F. Cristian and F. Schmuck. </author> <title> Agreeing on Process Group Membership in Asynchronous Distributed Systems. </title> <type> Technical Report CSE95-428, </type> <institution> Department of Conmputer Science and Engineering, University of California, </institution> <address> San Diego, </address> <year> 1995. </year>
Reference-contexts: This local counter is incremented by a process upon each installation. The counters in [FLS97] and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. In Phoenix [MS95], Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] and in the specifications of <ref> [CS95] </ref> a view is a set of pairs &lt; p i ; c i &gt; where p i is a process identifier and c i is a value of a local counter on p i . <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of <ref> [MAMSA94, FLS97, BBD96, CS95, JFR93] </ref>. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97].
Reference: [CT96] <author> Tushar Deepak Chandra and Sam Toueg. </author> <title> Unreliable failure detectors for reliable distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 43(2) </volume> <pages> 225-267, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Therefore, when restricted to the fail-stop model, our desired membership service is as strong as an eventual perfect failure detector <ref> [CT96] </ref>, which is not implementable in asynchronous fail-stop environments. <p> For example, [FvR95, DMS96] require that a process not be removed from the view unless it is a suspect. Other specifications [MS95, BDM95] take this approach one step further, and exploit the notion of eventual perfect failure detectors <ref> [CT96] </ref>. An eventual perfect failure detector eventually suspects all faulty processes and also eventually permanently stops suspecting non-faulty ones. <p> Unfortunately, such a "perfect" membership service is impossible to implement in an asynchronous system: A service that fulfills this property in a crash-failure environment is in particular an eventually perfect failure detector (as defined in <ref> [CT96] </ref>), and such a failure detector is impossible to implement in an asynchronous environment prone to process failures. However, we do expect of a membership service to use some failure detection mechanism based on time-outs or other methods (e.g. , [Vog96]) which attempts to approximate the network situation. <p> The GCS uses the failure detector in order to detect conditions under which the membership protocol should be invoked. Furthermore, the failure detector provides an initial approximation of the view that the membership service would agree upon. Chandra and Toueg <ref> [CT96] </ref> define several classes of unreliable failure detectors, which are strong enough to solve agreement problems like Consensus in asynchronous environments. In particular, they define an eventual perfect failure detector which eventually suspects all crashed processes and also eventually permanently stops suspecting correct processes.
Reference: [DFKM96] <author> D. Dolev, R. Friedman, I. Keidar, and D. Malki. </author> <title> Failure Detectors in Omission Failure Environments. </title> <type> TR 96-13, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <month> September </month> <year> 1996. </year> <type> Also Technical Report 96-1608, </type> <institution> Department of Computer Science, Cornell University. </institution> <note> Available in: 'ftp://ftp.cs.huji.ac.il/users/transis/FD-TR.ps.gz'. 75 </note>
Reference-contexts: Chandra and Toueg [CT96] define several classes of unreliable failure detectors, which are strong enough to solve agreement problems like Consensus in asynchronous environments. In particular, they define an eventual perfect failure detector which eventually suspects all crashed processes and also eventually permanently stops suspecting correct processes. In <ref> [DFKM96] </ref>, this definition is adapted to partitionable environments. The definitions we present in this paper (in Section 5.1.5) follow the ones of [DFKM96]. <p> In particular, they define an eventual perfect failure detector which eventually suspects all crashed processes and also eventually permanently stops suspecting correct processes. In <ref> [DFKM96] </ref>, this definition is adapted to partitionable environments. The definitions we present in this paper (in Section 5.1.5) follow the ones of [DFKM96]. We use these definitions in Requirement 5.1.5 (Preciseness): We require that if the failure detector is an eventual perfect failure detector, then when the network eventually stabilizes the membership service will eventually correctly reflect the network situation.
Reference: [DKM93] <author> D. Dolev, S. Kramer, and D. Malki. </author> <title> Early Delivery Totally Ordered Broadcast in Asynchronous Environments. </title> <booktitle> In 23rd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 544-553, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis <ref> [DKM93] </ref>, Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery.
Reference: [DM95] <author> D. Dolev and D. Malki. </author> <title> The design of the transis system. </title> <editor> In K. P. Birman, F. Mattern, and A. Schipper, editors, </editor> <booktitle> Theory and Practice in Distributed Systems: International Workshop, </booktitle> <pages> pages 83-98. </pages> <publisher> Springer, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science 938. </note>
Reference-contexts: Transis [ADKM92b] may be configured to use one of several protocols providing agreed delivery. More efficient ARTOP protocol [Cho97] guarantees only weak incorporated semantics between a reliable causal message and a strongly agreed message. On the other hand, the "all-ack" protocol <ref> [DM95, CHD] </ref> guarantees strong incorporated semantics between messages of these two types, but it incurs longer delivery latency.
Reference: [DM96] <author> D. Dolev and D. Malkhi. </author> <title> The Transis Approach to High Availability Cluster Communication. </title> <journal> Communications of the ACM, </journal> <volume> 39(4), </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: Another benefit of modularity is its flexibility to incorporate a variety of QoS options. Recently, several emerging projects addressed the challenge of incorporating QoS communication into the framework of group communication. For example, the MMTS [CHKD96] extends the Tran-sis <ref> [ADKM92b, DM96] </ref> GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications. 3.2 <p> For example, in RMP, the unreliable QoS level provides the guarantees of the underlying communication. Similarly, the MMTS [CHKD96] extends Transis <ref> [ADKM92b, DM96] </ref> by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications.
Reference: [DMS94] <author> D. Dolev, D. Malki, and H. R. </author> <title> Strong. An Asynchronous Membership Protocol that Tolerates Partitions. </title> <type> TR 94-6, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Yet few would argue that IP is useless. 3.2.3 Circumventing the Impossibility Result Specifications of group communication were made non-trivial using a variety of techniques. The first attempts at non-trivial membership specifications <ref> [DMS94] </ref> ruled out only those classes of trivial algorithms which, despite changes in the actual network situation, might at some point cease reporting view changes. These attempts were criticized as too trivial in [ACBMT95].
Reference: [DMS96] <author> D. Dolev, D. Malki, and H. R. </author> <title> Strong. A Framework for Partitionable Membership Service. </title> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, </booktitle> <month> May </month> <year> 1996. </year> <note> Full version vailable as TR94-6, </note> <institution> Inst. of Comp. Sci., the Hebrew University of Jerusalem. </institution>
Reference-contexts: This service provides information regarding the transitional set, which is defined in Section 5.1 and discussed in Section 6.3.2. The transitional set was initially proposed as a basic concept of the Extended Virtual Synchrony model (EVS) <ref> [MAMSA94, DMS96] </ref>. The transitional membership notification, which complements the regular membership notification, enables each replica to locally determine the set of other members that have the same state. Our proposed State Transfer Module may be implemented on top of any group communication layer that provides specifications defined in Chapter 5. <p> These attempts were criticized as too trivial in [ACBMT95]. Later specifications explicitly linked the behavior of the GCS to the output of an external failure detector module. The output of a failure detector is a list of suspects, i.e., processes which are suspected to be faulty. For example, <ref> [FvR95, DMS96] </ref> require that a process not be removed from the view unless it is a suspect. Other specifications [MS95, BDM95] take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. <p> A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. In addition, a view usually contains some identifier that distinguishes between different views with the same set of processes. In Transis <ref> [DMS96] </ref> this is a positive integer agreed upon all by the members of the view using a membership protocol. This integer is computed based on the values of local counters, maintained by all processes. This local counter is incremented by a process upon each installation. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> In [HS95] these possibilities are called individual startup and collective startup, respectively. In most of the existing group communication systems and specifications the latter approach is used, though Transis <ref> [DMS96] </ref> presents an exception. In a primary partition membership service installing a singleton view does not make sense. 6.2.4 Basic requirement Requirement 5.1.2 allows processes to install only those views of which they are members. <p> Since a membership of a view reflects the ability to communicate with the process and a process is always able to communicate with itself, this requirement is trivial and holds in all group communication systems and specifications, as explicitly specified in <ref> [DMS96, FvR95, EMS95, BDM95] </ref>. Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> It is possible in principle to overcome this problem by saving information on a disk before each view installation. However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] or above a group communication system conforming with the specifications of [Nei96] or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. <p> The latter circumstance renders the membership protocol more complicated and less efficient, because it demands at least two rounds of communication. Thus, only a few GCSs (e.g. Transis <ref> [DMS96] </ref> and Relacs [BDM97]) support this requirement, even in the absence of crashes. [YLKD97] is also concerned with this requirement implementation. 6.2.6 Non-triviality of membership Preciseness (Requirement 5.1.5) is one of the most fundamental properties of a membership service. <p> This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems <ref> [DMS96, EMS95, BDM97, FLS97] </ref>. Our approach is to guarantee that the the membership service will eventually be precise, provided that some well-defined conditions on the underlying network hold, as explained below. <p> According to Requirement 5.2.3 (Termination of Delivery) processes within a connected component eventually deliver each other's messages. This requirement precludes trivial protocols that never deliver messages or that deliver messages only before view changes. Similar termination requirements can be found in <ref> [DMS96] </ref>, [FvR95] and [BDM95]. This requirement is not fulfilled by Unreliable QoS levels (e.g. in RMP [WMK95]). <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service <ref> [FvR95, DMS96, EMS95, MAMSA94, BDM95] </ref>. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], Newtop [EMS95], Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. <p> It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis [BJ87], Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], Horus [FvR95] and Newtop [EMS95]. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. <p> They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. <p> The CBCAST primitive of Isis [BJ87] was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis <ref> [DMS96] </ref>, Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). <p> According to Requirement 5.3.5 (Reliable fifo), if a process p delivers a message m that was sent by process q in view V , then p delivers every message that q sent before m in V . Horus [FvR95] and RMP [WMK95] provide this service. Isis [BJ87], Transis <ref> [DMS96] </ref>, Totem [AMMS + 95], New-top [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis <ref> [DMS96] </ref>, Horus [vRHB94], Newtop [EMS95] and xAMp [RV92]. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery.
Reference: [EMS95] <author> P. D. Ezhilchelvan, A. Macedo, and S. K. Shrivastava. Newtop: </author> <title> a fault tolerant group communication protocol. </title> <booktitle> In International Conference on Distributed Computing Systems, number 15th, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top <ref> [EMS95] </ref>, Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop <ref> [EMS95] </ref>, Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously <p> On the other hand, other group communication systems and specifications strengthen this assumption even more and rely on the underlying protocol to provide the fifo order of low level message delivery <ref> [EMS95, Nei96, HS95, SS93] </ref>. Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions [SS93] and also eliminates message duplications [EMS95]. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. <p> Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions [SS93] and also eliminates message duplications <ref> [EMS95] </ref>. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. It states that the application does not send more than one message with the same contents, and thus each message is uniquely identified by its contents. <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> If two views contain the same p i , then the later view has greater c i . In Newtop <ref> [EMS95] </ref> a logical timestamp is used to sign all messages. The maximum value of this timestamp at the moment of the new view creation satisfies all the requirements of a view identifier. In RMP [WMK95] a membership protocol is asymmetric and has a coordinator. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop <ref> [EMS95] </ref> and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Since a membership of a view reflects the ability to communicate with the process and a process is always able to communicate with itself, this requirement is trivial and holds in all group communication systems and specifications, as explicitly specified in <ref> [DMS96, FvR95, EMS95, BDM95] </ref>. Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> Applications running above Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] or above a group communication system conforming with the specifications of [Nei96] or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop <ref> [EMS95] </ref> logical timestamp comparison can serve this purpose. In Phoenix [MS95] a view contains local counter values along with process identifiers. Thus, two views having a process in the intersection can be compared by comparing the counter values of this common process. <p> This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems <ref> [DMS96, EMS95, BDM97, FLS97] </ref>. Our approach is to guarantee that the the membership service will eventually be precise, provided that some well-defined conditions on the underlying network hold, as explained below. <p> This requirement is less trivial than Delivery Integrity, because the underlying network usually may duplicate messages. Most GCSs eliminate duplication <ref> [BDM95, EMS95, ADKM92b] </ref>. However, when a GCS 48 directly provides QoS of the underlying communication layer, duplication is not eliminated, e.g., in the Unreliable and Unordered QoS levels of RMP [WMK95]. Unfortunately, there is no general way to guarantee a certain latency of delivery in asynchronous systems. <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service <ref> [FvR95, DMS96, EMS95, MAMSA94, BDM95] </ref>. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis [DMS96], Totem [AMMS + 95], Newtop <ref> [EMS95] </ref>, Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. <p> This requirement thus incurs extra latency for message delivery. Among the group communication systems that support strong virtual synchrony are Isis [BJ87] and Totem [AMMS + 95]. In contrast, Newtop <ref> [EMS95] </ref> and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications [MAMSA94, FLS97, HS95]. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. <p> Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Horus [FvR95] and Newtop <ref> [EMS95] </ref>. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, [FLS97] and [FV97] present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. <p> They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Newtop <ref> [EMS95] </ref> and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. This order extends the fifo order by requiring that a response m 0 to a message m is always delivered after the delivery of m. <p> The CBCAST primitive of Isis [BJ87] was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop <ref> [EMS95] </ref> and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). <p> In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop <ref> [EMS95] </ref>, xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> Horus [FvR95] and RMP [WMK95] provide this service. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], New-top <ref> [EMS95] </ref> and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop <ref> [EMS95] </ref> and xAMp [RV92]. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery.
Reference: [FLP85] <author> M. Fischer, N. Lynch, and M. Paterson. </author> <title> Impossibility of Distributed Consensus with One Faulty Process. </title> <journal> J. ACM, </journal> <volume> 32 </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: In order to be precise, a membership service should be complete, i.e. eventually exclude crashed and detached processes, and it should be accurate, i.e. eventually permanently include reachable processes [HS95, BG93, BDM97]. Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment <ref> [FLP85, CHTCB96] </ref>, since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. <p> In particular, if there was only one class, no messages would need to be sent. Unfortunately, an accurate membership service in an asynchronous environment is impossible <ref> [FLP85, CHTCB96] </ref>. Therefore, there is no way for a process to know the precise membership of its class.
Reference: [FLS97] <author> A. Fekete, N. Lynch, and A. Shvartsman. </author> <title> Specifying and Using a Partitionable Group Communication Service. </title> <note> To appear in PODC, </note> <year> 1997. </year>
Reference-contexts: Such modular GCSs easily adapt to a variety of application needs. Traditionally, GCS developers concentrated primarily on system performance, in order to make their systems useful for real-world distributed applications. Only recently, the challenging task of specifying the semantics and services of GCSs has become an active research area <ref> [MAMSA94, FvR95, BDM95, FLS97] </ref>, but as of yet, no commonly accepted specifications have been established. The guarantees of different GCSs are stated using different terminologies and modeling techniques, and the specifications vary greatly in their rigor. <p> Many suggested specifications are complicated and difficult to understand, and some were shown to be ambiguous [ACBMT95]. This makes it difficult to analyze and compare the different systems. Furthermore, it is often unclear whether a given specification is necessary or sufficient for a certain application <ref> [FLS97] </ref>. In this work we formulate a comprehensive set of specification "building blocks" which may be combined to represent the guarantees of most existing GCSs. We specify clear and rigorous requirements formalized as trace properties of I/O automata [LT89, Lyn96] using a first order logic modeling technique [Avr98]. <p> We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> We say that fi is a fair trace of A if fi is the trace of a fair execution of A. We denote the set of fair traces of A by f airtraces (A). 2.2.6 Trace Properties The specifications in <ref> [FLS97] </ref> are defined using abstract implementations of I/O automata. The description of those implementations encompasses all aspects of the model. On contrary, this work is not concerned with an internal system implementation (even at an abtract level), but rather with external properties, visible to the user. <p> Modular design has another important advantage: it is possible to separately reason about the guarantees of each layer and the correctness of its implementation. Recently, the I/O automata formalism was exploited for specification and reasoning about GCSs <ref> [FLS97, Cho97] </ref>. The modular "layered" design nicely maps into compositions of I/O automata. This approach uncovers the subtleties of the interaction between the GCS and its applications, as well as among the layers of the GCS. Another benefit of modularity is its flexibility to incorporate a variety of QoS options. <p> Note that the eventual perfect failure detector is used here as an analysis tool to identify external conditions under which the membership service behaves correctly. We take this approach in this paper. Another approach <ref> [FLS97] </ref> is to guarantee correct behavior of the GCS at periods during which the underlying network is stable and timely. The specifications of [FLS97] are stronger than the 21 failure detector based ones in that they guarantee the timeliness of the service and not just eventual termination. <p> We take this approach in this paper. Another approach <ref> [FLS97] </ref> is to guarantee correct behavior of the GCS at periods during which the underlying network is stable and timely. The specifications of [FLS97] are stronger than the 21 failure detector based ones in that they guarantee the timeliness of the service and not just eventual termination. Of course, such guarantees can only be made when network message delivery and process scheduling are timely. <p> This integer is computed based on the values of local counters, maintained by all processes. This local counter is incremented by a process upon each installation. The counters in <ref> [FLS97] </ref> and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of <ref> [MAMSA94, FLS97, BBD96, CS95, JFR93] </ref>. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. <p> Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. For such applications some partitionable GCSs provide a primary partition notification to the members of exactly one partition [FvR95, HS95]. 6.2.3 The initial view All send and delivery events always occur in some view. <ref> [FLS97] </ref> assumes that processes start up with some default view. Otherwise, the first view installation is always a first event in the 44 history of each process, unless the process crashes before installing that view. This first view may be a singleton view, as stated in Requirement 5.1.1. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] and specifications <ref> [Nei96, FLS97] </ref> as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. Otherwise,crashes entail the violation of Requirement 5.1.3, as indeed occurs in most of the systems and specifications. <p> However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] or above a group communication system conforming with the specifications of [Nei96] or <ref> [FLS97] </ref> can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. In Phoenix [MS95] a view contains local counter values along with process identifiers. <p> This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul [MPS91b] and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems <ref> [DMS96, EMS95, BDM97, FLS97] </ref>. Our approach is to guarantee that the the membership service will eventually be precise, provided that some well-defined conditions on the underlying network hold, as explained below. <p> Furthermore, our preciseness requirement provides a rigorous definition of common network conditions under which the membership service is guaranteed to be precise. The obvious shortcoming of this analysis is its eventuality. Any protocol that behaves capriciously for a finite time period may satisfy this requirement. The approach of <ref> [FLS97] </ref> is not only to guarantee "good" behavior of the GCS during periods at which the underlying network behaves "well", but also to impose timing constraints on the membership service. As in our approach, the system is equipped with a global discrete clock which is unaccessible to processes. <p> It also appears in many specifications like <ref> [FLS97] </ref> and [HS95]. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. <p> In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications <ref> [MAMSA94, FLS97, HS95] </ref>. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. <p> In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, <ref> [FLS97] </ref> and [FV97] present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. Thus, the specifications of [FLS97] do not include Self-delivery. 6.4 Ordering Requirements As noticed above in Section 6.3.1, group communication systems provide different group multicast services with a variety of ordering and reliability guarantees. <p> It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, <ref> [FLS97] </ref> and [FV97] present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. Thus, the specifications of [FLS97] do not include Self-delivery. 6.4 Ordering Requirements As noticed above in Section 6.3.1, group communication systems provide different group multicast services with a variety of ordering and reliability guarantees. <p> Reliable Agreed is the highest QoS level in the ordering hierarchy. This property simplifies semantics of distributed application and the protocols in <ref> [FLS97] </ref> and in [FV97] make use of Reliable Agreed delivery. Unfortunately, Requirements 5.2.5, 5.2.6, 5.2.7 and this requirement cannot hold at the same time. Furthermore, even though a GCS does not support Requirement 5.2.7, implementing Reliable Agreed delivery either implies a severe execution penalty or forces deliberately discarding messages. <p> Here K (N) is a service parameter. In this work we follow the alternative approach employed, for example, in <ref> [FLS97] </ref>. Instead of deferring delivery until the message becomes stable, a message is delivered according to its QoS level without additional delay. However, this delivery is augmented with the delivery of Safe 53 Prefix Indications. <p> This is stated in Requirement 5.4.1 (Safe Indication Usage). In particular, from the case that q = p we can deduce that all messages delivered by p before m are also safe. That is why we call it safe prefix indication. Such safe prefix indications exist, for example, in <ref> [FLS97] </ref>. Note that this approach presents more simple semantics, because now there is no need to deliver transitional views [MAMSA94]. These semantics are also more flexible and powerful, because even applications that require message stability can partly process a message right after its delivery. <p> An important consequence of Requirement 5.4.1, is that if an agreed message is indicated as safe, it also satisfies the Reliable Agreed Delivery property (Requirement 5.3.7). This property is exploited by the applications in [ADMSM94], [KD96] and <ref> [FLS97] </ref>. It is supported by Totem [AMMS + 95] and Transis [ADKM92b] that do not provide Reliable Agreed Delivery (Requirement 5.3.7). A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception. <p> The application can also learn about partial k-stability [vRHB94], i.e. that k members have seen the message. Requirement 5.4.2 (Safe Indication Non-triviality) states that if there are no view changes then messages are eventually indicated as safe. Thus, any GCS or specifications providing safe prefix indications (e.g. <ref> [FLS97] </ref>) would satisfy this requirement. 54 Chapter 7 Conclusions and Future Work We have presented a comprehensive set of specifications which may be combined to represent the guarantees of most existing GCSs.
Reference: [FV97] <author> R. Friedman and A. Vaysburg. </author> <title> Fast Replicated State Machines Over Partitionable Networks. </title> <booktitle> In the IEEE International Symposium on Reliable Distributed Systems, number 16th, </booktitle> <month> October </month> <year> 1997. </year> <type> Also Technical Report 97-1639, </type> <institution> Department of Computer Science, Cornell University. </institution>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> Requirement 5.1.3 has another significant consequence: if two processes install the same two views, they install these views in the same order. The importance of view ordering properties is noted and emphasized in several works, for example in <ref> [HS95, FV97] </ref>. This feature is exploited by numerous applications, e.g. [KD96], [Ami95] and [FV97]. Requirement 5.1.4 (Termination of Membership) guarantees that if a process p installs a view V , then either all members of V install V or p installs a next view (unless it crashes). <p> The importance of view ordering properties is noted and emphasized in several works, for example in [HS95, FV97]. This feature is exploited by numerous applications, e.g. [KD96], [Ami95] and <ref> [FV97] </ref>. Requirement 5.1.4 (Termination of Membership) guarantees that if a process p installs a view V , then either all members of V install V or p installs a next view (unless it crashes). Usually, when several processes install the same new view, they exchange messages. <p> Causal monotony (Requirement 5.1.7) extends the partial order of views defined by Requirement 5.1.3. Intuitively, it states that a view identifier should reflect the "causal" order of events in the system. This requirement serves the same purposes as the ordering properties of [HS95] and <ref> [FV97] </ref>. When two processes reconnect, they can exploit this property to find out which process is more updated, i.e. was a member of a later primary partition in the global history. This information is useful for the implementation of a consistent replication service [ADMSM94, KD96]. <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In [MAMSA94] and <ref> [FV97] </ref> it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. Such applications change their state when they receive application messages and membership changes <ref> [HS95, FV97, ACDV97] </ref>. However, we are aware of only few distributed applications that explicitly base their operation on Virtual Synchrony, since Virtual Synchrony is an "external observer" requirement, formulated in terms of two processes that proceed together through the same two consecutive views. <p> Instead of regular views the membership service provides enriched views, which contain more useful information. Among other things, an enriched view relays information regarding the previous view of each of its members. Thus, the transitional set can be deduced from the enriched view. Horus <ref> [FvR95, FV97] </ref> overcomes this difficulty by requiring the Agreement on Successors property: if a process p installs two consecutive views V 1 and V 2 , both containing a process q, and q also installs V 2 , then q installed V 1 right before V 2 and Virtual Synchrony is <p> In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, [FLS97] and <ref> [FV97] </ref> present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. Thus, the specifications of [FLS97] do not include Self-delivery. 6.4 Ordering Requirements As noticed above in Section 6.3.1, group communication systems provide different group multicast services with a variety of ordering and reliability guarantees. <p> Reliable Agreed is the highest QoS level in the ordering hierarchy. This property simplifies semantics of distributed application and the protocols in [FLS97] and in <ref> [FV97] </ref> make use of Reliable Agreed delivery. Unfortunately, Requirements 5.2.5, 5.2.6, 5.2.7 and this requirement cannot hold at the same time. Furthermore, even though a GCS does not support Requirement 5.2.7, implementing Reliable Agreed delivery either implies a severe execution penalty or forces deliberately discarding messages.
Reference: [FvR95] <author> Roy Friedman and Robbert van Renesse. </author> <title> Strong and Weak Virtual Synchrony in Horus. </title> <type> TR 95-1537, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Such modular GCSs easily adapt to a variety of application needs. Traditionally, GCS developers concentrated primarily on system performance, in order to make their systems useful for real-world distributed applications. Only recently, the challenging task of specifying the semantics and services of GCSs has become an active research area <ref> [MAMSA94, FvR95, BDM95, FLS97] </ref>, but as of yet, no commonly accepted specifications have been established. The guarantees of different GCSs are stated using different terminologies and modeling techniques, and the specifications vary greatly in their rigor. <p> In such environments, the GCS simulates a "benign" world in which message delivery is reliable within the set of reachable (live and connected) processes. Furthermore, several GCSs provide semantic models such as Virtual Synchrony [BJ87], Strong Virtual Synchrony <ref> [FvR95] </ref> and Extended Virtual Synchrony [MAMSA94]. Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. <p> These attempts were criticized as too trivial in [ACBMT95]. Later specifications explicitly linked the behavior of the GCS to the output of an external failure detector module. The output of a failure detector is a list of suspects, i.e., processes which are suspected to be faulty. For example, <ref> [FvR95, DMS96] </ref> require that a process not be removed from the view unless it is a suspect. Other specifications [MS95, BDM95] take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> This local counter is incremented by a process upon each installation. The counters in [FLS97] and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. In Phoenix [MS95], Totem [AMMS + 95], Horus <ref> [FvR95] </ref>, Relacs [BDM97] and in the specifications of [CS95] a view is a set of pairs &lt; p i ; c i &gt; where p i is a process identifier and c i is a value of a local counter on p i . <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus <ref> [FvR95] </ref>, RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. For such applications some partitionable GCSs provide a primary partition notification to the members of exactly one partition <ref> [FvR95, HS95] </ref>. 6.2.3 The initial view All send and delivery events always occur in some view. [FLS97] assumes that processes start up with some default view. <p> Since a membership of a view reflects the ability to communicate with the process and a process is always able to communicate with itself, this requirement is trivial and holds in all group communication systems and specifications, as explicitly specified in <ref> [DMS96, FvR95, EMS95, BDM95] </ref>. Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> It is possible in principle to overcome this problem by saving information on a disk before each view installation. However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis [DMS96], Totem [AMMS + 95], Horus <ref> [FvR95] </ref>, Relacs [BDM97] or above a group communication system conforming with the specifications of [Nei96] or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. <p> According to Requirement 5.2.3 (Termination of Delivery) processes within a connected component eventually deliver each other's messages. This requirement precludes trivial protocols that never deliver messages or that deliver messages only before view changes. Similar termination requirements can be found in [DMS96], <ref> [FvR95] </ref> and [BDM95]. This requirement is not fulfilled by Unreliable QoS levels (e.g. in RMP [WMK95]). <p> According to Requirement 5.2.3 if p installs a view V and sends a message in this view, then either each member q of V delivers this message, or p installs a next view (unless p crashes). In similar requirements of <ref> [FvR95] </ref> and [BDM95] this next view installed at p excludes q. However, this refinement contradicts to the "best-effort accuracy" principle (see a more detailed discussion of the transitional set below). <p> However, this refinement contradicts to the "best-effort accuracy" principle (see a more detailed discussion of the transitional set below). In Transis [ADKM92b] it could also happen that q detached from p, installed another view and now reconnected again (in Horus <ref> [FvR95] </ref> this scenario is impossible due to Agreement on Successors property). In this case, q cannot deliver the message because it would violate Requirement 5.2.4, which is discussed next. Thus, there is no reason for p to exclude q from the next view. <p> This specification is strictly weaker than Requirement 5.2.6 (Same View Delivery), discussed below. However, it is sufficient for some applications like [Cho97]. Requirement 5.2.4 holds in Tran-sis [ADKM92b], Relacs [BDM95] and in all GCSs that support a stronger Requirement 5.2.6. Among the latter are Isis [BJ87], Horus <ref> [FvR95] </ref> and Totem [AMMS + 95]. Virtual Synchrony (Requirement 5.2.5) is perhaps the most well known property of GCSs, to the extent that it engendered the whole Virtual Synchrony model. <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service <ref> [FvR95, DMS96, EMS95, MAMSA94, BDM95] </ref>. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus <ref> [FvR95] </ref>, Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95], Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. <p> Instead of regular views the membership service provides enriched views, which contain more useful information. Among other things, an enriched view relays information regarding the previous view of each of its members. Thus, the transitional set can be deduced from the enriched view. Horus <ref> [FvR95, FV97] </ref> overcomes this difficulty by requiring the Agreement on Successors property: if a process p installs two consecutive views V 1 and V 2 , both containing a process q, and q also installs V 2 , then q installed V 1 right before V 2 and Virtual Synchrony is <p> Though this exclusion does not violate the weak accuracy requirement of 5.1.5, it does contradict the "best-effort accuracy" principle. Requirement 5.2.6 (Synchronous Delivery) states that every message is delivered in the view in which it was sent. <ref> [FvR95] </ref> defines strong and weak virtual synchrony models. The strong virtual synchrony model of [FvR95] includes Requirement 5.2.6 while the weak one does not. This requirement facilitates the writing of distributed applications because it introduces an additional level of synchronization. However, as proven in [FvR95], satisfying Virtual Synchrony, Synchronous Delivery and <p> Requirement 5.2.6 (Synchronous Delivery) states that every message is delivered in the view in which it was sent. <ref> [FvR95] </ref> defines strong and weak virtual synchrony models. The strong virtual synchrony model of [FvR95] includes Requirement 5.2.6 while the weak one does not. This requirement facilitates the writing of distributed applications because it introduces an additional level of synchronization. However, as proven in [FvR95], satisfying Virtual Synchrony, Synchronous Delivery and Self-delivery at the same time requires processes to block sending messages for a certain <p> view in which it was sent. <ref> [FvR95] </ref> defines strong and weak virtual synchrony models. The strong virtual synchrony model of [FvR95] includes Requirement 5.2.6 while the weak one does not. This requirement facilitates the writing of distributed applications because it introduces an additional level of synchronization. However, as proven in [FvR95], satisfying Virtual Synchrony, Synchronous Delivery and Self-delivery at the same time requires processes to block sending messages for a certain time period before a new view is installed. This requirement thus incurs extra latency for message delivery. <p> This requirement thus incurs extra latency for message delivery. Among the group communication systems that support strong virtual synchrony are Isis [BJ87] and Totem [AMMS + 95]. In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus <ref> [FvR95] </ref> can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications [MAMSA94, FLS97, HS95]. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. <p> It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Horus <ref> [FvR95] </ref> and Newtop [EMS95]. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. <p> This is the lowest QoS level in the ordering hierarchy. It is trivially implemented if low level message delivery of the underlying network guarantees fifo order itself. xAMp [RV92] provide several QoS levels that satisfy Requirement 5.3.1 but no stronger order constraints. They differ by their reliability guarantees. Horus <ref> [FvR95] </ref> and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. <p> According to Requirement 5.3.5 (Reliable fifo), if a process p delivers a message m that was sent by process q in view V , then p delivers every message that q sent before m in V . Horus <ref> [FvR95] </ref> and RMP [WMK95] provide this service. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], New-top [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery.
Reference: [HK94] <author> J. H. Howard and S. Katz. Reconciliations. </author> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, number 13th, </booktitle> <pages> pages 14-21. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1994. </year>
Reference-contexts: The state transfer tool of Isis [BCJ + 90] was, perhaps, the first to provide a generic solution to the State Transfer problem, It did this, though, within the framework of a primary partition model. Other work tackling the state transfer problem can be found in <ref> [Cri96, BBD96, HK94] </ref>. The approach presented in [BBD96] is the closest to ours. This work defines the shared state problem in a partitionable environment and contains a detailed survey of its different aspects.
Reference: [HS95] <author> M. Hiltunen and R. Schlichting. </author> <title> Properties of Membership Services. </title> <booktitle> In proc. of 2nd International Symposium on Autonomous Decentralized Systems, </booktitle> <pages> pages 200-207, </pages> <year> 1995. </year>
Reference-contexts: On the other hand, other group communication systems and specifications strengthen this assumption even more and rely on the underlying protocol to provide the fifo order of low level message delivery <ref> [EMS95, Nei96, HS95, SS93] </ref>. Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions [SS93] and also eliminates message duplications [EMS95]. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. <p> Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. <ref> [HS95] </ref> first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. <p> Some application semantics require that only one partition remains active following a partition <ref> [HS95, YLKD97] </ref>. For such applications some partitionable GCSs provide a primary partition notification to the members of exactly one partition [FvR95, HS95]. 6.2.3 The initial view All send and delivery events always occur in some view. [FLS97] assumes that processes start up with some default view. <p> Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. For such applications some partitionable GCSs provide a primary partition notification to the members of exactly one partition <ref> [FvR95, HS95] </ref>. 6.2.3 The initial view All send and delivery events always occur in some view. [FLS97] assumes that processes start up with some default view. <p> This first view may be a singleton view, as stated in Requirement 5.1.1. Alternatively, the first view, like any later view installed by the process, can be a view agreed upon by the membership protocol. In <ref> [HS95] </ref> these possibilities are called individual startup and collective startup, respectively. In most of the existing group communication systems and specifications the latter approach is used, though Transis [DMS96] presents an exception. <p> Requirement 5.1.3 has another significant consequence: if two processes install the same two views, they install these views in the same order. The importance of view ordering properties is noted and emphasized in several works, for example in <ref> [HS95, FV97] </ref>. This feature is exploited by numerous applications, e.g. [KD96], [Ami95] and [FV97]. Requirement 5.1.4 (Termination of Membership) guarantees that if a process p installs a view V , then either all members of V install V or p installs a next view (unless it crashes). <p> Only the installation of a next view guaranteed by Requirement 5.1.4 would interrupt this waiting. This specification also exists in [MAMSA94]. 45 6.2.5 Agreement on membership In general, there is some degree of agreement between processes on the next common view. <ref> [HS95] </ref> presents several possible specifications of such agreement in the context of a primary partition membership service. According to Requirement 5.1.5 1. <p> Note that the second part of this requirement is strictly weaker than the agreement imposed by causal monotony (Requirement 5.1.7) or by view synchrony (Requirement 5.2.5). However, it excludes the possibility of Simple Agreement <ref> [HS95] </ref>, in which a process decides locally that a change has occurred and distributes the information to all other processes. Most of the group communication systems guarantee this latter property. We defer the discussion of Requirement 5.1.6 (transitional set) until the discussion of Requirement 5.2.5 (virtual synchrony) in Section 6.3.2. <p> Causal monotony (Requirement 5.1.7) extends the partial order of views defined by Requirement 5.1.3. Intuitively, it states that a view identifier should reflect the "causal" order of events in the system. This requirement serves the same purposes as the ordering properties of <ref> [HS95] </ref> and [FV97]. When two processes reconnect, they can exploit this property to find out which process is more updated, i.e. was a member of a later primary partition in the global history. This information is useful for the implementation of a consistent replication service [ADMSM94, KD96]. <p> A group communication system is useless if its membership service is not precise at least to some extent. In order to be precise, a membership service should be complete, i.e. eventually exclude crashed and detached processes, and it should be accurate, i.e. eventually permanently include reachable processes <ref> [HS95, BG93, BDM97] </ref>. Unfortunately, no membership service can be both absolutely complete and accurate in an asynchronous environment [FLP85, CHTCB96], since in such environments it is impossible to distinguish a failed process from a slow one. Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. <p> Unfortunately, as we show in Section 3.2, such a desirable membership service is not implementable in purely asynchronous environments. In order to circumvent this impossibility result we augment the model with an external failure detector. A similar approach was taken in <ref> [SR93, MS95, BDM97, HS95] </ref>. We assume that each process is equipped with an external failure detector module (or oracle), which reports to the local process which of the other processes are suspected to have failed. <p> It also appears in many specifications like [FLS97] and <ref> [HS95] </ref>. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. <p> Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. Such applications change their state when they receive application messages and membership changes <ref> [HS95, FV97, ACDV97] </ref>. However, we are aware of only few distributed applications that explicitly base their operation on Virtual Synchrony, since Virtual Synchrony is an "external observer" requirement, formulated in terms of two processes that proceed together through the same two consecutive views. <p> In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications <ref> [MAMSA94, FLS97, HS95] </ref>. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes.
Reference: [HT93] <author> V. Hadzilacos and S. Toueg. </author> <title> Fault-Tolerant Broadcasts and Related Problems. In Sape Mullender, editor, chapter in: Distributed Systems. </title> <publisher> ACM Press, </publisher> <year> 1993. </year> <month> 76 </month>
Reference-contexts: Unfortunately, in such environments, agreement problems that resemble the services provided by GCSs are not solvable. An example of such a problem is Terminating Reliable Broadcast (TRB) <ref> [HT93] </ref>, which requires non-faulty processes to either deliver every message sent or to declare the sender as faulty. Ideally, group multicast should resemble TRB in that it should require non-faulty processes to either deliver every message, or to deliver a view change that excludes the sender.
Reference: [HvR96] <author> M. Hayden and R. van Renesse. </author> <title> Optimizing Layered Communication Protocols. </title> <type> Tech--nical Report TR96-1613, </type> <institution> Dept. of Computer Science, Cornell University, </institution> <address> Ithaca, NY 14850, USA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: The Horus [vRBM96] system tackled this problem with a new paradigm: modularity. Horus and its successor Ensemble <ref> [HvR96] </ref> are flexible GCSs comprised of independent protocol layers that implement different service levels and semantics. This approach allows the application builder to tailor a GCS to his needs, treating protocol layers as building blocks. <p> Recently, several emerging projects addressed the challenge of incorporating QoS communication into the framework of group communication. For example, the MMTS [CHKD96] extends the Tran-sis [ADKM92b, DM96] GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble <ref> [HvR96] </ref> group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications. 3.2 On the Formal Specifications of Group Communication Sys tems In this section we discuss the difficulties one encounters when trying <p> For example, in RMP, the unreliable QoS level provides the guarantees of the underlying communication. Similarly, the MMTS [CHKD96] extends Transis [ADKM92b, DM96] by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble <ref> [HvR96] </ref> GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) [RCHS97] implements similar concepts, geared towards distributed collaborative multimedia applications.
Reference: [JFR93] <author> F. Jahanian, S. Fakhouri, and R. Rajkumar. </author> <title> Processor Group Membership Protocols: Specification, </title> <booktitle> Design and Implementation. In Symposium on Reliable Distributed Systems, number 12th, </booktitle> <pages> pages 2-11. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1993. </year>
Reference-contexts: In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of <ref> [MAMSA94, FLS97, BBD96, CS95, JFR93] </ref>. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97].
Reference: [KD96] <author> I. Keidar and D. Dolev. </author> <title> Efficient Message Ordering in Dynamic Networks. </title> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 68-76, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: We present here a set of specifications carefully comprised to satisfy the common requirements of many fault tolerant distributed applications. We justify these specifications with examples of applications that benefit from them and of services constructed to effectively exploit them <ref> [FLS97, KD96, ADMSM94, FV97, ABCD96, ACDV97, ACK + 97] </ref>. Nonetheless, not all the specifications are useful for all the applications. <p> The State Transfer Problem deals with bringing such replicas to a consistent state when they re-connect. This work presents an efficient implementation of the State Transfer Module that may serve as a building block in object replication protocols. Replication is the focus of traditional distributed database applications <ref> [KD96, ADMSM94, AAD93, ABCD96] </ref> as well as of Computer Supported Cooperative Work [Rod91] applications. The latter includes multimedia and desktop conferencing systems, interactive distributed games and simulations, distributed applications with shared workspace, etc. <p> Requirement 5.1.3 has another significant consequence: if two processes install the same two views, they install these views in the same order. The importance of view ordering properties is noted and emphasized in several works, for example in [HS95, FV97]. This feature is exploited by numerous applications, e.g. <ref> [KD96] </ref>, [Ami95] and [FV97]. Requirement 5.1.4 (Termination of Membership) guarantees that if a process p installs a view V , then either all members of V install V or p installs a next view (unless it crashes). Usually, when several processes install the same new view, they exchange messages. <p> When two processes reconnect, they can exploit this property to find out which process is more updated, i.e. was a member of a later primary partition in the global history. This information is useful for the implementation of a consistent replication service <ref> [ADMSM94, KD96] </ref>. However, in order to fulfill Requirement 5.1.7 a process p must be aware of possible view installations at other processes of views that include p. The latter circumstance renders the membership protocol more complicated and less efficient, because it demands at least two rounds of communication. <p> Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. However, there are applications implementing a consistent replication paradigm, which re 51 quire that processes agree upon the order of messages even in case they disconnect from each other <ref> [ADMSM94, KD96] </ref>. This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix [MFSW95], Horus [vRHB94], Transis [Cho97] and RMP [WMK95]. <p> An important consequence of Requirement 5.4.1, is that if an agreed message is indicated as safe, it also satisfies the Reliable Agreed Delivery property (Requirement 5.3.7). This property is exploited by the applications in [ADMSM94], <ref> [KD96] </ref> and [FLS97]. It is supported by Totem [AMMS + 95] and Transis [ADKM92b] that do not provide Reliable Agreed Delivery (Requirement 5.3.7). A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception. <p> Currently, the protocol is implemented as part of the group membership of Transis communication system. In future we intend to build a generic State Transfer layer and to incorporate its services into the existing object replication protocols, e.g. <ref> [KD96] </ref> and [ADMSM94]. We will examine other known problems faced by distributed applications operating on top of GCSs. We are going to investigate how utilizing additional services and semantics may give rise to new, more efficient solutions to these problems. 72
Reference: [Lam78] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Comm. ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July 78. </month>
Reference-contexts: ^ fifo send (sa) ^ pid (se) = pid (sa) ^ time (se) &gt; time (sa) ^ app recv (de) ^ app recv (da) ^ content (se) = content (de) ^ content (sa) = content (da) ^ pid (de) = pid (da) ) time (de) &gt; time (da)) The causal <ref> [Lam78] </ref> order extends the fifo order by requiring that a response m 0 to a message m is always delivered after the delivery of m. <p> Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal <ref> [Lam78] </ref> order of delivery. This order extends the fifo order by requiring that a response m 0 to a message m is always delivered after the delivery of m. The CBCAST primitive of Isis [BJ87] was perhaps the first implementation of (Reliable) causal multicast.
Reference: [LT89] <author> N.A. Lynch and M.R. Tuttle. </author> <title> An Introduction to Input/Output Automata. </title> <journal> CWI Quarterly, </journal> <volume> 2(3) </volume> <pages> 219-246, </pages> <year> 1989. </year>
Reference-contexts: In this work we formulate a comprehensive set of specification "building blocks" which may be combined to represent the guarantees of most existing GCSs. We specify clear and rigorous requirements formalized as trace properties of I/O automata <ref> [LT89, Lyn96] </ref> using a first order logic modeling technique [Avr98]. In light of these requirements, we survey and analyze over thirty published specifications which cover a dozen leading GCSs. We correlate the terminology used in different papers to our terminology. <p> We say that sequence s is a prefix of sequence t, written s t, provided that there exists s 0 such that s s 0 = t. 2.2 The I/O Automaton Model We describe properties of our services and environment using untimed I/O automaton model of Lynch and Tuttle <ref> [LT89] </ref>, also described in Chapter 8 of [Lyn96]. Here, we provide a brief summary of those aspects of the model that are needed for our presentation. 2.2.1 Actions and Action Signatures An I/O automaton models a distributed system component that can interact with other system components.
Reference: [Lyn96] <author> N.A. Lynch. </author> <title> Distributed Algorithms. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year>
Reference-contexts: In this work we formulate a comprehensive set of specification "building blocks" which may be combined to represent the guarantees of most existing GCSs. We specify clear and rigorous requirements formalized as trace properties of I/O automata <ref> [LT89, Lyn96] </ref> using a first order logic modeling technique [Avr98]. In light of these requirements, we survey and analyze over thirty published specifications which cover a dozen leading GCSs. We correlate the terminology used in different papers to our terminology. <p> a prefix of sequence t, written s t, provided that there exists s 0 such that s s 0 = t. 2.2 The I/O Automaton Model We describe properties of our services and environment using untimed I/O automaton model of Lynch and Tuttle [LT89], also described in Chapter 8 of <ref> [Lyn96] </ref>. Here, we provide a brief summary of those aspects of the model that are needed for our presentation. 2.2.1 Actions and Action Signatures An I/O automaton models a distributed system component that can interact with other system components.
Reference: [MAMSA94] <author> L. E. Moser, Y. Amir, P. M. Melliar-Smith, and D. A. Agarwal. </author> <title> Extended Virtual Synchrony. </title> <booktitle> In Intl. Conference on Distributed Computing Systems, </booktitle> <volume> number 14, </volume> <pages> pages 56-65, </pages> <month> June </month> <year> 1994. </year> <note> Also available as technical report ECE93-22, </note> <institution> Department of Electrical and Computer Engineering, University of California, Santa Barbara, </institution> <address> CA. </address>
Reference-contexts: Such modular GCSs easily adapt to a variety of application needs. Traditionally, GCS developers concentrated primarily on system performance, in order to make their systems useful for real-world distributed applications. Only recently, the challenging task of specifying the semantics and services of GCSs has become an active research area <ref> [MAMSA94, FvR95, BDM95, FLS97] </ref>, but as of yet, no commonly accepted specifications have been established. The guarantees of different GCSs are stated using different terminologies and modeling techniques, and the specifications vary greatly in their rigor. <p> This service provides information regarding the transitional set, which is defined in Section 5.1 and discussed in Section 6.3.2. The transitional set was initially proposed as a basic concept of the Extended Virtual Synchrony model (EVS) <ref> [MAMSA94, DMS96] </ref>. The transitional membership notification, which complements the regular membership notification, enables each replica to locally determine the set of other members that have the same state. Our proposed State Transfer Module may be implemented on top of any group communication layer that provides specifications defined in Chapter 5. <p> In such environments, the GCS simulates a "benign" world in which message delivery is reliable within the set of reachable (live and connected) processes. Furthermore, several GCSs provide semantic models such as Virtual Synchrony [BJ87], Strong Virtual Synchrony [FvR95] and Extended Virtual Synchrony <ref> [MAMSA94] </ref>. Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. <p> Unfortunately, "all or nothing" semantics are impossible to achieve in distributed systems in which messages may be lost. As an approximation to "all or nothing" semantics, the extended virtual synchrony computation model <ref> [MAMSA94] </ref> introduced the concept of safe messages. The idea behind safe messages is to provide the user with an indication when the message was delivered to all of its destinations. In our formalization, safe indications are conveyed using safe pref indic events, which we are going to describe now. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP [WMK95], Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of <ref> [MAMSA94, FLS97, BBD96, CS95, JFR93] </ref>. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. Some application semantics require that only one partition remains active following a partition [HS95, YLKD97]. <p> In this case p could be stuck forever waiting for a message from q. Only the installation of a next view guaranteed by Requirement 5.1.4 would interrupt this waiting. This specification also exists in <ref> [MAMSA94] </ref>. 45 6.2.5 Agreement on membership In general, there is some degree of agreement between processes on the next common view. [HS95] presents several possible specifications of such agreement in the context of a primary partition membership service. According to Requirement 5.1.5 1. <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service <ref> [FvR95, DMS96, EMS95, MAMSA94, BDM95] </ref>. In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> This requirement was first introduced in the Isis literature [BJ87, Bir94, BSS91, Bir93] in the context of a primary partition membership service and later extended to a partitionable membership service [FvR95, DMS96, EMS95, MAMSA94, BDM95]. In <ref> [MAMSA94] </ref> and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". <p> Hence, the previous decision value of q is different from that of p and the transitional set delivered along with &lt;3; fp; qg&gt; on p, does not include q. The transitional set is contained in the transitional view , introduced in Extended Virtual Synchrony <ref> [MAMSA94] </ref> and implemented in Transis [ADKM92b] and Totem [AMMS + 95]. Other systems develop similar approaches: In Relacs [BDM97] every change in connectivity causes two views to be installed: first, a transitional set is installed as a regular view, and then a normal membership view is installed. <p> In contrast, Newtop [EMS95] and RMP [WMK95] do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications <ref> [MAMSA94, FLS97, HS95] </ref>. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. It comple-ments Requirement 5.2.3 that precludes a trivial protocol that never delivers a message in a stable connected component. Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. <p> This requirement is easily implementable and always holds in Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Horus [FvR95] and Newtop [EMS95]. In RMP [WMK95] it holds for all QoS levels except the Unreliable one. It also appears in the specifications of <ref> [MAMSA94] </ref>. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, [FLS97] and [FV97] present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. <p> In this case each member of this view will deliver the message unless it crashes. In particular, in a partitionable environment even if the network partitions at that point, the message is still delivered. These "approximated" semantics are called Safe Delivery in <ref> [MAMSA94] </ref> and Total Resiliency in [WMK95]. These "approximated" semantics can be reformulated for a GCS which provides a primary partition membership service, as follows: if a process delivers a message in view V , then all non-faulty members of V eventually deliver this message. <p> However, some systems provide a QoS level, corresponding to this message stability and some do not. The implementations we are aware of are the Safe messages of Totem <ref> [AMMS + 95, MAMSA94] </ref> and Transis [ADKM92b], the Totally Resilient QoS level of RMP [WMK95], the atomic, tight and delta QoS levels of xAMp [RV92] and the Uniform multicast of Phoenix [MFSW95]. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. <p> That is why we call it safe prefix indication. Such safe prefix indications exist, for example, in [FLS97]. Note that this approach presents more simple semantics, because now there is no need to deliver transitional views <ref> [MAMSA94] </ref>. These semantics are also more flexible and powerful, because even applications that require message stability can partly process a message right after its delivery.
Reference: [MFSW95] <author> C. P. Malloth, P. Felber, A. Schiper, and U. Wilhelm. </author> <title> Phoenix: A Toolkit for Building Fault-Tolerant, Distributed Applications in Large Scale. </title> <booktitle> In Workshop on Parallel and Distributed Platforms in Industrial Products, </booktitle> <month> October </month> <year> 1995. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix <ref> [MFSW95] </ref>, Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to different applications, <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix <ref> [MFSW95] </ref>, Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95] and Phoenix <ref> [MFSW95] </ref>) provide only higher QoS levels which extend fifo Delivery. Requirement 5.3.2 (Causal Delivery) preserves the causal [Lam78] order of delivery. This order extends the fifo order by requiring that a response m 0 to a message m is always delivered after the delivery of m. <p> As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix <ref> [MFSW95] </ref> and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). In particular, this work defines strong and weak total order in the context of a primary partition membership service. <p> The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix <ref> [MFSW95] </ref>). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. However, there are applications implementing a consistent replication paradigm, which re 51 quire that processes agree upon the order of messages even in case they disconnect from each other [ADMSM94, KD96]. <p> This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix <ref> [MFSW95] </ref>, Horus [vRHB94], Transis [Cho97] and RMP [WMK95]. Since processes do not know they are going to disconnect before they actually do, messages delivered under weak agreed semantics also comply with Strong Agreed Delivery until the moment of a link failure. <p> Horus [FvR95] and RMP [WMK95] provide this service. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], New-top [EMS95] and Phoenix <ref> [MFSW95] </ref>) provide only higher QoS levels which extend Reliable fifo Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92]. Totem [AMMS + 95], Phoenix <ref> [MFSW95] </ref> and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery. <p> The implementations we are aware of are the Safe messages of Totem [AMMS + 95, MAMSA94] and Transis [ADKM92b], the Totally Resilient QoS level of RMP [WMK95], the atomic, tight and delta QoS levels of xAMp [RV92] and the Uniform multicast of Phoenix <ref> [MFSW95] </ref>. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. Sometimes applications require a weaker degree of atomicity. For example, in quorum based systems it could be enough to defer delivery until the majority of the processes have the message.
Reference: [MPS91a] <author> S. Mishra, L. L. Peterson, and R. D. Schlichting. </author> <title> A Membership Protocol based on Partial Order. </title> <booktitle> In proc. of the intl. working conf. on Dependable Computing for Critical Applications, </booktitle> <pages> pages 137-145, </pages> <month> Feb </month> <year> 1991. </year>
Reference-contexts: Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and <ref> [MPS91a] </ref>. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition.
Reference: [MPS91b] <author> S. Mishra, L. L. Peterson, and R. L. Schlichting. </author> <title> Consul: A Communication Substrate for Fault-Tolerant Distributed Programs. </title> <type> TR 91-32, </type> <institution> dept. of Computer Science, University of Arizona, </institution> <year> 1991. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul <ref> [MPS91b] </ref>, Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications <p> In particular, we will discuss Consul <ref> [MPS91b] </ref>, Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul <ref> [MPS91b] </ref> and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul <ref> [MPS91b] </ref> and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. <p> Moreover, it is challenging to define the maximum degree of preciseness achievable [ACBMT95]. This challenge is discussed in detail in Section 3.2. 46 Most GCSs, e.g., Isis [BSS91], Consul <ref> [MPS91b] </ref> and Transis [ADKM92a], have chosen to be absolutely complete at the price of possibly being inaccurate. Various approaches have been undertaken to formulate the non-trivial accuracy in such systems [DMS96, EMS95, BDM97, FLS97].
Reference: [MS95] <author> C. Malloth and A. Schiper. </author> <title> View Synchronous Communication in Large Scale Networks. </title> <booktitle> In Proc 2nd Open Workshop of the ESPRIT projet BROADCAST (#6360), </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: The output of a failure detector is a list of suspects, i.e., processes which are suspected to be faulty. For example, [FvR95, DMS96] require that a process not be removed from the view unless it is a suspect. Other specifications <ref> [MS95, BDM95] </ref> take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. An eventual perfect failure detector eventually suspects all faulty processes and also eventually permanently stops suspecting non-faulty ones. The specifications in [MS95, BDM95] guarantee that if the external failure detector is an eventual <p> Other specifications <ref> [MS95, BDM95] </ref> take this approach one step further, and exploit the notion of eventual perfect failure detectors [CT96]. An eventual perfect failure detector eventually suspects all faulty processes and also eventually permanently stops suspecting non-faulty ones. The specifications in [MS95, BDM95] guarantee that if the external failure detector is an eventual perfect one then the membership service will at some point begin to correctly reflect the network situation. <p> This integer is computed based on the values of local counters, maintained by all processes. This local counter is incremented by a process upon each installation. The counters in [FLS97] and [Nei96] are taken from the ordered set. Hence, an integer counter is again a possible implementation. In Phoenix <ref> [MS95] </ref>, Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] and in the specifications of [CS95] a view is a set of pairs &lt; p i ; c i &gt; where p i is a process identifier and c i is a value of a local counter on p i . <p> Primary partition membership services are implemented in Isis [RB91], Phoenix <ref> [MS95] </ref>, Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application <p> Primary partition membership services are implemented in Isis [RB91], Phoenix <ref> [MS95] </ref>, Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. <p> [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix <ref> [MS95] </ref> do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> In Newtop [EMS95] logical timestamp comparison can serve this purpose. In Phoenix <ref> [MS95] </ref> a view contains local counter values along with process identifiers. Thus, two views having a process in the intersection can be compared by comparing the counter values of this common process. <p> Unfortunately, as we show in Section 3.2, such a desirable membership service is not implementable in purely asynchronous environments. In order to circumvent this impossibility result we augment the model with an external failure detector. A similar approach was taken in <ref> [SR93, MS95, BDM97, HS95] </ref>. We assume that each process is equipped with an external failure detector module (or oracle), which reports to the local process which of the other processes are suspected to have failed. <p> It should be emphasized that these two properties are only preconditions of the precise 47 ness requirement; when they are not fulfilled accuracy is not guaranteed but no other requirements are affected. It is common to assume transitivity, though it is not necessary, e.g. Phoenix <ref> [MS95] </ref> does not assume transitivity at all. Instead, it ensures eventual transitivity of communication by relaying messages. Typically communication links are symmetrical, however in wide area networks prone to various types of failures one-way partitions occasionally occur. Such absence of symmetry is a difficult problem.
Reference: [Nei96] <author> G. Neiger. </author> <title> A New Look at Membership Services. </title> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, number 15th, </booktitle> <pages> pages 331-340. </pages> <publisher> ACM, </publisher> <year> 1996. </year>
Reference-contexts: On the other hand, other group communication systems and specifications strengthen this assumption even more and rely on the underlying protocol to provide the fifo order of low level message delivery <ref> [EMS95, Nei96, HS95, SS93] </ref>. Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions [SS93] and also eliminates message duplications [EMS95]. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. <p> This integer is computed based on the values of local counters, maintained by all processes. This local counter is incremented by a process upon each installation. The counters in [FLS97] and <ref> [Nei96] </ref> are taken from the ordered set. Hence, an integer counter is again a possible implementation. <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of <ref> [Nei96] </ref>, [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] and specifications <ref> [Nei96, FLS97] </ref> as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. Otherwise,crashes entail the violation of Requirement 5.1.3, as indeed occurs in most of the systems and specifications. <p> However, no system implements this, because it imposes a severe execution penalty. Applications running above Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], Relacs [BDM97] or above a group communication system conforming with the specifications of <ref> [Nei96] </ref> or [FLS97] can use counter comparison in order to compare between view identifiers. In Newtop [EMS95] logical timestamp comparison can serve this purpose. In Phoenix [MS95] a view contains local counter values along with process identifiers.
Reference: [Pos81] <author> J. Postel. </author> <title> Internet Protocol. </title> <type> RFC 0791, </type> <institution> USC/Information Science Institute, </institution> <month> Septem-ber </month> <year> 1981. </year>
Reference-contexts: However, since the "best effort" principle is an important consideration of every system builder, actual systems provide more than their specifications require. For example, the Internet Protocol (IP) <ref> [Pos81] </ref> is an unreliable datagram protocol that does not guarantee to deliver any message. Yet few would argue that IP is useless. 3.2.3 Circumventing the Impossibility Result Specifications of group communication were made non-trivial using a variety of techniques.
Reference: [RB91] <author> A. M. Ricciardi and K. P. Birman. </author> <title> Using Process Groups to Implement Failure Detection in Asynchronous Environments. </title> <booktitle> In proc. annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 341-352, </pages> <month> August </month> <year> 1991. </year> <month> 77 </month>
Reference-contexts: Primary partition membership services are implemented in Isis <ref> [RB91] </ref>, Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of <p> Primary partition membership services are implemented in Isis <ref> [RB91] </ref>, Phoenix [MS95], Consul [MPS91b] and xAMp [RV92] and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. <p> While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis <ref> [RB91] </ref> and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. <p> Requirement 5.1.3 demands that for each process, views are installed at that process in such a way that their view identifiers increase monotonically. This requirement holds in most of the group communication systems <ref> [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] </ref> and specifications [Nei96, FLS97] as long as there are no crashes. In Isis [RB91] a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. <p> This requirement holds in most of the group communication systems [RB91, DMS96, AMMS + 95, FvR95, BDM97, EMS95, MS95] and specifications [Nei96, FLS97] as long as there are no crashes. In Isis <ref> [RB91] </ref> a process recovering after a crash is assigned a different identifier, hence this requirement is always satisfied in this system. Otherwise,crashes entail the violation of Requirement 5.1.3, as indeed occurs in most of the systems and specifications.
Reference: [RCHS97] <author> I. Rhee, S. Cheung, P. Hutto, and V. Sunderam. </author> <title> Group Communication Support for Distributed Multimedia and CSCW Systems. </title> <booktitle> In 17th Intl. Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997. </year> <note> Also available as technical report of Dept. </note> <institution> of Mathematics Computer Science, Emory University, </institution> <address> Atlanta, GA 30322. </address>
Reference-contexts: For example, the MMTS [CHKD96] extends the Tran-sis [ADKM92b, DM96] GCS by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] group communication system by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) <ref> [RCHS97] </ref> implements similar concepts, geared towards distributed collaborative multimedia applications. 3.2 On the Formal Specifications of Group Communication Sys tems In this section we discuss the difficulties one encounters when trying to formally specify meaningful group communication systems. 3.2.1 The Impossible Group communication systems typically run in asynchronous failure prone environments. <p> Similarly, the MMTS [CHKD96] extends Transis [ADKM92b, DM96] by providing a framework for synchronization of messages with different QoS requirements; Maestro [BFHR98] extends the Ensemble [HvR96] GCS by coordinating several protocol stacks with different QoS guarantees and the Collaborative Computing Transport Layer (CCTL) <ref> [RCHS97] </ref> implements similar concepts, geared towards distributed collaborative multimedia applications.
Reference: [Rod91] <author> Tom Rodden. </author> <title> A survey of CSCW systems. </title> <journal> Interacting with Computers, </journal> <volume> 3(3) </volume> <pages> 319-353, </pages> <year> 1991. </year>
Reference-contexts: This work presents an efficient implementation of the State Transfer Module that may serve as a building block in object replication protocols. Replication is the focus of traditional distributed database applications [KD96, ADMSM94, AAD93, ABCD96] as well as of Computer Supported Cooperative Work <ref> [Rod91] </ref> applications. The latter includes multimedia and desktop conferencing systems, interactive distributed games and simulations, distributed applications with shared workspace, etc. Other applications that employ object replication are those operating in a mobile environment, where changes in network connectivity are particularly frequent.
Reference: [RV92] <author> L. Rodrigues and P. Verissimo. </author> <title> x AMp, a protocol suite for group communication. </title> <type> RT /43-92, </type> <institution> INESC, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp <ref> [RV92] </ref> group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages and that all delivered messages are guaranteed to be uncorrupted. <p> Note that this assumption does not restrict the network to delivering messages at most once, so message duplication is still possible. While Assumption 4.3.1 is highly reasonable and realistic <ref> [RV92, BDM97, WMK95] </ref>, some group communication systems do not assume it. Instead, they cope with the problem of such messages by using a checksum algorithm, even though this imposes an execution penalty. <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp <ref> [RV92] </ref> and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a <p> Primary partition membership services are implemented in Isis [RB91], Phoenix [MS95], Consul [MPS91b] and xAMp <ref> [RV92] </ref> and discussed in the specifications of [Nei96], [Cri91] and [MPS91a]. While Consul [MPS91b], xAMp [RV92] and [Cri91] guarantee membership service properties only as long as no partitions occur, Isis [RB91] and Phoenix [MS95] do assume the possibility of partitions, but allow execution of the application to proceed only in a single partition. <p> Since the underlying network does not spontaneously generate messages (assumption 4.3.1) neither does the communication service. This requirement can be trivially implemented, so all GCSs support it, as explicitly specified in [BDM95] and <ref> [RV92] </ref>. 6.3.1 Quality of Service GCSs typically provide various types of multicast services. Traditionally, GCSs provide reliable multicast services with different ordering guarantees. We call these paradigms reliable quality of service options. However, this type of multicast is not appropriate for all applications. <p> Here we discuss only services of the hierarchy in Figure 5.1, although there are works presenting different services (e.g. <ref> [RV92] </ref> and [WMK95]). Requirement 5.3.1 (fifo Delivery) guarantees that messages from the same sender do not arrive out of order. This is the lowest QoS level in the ordering hierarchy. It is trivially implemented if low level message delivery of the underlying network guarantees fifo order itself. xAMp [RV92] provide several <p> services (e.g. <ref> [RV92] </ref> and [WMK95]). Requirement 5.3.1 (fifo Delivery) guarantees that messages from the same sender do not arrive out of order. This is the lowest QoS level in the ordering hierarchy. It is trivially implemented if low level message delivery of the underlying network guarantees fifo order itself. xAMp [RV92] provide several QoS levels that satisfy Requirement 5.3.1 but no stronger order constraints. They differ by their reliability guarantees. Horus [FvR95] and RMP [WMK95] provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. <p> The CBCAST primitive of Isis [BJ87] was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp <ref> [RV92] </ref> present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). <p> In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP [WMK95], Newtop [EMS95], xAMp <ref> [RV92] </ref> and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp <ref> [RV92] </ref>. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery. <p> This is called Uniformity in the Isis literature and in [SS93] and Unanimity <ref> [RV92] </ref>. If a message is stable, then no process will request its retransmission. Thus, once a process knows about message stability, it can safely discard this message after delivery. <p> The implementations we are aware of are the Safe messages of Totem [AMMS + 95, MAMSA94] and Transis [ADKM92b], the Totally Resilient QoS level of RMP [WMK95], the atomic, tight and delta QoS levels of xAMp <ref> [RV92] </ref> and the Uniform multicast of Phoenix [MFSW95]. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. Sometimes applications require a weaker degree of atomicity. <p> For example, in quorum based systems it could be enough to defer delivery until the majority of the processes have the message. This is guaranteed by Majority Resilient QoS level of RMP [WMK95]. The K resilient QoS level of RMP [WMK95] and atLeastN QoS level of xAMp <ref> [RV92] </ref> guarantee that if a process delivers a message, then at least K (N) processes will deliver this message unless they crash. Here K (N) is a service parameter. In this work we follow the alternative approach employed, for example, in [FLS97].
Reference: [Sch90] <author> F.B. Schneider. </author> <title> Implementing Fault Tolerant Services Using The State Machine Approach: A Tutorial. </title> <journal> Computing Surveys, </journal> <volume> 22(4) </volume> <pages> 299-319, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: It also appears in many specifications like [FLS97] and [HS95]. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines <ref> [Sch90] </ref>. Such applications change their state when they receive application messages and membership changes [HS95, FV97, ACDV97].
Reference: [SR93] <author> A. Schiper and A.M. Ricciardi. </author> <title> Virtually Synchronous Communication based on a Weak Failure Suspector. </title> <booktitle> Digest of Papers, FTCS-23, </booktitle> <pages> pages 534-543, </pages> <month> June 93. </month>
Reference-contexts: Unfortunately, as we show in Section 3.2, such a desirable membership service is not implementable in purely asynchronous environments. In order to circumvent this impossibility result we augment the model with an external failure detector. A similar approach was taken in <ref> [SR93, MS95, BDM97, HS95] </ref>. We assume that each process is equipped with an external failure detector module (or oracle), which reports to the local process which of the other processes are suspected to have failed.
Reference: [SS93] <author> A. Schiper and A. Sandoz. </author> <title> Uniform Reliable Multicast in a Virtually Synchronous Environment. </title> <booktitle> In IEEE Proc. of the 13th Intl. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 561-568, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: On the other hand, other group communication systems and specifications strengthen this assumption even more and rely on the underlying protocol to provide the fifo order of low level message delivery <ref> [EMS95, Nei96, HS95, SS93] </ref>. Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions [SS93] and also eliminates message duplications [EMS95]. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. <p> Some systems further assume that the underlying protocol eliminates message losses in the absence of partitions <ref> [SS93] </ref> and also eliminates message duplications [EMS95]. Assumption 4.4.1 (message uniqueness) is an assumption about an application operating on top of GCSs. It states that the application does not send more than one message with the same contents, and thus each message is uniquely identified by its contents. <p> In [MAMSA94] and [FV97] it was called "failure atomicity", and in [BDM95] it was called "view synchrony". This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95], Phoenix <ref> [SS93] </ref> and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP [WMK95]. It also appears in many specifications like [FLS97] and [HS95]. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. <p> These "approximated" semantics can be reformulated for a GCS which provides a primary partition membership service, as follows: if a process delivers a message in view V , then all non-faulty members of V eventually deliver this message. This is called Uniformity in the Isis literature and in <ref> [SS93] </ref> and Unanimity [RV92]. If a message is stable, then no process will request its retransmission. Thus, once a process knows about message stability, it can safely discard this message after delivery.
Reference: [Vog96] <author> W. Vogels. </author> <title> World Wide Failures. </title> <booktitle> In ACM SIGOPS European Workshop, </booktitle> <year> 1996. </year>
Reference-contexts: However, we do expect of a membership service to use some failure detection mechanism based on time-outs or other methods (e.g. , <ref> [Vog96] </ref>) which attempts to approximate the network situation. Such a mechanism is inherently unreliable, in the sense that it can make mistakes (and suspect correct but slow processes). However, when the failure detector does not make mistakes, the membership service should correctly reflect the network situation.
Reference: [vRBM96] <author> R. van Renesse, K. P. Birman, and S. Maffeis. Horus: </author> <title> A Flexible Group Communication System. </title> <journal> Communications of the ACM, </journal> <volume> 39(4), </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: The Horus <ref> [vRBM96] </ref> system tackled this problem with a new paradigm: modularity. Horus and its successor Ensemble [HvR96] are flexible GCSs comprised of independent protocol layers that implement different service levels and semantics. This approach allows the application builder to tailor a GCS to his needs, treating protocol layers as building blocks.
Reference: [vRHB94] <author> R. van Renesse, T. M. Hickey, and K. P. Birman. </author> <title> Design and Performance of Horus: A Lightweight Group Communications System. </title> <type> TR 94-1442, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus <ref> [vRHB94] </ref>, ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus <ref> [vRHB94] </ref>, Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP [WMK95], Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states <p> The CBCAST primitive of Isis [BJ87] was perhaps the first implementation of (Reliable) causal multicast. As a matter of fact, most of the GCSs that implement Causal Delivery provide only a QoS level of Reliable Causal delivery (Requirement 5.3.6). Isis [BJ87], Transis [DMS96], Horus <ref> [vRHB94] </ref>, Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). <p> In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus <ref> [vRHB94] </ref>, RMP [WMK95], Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix [MFSW95], Horus <ref> [vRHB94] </ref>, Transis [Cho97] and RMP [WMK95]. Since processes do not know they are going to disconnect before they actually do, messages delivered under weak agreed semantics also comply with Strong Agreed Delivery until the moment of a link failure. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus <ref> [vRHB94] </ref>, Newtop [EMS95] and xAMp [RV92]. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95] provide higher QoS levels which extend Reliable Causal Delivery. <p> Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer <ref> [vRHB94] </ref>. Sometimes applications require a weaker degree of atomicity. For example, in quorum based systems it could be enough to defer delivery until the majority of the processes have the message. This is guaranteed by Majority Resilient QoS level of RMP [WMK95]. <p> A process knows that a message is stable as soon as it learns that all other members of the view have acknowledged its reception. Usually such acknowledgements are given by a GC system of the process that receives the message. However, in Horus <ref> [vRHB94] </ref> it is responsibility of the application to acknowledge message reception. This approach may require extra communication and yields a bit more complex but more flexible and powerful semantics. Instead of delivering safe prefix notifications, Horus maintains a more general stability matrix at each process. <p> The ij entry of the matrix stores the number of messages sent by i which have been acknowledged by j. This matrix is accessible by the application, which can itself deduce the information provided by safe prefix indications. The application can also learn about partial k-stability <ref> [vRHB94] </ref>, i.e. that k members have seen the message. Requirement 5.4.2 (Safe Indication Non-triviality) states that if there are no view changes then messages are eventually indicated as safe.
Reference: [WMK95] <author> B. Whetten, T. Montgomery, and S. Kaplan. </author> <title> A high perfomance totally ordered multicast protocol. </title> <editor> In K. P. Birman, F. Mattern, and A. Schipper, editors, </editor> <booktitle> Theory and Practice in Distributed Systems: International Workshop, </booktitle> <pages> pages 33-57. </pages> <publisher> Springer, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science 938. </note>
Reference-contexts: Such models define relationships between view changes and message delivery which enable the application to derive some useful information regarding which processes delivered the message. Some of the leading GCSs today are: Consul [MPS91b], Horus [vRHB94], ISIS [BSS91], New-top [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP <ref> [WMK95] </ref>, Totem [AMMS + 95] and Transis [ADKM92b]. 19 3.1.2 Modularity: The New Trend in Group Communication Systems Experience with group communication systems and reliable distributed applications has shown that there are no "right" system semantics for all applications [Bir96]: different GCSs are tailored to different applications, which require different semantics <p> In particular, we will discuss Consul [MPS91b], Highways [Ahu93] Horus [vRHB94], Isis [BJ87], Maestro [BFHR98], Newtop [EMS95], Phoenix [MFSW95], Relacs [BDGB94], RMP <ref> [WMK95] </ref>, Totem [AMMS + 95], Transis [ADKM92b] and xAMp [RV92] group communication systems and the specifications in [SR93, MAMSA94, FvR95, RB91, CS95, Cri91, FLS97, MPS91a, HS95, JFR93, BDM95, BBD96, BDM97, DMS96, MS95, SS93, WS95, 6.1 Assumptions Assumption 4.3.1 states that the network may not spontaneously generate messages and that all delivered <p> Note that this assumption does not restrict the network to delivering messages at most once, so message duplication is still possible. While Assumption 4.3.1 is highly reasonable and realistic <ref> [RV92, BDM97, WMK95] </ref>, some group communication systems do not assume it. Instead, they cope with the problem of such messages by using a checksum algorithm, even though this imposes an execution penalty. <p> It does, however, simplify the definitions of the further requirements. 43 6.2 Membership service 6.2.1 View identifiers Group membership is a vital part of a group communication system <ref> [BJ87, ADKM92b, AMMS + 95, FvR95, WMK95, EMS95, BDGB94, MFSW95] </ref>. A membership view installed at a process always contains a set of processes that are able to communicate with that particular process. <p> In Newtop [EMS95] a logical timestamp is used to sign all messages. The maximum value of this timestamp at the moment of the new view creation satisfies all the requirements of a view identifier. In RMP <ref> [WMK95] </ref> a membership protocol is asymmetric and has a coordinator. In this system there is the notion of a token list ID analogous (in our terminology) to a view identifier. <p> In Isis [RB91] detached processes 'commit suicide', whereas in Phoenix [MS95] they are blocked until the link is mended. Partitionable membership services are implemented in Transis [DMS96], Totem [AMMS + 95], Horus [FvR95], RMP <ref> [WMK95] </ref>, Newtop [EMS95] and Relacs [BDGB94, BDM95, BDM97] and discussed in the specifications of [MAMSA94, FLS97, BBD96, CS95, JFR93]. [HS95] first presents the specifications of a primary-partition membership service and then shows how to extend them to specifications of a partitionable one. <p> Thus, two views having a process in the intersection can be compared by comparing the counter values of this common process. Requirement 5.1.3 has an important consequence: uniqueness of the pair (view identifier, view members list) throughout the entire history. RMP <ref> [WMK95] </ref> guarantee such uniqueness even in the face of crashes by initializing the local counter to the real clock value when a computer recovers after the crash. Requirement 5.1.3 has another significant consequence: if two processes install the same two views, they install these views in the same order. <p> Most GCSs eliminate duplication [BDM95, EMS95, ADKM92b]. However, when a GCS 48 directly provides QoS of the underlying communication layer, duplication is not eliminated, e.g., in the Unreliable and Unordered QoS levels of RMP <ref> [WMK95] </ref>. Unfortunately, there is no general way to guarantee a certain latency of delivery in asynchronous systems. Neither can we formulate a "best-effort" delivery requirement (see Section 3.2). However, we can prevent the triviality of the multicast service up to some extent. <p> This requirement precludes trivial protocols that never deliver messages or that deliver messages only before view changes. Similar termination requirements can be found in [DMS96], [FvR95] and [BDM95]. This requirement is not fulfilled by Unreliable QoS levels (e.g. in RMP <ref> [WMK95] </ref>). According to Requirement 5.2.3 if p installs a view V and sends a message in this view, then either each member q of V delivers this message, or p installs a next view (unless p crashes). <p> This requirement is supported by virtually all group communication systems, either for all QoS levels (Isis [BJ87], Horus [FvR95], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95], Phoenix [SS93] and Relacs [BDM97]) or starting from some QoS level, like the totally ordered QoS level of RMP <ref> [WMK95] </ref>. It also appears in many specifications like [FLS97] and [HS95]. Virtual Synchrony is an extremely important concept, as it facilitates the perception of how distributed applications operate in asynchronous environments. This is especially true for applications that can be viewed as replicated state machines [Sch90]. <p> This requirement thus incurs extra latency for message delivery. Among the group communication systems that support strong virtual synchrony are Isis [BJ87] and Totem [AMMS + 95]. In contrast, Newtop [EMS95] and RMP <ref> [WMK95] </ref> do not guarantee Requirement 5.2.6. Horus [FvR95] can or cannot provide this requirement depending on the QoS level. Requirement 5.2.6 also appears in various GCS specifications [MAMSA94, FLS97, HS95]. Requirement 5.2.7 (Self-delivery) obliges processes to deliver their own messages. <p> Self-delivery prevents processes from arbitrarily discarding left-over messages upon view changes. This requirement is easily implementable and always holds in Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Horus [FvR95] and Newtop [EMS95]. In RMP <ref> [WMK95] </ref> it holds for all QoS levels except the Unreliable one. It also appears in the specifications of [MAMSA94]. Unfortunately, Requirements 5.2.5, 5.2.6, 5.3.7 and 5.2.7 cannot hold at the same time. For example, [FLS97] and [FV97] present distributed applications that assume Requirements 5.2.5, 5.2.6 and 5.3.7. <p> Here we discuss only services of the hierarchy in Figure 5.1, although there are works presenting different services (e.g. [RV92] and <ref> [WMK95] </ref>). Requirement 5.3.1 (fifo Delivery) guarantees that messages from the same sender do not arrive out of order. This is the lowest QoS level in the ordering hierarchy. <p> It is trivially implemented if low level message delivery of the underlying network guarantees fifo order itself. xAMp [RV92] provide several QoS levels that satisfy Requirement 5.3.1 but no stronger order constraints. They differ by their reliability guarantees. Horus [FvR95] and RMP <ref> [WMK95] </ref> provide Reliable fifo delivery (Requirement 5.3.5, which is discussed below) that implies fifo Delivery. Some GCSs (e.g. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], Newtop [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend fifo Delivery. <p> Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP <ref> [WMK95] </ref>) provide higher QoS levels extending Causal Delivery. [WS95] introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). In particular, this work defines strong and weak total order in the context of a primary partition membership service. Here we extend these definitions to a partitionable environment. <p> In general, an agreed order preserves the causal order of delivery (see Figure 5.1). The ABCAST primitive of Isis [BJ87] was probably the first implementation of Weak Agreed multicast. Most of the GCSs provide this multicast service (e.g. Isis [BJ87], Transis [DKM93], Horus [vRHB94], RMP <ref> [WMK95] </ref>, Newtop [EMS95], xAMp [RV92] and Phoenix [MFSW95]). Some systems (e.g. Totem [AMMS + 95]) provide only higher QoS levels extending Weak Agreed Delivery. <p> This is guaranteed by Strong Agreed Delivery (Requirement 5.3.3). Among GCSs providing this service are Totem [AMMS + 95], Phoenix [MFSW95], Horus [vRHB94], Transis [Cho97] and RMP <ref> [WMK95] </ref>. Since processes do not know they are going to disconnect before they actually do, messages delivered under weak agreed semantics also comply with Strong Agreed Delivery until the moment of a link failure. <p> According to Requirement 5.3.5 (Reliable fifo), if a process p delivers a message m that was sent by process q in view V , then p delivers every message that q sent before m in V . Horus [FvR95] and RMP <ref> [WMK95] </ref> provide this service. Isis [BJ87], Transis [DMS96], Totem [AMMS + 95], New-top [EMS95] and Phoenix [MFSW95]) provide only higher QoS levels which extend Reliable fifo Delivery. <p> An appropriate QoS level exists in Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92]. Totem [AMMS + 95], Phoenix [MFSW95] and RMP <ref> [WMK95] </ref> provide higher QoS levels which extend Reliable Causal Delivery. <p> following: * unordered : there no ordering constraints on the delivery of m 1 and m 2 * weak incorporated : the delivery of m 1 and m 2 should comply with O 1 * strong incorporated : the messages are delivered according to O 2 52 For example, RMP <ref> [WMK95] </ref> supports weak incorporated semantics between any two messages of different QoS levels. Isis [BJ87] gives weak incorporated semantics between messages sent by AB-CAST and CBCAST multicast primitives. <p> In this case each member of this view will deliver the message unless it crashes. In particular, in a partitionable environment even if the network partitions at that point, the message is still delivered. These "approximated" semantics are called Safe Delivery in [MAMSA94] and Total Resiliency in <ref> [WMK95] </ref>. These "approximated" semantics can be reformulated for a GCS which provides a primary partition membership service, as follows: if a process delivers a message in view V , then all non-faulty members of V eventually deliver this message. <p> However, some systems provide a QoS level, corresponding to this message stability and some do not. The implementations we are aware of are the Safe messages of Totem [AMMS + 95, MAMSA94] and Transis [ADKM92b], the Totally Resilient QoS level of RMP <ref> [WMK95] </ref>, the atomic, tight and delta QoS levels of xAMp [RV92] and the Uniform multicast of Phoenix [MFSW95]. Safe delivery can also be provided by Horus by placing the ORDER layer over the STABLE layer [vRHB94]. Sometimes applications require a weaker degree of atomicity. <p> Sometimes applications require a weaker degree of atomicity. For example, in quorum based systems it could be enough to defer delivery until the majority of the processes have the message. This is guaranteed by Majority Resilient QoS level of RMP <ref> [WMK95] </ref>. The K resilient QoS level of RMP [WMK95] and atLeastN QoS level of xAMp [RV92] guarantee that if a process delivers a message, then at least K (N) processes will deliver this message unless they crash. Here K (N) is a service parameter. <p> Sometimes applications require a weaker degree of atomicity. For example, in quorum based systems it could be enough to defer delivery until the majority of the processes have the message. This is guaranteed by Majority Resilient QoS level of RMP <ref> [WMK95] </ref>. The K resilient QoS level of RMP [WMK95] and atLeastN QoS level of xAMp [RV92] guarantee that if a process delivers a message, then at least K (N) processes will deliver this message unless they crash. Here K (N) is a service parameter. In this work we follow the alternative approach employed, for example, in [FLS97].
Reference: [WS95] <author> U. G. Wilhelm and A. Schiper. </author> <title> A hierarchy of totally ordered multicasts. </title> <booktitle> In Proceedings of the IEEE International Symposium on Reliable Distributed Systems (SRDS-14), </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: Isis [BJ87], Transis [DMS96], Horus [vRHB94], Newtop [EMS95] and xAMp [RV92] present examples of such GCSs. Some systems (e.g. Totem [AMMS + 95], Phoenix [MFSW95] and RMP [WMK95]) provide higher QoS levels extending Causal Delivery. <ref> [WS95] </ref> introduced a classification of totally order multicast (sometimes called atomic or agreed multicast). In particular, this work defines strong and weak total order in the context of a primary partition membership service. Here we extend these definitions to a partitionable environment. <p> Therefore, no GCS we are aware of guarantees Requirement 5.3.7. Systems that provide more than one QoS need to specify the delivery semantics (order constraints) of messages with different qualities of service. For example, should causal messages be totally ordered with respect to agreed messages? <ref> [WS95] </ref> presents three possible semantics in the context of weak and strong total orders. However, these semantics can be generalized for the case of two messages m 1 and m 2 with any two different ordering semantics O 1 and O 2 such that O 2 implies O 1 .
Reference: [YLKD97] <author> E. Yeger Lotem, I. Keidar, and D. Dolev. </author> <title> Dynamic Voting for Consistent Primary Components. </title> <booktitle> In Annual ACM Symp. on Principles of Distributed Computing, </booktitle> <volume> number 16, </volume> <month> August </month> <year> 1997. </year> <note> To appear. 78 </note>
Reference-contexts: Some application semantics require that only one partition remains active following a partition <ref> [HS95, YLKD97] </ref>. For such applications some partitionable GCSs provide a primary partition notification to the members of exactly one partition [FvR95, HS95]. 6.2.3 The initial view All send and delivery events always occur in some view. [FLS97] assumes that processes start up with some default view. <p> The latter circumstance renders the membership protocol more complicated and less efficient, because it demands at least two rounds of communication. Thus, only a few GCSs (e.g. Transis [DMS96] and Relacs [BDM97]) support this requirement, even in the absence of crashes. <ref> [YLKD97] </ref> is also concerned with this requirement implementation. 6.2.6 Non-triviality of membership Preciseness (Requirement 5.1.5) is one of the most fundamental properties of a membership service. The main goal of a membership service is to reflect the actual connectivity situation of the physical network.
References-found: 73

