URL: http://www.ai.mit.edu/people/paulfitz/doc/sab98-bdi.ps.gz
Refering-URL: http://www.ai.mit.edu/people/paulfitz/paulfitz.html
Root-URL: 
Email: paulfitz@ai.mit.edu  
Title: Coarse Visual Homing using Azimuthal Cues  
Author: Paul Fitzpatrick 
Address: Cambridge, MA 02139  
Affiliation: Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: In local homing, an agent returns to a previously visited location by moving to maximize the correspondence between what it sees currently and a remembered view from the target. Clearly this is straightforward if the agent is close enough to the target, and less easy over longer distances. For example, Franz et al [2] give a homing algorithm which works well when close to the target, but the accuracy of which falls off rapidly once the agent is far enough away for features seen from the target to be occluded. This paper presents a scheme that attempts to move an agent into the same basic geometric relationship with its environment as it remembers being in at the target, at which point Franz's homing algorithm stands a better chance of success.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. A. Cartwright and T. S. Collett. </author> <title> Landmark learning in bees: Experiments and models. </title> <journal> Journal of Comparative Physiology, </journal> <volume> 151 </volume> <pages> 521-543, </pages> <year> 1983. </year>
Reference-contexts: of what it saw at some target location, in which direction should the agent move to return to that target? For example, honeybees exhibit an ability to return to an unmarked location based on the position of nearby landmarks, which it is suggested they achieve using this type of homing <ref> [1] </ref>. The same behavior has been implemented in robotic form using a number of different strategies. This paper will present a possible scheme for extending somewhat the currently limited area over which such strategies can be applied successfully. <p> are discussed. 1.1 Image-based homing One theory of the mechanics behind the homing behavior of bees is that they memorize the retinal image they see at the goal (e.g. at a food source), and then on returning search for the position from which the view best matches 1 that image <ref> [1] </ref>. This type of homing is called image-based homing. In image-based homing, there are two questions that need answers: how are qualities of matches between images evaluated, and what search strategy should the agent use to direct its motion. <p> in the next section, followed by results showing its performance under various simulated scenarios. 2 Geometric matching Experiments on honeybees have shown that when homing to an unmarked location whose position is defined by prominent nearby landmarks, the direction to these landmarks appears to be the dominant cue used (see <ref> [1] </ref> and Section 3.1 for a discussion). The same series of experiments also showed that bees have a sense of absolute direction. For example, when the target location is near a single radially symmetric landmark, the bee will search in the correct direction relative to that landmark. <p> To make this less subjective, the honeybee will be used as the benchmark against which the algorithm is judged. In particular, the experiments Cartwright and Collett performed with bees in <ref> [1] </ref> will be applied to the algorithm. See [6] for another homing algorithm compared with Cartwright and Collet's findings. In the series of experiments described in [1], the bees were trained to an inconspicuous food source placed close to an arrangement of prominent landmarks (matte black against a white background). <p> In particular, the experiments Cartwright and Collett performed with bees in <ref> [1] </ref> will be applied to the algorithm. See [6] for another homing algorithm compared with Cartwright and Collet's findings. In the series of experiments described in [1], the bees were trained to an inconspicuous food source placed close to an arrangement of prominent landmarks (matte black against a white background). Then the source was removed, and the searching behavior of the bees recorded. <p> In Cartwright and Collett's early study on landmark learning in bees <ref> [1] </ref>, there is a discussion of how bees resolve conflicts between matching directions to landmarks and matching their apparent size. The algorithm described here makes no explicit representation of the apparent size of an object, but still behaves as the bee does.
Reference: [2] <author> M. O. Franz, B. Scholkopf, and H. H. Bulthoff. </author> <title> Homing by parameterized scene matching. </title> <editor> In P. Husbands and I Harvey, editors, </editor> <booktitle> Proceedings of the 4th European Conference on Artificial Life. </booktitle> <publisher> MIT Press, </publisher> <year> 1997. </year>
Reference-contexts: It certainly becomes extremely difficult to do from local considerations. Any pair of features wrongly put in correspondence can make the homing algorithm give inaccurate results. A homing technique called parameterized scene matching advanced by Franz et al <ref> [2] </ref> avoids the problem of establishing explicit local correspondences by working over the entire view. 1.2 Parameterized scene matching A competent image-based local homing algorithm has been implemented by Franz et al in [2]. <p> A homing technique called parameterized scene matching advanced by Franz et al <ref> [2] </ref> avoids the problem of establishing explicit local correspondences by working over the entire view. 1.2 Parameterized scene matching A competent image-based local homing algorithm has been implemented by Franz et al in [2]. This algorithm uses a transformation that takes the current view from the agent and "warps" it, based on the assumption that all landmarks are equally distant from the agent, to give an estimate of the view the agent would have if it moved some distance in a particular direction. <p> The simulated agent has a 360 ffi horizontal view of its environment, divided into 160 pixels, and with no vertical extent. This is an idealization of the robotic implementations using spherical or conical mirrors placed above a camera, or equivalent arrangements <ref> [2, 4, 5] </ref>. 3.1 Comparison with the honeybee First it will be shown that the algorithm behaves "sensibly" for various types of environmental mutation. To make this less subjective, the honeybee will be used as the benchmark against which the algorithm is judged.
Reference: [3] <author> M. O. Franz, B. Scholkopf, P. Georg, H. A. Mallot, and H. H. Bulthoff. </author> <title> Learning view-graphs for robot navigation. </title> <editor> In W. L. Johnson, editor, </editor> <booktitle> Proceedings of the 1st International Conference on Autonomous Agents, </booktitle> <pages> pages 138-147. </pages> <publisher> ACM Press, </publisher> <year> 1997. </year>
Reference-contexts: But by accumulating a mosaic of known locations, the task of homing from a starting location to some distant target breaks down into short-range homing to a series of intermediate locations [4]. See Franz et al <ref> [3] </ref> for an implemented system. Alternatively, local homing could also be employed when an agent is able to use dead-reckoning or other cues to return to the general area of its goal, but with some error for which it must compensate.
Reference: [4] <author> J. Hong, X. Tan, B. Pinette, R. Weiss, and E. M. Riseman. </author> <title> Image-based homing. </title> <booktitle> Proceedings of the 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 620-625, </pages> <year> 1991. </year>
Reference-contexts: But by accumulating a mosaic of known locations, the task of homing from a starting location to some distant target breaks down into short-range homing to a series of intermediate locations <ref> [4] </ref>. See Franz et al [3] for an implemented system. Alternatively, local homing could also be employed when an agent is able to use dead-reckoning or other cues to return to the general area of its goal, but with some error for which it must compensate. <p> Robotic implementations often avoid directly grading how well images match, and instead compute in which direction the robot could move to most improve the match. The search strategy is then to follow this direction, recompute, move again, and so on <ref> [4] </ref>. How can the correct direction to move in be calculated? A common approach to homing is to somehow establish a correspondence between features of the current view and the home view. Cartwright and Collett presented a model of landmark navigation in bees along these lines. <p> Their model bee matches dark and light areas of its current view against corresponding areas in the view apparent at the target, and moves appropriately to bring the areas into agreement. Robotic implementations along different lines include those of Hong <ref> [4] </ref>, and Rofer [5]. In [6], Wittmann presented a more detailed model of landmark navigation than that given by Cartwright and Collett. In particular, he elaborated on this problem of establishing a correspondence between the current and home view. <p> The simulated agent has a 360 ffi horizontal view of its environment, divided into 160 pixels, and with no vertical extent. This is an idealization of the robotic implementations using spherical or conical mirrors placed above a camera, or equivalent arrangements <ref> [2, 4, 5] </ref>. 3.1 Comparison with the honeybee First it will be shown that the algorithm behaves "sensibly" for various types of environmental mutation. To make this less subjective, the honeybee will be used as the benchmark against which the algorithm is judged.
Reference: [5] <author> T. Rofer. </author> <title> Controlling a robot with image-based homing. </title> <editor> In B Krieg-Bruckner, G Roth, and H Schwegler, editors, </editor> <title> ZKW Bericht Nr. </title> <type> 3. </type> <institution> Report series of the Center for Cognitive Sciences at the University of Bremen, </institution> <year> 1995. </year>
Reference-contexts: Their model bee matches dark and light areas of its current view against corresponding areas in the view apparent at the target, and moves appropriately to bring the areas into agreement. Robotic implementations along different lines include those of Hong [4], and Rofer <ref> [5] </ref>. In [6], Wittmann presented a more detailed model of landmark navigation than that given by Cartwright and Collett. In particular, he elaborated on this problem of establishing a correspondence between the current and home view. <p> The simulated agent has a 360 ffi horizontal view of its environment, divided into 160 pixels, and with no vertical extent. This is an idealization of the robotic implementations using spherical or conical mirrors placed above a camera, or equivalent arrangements <ref> [2, 4, 5] </ref>. 3.1 Comparison with the honeybee First it will be shown that the algorithm behaves "sensibly" for various types of environmental mutation. To make this less subjective, the honeybee will be used as the benchmark against which the algorithm is judged.
Reference: [6] <author> T. Wittmann. </author> <title> Modeling landmark navigation. </title> <editor> In B Krieg-Bruckner, G Roth, and H Schwegler, editors, ZKW Bericht Nr. </editor> <volume> 3, </volume> <year> 1995. </year>
Reference-contexts: Their model bee matches dark and light areas of its current view against corresponding areas in the view apparent at the target, and moves appropriately to bring the areas into agreement. Robotic implementations along different lines include those of Hong [4], and Rofer [5]. In <ref> [6] </ref>, Wittmann presented a more detailed model of landmark navigation than that given by Cartwright and Collett. In particular, he elaborated on this problem of establishing a correspondence between the current and home view. <p> The exact features the algorithm relies on being extracted from the environment will be discussed in Section 2.2. The idea behind geometric matching is very simple. It is perhaps useful to introduce it by contrasting it with Wittmann's approach to the homing problem <ref> [6] </ref>. Wittmann observed that given the current direction to a landmark, and the direction expected for it from the home view, there are an infinite number of possible homing vectors consistent with that. His approach to resolving this ambiguity is to combine information from a number of landmarks. <p> To make this less subjective, the honeybee will be used as the benchmark against which the algorithm is judged. In particular, the experiments Cartwright and Collett performed with bees in [1] will be applied to the algorithm. See <ref> [6] </ref> for another homing algorithm compared with Cartwright and Collet's findings. In the series of experiments described in [1], the bees were trained to an inconspicuous food source placed close to an arrangement of prominent landmarks (matte black against a white background).
References-found: 6

