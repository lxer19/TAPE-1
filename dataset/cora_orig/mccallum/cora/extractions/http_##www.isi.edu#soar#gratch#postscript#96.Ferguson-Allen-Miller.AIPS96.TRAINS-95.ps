URL: http://www.isi.edu/soar/gratch/postscript/96.Ferguson-Allen-Miller.AIPS96.TRAINS-95.ps
Refering-URL: http://www.isi.edu/soar/gratch/readings.html
Root-URL: http://www.isi.edu
Email: fferguson,james,millerg@cs.rochester.edu  
Title: TRAINS-95: Towards a Mixed-Initiative Planning Assistant  
Author: George Ferguson and James Allen and Brad Miller 
Web: http://www.cs.rochester.edu/research/trains/  
Address: Rochester, NY, USA, 14627-0226  
Affiliation: Department of Computer Science University of Rochester  
Abstract: We have been examining mixed-initiative planning systems in the context of command and control or logistical overview situations. In such environments, the human and the computer must work together in a very tightly coupled way to solve problems that neither alone could manage. In this paper, we describe our implementation of a prototype version of such a system, TRAINS-95, which helps a manager solve routing problems in a simple transportation domain. Interestingly perhaps, traditional planning technology does not play a major role in the system, and in fact it is difficult to see how such components might fit into a mixed-initiative system. We describe some of these issues, and present our agenda for future research into mixed-initiative plan reasoning. At this writing, the TRAINS-95 system has been used by more than 100 people to solve simple problems at various conferences and workshops, and in our experiments. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. F.; Schubert, L. K.; Ferguson, G.; Hee-man, P.; Hwang, C. H.; Kato, T.; Light, M.; Martin, N. G.; Miller, B. W.; Poesio, M.; and Traum, D. R. </author> <year> 1995. </year> <title> The TRAINS project: A case study in building a conversational planning agent. </title> <journal> Journal of Experimental and Theoretical AI 7 </journal> <pages> 7-48. </pages> <note> Also available as University of Rochester, </note> <institution> Dept. </institution> <note> of Computer Science TRAINS Technical Note 94-3. </note>
Reference-contexts: The first of these is a robust parsing system based on a bottom-up chart parser (Allen 1994). The parser uses a fairly comprehensive lexicon of 1700 words and grammar of 275 rules, both built from the TRAINS dialogue corpus <ref> (Heeman & Allen 1995) </ref>. The parser accepts input from all the input modules|we treat spoken, typed, and moused input uniformly as linguistic communication. The parser's output is a set of speech acts expressing the content of the utterance. <p> In fact, in an informal analysis of one hour of human-human problem-solving dialogues (part of a larger eight hour study <ref> (Heeman & Allen 1995) </ref>), we found that a relatively small percentage of the utterances, 23%, dealt with explicitly adding or refining actions in the plan. Figure 4 summarizes this analysis. Note the importance of being able to explicitly evaluate and compare options, even between humans of roughly equal ability. <p> Conclusion The TRAINS-95 system is a concrete first step towards a mixed-initiative planning assistant. We have demonstrated the feasibility of the dialogue-based approach to interactive planning, and have developed a substantial infrastructure for future research. The TRAINS-95 system is being developed as part of the TRAINS Project <ref> (Allen et al. 1995) </ref>, a long-term research effort to develop intelligent assistants that interact with their human managers using natural language. More information is available via the World-Wide Web at URL: http://www.cs.rochester.edu/research/trains/. Acknowledgements This material is based upon work supported by ARPA - Rome Laboratory under research contract no.
Reference: <author> Allen, J. F.; Miller, B.; Ringger, E. K.; and Sikorski, T. </author> <year> 1996. </year> <title> Robust understanding in a dialogue system. </title> <note> Submitted for publication. </note>
Reference-contexts: As we refine those metrics, we can explore whether particular strategies are better than others at getting the task done, or whether the presence of certain components helps or hinders performance. In recent work <ref> (Allen et al. 1996) </ref>, we have evaluated the effects of input mode (speech vs. keyboard) on task performance and explored user input-mode preferences.
Reference: <author> Allen, J. F. </author> <year> 1994. </year> <title> Natural Language Understanding. </title> <publisher> Benjamin Cummings, </publisher> <address> 2nd edition edition. </address>
Reference-contexts: Language and Dialogue Processing The core of the TRAINS-95 system is the set of modules that perform language understanding and dialogue processing tasks. The first of these is a robust parsing system based on a bottom-up chart parser <ref> (Allen 1994) </ref>. The parser uses a fairly comprehensive lexicon of 1700 words and grammar of 275 rules, both built from the TRAINS dialogue corpus (Heeman & Allen 1995). The parser accepts input from all the input modules|we treat spoken, typed, and moused input uniformly as linguistic communication.
Reference: <author> Ferguson, G. </author> <year> 1995. </year> <title> Knowledge Representation and Reasoning for Mixed-Initiative Planning. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Rochester, Rochester, NY. </institution> <note> Available as Technical Report 562. </note>
Reference: <author> Finin, T.; Fritzson, R.; McKay, D.; and McEntire, R. </author> <year> 1994. </year> <title> KQML as an agent communication language. </title> <booktitle> In Proc. Third International Conference on Information and Knowledge Management (CIKM-94). </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: That is, the abstract plan reasoner needs to be able to reason about which specialists might be suitable for what tasks, and interpret their results. This is complicated by the desire to use existing components "off the shelf" as much as possible. We are currently looking at using KQML <ref> (Finin et al. 1994) </ref> for part of this purpose, as well as other work on specifying agent capabilities (Tate 1995). Current and Future Directions Our experiences with TRAINS-95 have opened up many research directions that we are currently pursuing, and this paper has already discussed several of them.
Reference: <author> Heeman, P. A., and Allen, J. F. </author> <year> 1995. </year> <title> The TRAINS-93 dialogues. </title> <type> TRAINS Technical Note 94-2, </type> <institution> Dept. of Computer Science, University of Rochester, Rochester, NY. </institution>
Reference-contexts: The first of these is a robust parsing system based on a bottom-up chart parser (Allen 1994). The parser uses a fairly comprehensive lexicon of 1700 words and grammar of 275 rules, both built from the TRAINS dialogue corpus <ref> (Heeman & Allen 1995) </ref>. The parser accepts input from all the input modules|we treat spoken, typed, and moused input uniformly as linguistic communication. The parser's output is a set of speech acts expressing the content of the utterance. <p> In fact, in an informal analysis of one hour of human-human problem-solving dialogues (part of a larger eight hour study <ref> (Heeman & Allen 1995) </ref>), we found that a relatively small percentage of the utterances, 23%, dealt with explicitly adding or refining actions in the plan. Figure 4 summarizes this analysis. Note the importance of being able to explicitly evaluate and compare options, even between humans of roughly equal ability.
Reference: <author> Huang, X.; Alleva, F.; Hon, H.-W.; Hwang, M.-Y.; and Rosenfeld, R. </author> <year> 1992. </year> <title> The SPHINX-II speech recognition system: An overview. </title> <type> Technical Report CS-92-112, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: The next section provides an example of the system in action and discusses the implications for mixed-initiative planning systems. Speech and Display Modules For speech input in TRAINS-95, we use the Sphinx-II recognizer from CMU <ref> (Huang et al. 1992) </ref>, trained on the ATIS airline reservation corpus, with a vocabulary of approximately 3000 words. We deliberately did not build a special recognizer for our task or domain, since we wanted to investigate using off-the-shelf components directly as "black boxes" in our system.
Reference: <author> Kambhampati, S., and Hendler, J. A. </author> <year> 1992. </year> <title> A validation-structure-based theory of plan modification and reuse. </title> <booktitle> Artificial Intelligence 55 </booktitle> <pages> 193-258. </pages>
Reference: <author> Kambhampati, S. </author> <year> 1989. </year> <title> Flexible reuse and modification in hierarchical planning: A validation structure based approach. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Maryland, College Park, MD. </institution> <note> Available as CS Technical Report 2334. </note>
Reference: <author> Lambert, L., and Carberry, S. </author> <year> 1991. </year> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proc. Twenty-Ninth Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 47-54. </pages> <address> Berkeley, CA: </address> <institution> University of Cali-fornia. </institution>
Reference-contexts: While critical to the overall system, the other three levels are more centrally concerned with the planning process. The problem solving level maintains meta-level information about the problem solving tasks, similar to the problem solving level actions described in (Litman & Allen 1987) and <ref> (Lambert & Carberry 1991) </ref>. Actions at this level are problem solving actions such as "solve goal directly," "decompose goal into subprob-lems," "resolve resource conflict," and so on. Note that we need explicit representations of such actions because they can be discussed in the dialogue.
Reference: <author> Litman, D., and Allen, J. F. </author> <year> 1987. </year> <title> A plan-recognition model for subdialogues in conversations. </title> <booktitle> Cognitive Science 11(2). </booktitle>
Reference-contexts: While critical to the overall system, the other three levels are more centrally concerned with the planning process. The problem solving level maintains meta-level information about the problem solving tasks, similar to the problem solving level actions described in <ref> (Litman & Allen 1987) </ref> and (Lambert & Carberry 1991). Actions at this level are problem solving actions such as "solve goal directly," "decompose goal into subprob-lems," "resolve resource conflict," and so on. Note that we need explicit representations of such actions because they can be discussed in the dialogue.
Reference: <author> Pollack, M. E. </author> <year> 1992. </year> <title> The uses of plans. </title> <booktitle> Artificial Intelligence 57. </booktitle>
Reference: <author> Ringger, E. K. </author> <year> 1995. </year> <title> A robust loose coupling for speech recognition and natural language understanding. </title> <type> Technical Report 592, </type> <institution> Dept. of Computer Science, University of Rochester, Rochester, NY. </institution>
Reference-contexts: To compensate for the under-constrained speech rec-ognizer, its output is post-processed by a domain-and/or speaker-dependent module <ref> (Ringger 1995) </ref>. This module uses techniques from machine translation to "correct" the output of the recognizer, based on a statistical model derived from a corpus of previous runs of the system. The speech generation component of TRAINS-95 is built on the TrueTalk generator from Entropics, Inc.
Reference: <author> Sacerdoti, E. </author> <year> 1977. </year> <title> A Structure for Plans and Be-haviour. </title> <address> New York, NY: </address> <publisher> Elsevier, North-Holland. </publisher>
Reference-contexts: If the solution appears acceptable (given the current focus), then we con tinue at step (A) by selecting a new focus. At first glance, this model seems quite similar to the expand-criticize cycle found in hierarchical planners since Sacerdoti <ref> (Sacerdoti 1977) </ref>. The significant difference is in step (C). Rather than pursuing a least commitment strategy and incremental top-down refinement, we "leap" to a solution as soon as possible. You might call this a "look then leap" strategy rather than the traditional "wait and see" strategy used in least-commitment planning.
Reference: <author> Sussman, G. J. </author> <year> 1974. </year> <title> The virtuous nature of bugs. </title> <booktitle> In Proc. First Conference of the Society for the Study of AI and the Simulation of Behaviour. </booktitle> <address> Brighton, UK: Sussex University. </address>
Reference-contexts: Third, concentrating on the type of planning that goes on in mixed-initiative systems, it is clear that much of it can be seen as replanning, in the sense of debugging a plan ala Sussman <ref> (Sussman 1974) </ref>. We are looking at the various approaches to replanning (e.g.., (Kambhampati 1989; Kambhampati & Hendler 1992)), but to some extent these seem to be burdened by the same constraints that make traditional planning systems unsuitable for direct use in the mixed-initiative situation.
Reference: <author> Tate, A. </author> <year> 1995. </year> <title> The O-Plan knowledge source framework. </title> <type> ARPA/RL O-Plan TR 21, </type> <institution> Artifical Intelligence Applications Institute, University of Edinburgh, Ed-inburgh, UK. </institution>
Reference-contexts: This is complicated by the desire to use existing components "off the shelf" as much as possible. We are currently looking at using KQML (Finin et al. 1994) for part of this purpose, as well as other work on specifying agent capabilities <ref> (Tate 1995) </ref>. Current and Future Directions Our experiences with TRAINS-95 have opened up many research directions that we are currently pursuing, and this paper has already discussed several of them. In this section we provide a brief survey of some additional issues for current and future work.
References-found: 16

