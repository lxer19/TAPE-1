URL: http://www.ai.mit.edu/people/polina/Papers/stereo.ps
Refering-URL: http://www.ai.mit.edu/people/polina/Papers/
Root-URL: 
Email: szeliski@microsoft.com  polina@ai.mit.edu  
Title: Stereo Matching with Transparency and Matting  
Author: Richard Szeliski and Polina Golland 
Date: April 29, 1997  
Note: Submitted to ICCV'98  
Address: One Microsoft Way Redmond, WA 98052-6399  545 Technology Square #810  Cambridge, Massachusetts 02139  
Affiliation: Microsoft Research  Artificial Intelligence Laboratory  Massachusetts Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [Arn83] <author> R. D. Arnold. </author> <title> Automated stereo perception. </title> <type> Technical Report AIM-351, </type> <institution> Artificial Intelligence Laboratory, Stanford University, </institution> <month> March </month> <year> 1983. </year>
Reference-contexts: Aggregating support is necessary to disambiguate potential matches. A support region can either be two-dimensional at a fixed disparity (favoring fronto-parallel surfaces), or three-dimensional in (x; y; d) space (allowing slanted surfaces). Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes <ref> [Arn83, KO94] </ref>. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes [SH85]), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation [SS96]. <p> Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [B + 96] <author> L. Blonde et al. </author> <title> A virtual studio for live broadcasting: The Mona Lisa project. </title> <journal> IEEE Multimedia, </journal> <volume> 3(2) </volume> <pages> 18-29, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: More recently, depth maps obtained from stereo have been painted with texture maps extracted from input images in order to create realistic 3-D scenes and environments for virtual reality and virtual studio applications <ref> [MB95, SK95, K + 96, B + 96] </ref>. Unfortunately, the quality and resolution of most stereo algorithms falls quite short of that demanded by these new applications, where even isolated errors in the depth map become readily visible when composited with synthetic graphical elements. <p> Different techniques have been developed for computing sub-pixel estimates, such as using a finer set of disparity hypotheses or finding the the analytic minimum of the local error surface [TH86, MSK89]. Unfortunately, for challenging applications such as z-keying (the insertion of graphics between different depth layers in video) <ref> [PW94, K + 96, B + 96] </ref>, even this is not good enough. Pixels lying near or on occlusion boundaries will typically be mixed, i.e., they will contain blends of both foreground and background colors.
Reference: [Bak80] <author> H. H. Baker. </author> <title> Edge based stereo correlation. </title> <editor> In L. S. Baumann, editor, </editor> <booktitle> Image Understanding Workshop, </booktitle> <pages> pages 168-175. </pages> <institution> Science Applications International Corporation, </institution> <month> April </month> <year> 1980. </year>
Reference-contexts: The most fundamental element of any correspondence algorithm is a matching cost that 2 measures the similarity of two or more corresponding pixels in different images. Matching costs can be defined locally (at the pixel level), e.g., as absolute [K + 96] or squared intensity differences [MSK89], using edges <ref> [Bak80] </ref> or filtered images [JJT91, JM92]. Alternatively, matching costs may be defined over an area, e.g., using correlation [RGH80] (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. Aggregating support is necessary to disambiguate potential matches.
Reference: [Bar89] <author> S. T. Barnard. </author> <title> Stochastic stereo matching over scale. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(1) </volume> <pages> 17-32, </pages> <year> 1989. </year>
Reference-contexts: In this paper, we will introduce the concept of a virtual camera which is used for the initial winner-take-all stage. Occlusion is another very important issue in generating high-quality stereo maps. Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation <ref> [Bar89] </ref>, or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming [Arn83, OK85, BM92, Cox94, GLY92, IB94]. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [BBHP92] <author> J. R. Bergen, P. J. Burt, R. Hingorani, and S. Peleg. </author> <title> A three-frame algorithm for estimating two-component image motion. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(9) </volume> <pages> 886-896, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation <ref> [BBHP92, SM91b, SM91a, JBJ96, DP91] </ref>. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. <p> For example, we plan to try our algorithm on data sets with true transparency (not just mixed pixels), such as traditional transparent random dot stereograms [Pra85, Wei89] and reflections in windows <ref> [BBHP92] </ref>. Estimating disparities to sub-integer precision should improve the quality of our reconstructions. Such fractional disparity estimates can be obtained by interpolating a variance vs. disparity curve (d), e.g., by fitting a parabola to the lowest variance and its two neighbors [TH86, MSK89]. <p> We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [BBM87] <author> R. C. Bolles, H. H. Baker, and D. H. Marimont. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 7-55, </pages> <year> 1987. </year>
Reference-contexts: However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. Multiframe stereo algorithms use more than two images to increase the stability of the algorithm <ref> [BBM87, MSK89, KWZK95, Col96] </ref>. In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of [OK93, KWZK95, Col96]. <p> It is also not the same as an epipolar-plane image (EPI) volume <ref> [BBM87] </ref>, which is a simple concatenation of warped input images. 6 space (y is fixed at a given scanline), where color samples varying in k are grouped together. 4 Estimating an initial disparity surface The first step in stereo matching is to compute some initial evidence for a surface existing at
Reference: [BF82] <author> S. T. Barnard and M. A. Fischler. </author> <title> Computational stereo. </title> <journal> Computing Surveys, </journal> <volume> 14(4) </volume> <pages> 553-572, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: We conclude the paper with a discussion of our results, and a list of topics for future research. 2 Previous Work Stereo matching (and the more general problem of stereo-based 3-D reconstruction) are fields with very rich histories <ref> [BF82, DA89] </ref>. In this section, we focus only on previous work related to our central topics of interest: pixel-accurate matching with sub-pixel precision, the handling of occlusion boundaries, and the use of more than two images.
Reference: [Bli94a] <author> J. F. Blinn. Jim Blinn's corner: Compositing, </author> <title> part 1: </title> <journal> Theory. IEEE Computer Graphics and Applications, </journal> <volume> 14(5) </volume> <pages> 83-87, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Practitioners in these fields quickly discovered that it is insufficient to merely label pixels as foreground and background: it is necessary to simultaneously recover both the true color of each pixel and its transparency or opacity <ref> [PD84, Bli94a] </ref>. 1 In this paper, we develop a new, multiframe stereo algorithm which simultaneously re-covers depth, color, and transparency estimates at each pixel. Unlike traditional blue-screen matting, we cannot use a known background color to perform the color and matte recovery. <p> None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. Our stereo algorithm has also been inspired by work in computer graphics, especially in image compositing <ref> [PD84, Bli94a] </ref> and blue screen techniques [VT93, SB96]. <p> In our experiments, the threshold is set to = min + s Var 3fi3 , with min = 10 and s = 0:02. 7 We may, for computational reasons, choose to represent this volume using colors premultiplied by their opacities (associated colors <ref> [PD84, Bli94a] </ref>), in which case voxels for which alpha (opacity) is 0 should have their color or intensity values set to 0. <p> See <ref> [Bli94a, Bli94b] </ref> for a discussion of the advantages of using premultiplied colors. 10 using the known homography x k = H k x 0 + t k d = (H k + t k [0 0 d]) x 0 (4) and the layers are then composited back-to-front (this is called a <p> Once the layers have been resampled, they are then composited using the standard over operator [PD84], f ^ b f + (1 ff f )b; where f and b are the premultiplied foreground and background colors, and ff f is the opacity of the foreground <ref> [PD84, Bli94a] </ref>. Using the over operator, we can form a composite image ~ c k (u; v) = d=d max (note that the over operator is associative but not commutative, and that d max is the layer closest to the camera). <p> Instead of representing our color volume ^ c (x; y; d) using colors pre-multiplied by their opacities <ref> [Bli94a] </ref>, we could keep these quantities separate. Thus, colors could "bleed" into areas which are transparent, which may be a more natural representation for color smoothness (e.g., for surfaces with small holes).
Reference: [Bli94b] <author> J. F. Blinn. Jim Blinn's corner: Compositing, </author> <title> part 2: </title> <journal> Practice. IEEE Computer Graphics and Applications, </journal> <volume> 14(6) </volume> <pages> 78-82, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: See <ref> [Bli94a, Bli94b] </ref> for a discussion of the advantages of using premultiplied colors. 10 using the known homography x k = H k x 0 + t k d = (H k + t k [0 0 d]) x 0 (4) and the layers are then composited back-to-front (this is called a
Reference: [BM92] <author> P. N. Belhumeur and D. Mumford. </author> <title> A Bayesian treatment of the stereo correspondence problem using half-occluded regions. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 506-512, </pages> <address> Champaign-Urbana, Illinois, </address> <year> 1992. </year>
Reference-contexts: Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [Col96] <author> R. T. Collins. </author> <title> A space-sweep approach to true multi-image matching. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'96), </booktitle> <pages> pages 358-363, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. Multiframe stereo algorithms use more than two images to increase the stability of the algorithm <ref> [BBM87, MSK89, KWZK95, Col96] </ref>. In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of [OK93, KWZK95, Col96]. <p> In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of <ref> [OK93, KWZK95, Col96] </ref>. Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91]. <p> Finally, for cameras in general position, steps in disparity will correspond to zooms (scalings) and sub-pixel shifts of the rectified images, which is quicker (and potentially more accurate) than general perspective resampling <ref> [Col96] </ref>. A potential disadvantage of pre-rectification is a slight loss in input image quality due to multiple re-samplings, but this can be mitigated using higher-order (e.g., bicubic) sampling filters, and potentially re-sampling the rectified images at higher resolution. <p> 4 For certain epipolar geometries, even more efficient algorithms are possible, e.g., by simply shifting along epipolar lines [K + 96]. 5 In many traditional stereo algorithms, it is common to effectively set the mean to be just the value in one image, which makes these algorithms not truly multiframe <ref> [Col96] </ref>.
Reference: [Cox94] <author> I. J. Cox. </author> <title> A maximum likelihood n-camera stereo algorithm. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'94), </booktitle> <pages> pages 23 733-739, </pages> <address> Seattle, Washington, June 1994. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [DA89] <author> U. R. Dhond and J. K. Aggarwal. </author> <title> Structure from stereo|a review. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 19(6) </volume> <pages> 1489-1510, </pages> <month> November/December </month> <year> 1989. </year>
Reference-contexts: We conclude the paper with a discussion of our results, and a list of topics for future research. 2 Previous Work Stereo matching (and the more general problem of stereo-based 3-D reconstruction) are fields with very rich histories <ref> [BF82, DA89] </ref>. In this section, we focus only on previous work related to our central topics of interest: pixel-accurate matching with sub-pixel precision, the handling of occlusion boundaries, and the use of more than two images.
Reference: [DP91] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Princeton, New Jersey, October 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation <ref> [BBHP92, SM91b, SM91a, JBJ96, DP91] </ref>. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. <p> We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [Fua93] <author> P. Fua. </author> <title> A parallel stereo algorithm that produces dense depth maps and preserves image features. </title> <journal> Machine Vision and Applications, </journal> <volume> 6 </volume> <pages> 35-49, </pages> <year> 1993. </year>
Reference-contexts: Occlusion is another very important issue in generating high-quality stereo maps. Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking <ref> [Fua93] </ref>. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming [Arn83, OK85, BM92, Cox94, GLY92, IB94]. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [GB95] <author> P. Golland and A.M. Bruckstein. </author> <title> Motion from color. </title> <type> Technical Report 9513, </type> <institution> IS Lab, CS Department, Technion, Haifa, Israel, </institution> <year> 1995. </year>
Reference-contexts: Thus, colors could "bleed" into areas which are transparent, which may be a more natural representation for color smoothness (e.g., for surfaces with small holes). Different color representations such as hue, saturation, intensity (HSV) may also be more suitable for performing correspondence <ref> [GB95] </ref>, and they would permit us to reason more directly about underlying physical processes (shadows, shading,etc.). We plan to investigate the relationship of our new disparity space model to more traditional layered motion models [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96].
Reference: [GGSC96] <author> S. J. Gortler, R. Grzeszczuk, R. Szeliski, and M. F. Cohen. </author> <booktitle> The lumigraph. In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 43-54, </pages> <booktitle> Proc. </booktitle> <address> SIG-GRAPH'96 (New Orleans), </address> <month> August </month> <year> 1996. </year> <note> ACM SIGGRAPH. </note>
Reference-contexts: As another example, we may wish to use a skewed camera model for constructing a Lumigraph <ref> [GGSC96] </ref>. Having chosen a virtual camera position, we can also choose the orientation and spacing of the disparity planes, i.e., the constant d planes. The relationship between d and 3-D space can be projective. <p> In particular, compositing these images in a back-to-front order, taking into account each voxel's opacity, should reconstruct what is seen by a given (rectified) input image (see Section 5). 1 1 Note that this 4-D space is not the same as that used in the Lumigraph <ref> [GGSC96] </ref>, where the description is one of rays in 3-D, as opposed to color distributions across multiple cameras in 3-D.
Reference: [GLY92] <author> D. Geiger, B. Ladendorf, and A. Yuille. </author> <title> Occlusions and binocular stereo. </title> <booktitle> In Second Eu-ropean Conference on Computer Vision (ECCV'92), </booktitle> <pages> pages 425-433, </pages> <address> Santa Margherita Liguere, Italy, May 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [Hub81] <author> P. J. Huber. </author> <title> Robust Statistics. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, New York, </address> <year> 1981. </year>
Reference-contexts: d. 14 2. a (weak) smoothness constraint on the colors and opacities, C 2 = (x;y;d) (x 0 ;y 0 ;d 0 )2N (x;y;d) 3. a prior distribution on the opacities, C 3 = (x;y;d) In the above equations, 1 and 2 are either quadratic functions or robust penalty functions <ref> [Hub81] </ref>, and is a function which encourages opacities to be 0 or 1, e.g., (x) = x (1 x). 12 The smoothness constraint on colors makes more sense with non-premultiplied colors.
Reference: [IB94] <author> S. S. Intille and A. F. Bobick. </author> <title> Disparity-space images and large occlusion stereo. </title> <booktitle> In Proc. Third European Conference on Computer Vision (ECCV'94), volume 1, </booktitle> <address> Stock-holm, Sweden, May 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [JBJ96] <author> S. X. Ju, M. J. Black, and A. D. Jepson. </author> <title> Skin and bones: Multi-layer, locally affine, optical flow and regularization with transparency. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'96), </booktitle> <pages> pages 307-314, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation <ref> [BBHP92, SM91b, SM91a, JBJ96, DP91] </ref>. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. <p> We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [JJT91] <author> M. R. M. Jenkin, A. D. Jepson, and J. K. Tsotsos. </author> <title> Techniques for disparity measurement. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 53(1) </volume> <pages> 14-30, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Matching costs can be defined locally (at the pixel level), e.g., as absolute [K + 96] or squared intensity differences [MSK89], using edges [Bak80] or filtered images <ref> [JJT91, JM92] </ref>. Alternatively, matching costs may be defined over an area, e.g., using correlation [RGH80] (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. Aggregating support is necessary to disambiguate potential matches.
Reference: [JM92] <author> D. G. Jones and J. Malik. </author> <title> A computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <booktitle> In Second European Conference on Computer Vision (ECCV'92), </booktitle> <pages> pages 397-410, </pages> <address> Santa Margherita Liguere, Italy, May 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Matching costs can be defined locally (at the pixel level), e.g., as absolute [K + 96] or squared intensity differences [MSK89], using edges [Bak80] or filtered images <ref> [JJT91, JM92] </ref>. Alternatively, matching costs may be defined over an area, e.g., using correlation [RGH80] (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. Aggregating support is necessary to disambiguate potential matches.
Reference: [K + 96] <author> T. Kanade et al. </author> <title> A stereo machine for video-rate dense depth mapping and its new 24 applications. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'96), </booktitle> <pages> pages 196-202, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: More recently, depth maps obtained from stereo have been painted with texture maps extracted from input images in order to create realistic 3-D scenes and environments for virtual reality and virtual studio applications <ref> [MB95, SK95, K + 96, B + 96] </ref>. Unfortunately, the quality and resolution of most stereo algorithms falls quite short of that demanded by these new applications, where even isolated errors in the depth map become readily visible when composited with synthetic graphical elements. <p> Different techniques have been developed for computing sub-pixel estimates, such as using a finer set of disparity hypotheses or finding the the analytic minimum of the local error surface [TH86, MSK89]. Unfortunately, for challenging applications such as z-keying (the insertion of graphics between different depth layers in video) <ref> [PW94, K + 96, B + 96] </ref>, even this is not good enough. Pixels lying near or on occlusion boundaries will typically be mixed, i.e., they will contain blends of both foreground and background colors. <p> The most fundamental element of any correspondence algorithm is a matching cost that 2 measures the similarity of two or more corresponding pixels in different images. Matching costs can be defined locally (at the pixel level), e.g., as absolute <ref> [K + 96] </ref> or squared intensity differences [MSK89], using edges [Bak80] or filtered images [JJT91, JM92]. Alternatively, matching costs may be defined over an area, e.g., using correlation [RGH80] (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. <p> can be replaced with gray-level intensity values without affecting the validity of our analysis. 3 In our current implementation, the warping (resampling) algorithm uses bi-linear interpolation of the pixel colors and opacities. 4 For certain epipolar geometries, even more efficient algorithms are possible, e.g., by simply shifting along epipolar lines <ref> [K + 96] </ref>. 5 In many traditional stereo algorithms, it is common to effectively set the mean to be just the value in one image, which makes these algorithms not truly multiframe [Col96].
Reference: [KO94] <author> T. Kanade and M. Okutomi. </author> <title> A stereo matching algorithm with an adaptive window: Theory and experiment. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(9) </volume> <pages> 920-932, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: One of the most common errors made by most stereo algorithms is a systematic "fattening" of depth layers near occlusion boundaries. Algorithms based on variable window sizes <ref> [KO94] </ref> or iterative evidence aggregation [SS96] can in many instances mitigate such errors. Another common problem is that disparities are only estimated to the nearest pixel, which is typically not sufficiently accurate for tasks such as view interpolation. <p> Aggregating support is necessary to disambiguate potential matches. A support region can either be two-dimensional at a fixed disparity (favoring fronto-parallel surfaces), or three-dimensional in (x; y; d) space (allowing slanted surfaces). Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes <ref> [Arn83, KO94] </ref>. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes [SH85]), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation [SS96]. <p> are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back [SD97].) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching costs at the discrete disparity levels <ref> [LK81, TH86, MSK89, KO94] </ref>. This provides an easy way to increase the resolution of a stereo algorithm with little additional computation. However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. <p> To help disambiguate matches, we can use local evidence aggregation. The most common form is averaging using square windows, which results in the traditional sum of squared difference (SSD and SSSD) algorithms [OK93]. To obtain results with better quality near discontinuities, it is preferable to use adaptive windows <ref> [KO94] </ref> or iterative evidence accumulation [SS96]. In the latter case, we may wish to accumulate an evidence measure which is not simply summed error (e.g., the probability of a correct match [SS96]).
Reference: [KWZK95] <author> S. B. Kang, J. Webb, L. Zitnick, and T. Kanade. </author> <title> A multibaseline stereo system with active illumination and real-time image acquisition. </title> <booktitle> In Fifth International Conference on Computer Vision (ICCV'95), </booktitle> <pages> pages 88-93, </pages> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. Multiframe stereo algorithms use more than two images to increase the stability of the algorithm <ref> [BBM87, MSK89, KWZK95, Col96] </ref>. In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of [OK93, KWZK95, Col96]. <p> In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of <ref> [OK93, KWZK95, Col96] </ref>. Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91].
Reference: [Lev90] <author> M. Levoy. </author> <title> Efficient ray tracing of volume data. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 9(3) </volume> <pages> 245-261, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: There are several techniques possible for performing this projection, including classical volume rendering techniques <ref> [Lev90, LL94] </ref>. In our approach, we interpret the (x; y; d) volume as a set of (potentially) transparent acetates stacked at different d levels.
Reference: [LK81] <author> B. D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application in stereo vision. </title> <booktitle> In Seventh International Joint Conference on Artificial Intelligence (IJCAI-81), </booktitle> <pages> pages 674-679, </pages> <address> Vancouver, </address> <year> 1981. </year>
Reference-contexts: are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back [SD97].) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching costs at the discrete disparity levels <ref> [LK81, TH86, MSK89, KO94] </ref>. This provides an easy way to increase the resolution of a stereo algorithm with little additional computation. However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates.
Reference: [LL94] <author> P. Lacroute and M. Levoy. </author> <title> Fast volume rendering using a shear-warp factorization of the viewing transformation. </title> <journal> Computer Graphics (SIGGRAPH'94), </journal> <pages> pages 451-457, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: There are several techniques possible for performing this projection, including classical volume rendering techniques <ref> [Lev90, LL94] </ref>. In our approach, we interpret the (x; y; d) volume as a set of (potentially) transparent acetates stacked at different d levels. <p> a discussion of the advantages of using premultiplied colors. 10 using the known homography x k = H k x 0 + t k d = (H k + t k [0 0 d]) x 0 (4) and the layers are then composited back-to-front (this is called a shear-warp algorithm <ref> [LL94] </ref>). 8 The resampling procedure for a given layer d into the coordinate system of camera k can be written as ~ c k (u; v; d) = W b ( ^ c (x; y; d); H k + t k [0 0 d]); (5) where ^ c = [r g
Reference: [MB95] <author> L. McMillan and G. Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <journal> Computer Graphics (SIGGRAPH'95), </journal> <pages> pages 39-46, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: More recently, depth maps obtained from stereo have been painted with texture maps extracted from input images in order to create realistic 3-D scenes and environments for virtual reality and virtual studio applications <ref> [MB95, SK95, K + 96, B + 96] </ref>. Unfortunately, the quality and resolution of most stereo algorithms falls quite short of that demanded by these new applications, where even isolated errors in the depth map become readily visible when composited with synthetic graphical elements.
Reference: [MP76] <author> D. Marr and T. Poggio. </author> <title> Cooperative computation of stereo disparity. </title> <journal> Science, </journal> <volume> 194 </volume> <pages> 283-287, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: A problem with this is that uniqueness of matches is only enforced for one image (the reference image), while points in the other image might get matched to multiple points. Cooperative algorithms employing symmetric uniqueness constraints are one attempt to solve this problem <ref> [MP76] </ref>. In this paper, we will introduce the concept of a virtual camera which is used for the initial winner-take-all stage. Occlusion is another very important issue in generating high-quality stereo maps.
Reference: [MSK89] <author> L. H. Matthies, R. Szeliski, and T. Kanade. </author> <title> Kalman filter-based algorithms for estimating depth from image sequences. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3 </volume> <pages> 209-236, </pages> <year> 1989. </year>
Reference-contexts: Different techniques have been developed for computing sub-pixel estimates, such as using a finer set of disparity hypotheses or finding the the analytic minimum of the local error surface <ref> [TH86, MSK89] </ref>. Unfortunately, for challenging applications such as z-keying (the insertion of graphics between different depth layers in video) [PW94, K + 96, B + 96], even this is not good enough. <p> The most fundamental element of any correspondence algorithm is a matching cost that 2 measures the similarity of two or more corresponding pixels in different images. Matching costs can be defined locally (at the pixel level), e.g., as absolute [K + 96] or squared intensity differences <ref> [MSK89] </ref>, using edges [Bak80] or filtered images [JJT91, JM92]. Alternatively, matching costs may be defined over an area, e.g., using correlation [RGH80] (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. <p> are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back [SD97].) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching costs at the discrete disparity levels <ref> [LK81, TH86, MSK89, KO94] </ref>. This provides an easy way to increase the resolution of a stereo algorithm with little additional computation. However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. <p> However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. Multiframe stereo algorithms use more than two images to increase the stability of the algorithm <ref> [BBM87, MSK89, KWZK95, Col96] </ref>. In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of [OK93, KWZK95, Col96]. <p> Optionally, they may also compute a fractional disparity value by fitting an analytic curve to the error surface around the winning disparity and then finding its minimum <ref> [MSK89, OK93] </ref>. <p> Estimating disparities to sub-integer precision should improve the quality of our reconstructions. Such fractional disparity estimates can be obtained by interpolating a variance vs. disparity curve (d), e.g., by fitting a parabola to the lowest variance and its two neighbors <ref> [TH86, MSK89] </ref>. Alternatively, we can linearly interpolate individual color errors c (x; y; d; k) (x; y; d) between disparity levels, and find the minimum of the summed squared error (which will be a quadratic function of the fractional disparity).
Reference: [MYT95] <author> T. Mitsunaga, T. Yokoyama, and T. Totsuka. Autokey: </author> <title> Human assisted key extraction. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 265-272, </pages> <booktitle> Proc. </booktitle> <address> SIGGRAPH'95 (Los Angeles), </address> <month> August </month> <year> 1995. </year> <note> ACM SIGGRAPH. </note>
Reference-contexts: A simple way to approach this problem is to take the binary opacity maps produced by our stereo matching algorithm, and to make them real-valued using a low-pass filter. Another possibility might be to recover the transparency information by looking at the magnitude of the intensity gradient <ref> [MYT95] </ref>, assuming that we can isolate regions which belong to different disparity levels. In our work, we have chosen instead to adjust the opacity and color values ^ c (x; y; d) to match the input images (after re-projection), while favoring continuity in the color and opacity values.
Reference: [OK85] <author> Y. Ohta and T. Kanade. </author> <title> Stereo by intra- and inter-scanline search using dynamic programming. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-7(2):139-154, </volume> <month> March </month> <year> 1985. </year>
Reference-contexts: Many approaches ignore the effects of occlusion; others try to minimize them by using a cyclopean disparity representation [Bar89], or try to recover occluded regions after the matching by cross-checking [Fua93]. Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming <ref> [Arn83, OK85, BM92, Cox94, GLY92, IB94] </ref>. However, such techniques require the strict enforcement of ordering constraints [YP84].
Reference: [OK93] <author> M. Okutomi and T. Kanade. </author> <title> A multiple baseline stereo. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(4) </volume> <pages> 353-363, </pages> <month> April </month> <year> 1993. </year> <month> 25 </month>
Reference-contexts: In this paper, we present a new framework for formulating the multiframe stereo problem based on the concept of a virtual camera and a projective generalized disparity space, which includes as special cases the multiple baseline stereo models of <ref> [OK93, KWZK95, Col96] </ref>. Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91]. <p> The relationship between d and 3-D space can be projective. For example, we can choose d to be inversely proportional to depth, which is the usual meaning of disparity <ref> [OK93] </ref>. The information about the virtual camera's position and disparity plane orientation and spacing can be captured in a single 4 fi 4 matrix ^ M 0 , which represents a collineation of 3-D space. <p> disparity space representation is the standard epipolar geometry for two or more cameras placed in a plane perpendicular to their optical axes, in which case a natural choice for disparity is inverse depth (since this corresponds to uniform steps in inter-camera displacements, i.e., the quantity which can be measured accurately) <ref> [OK93] </ref>. Other choices include the traditional cyclopean camera placed symmetrically between two verged cameras, or a uniform sampling of 3-D which is useful in a true verged multi-camera environment [SD97] or for motion stereo. <p> The sample variance then corresponds to the squared difference or sum of squared differences <ref> [OK93] </ref>. 7 6 k - d = 0 d = 5 (a) (b) (c) x x x (g) (h) (i) for free fusion), (c) (x; d; k) slice for scanline 17, (d) means and (e) variances as a function of (x; d) (smaller variances are darker), (f) variances after evidence accumulation, <p> To help disambiguate matches, we can use local evidence aggregation. The most common form is averaging using square windows, which results in the traditional sum of squared difference (SSD and SSSD) algorithms <ref> [OK93] </ref>. To obtain results with better quality near discontinuities, it is preferable to use adaptive windows [KO94] or iterative evidence accumulation [SS96]. In the latter case, we may wish to accumulate an evidence measure which is not simply summed error (e.g., the probability of a correct match [SS96]). <p> Optionally, they may also compute a fractional disparity value by fitting an analytic curve to the error surface around the winning disparity and then finding its minimum <ref> [MSK89, OK93] </ref>.
Reference: [PD84] <author> T. Porter and T. Duff. </author> <title> Compositing digital images. </title> <journal> Computer Graphics (SIG--GRAPH'84), </journal> <volume> 18(3) </volume> <pages> 253-259, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Practitioners in these fields quickly discovered that it is insufficient to merely label pixels as foreground and background: it is necessary to simultaneously recover both the true color of each pixel and its transparency or opacity <ref> [PD84, Bli94a] </ref>. 1 In this paper, we develop a new, multiframe stereo algorithm which simultaneously re-covers depth, color, and transparency estimates at each pixel. Unlike traditional blue-screen matting, we cannot use a known background color to perform the color and matte recovery. <p> However, such techniques require the strict enforcement of ordering constraints [YP84]. In this pa 3 per, we handle occlusion by re-projecting the disparity space into each input image using traditional back-to-front compositing operations <ref> [PD84] </ref>, and eliminating from consideration pixels which are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back [SD97].) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching <p> None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. Our stereo algorithm has also been inspired by work in computer graphics, especially in image compositing <ref> [PD84, Bli94a] </ref> and blue screen techniques [VT93, SB96]. <p> In our experiments, the threshold is set to = min + s Var 3fi3 , with min = 10 and s = 0:02. 7 We may, for computational reasons, choose to represent this volume using colors premultiplied by their opacities (associated colors <ref> [PD84, Bli94a] </ref>), in which case voxels for which alpha (opacity) is 0 should have their color or intensity values set to 0. <p> Once the layers have been resampled, they are then composited using the standard over operator <ref> [PD84] </ref>, f ^ b f + (1 ff f )b; where f and b are the premultiplied foreground and background colors, and ff f is the opacity of the foreground [PD84, Bli94a]. <p> Once the layers have been resampled, they are then composited using the standard over operator [PD84], f ^ b f + (1 ff f )b; where f and b are the premultiplied foreground and background colors, and ff f is the opacity of the foreground <ref> [PD84, Bli94a] </ref>. Using the over operator, we can form a composite image ~ c k (u; v) = d=d max (note that the over operator is associative but not commutative, and that d max is the layer closest to the camera).
Reference: [PFTV92] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <note> second edition, </note> <year> 1992. </year>
Reference: [PMF85] <author> S. B. Pollard, J. E. W. Mayhew, and J. P. Frisby. PMF: </author> <title> A stereo correspondence algorithm using a disparity gradient limit. </title> <journal> Perception, </journal> <volume> 14 </volume> <pages> 449-470, </pages> <year> 1985. </year>
Reference-contexts: Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes [Arn83, KO94]. Three-dimensional support functions include limited disparity gradient <ref> [PMF85] </ref>, Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes [SH85]), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation [SS96]. In this paper, our initial evidence aggregation uses an iterative technique, with estimates being refined later through a prediction/adjustment mechanism which explicitly models occlusions.
Reference: [Pra85] <author> K. Prazdny. </author> <title> Detection of binocular disparities. </title> <journal> Biological Cybernetics, </journal> <volume> 52 </volume> <pages> 93-99, </pages> <year> 1985. </year>
Reference-contexts: Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes [Arn83, KO94]. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle <ref> [Pra85] </ref> (which can be implemented using two diffusion processes [SH85]), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation [SS96]. In this paper, our initial evidence aggregation uses an iterative technique, with estimates being refined later through a prediction/adjustment mechanism which explicitly models occlusions. <p> Finally, the topic of transparent surfaces has not received much study in the context of computational stereo <ref> [Pra85, SH85, Wei89] </ref>. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91]. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. <p> For example, we plan to try our algorithm on data sets with true transparency (not just mixed pixels), such as traditional transparent random dot stereograms <ref> [Pra85, Wei89] </ref> and reflections in windows [BBHP92]. Estimating disparities to sub-integer precision should improve the quality of our reconstructions. Such fractional disparity estimates can be obtained by interpolating a variance vs. disparity curve (d), e.g., by fitting a parabola to the lowest variance and its two neighbors [TH86, MSK89].
Reference: [PW94] <author> Y. Paker and S. Wilbur, </author> <title> editors. Image Processing for Broadcast and Video Production, </title> <booktitle> Hamburg, 1994, Workshops in Computing, Hamburg, 1994. Springer. Proceedings of the European Workshop on Combined Real and Synthetic Image Processing for Broadcast and Video Production, </booktitle> <address> Hamburg, </address> <month> 23-24 November, </month> <year> 1994. </year>
Reference-contexts: Different techniques have been developed for computing sub-pixel estimates, such as using a finer set of disparity hypotheses or finding the the analytic minimum of the local error surface [TH86, MSK89]. Unfortunately, for challenging applications such as z-keying (the insertion of graphics between different depth layers in video) <ref> [PW94, K + 96, B + 96] </ref>, even this is not good enough. Pixels lying near or on occlusion boundaries will typically be mixed, i.e., they will contain blends of both foreground and background colors.
Reference: [RGH80] <author> T. W. Ryan, R. T. Gray, and B. R. Hunt. </author> <title> Prediction of correlation errors in stereo-pair images. </title> <journal> Optical Engineering, </journal> <volume> 19(3) </volume> <pages> 312-322, </pages> <month> May/June </month> <year> 1980. </year>
Reference-contexts: Matching costs can be defined locally (at the pixel level), e.g., as absolute [K + 96] or squared intensity differences [MSK89], using edges [Bak80] or filtered images [JJT91, JM92]. Alternatively, matching costs may be defined over an area, e.g., using correlation <ref> [RGH80] </ref> (this can be viewed as a combination of the matching and aggregation stages). In this paper, we use squared intensity differences. Aggregating support is necessary to disambiguate potential matches.
Reference: [SA96] <author> H. S. Sawhney and S. Ayer. </author> <title> Compact representation of videos through dominant multiple motion estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(8) </volume> <pages> 814-830, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [SB96] <author> A. R. Smith and J. F. </author> <title> Blinn. Blue screen matting. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 259-268, </pages> <booktitle> Proc. </booktitle> <address> SIGGRAPH'96 (New Orleans), </address> <month> August </month> <year> 1996. </year> <note> ACM SIGGRAPH. </note>
Reference-contexts: When such pixels are composited with other images or graphical elements, objectionable "halos" or "color bleeding" may be visible. The computer graphics and special effects industries faced a similar problem when extracting foreground objects using blue screen techniques <ref> [SB96] </ref>. A variety of techniques were developed for this matting problem, all of which model mixed pixels as combinations of foreground and background colors (the latter of which is usually assumed to be known). <p> None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. Our stereo algorithm has also been inspired by work in computer graphics, especially in image compositing [PD84, Bli94a] and blue screen techniques <ref> [VT93, SB96] </ref>.
Reference: [SD97] <author> S. M. Seitz and C. M. Dyer. </author> <title> Photorealistic scene reconstrcution by space coloring. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'97), </booktitle> <address> San Juan, Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: In this pa 3 per, we handle occlusion by re-projecting the disparity space into each input image using traditional back-to-front compositing operations [PD84], and eliminating from consideration pixels which are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back <ref> [SD97] </ref>.) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching costs at the discrete disparity levels [LK81, TH86, MSK89, KO94]. <p> For instance, if we wish to regularly sample a volume of 3-D space, we can make the camera orthographic, with the camera's (x; y; d) axes being orthogonal and evenly sampled (as in <ref> [SD97] </ref>). As another example, we may wish to use a skewed camera model for constructing a Lumigraph [GGSC96]. Having chosen a virtual camera position, we can also choose the orientation and spacing of the disparity planes, i.e., the constant d planes. <p> Other choices include the traditional cyclopean camera placed symmetrically between two verged cameras, or a uniform sampling of 3-D which is useful in a true verged multi-camera environment <ref> [SD97] </ref> or for motion stereo. Note that in all of these situations, integral steps in disparity may correspond to fractional shifts in displacement, which may be desirable for optimal accuracy.
Reference: [SH85] <author> R. Szeliski and G. Hinton. </author> <title> Solving random-dot stereograms using the heat equation. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'85), </booktitle> <pages> pages 284-288, </pages> <address> San Francisco, California, June 1985. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes [Arn83, KO94]. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes <ref> [SH85] </ref>), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation [SS96]. In this paper, our initial evidence aggregation uses an iterative technique, with estimates being refined later through a prediction/adjustment mechanism which explicitly models occlusions. <p> Finally, the topic of transparent surfaces has not received much study in the context of computational stereo <ref> [Pra85, SH85, Wei89] </ref>. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91]. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces.
Reference: [SK95] <author> R. Szeliski and S. B. Kang. </author> <title> Direct methods for visual scene reconstruction. </title> <booktitle> In IEEE Workshop on Representations of Visual Scenes, </booktitle> <pages> pages 26-33, </pages> <address> Cambridge, Mas-sachusetts, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: More recently, depth maps obtained from stereo have been painted with texture maps extracted from input images in order to create realistic 3-D scenes and environments for virtual reality and virtual studio applications <ref> [MB95, SK95, K + 96, B + 96] </ref>. Unfortunately, the quality and resolution of most stereo algorithms falls quite short of that demanded by these new applications, where even isolated errors in the depth map become readily visible when composited with synthetic graphical elements.
Reference: [SM91a] <author> M. Shizawa and K. Mase. </author> <title> Principle of superposition: A common computational frame 26 work for analysis of multiple motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 164-172, </pages> <address> Princeton, New Jersey, October 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation <ref> [BBHP92, SM91b, SM91a, JBJ96, DP91] </ref>. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. <p> We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [SM91b] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory of motion transparency and motion boundaries based on eigenenergy analysis. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'91), </booktitle> <pages> pages 289-295, </pages> <address> Maui, Hawaii, June 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo [Pra85, SH85, Wei89]. Relatively more work has been done in the context of transparent motion estimation <ref> [BBHP92, SM91b, SM91a, JBJ96, DP91] </ref>. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. <p> We plan to investigate the relationship of our new disparity space model to more traditional layered motion models <ref> [BBHP92, SM91b, SM91a, DP91, JBJ96, SA96] </ref>.
Reference: [SS96] <author> D. Scharstein and R. Szeliski. </author> <title> Stereo matching with non-linear diffusion. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'96), </booktitle> <pages> pages 343-350, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: One of the most common errors made by most stereo algorithms is a systematic "fattening" of depth layers near occlusion boundaries. Algorithms based on variable window sizes [KO94] or iterative evidence aggregation <ref> [SS96] </ref> can in many instances mitigate such errors. Another common problem is that disparities are only estimated to the nearest pixel, which is typically not sufficiently accurate for tasks such as view interpolation. <p> In thinking about stereo algorithms, we have found it useful to subdivide the stereo matching process into three tasks: the initial computation of matching costs, the aggregation of local evidence, and the selection or computation of a disparity value for each pixel <ref> [SS96] </ref>. The most fundamental element of any correspondence algorithm is a matching cost that 2 measures the similarity of two or more corresponding pixels in different images. <p> Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes [Arn83, KO94]. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes [SH85]), local winner-take-all [YYL93], and iterative (non-linear) evidence aggregation <ref> [SS96] </ref>. In this paper, our initial evidence aggregation uses an iterative technique, with estimates being refined later through a prediction/adjustment mechanism which explicitly models occlusions. The easiest way of choosing the best disparity is to select at each pixel the minimum aggregated cost across all disparities under consideration ("winner-take-all"). <p> Once we have a collection of color (or luminance) values at a given (x; y; d) cell, we can compute some initial statistics over the K (or fewer) colors, e.g., the sample mean and variance . 5 Robust estimates of sample mean and variance are also possible (e.g., <ref> [SS96] </ref>). Examples of the mean and variance values for our sample image are shown in Figures 1d and 1e, where darker values indicate smaller variances. <p> The most common form is averaging using square windows, which results in the traditional sum of squared difference (SSD and SSSD) algorithms [OK93]. To obtain results with better quality near discontinuities, it is preferable to use adaptive windows [KO94] or iterative evidence accumulation <ref> [SS96] </ref>. In the latter case, we may wish to accumulate an evidence measure which is not simply summed error (e.g., the probability of a correct match [SS96]). Continuing our simple example, Figure 1f shows the results of an evidence accumulation stage, where more certain depths are darker. <p> To obtain results with better quality near discontinuities, it is preferable to use adaptive windows [KO94] or iterative evidence accumulation <ref> [SS96] </ref>. In the latter case, we may wish to accumulate an evidence measure which is not simply summed error (e.g., the probability of a correct match [SS96]). Continuing our simple example, Figure 1f shows the results of an evidence accumulation stage, where more certain depths are darker. To generate these results, we aggregate evidence using a variant of the algorithm described in [SS96], t+1 i + b j2N 4 (i) j + c 0 i = min <p> measure which is not simply summed error (e.g., the probability of a correct match <ref> [SS96] </ref>). Continuing our simple example, Figure 1f shows the results of an evidence accumulation stage, where more certain depths are darker. To generate these results, we aggregate evidence using a variant of the algorithm described in [SS96], t+1 i + b j2N 4 (i) j + c 0 i = min ( t where t i is the variance of pixel i at iteration t, ^ t i is a robustified (limited) version of the variance, and N 4 are the usual four nearest neighbors.
Reference: [TH86] <author> Q. Tian and M. N. Huhns. </author> <title> Algorithms for subpixel registration. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 35 </volume> <pages> 220-233, </pages> <year> 1986. </year>
Reference-contexts: Different techniques have been developed for computing sub-pixel estimates, such as using a finer set of disparity hypotheses or finding the the analytic minimum of the local error surface <ref> [TH86, MSK89] </ref>. Unfortunately, for challenging applications such as z-keying (the insertion of graphics between different depth layers in video) [PW94, K + 96, B + 96], even this is not good enough. <p> are known to be occluded. (A related technique, developed concurrently with ours, traverses the disparity space from front to back [SD97].) Sub-pixel (fractional) disparity estimates, which are essential for applications such as view interpolation, can be computed by fitting a curve to the matching costs at the discrete disparity levels <ref> [LK81, TH86, MSK89, KO94] </ref>. This provides an easy way to increase the resolution of a stereo algorithm with little additional computation. However, to work well, the intensities being matched must vary smoothly. In this paper, we present two different representations for fractional disparity estimates. <p> Estimating disparities to sub-integer precision should improve the quality of our reconstructions. Such fractional disparity estimates can be obtained by interpolating a variance vs. disparity curve (d), e.g., by fitting a parabola to the lowest variance and its two neighbors <ref> [TH86, MSK89] </ref>. Alternatively, we can linearly interpolate individual color errors c (x; y; d; k) (x; y; d) between disparity levels, and find the minimum of the summed squared error (which will be a quadratic function of the fractional disparity).
Reference: [VT93] <author> P. Vlahos and B. Taylor. </author> <title> Traveling matte composite photography. </title> <booktitle> In American Cinematographer Manual, </booktitle> <pages> pages 430-445. </pages> <publisher> American Society of Cinematographers, </publisher> <address> Holly-wood, 7 edition, </address> <year> 1993. </year>
Reference-contexts: None of these techniques explicitly recover a per-pixel transparency value along with a corrected color value, as we do in this paper. Our stereo algorithm has also been inspired by work in computer graphics, especially in image compositing [PD84, Bli94a] and blue screen techniques <ref> [VT93, SB96] </ref>.
Reference: [Wei89] <author> D. Weinshall. </author> <title> Perception of multiple transparent planes in stereo vision. </title> <journal> Nature, </journal> <volume> 341 </volume> <pages> 737-739, </pages> <month> 26 October </month> <year> 1989. </year>
Reference-contexts: Finally, the topic of transparent surfaces has not received much study in the context of computational stereo <ref> [Pra85, SH85, Wei89] </ref>. Relatively more work has been done in the context of transparent motion estimation [BBHP92, SM91b, SM91a, JBJ96, DP91]. However, these techniques are limited to extracting a small number of dominant motions or planar surfaces. <p> For example, we plan to try our algorithm on data sets with true transparency (not just mixed pixels), such as traditional transparent random dot stereograms <ref> [Pra85, Wei89] </ref> and reflections in windows [BBHP92]. Estimating disparities to sub-integer precision should improve the quality of our reconstructions. Such fractional disparity estimates can be obtained by interpolating a variance vs. disparity curve (d), e.g., by fitting a parabola to the lowest variance and its two neighbors [TH86, MSK89].
Reference: [YP84] <author> A. L. Yuille and T. Poggio. </author> <title> A generalized ordering constraint for stereo correspondence. A. I. </title> <type> Memo 777, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1984. </year>
Reference-contexts: Several authors have addressed occlusions explicitly, using Bayesian models and dynamic programming [Arn83, OK85, BM92, Cox94, GLY92, IB94]. However, such techniques require the strict enforcement of ordering constraints <ref> [YP84] </ref>.
Reference: [YYL93] <author> Y. Yang, A. Yuille, and J. Lu. </author> <title> Local, global, and multilevel stereo matching. </title> <booktitle> In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'93), </booktitle> <pages> pages 274-279, </pages> <address> New York, New York, June 1993. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Two-dimensional evidence aggregation has been done using both fixed square windows (traditional) and windows with adaptive sizes [Arn83, KO94]. Three-dimensional support functions include limited disparity gradient [PMF85], Prazdny's coherence principle [Pra85] (which can be implemented using two diffusion processes [SH85]), local winner-take-all <ref> [YYL93] </ref>, and iterative (non-linear) evidence aggregation [SS96]. In this paper, our initial evidence aggregation uses an iterative technique, with estimates being refined later through a prediction/adjustment mechanism which explicitly models occlusions.
References-found: 54

