URL: http://www.neci.nj.nec.com/homepages/sebastien/papers/icpr96/final.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/sebastien/papers/
Root-URL: 
Email: E-mail: sebastienjingemar@research.nj.nec.com  
Title: Motion without Structure with both outdoor scenes and an indoor calibrated sequence achieve very good
Author: Sebastien Roy and Ingemar J. Cox 
Address: 4 Independence Way Princeton, NJ 08540, U.S.A.  C.P. 6128, Succ. Centre-Ville, Montreal, Quebec, H3C 3J7  
Affiliation: NEC Research Institute  Universite de Montreal, Departement d'informatique et de recherche operationnelle,  
Note: c 1996 IEEE. Proc. of Int. Conf. on Pattern Recognition, Vienna, August 1996, Vol. 1, p. 728-734. 1  Experiments  Visiting from  
Abstract: We propose a new paradigm, motion without structure, for determining the ego-motion between two frames. It is best suited for cases where reliable feature point correspondence is difficult, or for cases where the expected camera motion is large. The problem is posed as a five-dimensional search over the space of possible motions during which the structural information present in the two views is neither implicitly or explicitly used or estimated. To accomplish this search, a cost function is devised that measures the relative likelihood of each hypothesized motion. This cost function is invariant to the structure present in the scene. An analysis of the global scene statistics present in an image, together with the geometry of epipolar misalignment, suggests a measure based on the sum of squared differences between pixels in the first image and their corresponding epipolar line segments in the second image. The measure relies on a simple statistical characteristic of neighboring image intensity levels. Specifically, that the variance of intensity differences between two arbitrary points in an image is a monotonically increasing symmetrical function of the distance between the two points. This assumption is almost always true, though the size of the neighborhood over which the monotonic dependency holds varies from image to image. This range determines the maximum permissible motion between two frames, which can be quite large. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aloimonos and Z. Duric. </author> <title> Estimating the heading direction using normal flow. </title> <journal> Int. J. Computer Vision, </journal> <volume> 13(1) </volume> <pages> 33-56, </pages> <year> 1994. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene.
Reference: [2] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <journal> Int. J. Computer Vision, </journal> <volume> 2(1) </volume> <pages> 43-77, </pages> <year> 1994. </year>
Reference-contexts: In almost all cases, either optical flow or feature point correspondences are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see <ref> [2, 8, 10, 15] </ref>). Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. <p> Then we can assume that each sample behaves like a random variable u i with distribution f (u i ) = G [I A (~p); 2 ( ~ d u i )] (u i ) where G <ref> [; 2 ] </ref> is an arbitrary probability distribution and ~ d u i is the distance (x; y) from sample u i to position ~p z , the unknown location of the corresponding point to I A (~p).
Reference: [3] <author> I. J. Cox. </author> <title> A review of statistical data association techniques for motion correspondence. </title> <journal> Int. J. Computer Vision, </journal> <volume> 10(1) </volume> <pages> 53-66, </pages> <year> 1993. </year>
Reference-contexts: Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [3, 11, 16, 17] </ref>. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
Reference: [4] <author> I. J. Cox and S. Roy. </author> <title> Direct estimation of rotation from two frames via epipolar search. </title> <booktitle> In 6th Int. conf. on Computer Analysis of Images and Patterns, </booktitle> <year> 1995. </year>
Reference-contexts: The experimental results support this. The algorithm relies on statistically modeling the image behavior in the neighborhood of a point, as discussed in Section 2.1. This model is then used to estimate the likelihood of an assumed camera motion. In <ref> [4] </ref>, we proposed using the difference between histograms computed along assumed correspondence epipolar lines as a likelihood function. This statistical measure is very effective in determining the rotational component of ego-motion, but is not always a reliable measure of the likelihood of a translational mo-tion.
Reference: [5] <author> I. J. Cox and S. Roy. </author> <title> Statistical modelling of epipolar misalignment. </title> <booktitle> In International Workshop on Stereoscopic and Three-Dimensional Imaging, </booktitle> <year> 1995. </year>
Reference-contexts: This statistical measure is very effective in determining the rotational component of ego-motion, but is not always a reliable measure of the likelihood of a translational mo-tion. Consequently, we proposed in <ref> [5] </ref> a likelihood measure based on the sum of sums of squared differences between pixels in one image and their hypothesized corresponding line segments in the other image that is a reliable estimate of either the rotational or translational components of motion. This measure is detailed in Section 2.2. <p> In previous work <ref> [5] </ref>, the sub-problems of finding rotation or translation when the other component of motion is known was shown to be solvable by locating the single global minimum. This paper extends these results and considers the full motion case when both rotation and translation must be simultaneously estimated.
Reference: [6] <author> C. Fermuller. </author> <title> Global 3-d motion estimation. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 415-421, </pages> <year> 1993. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene.
Reference: [7] <author> B. K. P. Horn and E. J. Weldon, Jr. </author> <title> Direct methods for recovering motion. </title> <journal> Int. J. Computer Vision, </journal> <volume> 2 </volume> <pages> 51-76, </pages> <year> 1988. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene.
Reference: [8] <author> K. Horn and B. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: In almost all cases, either optical flow or feature point correspondences are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see <ref> [2, 8, 10, 15] </ref>). Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17].
Reference: [9] <author> R. Hummel and V. Sundareswaran. </author> <title> Motion parameter estimation from global flow field data. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(5) </volume> <pages> 459-476, </pages> <year> 1993. </year>
Reference-contexts: The true rotation is 0 ffi . The translation obtained is (0:994; 0:102; 0:035), which correspond to a 6 ffi error. While at first sight this appears large, we note that this is well within the accuracy of other two-frame algorithms <ref> [9, 15] </ref> and that, within the image, this error correspond to a maximum displacement of 0.3 pixel. The expected translation is (1; 0; 0).
Reference: [10] <author> A. D. Jepson and D. J. Heeger. </author> <title> A fast subspace algorithm for recovering rigid motion. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 124-131, </pages> <address> Prince-ton, NJ, </address> <year> 1991. </year>
Reference-contexts: In almost all cases, either optical flow or feature point correspondences are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see <ref> [2, 8, 10, 15] </ref>). Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17].
Reference: [11] <author> R. Kumar and A. R. Hanson. </author> <title> Robust estimation of camera location and orientation from noisy data having outliers. </title> <booktitle> In Proc. Workshop on Interpretation of 3D Scenes, </booktitle> <pages> pages 52-60, </pages> <address> Austin, TX, USA, </address> <year> 1989. </year>
Reference-contexts: Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [3, 11, 16, 17] </ref>. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
Reference: [12] <author> S. Negahdaripour and B. K. P. Horn. </author> <title> Direct passive navigation. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1) </volume> <pages> 168-176, </pages> <year> 1987. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene.
Reference: [13] <author> J. Oliensis. </author> <title> Rigorous bounds for two-frame structure from motion. </title> <type> Technical Report 95-155, </type> <institution> NEC Research Institute, Princeton, NJ, </institution> <year> 1993. </year>
Reference-contexts: This paper extends these results and considers the full motion case when both rotation and translation must be simultaneously estimated. The effect of motion ambiguity (see in <ref> [13] </ref>) on the accuracy of motion estimation is also discussed. Section 3 presents experimental results from a comprehensive evaluation based on real images of stereoscopic pairs and an indoor calibrated motion sequence. 2.
Reference: [14] <author> D. Sinclair, A. Blake, and D. Murray. </author> <title> Robust estimation of egomotion from normal flow. </title> <journal> Int. J. Computer Vision, </journal> <volume> 13(1) </volume> <pages> 57-69, </pages> <year> 1994. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene.
Reference: [15] <author> V. Sundareswaran. </author> <title> Egomotion from global flow field data. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 140-145, </pages> <address> Princeton, NJ, </address> <year> 1991. </year>
Reference-contexts: In almost all cases, either optical flow or feature point correspondences are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see <ref> [2, 8, 10, 15] </ref>). Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. <p> In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. <p> The true rotation is 0 ffi . The translation obtained is (0:994; 0:102; 0:035), which correspond to a 6 ffi error. While at first sight this appears large, we note that this is well within the accuracy of other two-frame algorithms <ref> [9, 15] </ref> and that, within the image, this error correspond to a maximum displacement of 0.3 pixel. The expected translation is (1; 0; 0).
Reference: [16] <author> C. Tomasi. </author> <title> Pictures and trails: a new framework for the computation of shape and motion from perspective image sequences. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 913-918, </pages> <year> 1994. </year>
Reference-contexts: Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [3, 11, 16, 17] </ref>. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
Reference: [17] <author> C. Tomasi and J. Shi. </author> <title> Direction of heading from image deformations. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 422-427, </pages> <year> 1993. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggest that errors can never be lowered to a negligible level (see [2, 8, 10, 15]). Even methods using the intensity derivatives directly or normal flow (see <ref> [1, 6, 7, 12, 14, 15, 17] </ref>), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [3, 11, 16, 17]. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. <p> Even methods using the intensity derivatives directly or normal flow (see [1, 6, 7, 12, 14, 15, 17]), suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [3, 11, 16, 17] </ref>. All prior methods of ego-motion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
References-found: 17

