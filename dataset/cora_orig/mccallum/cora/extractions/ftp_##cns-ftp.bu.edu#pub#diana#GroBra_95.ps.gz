URL: ftp://cns-ftp.bu.edu/pub/diana/GroBra:95.ps.gz
Refering-URL: http://www.inns.org/Misc-info/Online-pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: VIEWNET ARCHITECTURES FOR INVARIANT 3-D OBJECT LEARNING AND RECOGNITION FROM MULTIPLE 2-D VIEWS  
Author: Stephen Grossberg and Gary Bradski 
Address: 2 First Union Bank, NC-0600 and One First Union Center, TW8  Charlotte, NC 28288-0601  Boston, MA 02215 3  
Affiliation: 1 Department of Cognitive and Neural Systems  Center for Adaptive Systems  Boston University  
Abstract: 3 The recognition of 3-D objects from sequences of their 2-D views is modeled by a family of self-organizing neural architectures, called VIEWNET, that use View Information Encoded With NETworks. VIEWNET incorporates a preprocessor that generates a compressed but 2-D invariant representation of an image, a supervised incremental learning system (Fuzzy ARTMAP) that classifies the preprocessed representations into 2-D view categories whose outputs are combined into 3-D invariant object categories, and a working memory that makes a 3-D object prediction by accumulating evidence over time from 3-D object category nodes as multiple 2-D views are experienced. VIEWNET was benchmarked on an MIT Lincoln Laboratory database of 128x128 2-D views of aircraft, including small frontal views, with and without additive noise. A recognition rate of up to 90% is achieved with one 2-D view and of up to 98.5% correct with three 2-D views. The properties of 2-D view and 3-D object category nodes are compared with those of cells in monkey inferotemporal cortex. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bradski, G., & Grossberg, S. </author> <year> (1995). </year> <title> Fast learning VIEWNET architectures for recognizing 3-D objects from multiple 2-D views. Neural Networks,, in press. Special issue on automatic target recognition. </title>
Reference: <author> Carpenter, G., & Grossberg, S. </author> <year> (1987). </year> <title> ART 2: Self-organization of stable category recognition codes for analog input patterns. </title> <journal> Applied Optics, </journal> <volume> 26, </volume> <pages> 4919-4930. </pages>
Reference-contexts: In order to compress this invariant spectrum and reduce 3-D foreshortening effects, the result was coarse coded (compressed to 5x5 pixels from 128x128) using Gaussian filters. The coarse coded vectors (25 data points) were fed into an ART 2 <ref> (Carpenter and Gross-berg, 1987) </ref> network for unsupervised learning and categorization.
Reference: <author> Carpenter, G., & Grossberg, S. (Eds.). </author> <year> (1991). </year> <title> Pattern recognition by self-organizing neural networks. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: We utilized the simplified version of the Fuzzy ARTMAP network of Carpenter, Gross-berg, Markuzon, Reynolds, and Rosen, (1992) that was employed in Carpenter, Grossberg, and Iizuka (1992). This circuit consists of a Fuzzy ART module <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref> ART a that learns 2-D view categories and a field of 3-D object category output nodes F b . The 2-D view and 3-D object category nodes are linked together by an associative memory F ab that is called the Map Field (Figure 11). <p> Complement coding also normalizes the total input A p to ART a such that k A p k 1 = 1. It thereby prevents a category proliferation problem that could otherwise occur <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref>. Complement coding means intuitively that an input vector turns ON the cells corresponding to a p as it turns OFF the cells corresponding to a c p , much as in the ON and OFF channels of the CORT-X 2 filter.
Reference: <author> Carpenter, G., & Grossberg, S. </author> <year> (1993). </year> <title> Normal and amnesic learning, recognition, and memory by a neural model of cortico-hippocampal interactions. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 16, </volume> <pages> 131-137. </pages>
Reference: <author> Carpenter, G., & Grossberg, S. </author> <year> (1994). </year> <title> Integrating symbolic and neural processing in a self-organzing architecture for pattern recognition and prediction. </title> <editor> In Honavar, H., & Uhr, L. (Eds.), </editor> <booktitle> Artificial intelligence and neural networks: Steps towards principled predictions, </booktitle> <pages> pp. 387-421. </pages> <address> San Diego: </address> <publisher> Academic Press. </publisher>
Reference: <author> Carpenter, G., Grossberg, S., & Iizuka, K. </author> <year> (1992a). </year> <title> Comparative performance measures of fuzzy artmap, learned vector quantization, and back propagation for handwritten character recognition. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> Vol. I, </volume> <pages> pp. 794-799. </pages> <address> Piscataway, NJ: </address> <publisher> IEEE Service Center. </publisher>
Reference: <author> Carpenter, G., Grossberg, S., Markuzon, N., Reynolds, J., & Rosen, D. </author> <year> (1992b). </year> <title> Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3, </volume> <pages> 698-713. </pages>
Reference: <author> Carpenter, G., Grossberg, S., & Mehanian, C. </author> <year> (1989). </year> <title> Invariant recognition of cluttered scenes by a self-organizing ART architecture: CORT-X boundary segmentation. </title> <booktitle> Neural Networks, </booktitle> <volume> 2, </volume> <pages> 169-181. </pages>
Reference-contexts: This is a feedforward network that detects, regularizes, and completes image boundaries from edge, texture and shading contrasts, while suppressing noise that does not have an underlying anisotropic structure. The CORT-X 2 filter is an enhancement of the original CORT-X filter <ref> (Carpenter, Grossberg, and Mehanian, 1989) </ref>. It generates better boundary segmentations, deals better with noise, and may also be used for figure-ground separation. The figure-ground separation properties were not needed in this research because the data images were already separated from their backgrounds.
Reference: <author> Carpenter, G., Grossberg, S., & Reynolds, J. </author> <year> (1995). </year> <title> Fuzzy ARTMAP, slow learning and probability estimation. </title> <journal> IEEE Transactions on Neural Networks, </journal> <note> in press. </note> <institution> Boston, MA: Boston University Technical Report CAS/CNS-TR-93-014. </institution>
Reference: <author> Carpenter, G., Grossberg, S., & Rosen, D. </author> <year> (1991). </year> <title> Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system. </title> <booktitle> Neural Networks, </booktitle> <volume> 4, </volume> <pages> 493-504. </pages>
Reference-contexts: We utilized the simplified version of the Fuzzy ARTMAP network of Carpenter, Gross-berg, Markuzon, Reynolds, and Rosen, (1992) that was employed in Carpenter, Grossberg, and Iizuka (1992). This circuit consists of a Fuzzy ART module <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref> ART a that learns 2-D view categories and a field of 3-D object category output nodes F b . The 2-D view and 3-D object category nodes are linked together by an associative memory F ab that is called the Map Field (Figure 11). <p> Complement coding also normalizes the total input A p to ART a such that k A p k 1 = 1. It thereby prevents a category proliferation problem that could otherwise occur <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref>. Complement coding means intuitively that an input vector turns ON the cells corresponding to a p as it turns OFF the cells corresponding to a c p , much as in the ON and OFF channels of the CORT-X 2 filter.
Reference: <author> Grossberg, S. </author> <year> (1987a). </year> <title> The adaptive brain, Volumes 1 and 2. </title> <address> Amsterdam: Elsevier/North-Holland. </address>
Reference: <author> Grossberg, S. </author> <year> (1987b). </year> <title> Cortical dynamics of three-dimensional form, color, and brightness perception. I: </title> <journal> Monocular theory. Perception and Psychophysics, </journal> <volume> 41, </volume> <pages> 87-116. </pages>
Reference-contexts: In the VIEWNET architecture, simplified algorithms from theories that are working to develop general-purpose vision architectures, such as FACADE theory <ref> (Grossberg, 1987b, 1988, 1994) </ref>, and recognition architectures, such as Adaptive Resonance Theory (Carpenter and Grossberg, 1991, 1993, 1994; Grossberg, 1987a, 1988, 1995), illustrate this theme.
Reference: <author> Grossberg, S. (Ed.). </author> <year> (1988). </year> <booktitle> Neural networks and natural intelligence. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Grossberg, S. </author> <year> (1994). </year> <title> 3-D vision and figure-ground separation by visual cortex. </title> <journal> Perception and Psychophysics, </journal> <volume> 55, </volume> <pages> 48-120. </pages>
Reference: <author> Grossberg, S. </author> <year> (1995). </year> <title> Are there universal principles of brain computation?. American Scientist, in press. </title> <type> Tech Report: </type> <address> Boston, MA: Boston University CAS/CNS-TR-95-012. </address>
Reference: <author> Grossberg, S., & Mingolla, E. </author> <year> (1985). </year> <title> Neural dynamics of perceptual grouping: Boundary completion, illusory figures, and neon color spreading. </title> <journal> Psychological Review, </journal> <volume> 92, </volume> <pages> 173-211. </pages>
Reference: <author> Grossberg, S., Mingolla, E., & Todorovic, D. </author> <year> (1989). </year> <title> A neural network architecture for preattentive vision. </title> <journal> IEEE Transactions on Biomedical Engineering, </journal> <volume> 36, </volume> <pages> 79-102. </pages>
Reference-contexts: This is a feedforward network that detects, regularizes, and completes image boundaries from edge, texture and shading contrasts, while suppressing noise that does not have an underlying anisotropic structure. The CORT-X 2 filter is an enhancement of the original CORT-X filter <ref> (Carpenter, Grossberg, and Mehanian, 1989) </ref>. It generates better boundary segmentations, deals better with noise, and may also be used for figure-ground separation. The figure-ground separation properties were not needed in this research because the data images were already separated from their backgrounds.
Reference: <author> Grossberg, S., Mingolla, E., & Williamson, J. </author> <year> (1995). </year> <title> Synthetic aperture radar processing by a multiple scale neural system for boundary and surface representation. Neural Networks, Special Issue on Automatic Target Recognition, </title> <note> in press. Boston University Technical Report CAS/CNS-TR-94-001. </note>
Reference: <author> Grossberg, S., & Todorovic, D. </author> <year> (1988). </year> <title> Neural dynamics of 1-D and 2-D brightness perception: A unified model of classical and recent phenomena. </title> <journal> Perception and Psychophysics, </journal> <volume> 43, </volume> <pages> 241-277. </pages>
Reference: <author> Grossberg, S., & Wyse, L. </author> <year> (1991). </year> <title> A neural network architecture for figure-ground separation of connected scenic figures. </title> <booktitle> Neural Networks, </booktitle> <volume> 4, </volume> <pages> 723-742. </pages>
Reference-contexts: We utilized the simplified version of the Fuzzy ARTMAP network of Carpenter, Gross-berg, Markuzon, Reynolds, and Rosen, (1992) that was employed in Carpenter, Grossberg, and Iizuka (1992). This circuit consists of a Fuzzy ART module <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref> ART a that learns 2-D view categories and a field of 3-D object category output nodes F b . The 2-D view and 3-D object category nodes are linked together by an associative memory F ab that is called the Map Field (Figure 11). <p> Complement coding also normalizes the total input A p to ART a such that k A p k 1 = 1. It thereby prevents a category proliferation problem that could otherwise occur <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref>. Complement coding means intuitively that an input vector turns ON the cells corresponding to a p as it turns OFF the cells corresponding to a c p , much as in the ON and OFF channels of the CORT-X 2 filter.
Reference: <author> Grossberg, S., & Wyse, L. </author> <year> (1992). </year> <title> A neural network architecture for figure-ground separation of connected scenic figures. </title> <editor> In Pinter, R., & Nabet, B. (Eds.), </editor> <title> Nonlinear vision: Determination of neural receptive fields, </title> <booktitle> function , and networks, </booktitle> <pages> pp. 516-543. </pages> <address> Boca Ra-ton, FL: </address> <publisher> CRC Press, Inc. </publisher>
Reference-contexts: The latter generated somewhat better results for reasons summarized below. The output of this preprocessor is a coarse-coded, invariant spectrum of an illumination compensated, noise-suppressed boundary segmentation. This representation provides the input vectors to the self-organizing neural network classifier. Fuzzy ARTMAP <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref> was used to categorize the output spectra. This architecture is capable of fast, stable learning of recognition categories in response to nonstationary multidimensional data, and of learning to generate many-to-one output predictions from the recognition categories to output labels.
Reference: <author> Logothetis, N., Pauls, J., Buelthoff, H., & Poggio, T. </author> <year> (1994). </year> <title> View-dependent object recognition by monkeys. </title> <booktitle> Current Biology, </booktitle> <volume> 4, </volume> <pages> 401. </pages>
Reference-contexts: A similar type of of an HK-1. hierarchical organization from 2-D view to 3-D object has been reported in neurophysiological studies of cell responses in monkey inferotemporal cortex, where some cells respond to individual 2-D views whereas others, like 3-D object nodes, respond to a wide range of views <ref> (Logothetis et al., 1994) </ref>. These studies were motivated by the regularization networks of Poggio and Girosi (1990) which also add up responses from 2-D views at 3-D object nodes.
Reference: <author> Poggio, T., & Girosi, F. </author> <year> (1990). </year> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247, </volume> <pages> 978-982. </pages>
Reference: <author> Schwartz, E. </author> <year> (1977). </year> <title> Spatial mapping in primate sensory projection: Analytic structure and relevance to perception. </title> <journal> Biological Cybernetics, </journal> <volume> 25, </volume> <pages> 181-194. </pages>
Reference-contexts: A log-polar transform is then taken with respect to the center of the image. Each point (x; y) is represented as re i . Taking the logarithm yields coordinates of log radial magnitude and angle. As is well known <ref> (Schwartz, 1977) </ref>, figural sizes and rotations are converted into figural (a) (b) added to every pixel in the original image. The original image (left column) had pixels with activity levels between 0.0 and 1.0.
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1990a). </year> <title> Learning aspect graph representations of 3-D objects in a neural network. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks (IJCNN-90), Washington, D.C., </booktitle> <volume> Vol. 2, </volume> <pages> pp. 233-236. </pages>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1990b). </year> <title> Learning aspect graph representations from view sequences. </title> <editor> In Touretzky, D. (Ed.), </editor> <booktitle> Advances in neural information processing systems 2, </booktitle> <pages> pp. 258-265. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishing. </publisher>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1991). </year> <title> Learning and recognizing 3-D objects from multiple views in a neural system. </title> <editor> In Wechsler, H. (Ed.), </editor> <title> Neural networks for perception. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1992). </year> <title> Adaptive 3-D-object recognition from multiple views. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11, </volume> <pages> 107-124. </pages>
Reference: <author> Zadeh, L. </author> <year> (1965). </year> <title> Fuzzy sets. </title> <journal> Information Control, </journal> <volume> 8, </volume> <pages> 338-353. xxxiii </pages>
Reference-contexts: jw a ; (32) where w a j is the template belonging to the j th F a 2 node, and the operator ^ is defined as the fuzzy AND operation. (p ^ q) k min (p k ; q k ) (33) for M -dimensional vectors p and q <ref> (Zadeh, 1965) </ref>. If more than one T a j is maximal, the cat egory j with the smallest index is chosen.
References-found: 29

