URL: http://www.isi.edu/teamcore/tambe/papers/96/AT/SS96.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Email: ftambe,johnson,sheng@isi.edu  
Title: Adaptive Agent Tracking in Real-world Multi-Agent Domains: A Preliminary Report  
Author: Milind Tambe, Lewis Johnson and Wei-Min Shen 
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: In multi-agent environments, the task of agent tracking (i.e., tracking other agents' mental states) increases in difficulty when a tracker (tracking agent) only has an imperfect model of the trackee (tracked agent). Such model imperfections arise in many real-world situations, where a tracker faces resource constraints and imperfect information, and the trackees themselves modify their behaviors dynamically. While such model imperfections are unavoidable, a tracker must nonetheless attempt to be adaptive in its agent tracking. In this paper, we analyze some key issues in adaptive agent tracking, and describe an initial approach based on discrimination-based learning. The main idea is to identify the deficiency of a model based on prediction failures, and revise the model by using features that are critical in discriminating successful and failed episodes. Our preliminary experiments in simulated air-to-air combat environments have shown some promising results but many problems remain open for future research. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. R.; Boyle, C. F.; Corbett, A. T.; and Lewis, M. W. </author> <year> 1990. </year> <title> Cognitive modeling and intelligent tutoring. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 7-49. </pages>
Reference-contexts: In the arena of education, intelligent tutors, whether in the form of "standard" intelligent tutoring systems <ref> (Anderson et al. 1990) </ref> or as participants in virtual environments (e.g., a virtual guide in a historical simulation (Pimentel & Teixeira 1994)), must interact with students in real-time. <p> It is appropriate in domains where agents exhibit dynamic behaviors in response to the changing environment and the actions of other agents. This paper focuses on adaptive agent tracking, an important requirement to scale up tracking to real-world domains. In particular, agent tracking is typically based on model tracing <ref> (Anderson et al. 1990) </ref>, where a tracker (tracking agent) executes a runnable model of the trackee (tracked agent), matching the model's predictions with actual observations. However, in real-world domains, a tracker's model of the trackee's behaviors is often imperfect, i.e., incomplete or incorrect.
Reference: <author> Bates, J.; Loyall, A. B.; and Reilly, W. S. </author> <year> 1992. </year> <title> Integrating reactivity, goals and emotions in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference: <author> Cremer, J.; Kearney, J.; Papelis, Y.; and Romano, R. </author> <year> 1994. </year> <title> The software architecture for scenario control in the Iowa driving simulator. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle>
Reference-contexts: Many of these multi-agent domains are dynamic and real-time, requiring the interaction to be flexible and reactive. For instance, in the arena of training, there is a recent thrust on dynamic, real-time interactive simulations | e.g., realistic traffic environments <ref> (Cremer et al. 1994) </ref>, or realistic combat environments (Tambe et al. 1995) | where intelligent agents may interact with tens or hundreds of collaborative and non-collaborative participants (agents and humans).
Reference: <author> Gil, Y. </author> <year> 1993. </year> <title> Efficient domain-independent experimentation. Technical Report ISI/RR-93-337, </title> <booktitle> USC / Information Sciences Institute. Appears in the Pro ceedings of the Tenth International Conference on Machine Learning. </booktitle>
Reference-contexts: Under these circumstances, techniques akin to incremental enlargement (Shen 1993) or learning via experimentation <ref> (Gil 1993) </ref> can be employed to determine which features to discriminate. Incremental enlargement is a heuristic applicable to finding relevant features that are crucial in discriminating two environmental states that contain a large number of differences.
Reference: <author> Hayes-Roth, B.; Brownston, L.; and Gen, R. V. </author> <year> 1995. </year> <title> Multiagent collaobration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95). </booktitle>
Reference: <author> Johnson, W. </author> <year> 1994. </year> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 1257-1263. </pages> <address> Seattle, WA: </address> <publisher> AAAI. </publisher>
Reference-contexts: The discrimination-based approach is used to locate deficiencies in tracker's model of the trackee. This approach is augmented using discovery learning techniques for explaining successful and unsuccessful agent tracking experiences <ref> (Johnson 1994) </ref>, to further specialize the analysis of such deficiencies. The main idea of discrimination-based learning is the framework of predict-surprise-revise. <p> This analysis is performed by the Debrief explanation system. As described in <ref> (Johnson 1994) </ref>, when a user requests Debrief to explain a decision, it analyzes the situational factors leading to the decision, and builds chunks that recognize those factors in future decisions. <p> First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment (Tambe et al. 1995). To this end, two versions of the pilot agents | one developed for tracking (Tambe & Rosenbloom 1995; Tambe 1995) and one that learns models of decisions for explanation <ref> (Johnson 1994) </ref> | have been integrated. (The user interface in Figure 3 is from this integrated version.) We are experimenting with this integrated agent to address the 25-degree nose-off example discussed above. (These agents are based on the Soar integrated architecture (Newell 1990), and use chunking, a form of EBL, as
Reference: <author> Kautz, A., and Allen, J. F. </author> <year> 1986. </year> <title> Generalized plan recognition. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 32-37. </pages> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference: <author> Kuniyoshi, Y.; Rougeaux, S.; Ishii, M.; Kita, N.; Sakane, S.; and Kakikura, M. </author> <year> 1994. </year> <title> Cooperation by observation: the framework and the basic task pattern. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle>
Reference: <author> Laird, J. E.; Rosenbloom, P. S.; and Newell, A. </author> <year> 1986. </year> <title> Chunking in soar: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning 1(1) </booktitle> <pages> 11-46. </pages>
Reference-contexts: interface in Figure 3 is from this integrated version.) We are experimenting with this integrated agent to address the 25-degree nose-off example discussed above. (These agents are based on the Soar integrated architecture (Newell 1990), and use chunking, a form of EBL, as the basis of all of their learning <ref> (Laird, Rosenbloom, & Newell 1986) </ref>). We are also in the process of implementing the above approach in a simple test-bed, where agents mimic the behavior of fighter aircraft, and are provided limited information about other agents.
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cam-bridge, Mass.: </address> <publisher> Harvard Univ. Press. </publisher>
Reference-contexts: and one that learns models of decisions for explanation (Johnson 1994) | have been integrated. (The user interface in Figure 3 is from this integrated version.) We are experimenting with this integrated agent to address the 25-degree nose-off example discussed above. (These agents are based on the Soar integrated architecture <ref> (Newell 1990) </ref>, and use chunking, a form of EBL, as the basis of all of their learning (Laird, Rosenbloom, & Newell 1986)).
Reference: <author> Pimentel, K., and Teixeira, K. </author> <year> 1994. </year> <title> Virtual reality: Through the new looking glass. Blue Ridge Summit, </title> <address> PA: Windcrest/McGraw-Hill. </address>
Reference-contexts: In the arena of education, intelligent tutors, whether in the form of "standard" intelligent tutoring systems (Anderson et al. 1990) or as participants in virtual environments (e.g., a virtual guide in a historical simulation <ref> (Pimentel & Teixeira 1994) </ref>), must interact with students in real-time. Similarly, in the arena of entertainment, recent work has focused on real-time, dynamic interactivity among multiple agents within virtual reality environments (Bates, Loyall, & Reilly 1992; Hayes-Roth, Brownston, & Gen 1995).
Reference: <author> Rao, A. S. </author> <year> 1994. </year> <title> Means-end plan recognition: Towards a theory of reactive recognition. </title> <booktitle> In Proceedings of the International Conference on Knowledge Representation and Reasoning (KR-94). </booktitle>
Reference: <author> Shaw, R. L. </author> <year> 1988. </year> <title> Fighter combat: tactics and maneuvers. </title> <type> Annapolis, </type> <institution> Maryland: Naval Institute Press. </institution>
Reference-contexts: This situation may arise due to adaptiveness: an intelligent adversary will very likely adapt its tactics to exploit possible weaknesses in a tracker's behaviors. * Real-time and dynamism: The tracker and trackee interact in real-time; for example, in simulated air-to-air combat, speed is life <ref> (Shaw 1988) </ref> in the real world, and in the simulated combat environment. * Complexity of environment: This is a realistic environment, in which entities and objects have a rich set of properties. * Cost of trial: Trials are not straightforward to run.
Reference: <author> Shen, W. </author> <year> 1993. </year> <title> Discovery as autonomous learning from the environment. </title> <booktitle> Machine Learning 12 </booktitle> <pages> 143-165. </pages>
Reference-contexts: Thus, comparing the feature set where the missile firing was successfully tracked with one where the tracking failed may yield differences in a large number of irrelevant features, e.g., the altitude or speed of the trackee. Under these circumstances, techniques akin to incremental enlargement <ref> (Shen 1993) </ref> or learning via experimentation (Gil 1993) can be employed to determine which features to discriminate. Incremental enlargement is a heuristic applicable to finding relevant features that are crucial in discriminating two environmental states that contain a large number of differences.
Reference: <author> Shen, W. </author> <year> 1994. </year> <title> Autonomous Learning from the Environment. </title> <editor> W. H. </editor> <publisher> Freeman, Computer Science Press. </publisher>
Reference: <author> Song, F., and Cohen, R. </author> <year> 1991. </year> <title> Temporal reasoning during plan recognition. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference: <author> Tambe, M., and Rosenbloom, P. S. </author> <year> 1995. </year> <title> RESC: An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). </booktitle>
Reference-contexts: Many of these multi-agent domains are dynamic and real-time, requiring the interaction to be flexible and reactive. For instance, in the arena of training, there is a recent thrust on dynamic, real-time interactive simulations | e.g., realistic traffic environments (Cremer et al. 1994), or realistic combat environments <ref> (Tambe et al. 1995) </ref> | where intelligent agents may interact with tens or hundreds of collaborative and non-collaborative participants (agents and humans). <p> The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosenbloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> The initial core set of relevant features is provided by the prior analysis by Debrief of successful tracking episodes. Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>.
Reference: <author> Tambe, M.; Johnson, W. L.; Jones, R.; Koss, F.; Laird, J. E.; Rosenbloom, P. S.; and Schwamb, K. </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16(1). </journal>
Reference-contexts: Many of these multi-agent domains are dynamic and real-time, requiring the interaction to be flexible and reactive. For instance, in the arena of training, there is a recent thrust on dynamic, real-time interactive simulations | e.g., realistic traffic environments (Cremer et al. 1994), or realistic combat environments <ref> (Tambe et al. 1995) </ref> | where intelligent agents may interact with tens or hundreds of collaborative and non-collaborative participants (agents and humans). <p> The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosenbloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> The initial core set of relevant features is provided by the prior analysis by Debrief of successful tracking episodes. Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>.
Reference: <author> Tambe, M. </author> <year> 1995. </year> <title> Recursive agent and agent-group tracking in a real-time dynamic environment. </title> <booktitle> In Proceedings of the International Conference on Multi-agent systems (ICMAS). </booktitle>
Reference-contexts: Many of these multi-agent domains are dynamic and real-time, requiring the interaction to be flexible and reactive. For instance, in the arena of training, there is a recent thrust on dynamic, real-time interactive simulations | e.g., realistic traffic environments (Cremer et al. 1994), or realistic combat environments <ref> (Tambe et al. 1995) </ref> | where intelligent agents may interact with tens or hundreds of collaborative and non-collaborative participants (agents and humans). <p> The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosenbloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> The initial core set of relevant features is provided by the prior analysis by Debrief of successful tracking episodes. Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>.
Reference: <author> Ward, B. </author> <year> 1991. </year> <title> ET-Soar: Toward an ITS for Theory-Based Representations. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Science, Carnegie Mellon Univ. </institution>
References-found: 20

