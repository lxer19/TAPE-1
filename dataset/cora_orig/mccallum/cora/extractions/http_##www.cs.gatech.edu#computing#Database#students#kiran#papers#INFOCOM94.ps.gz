URL: http://www.cs.gatech.edu/computing/Database/students/kiran/papers/INFOCOM94.ps.gz
Refering-URL: http://www.cs.gatech.edu/computing/Database/students/kiran/kiran.html
Root-URL: 
Title: Managing Multiple Disjoint Priority Orders in Priority Queues  
Author: Yann-Hang Lee Kiran J. Achyutuni 
Address: Gainesville, FL 32611 Atlanta, GA 30332  
Affiliation: CIS Department College of Computing University of Florida Georgia Institute of Technology  
Abstract: In communication and computer systems, autonomous sources may assign priorities to their messages or jobs locally and independently. When a remote service (e.g., message transmission or RPC) is requested at a shared server, the server cannot use priority scheduling schemes effectively unless it can make a comparison between priorities defined by individual sources. In this paper, we investigate the strategies under which the service received by requests of one source is not affected by the priority assignments at other sources. The first approach is a combination of processor-sharing and priority queue strategies. The second approach is to map locally defined priorities onto a global priority system. The performance of these approaches is examined in terms of the average response time of all requests, the average response time of the highest priority requests and a fairness measure. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. J. Achyutuni, </author> <title> Managing Jobs with Priority in Distributed Systems, M.S. </title> <type> Thesis, </type> <institution> Computer and Information Sciences Department, University of Florida, </institution> <year> 1991. </year>
Reference-contexts: In other words, for each global priority level, the arriving jobs from a source is a constant proportion of all jobs at this priority level. The interested reader is referred to <ref> [1] </ref> for more details. We now present an algorithm to calculate the mapping probability p k ij , and then show that this mapping function achieves the transparency defined in Eq. (3). <p> We use f rms to compare the fairness of strategies PS1 and PS2 with that of the mapping scheme in Figure 8 for the exponential service time. Due to space constraints, we are unable to present the corresponding figures for Erlangian service time. The interested reader is referred to <ref> [1] </ref> for more details. The following observations can be made from the numerical results: 1. As expected, the mean response time of the highest priority job from any source with the mapping scheme is much lower than that with the proces sor sharing schemes. 2.
Reference: [2] <author> B. N. Bershad, T. E. Anderson, E. D. Lazowska, and H. M. Levy, </author> <title> "Lightweight Remote Procedure Calls", </title> <journal> Operating Systems Review, </journal> <volume> Vol. 23, No. 5, </volume> <year> 1989, </year> <pages> pp. 102-113. </pages>
Reference-contexts: With processor sharing strategy P S2, the server serves the highest priority job belonging to priority queue i with a rate that is proportional to the queue length of queue i. This scheme can be easily implemented in a system that supports lightweight processes <ref> [2, 11] </ref>, or maintains separate queues for each source stream. For instance, with multiple threads, each thread uses a dedicated port to receive calls from only one source. The server scheduling scheme is then processor sharing among the threads.
Reference: [3] <author> E. G. Coffman, Jr., and I. Mitrani, </author> <title> "A Characterization of Waiting Time Performance Realizable by Single-Server Queues," </title> <journal> Operations Research, </journal> <volume> Vol. 28, No. 3, </volume> <year> 1980, </year> <pages> pp. 810-821. </pages>
Reference-contexts: Other possible solutions to achieve the expected waiting time E [w G ij ( G )] can be obtained through the synthesis approach <ref> [3, 5] </ref>. We can treat each priority class as one job stream with a target waiting time E [w L ij ( G )].
Reference: [4] <author> G. Fayolle, I. Mitrani, and R. Iasnogorodski, </author> <title> "Sharing a Processor Among Many Job Classes," </title> <journal> JACM, </journal> <volume> Vol. 27, No. 3, </volume> <month> July, </month> <year> 1980, </year> <pages> pp. 519-532. </pages>
Reference-contexts: At the end of a busy cycle, one of these P N preemptive priority discipline is chosen probabilistically. If the service time is exponentially distributed, the synthesis approach on a generalized processor-sharing strategy can also be used to realize the set of waiting times <ref> [4] </ref>. The above possible solutions may have a deficiency of large variances in waiting time. Also, the solutions may not be desirable from the viewpoint of locally defined priority levels.
Reference: [5] <author> E. Gelenbe and I. Mitrani, </author> <title> Analysis and Synthesis of Computer Systems, </title> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Other possible solutions to achieve the expected waiting time E [w G ij ( G )] can be obtained through the synthesis approach <ref> [3, 5] </ref>. We can treat each priority class as one job stream with a target waiting time E [w L ij ( G )]. <p> That is: 1 L i X ij E [w G 1 L i 0 j 0 =1 i 0 j 0 ( G )] for 1 i; i N . Based on the work conservation law for non-preemptive service discipline <ref> [5, 6] </ref>, the transparent mapping defined in Eq. (3) ensures the fairness defined in Eq. (4). Notice that a first-come-first-serve discipline at the global source can also preserve the above defined fairness for all sources, since jobs at the global source are not distinguished.
Reference: [6] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems, </journal> <volume> Vol. 2, </volume> <publisher> John Wi-ley & Sons, </publisher> <year> 1976. </year>
Reference-contexts: That is: 1 L i X ij E [w G 1 L i 0 j 0 =1 i 0 j 0 ( G )] for 1 i; i N . Based on the work conservation law for non-preemptive service discipline <ref> [5, 6] </ref>, the transparent mapping defined in Eq. (3) ensures the fairness defined in Eq. (4). Notice that a first-come-first-serve discipline at the global source can also preserve the above defined fairness for all sources, since jobs at the global source are not distinguished.
Reference: [7] <author> S.S.Lavenberg, </author> <title> Computer Performance Modeling Handbook, </title> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: When a non-preemptive priority local server is located at each of the sources as shown in Figure 2, the expected waiting time of priority j job at source i is <ref> [7] </ref>: ij ( i )] = 2 [1 ((j 1); i)] [1 (j; i)] where (j; i) = P j k=1 a ik i E [S] is the utilization due to the jobs with priorities from level 1 to level j at source i and the superscript L indicates that the <p> For PS1 and PS2 strategies, the results are collected from simulation. For the mean response times, the confident intervals for a confidence level of 95% are also included in the table. For the mapping scheme, the results are calculated from the closed form equations <ref> [7] </ref>. With different G , the mean response time (over all jobs) due to the mapping scheme is compared with that due to PS1 and PS2 strategies in Figure 6 for exponential service time. <p> only does it minimize the response time for the highest priority job, it also offers fair service to all sources. 3 In M=G=1 queues, the response time of processor-sharing scheduling is greater than that of FCFS scheduling if the coefficient of variation of the service time is less than 1 <ref> [7] </ref>. In addition, PS2 is indeed a fair strategy if the service time is exponentially distributed.
Reference: [8] <author> R. M. Sanders and A. C. Weaver, </author> <title> "The Xpress Transfer Protocol (XTP) ATutorial," </title> <journal> Computer Communication Review , Vol. </journal> <volume> 20, No. 5, </volume> <year> 1990, </year> <pages> pp. 67-80. </pages>
Reference-contexts: When the routers try to forward the packets to their next hop through the output interface, the packet priority must be considered for multiplexing of packets from different protocol entities. Another example is the distinct priority assignment in a transport layer protocol. Consider the XTP lightweight transport layer protocol <ref> [8] </ref>, which supports a number of priority levels to be employed by the messages between applications. As--sume that a distributed conferencing application and a multi-media application want to take the advantages of this priority structure.
Reference: [9] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time Synchronization", </title> <journal> IEEE Trans. Computers, </journal> <volume> Vol. 39, No. 9, </volume> <month> September </month> <year> 1990, </year> <pages> pp. 1175-1185. </pages>
Reference: [10] <author> L. Takacs, </author> <title> "Priority Queues", </title> <journal> Oper. Res, </journal> <volume> Vol. 12, </volume> <pages> pp. 63-74, </pages> <year> 1964. </year>
Reference: [11] <author> B. H. Tay and A. L. Ananda, </author> <title> "A Survey of Remote Procedure Calls", </title> <journal> Operating Systems Review, </journal> <volume> Vol. 24, No. 3, </volume> <month> July </month> <year> 1990, </year> <pages> pp. 68-79. </pages>
Reference-contexts: With processor sharing strategy P S2, the server serves the highest priority job belonging to priority queue i with a rate that is proportional to the queue length of queue i. This scheme can be easily implemented in a system that supports lightweight processes <ref> [2, 11] </ref>, or maintains separate queues for each source stream. For instance, with multiple threads, each thread uses a dedicated port to receive calls from only one source. The server scheduling scheme is then processor sharing among the threads.
Reference: [12] <author> H. Tokuda, C. W. Mercer, Y. Ishikawa, and T. E. Marchok, </author> <title> "Priority Inversions in Real-Time Communications", </title> <booktitle> 1989 Real-Time Symposium, </booktitle> <pages> pp. 348-359. </pages>
References-found: 12

