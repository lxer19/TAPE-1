URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-94-06/MP-TR-94-06.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-94-06/
Root-URL: http://www.cs.wisc.edu
Email: Email: olvi@cs.wisc.edu, solodov@cs.wisc.edu  
Title: Backpropagation Convergence Via Deterministic Nonmonotone Perturbed Minimization  
Author: J.D. Cowan, G. Tesauro and J. Alspector (eds), O. L. Mangasarian M. V. Solodov 
Affiliation: Computer Sciences Department University of Wisconsin  
Date: 1994  
Address: San Francisco, CA,  Madison, WI 53706  
Note: pp 383-390 in Advances in Neural Information Processing Systems 6  Morgan Kaufmann Publishers,  
Abstract: The fundamental backpropagation (BP) algorithm for training artificial neural networks is cast as a deterministic nonmonotone perturbed gradient method . Under certain natural assumptions, such as the series of learning rates diverging while the series of their squares converging, it is established that every accumulation point of the online BP iterates is a stationary point of the BP error function. The results presented cover serial and parallel online BP, modified BP with a momentum term, and BP with weight decay. 
Abstract-found: 1
Intro-found: 1
Reference: <author> M. Arai. </author> <title> (1993) Bounds on the number of hidden units in binary-valued three-layer neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 6 </volume> <pages> 855-860. </pages>
Reference: <author> B. C. Cetin, J. W. Burdick, and J. Barhen. </author> <title> (1993) Global descent replaces gradient descent to avoid local minima problem in learning with artificial neural networks. </title> <booktitle> In IEEE International Conference on Neural Networks, (San Francisco), </booktitle> <volume> volume 2, </volume> <pages> 836-842. </pages>
Reference-contexts: Remark 2.9. Establishing convergence to a stationary point seems to be the best one can do for a first-order minimization method without any additional restrictive assumptions on the objective function. There have been some attempts to achieve global descent in training, see for example, <ref> (Cetin,Burdick & Barhen, 1993) </ref>. However, convergence to global minima was not proven rigorously in the multidimensional case. 3 MATHEMATICAL APPENDIX: CONVERGENCE OF ALGORITHMS WITH PERTURBATIONS In this section we state a new result that enables us to establish convergence properties of BP.
Reference: <author> P. </author> <title> Courrien.(1993) Convergent generator of neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 6 </volume> <pages> 835-844. </pages>
Reference: <editor> Yu. Ermoliev and R.J.-B. Wets (editors). </editor> <title> (1988) Numerical Techniques for Stochastic Optimization Problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> A.A. Gaivoronski. </author> <title> (1994) Convergence properties of backpropagation for neural networks via theory of stochastic gradient methods. Part 1. Optimization Methods and Software, </title> <note> 1994, to appear. </note>
Reference-contexts: More recently, Gaivoronski obtained stronger stochastic results <ref> (Gaivoronski, 1994) </ref>. It is worth noting that even if the data is assumed to be deterministic, the best that stochastic analysis can do is to establish convergence of certain sequences with probability one. This means that convergence is not guaranteed.
Reference: <author> L. Grippo. </author> <title> (1994) A class of unconstrained minimization methods for neural network training. Optimization Methods and Software, </title> <note> 1994, to appear. </note>
Reference-contexts: There are a number of ways to ensure that f (x) has Lipschitz continuous and bounded gradient on fx i g. In (Luo & Tseng, 1994) a simple projection onto a box is introduced which ensures that the iterates remain in the box. In <ref> (Grippo, 1994) </ref> a regularization term as in (6) is added to the error function so that the modified objective function has bounded level sets. We note that the latter provides a mathematical justification for weight decay (Hinton, 1986; Weigend,Huberman & Rumelhart, 1990).
Reference: <author> G. E. Hinton. </author> <title> (1986) Learning distributed representations of concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 1-12, </pages> <address> Hillsdale. </address> <publisher> Erlbaum. </publisher>
Reference: <author> R. L. Kashyap, C. C. Blaydon and K. S. Fu. </author> <title> (1970) Applications of stochastic approximation methods. In J.M.Mendel and K.S. Fu, editors, Adaptive, Learning, and Pattern Recognition Systems. </title> <publisher> Academic Press. </publisher>
Reference: <author> T. </author> <title> Khanna. </title> <booktitle> (1989) Foundations of neural networks. </booktitle> <publisher> Addison-Wesley, </publisher> <address> New Jersey. </address>
Reference: <author> Y. le Cun, P.Y. Simard, and B. Pearlmutter. </author> <title> (1993) Automatic learning rate maximization by on-line estimation of the Hessian's eigenvectors. </title> <editor> In C.L.Giles S.J.Hanson, J.D.Cowan, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> 156-163, </pages> <address> San Mateo, California, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For practical purposes the learning rate can be fixed or adjusted to some small but finite number to obtain an approximate solution to the minimization problem. For state-of-the-art techniques of computing the learning rate see <ref> (le Cun, Simard & Pearlmutter, 1993) </ref>. Remark 2.7. We wish to point out that Theorem 2.1 covers BP with momentum and/or decay terms for which there is no published convergence analysis of any kind. Remark 2.8.
Reference: <author> Z.-Q. Luo and P. Tseng. </author> <title> (1994) Analysis of an approximate gradient projection method with applications to the backpropagation algorithm. Optimization Methods and Software, </title> <note> 1994, to appear. </note>
Reference-contexts: Remark 3.1. The error function of BP is nonnegative, and thus the boundedness condition on f (x) is satisfied automatically. There are a number of ways to ensure that f (x) has Lipschitz continuous and bounded gradient on fx i g. In <ref> (Luo & Tseng, 1994) </ref> a simple projection onto a box is introduced which ensures that the iterates remain in the box. In (Grippo, 1994) a regularization term as in (6) is added to the error function so that the modified objective function has bounded level sets.
Reference: <author> O.L. Mangasarian. </author> <title> (1993) Mathematical programming in neural networks. </title> <journal> ORSA Journal on Computing, </journal> <volume> 5(4), </volume> <pages> 349-360. </pages>
Reference-contexts: The n-dimensional variable space here is that of the weights associated with the arcs of the neural network and the thresholds of the hidden and output units. For an explicit description of f (x) see <ref> (Mangasarian, 1993) </ref>. We note that our convergence results are equally applicable to any other form of the error function, provided that it is smooth. BP (Rumelhart,Hinton & Williams, 1986; Khanna, 1989) has long been successfully used by the artificial intelligence community for training artificial neural networks.
Reference: <editor> O.L. Mangasarian and M.V. Solodov. </editor> <title> (1994) Serial and parallel backpropagation convergence via nonmonotone perturbed minimization. Optimization Methods and Software, 1994, to appear. </title> <booktitle> Proceedings of Symposium on Parallel Optimization 3, </booktitle> <address> Madison July 7-9, </address> <year> 1993. </year>
Reference-contexts: To the best of our knowledge there are no published deterministic convergence proofs for either of Algorithms 2.1,2.2. Using new convergence analysis for a class of nonmonotone optimization methods with perturbations <ref> (Mangasarian & Solodov, 1994) </ref>, we are able to derive deterministic convergence properties for online BP and its modifications. Once again we emphasize the equivalence of either of those methods to a deterministic nonmonotone perturbed gradient-type algorithm. We now state our main convergence theorem. <p> Once again we emphasize the equivalence of either of those methods to a deterministic nonmonotone perturbed gradient-type algorithm. We now state our main convergence theorem. An important result used in the proof is given in the Mathematical Appendix. We refer interested readers to <ref> (Mangasarian & Solodov, 1994) </ref> for more details. Theorem 2.1. <p> However, convergence to global minima was not proven rigorously in the multidimensional case. 3 MATHEMATICAL APPENDIX: CONVERGENCE OF ALGORITHMS WITH PERTURBATIONS In this section we state a new result that enables us to establish convergence properties of BP. The full proof is nontrivial and is given in <ref> (Mangasarian & Solodov, 1994) </ref>. Theorem 3.1. General Nonmonotonic Perturbed Gradient Convergence (subsumes BP convergence). Suppose that f (x) is bounded below and that rf (x) is bounded and Lipschitz continuous on the sequence fx i g defined below. Consider the following perturbed gradient algorithm.
Reference: <author> M.F. Mtller. </author> <title> (1992) Supervised learning on large redundant training sets. In Neural Networks for Signal Processing 2. </title> <publisher> IEEE Press. </publisher>
Reference-contexts: Remark 2.2. The choice of ff i = 0 reduces Algorithm 2.1 to the original BP without a momentum term. Remark 2.3. We can easily handle the "mini-batch" methods <ref> (Mtller, 1992) </ref> by merely redefining the meaning of the partial error function f j to represent the error associated with a subset of training examples. Thus "mini-batch" methods also fall within our framework. We next present a parallel modification of BP. Suppose we have k parallel processors, k 1.
Reference: <author> B.T. Polyak. </author> <title> (1987) Introduction to Optimization. Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York. </address>
Reference-contexts: For simplicity we shall assume that the learning and momentum rates remain fixed within each major iteration. In a manner similar to that of conjugate gradients <ref> (Polyak, 1987) </ref> we reset the momentum term to zero periodically. Algorithm 2.1. Serial Online BP with a Momentum Term. Start with any x 0 2 &lt; n .
Reference: <author> D.E. Rumelhart, G.E. Hinton, and R.J. Williams. </author> <title> (1986) Learning internal representations by error propagation. </title> <editor> In D.E. Rumelhart and J.L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <pages> 318-362, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> T.J. Sejnowski and C.R. Rosenberg. </author> <title> (1987) Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 145-168. </pages>
Reference-contexts: Remark 2.8. We note that the approach of perturbed minimization provides theoretical justification to the well known properties of robustness and recovery from damage for neural networks <ref> (Sejnowski & Rosenberg, 1987) </ref>. In particular, this approach shows that the net should recover from any reasonably small perturbation. Remark 2.9. Establishing convergence to a stationary point seems to be the best one can do for a first-order minimization method without any additional restrictive assumptions on the objective function.
Reference: <author> A.S. Weigend, B.A. Huberman, and D.E. Rumelhart. </author> <title> (1990) Predicting the future:a connectionist approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> 1 </volume> <pages> 193-209. </pages>
Reference: <author> H. White. </author> <title> (1989) Some asymptotic results for learning in single hidden-layer feedforward network models. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 84(408) </volume> <pages> 1003-1013. </pages>
Reference-contexts: This difficulty makes convergence analysis of BP a challenging problem that has currently attracted interest of many researchers (Mangasarian & Solodov, 1994; Gaivoronski, 1994; Grippo, 1994; Luo & Tseng, 1994; White, 1989). By using stochastic approximation ideas (Kashyap,Blaydon & Fu, 1970; Ermoliev & Wets, 1988), White <ref> (White, 1989) </ref> has shown that, under certain stochastic assumptions, the sequence of weights generated by BP either diverges or converges almost surely to a point that is a stationary point of the error function. More recently, Gaivoronski obtained stronger stochastic results (Gaivoronski, 1994).
Reference: <author> X. Zhang, M. Mckenna, J. P. Mesirov, and D. L. Waltz. </author> <title> (1990) The backpropagation algorithm on grid and hypercube architectures. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 317-327. </pages>
Reference-contexts: Flowchart of the Parallel BP Remark 2.4. It is well known that ordinary backpropagation is a relatively slow algorithm. One appealing remedy is parallelization <ref> (Zhang,Mckenna,Mesirov & Waltz, 1990) </ref>. The proposed Algorithm 2.2 is a possible step in that direction. Note that in Algorithm 2.2 all processors typically use the same program for their computations. Thus load balancing is easily achieved. Remark 2.5.
References-found: 20

