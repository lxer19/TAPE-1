URL: http://www-graphics.stanford.edu/papers/modelbased/paper.ps
Refering-URL: http://www-graphics.stanford.edu/papers/modelbased/
Root-URL: http://www.cs.stanford.edu
Title: Model-Based Motion Estimation for Synthetic Animations  
Author: Maneesh Agrawala Andrew C. Beers Navin Chaddha 
Affiliation: Computer Science Department Computer Systems Laboratory Stanford University Stanford University  
Abstract: One approach to performing motion estimation on synthetic animations is to treat them as video sequences and use standard image-based motion estimation methods. Alternatively, we can take advantage of information used in rendering the animation to guide the motion estimation algorithm. This information includes the 3D movements of the objects in the scene and the projection transformations from 3D world space into screen space. In this paper we examine how to use this high level object motion information to perform fast, accurate block-based motion estimation for synthetic animations. The optical flow field is a 2D vector field describing the translational motion of each pixel from frame to frame. Our motion estimation algorithm first computes the optical flow field, based on the object motion information. We then combine the per-pixel motion information for a block of pixels to create a single 2D projective matrix that best encodes the motion of all the pixels in the block. The entries of the 2D matrix are determined using a least squares formulation. Our algorithms are more accurate and much faster in algorithmic complexity than many image-based motion estimation algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James Arvo, </author> <title> editor. Graphics Gems II. </title> <publisher> Academic Press, Inc., </publisher> <year> 1991. </year>
Reference-contexts: This decomposition is described in <ref> [1] </ref>. This factorization should decorrelate some of the motion parameters and thereby allow us to quantize the parameters more effectively.
Reference: [2] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View interpolation for image synthesis. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 279-288, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Given this information, we can backproject each pixel in frame N + 1 to its corre-sponding position in frame N , as shown in figure 1. This method for computing the optical flow field is used in the view interpolation schemes presented in <ref> [2] </ref>. It has also been used in previous work on motion compensation for synthetic animations and it is the basis for the model-based algorithms we present. Guenter et al. [5] describe a lossless motion compensated compression algorithm for synthetic animations.
Reference: [3] <author> P. A. Chou, T. Lookabaugh, and R. M. Gray. </author> <title> Optimal pruning with applications to tree-structured source coding and modelling. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 35 </volume> <pages> 299-315, </pages> <year> 1989. </year>
Reference-contexts: In this method the tree is grown one node at a time. The node with the largest ratio of decrease in distortion to increase in rate or entropy is split. Hence, each split optimizes the rate-distortion tradeoff. We further prune this unbalanced tree using the Generalized BFOS algorithm <ref> [3] </ref>. This algorithm trades off the entropy of leaves for the average distortion. In this algorithm the average entropy is minimized instead of the average length. Thus we obtain a TSVQ codebook using a greedy growing algorithm followed by pruning using a generalized BFOS algorithm.
Reference: [4] <author> A. Gersho and R. M. Gray. </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: In full search vector quantization, the encoder consists of an exhaustive search for the minimum distortion codeword while the decoder consists of a table lookup. A major drawback of full search VQ is its high encoding complexity. Tree structured VQ <ref> [4] </ref> (TSVQ) is one scheme to reduce the encoding complexity by replacing the full search by a sequence of binary searches. Both full search and TSVQ produce a fixed rate-code. A variable rate code can be implemented with TSVQ by using an unbalanced tree.
Reference: [5] <author> Brian K. Guenter, Hee Cheol Yun, and Russell M. Mersereau. </author> <title> Motion compensated compression of computer animation frames. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 297-304, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: This method for computing the optical flow field is used in the view interpolation schemes presented in [2]. It has also been used in previous work on motion compensation for synthetic animations and it is the basis for the model-based algorithms we present. Guenter et al. <ref> [5] </ref> describe a lossless motion compensated compression algorithm for synthetic animations. In their scheme all the information necessary to compute the optical flow vector for each pixel is sent to the decoder.
Reference: [6] <author> A. C. Hung and T. H. Meng. </author> <title> Parallel array ar-chitechures for motion estimation. </title> <editor> In T. Valero, M.; Lang, Sun-Yuan Kung, and J. Fortes, editors, </editor> <booktitle> Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <pages> pages 214-235. </pages> <publisher> IEEE, </publisher> <month> September </month> <year> 1991. </year>
Reference-contexts: The complexity of the final block reconstruction from the computed motion parameters at the decoder is not included in the analysis of the algorithms. Table 4 summarizes the analyses discussed in this section. 3.1 Complexity of Brute Force As described in <ref> [6] </ref>, for a square, symmetric search window of size [-n,n] (that is, n pixels in both horizontal and vertical directions),the BRUTE algorithm requires (2n + 1) 2 block compare operations. <p> Thus, the total cost per block of the BRUTE algorithm is (2n + 1) 2 2B 2 . Although faster image-based block motion estimation algorithms exist, as described in <ref> [6] </ref>, they are less accurate than BRUTE. Thus, we compare our model-based schemes to BRUTE. 3.2 Complexity of Optical Flow The first step in each of the model-based motion estimation techniques is calculating the optical flow field for each B fi B block.
Reference: [7] <author> D. LeGall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 46-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Ethernet) would require approximately 15 minutes, assuming a sustained transfer rate of 10 Mbit/sec. In order to store long sequences or send them across a network, the data must be compressed. Motion compensation is the first step in many video compression algorithms including MPEG <ref> [7] </ref>, because it allows the compression algorithm to take advantage of frame to frame image coherency. <p> One approach to performing motion estimation on synthetic animations is to treat them as video sequences and use standard image-based motion estimation algorithms such as those used in MPEG <ref> [7] </ref>. Alternatively, we can take advantage of information used in rendering the animation to guide the motion estimation algorithm. Such information includes the 3D world space movements of the objects in the scene and the projection transformations from world space into screen space.
Reference: [8] <author> E. A. Riskin and R. M. Gray. </author> <title> A greedy tree growing algorithm for the design of variable rate quantizers. </title> <journal> IEEE Transations on Signal Processing, </journal> <volume> 39 </volume> <pages> 2500-2507, </pages> <year> 1991. </year>
Reference-contexts: The advantage of doing this would be to allocate fewer bits to the commonly occuring motion matrices and more bits to matrices which occur very rarely. This is similar to the principle of Huffman coding. To design an unbalanced tree we use a greedy growing algorithm <ref> [8] </ref>. In this method the tree is grown one node at a time. The node with the largest ratio of decrease in distortion to increase in rate or entropy is split. Hence, each split optimizes the rate-distortion tradeoff. We further prune this unbalanced tree using the Generalized BFOS algorithm [3].
Reference: [9] <author> Dan S. Wallach, Sharma Kunapalli, and Michael F. Cohen. </author> <title> Accelerated MPEG compression of dynamic polygonal scenes. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> Proceedings of SIGGRAPH '94 (Orlando, </booktitle> <address> Florida, </address> <month> July 24-29, </month> <year> 1994), </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 193-197. </pages> <publisher> ACM SIG-GRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year> <note> ISBN 0-89791-667-0. </note>
Reference-contexts: The encoder determines the translational offset between two blocks and sends this translational vector to the decoder. The same translational vector is used for every pixel in the block. In <ref> [9] </ref>, Wallach et al. describe two methods for quickly calculating the optical flow and the per-block motion vectors of a synthetic animation using either the Gouraud interpolation or the texture mapping capabilities present in many modern hardware rendering systems. <p> The matrix B obj = P N T 1 N+1 is called the "backtransform matrix". While this is the most straightforward method for computing the optical flow field based on information about world space object movements, other methods have been developed. Wallach et al. <ref> [9] </ref> propose two different schemes for computing the optical flow field using graphics hardware, one using Gouraud interpolation and the other using texture mapping. They back-project each vertex of the object in frame N + 1, and then interpolate the flow field across each polygon using the interpolation hardware. <p> For comparison we have also implemented the predictive brute force (P-BRUTE) motion estimation scheme presented by Wallach et al. <ref> [9] </ref>. After generating the optical flow field they find the mode of the pixel motion vectors in each B fi B block and use that vector to center a brute force search. <p> Given a large enough search window, BRUTE and P-BRUTE will perform equivalently in terms of quality. With smaller search windows the differences between the two brute force schemes are more dramatic as reported in <ref> [9] </ref>. In table 9, we consider the average bitrate per frame required by P-BRUTE for each of the animations in the database. The first row of the table lists the average motion parameter overhead per frame, and the second row lists the total average bitrate per frame.
References-found: 9

