URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/paderborn.ps
Refering-URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/papers.html
Root-URL: 
Title: A Case for the PRAM As a Standard Programmer's Model  
Author: Uzi Vishkin 
Note: features various kinds of parallelism. 1  
Affiliation: University of Maryland Tel Aviv University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [Akl-89] <author> S.G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Engel-wood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, <ref> [Akl-89] </ref>, [GR-88], [J-92] and [R-92], and a few review papers, [EG-88], [KR-90], [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms.
Reference: [ALM-90] <author> S. Arora, T. Leighton and B. Maggs. </author> <title> On-line algorithms for path selection in a nonblocking network. </title> <booktitle> In Proc. of the 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 149-158, </pages> <year> 1990. </year>
Reference-contexts: This observation was useful for enhancing the interest of the academic computer science community (theoretical and other) in PRAM algorithmics. Elegant and insightful refinements and enhancements of this observation were given in [KU-86], [R-87], [U-89] and <ref> [ALM-90] </ref>. For more on this topic and machine designs that relate to it see [L-92a] and [L-92b], and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [EG-88] <author> D. Eppstein and Z. Galil. </author> <title> Parallel algorithmic techniques for combinatorial computation. </title> <journal> Ann. Rev. Comput. Sci., </journal> <volume> 3 </volume> <pages> 233-283, </pages> <year> 1988. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], [J-92] and [R-92], and a few review papers, <ref> [EG-88] </ref>, [KR-90], [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms. Note that some of these publications consider as efficient only algorithms whose running time is poly-logarithmic (i.e., asymptotically bounded by a polynomial in the logarithm of the problem size).
Reference: [GR-88] <author> A. Gibbons and W. Rytter. </author> <title> Efficient Parallel Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], <ref> [GR-88] </ref>, [J-92] and [R-92], and a few review papers, [EG-88], [KR-90], [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms.
Reference: [HP-90] <author> J.L. Hennessy and D.A. Patterson. </author> <title> Computer Architecture a Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: These stages coincide with the massive processor-parallelism approach. The main advantages of the multi-stage machine-parallelism approach are: * A gradual, rather than abrupt, transition of general purpose computing from serial to parallel algorithms. Using the terminology of <ref> [HP-90] </ref>, this gives the advantage of being more evolutionary in its demands from the user (and less revolutionary). * The first generations of machines that will be built this way will cost much less than massively parallel machines. (These first generations can be nicknamed a "poor-person's" parallel computer, as opposed to
Reference: [KR-90] <author> R.M. Karp and V. Ramachandran. </author> <title> A survey of parallel algorithms for shared-memory machines. In Handbook of Theoretical Computer Science: Volume A, Algorithms and Complexity (Editor J. </title> <editor> van Leeuwen), </editor> <publisher> MIT Press/Elsevier, </publisher> <year> 1990, </year> <pages> pages 869-942. 7 </pages>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], [J-92] and [R-92], and a few review papers, [EG-88], <ref> [KR-90] </ref>, [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms. Note that some of these publications consider as efficient only algorithms whose running time is poly-logarithmic (i.e., asymptotically bounded by a polynomial in the logarithm of the problem size).
Reference: [KRS-90] <author> C.P. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <booktitle> In Theoretical Computer Science, </booktitle> <volume> 71 </volume> <pages> 95-132, </pages> <year> 1990. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], [J-92] and [R-92], and a few review papers, [EG-88], [KR-90], <ref> [KRS-90] </ref> and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms. Note that some of these publications consider as efficient only algorithms whose running time is poly-logarithmic (i.e., asymptotically bounded by a polynomial in the logarithm of the problem size).
Reference: [J-92] <author> J. JaJa. </author> <title> Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], <ref> [J-92] </ref> and [R-92], and a few review papers, [EG-88], [KR-90], [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms.
Reference: [KU-86] <author> A. Karlin and E. Upfal. </author> <title> Parallel hashing an efficient implementation of shared memory. </title> <booktitle> In Proc. of the 18th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 160-168, </pages> <year> 1986. </year>
Reference-contexts: This observation was useful for enhancing the interest of the academic computer science community (theoretical and other) in PRAM algorithmics. Elegant and insightful refinements and enhancements of this observation were given in <ref> [KU-86] </ref>, [R-87], [U-89] and [ALM-90]. For more on this topic and machine designs that relate to it see [L-92a] and [L-92b], and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [L-92a] <author> F.T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: Elegant and insightful refinements and enhancements of this observation were given in [KU-86], [R-87], [U-89] and [ALM-90]. For more on this topic and machine designs that relate to it see <ref> [L-92a] </ref> and [L-92b], and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [L-92b] <author> F.T. Leighton. </author> <title> Methods for message routing in parallel machines. </title> <booktitle> In Proc. of the 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 77-96, </pages> <year> 1992. </year>
Reference-contexts: Elegant and insightful refinements and enhancements of this observation were given in [KU-86], [R-87], [U-89] and [ALM-90]. For more on this topic and machine designs that relate to it see [L-92a] and <ref> [L-92b] </ref>, and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [MR-90] <author> M. Metcalf and J. Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: The intention is that the first few generations of such computers will still provide competitive support for serial algorithms (including existing code). We note that Fortran 90, the new international standard described in <ref> [MR-90] </ref>, requires that manufacturers continue to provide support for serial algorithms, and at the same time to provide support for new array instructions that essentially enable implementing PRAM algorithms. <p> used the term "bridging model" for describing a whole spectrum of possibilities for such a programmer's model. (The general idea of trading algorithm-parallelism for more effective implementation has also been discussed in these four papers.) Such a "divide-and-conquer" strategy also led to Fortran 90, the new computer language international standard <ref> [MR-90] </ref>, which guides machine designers to support Fortran 90 in the future. As mentioned above, Fortran 90 enables coding PRAM algorithms, much in the same way that Fortran 77 enables coding of RAM algorithms.
Reference: [MV-84] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: We summarize in one paragraph a relationship between algorithm-parallelism and this well-studied kind of hardware-parallelism. The following observation, which is due to the companion papers <ref> [MV-84] </ref> and [Vi-84], discusses this relationship. The PRAM model can be formally emulated, in an efficient manner, by a synchronous distributed computer, where each processor is connected to a small number of others in a fixed pattern.
Reference: [R-87] <author> A.G. Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In Proc. of the 28th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 185-194, </pages> <year> 1987. </year>
Reference-contexts: This observation was useful for enhancing the interest of the academic computer science community (theoretical and other) in PRAM algorithmics. Elegant and insightful refinements and enhancements of this observation were given in [KU-86], <ref> [R-87] </ref>, [U-89] and [ALM-90]. For more on this topic and machine designs that relate to it see [L-92a] and [L-92b], and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [R-92] <author> J.H. Reif, </author> <title> editor. Synthesis of Parallel Algorithms. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], [J-92] and <ref> [R-92] </ref>, and a few review papers, [EG-88], [KR-90], [KRS-90] and [Vi-91a], attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms.
Reference: [U-89] <author> E. Upfal. </author> <title> An O(log N) deterministic packet routing scheme. </title> <booktitle> In Proc. of the 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 241-250, </pages> <year> 1989. </year>
Reference-contexts: This observation was useful for enhancing the interest of the academic computer science community (theoretical and other) in PRAM algorithmics. Elegant and insightful refinements and enhancements of this observation were given in [KU-86], [R-87], <ref> [U-89] </ref> and [ALM-90]. For more on this topic and machine designs that relate to it see [L-92a] and [L-92b], and references therein. 5.2 Machine-parallelism For background we note the following, * The new generation of "serial machines" is far from being literally serial.
Reference: [Va90a] <author> L.G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Comm. ACM, </journal> <volume> 33,8:103-111, </volume> <year> 1990. </year>
Reference-contexts: The Parallel-Design Distributed-Implementation (PDDI) machine scheme of [Vi-84], and the position paper [Vi-83] advocate 6 that software and algorithms people work on the PRAM as a programmer's model, while machine builders focus separately on implementing the PRAM. Valiant <ref> [Va90a] </ref> and [Va90b] used the term "bridging model" for describing a whole spectrum of possibilities for such a programmer's model. (The general idea of trading algorithm-parallelism for more effective implementation has also been discussed in these four papers.) Such a "divide-and-conquer" strategy also led to Fortran 90, the new computer language
Reference: [Va90b] <author> L.G. Valiant. </author> <title> General purpose parallel architectures. In Handbook of Theoretical Computer Science: Volume A, Algorithms and Complexity (Editor J. </title> <editor> van Leeuwen), </editor> <publisher> MIT Press/Elsevier, </publisher> <year> 1990, </year> <pages> pages 942-971. </pages>
Reference-contexts: The Parallel-Design Distributed-Implementation (PDDI) machine scheme of [Vi-84], and the position paper [Vi-83] advocate 6 that software and algorithms people work on the PRAM as a programmer's model, while machine builders focus separately on implementing the PRAM. Valiant [Va90a] and <ref> [Va90b] </ref> used the term "bridging model" for describing a whole spectrum of possibilities for such a programmer's model. (The general idea of trading algorithm-parallelism for more effective implementation has also been discussed in these four papers.) Such a "divide-and-conquer" strategy also led to Fortran 90, the new computer language international standard
Reference: [Vi-83] <author> U. Vishkin. </author> <title> Synchronous parallel computation a survey. </title> <type> Technical Report TR 71, </type> <institution> Dept. of Computer Science, Courant Institute, </institution> <address> New York University, </address> <year> 1983. </year>
Reference-contexts: Note that some of these publications consider as efficient only algorithms whose running time is poly-logarithmic (i.e., asymptotically bounded by a polynomial in the logarithm of the problem size). Our notion of algorithm efficiency, which is exactly the same as in an 1983 position paper <ref> [Vi-83] </ref>, categorically prefers poly-logarithmic time parallel algorithms to slower parallel algorithms only if their work complexity (i.e., total number of operations) is not larger. We view the fact that many of the known techniques provide poly-logarithmic running time as circumstantial (though, remarkable). * By default. <p> We refer the reader to [Vi-91b] for more details and references. 6 Conclusion A "divide-and-conquer" strategy to the advancement of parallel computing has been suggested in several theoretical and practical publications. The Parallel-Design Distributed-Implementation (PDDI) machine scheme of [Vi-84], and the position paper <ref> [Vi-83] </ref> advocate 6 that software and algorithms people work on the PRAM as a programmer's model, while machine builders focus separately on implementing the PRAM.
Reference: [Vi-84] <author> U. Vishkin. </author> <title> A parallel-design distributed-implementation (PDDI) general purpose computer. </title> <journal> Theoretical Computer Science, </journal> <volume> 32 </volume> <pages> 157-172, </pages> <year> 1984. </year>
Reference-contexts: We summarize in one paragraph a relationship between algorithm-parallelism and this well-studied kind of hardware-parallelism. The following observation, which is due to the companion papers [MV-84] and <ref> [Vi-84] </ref>, discusses this relationship. The PRAM model can be formally emulated, in an efficient manner, by a synchronous distributed computer, where each processor is connected to a small number of others in a fixed pattern. <p> We refer the reader to [Vi-91b] for more details and references. 6 Conclusion A "divide-and-conquer" strategy to the advancement of parallel computing has been suggested in several theoretical and practical publications. The Parallel-Design Distributed-Implementation (PDDI) machine scheme of <ref> [Vi-84] </ref>, and the position paper [Vi-83] advocate 6 that software and algorithms people work on the PRAM as a programmer's model, while machine builders focus separately on implementing the PRAM.
Reference: [Vi-91a] <author> U. Vishkin. </author> <title> Structural parallel algorithmics. </title> <booktitle> In Proc. of the 18th Int. Colloquium on Automata, Languages and Programming, </booktitle> <pages> pages 363-380, </pages> <year> 1991, </year> <booktitle> Lecture Notes in Computer Science 510, </booktitle> <publisher> Springer-Verlag. </publisher> <pages> 8 </pages>
Reference-contexts: The possibility of a more evolutionary (and less revolutionary) shift towards effective use of hardware-parallelism is also presented. * Successful theory. A knowledge-base of algorithm-parallelism of considerable extent has been developed. Several books, [Akl-89], [GR-88], [J-92] and [R-92], and a few review papers, [EG-88], [KR-90], [KRS-90] and <ref> [Vi-91a] </ref>, attest to a unique and comprehensive knowledge-base of PRAM algorithms, methods, techniques and paradigms. Note that some of these publications consider as efficient only algorithms whose running time is poly-logarithmic (i.e., asymptotically bounded by a polynomial in the logarithm of the problem size).
Reference: [Vi-91b] <author> U. Vishkin. </author> <title> Can parallel algorithms enhance serial implementation? TR-91-145, </title> <institution> University of Maryland Institute for Advanced Computer Studies (UMIACS), College Park, Maryland 20742-3251, </institution> <year> 1991. </year> <month> 9 </month>
Reference-contexts: Later, we provide a more general definition of machine-parallelism. It is argued that: (1) only few (if any) new and future computers are likely to escape this definition, and (2) algorithm-parallelism relates to effective use of this wider concept of machine-parallelism as well. Therefore, the recent paper <ref> [Vi-91b] </ref> argues that there are more reasons for considering algorithm-parallelism than merely its relationship with massive processor-parallelism. <p> at least forty years, to conceive of computers as literally serial; such textbooks are not to blame, of course, since software for currently widely available machines does not enable the typical user to express parallelism. * Parallel algorithms can be exploited to make more effective use of machine-parallelism; the paper <ref> [Vi-91b] </ref> demonstrates how to use parallel algorithms for prefetching from slow memories (using pipelining); other means include using the parallelism offered by VLIW; there, a CPU can process simultaneously several operands and potentially provide the same effect as having separate processors working in parallel on these operands. <p> As was explained above, the multi-stage approach does not mean to replace the effort for building massively parallel machines, but rather augment it, since both approaches share the same ultimate goal. We refer the reader to <ref> [Vi-91b] </ref> for more details and references. 6 Conclusion A "divide-and-conquer" strategy to the advancement of parallel computing has been suggested in several theoretical and practical publications.
References-found: 22

