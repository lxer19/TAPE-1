URL: http://www.robotics.stanford.edu/~koller/papers/aaai96kh.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/aaai96kh.html
Root-URL: http://www.robotics.stanford.edu
Email: koller@cs.stanford.edu  halpern@almaden.ibm.com  
Title: Irrelevance and Conditioning in First-Order Probabilistic Logic  
Author: Daphne Koller Joseph Y. Halpern 
Address: Gates Building 1A Stanford, CA 94305-9010  650 Harry Road San Jose, CA 95120-6099  
Affiliation: Computer Science Department  IBM Almaden Research Center  
Abstract: First-order probabilistic logic is a powerful knowledge representation language. Unfortunately, deductive reasoning based on the standard semantics for this logic does not support certain desirable patterns of reasoning, such as indifference to irrelevant information or substitution of constants into universal rules. We show that both these patterns rely on a first-order version of probabilistic independence, and provide semantic conditions to capture them. The resulting insight enables us to understand the effect of conditioning on independence, and allows us to describe a procedure for determining when independencies are preserved under conditioning. We apply this procedure in the context of a sound and powerful inference algorithm for reasoning from statistical knowledge bases. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bacchus, F.; Grove, A. J.; Halpern, J. Y.; and Koller, D. </author> <year> 1994. </year> <title> From statistical knowledge bases to degrees of belief. </title> <type> Technical Report 9855, </type> <institution> IBM. </institution> <note> To appear, Artificial Intelligence. Available via WWW at http://logos.uwaterloo.ca. A preliminary version appears in IJCAI '93, pages 563-569. </note>
Reference-contexts: Irrelevant information: If, in addition to KB fly , we also learn that Red (Tweety). We might hope to ignore the seemingly irrelevant information Red (Tweety) and still conclude that Pr (Fly (Tweety)) = 0:9. <ref> (Bacchus et al. 1994) </ref> presents one approach, called ran-dom worlds, to dealing with this problem: Start with a uniform prior over the set of possible worlds, condition on the knowledge base KB , and use the resulting posterior distribution 0 jKB to form degrees of belief. <p> So is the distribution 0 presented in Example 4.1. Thus, we have a large space in which we can look for a prior that would give us the benefits of the uniform prior without some of its disadvantages. For example, a rather general theorem was proved in <ref> (Bacchus et al. 1994) </ref> from which direct inference and preference for more specific information followed quite easily. The following result is a restatement of that theorem, but for arbitrary fully independent and exchangeable prior distributions, rather than just the uniform prior. <p> Since we know Bird (Tweety), and the formulas k are mutually exclusive and exhaustive, the desired conclusion follows easily. <ref> (Bacchus et al. 1994) </ref> also presents a theorem dealing with the treatment of irrelevant information. Similar arguments allow us to generalize that theorem, showing that it holds for all fully independent and exchangeable priors. <p> In particular, jKB j= Pr (Fly (Tweety)) = 0:9 ^ Pr (Has-Wings (Tweety)) = 0:99 ^ Pr (Domesticated (Tweety)) = 0:05. Note that, due to the complexity of this knowledge base, none of these conclusions follow from the <ref> (Bacchus et al. 1994) </ref> theorems. If we now condition on Antarctic (Tweety), we add an edge between Antarctic and Tweety. This creates a path from Tweety to Fly that is not blocked by Bird.
Reference: <author> Bacchus, F.; Grove, A. J.; Halpern, J. Y.; and Koller, D. </author> <year> 1995. </year> <title> Reasoning with noisy sensors in the situation calculus. </title> <booktitle> In Proc. Fourteenth International Joint Conference on Artificial Intelligence (IJCAI '95), </booktitle> <pages> 1933-1940. </pages>
Reference-contexts: As we show below, full independence and exchangeability are the only properties of the uniform prior that are required to prove these properties. It follows that these results actually hold for a large class of priors. For example, the random-propensities distribution considered in <ref> (Bacchus et al. 1995) </ref> is also fully independent and exchangeable. So is the distribution 0 presented in Example 4.1. Thus, we have a large space in which we can look for a prior that would give us the benefits of the uniform prior without some of its disadvantages.
Reference: <author> Bacchus, F. </author> <year> 1990. </year> <title> Representing and Reasoning with Probabilistic Knowledge. </title> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction First-order logic is widely recognized as being a fundamental building block in knowledge representation. As is well known, however, first-order logic does not have the necessary expressive power to deal with many situations of interest <ref> (Bacchus 1990) </ref>. For example, while first-order logic allows us to express statements like all birds fly, it does not allow us to assert in a natural way that most birds fly, or that any given bird is likely but not certain to fly.
Reference: <author> De Finetti, B. </author> <year> 1964. </year> <title> Foresight: Its logical laws, its subjective sources. </title> <editor> In Kyburg, Jr., H. E., and Smokler, H., eds., </editor> <title> Studies in Subjective Probability. </title> <publisher> Wiley. </publisher>
Reference: <author> Garson, J. W. </author> <year> 1977. </year> <title> Quantification in modal logic. </title> <editor> In Gabbay, D., and Guenthner, F., eds., </editor> <booktitle> Handbook of Philosophical Logic, </booktitle> <volume> Vol. II. </volume> <publisher> Reidel. </publisher> <pages> 249-307. </pages>
Reference-contexts: In classic first-order logic, the following axiom is valid: 8x'(x) ) '(c), where c is a constant. It is well known that in modal logics, this substitution property does not hold in general <ref> (Garson 1977) </ref>. Assume we are told, as above, that 8x (Pr (Fly (x) j Bird (x) = 0:9). <p> Exchangeability implies that Pr ('(d) j (d)) is the same for all d, a property which simplifies many of our results. 3 Irrelevance and Substitution Recall that we are primarily interested in the property of irrelevance. Assume that we are given a distribution that sat 2 As is well-known <ref> (Garson 1977) </ref>, in modal logic we run into problems with quantifying-in if we do not make this assumption.
Reference: <author> Halpern, J. Y. </author> <year> 1990. </year> <title> An analysis of first-order logics of probability. </title> <booktitle> Artificial Intelligence 46 </booktitle> <pages> 311-350. </pages>
Reference-contexts: The definition is fairly standard (see <ref> (Halpern 1990) </ref>). For example, (M; w; v) j= 8x (Pr ('(x) ff) if for all d 2 D, (M; w; v [x=d]) j= Pr ('(x)) ff), where the numerical term Pr ('(x)) is interpreted as (fw : (M; w; v [x=d]) j= '(x)g). <p> Hence, the outcomes must be related. To generalize this argument, we first introduce some notation. As in <ref> (Halpern 1990) </ref>, we augment first-order logic with a statistical quantifier. Formally, we allow proportion expressions of the form jj (x)jj x . This is interpreted as a rational number between 0 and 1, that represents the proportion (or fraction) of domain elements satisfying (x).
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: To obtain these patterns of reasoning, we must restrict attention to those models that support them. To accomplish this, we must first understand the underlying semantics of these reasoning patterns; i.e., when do we get them and why? This theme also appears in the work on belief networks <ref> (Pearl 1988) </ref>, which utilize independence to obtain a concise and intuitive representation of a probability distribution. The power and convenience of Bayesian networks has resulted in a resurgence of work on using probability as a knowledge representation paradigm and has led to a large number of applications. <p> This representation allows a simple procedure for answering a wide range of independence queries. Our representation utilizes a standard tool from the literature: Markov networks <ref> (Pearl 1988) </ref>. A Markov network is an undirected graph G that encodes the independencies that hold for a distribution . <p> Intuitively, G encodes the fact that A can only influence B via C. Hence, if we fix a particular interpretation for the symbols in C, the symbols in B can no longer influence A. We say that G is an independency mapping (I-map) for <ref> (Pearl 1988) </ref> if, whenever C separates A from B in G, the distribution makes the interpretations of the symbols in A conditionally independent of the interpretations of the symbols in B given an interpretation for the symbols in C. <p> Then the graph G 0 obtained by adding edges between all the nodes in A is an I-map for jE. Unlike many of the results on Markov networks (particularly those discussed in <ref> (Pearl 1988) </ref>), this result does not require the distribution to be positive (i.e., be such that (w) &gt; 0 for every world w).
Reference: <author> Reichenbach, H. </author> <year> 1949. </year> <title> The Theory of Probability. </title> <institution> University of California Press, Berkeley. </institution>
Reference: <editor> Sowa, J., ed. </editor> <booktitle> 1991. Principles of Semantic Networks. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Touretzky, D. S. </author> <year> 1986. </year> <title> The Mathematics of Inheritance Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: As we now demonstrate, this approach allows us to deal with quite complex knowledge bases. Example 7.3: Figure 1 is a graphical representation of a statistical knowledge base KB. The dark unlabeled arrows denote is-a arrows <ref> (Touretzky 1986) </ref>; for example, the edge between Tweety and Bird corresponds to the statement Bird (Tweety), while the edge between Bird and Animal corresponds to 8x (Bird (x) ) Animal (x)).
References-found: 10

