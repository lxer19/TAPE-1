URL: http://www.csl.sri.com/~livio/conpar94.ps.Z
Refering-URL: http://www.csl.sri.com/~livio/papers.html
Root-URL: 
Title: The Rewrite Rule Machine Node Architecture and its Performance*  
Author: Patrick Lincoln, Jos Meseguer, and Livio Ricciulli 
Address: Menlo Park, CA 94025, USA  
Affiliation: Computer Science Laboratory, SRI International,  
Abstract: The Rewrite Rule Machine (RRM) is a massively parallel MIMD/SIMD computer designed with the explicit purpose of supporting very- high-level parallel programming with rewrite rules. The RRM's node architecture consists of a SIMD processor, a SIMD controller, local memory, and network and I/O interfaces. A 64-node cluster board is already an attractive RRM system capable of extremely high performance on a variety of applications. A cluster is SIMD at the node level, but it is MIMD at the system level to flexibly exploit the parallelism of complex nonhomogeneous applications. In addition to reporting detailed simulation experiments used to validate the node design, we measure the performance of an RRM cluster on three relevant applications. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> H. Aida, J. Goguen, S. Leinwand, P. Lincoln, J. Meseguer, B. Taheri, and T. Winkler. </author> <title> "Simulation and Performance Estimation for the Rewrite Rule Machine". </title> <booktitle> In Proceedings of the Fourth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 336344. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Later, we justify this choice of configuration in more detail. Ensemble Our SIMD processor, called an ensemble, fits on a single die. The ensemble has been the object of extensive studies in the past <ref> [1, 3, 14] </ref> and its topology and architecture are based on the results of extensive theoretical and experimental research. For expository purposes we summarize the main characteristics of the ensemble. The ensemble contains a 12x12 grid of buses and a controller (Fig. 3a).
Reference: 2. <author> H. Aida, J. Goguen, and J. Meseguer. </author> <title> "Compiling Concurrent Rewriting onto the Rewrite Rule Machine". </title> <editor> In S. Kaplan and M. Okada, editors, </editor> <title> Conditional and Typed Rewriting Systems, </title> <address> Montreal, Canada, </address> <month> June </month> <year> 1990, </year> <pages> pages 320332. </pages> <publisher> Springer LNCS 516, </publisher> <year> 1991. </year>
Reference-contexts: The simplicity of our hardware somewhat increases software complexity, but this allows integration of message-passing and shared-memory communication schemes in a more natural way than in other shared-memory designs [10,13] . We have developed two compilers mapping rewrite rules to parallel RRM code <ref> [2, 15] </ref>. The latest compiler exhibits efficiencies within 20% of the corresponding hand-compiled codes. Given the great flexibility of the concurrent rewriting model, we believe that it is possible to compile and parallelize conventional code on the RRM with reasonable ease and efficiency.
Reference: 3. <author> H. Aida, S. Leinwand, and J. Meseguer. </author> <title> "Architectural Design of the Rewrite Rule Machine Ensemble. </title> <editor> In J. Delgado-Frias and W.R. Moore, editors, </editor> <title> VLSI for Artificial Intelligence and Neural (D)ARPA Image Understanding Benchmark for Parallel Computers Low- and Intermediate-Phase Cumulative Execution Times Connected Comp. </title> <editor> Rectangle Detection Total 23.07 27.43 13.92 78.25 85.85 20.97 0.5 1.76 0.0157 0.0003 0.0686 0.0898 Sun-4 FX80/8 Seq81/8 Warp CM2/64k ASP IUA RRM/128 (Sec.) Fig. </editor> <booktitle> 10 Networks, </booktitle> <pages> pages 1122. </pages> <publisher> Plenum Publ. Co., </publisher> <year> 1991. </year> <booktitle> Proceedings of an International Workshop held in Oxford, </booktitle> <address> England, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Later, we justify this choice of configuration in more detail. Ensemble Our SIMD processor, called an ensemble, fits on a single die. The ensemble has been the object of extensive studies in the past <ref> [1, 3, 14] </ref> and its topology and architecture are based on the results of extensive theoretical and experimental research. For expository purposes we summarize the main characteristics of the ensemble. The ensemble contains a 12x12 grid of buses and a controller (Fig. 3a).
Reference: 4. <author> Davis E., Arnold J., Buell D. </author> <title> "SPLASH-2". </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1992. </year>
Reference-contexts: The current RRM compiler will be extended to handle a wider class of rewrite rules and will be enriched with optimization techniques. In addition, a hardware prototype of the SIMD processor will be built using the SPLASH-2 FPGA system <ref> [4] </ref>. Acknowledgments We are saddened by the untimely loss of our colleague and friend Dr. Sany Leinwand. Sany contributed much to the RRM project; particularly to its architecture, simulation, and VLSI aspects. We gratefully thank Prof.
Reference: 5. <author> K. </author> <title> Batcher. </title> <booktitle> "The Architecture of Tomorrow's Massively Parallel Computer". In Frontiers of Massively Parallel Scientific Computing, </booktitle> <month> September </month> <year> 1986. </year> <note> NASA CP 2478. </note>
Reference-contexts: Several other features of the RRM are novel in combination, although most have been seen in earlier machine designs in isolation. As a concrete comparison, Goodyear/NASA MPP <ref> [5] </ref> has local connections between large numbers of (1-bit) cells; however, cells have minimal computational power and there is no support for indirect addressing. The CM-1 and CM-2 architectures are also composed of SIMD-controlled 1-bit cells and in addition have floating point hardware support.
Reference: 6. <author> T. Blank. </author> <title> "The MasPar MP-1 architecture". </title> <booktitle> In CompCon 1990, </booktitle> <year> 1990. </year>
Reference-contexts: The vector units could be thought of as a very limited form of SIMD computational agents, but they require significant hand-coded software support and are not designed for symbolic computation. The MasPar line of architectures <ref> [6] </ref> is another modern SIMD design with some similarity to the RRM. The MasPar architectures utilize 4-bit computational cells which are smaller and can store less than RRM cells.
Reference: 7. <author> C.Weems, E. Riseman, and A. Hanson. </author> <title> "The DARPA Image Understanding Benchmark for Parallel Computers". </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11(1), </volume> <year> 1991. </year>
Reference-contexts: 30 35 Problem Size (Thousands of Gates) RRM Execution Time (ms) 1 4 64 1080 8528 1152 3037 3547 14100 132250 7.05 9.1 119.74 Nodes Problem Size RRM Time (ms) SPARC-10 Time (ms) Speedup Gate-Level Hardware Simulator Fig. 9 Fig. 10 contains the reported execution times of several parallel machines <ref> [7] </ref> with the addition of the RRM performance. Notice that the RRM favorably compares with even the fastest reported simulated execution times that are based on massive special-purpose signal processing designs.
Reference: 8. <author> Veidenbaum A. Gornish E., Granston E. </author> <title> "Compiler-directed data prefetching in multiprocessors with memory hierarchies". </title> <booktitle> In Proceedings of the 1990 International Conference on Supercomputing, </booktitle> <year> 1990. </year>
Reference: 9. <author> H. Schwetman "Csim: </author> <title> A c-based, process-oriented simulation language". </title> <type> MCC Technical Report. </type>
Reference-contexts: A register transfer-level simulator of an RRM cluster has been implemented. The simulator holds a very detailed description of all the hardware down to the register level; it uses the libraries provided by the general-purpose simulation package Csim <ref> [9] </ref>. This package is an extension of the C language that allows very efficient processoriented event-driven simulations. Each device of each node is a separate process that interfaces with other processes through synchronization lines (events) and hardware queues (mailboxes).
Reference: 10. <author> Gupta A., Heinlein J., Gharachorloo K. </author> " <title> Integrating Multiple Communication Paradigms in High Performance Multiprocessors". </title> <type> Technical Report CSL-TR-94-604, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1994. </year>
Reference: 11. <editor> R. Keller and J. Fasel, editors. </editor> <booktitle> Proc. Workshop on graph reduction, </booktitle> <address> Santa Fe, New Mexico. </address> <publisher> Springer LNCS 279, </publisher> <year> 1987. </year>
Reference: 12. <author> Levy H., Klaiber A. </author> <title> "An architecture for Software-controlled Data Prefetching". </title> <booktitle> In International Symposium on Computer Architecture 1991, </booktitle> <volume> volume 19-3, </volume> <month> May </month> <year> 1991. </year>
Reference: 13. <author> Agarwal A., Kubiatowicz J. </author> <title> "Anatomy of a Message in the Alewife Multiprocessor". </title> <booktitle> In Proceedings of the 7th ACM International Conference on Supercomputing, </booktitle> <year> 1994. </year>
Reference: 14. <author> S. Leinwand, J.A. Goguen, and T. Winkler. </author> <booktitle> "Cell and Ensemble Architecture for the Rewrite Rule Machine" In Proceedings of the International Conference on Fifth Generation Computer Systems 1988, </booktitle> <address> Tokyo, Japan, </address> <pages> pages 869878. </pages> <publisher> ICOT, </publisher> <year> 1988. </year>
Reference-contexts: Later, we justify this choice of configuration in more detail. Ensemble Our SIMD processor, called an ensemble, fits on a single die. The ensemble has been the object of extensive studies in the past <ref> [1, 3, 14] </ref> and its topology and architecture are based on the results of extensive theoretical and experimental research. For expository purposes we summarize the main characteristics of the ensemble. The ensemble contains a 12x12 grid of buses and a controller (Fig. 3a).
Reference: 15. <author> P. Lincoln, N. Mart-Oliet, J. Meseguer, and L. Ricciulli. </author> <title> "Compiling Rewriting onto SIMD and MIMD/SIMD Machines". </title> <note> To Appear in PARLE'94, </note> <year> 1994. </year>
Reference-contexts: Rewrite rules are surprisingly well-suited to massively parallel computation. The most striking architectural advantage of using rewrite rules for parallel computation is that proper compilation techniques can greatly reduce the need for synchronization <ref> [15] </ref>. Consistent with our framework, rewrite rules allow our design to favor a solution that exposes the underlying architecture to satisfy synchronization requirements through applicationspecific software primitives. <p> The simplicity of our hardware somewhat increases software complexity, but this allows integration of message-passing and shared-memory communication schemes in a more natural way than in other shared-memory designs [10,13] . We have developed two compilers mapping rewrite rules to parallel RRM code <ref> [2, 15] </ref>. The latest compiler exhibits efficiencies within 20% of the corresponding hand-compiled codes. Given the great flexibility of the concurrent rewriting model, we believe that it is possible to compile and parallelize conventional code on the RRM with reasonable ease and efficiency.
Reference: 16. <author> P. Lincoln, N. Mart-Oliet, and J. Meseguer. </author> <title> "Specification, Transformation and Programming of Concurrent Systems in Rewriting Logic". </title> <editor> G. Belloch, K. M. Chandy, and S. Jagannathan (editors), </editor> <booktitle> Proceedings of the DIMACS Workshop on Specification of Parallel Algorithms, </booktitle> <publisher> American Mathematical Society, </publisher> <address> Providence, RI, </address> <year> 1994. </year>
Reference-contexts: However, when generalized adequately [18,16], rewrite rules are not limited to functional computations. They can express with similar ease many other parallel but nonfunctional applications. As explained in <ref> [16] </ref>, concurrent rewriting gives rise to a machine-independent parallel language Maude [19,16] in which a very wide range of parallel applications can be easily expressed in a very high level, declarative way. Maude supports three different types of rewriting: *Supported by Office of Naval Research Contract N00014-92-C-0222. Term Rewriting.
Reference: 17. <author> Active Memory Technology LTD. </author> <title> "Introducing the DAP/cp8 Range". DAP Series Technical Overview, </title> <month> April </month> <year> 1990. </year> <note> Sales Support Note 7. </note>
Reference-contexts: One can think of the SIMD processors as a self-modifiable programmable active store, and of the data memory as conventional passive memory. This organization blurs the distinction between the computational agent and memory, and thus limits the negative effects of random memory access <ref> [17] </ref>. As displayed in Fig. 1, the RRM is a 7-tiered hierarchical architecture. The most basic unit is a 16-bit processing element with 16 registers called a cell.
Reference: 18. <author> J. Meseguer. </author> <title> "Conditional Rewriting Logic as a Unified Model of Concurrency". </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 96(1):73155, </address> <year> 1992. </year>
Reference: 19. <author> J. Meseguer. </author> <title> "A logical Theory of Concurrent Objects and Its Realization in the Maude Language. </title> <editor> In Gul Agha, Peter Wegner, and Akinori Yonezawa, editors, </editor> <booktitle> Research Directions in Concurrent Object-Oriented Programming, </booktitle> <pages> pages 314390. </pages> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference: 20. <author> Microprocessor and Microcomputer Standards Subcommittee. </author> <title> "IEEE standard for scalable coherent interface". IEEE Standard, </title> <year> 1992. </year>
Reference-contexts: Details of the cluster interconnection topology have not yet been decided; for simulation purposes we model the node-to-node interconnection network as a point-to-point 500-Mbyte/s bidirectional 2-D mesh. We have derived the topology, the link controller architecture and the bandwidth estimates (500 Mbyte/s) from the IEEE SCI standard 1596-1992 <ref> [20] </ref>.
Reference: 21. <author> S. Peyton-Jones. </author> <booktitle> "The Implementation of Functional Programming Languages". </booktitle> <publisher> Prentice Hall, </publisher> <year> 1987. </year>
Reference: 22. <author> Sen S. Scherson I. </author> <title> "Parallel Sorting in Two-Dimensional VLSI Models of Computation. </title> <journal> IEEE Transactions on Computers, </journal> <month> Feb </month> <year> 1989. </year>
Reference-contexts: However, since our communication assumptions are based on existing off-the-shelf technologies, the performance estimates derived from the present simulation experiments are well-grounded. 3.1 Performance Estimates Sorting was implemented with a new version of the Shear Sort algorithm <ref> [22] </ref>. Even though our particular implementation is architecture-dependent, the ideas we used can be easily extended to other architectures offering good connectivity of their computational agents. <p> We have found that the register usage to hold long range pointers is fully justified by performance improvements. Another important improvement t o t h e a l gor i t hm di s - cussed in <ref> [22] </ref> is the fact of keeping a sublist of el 40 80 120 160 200 240 RRM/SPARC-10 Speedup Problem Size (Thousands of 16 Bit Integers) 0 1000 2000 0 50 100 150 200 250 300 SPARC-10 Execution Time (ms) Problem Size (Thousands of 16-Bit Integers) 0 1 3 5 7 9
Reference: 23. <author> T. von Eicken, D. Culler, S.C. Goldsten, and H.E. Schauser. </author> " <title> Active Messages: a Mechanism for Integrated Communication and Computation". </title> <booktitle> In Proceedings of the 19th International Symposium of Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Our design supports both the shared memory and message-passing communication schemes; shared memory consistency is entirely maintained with barrier synchronization mechanisms and test and set operations, while message passing is supported with a very simple active message scheme <ref> [23] </ref>. The simplicity of our hardware somewhat increases software complexity, but this allows integration of message-passing and shared-memory communication schemes in a more natural way than in other shared-memory designs [10,13] . We have developed two compilers mapping rewrite rules to parallel RRM code [2, 15].
Reference: 24. <editor> C. Weems, E. Riseman, A. Hanson, and A. Rosenfeld. </editor> <booktitle> "IU Parallel Processing Benchmark." In Proceedings of the Computer Society Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1988. </year>
Reference-contexts: The largest example required a total of 64,592 connections between gates of which 68% (44195) required, at each time step, the use of the distant communication mechanisms. The DARPA Image Understanding Benchmark for Parallel Computers <ref> [24] </ref> is a good benchmark because it allows direct performance comparisons with other parallel machines and because it is composed of different phases which test different performance aspects of a design.
References-found: 24

