URL: ftp://ftp.research.microsoft.com/users/lomet/pub/privlock.ps
Refering-URL: http://www.research.microsoft.com/users/lomet/pub/default.htm
Root-URL: http://www.research.microsoft.com
Title: Private Locking and Distributed Cache Management  
Author: David Lomet 
Address: One Kendall Sq., Cambridge, MA 02139  
Affiliation: DEC Cambridge Research Lab  
Abstract: For a data sharing database system, substantial cost is incurred for global locking, to support both transactions and cache management. Replacing global locks with local locks managed by local lock managers offers the opportunity to substantially reduce locking overhead. To do this requires the exploitation of global covering locks. We discuss covering in general, and describe the conflicts required for both covering and intention locks. We then describe how to generate new covering and intention modes when logical and physical resources are equated in a data sharing system, hence reducing locking overhead. The new intention modes, because they conflict, permit cache management without losing fine grained concurrency. Fine grained concurrency with combined resources was not previously possible. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gray, J.N., Lorie, R. A., Putzulo, G. R., and Traiger, I. L. </author> <title> Granularity of locks and degrees of consistency in a shared data base. </title> <booktitle> IFIP Working Conf on Modeling of Data Base Management Systems (1976) 1-29. </booktitle>
Reference-contexts: A lock in mode S covers only other S mode locks on the same resource. It is also possible for a lock or locks to cover another lock even when the locks are on different resources. The classic example of this is multi-granularity locking (MGL) <ref> [1] </ref>. EXAMPLE: An X or S lock on a large granule, e.g. a file, that contains other smaller granularity resources, e.g. pages, covers and hence implicitly locks the smaller granules (pages) in the same mode. So the large granule lock conflicts with all incompatible locks on the smaller granules. <p> Typically, it is a simple lock conflict detector for uniquely identified resources, as described in <ref> [1] </ref>. The single level LM needs changed protocols in order to provide M GL lock covering. In this case, the requesting principal becomes responsible for observing the M GL protocol. The principal must instruct the local LM when a lock request can be granted locally.
Reference: [2] <author> Joshi, A. </author> <title> Adaptive locking strategies in a multi-node data sharing model environment. </title> <booktitle> Proc. Very Large Databases Conf.(Sept. 1991) Barcelona, Spain, </booktitle> <pages> 181-192. </pages>
Reference-contexts: Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery. <p> How strong the lock is, i.e. whether it is an intention lock or a covering lock, and how long the lock is held, especially if it is a covering lock, need to be carefully considered. One approach is described in <ref> [2] </ref>, though not using a local LM. The local LM can, when it is holding a covering lock on a higher resource, grant the requested lock locally. 3.3.2 Single Level LM A single level LM has no knowledge of the M GH. <p> This requires that the uncovered local locks be posted globally. If system lock overhead is too high, it can be reduced by making formerly global locks private via the acquisition of covering locks. Rdb/VMS <ref> [2] </ref>, for example, supports this capability of switching between covering and intention locks, but does not perform local locking. Instead, it uses the VMS cluster wide distributed lock manager (DLM) [12] for global locks.
Reference: [3] <author> Korth, H.F. </author> <title> Locking primitives in a database system. </title> <journal> Journal of the ACM 30,1 (Jan. </journal> <year> 1983) </year> <month> 55-79. </month>
Reference-contexts: We can thus choose whether intention locks conflict with each other. Table 1 illustrates that IX and IS do not conflict. This is usually desirable. In <ref> [3] </ref>, a general treatment of intention lock modes is given in which intention lock modes do not conflict. This is called maximally permissive. However, for cache management, having intention locks that conflict is very useful, as we shall see. <p> Combination lock compatibility is defined in the same way in <ref> [3] </ref>. Combination lock modes are used to permit a transaction to lock a single resource in more than one mode using a single lock. Here we apply compound or combination locks to permit us to lock multiple resources with a single lock. <p> Second, we have introduced intention locks that conflict with other intention locks. These are not "maximally permissive" in the sense defined in <ref> [3] </ref>. But their extra conflicts are exactly what permit us to manage a distributed cache with reduced lock overhead while preserving all the concurrency possible when using separate physical and logical resources. Current systems require that logical and physical resources be in separate hierarchies to achieve high concurrency.
Reference: [4] <author> Lomet, </author> <title> D.B. Recovery for shared disk systems using multiple redo logs. </title> <institution> Digital Equipment Corp. </institution> <type> Tech Report CRL90/4 (Oct. </type> <institution> 1990), Cambridge Research Lab, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system [2, 6, 8, 9, 10, 11] while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to <ref> [11, 5, 4, 8] </ref> for discussions of recovery.
Reference: [5] <author> Lomet, D., Anderson, R., Rengarajan, T. and Spiro, P. </author> <title> How the Rdb/VMS data sharing system became fast. </title> <institution> Digital Equipment Corp. </institution> <type> Tech Report CRL 92/4 (May, </type> <institution> 1992) Cambridge Research Lab, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system [2, 6, 8, 9, 10, 11] while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to <ref> [11, 5, 4, 8] </ref> for discussions of recovery.
Reference: [6] <author> Lomet, </author> <title> D.B. Private lock management. </title> <institution> Digital Equipment Corp. </institution> <type> Tech Report CRL 92/9 (Nov., </type> <institution> 1992) Cam-bridge Research Lab, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery. <p> It is usually possible to separate the lock management for the two components, even though we treat 1 IS-S is called R in <ref> [6] </ref>. 2 IX-X is called M in [6]. them as a combined resource. One can acquire and drop the locks on each component relatively independently. For example, to drop an X lock on a physical resource, one de-escalates, e.g., from IX-X to IX. <p> It is usually possible to separate the lock management for the two components, even though we treat 1 IS-S is called R in <ref> [6] </ref>. 2 IX-X is called M in [6]. them as a combined resource. One can acquire and drop the locks on each component relatively independently. For example, to drop an X lock on a physical resource, one de-escalates, e.g., from IX-X to IX. We do not provide all the lock modes for complete independence.
Reference: [7] <author> Lomet, </author> <title> D.B. Range locking strategies for improved concurrency. </title> <booktitle> Proc. Very Large Databases Conf.(Aug. 1993) Dublin, Ireland, </booktitle> <pages> 655-664. </pages>
Reference-contexts: Indeed, IX must conflict with X (S) because X (S) is a covering lock. The difficulty here is that X and S lock modes are being used both for covering and for exclusion. 4.3 Compound Lock Modes In <ref> [7] </ref>, we described how to reduce the number of locks needed when performing range locking by introducing compound lock modes. Here, we use compound lock modes for merged logical and physical resources. Our lock modes are pairs (LogicalM ode; P hysicalM ode). <p> U or update mode lock is also defined [8].) Compound lock modes (L 1 ; P 1 ) and (L 2 ; P 2 ) for locking compound resources are compatible if and only if L 1 is compatible with L 2 and P 1 is compatible with P 2 <ref> [7] </ref>. Combination lock compatibility is defined in the same way in [3]. Combination lock modes are used to permit a transaction to lock a single resource in more than one mode using a single lock. <p> We denote a compound lock mode as Logical Mode-Physical Mode. For example, IX-X locks the logical resource in mode IX and the physical resource in mode X. As with the range compound lock modes of <ref> [7] </ref>, only some of the combinations are useful. (Utility may change with the specifics of a locking protocol.) For our purposes here, we have no use for modes -S and -X (nil is the implied logical lock mode) as these hold pages in cache but do not permit either reading or
Reference: [8] <author> Mohan, C. and Narang, I. </author> <title> Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment. </title> <booktitle> Proc. Very Large Databases Conf.(Sept. 1991) Barcelona, Spain, </booktitle> <pages> 193-207. </pages>
Reference-contexts: Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery. <p> Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system [2, 6, 8, 9, 10, 11] while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to <ref> [11, 5, 4, 8] </ref> for discussions of recovery. <p> P hysicalM odes include X when exclusive access to a page is required, e.g. for writing, and S when shared access is sufficient, e.g. for reading, and nil, when the page is not being accessed. (Sometimes a U or update mode lock is also defined <ref> [8] </ref>.) Compound lock modes (L 1 ; P 1 ) and (L 2 ; P 2 ) for locking compound resources are compatible if and only if L 1 is compatible with L 2 and P 1 is compatible with P 2 [7]. <p> Because of recovery considerations, some UCP implementations require that moving pages be clean [11]. That is, the page is written to disk at the time that it moves between servers. This is not a concurrency control issue but clearly impacts cost. In fact, the UCP strategy can support what <ref> [8] </ref> refers to as the "Super-Fast" or "Fast" schemes which do not require writing the moving page to disk. <p> It is analogous to a conflicting lock request message, but here, the locks do not conflict, and hence lock de-escalation is not needed. Notification involv-ing compatible locks has not traditionally been part of LM functionality. We adapt the concept from <ref> [8] </ref>. 6 Discussion 6.1 New Lock Modes We have introduced two innovations in lock modes. First, we have defined lock modes that make it possible for a single request to acquire a lock that protects multiple resources, in our particular case a physical and a logical resource.
Reference: [9] <author> Mohan, C. and Narang, I. </author> <title> Efficient locking and caching of data in the multisystem shared disks transaction environment. </title> <booktitle> Int'l. Conf. on Extending Database Technology (Mar. </booktitle> <address> 1992) Vienna. </address>
Reference-contexts: Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery. <p> In particular, our new intention lock modes permit pages with uncommitted record updates to be shared, i.e., move between processor caches of the data sharing system. This capability is not present in the prior approach described in <ref> [9] </ref>. 2 Multi-granularity Lock Covering Implicit locks are those that are covered by currently held locks and are not materialized at an LM. A lock protocol must ensure that there be at least one resource at which conflicts involving implicit locks are materialized as conflicts between explicit locks. <p> A merged lock covers locks on all descendents, be they physical or logical. Thus, e.g., a file or table lock covers local physical and logical page locks as well as logical record locks. Merging of logical and physical pages was described in <ref> [9] </ref>, but dealing with entirely merged hierarchies is not treated there and potential concurrency is restricted. In particular, the merging of logical and physical pages resulted in the page being the smallest unit of granularity for resources that could be shared between nodes of the data sharing system. <p> Prior versions of UCP required either * separate physical and logical resources [11], with the extra overhead to lock both kinds of resources, or * that the smallest locked resource in the M GH be a page when pages moved between servers <ref> [9] </ref>, hence sacrificing fine grained concurrency. No record locking on moving pages means that these pages can not contain uncommitted updates. We describe how to achieve UCP using a merged M GH while supporting record level locking on moving pages.
Reference: [10] <author> Rahm, E. </author> <title> Empirical performance evaluation of con-currency and coherency control protocols for database sharing systems. </title> <journal> ACM Trans. </journal> <note> on Database Systems 18,2 (June 1993) 333-377. </note>
Reference-contexts: Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery.
Reference: [11] <author> Rengarajan, T., Spiro, P., and Wright, W. </author> <title> High availability mechanisms of VAX DBMS software. </title> <note> Digital Technical Journal 8, </note> <month> (Feb. </month> <year> 1989), </year> <pages> 88-98. </pages>
Reference-contexts: Shared Nothing: Each data partition is accessed by only a single server (at a time) [13]. When several partitions are accessed, two phase commit is needed. Cache and lock management are done locally by each partition server. Data Sharing: Multiple servers access shared data simultaneously <ref> [11] </ref>. A user can be assigned to any of these servers. Servers need to hold locks on shared data, both when active transactions need the data and when the data is cached at the servers. Such shared access requires distributed locking [12]. <p> Such shared access requires distributed locking [12]. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system <ref> [2, 6, 8, 9, 10, 11] </ref> while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to [11, 5, 4, 8] for discussions of recovery. <p> Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system [2, 6, 8, 9, 10, 11] while providing high concurrency. We do not treat the recovery aspects of data sharing systems. Readers should refer to <ref> [11, 5, 4, 8] </ref> for discussions of recovery. <p> The covering modes X and S have been used to coordinate page usage. However, when a merged M GH is being used, page level X and S locks cannot simply be released as they may be covering transactional record locks. Lock de-escalation deals with this difficulty <ref> [11] </ref>. Covering locks are replaced by intention locks and explicit locks are acquired at the next lower level in the M GH, e.g. on the records. <p> That is, a page being transferred can contain updates of uncommitted transactions. Because of recovery considerations, some UCP implementations require that moving pages be clean <ref> [11] </ref>. That is, the page is written to disk at the time that it moves between servers. This is not a concurrency control issue but clearly impacts cost. <p> In fact, the UCP strategy can support what [8] refers to as the "Super-Fast" or "Fast" schemes which do not require writing the moving page to disk. Prior versions of UCP required either * separate physical and logical resources <ref> [11] </ref>, with the extra overhead to lock both kinds of resources, or * that the smallest locked resource in the M GH be a page when pages moved between servers [9], hence sacrificing fine grained concurrency.
Reference: [12] <author> Snaman, W. </author> <title> et al The VAX/VMS distributed lock manager. </title> <note> Digital Technical Journal 5 (Sept. </note> <year> 1987) </year> <month> 29-44. </month>
Reference-contexts: Data Sharing: Multiple servers access shared data simultaneously [11]. A user can be assigned to any of these servers. Servers need to hold locks on shared data, both when active transactions need the data and when the data is cached at the servers. Such shared access requires distributed locking <ref> [12] </ref>. Our focus in this paper is on locking, and on how to reduce its overhead in a data sharing system [2, 6, 8, 9, 10, 11] while providing high concurrency. We do not treat the recovery aspects of data sharing systems. <p> Rdb/VMS [2], for example, supports this capability of switching between covering and intention locks, but does not perform local locking. Instead, it uses the VMS cluster wide distributed lock manager (DLM) <ref> [12] </ref> for global locks. Covered locks are remembered in each process (the principals of the system). 6.3 Other Opportunities Local locking and lock covering should find application in more areas than cache management in data sharing systems.
Reference: [13] <author> Stonebraker, M. </author> <title> The case for shared nothing. </title> <journal> IEEE Database Engineering Bulletin 9,1 (1986). </journal>
Reference-contexts: 1 Introduction 1.1 Data Sharing and Shared Nothing There are two primary flavors of distributed database systems. Shared Nothing: Each data partition is accessed by only a single server (at a time) <ref> [13] </ref>. When several partitions are accessed, two phase commit is needed. Cache and lock management are done locally by each partition server. Data Sharing: Multiple servers access shared data simultaneously [11]. A user can be assigned to any of these servers.
References-found: 13

