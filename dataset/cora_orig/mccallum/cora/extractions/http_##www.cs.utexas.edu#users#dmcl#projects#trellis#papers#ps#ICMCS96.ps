URL: http://www.cs.utexas.edu/users/dmcl/projects/trellis/papers/ps/ICMCS96.ps
Refering-URL: http://www.cs.utexas.edu/users/dmcl/projects/trellis/papers.html
Root-URL: http://www.cs.utexas.edu
Email: frajatm, diasg@watson.ibm.com ftewari, ving@cs.utexas.edu  
Title: Design and Performance Tradeoffs in Clustered Video Servers  
Author: Renu Tewariy Rajat Mukherjee Daniel M. Dias Harrick M. Viny T. J. 
Address: NY 10532 Austin, TX 78712  
Affiliation: IBM Research Division yDepartment of Computer Sciences  Watson Research Center University of Texas at Austin Hawthorne,  
Abstract: In this paper, we investigate the suitability of clustered architectures for designing scalable multimedia servers. Specifically, we evaluate the effects of: (i) architectural design of the cluster, (ii) the size of the unit of data interleaving, and (iii) read-ahead buffering and scheduling on the real-time performance guarantees provided by the server. To analyze the effects of these parameters, we develop an analytical model of clustered multimedia servers, and then validate it through extensive simulations. The results of our analysis have formed the basis of our prototype implementation based on a cluster of switch-connected RS/6000 machines. We briefly describe the prototype and discuss some implementation details. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.R. Attanasio, M. Butrico, C.A. Polyzois, S.E. Smith, and J.L. Peterson. </author> <title> Design and implementation of a recoverable virtual shared disk. </title> <institution> IBM Research Report RC-19843, </institution> <month> Novem-ber </month> <year> 1994. </year>
Reference-contexts: It is intuitive that EDF will perform better than FCFS for real-time requests. However, implementing EDF requires significant modifications to existing I/O subsystem software <ref> [1] </ref> that uses standard UNIX interfaces. If the arrival time of a request is proportional to its deadline, FCFS and EDF are nearly equivalent; however, due to a clustered architecture and switch delays, requests from different nodes may arrive out of order at the disk. <p> To provide for a single system image to the VOD application, in such a loosely coupled architecture, it is necessary that every node has an identical view of all the I/O resources in the cluster. This is provided by a layer of software called virtual shared disk (VSD) <ref> [1] </ref>, which is a software disk proxy that allows a remote I/O device to appear as if it was a local device.
Reference: [2] <author> S. Berson, S. Ghandeharizadeh, R. Muntz, and X. Ju. </author> <title> Staggered striping in multimedia information systems. </title> <booktitle> Proceedings of the 5th SIGMOD, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications. <p> Blocks of a video stream may either span all the disks in the system (referred to as wide striping) or may be confined to a smaller subset of disks (referred to as short striping). Wide striping implicitly achieves higher disk-arm bandwidth and load balancing <ref> [2, 9] </ref>, but is more susceptible to failure. Successive blocks of a video object may be allocated to disks either using a round-robin or random placement algorithm. As per the round-robin placement, successive blocks of a video stream are placed on consecutive disks.
Reference: [3] <author> M. M. Buddhikot, G. M. Parulkar, and J.R. Cox. </author> <title> Design of a large scale multimedia storage server. </title> <journal> Journal on Computer Networks and ISDN Systems, </journal> <year> 1995. </year>
Reference-contexts: Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications. Recently, there have been some research efforts for designing scalable video servers. An ATM switch based storage server is described in <ref> [3] </ref>. Similarly, Freedman and De-Witt [6] have described the SPIFFI video server. Whereas their model of a cluster is appropriate for a set of terminals connected to a group of processors, it is unsuited for geographically separated clients that do not possess information about server internals.
Reference: [4] <author> E. Chang and A. Zakhor. </author> <title> Scalable video data placement on parallel disk arrays. Proceedings of Storage and Retrieval for Image and Video Databases II, </title> <month> February </month> <year> 1994. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [5] <author> H.-J. Chen and T.D.C. Little. </author> <title> Physical storage organizations for time-dependent multimedia data. </title> <booktitle> Proceedings of the fourth international conf. on the foundations of data organizations and algorithms, </booktitle> <month> October </month> <year> 1993. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [6] <author> C. Freedman and D. DeWitt. </author> <title> The SPIFFI scalable video-on-demand server. </title> <booktitle> Proceedings of SIGMOD, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications. Recently, there have been some research efforts for designing scalable video servers. An ATM switch based storage server is described in [3]. Similarly, Freedman and De-Witt <ref> [6] </ref> have described the SPIFFI video server. Whereas their model of a cluster is appropriate for a set of terminals connected to a group of processors, it is unsuited for geographically separated clients that do not possess information about server internals.
Reference: [7] <author> D. Gross and C. M. Harris. </author> <title> Fundamentals of Queueing Theory. </title> <publisher> John Wiley and Sons, </publisher> <year> 1985. </year>
Reference-contexts: Each disk thus behaves like an M/D/1 queue, given that we are only interested in the tail of the distribution. From the results for an M/D/1 queue <ref> [7] </ref> we know the queue length distribution, p n , from which the delay distribution can be derived.
Reference: [8] <author> R. Haskin. </author> <type> Personal Communication, </type> <year> 1994. </year>
Reference-contexts: The read-ahead buffers are allocated from a shared memory segment, which is also used to cache the data read from disk using a simple LRU scheme <ref> [8] </ref>. Front-end nodes have a T1 adapter which connects the node to a set-top box via a T1 (1.53 Mbits/sec) line. The set-top box supports hardware MPEG decoding and plays the output to a TV set.
Reference: [9] <author> R. Haskin and F. L. Stein. </author> <title> A system for delivery of interactive television programming. </title> <booktitle> Proceedings of COMPCON, </booktitle> <month> Spring </month> <year> 1995. </year>
Reference-contexts: Blocks of a video stream may either span all the disks in the system (referred to as wide striping) or may be confined to a smaller subset of disks (referred to as short striping). Wide striping implicitly achieves higher disk-arm bandwidth and load balancing <ref> [2, 9] </ref>, but is more susceptible to failure. Successive blocks of a video object may be allocated to disks either using a round-robin or random placement algorithm. As per the round-robin placement, successive blocks of a video stream are placed on consecutive disks.
Reference: [10] <author> J. Hsieh, M. Lin, J.C.L. Liu, David D.C. Du, and T. M. Ruwart. </author> <title> Performance of a mass storage system for video-on-demand. </title> <booktitle> Proceedings of INFOCOM-1995, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [11] <author> J. Hsieh et.al. </author> <title> Performance of a mass storage system for video-on-demand. </title> <journal> Journal of parallel and distributed computing, </journal> <note> submitted. </note>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [12] <author> C.L. Liu and J.W. Layland. </author> <title> Scheduling Algorithms for Multiprogramming in a Hard Real-Time Environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1):46 - 61, </volume> <month> January </month> <year> 1973. </year>
Reference-contexts: Scheduling Effects We quantify the effects of different scheduling policies on the stream loss rates. Typical I/O device drivers assume a FCFS (First Come First Served) schedule. With EDF (Earliest Deadline First <ref> [12] </ref>), each stream request for a block needs to be tagged with a deadline, which is a function of the read-ahead buffer size and the play-out rate of the stream. It is intuitive that EDF will perform better than FCFS for real-time requests.
Reference: [13] <author> L.A. Rowe and B.C. Smith. </author> <title> A continous media player. </title> <booktitle> Proceedings of the 3rd Intl. NOSSDAV workshop, </booktitle> <month> November </month> <year> 1992. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [14] <author> H. Schwetman. </author> <title> CSIM Reference Manual (Revision 16). </title> <type> MCC Technical Report ACT-ST-252-87, </type> <institution> Microelectronics and Computer Technology Corporation, Austin, Texas 78759, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: More details of the configuration can be found in [15]. The arrival pattern of the streams is a distribution function handling various lengths of play with pause and resume requests. The simulation model is implemented using CSIM <ref> [14] </ref>, and Table 1 gives the default parameter values used. Description Default Front-End Processing Delay 8.192 msec. Back-End Processing Delay 8.96 msec. Block Size 256 KB Number of Streams 500 Stream Data Rate 0.2-0.5 MB/sec Processor Speed 100 MHz Switch Bandwidth 20MB/sec Switch setup overhead 2 msec.
Reference: [15] <author> R. Tewari, D. Dias, R. Mukherjee, and H. M. Vin. </author> <title> Real-time issues for a clustered multimedia server. </title> <note> IBM- Research Report - RC-20020, also available from http://www.cs.utexas.edu/users/dmcl, April 1995. </note>
Reference-contexts: Random placement policy adapts to incremental growth (adding disks and nodes) since redistribution is simple, but has more unpredictability in performance. A detailed comparison of these two policies can be found in <ref> [15] </ref>. For the purpose of the analysis presented in this paper, we will assume that the server employs wide striping and random placement policies. <p> We assume that the disks are zoned with different transfer rates per zone. The parameters selected for the switch are similar to a commercially available FCS product. More details of the configuration can be found in <ref> [15] </ref>. The arrival pattern of the streams is a distribution function handling various lengths of play with pause and resume requests. The simulation model is implemented using CSIM [14], and Table 1 gives the default parameter values used. Description Default Front-End Processing Delay 8.192 msec. Back-End Processing Delay 8.96 msec.
Reference: [16] <author> H.M. Vin and P.V. Rangan. </author> <title> Designing a multiuser hdtv storage server. </title> <journal> IEEE journal on selected areas of communications, </journal> <month> January </month> <year> 1993. </year>
Reference-contexts: Watson Research Center. a single node <ref> [2, 4, 5, 10, 11, 13, 16] </ref>. In such servers, however, the node becomes the bottleneck as it cannot sustain the bandwidth requirements of a large number of streams. Consequently, such servers cannot scale to support the number of streams required for high-end video-on-demand (VOD) type applications.
Reference: [17] <author> H.M. Vin, S.S. Rao, and P. Goyal. </author> <title> Optimizing the placement of multimedia objects on disk arrays. </title> <booktitle> Proceedings of the Second IEEE International Conference on Multimedia Computing and Systems, </booktitle> <address> Washington, D.C., </address> <pages> pages 158-165, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Even a small queue length results in long delays. This results in a smaller block size being favored. Figure 6 (a) shows the two phenomena for different block sizes. The tradeoff between disk thruput and delay variance results in an optimal block size <ref> [17] </ref>. We can compute the optimal block size from the delay distribution at the disk. The delay distribution and the service time distribution at the disk can be modified to be a function of the block size.
References-found: 17

