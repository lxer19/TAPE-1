URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-30.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The Mentat Computation Model Data-Driven Support for Object-Oriented Parallel Processing  
Author: Andrew S. Grimshaw 
Note: This work was partially supported by NASA grant NAG-1-1-1181 and NSF grant ASC-9201822.  
Abstract: Technical Report No. CS-93-30 May 28, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Abelson, G. J. Sussman, and J. Sussman, </author> <title> Structure and Interpretation of Computer Programs, </title> <publisher> The MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1985. </year>
Reference-contexts: The model guarantees that the actors that share state will be executed in mutual exclusion, that is, no two actors that share the same state will ever be executing simultaneously. (This can be modeled in stateless data-ow using a single state token and a non-deterministic merge operator <ref> [1] </ref>. Only one actor can possess the state token at a time, guaranteeing mutual exclusion.) Thus, the set of actors that share state combined with the state they share can be thought of as a monitor. <p> Although actors E and F are in the same program graph as A, they are not in As future, nor is A in their future. In many respects a future is like a parallel form of a continuation <ref> [1] </ref>. Both represent the remainder of the computation at a particular instant. The difference between a future and a continuation is that a future does not encapsulate an environment, and can only be used once, while a contin 3. MDF futures should not be confused with Multilisp futures [20]. <p> MDF futures should not be confused with Multilisp futures [20]. Multilisp futures represent a promise to deliver a value in the future. MDF futures represent the future of a computation, and have more in common with continuations <ref> [1] </ref>. Es future A D F As future 12 uation can be used again. In addition, continuations are sequential, while futures may be parallel. When an actor such as A receives its tokens, it receives with them a future.
Reference: [2] <author> T. Agerwala and Arvind, </author> <title> Data Flow Systems, </title> <journal> IEEE Computer, </journal> <volume> vol. 15, no. 2, </volume> <pages> pp. 10-13, </pages> <month> February, </month> <year> 1982. </year>
Reference: [3] <author> J. R. Allen, and K Kennedy, </author> <title> PFC: A Program to Convert FORTRAN to Parallel Form, </title> <booktitle> Proceedings of the IBM Conference on Parallel Computers and Scientific Computations, </booktitle> <address> Rome, </address> <year> 1982. </year>
Reference: [4] <author> G.S. Almasi and A. Gottlieb, </author> <title> Highly Parallel Computing, </title> <publisher> Benjamin/Cummings Publishing Co., </publisher> <address> Redwood City, CA., </address> <year> 1989. </year>
Reference: [5] <author> Arvind and J. D. Brock, </author> <title> Resource Managers in Functional Programming, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol.1, </volume> <pages> pp. 5-21, </pages> <year> 1984. </year>
Reference: [6] <author> R. F. Babb, </author> <title> Parallel Processing with Large-Grain Data Flow Techniques, </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 55-61, </pages> <month> July, </month> <year> 1984. </year>
Reference: [7] <author> B. Beck, </author> <title> Shared Memory Parallel Programming in C++, </title> <journal> IEEE Software, </journal> <pages> 7(4) pp. 38-48, </pages> <month> July, </month> <year> 1990. </year>
Reference-contexts: In general though, this is not the case. Non-determinism is not necessarily bad. There are in fact many correct non-deterministic applications. Concurrent database applications in particular are non-determinate. They do have a notion of correctness called consistency <ref> [7] </ref> based on the idea of transaction serializability. However, the enforcement of monitor properties alone on objects, as is done in MDF, is not sufficient to guarantee serializability.
Reference: [8] <author> A. Beguelin et al., </author> <title> HeNCE: Graphical Development Tools for Network-Based Concurrent Computing, </title> <booktitle> Proceedings SHPCC-92, </booktitle> <pages> pp. 129-136, </pages> <address> Williamsburg, VA, </address> <month> May, </month> <year> 1992. </year>
Reference: [9] <author> P. A. Bernstein, and N. Goodman, </author> <title> Concurrency Control in Distributed Database Systems, </title> <journal> ACM Computer Surveys, </journal> <pages> pp. 185-221, </pages> <note> vol. 13:2, </note> <month> June, </month> <year> 1981.J. </year>
Reference: [10] <author> Boyle et al., </author> <title> Portable Programs for Parallel Processors, </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [11] <author> J. C. Browne, T. Lee, and J. Werth, </author> <title> Experimental Evaluation of a Reusability-Oriented Parallel Programming Environment, </title> <journal> IEEE Transactions on Software Engineering, pp. </journal> <volume> 111-120, vol. 16, no. 2, </volume> <month> Feb., </month> <year> 1990. </year>
Reference: [12] <author> N. Carriero and D. Gelernter, </author> <title> Linda in Context, </title> <journal> Comm. of the ACM, </journal> <pages> pp. 444-458, </pages> <month> April, </month> <year> 1989. </year>
Reference: [13] <author> N. Carriero, and D. Gelernter, </author> <title> How to Write Parallel Programs: A Guide to the Perplexed, </title> <journal> ACM Computing Surveys, </journal> <pages> pp. 91-125, </pages> <note> vol. 23, num. 1, </note> <month> March. </month> <year> 1991. </year>
Reference: [14] <author> J. Dennis, </author> <title> First Version of a Data Flow Procedure Language, </title> <publisher> MIT TR-673, </publisher> <month> May, </month> <year> 1975. </year>
Reference-contexts: Mentat has been ported to six platforms, including networks of Sun 3s, Sun 4s, Silicon Graphics Irises, the Intel iPSC/2, the Intel iPSC/860, and the TMC CM-5. The high-level and applications performance aspects of Mentat have been presented elsewhere <ref> [14] </ref>[15][16]. In [14] we present an overview, the Mentat philosophy, the Mentat approach to parallel computing, and performance results.
Reference: [15] <author> G. </author> <title> Fox et al.,Solving Problems on Concurrent Processors Volume I, </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1988. </year>
Reference: [16] <author> A. S. Grimshaw, </author> <title> Easy to Use Object-Oriented Parallel Programming with Mentat, </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 39-51, </pages> <month> May, </month> <year> 1993. </year>
Reference-contexts: The high-level and applications performance aspects of Mentat have been presented elsewhere [14][15]<ref> [16] </ref>. In [14] we present an overview, the Mentat philosophy, the Mentat approach to parallel computing, and performance results. In [16] the performance of a range of applications with a range of speedups are explored; the results are promising, speedups are not only good -- they are competitive with hand-coded versions of the same applications.
Reference: [17] <author> A. S. Grimshaw, E. A. West, and W.R. Pearson, </author> <title> No Pain and Gain! - Experiences with Mentat on Biological Application, </title> <note> to appear in Concurrency: Practice & Experience, Vol. 5, issue 4, </note> <month> July, </month> <year> 1993. </year>
Reference-contexts: The RTS provides functions that instantiate new object instances, and perform token matching, run-time data-ow detection, run-time program graph construction, and actor elaboration. A RTS Libraries Executable object mplc C++ compiler MPL Source C++ 19 complete discussion of the RTS is given in <ref> [17] </ref>. We consider here three sets of services that the RTS provides, Mentat object back-end processes, mentat_object front-end classes, and the data-ow detection library.
Reference: [18] <author> A. S. Grimshaw, W. T. Strayer, and P. Narayan, </author> <title> Dynamic Object-Oriented Parallel Processing, to appear, </title> <booktitle> IEEE Parallel & Distributed Technology: Systems & Applications, </booktitle> <month> May, </month> <year> 1993. </year>
Reference: [19] <author> A. S. Grimshaw. </author> <title> The Mentat Run-Time System: Support for Medium Grain Parallel Com 28 putation. </title> <booktitle> Proceedings of the Fifth Distributed Memory Computing Conference, </booktitle> <pages> pp. 1064-1073. </pages> <address> Charleston, SC., </address> <month> April, </month> <year> 1990. </year>
Reference-contexts: That is called intra-object parallelism encapsulation; the caller only sees the member function invocation. There are four MPL extensions to C++: Mentat classes (both persistent and regular), the Mentat class member functions create () and destroy (), the mselect/maccept guarded statements, and the rtf () (return to future) function <ref> [19] </ref>. We will limit our discussion here to the most important of these with respect to parallelism, Mentat classes and rtf (). 4.1 Mentat Classes The most important extension to C++ is the keyword mentat as a prefix to class definitions, as shown on line 1 of Figure 9.
Reference: [20] <author> A. S. Grimshaw, and V. E. Vivas, </author> <title> FALCON: A Distributed Scheduler for MIMD Architectures, </title> <booktitle> Proceedings of the Symposium on Experiences with Distributed and Multiprocessor Systems, </booktitle> <pages> pp. 149-163, </pages> <address> Atlanta, GA, </address> <month> March, </month> <year> 1991. </year>
Reference-contexts: Both represent the remainder of the computation at a particular instant. The difference between a future and a continuation is that a future does not encapsulate an environment, and can only be used once, while a contin 3. MDF futures should not be confused with Multilisp futures <ref> [20] </ref>. Multilisp futures represent a promise to deliver a value in the future. MDF futures represent the future of a computation, and have more in common with continuations [1]. Es future A D F As future 12 uation can be used again.
Reference: [21] <author> A. S. Grimshaw, E. Loyot Jr., and J. Weissman, </author> <title> Mentat Programming Language (MPL) Reference Manual, </title> <institution> University of Virginia, Computer Science TR 91-32, </institution> <year> 1991. </year>
Reference: [22] <author> R. H. Halstead Jr., </author> <title> Multilisp: A Language for Concurrent Symbolic Computation, </title> <journal> ACM Transactions on Programming Languages and Systems, pp. </journal> <volume> 501-538, vol. 7, no. 4, Octo-ber, </volume> <year> 1985. </year>
Reference: [23] <author> C.A.R. Hoare, </author> <title> Communicating Sequential Processes, </title> <journal> Communications of the ACM, pp. </journal> <volume> 666-677, vol. 21, no. 8, </volume> <month> August, </month> <year> 1978. </year>
Reference: [24] <author> Inmos Ltd., </author> <title> Occam Programming Manual, </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1984. </year>
Reference: [25] <author> Intel Corporation, </author> <title> iPSC/2 USERS GUIDE, Intel Scientific Computers, </title> <address> Beaverton, OR, </address> <month> March </month> <year> 1988. </year>
Reference: [26] <author> D. Kuck, R. Kuhn, B. Leasure, D. Padua, and M. Wolfe, </author> <title> Dependence Graphs and Compiler Optimizations, </title> <booktitle> ACM Proceedings of the 8th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 207-218, </pages> <month> January, </month> <year> 1981. </year>
Reference: [27] <author> T. G. Lewis and H. El-Rewini, </author> <title> Introduction to Parallel Computing, </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1992. </year>
Reference: [28] <author> S. Mullender ed., </author> <title> Distributed Systems, </title> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference: [29] <author> A. </author> <title> Osterhaug GUIDE TO PARALLEL PROGRAMMING On Sequent Computer Systems, </title> <type> Sequent Technical Publications, </type> <institution> Sequent Computer Systems, Beaverton, </institution> <address> OR, </address> <year> 1989. </year>
Reference: [30] <author> C. M. Pancake and D. Bergmark, </author> <title> Do Parallel Languages Respond to the Needs of Scientific Programmers?, </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 13-23, </pages> <month> December, </month> <year> 1990. </year>
Reference: [31] <author> C. Polychronopoulos, </author> <title> Parallel Programming and Compilers, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference: [32] <author> M. J. Quinn, </author> <title> Designing Efficient Algorithms For Parallel Computers, </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [33] <author> V.S. Sunderam, </author> <title> PVM: A framework for parallel distributed computing, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 2(4), </volume> <pages> pp. 315-339, </pages> <month> December, </month> <year> 1990. </year>
Reference: [34] <author> A. H. Veen, </author> <title> Dataow Machine Architecture, </title> <journal> ACM Computing Surveys, pp. </journal> <volume> 365-396, vol. 18, no. 4, </volume> <month> December, </month> <year> 1986. </year>
References-found: 34

