URL: http://www.umiacs.umd.edu/users/sarit/Articles/19.ps
Refering-URL: http://www.umiacs.umd.edu/users/sarit/articles.html
Root-URL: 
Email: sarit@bimacs.cs.biu.ac.il  
Title: An Overview of Incentive Contracting  
Author: Sarit Kraus 
Note: Note: This article will appear in Artificial Intelligence.  
Address: Ramat Gan, 52900 Israel  
Affiliation: Department of Mathematics and Computer Science Bar Ilan University  
Abstract: Agents may contract some of their tasks to other agents even when they do not share a common goal. An agent may try to contract some of the tasks that it cannot perform by itself, or that may be performed more efficiently by other agents. One self-motivated agent may convince another self-motivated agent to help it with its task, by promises of rewards, even if the agents are not assumed to be benevolent. We propose techniques that provide efficient ways for agents to make incentive contracts in varied situations: when agents have full information about the environment and each other, or when agents do not know the exact state of the world. We consider situations of repeated encounters, cases of asymmetric information, situations where the agents lack information about each other, and cases where an agent subcontracts a task to a group of agents. Situations in which there is competition among possible contractor-agents or possible manager-agents are also considered. In all situations we assume that the contractor can choose a level of effort when carrying out the task and we would like the contractor to carry out the task efficiently without the need of close observation by the manager. fl This paper is based upon work supported by the National Science Foundation under Grants No. IRI-9423967 and the Israeli Ministry of Science and the Arts under grant 4210, and is an extension of [47]. I would like to thank Jonathan Wilkenfeld, Barbara Grosz and an anonymous referee for their comments, and Sean Engelson and Onn Shehory for useful discussions. y Also affiliated with the Institute for Advanced Computer Studies, University of Maryland, College Park. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Abrereu, P. Dutta, and L. Smith. </author> <title> The folk theorem for repeated games: a new condition. </title> <journal> Econometrica, </journal> <volume> 62(4) </volume> <pages> 939-948, </pages> <year> 1994. </year>
Reference-contexts: Suppose the world's situation is which is uniformly distributed on <ref> [0; 1] </ref> and the outcome function is q (e; ) = e + . The monitoring technology then includes only monitors, which are uniformly distributed on [e *; e + *] for some * &gt; 0. <p> Their expected value is ^c. We let b n be a strictly increasing sequence of positive numbers (n 1), 29 This theorem is called "Folk Theorem" because no one remembers who should get credit for it [5]. The theorem says that under certain conditions (see <ref> [5, 25, 1] </ref>) in any infinitely repeated n-person game, with finite action sets at each repetition, any combination of actions observed in any finite number of repetitions is a unique outcome of a subgame perfect equilibrium. 45 and define the random variables ~ N and N by: ~ N = minfn
Reference: [2] <author> K. J. </author> <title> Arrow. The economics of agency. </title> <editor> In J. Pratt and R. Zeckhauser, editors, </editor> <booktitle> Principals and Agents: The Structure of Business, </booktitle> <pages> pages 37-51. </pages> <institution> Harvard Business School Press, </institution> <year> 1985. </year> <month> 62 </month>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications. <p> These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., <ref> [2] </ref>); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist. <p> or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., <ref> [2] </ref>); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist. The first party (called "the agent" in the economics literature) must choose an action or a level of effort from a number of possibilities, thereby affecting the outcome of both parties.
Reference: [3] <author> K. J. Arrow and F. H. Hahn. </author> <title> General Competitive Analysis. </title> <publisher> Holden-Day, Inc., </publisher> <address> San Franscisco, California, </address> <year> 1971. </year>
Reference-contexts: However, the slaves' main goal is still to satisfy their master's wishes. In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., <ref> [4, 66, 39, 3, 45] </ref>). Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system.
Reference: [4] <author> K. J. Arrow, L. Hurwicz, and H. Uzawa. </author> <title> Studies in linear and non-linear programming. </title> <institution> Stanford Univ. Pr., </institution> <year> 1958. </year>
Reference-contexts: However, the slaves' main goal is still to satisfy their master's wishes. In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., <ref> [4, 66, 39, 3, 45] </ref>). Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system.
Reference: [5] <author> R. J. Aumann. </author> <title> Survey of Repeated Games. </title> <booktitle> Essays in Game Theory and Mathematical Economics in Honor of Oskar Morgenstern, </booktitle> <address> Wissenschaftsverlag. </address> <publisher> Bibliographisches Institut, Mannheim, </publisher> <year> 1981. </year>
Reference-contexts: Their expected value is ^c. We let b n be a strictly increasing sequence of positive numbers (n 1), 29 This theorem is called "Folk Theorem" because no one remembers who should get credit for it <ref> [5] </ref>. <p> Their expected value is ^c. We let b n be a strictly increasing sequence of positive numbers (n 1), 29 This theorem is called "Folk Theorem" because no one remembers who should get credit for it [5]. The theorem says that under certain conditions (see <ref> [5, 25, 1] </ref>) in any infinitely repeated n-person game, with finite action sets at each repetition, any combination of actions observed in any finite number of repetitions is a unique outcome of a subgame perfect equilibrium. 45 and define the random variables ~ N and N by: ~ N = minfn
Reference: [6] <author> S. Baiman and J. Demski. </author> <title> Economically optimal performance evaluation and control systems. </title> <journal> Journal of Accounting Research, </journal> <volume> 18 </volume> <pages> 184-220, </pages> <year> 1980. </year>
Reference-contexts: These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., <ref> [78, 6, 7, 64] </ref>); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and <p> If the contractor has full information about the state of the world before signing the contract, then the manager's expected utility is lower than in the case where it and the contractor have symmetric beliefs (either perfect or imperfect) about the state of the world before signing the contract <ref> [6, 15] </ref>.
Reference: [7] <author> A. Banerjee and A. Beggs. </author> <title> Efficiency in hierarchies: implementing the first-best solution by sequential actions. </title> <journal> The Rand Journal of Economics, </journal> <volume> 20(4) </volume> <pages> 637-645, </pages> <year> 1989. </year>
Reference-contexts: These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., <ref> [78, 6, 7, 64] </ref>); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and <p> n to compensate for the slack and if for fixed effort levels e 1 ; :::; e i , z is a monotonic function of the effort level of the rest of the contractors, then the manager can construct a contract in which it can obtain its first best outcome <ref> [7] </ref>. The contract enables agent i, whose choice of effort level is a function of 58 the effort levels of agents 1; :::i 1, to use its monitoring capability effectively. Another interesting situation is when a group of contractors can commit themselves to cooperate.
Reference: [8] <author> A. H. Bond and L. Gasser. </author> <title> An analysis of problems and research in DAI. </title> <editor> In A. H. Bond and L. Gasser, editors, </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <pages> pages 3-35. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Throughout the paper, we use a robotics domain and an example of software agents to demonstrate the contracting techniques introduced above. 2 Related work in DAI Research in DAI is divided into two basic classes: Cooperative Distributed Problem Solving and Multi-Agent Systems (MA) <ref> [8, 28] </ref>. <p> Cooperative Distributed Problem Solving (e.g., [61, 59, 12, 101, 18]) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system <ref> [8] </ref>: Performance: Concurrency may increase the speed of computation and reasoning, and may allow the system to solve large problems faster. Reliability and Stability: The modules may provide redundancy, cross-checking and triangulation of the results.
Reference: [9] <author> B. Caillaud, R. Guesnerie, P. Rey, and J. Tirole. </author> <title> Government intervention in production and incentives theory: a review of recent contributions. </title> <journal> Rand Journal of Economics, </journal> <volume> 19(1) </volume> <pages> 1-26, </pages> <year> 1988. </year>
Reference-contexts: These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., <ref> [9] </ref>); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc.
Reference: [10] <author> J. Christensen. </author> <title> Communication in agencies. </title> <journal> Bell Journal of Economics, </journal> <volume> 12:661|674, </volume> <year> 1981. </year>
Reference-contexts: This means, that the contractor cannot predict the outcome based on its private information, since the private information only provides a better estimation of what the outcome may be. One example of such a situation is as follows <ref> [10] </ref>. In the first stage of the interaction, the manager offers the contractor a menu of contracts based on a message it will send in 36 addition to the observed outcome. The contractor may reject the offer or agree to it and sign a contract. <p> In the fourth stage the outcome is observed by both agents, and the contractor is paid according to the outcome and its earlier message. Note that in such situations, the contractor has committed itself not to leave the agreement once it has observed ~. 22 Also in this case <ref> [10] </ref>, the agents can concentrate on the class of contracts that induce the contractor to send a truthful message to the manager. This is due to the fact that it has been shown [10] for any untruthful contracts, a truthful one can be found in which the expected utility of the <p> committed itself not to leave the agreement once it has observed ~. 22 Also in this case <ref> [10] </ref>, the agents can concentrate on the class of contracts that induce the contractor to send a truthful message to the manager. This is due to the fact that it has been shown [10] for any untruthful contracts, a truthful one can be found in which the expected utility of the agents is the same. <p> its original beliefs do not play an important role since the contractor cares only about how the manager's type will affect its behavior in the implementation of the mechanism, but no more than that. 5.6 Value of Information and Communication There are two important questions related to asymmetric information situations <ref> [74, 10] </ref>: 23 Maskin and Tirole [68] show that any equilibrium of the mechanism design presented here can be computed as a Walrasian equilibrium of a fictitious economy. In this economy, the traders are the different types of manager. For more technical and formal details see [68]. 40 1. <p> The contractor may use its additional information in two ways: It may use its information to take a low effort level, thereby reducing the benefits for the managers, or it may use the information to improve the outcome (see two demonstrating examples in <ref> [10] </ref>). If the manager gains information after signing an agreement, then the information is only valuable if it is affected by the contractor's level of effort (see Section 4.2.3), and can therefore be used to estimate the contractor's effort level [30].
Reference: [11] <author> C. Congdon, M. Huber, D. Kortenkamp, K. Konolige, K. Myres, A. Saffiotti, and E. Ruspini. </author> <title> Carmel versus Flakey a comparison of two winners. </title> <journal> The AI Magazine, </journal> <volume> 14(1) </volume> <pages> 49-57, </pages> <year> 1993. </year>
Reference-contexts: the manager, or reject it. 9 The robots of company CompM will play the role of the managers and the robots of CompC will play the role of the contractors. 10 Most of the autonomous robots up today operate indoors (e.g., Flakey's of SRI, Polly's of MIT, Schimmer of Stanford <ref> [11, 80, 44] </ref>). Mobile robots that operate in rougher terrain are usually less autonomous (e.g DANTE II that was developed by NASA and CMU and explored the crater on Mt.
Reference: [12] <author> S. Conry, D. J. MacIntosh, and R. Meyer. DARES: </author> <title> A distributed automated REasoning system. </title> <booktitle> In Proc. of AAAI-90, </booktitle> <pages> pages 78-85, </pages> <address> Boston, MA, </address> <year> 1990. </year> <month> 63 </month>
Reference-contexts: Research in Cooperative Distributed Problem Solving (e.g., <ref> [61, 59, 12, 101, 18] </ref>) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system [8]: Performance: Concurrency may increase the <p> This approach assumes that an agent not otherwise occupied will readily take on the task and do it to the best of its abilities. Similarly, results and information are shared among agents in such environments with no expectation of reciprocation <ref> [61, 59, 12] </ref>. This benevolence is based on an assumption common to many approaches to coordination: that the system's goal is to solve the problem as best it can, thereby giving the agents shared, often implicit, global goals that they are all unselfishly committed to achieving.
Reference: [13] <author> D. Corkill. </author> <title> Hierarchical planning in a distributed environment. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 168-175, </pages> <address> Tokyo, </address> <month> August </month> <year> 1979. </year>
Reference-contexts: Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a group of agents (the slaves), and then hands out the pieces of the plan to the relevant individuals <ref> [90, 13, 60] </ref>. Werner [109] presents a formal logical model for a master-slave relationship by one-way communication. Also in the master-slave model there is no need to choose a level of effort and there is no need for incentive-contracting.
Reference: [14] <author> D. Demougin. </author> <title> A renegotiation-proof mechanism for a principle-agent model with moral hazard and adverse selection. </title> <journal> The Rand Journal of Economics, </journal> <volume> 20 </volume> <pages> 256-267, </pages> <year> 1989. </year>
Reference-contexts: The search for an equilibrium in such situations may often be extremely difficult, but there is a useful technique that, in using it, the manager can reduce the number of contracts it needs to consider, as we explain below. The manager should search for an optimal mechanism <ref> [14] </ref> as follows: the manager offers the contractor a menu of contracts indexed by the agent's type (or the state of the world). The contractor can then decide whether to accept the menu of contracts or not. <p> Suppose that each of the agents has some probabilistic beliefs about its opponent's private 22 In most of the situations the manager is better off making such a commitment. However, in some situations, both agents can be made better off through re-negotiation <ref> [26, 55, 14, 38] </ref>. 37 information, then, in order for an informed manager to do better than an uniformed one, it must actively participate in the contract selection and not only in the mechanism design. <p> The manager can then replicate its benefits, using a single contract. Furthermore, even if the contractor does not have perfect information, there are many situations in which there is 41 no value for communication <ref> [74, 14] </ref>. These situations are such that the stochastic outcome is informative. If the outcome is not informative, however 24 , then communication is valuable.
Reference: [15] <author> J. S. Demski and D. Sappington. </author> <title> Optimal incentive contracts with multiple agents. </title> <journal> Journal of Economic Theory, </journal> <volume> 33 </volume> <pages> 152-171, </pages> <year> 1984. </year>
Reference-contexts: If the contractor has full information about the state of the world before signing the contract, then the manager's expected utility is lower than in the case where it and the contractor have symmetric beliefs (either perfect or imperfect) about the state of the world before signing the contract <ref> [6, 15] </ref>. <p> then * if agent B produces q B 1 , you will be paid r A i1 * if agent B produces q B 2 , you will be paid r A i2 * if agent B does not sign the contract, you will be paid r A i0 In <ref> [15] </ref> the maximization problem of the manager was stated. It restricted the contractor's output choices to a Bayes-Nash equilibrium, given that they are guaranteed at least their reservation price (conditional on their private information). This is done for l = A; B. <p> The outcome for the manager, if they choose that level of effort is, however, low <ref> [15] </ref>. <p> Of course, in this case, the manager will definitely be worse off. It was suggested in <ref> [15] </ref> to strengthen the incentive constraints of one contractor, so that its chosen strategy will provide a better outcome for the manager. But although this method does guarantee a unique equilibrium, it is also costly to the manager.
Reference: [16] <author> E. J. Douglas. </author> <title> The simple analytics of the principal-agent incentive contract. </title> <journal> The Journal of Economic Education, </journal> <volume> 20(1) </volume> <pages> 39-51, </pages> <year> 1989. </year>
Reference-contexts: Under these circumstances, there is no uncertainty concerning the results of the contractor's actions, i.e., the outcome is a function of the contractor's effort. If this function is known to both agents, then the manager can offer the contractor a forcing contract <ref> [34, 88, 16] </ref>, which means that the manager will pay the contractor only if it provides the outcome required by the manager.
Reference: [17] <author> J. Doyle. </author> <title> Rationality and its role in reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 8(2) </volume> <pages> 376-409, </pages> <year> 1992. </year>
Reference-contexts: Structures of symbolic goals provide the agents with a good framework for planning, when the world is perfectly controlled by the agent and the effects of all the operators are known completely and with certainty to the agent <ref> [33, 17] </ref>. Symbolic goals are easily communicated, they guide the search for alternative plans and the projection process, and they also solve the horizon problem (see [33] for detailed discussion.) However, symbolic goals do not give any information about the relative merits of different desirable alternatives.
Reference: [18] <author> E. H. Durfee. </author> <title> Coordination of Distributed Problem Solvers. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: Research in Cooperative Distributed Problem Solving (e.g., <ref> [61, 59, 12, 101, 18] </ref>) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system [8]: Performance: Concurrency may increase the
Reference: [19] <author> E. H. Durfee. </author> <title> What your computer really needs to know, you learned in kindergarten. </title> <booktitle> In Proc. of AAAI-92, </booktitle> <pages> pages 858-864, </pages> <address> California, </address> <year> 1992. </year>
Reference-contexts: The provision of incentives is in general not essential in Cooperative Distributed Problem Solving systems. It is assumed that it is in the agents' interests to help one another. This help can take the form of sharing tasks, results, or information <ref> [19] </ref>. In task sharing, an agent, which cannot fulfill a task on its own, will attempt to pass the task, in whole or in part, to other agents, usually on a contractual basis [101].
Reference: [20] <author> E. Ephrati and J. S. Rosenschein. </author> <title> The clarke tax as a consensus mechanism among automated agents. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 173-178, </pages> <address> California, </address> <year> 1991. </year>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents.
Reference: [21] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Planning to please: Following another agent's intended plan. </title> <journal> Journal of Group Decision and Negotiation, </journal> <volume> 2(3) </volume> <pages> 219-235, </pages> <year> 1993. </year>
Reference-contexts: That is, the main problem for a master is finding the best plan and synchronizing the agent's actions, rather than convincing other agents to carry out the plan appropriately without its observation. The simple master/slaves model was extended by Ephrati and Rosenschein <ref> [21] </ref> to allow the "slaves" more freedom in carrying out the plans. However, the slaves' main goal is still to satisfy their master's wishes.
Reference: [22] <author> R. Fletcher. </author> <title> Practical Methods of Optimization. </title> <publisher> John Wiley & Sons, </publisher> <year> 1987. </year>
Reference-contexts: Optimization problems are therefore classified into particular categories, where each category is defined by the objective function of the maximization and the constraints; special purpose procedures were developed for each case. Currently, there are several computer optimization packages available using a variety 59 of practical optimization methods <ref> [22] </ref> that can be used for automating those procedures. The designer of the automated agent should build an interface between the chosen package and its agent's software.
Reference: [23] <author> S. </author> <title> French. Decision Theory: An Introduction to the Mathematics of Rationality. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1986. </year>
Reference-contexts: Decision theory offers a formalization for capturing risk attitudes. If an agent's utility function is concave, it is risk averse. If the function is convex, it is risk prone. A linear utility function yields risk neutral behavior <ref> [46, 23] </ref>. We propose that a utility function of an automated agent in our contracting multi-agent (CMA) environment depends on the agent's monetary gain and effort. Developing a quantitative evaluation of effort and world states and assigning numerical values to these is a difficult problem.
Reference: [24] <author> D. Fudenberg and D. Levine. </author> <title> Limit games and limit equlibrium. </title> <journal> Journal of Economic Theory, </journal> <volume> 38(2) </volume> <pages> 261-279, </pages> <year> 1986. </year> <month> 64 </month>
Reference-contexts: One rationale for epsilon equilibrium is, that if the agents have sufficient inertia, they will not bother to realize possible small gains <ref> [24] </ref>. The main motivation for using the epsilon equilibrium concept is as follows: In every perfect equilibrium (defined in Section 3.2) of the (finite) T -period game, the outcome in every period is a Nash-equilibrium of the one-period game.
Reference: [25] <author> D. Fudenberg and E. Maskin. </author> <title> The folk theorem in repeated games with discounting or incomplete information. </title> <journal> Econometrica, </journal> <volume> 54 </volume> <pages> 533-554, </pages> <year> 1986. </year>
Reference-contexts: Their expected value is ^c. We let b n be a strictly increasing sequence of positive numbers (n 1), 29 This theorem is called "Folk Theorem" because no one remembers who should get credit for it [5]. The theorem says that under certain conditions (see <ref> [5, 25, 1] </ref>) in any infinitely repeated n-person game, with finite action sets at each repetition, any combination of actions observed in any finite number of repetitions is a unique outcome of a subgame perfect equilibrium. 45 and define the random variables ~ N and N by: ~ N = minfn
Reference: [26] <author> D. Fudenberg and J. Tirole. </author> <title> Moral hazard and renegotiation in agency contracts. </title> <journal> Econometrica, </journal> <volume> 58(6) </volume> <pages> 1279-1319, </pages> <year> 1990. </year>
Reference-contexts: Suppose that each of the agents has some probabilistic beliefs about its opponent's private 22 In most of the situations the manager is better off making such a commitment. However, in some situations, both agents can be made better off through re-negotiation <ref> [26, 55, 14, 38] </ref>. 37 information, then, in order for an informed manager to do better than an uniformed one, it must actively participate in the contract selection and not only in the mechanism design.
Reference: [27] <author> D. Fudenberg, J. Tirole, and P. Milgrom. </author> <title> Short-term contracts and long-term relationships. </title> <journal> Journal of Economic Theory, </journal> <volume> 51 </volume> <pages> 1-31, </pages> <year> 1990. </year>
Reference-contexts: encounter a new contract is agreed upon by the agents. 6.1 Short Term Contracts Repetition of the encounters between the manager and the contractors enables the agents to reach efficient short term contracts if the number of encounters is large enough 27 and if the contractor can be "punished" sufficiently <ref> [85, 86, 43, 65, 27] </ref>. Based on the average outcome, the manager could form an accurate estimate of the contractor's effort over a certain amount of time. <p> Fudenberg at el. <ref> [27] </ref> assume that there is a terminal date, T , such that after T the manager's profit will no longer depend on the contractor's actions, that there will be no additional information arriving, and that the manager won't give the contractor any further rewards. <p> On the other hand, in infinite multiple stage games (i.e., T is infinite), in which each agent can observe the other agent's 28 In <ref> [27] </ref> it is assumed that past actions and signals can affect current outcomes and signals, as long as these dependencies are publicly revealed. 44 one period strategies, there are perfect equilibria of the game which result in the use of "co-operative" pairs of strategies (in our situations, the first best strategies)
Reference: [28] <author> L. Gasser. </author> <title> Social concepts of knowledge and action: DAI foundations and open systems semantics. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):107-138, </volume> <year> 1991. </year>
Reference-contexts: Throughout the paper, we use a robotics domain and an example of software agents to demonstrate the contracting techniques introduced above. 2 Related work in DAI Research in DAI is divided into two basic classes: Cooperative Distributed Problem Solving and Multi-Agent Systems (MA) <ref> [8, 28] </ref>.
Reference: [29] <author> L. Gasser. </author> <title> Social knowledge and social action. </title> <booktitle> In IJCAI-93, </booktitle> <pages> pages 751-757, </pages> <address> French, </address> <year> 1993. </year>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents.
Reference: [30] <author> F. Gjesdal. </author> <title> Information and incentives: The agency information problem. </title> <journal> Review of Economic Studies, </journal> <volume> XLIX:373-390, </volume> <year> 1982. </year>
Reference-contexts: Surprisingly, the answer to both questions is, that it is not always the case that communications and knowledgeable contractors will improve the managers' benefits, rather their effect depends on the exact details of the situation. There are even situations when less information by the manager is preferred to more <ref> [30] </ref>. As we explained in Section 5.1, when the contractor has full private information before signing the contract, the manager's expected utility is lower than if they have symmetric beliefs. If the contractor acquires its information after signing the agreement, then its effect on the manager varies. <p> If the manager gains information after signing an agreement, then the information is only valuable if it is affected by the contractor's level of effort (see Section 4.2.3), and can therefore be used to estimate the contractor's effort level <ref> [30] </ref>. For example, information gained by setting up a camera in a garbage collection site provides the manager with an estimation of the contractor's effort level and may therefore be useful to the manager.
Reference: [31] <author> S. Grossman and O. Hart. </author> <title> An analysis of the principal-agent problem. </title> <journal> Econometrica, </journal> <volume> 51(1) </volume> <pages> 7-45, </pages> <year> 1983. </year>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications. <p> However, if the agents' utility functions are carefully chosen, then an algorithm does exist. Suppose the contractor is risk averse and the manager is risk neutral (the methods are also applicable when both are risk averse). Grossman and Hart <ref> [31] </ref> present a three-step procedure in order to find appropriate contracts in such situations. The first step of the procedure is to find for each possible effort level, the set of reward contracts that will induce the contractor to choose that particular effort level. <p> For this minimization problem there is an algorithm if U c satisfies several properties, including the property that the preferences of the contractor over entering uncertain situations are independent of its actions <ref> [31, 83, 89] </ref>. 17 That is, the contractor's preferences over reward lotteries are independent of its actions and effort level. <p> that the manager should solve is: M aximize r 1 ;:::;r n n X -(^e; q i )(q i r i ) (8) with the constraints: (IR) 1 10 2e) 1 (9) (IC) ^e = argmax e2f1;2g 2 X -(e; q i )(17 r i Grossman and Hart's three-step procedure <ref> [31] </ref> requires that the manager first determine the minimal reward needed to make the contractor choose e 1 = 1 and what the minimal reward is that will make it choose e 2 = 2: C (e 1 ) = M inimize r 1 ;r 2 3 r 1 + 4
Reference: [32] <author> B. Grosz and S. Kraus. </author> <title> Collaborative plans for group activities. </title> <booktitle> In IJCAI-93, </booktitle> <pages> pages 367-373, </pages> <address> French, </address> <year> 1993. </year>
Reference-contexts: This model is also applicable when the agents need to share a resource. Zlotkin and Rosenschein [111] present a theoretical negotiation model for two rational agents which have symmetric capabilities and identical costs for their actions. Contracting in multi-agent systems was previously studied in <ref> [32] </ref>. A formal definition of the mental state of an agent (or a group of agents) that would like to contract out one of its tasks was presented. <p> Contracting depends mainly on an agent which believes that by taking some action (and thus bringing about a certain state of affairs), it can get another agent to perform an action. However, a detailed algorithm for finding the "motivating" action and the appropriate contractor is not presented in <ref> [32] </ref>. Also, the issue of choosing the appropriate effort level by the contractor is not explicitly considered.
Reference: [33] <author> P. Haddaway and S. Hanks. </author> <title> Issues in decision-theoretic planning: Symbolic goals and numeric utilities. </title> <booktitle> In Proc. of the Workshop on Innovative Approaches to Planning, </booktitle> <pages> pages 48-58, </pages> <booktitle> Scheduling and Control, </booktitle> <address> San Diego, CA, </address> <year> 1990. </year>
Reference-contexts: Structures of symbolic goals provide the agents with a good framework for planning, when the world is perfectly controlled by the agent and the effects of all the operators are known completely and with certainty to the agent <ref> [33, 17] </ref>. Symbolic goals are easily communicated, they guide the search for alternative plans and the projection process, and they also solve the horizon problem (see [33] for detailed discussion.) However, symbolic goals do not give any information about the relative merits of different desirable alternatives. <p> Symbolic goals are easily communicated, they guide the search for alternative plans and the projection process, and they also solve the horizon problem (see <ref> [33] </ref> for detailed discussion.) However, symbolic goals do not give any information about the relative merits of different desirable alternatives. <p> We discuss the notion of Nash Equilibrium and other equilibria concepts in Section 3.2 below. 4 The problem of integrating goals and utility is considered in <ref> [33] </ref>. 12 that each designer of autonomous agents develop a numerical utility function that it would like its agent to maximize. In situations where there is uncertainty and the agents need to make decisions under risk, the designers need to decide on their agents' attitude toward risk.
Reference: [34] <author> M. Harris and A. Raviv. </author> <title> Some results on incentive contracts with applications to education and employment, health insurance, and law enforcement. </title> <journal> The American Economic Review, </journal> <volume> 68(1) </volume> <pages> 20-30, </pages> <year> 1978. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., <ref> [93, 34, 102, 58] </ref>); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist. <p> Under these circumstances, there is no uncertainty concerning the results of the contractor's actions, i.e., the outcome is a function of the contractor's effort. If this function is known to both agents, then the manager can offer the contractor a forcing contract <ref> [34, 88, 16] </ref>, which means that the manager will pay the contractor only if it provides the outcome required by the manager. <p> There is the possibility that the contractor may gain more information about the world during or after completing the task, but only after signing the contract and choosing the effort level. The manager, however, is not capable of gaining more information about the world. Following <ref> [34] </ref>, we also assume that there is a set of possible outcomes to the contractor carrying out the task Outcome = fq 1 ; :::; q n g such that q 1 &lt; q 2 &lt; ::: &lt; q n depends upon the state of the world and upon the effort <p> in which the outcome is a function of the state of the world and the contractor's effort level, and in which the probabilistic function gives the probability of the state of the world which is independent of the contractor's effort level, is a special case of the model described here <ref> [81, 91, 34] </ref>. 21 problem can be constructed as follows (see also [88]). 14 M aximize r 1 ;:::;r n n X -(^e; q i )U m (q i ; r i ) (1) with the constraints: (IR) 1 (IC) ^e = argmax e2Effort n X -(e; q i )U c
Reference: [35] <author> M. Harris and A. Raviv. </author> <title> Optimal incentive contracts with imperfect information. </title> <journal> J. Economics Theory, </journal> <volume> 20 </volume> <pages> 231-259, </pages> <year> 1979. </year>
Reference-contexts: Under the above conditions, it has been shown that if the contractor is risk neutral, there are no gains (to either agent) from the use of any monitoring mechanism <ref> [35] </ref>. This claim holds when the manager is either risk neutral or risk averse. 19 However, according to the above conditions, if the contractor is risk averse, there are potential gains to monitoring. <p> Since all variables are known, based on the suggested contract, this check is straight-forward. 19 The manager's utility function should be monotone increasing with q r, concave and continuously differentiable. The proof to the claim appears in proposition 3 of <ref> [35] </ref>. 27 form is an optimal monitoring contract: If the contractor's action is judged acceptable on the basis of the monitored outcome, the contractor will then be paid according to a prespecified schedule. Otherwise, it will receive less preferred, fixed rewards [35]. <p> proof to the claim appears in proposition 3 of <ref> [35] </ref>. 27 form is an optimal monitoring contract: If the contractor's action is judged acceptable on the basis of the monitored outcome, the contractor will then be paid according to a prespecified schedule. Otherwise, it will receive less preferred, fixed rewards [35]. To demonstrate this idea we use a modification of an example that appears in [35]. <p> Otherwise, it will receive less preferred, fixed rewards <ref> [35] </ref>. To demonstrate this idea we use a modification of an example that appears in [35]. <p> This is higher than in Example 4.3, where its expected outcome is 6 3 4 . We would like to consider the option of monitoring in such situations. It was proved in <ref> [35] </ref> that if the contractor is risk neutral, and if it is able to get information about the exact state of the world after signing the agreement, then monitoring is not valuable. If the contractor is risk averse, monitoring may be beneficial as we will explain in Section 5.6.
Reference: [36] <author> M. Harris and R. Townsend. </author> <title> Resource allocation under asymmetric information. </title> <journal> Econometrica, </journal> <volume> 49 </volume> <pages> 33-64, </pages> <year> 1981. </year> <month> 65 </month>
Reference-contexts: If the contractor chooses a level of effort e and the state of the world is , then the outcome will be f (e; ) <ref> [36] </ref>. As in previous cases the contractor's utility function (U c (e; r)) increases with the reward it gets from the manager (r), and decreasing with its effort (e). The manager's utility function (U m (q; r)) increases with the outcome, and decreases with its reward to the contractor. <p> We assume that the utility function of the contractor can be written as a function of q and r as follows: U c (q; r) = r e (q; ) where f (e (q; ); ) = q. In such situations the optimal strategy for the manager <ref> [36] </ref> is to design at most D distinct contracts from which the contractor can make a binding choice by sending a message to the manager.
Reference: [37] <author> J. Harsanyi. </author> <title> Games with incomplete information played by bayesian players. </title> <journal> Manage--ment Science, </journal> <volume> 14 159-182,320-334,486|502, </volume> <pages> 1967-1968. </pages>
Reference-contexts: A strategy combination and a set of beliefs form a Bayesian-Nash equilibrium if the strategies are in Nash equilibrium given the set of beliefs, and the agents update their beliefs, according to Bayes' rule <ref> [37] </ref>. When there are several stages of interaction among the agents, the Nash equilibrium strategies may involve threats that in certain senses, are not credible. In order to rule out such equilibria we use the concept of perfect equilibrium [97].
Reference: [38] <author> O. D. Hart and J. Tirole. </author> <title> Contract renegotiation and Coasian dynamics. </title> <journal> Review of Economic Studies, </journal> <pages> pages 509-540, </pages> <year> 1988. </year>
Reference-contexts: Suppose that each of the agents has some probabilistic beliefs about its opponent's private 22 In most of the situations the manager is better off making such a commitment. However, in some situations, both agents can be made better off through re-negotiation <ref> [26, 55, 14, 38] </ref>. 37 information, then, in order for an informed manager to do better than an uniformed one, it must actively participate in the contract selection and not only in the mechanism design.
Reference: [39] <author> G. Heal. </author> <title> Planning without prices. </title> <journal> Review of Economic Studies, </journal> <volume> 36 </volume> <pages> 346-362, </pages> <year> 1969. </year>
Reference-contexts: However, the slaves' main goal is still to satisfy their master's wishes. In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., <ref> [4, 66, 39, 3, 45] </ref>). Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system.
Reference: [40] <author> J. Hirshleifer and J. Riley. </author> <title> The Analytics of Uncertainty and Information. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications.
Reference: [41] <author> Y. Ho, L. Servi, and R. Suri. </author> <title> A class of center-free resource allocation algorithms. </title> <booktitle> Large Scale Systems, </booktitle> <volume> 1 </volume> <pages> 51-62, </pages> <year> 1980. </year>
Reference-contexts: In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., [4, 66, 39, 3, 45]). Researchers in distributed systems and distributed artificial intelligence (e.g., <ref> [41, 53, 106, 107] </ref>) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system. For example, Wellman [107] uses market price mechanisms for coordination and task distribution in distributed planning systems.
Reference: [42] <author> B. Holmstrom. </author> <title> Moral hazard in teams. </title> <journal> Bell Journal of Economics, </journal> <volume> 13(2):324|340, </volume> <year> 1982. </year>
Reference-contexts: the contractors choose the appropriate actions of the second best contract. 7.2 Individual Outcome is Not Observed There are other situations in which the manager cannot observe the individual outcome (or such an outcome does not exist), but rather can only observe the overall outcome of all the agents' efforts <ref> [42, 87] </ref>.
Reference: [43] <author> B. Holmstrom and P. Milgrom. </author> <title> Aggregation and linearity in the provision of intertem-poral incentives. </title> <journal> Econometrica, </journal> <volume> 55(2) </volume> <pages> 303-328, </pages> <year> 1987. </year>
Reference-contexts: encounter a new contract is agreed upon by the agents. 6.1 Short Term Contracts Repetition of the encounters between the manager and the contractors enables the agents to reach efficient short term contracts if the number of encounters is large enough 27 and if the contractor can be "punished" sufficiently <ref> [85, 86, 43, 65, 27] </ref>. Based on the average outcome, the manager could form an accurate estimate of the contractor's effort over a certain amount of time. <p> They don't assume that T is large, but rather make other assumptions such as, that there is common knowledge of technology and preferences, and equal access to banking. Also, Holmstrom and Milgrom <ref> [43] </ref> Malcomson and Spinnewyn [65] don't assume that T is large, but make additional assumptions about the agents' utility functions and about the environment.
Reference: [44] <author> I. Horswill. Polly: </author> <title> A vision-based artificial agent. </title> <booktitle> In Proc. of AAAI-93, </booktitle> <pages> pages 824-829, </pages> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: the manager, or reject it. 9 The robots of company CompM will play the role of the managers and the robots of CompC will play the role of the contractors. 10 Most of the autonomous robots up today operate indoors (e.g., Flakey's of SRI, Polly's of MIT, Schimmer of Stanford <ref> [11, 80, 44] </ref>). Mobile robots that operate in rougher terrain are usually less autonomous (e.g DANTE II that was developed by NASA and CMU and explored the crater on Mt.
Reference: [45] <author> L. Hurwicz. </author> <title> The design mechanisms for resource allocation. </title> <journal> The American Economic Review, </journal> <volume> 63(2) </volume> <pages> 1-30, </pages> <year> 1963. </year>
Reference-contexts: However, the slaves' main goal is still to satisfy their master's wishes. In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., <ref> [4, 66, 39, 3, 45] </ref>). Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system.
Reference: [46] <author> R. Keeney and H. Raiffa. </author> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: In such situations numeric utility functions and decision theory offer a normative model for choice under uncertainty by providing support in evaluating multiple objectives and value tradeoffs <ref> [46, 108] </ref>. 4 We therefore propose 3 A pair of strategies (; t ) is a Nash Equilibrium if, given t , no strategy of Agent 1 results in an outcome that Agent 1 prefers to the outcome generated by (; t ) and similarly for Agent 2 given . <p> Decision theory offers a formalization for capturing risk attitudes. If an agent's utility function is concave, it is risk averse. If the function is convex, it is risk prone. A linear utility function yields risk neutral behavior <ref> [46, 23] </ref>. We propose that a utility function of an automated agent in our contracting multi-agent (CMA) environment depends on the agent's monetary gain and effort. Developing a quantitative evaluation of effort and world states and assigning numerical values to these is a difficult problem.
Reference: [47] <author> S. Kraus. </author> <title> Agents contracting tasks in non-collaborative environments. </title> <booktitle> In Proc. of AAAI-93, </booktitle> <pages> pages 243-248, </pages> <address> Washington, D.C., </address> <year> 1993. </year>
Reference: [48] <author> S. Kraus and D. Lehmann. </author> <title> Designing and building a negotiating automated agent. </title> <journal> Computational Intelligence, </journal> <volume> 11(1) </volume> <pages> 132-171, </pages> <year> 1995. </year> <month> 66 </month>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents.
Reference: [49] <author> S. Kraus, M. Nirkhe, and K. P. Sycara. </author> <title> Reaching agreements through argumentation: a logical model. </title> <booktitle> In Proc. of DAI93, </booktitle> <pages> pages 233-247, </pages> <year> 1993. </year> <title> Also presented in AAAI-93 workshop on AI theories of Groups and Organizations: Conceptual and Empirical Research. </title>
Reference-contexts: There are two main ways to convince another self-motivated agent to perform a task that is not among its own tasks: by threatening to interfere with the agent carrying out its own tasks, or by promising rewards <ref> [49] </ref>. This paper concentrates on subcontracting by rewards which may be accomplished in two forms: The first approach is a bartering system, where one agent may promise to help the other with future tasks in return for current help.
Reference: [50] <author> S. Kraus and J. Wilkenfeld. </author> <title> The function of time in cooperative negotiations. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 179-184, </pages> <address> California, </address> <year> 1991. </year>
Reference-contexts: For example, Sycara [105, 104] presents a model of negotiation that combines case-based reasoning and optimization of the multi-attribute utilities. This model is used 10 in labor management negotiations where two agents need to reach an acceptable agreement. In <ref> [50, 51, 52] </ref>, a strategic-negotiation model is presented for situations where a set of self-motivated autonomous agents have common goals that they want to satisfy as soon as possible. <p> cases, the contractor will decide how much effort to expend, but its decision may be influenced by the contract offered 7 In our previous work on negotiation under time constraints, we have identified perfect-equilibrium strate gies and proposed to develop a library of meta strategies to be used when appropriate <ref> [50, 51, 52] </ref>. 15 Notation Meaning Comments Effort Set of efforts of the contractor e; e 1 ; :::; e i 2 Effort Outcome Set of possible monetary outcomes q; q 1 ; :::q j 2 Outcome. q (e) 2 Outcome for carrying out a task. when q is a function
Reference: [51] <author> S. Kraus and J. Wilkenfeld. </author> <title> Negotiations over time in a multi agent environment: Preliminary report. </title> <booktitle> In Proc. of IJCAI-91, </booktitle> <pages> pages 56-61, </pages> <address> Australia, </address> <year> 1991. </year>
Reference-contexts: For example, Sycara [105, 104] presents a model of negotiation that combines case-based reasoning and optimization of the multi-attribute utilities. This model is used 10 in labor management negotiations where two agents need to reach an acceptable agreement. In <ref> [50, 51, 52] </ref>, a strategic-negotiation model is presented for situations where a set of self-motivated autonomous agents have common goals that they want to satisfy as soon as possible. <p> cases, the contractor will decide how much effort to expend, but its decision may be influenced by the contract offered 7 In our previous work on negotiation under time constraints, we have identified perfect-equilibrium strate gies and proposed to develop a library of meta strategies to be used when appropriate <ref> [50, 51, 52] </ref>. 15 Notation Meaning Comments Effort Set of efforts of the contractor e; e 1 ; :::; e i 2 Effort Outcome Set of possible monetary outcomes q; q 1 ; :::q j 2 Outcome. q (e) 2 Outcome for carrying out a task. when q is a function
Reference: [52] <author> S. Kraus, J. Wilkenfeld, and G. Zlotkin. </author> <title> Multiagent negotiation under time constraints. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 75(2) </volume> <pages> 297-345, </pages> <year> 1995. </year>
Reference-contexts: For example, Sycara [105, 104] presents a model of negotiation that combines case-based reasoning and optimization of the multi-attribute utilities. This model is used 10 in labor management negotiations where two agents need to reach an acceptable agreement. In <ref> [50, 51, 52] </ref>, a strategic-negotiation model is presented for situations where a set of self-motivated autonomous agents have common goals that they want to satisfy as soon as possible. <p> cases, the contractor will decide how much effort to expend, but its decision may be influenced by the contract offered 7 In our previous work on negotiation under time constraints, we have identified perfect-equilibrium strate gies and proposed to develop a library of meta strategies to be used when appropriate <ref> [50, 51, 52] </ref>. 15 Notation Meaning Comments Effort Set of efforts of the contractor e; e 1 ; :::; e i 2 Effort Outcome Set of possible monetary outcomes q; q 1 ; :::q j 2 Outcome. q (e) 2 Outcome for carrying out a task. when q is a function
Reference: [53] <author> J. Kurose and R. Simha. </author> <title> A microeconomic approach to optimal resource allocation in distributed computer systems. </title> <journal> IEEE Transaction on Computers, </journal> <volume> 38(5) </volume> <pages> 705-717, </pages> <year> 1989. </year>
Reference-contexts: In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., [4, 66, 39, 3, 45]). Researchers in distributed systems and distributed artificial intelligence (e.g., <ref> [41, 53, 106, 107] </ref>) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system. For example, Wellman [107] uses market price mechanisms for coordination and task distribution in distributed planning systems.
Reference: [54] <author> J. Laffont, E. Maskin, and J. Rochet. </author> <title> Optimal nonlinear pricing with two-dimensional characteristic. </title> <editor> In T. Groves, R. Radner, and S. Reiter, editors, </editor> <booktitle> Information, Incentives, and Economic Mechanisms, </booktitle> <pages> pages 256-266. </pages> <publisher> University of Minnesota Press, </publisher> <year> 1987. </year>
Reference-contexts: That is, the manager is uncertain about different aspects of the contractor that are independent; for example, its capabilities and its disk space. Techniques to formalize the maximization problem in such situations, and methods to solve it can be found in <ref> [54, 71] </ref>. 26 The measure of risk aversion will influence the agents' behavior when there are more than one possible contractor in the environment.
Reference: [55] <author> J. Laffont and J. Tirole. </author> <title> Adverse selection and renegotiation in procurement. </title> <journal> Review Economics Studies, </journal> <volume> 57 </volume> <pages> 597-625, </pages> <year> 1990. </year>
Reference-contexts: Suppose that each of the agents has some probabilistic beliefs about its opponent's private 22 In most of the situations the manager is better off making such a commitment. However, in some situations, both agents can be made better off through re-negotiation <ref> [26, 55, 14, 38] </ref>. 37 information, then, in order for an informed manager to do better than an uniformed one, it must actively participate in the contract selection and not only in the mechanism design.
Reference: [56] <author> J. Laffont and J. Tirole. </author> <title> A Theory Of Incentives in Procurement and Regulation. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications.
Reference: [57] <author> R. A. Lambert. </author> <title> Long term contracts and moral hazard. </title> <journal> Bell Journal of Economics, </journal> <volume> 14 </volume> <pages> 441-452, </pages> <year> 1983. </year>
Reference-contexts: The contractor, therefore, is motivated to adjust its effort over time as a function of its previous performance. As a result of this phenomenon, the optimal contracts in situations where the number of encounters is small, will not be a simple function of the average outcomes <ref> [57] </ref> in 30 In [86] the situation of symmetric information with uncertainty is considered. That is, the situation of a single encounter is as in Section 4.2. It provides Pareto-optimal strategies only in the case that there are infinite encounters. 46 general. <p> However, if the number of encounters is very large, such behavior will eventually be detected. The problem of subcontracting when the number of repeated encounters is small is considered in <ref> [57] </ref>. It is assumed that the manager can commit itself before the first encounter to a long term contract that will be implemented during all their encounters. <p> The outcome of each encounter depends on the contractor's effort level (which is unobservable to the manager), and the state of the world in that encounter, which is not known to either agent, as in Section 4.2. Suppose there are only two encounters <ref> [57] </ref>, and before the first encounter the manager offers a binding contract. Then the reward in the first encounter will depend upon the outcome of that encounter, but the reward of the second encounter will depend upon the outcomes of the first and second encounters. <p> Similarly, it should consider the appropriate constraints (i.e., IR and IC) on the effort levels chosen by the contractor in both encounters. Subject to these constraints, the manager is able to update the contractor's rewards over time in any fashion that it desires. It was shown in <ref> [57] </ref> that the rewards in the second encounter should be an increasing function of the outcome of the first encounter. 7 Subcontracting to a Group Suppose that the task the manager wants to contract out can be performed by a group of agents.
Reference: [58] <author> M. Landsberger and I. Meilijson. </author> <title> Monopoly insurance under adverse selection when agents differ in risk aversion. </title> <journal> Journal of Economic Theory, </journal> <volume> 63 </volume> <pages> 392-407, </pages> <year> 1994. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., <ref> [93, 34, 102, 58] </ref>); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist.
Reference: [59] <author> V. Lesser. </author> <title> A retrospective view of FA/C distributed problem solving. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, Special Issue on Distributed Artificial Intelligence, </journal> <volume> 21(6) </volume> <pages> 1347-1362, </pages> <month> December </month> <year> 1991. </year> <month> 67 </month>
Reference-contexts: Research in Cooperative Distributed Problem Solving (e.g., <ref> [61, 59, 12, 101, 18] </ref>) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system [8]: Performance: Concurrency may increase the <p> This approach assumes that an agent not otherwise occupied will readily take on the task and do it to the best of its abilities. Similarly, results and information are shared among agents in such environments with no expectation of reciprocation <ref> [61, 59, 12] </ref>. This benevolence is based on an assumption common to many approaches to coordination: that the system's goal is to solve the problem as best it can, thereby giving the agents shared, often implicit, global goals that they are all unselfishly committed to achieving.
Reference: [60] <author> V. R. Lesser. </author> <title> Distributed problem solving. </title> <editor> In S. C. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 245-251. </pages> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a group of agents (the slaves), and then hands out the pieces of the plan to the relevant individuals <ref> [90, 13, 60] </ref>. Werner [109] presents a formal logical model for a master-slave relationship by one-way communication. Also in the master-slave model there is no need to choose a level of effort and there is no need for incentive-contracting.
Reference: [61] <author> V. R. Lesser and L. D. Erman. </author> <title> Distributed interpretation:a model and experiment. </title> <journal> IEEE Transaction on Computers, </journal> <volume> 29(12) </volume> <pages> 1144-1163, </pages> <year> 1980. </year>
Reference-contexts: Research in Cooperative Distributed Problem Solving (e.g., <ref> [61, 59, 12, 101, 18] </ref>) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system [8]: Performance: Concurrency may increase the <p> This approach assumes that an agent not otherwise occupied will readily take on the task and do it to the best of its abilities. Similarly, results and information are shared among agents in such environments with no expectation of reciprocation <ref> [61, 59, 12] </ref>. This benevolence is based on an assumption common to many approaches to coordination: that the system's goal is to solve the problem as best it can, thereby giving the agents shared, often implicit, global goals that they are all unselfishly committed to achieving.
Reference: [62] <author> C. Ma. </author> <title> Unique implementation of incentive contracts with many agents. </title> <journal> Review of Economic Studies, </journal> <volume> 51(3) </volume> <pages> 555-572, </pages> <year> 1988. </year>
Reference-contexts: The manager may then appeal to the other agents for verification. We will consider the case where there are only two contractors <ref> [62] </ref>, denoted by A and B, with the same utility function U c (e; r) = v (r) c (e). <p> It was shown in <ref> [62] </ref> that the following strategies form a unique perfect equilibrium of the described mechanism: Agent A chooses e fl a at Stage 1, and reports honestly at Stage 2, which action pair was chosen at Stage 1. <p> In addition, given that the contractors report honestly, the rewards will motivate them to choose the required actions. These results can easily be extended to the case of more than two contractors <ref> [62] </ref>. In the case that actions are only privately observed, it is not possible to implement the results of perfect observation (i.e., the first best contract, where the result is that the manager observes the contractors' actions). However, even the implementation of the second 57 best is not so simple. <p> The rewards that were suggested in the beginning of the section are appropriate only if the agents follow the actions prescribed by the manager. It is possible, however, that the contractors may be better off (given the suggested rewards) if they all deviated from the required actions. In <ref> [62] </ref> a multi-stage mechanism is presented that makes the contractors choose the appropriate actions of the second best contract. 7.2 Individual Outcome is Not Observed There are other situations in which the manager cannot observe the individual outcome (or such an outcome does not exist), but rather can only observe the
Reference: [63] <author> C. Ma, J. Moore, and S. Turnbull. </author> <title> Stopping agents from "cheating". </title> <journal> Journal of Economic Theory, </journal> <volume> 46 </volume> <pages> 355-372, </pages> <year> 1988. </year>
Reference-contexts: CompM's robot, however, does not know either distribution. Suppose there are only two agents, A and B, and two output function f l (e l ; l ); l = A; B <ref> [63] </ref>. Then we also assume that l can be l 1 or l 2 (i.e., the world can be in four different states with two possibilities for each variable). <p> A typical contract that can be offered by the manager to agent A in this case, is of the following form <ref> [63] </ref>: You may choose to produce either q A 1 or q A 2 . Your reward, r A will depend not only on your output, but also on what agent B will produce. <p> But although this method does guarantee a unique equilibrium, it is also costly to the manager. A costless method of making the contractors choose the "correct" strategies is suggested in <ref> [63] </ref>. This method, however, makes the contracts more complicated. The main idea is that the manager offers one of the contractors, e.g., A, a range of extra possible output options q A 1 (*), indexed by *, where 0 &lt; * 1 s A 1 . <p> See <ref> [63] </ref> for more details. 52 Agent A's Payments B's choice ! q B 1 q B 2 Refuse A's choice # q A 11 r A 11 1 (*) r A 12 t (*) r A q A 2 r A 2 fl Refuse | | | Agent B's Payments B's <p> A 1 r B q A 12 r B Refuse r B 11 r B contractors choose the equilibrium preferred by the manager. fl &gt; 0, s (*) and t (*) are continuous functions that are both strictly positive for 0 &lt; * &lt; 1 s A 1 . in <ref> [63] </ref> are specified in Figure 2. <p> The proof that this mechanism provides a unique equilibrium that guarantees the manager its second best outcome can be found in <ref> [63] </ref>. 53 7.1.2 The Contractor's Effort Influences Others In this section we consider situations where the output of a contractor depends both on its level of effort and the other contractors' levels of effort. In addition, there is symmetrical uncertainty about the state of the world.
Reference: [64] <author> I. Macho-Stadler and J. Perez-Castrillo. </author> <title> Moral hazard and cooperation. </title> <journal> Economics Letters, </journal> <volume> 35 </volume> <pages> 17-20, </pages> <year> 1991. </year>
Reference-contexts: These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., <ref> [78, 6, 7, 64] </ref>); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and <p> An even more efficient result may be obtained if the contractors work as a team and share the outcome. Such a situation may occur, for example, if all the contractors are robots of CompC, that have the same general task to maximize CompC's profits <ref> [64] </ref>. 8 Conclusions In this paper we presented techniques that can be used in different cases where incentive contracting of a task by an agent to another agent or a set of agents in non-collaborative environments is beneficial.
Reference: [65] <author> J. Malcomson and F. Spinnewyn. </author> <title> The multiperiod principal-agent problem. </title> <journal> Review of Economic Studies, </journal> <volume> LV:391-408, </volume> <year> 1988. </year>
Reference-contexts: encounter a new contract is agreed upon by the agents. 6.1 Short Term Contracts Repetition of the encounters between the manager and the contractors enables the agents to reach efficient short term contracts if the number of encounters is large enough 27 and if the contractor can be "punished" sufficiently <ref> [85, 86, 43, 65, 27] </ref>. Based on the average outcome, the manager could form an accurate estimate of the contractor's effort over a certain amount of time. <p> They don't assume that T is large, but rather make other assumptions such as, that there is common knowledge of technology and preferences, and equal access to banking. Also, Holmstrom and Milgrom [43] Malcomson and Spinnewyn <ref> [65] </ref> don't assume that T is large, but make additional assumptions about the agents' utility functions and about the environment.
Reference: [66] <author> E. Malinvaud. </author> <title> Decentralized procedures for planning. </title> <booktitle> In Activity Analysis in the Theory of Growth and Planning, </booktitle> <pages> pages 170-208. </pages> <publisher> St Martin's Press, </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: However, the slaves' main goal is still to satisfy their master's wishes. In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., <ref> [4, 66, 39, 3, 45] </ref>). Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system.
Reference: [67] <author> T. W. Malone, R. E. Fikes, K. R. Grant, and M. T. Howard. </author> <title> Enterprise: A marketlike task schedule for distributed computing environments. </title> <editor> In B. A. Huberman, editor, </editor> <booktitle> The Ecology of Computation, </booktitle> <pages> pages 177-205. </pages> <publisher> North Holland, </publisher> <year> 1988. </year>
Reference-contexts: The contract net protocol is a very general protocol for task distribution, and several refinements of the protocol were made in the last ten years. Malone et al. <ref> [67] </ref> developed a Distributed Scheduling Protocol (DSP) based on the contract net protocol. The most important way in which DSP differs from the original contract net protocol is by its criteria for matching between tasks and agents (i.e., the problem of sub-tasks distribution). <p> In this paper, we also allow both of these addressing methods. 2 Some of these problems were considered by <ref> [101, 99, 67] </ref> but they are revisited in [94] while taking into consideration the specific domain. 9 Subcontracting in Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a
Reference: [68] <author> E. Maskin and J. Tirole. </author> <title> The principal-agent relationship with an informed principal: The case of private values. </title> <journal> Econometrica, </journal> <volume> 58(2) </volume> <pages> 379-409, </pages> <year> 1990. </year>
Reference-contexts: We describe here an interaction procedure that satisfies the following properties: The Revelation Principle holds, there exists a perfect Bayesian equilibrium which is Pareto optimal for the different types of managers, and the manager generically does strictly better than when the contractor knows the manager's private information <ref> [68] </ref>. There are up to four possible stages in an interaction. 1. <p> As in previous cases, the agents can limit themselves to honest reports. In situations where the exact type of the manager does not directly influence the contractor's utilities, <ref> [68, 77] </ref> show that the manager can profit from the contractor's incomplete information. The intuition behind these results is as follows. When the manager proposes a contract, it is subject to two types of constraints. <p> Actually, it was proved in <ref> [68] </ref> that in most of these 39 situations, there exists a mechanism in which all types of managers do strictly better than in the instances where the contractor is fully informed. <p> an important role since the contractor cares only about how the manager's type will affect its behavior in the implementation of the mechanism, but no more than that. 5.6 Value of Information and Communication There are two important questions related to asymmetric information situations [74, 10]: 23 Maskin and Tirole <ref> [68] </ref> show that any equilibrium of the mechanism design presented here can be computed as a Walrasian equilibrium of a fictitious economy. In this economy, the traders are the different types of manager. For more technical and formal details see [68]. 40 1. <p> to asymmetric information situations [74, 10]: 23 Maskin and Tirole <ref> [68] </ref> show that any equilibrium of the mechanism design presented here can be computed as a Walrasian equilibrium of a fictitious economy. In this economy, the traders are the different types of manager. For more technical and formal details see [68]. 40 1. Will the manager always be better off, the more the contractor knows about the world? 2.
Reference: [69] <author> E. Maskin and J. Tirole. </author> <title> The principal-agent relationship with an informed principal II:common values. </title> <journal> Econometrica, </journal> <volume> 60 </volume> <pages> 1-42, </pages> <year> 1992. </year>
Reference-contexts: Therefore, any manager, regardless of its type, should offer the same mechanism. 23 Cases in which the manager's private information influences the contractor's utilities are more complex <ref> [69] </ref>. In such situations it is no longer true that, without loss of generality, the manager can postpone revealing its type until the third stage of the interaction.
Reference: [70] <author> S. Matthews. </author> <title> Selling to risk averse buyers with unobservable tastes. </title> <journal> Journal of Economy Theory, </journal> <volume> 30 </volume> <pages> 370-400, </pages> <year> 1983. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., <ref> [70, 77] </ref>); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist.
Reference: [71] <author> R. McAfee and J. McMillan. </author> <title> Multidimensional incentive compatibility and mechanism design. </title> <journal> Journal of Economic Theory, </journal> <volume> 46 </volume> <pages> 335-354, </pages> <year> 1988. </year> <month> 68 </month>
Reference-contexts: That is, the manager is uncertain about different aspects of the contractor that are independent; for example, its capabilities and its disk space. Techniques to formalize the maximization problem in such situations, and methods to solve it can be found in <ref> [54, 71] </ref>. 26 The measure of risk aversion will influence the agents' behavior when there are more than one possible contractor in the environment.
Reference: [72] <author> R. P. McAfee and J. McMillan. </author> <title> Bidding for contracts: a principal-agent analysis. </title> <journal> The Rand Journal of Economics, </journal> <volume> 17(3) </volume> <pages> 326-338, </pages> <year> 1986. </year>
Reference-contexts: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., <ref> [72] </ref>); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist.
Reference: [73] <author> R. P. McAfee and J. McMillan. </author> <title> Competition for agency contracts. </title> <journal> The Rand Journal of Economics, </journal> <volume> 18(2) </volume> <pages> 296-307, </pages> <year> 1987. </year>
Reference-contexts: If the manager does not know the types of the other agents, the following mechanism is appropriate: The manager announces a set of contracts indexed by agents' types and asks the potential contractors to report their types. On the basis of these reports, the manager chooses one agent <ref> [73] </ref>. 25 The agent that is chosen, chooses a level of effort that is not observable by the manager. The rewards to the chosen contractor depend upon the contractor's reported type and the observed outcome. <p> To prevent this, the manager must improve the rewards for all the types that are higher than z i . If the agents' types satisfy the appropriate conditions (see details in <ref> [73] </ref>) that are related to the above described aspect, and if the highest reported type is chosen, then the contract may be optimal for the manager.
Reference: [74] <author> N. D. Melumad and S. Reichelstein. </author> <title> Value of communication in agencies. </title> <journal> Journal of Economic Theory, </journal> <volume> 47 </volume> <pages> 334-368, </pages> <year> 1989. </year>
Reference-contexts: its original beliefs do not play an important role since the contractor cares only about how the manager's type will affect its behavior in the implementation of the mechanism, but no more than that. 5.6 Value of Information and Communication There are two important questions related to asymmetric information situations <ref> [74, 10] </ref>: 23 Maskin and Tirole [68] show that any equilibrium of the mechanism design presented here can be computed as a Walrasian equilibrium of a fictitious economy. In this economy, the traders are the different types of manager. For more technical and formal details see [68]. 40 1. <p> The manager can then replicate its benefits, using a single contract. Furthermore, even if the contractor does not have perfect information, there are many situations in which there is 41 no value for communication <ref> [74, 14] </ref>. These situations are such that the stochastic outcome is informative. If the outcome is not informative, however 24 , then communication is valuable. <p> This marginal return consists of the outcome minus the rewards that the contractor receives, and minus 24 See <ref> [74] </ref> for exact conditions. 25 There are situations where the agents' types are multidimensional. That is, the manager is uncertain about different aspects of the contractor that are independent; for example, its capabilities and its disk space.
Reference: [75] <author> D. Mookherjee. </author> <title> Optimal incentive schemes with many agents. </title> <journal> Review of Economic Studies, </journal> <volume> 51(3):433|446, </volume> <year> 1984. </year>
Reference-contexts: In some situations, depending on the probability function - (e.g., if there is perfect correlation between the i s), and the contractors' utility functions 34 the manager may gain similar expected utility as in the case where it can observe the agents' effort levels (i.e., as in a first-best contract) <ref> [75] </ref>. In some situations, however, the contracts found by the above maximization problem 34 The exact restrictions on the contractors' utility functions and the environment can be found in [75]. 54 may fail to uniquely implement the manager's preferred actions, as in the previous section. <p> similar expected utility as in the case where it can observe the agents' effort levels (i.e., as in a first-best contract) <ref> [75] </ref>. In some situations, however, the contracts found by the above maximization problem 34 The exact restrictions on the contractors' utility functions and the environment can be found in [75]. 54 may fail to uniquely implement the manager's preferred actions, as in the previous section. There may be other actions according to the contract that are better to the contractors, as in the previous section, where the agent's effort does not influence the others.
Reference: [76] <author> R. Myerson. </author> <title> Optimal coordination mechanisms in generalized principal-agent problem. </title> <journal> Journal of Mathematical Economics, </journal> <volume> 10 </volume> <pages> 67-81, </pages> <year> 1982. </year>
Reference-contexts: Therefore, without loss of generality, it is enough for the manager to consider only contracts where it is in the contractor's interest to honestly report its type <ref> [76] </ref>. There are two main limitations in using the Revelation Principle. First, there is a need for communication since the contractor needs to send a message to the manager specifying its type. Second, this mechanism requires strong pre-commitment capability on the part of the manager. <p> The rewards to the chosen contractor depend upon the contractor's reported type and the observed outcome. As in previous cases, the manager can use, without loss of generality, contracts in which the agents report their types honestly <ref> [76] </ref>. 26 An important aspect in the design of the contracts is the marginal return to the manager by increasing the probability that a specific type (e.g., z i ) will be chosen.
Reference: [77] <author> R. Myerson. </author> <title> Mechanism design by an informed principal. </title> <journal> Econometrica, </journal> <volume> 51:1767| 1798, </volume> <year> 1983. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., <ref> [70, 77] </ref>); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist. <p> As in previous cases, the agents can limit themselves to honest reports. In situations where the exact type of the manager does not directly influence the contractor's utilities, <ref> [68, 77] </ref> show that the manager can profit from the contractor's incomplete information. The intuition behind these results is as follows. When the manager proposes a contract, it is subject to two types of constraints.
Reference: [78] <author> B. Nalebuff and J. Stiglitz. </author> <title> Information, competition, and markets. </title> <journal> American Economic Review, </journal> <volume> 73(2) </volume> <pages> 278-283, </pages> <year> 1983. </year>
Reference-contexts: These works in economics and game theory consider different types of contracts for different applications. Examples of these are contracts between: a firm and an employer or employers (e.g., <ref> [78, 6, 7, 64] </ref>); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and <p> For example, giving a reward only to the agent whose output is the highest or, punishing the agent that came in last [79]. Rewards that are based on relative performance are generally more flexible, and reduce the risk taken by the contractors <ref> [78] </ref>. 7.1.1.2 The Contractors have Private Information In this case we assume that each of the contractor's outcomes is affected by different aspects of the state of the world, in which each agent can only observe its own private "aspect" of that world.
Reference: [79] <author> B. Nalebuff and J. Stiglitz. Prizes and incentives: </author> <title> towards a general theory of compensation and competition. </title> <journal> Bell Journal of Economics, </journal> <volume> 14(1) </volume> <pages> 21-43, </pages> <year> 1983. </year>
Reference-contexts: The advantage of using the multiple outputs to form the basis for a reward to each agent is that usually some information about the state of the world can be concluded from observing the whole array of q i s <ref> [79] </ref>, i.e., in such a situation, the individual actions can be estimated by comparing the performances of the different agents. 7.1.1 One Agent's Effort does not Influence the Other Agents' Outcomes 7.1.1.1 The Contractors have Symmetric Information Suppose the outcome for an agent is a probabilistic function of its effort level <p> The rewards of a specific agent should then depend upon its individual outcome and on T (fq 1 ; :::; q n g) <ref> [79] </ref>. For example, if both and * are normally distributed random variables, then the average value of fq 1 ; :::; q n g provides sufficient statistical information for . When the number of contractors becomes very large, the estimation of converges to the true value. <p> This is done in order to motivate the contractors to choose greater effort levels. A larger prize for the winner, motivates greater effort by all agents and increases the manager's outcome <ref> [79] </ref>. If the first contractor chooses effort level e 1 , and the second chooses effort level e 2 , then the first one will "win" if e 1 + * 1 &gt; e 2 + * 2 . <p> The expected utility of a contractor i is therefore, 1 [v (r r ) + v (r l )] c (e i ) (29) The details of how to compute r w and r l in a given situation are described in <ref> [79] </ref>. An interesting result from this is that in some situations it is possible to make the contractors choose an effort level, using the above "contest" mechanism, which is even larger than when the manager can observe the agent's effort levels, i.e., better than the first best contract. <p> There are several other methods for possible rewards for members of a group. For example, giving a reward only to the agent whose output is the highest or, punishing the agent that came in last <ref> [79] </ref>.
Reference: [80] <author> I. Nourbakhsh, S. Morse, C. Becker, M. Balabanovic, E. Gat, R. Simmons, S. Goodridge, H. Potlapalli, D. Hinkle, K. Jung, and D. V. Vactor. </author> <title> The winning robots from the 1993 robot competition. </title> <journal> The AI Magazine, </journal> <volume> 14(4) </volume> <pages> 51-62, </pages> <year> 1993. </year>
Reference-contexts: the manager, or reject it. 9 The robots of company CompM will play the role of the managers and the robots of CompC will play the role of the contractors. 10 Most of the autonomous robots up today operate indoors (e.g., Flakey's of SRI, Polly's of MIT, Schimmer of Stanford <ref> [11, 80, 44] </ref>). Mobile robots that operate in rougher terrain are usually less autonomous (e.g DANTE II that was developed by NASA and CMU and explored the crater on Mt.
Reference: [81] <author> F. </author> <title> Page. The existence of optimal contracts in the principal-agent model. </title> <journal> Journal of Mathematical Economics, </journal> <volume> 16(2) </volume> <pages> 157-167, </pages> <year> 1987. </year>
Reference-contexts: In the worst case, they may assume an equal distribution. The model can be easily extended to the case that each agent has different beliefs about the state of the world, i.e., has its own probability function, which is known to its opponent <ref> [81] </ref>. 13 The formal model in which the outcome is a function of the state of the world and the contractor's effort level, and in which the probabilistic function gives the probability of the state of the world which is independent of the contractor's effort level, is a special case of <p> in which the outcome is a function of the state of the world and the contractor's effort level, and in which the probabilistic function gives the probability of the state of the world which is independent of the contractor's effort level, is a special case of the model described here <ref> [81, 91, 34] </ref>. 21 problem can be constructed as follows (see also [88]). 14 M aximize r 1 ;:::;r n n X -(^e; q i )U m (q i ; r i ) (1) with the constraints: (IR) 1 (IC) ^e = argmax e2Effort n X -(e; q i )U c
Reference: [82] <author> H. Pattison, D. Corkill, and V. Lesser. </author> <title> Instantiating descriptions of organizational structures. </title> <editor> In M. N. Huhns, editor, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <pages> pages 59|96. </pages> <publisher> Pitman Publishing/Morgan Kaufman Publishers, </publisher> <address> San Matheo, CA, </address> <year> 1987. </year>
Reference-contexts: In <ref> [82] </ref> a language for specification of complex relations among agents in Cooperative Distributed Problem Solving is described. By using this language, a designer of a system can define hierarchical relationships among the agents and specify to one agent the other agents' authority on it.
Reference: [83] <author> R. Pfaffenberger and D. Walker. </author> <title> Mathematical Programming for Economics and Business. </title> <institution> The IOWA State University Press, Ames, IOWA, </institution> <year> 1976. </year> <month> 69 </month>
Reference-contexts: used depend primarily on the utility functions of the agents, as we will describe in the next two sections. 4.2.1 Risk Neutral Agents If the manager and the contractor are risk neutral, then solving the maximization problem can be done using any linear programming technique (e.g, simplex, see for example <ref> [83, 103] </ref>). Furthermore, in most situations, the solution will be very simple: the manager will receive a fixed amount from the outcome, and the rest will go to the contractor. <p> For this minimization problem there is an algorithm if U c satisfies several properties, including the property that the preferences of the contractor over entering uncertain situations are independent of its actions <ref> [31, 83, 89] </ref>. 17 That is, the contractor's preferences over reward lotteries are independent of its actions and effort level.
Reference: [84] <author> R. H. Porter. </author> <title> Optimal cartel trigger price strategies. </title> <journal> Journal of Economic Theory, </journal> <volume> 29 </volume> <pages> 313-338, </pages> <year> 1983. </year>
Reference-contexts: Unfortunately, the number of perfect equilibria in infinite-horizon repeated games is very large, as is indicated by the "Folk Theorem." 29 However, the number of possible equilibria strategies can be limited by considering "trigger strategies" <ref> [84] </ref>, and first-best strategies can be sustained in epsilon equilibria of the multiple encounters situation by the "trigger strategies." The trigger strategy for the contractor, denoted by , is very simple: It uses the effort level function ^e until the first encounter where the manager does not use the reward function
Reference: [85] <author> R. Radner. </author> <title> Monitoring cooperative agreements in a repeated principal-agent relationships. </title> <journal> Econometrica, </journal> <volume> 49(5) </volume> <pages> 1127-1148, </pages> <year> 1981. </year>
Reference-contexts: encounter a new contract is agreed upon by the agents. 6.1 Short Term Contracts Repetition of the encounters between the manager and the contractors enables the agents to reach efficient short term contracts if the number of encounters is large enough 27 and if the contractor can be "punished" sufficiently <ref> [85, 86, 43, 65, 27] </ref>. Based on the average outcome, the manager could form an accurate estimate of the contractor's effort over a certain amount of time. <p> That is, if the manager wants the contractor to make a certain effort level of ^e 2 Effort in all the encounters, it can compute the expected 27 In <ref> [85] </ref> the number of encounters should be larger than some thresholds, but finite and known to the agents. <p> If after several encounters the manager realizes that the cumulative outcome is below a given function of the expected outcome, it should impose a severe "punishment" on the contractor. If the function over the expected outcome is chosen carefully <ref> [85] </ref>, then the probability of imposing a "punishment" when the contractor is in fact carrying out the desired effort level, can be made very low. Meanwhile, the probability of eventually imposing the "punishment" if the agent does not do ^e is 1.0. <p> We denote the first-best solution by (^r; ^e) and the expected outcome in this case for the manager and the contractor by ^v and ^x, respectively. The notion of an epsilon equilibrium <ref> [85] </ref> will be used, although it imposes weaker restrictions on the agents' strategies than the restrictions imposed by Nash equilibrium. <p> We define B as the class of positive sequences (b n ) that satisfy (<ref> [85] </ref>): * b n are strictly increasing, and lim n!1 b n * there exists &gt; 1 such that b n b 0 n , n 1. The main result of [85] on these strategies is as follows: For any * &gt; 0 there exists a sequence (b n ) in B and T * , such that for all T T * the pair of strategies (((b n )); ) is an * equilibrium, and yields the manager and contractor average
Reference: [86] <author> R. Radner. </author> <title> Repeated principal agents games with discounting. </title> <journal> Econometrica, </journal> <volume> 53 </volume> <pages> 1173-1198, </pages> <year> 1985. </year>
Reference-contexts: encounter a new contract is agreed upon by the agents. 6.1 Short Term Contracts Repetition of the encounters between the manager and the contractors enables the agents to reach efficient short term contracts if the number of encounters is large enough 27 and if the contractor can be "punished" sufficiently <ref> [85, 86, 43, 65, 27] </ref>. Based on the average outcome, the manager could form an accurate estimate of the contractor's effort over a certain amount of time. <p> As a result of this phenomenon, the optimal contracts in situations where the number of encounters is small, will not be a simple function of the average outcomes [57] in 30 In <ref> [86] </ref> the situation of symmetric information with uncertainty is considered. That is, the situation of a single encounter is as in Section 4.2. It provides Pareto-optimal strategies only in the case that there are infinite encounters. 46 general.
Reference: [87] <author> E. Rasmusen. </author> <title> Moral hazard in risk-averse teams. </title> <journal> Rand Journal of Economics, </journal> <volume> 18(3):324|340, </volume> <year> 1987. </year>
Reference-contexts: the contractors choose the appropriate actions of the second best contract. 7.2 Individual Outcome is Not Observed There are other situations in which the manager cannot observe the individual outcome (or such an outcome does not exist), but rather can only observe the overall outcome of all the agents' efforts <ref> [42, 87] </ref>.
Reference: [88] <author> E. Rasmusen. </author> <title> Games and Information. </title> <publisher> Basil Blackwell Ltd., </publisher> <address> Cambridge, Ma, </address> <year> 1989. </year>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications. <p> Under these circumstances, there is no uncertainty concerning the results of the contractor's actions, i.e., the outcome is a function of the contractor's effort. If this function is known to both agents, then the manager can offer the contractor a forcing contract <ref> [34, 88, 16] </ref>, which means that the manager will pay the contractor only if it provides the outcome required by the manager. <p> The manager's problem is to find a contract that will maximize the manager's expected utility, knowing that the contractor may reject the contract or, even if it accepts the contract, the effort level will be chosen later <ref> [88] </ref>. The manager's reward to the contractor can be based only on the outcome. Let us assume that in the contract that will be offered by the manager, for any q i i = 1; :::; n; the manager will pay the contractor the reward r i . <p> world and the contractor's effort level, and in which the probabilistic function gives the probability of the state of the world which is independent of the contractor's effort level, is a special case of the model described here [81, 91, 34]. 21 problem can be constructed as follows (see also <ref> [88] </ref>). 14 M aximize r 1 ;:::;r n n X -(^e; q i )U m (q i ; r i ) (1) with the constraints: (IR) 1 (IC) ^e = argmax e2Effort n X -(e; q i )U c (e; r i ) (3) Equation (1) states that the manager tries
Reference: [89] <author> W. Rogerson. </author> <title> The first-order approach to the principle-agent problems. </title> <journal> Econometrica, </journal> <volume> 53(6) </volume> <pages> 1357-1367, </pages> <year> 1985. </year>
Reference-contexts: For this minimization problem there is an algorithm if U c satisfies several properties, including the property that the preferences of the contractor over entering uncertain situations are independent of its actions <ref> [31, 83, 89] </ref>. 17 That is, the contractor's preferences over reward lotteries are independent of its actions and effort level. <p> In both cases, since all variables are known, based on the suggested contract, these checks are very easy. 17 In <ref> [89] </ref> the problem of finding a contract when the manager can choose an effort level from a real interval is considered. Rogerson identifies the sufficient condition in which the constraints (IC) can be replaced with the requirement that the effort level be a stationary point for the contractor.
Reference: [90] <author> J. S. Rosenschein. </author> <title> Synchronization of multi-agent plans. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 115-119, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> August </month> <year> 1982. </year>
Reference-contexts: Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a group of agents (the slaves), and then hands out the pieces of the plan to the relevant individuals <ref> [90, 13, 60] </ref>. Werner [109] presents a formal logical model for a master-slave relationship by one-way communication. Also in the master-slave model there is no need to choose a level of effort and there is no need for incentive-contracting.
Reference: [91] <author> S. Ross. </author> <title> The economic theory of agency: The principal's problem. </title> <journal> The American Economic Review, </journal> <volume> 63(2) </volume> <pages> 134-139, </pages> <year> 1973. </year>
Reference-contexts: Assuming that each agent has its own personal goals, contracting would allow the agents to fulfill their goals more efficiently as opposed to working on their own. The issue of incentive contracting has been investigated in economics and game theory during the last two decades (e.g., <ref> [2, 91, 88, 31, 40, 56] </ref>). These works in economics and game theory consider different types of contracts for different applications. <p> in which the outcome is a function of the state of the world and the contractor's effort level, and in which the probabilistic function gives the probability of the state of the world which is independent of the contractor's effort level, is a special case of the model described here <ref> [81, 91, 34] </ref>. 21 problem can be constructed as follows (see also [88]). 14 M aximize r 1 ;:::;r n n X -(^e; q i )U m (q i ; r i ) (1) with the constraints: (IR) 1 (IC) ^e = argmax e2Effort n X -(e; q i )U c
Reference: [92] <author> S. Ross. </author> <title> Equilibrium and agency-inadmissible agents and in the public agency problem. </title> <journal> The American Economic Review, </journal> <volume> 69 </volume> <pages> 308-312, </pages> <year> 1979. </year>
Reference-contexts: A less risk-averse agent will usually have the ability to win over more risk-averse agents in service of any risk averse manager <ref> [92] </ref>. 42 the increase in the expected rewards to the other types of agents. The latter effect arises because, by increasing the probability that a report of z i will be chosen, the manager makes it more attractive for higher types to pretend to be z i .
Reference: [93] <author> A. Rubinstein and M. Yaari. </author> <title> Repeated insurance contracts and moral hazard. </title> <journal> Journal of Economic Theory, </journal> <volume> 30 </volume> <pages> 74-97, </pages> <year> 1983. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., <ref> [93, 34, 102, 58] </ref>); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist.
Reference: [94] <author> T. Sandholm. </author> <title> An implementation of the contract net protocol based on marginal cost calculations. </title> <booktitle> In Proc. of AAAI-93, </booktitle> <pages> pages 256-262, </pages> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: A modified version of the Contract Net protocol for competitive agents in the transportation domain is presented in <ref> [94] </ref>. It provides a formalization of the bidding and the decision awarding processes, based on marginal cost calculations based on local agent criteria. <p> Therefore, there is no need for monitoring (beside checking whether the deliveries were done or not) or incentives to the contractors to choose an efficient level of action. On the other hand, in <ref> [94] </ref>, Sandholm deals with the following challenging problems that are not considered part of our incentive contracting model: 2 * how to choose which tasks to contract out * how to cluster tasks into sets to bargain over as atomic bargaining * how to bid when multiple bids and awards should <p> be handled simultaneously * how to handle a large amount of messages consisting of bids and awards from other agents and how to prevent the agents from receiving announcements at a faster pace than they can process * how to decide to whom to award a set of tasks In <ref> [94] </ref> a set of experiments is described which demonstrates that the approach presented in that paper reduces the total transportation costs among autonomous dispatch centers. In [82] a language for specification of complex relations among agents in Cooperative Distributed Problem Solving is described. <p> In this paper, we also allow both of these addressing methods. 2 Some of these problems were considered by [101, 99, 67] but they are revisited in <ref> [94] </ref> while taking into consideration the specific domain. 9 Subcontracting in Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a group of agents (the slaves), and then hands <p> However, in situations where the agents (or their owners) are paid according to the outcomes of their activities and there is a direct relationship between effort and expense, it is easier to develop such evaluations and numerical utility functions. Examples of such domains include the transportation domain of <ref> [94] </ref> where agents may be paid according to the value of the deliveries they make and their expenses may depend on the number of miles they travel, their speed, weather, etc.
Reference: [95] <author> D. Sappington. </author> <title> Limited liability contracts between principle and agent. </title> <journal> Journal of Economic Theory, </journal> <volume> 29 </volume> <pages> 1-21, </pages> <year> 1983. </year> <month> 70 </month>
Reference-contexts: If it is possible for the contractor to cancel the contract after obtaining the information about the state of the world, then this possibility should be taken into consideration when the agents agree on the contract <ref> [95] </ref>. When the contractor can opt out of an agreement, the question is what are its alternatives at that point. It may be that it can still gets its original outside options, i.e., its reservation price ^u.
Reference: [96] <author> D. Sappington. </author> <title> Incentive contracting with asymmetric and imperfect precontractual knowledge. </title> <journal> Journal of Economic Theory, </journal> <volume> 34 </volume> <pages> 52-70, </pages> <year> 1984. </year>
Reference-contexts: In such situations the optimal strategy for the manager [36] is to design at most D distinct contracts from which the contractor can make a binding choice by sending a message to the manager. Thus the maximization problem of the manager is as follows <ref> [96] </ref>: M aximize f (q 1 1 ;r 1 1 ;r D D X d i=1 subject to: (IR) i=1 i e (q d (SS) i=1 i e (q d n X -d ( i )(r r i ; i )) 8r; d = 1; :::; D (26) i e (q
Reference: [97] <author> R. Selten. </author> <title> Re-examination of the perfectness concept for equilibrium points in extensive games. </title> <journal> International Journal of Game Theory, </journal> <volume> 4 </volume> <pages> 25-55, </pages> <year> 1975. </year>
Reference-contexts: When there are several stages of interaction among the agents, the Nash equilibrium strategies may involve threats that in certain senses, are not credible. In order to rule out such equilibria we use the concept of perfect equilibrium <ref> [97] </ref>.
Reference: [98] <author> S. Shavell. </author> <title> Risk sharing and incentives in the principal and agent relationship. </title> <journal> Bell Journal of Economics, </journal> <volume> 10 </volume> <pages> 55-79, </pages> <year> 1979. </year>
Reference-contexts: 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., [93, 34, 102, 58]); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client <ref> [98] </ref>, etc. In these situations two parties usually exist. The first party (called "the agent" in the economics literature) must choose an action or a level of effort from a number of possibilities, thereby affecting the outcome of both parties. <p> Furthermore, in most situations, the solution will be very simple: the manager will receive a fixed amount from the outcome, and the rest will go to the contractor. That is, r i = q i C for 1 i n, where the constant C is determined by constraint (IR:2) <ref> [98] </ref>. 14 As we mentioned above, we omitted the definitions of the variables in some of the formulas.
Reference: [99] <author> R. Smith. </author> <title> The contract net protocol: High-level communication and control in a distributed problem soler. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 29 </volume> <pages> 1104-1113, </pages> <year> 1980. </year>
Reference-contexts: The main problems addressed by <ref> [100, 101, 99] </ref> are as follows: Tasks decomposition: how to break a large task into smaller ones. Sub-tasks distribution: how to match sub-tasks with problem solvers capable of handling them. Synthesis of the overall solution: how to synthesize the individual results of sub-tasks into a single overall solution. <p> In this paper, we also allow both of these addressing methods. 2 Some of these problems were considered by <ref> [101, 99, 67] </ref> but they are revisited in [94] while taking into consideration the specific domain. 9 Subcontracting in Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a <p> We also deal with situations where agents are uncertain about the world, and the contractors (the producers in Wellman's terminology) may not carry out the tasks as promised. In our incentive-contract model and in the automated contracting frameworks <ref> [99] </ref> there is a hierarchical relationship among the agents. In most of the multi-agent systems (MA) where agents are self-motivated, there is no hierarchy among the agents that communicate and cooperate.
Reference: [100] <author> R. Smith and R. Davis. </author> <title> Framework for cooperation in distributed problem solvers. </title> <journal> IEEE Transactions on Systems, Man and Cybernetic, </journal> <volume> C-29(12):61-70, </volume> <year> 1981. </year>
Reference-contexts: However, work on automated contracting considers other problems essential to distributed problem solving as we discuss below. A well-known framework for automated contracting is the Contract Net protocol <ref> [100, 101] </ref>. In the Contract Net protocol a contract is an explicit agreement between an agent that generates a task (the manager) and an agent that is willing to execute the task (the contractor). <p> The main problems addressed by <ref> [100, 101, 99] </ref> are as follows: Tasks decomposition: how to break a large task into smaller ones. Sub-tasks distribution: how to match sub-tasks with problem solvers capable of handling them. Synthesis of the overall solution: how to synthesize the individual results of sub-tasks into a single overall solution.
Reference: [101] <author> R. Smith and R. Davis. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 63-109, </pages> <year> 1983. </year>
Reference-contexts: Research in Cooperative Distributed Problem Solving (e.g., <ref> [61, 59, 12, 101, 18] </ref>) considers how the work involved in solving a particular problem can be divided among a number of modules or "nodes." The modules in a Cooperative Distributed Problem Solving system are centrally designed to improve the following properties of the system [8]: Performance: Concurrency may increase the <p> This help can take the form of sharing tasks, results, or information [19]. In task sharing, an agent, which cannot fulfill a task on its own, will attempt to pass the task, in whole or in part, to other agents, usually on a contractual basis <ref> [101] </ref>. This approach assumes that an agent not otherwise occupied will readily take on the task and do it to the best of its abilities. Similarly, results and information are shared among agents in such environments with no expectation of reciprocation [61, 59, 12]. <p> However, work on automated contracting considers other problems essential to distributed problem solving as we discuss below. A well-known framework for automated contracting is the Contract Net protocol <ref> [100, 101] </ref>. In the Contract Net protocol a contract is an explicit agreement between an agent that generates a task (the manager) and an agent that is willing to execute the task (the contractor). <p> The main problems addressed by <ref> [100, 101, 99] </ref> are as follows: Tasks decomposition: how to break a large task into smaller ones. Sub-tasks distribution: how to match sub-tasks with problem solvers capable of handling them. Synthesis of the overall solution: how to synthesize the individual results of sub-tasks into a single overall solution. <p> In this paper, we also allow both of these addressing methods. 2 Some of these problems were considered by <ref> [101, 99, 67] </ref> but they are revisited in [94] while taking into consideration the specific domain. 9 Subcontracting in Cooperative Distributed Problem Solving also appears in the paradigm of planning for multiple agents, where a single intelligent agent (usually called the master) constructs a plan to be carried out by a
Reference: [102] <author> M. Spence and R. Zeckhauser. </author> <title> Insurance, information and individual action. </title> <journal> The American Economic Review, </journal> <volume> 61(1) </volume> <pages> 380-391, </pages> <year> 1971. </year>
Reference-contexts: Examples of these are contracts between: a firm and an employer or employers (e.g., [78, 6, 7, 64]); a government and taxpayers (e.g., [9]); a landlord and a tenant (e.g., [2]); an insurance company and a policy holder (e.g., <ref> [93, 34, 102, 58] </ref>); a buyer and a seller (e.g., [70, 77]); a government and firms (e.g., [72]); stockholders and managements (e.g., [2]); a professional and a client [98], etc. In these situations two parties usually exist.
Reference: [103] <author> W. Spivey and R. Thrall. </author> <title> Linear Optimization. </title> <publisher> Holt, Rinehart and Winston, INC, </publisher> <year> 1970. </year>
Reference-contexts: used depend primarily on the utility functions of the agents, as we will describe in the next two sections. 4.2.1 Risk Neutral Agents If the manager and the contractor are risk neutral, then solving the maximization problem can be done using any linear programming technique (e.g, simplex, see for example <ref> [83, 103] </ref>). Furthermore, in most situations, the solution will be very simple: the manager will receive a fixed amount from the outcome, and the rest will go to the contractor.
Reference: [104] <author> K. Sycara. </author> <title> Resolving Adversarial Conflicts: An Approach to Integrating Case-Based and Analytic Methods. </title> <type> PhD thesis, </type> <institution> School of Information and Computer Science, Georgia Institute of Technology, </institution> <year> 1987. </year>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents. <p> In our incentive-contract model and in the automated contracting frameworks [99] there is a hierarchical relationship among the agents. In most of the multi-agent systems (MA) where agents are self-motivated, there is no hierarchy among the agents that communicate and cooperate. For example, Sycara <ref> [105, 104] </ref> presents a model of negotiation that combines case-based reasoning and optimization of the multi-attribute utilities. This model is used 10 in labor management negotiations where two agents need to reach an acceptable agreement.
Reference: [105] <author> K. P. Sycara. </author> <title> Persuasive argumentation in negotiation. </title> <journal> Theory and Decision, </journal> <volume> 28 </volume> <pages> 203-242, </pages> <year> 1990. </year>
Reference-contexts: In our incentive-contract model and in the automated contracting frameworks [99] there is a hierarchical relationship among the agents. In most of the multi-agent systems (MA) where agents are self-motivated, there is no hierarchy among the agents that communicate and cooperate. For example, Sycara <ref> [105, 104] </ref> presents a model of negotiation that combines case-based reasoning and optimization of the multi-attribute utilities. This model is used 10 in labor management negotiations where two agents need to reach an acceptable agreement.
Reference: [106] <author> C. Waldspurger, T. Hogg, A. Huberman, J. Kephrat, and W. Stornetta. Spawn: </author> <title> A distributed computational economy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2):103|117, </volume> <year> 1992. </year>
Reference-contexts: In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., [4, 66, 39, 3, 45]). Researchers in distributed systems and distributed artificial intelligence (e.g., <ref> [41, 53, 106, 107] </ref>) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system. For example, Wellman [107] uses market price mechanisms for coordination and task distribution in distributed planning systems.
Reference: [107] <author> M. Wellman. </author> <title> A general-equilibrium approach to distributed transportation planning. </title> <booktitle> In Proc. of AAAI-92, </booktitle> <pages> pages 282-289, </pages> <address> San Jose, California, </address> <year> 1992. </year> <month> 71 </month>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents. <p> In the last 35 years, mathematical economists have developed market mechanism models describing how resources in an economy may be optimally shared in informationally and computationally decentralized ways (e.g., [4, 66, 39, 3, 45]). Researchers in distributed systems and distributed artificial intelligence (e.g., <ref> [41, 53, 106, 107] </ref>) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system. For example, Wellman [107] uses market price mechanisms for coordination and task distribution in distributed planning systems. <p> Researchers in distributed systems and distributed artificial intelligence (e.g., [41, 53, 106, 107]) applied these models to resource allocation and task distribution problems in computerized environments, where one of their main goals was to improve the overall performance of the system. For example, Wellman <ref> [107] </ref> uses market price mechanisms for coordination and task distribution in distributed planning systems. The agents are divided into consumers and producers and use an iterative method to adjust prices and reach an equilibrium.
Reference: [108] <author> M. Wellman and J. Doyle. </author> <title> Modular utility representation for decision-theoretic plan-ning. </title> <booktitle> In Proc. of AI planning Systems, </booktitle> <pages> pages 236|242, </pages> <address> Maryland, </address> <year> 1992. </year>
Reference-contexts: In such situations numeric utility functions and decision theory offer a normative model for choice under uncertainty by providing support in evaluating multiple objectives and value tradeoffs <ref> [46, 108] </ref>. 4 We therefore propose 3 A pair of strategies (; t ) is a Nash Equilibrium if, given t , no strategy of Agent 1 results in an outcome that Agent 1 prefers to the outcome generated by (; t ) and similarly for Agent 2 given .
Reference: [109] <author> E. Werner. </author> <title> Toward a theory of communication and cooperation for multiagent planning. </title> <booktitle> In Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 129-143, </pages> <address> Pacific Grove, California, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Werner <ref> [109] </ref> presents a formal logical model for a master-slave relationship by one-way communication. Also in the master-slave model there is no need to choose a level of effort and there is no need for incentive-contracting.
Reference: [110] <author> G. Zlotkin and J. S. Rosenschein. </author> <title> Incomplete information and deception in multi-agent negotiation. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <pages> pages 225-231, </pages> <address> Australia, </address> <year> 1991. </year>
Reference-contexts: Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules include the development of cooperating mechanisms designed to find a solution to a given problem. Research in MA (e.g., <ref> [104, 110, 107, 29, 48, 20] </ref>) is concerned with coordinating intelligent behavior among a collection of autonomous (possibly heterogeneous) intelligent (possibly preexisting) agents. In MA, there is no global control, and no globally shared goals or success criteria. There is, however, a possibility for real competition among the agents.
Reference: [111] <author> G. Zlotkin and J. S. Rosenschein. </author> <title> A domain theory for task oriented negotiation. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 416-422, </pages> <address> Chambery, France, </address> <month> August </month> <year> 1993. </year> <month> 72 </month>
Reference-contexts: Each agent, while wanting to minimize its costs, prefers to do as little as possible and therefore tries to reach an agreement over the division of labor. This model is also applicable when the agents need to share a resource. Zlotkin and Rosenschein <ref> [111] </ref> present a theoretical negotiation model for two rational agents which have symmetric capabilities and identical costs for their actions. Contracting in multi-agent systems was previously studied in [32].
References-found: 111

