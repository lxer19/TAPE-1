URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/craven.mlrgwp93.ps.Z
Refering-URL: 
Root-URL: 
Title: Track on AI and Molecular Biology). Machine Learning Approaches to Gene Recognition  
Author: Mark W. Craven Jude W. Shavlik 
Keyword: machine learning computational biology genetic sequence analysis neural networks decision trees nearest-neighbor methods Bayesian methods case-based reasoning  
Address: 1210 West Dayton St. Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin  
Note: Revised version submitted (3/94) to IEEE Expert (Special  
Email: email: fcraven, shavlikg@cs.wisc.edu  
Phone: phone: (608) 263-0475  
Abstract: Currently, a major computational problem in molecular biology is to identify genes in uncharacterized DNA sequences. The variation, complexity, and incompletely-understood nature of genes make it impractical to hand-code algorithms to recognize them. Machine learning methods which are able to form their own descriptions of genetic concepts offer a promising approach to this problem. This article surveys machine-learning approaches to identifying genes in DNA. We discuss two broad classes of gene-recognition approaches: search by signal and search by content. For both classes, we define the specific tasks that they address, describe how these tasks have been framed as machine-learning problems, and survey some of the machine-learning algorithms that have been applied to them. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. G. Cooper, </author> <title> editor. Los Alamos Science, Number 20: The Human Genome Project. </title> <institution> Los Alamos National Laboratory, </institution> <address> Los Alamos, NM, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Biological laboratories around the world are now sequencing large stretches of DNA from humans and other organisms <ref> [1] </ref>. Determining the nucleotide sequence of a DNA molecule, however, is only a first step toward the ultimate goals of (1) understanding the functionality and (2) knowing the locations of all of the genes and regulatory sites on the molecule. <p> Our description of this topic is quite simplified and ignores many salient aspects of molecular genetics. A thorough treatment of the biology underlying gene recognition can be found elsewhere <ref> [1, 2] </ref>. Our description emphasizes aspects of the biology that are relevant to finding genes by computational methods. A DNA molecule usually comprises two strands that coil around each other into a double helix. A strand of DNA is a linear sequence of chained nucleotides. <p> Shaded input units have activations of 1, the other input units have activations of 0. one for each possible value that the feature can have. The state of a unit is represented by its activation, which is typically a real-valued number in the range <ref> [0, 1] </ref>. The activations of the input units are set to represent the feature values of a particular instance. Real-valued weights connect input units to the output unit.
Reference: [2] <author> J. D. Watson, N. H. Hopkins, J. W. Roberts, J. A. Steitz, and A. M. Weiner. </author> <title> Molecular Biology of the Gene, volume I. </title> <address> Benjamin/Cummings, Menlo Park, CA, </address> <note> fourth edition, </note> <year> 1987. </year>
Reference-contexts: Our description of this topic is quite simplified and ignores many salient aspects of molecular genetics. A thorough treatment of the biology underlying gene recognition can be found elsewhere <ref> [1, 2] </ref>. Our description emphasizes aspects of the biology that are relevant to finding genes by computational methods. A DNA molecule usually comprises two strands that coil around each other into a double helix. A strand of DNA is a linear sequence of chained nucleotides.
Reference: [3] <author> G. D. Stormo, T. D. Schneider, L. Gold, and A. Ehrenfeucht. </author> <title> Use of the perceptron algorithm to distinguish translational initiation sites in E. coli. </title> <journal> Nucleic Acids Research, </journal> <volume> 10(9) </volume> <pages> 2997-3011, </pages> <year> 1982. </year>
Reference-contexts: Recognizing them, however, is not straightforward since the nucleotides present in the Shine-Dalgarno region show considerable variation in actual translation initiation sites. An early application of machine learning to molecular biology involved training perceptrons to recognize translation initiation sites in DNA of the bacterium E. coli <ref> [3] </ref>. As illustrated in Figure 4, a perceptron is an artificial neural network that has only one output unit and no hidden units. The input units of a perceptron represent features of the problem at hand.
Reference: [4] <author> J. Hertz, A. Krogh, and R. G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA, </address> <year> 1991. </year>
Reference-contexts: A comprehensive introduction to neural-network learning techniques can be found elsewhere <ref> [4] </ref>. In training perceptrons to recognize translation initiation sites, Stormo and his colleagues experimented with windows that were 101, 71, and 51 nucleotides wide. As in Figure 4, they used four input units to represent each nucleotide in the window.
Reference: [5] <author> G. Towell, J. Shavlik, and M. Noordewier. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1990. </year>
Reference-contexts: Several research groups have investigated using artificial neural networks to recognize promoters. One such group, Towell, Shavlik, and Noordewier have employed a novel approach, the Kbann algorithm, that combines neural network and symbolic learning <ref> [5] </ref>. The Kbann algorithm uses a set of approximately-correct, propositional rules to initialize the topology and weights of a neural network. After the network is initialized, ordinary neural-network learning techniques are used to adjust the weights.
Reference: [6] <author> A. Lapedes, C. Barnes, C. Burks, R. Farber, and K. Sirotkin. </author> <title> Application of neural networks and other machine learning algorithms to DNA sequence analysis. </title> <editor> In G. Bell and T. Marr, editors, </editor> <title> Computers and DNA, </title> <booktitle> SFI Studies in the Sciences of Complexity, </booktitle> <volume> vol. VII, </volume> <pages> pages 157-182. </pages> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Lapedes and his colleagues applied several machine learning approaches to the problem of recognizing splice junctions in human DNA <ref> [6] </ref>. In addition to artificial neural networks, they also used decision trees and k-nearest neighbor classifiers on this problem. Lapedes et al. used the ID3 algorithm [7] to induce decision trees.
Reference: [7] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Lapedes and his colleagues applied several machine learning approaches to the problem of recognizing splice junctions in human DNA [6]. In addition to artificial neural networks, they also used decision trees and k-nearest neighbor classifiers on this problem. Lapedes et al. used the ID3 algorithm <ref> [7] </ref> to induce decision trees. As illustrated in Figure 6, each internal node in a decision tree represents a test applied to one of the problem features. The branches emanating from a node represent the possible outcomes of the test.
Reference: [8] <author> T. M. Cover and P. E. Hart. </author> <title> Nearest neighbor pattern classification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 13 </volume> <pages> 21-27, </pages> <year> 1967. </year>
Reference-contexts: The ID3 algorithm uses an information-theoretic measure to determine which feature is branched on at each node. 11 Lapedes and his colleagues also applied a k-nearest neighbor approach <ref> [8] </ref> to the problem of splice-junction recognition. The k-nearest neighbor method is a simple learning technique that does not require any training per se. The concept representation is simply the entire training set.
Reference: [9] <author> R. Staden and A. D. McLachlan. </author> <title> Codon preference and its use in identifying protein coding regions in long DNA sequences. </title> <journal> Nucleic Acids Research, </journal> <volume> 10(1) </volume> <pages> 141-156, </pages> <year> 1982. </year>
Reference-contexts: By sliding the window of a trained classifier along a sequence, predictions can be generated for the entire length of the sequence. 5.1 Bayesian Approaches Several search-by-content methods, including Staden and McLachlan's codon usage method <ref> [9] </ref>, are based on Bayes' theorem. Given a window of nucleotides, their approach estimates the probability that each of the three reading frames of the strand encodes a protein.
Reference: [10] <author> M. Borodovsky and J. McIninch. </author> <title> Predictions of gene locations using DNA Markov chain models. </title> <editor> In H. Lim, J. Fickett, C. Cantor, and R. Robbins, editors, </editor> <booktitle> Proceedings of the Second International Conference on Bioinformatics, Supercomputing, and Complex Genome Analysis, </booktitle> <pages> pages 231-248. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1993. </year>
Reference-contexts: A frameshift error is indicated by a sharp drop in the plot of one reading frame accompanied by a steep increase in the plot of another frame. A related statistical method, the Markov chain model, has also been applied to gene recognition <ref> [10] </ref>. This approach, like the Bayesian method, is based on computing the likelihoods of encountering a given sequence in each reading frame and in noncoding DNA. In the Markov chain approach, however, a DNA sequence is viewed as being generated by a state-based model.
Reference: [11] <author> R. Farber, A. Lapedes, and K. Sirotkin. </author> <title> Determination of eucaryotic protein coding regions using neural networks and information theory. </title> <journal> Journal of Molecular Biology, </journal> <volume> 226 </volume> <pages> 471-479, </pages> <year> 1992. </year>
Reference-contexts: Because interactions among neighboring amino acids partly determine the shape, and hence the function of a protein, neighboring codons are certainly not independent. Farber, Lapedes, and Sirotkin have shown that better coding-region predictions can be gained by taking into account the joint probabilities of neighboring codons <ref> [11] </ref>. The problem that they addressed in their experiments was to distinguish introns from exons. They demonstrated that perceptrons are able to outperform Bayesian approaches because they can account for some of the dependence between neighboring codons.
Reference: [12] <author> E. C. Uberbacher and R. J. </author> <title> Mural. Locating protein coding regions in human DNA sequences by a multiple sensor neural network approach. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 88 </volume> <pages> 11261-11265, </pages> <year> 1991. </year>
Reference-contexts: Similarly, they found that using a feature representation of the individual nucleotides in the input window resulted in networks that did not generalize nearly as well as those that used a feature representation of codons. Uberbacher and Mural have also applied neural networks to coding-region recognition in eukaryotic DNA <ref> [12] </ref>. Their coding recognition module (CRM) is a component in an automated sequence-analysis server called Grail [13]. The heavily-used Grail server accepts DNA sequences via electronic mail, analyzes them, and then returns e-mail messages describing the results of its analysis.
Reference: [13] <author> E. C. Uberbacher, J. R. Einstein, X. Guan, and R. J. </author> <title> Mural. Gene recognition and assembly in the GRAIL system: Progress and challenges. </title> <editor> In H. Lim, J. Fickett, C. Cantor, and R. Robbins, editors, </editor> <booktitle> Proceedings of the Second International Conference on Bioinformatics, Supercomputing, and Complex Genome Analysis, </booktitle> <pages> pages 465-476. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1993. </year>
Reference-contexts: Uberbacher and Mural have also applied neural networks to coding-region recognition in eukaryotic DNA [12]. Their coding recognition module (CRM) is a component in an automated sequence-analysis server called Grail <ref> [13] </ref>. The heavily-used Grail server accepts DNA sequences via electronic mail, analyzes them, and then returns e-mail messages describing the results of its analysis. Uberbacher and Mural's research has also focused on finding a set of features that lead to good coding region predictions.
Reference: [14] <author> S. F. Altschul, W. Gish, W. Miller, E. W. Myers, and D. J. Lipman. </author> <title> Basic local alignment search tool. </title> <journal> Journal of Molecular Biology, </journal> <volume> 215 </volume> <pages> 403-410, </pages> <year> 1990. </year> <month> 20 </month>
Reference-contexts: Although dynamic programming methods are able to find the optimal partial match between two different-sized sequences, these methods are too expensive to be used with large sequence databases. There are, however, several fast approximations to dynamic programming that are commonly used to search for similar sequences <ref> [14] </ref>. An issue that arises in constructing a case memory is deciding what constitutes a case. 17 Our discussion to this point has assumed that each case is an entire protein sequence. An--other approach is to store protein domains as cases.
Reference: [15] <author> L. Hunter, N. Harris, and D. J. </author> <title> States. Efficient classification of massive, </title> <booktitle> unsegmented datas--treams. In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pages 224-232. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: How can a case memory of proteins and domains be assembled from a database of protein sequences? Hunter, Harris, and States have developed an unsupervised learning system that clusters related amino-acid sequences into domains and "families" of proteins <ref> [15] </ref>. Unlike the supervised learning methods which have been the focus of this article, unsupervised learning approaches are not told what the "correct" classes are, but instead they form their own class definitions.
Reference: [16] <author> N. L. Harris, D. J. States, and L. Hunter. ClassX: </author> <title> A browsing tool for protein sequence megaclassification. </title> <booktitle> In Proceedings of the 26th Hawaii International Conference on System Sciences, </booktitle> <pages> pages 554-563. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: Their unsupervised algorithm formed about 12,000 clusters; some of these corresponded to protein families, some represented functional domains, and some contained a mixture of whole and partial proteins. They have developed a tool, called ClassX <ref> [16] </ref>, that allows novel sequences to be matched against a case memory consisting of the clusters formed by their unsupervised learning algorithm. 6 Combined Methods Although we have discussed how each of the search-by-signal and search-by-content problems is addressed in isolation, the most promising approaches to gene-recognition combine predictions of several
Reference: [17] <author> R. Guigo, S. Knudsen, N. Drake, and T. Smith. </author> <title> Prediction of gene structure. </title> <journal> Journal of Molecular Biology, </journal> <volume> 226 </volume> <pages> 141-157, </pages> <year> 1992. </year>
Reference-contexts: The previously mentioned Grail system is one such multi-strategy approach; another is the GeneId system <ref> [17] </ref>. GeneId predicts initiation codons, stop codons, donor sites, and acceptor sites and then assembles these predictions into possible genes. GeneId, like Grail, is publicly available as an e-mail server on the Internet.
Reference: [18] <author> E. E. Snyder and G. D. Stormo. </author> <title> Identification of coding regions in genomic DNA sequences: An application of dynamic programming and neural networks. </title> <journal> Nucleic Acids Research, </journal> <volume> 21(3) </volume> <pages> 607-613, </pages> <year> 1993. </year>
Reference-contexts: GeneId predicts initiation codons, stop codons, donor sites, and acceptor sites and then assembles these predictions into possible genes. GeneId, like Grail, is publicly available as an e-mail server on the Internet. The GeneParser system, developed by Snyder and Stormo <ref> [18] </ref>, also integrates both signal and content predictions to identify introns and exons in DNA. GeneParser uses a dynamic-programming algorithm to predict the extent of individual exons and introns in a given DNA sequence.
Reference: [19] <editor> L. Hunter, D. Searls, and J. Shavlik, editors. </editor> <booktitle> Proceedings of the First International Conference on Intelligent Systems for Molecular Biology. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1993. </year> <month> 21 </month>
Reference-contexts: Biologists benefit from having effective, automated methods for analyzing sequence data. Machine learning researchers benefit from having important, real-world testbeds. 2 Because of these mutual interests, computational biology is a rapidly-growing field in its own right (e.g., see <ref> [19] </ref>).
References-found: 19

