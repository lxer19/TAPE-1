URL: http://www.cs.twsu.edu/~haynes/mpi.ps
Refering-URL: http://adept.cs.twsu.edu/~thomas/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: haynes@cs.twsu.edu  
Title: Distributed Collective Adaptation Applied to a Hard Combinatorial Optimization Problem  
Author: Thomas Haynes 
Address: Wichita, KS 67260  
Affiliation: Department of Computer Science Wichita State University  
Abstract: We utilize collective memory to integrate weak and strong search heuristics to find cliques in FC, a family of graphs. We construct FC such that pruning of partial solutions will be ineffective. Each weak heuristic maintains a local cache of the collective memory. We examine the impact on the distributed search from the various characteristics of the distribution of the collective memory, the search algorithms, and our family of graphs. We find the distributed search performs better than the individuals, even though the space of partial solutions is combinatorially explosive. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Decker, K. S.; Garvey, A. J.; Humphrey, M. A.; and Lesser, V. R. </author> <year> 1993. </year> <title> Control heuristics for scheduling in a parallel blackboard system. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence 7(2) </journal> <pages> 243-264. </pages>
Reference-contexts: Common knowledge is knowledge which is either learned through interaction with the environment or explicitly communicated from one individual to all others in the group. The collective memory can itself be either centralized or distributed (for examples of centralized and distributed blackboard architectures see (Corkill 1989) and <ref> (Decker et al. 1993) </ref>). Garland and Alterman present a distributed collective memory in their research: agents manipulate their own slice of the collective memory (Garland & Alterman 1996). In distributed programming, the main bottle is the interprocess communication (Pacheco 1997).
Reference: <author> Fennell, R. D., and Lesser, V. R. </author> <year> 1977. </year> <title> Parallelism in Artificial Intelligence problem solving: A case study of Hearsay II. </title> <journal> IEEE Transactions on Computers C-26(2):98-111. </journal> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 106-119, </address> <publisher> Morgan Kaufmann, 1988.). </publisher>
Reference-contexts: We can add a collective memory (either centralized or distributed) in the form of a blackboard system <ref> (Fennell & Lesser 1977) </ref> and restrict all communication between the search agents to take place via the blackboard. For NP-complete problems, search heuristics tend to produce many partial solutions, each of which may or may not expand to become complete solutions.
Reference: <author> Garey, M. R., and Johnson, D. S. </author> <year> 1979. </year> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <address> San Francisco, CA: </address> <publisher> W.H. Freeman and Co. </publisher>
Reference-contexts: Furthermore, we define a candidate clique to be a complete subgraph which may or may not be maximal. We consider two NP-complete problems, finding either the maximum clique, max clique (MC), of G or the set of all cliques, clique cover (CC), of G <ref> (Garey & Johnson 1979) </ref> (page 194): Covering by cliques: Given that G = (V; E) and a positive integer K E, are there are k K subsets V 1 ; V 2 ; : : : ; V k of V such that each V i induces a complete subgraph of
Reference: <author> Garland, A., and Alterman, R. </author> <year> 1996. </year> <title> Multiagent learning through collective memory. </title> <editor> In Sen, S., ed., </editor> <booktitle> Working Notes for the AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, </booktitle> <pages> 33-38. </pages>
Reference-contexts: The collective memory can itself be either centralized or distributed (for examples of centralized and distributed blackboard architectures see (Corkill 1989) and (Decker et al. 1993)). Garland and Alterman present a distributed collective memory in their research: agents manipulate their own slice of the collective memory <ref> (Garland & Alterman 1996) </ref>. In distributed programming, the main bottle is the interprocess communication (Pacheco 1997). While we have a centralized collective memory, we employ distributed caches to re 1 duce communication overhead.
Reference: <author> Goldberg, D. E. </author> <year> 1989. </year> <title> Genetic Algorithms in Search, Optimization & Machine Learning. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: For both, we use a maximum number of generations of 256, population size of 64, and linear scaling, with the maximum expected offspring being 2.0 <ref> (Goldberg 1989) </ref>.
Reference: <author> Goldberg, D. E. </author> <year> 1994. </year> <title> Genetic and evolutionary algorithms come of age. </title> <journal> Communications of the ACM 37(3) </journal> <pages> 113-119. </pages>
Reference: <author> Haynes, T. D. </author> <year> 1998. </year> <title> Collective Adaptation: The Sharing of Building Blocks. </title> <type> Ph.D. Dissertation, </type> <institution> The University of Tulsa. </institution>
Reference-contexts: We have used collective adaptation to solve two related NP-complete problems: finding the max clique and the set of all cliques in a graph <ref> (Haynes 1998) </ref>. <p> Each of these heuristics have corresponding algorithms in the original search space. Such algorithms quickly become infeasible as the problem complexity scales up. However, they can remain feasible in the focused search space <ref> (Haynes 1998) </ref>. As the performance of the MAC heuristic in the FC family of graphs is not characteristic of its performance in general, we will also consider a second family of graphs, FCR, which simply shu*es the vertex labels. <p> The search agents are GA1, GP, RS, HC, SA, and GA2. We employ two GA search agents because they have been shown to be the most effective in the serial case <ref> (Haynes 1998) </ref>. Each distributed cache and the centralized collective memory have their own process agents for both collating partial solutions and engaging in local search. We synchronize generations and epochs such that all heuristics proceed at the same pace. <p> However, we can determine all of the max cliques for all of the graphs. Finally, it is often the case the solution can not be generated within the given chromosomal structure; a collective memory must be used to store and integrate the solution <ref> (Haynes 1998) </ref>. In our experiments, we utilize a serial version as a baseline and have 3 variants of the distributed search. The serial version was the best performing system from (Haynes 1998) and utilized the GA system for the search heuristic and the process agent used the MRC algorithm. <p> not be generated within the given chromosomal structure; a collective memory must be used to store and integrate the solution <ref> (Haynes 1998) </ref>. In our experiments, we utilize a serial version as a baseline and have 3 variants of the distributed search. The serial version was the best performing system from (Haynes 1998) and utilized the GA system for the search heuristic and the process agent used the MRC algorithm. <p> For both of the variants which employed MAC (a1r0 and a1r1), we see that the num ber of cliques represented in the collective memory is 2 Not all serial versions are able to find the optimal for fc1-64.clq <ref> (Haynes 1998) </ref> small, but the number of nodes per clique is large. For those variants not utilizing MAC (a0r1 and serial), there tends to be many more partial solutions in the collective memory. <p> All of the distributed variants were able to find the maximum clique for this graph, but the best clique cover was was less than 40% of the graph. The serial version did not come close to discovering the maximum clique; as with all the serial versions from <ref> (Haynes 1998) </ref>, the search space is too large and it can not discover many partial solutions.
Reference: <author> Hogg, T., and Williams, C. P. </author> <year> 1993. </year> <title> Solving the really hard problems with cooperative search. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 231-236. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Hogg, T., and Williams, C. P. </author> <year> 1994. </year> <title> Expected gains from parallelizing constraint solving for hard problems. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 331-336. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: They de termined while the exchange of information was useful, if there are a large number of candidate solution, few of which can be extended to full solutions, then there is a decrease in the ability of the heuristics to effectively prune unproductive branches <ref> (Hogg & Williams 1994) </ref>. Search Algorithms A weak search heuristic utilizes minimal domain knowledge during the search process. In contrast, a strong search heuristic depends heavily on domain dependent knowledge to find a solution.
Reference: <author> Holland, J. H. </author> <year> 1975. </year> <booktitle> Adpatation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press. </publisher>
Reference-contexts: Otherwise, we accept with some probability, p = e jf (c 0 )f (c)j T , the worse solution. T is a parameter modeling a decreasing temperature; as it decreases, the probability of accepting a worse solution also decreases. The genetic algorithm (GA) <ref> (Holland 1975) </ref> approach maintains a population of chromosomes. After each chromosome has been evaluated, reproduction, a domain independent process, drives the creation of new chromosomes for the next population of solutions. Such a cycle of evaluation and reproduction is called a generation.
Reference: <author> Koza, J. R. </author> <year> 1992. </year> <title> Genetic Programming: On the Programming of Computers by Natural Selection. </title> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: They are integral to the schema theorem, which defines how the implicit parallel search of a GA "builds" better solutions over time (Holland 1975; Goldberg 1989). Genetic Programming (GP) <ref> (Koza 1992) </ref> is an offshoot of GA which utilizes the basic GA algorithm and also has the concepts of crossover and mutation. However, the canonical GP chromosome representation is a parse tree (S-expression) and the alphabet is n-ary.
Reference: <author> Mitchell, M.; Forrest, S.; and Holland, J. H. </author> <year> 1992. </year> <title> The royal road for genetic algorithms: Fitness landscapes and GA performance. In Toward a Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First Eu-ropean Conference on Artificial Life, </booktitle> <pages> 245-254. </pages> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Domain Characteristics We can illustrate that the combination of the low cardi-nality candidate cliques into higher cardinality candidate cliques meets the characteristics of a Royal Road function <ref> (Mitchell, Forrest, & Holland 1992) </ref>: 1) All of the desired building blocks are known in advance. 2) The landscape can be varied systematically. 3) The global optimum, and all local optimum, can be enumerated.
Reference: <author> Pacheco, P. </author> <year> 1997. </year> <title> Parallel Programming with MPI. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Garland and Alterman present a distributed collective memory in their research: agents manipulate their own slice of the collective memory (Garland & Alterman 1996). In distributed programming, the main bottle is the interprocess communication <ref> (Pacheco 1997) </ref>. While we have a centralized collective memory, we employ distributed caches to re 1 duce communication overhead.
Reference: <author> Talukdar, S. N.; Pyo, S. S.; and Giras, T. </author> <year> 1983. </year> <title> Asynchronous procedures for parallel processing. </title> <journal> IEEE Transactions on PAS PAS-102(11). </journal> <volume> 8 </volume>
References-found: 14

