URL: http://www.media.mit.edu/~daniel/papers/csu-thesis.ps.gz
Refering-URL: http://www.media.mit.edu/~daniel/research.html
Root-URL: http://www.media.mit.edu
Title: THESIS DESCRIPTION AND EVALUATION OF A META-SEARCH AGENT  
Author: Daniel E. Dreilinger 
Degree: Submitted by  In partial fulfillment of the requirements for the degree of Master of Science  
Date: Summer 1996  
Address: Fort Collins, Colorado  
Affiliation: Department of Computer Science  Colorado State University  
Abstract-found: 0
Intro-found: 1
Reference: [BDM + 95] <author> C. Mic Bowman, Peter B. Danzig, Udi Manber, Michael F. Schwartz, Darren R. Hardy, and Duane P. Wessels. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical report, </type> <institution> University of Colorado - Boulder, </institution> <year> 1995. </year>
Reference-contexts: The solution 11 described in this thesis involves a meta-index similar to that described in [GGMT94], but which differs in that no assumption is made about the availability of search engine indexes, which are often unavailable. 2.3.2.6 Harvest The Harvest system <ref> [BDMS94, BDM + 95] </ref> comprises an integrated set of tools developed by the Research Group on Resource Discovery and Directory Service of the Internet Research Task Force.
Reference: [BDMS94] <author> C. Mic Bowman, Peter B. Danzig, Udi Manber, and Michael F. Schwartz. </author> <title> Scalable internet resource discovery: research problems and approaches. </title> <journal> CACM, </journal> <volume> 37(8), </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: The solution 11 described in this thesis involves a meta-index similar to that described in [GGMT94], but which differs in that no assumption is made about the availability of search engine indexes, which are often unavailable. 2.3.2.6 Harvest The Harvest system <ref> [BDMS94, BDM + 95] </ref> comprises an integrated set of tools developed by the Research Group on Resource Discovery and Directory Service of the Internet Research Task Force.
Reference: [Bra] <author> Tim Bray. </author> <title> The Open Text Web Index. </title> <address> http://www.opentext.com/. </address>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web.
Reference: [CNE] <author> CNET. </author> <title> CNET's Virtual Software Library. </title> <address> http://vsl.cnet.com/. </address>
Reference-contexts: For example, Yahoo [FY94] and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool [YGM95, Yan] specialize in searching archives of recent Usenet news articles. Tools such as FTPSearch [EGB] and the Virtual Software Library <ref> [CNE] </ref> assist users in finding software and other items available via File Transfer Protocol (FTP).
Reference: [Cor] <author> Infoseek Corporation. </author> <title> Infoseek Net Search. </title> <address> http://www.infoseek.com/. </address>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web.
Reference: [Cro95] <author> William Cross. </author> <title> All-In-One Search Page. </title> <note> http://www.albany.net/allinone/, 1995. </note>
Reference-contexts: SavvySearch served as the foundation upon with the experiments reported in Chapter 5 were conducted. Chapter 3 describes SavvySearch in detail. 2.3.2.2 All-In-One Another type of resource commonly referred to as a meta-search engine is actually quite different from the others described here. Tools such as All-In-One <ref> [Cro95] </ref> and CUSI [Kos94] are essentially pages full of forms with which queries can be sent to a number 10 of different search engines. The selection process is entirely up to the user|they must type their query into a separate form for each query submission.
Reference: [DH95] <author> Daniel Dreilinger and Adele Howe. </author> <title> An information gathering agent for querying web search engines. </title> <type> Technical report, </type> <institution> Colorado State University, </institution> <year> 1995. </year> <type> TR 96-111. </type>
Reference-contexts: The display mechanism rank-orders the complete set of results, removes duplicates, and formats them for display by the user's Web browser. 2.3.2 Examples of Meta-Search Engines 2.3.2.1 SavvySearch SavvySearch <ref> [Dre95, DH95] </ref> is a Web meta-search engine designed to intelligently integrate over two dozen conventional search engines. It has been used to conduct several experiments investigating how to select appropriate resources. SavvySearch served as the foundation upon with the experiments reported in Chapter 5 were conducted. <p> a summary measure of the overall effectiveness or quality of a search engine. 15 3.2 Search Plans Information gathering on the Web can be viewed as a simple planning problem in which the goal is to find sites satisfying specific criteria and where the actions are queries to search engines <ref> [DH95] </ref>. Search plans are constrained by the resources available: how much time should be allocated to the query and how much of Internet resources should be consumed by it. <p> This chapter reports the design and findings of the pilot experiment in Section 5.1. Results of the longitudinal study are reported in Section 5.2. 5.1 Pilot Study A version of SavvySearch very similar to the one described in Chapter 3 was used to conduct several pilot studies <ref> [DH95] </ref>. An experiment (summarized in Table 5.1) was conducted to determine whether characteristics of the current design affected the quality of the information displayed to the user. Quality was measured in two ways: number of links followed per query (link-ratio) 1 and self-reported user satisfaction.
Reference: [Dre95] <author> Daniel Dreilinger. </author> <note> SavvySearch Home Page. http://www.cs.colostate.edu/~dreiling/smartform.html, 1995. </note>
Reference-contexts: As the number of resources increases, searching them all becomes prohibitively expensive; querying more search engines than necessary is an inefficient use of the Internet's resources. In addition, too many search results can overwhelm users and obscure those references that are most relevant. SavvySearch <ref> [Dre95] </ref>, a meta-search engine created by the author and described in Chapter 3, pays close attention to which resources are selected for an individual user's query. The primary version of SavvySearch described here employs a unique approach for selecting relevant search engines based on the terms in a user's query. <p> The display mechanism rank-orders the complete set of results, removes duplicates, and formats them for display by the user's Web browser. 2.3.2 Examples of Meta-Search Engines 2.3.2.1 SavvySearch SavvySearch <ref> [Dre95, DH95] </ref> is a Web meta-search engine designed to intelligently integrate over two dozen conventional search engines. It has been used to conduct several experiments investigating how to select appropriate resources. SavvySearch served as the foundation upon with the experiments reported in Chapter 5 were conducted. <p> Similar to Harvest, using WAIS in a meta-search context depends on global participation of information providers and is limited to other WAIS search engines. 12 Chapter 3 SAVVYSEARCH 3.1 Introduction SavvySearch, a meta-search engine, is an experimental searching tool which serves as a single interface to many conventional search engines <ref> [Dre95] </ref>. The original version of SavvySearch was created in March, 1995. Since then, one or more of its experimental variations has been publicly available. Users have emailed hundreds of favorable comments, several dozen less-than-favorable ones, and the daily usage has increased to over 20,000 queries per day.
Reference: [EGB] <author> Tor Egge, Hugo Eide Gunnarsen, and Stig Sther Bakken. </author> <note> FTP Search v3.1. http://ftpsearch.unit.no/ftpsearch. </note>
Reference-contexts: For example, Yahoo [FY94] and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool [YGM95, Yan] specialize in searching archives of recent Usenet news articles. Tools such as FTPSearch <ref> [EGB] </ref> and the Virtual Software Library [CNE] assist users in finding software and other items available via File Transfer Protocol (FTP).
Reference: [Eic94] <author> David Eichmann. </author> <title> Ethical web agents. </title> <booktitle> In Electronic Proceedings of the Second World Wide Web Conference '94: Mosaic and the Web, </booktitle> <year> 1994. </year> <note> http://www.ncsa.uiuc.edu/SDG/IT94/Proceedings/Agents/ eichmann.ethical/ethics.html. </note>
Reference-contexts: Furthermore, some experimental resources have features that are not readily generalized to the uniform format of meta-search engines, and thus must be accessed from the native interface. Search engines are insulated from their human users and thus no longer know who is making search requests <ref> [Eic94] </ref>. 3. Advertisements are not always propagated to end users. Currently, SavvySearch ignores advertisement banners displayed by search engines. While this obviously aids in the overall utility of a meta-search tool by reducing information overload, it does not work well with a conventional search engine's business model. <p> This operation must be performed in the presence of two goals: minimizing resource consumption and maximizing search quality. Resource limitations make it impractical to send every query to every known search engine and programs that did so would be considered poor citizens of the Internet <ref> [Eic94] </ref>. There are simply too many search engines|it is prohibitively expensive (from a 14 resource utilization point of view) to query dozens of search engines for each individual user, especially when some of the search engines are so specialized that they are unlikely to return relevant results for most queries.
Reference: [Fe92] <author> William B. Frakes and Ricardo Baeza-Yates (eds.). </author> <title> Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1992. </year>
Reference-contexts: The suffix removal process, called stemming, is carried out by applying a set of heuristic rules that are specific to a particular language, like English <ref> [Fe92] </ref>. 3 Due to the falling cost of storage, several new systems have achieved very promising results with phrase searching when the stop words are indexed as well. [WMB94] strongly endorses not removing stop words. 4 Along with every transformed word in the inverted index is a list of pointers to
Reference: [fNIDR] <institution> The Center for Networked Information Discovery and Retrieval. freewais. </institution> <note> http://wais.com/pub/freeware/. </note>
Reference-contexts: Similarly, the searching technology of the many diverse, unique Web artifacts cannot be replicated, but must be substituted with alternative technologies, such as WAIS and Glimpse [MW93]. 2.3.2.7 WAIS Wide Area Information System (WAIS) (and freeWAIS, a public domain version) <ref> [web, fNIDR] </ref> is a widely used information retrieval system. Content providers can use it to create a searchable index of their information. In addition, it is theoretically possible to search a meta-index of the hundreds of WAIS servers.
Reference: [FY94] <author> David Filo and Jerry Yang. </author> <note> Yahoo Home Page. http://www.yahoo.com/, 1994. </note>
Reference-contexts: In addition to the seven large-scale robot-based search engines 1 , which contain references to millions of Web pages, many more search engines specialize in a subset of the Web. For example, Yahoo <ref> [FY94] </ref> and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool [YGM95, Yan] specialize in searching archives of recent Usenet news articles.
Reference: [GB] <author> Paul Gauthier and Eric Brewer. </author> <note> Inktomi web services. http://inktomi.berkeley.edu/. </note>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web.
Reference: [GGMT94] <author> Luis Gravano, Hector Garca-Molina, and Anthony Tomasic. </author> <title> Precision and recall of GlOSS estimators for database discovery. </title> <booktitle> In Proceedings of the 3rd international Conference on Parallel and Distributed Information Systems (PDIS'94), </booktitle> <year> 1994. </year>
Reference-contexts: Users can manually select a checkbox for each possible search engine. Thus, users are blessed (or burdened) with the task of choosing the exact combination of databases to search. 2.3.2.5 GlOSS The GlOSS (Glossary-of-Servers Server) project <ref> [GGMT94] </ref> has suggested a solution to the text-database discovery problem. A meta-index is constructed by integrating the indexes of each of the databases. For each database and each word, the number of documents containing that word is included in the meta-index. <p> This could add a prohibitive amount of administrative complexity as the number of databases increases. The solution 11 described in this thesis involves a meta-index similar to that described in <ref> [GGMT94] </ref>, but which differs in that no assumption is made about the availability of search engine indexes, which are often unavailable. 2.3.2.6 Harvest The Harvest system [BDMS94, BDM + 95] comprises an integrated set of tools developed by the Research Group on Resource Discovery and Directory Service of the Internet Research
Reference: [IBM95] <institution> IBM. </institution> <note> InfoMarket Search. http://www.infomkt.ibm.com/, 1995. </note>
Reference-contexts: This system also has the benefit of pruning out unavailable resources and entirely irrelevant documents. There is a cost for this precision, however. Searching takes significantly longer than with other search engines as users must wait for all referenced documents to be retrieved. 2.3.2.4 InfoMarket IBM's InfoMarket Search tool <ref> [IBM95] </ref> sends queries to about ten search resources. Users can manually select a checkbox for each possible search engine. <p> But this wastes resources and in some cases is unacceptable. Another simple alternative is to give the user complete control by providing the opportunity for them to explicitly state which search engines are to be used, as in InfoMarket <ref> [IBM95] </ref>. The problem with this are that all users must be aware of the domains of expertise of each and every search engine.
Reference: [Kos94] <author> Martijn Koster. </author> <title> Configurable Unified Search Engine (CUSI). </title> <note> http://pubweb.nexor.co.uk/public/cusi/doc/about.html, 1994. </note>
Reference-contexts: Chapter 3 describes SavvySearch in detail. 2.3.2.2 All-In-One Another type of resource commonly referred to as a meta-search engine is actually quite different from the others described here. Tools such as All-In-One [Cro95] and CUSI <ref> [Kos94] </ref> are essentially pages full of forms with which queries can be sent to a number 10 of different search engines. The selection process is entirely up to the user|they must type their query into a separate form for each query submission.
Reference: [Mad95] <author> Steve Madere. </author> <note> DejaNews research service. http://dejanews3.dejanews.com/, 1995. </note>
Reference-contexts: In addition to the seven large-scale robot-based search engines 1 , which contain references to millions of Web pages, many more search engines specialize in a subset of the Web. For example, Yahoo [FY94] and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews <ref> [Mad95] </ref> and the Stanford Information Filtering Tool [YGM95, Yan] specialize in searching archives of recent Usenet news articles. Tools such as FTPSearch [EGB] and the Virtual Software Library [CNE] assist users in finding software and other items available via File Transfer Protocol (FTP).
Reference: [Mau94] <author> Michael Mauldin. Lycos, </author> <title> the catalog of the internet. </title> <note> http://www.lycos.com/, 1994. </note>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web. <p> This gets old rather quickly! For this reason many Web search engines have been created. Some of the larger ones attempt to index the Web in its entirety <ref> [Pin94, Mau94] </ref>. Numerous smaller Web search engines allow searching of considerably more focussed databases|names and email addresses or the full text of Shakespeare's plays, for example. Both the enormous robot-based search engines and 6 smaller more focussed search engines serve as invaluable Internet resources.
Reference: [MB] <author> Loius Monier and Mike Burrows. </author> <title> Alta Vista Search Engine. </title> <address> http://www.altavista.digital.com/. </address>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web.
Reference: [MW93] <author> Udi Manber and Sun Wu. Glimpse: </author> <title> A tool to search through entire file systems. </title> <type> Technical report, </type> <institution> University of Arizona, </institution> <month> October </month> <year> 1993. </year> <type> tr 93-34. </type>
Reference-contexts: Similarly, the searching technology of the many diverse, unique Web artifacts cannot be replicated, but must be substituted with alternative technologies, such as WAIS and Glimpse <ref> [MW93] </ref>. 2.3.2.7 WAIS Wide Area Information System (WAIS) (and freeWAIS, a public domain version) [web, fNIDR] is a widely used information retrieval system. Content providers can use it to create a searchable index of their information.
Reference: [Pin94] <author> Brian Pinkerton. </author> <note> WebCrawler Home Page. http://webcrawler.com/, 1994. </note>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web. <p> This gets old rather quickly! For this reason many Web search engines have been created. Some of the larger ones attempt to index the Web in its entirety <ref> [Pin94, Mau94] </ref>. Numerous smaller Web search engines allow searching of considerably more focussed databases|names and email addresses or the full text of Shakespeare's plays, for example. Both the enormous robot-based search engines and 6 smaller more focussed search engines serve as invaluable Internet resources.
Reference: [RH] <editor> Editor in Chief R.F. Holznagel. </editor> <title> Point Web Reviews. </title> <address> http://www.pointcom.com/ </address> . 
Reference-contexts: In addition to the seven large-scale robot-based search engines 1 , which contain references to millions of Web pages, many more search engines specialize in a subset of the Web. For example, Yahoo [FY94] and Point <ref> [RH] </ref> search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool [YGM95, Yan] specialize in searching archives of recent Usenet news articles.
Reference: [SE95a] <author> Erik Selberg and Oren Etzioni. </author> <title> Multi-service search and comparison using the MetaCrawler. </title> <booktitle> In Proceedings of the 4th International World Wide Web Conference, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: More thorough searching can be performed. Web search engines have thus far ex-perienced less than complete coverage of the Web's many documents <ref> [SE95a] </ref>. Additionally, some search engines specialize in a particular subset of the available information. The meta-search engine retrieves more of the relevant documents to a particular query. It has higher recall in information retrieval terminology. There are also several potential disadvantages: 1. <p> The selection process is entirely up to the user|they must type their query into a separate form for each query submission. Only one search engine is activated at a time, and the results appear in the native format of whichever search engine produced them. 2.3.2.3 MetaCrawler The MetaCrawler <ref> [SE95b, SE95a] </ref> is a meta-search project at the University of Wash-ington. This tool integrates a small set of general Web search engines and always dispatches queries to every search engine.
Reference: [SE95b] <author> Erik Selberg and Oren Etzioni. </author> <title> The MetaCrawler WWW Search Engine. </title> <note> http://metacrawler.cs.washington.edu:8080/home.html, 1995. </note>
Reference-contexts: The selection process is entirely up to the user|they must type their query into a separate form for each query submission. Only one search engine is activated at a time, and the results appear in the native format of whichever search engine produced them. 2.3.2.3 MetaCrawler The MetaCrawler <ref> [SE95b, SE95a] </ref> is a meta-search project at the University of Wash-ington. This tool integrates a small set of general Web search engines and always dispatches queries to every search engine. <p> Adjusting the meta-index for a No Results event is similar to the Visit adjustment, but a negative unit is used instead. 3.3.2 Approach II: Categorical Selection One simple alternative to a Meta-Index is to simply send the query to all search engines in all cases, as in MetaCrawler <ref> [SE95b] </ref>. But this wastes resources and in some cases is unacceptable. Another simple alternative is to give the user complete control by providing the opportunity for them to explicitly state which search engines are to be used, as in InfoMarket [IBM95]. <p> A well-defined ranking function can be applied to each document if the meta-search system is willing to retrieve each of the referenced documents, and its user is willing to wait <ref> [SE95b] </ref>. 3 This procedure only realizes approximate correctness. It is actually impossible to detect all duplicate URLs without actually retrieving their corresponding documents' full text, due to aliasing problems.
Reference: [Sof] <institution> Architext Software. excite Netsearch. </institution> <note> http://www.excite.com/. </note>
Reference-contexts: Still more search engines help us find email addresses, newspaper articles, technical reports, books, movie reviews, music recordings|a new database appears daily to satisfy yet another niche information need. 1 Specifically, these are Lycos, WebCrawler, Infoseek, Open Text, Inktomi, Excite, and Alta Vista <ref> [Mau94, Pin94, Cor, Bra, GB, Sof, MB] </ref>. These tools produce superb results. They serve as invaluable aids in simplifying the otherwise unmanageable task of navigating the Web.
Reference: [Tea96] <institution> The Internet Movie Database Team. The Internet Movie Database. </institution> <note> http://www.msstate.edu/Movies/, 1996. [web] webmaster@wais.com. WAIS Inc. http://www.wais.com/. </note>
Reference-contexts: When an irrelevant query is sent to a search engine, it will fail to produce any results. For example, asking the Internet Movie Database <ref> [Tea96] </ref> about a technical computer problem will invariably lead to a wasted query. Clearly, this type of event should be minimized in order to attain the goal of efficient use of Internet resources.
Reference: [WMB94] <author> Ian H. Witten, Alistair Moffat, and Timothy C. Bell. </author> <title> Managing Gigabytes: Compressing and Indexing Documents and Images. </title> <publisher> Von Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: process, called stemming, is carried out by applying a set of heuristic rules that are specific to a particular language, like English [Fe92]. 3 Due to the falling cost of storage, several new systems have achieved very promising results with phrase searching when the stop words are indexed as well. <ref> [WMB94] </ref> strongly endorses not removing stop words. 4 Along with every transformed word in the inverted index is a list of pointers to each document where that word occurs. <p> Search engines using the common Tf*Idf (Term Frequency times Inverse Document Frequency) ranking algorithm exploit two important qualities of natural language text to perform accurate retrieval <ref> [WMB94] </ref>: Frequency if a term occurs frequently in a document, that document is considered more relevant to a query than other documents with fewer or no occurrences of the same term. <p> Normalization adjustments are made to neutralize the dominant effect that longer documents would otherwise possess. Tf*Idf weighting is used to combine the frequency and scarcity information when ranking documents for a query <ref> [WMB94] </ref>. Term frequency, or Tf, is the number of times a term appears within a document. Symbolically, we can represent the term frequency of term t in document d using f d;t . 5 Inverse document frequency, or Idf, is a measure of the relative scarcity of a term.
Reference: [Yan] <author> Tak Woon Yan. </author> <title> Stanford Information Filtering Tool (SIFT). </title> <address> http://sift.stanford.edu/. </address>
Reference-contexts: For example, Yahoo [FY94] and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool <ref> [YGM95, Yan] </ref> specialize in searching archives of recent Usenet news articles. Tools such as FTPSearch [EGB] and the Virtual Software Library [CNE] assist users in finding software and other items available via File Transfer Protocol (FTP).
Reference: [YGM95] <author> Tak Woon Yan and Hector Garcia-Molina. </author> <title> SIFT a tool for wide-area information dissemination. </title> <booktitle> In Proceedings of the 1995 USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <institution> Stanford University, </institution> <year> 1995. </year> <month> 56 </month>
Reference-contexts: For example, Yahoo [FY94] and Point [RH] search within smaller, human-reviewed collections of Web site descriptions. DejaNews [Mad95] and the Stanford Information Filtering Tool <ref> [YGM95, Yan] </ref> specialize in searching archives of recent Usenet news articles. Tools such as FTPSearch [EGB] and the Virtual Software Library [CNE] assist users in finding software and other items available via File Transfer Protocol (FTP).
Reference: [Zil95] <author> Shlomo Zilberstein. </author> <title> An anytime computation approach to information gathering. </title> <booktitle> In Working Notes of the AAAI Spring Symposium Series on Information Gathering from Distributed, Heterogeneous Environments, </booktitle> <address> Palo Alto, CA, </address> <year> 1995. </year> <month> 57 </month>
Reference-contexts: This question has proven to be one of the most challenging aspects of the SavvySearch project. Resource reasoning is an additional challenge|the agent is expected to balance 16 17 network resource consumption against quality <ref> [Zil95] </ref>. Two contrasting approaches to dispatch have been explored so far: a meta-index and categorical selection. These are described in detail in the following two subsections. 3.3.1 Approach I: Meta-Index SavvySearch relies on considerable knowledge about current conditions and relationships between queries and search engines.
References-found: 31

