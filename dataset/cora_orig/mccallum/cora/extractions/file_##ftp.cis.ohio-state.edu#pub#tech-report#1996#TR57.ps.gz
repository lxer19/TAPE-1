URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1996/TR57.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: email: (mostafa,singhal)@cis.ohio-state.edu  
Phone: Phone: 614-292-5839 Fax: 614-292-2991  
Title: A Distributed Fault-Detection and Recovery Protocol for Reliable Multicast Collaborative Communications  
Author: Walid Mostafa Mukesh Singhal 
Keyword: Distibuted Fault-Tolerence, Reliable Multicast, Session Protocols, and Collaborative Communication.  
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Reliable multicast transport protocols support dissemination communication and their throughputs are either limited by the sender or by intermediate nodes that consolidate acknowledgements and retransmissions. RMSP is a portable reliable multicast protocol that supports collaborative communication at the session-layer level and provides higher throughput by maintaining two transport connections per node irrespective of the number of nodes. However, the throughput only of RMSP may degrade if one or more nodes or the centralized connection manager that monitors them fails. In this report, we propose a fully distributed fault-tolerant protocol, DFT-RMSP, that detects and isolates faulty nodes and reinstates the multicast collaborative communications. We derive analytic expressions for throughput degradation and analyze its sensitivity to node-failure rates, network delay, and multicast group size. We show that DFT-RMSP provides less downtime and achieves graceful throughput degradation under high failure rates compared with RMSP. simultaneous node failures. 
Abstract-found: 1
Intro-found: 1
Reference: [AFM92] <author> S. Armstrong, A. Freier, and K. Marzullo. </author> <title> "Multicast Transport Protocol ". Internet Request for Comment (RFC 1301), </title> <month> February </month> <year> 1992. </year>
Reference-contexts: Braudes and Zabele introduced in [BZ93] a Multicast Group Authority, MGA, that arranges nodes into a tree and requires a parent to poll its children for heartbeats to check their connectivity. The owner of the transmit token in the MTP protocol <ref> [AFM92] </ref> must transmit at least one message in every heartbeat or the master node assumes that it failed and generates a new transmission token. A source node in TRM [SBD96] send heartbeats periodically to the multicast group to declare its state when there is no data to transmit.
Reference: [BZ93] <author> R. Braudes and S. Zabele. </author> <title> "Requirements for Multicast Protocols ". Internet Request for Comment (RFC 1458), </title> <month> May </month> <year> 1993. </year>
Reference-contexts: Node failure detection and isolation is essential to maintain multicast communications, specially for nodes that assume a particular role besides receiving multicast traffic. For example, the failure of the master node in MTP <ref> [BZ93] </ref>, a domain manager node in TMTP [YGS95], or a designated receiver in [LP96] will terminate the multicast connection. Therefore, some protocols provide mechanisms to detect, isolate, and replace faulty nodes. A common mechanism for detecting node failure is a heartbeat. <p> The length of a heartbeat interval is impacted by the longest round-trip delay of communicating nodes. Longer heartbeat intervals delay the availability of information while shorter heartbeat intervals incur higher bandwidth utilization and require more processing. Braudes and Zabele introduced in <ref> [BZ93] </ref> a Multicast Group Authority, MGA, that arranges nodes into a tree and requires a parent to poll its children for heartbeats to check their connectivity. <p> Consequently, the heartbeat period must be long enough to accommodate message exchange with all nodes. Longer heartbeat periods imply delayed detection and isolation of faulty nodes and slower recovery of a multicast connection. Tree-based fault-detection protocols <ref> [BZ93] </ref> achieve better scalability but incur nonuniform overhead per node, e.g., non-leaf nodes are responsible for their children while leaf nodes have no responsibility.
Reference: [Che92] <author> D. Cheriton. </author> <title> "Dissemination-Oriented Communication Systems". </title> <note> DSG Working Paper, </note> <year> 1992. </year>
Reference-contexts: Multicast protocols provide a spectrum of services to cater for the needs of a wide array of multicast applications. Such protocols support multicast communications in two modes: dissemination and collaboration. Dissemination is a 1xR communication scheme where a single sender multicasts data to a group of R receivers <ref> [Che92] </ref>. Collaboration is a RxR communication scheme where each node is actively involved in multicasting data to and receiving data from all other (R 1) nodes [MS97a]. Fault-tolerance of multicast protocols addresses both reliable delivery of messages and maintaining multicast communication despite node failures.
Reference: [CM84] <author> J. Chang and N. F. Maxemchuk. </author> <title> Reliable broadcast protocols. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 251-273, </pages> <month> August </month> <year> 1984. </year> <month> 21 </month>
Reference-contexts: Fault-tolerance of multicast protocols addresses both reliable delivery of messages and maintaining multicast communication despite node failures. Reliable message delivery is accomplished using acknowledgements and message retransmissions and is classified into sender-initiated, receiver-initiated, and hierarchical approaches. Sender-initiated protocols <ref> [CM84] </ref> require a sender to maintain state information for each receiver using positive acknowledgements, ACKs. Receiver-initiated protocols [HSC95] rely on receivers to detect and request retransmission of missing packets using negative acknowledgements (NAKs).
Reference: [FJM + 95] <author> S. Floyd, V. Jacobson, S. McCanne, C. Liu, and L. Zhang. </author> <title> "A Reliable Multicast Framework for Light-weight Sessions and Application Level Framing". </title> <booktitle> In Proceedings of ACM SIGCOMM '95. ACM, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: Sender-initiated protocols [CM84] require a sender to maintain state information for each receiver using positive acknowledgements, ACKs. Receiver-initiated protocols [HSC95] rely on receivers to detect and request retransmission of missing packets using negative acknowledgements (NAKs). Hierarchical protocols, e.g., [YGS95] and <ref> [FJM + 95] </ref>), arrange nodes into a tree-like configuration to consolidate acknowledgements and localize retransmissions at a subtree level. Node failure detection and isolation is essential to maintain multicast communications, specially for nodes that assume a particular role besides receiving multicast traffic.
Reference: [HSC95] <author> H. Holbrook, S. Singhal, and D. Cheriton. </author> <title> "Log-Based Receiver-Reliable Multicast for Distributed Interactive Simulation". </title> <booktitle> In ACM SIGCOMM Conference. ACM, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: Reliable message delivery is accomplished using acknowledgements and message retransmissions and is classified into sender-initiated, receiver-initiated, and hierarchical approaches. Sender-initiated protocols [CM84] require a sender to maintain state information for each receiver using positive acknowledgements, ACKs. Receiver-initiated protocols <ref> [HSC95] </ref> rely on receivers to detect and request retransmission of missing packets using negative acknowledgements (NAKs). Hierarchical protocols, e.g., [YGS95] and [FJM + 95]), arrange nodes into a tree-like configuration to consolidate acknowledgements and localize retransmissions at a subtree level.
Reference: [Jac94] <author> Van Jacobson. </author> <title> "Multimedia Conferencing on the Internet". </title> <booktitle> In SIGCOMM 1994 Tutorial Notes. ACM, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The continuous growth in applications that require communications among a group of hosts or simultaneous dissemination of data to multiple sites on the Internet has led to considerable interests in multicast communication (e.g., video conferencing <ref> [Jac94] </ref> and distributed whiteboards [McC92]). Multicast protocols provide a spectrum of services to cater for the needs of a wide array of multicast applications. Such protocols support multicast communications in two modes: dissemination and collaboration.
Reference: [Kle75] <author> L. Kleinrock. </author> <title> Queueing Systems. </title> <publisher> John Wiley & Sons, </publisher> <year> 1975. </year>
Reference-contexts: Figure 5 illustrates a transition diagram of a multicast group with four nodes. 4.2 Birth-Death Model One approach to solve a general N -node state transition diagram is to use the Chapman-Kolomogorov equation <ref> [Kle75] </ref>. However, we are not interested in the steady-state behavior of all the different states of the multicast connection. Rather, we are only interested in those states where the multicast connection is up and active. <p> The transition rate i is defned similarly. The transition rates within a cluster i are not 11 required if we are only interested in the steady-state probability of this cluster. The steady state solution of this model can be found in <ref> [Kle75] </ref>.
Reference: [LP96] <author> J. Lin and S. Paul. "RMTP: </author> <title> A Reliable Multicast Transport Protocol ". In INFOCOM `96 Conference. </title> <publisher> IEEE, </publisher> <month> March </month> <year> 1996. </year>
Reference-contexts: Node failure detection and isolation is essential to maintain multicast communications, specially for nodes that assume a particular role besides receiving multicast traffic. For example, the failure of the master node in MTP [BZ93], a domain manager node in TMTP [YGS95], or a designated receiver in <ref> [LP96] </ref> will terminate the multicast connection. Therefore, some protocols provide mechanisms to detect, isolate, and replace faulty nodes. A common mechanism for detecting node failure is a heartbeat. A heartbeat is an interval of time that is relevant to the function of a transport protocol.
Reference: [McC92] <author> S. McCanne. </author> <title> "A Distributed Whiteboard for Network Conferencing". </title> <note> DSG Working Paper, </note> <year> 1992. </year>
Reference-contexts: 1 Introduction The continuous growth in applications that require communications among a group of hosts or simultaneous dissemination of data to multiple sites on the Internet has led to considerable interests in multicast communication (e.g., video conferencing [Jac94] and distributed whiteboards <ref> [McC92] </ref>). Multicast protocols provide a spectrum of services to cater for the needs of a wide array of multicast applications. Such protocols support multicast communications in two modes: dissemination and collaboration. Dissemination is a 1xR communication scheme where a single sender multicasts data to a group of R receivers [Che92].
Reference: [MS97a] <author> W. Mostafa and M. Singhal. </author> <title> "A Reliable Multicast Session Protocol for Collaborative Continuous-Feed Applications". </title> <booktitle> In 12th ACM Annual Symposium for Applied Computing [SAC'97]. ACM, </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: Dissemination is a 1xR communication scheme where a single sender multicasts data to a group of R receivers [Che92]. Collaboration is a RxR communication scheme where each node is actively involved in multicasting data to and receiving data from all other (R 1) nodes <ref> [MS97a] </ref>. Fault-tolerance of multicast protocols addresses both reliable delivery of messages and maintaining multicast communication despite node failures. Reliable message delivery is accomplished using acknowledgements and message retransmissions and is classified into sender-initiated, receiver-initiated, and hierarchical approaches. <p> A source node in TRM [SBD96] send heartbeats periodically to the multicast group to declare its state when there is no data to transmit. A connection manager in RMSP <ref> [MS97a] </ref> polls all nodes in a multicast group every heartbeat period and rearranges the connection around faulty nodes. Fault-detection using a centralized manager, e.g., RMSP [MS97a], does not scale well as the number of nodes in a multicast group increase. <p> A connection manager in RMSP <ref> [MS97a] </ref> polls all nodes in a multicast group every heartbeat period and rearranges the connection around faulty nodes. Fault-detection using a centralized manager, e.g., RMSP [MS97a], does not scale well as the number of nodes in a multicast group increase. This is because the manager has to send more polling messages and process more responses during a heartbeat period. Consequently, the heartbeat period must be long enough to accommodate message exchange with all nodes. <p> Thus, the fault-tolerance mechanism of RMSP is subject to poor scalability and longer heartbeat intervals as discussed earlier. In this report, we present DFT-RMSP; a distributed fault-detection, isolation, and recovery 2 protocol variation to the RMSP protocol <ref> [MS97a] </ref>. Our objective is improve the scalability of fault-detection and isolation and increase the overall throughput of multicast communication. We accomplish this by distributing fault-tolerance responsibilities among all nodes. <p> In Section 4, we develop analytic models of both centralized and distributed fault-detection and isolation and derive throughput-degradation expressions for each approach. Section 5 provides a performance comparison between the centralized and distributed fault-tolerance approaches. Summary and concluding remarks are presented in Section 6. 2 RMSP Overview RMSP <ref> [MS97a] </ref> is a reliable multicast session protocol for collaborative continuous-feed applications. It supports N xN group multicast communications at the session layer and runs on the top of existing reliable transport protocols (e.g., TCP). It does not assume multicast support at the network layer.
Reference: [MS97b] <author> W. Mostafa and M. Singhal. </author> <title> "Performance Analysis of a Reliable Multicast Session Protocol for Collaborative Continuous-Feed Applications". </title> <booktitle> In Fifth International Symposium on Modeling, Analysis, </booktitle> <institution> and Simulation of Computer and Telecommunication Systems [MASCOTS'97]. IEEE Computer Society, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: It multiplexes messages from different nodes into transport packets to reduce the transport-layer processing requirements per message. It requires only two transport-level connections per node, irrespective of the multicast group size, to reduce the processing requirements of acknowledgements and retransmissions per node. Analytical studies <ref> [MS97b] </ref> show that the protocol yields higher throughput than general sender-initiated and receiver-initiated reliable multicast transport protocols [PSK94]. RMSP maintains all multicast communication information at the session level.
Reference: [PSK94] <author> S. Paul, K. Sabnani, and D. Kristol. </author> <title> "Multicast Transport Protocols for High Speed Networks ". In Proceedings of International Conference on Network Protocols, </title> <month> October </month> <year> 1994. </year>
Reference-contexts: It requires only two transport-level connections per node, irrespective of the multicast group size, to reduce the processing requirements of acknowledgements and retransmissions per node. Analytical studies [MS97b] show that the protocol yields higher throughput than general sender-initiated and receiver-initiated reliable multicast transport protocols <ref> [PSK94] </ref>. RMSP maintains all multicast communication information at the session level. It has a data structure for every session in the multicast group to maintain state information (e.g., last message received, last message sent, last message acknowledged, etc.). The transport layer has no knowledge of the multicast group.
Reference: [SBD96] <author> B. Sabata, M. Brown, and B. Denny. </author> <title> "Transport Protocol for Reliable Multicast: </title> <booktitle> TRM ". In Proccedings of the IASTED International Conference on Networks. IEEE, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: The owner of the transmit token in the MTP protocol [AFM92] must transmit at least one message in every heartbeat or the master node assumes that it failed and generates a new transmission token. A source node in TRM <ref> [SBD96] </ref> send heartbeats periodically to the multicast group to declare its state when there is no data to transmit. A connection manager in RMSP [MS97a] polls all nodes in a multicast group every heartbeat period and rearranges the connection around faulty nodes.
Reference: [YGS95] <author> R. Yavatkar, J. Griffioen, and M. Sudan. </author> <title> "A Reliable Dissemination Protocol for Interactive Collaborative Applications". </title> <booktitle> In ACM Multimedia Conference. ACM, 1995. </booktitle> <volume> 22 23 24 25 </volume>
Reference-contexts: Sender-initiated protocols [CM84] require a sender to maintain state information for each receiver using positive acknowledgements, ACKs. Receiver-initiated protocols [HSC95] rely on receivers to detect and request retransmission of missing packets using negative acknowledgements (NAKs). Hierarchical protocols, e.g., <ref> [YGS95] </ref> and [FJM + 95]), arrange nodes into a tree-like configuration to consolidate acknowledgements and localize retransmissions at a subtree level. Node failure detection and isolation is essential to maintain multicast communications, specially for nodes that assume a particular role besides receiving multicast traffic. <p> Node failure detection and isolation is essential to maintain multicast communications, specially for nodes that assume a particular role besides receiving multicast traffic. For example, the failure of the master node in MTP [BZ93], a domain manager node in TMTP <ref> [YGS95] </ref>, or a designated receiver in [LP96] will terminate the multicast connection. Therefore, some protocols provide mechanisms to detect, isolate, and replace faulty nodes. A common mechanism for detecting node failure is a heartbeat.
References-found: 15

