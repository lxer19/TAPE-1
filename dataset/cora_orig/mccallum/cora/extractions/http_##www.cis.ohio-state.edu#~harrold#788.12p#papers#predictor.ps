URL: http://www.cis.ohio-state.edu/~harrold/788.12p/papers/predictor.ps
Refering-URL: http://www.cis.ohio-state.edu/~harrold/788.12p/readings.html
Root-URL: 
Title: Empirical Studies of a Prediction Model for Regression Test Selection recently proposed coverage-based predictors for
Author: Mary Jean Harrold David Rosenblum Gregg Rothermel Elaine Weyuker White, Rosenblum and Weyuker 
Note: Rosenblum and Weyuker  
Date: January 27, 1998  
Abstract: Regression testing is an important testing activity that can account for a large proportion of the cost of software maintenance. One approach to reducing the cost of regression testing is to employ a selective regression testing technique that (1) selects a subset of a test suite that was used to test the software before the modifications, and then (2) uses this subset to test the modified software. Selective regression testing techniques reduce the cost of regression testing if the cost of selecting the subset from the test suite together with the cost of running the selected subset of tests is less than the cost of running the entire test suite. To further investigate the applicability of the Rosenblum-Weyuker (RW) predictor, we have performed additional empirical studies. We applied the RW predictor to a number of subjects, using two different selective regression testing tools, DejaVu and TestTube. Our studies support two conclusions. First, they show that for some of the subject programs, the RW model fares rather well at predicting whether test selection will be effective on average over the modified versions of a base program, whereas for other subject programs it does not fare as well as it fared in the initial case study. Second, the studies show that, for the subjects utilized, the RW predictor fares worse at predicting test selection results for specific modified versions. These results suggest that an effective predictive model for safe regression test selection techniques should also account for the distribution of modifications. We show how the RW prediction model can be improved to provide such an accounting.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Balcer, W. Hasling, and T. </author> <title> Ostrand. Automatic generation of test scripts from formal test specifications. </title> <booktitle> In Proceedings of the Third Symposium on Software Testing, Analysis, and Verification, </booktitle> <pages> pages 210-218, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: To create these test pools, they first created an initial test pool of black-box tests "according to good testing practices, based on the tester's understanding of the program's functionality and knowledge of . . . the code," using the category partition method and the Siemens Test Specification Language tool <ref> [1, 8] </ref>. They then created additional white-box tests by hand to ensure that each executable statement, edge, and definition-use pair in the base program or its control flow graph was exercised by at least 30 tests.
Reference: [2] <author> B. Beizer. </author> <title> Software Testing Techniques. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction Regression testing is an important testing activity that can account for a large proportion of the cost of software maintenance <ref> [2, 6] </ref>. Regression testing is performed on modified software to provide confidence that the software behaves correctly and that modifications have not adversely impacted the software's quality. One approach to reducing the cost of regression testing is to employ a selective regression testing technique.
Reference: [3] <author> Y.F. Chen, D.S. Rosenblum, and K.P. Vo. TestTube: </author> <title> A system for selective regression testing. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 211-222, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Furthermore, other studies performed independently by Rosenblum and Weyuker with a different selective regression testing algorithm, implemented as a tool called TestTube <ref> [3] </ref>, also show that such methods are not always cost-effective [9]. When selective regression testing is not efficient, the resources spent performing the test case selection are wasted.
Reference: [4] <author> W. Harrison and C. Cook. </author> <title> Insights on improving the maintenance process through software measurement. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1990, </booktitle> <pages> pages 37-45, </pages> <month> November </month> <year> 1990. </year> <month> 16 </month>
Reference-contexts: One approach is 14 to utilize change history information about the program, often available from configuration management systems. Assuming that the change histories do accurately model the pattern of future modifications (a result suggested by the work of Harrison and Cook <ref> [4] </ref>), we can use this information to compute probabilities and use these as weights in M .
Reference: [5] <author> M. Hutchins, H. Foster, T. Goradia, and T. </author> <title> Ostrand. Experiments on the effectiveness of dataflow--and controlflow-based test adequacy criteria. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 191-200, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Therefore, to empirically investigate the effectiveness of the predictor, we performed two new studies. For these studies, we used seven C programs as subjects; these programs were used in an earlier study by researchers at Siemens Corporate Research to compare control flow-based and data flow-based coverage criteria <ref> [5] </ref>. The researchers at Siemens sought to study error detection; thus, they created faulty modified versions of the seven base programs by manually seeding faults into those programs.
Reference: [6] <author> H.K.N. Leung and L.J. White. </author> <title> Insights into regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1989, </booktitle> <pages> pages 60-69, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Regression testing is an important testing activity that can account for a large proportion of the cost of software maintenance <ref> [2, 6] </ref>. Regression testing is performed on modified software to provide confidence that the software behaves correctly and that modifications have not adversely impacted the software's quality. One approach to reducing the cost of regression testing is to employ a selective regression testing technique.
Reference: [7] <author> H.K.N. Leung and L.J. White. </author> <title> A cost model to compare regression test strategies. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1991, </booktitle> <pages> pages 201-208, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: One of these predictors is used to predict whether a safe selective regression testing strategy (one that selects all tests that cover affected entities) will be cost-effective. Using the regression testing cost model of Leung and White <ref> [7] </ref>, Rosenblum and Weyuker demonstrate the usefulness of this predictor by describing the results of a case study they performed involving 31 versions of the Korn shell [9]. In that study, the predictor reported that, on average, it was expected that 87.3% of the test cases would be selected. <p> Their model builds on work by Leung and White on modeling the cost of employing a regression testing method <ref> [7] </ref>. In both models, the total cost of regression testing incorporates two factors: the cost of executing test cases and the cost of performing analyses to support test selection.
Reference: [8] <author> T.J. Ostrand and M.J. Balcer. </author> <title> The category-partition method for specifying and generating functional tests. </title> <journal> Communications of the ACM, </journal> <volume> 31(6), </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: To create these test pools, they first created an initial test pool of black-box tests "according to good testing practices, based on the tester's understanding of the program's functionality and knowledge of . . . the code," using the category partition method and the Siemens Test Specification Language tool <ref> [1, 8] </ref>. They then created additional white-box tests by hand to ensure that each executable statement, edge, and definition-use pair in the base program or its control flow graph was exercised by at least 30 tests.
Reference: [9] <author> D. S. Rosenblum and E. J. Weyuker. </author> <title> Using coverage information to predict the cost-effectiveness of regression testing strategies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 23(3) </volume> <pages> 146-156, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: Furthermore, other studies performed independently by Rosenblum and Weyuker with a different selective regression testing algorithm, implemented as a tool called TestTube [3], also show that such methods are not always cost-effective <ref> [9] </ref>. When selective regression testing is not efficient, the resources spent performing the test case selection are wasted. Thus, Rosenblum and Weyuker argue in [9] that it would be very desirable to have a predictor that is very inexpensive to apply but could indicate whether or not using a selective regression <p> Rosenblum and Weyuker with a different selective regression testing algorithm, implemented as a tool called TestTube [3], also show that such methods are not always cost-effective <ref> [9] </ref>. When selective regression testing is not efficient, the resources spent performing the test case selection are wasted. Thus, Rosenblum and Weyuker argue in [9] that it would be very desirable to have a predictor that is very inexpensive to apply but could indicate whether or not using a selective regression testing method is likely to be worthwhile. With this motivation, Rosenblum and Weyuker [9] propose coverage-based predictors for use in predicting the cost-effectiveness of <p> Thus, Rosenblum and Weyuker argue in <ref> [9] </ref> that it would be very desirable to have a predictor that is very inexpensive to apply but could indicate whether or not using a selective regression testing method is likely to be worthwhile. With this motivation, Rosenblum and Weyuker [9] propose coverage-based predictors for use in predicting the cost-effectiveness of selective regression testing strategies. Their predictors use the average percentage of test cases that execute coverable entities|such as statements, branches, or functions|to predict the number of tests that will be selected when a change is made to those entities. <p> Using the regression testing cost model of Leung and White [7], Rosenblum and Weyuker demonstrate the usefulness of this predictor by describing the results of a case study they performed involving 31 versions of the Korn shell <ref> [9] </ref>. In that study, the predictor reported that, on average, it was expected that 87.3% of the test cases would be selected. Using the TestTube approach, 88.1% were actually selected. <p> The authors explain, however, that because of the way their selective regression testing model employs averages, the accuracy of their predictor might vary significantly in practice. In particular, this is an issue if there is a wide variation in the distribution of changes among entities <ref> [9] </ref>. However, because their predictor is intended to be used for predicting the long-term behavior of a method over multiple versions, they argue that the use of averages is acceptable. <p> In the following sections we discuss the results of these studies. 2 The Rosenblum-Weyuker Regression Test Selection Model and Predictor Rosenblum and Weyuker present a formal model of regression testing to support the definition and computation of predictors of cost-effectiveness <ref> [9] </ref>. Their model builds on work by Leung and White on modeling the cost of employing a regression testing method [7]. In both models, the total cost of regression testing incorporates two factors: the cost of executing test cases and the cost of performing analyses to support test selection. <p> The models view cost-effectiveness as being an inherent attribute of test selection over the complete maintenance life-cycle, rather than an attribute of individual versions. As in <ref> [9] </ref>, we let P denote the system under test, S denote the specification of P , and T be the regression test suite for P , with jT j denoting the size of T . <p> N C CC Then the fraction of the test suite that must be rerun is denoted M , the predictor for jT M j=jT j: M = M = jE C jjT j Rosenblum and Weyuker <ref> [9] </ref> discuss results of a case study in which test selection and predictor results are compared for 31 versions of the KornShell using the TestTube selective regression testing method. <p> It was determined during the case study described in <ref> [9] </ref> that for the KornShell system, the relation covers M (t; e) changes very little during maintenance. <p> was defined to be: C i;j = 1 if covers M (i; j) 0 otherwise: For this weighted average, the fraction of the test suite T that must be rerun, denoted by M , is given as follows: M = M Note that the RW predictor, M , introduced in <ref> [9] </ref> and described in Section 2, is a version of this weighted predictor in which w i is 1 jE C j for all e i : W N C jT j P jE C j 1 P jT j jT j P jE C j P jT j jE C <p> Assume that the patterns are generalized over a large number of entities, n. As discussed by Rosenblum and Weyuker <ref> [9] </ref>, using M , the value predicted for each pattern is 2=n. In Pattern A, the test cases are distributed evenly over the coverable entities, and thus, M and M are the same, and yield the exact number of test cases that would be selected by either DejaVu or TestTube. <p> For Pattern B, in contrast, the RW predictor is never exact and is significantly inaccurate for the core element of that pattern. Suppose, however, that, instead of assuming an equally likely change probability for each entity in Pattern B as was tacitly assumed in <ref> [9] </ref>, we had information about the probability of modifications of individual entities. In this case, using the weighted predictor, we could compute a more accurate W N C M .
Reference: [10] <author> G. Rothermel and M.J. Harrold. </author> <title> Analyzing regression test selection techniques. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(8) </volume> <pages> 529-551, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: During the preliminary phase, changes are made to the software, and the new version of the software is built. During the critical phase, the new version of the software is tested prior to its release to customers <ref> [10] </ref>. 15 Using the weighted predictor, M , as a version-specific predictor will be especially appropriate for test suites whose test cases are not evenly distributed across the entities, such as the case illustrated by Pattern B, where test selection results for specific versions may differ widely from average test selection
Reference: [11] <author> G. Rothermel and M.J. Harrold. </author> <title> A safe, efficient regression test selection technique. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 6(2) </volume> <pages> 173-210, </pages> <year> 1997. </year> <month> 17 </month>
Reference-contexts: Empirical results obtained by Rothermel and Harrold on the effectiveness of their selective regression testing algorithms, implemented as a tool called DejaVu, suggest that test selection can be effective in reduc ing the cost of regression testing by reducing the number of test cases that need to be rerun <ref> [11] </ref>. However, 1 Department of Computer and Information Science, Ohio State University. 2 Department of Information and Computer Science, University of California, Irvine. 3 Department of Computer Science, Oregon State University. 4 AT&T Research. 1 these studies also show that there are cases in which their algorithm is not cost-effective.
References-found: 11

