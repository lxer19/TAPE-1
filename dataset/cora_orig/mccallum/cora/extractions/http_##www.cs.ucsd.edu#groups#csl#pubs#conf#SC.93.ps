URL: http://www.cs.ucsd.edu/groups/csl/pubs/conf/SC.93.ps
Refering-URL: http://www.cs.ucsd.edu/groups/csl/pubs/author.html
Root-URL: http://www.cs.ucsd.edu
Email: bittel, polyzos-@cs.ucsd.edu  
Title: the growing system imbalance between CPU and I/O performance. Now however, scientific research based on
Author: Barbara K. Pasquale and George C. Polyzos 
Keyword: virtual I/O rate  
Address: La Jolla, CA 92093-0114  
Affiliation: Computer Systems Laboratory Department of Computer Science and Engineering University of California, San Diego  
Note: 1.0 Introduction Until recently, little concern has been expressed over  A  This work is funded in part by grants from DEC, the U.C. Micro program, and the Sequoia 2000 Project.  
Abstract: Past research on high performance computers for scientific applications has concentrated on CPU speed and exploitation of parallelism, but has, until very recently, neglected I/O considerations. This paper presents a study of the production workload at the San Diego Supercomputer Center from an I/O requirements and characteristics perspective. Results of our analyses support our hypothesis that a significant proportion of I/O intensive, long running, frequently executed scientific applications have predict able I/O requirements. Past efforts in the development of high performance computer systems have been primarily focused on the computational speeds of processors, often ignoring other important system components, such as the I/O subsystem and the operating system [3, 8, 18, 20]. Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem [1, 8, 9]. Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance [1, 8, 9, 11, 12, 19]. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13]. In order to maintain well-balanced systems, we must establish a thorough understanding of the I/O behavior of scientific applications, and from this knowledge, design the mechanisms and implement the policies that are needed to improve the I/O subsystem and provide these I/O intensive applications with their needed resources without degrading overall system performance. The research presented in this paper describes an I/O workload characterization study of the Cray Y-MP8/864 at SDSC intended to identify I/O intensive applications and to quantify their resource demands. Our goal here is to present some of the observations of that study and to investigate the hypothesis that a high proportion of I/O intensive applications exhibit regular behavior. The I/O metrics considered in this study include the number of total bytes transferred by an application, the number of bytes transferred per CPU second, and the number and average virtual rate of logical I/O requests. We are interested in identifying a set of I/O intensive applications and in summarizing their I/O resource usage in a way that describes the relationship between the applications, their resource usage, and their contribution to the entire system workload. The remainder of this paper is organized as follows. In section 2 we discuss the motivation for investigating I/O behavior, and particularly, the roles of static and dynamic characterizations. We also discuss two recent scientific application I/O studies, and present our hypothesis. In section 3 we provide a description of the observed environment at the SDSC. In sections 4 and 5 we progressively present our selection of interesting subsets of the workload and we describe the analyses performed and results obtained. Our conclusions are presented in section 6. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> Bell, G., </author> <title> The Future of High Performance Computers in Science and Engineering, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 32, No. 9, </volume> <pages> pp. 1091-1101, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem <ref> [1, 8, 9] </ref>. Until recently, little concern has been expressed over the growing system imbalance between CPU and I/O performance. Now however, scientific research based on computational approaches has intensified and the number of I/ O intensive scientific applications is increasing. <p> Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13].
Reference: [2] <author> Calzarossa, M., and Ferrari, D., </author> <title> A Sensitivity Study of the Clustering Approach to Workload Modeling, </title> <journal> Performance Evaluation, </journal> <volume> Vol. 6, </volume> <pages> pp. 25-33, </pages> <publisher> North-Holland, </publisher> <year> 1986. </year>
Reference-contexts: An average logical I/O request rate was also calculated for each resulting cluster. Although clustering algorithms are nontrivial because they must recognize nearness among the characteristic parameters selected, Calzarossa and Ferrari <ref> [2] </ref> found that the nonhierarchical means algorithm produces reliable results for workload characterization and modeling.
Reference: [3] <author> Calzarossa, M., and Serazzi, G., </author> <title> Workload Characterization for Supercomputers, Performance Evaluation of Supercom puters, </title> <editor> Ed. J. L. </editor> <publisher> Martin, </publisher> <pages> pp. 283-315, </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: 1.0 Introduction Past efforts in the development of high performance computer systems have been primarily focused on the computational speeds of processors, often ignoring other important system components, such as the I/O subsystem and the operating system <ref> [3, 8, 18, 20] </ref>. Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem [1, 8, 9]. <p> Although the CSA data only provides aggregate resource usage, it enabled us to analyze the workload at two important levels, the functional level and the physical resource level <ref> [3, 5, 7] </ref>. Serazzi [16] showed that reliable workload characterizations can capture the functionality of the real system workload while still preserving the underlying physical resource usage.
Reference: [4] <author> Denning, P. J., and Adams III, G. B., </author> <title> Research Questions for Performance Analysis of Supercomputers, Performance Evaluation of Supercomputers, </title> <editor> Ed. J. L. Martin, pp. </editor> <volume> 403 419, </volume> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Relying on these large-scale computations and data analysis techniques, progress in many scientific disciplines is limited only by the available capacity of high performance computing <ref> [4] </ref>. The sheer volume of this data and the need to access, store, distribute and visualize this data intensifies I/O demands within the local system and communication requirements across networks [17].
Reference: [5] <author> Ferrari, D., </author> <title> Workload Characterization and Selection in Computer Performance Measurement, </title> <booktitle> Computer, </booktitle> <pages> pp. 18 24, </pages> <month> July/August </month> <year> 1972. </year>
Reference-contexts: Although the CSA data only provides aggregate resource usage, it enabled us to analyze the workload at two important levels, the functional level and the physical resource level <ref> [3, 5, 7] </ref>. Serazzi [16] showed that reliable workload characterizations can capture the functionality of the real system workload while still preserving the underlying physical resource usage.
Reference: [6] <author> Hartigan, J. A., </author> <title> Clustering Algorithms, </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: workload, these 24 applications consumed 6% of the total CPU time and were responsible for 55% of the total number of bytes transferred. 5.1 Cluster Analysis To find natural partitions or patterns within the resource usage records for a given application, the multidimensional analysis technique of means clustering was used <ref> [6, 7] </ref>. A notable feature of the clustering algorithm is that it uses weighted Euclidean distance as a dissimilarity measure, which allows the size of each cluster to vary in inverse proportion to its variance.
Reference: [7] <author> Heidelberger, P., and Lavenberg, S. S., </author> <title> Computer Perfor mance Evaluation Methodology, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 33, No. 12, </volume> <pages> pp. 1195-1220, </pages> <month> December </month> <year> 1984. </year>
Reference-contexts: Although the CSA data only provides aggregate resource usage, it enabled us to analyze the workload at two important levels, the functional level and the physical resource level <ref> [3, 5, 7] </ref>. Serazzi [16] showed that reliable workload characterizations can capture the functionality of the real system workload while still preserving the underlying physical resource usage. <p> workload, these 24 applications consumed 6% of the total CPU time and were responsible for 55% of the total number of bytes transferred. 5.1 Cluster Analysis To find natural partitions or patterns within the resource usage records for a given application, the multidimensional analysis technique of means clustering was used <ref> [6, 7] </ref>. A notable feature of the clustering algorithm is that it uses weighted Euclidean distance as a dissimilarity measure, which allows the size of each cluster to vary in inverse proportion to its variance.
Reference: [8] <author> Hennessy, J. L., and Patterson, D. A., </author> <title> Computer Architec ture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publish ers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: 1.0 Introduction Past efforts in the development of high performance computer systems have been primarily focused on the computational speeds of processors, often ignoring other important system components, such as the I/O subsystem and the operating system <ref> [3, 8, 18, 20] </ref>. Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem [1, 8, 9]. <p> Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem <ref> [1, 8, 9] </ref>. Until recently, little concern has been expressed over the growing system imbalance between CPU and I/O performance. Now however, scientific research based on computational approaches has intensified and the number of I/ O intensive scientific applications is increasing. <p> Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13].
Reference: [9] <author> Katz, R. H., Gibson, G. A., and Patterson, D. A., </author> <title> Disk Sys tem Architectures for High Performance Computing, </title> <journal> Pro ceedings of the IEEE, </journal> <volume> Vol. 77, No. 12, </volume> <pages> pp. 1842-1858, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem <ref> [1, 8, 9] </ref>. Until recently, little concern has been expressed over the growing system imbalance between CPU and I/O performance. Now however, scientific research based on computational approaches has intensified and the number of I/ O intensive scientific applications is increasing. <p> Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13].
Reference: [10] <author> Lim, S. B., and Condry, M. W., </author> <title> Supercomputing Applica tion Access Characteristics, </title> <type> Technical Report No. </type> <institution> UIUCDCS-R-91-1708, University of Illinois at Urbana Champaign, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: believe that it is necessary to undertake a thorough study of production workloads in order to extract the char acteristic behavior of I/O intensive applications. 2.1 Related Research The analysis of application I/O has been seriously addressed in two recent studies by Miller and Katz [12] and Lim and Condry <ref> [10] </ref>. By recording detailed information about each I/O request (e.g., type of I/O, request size, number of bytes transferred, file accessed, and file position), they were able to construct runtime profiles depicting an application's I/O behavior over time. <p> This strong cor relation between CPU time and these I/O measures is compatible with the hypothesis that griz.exe contains a regular, repetitive I/O processing phase, like those observed in <ref> [10, 12] </ref>. Regression results for all selected applications are provided in Appendix C. Table C.1 shows results for the standard linear model: We have grouped the 24 applications into three categories based on the regression results.
Reference: [11] <author> Martin, J. L., </author> <title> Supercomputer Performance Evaluation: The Comparative Analysis of HighSpeed Architectures Against Their Applications, Performance Evaluation of Supercom puters, </title> <editor> Ed. J. L. </editor> <publisher> Martin, </publisher> <pages> pp. 3-19, </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13].
Reference: [12] <author> Miller, E. L. and Katz, R. H., </author> <booktitle> Input/Output Behavior of Supercomputing Applications, Proceedings of Supercom puting '91, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13]. <p> We believe that it is necessary to undertake a thorough study of production workloads in order to extract the char acteristic behavior of I/O intensive applications. 2.1 Related Research The analysis of application I/O has been seriously addressed in two recent studies by Miller and Katz <ref> [12] </ref> and Lim and Condry [10]. By recording detailed information about each I/O request (e.g., type of I/O, request size, number of bytes transferred, file accessed, and file position), they were able to construct runtime profiles depicting an application's I/O behavior over time. <p> On a real memory machine like the Cray Y-MP, the entire application and its data set must be resident in memory during execution. Since data sets often eclipse the maximum available memory partition, the technique of data overlaying or data staging is used <ref> [12] </ref>. At regular intervals in the computation or at each iteration of a looping construct, processing is temporarily suspended while the entire in-core data set is replaced with a new data set. <p> As a result of this data swapping, a cyclic pattern of same size I/O requests is generated by the application. The same is also true when checkpointing is performed <ref> [12] </ref>. Checkpointing involves writing a portion of the in-core data set to disk to save the state of the computation should the system fail. If failure does occur, the application can then be restarted from the last checkpoint, with minimal recomputation. <p> This strong cor relation between CPU time and these I/O measures is compatible with the hypothesis that griz.exe contains a regular, repetitive I/O processing phase, like those observed in <ref> [10, 12] </ref>. Regression results for all selected applications are provided in Appendix C. Table C.1 shows results for the standard linear model: We have grouped the 24 applications into three categories based on the regression results. <p> The stability in logical I/O rates across different execution times may represent the dominating effects of a highly regular main processing phase within the application. Through dynamic profiling, Miller and Katz <ref> [12] </ref> observed a class of scientific applications whose main processing phase consisted of a period of CPU processing followed by a burst of intense I/O activity, which repeated at regular intervals.
Reference: [13] <author> Moore, R., </author> <title> File Servers, Supercomputers, and Network ing, </title> <booktitle> Proceedings of the NSSDC Conference on Mass Storage Systems and Technologies for Space and Earth Science Applications, </booktitle> <year> 1991. </year>
Reference-contexts: In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking <ref> [13] </ref>. <p> To support the I/O requirements of a combined interactive and production workload, the storage system for SDSC's Cray Y-MP is a 5-level buffer and cache hierarchy. Table1 details the levels in this hierarchy and their characteristics <ref> [13] </ref>. The critical levels in this hierarchy are the SSD and the local disks. Together these devices must meet the demands of the two major sources of I/O in the system, namely job swapping and application disk I/O.
Reference: [14] <author> Pasquale, B. K. and Polyzos, G. C., </author> <title> I/O Profiles of a Scien tific Application on a Workstation and a Supercomputer, </title> <type> Technical Report No. </type> <institution> CS93-299, University of California, </institution> <address> San Diego, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: We intend to proceed in that direction and the present analysis will guide us in selecting the applications to consider and also to generalize the results obtained by dynamic analysis to classes of applications determined by this study. A first step in this direction is our work described in <ref> [14] </ref>.
Reference: [15] <author> Pasquale, J. C., Bittel, B. K., and Kraiman, D. J., </author> <title> A Static and Dynamic Workload Characterization Study of the San Diego Supercomputer Center CRAY X-MP, </title> <booktitle> Proceedings of the 1991 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <address> pp.218-219, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Even though it represents an extremely small portion of all executed jobs (5%), it accounts for 92% of total CPU time and 88% of total bytes transferred. The results of this workload characterization study are consistent with an earlier study of the SDSC workload <ref> [15] </ref> where it was found that user applications represented 7% of the workload and con sumed 90% of total CPU time and 75% of I/O channel time 4.3 I/O Intensive Applications To extract the set of I/O intensive applications from the set of all user applications, we produced an average virtual
Reference: [16] <author> Serazzi, G., </author> <title> A Functional and Resource-Oriented Procedure for Workload Modeling, Performance '81, </title> <journal> pp. </journal> <volume> 345 361, </volume> <publisher> North-Holland, </publisher> <year> 1981. </year>
Reference-contexts: Although the CSA data only provides aggregate resource usage, it enabled us to analyze the workload at two important levels, the functional level and the physical resource level [3, 5, 7]. Serazzi <ref> [16] </ref> showed that reliable workload characterizations can capture the functionality of the real system workload while still preserving the underlying physical resource usage.
Reference: [17] <author> Stonebraker, M., and Dozier, J., </author> <title> Overview of the Sequoia 2000 Project, </title> <booktitle> Proceedings of COMPCON 92, </booktitle> <address> San Fran cisco, California, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: The sheer volume of this data and the need to access, store, distribute and visualize this data intensifies I/O demands within the local system and communication requirements across networks <ref> [17] </ref>. Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance [1, 8, 9, 11, 12, 19].
Reference: [18] <author> Williams, E., </author> <title> The Effects of Operating Systems on Supercomputer Performance, Performance Evaluation of Super computers, </title> <editor> Ed. J. L. </editor> <publisher> Martin, </publisher> <pages> pp. 69-81, </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: 1.0 Introduction Past efforts in the development of high performance computer systems have been primarily focused on the computational speeds of processors, often ignoring other important system components, such as the I/O subsystem and the operating system <ref> [3, 8, 18, 20] </ref>. Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem [1, 8, 9].
Reference: [19] <author> Lazowska, E. D., and Sevcik, K. C., cochairs, </author> <title> Report of the Workshop on Scientific Computing Performance Analy sis, </title> <institution> Division of Advanced Scientific Computing, NSF, Boulder, Colorado, </institution> <month> August 29-31, </month> <year> 1989. </year>
Reference-contexts: Continuing to increase CPU speeds and to further exploit parallelism without improving the I/O system will create more I/O bound jobs which can become a bottleneck to system performance <ref> [1, 8, 9, 11, 12, 19] </ref>. In a recent study of the San Diego Supercomputer Center (SDSC), an increase in CPU idle time was directly attributed to I/O blocking [13].
Reference: [20] <author> Committee on Supercomputer Performance and Develop ment, </author> <title> An Agenda for Improved Evaluation of Supercom puter Performance, </title> <institution> National Research Council, </institution> <address> Washington, D.C., </address> <year> 1986. </year>
Reference-contexts: 1.0 Introduction Past efforts in the development of high performance computer systems have been primarily focused on the computational speeds of processors, often ignoring other important system components, such as the I/O subsystem and the operating system <ref> [3, 8, 18, 20] </ref>. Resulting progress in the areas of raw processor speed and parallelism, both in hardware and software, has produced GFLOPS machines, but has done little to close the ever widening gap between CPU performance and that of the attached I/O subsystem [1, 8, 9].
References-found: 20

