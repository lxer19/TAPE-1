URL: http://www.cs.washington.edu/homes/anderson/papers/near.ps
Refering-URL: http://www.cs.washington.edu/homes/anderson/papers.html
Root-URL: 
Email: Email: anderson@csa.iisc.ernet.in  
Title: Nearest Neighbor Trees and N-body Simulation  
Author: Richard Anderson 
Address: Bangalore, 560012, India.  
Note: Sabbatical Address:  
Affiliation: Department of Computer Science and Engineering University of Washington  Department of Computer Science and Automation, Indian Institute of Science,  
Abstract: In this paper, we study data structures for N-body simulation. The basic data structure is a hierarchical partition of the input which is used for clustering particles in order to perform an efficient force computation. We are interested in Nearest Neighbor Trees which are formed by repeatedly combining mutually closest pairs of points to create a binary tree. This data structure is an alternative to the more commonly used oct-tree structure, and may be advantageous in practice. In this paper, our goal is to establish a theoretical basis to support the use of Nearest Neighbor Trees. Our main result is to prove that Strict Nearest Neighbor Trees satisfy a logarithmic height bound. We also establish various performance bounds on the N-body computation using Strict Nearest Neighbor Trees. 
Abstract-found: 1
Intro-found: 1
Reference: [App85] <author> A. W. Appel. </author> <title> An efficient program for many-body simulation. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 6 </volume> <pages> 85-103, </pages> <year> 1985. </year>
Reference-contexts: Improvements on this run time have come by computing an approximation of the forces instead of exact forces. The particle-cluster algorithm computes the force on each particle by using a spatial hierarchy to cluster particles. The algorithm was independently developed by several researchers <ref> [App85, BH86, JP89] </ref>, with the algorithm due to Barnes and Hut being the one that is currently most widely used. The run time for the particle-cluster algorithm is generally considered to be O (n log n).
Reference: [BBCP90] <author> W. Benz, R. L. Bowers, A. G. W. Cameron, and W. H. </author> <title> Press. Dynamic mass exchange in doubly degenerate binaries. I. 0.9 and 1.2 M fi stars. </title> <journal> The Astrophysical Journal, </journal> <volume> 348 </volume> <pages> 647-667, </pages> <year> 1990. </year>
Reference-contexts: The current algorithm of choice for astrophysical simulation is the Particle-Cluster algorithm. Our goal is to prove that a Particle-Cluster algorithm based upon Nearest Neighbor Trees is as good as the more commonly used Barnes-Hut algorithm [BH86]. The Nearest Neighbor algorithm was developed independently by Benz et al. <ref> [BBCP90] </ref> and by Jernigan and Porter [JP89], and has been observed to run very well in practice [Mak90]. Heuristic arguments have been given to explain the good performance, but up until now there has been no rigorous proofs that it is a fast algorithm. <p> The candidate data structure to use instead of oct-trees is the nearest neighbor tree. This data structure was independently introduced by Benz et al. <ref> [BBCP90] </ref>, and by Jernigan and Porter [JP89]. Experimental studies [Mak90] have shown that this data structure is competitive with oct-trees, although results are not conclusive. The goal of this paper is to develop a theoretical justification for using nearest neighbor trees. <p> Since the minimal separation is p 2=3Rad fl (p) the number of points is bounded by a constant, so the number of subtrees is bounded. The proof gives a bound of 215 (log M +log ). Benz et al. <ref> [BBCP90] </ref> give a heuristic argument that the average case is 1:8 log n and cite experimental evidence of 1:3 log n.
Reference: [BH86] <author> J. E. Barnes and P. Hut. </author> <title> A hierarchical O(N log N ) force-calculation algorithm. </title> <journal> Nature, </journal> <volume> 324 </volume> <pages> 446-449, </pages> <year> 1986. </year>
Reference-contexts: The current algorithm of choice for astrophysical simulation is the Particle-Cluster algorithm. Our goal is to prove that a Particle-Cluster algorithm based upon Nearest Neighbor Trees is as good as the more commonly used Barnes-Hut algorithm <ref> [BH86] </ref>. The Nearest Neighbor algorithm was developed independently by Benz et al. [BBCP90] and by Jernigan and Porter [JP89], and has been observed to run very well in practice [Mak90]. <p> Improvements on this run time have come by computing an approximation of the forces instead of exact forces. The particle-cluster algorithm computes the force on each particle by using a spatial hierarchy to cluster particles. The algorithm was independently developed by several researchers <ref> [App85, BH86, JP89] </ref>, with the algorithm due to Barnes and Hut being the one that is currently most widely used. The run time for the particle-cluster algorithm is generally considered to be O (n log n).
Reference: [CK92] <author> P. B. Callahan and S. R. Kosaraju. </author> <title> A decomposition of multi-dimensional point-sets with applications to k-nearest-neighbors and n-body potential fields. </title> <booktitle> In Proceedings of the 24th ACM Symposium on Theory of Computation, </booktitle> <pages> pages 546-555, </pages> <year> 1992. </year>
Reference-contexts: In an oct-tree, the tree can have an arbitrarily large height for a fixed number of particles, so the run time is actually unbounded. If a tree such as a fair-split tree is used <ref> [CK92] </ref>, then the height is bounded by O (n). (However, these pathological examples are of no interest to astrophysicists, since the data is not represented with sufficient precision for these bad cases to occur.) It is possible to give a run time bound for the Barnes-Hut algorithm in terms of the <p> This is done by using a data structure that can record nearest neighbor information and supports efficient insertion and deletion of points. We use the Fair Split Tree <ref> [CK92] </ref> augmented so that it can support incremental operations [CK93]. O (n log n) is optimal, based upon lower bounds for element distinctness.
Reference: [CK93] <author> P. B. Callahan and S. R. Kosaraju, </author> <year> 1993. </year> <type> Personal Communication. </type>
Reference-contexts: This is done by using a data structure that can record nearest neighbor information and supports efficient insertion and deletion of points. We use the Fair Split Tree [CK92] augmented so that it can support incremental operations <ref> [CK93] </ref>. O (n log n) is optimal, based upon lower bounds for element distinctness.
Reference: [GR87] <author> L. Greengard and V. Rokhlin. </author> <title> A fast algorithm for particle simulations. </title> <journal> Journal of Computational Physics, </journal> <volume> 73 </volume> <pages> 325-348, </pages> <year> 1987. </year>
Reference-contexts: The algorithm was independently developed by several researchers [App85, BH86, JP89], with the algorithm due to Barnes and Hut being the one that is currently most widely used. The run time for the particle-cluster algorithm is generally considered to be O (n log n). The Greengard-Rokhlin algorithm <ref> [GR87, Gre87] </ref> is a cluster-cluster algorithm which achieves O (n) run time by computing forces between clusters. Although the Greengard-Rokhlin algorithm is 2 elegant and asymptotically superior, it is not widely used in astrophysical simulation because of the algorithm's complexity and large constant factors.
Reference: [Gre87] <author> L. Greengard. </author> <title> The Rapid Evaluation of Potential Fields in Particle Systems. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1987. </year> <month> 12 </month>
Reference-contexts: The algorithm was independently developed by several researchers [App85, BH86, JP89], with the algorithm due to Barnes and Hut being the one that is currently most widely used. The run time for the particle-cluster algorithm is generally considered to be O (n log n). The Greengard-Rokhlin algorithm <ref> [GR87, Gre87] </ref> is a cluster-cluster algorithm which achieves O (n) run time by computing forces between clusters. Although the Greengard-Rokhlin algorithm is 2 elegant and asymptotically superior, it is not widely used in astrophysical simulation because of the algorithm's complexity and large constant factors.
Reference: [Her87] <author> L. Hernquist. </author> <title> Performance characteristics of tree codes. </title> <journal> The Astrophysical Journal Supplement, </journal> <volume> 64 </volume> <pages> 715-734, </pages> <year> 1987. </year>
Reference-contexts: The cost can be measured by counting the number of calls to ApproxForce and ExactForce, (with the ApproxForce computations being more expensive). * The cost of tree construction if very small, figures cited for the Barnes-Hut algo rithm range from 2% to 4% of the total run time <ref> [Sal90, Her87] </ref>. * Achieving a constant factor improvement in run time would be of substantial practical interest. 3 Data Structures One way to improve the performance of the particle-cluster algo-rithm is to find a better data structure. The data structure determines the number of force computations that are performed.
Reference: [JP89] <author> J. G. Jernigan and D. H. Porter. </author> <title> A tree code with logarithmic reduction of force terms, hierarchical regularization of all variables and explicit accuracy controls. </title> <journal> The Astrophysical Journal Supplement, </journal> <volume> 71 </volume> <pages> 871-893, </pages> <year> 1989. </year>
Reference-contexts: Our goal is to prove that a Particle-Cluster algorithm based upon Nearest Neighbor Trees is as good as the more commonly used Barnes-Hut algorithm [BH86]. The Nearest Neighbor algorithm was developed independently by Benz et al. [BBCP90] and by Jernigan and Porter <ref> [JP89] </ref>, and has been observed to run very well in practice [Mak90]. Heuristic arguments have been given to explain the good performance, but up until now there has been no rigorous proofs that it is a fast algorithm. <p> Improvements on this run time have come by computing an approximation of the forces instead of exact forces. The particle-cluster algorithm computes the force on each particle by using a spatial hierarchy to cluster particles. The algorithm was independently developed by several researchers <ref> [App85, BH86, JP89] </ref>, with the algorithm due to Barnes and Hut being the one that is currently most widely used. The run time for the particle-cluster algorithm is generally considered to be O (n log n). <p> The candidate data structure to use instead of oct-trees is the nearest neighbor tree. This data structure was independently introduced by Benz et al. [BBCP90], and by Jernigan and Porter <ref> [JP89] </ref>. Experimental studies [Mak90] have shown that this data structure is competitive with oct-trees, although results are not conclusive. The goal of this paper is to develop a theoretical justification for using nearest neighbor trees.
Reference: [Mak90] <author> J. Makino. </author> <title> Comparison of two different tree algorithms. </title> <journal> The Journal of Computational Physics, </journal> <volume> 88 </volume> <pages> 393-408, </pages> <year> 1990. </year>
Reference-contexts: The Nearest Neighbor algorithm was developed independently by Benz et al. [BBCP90] and by Jernigan and Porter [JP89], and has been observed to run very well in practice <ref> [Mak90] </ref>. Heuristic arguments have been given to explain the good performance, but up until now there has been no rigorous proofs that it is a fast algorithm. We begin with a discussion of N-body simulation in Astrophysics and present the generic Particle-Cluster algorithm as well as the Barnes-Hut algorithm. <p> The candidate data structure to use instead of oct-trees is the nearest neighbor tree. This data structure was independently introduced by Benz et al. [BBCP90], and by Jernigan and Porter [JP89]. Experimental studies <ref> [Mak90] </ref> have shown that this data structure is competitive with oct-trees, although results are not conclusive. The goal of this paper is to develop a theoretical justification for using nearest neighbor trees. Up until now, only heuristic arguments have been given to show that nearest neighbor trees behave well.
Reference: [Sal90] <author> J. K. Salmon. </author> <title> Parallel Hierarchical N-body Methods. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: The cost can be measured by counting the number of calls to ApproxForce and ExactForce, (with the ApproxForce computations being more expensive). * The cost of tree construction if very small, figures cited for the Barnes-Hut algo rithm range from 2% to 4% of the total run time <ref> [Sal90, Her87] </ref>. * Achieving a constant factor improvement in run time would be of substantial practical interest. 3 Data Structures One way to improve the performance of the particle-cluster algo-rithm is to find a better data structure. The data structure determines the number of force computations that are performed.
Reference: [SW92a] <author> J. K. Salmon and M. S. Warren. </author> <title> Astrophysical N-body simulations using hierarchical tree data structures. </title> <booktitle> In Supercomputing, </booktitle> <pages> pages 570-576, </pages> <year> 1992. </year>
Reference-contexts: The problem of computing the forces is generally referred to as the N-body problem. In astrophysics it is critical to be able to study systems with a very large number of particles. The largest simulations to date have followed about 20 million particles for one thousand time steps <ref> [SW92a] </ref>. Astrophysicists argue that qualitatively different problems could be addressed by simulation if the number of particles were increased by one or two orders of magnitude. There is currently substantial research work going on to enable these massive simulations. N-body algorithms have been improved dramatically in the last two decades.
Reference: [SW92b] <author> J. K. Salmon and M. S. Warren. </author> <title> Skeletons from the treecode closet. </title> <type> Technical report, </type> <institution> Los Alamos National Laboratory, </institution> <year> 1992. </year> <month> 13 </month>
Reference-contexts: We assume that the radius test is implemented so that if x is inside the cluster T , the test fails. (This is not done in the Barnes-Hut algorithm, which leads to problems <ref> [SW92b] </ref>). The bad case is when the particle x has a close by particle y which falls into a cluster with center of mass far away from x.
References-found: 13

