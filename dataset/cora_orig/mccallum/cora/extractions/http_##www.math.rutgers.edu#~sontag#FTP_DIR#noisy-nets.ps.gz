URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/noisy-nets.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Email: email: maass@igi.tu-graz.ac.at  email: sontag@hilbert.rutgers.edu  
Title: Analog Neural Nets with Gaussian or other Common Noise Distributions cannot Recognize Arbitrary Regular Languages  
Author: Wolfgang Maass Eduardo D. Sontag 
Address: Klosterwiesgasse 32/2, A-8010 Graz, Austria  New Brunswick, NJ 08903, USA  
Affiliation: Inst. for Theoretical Computer Science, Technische Universitat Graz  Dep. of Mathematics Rutgers University  
Abstract: We consider recurrent analog neural nets where the output of each gate is subject to Gaussian noise, or any other common noise distribution that is nonzero on a large set. We show that many regular languages cannot be recognized by networks of this type, and we give a precise characterization of those languages which can be recognized. This result implies severe constraints on possibilities for constructing recurrent analog neural nets that are robust against realistic types of analog noise. On the other hand we present a method for constructing feedforward analog neural nets that are robust with regard to analog noise of this type.
Abstract-found: 1
Intro-found: 1
Reference: [Casey, 1996] <author> Casey, M., </author> <title> "The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction", </title> <booktitle> Neural Computation 8, </booktitle> <pages> 1135-1178, </pages> <year> 1996. </year>
Reference-contexts: More precisely, Rabin had shown that probabilistic automata with strictly positive matrices can recognize exactly the same class of languages L that occur in our Theorem 1.1. Rabin referred to these languages as definite languages. Language recognition by analog computational systems with analog noise has previously been investigated in <ref> [Casey, 1996] </ref> for the special case of bounded noise and perfect reliability (i.e. R kvk (v)dv = 1 for some small &gt; 0 and " = 1=2 in our terminology), and in [Maass, Orponen, 1997] for the general case.
Reference: [Doeblin, 1937] <author> Doeblin, W., </author> <title> "Sur le proprietes asymtotiques de mouvement regis par certain types de cha ^ ines simples", </title> <journal> Bull. Math. Soc. Roumaine Sci. </journal> <volume> 39(1): </volume> <pages> 57-115; (2) 3-61, </pages> <year> 1937. </year>
Reference-contexts: Doeblin's condition (with constant c) if there is some probability measure on (S; S) so that K (x; A) c (A) for all x 2 S; A 2 S : (6) (Necessarily c 1, as is seen by considering the special case A = S.) This condition is due to <ref> [Doeblin, 1937] </ref>. We denote by kk the total variation of the (signed) measure . Recall that kk is defined as follows. One may decompose S into a disjoint union of two sets A and B, in such a manner that is nonnegative on A and nonpositive on B.
Reference: [Maass, Orponen, 1997] <author> Maass, W., and Orponen, P. </author> <title> "On the effect of analog noise on discrete-time analog computations", </title> <booktitle> Advances in Neural Information Processing Systems 9, </booktitle> <year> 1997, </year> <note> 218-224; journal version: Neural Computation 10, 1998. detailed version see http://www.math.jyu.fi/~orponen/papers/noisyac.ps </note> . 
Reference-contexts: However it is technically more involved since we have to deal here with an infinite state space. Recognition of a language L U fl by a noisy analog computational system M with discrete time is defined essentially as in <ref> [Maass, Orponen, 1997] </ref>. The set of possible internal states of M is assumed to be some compact set R n , for some integer n (which is called the "number of neurons" or the "dimension"). A typical choice is = [1; 1] n . <p> Then one defines w 2 L () (K ~w ffi ~ )(F ) 2 w 62 L () (K ~w ffi ~ )(F ) 2 This completes our definition of language recognition by a noisy analog computational system M with discrete time. This definition agrees with that given in <ref> [Maass, Orponen, 1997] </ref>. The main result of this article is the following: 4 Theorem 1.1 Assume that U is some arbitrary finite alphabet. <p> Language recognition by analog computational systems with analog noise has previously been investigated in [Casey, 1996] for the special case of bounded noise and perfect reliability (i.e. R kvk (v)dv = 1 for some small &gt; 0 and " = 1=2 in our terminology), and in <ref> [Maass, Orponen, 1997] </ref> for the general case. It was shown in [Maass, Orponen, 1997] that any such system can only recognize regular languages. Furthermore it was shown there that if R kvk (v)dv = 1 for some small &gt; 0 then all regular languages can be recognized by such systems. <p> R kvk (v)dv = 1 for some small &gt; 0 and " = 1=2 in our terminology), and in <ref> [Maass, Orponen, 1997] </ref> for the general case. It was shown in [Maass, Orponen, 1997] that any such system can only recognize regular languages. Furthermore it was shown there that if R kvk (v)dv = 1 for some small &gt; 0 then all regular languages can be recognized by such systems.
Reference: [Omlin, Giles, 1996] <author> Omlin, C. W., Giles, C. L. </author> <title> "Constructing deterministic finite-state automata in recurrent neural networks", </title> <journal> J. Assoc. Comput. Mach. </journal> <volume> 43 (1996), </volume> <pages> 937-972. </pages>
Reference-contexts: 1 Introduction A fairly large literature (see <ref> [Omlin, Giles, 1996] </ref> and the references therein) is devoted to the construction of analog neural nets that recognize regular languages. <p> that simulates a DFA will carry out not just one, but a fixed number k of computation steps (=state transitions) of the form x 0 = sat (W x + h + uc) + V for each input symbol u 2 U that it reads (see the constructions described in <ref> [Omlin, Giles, 1996] </ref>, and in section 3 of this article).
Reference: [Papinicolaou, 1978] <author> Papinicolaou, G., </author> <title> "Asymptotic Analysis of Stochastic Equations", in Studies in Probability Theory, </title> <journal> MAA Studies in Mathematics, </journal> <volume> vol. 18, </volume> <pages> 111-179, </pages> <note> edited by M. Rosenblatt, Math. Assoc. </note> <institution> of America, </institution> <year> 1978. </year>
Reference: [Pippenger, 1985] <author> Pippenger, N., </author> <title> "On networks of noisy gates", </title> <booktitle> IEEE Sympos. on Foundations of Computer Science, </booktitle> <volume> vol. 26, </volume> <publisher> IEEE Press, </publisher> <address> New York, 30-38, </address> <year> 1985. </year> <month> 11 </month>
Reference-contexts: Before we can give the exact statement of Theorem 1.1 and discuss related preceding work we have to give a precise definition of computations in noisy neural networks. From the conceptual point of view this definition is basically the same as for computations in noisy boolean circuits (see <ref> [Pippenger, 1985] </ref> and [Pippenger, 1990]). However it is technically more involved since we have to deal here with an infinite state space. Recognition of a language L U fl by a noisy analog computational system M with discrete time is defined essentially as in [Maass, Orponen, 1997]. <p> by a sufficiently small constant (which can be chosen independently of the size of the given circuit), then one can combine the argument from the proof of Theorem 3.1 with standard methods for constructing boolean circuits that are robust with regard to common models for digital noise (see for example <ref> [Pippenger, 1985] </ref>, [Pippenger, 1989], [Pippenger, 1990]).
Reference: [Pippenger, 1989] <author> Pippenger, N., </author> <title> "Invariance of complexity measures for networks with unreliable gates", </title> <journal> J. of the ACM, </journal> <volume> vol. 36, </volume> <pages> 531-539, </pages> <year> 1989. </year>
Reference-contexts: sufficiently small constant (which can be chosen independently of the size of the given circuit), then one can combine the argument from the proof of Theorem 3.1 with standard methods for constructing boolean circuits that are robust with regard to common models for digital noise (see for example [Pippenger, 1985], <ref> [Pippenger, 1989] </ref>, [Pippenger, 1990]).
Reference: [Pippenger, 1990] <author> Pippenger, N., </author> <title> "Developments in `The Synthesis of Reliable Organisms from Unreliable Components' ", Proc. </title> <journal> of Symposia in Pure Mathematics, </journal> <volume> vol. 50, </volume> <pages> 311-324, </pages> <year> 1990. </year>
Reference-contexts: From the conceptual point of view this definition is basically the same as for computations in noisy boolean circuits (see [Pippenger, 1985] and <ref> [Pippenger, 1990] </ref>). However it is technically more involved since we have to deal here with an infinite state space. Recognition of a language L U fl by a noisy analog computational system M with discrete time is defined essentially as in [Maass, Orponen, 1997]. <p> constant (which can be chosen independently of the size of the given circuit), then one can combine the argument from the proof of Theorem 3.1 with standard methods for constructing boolean circuits that are robust with regard to common models for digital noise (see for example [Pippenger, 1985], [Pippenger, 1989], <ref> [Pippenger, 1990] </ref>).
Reference: [Rabin, 1963] <author> Rabin, M., </author> <title> "Probabilistic automata", </title> <journal> Information and Control, </journal> <volume> vol. 6, </volume> <pages> 230-245, </pages> <year> 1963. </year>
Reference-contexts: The proof of Theorem 1.1 follows immediately from Corollary 2.2 and Corollary 3.3. A corresponding version of Theorem 1.1 for discrete computational systems was previously shown in <ref> [Rabin, 1963] </ref>. More precisely, Rabin had shown that probabilistic automata with strictly positive matrices can recognize exactly the same class of languages L that occur in our Theorem 1.1. Rabin referred to these languages as definite languages.
References-found: 9

