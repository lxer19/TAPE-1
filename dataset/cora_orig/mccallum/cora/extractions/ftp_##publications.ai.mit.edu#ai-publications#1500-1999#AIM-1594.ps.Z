URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1594.ps.Z
Refering-URL: http://www.ai.mit.edu/people/gideon/Demos/DirectMethods/DirectMethods.html
Root-URL: 
Email: gideon@ai.mit.edu shashua@cs.huji.ac.il  
Title: Direct methods for estimation of structure and motion from three views  
Author: Gideon P. Stein and Amnon Shashua 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1996  
Date: 1594 November, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: We describe a new direct method for estimating structure and motion from image intensities of multiple views. We extend the direct methods of [7] to three views. Adding the third view enables us to solve for motion, and compute a dense depth map of the scene, directly from image spatio-temporal derivatives in a linear manner without first having to find point correspondences or compute optical flow. We describe the advantages and limitations of this method which are then verified through simulation and experiments with real images. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-94-01-0994. G.P.S. is supported by Alphatech/ DARPA "Automatic Target Recognition" project 95009-5381 and TASC/ DARPA "MSTAR Match Module" project J-08011-S95042. A.S. is supported by US-IS Binational Science Foundation 94-00120/2 and by the European ACTS project AC074 VANGUARD. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Avidan, S. and Shashua, A., </author> <title> "Novel View Synthesis in Tensor Space", </title> <note> to be published SIG-GRAPH96. </note>
Reference: [2] <author> Bergen, J.R., Anandan, P., Hanna, K.J. and Hingorani, R. </author> <title> "Hierarchical model-based motion estimation", </title> <booktitle> In Proceedings EECV, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> (1992) </year>
Reference: [3] <author> Burt, P.J. and Adelson, </author> <title> E.H. "The Laplacian pyramid as a compact image code" IEEE Transactions on Communications, </title> <booktitle> 31 </booktitle> <pages> 532-540, </pages> <year> (1983) </year>
Reference: [4] <author> Hartley, R. </author> <title> "A linear method for reconstruction from lines and points" In Proceedings ICCV, </title> <address> 882-887, Cambridge, MA, </address> <month> June </month> <year> (1995) </year>
Reference-contexts: Since the free indices are ; each in the range 1,2, we have 4 trilinear equations (which are unique up to linear combinations). More details can be found in <ref> [4, 12, 15, 13] </ref>. Geometrically, a trilinear matching constraint is produced by contracting the tensor with the point p of im age 0, some line coincident with p 0 in image 1, and some line coincident with p 00 in image 2.
Reference: [5] <author> Heel, </author> <title> J "Direct Estimation of Structure and Motion from Multiple Frames" AI memo 1190, </title> <month> March </month> <year> (1990) </year>
Reference-contexts: The FOE is on a line perpendicular to the gradient at these points. But by using only this subset of the points we are throwing away the information from most of the image. Heel <ref> [5] </ref> uses multiple images from an image sequence. He then employs Kalman filters to build up a structure model from more than one image pair but the core computation is fundamentally the same single image pair computation. This work is based on the work of Shashua and Hanna [14].
Reference: [6] <author> Horn, B.K.P. and Schunk, B.G. </author> <title> "Determining optical flow" Artificial Intelligence, </title> <type> 17 </type> <month> 185-203 </month> <year> (1981) </year>
Reference-contexts: These methods are dubbed 'direct methods' because they do not require prior computation of optical flow. As with other gradient methods we assume small image motions on the order of a few pixels. Applying the constant brightness constraint <ref> [6] </ref> to the trilinear tensor of Shashua and Werman [12, 15] results in an equation relating camera motion and calibration parameters to the image gradients (first order only). <p> x ; I y at (x; y) in image 0, then the line s 0 has the form: S 0 = I x x 0 I x y 0 I y The contribution of x 0 ; y 0 can be removed by using the constant brightness equation due to <ref> [6] </ref>: u 0 I x + v 0 I y + I 0 where u 0 = x x 0 , v 0 = y y 0 and I 0 t is the discrete temporal derivative at (x; y), i.e., I 1 (x; y)I 0 (x; y) where I 1 and
Reference: [7] <author> Horn, B.K.P. and Weldon, E.J. </author> <title> "Direct methods for recovering motion" IJCV 2 </title> <type> 51-76, </type> <year> (1988) </year>
Reference-contexts: 1 Introduction In this paper we present a new method for computing motion and dense structure from three views. This method can be viewed as an extension of the 'direct methods' of Horn and Weldon <ref> [7] </ref> from two views (one motion) to three views (two motions). These methods are dubbed 'direct methods' because they do not require prior computation of optical flow. As with other gradient methods we assume small image motions on the order of a few pixels. <p> The method is shown to produce useful results in both camera motion and depth estimation. Section (7) discusses some of the open questions and suggests possible solutions. 1.1 Previous Work The 'direct methods' were pioneered by Horn and Wel-don in <ref> [7] </ref>. Using only a single image pair one has N equations in N + 6 unknowns, where N is the number of points in the image, so some added constraint is needed. Negahdaripour and Horn [11] present a closed form solution assuming a planar or quadratic surface. <p> Equations (12)(13) are obtained by substituting (eq. 8) in equation (3) and rearranging the terms. See <ref> [7] </ref> for more details. 2 3 Solving the bilinear equation 3.1 The pure translation case In the pure translation case equation (11) becomes: I 00 t S T t 00 = 0 (14) We have one such equation for each image point and we can write it out in the matrix
Reference: [8] <author> McQuirk, </author> <title> I.S. "An Analog VLSI Chip for Estimating the Focus of Expansion" AITR-1577,(1996) </title>
Reference-contexts: Using only a single image pair one has N equations in N + 6 unknowns, where N is the number of points in the image, so some added constraint is needed. Negahdaripour and Horn [11] present a closed form solution assuming a planar or quadratic surface. McQuirk <ref> [8] </ref> shows that, assuming a pure translation model, the subset of the image points with a nonzero spatial derivative but a zero time derivative gives the direction of motion. The FOE is on a line perpendicular to the gradient at these points.
Reference: [9] <author> Longuett-Higgins, H.C. and Prazdny, K. </author> <title> "The interpretation of a moving retinal image." </title> <journal> Proceedings of the Royal Society of London B, </journal> <volume> 208 </volume> <year> 385-397,(1980) </year>
Reference-contexts: Starting with the general uncalibrated model we proceed through a hierarchy of reduced models first by assuming calibrated cameras and then by assuming the Longuett-Higgins and Prazdny small motion model <ref> [9] </ref>. This is described in section (2). We then show how to solve the simplified model for the motion parameters (section 3). This method has advantages over both optical flow methods [9][10] and feature based methods [15]. <p> where V 0 = p fi S 0 = I y + y (I 0 I x x (I 0 xI y yI x and t xI x yI y ) t xI x yI y ) ! If, in addition, we enforce infinitesimal translational motion (the Longuett-Higgins & Prazdny <ref> [9] </ref> motion model), which results in the image motion equations: u 0 = z 1 xt 0 3 y + w 0 1 xy (8) 1 (t 0 3 ) + w 0 1 (1 + y 2 ) + w 0 then S has the simpler form: S = I
Reference: [10] <author> Lucas, B.D. and Kanade, T. </author> <title> "An iterative image registration technique with an application to stereo vision" In Proceedings IJCAI, </title> <address> 674-679, Vancouver, </address> <year> (1981) </year>
Reference: [11] <author> Negahdaripour, S. and Horn, </author> <title> B.K.P "Direct passive navigation". </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1) </volume> <year> 168-176,(1987) </year>
Reference-contexts: Using only a single image pair one has N equations in N + 6 unknowns, where N is the number of points in the image, so some added constraint is needed. Negahdaripour and Horn <ref> [11] </ref> present a closed form solution assuming a planar or quadratic surface. McQuirk [8] shows that, assuming a pure translation model, the subset of the image points with a nonzero spatial derivative but a zero time derivative gives the direction of motion.
Reference: [12] <author> Shashua, A. </author> <title> "Algebraic functions for recognition", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: These methods are dubbed 'direct methods' because they do not require prior computation of optical flow. As with other gradient methods we assume small image motions on the order of a few pixels. Applying the constant brightness constraint [6] to the trilinear tensor of Shashua and Werman <ref> [12, 15] </ref> results in an equation relating camera motion and calibration parameters to the image gradients (first order only). We get one equation for each point in the image and we have a fixed number of parameters which results in a highly over-constrained set of equations. <p> Since the free indices are ; each in the range 1,2, we have 4 trilinear equations (which are unique up to linear combinations). More details can be found in <ref> [4, 12, 15, 13] </ref>. Geometrically, a trilinear matching constraint is produced by contracting the tensor with the point p of im age 0, some line coincident with p 0 in image 1, and some line coincident with p 00 in image 2.
Reference: [13] <author> Shashua, A. and Anandan, P. </author> <title> "Trilinear Constraints Revisited: Generalized Trilinear Constraints and the Tensor Brightness Constraint", </title> <booktitle> Proceedings of the ARPA Image Understanding Workshop, </booktitle> <month> February </month> <year> 1996, </year> <title> Palm Springs, </title> <address> CA. </address> <month> 7 </month>
Reference-contexts: Since the free indices are ; each in the range 1,2, we have 4 trilinear equations (which are unique up to linear combinations). More details can be found in <ref> [4, 12, 15, 13] </ref>. Geometrically, a trilinear matching constraint is produced by contracting the tensor with the point p of im age 0, some line coincident with p 0 in image 1, and some line coincident with p 00 in image 2.
Reference: [14] <author> Shashua, A. and Hanna, K.J. </author> <title> "The Tensor Brightness Constraints: Direct Estimation of Motion Revisited" Technion Technical Report, </title> <institution> Haifa, Israel, </institution> <month> November </month> <year> (1995) </year>
Reference-contexts: Heel [5] uses multiple images from an image sequence. He then employs Kalman filters to build up a structure model from more than one image pair but the core computation is fundamentally the same single image pair computation. This work is based on the work of Shashua and Hanna <ref> [14] </ref>. Here we describe the results of implementing these ideas in practice. <p> This constraint was introduced by <ref> [14] </ref> under the name "Tensor Brightness Constraint". This is briefly derived next. We can describe any line, in particular a line through p 0 , as a linear combination of the vertical (1; 0; x 0 ) and horizontal (0; 1; y 0 ) lines.
Reference: [15] <author> Shashua, A. and Werman, M., </author> <title> "Trilinearity of Three Perspective Views and its Associated Tensor", </title> <booktitle> In Proceedings of ICCV 95, </booktitle> <address> 920-925 Boston, MA, USA, </address> <month> June </month> <year> (1995) </year>
Reference-contexts: These methods are dubbed 'direct methods' because they do not require prior computation of optical flow. As with other gradient methods we assume small image motions on the order of a few pixels. Applying the constant brightness constraint [6] to the trilinear tensor of Shashua and Werman <ref> [12, 15] </ref> results in an equation relating camera motion and calibration parameters to the image gradients (first order only). We get one equation for each point in the image and we have a fixed number of parameters which results in a highly over-constrained set of equations. <p> This is described in section (2). We then show how to solve the simplified model for the motion parameters (section 3). This method has advantages over both optical flow methods [9][10] and feature based methods <ref> [15] </ref>. We combine the information from all the points in the image and thus we avoid the aperture problem which makes computation of optical flow difficult. There is also no need to explicitly define feature points. <p> Since the free indices are ; each in the range 1,2, we have 4 trilinear equations (which are unique up to linear combinations). More details can be found in <ref> [4, 12, 15, 13] </ref>. Geometrically, a trilinear matching constraint is produced by contracting the tensor with the point p of im age 0, some line coincident with p 0 in image 1, and some line coincident with p 00 in image 2. <p> The second open problem deals with the current limitation that the two motions cannot be collinear since this has been shown (section 3.3) to be a singular case. On the other hand no such limitation exists in the discrete case <ref> [15] </ref>. There is a question whether this is a general phenomena resulting from using the constant brightness equation or whether this is specific to the LH model. There are two avenues to proceed.
Reference: [16] <author> Spetsakis, M.E. and Aloimonos, J. </author> <title> "A unified theory of structure from motion", </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <year> 1990. </year>
Reference-contexts: In particular, we may use the tangent to the iso-brightness contour at p 0 and p 00 , respectively. In other words, one can recover in principle the camera matrices across three views in the context of the "aperture" problem, as noticed by <ref> [16] </ref>. Alternatively, if we represent the tangent to the corresponding iso-brightness contours by the instantaneous spatio-temporal derivatives at p (shown next), we will get a constraint equation involving the unknowns ff jk i and the spatio-temporal derivatives at each pixel | the constraint is linear in the unknowns.
Reference: [17] <author> Wang, J. Y. A and Adelson, E. H. </author> " <title> Representing Moving Images with Layers. </title> " <journal> IEEE Transactions on Image Processing Special Issue: Image Sequence Compression, </journal> <volume> 3(5) </volume> <pages> 625-638, </pages> <month> September </month> <year> (1994). </year> <month> 8 </month>
References-found: 17

