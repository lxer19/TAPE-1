URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/95.tr565.3d_recognition_via_2stage_associative_memory.ps.gz
Refering-URL: http://www.cs.rochester.edu/trs/ai-trs.html
Root-URL: 
Title: 3-D recognition via 2-stage associative memory  
Author: Randal C. Nelson 
Date: January 16, 1995  
Affiliation: Department of Computer Science University of Rochester  
Abstract: We describe a method of 3-D object recognition based on two stage use of a general purpose associative memory and a principal views representation. The basic idea is to make use of semi-invariant objects called keys. A key is any robustly extractable feature that has sufficient information content to specify a 2-D configuration of an associated object (location, scale, orientation) plus sufficient additional parameters to provide efficient indexing and meaningful verification. The recognition system utilizes an associative memory organized so that access via a key feature evokes associated hypotheses for the identity and configuration of all objects that could have produced it. These hypothesis are fed into a second stage associative memory, which maintains a probabilistic estimate of the likelihood of each hypothesis based on statistics about the occurrence of the keys in the primary database. Because it is based on a merged percept of local features rather than global properties, the method is robust to occlusion and background clutter, and does not require prior segmentation. Entry of objects into the memory is an active, automatic procedure. We have implemented a version of the system that allows arbitrary definitions for key features. Experiments using keys based on perceptual groups of line segments are reported. Good results were obtained on a database derived from of approximately 150 images representing different views of 7 polyhedral objects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aloimomos. </author> <title> Active vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 333-356, </pages> <month> 15 </month> <year> 1988. </year>
Reference-contexts: The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1; 10; 3; 4] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [2] <author> N. Ayache and O. Faugeras. </author> <title> Hyper: a new approach for the recognition and positioning of two-dimensional objects. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 8(1) </volume> <pages> 44-54, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Similarly, [33] propose a neural architecture for learning aspect-graph representation, but don't apply it to real objects. Work on automatic acquisition of 2-D representation has been more successful, since all the information is present (e.g. <ref> [7; 2; 12] </ref>) We expect these techniques to be useful here, since we essentially propose utilizing a collection of augmented 2-D representations. There is some recent work that has a memory-based flavor too it.
Reference: [3] <author> D. H. Ballard. </author> <title> Reference frames for animate vision. </title> <booktitle> In Proc. IJCAI, </booktitle> <pages> pages 1635-1641, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1; 10; 3; 4] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [4] <author> D. H. Ballard and C. M. Brown. </author> <title> Principles of animate vision. </title> <journal> CVGIP, </journal> <volume> 56(1) </volume> <pages> 3-21, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1; 10; 3; 4] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [5] <author> P. J. Besl and R. C. Jain. </author> <title> Three dimensional object recognition. </title> <journal> ACM Computing Surveys, </journal> <volume> 17(1) </volume> <pages> 75-154, </pages> <year> 1985. </year>
Reference-contexts: Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [22; 21; 19; 16]. Besl and Jain <ref> [5] </ref> give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined [17; 18]. Most model acquisition strategies have focussed on CAD-like techniques.
Reference: [6] <author> A. F. Bobick and R. C. Bolles. </author> <title> Representation space: An approach to the integration of visual information. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 492-499, </pages> <address> San Diego CA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: There is little work on direct acquisition of 3-D representation from visual exploration, or on implicit representation of 3-D structure, though some research on recovery of explicit models from range sensors has been done [32; 34]. <ref> [6] </ref> address the problem of refining world and object representations during navigation by a mobile robot. [35] discuss a rigid body representation that is implicitly encoded in linear combinations of three views, and thus in principle automatically acquirable, but don't actually do it.
Reference: [7] <author> R. C. Bolles and R. A. Cain. </author> <title> Recognizing and localizing partially visible objects: The local-features-focus method. </title> <journal> International Journal of Robotics Research, </journal> <volume> 1(3) </volume> <pages> 57-82, </pages> <month> Fall </month> <year> 1982. </year>
Reference-contexts: Similarly, [33] propose a neural architecture for learning aspect-graph representation, but don't apply it to real objects. Work on automatic acquisition of 2-D representation has been more successful, since all the information is present (e.g. <ref> [7; 2; 12] </ref>) We expect these techniques to be useful here, since we essentially propose utilizing a collection of augmented 2-D representations. There is some recent work that has a memory-based flavor too it.
Reference: [8] <author> R. A. Brooks. </author> <title> Achieving artificial intelligence though building robots. </title> <type> Technical Report TR 899, </type> <institution> MIT, </institution> <year> 1986. </year>
Reference-contexts: What distinguishes the recent interest in behavioral vision from the historical efforts is the commitment to establish it within a computational framework. The resurgence of interest in the behavioral aspects of intelligence is perhaps most clearly illustrated by the subsumption architecture proposed by Brooks <ref> [8; 9] </ref>. This paradigm is rather rigorously Gibsonian in that it explicitly disavows the notion of internal representation, relying instead on purely reactive strategies.
Reference: [9] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-23, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: What distinguishes the recent interest in behavioral vision from the historical efforts is the commitment to establish it within a computational framework. The resurgence of interest in the behavioral aspects of intelligence is perhaps most clearly illustrated by the subsumption architecture proposed by Brooks <ref> [8; 9] </ref>. This paradigm is rather rigorously Gibsonian in that it explicitly disavows the notion of internal representation, relying instead on purely reactive strategies.
Reference: [10] <author> P. J. Burt. </author> <title> Smart sensing within a pyramid vision machine. </title> <journal> IEEE Procedings, </journal> <volume> 76(8) </volume> <pages> 1006-1015, </pages> <year> 1988. </year>
Reference-contexts: The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1; 10; 3; 4] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [11] <author> T. J. O. David J. Coombs and C. M. Brown. </author> <title> Gaze control and segmentation. </title> <booktitle> In Proc. AAAI Qualitative Vision Workshop, </booktitle> <address> Boston MA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Recent work on active vision [1; 10; 3; 4] has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information. Most work to date has focussed on the effect of the ability to move the sensor <ref> [11; 36] </ref> or dynamically change an internal focus of attention [31]. Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature.
Reference: [12] <author> F.Stein and G. Medioni. </author> <title> Efficient 2-dimensional object recgnition. </title> <booktitle> In Proc. ICPR, </booktitle> <pages> pages 13-17, </pages> <address> Atlantic City NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Similarly, [33] propose a neural architecture for learning aspect-graph representation, but don't apply it to real objects. Work on automatic acquisition of 2-D representation has been more successful, since all the information is present (e.g. <ref> [7; 2; 12] </ref>) We expect these techniques to be useful here, since we essentially propose utilizing a collection of augmented 2-D representations. There is some recent work that has a memory-based flavor too it. <p> This use of segment chains is somewhat similar to the structural indexing of Stein and Medioni <ref> [12] </ref>. 3 Recognition Algorithms The basic recognition procedure consists of four steps. First, potential key features are extracted from the image using low and intermediate level visual routines.
Reference: [13] <author> J. J. Gibson. </author> <title> The Perception of the Visual World. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1950. </year>
Reference-contexts: In fact, prior to the development of electronic computers, behavioral description was the only avenue available for investigating the phenomenon of vision. This precomputational work culminated in a series of books by Gibson <ref> [13; 14; 15] </ref> who advanced the central postulate that vision was essentially a modality that allowed biological systems to react to invariants 3 in the structure of the world. What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives.
Reference: [14] <author> J. J. Gibson. </author> <title> The Senses Considered as Perceptual Systems. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1966. </year>
Reference-contexts: In fact, prior to the development of electronic computers, behavioral description was the only avenue available for investigating the phenomenon of vision. This precomputational work culminated in a series of books by Gibson <ref> [13; 14; 15] </ref> who advanced the central postulate that vision was essentially a modality that allowed biological systems to react to invariants 3 in the structure of the world. What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives.
Reference: [15] <author> J. J. Gibson. </author> <title> The Ecological Approach to Visual Perception. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1979. </year>
Reference-contexts: In fact, prior to the development of electronic computers, behavioral description was the only avenue available for investigating the phenomenon of vision. This precomputational work culminated in a series of books by Gibson <ref> [13; 14; 15] </ref> who advanced the central postulate that vision was essentially a modality that allowed biological systems to react to invariants 3 in the structure of the world. What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives.
Reference: [16] <author> W. E. L. </author> <title> Grimson. Object Recognition by Computer: The role of geometric constraints. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [22; 21; 19; 16] </ref>. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined [17; 18]. Most model acquisition strategies have focussed on CAD-like techniques.
Reference: [17] <author> W. E. L. Grimson and D. P. Huttenlocher. </author> <title> On the sensitivity of geometric hashing. </title> <booktitle> In 3rd International Conference on Computer Vision, </booktitle> <pages> pages 334-338, </pages> <year> 1990. </year> <month> 16 </month>
Reference-contexts: Notable recent examples are [22; 21; 19; 16]. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined <ref> [17; 18] </ref>. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [18] <author> W. E. L. Grimson and D. P. Huttenlocher. </author> <title> On the sensitivity of the hough transform for object recognition. </title> <journal> IEEE PAMI, </journal> <volume> 12(3) </volume> <pages> 255-274, </pages> <year> 1990. </year>
Reference-contexts: Notable recent examples are [22; 21; 19; 16]. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined <ref> [17; 18] </ref>. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [19] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [22; 21; 19; 16] </ref>. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined [17; 18]. Most model acquisition strategies have focussed on CAD-like techniques.
Reference: [20] <author> K. N. Kutulakos and C. R. Dyer. </author> <title> Recovering shape by purposive viewpoint adjustment. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 16-28, </pages> <address> Champaign Il, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Most work to date has focussed on the effect of the ability to move the sensor [11; 36] or dynamically change an internal focus of attention [31]. Work on purposive or behavioral vision <ref> [27; 26; 20] </ref> attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [22; 21; 19; 16]. Besl and Jain [5] give a survey of older work.
Reference: [21] <author> Y. Lamdan and H. J. Wolfson. </author> <title> Geometric hashing: A general and efficient model-based recognition scheme. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 238-249, </pages> <address> Tampa FL, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [22; 21; 19; 16] </ref>. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined [17; 18]. Most model acquisition strategies have focussed on CAD-like techniques.
Reference: [22] <author> D. G. Lowe. </author> <title> Three-dimensional object recognition from single two-dimensional images. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 355-395, </pages> <year> 1987. </year>
Reference-contexts: Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [22; 21; 19; 16] </ref>. Besl and Jain [5] give a survey of older work. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various pertubations determined [17; 18]. Most model acquisition strategies have focussed on CAD-like techniques.
Reference: [23] <author> D. C. Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives. The first influential theory of computational vision, due to <ref> [23] </ref>, essentially defined vision as the problem of determining what is where, and focussed almost entirely on the computational and representational aspects of the problem. Marr's theory of vision essentially described a staged computational architecture leading from image, to primal sketch, to 2-1/2 D sketch to invariant object centered descriptions.
Reference: [24] <author> B. </author> <title> Mel. Object classification with high-dimensional vectors. </title> <booktitle> In Proc. Telluride Workshop on Neuromorphic Engineering, </booktitle> <address> Telluride CO, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: There is some recent work that has a memory-based flavor too it. Rao and Ballard [30] describe an approach based on the memorization of the responses of a set of steerable 4 filters centered on, or located at key points of an object. Mel <ref> [24] </ref> takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Murase and Nayar [25] find the major principal components of an image dataset, and uses the projections of unknown images onto these as indices into a recognition memory.
Reference: [25] <author> H. Murase and S. K. Nayar. </author> <title> Learning and recognition of 3d objects from appearance. </title> <booktitle> In Proc. IEEE Workshop on Qualitative Vision, </booktitle> <pages> pages 39-50, </pages> <year> 1993. </year>
Reference-contexts: Mel [24] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Murase and Nayar <ref> [25] </ref> find the major principal components of an image dataset, and uses the projections of unknown images onto these as indices into a recognition memory.
Reference: [26] <author> R. C. Nelson. </author> <title> Qualitative detection of motion by a moving observer. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(1) </volume> <pages> 33-46, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Most work to date has focussed on the effect of the ability to move the sensor [11; 36] or dynamically change an internal focus of attention [31]. Work on purposive or behavioral vision <ref> [27; 26; 20] </ref> attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [22; 21; 19; 16]. Besl and Jain [5] give a survey of older work.
Reference: [27] <author> R. C. Nelson. </author> <title> Vision as intelligent behavior: Research in machine vision at the university of rochester. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(1) </volume> <pages> 5-9, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: A natural viewpoint is thus one that is expected to occur in the context of the application, a normal object is one whose identification is important, and a reasonable environment is one in which the application must be carried out. We have called this a behavioral approach <ref> [27] </ref>. In this context, recognition appears less as a process of solving a geometric/optical puzzle and more as a matter of using sensory information to get at stored state that permits the system to successfully interact with the environment, however success is defined. <p> Most work to date has focussed on the effect of the ability to move the sensor [11; 36] or dynamically change an internal focus of attention [31]. Work on purposive or behavioral vision <ref> [27; 26; 20] </ref> attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [22; 21; 19; 16]. Besl and Jain [5] give a survey of older work.
Reference: [28] <author> R. C. Nelson. </author> <title> Visual homing using an associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 65 </volume> <pages> 281-291, </pages> <year> 1991. </year>
Reference-contexts: Second, taking a memory-based view can allow us to recognize and profit by relationships with other visual processes not generally thought of as recognition, for example, visual stabilization, and homing <ref> [28] </ref>. More generally, it provides a functional definition of recognition that ties in well with the behavioral notion of intelligence that has been gaining currency recently. It also provides a direct connection to learning and experience.
Reference: [29] <author> R. C. Nelson. </author> <title> Finding line segments by stick growing. </title> <journal> IEEE Trans PAMI, </journal> <volume> 16(5) </volume> <pages> 519-523, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Component segments were extracted using a stick-growing method developed recently at Rochester <ref> [29] </ref>, and organized into chains. For objects entered into the database, the best 10 chains were selected to represent the object.
Reference: [30] <author> R. P. Rao. </author> <title> Top-down gaze targeting for space-variant active vision. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, </booktitle> <pages> pages 1049-1058, </pages> <address> Monterey CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: There is some recent work that has a memory-based flavor too it. Rao and Ballard <ref> [30] </ref> describe an approach based on the memorization of the responses of a set of steerable 4 filters centered on, or located at key points of an object. Mel [24] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues.
Reference: [31] <author> R. D. Rimey and C. M. Brown. </author> <title> Where to look next using a bayes net: Incorporating geometric relations. </title> <booktitle> In Proc ECCV, </booktitle> <pages> pages 542-550, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Most work to date has focussed on the effect of the ability to move the sensor [11; 36] or dynamically change an internal focus of attention <ref> [31] </ref>. Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [22; 21; 19; 16].
Reference: [32] <author> R. K. Ruud M. Bolle and D. Sabbah. </author> <title> Primitive shape extraction from range data. </title> <booktitle> In Proc. IEEE Workshop on Computer Vision, </booktitle> <pages> pages 324-326, </pages> <address> Miami FL, </address> <month> Nov-Dec </month> <year> 1989. </year>
Reference-contexts: There is little work on direct acquisition of 3-D representation from visual exploration, or on implicit representation of 3-D structure, though some research on recovery of explicit models from range sensors has been done <ref> [32; 34] </ref>. [6] address the problem of refining world and object representations during navigation by a mobile robot. [35] discuss a rigid body representation that is implicitly encoded in linear combinations of three views, and thus in principle automatically acquirable, but don't actually do it.
Reference: [33] <author> M. Seibert and A. M. Waxman. </author> <title> Learning Aspect Graph Representations from View Sequences. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Similarly, <ref> [33] </ref> propose a neural architecture for learning aspect-graph representation, but don't apply it to real objects.
Reference: [34] <author> F. Solina and R. </author> <title> Bajcsy. Recovery of parameteric models from range images. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 12 </volume> <pages> 131-147, </pages> <month> February </month> <year> 1990. </year> <month> 17 </month>
Reference-contexts: There is little work on direct acquisition of 3-D representation from visual exploration, or on implicit representation of 3-D structure, though some research on recovery of explicit models from range sensors has been done <ref> [32; 34] </ref>. [6] address the problem of refining world and object representations during navigation by a mobile robot. [35] discuss a rigid body representation that is implicitly encoded in linear combinations of three views, and thus in principle automatically acquirable, but don't actually do it.
Reference: [35] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 13(10), </volume> <year> 1991. </year>
Reference-contexts: little work on direct acquisition of 3-D representation from visual exploration, or on implicit representation of 3-D structure, though some research on recovery of explicit models from range sensors has been done [32; 34]. [6] address the problem of refining world and object representations during navigation by a mobile robot. <ref> [35] </ref> discuss a rigid body representation that is implicitly encoded in linear combinations of three views, and thus in principle automatically acquirable, but don't actually do it. Similarly, [33] propose a neural architecture for learning aspect-graph representation, but don't apply it to real objects.
Reference: [36] <author> D. Wilkes and J. Tsotsos. </author> <title> Active object recognition. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 136-141, </pages> <address> Champaign IL, </address> <month> June </month> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Recent work on active vision [1; 10; 3; 4] has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information. Most work to date has focussed on the effect of the ability to move the sensor <ref> [11; 36] </ref> or dynamically change an internal focus of attention [31]. Work on purposive or behavioral vision [27; 26; 20] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature.
References-found: 36

