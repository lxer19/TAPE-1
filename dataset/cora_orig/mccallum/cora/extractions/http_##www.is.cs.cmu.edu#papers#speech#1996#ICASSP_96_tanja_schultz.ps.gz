URL: http://www.is.cs.cmu.edu/papers/speech/1996/ICASSP_96_tanja_schultz.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: ftanja,rogina,waibelg@ira.uka.de  
Title: LVCSR-BASED LANGUAGE IDENTIFICATION  
Author: T.Schultz, I.Rogina, and A. Waibel 
Address: (USA)  
Affiliation: Interactive Systems Laboratories University of Karlsruhe (Germany), Carnegie Mellon University  
Abstract: Automatic language identification is an important problem in building multilingual speech recognition and understanding systems. Building a language identification module for four languages we studied the influence of applying different levels of knowledge sources on a large vocabulary continuous speech recognition (LVCSR) approach, i.e. the phonetic, phonotactic, lexical, and syntactic-semantic knowledge. The resulting language identification (LID) module can identify spontaneous speech input and can be used as a front-end for our multilingual speech-to-speech translation system JANUS-II. A comparison of five LID systems showed that the incorporation of lexical and linguistic knowledge reduces the language identification error for the 2-language tests up to 50%. Based on these results we build a LID module for German, English, Spanish, and Japanese which yields 84% identification rate on the Spontaneous Scheduling Task (SST). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.A. Zissmann and E. Singer: </author> <title> Automatic Language Identification of Telephone Speech Messages using Phoneme Recognition and N-gram Modeling. </title> <booktitle> Proceedings of the ICASSP 1993, </booktitle> <volume> volume 2, </volume> <pages> pp. 309-402. </pages>
Reference-contexts: 1. INTRODUCTION In recent years language identification (LID) has received renewed and increased interest as large vocab ulary continuous speech recognition (LVCSR) technology is being applied to multiple languages. Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes <ref> [1] </ref>, [2] or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], [5], another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. <p> Each system decodes the utterance with the language-dependent system to determine the best hypothesis and the language belonging to the system with the best score (or highest likelihood) is hypothesized. This kind of structure is used in [2], [5] and <ref> [1] </ref>. One problem with this approach is, that the scores of the language dependent system cannot be compared without prior normalization.
Reference: [2] <author> L.F. Lamel and J. Gauvain: </author> <title> Identifying Nonlinguistic Speech Features. </title> <booktitle> Proceedings of the Eu-rospeech 1993, </booktitle> <volume> volume 1, </volume> <pages> pp. 23-30. </pages>
Reference-contexts: 1. INTRODUCTION In recent years language identification (LID) has received renewed and increased interest as large vocab ulary continuous speech recognition (LVCSR) technology is being applied to multiple languages. Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], <ref> [2] </ref> or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], [5], another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. <p> Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], <ref> [2] </ref> or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], [5], another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. <p> Each system decodes the utterance with the language-dependent system to determine the best hypothesis and the language belonging to the system with the best score (or highest likelihood) is hypothesized. This kind of structure is used in <ref> [2] </ref>, [5] and [1]. One problem with this approach is, that the scores of the language dependent system cannot be compared without prior normalization. <p> The phoneme sets include special noise models to model different non-speech events as described in [10]. System 2: PwithPT is similar to PnoPT but in addition phonotactics i.e. a phoneme bigram is applied. This phonological knowledge is integrated into the search procedure as shown in <ref> [2] </ref>. The phoneme accuracy for the PwithPT system was 49.6% for German input, 48.3% for English and 46.9% for Spanish speech which is comparable to the performance of other spontaneous spoken speech systems.
Reference: [3] <author> Y. Muthusamy, K. Berkling, T. Arai, R.A. Cole, and E. Barnard: </author> <title> Comparison of Approaches to Automatic Language Identification using Telephone Speech. </title> <booktitle> Proceedings of the Eurospeech 1993, </booktitle> <pages> pp. 1307-1310. </pages>
Reference-contexts: Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], [2] or broad phoneme classes <ref> [3] </ref> for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], [5], another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. <p> The identification process is performed by presenting a complete utterance to the system. 3. OVERALL SYSTEM STRUCTURE There are several kinds of architectures for LID systems. An integrated architecture consists of a single global recognition system which is language-independent as described in <ref> [3] </ref>. One drawback is the increasing ambiguity when adding languages to be identified to the system. In parallel architectures, for each language to be identified a language-dependent system is trained, language identification is performed by running all systems in parallel.
Reference: [4] <author> A.A. Reyes, T. Seino, and S. </author> <title> Nakagawa Three Language Identification Methods based on HMMs. </title> <booktitle> Proceedings of the ICSLP 1994, </booktitle> <pages> pp. 1895-1898. </pages>
Reference-contexts: Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], [2] or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams <ref> [4] </ref>, [5], another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources.
Reference: [5] <author> T.J. Hazen and V.W. </author> <title> Zue Automatic Language Identification using a Segment-based Approach. </title> <booktitle> Proceedings of the Eurospeech 1993, </booktitle> <pages> pp. 1303-1306. </pages>
Reference-contexts: Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], [2] or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], <ref> [5] </ref>, another approach was presented by [6], using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. <p> Each system decodes the utterance with the language-dependent system to determine the best hypothesis and the language belonging to the system with the best score (or highest likelihood) is hypothesized. This kind of structure is used in [2], <ref> [5] </ref> and [1]. One problem with this approach is, that the scores of the language dependent system cannot be compared without prior normalization.
Reference: [6] <author> S. Lowe et al.: </author> <title> Language Identification via Large Vocabulary Speaker Independent Continuous Speech Recognition Personal Communication. </title>
Reference-contexts: Most of the recent approaches to LID take advantage of units that are smaller than words such as phonemes [1], [2] or broad phoneme classes [3] for the identification process. Some approaches add phonotactic information encoded as phoneme bigrams [2] or trigrams [4], [5], another approach was presented by <ref> [6] </ref>, using a word-based recognizer. Nevertheless, most approaches for identifying languages are restricted to phoneme-based knowledge sources. Knowing that the integration of a word-based lexicon and grammars leads to a large improvement in speech recognition systems, we focused our experiments on how such knowledge sources can improve a LID system.
Reference: [7] <author> A. Waibel, M. Finke, D. Gates, M. Gavalda, T. Kemp, A. Lavie, L. Levin, M. Maier, L. May-field, A. McNair, I. Rogina, K. Shima, T. Slo-boda, M. Woszczyna, T. Zeppenfeld, and P. Zhan: </author> <note> JANUS-II Translation of Spontaneous Conversational Speech to appear in ICASSP 96. </note>
Reference-contexts: Nevertheless, in multilingual speech processing tasks, in which recognition is the objective, dictionaries, language models and other higher-level knowledge sources are already available. In speech-to-speech translation applications like JANUS-II <ref> [7] </ref> the identification of the language could be employed as a front-end module to language-dependent LVCSR. Word level LID using higher linguistic knowledge can be integrated into the speech recognition process without requiring additional computational effort. <p> WwithLM gave 86% language identification rate on the 3-language test. 5.3. Final System Finally we built two 4-language systems to identify German, English, Spanish and Japanese. For these final systems we used the new recognizer <ref> [7] </ref> which were improved in the meantime by e.g. incorporating trigrams into the decoder and better phoneme models for the German recognizer. Therefore we called the new LID systems Pwith3PT and Wwith3LM respectively. The table 3 summarizes the recognition performance and the language identification rate of Pwith3PT and Wwith3LM.
Reference: [8] <author> B. Suhm, P. Geutner, T. Kemp, A. Lavie, L. May-field, A.E. McNair, I. Rogina, T. Sloboda, W. Ward, M. Woszczyna, A. Waibel: </author> <title> JANUS: Towards Multilingual Spoken Language Translation. </title> <booktitle> DARPA Speech and Natural Language Workshop 1994. </booktitle>
Reference-contexts: This database has been collected at Carnegie Mellon University (Pittsburgh, USA), Karlsruhe University (Ger-many), and at ATR International (Japan) over the last two years <ref> [8] </ref>. Languages utterances hours English 7644 6.9 German 12292 30.5 Spanish 5730 10.7 Japanese 3311 8.0 Table 1: The Spontaneous Scheduling Task SST The SST corpus currently consists of English, German, Spanish, Japanese and Korean dialogs, spontaneously spoken by native speakers. Table 1 summarizes the currently available data.
Reference: [9] <author> T. Schultz, I. Rogina, and A. Waibel: </author> <title> Experiments with LVCSR based Language Identification. </title> <booktitle> Proceedings of the SRS 1995, </booktitle> <pages> pp. 89-94. </pages>
Reference-contexts: EXPERIMENTAL LID-SYSTEMS To investigate the benefit of different knowledge sources for LID we constructed five systems applying various degrees of knowledge and applied the resulting systems to language pairs <ref> [9] </ref>. System 1: PnoPT is a recognizer with phoneme-based acoustic modeling. For each language a system with context-independent phonemes which are modeled by CDHMMs with 50 mixture Gaussians was built. For the German language we used a set of 46 phonemes, for English 54 phonemes and for Spanish 48 phonemes. <p> The CMU data are collected in a noisy office environment while the data collected at Karlsruhe are very clean. We found that testing under different channel conditions overestimate the language identification performance significantly <ref> [9] </ref>. To further avoid such influences on our LID-results, we collected additional German data under noisy conditions at CMU and English data under clean conditions at Karlsruhe.
Reference: [10] <author> T. Schultz, and I. Rogina: </author> <booktitle> Acoustic and Language Modeling of Human and Nonhuman Noises for Human-to-Human Spontaneous Speech Recognition Proceedings of the ICASSP 1995, </booktitle> <pages> pp. 293-296. </pages>
Reference-contexts: For the German language we used a set of 46 phonemes, for English 54 phonemes and for Spanish 48 phonemes. The phoneme sets include special noise models to model different non-speech events as described in <ref> [10] </ref>. System 2: PwithPT is similar to PnoPT but in addition phonotactics i.e. a phoneme bigram is applied. This phonological knowledge is integrated into the search procedure as shown in [2].
References-found: 10

