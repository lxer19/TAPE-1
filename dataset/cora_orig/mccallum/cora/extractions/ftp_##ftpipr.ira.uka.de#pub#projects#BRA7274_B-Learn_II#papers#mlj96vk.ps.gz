URL: ftp://ftpipr.ira.uka.de/pub/projects/BRA7274_B-Learn_II/papers/mlj96vk.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/projects/blearn/blearnpub.html
Root-URL: 
Email: klingspor@ls8.informatik.uni-dortmund.de  morik@ls8.informatik.uni-dortmund.de  rieger@ls8.informatik.uni-dortmund.de  
Title: Learning Concepts from Sensor Data of a Mobile Robot  
Author: VOLKER KLINGSPOR KATHARINA J. MORIK ANKE D. RIEGER 
Keyword: inductive logic programming, robot navigation, combining sensing and action, perceptually anchored concepts  
Address: VIII, 44221 Dortmund, Germany  
Affiliation: Univ. Dortmund, Computer Science Dept. LS  
Note: 1?? c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: Machine learning can be a most valuable tool for improving the flexibility and efficiency of robot applications. Many approaches to applying machine learning to robotics are known. Some approaches enhance the robot's high-level processing, the planning capabilities. Other approaches enhance the low-level processing, the control of basic actions. In contrast, the approach presented in this paper uses machine learning for enhancing the link between the low-level representations of sensing and action and the high-level representation of planning. The aim is to facilitate the communication between the robot and the human user. A hierarchy of concepts is learned from route records of a mobile robot. Perception and action are combined at every level, i.e., the concepts are perceptually anchored. The relational learning algorithm grdt has been developed which completely searches in a hypothesis space, that is restricted by rule schemata, which the user defines in terms of grammars. 
Abstract-found: 1
Intro-found: 1
Reference: <author> N. I. Badler, B. L. Webber, J. Kalita, and J. Esakov. </author> <title> Animation from instructions. In N.I. </title> <editor> Badler, B.A. Barsky, and D. Zeltzer, editors, </editor> <title> Making Them Move: Mechanics, </title> <journal> Control, and Animation of Articulated Figures, </journal> <pages> pages 51-93. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Therefore, the representation for learning resembles the robot's low-level representation and is not easily understandable to human users. It has been argued, however, that human-machine interaction is necessary in order to fully exploit the opportunities of a robot (Nilsson, 1984), <ref> (Badler et al., 1991) </ref>. In order to facilitate access to a robot for human users, the low-level representation has to be translated into an understandable form. We address robot applications in which the robot is not completely autonomous but is interacting with human users.
Reference: <author> C. Baroglio, A. Giordana, and R. Piola. </author> <title> Learning control functions for industrial robots. </title> <booktitle> In MLC-COLT '94 Robot Learning Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: In our approach, machine learning helps to construct the description of a robot's actions and its environment. At lower levels of a robot's processing, machine learning can be applied in order to improve its performance (Kaelbling & Rosenschein, 1990), (Millan & Torras, 1992), (Mitchell & Thrun, 1993), <ref> (Baroglio et al., 1994) </ref>. These approaches assume a fully automated mode of robot operation and learning where no human interaction 2 V. KLINGSPOR, K.J. MORIK, AND A.D. RIEGER with the robot or the learning component is intended.
Reference: <author> Scott William Bennett. </author> <title> Learning uncertainty tolerant plans through approximation in complex domains. </title> <type> Technical Report UILU-ENG-89-2204, </type> <institution> The Beckman Institute for Advanced Science and Technology, University of Illinois at Urbana-Champaign, </institution> <month> January </month> <year> 1989. </year>
Reference: <author> F. Bergadano and D. Gunetti. </author> <title> An interactive system to learn funcional logic programs. </title> <booktitle> In Procs. 13th IJCAI, </booktitle> <pages> pages 1044-1049. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: The information gain heuristic, used by foil (Quinlan, 1990), is an example for a semantic restriction. Syntactic bias, particularly language bias, is used by many different systems to restrict the search space (e.g., (Silverstein & Pazzani, 1991), (De Raedt, 1992), <ref> (Bergadano & Gunetti, 1993) </ref>, (Tausend, 1993)). For all of them, the user must be able to provide the structure of the expected rules to generate the search space description. This step depends heavily on the chosen representation language, the signature.
Reference: <author> R. A. Brooks. </author> <title> The role of learning in autonomous robots. </title> <booktitle> In Procs. </booktitle> <volume> COLT 91, </volume> <pages> pages 5-10, </pages> <year> 1991. </year>
Reference-contexts: We address robot applications in which the robot is not completely autonomous but is interacting with human users. In our approach, machine learning is applied to bridge the gap between low-level and high-level representations. Biologically inspired work in robotics has developed artificial beings that adapt to their environment <ref> (Brooks, 1991) </ref>, (Steels, 1993). This type of learning is restricted to reflex-like behavior. Higher levels of cognition such as reasoning and concept formation are excluded. In contrast, we are interested in the link between perception and concepts. This is the problem of symbol grounding (Harnad, 1990), (Wrobel, 1991).
Reference: <author> William W. Cohen. </author> <title> Grammatically biased learning: Learning logic programs using an explicit antecedent description language. </title> <journal> Artificial Intelligence, </journal> <volume> 68(2) </volume> <pages> 243-302, </pages> <year> 1994. </year>
Reference: <author> Luc De Raedt. </author> <title> Interactive Theory Revision: an Inductive Logic Programming Approach. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference: <author> G. DeJong and S. Bennett. </author> <title> Permissive planning a machine learning approach to linking internal and external worlds. </title> <booktitle> In Procs. 11th AAAI, </booktitle> <pages> pages 508-513, </pages> <year> 1993. </year>
Reference-contexts: Lessons learned from failures of robot actions can be used to enhance the planning capabilities of a robot (Bennett, 1989), (Zercher, 1992). Learning is used to link the environment model with the perception when executing a plan <ref> (DeJong & Bennett, 1993) </ref>, (Gil, 1994). The plan or the environment model is refined to accommodate practical experience with the plan. These approaches require an almost complete description of the robot's actions and its environment. It is a time consuming task to build up such a description. <p> The idea being the same, our approach differs in that we represent and learn plans within the ILP-framework. Our approach to the application of learning to robotics is closely related to approaches to learning plans for robots (Mitchell, 1990), <ref> (DeJong & Bennett, 1993) </ref>, (Gervasio & DeJong, 1994), and (Gil, 1994). Some distinctions need to be mentioned. First, we do not use an a priori model of the environment. Therefore, we do not learn from mismatches between the predicted and the observed effects of actions as (DeJong & Bennett, 1993) and <p> for robots (Mitchell, 1990), <ref> (DeJong & Bennett, 1993) </ref>, (Gervasio & DeJong, 1994), and (Gil, 1994). Some distinctions need to be mentioned. First, we do not use an a priori model of the environment. Therefore, we do not learn from mismatches between the predicted and the observed effects of actions as (DeJong & Bennett, 1993) and (Gil, 1994) do. Our learning does not refine a given plan, instead it actually constructs the rules to be used for planning. Second, our representation of planning operators is not that of classical planning with add and delete lists which makes inference non-monotonic.
Reference: <author> Rudiger Dillmann, Jurgen Kreuziger, and Frank Wallner. </author> <title> PRIAMOS an experimental platform for reflexive navigation. </title> <editor> In Groen, Hirose, and Thorpe, editors, IAS-3: </editor> <booktitle> Intelligent Autonomous Systems, chapter 18, </booktitle> <pages> pages 174-183. </pages> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference: <author> R. J. Doyle, D. J. Atkinson, and R. S. Doshi. </author> <title> Generating perception requests and expectations to verify the execution of plans. </title> <booktitle> In Procs. of the AAAI, </booktitle> <pages> pages 81-88, </pages> <year> 1986. </year>
Reference-contexts: With respect to the bidirectional use, our concepts are similar to the prediction rules used by Shen. The main difference concerns the domain of application, which in our case is much more demanding, as we are dealing with real-world data. In the jpl Telerobot <ref> (Doyle et al., 1986) </ref> a strips-like planner is used, in which the precondition lists are amended to contain sensory requests to verify beliefs, and 26 V. KLINGSPOR, K.J. MORIK, AND A.D. RIEGER the postcondition lists are amended to include sensory requests that validate the effects of each action.
Reference: <author> Saso Dzeroski, Stephen Muggleton, and Stuart Russell. </author> <title> PAC-learnability of determinate logic programs. Procs. </title> <booktitle> of 5th COLT, </booktitle> <pages> pages 128-135, </pages> <year> 1992. </year>
Reference: <author> M. Gervasio and G. DeJong. </author> <title> An incremental learning approach to completable planning. </title> <editor> In W. Cohen and H. Hirsh, editors, </editor> <booktitle> Procs. 11th Int. Machine Learning Conf., </booktitle> <pages> pages 78-86, </pages> <year> 1994. </year>
Reference-contexts: We are aware of problems with the time constraint of real-time processing that can hardly be met by our planner. This may well force us to distinguish in the future between planning in advance and planning at runtime as do <ref> (Gervasio & DeJong, 1994) </ref>. We explore the compilation of a rule set and facts into a structure that can more efficiently be executed in real-time. <p> The idea being the same, our approach differs in that we represent and learn plans within the ILP-framework. Our approach to the application of learning to robotics is closely related to approaches to learning plans for robots (Mitchell, 1990), (DeJong & Bennett, 1993), <ref> (Gervasio & DeJong, 1994) </ref>, and (Gil, 1994). Some distinctions need to be mentioned. First, we do not use an a priori model of the environment. Therefore, we do not learn from mismatches between the predicted and the observed effects of actions as (DeJong & Bennett, 1993) and (Gil, 1994) do. <p> This way, we avoid committing ourselves prematurely to a firm sensor value. Our plan just states that a move has to be executed until a pattern of distance measurements is registered. This is similar to the contingent variables of <ref> (Gervasio & DeJong, 1994) </ref>. Note, however, that in our case the sensor pattern is more complex than just a variable for a particular distance. A perceptual feature in our approach already abstracts beyond particular distance values and gives relations between sensor measurements instead.
Reference: <author> Y. Gil. </author> <title> Learning by experimentation incremental refinement of incomplete planning. </title> <editor> In W. Cohen and H. Hirsh, editors, </editor> <booktitle> Procs. 11th Int. Machine Learning Conf., </booktitle> <pages> pages 87-95, </pages> <year> 1994. </year> <title> Stevan Harnad. The symbol grounding problem. </title> <journal> Physica D, </journal> <volume> 42 </volume> <pages> 335-346, </pages> <year> 1990. </year>
Reference-contexts: Lessons learned from failures of robot actions can be used to enhance the planning capabilities of a robot (Bennett, 1989), (Zercher, 1992). Learning is used to link the environment model with the perception when executing a plan (DeJong & Bennett, 1993), <ref> (Gil, 1994) </ref>. The plan or the environment model is refined to accommodate practical experience with the plan. These approaches require an almost complete description of the robot's actions and its environment. It is a time consuming task to build up such a description. <p> The idea being the same, our approach differs in that we represent and learn plans within the ILP-framework. Our approach to the application of learning to robotics is closely related to approaches to learning plans for robots (Mitchell, 1990), (DeJong & Bennett, 1993), (Gervasio & DeJong, 1994), and <ref> (Gil, 1994) </ref>. Some distinctions need to be mentioned. First, we do not use an a priori model of the environment. Therefore, we do not learn from mismatches between the predicted and the observed effects of actions as (DeJong & Bennett, 1993) and (Gil, 1994) do. <p> & Bennett, 1993), (Gervasio & DeJong, 1994), and <ref> (Gil, 1994) </ref>. Some distinctions need to be mentioned. First, we do not use an a priori model of the environment. Therefore, we do not learn from mismatches between the predicted and the observed effects of actions as (DeJong & Bennett, 1993) and (Gil, 1994) do. Our learning does not refine a given plan, instead it actually constructs the rules to be used for planning. Second, our representation of planning operators is not that of classical planning with add and delete lists which makes inference non-monotonic.
Reference: <author> Nicolas Helft. </author> <title> Induction as nonmonotonic inference. </title> <booktitle> In Procs. of the 1st Int. Conf. on Knowledge Representation and Reasoning, </booktitle> <year> 1989. </year>
Reference: <author> F. Jelinek. </author> <title> Continuous speech recognition by statistical methods. Procs. </title> <journal> of the IEEE, </journal> <volume> 64 </volume> <pages> 532-556, </pages> <year> 1976. </year>
Reference-contexts: During learning, the training data is evaluated in order to derive relative frequencies, which are taken as estimates for the transition probabilities. During the performance phase, we use a modified version of the Viterbi algorithm <ref> (Jelinek, 1976) </ref>, with which we determine the concept, which most probably has been perceived. In this way, the acting phase of our performance step is enhanced. 6.2. Related Work There are similarities between our work and Shen's approach (Shen, 1993) to learning from the environment.
Reference: <author> L. P. Kaelbling and S. J. Rosenschein. </author> <title> Action and planning in embedded agents. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 6 </volume> <pages> 35-48, </pages> <year> 1990. </year>
Reference-contexts: This makes the application of robots inflexible. In our approach, machine learning helps to construct the description of a robot's actions and its environment. At lower levels of a robot's processing, machine learning can be applied in order to improve its performance <ref> (Kaelbling & Rosenschein, 1990) </ref>, (Millan & Torras, 1992), (Mitchell & Thrun, 1993), (Baroglio et al., 1994). These approaches assume a fully automated mode of robot operation and learning where no human interaction 2 V. KLINGSPOR, K.J. MORIK, AND A.D. RIEGER with the robot or the learning component is intended.
Reference: <author> Jorg-Uwe Kietz and Stefan Wrobel. </author> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, chapter 16, </booktitle> <pages> pages 335-360. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1992. </year>
Reference: <author> Jose Millan and Carme Torras. </author> <title> A reinforcement connectionist approach to robot path finding in non-maze-like environments. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 363-395, </pages> <year> 1992. </year> <note> 30 V. </note> <author> KLINGSPOR, K.J. MORIK, AND A.D. RIEGER T. M. Mitchell and S. B. Thrun. </author> <title> Explanation-based neural network learning for robot control. </title> <editor> In C. L. Giles, S. J. Hanson, and J. D. Cowan, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> T. Mitchell. </author> <title> Becoming increasingly reactive. </title> <booktitle> In Procs. 8th AAAI, </booktitle> <pages> pages 1051-1058, </pages> <year> 1990. </year>
Reference-contexts: The idea being the same, our approach differs in that we represent and learn plans within the ILP-framework. Our approach to the application of learning to robotics is closely related to approaches to learning plans for robots <ref> (Mitchell, 1990) </ref>, (DeJong & Bennett, 1993), (Gervasio & DeJong, 1994), and (Gil, 1994). Some distinctions need to be mentioned. First, we do not use an a priori model of the environment.
Reference: <author> K. Morik, S. Wrobel, J.-U. Kietz, and W. Emde. </author> <title> Knowledge Acquisition and Machine Learning Theory, Methods, and Applications. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: Testing a hypothesis means to find all solutions for the goal concept with the hypothesis | which is just a Horn clause | as concept definition and the background knowledge as theory. This test is tractable because the facts are ground (Wrobel, 1987), <ref> (Morik et al., 1993) </ref>. Since the knowledge is managed by mobal's inference engine im-2, the test itself is slightly different to a simple prolog-call. The user constructs an acceptance criterion using the cardinalities above. <p> The described system is the result of the collective effort of everybody involved. We thank wholeheartedly the mobal team at the Gesellschaft fur Mathematik und Datenverarbeitung (GMD), Werner Emde, Jorg-Uwe Kietz, Edgar Sommer, and Stefan Wrobel. We use the mobal-system <ref> (Morik et al., 1993) </ref> for the maintenance of the knowledge base and parts of grdt are directly taken from mobal's learning component rdt. In particular, Jorg-Uwe Kietz advocated the relational representation of time and assisted us with theoretical effort estimations. Notes 1. <p> The difference is, first, the flexible user-given acceptance criterion, applied by GRDT, and, second, the focus on one goal concept for learning in one learning run. 6. rdt is one of the learning tools of the knowledge acquisition system mobal <ref> (Morik et al., 1993) </ref> 7. A short note about our typographical conventions: rule schemata of rdt are written with ordinary arrows (! ), grendel's grammars with ,! , and grdt's grammars with ; . Nonterminal literals are written slanted, terminals are written sans serif.
Reference: <author> S. Muggleton and L. De Raedt. </author> <title> Inductive logic programming: Theory and methods. </title> <type> Technical Report CW 178, </type> <institution> Department of Computing Science, K.U. Leuven, </institution> <month> May </month> <year> 1993. </year> <editor> Stephen Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: An example is the rule through door (Tr, T1, T2, PDir, Side, Orien) ! period of time perception (Tr, T1, T2, through door, PDir, Side, Orien). 3. Learning an incremental function approximator definitely goes beyond the purpose of our research. 4. This and the following definition are taken from <ref> (Muggleton & De Raedt, 1993) </ref>. 5. Helft's approach actually does not use positive and negative examples but completes the given observations by the generalizationstep, which implies a closed-world assumption.
Reference: <author> N. J. Nilsson. </author> <title> Shakey the robot. </title> <type> Technical Note 323, </type> <institution> Artificial Intelligence Center, SRI International, </institution> <address> Menlo Park, CA, </address> <year> 1984. </year>
Reference-contexts: RIEGER with the robot or the learning component is intended. Therefore, the representation for learning resembles the robot's low-level representation and is not easily understandable to human users. It has been argued, however, that human-machine interaction is necessary in order to fully exploit the opportunities of a robot <ref> (Nilsson, 1984) </ref>, (Badler et al., 1991). In order to facilitate access to a robot for human users, the low-level representation has to be translated into an understandable form. We address robot applications in which the robot is not completely autonomous but is interacting with human users.
Reference: <author> Gordon D. Plotkin. </author> <title> A note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, chapter 8, </booktitle> <pages> pages 153-163. </pages> <publisher> American Elsevier, </publisher> <year> 1970. </year>
Reference: <author> Gordon D. Plotkin. </author> <title> Automatic methods of inductive inference. </title> <type> PhD thesis, </type> <institution> University of Edin-burgh, </institution> <year> 1971. </year>
Reference: <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Semantically pruning the search restricts the hypothesis space dependent on the given data, leading the search into areas of special interest and pruning parts that seem to be unnecessary to characterize the goal concept. The information gain heuristic, used by foil <ref> (Quinlan, 1990) </ref>, is an example for a semantic restriction. Syntactic bias, particularly language bias, is used by many different systems to restrict the search space (e.g., (Silverstein & Pazzani, 1991), (De Raedt, 1992), (Bergadano & Gunetti, 1993), (Tausend, 1993)).
Reference: <author> A. Rieger. </author> <title> Data preparation for inductive learning in robotics. </title> <booktitle> In Procs. of the IJCAI-Workshop on Data Engineering for Inductive Learning, </booktitle> <year> 1995. </year> <note> to appear. </note>
Reference: <author> A. Rieger. </author> <title> Inferring probabilistic automata from sensor data for robot navigation. </title> <booktitle> In Procs. of the 3rd European Workshop on Learning Robots, </booktitle> <year> 1995. </year>
Reference: <author> Alberto Segre. </author> <title> Machine Learning of Robot Assembly Plans. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference: <author> Wei-Min Shen. </author> <title> Discovery as autonomous learning from the environment. </title> <journal> Machine Learning, </journal> <volume> 12 </volume> <pages> 143-165, </pages> <year> 1993. </year>
Reference: <author> Glenn Silverstein and Michael J. Pazzani. </author> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <editor> In L. Birnbaum and G. Collins, editors, </editor> <booktitle> Machine Learning: Procs. of the 8th Int. Workshop, </booktitle> <pages> pages 298-302, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Luc Steels. </author> <title> Building agents out of autonomous behavior systems. </title> <editor> In L. Steels and R. Brooks, editors, </editor> <title> The 'artificial life' route to 'artificial intelligence' Building situated embodied agents. </title> <publisher> Lawrence Erlbaum, </publisher> <address> New Haven, </address> <year> 1993. </year>
Reference: <author> Eva Stopp, Klaus-Peter Gapp, Gerd Herzog, Thomas Laengle, and Tim Lueth. </author> <title> Utilizing spatial relations for natural language access to an autonomous mobile robot. </title> <booktitle> In KI-94, Procs. of the German Conference on AI, </booktitle> <address> Berlin, 1994. </address> <publisher> Springer. </publisher>
Reference: <author> Birgit Tausend. </author> <title> Representing biases for inductive logic programming. </title> <editor> In Pavel Brazdil, editor, </editor> <booktitle> Machine Learning Procs. of ECML-93, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 427-430, </pages> <address> Berlin, Heidelberg, New York, </address> <year> 1993. </year> <title> Springer. Stefanie Wessel. Lernen qualitativer Merkmale aus numerischen Robotersensordaten. </title> <type> Master's thesis, </type> <institution> Universitat Dortmund, </institution> <year> 1995. </year>
Reference: <author> Stefan Wrobel. </author> <title> Higher-order concepts in a tractable knowledge representation. </title> <editor> In K. Morik, editor, </editor> <booktitle> GWAI-87 11th German Workshop on Artificial Intelligence, </booktitle> <pages> pages 129-138, </pages> <address> Berlin, New York, Tokyo, October 1987. </address> <publisher> Springer Verlag. </publisher>
Reference: <author> Stefan Wrobel. </author> <title> Towards a model of grounded concept formation. </title> <booktitle> In Procs. 12th IJCAI, </booktitle> <pages> pages 712-719, </pages> <address> Los Altos, CA, 1991. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <institution> Kai Zercher. Wissensintensives Lernen fur zeitkritische technische Diagnoseaufgaben. infix, Sankt Augustin, </institution> <year> 1992. </year>
References-found: 36

