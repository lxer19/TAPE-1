URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/JanSmaGro95.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: NESTED NETWORKS FOR ROBOT CONTROL  
Author: Arjen Jansen*+, Patrick van der Smagt*, and Frans Groen* A. F. Murray 
Note: (ed.), Applications of Neural Networks, 221-239. c 1995 Kluwer Academic Publishers. Printed in the Netherlands. 221  
Address: Amsterdam Kruislaan 403, 1098 SJ Amsterdam The Netherlands I.B.M. The Netherlands N.V. Marketing  Watsonweg 2, 1423 ND Uithoorn The Netherlands  
Affiliation: Department of Computer Systems University of  Information and Services Centre  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. Martinetz, H. Ritter, and K. Schulten. </author> <title> Three-dimensional neural net for learning visuomotor coordination of a robot arm. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 1(1) </volume> <pages> 131-136, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In our study on neural adaptive robot controllers we have found that proposed methods which attack the problem of camera-motor coordination either suffer from long learning times or from a less precise approximation. For example, Ko-honen networks as initially proposed by Ritter et al. <ref> [1, 2, 3] </ref> can get a precision of around 0.5 cm in the end-effector position in a few feedback steps, but need thousands of iterations to attain reasonable results. <p> It is preferred that this number be kept low, since we favour local over global approximation. Also, our simulation results show that linear feed-forward networks (i.e., no hidden units at all; a method very comparable to <ref> [1, 3] </ref>) give much worse results than networks with a few hidden units. In most runs we chose five hidden units for each network. There are a few constants in the conjugate gradient learning process which determine the summed squared error reached in the networks.
Reference: [2] <author> T. Martinetz and K. Schulten. </author> <title> A "neural-gas" network learns topologies. </title> <booktitle> In Proceedings of the 1991 International Conference on Artificial Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages 397-402, </pages> <address> Espoo, Finland, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: In our study on neural adaptive robot controllers we have found that proposed methods which attack the problem of camera-motor coordination either suffer from long learning times or from a less precise approximation. For example, Ko-honen networks as initially proposed by Ritter et al. <ref> [1, 2, 3] </ref> can get a precision of around 0.5 cm in the end-effector position in a few feedback steps, but need thousands of iterations to attain reasonable results.
Reference: [3] <author> T. Hesselroth, K. Sarkar, P. van der Smagt, and K. Schulten. </author> <title> Neural network control of a pneumatic robot arm. </title> <journal> Technical Report UIUC-BI-TB-92-15 (IEEE Systems, Man, and Cybernetics, </journal> <note> to be published), </note> <institution> Theoretical Biophysics, University of Illinois at Urbana/Champaign, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: In our study on neural adaptive robot controllers we have found that proposed methods which attack the problem of camera-motor coordination either suffer from long learning times or from a less precise approximation. For example, Ko-honen networks as initially proposed by Ritter et al. <ref> [1, 2, 3] </ref> can get a precision of around 0.5 cm in the end-effector position in a few feedback steps, but need thousands of iterations to attain reasonable results. <p> It is preferred that this number be kept low, since we favour local over global approximation. Also, our simulation results show that linear feed-forward networks (i.e., no hidden units at all; a method very comparable to <ref> [1, 3] </ref>) give much worse results than networks with a few hidden units. In most runs we chose five hidden units for each network. There are a few constants in the conjugate gradient learning process which determine the summed squared error reached in the networks.
Reference: [4] <author> P. van der Smagt and B. Krose. </author> <title> A real-time learning neural robot controller. </title> <booktitle> In Proceedings of the 1991 International Conference on Artificial Neural Networks, </booktitle> <pages> pages 351-356, </pages> <address> Espoo, Finland, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The use of a single feed-forward network trained with conjugate gradient back-propagation has been shown to give fast and highly adaptive approximation of inverse kinematics functions, but a large number of feedback steps is needed to get high-precision results <ref> [4] </ref>. Thus, accurate representations can be obtained with local representations, but it takes many learning samples (and therefore a long time) to get a reasonable distribution amongst all the learning kernels.
Reference: [5] <author> P. van der Smagt, A. Jansen, and F. Groen. </author> <title> Interpolative robot control with the nested network approach. </title> <booktitle> In Proceedings of the 1992 IEEE International Symposium on Intelligent Control, </booktitle> <pages> pages 475-480. </pages> <address> Glasgow, Scotland, U.K., </address> <month> August </month> <year> 1992. </year>
Reference-contexts: We combine both global and local representations in our method. The approximation starts with a global map in the form of a fast-learning feed-forward network, but as learning proceeds local maps will be built in a tree-like structure where needed. This method we named the nested network method <ref> [5, 6] </ref>. Nested Networks for Robot Control 223 the reach space used in the simulations.
Reference: [6] <author> A. Jansen, P. van der Smagt, and F. Groen. </author> <title> High-precision robot control: The nested network. </title> <editor> In I. Aleksander and J. Taylor, editors, </editor> <booktitle> Artificial Neural Networks 2, </booktitle> <pages> pages 583-586. </pages> <publisher> North-Holland/Elsevier Science Publishers, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: We combine both global and local representations in our method. The approximation starts with a global map in the form of a fast-learning feed-forward network, but as learning proceeds local maps will be built in a tree-like structure where needed. This method we named the nested network method <ref> [5, 6] </ref>. Nested Networks for Robot Control 223 the reach space used in the simulations.
Reference: [7] <author> P. van der Smagt, B. Krose, and F. Groen. </author> <title> Using time-to-contact to guide a robot manipulator. </title> <booktitle> In Proceedings of the 1992 IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 177-182. </pages> <address> Raleigh, N. C., </address> <month> June </month> <year> 1992. </year> <title> Nested Networks for Robot Control 239 </title>
Reference-contexts: Restricting ourselves to 3 DoF we have chosen to keep the camera always looking downwards. The position in the image frame, combined with the observed area versus the `known' area, can be translated in a position of the object relative to the end-effector (cf. <ref> [7] </ref>). Having an ego-centered system we have chosen to control the robot with delta joint values, i.e., a rotation from the current state of the robot. The aim of our system is to get the object in the centre of the camera image at a predefined size.
Reference: [8] <author> D. Psaltis, A. Sideris, and A. Yamamura. </author> <title> A multilayer neural network controller. </title> <journal> Control Systems Magazine, </journal> <volume> 8(2) </volume> <pages> 17-21, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Both these conditions can be observed by the camera. From the joint and camera information input samples to train the control system can be constructed. This is done according to the input adjustment method <ref> [8] </ref>.
Reference: [9] <author> C. Brice and C. Fennema. </author> <title> Scene analysis using regions. </title> <journal> Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 205-226, </pages> <year> 1970. </year>
Reference-contexts: This process can be compared with the first part of the well-known split and merge process as used in image processing. This method used in image processing was first mentioned in <ref> [9] </ref>. On the other hand we want to have a very flexible system being able to adjust itself to changes in the system.
Reference: [10] <author> V. Vysniauskas, F. Groen, and B. Krose. </author> <title> Function approximation with a feedforward network: the optimal number of learning samples and hidden units. </title> <type> Technical report, </type> <institution> Department of Computer Systems, University of Amsterdam, </institution> <address> Amsterdam, Netherlands, </address> <year> 1992. </year>
Reference-contexts: When the error in the approximation by a network is large due to the fact that this network has been trained on too few learning samples, it is useless to perform a split operation; the choice of " depends on the form of the learning error curve <ref> [10] </ref>. The feed-forward networks are trained with conjugate gradient optimisation [11]. 3 Tree destruction When the function from which learning samples are generated is changed considerably, the bins containing the new as well as old learning samples will provide ambiguous learning samples. <p> In most runs we chose five hidden units for each network. There are a few constants in the conjugate gradient learning process which determine the summed squared error reached in the networks. We choose them according to results published in <ref> [11, 10] </ref>. The maximum depth that the tree is allowed to grow should, theoretically, be infinity. However, due to the finiteness of computer memory, a value is chosen higher than the maximum depth the tree (i.e., the deepest network node) would reach in a typical run.
Reference: [11] <author> P. van der Smagt. </author> <title> Minimisation methods for training feed-forward networks. </title> <note> Technical Report UIUC-BI-TB-92-17 (submitted to Neural Networks), </note> <institution> Theoretical Biophysics, University of Illinois at Ur-bana/Champaign, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: The feed-forward networks are trained with conjugate gradient optimisation <ref> [11] </ref>. 3 Tree destruction When the function from which learning samples are generated is changed considerably, the bins containing the new as well as old learning samples will provide ambiguous learning samples. <p> In most runs we chose five hidden units for each network. There are a few constants in the conjugate gradient learning process which determine the summed squared error reached in the networks. We choose them according to results published in <ref> [11, 10] </ref>. The maximum depth that the tree is allowed to grow should, theoretically, be infinity. However, due to the finiteness of computer memory, a value is chosen higher than the maximum depth the tree (i.e., the deepest network node) would reach in a typical run.
Reference: [12] <author> Arjen Jansen. </author> <title> Neural Approaches in the Approximation of the Inverse Kinematics Function: A Comparative Study. </title> <publisher> Universiteit van Amsterdam, Faculteit Computer Systemen, </publisher> <month> April </month> <year> 1992. </year> <note> graduation thesis. </note>
Reference-contexts: At iteration 250, the collapse of the network is clearly visible. Nested Networks for Robot Control 235 neural network after one and two feedback steps <ref> [12] </ref>. The curve has been smoothed with a moving average filter of width 20. show the precision after three feedback steps, as well as how the network grows during learning.
References-found: 12

