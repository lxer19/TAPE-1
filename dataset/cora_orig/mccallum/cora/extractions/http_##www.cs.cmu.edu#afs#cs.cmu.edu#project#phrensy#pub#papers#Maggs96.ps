URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/phrensy/pub/papers/Maggs96.ps
Refering-URL: http://www.cs.cmu.edu/~bmm/Maggs96.html
Root-URL: 
Title: A Critical Look at Three of Parallel Computing's Maxims  
Author: Bruce M. Maggs 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper takes a critical look at the following three maxims. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bailey, E. Barszcz, J. Barton, D. Browning, R. Carter, L. Dagum, R. Fatoohi, S. Fineberg, P. Frederickson, T. Lasinski, R. Schreiber, H. Si-mon, V. Venkatakrishnan, and S. Weeratunga. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report RNR-94-007, </type> <institution> Numerical Aerospace Simulation Facility, NASA Ames Research Center, Mof-fett Field, </institution> <address> CA, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: Manufacturers produced machines that achieved very high peak floating point performance, but this measure was found to be non-predictive because the machines could rarely achieve it. More recently, the performance of these machines has been judged against a set of standard benchmarks, which include the LINPACK and NAS <ref> [1, 23] </ref> benchmarks. The results of the NAS benchmarks for several machines summarized in Table 2. The same data is shown in a different format in Table 3. Here, each ma-chine's performance is given as a fraction of peak floating point performance.
Reference: [2] <author> A. Bar-Noy and S. Kipnis. </author> <title> Designing broadcast ing algorithms in the postal model for message-passing systems. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 13-22, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: In this case, the bandwidth can be expressed as the minimum gap g between successive injections of messages into the network. Three models of computation that are based on latency and gap are the Postal model <ref> [2] </ref>, the Bulk-Synchronous Parallel (BSP) model [27], and the LogP model [5]. In the Postal model, a network is described by a single parameter L, its latency, and it is assumed that the bandwidth of the network is sufficient to support as much traffic as the processors can generate.
Reference: [3] <author> S. Borkar, R. Cohn, G. Cox, S. Gleason, T. Gross, H. T. Kung, M. Lam, B. Moore, C. Peterson, J. Pieper, L. Rankin, P.S. Tseng, J. Sutton, J. Ur-banski, and J Webb. </author> <title> iWarp, an integrated solution to high-speed parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 330-339, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: In the J-Machine, a processor can compose and inject a four word message into the network in four clock cycles [19]. In iWarp, a processor can access a logical channel in two cycles <ref> [3] </ref>. <p> Many papers begin with a similar remark, and there is no denying that wormhole routing has become the routing method of choice in the latest generation of massively parallel computers, appearing in experimental machines such as iWarp <ref> [3] </ref> and the J-Machine [19], and commercial machines such as the Intel Paragon, Cray T3D [12], and Connection Machine CM-5 [17]. Nevertheless, in light of recent analytical discoveries, and based on the benchmark performance of the current generation of parallel machines, the validity of this maxim deserves a hard look.
Reference: [4] <author> R. J. Cole, B. M. Maggs, and R. K. Sitaraman. </author> <title> On the benefit of supporting virtual channels in wormhole routers. </title> <booktitle> In Proceedings of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Cypher et al. [8] showed that there is a wormhole routing algorithm that takes time O (bcd 1=q + (d+ b) log N ) time, for any q log N , where N is the number of nodes in the network. Cole, Maggs,and Sitara-man <ref> [4] </ref> also independently showed that it is possible to route any set of b-bit messages whose paths are edge simple and have congestion c and dilation d in (b + d)c (d log d) 1=q 2 O (log fl (c=d))=q bit-steps. (They did not provide an on-line algorithm, however.) What is <p> As in the case of general networks, however, the performance of wormhole routing algorithms on butterfly networks has a non-linear dependence on q, both in the case of static routing <ref> [4, 8, 11] </ref> and dynamic routing [24]. By making q large enough, the algorithms can be made competitive with store-and-forward algorithms. Early work focused on the case q = 1. <p> They also proved a lower bound of (kb log 1=q N (log log N ) 2=q ) bit steps. Cole, Maggs, and Sitarmanan <ref> [4] </ref> independently discovered a randomized algorithm that routes a k-relation on the inputs and outputs of an N -input butterfly in O (b (k + log N )(log 1=q N ) log log N k) bit-steps.
Reference: [5] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In this case, the bandwidth can be expressed as the minimum gap g between successive injections of messages into the network. Three models of computation that are based on latency and gap are the Postal model [2], the Bulk-Synchronous Parallel (BSP) model [27], and the LogP model <ref> [5] </ref>. In the Postal model, a network is described by a single parameter L, its latency, and it is assumed that the bandwidth of the network is sufficient to support as much traffic as the processors can generate.
Reference: [6] <author> R. Cypher. </author> <title> Minimal, deadlock-free routing in hypercubic and arbitrary networks. </title> <booktitle> In Proceedings of the 7th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 122-129, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: For example, each physical channel of iWarp supports 4 virtual channels, and each physical channel of the J-Machine supports 2 virtual channels [19]. The paper by Dally and Seitz was followed by a large number of papers describing different forms of deadlock free routing for various networks, e.g., <ref> [7, 6, 18, 21] </ref>. 3.1 Rigorous analyses of wormhole routing Recently there have been a number of breakthroughs in analyzing the time required by wormhole routing algorithms. The results are most easily stated for the case of static oblivious routing.
Reference: [7] <author> R. Cypher and L. Gravano. Storage-efficient, </author> <title> deadlock-free, adaptive packet routing algorithms for torus networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 43(12) </volume> <pages> 1376-1385, </pages> <year> 1994. </year>
Reference-contexts: For example, each physical channel of iWarp supports 4 virtual channels, and each physical channel of the J-Machine supports 2 virtual channels [19]. The paper by Dally and Seitz was followed by a large number of papers describing different forms of deadlock free routing for various networks, e.g., <ref> [7, 6, 18, 21] </ref>. 3.1 Rigorous analyses of wormhole routing Recently there have been a number of breakthroughs in analyzing the time required by wormhole routing algorithms. The results are most easily stated for the case of static oblivious routing.
Reference: [8] <editor> R. Cypher, F. Meyer auf der Heide, C. Schei deler, and B. Vocking. </editor> <title> Universal algorithms for store-and-forward and wormhole routing. </title> <booktitle> In Proceedings of the 28th Annual ACM Symposium on the Theory of Computing, </booktitle> <month> May </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Note that the time for the optimal store-and-forward algorithm is at most O (b (c + d)), which can be much smaller than bcd when c and d are roughly equal. Cypher et al. <ref> [8] </ref> showed that there is a wormhole routing algorithm that takes time O (bcd 1=q + (d+ b) log N ) time, for any q log N , where N is the number of nodes in the network. <p> As in the case of general networks, however, the performance of wormhole routing algorithms on butterfly networks has a non-linear dependence on q, both in the case of static routing <ref> [4, 8, 11] </ref> and dynamic routing [24]. By making q large enough, the algorithms can be made competitive with store-and-forward algorithms. Early work focused on the case q = 1. <p> Next, Cypher et al. <ref> [8] </ref> found an algorithm for routing k worms from each input of an N -input butterfly to randomly-chosen outputs in O (kb log 1=q N + log (kN ) log N ) time.
Reference: [9] <author> W. Dally and C. Seitz. </author> <title> Deadlock free message routing in multiprocessor interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):547-553, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: In addition to reduced latency, wormhole routing also has the advantage that it can be implemented with small, fast switches. Wormhole routing owes much of its recent popularity to an influential paper by Dally and Seitz <ref> [9] </ref>, which introduced the method. Much of the paper by Dally and Seitz is devoted to the design of wormhole routing algorithms that avoid deadlock.
Reference: [10] <author> S. Felperin, P. Raghavan, and E. Upfal. </author> <title> A the ory of wormhole routing in parallel computers. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 563-572, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: For the interesting case of b = O (log N ) and k = log N , the time is O (log 3 N ) bit steps. Felperin et al. <ref> [10] </ref> independently discovered an O (log 4 N ) bit-step algorithm for solving a random problem for the case b = O (log N ) and k = log N , and then Ranade et al. [22] discovered an O (log 3 N log log N ) bit-step algorithm.
Reference: [11] <author> R. R. Koch. </author> <title> Increasing the size of a network by a constant factor can increase performance by more than a constant factor. </title> <booktitle> In Proceedings of the 29th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 221-230. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1988. </year>
Reference-contexts: In particular, an increase in q results in superlinear speedup. This effect was first observed by Koch <ref> [11] </ref> in the context of circuit-switching on the butterfly. In addition to these upper bounds, Cole, Maggs, and Sitaraman also proved a nearly matching lower bound. <p> As in the case of general networks, however, the performance of wormhole routing algorithms on butterfly networks has a non-linear dependence on q, both in the case of static routing <ref> [4, 8, 11] </ref> and dynamic routing [24]. By making q large enough, the algorithms can be made competitive with store-and-forward algorithms. Early work focused on the case q = 1.
Reference: [12] <author> R. K. Koeninger, M. Furtney, and M. Walker. </author> <title> A shared MPP from Cray research. </title> <journal> Digital Technical Journal, </journal> <volume> 6(2) </volume> <pages> 8-21, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: begin with a similar remark, and there is no denying that wormhole routing has become the routing method of choice in the latest generation of massively parallel computers, appearing in experimental machines such as iWarp [3] and the J-Machine [19], and commercial machines such as the Intel Paragon, Cray T3D <ref> [12] </ref>, and Connection Machine CM-5 [17]. Nevertheless, in light of recent analytical discoveries, and based on the benchmark performance of the current generation of parallel machines, the validity of this maxim deserves a hard look.
Reference: [13] <author> C. P. Kruskal and M. Snir. </author> <title> The performance of multistage interconnection networks for multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(12):1091-1098, </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: By making q large enough, the algorithms can be made competitive with store-and-forward algorithms. Early work focused on the case q = 1. Kruskal and Snir <ref> [13] </ref> showed that if each input in an N -input butterfly node sends a message to a randomly-chosen output, then the expected number of worms that reach their destinations without ever being delayed is fi (N= log N ).
Reference: [14] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algo rithms and Architectures: Arrays * Trees * Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Kruskal and Snir [13] showed that if each input in an N -input butterfly node sends a message to a randomly-chosen output, then the expected number of worms that reach their destinations without ever being delayed is fi (N= log N ). In Problem 3.285 of <ref> [14] </ref>, Leighton describes an algorithm for solving a random routing problem in which each input has one b-bit worm to send. The algorithm runs in O ((b + log N ) log N ) bit steps. <p> This lower bound is nearly tight. Note that several known store-and-forward routing algorithms run in O (log 2 N ) bit steps (see Leighton <ref> [14] </ref>). Hence, the store-and-forward algorithms are faster. The switches executing the store-and-forward algorithms, however, must each have the capacity to queue an entire message, i.e., O (log N ) bits. For q &gt; 1, a non-linear dependence on q has been observed.
Reference: [15] <author> F. T. Leighton, B. M. Maggs, A. G. Ranade, and S. B. Rao. </author> <title> Randomized routing and sorting on fixed-connection networks. </title> <journal> Journal of Algorithms, </journal> <volume> 17(1) </volume> <pages> 157-205, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The proof used the Lovasz Local Lemma and was nonconstructive. For the special case of leveled networks, Leighton, Maggs, Ranade, and Rao <ref> [15] </ref> presented a simple randomized on-line store-and-forward algorithm. In a leveled network with depth L, each node is labeled with an integer between 0 and L (its level), and each edge with its tail on level i, 0 i &lt; L, has its head on level i + 1. <p> In a leveled network with depth L, each node is labeled with an integer between 0 and L (its level), and each edge with its tail on level i, 0 i &lt; L, has its head on level i + 1. The algorithm in <ref> [15] </ref> routes any set of N messages in a leveled network with depth L in O (c+L+log N ) message steps. Translated to bit steps, the time is O (bc + bL + b log N ), which is optimal for c L + log N .
Reference: [16] <author> F. T. Leighton, B. M. Maggs, and S. B. Rao. </author> <title> Packet routing and job-shop scheduling in O(congestion + dilation) steps. </title> <journal> Combinatorica, </journal> <volume> 14(2) </volume> <pages> 167-180, </pages> <year> 1994. </year>
Reference-contexts: Finally, the bit-length, b, is the number of bits in each worm. The idea of decoupling the path selection process from the scheduling process, and then analyzing the scheduling process alone, was first used by Leighton, Maggs, and Rao <ref> [16] </ref> in the context of store-and-forward routing.
Reference: [17] <author> C. E. Leiserson, Z. S. Abuhamdeh, D. C. Dou glas, C. R. Feynman, M. N. Ganmukhi, J. V. Jill, W. D. Hillis, B. C. Kuszmaul, M. A. St. Pierre, D. S. Wells, M. C. Wong, S.-W. Yang, and R. Zak. </author> <title> The network architecture of the connection machine CM-5. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 272-285, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: and there is no denying that wormhole routing has become the routing method of choice in the latest generation of massively parallel computers, appearing in experimental machines such as iWarp [3] and the J-Machine [19], and commercial machines such as the Intel Paragon, Cray T3D [12], and Connection Machine CM-5 <ref> [17] </ref>. Nevertheless, in light of recent analytical discoveries, and based on the benchmark performance of the current generation of parallel machines, the validity of this maxim deserves a hard look.
Reference: [18] <author> P. M. Merlin and P. J. Schweitzer. </author> <title> Dead lock avoidance in store-and-forward networks. 1: Store-and-forward deadlock. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 28 </volume> <pages> 345-354, </pages> <year> 1980. </year>
Reference-contexts: For example, each physical channel of iWarp supports 4 virtual channels, and each physical channel of the J-Machine supports 2 virtual channels [19]. The paper by Dally and Seitz was followed by a large number of papers describing different forms of deadlock free routing for various networks, e.g., <ref> [7, 6, 18, 21] </ref>. 3.1 Rigorous analyses of wormhole routing Recently there have been a number of breakthroughs in analyzing the time required by wormhole routing algorithms. The results are most easily stated for the case of static oblivious routing.
Reference: [19] <author> M. D. Noakes, D. A. Wallach, and W. J. Dally. </author> <title> The J-Machine multicomputer: an architectural evaluation. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 224-235, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In the Cray C916, for example, a processor can inject up to 8 64-bit words into the network in each cycle [20]. In the J-Machine, a processor can compose and inject a four word message into the network in four clock cycles <ref> [19] </ref>. In iWarp, a processor can access a logical channel in two cycles [3]. <p> Many papers begin with a similar remark, and there is no denying that wormhole routing has become the routing method of choice in the latest generation of massively parallel computers, appearing in experimental machines such as iWarp [3] and the J-Machine <ref> [19] </ref>, and commercial machines such as the Intel Paragon, Cray T3D [12], and Connection Machine CM-5 [17]. Nevertheless, in light of recent analytical discoveries, and based on the benchmark performance of the current generation of parallel machines, the validity of this maxim deserves a hard look. <p> This solution has also been implemented in hardware. For example, each physical channel of iWarp supports 4 virtual channels, and each physical channel of the J-Machine supports 2 virtual channels <ref> [19] </ref>.
Reference: [20] <author> W. Oed. </author> <title> Cray Y-MP C90: system features and early benchmark results. </title> <journal> Parallel Computing, </journal> <volume> 18(8) </volume> <pages> 947-954, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Overhead, however, should not be viewed as an inherent or unavoidable penalty for interprocessor communication. In particular, the overhead on the parallel machines with custom processors is negligible. In the Cray C916, for example, a processor can inject up to 8 64-bit words into the network in each cycle <ref> [20] </ref>. In the J-Machine, a processor can compose and inject a four word message into the network in four clock cycles [19]. In iWarp, a processor can access a logical channel in two cycles [3].
Reference: [21] <author> G. D. Pifarre, L. Gravano, S. A. Felperin, and J. L. C. Sanz. </author> <title> Fully-adaptive minimal deadlock-free packet routing in hypercubes, meshes, and other networks. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 278-290, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: For example, each physical channel of iWarp supports 4 virtual channels, and each physical channel of the J-Machine supports 2 virtual channels [19]. The paper by Dally and Seitz was followed by a large number of papers describing different forms of deadlock free routing for various networks, e.g., <ref> [7, 6, 18, 21] </ref>. 3.1 Rigorous analyses of wormhole routing Recently there have been a number of breakthroughs in analyzing the time required by wormhole routing algorithms. The results are most easily stated for the case of static oblivious routing.
Reference: [22] <author> A. Ranade, S. Schleimer, and D. S. Wilkerson. </author> <title> Nearly tight bounds for wormhole routing. </title> <booktitle> In Proceedings of the 35th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1994. </year>
Reference-contexts: Translated to bit steps, the time is O (bc + bL + b log N ), which is optimal for c L + log N . Ranade, Schleimer, and Wilkerson <ref> [22] </ref> were the first to state non-trivial wormhole routing results in terms of these four parameters. They showed that on any network, any set of b-bit messages whose paths have congestion c and dilation d can be routed in O (bcd) bit steps. <p> Felperin et al. [10] independently discovered an O (log 4 N ) bit-step algorithm for solving a random problem for the case b = O (log N ) and k = log N , and then Ranade et al. <ref> [22] </ref> discovered an O (log 3 N log log N ) bit-step algorithm.
Reference: [23] <author> S. Saini and D. H. Bailey. </author> <title> NAS parallel bench mark results 12-95. </title> <type> Technical Report Report NAS-95-021, </type> <institution> Numerical Aerospace Simulation Facility, NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Manufacturers produced machines that achieved very high peak floating point performance, but this measure was found to be non-predictive because the machines could rarely achieve it. More recently, the performance of these machines has been judged against a set of standard benchmarks, which include the LINPACK and NAS <ref> [1, 23] </ref> benchmarks. The results of the NAS benchmarks for several machines summarized in Table 2. The same data is shown in a different format in Table 3. Here, each ma-chine's performance is given as a fraction of peak floating point performance.
Reference: [24] <author> C. Scheideler and B. Vocking. </author> <title> Universal contin uous routing strategies. </title> <booktitle> In Proceedings of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: As in the case of general networks, however, the performance of wormhole routing algorithms on butterfly networks has a non-linear dependence on q, both in the case of static routing [4, 8, 11] and dynamic routing <ref> [24] </ref>. By making q large enough, the algorithms can be made competitive with store-and-forward algorithms. Early work focused on the case q = 1. <p> Cole et al. also proved an (bk (minfb; log N g) 1=q = log log N ) lower bound that holds for a broad class of algorithms. Scheideler and Vocking <ref> [24] </ref> proved that the non-linear dependence on q holds for the case of dynamic wormhole routing on butterflies as well.
Reference: [25] <author> B. J. Smith. </author> <title> Architecture and applications of the HEP multiprocessor computer system. </title> <booktitle> In Real-Time Signal Processing IV, </booktitle> <pages> pages 241-248, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: These techniques include assigning a lot of work to each processor, emulating many virtual processors on each physical processors, executing multiple independent threads (with rapid context switching) <ref> [25] </ref> on each processor, performing vector-accesses (gather and scatter), using split-phase operations, prefetching instructions and data, and performing redundant computation. Gap Large gap is more difficult to overcome.
Reference: [26] <author> L. G. Valiant. </author> <title> A scheme for fast parallel communication. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(2) </volume> <pages> 350-361, </pages> <month> May </month> <year> 1982. </year>
Reference-contexts: The algorithm runs in O ((b + log N ) log N ) bit steps. In Problem 3.286, he shows that the algorithm can be converted to one that routes any permutation using Valiant's idea <ref> [26] </ref> of first routing to random intermediate destinations. For the interesting case of b = O (log N ), the time is O (log 2 N ) bit steps.
Reference: [27] <author> L. G. Valiant. </author> <title> A bridging model for paral lel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: In this case, the bandwidth can be expressed as the minimum gap g between successive injections of messages into the network. Three models of computation that are based on latency and gap are the Postal model [2], the Bulk-Synchronous Parallel (BSP) model <ref> [27] </ref>, and the LogP model [5]. In the Postal model, a network is described by a single parameter L, its latency, and it is assumed that the bandwidth of the network is sufficient to support as much traffic as the processors can generate. <p> Latency Of the three parameters, large latency appears to be the easiest to cope with. There are a variety of automatic techniques for hiding latency with minimal hardware support provided that the amount of excess parallelism, called slackness <ref> [27] </ref>, is sufficiently large.
References-found: 27

