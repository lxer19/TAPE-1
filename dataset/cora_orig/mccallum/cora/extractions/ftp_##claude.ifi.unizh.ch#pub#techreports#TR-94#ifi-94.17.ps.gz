URL: ftp://claude.ifi.unizh.ch/pub/techreports/TR-94/ifi-94.17.ps.gz
Refering-URL: http://www.cs.gatech.edu/people/home/jmankoff/collab-immers-env.html
Root-URL: 
Title: Specifying Logic Programs in Controlled Natural Language  
Author: Norbert E. Fuchs, Hubert F. Hofmann, Rolf Schwitter 
Affiliation: Department of Computer Science, University of Zurich  
Abstract: TECHNICAL REPORT 94.17, DEPARTMENT OF COMPUTER SCIENCE, UNIVERSITY OF ZURICH, NOVEMBER 1994 
Abstract-found: 1
Intro-found: 1
Reference: [AECMA 85] <author> AECMA Document: PSC-85-16598, </author> <title> AECMA/AIA Simplified English, A Guide for the Preparation of Aircraft Maintenance Documentation in the International Aerospace Maintenance Language, </title> <type> BDC Technical Services, Slack Lane, Derby, </type> <year> 1985. </year>
Reference-contexts: In aerospace industry a notation was developed that relies on using natural language in a controlled way for the preparation of aircraft maintenance documentation <ref> [AECMA 85] </ref>. Epstein used syntactically restricted natural language as data base query language [Epstein 85]. Another well-known example for controlled language is legislation.
Reference: [Anderson et al. 76] <editor> R.C. Anderson, J.W. Pichert, E.T. Goetz et al., </editor> <title> Instantiation of General Terms, </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> vol. 15, </volume> <pages> pp. 667-679, </pages> <year> 1976 </year>
Reference-contexts: For example, there is evidence that people remember a 25 passage differently according to the goal (s) they want to achieve. This evidence supports the notion that the motivation for processing a sentence can affect the way it is processed <ref> [Anderson et al. 76, Barsalou 82] </ref>. From the point of view of a NLP system, a rich and extensive conceptual lexicon can offer improvements in its robustness of coverage, especially in ambiguity resolution during parsing.
Reference: [Ayuso et al. 87] <author> D.M. Ayuso, V. Shaked, R.M. Weischedel, </author> <title> An Environment for Acquiring Semantic Information, </title> <booktitle> 25 (24)th Annual Meeting of the ACL, Stanford, </booktitle> <pages> pp. 32-40, </pages> <year> 1987 </year>
Reference-contexts: Moreover, several text understanding systems have incorporated conceptual knowledge, e.g. PETRARCA [Velardi et al. 89], RINA [Jacobs and Zernik 88], GENESIS [Mooney and DeJong 85]. Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ <ref> [Ayuso et al. 87] </ref>, SCISOR [Rau et al. 89]. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK [Thompson & Thompson 85].
Reference: [Ballard & Stumberger 88] <author> W. Ballard, D.E. Stumberger, </author> <title> Semantic Acquisition in TELI: A Transportable, User-Customized Natural Language Processor, </title> <booktitle> 25th Annual Meeting of the ACL, </booktitle> <address> New York, </address> <pages> pp. 20-29, </pages> <year> 1988 </year>
Reference-contexts: Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ [Ayuso et al. 87], SCISOR [Rau et al. 89]. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI <ref> [Ballard & Stumberger 88] </ref>, TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK [Thompson & Thompson 85]. Other systems are the ACME system [Kersten et al. 86] or SECSI from Bouzeghoub [Bouzeghoub & Metais 86].
Reference: [Balzer et al. 78] <author> R. Balzer, N. Goldman, D. Wile, </author> <title> Informality in Program Specifications, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 4, no. 2, </volume> <pages> pp. 94-103, </pages> <year> 1978 </year>
Reference-contexts: The availability of such a computer-based tool is highly desirable because it simplifies the creation of a formal specification while increasing the reliability of the formulation process. Moreover, it improves the maintainability of the formal specification and expands the base of potential users <ref> [Balzer et al. 78] </ref>. The question of feasibility the paramount issue rests clearly on the ability to correctly interpret an informal specification (i.e. the problem statement).
Reference: [Barsalou 82] <author> L.W. Barsalou, </author> <title> Context-Independent and Context-Dependent Information in Concepts, </title> <journal> Memory and Cognition, </journal> <volume> no. 10, </volume> <pages> pp. 82-93, </pages> <year> 1982 </year>
Reference-contexts: More specifically, it will be assumed that the concept used to represent a category on a 23 particular occasion contains (1) information that provides relevant expectations about the category in that context, and (2) information that provides relevant expectations when interacting with the category in most contexts <ref> [Barsalou 82, Medin & Smith 84, Lakoff 87] </ref>. When dealing with a concept lexicon we are especially interested in the features of a concept, its instances in the application domain, and its links to other concepts. <p> For example, there is evidence that people remember a 25 passage differently according to the goal (s) they want to achieve. This evidence supports the notion that the motivation for processing a sentence can affect the way it is processed <ref> [Anderson et al. 76, Barsalou 82] </ref>. From the point of view of a NLP system, a rich and extensive conceptual lexicon can offer improvements in its robustness of coverage, especially in ambiguity resolution during parsing.
Reference: [Bierwisch & Lang 87] <author> M. Bierwisch, E. Lang, </author> <title> Dimensional Adjectives: Grammatical Structure and Conceptual Interpretation, </title> <address> New York, </address> <publisher> Springer, </publisher> <year> 1987 </year>
Reference-contexts: These features are often referred to as the extension of an NL statement. In linguistics, this view has emerged in the componential analysis of Katz and Fodor [Katz & Fodor 63]. Leech and Bierwisch continue this line of research <ref> [Bierwisch & Lang 87] </ref>. This, indeed, is the typical form of the classical view in linguistics: the meaning of a word is essentially decomposable into a set of features. The features that represent the meaning of a word are just those which distinguish it from others in the relevant domain.
Reference: [Brger & Rosenzweig 94] <author> E. Brger, D. Rosenzweig, </author> <title> A Mathematical Definition of Full Prolog, </title> <journal> Science of Computer Programming, </journal> <note> 1994 (to appear) </note>
Reference-contexts: By making "true statements about the intended domain of discourse" [Kramer & Mylopoulos 92] and "expressing basic concepts directly, without encoding, taking the objects of the language [of the domain of discourse] as abstract entities" <ref> [Brger & Rosenzweig 94] </ref>, applicationspecific specification languages are in the original sense of the word declarative, and have all the practical advantages of declarative programming [Lloyd 94]. Specifically, they are understood by application specialists. <p> We plan to combine the Explore system with the current system to provide users with graphical and textual specification notations. Another problem are algorithms. Natural language is not suited to express algorithms concisely. Evolving algebras, however, have been shown to be optimal for this task <ref> [Gurevich 91, Brger & Rosenzweig 94] </ref>. Evolving algebras use if-then rules to express the dynamic behaviour of systems. As it happens these rules resemble very much the if-then sentences of our controlled natural language.
Reference: [Bouzeghoub & Metais 86] <author> M. Bouzeghoub, E. Metais, SECSI: </author> <title> An Expert System Approach for Database Design, </title> <booktitle> IFIP Information Processing '86, </booktitle> <publisher> North-Holland, </publisher> <pages> pp. 251-257, </pages> <year> 1986 </year>
Reference-contexts: Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK [Thompson & Thompson 85]. Other systems are the ACME system [Kersten et al. 86] or SECSI from Bouzeghoub <ref> [Bouzeghoub & Metais 86] </ref>. While both have natural language text as input, ACME derives an extended Entity-Relationship model and SECSI generates semantic networks describing the application domain.
Reference: [Brachman 79] <author> R.J. Brachman, </author> <title> On the Epistemelogical Status of Semantic Networks, </title> <editor> in: N. Findler (eds.), </editor> <title> Associative Networks: Representation and Use of Knowledge by Computers, </title> <address> New York, </address> <publisher> Academic Press, </publisher> <year> 1979 </year>
Reference-contexts: what actor has which objects, or what directions does a particular actor have? In contrast to this primitive-based view, a relation-based view of word meaning claims that there is no need for decomposition into primitives if words (and their concepts) are associated through a network of explicitly defined links (e.g. <ref> [Quillian 68, Brachman 79, Lyons 81] </ref>). Sometimes referred to as meaning postulate, these links establish any inference between lexems as an explicit part of a conceptual network.
Reference: [Brodie et al. 84] <editor> M. Brodie, J. Mylopoulos, J. Schmidt, </editor> <booktitle> On Conceptual Modeling: Perspectives from Artificial Intelligence, Data Bases and Programming Languages, </booktitle> <address> New York, </address> <publisher> Springer, </publisher> <year> 1984 </year>
Reference-contexts: Various experiments to construct such tools have been carried out in recent years, especially in restricted domains characterised by a typical sublanguage (e.g. <ref> [Brodie et al. 84, Mylopoulos 86] </ref>). Research in the field is furthermore encouraged by the increasing availability of large quantities of machine-readable texts and lexica. Nevertheless, the results are far from being satisfactory.
Reference: [Brown 94] <author> D. W. Brown, </author> <title> A Natural Language Querying System Based on Discourse Representation Theory and Incorporating Event Semantics, </title> <institution> Research Report AI-1994-03, Artificial Intelligence Center, University of Georgia, </institution> <year> 1994 </year>
Reference-contexts: To specify time explicitly, e.g. in the form of sequences of events, requires first an extension of the controlled natural language by temporal constructs like before, after and when, second an already suggested event-oriented extension of DRT <ref> [Brown 94] </ref>. 7.2 Complementary Specification Notations Though natural language even in a controlled form is a universal specification notation, we believe that it is not in each case the optimal notation. A case in point are graphical user interfaces which are much better specified directly with a graphical editor.
Reference: [Capindale & Crawford 89] <author> R. A. Capindale, R. G. Crawford, </author> <title> Using a natural language interface with casual users, </title> <journal> International Journal Man-Machine Studies, </journal> <volume> 32, </volume> <pages> pp. 341-362, </pages> <year> 1989 </year>
Reference-contexts: Habitability i.e. the ability to construct sentences in controlled natural language, and to avoid constructions that fall outside the bounds of the language seems to be achievable, particularly when the system gives feedback to its users <ref> [Epstein 85, Capindale & Crawford 89] </ref>. However, we are convinced that employing controlled natural language for specifications will be only successful when users are trained and willing to strive for clear writing. Here we present some short guidelines patterned after standard prescriptions for good style [e.g.
Reference: [Covington et al. 88] <author> M. A. Covington, D. Nute, N. Schmitz, D. Goodman, </author> <title> From English to Prolog via Discourse Representation Theory, Research Report 01-0024, </title> <booktitle> Artificial Intelligence Programs, </booktitle> <institution> University of Georgia, </institution> <year> 1988 </year>
Reference-contexts: First, Prolog rules cannot have two predicates in its consequent, i.e. rules of the form a,b :- c,d. are not permitted. To deal with this problem, Covington and his collaborators introduce a special operator (::-) as intermediate representation for rules with more than one consequent <ref> [Covington et al. 88] </ref>. Now we can write a,b ::- c,d. Since this rule cannot be asserted directly into the knowledge base it is split up into several Prolog rules by distributing the consequents: a :- c,d.
Reference: [Covington 94 a] <author> M. A. Covington. GULP 3.1: </author> <title> An Extension of Prolog for Unification Based Grammar, </title> <institution> Research Report AI-1994-06, Artificial Intelligence Center, University of Georgia, </institution> <year> 1994 </year>
Reference: [Covington 94 b] <author> M. A. Covington. </author> <title> Natural Language Processing for Prolog Programmers, </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1994 </year>
Reference: [Damerau 85] <author> F. Damerau, </author> <title> Problems and Some Solutions in Customization of Natural Language Database Front Ends, </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 165-184, </pages> <year> 1985 </year>
Reference-contexts: Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ [Ayuso et al. 87], SCISOR [Rau et al. 89]. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA <ref> [Damerau 85] </ref> and ASK [Thompson & Thompson 85]. Other systems are the ACME system [Kersten et al. 86] or SECSI from Bouzeghoub [Bouzeghoub & Metais 86]. While both have natural language text as input, ACME derives an extended Entity-Relationship model and SECSI generates semantic networks describing the application domain.
Reference: [Diederich et al. 86] <author> J. Diederich, M. May, I. Ruhmann, </author> <title> KRITON A Knowledge Acquisition Tool for Expert Systems, AAAI Workshop on Knowledge Acquisition for Knowledge Acquisition for Knowledge-Based System, </title> <address> Banff, </address> <year> 1986 </year> <month> 37 </month>
Reference-contexts: Extracting concepts from given texts has been a very early research topic in logic programming [Kowalski 79]. Research efforts in this vein lead, for example, to methods for incremental text analysis implemented in systems like KRITON <ref> [Diederich et al. 86] </ref> and KNACK [Klinker et al. 86]. Moreover, several text understanding systems have incorporated conceptual knowledge, e.g. PETRARCA [Velardi et al. 89], RINA [Jacobs and Zernik 88], GENESIS [Mooney and DeJong 85]. Natural language processing has been used in building of knowledge-based systems, e.g.
Reference: [Drre 91] <author> J. Drre. </author> <title> The Language of STUF, </title> <editor> in: O. Herzog, C.-R. Rollinger (eds.): </editor> <booktitle> Text Understanding in LILOG: Integrating Computational Linguistics and Artificial Intelligence, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, </address> <pages> pp. 39-50, </pages> <year> 1991 </year>
Reference: [Epstein 85] <author> S. S. Epstein, </author> <title> Transportable Natural Language Processing Through Simplicity the PRE System, </title> <journal> ACM Transactions on Office Automation Systems, </journal> <volume> 3(2), </volume> <pages> pp. 107-120, </pages> <year> 1985 </year>
Reference-contexts: In aerospace industry a notation was developed that relies on using natural language in a controlled way for the preparation of aircraft maintenance documentation [AECMA 85]. Epstein used syntactically restricted natural language as data base query language <ref> [Epstein 85] </ref>. Another well-known example for controlled language is legislation. This case is especially relevant for our approach since it was shown that the language of legislation has many similarities with the language of logic programming, and that statutes can easily be translated into Prolog clauses [Kowalski 90, Kowalski 92]. <p> Habitability i.e. the ability to construct sentences in controlled natural language, and to avoid constructions that fall outside the bounds of the language seems to be achievable, particularly when the system gives feedback to its users <ref> [Epstein 85, Capindale & Crawford 89] </ref>. However, we are convinced that employing controlled natural language for specifications will be only successful when users are trained and willing to strive for clear writing. Here we present some short guidelines patterned after standard prescriptions for good style [e.g.
Reference: [Fromherz 93] <author> M. P. J. Fromherz, </author> <title> A Methodology for Executable Specifications Combining Logic Programming, ObjectOrientation and Multiple Views, </title> <institution> University of Zurich, Computer Science Dept., </institution> <type> Ph.D. thesis, </type> <year> 1993 </year>
Reference-contexts: A case in point are graphical user interfaces which are much better specified directly with a graphical editor. The Explore system <ref> [Fromherz 93] </ref> provides graphical editors for the specification of both finite state machines and window-oriented user-interfaces. We plan to combine the Explore system with the current system to provide users with graphical and textual specification notations. Another problem are algorithms. Natural language is not suited to express algorithms concisely.
Reference: [Fuchs & Fromherz 94] <author> N. E. Fuchs, M. P. J. Fromherz, </author> <title> Transformational Development of Logic Programs from Executable Specifications Schema-Based Visual and Textual Composition of Logic Programs, </title> <editor> in C. Beckstein, U. Geske (eds.), </editor> <title> Entwicklung, Test und Wartung deklarativer KIProgramme, GMD Studien Nr. </title> <type> 238, </type> <institution> Gesellschaft fr Informatik und Datenverarbeitung, </institution> <year> 1994 </year>
Reference-contexts: Specifically, they are understood by application specialists. In a previous phase of our project we have shown that graphical and textual views of logic programs can be considered as applicationspecific specification languages <ref> [Fuchs & Fromherz 94] </ref>. Each view has an associated editor, and between a program and its views there is an automatic bidirectional mapping. Both these features lead to the following important consequences.
Reference: [Gazdar et al. 85] <author> G. Gazdar, E. Klein, G. Pullum, I. A. Sag, </author> <title> Generalized Phrase Structure Grammar, </title> <publisher> Blackwell, Oxford, </publisher> <year> 1985 </year>
Reference: [Gazdar & Mellish 89] <author> G. Gazdar, Chris Mellish, </author> <title> Natural Language Processing in Prolog, An Introduction to Computational Linguistics, </title> <publisher> Wokingham, Addison-Wesley, </publisher> <year> 1989 </year>
Reference-contexts: Second, UBGs use context-free grammar rules in which nonterminal symbols are augmented by sets of features. A careful addition of features increases the power of the 7 grammar and results in a class of languages often described as indexed grammars <ref> [Gazdar & Mellish 89] </ref>. Third, we want machines to be able to understand and employ the formalism in realistic amounts of time.
Reference: [Glckner et al. 94] <author> J. Glckner, A. Grieszl, M. Mller, M. Ronthaler, TabVer: </author> <title> A Case Study in Table Verbalization, </title> <editor> in: B. Nebel, L. Dreschler-Fischer (eds.), </editor> <booktitle> Proceedings of KI-94: Advances in Artificial Intelligence, </booktitle> <address> Saarbrcken, </address> <publisher> Springer-Verlag, </publisher> <pages> pp. 94-105, </pages> <year> 1994 </year>
Reference-contexts: To avoid the difficulties of full natural language generation we will follow an approach used in the TabVer project <ref> [Glckner et al. 94] </ref>. In this approach text is generated with the help of predefined templates containing fixed phrases and place holders for variable phrases. During text generation an appropriate template is selected and its variable parts replaced by the pertinent phrases. In the TabVer project the templates are domainspecific.
Reference: [Grimshaw 90] <author> J. Grimshaw, </author> <title> Argument Structure, </title> <publisher> Cambridge, MIT Press, </publisher> <year> 1990 </year>
Reference: [Grosz et al. 87] <author> B.J. Grosz, D.E. Appelt, P.M. Appelt et al., </author> <title> TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces, </title> <journal> Artificial Intelligence, </journal> <volume> vol. 33, </volume> <pages> pp. 172-243, </pages> <year> 1987 </year>
Reference-contexts: Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ [Ayuso et al. 87], SCISOR [Rau et al. 89]. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM <ref> [Grosz et al. 87] </ref>, TQA [Damerau 85] and ASK [Thompson & Thompson 85]. Other systems are the ACME system [Kersten et al. 86] or SECSI from Bouzeghoub [Bouzeghoub & Metais 86].
Reference: [Gurevich 91] <author> Y. Gurevich, </author> <title> Evolving Algebras: An Attempt to Discover Semantics, </title> <journal> Bull. EATCS, </journal> <volume> 43, </volume> <month> February </month> <year> 1991, </year> <pages> pp. 264 - 284, </pages> <year> 1991 </year>
Reference-contexts: We plan to combine the Explore system with the current system to provide users with graphical and textual specification notations. Another problem are algorithms. Natural language is not suited to express algorithms concisely. Evolving algebras, however, have been shown to be optimal for this task <ref> [Gurevich 91, Brger & Rosenzweig 94] </ref>. Evolving algebras use if-then rules to express the dynamic behaviour of systems. As it happens these rules resemble very much the if-then sentences of our controlled natural language.
Reference: [Hoare 87] <author> C. A. R. Hoare, </author> <title> An overview of some formal methods for program design, </title> <editor> in: C. A. R. Hoare, C. B. Jones, </editor> <booktitle> Essays in Computing Science, </booktitle> <publisher> Prentice Hall, </publisher> <pages> pp. 371-387, </pages> <year> 1987 </year>
Reference-contexts: Furthermore, we demand that specifications be formal. The derivation of formal specifications from informal requirements is difficult, and known to be crucial for the subsequent software development process. The specification process itself cannot be formalised, neither are there formal methods to validate the specifications with respect to the requirements <ref> [Hoare 87] </ref>. Nevertheless, the process can be made easier by the choice of a specification language that allows us to express the concepts of the application domain concisely and directly, and to convince ourselves of the adequacy of the specification without undue difficulty.
Reference: [Hofmann 93] <author> H.F. Hofmann, </author> <title> Requirements Engineering: A Survey of Methods and Tools, </title> <type> TR 93.05, </type> <institution> Department of Computer Science, University of Zurich, </institution> <year> 1993 </year>
Reference-contexts: Thus, their considerations in lexical development is essential. Adopting a rich and expressive lexicon of domain concepts has a number of benefits. Such a lexicon helps, for example, to take into account different viewpoints, which are an important issue in requirements engineering and in software development in general <ref> [Hofmann 93] </ref>. The immediate understanding of a lexical item is often restricted to simple items. For most items, however, their understanding requires the exploration of their conceptual dependencies (e.g. usage context) in order to grasp their meaning.
Reference: [Jacobs & Zernik 88] <author> P. Jacobs, U. Zernik, </author> <title> Acquiring Lexical Knowledge from Text: A Case Study, </title> <booktitle> 7th National Conference on Artificial Intelligence, </booktitle> <address> St. Paul, </address> <publisher> Minnesota, </publisher> <pages> pp. 739-744, </pages> <year> 1988 </year>
Reference: [Kamp 81] <author> H. Kamp. </author> <title> A theory of truth and semantic representation, </title> <editor> in: J. A. G. Groenendijk, T. M. V. Janssen, M. B. J. Stokhof (eds.): </editor> <title> Formal Methods in the Study of Language, Mathematical Center Tract 135, </title> <publisher> Amsterdam, </publisher> <pages> pp. 277-322, </pages> <year> 1981 </year>
Reference-contexts: DRT is a method for representing a multisentential natural language discourse in a single logical unit called a discourse representation structure (DRS) <ref> [Kamp 81, Kamp & Reyle 93] </ref>. DRT differs from the standard formal semantic account in giving up the restriction to the treatment of isolated sentences. It has been recognised that aspects such as pronominal reference, tense and propositional attitudes cannot be successfully handled without taking the preceding discourse into consideration.
Reference: [Kamp & Reyle 93] <author> H. Kamp, U. Reyle, </author> <title> From Discourse to Logic, Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, </address> <year> 1993 </year>
Reference-contexts: DRT is a method for representing a multisentential natural language discourse in a single logical unit called a discourse representation structure (DRS) <ref> [Kamp 81, Kamp & Reyle 93] </ref>. DRT differs from the standard formal semantic account in giving up the restriction to the treatment of isolated sentences. It has been recognised that aspects such as pronominal reference, tense and propositional attitudes cannot be successfully handled without taking the preceding discourse into consideration. <p> Kamp and Reyle propose methods to deal with disjunction, conjunction, plural, tense and aspect <ref> [Kamp & Reyle 93] </ref>. 5.4 Ways to investigate a DRS It is important to realise that a DRS can be investigated in several different ways.
Reference: [Kaplan & Bresnan 82] <author> R. M. Kaplan, J. Bresnan. </author> <title> Lexical-Functional Grammar: A Formal System for Grammatical Representation, </title> <editor> in: J. Bresnan (ed.): </editor> <title> The Mental Representation of Grammatical Relations, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1982 </year>
Reference: [Katz & Fodor 63] <author> J.J. Katz, J. Fodor, </author> <title> The Structure of a Semantic Theory, </title> <booktitle> Language, </booktitle> <volume> vol. 39, </volume> <pages> pp. 170-210, </pages> <year> 1963 </year> <month> 38 </month>
Reference-contexts: Following the classical view an ATM is defined by an enumeration of its features, e.g. screen, keypad and cardslot. These features are often referred to as the extension of an NL statement. In linguistics, this view has emerged in the componential analysis of Katz and Fodor <ref> [Katz & Fodor 63] </ref>. Leech and Bierwisch continue this line of research [Bierwisch & Lang 87]. This, indeed, is the typical form of the classical view in linguistics: the meaning of a word is essentially decomposable into a set of features.
Reference: [Kersten et al. 86] <author> M.L. Kersten, H. Weigand, F. Dignum et al., </author> <title> A Conceptual Modelling Expert System, </title> <booktitle> 5th International Conference on Entity-Relationship Approach, Dijon, </booktitle> <pages> pp. 275-288, </pages> <year> 1986 </year>
Reference-contexts: Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK [Thompson & Thompson 85]. Other systems are the ACME system <ref> [Kersten et al. 86] </ref> or SECSI from Bouzeghoub [Bouzeghoub & Metais 86]. While both have natural language text as input, ACME derives an extended Entity-Relationship model and SECSI generates semantic networks describing the application domain.
Reference: [Klinker et al. 86] <author> G. Klinker, S. Bentolila, M. Genetet et al., </author> <title> KNACK Report Driven Knowledge Acquisition, AAAI Workshop on Knowledge Acquisition for Knowledge Acquisition for Knowledge-Based Systems, </title> <address> Banff, </address> <year> 1986 </year>
Reference-contexts: Extracting concepts from given texts has been a very early research topic in logic programming [Kowalski 79]. Research efforts in this vein lead, for example, to methods for incremental text analysis implemented in systems like KRITON [Diederich et al. 86] and KNACK <ref> [Klinker et al. 86] </ref>. Moreover, several text understanding systems have incorporated conceptual knowledge, e.g. PETRARCA [Velardi et al. 89], RINA [Jacobs and Zernik 88], GENESIS [Mooney and DeJong 85]. Natural language processing has been used in building of knowledge-based systems, e.g.
Reference: [Kowalski 79] <author> R. Kowalski, </author> <title> Logic for Problem Solving, </title> <publisher> Amsterdam, North-Holland, </publisher> <year> 1979 </year>
Reference-contexts: Derivational techniques determine the meaning of a text fragment by combining its components, from the fragment's context, or by a mixture of both. Extracting concepts from given texts has been a very early research topic in logic programming <ref> [Kowalski 79] </ref>. Research efforts in this vein lead, for example, to methods for incremental text analysis implemented in systems like KRITON [Diederich et al. 86] and KNACK [Klinker et al. 86]. Moreover, several text understanding systems have incorporated conceptual knowledge, e.g.
Reference: [Kowalski 85] <author> R. A. Kowalski, </author> <title> The relation between logic programming and logic specification, </title> <editor> in: C. A. R. Hoare, J. C. Shepherdson (eds.), </editor> <booktitle> Mathematical Logic and Programming Languages, Prentice-Hall International, </booktitle> <year> 1985 </year>
Reference-contexts: Which specification languages fulfil these prerequisites? Since we want to develop logic programs, specifically Prolog programs, it is only natural that we consider Prolog itself as a first candidate. Though Prolog has been recommended as a suitable specification language <ref> [Kowalski 85, Sterling 94] </ref> and has often been used as such, applicationspecific specification languages seem to be a better choice since they allow us to express the concepts of the application domain directly, and still can be mapped to Prolog [Sterling 92].
Reference: [Kowalski 90] <author> R. A. Kowalski, </author> <title> English as a Logic Programming Language, in: </title> <journal> New Generation Computing, </journal> <volume> 8, </volume> <pages> pp. 91-93, </pages> <year> 1990 </year>
Reference-contexts: Another well-known example for controlled language is legislation. This case is especially relevant for our approach since it was shown that the language of legislation has many similarities with the language of logic programming, and that statutes can easily be translated into Prolog clauses <ref> [Kowalski 90, Kowalski 92] </ref>. Finally, LPA's Prolog-based flex tool kit represents rules and frames for expert systems in the Knowledge Specification Language KSL an English-like notation enhanced by mathematical and control expressions [Vasey 89].
Reference: [Kowalski 92] <author> R. A. Kowalski, </author> <title> Legislation as Logic Programs, </title> <editor> in: G. Comyn, N. E. Fuchs, M. J. Ratcliffe (eds.), </editor> <booktitle> Logic Programming in Action, Lecture Notes in Artificial Intelligence 636, </booktitle> <pages> pp. 203-230, </pages> <year> 1992 </year>
Reference-contexts: Another well-known example for controlled language is legislation. This case is especially relevant for our approach since it was shown that the language of legislation has many similarities with the language of logic programming, and that statutes can easily be translated into Prolog clauses <ref> [Kowalski 90, Kowalski 92] </ref>. Finally, LPA's Prolog-based flex tool kit represents rules and frames for expert systems in the Knowledge Specification Language KSL an English-like notation enhanced by mathematical and control expressions [Vasey 89].
Reference: [Kowalski 93] <author> R.A. Kowalski, </author> <title> Logic without Model Theory, </title> <type> Technical Report, </type> <institution> Imperial College, </institution> <year> 1993 </year>
Reference-contexts: And third, a DRS can be investigated from a more psychological point of view as a contribution of building up a mental model of a language user. The second and the third ways lead to the concept of knowledge assimilation <ref> [Kowalski 93] </ref>. In this proof theoretic account a DRS is processed by resource-constrained deduction and tested whether it can be added to a continuously changing theory. <p> These Prolog clauses are currently simply added to a knowledge-base. A more refined solution should employ knowledge assimilation <ref> [Kowalski 93] </ref>. The knowledge-base is considered as a (changing) theory of the domain in question. New information arrives confirming or refuting the current theory. Four cases have to be considered: The new Prolog clauses can be derived from the existing theory. <p> With the help of induction and abduction it is also possible to abstract away from the huge amount of factual information entered into the knowledge base and to derive more concise theoretical sentences <ref> [Kowalski 93] </ref>. 7.4 Template-Based Text Generation To lead a coherent dialog with the user we need not only to process input, e.g. specification text, queries, in controlled natural language but also to generate answers of the system, e.g. results of inferences, paraphrases, in a similar language.
Reference: [Kramer & Mylopoulos 92] <author> B. Kramer, J. Mylopoulos, </author> <title> Knowledge Representation, </title> <editor> in: S. C. Shapiro (ed.), </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <publisher> Wiley, </publisher> <year> 1992 </year>
Reference-contexts: By making "true statements about the intended domain of discourse" <ref> [Kramer & Mylopoulos 92] </ref> and "expressing basic concepts directly, without encoding, taking the objects of the language [of the domain of discourse] as abstract entities" [Brger & Rosenzweig 94], applicationspecific specification languages are in the original sense of the word declarative, and have all the practical advantages of declarative programming [Lloyd
Reference: [Lakoff 87] <author> G. Lakoff, Woman, </author> <title> Fire, and Dangerous Things, </title> <publisher> Chicago, University of Chicago Press, </publisher> <year> 1987 </year>
Reference-contexts: More specifically, it will be assumed that the concept used to represent a category on a 23 particular occasion contains (1) information that provides relevant expectations about the category in that context, and (2) information that provides relevant expectations when interacting with the category in most contexts <ref> [Barsalou 82, Medin & Smith 84, Lakoff 87] </ref>. When dealing with a concept lexicon we are especially interested in the features of a concept, its instances in the application domain, and its links to other concepts.
Reference: [Leite & Franco 93] <author> J.C. Leite, A.P. Franco, </author> <title> A Strategy for Conceptual Model Acquisition, </title> <editor> in: S. Fickas and A. Finkelstein (eds.), </editor> <booktitle> IEEE International Symposium on Requirements Engineering, </booktitle> <address> San Diego, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 243-246, </pages> <year> 1993 </year>
Reference-contexts: While both have natural language text as input, ACME derives an extended Entity-Relationship model and SECSI generates semantic networks describing the application domain. In the area of requirements analysis, for example, Leite proposes a natural language approach conceptual model derivation from a lexicon <ref> [Leite & Franco 93] </ref>. The vocabulary of the application domain is defined in a lexicon.
Reference: [Lloyd 94] <author> J. Lloyd, </author> <title> Practical Advantages of Declarative Programming, </title> <booktitle> Invited Lecture, </booktitle> <address> GULP-PRODE '94, Peiscola (Spain), </address> <month> September </month> <year> 1994 </year>
Reference-contexts: [Kramer & Mylopoulos 92] and "expressing basic concepts directly, without encoding, taking the objects of the language [of the domain of discourse] as abstract entities" [Brger & Rosenzweig 94], applicationspecific specification languages are in the original sense of the word declarative, and have all the practical advantages of declarative programming <ref> [Lloyd 94] </ref>. Specifically, they are understood by application specialists. In a previous phase of our project we have shown that graphical and textual views of logic programs can be considered as applicationspecific specification languages [Fuchs & Fromherz 94].
Reference: [Lyons 81] <author> J. Lyons, </author> <title> Language, Meaning and Context, </title> <address> London, Fontana, </address> <year> 1981 </year>
Reference-contexts: what actor has which objects, or what directions does a particular actor have? In contrast to this primitive-based view, a relation-based view of word meaning claims that there is no need for decomposition into primitives if words (and their concepts) are associated through a network of explicitly defined links (e.g. <ref> [Quillian 68, Brachman 79, Lyons 81] </ref>). Sometimes referred to as meaning postulate, these links establish any inference between lexems as an explicit part of a conceptual network. <p> This view has been held by linguists such as Lyons, and comes from the Saussurian tradition [Saussure 66]. Lyons, for example, puts it like this <ref> [Lyons 81, p. 124] </ref>: The sense of a lexical item is [...] identical with, the set of relations which hold between the item in question and other items in the same lexical system. However, according to the organisation of lexicons, primitive-based and relation-based approaches follow a single strategy.
Reference: [Macias & Pulman 92] <author> B. Macias, S. Pulman, </author> <title> Natural Language Processing for Requirements Specifications, </title> <editor> in: F. Redmill, T. Anderson (eds.), </editor> <title> Safety-Critical Systems, Current Issues, Techniques and Standards, </title> <publisher> Chapman & Hall, </publisher> <pages> pp. 67-89, </pages> <year> 1993 </year>
Reference-contexts: both subject and object modifying comparative constructions like bigger than, smaller than and equal to compound sentences like and-lists, or-lists, and-then-lists sentence patterns like if ... then negation like does not, is not and has not This language overlaps with the computer-processable natural language proposed by Pulman and his collaborators <ref> [Macias & Pulman 92, Pulman 94] </ref>. Habitability i.e. the ability to construct sentences in controlled natural language, and to avoid constructions that fall outside the bounds of the language seems to be achievable, particularly when the system gives feedback to its users [Epstein 85, Capindale & Crawford 89].
Reference: [Medin & Smith 84] <author> D.L. Medin, E.E. Smith, </author> <title> Concepts and Concept Formation, </title> <journal> Annual Psychological Review, </journal> <volume> vol. 35, </volume> <pages> pp. 113-138, </pages> <year> 1984 </year>
Reference-contexts: More specifically, it will be assumed that the concept used to represent a category on a 23 particular occasion contains (1) information that provides relevant expectations about the category in that context, and (2) information that provides relevant expectations when interacting with the category in most contexts <ref> [Barsalou 82, Medin & Smith 84, Lakoff 87] </ref>. When dealing with a concept lexicon we are especially interested in the features of a concept, its instances in the application domain, and its links to other concepts.
Reference: [Miller & Johnson-Laird 76] <author> G.A. Miller, </author> <title> P.N. Johnson-Laird, Language and Perception, </title> <publisher> Cambridge, MIT Press, </publisher> <year> 1976 </year>
Reference-contexts: These primitive concepts are simple actions of the kind move a body part (MOVE), build a thought (MBUILD), transfer a physical object (PTRANS), and transfer mental information (MTRANS). Inferences are made through such primitives <ref> [Miller & Johnson-Laird 76] </ref>.
Reference: [Mooney & DeJong 85] <author> R. Mooney, G. DeJong, </author> <title> Learning Schemata for Natural Language Processing, </title> <booktitle> 9th IJCAI, </booktitle> <pages> pp. 681-687, </pages> <year> 1985 </year>
Reference: [Mylopoulos 86] <author> J. Mylopoulos, </author> <title> The Role of Knowledge Representation in the Development of Specifications, </title> <editor> in: H.-J. Kugler (eds.), </editor> <booktitle> IFIP Information Processing '86, </booktitle> <address> Amsterdam, </address> <publisher> Elsevier, </publisher> <year> 1986 </year>
Reference-contexts: Various experiments to construct such tools have been carried out in recent years, especially in restricted domains characterised by a typical sublanguage (e.g. <ref> [Brodie et al. 84, Mylopoulos 86] </ref>). Research in the field is furthermore encouraged by the increasing availability of large quantities of machine-readable texts and lexica. Nevertheless, the results are far from being satisfactory.
Reference: [Pereira & Warren 80] <author> F. C. N. Pereira, D. H. D. Warren, </author> <title> Definite Clause Grammars for Language Analysis a Survey of the Formalism and a Comparison with Augmented Transition Networks, in: </title> <journal> Artificial Intelligence, </journal> <volume> 13, </volume> <pages> pp. 231-278, </pages> <year> 1980 </year>
Reference: [Pollard & Sag 94] <author> C. Pollard, I. A. Sag. </author> <title> Head-Driven Phrase Structure Grammar, Center for the Study of Language and Information, </title> <publisher> Stanford, Chicago Press, </publisher> <address> Chicago, London, </address> <year> 1994 </year>
Reference: [Pulman 94] <author> S. G. Pulman. </author> <title> Natural Language Processing and Requirements Specification, Presentation at the Prolog Forum, </title> <institution> Department of Computer Science, University of Zurich, </institution> <month> February </month> <year> 1994 </year> <month> 39 </month>
Reference-contexts: On the one hand this subset should be expressive enough to allow natural usage by nonspecialists, and on the other hand the language should be accurately and efficiently processable by a computer. This means that we have to find the right tradeoff between expressiveness and processability <ref> [Pulman 94] </ref>. In our approach controlled natural language specifications are translated into semantically equivalent Prolog clauses. This dual representation of specifications narrows the gap between full natural language and formal specification languages and gives us most of the benefits of both. <p> both subject and object modifying comparative constructions like bigger than, smaller than and equal to compound sentences like and-lists, or-lists, and-then-lists sentence patterns like if ... then negation like does not, is not and has not This language overlaps with the computer-processable natural language proposed by Pulman and his collaborators <ref> [Macias & Pulman 92, Pulman 94] </ref>. Habitability i.e. the ability to construct sentences in controlled natural language, and to avoid constructions that fall outside the bounds of the language seems to be achievable, particularly when the system gives feedback to its users [Epstein 85, Capindale & Crawford 89].
Reference: [Quillian 68] <author> M.R. Quillian, </author> <title> Semantic Memory, </title> <editor> in: M. Minsky (eds.), </editor> <booktitle> Semantic Information Processing, </booktitle> <address> Cambridge, </address> <publisher> MIT Press, </publisher> <year> 1968 </year>
Reference-contexts: what actor has which objects, or what directions does a particular actor have? In contrast to this primitive-based view, a relation-based view of word meaning claims that there is no need for decomposition into primitives if words (and their concepts) are associated through a network of explicitly defined links (e.g. <ref> [Quillian 68, Brachman 79, Lyons 81] </ref>). Sometimes referred to as meaning postulate, these links establish any inference between lexems as an explicit part of a conceptual network.
Reference: [Rau et al. 89] <author> L. Rau, P. Jacobs, U. Zernik, </author> <title> Information Extraction and Text Summarization Using Linguistic Knowledge Acquisition, </title> <booktitle> Information Processing and Management, </booktitle> <volume> vol. 25, no. 4, </volume> <pages> pp. 419-428, </pages> <year> 1989 </year>
Reference-contexts: Moreover, several text understanding systems have incorporated conceptual knowledge, e.g. PETRARCA [Velardi et al. 89], RINA [Jacobs and Zernik 88], GENESIS [Mooney and DeJong 85]. Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ [Ayuso et al. 87], SCISOR <ref> [Rau et al. 89] </ref>. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK [Thompson & Thompson 85].
Reference: [Rosch & Loyd 78] <author> E. Rosch, B.B. Loyd, </author> <title> Cognition and Categorization, </title> <address> Hillsdale, </address> <publisher> Erlbaum, </publisher> <year> 1978 </year>
Reference-contexts: NL) stand for in another language (e.g. Prolog). In requirements engineering, a lexicon can be thought of as the collection of concepts used in a particular application domain. A concept refers to the particular information used to represent a category (or exemplar) on a particular occasion <ref> [Rosch & Loyd 78] </ref>.
Reference: [Saussure 66] <author> F. Saussure, </author> <title> Course in General Linguistics, </title> <address> New York, McGraw Hill, </address> <year> 1966 </year>
Reference-contexts: This view has been held by linguists such as Lyons, and comes from the Saussurian tradition <ref> [Saussure 66] </ref>. Lyons, for example, puts it like this [Lyons 81, p. 124]: The sense of a lexical item is [...] identical with, the set of relations which hold between the item in question and other items in the same lexical system.
Reference: [Schank 75] <editor> R.C. Schank, </editor> <booktitle> Conceptual Information Processing, </booktitle> <address> Amsterdam, </address> <publisher> North Holland, </publisher> <year> 1975 </year>
Reference-contexts: The features that represent the meaning of a word are just those which distinguish it from others in the relevant domain. Moreover, most of these approaches assume that word meaning can be exhaustively defined in terms of a fixed set of primitive elements (e.g. <ref> [Schank 75, Wilks 75] </ref>). Schank, for example, argues that a small number of concepts corresponding to primitive acts can be used to construct meaning representations for most descriptions of events. <p> Second, instead of a fixed meaning ascribed to a certain lexical item, we rely on contextual expansion to derive its meaning. Evolving Set of Core Components. In AI literature primitives have been suggested and employed with varying success <ref> [Schank 75, Wilks 75] </ref>. What we would like to do, however, is to propose a new way of viewing primitives looking more at the generative or compositional aspects of lexical semantics, rather than the decomposition into a specific number of primitives.
Reference: [Shieber et al. 83] <author> S. M. Shieber, H. Uszkoreit, F. C. N. Pereira, J. J. Robinson, M. Tyson, </author> <title> The Formalism and Implementation of PATR-II, in: Research on Interactive Acquisition and Use of Knowledge, </title> <booktitle> Artificial Intelligence Center, SRI International, </booktitle> <address> Menlo Park, </address> <institution> Cal., </institution> <year> 1983 </year>
Reference: [Shieber 86] <author> S. M. Shieber, </author> <title> An Introduction to Unification-Based Approaches to Grammar, CSLI Lecture Notes 4, Center for the Study of Language and Information, </title> <institution> Stanford University, Cal., </institution> <year> 1986 </year>
Reference-contexts: Grammar formalisms are metalanguages whose intended use is to describe a set of well-formed sentences in an object language. The choice of this metalanguage for natural language processing is critical and should fulfil three important criteria: linguistic felicity, expressiveness, and computational effectiveness <ref> [Shieber 86] </ref>. First, linguists need notations that allow them to encode their linguistic descriptions concisely and flexibly, and to express the relevant generalisations over rules and lexical entries.
Reference: [Sommerville 92] <author> I. Sommerville, </author> <title> Software Engineering, Fourth Edition, </title> <publisher> Addison Wesley, </publisher> <address> Wokingham, </address> <year> 1992 </year>
Reference-contexts: (Status: not yet implemented) 3 Controlled Natural Language A software specification is a statement of the services a software system is expected to provide to its users, and should be written in a concise way that is understandable by potential users of the system, by management and by software suppliers <ref> [Sommerville 92] </ref>. Strangely enough, this goal is hard to achieve if specifications are expressed in full natural language. Natural language terminology tends to be ambiguous, imprecise and unclear. Also, there is considerable room for errors and misunderstandings since people may have different views of the role of the software system.
Reference: [Sterling 92] <author> L. Sterling, </author> <title> A Role for Prolog in Software Engineering, </title> <institution> Computer Science Colloquium, Department of Computer Science, University of Zurich, </institution> <year> 1992 </year>
Reference-contexts: Though Prolog has been recommended as a suitable specification language [Kowalski 85, Sterling 94] and has often been used as such, applicationspecific specification languages seem to be a better choice since they allow us to express the concepts of the application domain directly, and still can be mapped to Prolog <ref> [Sterling 92] </ref>.
Reference: [Sterling 94] <author> L. Sterling, </author> <title> Prolog for Software Engineering, </title> <booktitle> Tutorial at the Second International Conference on the Practical Applications of Prolog PAP'94, </booktitle> <address> London, </address> <month> April </month> <year> 1994 </year>
Reference-contexts: Which specification languages fulfil these prerequisites? Since we want to develop logic programs, specifically Prolog programs, it is only natural that we consider Prolog itself as a first candidate. Though Prolog has been recommended as a suitable specification language <ref> [Kowalski 85, Sterling 94] </ref> and has often been used as such, applicationspecific specification languages seem to be a better choice since they allow us to express the concepts of the application domain directly, and still can be mapped to Prolog [Sterling 92].
Reference: [Thompson & Thompson 85] <author> B. Thompson, F. Thompson, </author> <title> ASK Is Transportable in Half a Dozen Ways, </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 185-203, </pages> <year> 1985 </year>
Reference-contexts: IRACQ [Ayuso et al. 87], SCISOR [Rau et al. 89]. Work on natural language interfaces for databases also leads to system components for knowledge acquisition, e.g. TELI [Ballard & Stumberger 88], TEAM [Grosz et al. 87], TQA [Damerau 85] and ASK <ref> [Thompson & Thompson 85] </ref>. Other systems are the ACME system [Kersten et al. 86] or SECSI from Bouzeghoub [Bouzeghoub & Metais 86]. While both have natural language text as input, ACME derives an extended Entity-Relationship model and SECSI generates semantic networks describing the application domain.
Reference: [Vasey 89] <author> P. Vasey, </author> <title> flex Expert System Toolkit, Version 1.2, </title> <booktitle> Logic Programming Associates, </booktitle> <address> London, </address> <year> 1989 </year>
Reference-contexts: Finally, LPA's Prolog-based flex tool kit represents rules and frames for expert systems in the Knowledge Specification Language KSL an English-like notation enhanced by mathematical and control expressions <ref> [Vasey 89] </ref>. Thus we propose to restrict the use of natural language in specifications to a controlled subset with a well-defined syntax and semantics.
Reference: [Velardi et al. 89] <author> P. Velardi, M.T. Pazienza, S. Magrini, </author> <title> Acquisition of Semantic Patterns from a Natural Language Corpus of Texts, </title> <journal> SIGART Newsletter, </journal> <volume> vol. 108, </volume> <pages> pp. 115-123, </pages> <year> 1989 </year>
Reference-contexts: Research efforts in this vein lead, for example, to methods for incremental text analysis implemented in systems like KRITON [Diederich et al. 86] and KNACK [Klinker et al. 86]. Moreover, several text understanding systems have incorporated conceptual knowledge, e.g. PETRARCA <ref> [Velardi et al. 89] </ref>, RINA [Jacobs and Zernik 88], GENESIS [Mooney and DeJong 85]. Natural language processing has been used in building of knowledge-based systems, e.g. IRACQ [Ayuso et al. 87], SCISOR [Rau et al. 89].
Reference: [Wilks 75] <author> Y. Wilks, </author> <title> A Preferential Pattern Seeking Semantics for Natural Language Inference, </title> <journal> Artificial Intelligence, </journal> <volume> no. 6, </volume> <pages> pp. 53-74, </pages> <year> 1975 </year>
Reference-contexts: The features that represent the meaning of a word are just those which distinguish it from others in the relevant domain. Moreover, most of these approaches assume that word meaning can be exhaustively defined in terms of a fixed set of primitive elements (e.g. <ref> [Schank 75, Wilks 75] </ref>). Schank, for example, argues that a small number of concepts corresponding to primitive acts can be used to construct meaning representations for most descriptions of events. <p> Second, instead of a fixed meaning ascribed to a certain lexical item, we rely on contextual expansion to derive its meaning. Evolving Set of Core Components. In AI literature primitives have been suggested and employed with varying success <ref> [Schank 75, Wilks 75] </ref>. What we would like to do, however, is to propose a new way of viewing primitives looking more at the generative or compositional aspects of lexical semantics, rather than the decomposition into a specific number of primitives.
Reference: [Williams 85] <author> J. Williams, </author> <title> Style Ten Lessons in Clarity and Grace, Scott, </title> <publisher> Foremann Co., </publisher> <year> 1985 </year> <month> 40 </month>
References-found: 70

