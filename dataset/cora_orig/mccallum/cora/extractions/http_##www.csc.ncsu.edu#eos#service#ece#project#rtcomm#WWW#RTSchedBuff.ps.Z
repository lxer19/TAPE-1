URL: http://www.csc.ncsu.edu/eos/service/ece/project/rtcomm/WWW/RTSchedBuff.ps.Z
Refering-URL: http://www.csc.ncsu.edu/eos/service/ece/project/rtcomm/WWW/other.html
Root-URL: http://www.csc.ncsu.edu
Email: E-mail: (sdrampal,dpa,reeves)@eos.ncsu.edu  
Phone: Tel: 919-515-3984  
Title: Processor Scheduling Algorithms for Minimizing Buffer Requirements in Multimedia Applications  
Author: Rampal, Dharma P. Agrawal, and Douglas Reeves, 
Address: Box 7911, Raleigh, NC 27695-7911  
Affiliation: Dept. of Electrical Computer Engineering, North Carolina State University,  
Note: Sanjeev  
Abstract: Center for Communications and Signal Processing North Carolina State University Technical Report TR 94/16 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E.A. Fox, </author> <title> "The Coming Revolution in Interactive Digital Video," </title> <journal> Commun. of the ACM, </journal> <month> July </month> <year> 1989, </year> <month> pp.794-801. </month>
Reference-contexts: 1 Introduction 1.1 Motivation Multimedia based systems are expected to dominate the workstation environment in the near future. Such systems will be expected to readily handle audio, video and other forms of time constrained data often referred to as real-time data <ref> [1] </ref>, [2]. Real-time data is typically required to be processed within a given time bound or deadline for it to be useful. For instance, in order to play out a movie stored on disk, the video processor has to set a playback point.
Reference: [2] <author> P.V. Rangan, H.M. Vin and S. Ramanathan, </author> <title> "Designing an On-Demand Multimedia Service," </title> <journal> IEEE Communications Mag., </journal> <month> July </month> <year> 1992, </year> <month> pp.56-65. </month>
Reference-contexts: 1 Introduction 1.1 Motivation Multimedia based systems are expected to dominate the workstation environment in the near future. Such systems will be expected to readily handle audio, video and other forms of time constrained data often referred to as real-time data [1], <ref> [2] </ref>. Real-time data is typically required to be processed within a given time bound or deadline for it to be useful. For instance, in order to play out a movie stored on disk, the video processor has to set a playback point.
Reference: [3] <author> C.L. Liu and J.W. Layland, </author> <title> "Scheduling algorithms for multiprogramming in a hard real-time environment," </title> <journal> Journal of the ACM, </journal> <volume> 20, </volume> <year> 1973, </year> <pages> pp. 46-61. </pages>
Reference-contexts: Conventional operating systems and processor scheduling techniques do not provide for such real-time constraints. Consequently, real-time processor scheduling techniques have been developed for deadline based 2 task systems. In particular, processor scheduling algorithms for periodic real-time systems have been studied extensively <ref> [3] </ref>, [4]. Such task systems consist of a number of jobs (say n jobs numbered as J i ; i = 1; : : : n). Each job J i arrives (i.e. is ready for execution) periodically with a period T i . <p> For the case where deadlines are equal to the invocation periods (i.e. each task has to be completed before the arrival of the next task of the same job), the rate-monotone priority allocation algorithm has been shown <ref> [3] </ref> to be an optimal static priority allocation algorithm in the sense that if this algorithm does not lead to a schedule in which every deadline is met (i.e. a feasible schedule), then no priority allocation algorithm will result in a feasible schedule. <p> Now, zero buffering is required if and only if the rate-monotone priority assignment is able to yield a feasible schedule for this job set with these deadlines. Hence, a task set which requires no buffering will be referred to in the paper as being LL-schedulable (for "Liu-Layland Schedulable" <ref> [3] </ref>). Lemma 2.1 A necessary and sufficient condition for the buffered-schedulability of a job set using an appropriately large but finite buffer is that the total processor utilization ( P n more than 1. <p> Proof: The proof is similar to that of Theorem 1 in [5] and is not included here for lack of space. The rate-monotonic (RM) scheduling algorithm has been shown to be optimal for scheduling job sets when the deadlines equal the invocation periods <ref> [3] </ref>. The following example shows that it is 7 not an optimal algorithm for minimizing the buffer requirements for buffer-scheduling a given job set. <p> In practice most of the tasks in a job system will require zero buffering. These jobs form a LL-schedulable set and must all execute at higher priorities than the remaining jobs. An optimal algorithm for allocating priorities to these LL-schedulable jobs is ofcourse the rate-monotone (RM) algorithm <ref> [3] </ref>. The key point is how to partition a given job set into the set which can be LL-scheduled and another set consisting of jobs which will overflow so that the total amount of buffering is minimized. Fig. 1 lists an algorithm which we will call the CP (i.e. <p> Polynomial algorithms can also be derived along the same lines. If in step 1 of the CP algorithm (Fig. 1) , instead of using the necessary and sufficient conditions of [6] we use the sufficient conditions presented in <ref> [3] </ref> using only the worst-case total utilization bounds, the running times of the CP-I, CP-II and CP-RM algorithms become polynomial. Liu & Layland [3] have proved that an n job set is LL-schedulable if the total utilization is no more than the value n (2 1=n 1). <p> in step 1 of the CP algorithm (Fig. 1) , instead of using the necessary and sufficient conditions of [6] we use the sufficient conditions presented in <ref> [3] </ref> using only the worst-case total utilization bounds, the running times of the CP-I, CP-II and CP-RM algorithms become polynomial. Liu & Layland [3] have proved that an n job set is LL-schedulable if the total utilization is no more than the value n (2 1=n 1). <p> For each value of n (the number of jobs), a total of 250 different job sets were generated with the total utilization varying uniformly between W CU B and 1 where W CU B is the worst case upper bound of Liu & Layland for LL-schedulability <ref> [3] </ref>. This was done since no buffering is required anyway for job sets with total utilization below this bound. A random search algorithm (RAND OPT) was additionally used to get some idea of the "optimal" amount of buffering.
Reference: [4] <author> L. Sha and J. Goodenough, </author> <title> "Real time scheduling theory and ADA," </title> <booktitle> IEEE Computer, </booktitle> <month> April </month> <year> 1990, </year> <pages> pp. 53-62. </pages>
Reference-contexts: Conventional operating systems and processor scheduling techniques do not provide for such real-time constraints. Consequently, real-time processor scheduling techniques have been developed for deadline based 2 task systems. In particular, processor scheduling algorithms for periodic real-time systems have been studied extensively [3], <ref> [4] </ref>. Such task systems consist of a number of jobs (say n jobs numbered as J i ; i = 1; : : : n). Each job J i arrives (i.e. is ready for execution) periodically with a period T i . <p> This algorithm although optimal in the sense described above, cannot always achieve 100% processor utilization. For a large number of jobs, the achievable utilization may be as low as 69% <ref> [4] </ref>. In contrast, the optimal dynamic priority algorithm for the same problem viz. the Earliest Deadline First (EDF) algorithm is always able to find a feasible schedule as long as total utilization of the task set is no more than 100%. <p> However static priority scheduling has some advantages over dynamic schemes such as ensuring that the timing requirements of the most important jobs are met during transient overloads, easier implmentation of task synchronization protocols such as the priority ceiling protocol <ref> [4] </ref> and most importantly, ease of implementation in processors, I/O controllers and communication switches. Analysis of static priority schemes is hence an important problem. 1.3 Overview of the Paper In the next section we introduce some definitions which are used throughout the paper. <p> However, overall the values were quite low since even at high values of total utilization, there are many job sets which are LL-schedulable and hence require no buffering at all. (This is in accordance with the results in <ref> [4] </ref> in which the average total utilisation for LL-schedulability was found to be about 83%.) The average values produced by the CP-II algorithm are between 20 and 50 % of those produced by the other algoritthms. Next the relative performance of the polynomial versions of the same algorithms was evaluated.
Reference: [5] <author> J.P. Lehoczky, </author> <title> "Fixed priority scheduling of periodic task sets with arbitrary deadlines," </title> <booktitle> Proc. IEEE Real Time Systems Symposium, </booktitle> <year> 1990, </year> <pages> pp. 201-209. </pages>
Reference-contexts: The inverse deadline monotone priority allocation algorithm, has been shown to be optimal for the case of deadlines less than or equal to the invocation periods [7]. Not much work has been reported on static priority scheduling for the case of arbitrary deadlines. Lehoczky <ref> [5] </ref> has analyzed the performance of the rate-monotone algorithm for the case where all deadlines are a constant multiple of the periods but has also shown that the rate-monotone algorithm is not an optimal algorithm even for this special case. <p> Let the jobs be numbered according to priority so that job J 1 has the highest priority, J 2 has the second highest and so on. Using terminology introduced by Lehoczky <ref> [5] </ref>, we first define a level-i busy period. <p> Also, there must be at least one instant during the level-n busy period initiated by the critical instant I 1 = I 2 = = I n = 0 at which there are M LT late tasks. Proof: The proof is similar to that of Theorem 1 in <ref> [5] </ref> and is not included here for lack of space. The rate-monotonic (RM) scheduling algorithm has been shown to be optimal for scheduling job sets when the deadlines equal the invocation periods [3]. <p> These polynomial-time algorithms are expected to result in higher amounts of buffering than their pseudo-polynomial versions since in general more jobs will be transferred to the set S other than necessary. 3.5 A third upper bound for the P CP-RM algorithm Lehoczky <ref> [5] </ref> has derived worst-case utilization bounds for scheduling jobs with deadlines given by D i = fi T i using rate-monotone priority ordering. <p> Currently, the only known approach to this problem is a sufficient (but not necessary) condition based on the worst case utilization bounds formulated by Lehoczky <ref> [5] </ref> as discussed above. The bounds in [5] have been derived assuming rate-monotone ordering of job priorities even though it is known that this is not an optimal ordering. <p> Currently, the only known approach to this problem is a sufficient (but not necessary) condition based on the worst case utilization bounds formulated by Lehoczky <ref> [5] </ref> as discussed above. The bounds in [5] have been derived assuming rate-monotone ordering of job priorities even though it is known that this is not an optimal ordering. <p> Scheduling algorithms based on input buffer minimization techniques will 20 also be applicable to a more general class of applications since the deadlines will not be restricted to be a multiple of the task periods as in <ref> [5] </ref>. A detailed evaluation of this approach was beyond the scope of this paper and is a topic for further investigation. The question of intractability of the problem (obtaining an optimal priority allocation in polynomial time, which minimizes buffering requirements) is open.
Reference: [6] <author> J.P. Lehoczky, L. Sha, and Y. </author> <title> Ding,"The rate monotonic scheduling algorithm: Exact characterization and average case behaviour," </title> <booktitle> Proc. IEEE Real Time Systems Symposium, </booktitle> <year> 1989, </year> <pages> pp. 166-171. </pages>
Reference-contexts: denotes the set of jobs allocated priorities using the ICTM/ ICM algorithms */ S rm = S; S other = OE Evaluate parameter i , i = 1; : : :; n Step 1: Test the jobs in S rm for LL-schedulability using the necessary and sufficient tests derived in <ref> [6] </ref>. If successful, goto Step 3. Step 2: From the set S rm move the job with the largest value of parameter i to the set S other . Goto Step 1. <p> Polynomial algorithms can also be derived along the same lines. If in step 1 of the CP algorithm (Fig. 1) , instead of using the necessary and sufficient conditions of <ref> [6] </ref> we use the sufficient conditions presented in [3] using only the worst-case total utilization bounds, the running times of the CP-I, CP-II and CP-RM algorithms become polynomial.
Reference: [7] <author> J. Leung and J. Whitehead, </author> <title> "On the complexity of fixed-priority scheduling of periodic real-time tasks," Performance Evaluation, </title> <type> 2, </type> <year> 1982, </year> <pages> pp. 237-250. 21 </pages>
Reference-contexts: The inverse deadline monotone priority allocation algorithm, has been shown to be optimal for the case of deadlines less than or equal to the invocation periods <ref> [7] </ref>. Not much work has been reported on static priority scheduling for the case of arbitrary deadlines. <p> For most of this paper, we will consider throughput oriented applications as mentioned earlier and hence there are no task deadlines. Additionally, we will assume that all the start times (the I i 's) are equal to 0. Such job sets are also referred to as being synchronous <ref> [7] </ref>. Input buffer size is determined by the number of tasks which have arrived but for which processing has not yet begun. An inherent assumption is thus that buffer memory required for tasks being processed is not considered.
References-found: 7

