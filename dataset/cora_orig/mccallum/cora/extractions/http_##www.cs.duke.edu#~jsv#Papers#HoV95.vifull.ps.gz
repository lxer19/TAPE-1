URL: http://www.cs.duke.edu/~jsv/Papers/HoV95.vifull.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node31.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Error Modeling for Hierarchical Lossless Image Compression  
Author: Paul G. Howard and Jeffrey Scott Vitter 
Abstract: A shorter version of this paper appears in Proceedings of the IEEE Data Compression Conference, Snowbird, Utah, March 23-26, 1992, 269-278. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> "Digital Compression and Coding of Continuous-Tone Still Images, </institution> <note> Part 1, Requirements and Guidelines," ISO/IEC JTC1 Draft International Standard 10918-1, </note> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: To avoid cluttering the graphs in Figure 3 we include results for only one version of MLP, and to keep the scale large we omit data for the three highly compressible Landsat images. The CCITT/ISO Joint Photographic Experts Group (JPEG) has recently proposed a standard for image compression <ref> [1] </ref> that addresses both lossless and lossy compression. We compare our results with the lossless mode of the JPEG proposed standard. The JPEG lossless mode is based on prediction by one, two, or three points, followed by Huffman coding or arithmetic coding; encoding proceeds in raster scan order.
Reference: [2] <author> P. G. Howard & J. S. Vitter, </author> <title> "New Methods for Lossless Image Compression Using Arithmetic Coding," </title> <booktitle> Information Processing and Management 28 (1992), </booktitle> <pages> 765-779. </pages>
Reference-contexts: This will allow us to select the appropriate Laplace distribution (the one with the estimated variance) to use in encoding each pixel's prediction error by arithmetic coding. Using a single variance for the entire level (as in <ref> [2] </ref>) disregards local variations in the image; estimating and explicitly encoding variances for small sections of the image (also done in [2]) incurs considerable overhead. <p> Using a single variance for the entire level (as in <ref> [2] </ref>) disregards local variations in the image; estimating and explicitly encoding variances for small sections of the image (also done in [2]) incurs considerable overhead. It would seem that previously encountered prediction errors of nearby pixels would be related to a given pixel's error, but there is no obvious way to use them directly. <p> In Section 4.2 we briefly describe the test images and the compression methods compared, and we present the results in narrative, tabular and graphical form. 4.1 Compression gain A robust measure of compression performance, called compression gain, is introduced in <ref> [2] </ref>. Here we give a slightly different formulation, using a more convenient scale.
Reference: [3] <author> P. G. Howard & J. S. Vitter, </author> <title> "Design and Analysis of Fast Text Compression Based on Quasi-Arithmetic Coding," </title> <booktitle> Information Processing and Management 30 (1994), </booktitle> <pages> 777-794, </pages> <note> also appears in shorter form in the proceedings of the Data Compression Conference, </note> <editor> J. A. Storer and M. Cohn, eds., </editor> <address> Snowbird, Utah, March 30-April 1, </address> <year> 1993, </year> <pages> 98-107. </pages>
Reference: [4] <author> P. G. Howard & J. S. Vitter, </author> <title> "Fast Progressive Lossless Image Compression," </title> <booktitle> in Image and Video Compression Conference, Symposium on Electronic Imaging: Science & Technology #SPIE-2186, </booktitle> <address> San Jose, California, </address> <month> Feb. </month> <pages> 9-10, </pages> <year> 1994, </year> <pages> 98-109. </pages>
Reference-contexts: FELICS runs nearly 50 times faster than MLP, five times faster than a commonly used implementation of the JPEG lossless mode, and as fast as the Unix compress program. We have also investigated a progressive version of FELICS <ref> [4] </ref> that uses MLP's pixel sequence; it obtains about 1 ffi ffi better compression than non-progressive FELICS at the cost of a small decrease in speed. 5 CONCLUSIONS 12 Acknowledgments. We wish to thank James C.
Reference: [5] <author> P. G. Howard & J. S. Vitter, </author> <title> "Arithmetic Coding for Data Compression," </title> <booktitle> Proc. IEEE 82 (June 1994), </booktitle> <pages> 857-865. </pages>
Reference: [6] <author> J. B. O'Neal, </author> <title> "Predictive Quantizing Differential Pulse Code Modulation for the Transmission of Television Signals," </title> <institution> Bell Syst. Tech. J. </institution> <month> 45 (May-June </month> <year> 1966), </year> <pages> 689-721. </pages>
Reference-contexts: In Section 5 we discuss the direction of our current work. 2 Modeling by Variability Index In this section we assume that prediction errors are random variates from a Laplace (or symmetric exponential) distribution with zero mean. This assumption is based on considerable experimental evidence beginning with O'Neal <ref> [6] </ref>, although in Section 3 we provide evidence that Laplace distributions are not always the best models for predictive coders. Our goal is to estimate the local variance of the pixel prediction errors in a given level of the MLP encoding.
References-found: 6

