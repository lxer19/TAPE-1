URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume3/bergmann95a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/bergmann95a.html
Root-URL: 
Email: bergmann@informatik.uni-kl.de  wilke@informatik.uni-kl.de  
Title: Building and Refining Abstract Planning Cases by Change of Representation Language  
Author: Ralph Bergmann Wolfgang Wilke 
Address: P.O.-Box 3049, D-67653 Kaiserslautern, Germany  
Affiliation: Centre for Learning Systems and Applications (LSA) University of Kaiserslautern,  
Note: Journal of Artificial Intelligence Research 3 (1995) 53-118 Submitted 3/95; published 7/95  
Abstract: Abstraction is one of the most promising approaches to improve the performance of problem solvers. In several domains abstraction by dropping sentences of a domain description as used in most hierarchical planners has proven useful. In this paper we present examples which illustrate significant drawbacks of abstraction by dropping sentences. To overcome these drawbacks, we propose a more general view of abstraction involving the change of representation language. We have developed a new abstraction methodology and a related sound and complete learning algorithm that allows the complete change of representation language of planning cases from concrete to abstract. However, to achieve a powerful change of the representation language, the abstract language itself as well as rules which describe admissible ways of abstracting states must be provided in the domain model. This new abstraction approach is the core of Paris (Plan Abstraction and Refinement in an Integrated System), a system in which abstract planning cases are automatically learned from given concrete cases. An empirical study in the domain of process planning in mechanical engineering shows significant advantages of the proposed reasoning from abstract cases over classical hierarchical planning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Althoff, K. D., & Wess, S. </author> <year> (1992). </year> <title> Case-based reasoning and expert system development. </title>
Reference: <editor> In Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), </editor> <title> Contemporary Knowledge Engineering amd Cognition. </title> <publisher> Springer, </publisher> <address> Heidelberg. </address>
Reference: <author> Anderson, J. S., & Farly, A. M. </author> <year> (1988). </year> <title> Plan abstraction based on operator generalization. </title> <booktitle> In Proceedings of the 7th International Conference on Artifical Intelligence, </booktitle> <pages> pp. </pages> <address> 100-104 San Mateo. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Bacchus, F., & Yang, Q. </author> <year> (1994). </year> <title> Downward refinement and efficiency of hierarchical problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 71, </volume> <pages> 43-100. </pages>
Reference: <author> Bergmann, R. </author> <year> (1992a). </year> <title> Knowledge acquisition by generating skeletal plans. </title> <editor> In Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), </editor> <booktitle> Contemporary Knowledge Engineering and Cognition, </booktitle> <pages> pp. </pages> <address> 125-133 Heidelberg. </address> <publisher> Springer. </publisher>
Reference-contexts: More details on the generalization procedure can be found in <ref> (Bergmann, 1992a) </ref>, while the evaluation and retrieval mechanisms are reported in (Bergmann & Wilke, 1994; Wilke, 1994). The whole multi- strategy system including the various interactions of the described components will be the topic of a forthcoming article, while first ideas can already be found in (Bergmann, 1992b, 1993).
Reference: <author> Bergmann, R. </author> <year> (1992b). </year> <title> Learning abstract plans to speed up hierarchical planning. </title> <editor> In Tadepalli, P. (Ed.), </editor> <booktitle> Proceedings of the ML92 Workshop on Knowledge Compilation and Speedup Learning. </booktitle> <institution> University of Aberdeen, </institution> <address> Scotland. </address>
Reference-contexts: The whole multi- strategy system including the various interactions of the described components will be the topic of a forthcoming article, while first ideas can already be found in <ref> (Bergmann, 1992b, 1993) </ref>.
Reference: <author> Bergmann, R. </author> <year> (1992c). </year> <title> Learning plan abstractions. </title> <editor> In Ohlbach, H. (Ed.), </editor> <booktitle> GWAI-92 16th German Workshop on Artificial Intelligence, Vol. 671 of Springer Lecture Notes on AI, </booktitle> <pages> pp. 187-198. </pages>
Reference-contexts: This transformation will now be formally decomposed into two independent mappings: a state abstraction mapping ff, and a sequence abstraction mapping fi <ref> (Bergmann, 1992c) </ref>. The state abstraction mapping transforms a selection of concrete state descriptions that occur in the solution to a problem into abstract state descriptions, 8. In the following, we will simply omit the parameters of operators and instantiated operators in case they are unambiguous or not relevant. 9.
Reference: <author> Bergmann, R. </author> <year> (1993). </year> <title> Integrating abstraction, explanation-based learning from multiple examples and hierarchical clustering with a performance component for planning. </title>
Reference: <editor> In Plaza, E. (Ed.), </editor> <booktitle> Proceedings of the ECML-93 Workshop on Integrated Learning Architectures (ILA-93) Vienna, </booktitle> <address> Austria. </address>
Reference: <author> Bergmann, R., Pews, G., & Wilke, W. </author> <year> (1994). </year> <title> Explanation-based similarity: A unifying approach for integrating domain knowledge into case-based reasoning. </title> <editor> In Richter, M., Wess, S., Althoff, K., & Maurer, F. (Eds.), </editor> <booktitle> Topics in Case-Based Reasoning, Vol. 837 of Lecture Notes on Artificial Intelligence, </booktitle> <pages> pp. 182-196. </pages> <publisher> Springer. </publisher>
Reference: <author> Bergmann, R., & Wilke, W. </author> <year> (1994). </year> <editor> Inkrementelles Lernen von Abstraktionshierarchien aus maschinell abstrahierten Planen. In Fensel, D., & Nakhaeizadeh, G. (Eds.), </editor> <booktitle> Proceedings of the Workshop Maschinelles Lernen: Theoretische Ansatze und Anwendungsaspekte, </booktitle> <volume> No. </volume> <pages> 291. </pages> <institution> Institut fur angewandte Informatik und formale Beschreibungsverfahren, University of Karlsruhe, Germany. </institution> <note> 113 Bergmann & Wilke Blythe, </note> <author> J., Etzioni, O., & et al. </author> <year> (1992). </year> <title> Prodigy4.0: The manual and tutorial. </title> <type> Tech. rep. </type> <institution> CMU-CS-92-150, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Carbonell, J. G. </author> <year> (1986). </year> <title> Derivational analogy: A theory of reconstructive problem solving and expertise aquisition. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach, </booktitle> <volume> Vol. 2, chap. 14, </volume> <pages> pp. 371-392. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> DeJong, G., & Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 (2), </volume> <pages> 145-176. </pages>
Reference: <author> Etzioni, O. </author> <year> (1993). </year> <title> A structural theory of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 60, </volume> <pages> 93-139. </pages>
Reference: <author> Etzioni, O., & Etzioni, R. </author> <year> (1994). </year> <title> Statistical methods for analyzing speedup learning. </title> <journal> Machine Learning, </journal> <volume> 14, </volume> <pages> 333-347. </pages>
Reference-contexts: We have determined these values for reasoning from abstract cases separately for each of the three types of abstract cases. The significance of the speedup results has be investigated by using a maximally conservative sign test <ref> (Etzioni & Etzioni, 1994) </ref>. Unfortunately it turned out that the speedup of hierarchical planning over pure search was not significant. We also couldn't find a significant speedup of reasoning from abstract cases when using always the worst applicable abstract case (c) over pure search. <p> The mentioned p-value is a standard value used in statistical hypothesis tests. It is the probability, assuming that the hypothesis does not hold, of encountering data that favors the hypothesis as much or more than the observed data in the experiment <ref> (Etzioni & Etzioni, 1994) </ref>. Therefore a result is more significant if the p-value is smaller. From this analysis, we can clearly see, that our two basic hypotheses are supported by our experimental data. <p> Even in the worst training set considerably more problems could be solved than by pure search or hierarchical planning. Additionally all of the above mentioned speedup results were analyzed with the maximally conservative sign test as described in <ref> (Etzioni & Etzioni, 1994) </ref>. Table 11 summarizes the significance results for speeding up pure search and a hierarchical problem solver. It turned out that 19 of the 20 training sets lead to highly significant speedups (p &lt; 0:0005) over pure search.
Reference: <author> Fikes, R. E., Hart, P. E., & Nilsson, N. J. </author> <year> (1972). </year> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3, </volume> <pages> 251-288. </pages>
Reference: <author> Fikes, R. E., & Nilsson, N. J. </author> <year> (1971). </year> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2, </volume> <pages> 189-208. </pages>
Reference-contexts: Therefore we will define a formal representation for problem solving domains. We want to assume that problem solving in general can be viewed as transforming an initial state into a final state by using a sequence of operators (Newell & Simon, 1972). Following a Strips-oriented representation <ref> (Fikes & Nilsson, 1971) </ref>, the domain of problem solving D = hL; E; O; Ri is described by a first-order language 6 L, a set of essential atomic sentences E of L (Lifschitz, 1987), a set of operators O with related descriptions, and additionally, a set of rules (Horn clauses) R <p> the usual refinement procedure used in hierarchical problem solving, the main computational advantage of abstraction caused by the decomposition of the original problem into smaller subproblems is maintained. 7.4 Alternative Search Procedures for Refinement Besides the forward-directed search procedure currently used in Paris backward-directed search as used in means-end analysis <ref> (Fikes & Nilsson, 1971) </ref> or in nonlinear partial-ordered 82 Building and Refining Abstract Planning Cases planning (McAllester & Rosenblitt, 1991) can also be applied for refinement under certain circumstances.
Reference: <author> Friedland, P. E., & Iwasaki, Y. </author> <year> (1985). </year> <title> The concept and implementation of skeletal plans. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 1 (2), </volume> <pages> 161-208. </pages>
Reference-contexts: Note, that this is fulfilled for the retrieval mechanism (sequential search from longer to shorter plans) we used in our experiments. 10.1.2 Skeletal Plans As already mentioned in Section 3.4 the Paris approach is inspired by the idea of skeletal plans <ref> (Friedland & Iwasaki, 1985) </ref>. A abstract cases can be seen as a skeletal plan, and our learning algorithm is a means to learn skeletal plans automatically out of concrete plans.
Reference: <author> Giordana, A., Roverso, D., & Saitta, L. </author> <year> (1991). </year> <title> Abstracting background knowledge for concept learning. </title> <editor> In Kodratoff, Y. (Ed.), </editor> <booktitle> Proceedings of the European Working Session on Learning (EWSL-91), Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1-13 Berlin. </address> <publisher> Springer. </publisher>
Reference-contexts: This knowledge must be expressed in terms of a domain specific generic abstraction theory A <ref> (Giordana, Roverso, & Saitta, 1991) </ref>. Definition 2 (Generic Abstraction Theory) A generic abstraction theory is a set of Horn clauses of the form e a a 1 ; : : : ; a k .
Reference: <author> Giunchiglia, F., & Walsh, T. </author> <year> (1992). </year> <title> A theory of abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 57, </volume> <pages> 323-389. </pages>
Reference: <author> Green, C. </author> <year> (1969). </year> <title> Application of theorem proving to problem solving. </title> <booktitle> In Proceedings of IJCAI-69, </booktitle> <pages> pp. </pages> <address> 219-239 Washington, DC. </address>
Reference-contexts: relation to other relevant work in the field. 10.1.1 Theory of Abstraction Within Giunchiglia and Walsh's (1992) theory of abstraction, the Paris approach can be classified as follows: The formal system of the ground space 1 is given by the concrete problem solving domain D c using the situation calculus <ref> (Green, 1969) </ref> for representation. The language of the abstract formal system 2 is given by the language of the abstract problem solving domain D a . However, the operators of D a are not turned into axioms of 2 . Instead, the abstract cases build the axioms of 2 .
Reference: <author> Holte, R., Drummond, C., Perez, M., Zimmer, R., & MacDonald, A. </author> <year> (1994). </year> <title> Searching with abstractions: A unifying framework and new high-performance algorithm. </title> <booktitle> In Proceedings of the 10th Canadian Conference on Artificial Intelligence, </booktitle> <pages> pp. 263-270. </pages> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Recently, Bacchus and Yang (1994) presented an improved method for automatically generating abstraction hierarchies based on a more detailed model of search costs. All these abstraction methods, however, rely on abstraction by dropping sentences of the domain description which is a kind of homomorphic abstraction <ref> (Holte et al., 1994, 1995) </ref>. It has been shown that these kinds of abstractions are highly representation dependent (Holte et al., 1994, 1995). <p> All these abstraction methods, however, rely on abstraction by dropping sentences of the domain description which is a kind of homomorphic abstraction <ref> (Holte et al., 1994, 1995) </ref>. It has been shown that these kinds of abstractions are highly representation dependent (Holte et al., 1994, 1995). For two classical planning domains, different "natural" representations have been analyzed and it turns out that there are several representations for which the classical abstraction techniques do not lead to significantly improved problem solvers (Knoblock, 1994; Holte et al., 1995). <p> Even if this restriction is not completely fulfilled, i.e., backtracking is still required in a few cases, several empirical studies (especially Knoblock, 1991, 1993, 1994) have shown that abstraction can nevertheless lead to performance improvements. Unfortunately, there are also domains and representations of domains <ref> (Holte et al., 1994, 1995) </ref> in which the way abstraction is used in hierarchical problem solving cannot improve problem solving because the derived abstract solutions don't fulfill the above mentioned requirement at all. <p> All hierarchical planners including 96 Building and Refining Abstract Planning Cases Prodigy and Alpine are highly dependent on the representation used, in particular if their strategy is restricted to dropping sentences <ref> (Holte et al., 1994, 1995) </ref>. However, there might be another representation of our domain for which those hierarchical planners can improve performance but we think that our representation is quite "natural" for our domain.
Reference: <author> Holte, R., Mkadmi, T., Zimmer, R., & MacDonald, A. </author> <year> (1995). </year> <title> Speeding up problem solving by abstraction: A graph-oriented approach. </title> <type> Tech. rep. </type> <institution> TR-95-07, Computer Science Dept., University of Ottawa, </institution> <address> Ontario, Canada. </address>
Reference-contexts: This observation is supported by comprehensive artificial examples (see Section 2.1 and 2.2) and a real-world example from the domain of mechanical engineering (see Section 8), further supported by an experiment (see Section 9.2). The recent results reported in <ref> (Holte et al., 1995) </ref> support these observations very well. In general, abstraction is the task of transforming a problem or a solution from a concrete representation into a different abstract representation, while reducing the level of detail (Michalski & Kodratoff, 1990; Giunchiglia & Walsh, 1992; Michalski, 1994).
Reference: <author> Kambhampati, S., & Hendler, J. A. </author> <year> (1992). </year> <title> A validation-structure-based theory of plan modification and reuse. </title> <journal> Artificial Intelligence, </journal> <volume> 55, </volume> <month> 193-258. </month> <title> 114 Building and Refining Abstract Planning Cases Kambhampati, </title> <editor> S., & Kedar, S. </editor> <year> (1994). </year> <title> A unified framework for explanation-based gener-alization of partially ordered partially instantiated plans. </title> <journal> Artificial Intelligence, </journal> <volume> 67, </volume> <pages> 29-70. </pages>
Reference-contexts: Explanation-based approaches generalize the constructed explanations during learning by extensive use of the available domain knowledge and store the result in a control rule (Minton, 1988) or schema (Mooney & DeJong, 1985). In case-based reasoning systems like Priar <ref> (Kambhampati & Hendler, 1992) </ref> or Prodigy/Analogy (Veloso & Carbonell, 1993; Veloso, 1994) cases are usually not explicitly generalized in advance. They are kept fully instantiated in a case library, annotated with the created explanations.
Reference: <author> Knoblock, C. A. </author> <year> (1989). </year> <title> A theory of abstraction for hierachical planning. </title> <booktitle> In Proceedings of the Workshop on Change of Representation and Inductive Bias, </booktitle> <pages> pp. </pages> <address> 81-104 Boston, MA. </address> <publisher> Kluwer. </publisher>
Reference-contexts: Moreover, in the abstracted plan, every concrete operator is abstracted, so that the number of operators is not reduced during abstraction. Thereby this abstraction approach is less powerful than Paris style abstractions. 10.1.3 Alpine's Ordered Monotonic Abstraction Hierarchies Alpine <ref> (Knoblock, 1989, 1990, 1993, 1994) </ref> automatically learns hierarchies of abstraction spaces from a given domain description or from a domain description together with a planning problem. As mentioned several times before, Alpine relies on abstraction by dropping sentences. However, this enables Alpine to generate abstraction hierarchies automatically.
Reference: <author> Knoblock, C. A. </author> <year> (1990). </year> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings Eighth National Conference on Artificial Intelligence, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 923-928 London. </address> <publisher> MIT Press. </publisher>
Reference-contexts: He has shown that in the optimal case, abstraction can reduce the expected search time from exponential to linear. Knoblock has developed an approach to construct a hierarchy of abstraction spaces automatically from a given concrete-level problem solving domain <ref> (Knoblock, 1990, 1993, 1994) </ref>. These so called ordered monotonic abstraction hierarchies (Knoblock, Tenenberg, & Yang, 1991b) have proven useful in many domains. Recently, Bacchus and Yang (1994) presented an improved method for automatically generating abstraction hierarchies based on a more detailed model of search costs.
Reference: <author> Knoblock, C. A. </author> <year> (1991). </year> <title> Search reduction in hierarchical problem solving. </title> <booktitle> In Proceedings of the 9th National Conference on Artificial Intelligence, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 686-691 Anaheim, CA. </address>
Reference-contexts: This avoids backtracking between the solution of each subproblem and consequently cuts down the necessary overall search space. Even if this restriction is not completely fulfilled, i.e., backtracking is still required in a few cases, several empirical studies <ref> (especially Knoblock, 1991, 1993, 1994) </ref> have shown that abstraction can nevertheless lead to performance improvements.
Reference: <author> Knoblock, C. A. </author> <year> (1993). </year> <title> Generating abstraction hierarchies: An automated approach to reducing search in planning. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: As pointed out by Korf, a good abstract solution must lead to mostly independent subproblems of equal size. In classical problem solving, an abstract solution is found by breadth-first or depth-first search using linear <ref> (e.g., Alpine, Knoblock, 1993) </ref> or non-linear (e.g., Abtweak, Yang & Tenenberg, 1990) problem solvers. For these problem solvers, the upward-solution property (Tenenberg, 1988) usually holds, which means that an abstract solution exists if a concrete-level solution exists. <p> Such redundant steps have been removed. Although these solutions are not necessarily shortest solutions, they are nevertheless acceptably short. 9.2 Evaluating Abstraction by Dropping Sentences At first we used the recent version of Alpine <ref> (Knoblock, 1993) </ref> together with Prodigy- 4 (Blythe et al., 1992) to check whether abstraction by dropping sentences can improve problem solving in our domain represented as described in Section 8. Therefore, we used only the concrete problem solving domain as domain theory for Prodigy.
Reference: <author> Knoblock, C. A. </author> <year> (1994). </year> <title> Automatically generating abstractions for planning. </title> <journal> Artificial Intelligence, </journal> <volume> 68, </volume> <pages> 243-302. </pages>
Reference-contexts: An Example Domain: Process Planning in Mechanical Engineering The Paris approach has been successfully tested with toy-domains such as the familiar towers of Hanoi (Simon, 1975). For these domains, hierarchical problem solvers which use a dropping sentence approach have also proven very useful <ref> (Knoblock, 1994) </ref>. This section presents a new example domain we have selected from the field of process planning in mechanical engineering and which really requires a stronger abstraction approach. 13 We have selected the goal of generating a process plan for the production of a rotary-symmetric workpiece on a lathe.
Reference: <author> Knoblock, C. A., Minton, S., & Etzioni, O. </author> <year> (1991a). </year> <title> Integrating abstraction and explanation-based learning in PRODIGY. </title> <booktitle> In Proceedings of the 9th National Conference on Artificial Intelligence, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 541-546 Anaheim, CA. </address>
Reference-contexts: As already noted in (Michalski & Kodratoff, 1990; Michalski, 1994), abstraction and generalization must not be confused. While generalization transforms a description along a set-superset dimension, abstraction transforms a description along a level-of-detail dimension. The only exception is given in <ref> (Knoblock, Minton, & Etzioni, 1991a) </ref> where Alpine's abstractions are combined with EBL component of Prodigy. Thereby, control rules are learned which do not refer to the ground space of problem solving but also to the abstract spaces. These control rules speedup problem solving at the abstract level.
Reference: <author> Knoblock, C. A., Tenenberg, J. D., & Yang, Q. </author> <year> (1991b). </year> <title> Characterizing abstraction hi-erarchies for planning. </title> <booktitle> In Proceedings of the 9th National Conference on Artificial Intelligence, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 692-697 Anaheim, CA. </address>
Reference-contexts: Knoblock has developed an approach to construct a hierarchy of abstraction spaces automatically from a given concrete-level problem solving domain (Knoblock, 1990, 1993, 1994). These so called ordered monotonic abstraction hierarchies <ref> (Knoblock, Tenenberg, & Yang, 1991b) </ref> have proven useful in many domains. Recently, Bacchus and Yang (1994) presented an improved method for automatically generating abstraction hierarchies based on a more detailed model of search costs. <p> fl ; s c G ; Deep 1) (* Continue search with new state *) if search bounded returns success (p) then return success ((o c ) ffi p)) return failure Please note that this kind of refinement is different from the standard notion of refinement in hierarchical problem solving <ref> (Knoblock et al., 1991b) </ref>. This is because there is no strong correspondence between an abstract operator and a possible concrete operator.
Reference: <author> Kolodner, J. L. </author> <year> (1980). </year> <title> Retrieval and Organizational Strategies in Conceptual Memory. </title> <type> Ph.D. thesis, </type> <institution> Yale University. </institution>
Reference: <author> Kolodner, J. L. </author> <year> (1993). </year> <title> Case-based reasoning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Korf, R. E. </author> <year> (1980). </year> <title> Toward a model of representation changes. </title> <journal> Artifical Intelligence, </journal> <volume> 14, </volume> <pages> 41-78. </pages>
Reference: <author> Korf, R. E. </author> <year> (1985a). </year> <title> Depth-first iterative-deepening: An optimal admissible tree search. </title> <journal> Artifical Intelligence, </journal> <volume> 27, </volume> <pages> 97-109. </pages>
Reference-contexts: Thereby the goal of abstraction is to improve the concrete-level problem solver, which performs a brute-force search with a depth-first iterative-deepening search strategy <ref> (Korf, 1985a) </ref> as introduced in Section 7.3. The improvement is determined in terms of problem solving time required to solve a single problem. <p> experiments give strong indications that even a small set of concrete cases for training leads to high improvements in problem solving (see Table 9 to 11). 10.3 Generality of the Achieved Results The reported experiments were performed with a specific base-level problem solver which performs a depth-first iterative-deepening search strategy <ref> (Korf, 1985a) </ref>. However, we strongly believe that the Paris abstractions are also beneficial for other problem solvers using backward-chaining, means-end analysis or nonlinear partial-order planning. As shown in (Veloso & Blythe, 1994), there is not one optimal planning strategy. Different planning strategies usually rely on different commitments during search.
Reference: <author> Korf, R. E. </author> <year> (1985b). </year> <title> Macro-operators: A weak method for learning. </title> <journal> Artifical Intelligence, </journal> <volume> 26, </volume> <pages> 35-77. </pages>
Reference-contexts: If this concrete goal state has been reached the concatenation of concrete partial solutions leads to a complete solution to original problem. This refinement demands for a search procedure which allows an abstract goal specification. All kinds of forward-directed search such as depth-first iterative-deepening <ref> (Korf, 1985b) </ref> or best-first search (Korf, 1993) procedures can be used for this purpose because states are explicitly constructed during search. These states can then be tested to see if they can be abstracted towards the desired goal. In Paris we use depth-first iterative-deepening search described by Algorithm 6.
Reference: <author> Korf, R. E. </author> <year> (1987). </year> <title> Planning as search: A quantitative approach. </title> <journal> Artifical Intelligence, </journal> <volume> 33, </volume> <pages> 65-88. </pages>
Reference-contexts: For hierarchical planning, Korf 's model of abstraction in problem solving <ref> (Korf, 1987) </ref> allows the analysis of reductions in c fl1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Bergmann & Wilke search caused by single and multiple levels of abstraction. <p> overall problem solving time is influenced mainly by the following four factors: independent refinability of abstract operators, goal distance of abstract operators, concrete scope of applicability of abstract operators, and the complexity of the generic abstraction theory. 7.5.1 Independent Refinability of Abstract Operators Following Korf's analysis of hierarchical problem solving <ref> (Korf, 1987) </ref> introduced in Section 2, our plan refinement approach reduces the overall search space from b n to P m i=1 b (fi (i)fi (i1)) . <p> The more abstract operators that can be refined independently in many situations, the higher is the chance that an abstract plan composed of these operators is also refinable. 7.5.2 Goal Distance of Abstract Operators The goal distance <ref> (cf. subgoal distance, Korf, 1987) </ref> is the maximum length of the sequence of concrete operators required to refine a particular abstract operator. The longer the goal distance the larger is the search space required to refine the abstract operator.
Reference: <author> Korf, R. E. </author> <year> (1993). </year> <title> Linear-space best-first search. </title> <journal> Artifical Intelligence, </journal> <volume> 62, </volume> <pages> 41-78. </pages> <note> 115 Bergmann & Wilke Kramer, </note> <author> M., & Unger, C. </author> <year> (1992). </year> <title> Abstracting operators for hierarchical planning. </title> <editor> In Hendler, J. (Ed.), </editor> <booktitle> Proceedings of the International Conference on AI Planning, </booktitle> <pages> pp. 287-288. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: If this concrete goal state has been reached the concatenation of concrete partial solutions leads to a complete solution to original problem. This refinement demands for a search procedure which allows an abstract goal specification. All kinds of forward-directed search such as depth-first iterative-deepening (Korf, 1985b) or best-first search <ref> (Korf, 1993) </ref> procedures can be used for this purpose because states are explicitly constructed during search. These states can then be tested to see if they can be abstracted towards the desired goal. In Paris we use depth-first iterative-deepening search described by Algorithm 6.
Reference: <author> Laird, J., Rosenbloom, P., & Newell, A. </author> <year> (1986). </year> <title> Universal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA. </address>
Reference: <author> Langley, P., & Allen, J. </author> <year> (1993). </year> <title> A unified framework for planning and learning. </title> <editor> In Minton, S. (Ed.), </editor> <title> Machine Learning Methods for Planning, </title> <journal> chap. </journal> <volume> 10, </volume> <pages> pp. 317-350. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Lifschitz, V. </author> <year> (1987). </year> <title> On the semantics of STRIPS. </title> <booktitle> In Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pp. </pages> <address> 1-9 Timberline, Oregon. </address>
Reference-contexts: Following a Strips-oriented representation (Fikes & Nilsson, 1971), the domain of problem solving D = hL; E; O; Ri is described by a first-order language 6 L, a set of essential atomic sentences E of L <ref> (Lifschitz, 1987) </ref>, a set of operators O with related descriptions, and additionally, a set of rules (Horn clauses) R out of L. The essential sentences (which must be atomic) are the only sentences that are used to describe a state.
Reference: <author> Lloyd, J. </author> <year> (1984). </year> <title> Foundations of Logic Programming. </title> <publisher> Springer. </publisher>
Reference-contexts: Full Horn logic is available to describe static rules. The restriction to Horn clauses has the advantage of being powerful while allowing efficient proof construction by using the well known SLD-refutation procedures <ref> (Lloyd, 1984) </ref>. Compared to the Prodigy Description Language (PDL) (Minton, 1988; Blythe et al., 1992) our language does not provide explicit quantification by a specific syntactic construct, but a similar expressiveness can be reached by the implicit quantification in Horn clauses. <p> In the following we will present these phases in more detail. In the first three phases, we require a procedure for determining whether a conjunctive formula is a consequence of a set of Horn clauses. For this purpose, we use a SLD-refutation procedure <ref> (Lloyd, 1984) </ref> which is given a set of Horn clauses (a logic program) C together with conjunctive formula G (a goal clause). The refutation procedure determines a set of answer substitutions such that C ` G holds for all 2 . We write = SLD (C; G).
Reference: <author> McAllester, D., & Rosenblitt, D. </author> <year> (1991). </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the 9th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 634-639. </pages>
Reference-contexts: by the decomposition of the original problem into smaller subproblems is maintained. 7.4 Alternative Search Procedures for Refinement Besides the forward-directed search procedure currently used in Paris backward-directed search as used in means-end analysis (Fikes & Nilsson, 1971) or in nonlinear partial-ordered 82 Building and Refining Abstract Planning Cases planning <ref> (McAllester & Rosenblitt, 1991) </ref> can also be applied for refinement under certain circumstances. Therefore, we would either require a state concretion function or we have to turn the rules of the generic abstraction theory A into virtual concrete operators.
Reference: <author> Michalski, R. S. </author> <year> (1994). </year> <title> Inferential theory of learning as a conceptual basis for multistrategy learning. </title> <editor> In Michalski, R., & Tecuci, G. (Eds.), </editor> <booktitle> Machine Learning: A Multistrategy Approach, </booktitle> <volume> No. 11, chap. 1, </volume> <pages> pp. 3-62. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Michalski, R. S., & Kodratoff, Y. </author> <year> (1990). </year> <title> Research in machine learning: Recent progress, classification of methods, and future directions. </title> <editor> In Kodratoff, Y., & Michalski, R. S. (Eds.), </editor> <booktitle> Machine learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 3, chap. 1, </volume> <pages> pp. 3-30. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Each abstract state must have a corresponding concrete state but not every concrete state must have an associated abstract state. This is due to the fact that abstraction is always a reduction in the level of detail <ref> (Michalski & Kodratoff, 1990) </ref>, in this situation, a reduction in the number of states.
Reference: <author> Minton, S. </author> <year> (1988). </year> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer, </publisher> <address> Boston, MA. </address>
Reference-contexts: Explanation-based approaches generalize the constructed explanations during learning by extensive use of the available domain knowledge and store the result in a control rule <ref> (Minton, 1988) </ref> or schema (Mooney & DeJong, 1985). In case-based reasoning systems like Priar (Kambhampati & Hendler, 1992) or Prodigy/Analogy (Veloso & Carbonell, 1993; Veloso, 1994) cases are usually not explicitly generalized in advance. They are kept fully instantiated in a case library, annotated with the created explanations.
Reference: <author> Minton, S. </author> <year> (1990). </year> <title> Quantitativ results concerning the utility of explanation-based learning. </title> <journal> Artifical Intelligence, </journal> <volume> 42, </volume> <pages> 363-391. </pages>
Reference-contexts: Furthermore, we will address the development of highly efficient retrieval algorithms for abstract cases. As Table 7 shows, the retrieval mechanism has a strong influence on the achieved speedup. Even if the linear retrieval we have presented turned out to be pretty good, we expect a utility problem <ref> (Minton, 1990) </ref> to occur when the size of the case- base grows. Furthermore, a good selection procedure for abstract cases should also use some feedback from the problem solver to evaluate the learned abstract cases based on the speedup they cause.
Reference: <author> Minton, S., Carbonell, J. G., Knoblock, C., Kuokka, D. R., Etzioni, O., & Gil, Y. </author> <year> (1989). </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 63-118. </pages>
Reference-contexts: As a source for learning, we assume a set of concrete planning cases, each of which consists of a problem statement together with a related solution. As is the case in Prodigy <ref> (Minton et al., 1989) </ref>, we only consider sequential plans, i.e., plans with totally ordered operators. The planning cases we assume do not include a problem solving trace as for example the problem solving cases in Prodigy/Analogy (Veloso, 1992; Veloso & Carbonell, 1993; Veloso, 1994).
Reference: <author> Minton, S., & Zweben, M. </author> <year> (1993). </year> <title> Learning, planning and scheduling: An overview. </title> <editor> In Minton, S. (Ed.), </editor> <title> Machine Learning Methods for Planning, </title> <journal> chap. </journal> <volume> 1, </volume> <pages> pp. 1-30. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. </author> <year> (1986). </year> <title> Explanation-based general-ization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 47-80. </pages>
Reference: <author> Mooney, R. J. </author> <year> (1988). </year> <title> Generalizing the order of operators in macro-operators. </title> <editor> In Laird, J. (Ed.), </editor> <booktitle> Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 270-283 San Mateo, CA. </address> <note> Morgan Kaufmann. 116 Building and Refining Abstract Planning Cases Mooney, </note> <author> R. J., & DeJong, G. F. </author> <year> (1985). </year> <title> Learning schemata for natural language processing. </title> <booktitle> In Proceedings of IJCAI, </booktitle> <pages> pp. </pages> <address> 681-687 Los Angeles, CA. </address>
Reference: <author> Mozetic, I. </author> <year> (1990). </year> <title> Abstraction in model-based diagnosis. </title> <booktitle> In AAAI Workshop on Automatic Generation of Approximations and Abstractions, </booktitle> <pages> pp. </pages> <address> 64-75 Boston, MA. </address>
Reference-contexts: (1992) have presented a comprehensive formal framework for abstraction and a comparison of the different abstraction approaches from theorem proving (Plaisted, 1981, 1986; Tenenberg, 1987), planning (Newell & Simon, 1972; Sacerdoti, 1974, 1977; Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock, 1989, 1994), and model based diagnosis <ref> (Mozetic, 1990) </ref>. For hierarchical planning, Korf 's model of abstraction in problem solving (Korf, 1987) allows the analysis of reductions in c fl1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Bergmann & Wilke search caused by single and multiple levels of abstraction.
Reference: <author> Newell, A., & Simon, H. </author> <year> (1972). </year> <title> Human Problem Solving. </title> <publisher> Prentice-Hall Englewood Cliffs, </publisher> <address> NJ. </address>
Reference-contexts: Therefore we will define a formal representation for problem solving domains. We want to assume that problem solving in general can be viewed as transforming an initial state into a final state by using a sequence of operators <ref> (Newell & Simon, 1972) </ref>.
Reference: <author> Paulokat, J., & Wess, S. </author> <year> (1994). </year> <title> Planning for machining workpieces with a partial-order, nonlinear planner. In AAAI-Fall Symposium on Planning and Learning: On to Real Applications. </title>
Reference-contexts: One restriction is that we can only represent workpieces with right-angled contour elements. For example, a conical contour cannot be represented. Many different cutting and chucking tools are available in real-life process planning. We 13. This domain was adapted from the CaPlan-System <ref> (Paulokat & Wess, 1994) </ref>, developed at the Univer <br>- sity of Kaiserslautern. 14. Note that this figure shows a 2-dimensional drawing of the 3-dimensional workpiece. The measure 1 in. equals 25.4 mm. 85 Bergmann & Wilke have restricted ourselves to a single chucking tool and three different cutting tools.
Reference: <author> Perez, M., & Carbonell, J. </author> <year> (1993). </year> <title> Automated acquisition of control knowledge to improve the quality of plans. </title> <type> Tech. rep. </type> <institution> CMU-CS-93-142, Carnegie Mellon University. </institution>
Reference-contexts: The solution length can be used as a very simple criterion to determine the quality of a solution. However, in general the quality of a solution should reflect the execution costs of a plan, the plans robustness, or certain user preferences <ref> (Perez & Carbonell, 1993) </ref>.
Reference: <author> Pews, G., & Wess, S. </author> <year> (1993). </year> <title> Combining model-based approaches and case-based reasoning for similarity assessment and case adaptation in diagnositc applications. </title> <editor> In Richter, M. M., Wess, S., Althoff, K., & Maurer, F. (Eds.), </editor> <booktitle> Preprints of the First European Workshop on Case-Based Reasoning (EWCBR-93), </booktitle> <volume> Vol. II, </volume> <pages> pp. 325-328. </pages> <institution> University of Kaiserslautern, Germany. </institution>
Reference: <author> Plaisted, D. </author> <year> (1981). </year> <title> Theorem proving with abstraction. </title> <journal> Artifical Intelligence, </journal> <volume> 16, </volume> <pages> 47-108. </pages>
Reference: <author> Plaisted, D. </author> <year> (1986). </year> <title> Abstraction using generalization functions. </title> <booktitle> In Proceedings of the 8th Conference on Automated Deduction, </booktitle> <volume> Vol. 16, </volume> <pages> pp. 365-376. </pages>
Reference: <author> Rosenbloom, P., & Laird, J. </author> <year> (1986). </year> <title> Mapping explanation-based learning onto SOAR. </title> <booktitle> In Proceedings National Conference on Artificial Intelligence, Vol. </booktitle> <address> 2 Philadelphia, PA. </address>
Reference: <author> Sacerdoti, E. </author> <year> (1974). </year> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5, </volume> <pages> 115-135. </pages>
Reference: <author> Sacerdoti, E. </author> <year> (1977). </year> <title> A Structure for Plans and Behavior, </title> <booktitle> Vol. 5. </booktitle> <address> American-Elsevier, New York. </address>
Reference: <author> Schank, R. C. </author> <year> (1982). </year> <title> Dynamic Memory: A Theory of Learning in Computers and People. </title> <publisher> Cambridge University Press, </publisher> <address> New York. </address>
Reference: <author> Schmidt, G. </author> <year> (1994). </year> <title> Modellbasierte, interaktive Wissensakquisition und Dokumentation von Domaenenwissen. </title> <type> Ph.D. thesis, </type> <institution> University of Kaiserslautern, Germany. </institution>
Reference: <author> Schmidt, G., & Zickwolff, M. </author> <year> (1992). </year> <title> Cases, models and integrated knowledge acquisition to formalize operators in manufacturing. </title> <booktitle> In Proceedings of the 7th Knowledge Acquisition for Knowledge-based Systems Workshop (Banff </booktitle> ). 
Reference: <author> Shavlik, J., & O'Rorke, P. </author> <year> (1993). </year> <title> Empirically evluation EBL. </title> <booktitle> In Investigating ExplanationBased Learning, </booktitle> <volume> Vol. 5, chap. 7, </volume> <pages> pp. 222-294. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Simon, H. </author> <year> (1975). </year> <title> The functional equivalence of problem solving skills. </title> <journal> Cognitive Psychology, </journal> <volume> 7, </volume> <pages> 268-288. </pages>
Reference-contexts: An Example Domain: Process Planning in Mechanical Engineering The Paris approach has been successfully tested with toy-domains such as the familiar towers of Hanoi <ref> (Simon, 1975) </ref>. For these domains, hierarchical problem solvers which use a dropping sentence approach have also proven very useful (Knoblock, 1994).
Reference: <author> Bergmann & Wilke Tenenberg, J. </author> <year> (1987). </year> <title> Preserving consistency across abstraction mappings. In McDermott, </title> <editor> J. (Ed.), </editor> <booktitle> Proceedings of the 10th International Conference on Artifical Intelligence, </booktitle> <pages> pp. </pages> <address> 1011-1014 Los Altos, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tenenberg, J. </author> <year> (1988). </year> <title> Abstraction in Planning. </title> <type> Ph.D. thesis, </type> <institution> Computer Science Department, University of Rochester, </institution> <address> New York. </address>
Reference-contexts: In classical problem solving, an abstract solution is found by breadth-first or depth-first search using linear (e.g., Alpine, Knoblock, 1993) or non-linear (e.g., Abtweak, Yang & Tenenberg, 1990) problem solvers. For these problem solvers, the upward-solution property <ref> (Tenenberg, 1988) </ref> usually holds, which means that an abstract solution exists if a concrete-level solution exists. Usually, these problem solvers find an arbitrary abstract solution (e.g., the shortest possible solution). <p> Even if applicability is a necessary precondition for refinability it does not formally guarantee refinability, since the downward solution property <ref> (Tenenberg, 1988) </ref>, which states that every abstract solution can be refined, is a too strong requirement to hold in general for our abstraction methodology. <p> The second weakness of most hierarchical problem solvers is that they usually compute arbitrary abstract solutions and not solutions which have a high chance of being refinable at the next concrete level. Although the upward solution property <ref> (Tenenberg, 1988) </ref> guarantees that a refin- able abstract solution exists, it is not guaranteed that the problem solver finds this abstract solution (e.g., see Section 2.2). Problem solvers are not even heuristically guided towards refinable abstract solutions.
Reference: <author> Unruh, A., & Rosenbloom, P. </author> <year> (1989). </year> <title> Abstraction in problem solving and learning. </title> <booktitle> In Proceedings of the International Joint Conference on Artifical Intelligence-89, </booktitle> <pages> pp. </pages> <address> 590-595 Detroit, MI. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Veloso, M. M. </author> <year> (1992). </year> <title> Learning by analogical reasoning in general problem solving. </title> <type> Ph.D. thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: Because such quality measures are very difficult to assess, in particular in our manufacturing domain, we rely on this simple criterion also used for evaluating the quality of solutions in Prodigy/Analogy <ref> (Veloso, 1992) </ref>. 9.5.1 Experimental Setting We have analyzed the solutions computed in the previous set of experiments to assess the quality of the solutions produced by Paris.
Reference: <author> Veloso, M. M. </author> <year> (1994). </year> <title> PRODIGY/ANALOGY: Analogical reasoning in general problem solving. </title> <editor> In Richer, M., Wess, S., Althoff, K., & Maurer, F. (Eds.), </editor> <booktitle> Topics in CaseBased Reasoning, </booktitle> <pages> pp. 33-52. </pages> <booktitle> Lecture Notes in AI, </booktitle> <volume> Vol. 837, </volume> <publisher> Springer. </publisher>
Reference-contexts: However, we strongly believe that the Paris abstractions are also beneficial for other problem solvers using backward-chaining, means-end analysis or nonlinear partial-order planning. As shown in <ref> (Veloso & Blythe, 1994) </ref>, there is not one optimal planning strategy. Different planning strategies usually rely on different commitments during search. Each strategy can be useful in one domain but may be worse in others.
Reference: <author> Veloso, M. M., & Blythe, J. </author> <year> (1994). </year> <title> Linkability: Examining causal link commitments in partial-order planning. </title> <booktitle> In Proceedings of the 2nd International Conference on Planning for AI Systems AIPS-94. </booktitle>
Reference-contexts: However, we strongly believe that the Paris abstractions are also beneficial for other problem solvers using backward-chaining, means-end analysis or nonlinear partial-order planning. As shown in <ref> (Veloso & Blythe, 1994) </ref>, there is not one optimal planning strategy. Different planning strategies usually rely on different commitments during search. Each strategy can be useful in one domain but may be worse in others.
Reference: <author> Veloso, M. M., & Carbonell, J. G. </author> <year> (1988). </year> <title> Integrating derivational analogy into a general problem solving architecture. </title> <editor> In Minton, S. (Ed.), </editor> <booktitle> Proceedings of the First Workshop on Case-Based Reasoning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Veloso, M. M., & Carbonell, J. G. </author> <year> (1993). </year> <title> Towards scaling up machine learning: A case study with derivational analogy in PRODIGY. </title> <editor> In Minton, S. (Ed.), </editor> <title> Machine Learning Methods for Planning, </title> <journal> chap. </journal> <volume> 8, </volume> <pages> pp. 233-272. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Wilke, W. </author> <year> (1993). </year> <title> Entwurf und Implementierung eines Algorithmus zum wissensintensiven Lernen von Planabstraktionen nach der PABS-Methode. </title> <institution> Projektarbeit, Universitat Kaiserslautern. </institution>
Reference: <author> Wilke, W. </author> <year> (1994). </year> <title> Entwurf, Implementierung und experimentelle Bewertung von Auswahlverfahren fur abstrakte Plane im fallbasierten Planungssystem PARIS. </title> <type> Master's thesis, </type> <institution> University of Kaiserslautern, Germany. </institution>
Reference: <author> Wilkins, D. </author> <year> (1988). </year> <title> Practical Planning: Extending the classical AI planning paradigm. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In problem solving, such a new abstract representation language must consist of completely new sentences and operators and not only of a subset of the sentences and operators of the concrete language. To our knowledge, Sipe <ref> (Wilkins, 1988) </ref> is the only planning system which currently allows the change of representation language across different levels of abstraction. However, a general abstraction methodology which allows efficient algorithms for abstraction and refinement has not yet been developed. <p> However, this assumption does not hold in all domains. For example, in many real world domains, certain events need to be counted, e.g., when transporting a certain number of 1. Only Tenenberg's (1988) abstraction by analogical mappings and the planning system Sipe <ref> (Wilkins, 1988) </ref> contains first approaches that allow a change of representation language. 56 Building and Refining Abstract Planning Cases containers from one location to another.
Reference: <author> Yang, Q., & Tenenberg, J. </author> <year> (1990). </year> <title> Abtweak: Abstracting a nonlinear, least commitment planner. </title> <booktitle> In Proceedings of the 8th National Conference on Aritificial Intelligence, </booktitle> <pages> pp. </pages> <address> 204-209 Boston, MA. </address> <month> 118 </month>
Reference-contexts: As pointed out by Korf, a good abstract solution must lead to mostly independent subproblems of equal size. In classical problem solving, an abstract solution is found by breadth-first or depth-first search using linear (e.g., Alpine, Knoblock, 1993) or non-linear <ref> (e.g., Abtweak, Yang & Tenenberg, 1990) </ref> problem solvers. For these problem solvers, the upward-solution property (Tenenberg, 1988) usually holds, which means that an abstract solution exists if a concrete-level solution exists. Usually, these problem solvers find an arbitrary abstract solution (e.g., the shortest possible solution).
References-found: 78

