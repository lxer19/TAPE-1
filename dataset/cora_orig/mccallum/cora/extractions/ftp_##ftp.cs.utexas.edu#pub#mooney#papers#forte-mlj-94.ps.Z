URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/forte-mlj-94.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: bradley@lia.di.epfl.ch  mooney@cs.utexas.edu  
Title: Automated Refinement of First-Order Horn-Clause Domain Theories  
Author: BRADLEY L. RICHARDS RAYMOND J. MOONEY Editor: Steve Minton 
Keyword: Theory Revision, Knowledge Refinement, Inductive Logic Programming  
Address: Switzerland  Austin, Texas, 78712  
Affiliation: Artificial Intelligence Laboratory, Swiss Federal Institute of Technology, Lausanne,  Department of Computer Sciences, University of Texas,  
Note: Machine Learning, 1-39 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: Knowledge acquisition is a difficult, error-prone, and time-consuming task. The task of automatically improving an existing knowledge base using learning methods is addressed by the class of systems performing theory refinement. This paper presents a system, Forte (First-Order Revision of Theories from Examples), which refines first-order Horn-clause theories by integrating a variety of different revision techniques into a coherent whole. Forte uses these techniques within a hill-climbing framework, guided by a global heuristic. It identifies possible errors in the theory and calls on a library of operators to develop possible revisions. The best revision is implemented, and the process repeats until no further revisions are possible. Operators are drawn from a variety of sources, including propositional theory refinement, first-order induction, and inverse resolution. Forte is demonstrated in several domains, including logic programming and qualitative modelling. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aben, M., & van Someren, M. </author> <year> (1990). </year> <title> Heuristic Refinement of Logic Programs. </title> <booktitle> Proceedings of the Ninth European Conference on Artificial Intelligence (pp. </booktitle> <pages> 7-12). </pages> <address> London: </address> <publisher> Pitman. </publisher>
Reference: <author> Bain, M., & Muggleton, S. </author> <year> (1992a). </year> <title> Non-monotonic learning. </title> <editor> In S. Muggleton (Ed.), </editor> <booktitle> Inductive Logic Programming. </booktitle> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Bain, M., & Muggleton, S. </author> <year> (1992b). </year> <title> Experiments in Non-monotonic First-Order Induction. </title> <booktitle> In S. </booktitle>
Reference: <editor> Muggleton (Ed.), </editor> <booktitle> Inductive Logic Programming. </booktitle> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Bergadano, F., & Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <booktitle> Proceedings of the Fifth International Workshop on Machine Learning (pp. </booktitle> <pages> 305-317). </pages> <address> San Mateo, </address> <note> CA: </note> <author> Morgan Kaufman. </author> <title> REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 37 Bratko, I. </title> <booktitle> (1991). Prolog programming for artificial intelligence. </booktitle> <address> Reading: MA, </address> <publisher> Addison Wesley. </publisher>
Reference-contexts: Unlike MIS and Clint, Forte automatically revises theories without any user interaction. 32 B. RICHARDS AND R. MOONEY A number of recent knowledge-based learning systems use a first-order domain theory to bias the learning of an operational concept description but do not modify the actual domain theory. ML-Smart <ref> (Bergadano & Giordana, 1988) </ref> was the first system to take this approach. Focl (Pazzani & Kibler, 1992) is a more recent approach based on Foil. Focl successively operationalizes a theory by either including portions of the domain theory or adding new literals via induction.
Reference: <author> Bratko, I., Mozetic, I., & Lavrac, N. </author> <year> (1989) </year> <month> KARDIO: </month> <title> A study in deep and qualitative knowledge for expert systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Bratko, I., Muggleton, S., & Varsek, A. </author> <year> (1991). </year> <title> Learning qualitative models of dynamic systems. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 385-388). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Cain, T. </author> <year> (1991). </year> <title> The DUCTOR: A theory revision system for propositional domains. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 485-489). </pages> <address> San Mateo: CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Unlike Forte, Either does not hill-climb and is guaranteed to fit an arbitrary theory to any set of noise-free data. However, Either's approach of computing all abductive proofs of unprovable positive examples was deemed computationally intractable for first-order theories. RTLS (Ginsberg, 1990), Kbann (Towell & Shavlik, 1993), Ductor <ref> (Cain, 1991) </ref>, and Krust (Craw & Sleeman, 1991) are other theory refinement systems that are restricted to propositional theories. Of these, Krust is most closely related to Forte, since it follows the approach of generating many possible revisions to theories, and then choosing among them based on their performance.
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 102-110). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Focl successively operationalizes a theory by either including portions of the domain theory or adding new literals via induction. The addition that provides the best information gain is chosen at each point. This general approach is at a disadvantage when the initial theory is missing lower-level rules <ref> (Cohen, 1992) </ref> since it must learn a completely new disjunct at the top level. Also, it can unnecessarily eliminate large portions of the theory that are consistent with the data but happen not to be needed to explain the training examples. <p> Focl has been used as the basis for an interactive theory refinement system, KR-Focl (Pazzani & Brunk, 1990). However, this system requires the user to determine where to make most theory changes. Grendel <ref> (Cohen, 1992) </ref> is a recent system to use domain knowledge to guide induction. Grendel is a Foil-like inductive learner that allows the user to provide an explicit bias in the form of a grammar.
Reference: <author> Cohen, W. </author> <year> (1993). </year> <title> Pac-learning a restricted class of recursive logic programs. </title> <booktitle> Proceedings of the Eleventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 86-92). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Coiera, E. </author> <year> (1989). </year> <title> Generating qualitative models from example behaviors. </title> <type> Technical Report DCS 8901, </type> <institution> Department of Computer Science, University of New South Wales. </institution>
Reference: <author> Craw, S., & Sleeman, D. </author> <year> (1991). </year> <title> The flexibility of speculative refinement. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 28-32). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Although Either is limited to propositional domains, it is the conceptual predecessor of Forte. 4 B. RICHARDS AND R. MOONEY Krust <ref> (Craw & Sleeman, 1991) </ref> generates a wide array of possible revisions to a knowledge base, and then filters and ranks the revisions to choose the most suitable one. Much of the filtering depends on the existence of certain canonical "chestnut" examples, which must be identified by a human expert. <p> However, Either's approach of computing all abductive proofs of unprovable positive examples was deemed computationally intractable for first-order theories. RTLS (Ginsberg, 1990), Kbann (Towell & Shavlik, 1993), Ductor (Cain, 1991), and Krust <ref> (Craw & Sleeman, 1991) </ref> are other theory refinement systems that are restricted to propositional theories. Of these, Krust is most closely related to Forte, since it follows the approach of generating many possible revisions to theories, and then choosing among them based on their performance.
Reference: <author> DeRaedt, L., & Bruynooghe, M. </author> <year> (1992). </year> <title> Interactive concept learning and constructive induction by analogy. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <pages> 107-150. </pages>
Reference-contexts: His Prolog debugging system, PDS6, required even more interaction with the user. It required the user to judge the correctness of predicate calls, determine which clause in a predicate to change, and to actually write missing clauses. Other interactive systems include Marvin (Sammut & Banerji, 1986) and Clint <ref> (DeRaedt & Bruynooghe, 1992) </ref>. Clint generalizes and specializes theories and also creates new predicates via analogy. Clint's revisions only include adding and removing clauses; it does not attempt to modify existing clauses. Unlike MIS and Clint, Forte automatically revises theories without any user interaction. 32 B. RICHARDS AND R.
Reference: <author> Falkenhainer, B. </author> <year> (1990). </year> <title> A unified approach to explanation and theory formation. </title> <editor> In J. Shrager and P. Langley (Eds.), </editor> <title> Computational Models of Scientific Discovery and Theory Formation. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Golem also requires extensionally defined background knowledge, whereas Forte's fundamental domain theory allows background knowledge to be defined intensionally. There has also been some recent work in constructing and revising models based on Forbus's (1984) qualitative process theory (Falkenhainer & Rajamoney, 1988). However this work uses analogy <ref> (Falkenhainer, 1990) </ref> and experimentation (Raja-money, 1990) rather than induction from a fixed set of behaviors. 9. Future Work Although Forte performs hill-climbing search, it considers a large number of operations at each step.
Reference: <author> Falkenhainer, B., & Forbus, K. </author> <year> (1991). </year> <title> Compositional modelling: Finding the right model for the job. </title> <journal> Artificial Intelligence, </journal> <volume> 51, </volume> <pages> 95-144. </pages>
Reference-contexts: Qualitative models can be given to simulators like Qsim (Kuipers, 1986) to determine all possible qualitative behaviors of the system. Traditionally, qualitative models have been constructed by hand. This works for simple, well-understood systems. For complex systems, the approach of compositional modelling <ref> (Falkenhainer & Forbus, 1991) </ref> allows a system model to be built up from predefined components. Although this makes constructing models easier, it still requires the user to understand the system being modelled. Often, however, users want a model precisely because the target system is not well-understood.
Reference: <author> Falkenhainer, B., & Rajamoney, S. </author> <year> (1988). </year> <title> The interdependencies of theory formation, revision, and experimentation. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning (pp. </booktitle> <pages> 353-366). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Golem also requires extensionally defined background knowledge, whereas Forte's fundamental domain theory allows background knowledge to be defined intensionally. There has also been some recent work in constructing and revising models based on Forbus's (1984) qualitative process theory <ref> (Falkenhainer & Rajamoney, 1988) </ref>. However this work uses analogy (Falkenhainer, 1990) and experimentation (Raja-money, 1990) rather than induction from a fixed set of behaviors. 9. Future Work Although Forte performs hill-climbing search, it considers a large number of operations at each step.
Reference: <author> Gardenfors, P. </author> <year> (1992) </year> <month> (Ed.). </month> <title> Belief Revision. </title> <address> Cambridge, England: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Relational pathfinding uses spreading activation and can specialize paths by adding additional literals. 8.3. Belief Revision Research in belief revision addresses the problem of finding a minimal retraction of beliefs required to consistently incorporate a new belief <ref> (Gardenfors, 1992) </ref>. However this work does not address the inductive problem of generalizing a theory or specializing it by adding constraints (e.g., by adding additional antecedents to rules).
Reference: <author> Ginsberg, A. </author> <year> (1990). </year> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 777-782). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Unlike Forte, Either does not hill-climb and is guaranteed to fit an arbitrary theory to any set of noise-free data. However, Either's approach of computing all abductive proofs of unprovable positive examples was deemed computationally intractable for first-order theories. RTLS <ref> (Ginsberg, 1990) </ref>, Kbann (Towell & Shavlik, 1993), Ductor (Cain, 1991), and Krust (Craw & Sleeman, 1991) are other theory refinement systems that are restricted to propositional theories. <p> Consequently, its range of revisions is limited compared to Forte. Rx (Tangkitvanich & Shimura, 1992) first produces a revised opera REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 33 tional definition and then translates this into changes to the original theory (as in the RTLS propositional system <ref> (Ginsberg, 1990) </ref>). The basic learning mechanism is very similar to Focl, and therefore has some of the same problems discussed above.
Reference: <author> Ginsberg, A., & Weiss, S. and Politakis, P. </author> <year> (1988). </year> <title> Automatic knowledge-base refinement for classification systems. </title> <journal> Artificial Intelligence, </journal> <volume> 35, </volume> <pages> 197-226. </pages>
Reference-contexts: The goal of this work is to automate the laborious process of knowledge-base refinement and thereby speed the development of knowledge-based systems <ref> (Ginsberg, Weiss, & Politakis, 1988) </ref>. Theory refinement normally integrates analytical and empirical machine learning methods in an attempt to leverage two sources of information: approximate rules obtained from an expert or a textbook, and empirical data on actual problems.
Reference: <author> Hinton, G.E. </author> <year> (1986). </year> <title> Learning distributed representations of concepts. </title> <booktitle> Proceedings of the Eighth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 1-12). </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Kay, H. </author> <year> (1992). </year> <title> A qualitative model of the space shuttle reaction control system. </title> <type> Technical Report AI92-188, </type> <institution> Artificial Intelligence Laboratory, University of Texas at Austin. </institution>
Reference-contexts: The netflow variables are reintroduced by relational pathfinding, as a way of satisfying the requirement (enforced by the revision verifier) that the model be connected. 7.3. Reaction Control System The Space Shuttle Reaction Control System (RCS) <ref> (Kay, 1992) </ref> is substantially more complex than the system of cascaded tanks, and provides a more realistic test of Forte's capabilities in this domain. The RCS consists of a number of identical, parallel components; our test domain consisted of one of these components with its valves in fixed positions.
Reference: <author> Kijsirikul, B., Numao, M., & Shimura, M. </author> <year> (1992). </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 44-49). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Kuipers, B. </author> <year> (1986). </year> <title> Qualitative simulation. </title> <journal> Artificial Intelligence, </journal> <volume> 29, </volume> <pages> 289-338. </pages>
Reference-contexts: Application: Qualitative Modelling To demonstrate Forte's ability to work in diverse domains, we have also applied it to qualitative modelling. When supplied with appropriate domain knowledge, through the fundamental domain theory and the revision verifier, Forte is able to synthesize and revise qualitative models suitable for use by Qsim <ref> (Kuipers, 1986) </ref>. 7.1. Background Qualitative modelling uses constraint-based models to predict and explain the behavior of dynamic systems in intuitive terms. <p> For example, when trying to understand the effect of heating a pot of water, it may be more useful to simply know that the pot may boil over rather than to understand the numerical thermodynamic equations. Qualitative models can be given to simulators like Qsim <ref> (Kuipers, 1986) </ref> to determine all possible qualitative behaviors of the system. Traditionally, qualitative models have been constructed by hand. This works for simple, well-understood systems. For complex systems, the approach of compositional modelling (Falkenhainer & Forbus, 1991) allows a system model to be built up from predefined components.
Reference: <author> Kuipers, B. </author> <year> (1989). </year> <title> Qualitative reasoning: Modelling and simulation with incomplete knowledge Automatica, </title> <booktitle> 25, </booktitle> <pages> 571-585. </pages>
Reference: <author> Langley, P. </author> <year> (1980). </year> <title> Finding common paths as a learning mechanism. </title> <note> CIP Working Paper 419, Carnegie-Mellon University. </note>
Reference: <author> Lapointe, S., & Matwin, S. </author> <year> (1992). </year> <title> Sub-unification: A tool for efficient induction of recursive programs. </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 273-281). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Lloyd, J.W. </author> <year> (1987). </year> <title> Foundations of logic programming, second, extended edition. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: A definite program clause is a clause of the form ff fi 1 ; : : : fi n where ff; fi 1 ; : : : fi n are atomic formulae <ref> (Lloyd, 1987) </ref>. 3. Mooney (in press) presents a formal definition of minimal change based on the notion of syntactic distance and shows that it guarantees convergence to a probably approximately correct (PAC) theory if the initial theory is guaranteed to be within a fixed distance of the true theory.
Reference: <author> Mahoney, J., & Mooney, R. </author> <year> (1993). </year> <title> Combining connectionist and symbolic learning to refine certainty-factor rule bases. </title> <journal> Connection Science, </journal> <volume> 5, </volume> <pages> 339-364. </pages> <note> 38 B. </note> <author> RICHARDS AND R. MOONEY Mooney, </author> <title> R.J. (in press). A preliminary PAC analysis of theory revision. </title> <editor> In T. Petsche, S. Judd, and S. Hanson (Eds.) </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Vol. </volume> <pages> 3. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In many domains, some form of uncertain or probabilistic reasoning is desirable; however, current theory refinement systems like Forte are restricted to purely logical domain theories. Rapture <ref> (Mahoney & Mooney, 1993) </ref> is a recent system that combines connectionist and symbolic methods to refine propositional certainty-factor rule bases (Shortliffe & Buchanan, 1975). However, its basic approach should be applicable to first-order theories. 10.
Reference: <author> Muggleton, S. </author> <year> (1992a). </year> <title> Inductive logic programming. </title> <editor> In S. Muggleton (Ed.), </editor> <booktitle> Inductive Logic Programming (pp. </booktitle> <pages> 3-27). </pages> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Muggleton, S. </author> <year> (1992b). </year> <title> Inverting implication. </title> <booktitle> Proceedings of the Second International Workshop on Inductive Logic Programming. </booktitle> <address> Tokyo. </address>
Reference: <author> Muggleton, S., & Buntine, W. </author> <year> (1988). </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning (pp. </booktitle> <pages> 339-352). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Forte's revision operators include methods from propositional theory refinement (Ourston & Mooney, 1990), first order induction (Quinlan, 1990), and inverse resolution <ref> (Muggleton & Buntine, 1988) </ref>. The system has successfully been used to debug Prolog programs collected from students in a course on programming languages, to debug a decision-tree induction program, and to revise a qualitative model of a portion of the Reaction Control System of the NASA Space Shuttle. <p> It is important to note that, when working in first-order logic, inverse resolution operations must take into account variable substitutions, so that any literal appearing in the goal or input clause is (non-strictly) more general than the corresponding literal in the resolvent. Cigol <ref> (Muggleton & Buntine, 1988) </ref> used this technique to learn first-order theories from examples; however, it required the user to interactively verify certain steps. <p> Another major problem is that Forte, like many ILP systems, cannot invent new predicates. The invention of new recursive predicates is a particularly difficult and important problem. Using general inverse resolution methods <ref> (Muggleton & Buntine, 1988) </ref> to invent new predicates without an oracle is computationally intractable.
Reference: <author> Muggleton, S & Feng, C. </author> <year> (1992). </year> <title> Efficient induction of logic programs. </title> <editor> In S. Muggleton (Ed.) </editor> <booktitle> Inductive Logic Programming (pp. </booktitle> <pages> 281-298). </pages> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference-contexts: This more powerful representation language allows Forte to work in domains involving relations, such as computer programming, qualitative modelling, and natural language processing. Since it uses first-order Horn-clauses as a representation language, Forte can be viewed as part of the growing body of work in inductive logic programming (ILP) <ref> (Muggleton, 1992) </ref>. However, existing ILP research has primarily focussed on generalizing an existing theory by adding clauses, which does not address the issue of modifying incorrect knowledge. <p> Cigol (Muggleton & Buntine, 1988) used this technique to learn first-order theories from examples; however, it required the user to interactively verify certain steps. Golem <ref> (Muggleton & Feng, 1992) </ref> is a more efficient, automated induction system based on Plotkin's (1971) framework of relative least-general generalization (RLGG), which Muggleton (1992a) shows to be closely related to inverse reso REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 5 Initial Theory ? Language Bias - Training Set - Revised Theory - Theory <p> Also, revisions are evaluated based on rule-belief factors which ignore the difference between specialization and generalization errors; hence, a specialization error can be used to justify further specialization of a rule. 8.2. First-Order Learning Most work in inductive logic programming <ref> (Muggleton, 1992) </ref> concerns generalizing an existing first-order Horn-clause theory by adding clauses, but does not address the problems of generalizing existing clauses or removing or specializing incorrect clauses.
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 815-820). </pages> <address> Cambridge, MA: </address> <publisher> MIT press. </publisher>
Reference-contexts: Forte's revision operators include methods from propositional theory refinement <ref> (Ourston & Mooney, 1990) </ref>, first order induction (Quinlan, 1990), and inverse resolution (Muggleton & Buntine, 1988).
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1991). </year> <title> Improving shared rules in multiple category domain theories. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 534-538). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Ourston, D., & Mooney, R. </author> <title> (in press). Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence. </journal>
Reference: <author> Pazzani, M., & Brunk, C. </author> <year> (1990). </year> <title> Detecting and correcting errors in rule-based expert systems: An integration of empirical and explanation-based learning. </title> <booktitle> Proceedings of the 5th Knowledge Acquisition for Knowledge-Based Systems Workshop. </booktitle>
Reference-contexts: By contrast, Forte preserves as much of the initial theory as possible and can learn rules at any level in the theory. Focl has been used as the basis for an interactive theory refinement system, KR-Focl <ref> (Pazzani & Brunk, 1990) </ref>. However, this system requires the user to determine where to make most theory changes. Grendel (Cohen, 1992) is a recent system to use domain knowledge to guide induction.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of prior knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: RICHARDS AND R. MOONEY A number of recent knowledge-based learning systems use a first-order domain theory to bias the learning of an operational concept description but do not modify the actual domain theory. ML-Smart (Bergadano & Giordana, 1988) was the first system to take this approach. Focl <ref> (Pazzani & Kibler, 1992) </ref> is a more recent approach based on Foil. Focl successively operationalizes a theory by either including portions of the domain theory or adding new literals via induction. The addition that provides the best information gain is chosen at each point.
Reference: <author> Plotkin, G. D. </author> <year> (1971). </year> <title> Automatic Methods of Inductive Inference. </title> <type> Ph.D. Thesis. </type> <institution> Edinburgh University, Edinburgh, </institution> <address> Scotland. </address>
Reference: <author> Quillian, </author> <title> M.R. (1968). Semantic memory. </title> <editor> In M. Minsky (Ed.) </editor> <booktitle> Semantic Information Processing. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Quinlan, J.R. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266. </pages>
Reference-contexts: Forte's revision operators include methods from propositional theory refinement (Ourston & Mooney, 1990), first order induction <ref> (Quinlan, 1990) </ref>, and inverse resolution (Muggleton & Buntine, 1988). <p> Forte's overall approach is similar to Krust's, in that it generates a number of possible revisions, and then selects the one which performs best. 3.2. Top-Down First-Order Induction Foil <ref> (Quinlan, 1990) </ref> is a recent, efficient algorithm for inducing first-order Horn-clause rules. Its outer loop is a greedy covering algorithm that learns one clause at a time. Each clause is constructed to maximize coverage of positive examples while excluding all negatives. <p> Thus, it replaces the uncle rule with the new rule uncle (A, B) :- gender (A, male), aunt uncle (A, B). 5. Experimental Results in the Family Domain In this section, we examine Forte's performance in the domain of family relationships, a standard benchmark problem in relational learning <ref> (Quinlan, 1990) </ref>. Richards (1992) also presents results on another standard benchmark problem, illegal chess positions for king-rook-king endgames. The results indicate that Forte improves the accuracy of randomly corrupted theories and produces more accurate theories than pure inductive learning.
Reference: <author> Quinlan, J.R. </author> <year> (1991). </year> <title> Determinate literals in inductive logic programming. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 442-446). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Rajamoney, S. </author> <year> (1990). </year> <title> A computational approach to theory revision. </title> <editor> In J. Shrager and P. Langley (Eds.), </editor> <title> Computational Models of Scientific Discovery and Theory Formation. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Richards, B. </author> <year> (1992). </year> <title> An operator-based approach to first-order theory revision. </title> <type> Ph.D. Thesis. </type> <institution> Department of Computer Sciences, University of Texas, Austin, TX. </institution> <note> Also appears as Technical Report AI 92-181, Artificial Intelligence Laboratory. </note>
Reference-contexts: This process continues until we have a set of clauses that retains the provability of all of the originally provable positive instances. Forte provides two separate algorithms for producing a specialized clause: hill-climbing antecedent addition and relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. As shown in Figure 4, both methods are used to develop specializations of a clause, and the one with the best performance is selected. <p> To do this, we need a method which is capable of searching for relationships among the constants in a domain. Our method for accomplishing this is called relational pathfinding. Relational pathfinding. Relational pathfinding <ref> (Richards & Mooney, 1992) </ref> is a method of antecedent addition designed to escape local maxima and local plateaus. The idea of pathfinding in a relational domain is to view the domain as a (possibly infinite) hypergraph of terms linked by the relations that hold among the terms. <p> Much of Forte's performance in REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 23 highly relational domains of this sort comes from relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. To demonstrate this, Figure 12 shows Forte performing inductive learning both with and without relational pathfinding. These curves are averaged over 20 runs for each data point. The difference between them is statistically significant (p &lt; 0.01) at all points. 1.0ff, also averaged over 20 trials. <p> If a monotonically increasing function holds between the two behavior terms, m plus succeeds; otherwise it fails. A more complete description of Qsim constraints is beyond the scope of this paper, and is discussed by Kuipers (1986, 1989). Forte's implementation of the Qsim constraints is taken from Misq <ref> (Richards, Kraan, & Kuipers, 1992) </ref>, and includes: constant, M+, M, add, multiply, and derivative. From Forte's point of view, the constraints in the fundamental domain theory are simply predicates that succeed or fail in the course of a proof.
Reference: <author> Richards, B., Kraan, I., & Kuipers, B. </author> <year> (1992). </year> <title> Automatic abduction of qualitative models. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 723-728). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This process continues until we have a set of clauses that retains the provability of all of the originally provable positive instances. Forte provides two separate algorithms for producing a specialized clause: hill-climbing antecedent addition and relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. As shown in Figure 4, both methods are used to develop specializations of a clause, and the one with the best performance is selected. <p> To do this, we need a method which is capable of searching for relationships among the constants in a domain. Our method for accomplishing this is called relational pathfinding. Relational pathfinding. Relational pathfinding <ref> (Richards & Mooney, 1992) </ref> is a method of antecedent addition designed to escape local maxima and local plateaus. The idea of pathfinding in a relational domain is to view the domain as a (possibly infinite) hypergraph of terms linked by the relations that hold among the terms. <p> Much of Forte's performance in REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 23 highly relational domains of this sort comes from relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. To demonstrate this, Figure 12 shows Forte performing inductive learning both with and without relational pathfinding. These curves are averaged over 20 runs for each data point. The difference between them is statistically significant (p &lt; 0.01) at all points. 1.0ff, also averaged over 20 trials. <p> If a monotonically increasing function holds between the two behavior terms, m plus succeeds; otherwise it fails. A more complete description of Qsim constraints is beyond the scope of this paper, and is discussed by Kuipers (1986, 1989). Forte's implementation of the Qsim constraints is taken from Misq <ref> (Richards, Kraan, & Kuipers, 1992) </ref>, and includes: constant, M+, M, add, multiply, and derivative. From Forte's point of view, the constraints in the fundamental domain theory are simply predicates that succeed or fail in the course of a proof.
Reference: <author> Richards, B., & Mooney, R. </author> <year> (1992). </year> <title> Learning relations by pathfinding. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 50-55). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This process continues until we have a set of clauses that retains the provability of all of the originally provable positive instances. Forte provides two separate algorithms for producing a specialized clause: hill-climbing antecedent addition and relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. As shown in Figure 4, both methods are used to develop specializations of a clause, and the one with the best performance is selected. <p> To do this, we need a method which is capable of searching for relationships among the constants in a domain. Our method for accomplishing this is called relational pathfinding. Relational pathfinding. Relational pathfinding <ref> (Richards & Mooney, 1992) </ref> is a method of antecedent addition designed to escape local maxima and local plateaus. The idea of pathfinding in a relational domain is to view the domain as a (possibly infinite) hypergraph of terms linked by the relations that hold among the terms. <p> Much of Forte's performance in REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 23 highly relational domains of this sort comes from relational pathfinding <ref> (Richards & Mooney, 1992) </ref>. To demonstrate this, Figure 12 shows Forte performing inductive learning both with and without relational pathfinding. These curves are averaged over 20 runs for each data point. The difference between them is statistically significant (p &lt; 0.01) at all points. 1.0ff, also averaged over 20 trials. <p> If a monotonically increasing function holds between the two behavior terms, m plus succeeds; otherwise it fails. A more complete description of Qsim constraints is beyond the scope of this paper, and is discussed by Kuipers (1986, 1989). Forte's implementation of the Qsim constraints is taken from Misq <ref> (Richards, Kraan, & Kuipers, 1992) </ref>, and includes: constant, M+, M, add, multiply, and derivative. From Forte's point of view, the constraints in the fundamental domain theory are simply predicates that succeed or fail in the course of a proof.
Reference: <author> Sammut, C., & Banerji, R.B. </author> <year> (1986). </year> <title> Learning concepts by asking questions. In R.S. </title> <editor> Michal-ski, J.G. Carbonell, and T.M. Mitchell (Eds.) </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: His Prolog debugging system, PDS6, required even more interaction with the user. It required the user to judge the correctness of predicate calls, determine which clause in a predicate to change, and to actually write missing clauses. Other interactive systems include Marvin <ref> (Sammut & Banerji, 1986) </ref> and Clint (DeRaedt & Bruynooghe, 1992). Clint generalizes and specializes theories and also creates new predicates via analogy. Clint's revisions only include adding and removing clauses; it does not attempt to modify existing clauses.
Reference: <author> Shapiro, E. </author> <year> (1983). </year> <title> Algorithmic program debugging. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Shortliffe, E.H., & Buchanan, B.G. </author> <year> (1975). </year> <title> A model of inexact reasoning in medicine. </title> <journal> Mathematical Biosciences, </journal> <volume> 23, </volume> <pages> 351-379. </pages>
Reference-contexts: In many domains, some form of uncertain or probabilistic reasoning is desirable; however, current theory refinement systems like Forte are restricted to purely logical domain theories. Rapture (Mahoney & Mooney, 1993) is a recent system that combines connectionist and symbolic methods to refine propositional certainty-factor rule bases <ref> (Shortliffe & Buchanan, 1975) </ref>. However, its basic approach should be applicable to first-order theories. 10. Conclusions This paper has described and evaluated a completely automated approach to revising imperfect first-order Horn-clause domain theories by incorporating methods from propositional theory refinement and inductive logic programming.
Reference: <author> Tangkitvanich, S., & Shimura, M. </author> <year> (1992). </year> <title> Refining a relational theory with multiple faults in the concept and subconcepts. </title> <booktitle> Proceeding of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 436-444). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: A few other automated refinement systems for first-order theories have also recently been developed. Audrey (Wogulis, 1991) first specializes a theory by deleting clauses and then generalizes it using an abductive method that makes a single fault assumption. Consequently, its range of revisions is limited compared to Forte. Rx <ref> (Tangkitvanich & Shimura, 1992) </ref> first produces a revised opera REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 33 tional definition and then translates this into changes to the original theory (as in the RTLS propositional system (Ginsberg, 1990)).
Reference: <author> Towell, G., & Shavlik, J. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13, </volume> <month> 71-101. </month> <title> REFINEMENT OF FIRST-ORDER DOMAIN THEORIES 39 Wilkins, </title> <address> D. </address> <year> (1988). </year> <title> Knowledge base refinement using apprenticeship learning techniques. </title> <booktitle> Proceedings of the Seventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 646-651). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Unlike Forte, Either does not hill-climb and is guaranteed to fit an arbitrary theory to any set of noise-free data. However, Either's approach of computing all abductive proofs of unprovable positive examples was deemed computationally intractable for first-order theories. RTLS (Ginsberg, 1990), Kbann <ref> (Towell & Shavlik, 1993) </ref>, Ductor (Cain, 1991), and Krust (Craw & Sleeman, 1991) are other theory refinement systems that are restricted to propositional theories.
Reference: <author> Wirth, R., & O'Rorke, P. </author> <year> (1991). </year> <title> Constraints on predicate invention. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 457-461). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Wrobel, S. </author> <year> (1993). </year> <title> On the proper definition of minimality in specialization and theory revision. </title> <editor> In Brazdil (Ed.) </editor> <booktitle> Machine Learning - ECML-93 (pp. </booktitle> <pages> 65-81). </pages> <booktitle> Springer Lecture Notes on Artificial Intelligence Vol. </booktitle> <pages> 667. </pages>
Reference: <author> Wogulis, J. </author> <year> (1991). </year> <title> Revising relational domain theories. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 462-466). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Wrobel (1993) presents an alternative definition of minimal semantic specialization, but does not address the issue of generalizing the resulting exceptions. A few other automated refinement systems for first-order theories have also recently been developed. Audrey <ref> (Wogulis, 1991) </ref> first specializes a theory by deleting clauses and then generalizes it using an abductive method that makes a single fault assumption. Consequently, its range of revisions is limited compared to Forte.
References-found: 53

