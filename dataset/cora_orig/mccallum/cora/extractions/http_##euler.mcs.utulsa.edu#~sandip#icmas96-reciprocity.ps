URL: http://euler.mcs.utulsa.edu/~sandip/icmas96-reciprocity.ps
Refering-URL: http://euler.mcs.utulsa.edu/~sandip/DAI.html
Root-URL: 
Email: e-mail: sandip@kolkata.mcs.utulsa.edu  
Phone: Phone: (918) 631-2985, FAX: (918) 631-3077  
Title: Reciprocity: a foundational principle for promoting cooperative behavior among self-interested agents  
Author: Sandip Sen 
Address: Tulsa  
Affiliation: Department of Mathematical Computer Sciences, The University of  
Abstract: If participating agents in a multiagent system can be assumed to be cooperative in nature, coordination mechanisms can be used that will realize desirable system performance. Such assumptions, however, are untenable in open systems. Agent designers have to design agents and agent environments with the understanding that participating agents will act to serve their self-interests instead of working towards group goals. We investigate the choice of interaction strategies and environmental characteristics that will make the best self-interested actions to be cooperative in nature. We analyze the inadequacy of traditional deterministic reciprocity mechanisms to promote cooperative behavior with a fair distribution of the workload. A probabilistic reciprocity mechanism is introduced and shown to generate stable and cooperative behavior among a group of self-interested agents. The resultant system exhibits close to optimal throughput with a fair distribution of the workload among the participating agents. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Axelrod, R. </author> <year> 1984. </year> <title> The Evolution of Cooperation. </title> <publisher> Basic Books. </publisher>
Reference-contexts: In a seminal piece of work Robert Axelrod has shown how stable cooperative behavior can arise in self-interested agents when they adopt a reciprocative attitude towards each other <ref> (Axelrod 1984) </ref>.
Reference: <author> Booker, L. B. </author> <year> 1988. </year> <title> Classifier systems that learn internal world models. </title> <booktitle> Machine Learning 3 </booktitle> <pages> 161-192. </pages>
Reference: <author> Boyd, R. </author> <year> 1988. </year> <title> Is the repeated prisoner's dilemma a good model of reciprocal altruism? Ethol. </title> <booktitle> Sociobiol-ogy 9 </booktitle> <pages> 211-222. </pages>
Reference-contexts: Some objections have already been raised to using such sanitized, abstract games for understanding the evolution of complex phenomena like reciprocal altruism <ref> (Boyd 1988) </ref>. In the following we analyze in some detail one of the often-cited work that share the typical assumptions made by economists and mathematical biologists, and then present our own set of suggestions for relaxing the restrictive assumptions made in that work.
Reference: <author> Dugatkin, L.; Wilson, D.; III, L. F.; and Wilkens, R. </author> <year> 1994. </year> <title> Altruism tit for tat and `outlaw' genes. </title> <booktitle> Evolutionary Ecology 8 </booktitle> <pages> 431-437. </pages>
Reference: <author> Goldman, C., and Rosenschein, J. S. </author> <year> 1994. </year> <title> Emergent coordination through the use of cooperative state-changing rules. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 408-413. </pages>
Reference-contexts: Similar analyses of the effects of fi and t can be made for any cooperation decision after agents have experienced a number of exchanges. In essence, fi and t can be used to choose a cooperation level <ref> (Goldman & Rosenschein 1994) </ref> for the agents at the onset of the experiments.
Reference: <author> Kephart, J. O.; Hogg, T.; and Huberman, B. A. </author> <year> 1989. </year> <title> Dynamics of computational ecosystems: Implications for DAI. </title> <editor> In Huhns, M. N., and Gasser, L., eds., </editor> <booktitle> Distributed Artificial Intelligence, volume 2 of Research Notes in Artificial Intelligence. </booktitle> <publisher> Pitman. </publisher>
Reference: <author> Krebs, D. </author> <year> 1970. </year> <title> Altruism an examination of the concept and a review of the literature. </title> <journal> Psychological Bulletin 73(4) </journal> <pages> 258-302. </pages>
Reference: <author> Nee, S. </author> <year> 1989. </year> <title> Does hamilton's rule describe the evolution of reciprocal altruism? Journal of Theoretical Biology 141 </title> <type> 81-91. </type>
Reference: <author> Nowak, M.; May, R.; and Sigmund, K. </author> <year> 1995. </year> <title> The arithmetics of mutual help. </title> <publisher> Scientific American 272(6) </publisher> <pages> 76-81. </pages>
Reference: <author> Rapoport, A. </author> <year> 1989. </year> <title> Prisoner's dilemma. </title> <editor> In Eatwell, J.; Milgate, M.; and Newman, P., eds., </editor> <title> The New Pal-grave: Game Theory. </title> <publisher> London: Macmillan. </publisher> <pages> 199-204. </pages>
Reference-contexts: Most of the work by mathematical biologists or economists on the evolution of altruistic behavior deals with the idealized problem called Prisoner's dilemma <ref> (Rapoport 1989) </ref> or some other repetitive, symmetrical, and identical `games'. Some objections have already been raised to using such sanitized, abstract games for understanding the evolution of complex phenomena like reciprocal altruism (Boyd 1988).
Reference: <author> Schmitz, D. </author> <year> 1993. </year> <title> Reasons for altruism. Social Philosophy & Policy 10(1) </title> <type> 52-68. </type>
Reference: <author> Trivers, R. </author> <year> 1972. </year> <title> The evolution of reciprocal altruism. </title> <journal> Quarterly Review of Biology 46 </journal> <pages> 35-57. </pages>
Reference: <author> Watkins, C. </author> <year> 1989. </year> <title> Learning from Delayed Rewards. </title> <type> Ph.D. Dissertation, </type> <institution> King's College, Cambridge University. </institution>
Reference: <author> Wei, G., and Sen, S., eds. </author> <year> 1996. </year> <title> Adaptation and Learning in Multi-Agent Systems. </title> <booktitle> Lecture Notes in Artificial Intelligence. </booktitle> <address> Berlin: </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Introduction Researchers involved in the design of intelligent agents that will interact with other agents in an open, distributed system are faced with the challenge of modeling other agents and their behavior <ref> (Wei & Sen 1996) </ref>. If one can can assume that all agents will be cooperative in nature, efficient mechanisms can be developed to take advantage of mutual cooperation. These will lead to improved global as well as individual performance.
References-found: 14

