URL: ftp://www-flash.stanford.edu/pub/flash/asplos4.ps.Z
Refering-URL: http://http.cs.berkeley.edu/~culler/cs258/
Root-URL: 
Title: Performance Evaluation of Memory Consistency Models for Shared-Memory Multiprocessors  
Author: Kourosh Gharachorloo, Anoop Gupta, and John Hennessy 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: The memory consistency model supported by a multiprocessor architecture determines the amount of buffering and pipelining that may be used to hide or reduce the latency of memory accesses. Several different consistency models have been proposed. These range from sequential consistency on one end, allowing very limited buffering, to release consistency on the other end, allowing extensive buffering and pipelining. The processor consistency and weak consistency models fall in between. The advantage of the less strict models is increased performance potential. The disadvantage is increased hardware complexity and a more complex programming model. To make an informed decision on the above tradeoff requires performance data for the various models. This paper addresses the issue of performance benefits from the above four consistency models. Our results are based on simulation studies done for three applications. The results show that in an environment where processor reads are blocking and writes are buffered, a significant performance increase is achieved from allowing reads to bypass previous writes. Pipelining of writes, which determines the rate at which writes are retired from the write buffer, is of secondary importance. As a result, we show that the sequential consistency model performs poorly relative to all other models, while the processor consistency model provides most of the benefits of the weak and release consistency models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sarita Adve and Mark Hill. </author> <title> Implementing sequential consistency in cache-based systems. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages I: 47-50, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Operation BASE SC PC WC RC 1. Read (a) Processor issues read and stalls for read to perform. Note: (i) No pending writes are possible. See point 2. (a) Processor stalls for pending writes to perform (or, in very aggressive implementations, to gain ownership <ref> [1] </ref>). (b) Processor issues read and stalls for read to perform. (a) Processor issues read and stalls for read to perform. Note: (i) Reads are allowed to bypass pending writes. (a) Processor issues read and stalls for read to perform. <p> Note: (i) No need for write buffer. (a) Processor sends write to write buffer (stalls if write buffer is full). Note: (i) Write buffer retires a write only after the write is performed, or in very aggressive implementations, when ownership is gained <ref> [1] </ref>. (a) Processor sends write to write buffer (stalls if write buffer is full). Notes: (i) Write buffer does not require ownership to be gained before retiring a write. (ii) For interaction with acquires/releases, see points 3,4. 3. <p> To determine the tradeoffs described above will require a more in-depth study of such update-based schemes. 8 Related Work In this section, we discuss some alternative implementations that have been proposed for sequential consistency and weak consistency and briefly describe previous evaluation efforts. Adve and Hill <ref> [1] </ref> have proposed a very aggressive implementation for sequential consistency. Their scheme requires an invalidation-based cache coherence protocol. At points where our SC implementation stalls for the full latency of pending writes, their implementation stalls only until ownership is gained.
Reference: [2] <author> Sarita Adve and Mark Hill. </author> <title> Weak ordering Anew definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Page 11 Another issue concerning consistency models is the complex-ity of the model as presented to the programmer. There have been several efforts in specifying programming restrictions that result in the relaxed models being equivalent to sequential consistency as far as correctness is concerned <ref> [2, 6] </ref>. In practice, we have found that satisfying such restrictions is not a problem. Most user-level applications developed in our group already satisfy the restrictions with no change to the programs. <p> This is because the number of invalidations caused by a write is usually small [20]. Since the visibility-control mechanism reduces the stall time for SC only slightly, we still expect PC to perform significantly better than SC. Adve and Hill <ref> [2] </ref> have also proposed an implementation for weak ordering that is less strict than WC. The constraints in their implementation are quite similar to the constraints imposed by RC.
Reference: [3] <author> Anant Agarwal, Beng-Hong Lim, David Kranz, and John Kubiatowicz. </author> <month> April: </month> <title> A processor architecture for multiprocessing. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 104-114, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Two powerful techniques that can help reduce or hide this latency are buffering and pipelining of memory accesses. Unfortunately, the distributed memory, caches, and general interconnection networks used by large scale multiprocessors <ref> [3, 11, 15] </ref> can cause multiple requests issued by a processor to execute out of order. Depending on the memory consistency model supported, various restrictions are placed on the amount of buffering and pipelining allowed. Thus, the choice of the memory consistency model directly affects the performance of the machine.
Reference: [4] <author> Michel Dubois and Christoph Scheurich. </author> <title> Memory access dependencies in shared-memory multiprocessors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(6) </volume> <pages> 660-673, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: One of the least strict models is release consistency (RC) [6], which allows significant overlap of memory accesses given synchronization accesses are identified and classified into acquires and releases. Two other models that have been discussed in the literature are processor consistency (PC) [6, 8] and weak consistency (WC) <ref> [4, 5] </ref>. These fall between sequential and release consistency models in terms of strictness. While the less strict models provide a higher potential for performance, they also require more complicated hardware and result in a more complex programming model. <p> The constraints to satisfy processor consistency are specified formally in [6]. A more relaxed consistency model can be derived by relating memory request ordering to synchronization points in the program. The weak consistency model (WC) proposed by Dubois et al. <ref> [4, 5] </ref> is based on the above idea and ensures that memory is consistent only at synchronization points. As an example, consider a process updating a data structure within a critical section. Under SC, every access within the critical section is delayed until the previous access completes.
Reference: [5] <author> Michel Dubois, Christoph Scheurich, and Faye Briggs. </author> <title> Memory access buffering in multiprocessors. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 434-442, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: One of the least strict models is release consistency (RC) [6], which allows significant overlap of memory accesses given synchronization accesses are identified and classified into acquires and releases. Two other models that have been discussed in the literature are processor consistency (PC) [6, 8] and weak consistency (WC) <ref> [4, 5] </ref>. These fall between sequential and release consistency models in terms of strictness. While the less strict models provide a higher potential for performance, they also require more complicated hardware and result in a more complex programming model. <p> In the simulated architecture, a read is considered performed when the return value is bound and can not be modified by other write operations. Similarly, a write is considered performed when exclusive ownership is acquired and all other copies have been invalidated. For simplicity, we assume writes are atomic <ref> [5] </ref>. The architecture provides a mechanism to keep track of multiple outstanding accesses for each processor and allows for the processor to be stalled until all pending accesses have performed (for details, see [6]). <p> The constraints to satisfy processor consistency are specified formally in [6]. A more relaxed consistency model can be derived by relating memory request ordering to synchronization points in the program. The weak consistency model (WC) proposed by Dubois et al. <ref> [4, 5] </ref> is based on the above idea and ensures that memory is consistent only at synchronization points. As an example, consider a process updating a data structure within a critical section. Under SC, every access within the critical section is delayed until the previous access completes. <p> The constraints in their implementation are quite similar to the constraints imposed by RC. Therefore, the performance of their model is expected to be comparable to RC in practice, and thus not significantly better than PC. Scheurich and Dubois <ref> [5, 17] </ref> provide simple analytical models to estimate the benefits arising from weak consistency and lockup-free caches. The gains predicted by these models are large, sometimes close to an order of magnitude gain in perfor mance.
Reference: [6] <author> Kourosh Gharachorloo, Dan Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: While conceptually intuitive and elegant, the model imposes severe restrictions on the outstanding accesses that a process may have, thus restricting the buffering and pipelining allowed. One of the least strict models is release consistency (RC) <ref> [6] </ref>, which allows significant overlap of memory accesses given synchronization accesses are identified and classified into acquires and releases. Two other models that have been discussed in the literature are processor consistency (PC) [6, 8] and weak consistency (WC) [4, 5]. <p> One of the least strict models is release consistency (RC) [6], which allows significant overlap of memory accesses given synchronization accesses are identified and classified into acquires and releases. Two other models that have been discussed in the literature are processor consistency (PC) <ref> [6, 8] </ref> and weak consistency (WC) [4, 5]. These fall between sequential and release consistency models in terms of strictness. While the less strict models provide a higher potential for performance, they also require more complicated hardware and result in a more complex programming model. <p> For simplicity, we assume writes are atomic [5]. The architecture provides a mechanism to keep track of multiple outstanding accesses for each processor and allows for the processor to be stalled until all pending accesses have performed (for details, see <ref> [6] </ref>). The notion of being performed and having completed will be used interchangeably in the rest of the paper. to do single cycle write operations. The first-level data cache interfaces to a 256-Kbyte second-level write-back cache. The interface consists of a read buffer and a write buffer. <p> However, the order in which writes from two processors occur, as observed by themselves or a third processor, need not be identical. The constraints to satisfy processor consistency are specified formally in <ref> [6] </ref>. A more relaxed consistency model can be derived by relating memory request ordering to synchronization points in the program. The weak consistency model (WC) proposed by Dubois et al. [4, 5] is based on the above idea and ensures that memory is consistent only at synchronization points. <p> Weak consistency exploits this by allowing accesses within the critical section to be pipelined. Correctness is achieved by guaranteeing that all previous accesses are performed at the beginning and end of each critical section. Release consistency (RC) <ref> [6] </ref> is an extension of weak consistency that exploits further information about synchronization by classifying them into acquire and release accesses. An acquire synchronization access (e.g., a lock operation or a process spinning for a flag to be set) is performed to gain access to a set of shared locations. <p> A release synchronization access (e.g., an unlock operation or a process setting a flag) grants this permission. An acquire is accomplished by reading a shared location until an appropriate value is read. Thus, an acquire is always associated with a read synchronization access (see <ref> [6] </ref> for discussion of read-modify-write accesses). Similarly, a release is always associated with a write synchronization access. <p> Weak consistency and release consistency differ from SC and PC in that they exploit information about synchronization accesses. Both WC and RC allow accesses between two synchronization opera 1 The weak consistency and release consistency models shown are the WCsc and RCpc models, respectively, in the terminology presented in <ref> [6] </ref>. <p> The lockup-free cache for PC is simpler than for WC and RC since there are at most two accesses, a read and a write, outstanding at any time. Furthermore, WC and RC require additional counters to keep track of when the outstanding accesses are complete (see <ref> [6] </ref> for more details). There are several secondary effects that are not discussed above. For example, less strict models allow accesses to be issued at a faster rate that in turn may result in more contention at the network or in the memory system, thus increasing the latency of accesses. <p> Page 11 Another issue concerning consistency models is the complex-ity of the model as presented to the programmer. There have been several efforts in specifying programming restrictions that result in the relaxed models being equivalent to sequential consistency as far as correctness is concerned <ref> [2, 6] </ref>. In practice, we have found that satisfying such restrictions is not a problem. Most user-level applications developed in our group already satisfy the restrictions with no change to the programs.
Reference: [7] <author> Stephen R. Goldschmidt and Helen Davis. </author> <title> Tango introduction and tutorial. </title> <type> Technical Report CSL-TR-90-410, </type> <institution> Stanford University, </institution> <year> 1990. </year>
Reference-contexts: For our studies, an event-driven simulator is used to simulate the major components of the DASH architecture at a behavioral level. The simulations are based on a 16 processor configuration. The simulator is tightly coupled to the Tango <ref> [7] </ref> reference generator to assure a correct interleaving of accesses. For example, a process doing a read operation is blocked until that read completes, where the latency of the read is determined by the architecture simulator.
Reference: [8] <author> James R. Goodman. </author> <title> Cache consistency and sequential consistency. </title> <type> Technical Report no. 61, </type> <institution> SCI Committee, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: One of the least strict models is release consistency (RC) [6], which allows significant overlap of memory accesses given synchronization accesses are identified and classified into acquires and releases. Two other models that have been discussed in the literature are processor consistency (PC) <ref> [6, 8] </ref> and weak consistency (WC) [4, 5]. These fall between sequential and release consistency models in terms of strictness. While the less strict models provide a higher potential for performance, they also require more complicated hardware and result in a more complex programming model. <p> The strictest model, originally proposed by Lamport [10], is sequential consistency (SC). Sequential consistency requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. Processor consistency (PC) was proposed by Goodman <ref> [8] </ref> to relax some of the restrictions imposed by sequential consistency. Processor consistency requires that writes issued from a processor may not Page 3 Table 3: Number of shared read, write, and synchronization accesses for a 16 processor configuration.
Reference: [9] <author> D. Kroft. </author> <title> Lockup-free instruction fetch/prefetch cache organization. </title> <booktitle> In Proceedings of the 8th Annual International Symposium on Computer Architecture, </booktitle> <year> 1981. </year>
Reference-contexts: We will consider three versions of the implementation: (i) LFC, an aggressive implementation with lockup-free caches <ref> [9, 16] </ref>, reads that bypass the write buffer, and a 16 word deep write buffer; (ii) RDBYP, which is the same as LFC, except caches are no longer lockup-free; and (iii) BASIC, which is the same as RDBYP, except that reads are not allowed to bypass the write buffer.
Reference: [10] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Thus, the choice of the memory consistency model directly affects the performance of the machine. Several memory consistency models have been proposed in the literature. The strictest model is sequential consistency (SC) <ref> [10] </ref>, which requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. <p> The contents of this section will also form the basis of arguments used to explain simulation data in the following sections. 4.1 General Overview A consistency model imposes restrictions on the order of shared memory accesses initiated by each process. The strictest model, originally proposed by Lamport <ref> [10] </ref>, is sequential consistency (SC). Sequential consistency requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. Processor consistency (PC) was proposed by Goodman [8] to relax some of the restrictions imposed by sequential consistency.
Reference: [11] <author> Dan Lenoski, James Laudon, Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> The directory-based cache coherence protocol for the DASH multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Two powerful techniques that can help reduce or hide this latency are buffering and pipelining of memory accesses. Unfortunately, the distributed memory, caches, and general interconnection networks used by large scale multiprocessors <ref> [3, 11, 15] </ref> can cause multiple requests issued by a processor to execute out of order. Depending on the memory consistency model supported, various restrictions are placed on the amount of buffering and pipelining allowed. Thus, the choice of the memory consistency model directly affects the performance of the machine. <p> The applications are a particle-based simulator used in aeronautics (MP3D) [13], an LU-decomposition program (LU), and a digital logic simulation program (PTHOR) [18]. The simulated architecture is based on the Stanford DASH multiprocessor <ref> [11] </ref>. Our results show that in an architecture with blocking reads and buffered writes (typical for current commercial microprocessors), the sequential consistency model does significantly worse than all other models. <p> For our study, we have chosen an architecture that resembles the DASH shared-memory multiprocessor <ref> [11] </ref>, a large scale cache-coherent machine currently being built at Stanford. We use the actual parameters from the DASH prototype wherever possible, but have removed some of the limitations that were imposed on the DASH prototype due to design-time constraints. through a low-latency scalable interconnection network. <p> A remote node is any other node. Synchronization primitives are also modeled after DASH. The queue-based lock primitive <ref> [11] </ref> is used for supporting locks. In general, locks are not cached except when a processor is spinning on a locked value. <p> In this section, we explore the effects of reduced read latency on the relative performance of the models. In particular, we model a prefetch mechanism similar to that provided in the DASH architecture <ref> [11] </ref>. In general, there are two types of prefetching: binding and non-binding. In binding prefetch, the value of the access is bound at the time the prefetch is completed. <p> Prefetch instructions were inserted in appropriate places in the program. Prefetching within the simulator is modeled after the way prefetches work in DASH <ref> [11] </ref>; the prefetch brings a copy of the location into a special cache associated with each node. Figure 9 shows the relative performance of the models. The performance in each case is normalized to the performance of LFC with the BASE model.
Reference: [12] <editor> Ewing Lusk, Ross Overbeek, et al. </editor> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <year> 1987. </year>
Reference-contexts: All of the applications are written in C and use the synchronization primitives provided by the Argonne National Laboratory macro package <ref> [12] </ref>. The three applications that we study are MP3D, LU, and PTHOR. MP3D [13] is a 3-dimensional particle simulator. It is used to study the pressure and temperature profiles created as an object flies at high speed through the upper atmosphere.
Reference: [13] <author> Jeffrey D. McDonald and Donald Baganoff. </author> <title> Vectoriza-tion of a particle simulation method for hypersonic rari-fied flow. </title> <booktitle> In AIAA Thermodynamics, Plasmadynamics and Lasers Conference, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: So far, detailed performance data has not been available. This paper presents simulation results comparing the performance of these consistency models based on three engineering applications. The applications are a particle-based simulator used in aeronautics (MP3D) <ref> [13] </ref>, an LU-decomposition program (LU), and a digital logic simulation program (PTHOR) [18]. The simulated architecture is based on the Stanford DASH multiprocessor [11]. <p> All of the applications are written in C and use the synchronization primitives provided by the Argonne National Laboratory macro package [12]. The three applications that we study are MP3D, LU, and PTHOR. MP3D <ref> [13] </ref> is a 3-dimensional particle simulator. It is used to study the pressure and temperature profiles created as an object flies at high speed through the upper atmosphere. The overall computation of MP3D consists of evaluating the positions and velocities of molecules over a sequence of time steps.
Reference: [14] <author> Todd Mowry and Anoop Gupta. </author> <title> Tolerating latency through software-controlled prefetching in scalable shared-memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> to appear in June 1991. </note>
Reference-contexts: Therefore, non-binding prefetch is more flexible, easier to use (does not affect correctness), and can provide benefits for all consistency models. Indeed, the prefetch mechanism provided in DASH is non-binding, and we will assume such a prefetch mechanism in this section. For a detailed evaluation of nonbinding prefetching, see <ref> [14] </ref>. The results in this section show that the pipelining of writes allowed by RC (and WC) becomes significantly more important in achieving high performance once the latency of reads is reduced through prefetching. Section 6.1 presents simulation results for ideal prefetching of reads. <p> In summary, read and read-exclusive prefetching substantially improve the performance of all models, including BASE and SC. We should note, however, that prefetching is not always successful in reducing the latency of accesses <ref> [14] </ref>. In cases where read prefetching is successful, we show that the pipelining of writes becomes more important. We expect read-exclusive prefetching to also be successful if read prefetching works.
Reference: [15] <author> G. F. Pfister, W. C. Brantley, D. A. George, S. L. Harvey, W. J. Kleinfelder, K. P. McAuliffe, E. A. Melton, V. A. Norton, and J. Weiss. </author> <title> The IBM research parallel processor prototype (RP3): Introduction and architecture. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <pages> pages 764-771, </pages> <year> 1985. </year>
Reference-contexts: Two powerful techniques that can help reduce or hide this latency are buffering and pipelining of memory accesses. Unfortunately, the distributed memory, caches, and general interconnection networks used by large scale multiprocessors <ref> [3, 11, 15] </ref> can cause multiple requests issued by a processor to execute out of order. Depending on the memory consistency model supported, various restrictions are placed on the amount of buffering and pipelining allowed. Thus, the choice of the memory consistency model directly affects the performance of the machine.
Reference: [16] <author> Christoph Scheurich. </author> <title> Access Ordering and Coherence in Shared Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of Southern California, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: We will consider three versions of the implementation: (i) LFC, an aggressive implementation with lockup-free caches <ref> [9, 16] </ref>, reads that bypass the write buffer, and a 16 word deep write buffer; (ii) RDBYP, which is the same as LFC, except caches are no longer lockup-free; and (iii) BASIC, which is the same as RDBYP, except that reads are not allowed to bypass the write buffer.
Reference: [17] <author> Christoph Scheurich and Michel Dubois. </author> <title> Concurrent miss resolution in multiprocessor caches. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages I: 118-125, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The constraints in their implementation are quite similar to the constraints imposed by RC. Therefore, the performance of their model is expected to be comparable to RC in practice, and thus not significantly better than PC. Scheurich and Dubois <ref> [5, 17] </ref> provide simple analytical models to estimate the benefits arising from weak consistency and lockup-free caches. The gains predicted by these models are large, sometimes close to an order of magnitude gain in perfor mance.
Reference: [18] <author> Larry Soule and Anoop Gupta. </author> <title> Parallel distributed-time logic simulation. </title> <journal> IEEE Design and Test of Computers, </journal> <volume> 6(6) </volume> <pages> 32-48, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: So far, detailed performance data has not been available. This paper presents simulation results comparing the performance of these consistency models based on three engineering applications. The applications are a particle-based simulator used in aeronautics (MP3D) [13], an LU-decomposition program (LU), and a digital logic simulation program (PTHOR) <ref> [18] </ref>. The simulated architecture is based on the Stanford DASH multiprocessor [11]. Our results show that in an architecture with blocking reads and buffered writes (typical for current commercial microprocessors), the sequential consistency model does significantly worse than all other models. <p> Each processor waits until a column has been produced, and then that column is used to modify all columns that the processor owns. Once a processor completes a column, it releases any processors waiting for that column. For our experiments we performed LU-decomposition on a 200x200 matrix. PTHOR <ref> [18] </ref> is a parallel distributed-time logic simulator based on the Chandy-Misra simulation algorithm. The primary data structures associated with the simulator are the logic elements (e.g., AND-gates, flip-flops), the nets (wires linking the Table 2: General statistics on the benchmarks.
Reference: [19] <author> Josep Torrellas and John Hennessy. </author> <title> Estimating the performance advantages of relaxing consistency in a shared-memory multiprocessor. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages I: 26-33, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: We can not compare our results to this work, however, since their models are based on non-blocking reads, while our simulation results assume the processor stalls on reads. Torrellas and Hennessy <ref> [19] </ref> present a more detailed analytical model of a multiprocessor architecture and estimate the effects of relaxing the consistency model on performance. A maximum gain of 20% in performance is predicted for using weak consistency over sequential consistency. <p> A maximum gain of 20% in performance is predicted for using weak consistency over sequential consistency. This prediction is lower than the results in our study due to mainly two reasons: (i) the latencies assumed in <ref> [19] </ref> are lower than the ones in our simulated architecture; and (ii) the bus bandwidth assumed in their architecture became a limiting factor for cases with high sharing, where the weaker models could gain more otherwise. 9 Concluding Remarks To enable multiprocessors to hide and reduce memory latency, a number of
Reference: [20] <author> Wolf-Dietrich Weber and Anoop Gupta. </author> <title> Analysis of cache invalidation patterns in multiprocessors. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 243-256, </pages> <month> April </month> <year> 1989. </year> <pages> Page 13 </pages>
Reference-contexts: Simulations show, however, that the latency of obtaining ownership is only slightly smaller than the latency for the write to complete. This is because the number of invalidations caused by a write is usually small <ref> [20] </ref>. Since the visibility-control mechanism reduces the stall time for SC only slightly, we still expect PC to perform significantly better than SC. Adve and Hill [2] have also proposed an implementation for weak ordering that is less strict than WC.
References-found: 20

