URL: http://www.cs.berkeley.edu/~inderjit/public_papers/fannchem1.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~inderjit/
Root-URL: 
Title: Application of a New Algorithm for the Symmetric Eigenproblem to Computational Quantum Chemistry  
Author: Inderjit Dhillon George Fann Beresford Parlett 
Abstract: We present performance results of a new method for computing eigenvectors of a real symmetric tridiagonal matrix. The method is a variation of inverse iteration and can in most cases substantially reduce the time required to produce orthogonal eigenvectors. Our implementation of this algorithm has been quite effective in solving "degenerate" eigenproblems in computational chemistry. On a biphenyl example, the implementation is 46 times faster than an earlier PeIGS 2.0 code using 1 processor of the IBM SP. It reduces the time for computing eigenvectors of this 966 fi 966 matrix to under 0.15 seconds using 64 processors of the IBM SP. We present performance results for calculations from the SGI PowerChallenge and the IBM SP.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bernholdt and R. Harrison, </author> <title> Orbital Invariant Second Order Many-Body Perturbation on Parallel Computers: An Approach for Large Molecules. </title> <journal> J. Chem. Phys. </journal> <volume> 102, </volume> <year> 1995. </year>
Reference-contexts: As an illustration of the performance improvements, we have chosen to present results for an overlap matrix from a quantum chemistry application; resolution of the identity Moller-Plesset second order perturbation method (RI-MP2) applied to the modeling of a biphenyl (2,2'- ditrifluoromethyl) <ref> [1] </ref>. This example shows that improvements can be extremely beneficial and also have exciting implications. The real symmetric tridiagonal biphenyl matrix is generated by Householder tridiagonalization of the overlap matrix of dimension 966.
Reference: [2] <author> J. Demmel and W. Kahan, </author> <title> Accurate singular values of bidiagonal matrices. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 11(5) </volume> <pages> 873-912, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The savings in time due to loose clusters can be significant. 5 As we have mentioned earlier, our algorithm can be much faster than existing implementations of inverse iteration. The major advance is in using the bidiagonal matrix L for computational purposes. Theory developed in <ref> [12, 2, 7, 14] </ref> implies that by using carefully constructed inner loops, we can compute very accurate eigenvectors of LL t . The dot products between these computed eigenvectors are determined by the relative gaps between eigenvalues.
Reference: [3] <author> I. S. Dhillon, </author> <title> A Stable O(n 2 ) Algorithm for the Symmetric Tridiagonal Eigenproblem. </title> <type> Ph.D. thesis, </type> <institution> University of California, Berkeley, California, </institution> <note> Expected 1997, in preparation. </note>
Reference-contexts: Extensive spectral and timing results are presented in section 3. 2 The Berkeley Algorithm We outline here a preliminary version of the Berkeley algorithm being developed by Dhillon and Parlett <ref> [3, 4] </ref> to compute orthogonal eigenvectors of a symmetric tridiagonal matrix. The Berkeley algorithm promises to be an O (n 2 ), reliable and embarrassingly parallel method. <p> The Berkeley algorithm promises to be an O (n 2 ), reliable and embarrassingly parallel method. This algorithm is still under development, so in this paper we present only the preliminary algorithm, based on some of the ideas in references <ref> [3, 4] </ref>. <p> The bidiagonal matrix L is a "better" representation of the tridiagonal matrix for our purposes <ref> [3, 4] </ref>. 2. In our Berkeley algorithm, each individual eigenvector is computed by Algorithm 2.2, which in step 3 above can be thought of as doing the initial step of inverse iteration with starting vector e r . <p> Additional details on this method, such as alternative formulae for fl k that are better for computational purposes, can be found in <ref> [9, 5, 3] </ref>. 3. <p> The interested reader is referred to <ref> [3, 4] </ref> for more details about the theoretical foundations. Although the algorithm presented in this paper does explicit orthogonalization that can lead to O (n 3 ) in total work, our goal is to develop a reliable O (n 2 ) algorithm. <p> We have had considerable numerical success in doing so. Currently, there is no theory that completely explains our numerical observations. We are in the process of developing the appropriate theory, and the patient reader is requested to wait for <ref> [3, 4] </ref>. 3 Application and Results Our parallel version of the Berkeley algorithm has been applied to produce eigenvectors for a number of tridiagonal matrices derived from quantum chemistry applications. <p> The residual of the two outputs are comparable and the orthogonality of eigenvectors produced by PeIGS is slightly better than that of LAPACK, O (10 14 ) compared to O (10 13 ). Further improvements in removing the orthogonalization step with the tight clusters are expected <ref> [3] </ref>. The improvements to the tridiagonal eigensystem problem are realized in the standard eigenproblem. The standard eigensystem problem for the n=966 biphenyl example can now be solved in 90 seconds using the Berkeley algorithm on 1 processor; the old PeIGS algorithm took 248 seconds.
Reference: [4] <author> I. S. Dhillon and B. N. Parlett, </author> <title> Orthogonal Eigenvectors without Gram-Schmidt. </title> <note> In preparation. </note>
Reference-contexts: The algorithm has as its impetus K.V. Fernando's solution to the Wilkinson problem [9]; how to choose the starting vector for inverse iteration. The Berkeley algorithm outlines one approach to solving the tridiagonal eigenproblem. It is based on an algorithm being developed by Dhillon and Parlett <ref> [4] </ref>. The main innovation lies in discarding the 2n 1 diagonal and off-diagonal elements of the symmetric tridiagonal matrix in favour of more "stable" bidiagonal factors from which the eigenvectors can be computed. Carefully chosen inner loops that do not compromise computational efficiency are used to obtain greater accuracy. <p> Extensive spectral and timing results are presented in section 3. 2 The Berkeley Algorithm We outline here a preliminary version of the Berkeley algorithm being developed by Dhillon and Parlett <ref> [3, 4] </ref> to compute orthogonal eigenvectors of a symmetric tridiagonal matrix. The Berkeley algorithm promises to be an O (n 2 ), reliable and embarrassingly parallel method. <p> The Berkeley algorithm promises to be an O (n 2 ), reliable and embarrassingly parallel method. This algorithm is still under development, so in this paper we present only the preliminary algorithm, based on some of the ideas in references <ref> [3, 4] </ref>. <p> The bidiagonal matrix L is a "better" representation of the tridiagonal matrix for our purposes <ref> [3, 4] </ref>. 2. In our Berkeley algorithm, each individual eigenvector is computed by Algorithm 2.2, which in step 3 above can be thought of as doing the initial step of inverse iteration with starting vector e r . <p> The interested reader is referred to <ref> [3, 4] </ref> for more details about the theoretical foundations. Although the algorithm presented in this paper does explicit orthogonalization that can lead to O (n 3 ) in total work, our goal is to develop a reliable O (n 2 ) algorithm. <p> We have had considerable numerical success in doing so. Currently, there is no theory that completely explains our numerical observations. We are in the process of developing the appropriate theory, and the patient reader is requested to wait for <ref> [3, 4] </ref>. 3 Application and Results Our parallel version of the Berkeley algorithm has been applied to produce eigenvectors for a number of tridiagonal matrices derived from quantum chemistry applications.
Reference: [5] <author> B.N. Parlett and I.S. Dhillon, </author> <title> On Fernando's method to find the most redundant equation in a tridiagonal system. Linear Algebra and its Applications, </title> <note> 1996, to appear. </note>
Reference-contexts: Additional details on this method, such as alternative formulae for fl k that are better for computational purposes, can be found in <ref> [9, 5, 3] </ref>. 3.
Reference: [6] <author> B. T. Smith, J. M. Boyle, J. J. Dongarra, B. S. Garbow, Y. Ikebe, V. C. Klema, and C. B. Moler, </author> <title> Matrix Eigensystem Routines - EISPACK Guide. </title> <booktitle> volume 6 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1976. </year>
Reference-contexts: In general construction of the matrix is the time-consuming step. These considerations limit the type and size of problems that can currently be solved. In current software implementations, it is common practice to reduce the generalized and the standard eigenproblems to a tridiagonal eigenproblem <ref> [6] </ref> [13]. One of the most flexible, general, and fast methods for solving the real symmetric tridiagonal eigenproblem is based on some form of bisection for the eigenvalues and inverse iteration for the eigenvectors.
Reference: [7] <author> S. Eisenstat and I. Ipsen, </author> <title> Relative perturbation techniques for singular value problems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 32(6), </volume> <year> 1995. </year>
Reference-contexts: The savings in time due to loose clusters can be significant. 5 As we have mentioned earlier, our algorithm can be much faster than existing implementations of inverse iteration. The major advance is in using the bidiagonal matrix L for computational purposes. Theory developed in <ref> [12, 2, 7, 14] </ref> implies that by using carefully constructed inner loops, we can compute very accurate eigenvectors of LL t . The dot products between these computed eigenvectors are determined by the relative gaps between eigenvalues.
Reference: [8] <author> G. I. Fann, R.J. Littlefield, and D. M. Elwood, </author> <title> Performance of a Fully Parallel Dense Real Symmetric Eigensolver in Quantum Chemistry Applications. </title> <booktitle> Proceedings of High Performance Computing '95, Simulation MultiConference, The Society for Computer Simulation 1995. </booktitle>
Reference-contexts: Support provided by ONR contract N000014-90-J-1372. 1 2 is to orthonormalize the approximate eigenvectors in some fashion. Unfortunately, the need for orthogonalization introduces load balancing problems and possible bottlenecks in an otherwise perfectly parallel algorithm. Three examples from real world quantum chemistry simulations <ref> [8] </ref> using the parallel eigensolver PeIGS have shown that the definition of a cluster of degenerate eigenvalues from LAPACK's inverse iteration solver DSTEIN may be unnecessarily large. The parallel eigensolver PeIGS 2.0 uses DSTEIN's definition of a cluster of close eigenvalues and performs parallel orthogonalization of eigenvectors. <p> On massively parallel processors the performance is similar, with orthonormalization consuming 75% of the total CPU time of PeIGS 2.0 on 64 processors of an Intel Paragon 1 <ref> [8] </ref>. In this paper we focus on a new preliminary version of a fast and scalable algorithm for finding orthonormal eigenvectors of real symmetric tridiagonal matrices. For the sake of brevity we call it the Berkeley algorithm in this paper. <p> Using an older version of the parallel eigensolver PeIGS 2.0 more than 75% of the total solution time for the standard eigensolve on more than 64 processors of the Intel Paragon <ref> [8] </ref> was consumed by parallel modified Gram Schmidt (MGS) orthonormalization of the eigenvectors. The maximum parallel speedup obtainable was quite limited. However, if we use the definition of a cluster from the Berkeley algorithm (Algorithm 2.1 step 4), there is no tight cluster of eigenvalues in this case.
Reference: [9] <author> K. V. Fernando, </author> <title> On computing an eigenvector of a tridiagonal matrix, </title> <note> to appear in SIMAX. </note>
Reference-contexts: It is preliminary because this paper contains work in progress, and components of the preliminary algorithm are expected to change in the near future. The Berkeley algorithm shows promise in reducing the amount of required orthonormalization. The algorithm has as its impetus K.V. Fernando's solution to the Wilkinson problem <ref> [9] </ref>; how to choose the starting vector for inverse iteration. The Berkeley algorithm outlines one approach to solving the tridiagonal eigenproblem. It is based on an algorithm being developed by Dhillon and Parlett [4]. <p> Additional details on this method, such as alternative formulae for fl k that are better for computational purposes, can be found in <ref> [9, 5, 3] </ref>. 3.
Reference: [10] <author> K. Fernando and B. N. Parlett, </author> <title> Accurate singular values and the differential qd algorithms. </title> <journal> Numerische Mathematik, </journal> <volume> 67 </volume> <pages> 191-229, </pages> <year> 1994. </year>
Reference-contexts: Compute the singular values of L, denoted by 0 ^ 1 ^ 2 ^ n , to high relative accuracy (this may be done by a bisection algorithm or by the dqds algorithm of Fernando and Parlett <ref> [10] </ref>). 4.
Reference: [11] <author> R. Harrison, </author> <note> TCGMSG Manual. The latest version of TCGMSG can be obtained via anonymous ftp from ftp.pnl.gov:/pub/global/global2.2.tar.gz. </note>
Reference-contexts: There is essentially no further speedup obtained using 3 PeIGS uses TCGMSG or MPI for communication. 4 Thanks to the Molecular Sciences Computing Facility at PNNL for providing access to the IBM SP. 5 The eigensolver PeIGS 3.0 uses the communication package TCGMSG <ref> [11] </ref> or MPI. On the IBM SP the PeIGS code was compiled using xlhpf90 -Pv -O3 -qstrict and mpcc -O3 -qstrict and used native MPI.
Reference: [12] <author> W. Kahan, </author> <title> Accurate eigenvalues of a symmetric tridiagonal matrix. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS41, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <month> July </month> <year> 1966 </year> <month> (revised June </month> <year> 1968). </year>
Reference-contexts: The savings in time due to loose clusters can be significant. 5 As we have mentioned earlier, our algorithm can be much faster than existing implementations of inverse iteration. The major advance is in using the bidiagonal matrix L for computational purposes. Theory developed in <ref> [12, 2, 7, 14] </ref> implies that by using carefully constructed inner loops, we can compute very accurate eigenvectors of LL t . The dot products between these computed eigenvectors are determined by the relative gaps between eigenvalues.
Reference: [13] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen, </author> <note> LAPACK Users' Guide ( second edition ). SIAM, Philadelphia, </note> <year> 1995, </year> <pages> 324 pages. </pages>
Reference-contexts: In general construction of the matrix is the time-consuming step. These considerations limit the type and size of problems that can currently be solved. In current software implementations, it is common practice to reduce the generalized and the standard eigenproblems to a tridiagonal eigenproblem [6] <ref> [13] </ref>. One of the most flexible, general, and fast methods for solving the real symmetric tridiagonal eigenproblem is based on some form of bisection for the eigenvalues and inverse iteration for the eigenvectors.
Reference: [14] <author> R.-C. Li, </author> <title> Relative perturbation theory: (I) eigenvalue and singular value variations. </title> <type> Technical Report UCB//CSD-94-855, </type> <institution> Computer Science Division, Department of EECS, University of California at Berkeley, </institution> <year> 1994(revised </year> <month> January </month> <year> 1996). </year>
Reference-contexts: The savings in time due to loose clusters can be significant. 5 As we have mentioned earlier, our algorithm can be much faster than existing implementations of inverse iteration. The major advance is in using the bidiagonal matrix L for computational purposes. Theory developed in <ref> [12, 2, 7, 14] </ref> implies that by using carefully constructed inner loops, we can compute very accurate eigenvectors of LL t . The dot products between these computed eigenvectors are determined by the relative gaps between eigenvalues.
Reference: [15] <author> J. H. Wilkinson, </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965. </year>
References-found: 15

