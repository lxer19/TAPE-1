URL: ftp://ftp.imag.fr/pub/MAI/simark.ps.gz
Refering-URL: http://www-lmc.imag.fr/MAI/cours.fr.html
Root-URL: http://www.imag.fr
Email: bernard.ycart@imag.fr  
Title: Simulation de modeles markoviens  DESS d'Ingenierie Mathematique  
Author: B. Ycart ae ae ae ae ae ae s s @R Universite Joseph Fourier 
Date: 5 6  1997  
Address: BP 53, 38041 Grenoble Cedex 09  
Affiliation: LMC/IMAG,  
Pubnum: fi 1 fi 2  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Azencott. </author> <title> Simulated annealing. </title> <type> Seminaire Bourbaki, 697 </type> <pages> 161-175, </pages> <year> 1988. </year>
Reference-contexts: Ce que l'on entend par "nombres au hasard" depend d'abord du type des nombres (booleens, entiers, reels). Nous conviendrons de noter Random la fonction qui "retourne un reel au hasard dans <ref> [0; 1] </ref>". Ce que nous en dirons s'etend de maniere evidente a d'autres formats. La phrase "retourner des reels au hasard dans [0; 1]" recouvre en fait deux proprietes distinctes, que nous admettrons comme postulats. <p> Nous conviendrons de noter Random la fonction qui "retourne un reel au hasard dans <ref> [0; 1] </ref>". Ce que nous en dirons s'etend de maniere evidente a d'autres formats. La phrase "retourner des reels au hasard dans [0; 1]" recouvre en fait deux proprietes distinctes, que nous admettrons comme postulats. Postulats 1. 8a; b ; 0 a &lt; b 1 P rob [ Random 2]a; b] ] = b a. 2. Les appels successifs de Random sont des variables aleatoires independantes. <p> Les appels successifs de Random sont des variables aleatoires independantes. Interpretation Dans le langage courant "au hasard" ne signifie pas seulement aleatoire mais en plus uniformement reparti. Choisir au hasard, c'est donner les m^emes chances a tous les resultats possibles (equiprobabilite). On attend d'un reel "au hasard" dans <ref> [0; 1] </ref> qu'il tombe entre 0; 4 et 0; 5 avec probabilite 1=10, de m^eme qu'entre 0; 8 et 0; 9. Deux intervalles inclus dans [0; 1] ont la m^eme probabilite d'^etre atteints s'ils ont m^eme longueur, et cette probabilite est la longueur des intervalles. <p> Choisir au hasard, c'est donner les m^emes chances a tous les resultats possibles (equiprobabilite). On attend d'un reel "au hasard" dans <ref> [0; 1] </ref> qu'il tombe entre 0; 4 et 0; 5 avec probabilite 1=10, de m^eme qu'entre 0; 8 et 0; 9. Deux intervalles inclus dans [0; 1] ont la m^eme probabilite d'^etre atteints s'ils ont m^eme longueur, et cette probabilite est la longueur des intervalles. Les postulats ci-dessus ont une autre consequence. <p> Les postulats ci-dessus ont une autre consequence. Si on considere des couples successifs d'appels de Random comme des coordonnees de points du plan, ces points sont des "points au hasard" dans <ref> [0; 1] </ref> 2 . <p> Ceci peut evidemment ^etre etendu en dimension quelconque. Des triplets d'appels de Random successifs sont les coordonnees de "points au hasard" dans le cube <ref> [0; 1] </ref> 3 , etc: : : Proposition 2.1 Pour tout k 2 IN fl , soient (R 1 ; : : : ; R k ) k appels successifs de Ran dom. <p> Definition 2.1 Une suite de reels x = (x n ); n 2 IN dans <ref> [0; 1] </ref> est dite k-uniforme si pour tout rectangle D = [a 1 ; b 1 [fi fi [a k ; b k [; 0 a i &lt; b i 1 ; i = 1; : : : ; k ; n!1 n i=0 La notation 11 D (y) (fonction indicatrice <p> Cette definition est passablement utopique. En particulier elle entra^ine que la probabilite que Random tombe sur un point donne est nulle. Comme qu'il n'y a qu'une quantite denombrable de rationnels dans <ref> [0; 1] </ref>, la probabilite de tomber sur un rationnel est egalement nulle. <p> conna^it que les decimaux, et m^eme seulement un nombre fini d'entre eux, donc la fonction Random ne peut retourner que des rationnels: : : Qu'a cela ne tienne, si on sait construire une suite uniforme de chiffres entre 0 et 9, on pourra en deduire des reels au hasard dans <ref> [0; 1] </ref>, approches a la k-eme decimale, en considerant des k-uplets consecutifs de chiffres de la suite initiale. C'est le principe des "tables de nombres au hasard" que l'on trouve encore dans certains livres. La m^eme remarque vaut bien s^ur en base 2. <p> Tout ce que l'on peut faire, c'est verifier que rien d'invraisemblable ne se produit pour la suite finie observee. C'est precisement l'objet des tests statistiques que de distinguer le plausible de ce qui est trop peu vraisemblable. "Definition" Un N uplet de nombres dans <ref> [0; 1] </ref> sera dit pseudo-aleatoire s'il passe avec succes une serie de tests statistiques, chacun etant destine a verifier une consequence de la k-uniformite. Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. <p> Les valeurs de Random sont toujours calculees a partir d'entiers repartis dans f0; 1; : : : ; M g ou M est un grand nombre (de l'ordre 10 8 au moins pour les generateurs usuels). Pour retourner un reel dans <ref> [0; 1] </ref>, il suffit de diviser par M . En pratique, un nombre fini de valeurs peuvent seules ^etre atteintes, et elles le sont avec une probabilite positive. <p> X 6 Repeter 12 fois X X+Random finRepeter Justification Si (R n ) designe la suite des appels de Random (suite de variables independantes de loi uniforme sur <ref> [0; 1] </ref>), on a R 1 + + R n n=2 n 1 L On evite une division et on obtient une approximation deja correcte en prenant n = 12. Cet algorithme n'est cependant pas conseille avec les generateurs classiques. <p> Elle consiste a composer un appel de Random avec l'inverse de la fonction de repartition de la loi a simuler. Soit F cette fonction de repartition. C'est une fonction de IR dans <ref> [0; 1] </ref>, croissante au sens large et continue a droite. Nous convenons de definir son inverse de la facon suivante. 8u 2 [0; 1] ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire <p> Soit F cette fonction de repartition. C'est une fonction de IR dans <ref> [0; 1] </ref>, croissante au sens large et continue a droite. Nous convenons de definir son inverse de la facon suivante. 8u 2 [0; 1] ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire de loi uniforme sur [0; 1]. <p> Nous convenons de definir son inverse de la facon suivante. 8u 2 <ref> [0; 1] </ref> ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire de loi uniforme sur [0; 1]. La variable aleatoire X = F 1 (U ) a pour fonction de repartition F . <p> Supposons qu'il existe une constante c telle que 19 Soit X une variable aleatoire de loi q et U une variable aleatoire de loi uniforme sur <ref> [0; 1] </ref>, independante de X. Alors la loi conditionnelle de X sachant l'evenement "U cq (X) &lt; p (X) est la loi p. On verifie facilement que la probabilite de l'evenement par lequel on conditionne est 1=c. Le nombre moyen de tirages avant acceptation est donc c. <p> Proposition 2.6 Soient f et g deux densites de probabilite sur IR d telles qu'il existe une constante c verifiant : 8x 2 IR d ; cg (x) f (x) : Soit X une variable aleatoire de densite g et U une variable aleatoire de loi uniforme sur <ref> [0; 1] </ref>, independante de X. Alors la loi conditionnelle de X sachant l'evenement E "cUg (X) &lt; f (X)" a pour densite f . Demonstration : On peut deduire ce resultat des propositions 2.3 et 2.4. Voici une demonstration directe. <p> Exemple Soit a simuler la loi de densite f (x) = 1 x 2 11 [1;1] (x) : (loi de l'abscisse d'un point au hasard dans le disque unite). Partons de la loi uniforme sur <ref> [1; 1] </ref>: 1 11 [1;1] (x) : Prenons c = 4 (n'importe quelle constante superieure a 4 conviendrait mais il faut choisir c minimale). Voici l'algorithme. <p> Exemple. Considerons la densite suivante. f (x) = &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; 0 si x &lt; 0 5 x si x 2 <ref> [0; 1] </ref> 5 1 1 5 x si x 2 [2; 3] 5 2 0 si x &gt; 4 @ @ @ A A A A A j 1 j 2 j 3 j 4 26 Voici un algorithme de simulation par decomposition correspondant au decoupage en 5 densites de la <p> Supposons par exemple que la loi (p ij ) j2E soit simulee par inversion. Notons * U n le n-eme appel de Random. * l'application de E fi <ref> [0; 1] </ref> dans E qui au couple (i; u) associe l'inverse de la fonction de repartition de la loi (p ij ) j2E , evalue en u (voir 2.3.2). L'algorithme calcule bien X n+1 = (X n ; U n ) : Ceci a une portee plutot theorique. <p> Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [1, 6, 19] </ref>. 3.2.1 Mesures de Gibbs Definition 3.4 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [2] <author> F. Baccelli, G. Cohen, G. Olsder, and J.P. Quadrat. </author> <title> Synchronization and Linearity: an algebra for discrete event systems. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1992. </year>
Reference-contexts: Exemple. Considerons la densite suivante. f (x) = &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; 0 si x &lt; 0 5 x si x 2 [0; 1] 5 1 1 5 x si x 2 <ref> [2; 3] </ref> 5 2 0 si x &gt; 4 @ @ @ A A A A A j 1 j 2 j 3 j 4 26 Voici un algorithme de simulation par decomposition correspondant au decoupage en 5 densites de la figure (remarquer que les probabilites p i sont les aires <p> des taux que peu de coordonnees seront non nulles simultanement pendant une forte proportion du temps, alors la simulation de la cha^ine incluse redevient competitive. 4.2.3 Reseaux de Petri Les reseaux de Petri markoviens peuvent ^etre vus comme le modele markovien le plus general pour des files d'attente synchronisees (voir <ref> [2, 10] </ref>). Un reseau de Petri se compose d'un nombre fini de N places (ou sites) et d'un ensemble fini de T transitions. Chaque place n peut contenir un nombre entier i n de marques (aussi appelees jetons ou charges).
Reference: [3] <author> T. </author> <title> Back. Evolutionary algorithms in theory and practice. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1996. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire. <p> Exemple. Considerons la densite suivante. f (x) = &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; 0 si x &lt; 0 5 x si x 2 [0; 1] 5 1 1 5 x si x 2 <ref> [2; 3] </ref> 5 2 0 si x &gt; 4 @ @ @ A A A A A j 1 j 2 j 3 j 4 26 Voici un algorithme de simulation par decomposition correspondant au decoupage en 5 densites de la figure (remarquer que les probabilites p i sont les aires <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [3, 32, 30, 50, 51] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [4] <author> A.T. Barucha-Reid. </author> <title> Elements of the theory of Markov processes and their Applications. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid <ref> [4] </ref> et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. 78 La file M/M/1 (voir par exemple <ref> [4, 35, 66, 67] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : Pour la simulation par la cha^ine incluse, on aura p ij
Reference: [5] <author> M.A. Berger. </author> <title> An introduction to probability and stochastic processes. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [11] ou Feller [25, 26]. Les livres de Bouleau [7], Snell [65] et Berger <ref> [5] </ref> font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair.
Reference: [6] <author> D. Bertsimas and J. Tsitsiklis. </author> <title> Simulated annealing. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 10-15, </pages> <year> 1993. </year>
Reference-contexts: Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [1, 6, 19] </ref>. 3.2.1 Mesures de Gibbs Definition 3.4 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [7] <author> N. Bouleau. Probabilites de l'ingenieur, </author> <title> variables aleatoires et simulation. </title> <address> Her-mann, Paris, </address> <year> 1985. </year>
Reference-contexts: Les developpements theoriques y seront strictement limites aux justifications des algorithmes introduits. Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [11] ou Feller [25, 26]. Les livres de Bouleau <ref> [7] </ref>, Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. <p> Il est naturel de se demander s'il existe des cha^ines de Markov non simulables. Il n'en existe pas si E est denombrable, ou si E = IR d , muni de sa tribu de boreliens. On n'en rencontrera donc jamais en pratique (voir Bouleau <ref> [7] </ref> p. 208-211 et p. 225). Exemple : Marches aleatoires sur IR d . Soit (U n ); n 2 IN une suite de variables aleatoires independantes et de m^eme loi sur IR d .
Reference: [8] <author> N. Bouleau. </author> <title> Processus stochastiques et applications. </title> <publisher> Hermann, </publisher> <address> Paris, </address> <year> 1988. </year>
Reference-contexts: processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.2) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [46, 8, 33, 42] </ref>). <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [11, 17, 26, 8] </ref>). Comme pour la definition algorithmique des cha^ines de Markov 3.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. Il existe de nom-breuses varietes de processus de Markov.
Reference: [9] <author> N. Bouleau and D. Lepingle. </author> <title> Numerical methods for stochastic processes. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle <ref> [9] </ref>. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58].
Reference: [10] <author> G.W. Brams. Reseaux de Petri: </author> <title> theorie et pratique. </title> <publisher> Masson, </publisher> <address> Paris, </address> <year> 1983. </year>
Reference-contexts: des taux que peu de coordonnees seront non nulles simultanement pendant une forte proportion du temps, alors la simulation de la cha^ine incluse redevient competitive. 4.2.3 Reseaux de Petri Les reseaux de Petri markoviens peuvent ^etre vus comme le modele markovien le plus general pour des files d'attente synchronisees (voir <ref> [2, 10] </ref>). Un reseau de Petri se compose d'un nombre fini de N places (ou sites) et d'un ensemble fini de T transitions. Chaque place n peut contenir un nombre entier i n de marques (aussi appelees jetons ou charges).
Reference: [11] <author> L. Breiman. </author> <title> Probability. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1968. </year>
Reference-contexts: L'ambition de ce cours est uniquement pratique. Les developpements theoriques y seront strictement limites aux justifications des algorithmes introduits. Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman <ref> [11] </ref> ou Feller [25, 26]. Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [11, 17, 26, 8] </ref>). Comme pour la definition algorithmique des cha^ines de Markov 3.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. Il existe de nom-breuses varietes de processus de Markov.
Reference: [12] <author> R. Cairoli and R.C. Dalang. </author> <title> Sequential stochastic optimization. </title> <publisher> Wiley, </publisher> <address> New-York, </address> <year> 1996. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire.
Reference: [13] <author> R. </author> <type> Cerf. </type> <institution> Une theorie asymptotique des algorithmes genetiques. These, Universite Montpellier II, </institution> <year> 1994. </year>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [3, 32, 30, 50, 51]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [13, 14, 15] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28]. <p> dependant des autres parametres de l'algorithme ainsi que de la fonction f, telle que pour m &gt; m fl , lim max ) = 1 : La demonstration est assez technique et il nous est impossible d'en donner un apercu significatif dans le cadre restreint de ce cours : voir <ref> [13] </ref> p. 27 et p. 72. La valeur critique m fl y est decrite en fonction de a; b; c; et f de maniere relativement precise, mais malheureusement elle n'est pas calculable en pratique.
Reference: [14] <author> R. Cerf. </author> <title> The dynamics of mutation-selection algorithms with large population sizes. </title> <journal> Ann. Inst. H. Poincare, Probab. Stat., </journal> <volume> 32(4) </volume> <pages> 455-508, </pages> <year> 1996. </year>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [3, 32, 30, 50, 51]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [13, 14, 15] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [15] <author> R. Cerf. </author> <title> A new genetic algorithm. </title> <journal> Ann. Appl. Probab., </journal> <volume> 6(3) </volume> <pages> 778-817, </pages> <year> 1996. </year>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [3, 32, 30, 50, 51]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [13, 14, 15] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [16] <author> K.L. Chung. </author> <title> Markov chains with stationary transition probabilities. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung <ref> [16] </ref> et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. <p> Dans le cas de variables independantes, nous disposions pour cela du theoreme central limite (theoreme 2.1) dont nous pouvions deduire des intervalles de confiance. Un theoreme central limite est vrai pour la suite (f (X n )) (voir <ref> [16] </ref> p. 94). Mais la variance asympto-tique, qui determine l'amplitude des intervalles de confiance, n'est pas V ar p [f]. Elle est en general impossible a calculer, et peut ^etre tres grande.
Reference: [17] <author> E. C inlar. </author> <title> Introduction to stochastic processes. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1975. </year> <month> 97 </month>
Reference-contexts: Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar <ref> [17] </ref> est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. <p> Ces proprietes du spectre des matrices de transition reversibles sont des cas particuliers de proprietes plus generales que l'on deduit classiquement du theoreme de Perron-Frobenius (voir par exemple <ref> [17] </ref>). Demonstration : Comme DP D 1 est symetrique, ses valeurs propres sont toutes reelles, et ce sont celles de P . Les valeurs propres de I DP D 1 et de I +DP D 1 sont positives ou nulles. Donc celles de P sont comprises entre 1 et 1. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [11, 17, 26, 8] </ref>). Comme pour la definition algorithmique des cha^ines de Markov 3.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. Il existe de nom-breuses varietes de processus de Markov. <p> Sur un espace d'etats denombrable, la plupart des processus de Markov d'inter^et pratique peuvent s'ecrire comme des versions temporisees de cha^ines de Markov (voir ci-dessous 4.1.4 et C inlar <ref> [17] </ref>). 4.1.3 Taux de transition et generateur Nous supposons desormais que l'espace d'etats E = fi; j; : : :g est fini. <p> de matrice de transition P = I + ou i i j6=i La definition de la cha^ine harmonisee s'etend de maniere evidente a des processus de Markov sur des ensembles infinis denombrables, pourvu que sup X ij &lt; 1 : On parle alors de processus harmonisable, ou processus uniformisable (voir <ref> [17, 36] </ref>). 76 On peut voir la simulation de la cha^ine harmonisee comme une extension de la methode de rejet (comparer avec la proposition 2.5). Dans la version temporisee, la suite des instants de saut forme un processus de Poisson homogene d'intensite .
Reference: [18] <author> L. Devroye. </author> <title> Non-uniform random variate generation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye <ref> [18] </ref>. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. <p> Pour I de 1 a 1 000 Pour J de 1 a 1 000 : : : finPour finPour 12 2.3 Methodes d'inversion Nous ne traiterons pas en detail des differentes methodes de simulation des variables aleatoires (voir Devroye <ref> [18] </ref>). Nous donnons simplement quelques idees de base qui sont suffisantes pour la plupart des applications. 2.3.1 Principe La methode d'inversion est la plus simple des methodes generales de simulation. Elle consiste a composer un appel de Random avec l'inverse de la fonction de repartition de la loi a simuler. <p> Toutes ne sont pas a con-seiller. Il est bien s^ur possible de trouver une methode de decomposition, adaptee non seulement a la densite de la loi N (0; 1) mais aussi aux qualites du generateur et du compilateur, qui soit plus rapide que celles qui suivent (voir Devroye <ref> [18] </ref> ou Morgan [52]). Les methodes que nous donnons ici sont faciles a programmer. 2.6.1 Principe Deux algorithmes de simulation usuels sont bases sur le resultat theorique suivant. <p> (x) = e x 11 IR La fonction de repartition correspondante est F X (x) = P rob [X x] = (1 e x ) 11 IR L'esperance et la variance valent respectivement IE [X] = 1 De nombreux algorithmes ont ete proposes pour la simulation des lois exponentielles (voir <ref> [18] </ref>). Nous retiendrons le plus simple, qui est l'algorithme d'inversion. X log (Random)= : Si X suit la loi E (1) alors X= suit la loi E (). En pratique, X represente une duree, typiquement le temps d'attente d'un evenement ou une duree de vie.
Reference: [19] <author> P. Diaconis and L. Saloff-Coste. </author> <title> What do we know about the Metropolis algorithm ? J. </title> <institution> Comp. Sci. Syst., </institution> <note> To appear. </note>
Reference-contexts: la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste [64] ou Diaconis et Saloff-Coste <ref> [19] </ref>). Voici une des plus simples. Proposition 3.6 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [64, 19] </ref>. Au vu de la proposition 3.7, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps. Ceci est justifie par le theoreme suivant. <p> Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [1, 6, 19] </ref>. 3.2.1 Mesures de Gibbs Definition 3.4 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [20] <author> P. Doyle and J. Snell. </author> <title> Random walks and electrical networks. </title> <editor> M. A. A., Washing-ton, </editor> <year> 1984. </year>
Reference-contexts: La cha^ine de Markov de matrice de transition P s'appelle marche aleatoire symetrique sur le graphe G. Il existe une analogie etroite entre les cha^ines de Markov symetriques et les reseaux electriques (voir <ref> [20] </ref>). Les etats de E sont vus comme les sommets d'un reseau, relies par des lignes electriques. L'analogue de la probabilite de transition p ij est la conductance (inverse de la resistance) de la ligne reliant i a j.
Reference: [21] <author> E.J. Dudewicz and T.G. Ralley. </author> <title> The handbook of random number generation and testing with TESTRAND computer code. </title> <publisher> American Sciences Press Inc., </publisher> <address> Colum-bus., </address> <year> 1981. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley <ref> [21] </ref>. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen [40, 41]. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [43, 21, 27] </ref>). 5 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs
Reference: [22] <author> M. Duflo. Methodes recursives aleatoires. Masson, Paris, </author> <year> 1990. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo <ref> [22, 23] </ref> et Robert [57, 58].
Reference: [23] <author> M. Duflo. </author> <title> Algorithmes stochastiques. Mathematiques et applications 23. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo <ref> [22, 23] </ref> et Robert [57, 58].
Reference: [24] <author> R.T. Durrett. </author> <title> Ten lectures on particle systems. </title> <editor> In Ecole d'ete de probabilite de Saint-Flour XXIII (P. Bernard ed.), </editor> <title> L.N. </title> <journal> in Math. </journal> <volume> 1608, </volume> <pages> pages 97-201. </pages> <publisher> Springer, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: faire Si (X (5) &gt; 0 et X (6) &gt; 0) alors X (5) X (5) 1 finSi finSelon t t + 1 Jusqu'a (arr^et de la simulation) t t= 4.2.4 Systemes de particules interactives Nos deux references generales sur les systemes de particules interactives sont Liggett [47] et Durrett <ref> [24] </ref>. Il n'y a pas de difference mathematique entre un reseau de Petri markovien et un systeme de particules sur un ensemble fini de sites. Ce sont deux points de vue de modelisation assez differents, et les deux theories se sont developpees de maniere largement independante.
Reference: [25] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume I. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1968. </year>
Reference-contexts: L'ambition de ce cours est uniquement pratique. Les developpements theoriques y seront strictement limites aux justifications des algorithmes introduits. Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [11] ou Feller <ref> [25, 26] </ref>. Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38].
Reference: [26] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume II. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1971. </year>
Reference-contexts: L'ambition de ce cours est uniquement pratique. Les developpements theoriques y seront strictement limites aux justifications des algorithmes introduits. Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [11] ou Feller <ref> [25, 26] </ref>. Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [11, 17, 26, 8] </ref>). Comme pour la definition algorithmique des cha^ines de Markov 3.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. Il existe de nom-breuses varietes de processus de Markov. <p> Sur K iterations, l'echelle de temps aura ete incrementee de la somme de K variables exponentielles independantes. Bien que ces variables ne soient pas de m^eme loi, le theoreme central limite s'applique dans ce cas (voir Feller <ref> [26] </ref> p. 262). On pourra donc remplacer l'incrementation totale sur les 77 K pas de temps par une variable aleatoire suivant une loi normale de m^eme moyenne et de m^eme variance.
Reference: [27] <author> G.S. Fishman. </author> <title> Monte Carlo concepts algorithms and applications. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman <ref> [27] </ref>. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman [48, 49], bien qu'une litterature importante continue a se developper sur la question. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [43, 21, 27] </ref>). 5 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs
Reference: [28] <author> M.I. Freidlin and A.D. Wentzell. </author> <title> Random perturbations of dynamical systems. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell <ref> [28] </ref>. Nous suivons sa presentation sans rentrer dans les details mathematiques, qui sont tres techniques. 3.3.1 Version classique Les algorithmes genetiques s'inspirent des mecanismes de la selection naturelle, comme le recuit simule s'inspirait de principes physiques. La fonction a optimiser est ici l'adaptation et c'est son maximum que l'on recherche.
Reference: [29] <author> E. Gelenbe and G. Pujolle. </author> <title> Introduction aux reseaux de files d'attente. </title> <publisher> Eyrolles, </publisher> <address> Paris, </address> <year> 1985. </year>
Reference-contexts: La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [29, 37, 59, 61, 67] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [30] <author> D. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [3, 32, 30, 50, 51] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [31] <author> J.M. </author> <title> Hammersley and Handscomb D.C. Monte-Carlo methods. </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1964. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb <ref> [31] </ref>, Morgan [52], Rubinstein [60], Ripley [56], Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9].
Reference: [32] <author> J.H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [3, 32, 30, 50, 51] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [33] <author> I. Karatzas and S.E. Shreve. </author> <title> Brownian motion and stochastic calculus. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year> <month> 98 </month>
Reference-contexts: processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.2) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [46, 8, 33, 42] </ref>).
Reference: [34] <author> S. Karlin. </author> <title> A first course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1966. </year>
Reference-contexts: Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor <ref> [34, 35] </ref>. C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> Ces N echelles de temps sont independantes. La superposition de N echelles de temps independantes est encore un processus de Poisson homogene, d'intensite (1) + + (N) (voir <ref> [34] </ref> p. 226). Cette intensite est l'horloge interne du processus fZ t ; t 0g.
Reference: [35] <author> S. Karlin and H.M. Taylor. </author> <title> A second course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1981. </year>
Reference-contexts: Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor <ref> [34, 35] </ref>. C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 66 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [4, 34, 35, 11, 17, 26, 8] </ref>). La presentation que nous proposons ici n'est pas classique. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. 78 La file M/M/1 (voir par exemple <ref> [4, 35, 66, 67] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : Pour la simulation par la cha^ine incluse, on aura p ij
Reference: [36] <author> J. Keilson. </author> <title> Markov chain models rarity and exponentiality. </title> <booktitle> Applied Mathematical Sciences 28. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: de matrice de transition P = I + ou i i j6=i La definition de la cha^ine harmonisee s'etend de maniere evidente a des processus de Markov sur des ensembles infinis denombrables, pourvu que sup X ij &lt; 1 : On parle alors de processus harmonisable, ou processus uniformisable (voir <ref> [17, 36] </ref>). 76 On peut voir la simulation de la cha^ine harmonisee comme une extension de la methode de rejet (comparer avec la proposition 2.5). Dans la version temporisee, la suite des instants de saut forme un processus de Poisson homogene d'intensite .
Reference: [37] <author> F.P. Kelly. </author> <title> Reversibility and Stochastic Networks. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: On dit que p est une mesure reversible pour la cha^ine de Markov de matrice de transition P , ou que la matrice P est p-reversible, si p i p ij = p j p ji ; 8i; j 2 E : (3.3) Le livre de Kelly <ref> [37] </ref> est une bonne reference generale sur la reversibilite et ses applications. La relation (3.3) s'appelle condition de bilan detaille. Observons tout d'abord qu'une mesure reversible est necessairement stationnaire. <p> avec probabilite 1=r parmi les voisins de i dans E 0 Si (j 2 E) alors X j finSi m m + 1 Jusqu'a (arr^et de la simulation) Des criteres pour verifier si une matrice de transition donnee admet ou non une mesure reversible ont ete donnes par Kolmogorov (voir <ref> [37] </ref>). Nous nous interesserons plutot ici a la construction d'une matrice de transition p-reversible, quand p est une mesure donnee. Voici une methode generale. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [29, 37, 59, 61, 67] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [38] <author> J.G. Kemeny and J.L. Snell. </author> <title> Finite Markov chains. </title> <publisher> Van Nostrand, Princeton, </publisher> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [7], Snell [65] et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell <ref> [38] </ref>. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair. Les livres de Neuts [53, 54] proposent une vision systematiquement tournee vers l'outil informatique. <p> Ce sont en quelque sorte les boutons de reglage de l'algorithme. La cha^ine de Markov (X T n ) est irreductible et aperiodique. Elle converge donc en loi vers une mesure stationnaire unique p T (voir par exemple <ref> [38] </ref>). On souhaite verifier que lorsque T tend vers 0, cette mesure stationnaire se concentre sur les populations optimales. Contrairement au cas du recuit simule, ce n'est pas toujours vrai.
Reference: [39] <author> W.J. Kennedy and J.E. </author> <title> Gentle. Statistical computing. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle <ref> [39] </ref>, Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9].
Reference: [40] <author> J.P.C. Kleijnen. </author> <title> Statistical techniques in simulation, Part I. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen <ref> [40, 41] </ref>. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable.
Reference: [41] <author> J.P.C. Kleijnen and W. Van Groenendaal. </author> <title> Simulation, a statistical perspective. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen <ref> [40, 41] </ref>. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable.
Reference: [42] <author> P.E. Kloeden and E. Platen. </author> <title> Numerical solution of stochastic differential equations. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen <ref> [42] </ref> est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. <p> Nous traitons dans le paragraphe suivant une methode de simulation des processus de diffusion, dont le mouvement brownien est un cas particulier. 3.1.2 Simulation des processus de diffusion La reference generale sur le sujet est le livre de Kloeden et Platen <ref> [42] </ref>. Nous ne presentons ici que la methode la plus simple, qui est la generalisation aux processus de diffusion de la methode d'Euler pour les solutions d'equations differentielles ordinaires. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.2) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [46, 8, 33, 42] </ref>). <p> Ceci ne pose pas de probleme si d 0 est pair, mais peut conduire a doubler les instructions dans la boucle principale (simuler deux pas consecutifs) si d 0 est impair. Il existe de nombreuses autres methodes pour simuler les processus de diffusion (voir Kloeden et Platen <ref> [42] </ref>). La methode d'Euler-Maruyama, si elle est la moins precise de toutes, presente l'avantage d'^etre la plus naturelle, la plus facile a programmer, et la plus rapide a l'execution. <p> Dans le cas deterministe, la methode d'Euler est connue pour "cumuler les erreurs" (au sens ou l'ecart entre la solution exacte et son approximation numerique augmente avec le temps). C'est aussi le cas pour la version stochastique. Le probleme de la stabilite numerique est aborde dans <ref> [42] </ref> p. 331-337. 3.1.3 Cha^ines homogenes sur un ensemble fini Lorsque E = fi; j; : : :g est un ensemble fini, la famille de lois de probabilite des variables aleatoires (n; i; U n ) (cf. definition 3.1) avec laquelle on tire le pas n+1 a partir du pas n,
Reference: [43] <author> D.E. Knuth. </author> <booktitle> The art of computer programming, volume 2, seminumerical algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1981. </year>
Reference-contexts: La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman [48, 49], bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth <ref> [43] </ref> et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen [40, 41]. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [43, 21, 27] </ref>). 5 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs
Reference: [44] <author> P. J. Laurent. </author> <title> Les methodes de Monte-Carlo. </title> <institution> Universite Joseph Fourier, Grenoble, </institution> <year> 1966. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent <ref> [44] </ref>, Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley [56], Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9].
Reference: [45] <author> E.L. Lawler, J.K. Lensra, A.H.G. Rinnooy Kan, </author> <title> and D.B. Shmoys. The traveling salesman problem. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: En general plusieurs choix sont possibles et on pourra opter pour une structure de voisinage qui permette une exploration plus rapide de l'espace si cela n'alourdit pas trop l'algorithme. A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [45, 55] </ref>). Exemple : Le probleme du voyageur de commerce [45, 55]. <p> A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [45, 55] </ref>). Exemple : Le probleme du voyageur de commerce [45, 55].
Reference: [46] <author> A. Le Breton. Calcul stochastique. Cours de DEA UJF, </author> <year> 1996. </year>
Reference-contexts: processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.2) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [46, 8, 33, 42] </ref>).
Reference: [47] <author> T.M. Liggett. </author> <title> Interacting Particle Systems. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: type = fl faire Si (X (5) &gt; 0 et X (6) &gt; 0) alors X (5) X (5) 1 finSi finSelon t t + 1 Jusqu'a (arr^et de la simulation) t t= 4.2.4 Systemes de particules interactives Nos deux references generales sur les systemes de particules interactives sont Liggett <ref> [47] </ref> et Durrett [24]. Il n'y a pas de difference mathematique entre un reseau de Petri markovien et un systeme de particules sur un ensemble fini de sites. Ce sont deux points de vue de modelisation assez differents, et les deux theories se sont developpees de maniere largement independante.
Reference: [48] <author> G. Marsaglia and A. Zaman. </author> <title> Toward a universal random number generator. </title> <journal> Stat. Prob. Lett., </journal> <volume> 8 </volume> <pages> 35-39, </pages> <year> 1990. </year>
Reference-contexts: La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [48, 49] </ref>, bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. <p> La solution de l'initialisation par le compteur de temps peut poser un probleme sur les gros systemes ou l'horloge est d'acces reserve. On trouve depuis quelques annees sur le reseau un ensemble de procedures proposees par Marsaglia et Zaman <ref> [48, 49] </ref>. Ces procedures sont presentees sous forme de fichier compresse, selon les systemes d'exploitation (par exemple FSULTRA1.ZIP pour DOS). Une fois decompresse on obtient un ensemble de procedures en Assembleur, Pascal, C, Fortran qui implementent le generateur ULTRA, dont les qualites sont tres superieures a celles des generateurs classiques.
Reference: [49] <author> G. Marsaglia and A. Zaman. </author> <title> A new class of random number generators. </title> <journal> Ann. Appl. Probab., </journal> <volume> 1 </volume> <pages> 462-480, </pages> <year> 1991. </year>
Reference-contexts: La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27]. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [48, 49] </ref>, bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. <p> La solution de l'initialisation par le compteur de temps peut poser un probleme sur les gros systemes ou l'horloge est d'acces reserve. On trouve depuis quelques annees sur le reseau un ensemble de procedures proposees par Marsaglia et Zaman <ref> [48, 49] </ref>. Ces procedures sont presentees sous forme de fichier compresse, selon les systemes d'exploitation (par exemple FSULTRA1.ZIP pour DOS). Une fois decompresse on obtient un ensemble de procedures en Assembleur, Pascal, C, Fortran qui implementent le generateur ULTRA, dont les qualites sont tres superieures a celles des generateurs classiques.
Reference: [50] <author> Z. Michalewicz. </author> <title> Genetic algorithms + Data structures = Evolution programs, </title> <publisher> 3rd ed. Springer, </publisher> <address> New-York, </address> <year> 1996. </year> <month> 99 </month>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [3, 32, 30, 50, 51] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [51] <author> M. Mitchell. </author> <title> An introduction to genetic algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [3, 32, 30, 50, 51] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [13, 14, 15] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [28].
Reference: [52] <author> B.J.T. Morgan. </author> <title> Elements of simulation. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1984. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan <ref> [52] </ref>, Rubinstein [60], Ripley [56], Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. <p> Il est bien s^ur possible de trouver une methode de decomposition, adaptee non seulement a la densite de la loi N (0; 1) mais aussi aux qualites du generateur et du compilateur, qui soit plus rapide que celles qui suivent (voir Devroye [18] ou Morgan <ref> [52] </ref>). Les methodes que nous donnons ici sont faciles a programmer. 2.6.1 Principe Deux algorithmes de simulation usuels sont bases sur le resultat theorique suivant.
Reference: [53] <author> M.F. Neuts. </author> <title> Matrix-geometric solutions in stochastic models. </title> <publisher> The John Hopkins University Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair. Les livres de Neuts <ref> [53, 54] </ref> proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27].
Reference: [54] <author> M.F. Neuts. </author> <title> Algorithmic Probability: a collection of problems. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35]. C inlar [17] est particulierement clair. Les livres de Neuts <ref> [53, 54] </ref> proposent une vision systematiquement tournee vers l'outil informatique. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [27].
Reference: [55] <author> G. Reinelt. </author> <title> The traveling salesman: computational solutions for TSP applications. </title> <editor> L. N. </editor> <booktitle> in Computer Science 840. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: En general plusieurs choix sont possibles et on pourra opter pour une structure de voisinage qui permette une exploration plus rapide de l'espace si cela n'alourdit pas trop l'algorithme. A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [45, 55] </ref>). Exemple : Le probleme du voyageur de commerce [45, 55]. <p> A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [45, 55] </ref>). Exemple : Le probleme du voyageur de commerce [45, 55].
Reference: [56] <author> B.D. Ripley. </author> <title> Stochastic simulation. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein [60], Ripley <ref> [56] </ref>, Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable.
Reference: [57] <author> C.P. Robert. L'Analyse Statistique Bayesienne. Economica, </author> <year> 1992. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert <ref> [57, 58] </ref>.
Reference: [58] <editor> C.P. Robert. Methodes de Monte-Carlo par cha^ines de Markov. CREST-INSEE, </editor> <address> Paris, </address> <year> 1996. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable. Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert <ref> [57, 58] </ref>.
Reference: [59] <author> T.G. Robertazzi. </author> <title> Computer networks and systems: queuing theory and performance evaluation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [29, 37, 59, 61, 67] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [60] <author> R.Y. Rubinstein. </author> <title> Simulation and the Monte-Carlo method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [43] et Dudewicz et Ralley [21]. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Laurent [44], Kennedy et Gentle [39], Hammersley et Handscomb [31], Morgan [52], Rubinstein <ref> [60] </ref>, Ripley [56], Kleijnen [40, 41]. Le plus complet sur le sujet est le livre de Devroye [18]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [9]. Pour les processus de diffusion Kloeden et Platen [42] est la reference indispensable.
Reference: [61] <author> R.Y. Rubinstein. </author> <title> Monte-Carlo optimization, simulation and sensitivity of queuing networks. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [29, 37, 59, 61, 67] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [62] <author> R.Y. Rubinstein and B. Melamed. </author> <title> Efficient simulation and Monte-Carlo methods. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente.
Reference: [63] <author> R.Y. Rubinstein and A. Shapiro. </author> <title> Discrete event systems: sensitivity analysis and stochastic optimization by the score function method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente.
Reference: [64] <author> L. Saloff-Coste. </author> <title> Lectures on finite Markov chains. </title> <institution> Notes de Cours, Ecole d'ete de probabilites de Saint-Flour, a para^itre, </institution> <year> 1996. </year>
Reference-contexts: Il existe dans la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste <ref> [64] </ref> ou Diaconis et Saloff-Coste [19]). Voici une des plus simples. Proposition 3.6 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [64, 19] </ref>. Au vu de la proposition 3.7, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps. Ceci est justifie par le theoreme suivant.
Reference: [65] <author> J.L. Snell. </author> <title> Introduction to probability. Random House, </title> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Les developpements theoriques y seront strictement limites aux justifications des algorithmes introduits. Les notions de probabilites qui seront utilisees sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [11] ou Feller [25, 26]. Les livres de Bouleau [7], Snell <ref> [65] </ref> et Berger [5] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [16] et Kemeny et Snell [38]. Un point de vue plus applique est celui de Barucha-Reid [4] et Karlin et Taylor [34, 35].
Reference: [66] <author> K.S. Trivedi. </author> <title> Probability and Statistics with Reliability, Queuing and Computer Science Applications. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. 78 La file M/M/1 (voir par exemple <ref> [4, 35, 66, 67] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : Pour la simulation par la cha^ine incluse, on aura p ij
Reference: [67] <author> J. Walrand. </author> <title> Introduction to Queuing Networks. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. 78 La file M/M/1 (voir par exemple <ref> [4, 35, 66, 67] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : Pour la simulation par la cha^ine incluse, on aura p ij <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [29, 37, 59, 61, 67] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [68] <author> K. Watkins. </author> <title> Discrete event simulation in C. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1993. </year> <month> 100 </month>
Reference-contexts: 1 Introduction La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite non seulement une litterature importante <ref> [59, 61, 63, 62, 66, 68, 70] </ref>, mais aussi le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP. Ces langages offrent de nombreuses possibilites de choix en particulier pour les lois de probabilite des temps d'interarrivees et temps de service des files d'attente.
Reference: [69] <author> G. Winkler. </author> <title> Image analysis, random fields and dynamic Monte-Carlo methods. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Les applications des methodes MCMC en statistique sont traitees en particulier par Duflo [22, 23] et Robert [57, 58]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [3, 12, 30, 32, 50, 51, 69] </ref>). 2 2 Simulation des variables aleatoires 2.1 Generateurs pseudo-aleatoires 2.1.1 Postulats Tous les langages (ou presque) disposent d'un generateur pseudo-aleatoire.

References-found: 69

