URL: http://www.cs.berkeley.edu/~cpwen/cpwen/nn.ps
Refering-URL: http://www.cs.berkeley.edu/~cpwen/
Root-URL: 
Email: Email: cywen@fuzzy.ee.hwh.edu.tw  
Title: EXPLOITING DON'T-CARE INFORMATION IN NEURAL NETWORK LEARNING  
Author: Chung-Yao Wen 
Address: Taipei, Taiwan  
Affiliation: Department of Electronics Engineering Hwa-Hsia College of Technology and Commerce  
Abstract: In this paper, we present a novel neural network architecture called M-net, which exploits the don't-care information in training multilayer feedforward neural networks. Our method takes advantage of the user's prior knowledge as well as the neural network's ability to learn from examples. The user's prior knowledge is encoded in the form of don't-care inputs to reduce the number of training patterns required to represent a function. We derive the learning rule of M-net in the context of error backpropagation, and demonstrate its use on the priority decoding problem. Compared with conventional backpropagation networks, M-net drastically reduces the learning time while achieving superior quality. 
Abstract-found: 1
Intro-found: 1
Reference: [Dru90] <author> H. </author> <title> Drucker. Implementation of a neural net expert system in the presence of don't care and don't know features. </title> <booktitle> In International Symposium on Circuits and Systems, </booktitle> <address> New Orleans, </address> <year> 1990. </year>
Reference-contexts: The former is alleviated using incremental weight updates, while the latter is an intended trade-off of accuracy for speed. However, learning with M-net has much better predictive power than backpropagation given the same training error. 4. RELATED WORK Drucker <ref> [Dru90] </ref> proposes an ad hoc architecture for handling don't-care and don't-know attributes in ordnance identification. He uses a special weight setting method for learning, in which special input tokens are used to represent don't-care and don't-know attributes.

References-found: 1

