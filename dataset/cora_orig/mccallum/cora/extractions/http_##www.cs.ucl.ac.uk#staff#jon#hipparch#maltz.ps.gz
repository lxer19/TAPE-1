URL: http://www.cs.ucl.ac.uk/staff/jon/hipparch/maltz.ps.gz
Refering-URL: http://www.cs.ucl.ac.uk/staff/jon/hipparch/program.html
Root-URL: http://www.cs.ucl.ac.uk
Email: dmaltz@cs.cmu.edu  pravin@watson.ibm.com  
Title: Improving HTTP Caching Proxy Performance with TCP Tap  
Author: David A. Maltz Pravin Bhagwat 
Keyword: TCP, HTTP Caches, Application Layer Proxies, Performance  
Affiliation: Dept. of Computer Science Carnegie Mellon University  IBM T.J. Watson Research Center  
Abstract: Application layer proxies are an extremely popular method for adding new services to existing network applications. They provide backwards compatibility, centralized administration, and the convenience of the application layer programming environment. Since proxies serve multiple clients at the same time, they are traffic concentrators that often become performance bottlenecks during peak load periods. In this paper we present an extension of the TCP Splice technique [6] called TCP Tap that promises to dramatically improve the performance of an HTTP caching proxy, just as TCP Splice doubled the throughput of an application layer firewall proxy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Berners-Lee, R. Fielding, and H. Frystyk. </author> <title> Hypertext transfer protocol - HTTP/1.0. Internet Request For Comments RFC 1945, </title> <month> May </month> <year> 1996. </year>
Reference-contexts: TCP Tap extends TCP Splice to support the class of proxies which need to read the data that flows through them, such as HTTP <ref> [1, 4] </ref> and PICS proxies [8]. Using a combination of TCP Splice and TCP Tap, we describe how it is possible to build HTTP caching proxies that can provide better throughput in addition to reducing access latency for all web clients. <p> This use of TCP Tap is illustrated in Figure 4. The TCP Tap can be easily integrated into an application layer HTTP/1.0 caching proxy <ref> [1] </ref> as follows: Web browsers using a caching proxy first connect to the proxy and transmit their HTTP GET request. If the cache already holds the requested entity and the contents of the cache are valid, the application layer proxy serves the entity from its cache. <p> The proxy receives a GET from the client. 2. The proxy consults its cache, and if it must fetch the requested entity from the server it converts the GET headers into the form that can be sent to the server as is standard practice for HTTP caches <ref> [1, 4] </ref>. 3. The proxy opens a connection to the server, and splices the client-proxy connection to the proxy-server connection. The proxy tells the splice that it intends to write the number of bytes in the GET header into the proxy-server connection before the splice completes. 4.
Reference: [2] <author> Jose Carlos Brustoloni. </author> <title> User-level protocol servers with kernel-level performance. </title> <booktitle> In IEEE INFOCOM'98: Proceedings of the Seventeenth Annual Joint Conference of the IEEE Computer and Communications Societies, </booktitle> <pages> pages 463-471, </pages> <address> San Francisco, CA, </address> <month> April </month> <year> 1998. </year> <note> IEEE. Available as http://www.cs.cmu.edu/afs/cs/user /jcb/papers/infocom98.ps. </note>
Reference-contexts: We do no yet have the experimental data to evaluate this strategy. operations that have to be performed when the packet is received and forwarded by an application layer proxy with a checksum update operation. Advanced buffer management techniques <ref> [2] </ref> could be used to eliminate the data copies, but unless TCP Splice is in use the proxy must still incur the overhead of checksumming the data twice and of running two TCP state machines with their associated buffers, sockets, and timers.
Reference: [3] <author> David D. Clark, Van Jacobson, John Romkey, and Howard Salwen. </author> <title> An analysis of TCP processing overhead. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The first is a decrease in system overhead and resource requirements. The second is a reduction in the latency the proxy system imposes on end-to-end transfer times, and the third is a simple API to ease integration into proxy systems. TCP Splice reduces system overhead in several ways. Clark <ref> [3] </ref> reports that the cost of operating a TCP connection is dominated by the per-byte operations and the operating system support, such as timers and memory buffers (mbufs).
Reference: [4] <author> R. Fielding, J. Gettys, J. Mogul, H. Frystyk, and T. Berners-Lee. </author> <title> Hypertext transfer protocol - HTTP/1.1. Internet Request For Comments RFC 2068, </title> <month> January </month> <year> 1997. </year>
Reference-contexts: TCP Tap extends TCP Splice to support the class of proxies which need to read the data that flows through them, such as HTTP <ref> [1, 4] </ref> and PICS proxies [8]. Using a combination of TCP Splice and TCP Tap, we describe how it is possible to build HTTP caching proxies that can provide better throughput in addition to reducing access latency for all web clients. <p> The proxy receives a GET from the client. 2. The proxy consults its cache, and if it must fetch the requested entity from the server it converts the GET headers into the form that can be sent to the server as is standard practice for HTTP caches <ref> [1, 4] </ref>. 3. The proxy opens a connection to the server, and splices the client-proxy connection to the proxy-server connection. The proxy tells the splice that it intends to write the number of bytes in the GET header into the proxy-server connection before the splice completes. 4. <p> It does this by telling the splice that it intends to write those bytes into the proxy-client connection before the splice completes. Queued packets are forwarded using the normal splice forwarding logic thereafter. The HTTP 1.1 protocol <ref> [4] </ref> introduces several new complexities to the role of the proxy, and especially a proxy using TCP Splice and TCP Tap. In HTTP 1.1, the client makes one connection to the proxy, and then sends the proxy multiple HTTP GET requests over that one connection. <p> Later, whenever it finds spare cycles, it can fill the gaps by issuing additional requests for the document to the server using the Range Request header with a conditional GET <ref> [4] </ref> to retrieve only the missing parts. We have not tested TCP Tap against a real HTTP cache workload, but insights derived from the TCP Splice performance measurements suggest that the probability of a tap buffer overflow will be low.
Reference: [5] <author> David A. Maltz and Pravin Bhagwat. MSOCKS: </author> <title> an architecture for transport layer mobility. </title> <booktitle> In IEEE INFOCOM'98: Proceedings of the Seventeenth Annual Joint Conference of the IEEE Computer and Communications Societies, </booktitle> <pages> pages 1037-1045, </pages> <address> San Francisco, CA, </address> <month> April </month> <year> 1998. </year> <note> IEEE. Available from http://www.cs.cmu.edu/dmaltz. </note>
Reference-contexts: In HTTP 1.1, the client makes one connection to the proxy, and then sends the proxy multiple HTTP GET requests over that one connection. We plan to support HTTP 1.1 caching proxies using a combination of TCP Tap and the TCP Resplice operation <ref> [5] </ref>, which allows sets of arbitrary TCP connections to be spliced together, unspliced, and spliced back together again.
Reference: [6] <author> David A. Maltz and Pravin Bhagwat. </author> <title> TCP splicing for application layer proxy performance. </title> <type> Technical Report RC 21139, </type> <institution> IBM, </institution> <month> March </month> <year> 1998. </year> <note> Available from http://www.cs.cmu.edu/dmaltz. </note>
Reference-contexts: The performance and latency problems both stem from the application layer nature of the proxies. The semantics problem stems from their split-connection nature. TCP Splice <ref> [6] </ref> is a new technique that solves these three problems for some classes of split-connection proxies, such as firewall proxies, which spend most of the processing resources at the proxy moving data between the two connections. <p> There is no protocol state machine at the endpoints on the proxy. There are no buffers or timers to manage, and the proxy does not send retransmissions, as happens in the other systems. 2.1 TCP Splice Implementation A detailed description of how to implement TCP Splice is presented in <ref> [6] </ref>. This section gives a very high-level overview in order to explain the performance and semantics benefits of TCP Splice.
Reference: [7] <author> Erich Nahum, Tsipora Barzilai, and Dilip Kandlur. </author> <title> Evaluating high performance socket api's on aix. </title> <type> Technical report, </type> <institution> IBM Thomas J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> February </month> <year> 1998. </year> <note> Submitted for publication. </note>
Reference-contexts: We have made minimal changes to the socket API to maximize the ability of programmers to include TCP Splice and TCP Tap in their proxies. Recent studies of web server performance <ref> [7, 10] </ref> have shown that WWW servers spend most of their time in the kernel. A significant part of this time is spent in system call processing and copying data across the user-kernel protection boundary. <p> A significant part of this time is spent in system call processing and copying data across the user-kernel protection boundary. A web sever makes at least fourteen system calls to process even the smallest GET request <ref> [7] </ref>, thus reducing system call overhead is a commonly used technique for improv 5 ing web server and proxy performance.
Reference: [8] <author> Paul Resnick and Jim Miller. PICS: </author> <title> internet access controls without censorship. </title> <journal> Communications of the ACM, </journal> <volume> 39(10) </volume> <pages> 87-93, </pages> <year> 1996. </year>
Reference-contexts: TCP Tap extends TCP Splice to support the class of proxies which need to read the data that flows through them, such as HTTP [1, 4] and PICS proxies <ref> [8] </ref>. Using a combination of TCP Splice and TCP Tap, we describe how it is possible to build HTTP caching proxies that can provide better throughput in addition to reducing access latency for all web clients.
Reference: [9] <author> Gary R. Wright and W. Richard Stevens. TCP/IP IIlustrated, </author> <booktitle> The Implementation, </booktitle> <volume> volume 2. Addison-Welsley, </volume> <year> 1995. </year>
Reference-contexts: As a result, maintaining a TCP Tap into a spliced connection is a relatively inexpensive operation. The basic operation of a TCP Tap is identical to that of the normal TCP reassembly buffer <ref> [9] </ref>. As data flows through the splice, data not currently in the reassembly buffer are added in the appropriate place. However, as described earlier, there is no TCP state machine associated with the tap buffer at the proxy.
Reference: [10] <author> David Yates, Virgilio Almeida, and Jussara M Almeida. </author> <title> On the Interaction Between an Operating System and Web Server. </title> <type> Technical Report CS 97-012, </type> <institution> Boston University, Computer Science Dept., </institution> <address> Boston, MA, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: We have made minimal changes to the socket API to maximize the ability of programmers to include TCP Splice and TCP Tap in their proxies. Recent studies of web server performance <ref> [7, 10] </ref> have shown that WWW servers spend most of their time in the kernel. A significant part of this time is spent in system call processing and copying data across the user-kernel protection boundary.
Reference: [11] <author> Bruce Zenel and Dan Duchamp. </author> <title> General purpose proxies: Solved and unsolved problems. </title> <booktitle> In Proceedings of Hot-OS VI, </booktitle> <month> May </month> <year> 1997. </year> <note> Read as http://www.mcl.cs.columbia.edu/baz/ps/hot-os-vi.ps. 6 </note>
Reference-contexts: 1 Introduction Many designs for Internet services use application layer split-connection proxies in which a proxy machine is interposed between the server and the client machines in order to mediate the communication between them. Split-connection proxies have been used for everything from HTTP caches to security firewalls to encryption servers <ref> [11] </ref>. Split-connection proxy designs are attractive because they are backwards compatible with existing servers, allow administration of the service at a single point (the proxy), and typically are easy to integrate with existing applications.
References-found: 11

