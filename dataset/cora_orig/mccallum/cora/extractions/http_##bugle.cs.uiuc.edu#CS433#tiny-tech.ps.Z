URL: http://bugle.cs.uiuc.edu/CS433/tiny-tech.ps.Z
Refering-URL: http://bugle.cs.uiuc.edu/CS433.html
Root-URL: http://www.cs.uiuc.edu
Email: mwolfe@cse.ogi.edu  
Phone: (503)-690-1153  
Title: The Tiny Loop Restructuring Research Tool  
Author: Michael Wolfe 
Address: 19600 NW von Neumann Drive Beaverton, OR 97006  
Affiliation: Oregon Graduate Institute of Science and Technology Department of Computer Science and Engineering  
Abstract-found: 0
Intro-found: 1
Reference: [AKL81] <author> W. A. Abu-Sufah, D. J. Kuck and D. H. Lawrie, </author> <title> On the Performance Enhancement of Paging Systems Through Program Analysis and Transformations, </title> <journal> IEEE Trans. on Computers C-30, </journal> <month> 5 (May </month> <year> 1981), </year> <pages> 341-356. </pages>
Reference-contexts: we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory <ref> [AKL81] </ref> reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies.
Reference: [AlK82] <author> J. R. Allen and K. Kennedy, </author> <title> PFC: A Program to Convert Fortran to Parallel Form, in Supercomputers: Design and Applications, </title> <editor> K. Hwang (ed.), </editor> <publisher> IEEE Computer Society Press, </publisher> <address> Silver Spring, MD, </address> <year> 1982, </year> <pages> 186-203. </pages>
Reference-contexts: We present a table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism <ref> [AlK82] </ref> strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L
Reference: [AlK84] <author> J. R. Allen and K. Kennedy, </author> <title> Automatic Loop Interchange, </title> <booktitle> in Proc. of the SIGPLAN 84 Symposium on Compiler Construction, </booktitle> <address> New York, </address> <month> June </month> <year> 1984, </year> <pages> 233-246. </pages>
Reference-contexts: table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism <ref> [AlK84] </ref> interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation
Reference: [ACK87] <author> R. Allen, D. Callahan and K. Kennedy, </author> <title> Automatic Decomposition of Scientific Programs for Parallel Execution, </title> <booktitle> in Conf. Record of the 14th Annual ACM Symp. on Principles of Programming Languages, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1987, </year> <pages> 63-76. </pages>
Reference-contexts: of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism <ref> [ACK87] </ref> splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies. <p> Parallelization. Simple parallelization corresponds to finding loops with no loop carried dependence relations and marking them parallel <ref> [ACK87] </ref>. It is not a restructuring transformation in the sense of the previous transformations, but simply a recognition of parallelism in the program. Tiny can also attempt parallel-ization of each loop in the program after each transformation. Bumping.
Reference: [AlK87] <author> J. R. Allen and K. Kennedy, </author> <title> Automatic Translation of Fortran Programs to Vector Form, </title> <journal> ACM Transactions on Programming Languages and Systems 9, </journal> <month> 4 (October </month> <year> 1987), </year> <pages> 491-542. </pages>
Reference-contexts: We present a table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization <ref> [AlK87] </ref> interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory"
Reference: [BCK79] <author> U. Banerjee, S. Chen, D. J. Kuck and R. A. Towle, </author> <title> Time and Parallel Processor Bounds for Fortran-Like Loops, </title> <journal> IEEE Trans. on Computers C-28, </journal> <month> 9 (September </month> <year> 1979), </year> <pages> 660-670. </pages>
Reference-contexts: Reversal negates the dependence distance and direction vector elements for that loop, and is its own inverse. Distribution. Loop distribution is useful when attempting to interchange non-tightly nested loops, or to break a loop with a forward loop-carried dependence relation into two separate parallel loops <ref> [BCK79] </ref>. Loop distribution partitions the statements of the loop into strongly-connected regions (treating inner loops like a single statement) based on the dependence graph [Tar72].
Reference: [Ban79] <author> U. Banerjee, </author> <title> Speedup of Ordinary Programs, </title> <type> PhD Thesis, </type> <institution> Univ. of Illinois, </institution> <month> October </month> <year> 1979. </year> <pages> (UMI 80-08967). </pages>
Reference-contexts: list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism <ref> [Ban79] </ref> ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies. <p> Splitting. We also see the need for index set splitting; this has been proposed in the past as a way of exposing more parallelism in a loop, where the dependence relations change sense half-way through the execution of the loop <ref> [Ban79] </ref>. We see the need for splitting the index set to enable other transformations. For instance, if we use Tiny to produce the 6 versions of Gaussian Elimination (without pivoting), it turns out we get stuck in one place.
Reference: [Ban90] <author> U. Banerjee, </author> <title> A Theory of Loop Permutations, in Languages and Compilers for Parallel Computing, </title> <editor> D. Gelernter, A. Nicolau and D. Padua (ed.), </editor> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990, </year> <pages> 54-74. </pages>
Reference-contexts: Tiny uses the same algorithm as used in loop distribution to insure that there are no infeasible cycles and the proper placement of statements after interchanging. The second variation is a generalized loop interchanging called loop circulation <ref> [Ban90] </ref>. Loop circulation corresponds to interchanging one loop outwards (or inwards) multiple times (over tightly nested loops). One advantage of loop circulation is that it requires only a single dependence test (so is a little faster).
Reference: [GJG88] <author> D. Gannon, W. Jalby and K. Gallivan, </author> <title> Strategies for Cache and Local Memory Management by Global Program Transformation, </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing 5, </booktitle> <month> 5 (October </month> <year> 1988), </year> <pages> 587-616, </pages> <publisher> Academic Press. </publisher>
Reference-contexts: of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory <ref> [GJG88] </ref> skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance
Reference: [GoT88] <author> M. B. Gokhale and T. C. Torgerson, </author> <title> The Symbolic Hyperplane Transformation for Recursively Defined Arrays, </title> <booktitle> in Proc. of Supercomputing 88, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Los Angeles, </address> <year> 1988, </year> <pages> 207-214. </pages> <address> Orlando, FL, </address> <month> November 14-18, </month> <year> 1988. </year>
Reference: [Knu73] <author> D. Knuth, </author> <title> The Art of Computer Programming: Fundamental Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: of a nested loop algorithm, but that does not mean that they shouldO be written in such a most primitive form (e.g., we can argue that any computer program can be written using an idealized assembler language, but that does not mean we should write all our programs in MIX <ref> [Knu73] </ref>). We believe that loop restructuring is a powerful method to improve the performance characteristics of a program by matching the program to complex architectures.
Reference: [Lam75] <author> L. Lamport, </author> <title> The Hyperplane Method for an Array Computer, </title> <booktitle> in Parallel Processing: Proc. of the Sagamore Computer Conference, </booktitle> <volume> vol. 24, </volume> <editor> T. Feng (ed.), </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1975, </year> <pages> 113-131. </pages>
Reference-contexts: Additionally, there are loops where neither the inner nor the outer loop can be executed in parallel; in these cases, the wavefront methodO or hyperplane methodO was proposed to allow parallel execution of a reindexed loop <ref> [Lam75] </ref>. It has been shown that the wavefront method can be viewed as nothing more than a combination of loop skewing and interchanging, again combining two elementary loop transformations to achieve a powerful result [Wol86b].
Reference: [LeK90] <author> P. Lee and Z. M. Kedem, </author> <title> Mapping Nested Loop Algorithms into Multidimensional Systolic Arrays, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 1 (January </month> <year> 1990), </year> <pages> 64-76. 18 </pages>
Reference: [Lov77] <author> D. Loveman, </author> <title> Program Improvement by Source-to-Source Transformation, </title> <editor> J. </editor> <booktitle> of the ACM 20, </booktitle> <month> 1 (January </month> <year> 1977), </year> <pages> 121-145. </pages>
Reference-contexts: We present a table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization <ref> [Lov77] </ref> distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry
Reference: [Sch72] <author> P. B. Schneck, </author> <title> Automatic Recognition of Vector and Parallel Operations in a Higher Level Language, </title> <journal> SIGPLAN Notices 7, </journal> <month> 11 (November </month> <year> 1972), </year> <pages> 45-52. </pages>
Reference-contexts: We present a table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism <ref> [Sch72] </ref> parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L
Reference: [Tar72] <author> R. Tarjan, </author> <title> Depth-First Search and Linear Graph Algorithms, </title> <journal> in SIAM J. Comput., </journal> <volume> vol. 1, </volume> <month> June. </month> <year> 1972, </year> <pages> 146-160. </pages>
Reference-contexts: Loop distribution partitions the statements of the loop into strongly-connected regions (treating inner loops like a single statement) based on the dependence graph <ref> [Tar72] </ref>. Distribution has little affect on the 13 dependence graph (the distance and direction vectors for dependence relations between statements that get distributed into separate loops get shortened a little); its inverse transformation, loop fusion, is not yet implemented in Tiny. Parallelization.
Reference: [Wed75] <author> D. Wedel, </author> <title> Fortran for the Texas Instruments ASC System, </title> <journal> SIGPLAN Notices 10, </journal> <month> 3 (March </month> <year> 1975), </year> <pages> 119-132. </pages>
Reference-contexts: Those listed above with an bullet are implemented in commercial language products (reversal was implemented in one of the TI ASC compilers <ref> [Wed75] </ref>).
Reference: [Wol78] <author> M. Wolfe, </author> <title> Techniques for Improving the Inherent Parallelism in Programs, </title> <institution> UIUCDCS-R-78-929, Univ. of Illinois, </institution> <month> July </month> <year> 1978. </year>
Reference: [Wol82] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <type> Ph.D. Thesis, </type> <institution> Univ. of Illinois UIUCDCS-82-1105, Urbana, IL, </institution> <month> October </month> <year> 1982. </year> <pages> (UMI 83-03027). </pages>
Reference-contexts: representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging <ref> [Wol82] </ref> alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies.
Reference: [Wol86a] <author> M. Wolfe, </author> <title> Advanced Loop Interchanging, </title> <booktitle> in Proc. of the 1986 Intl Conf. on Parallel Processing, </booktitle> <editor> K. Hwang, S. M. Jacobs and E. E. Swartzlander (ed.), </editor> <address> St. Charles, IL, </address> <month> August 19-22, </month> <year> 1986, </year> <pages> 536-543. </pages>
Reference-contexts: We believe further research is justified into these costs and potential benefits by further experimentation into loop restructuring. 3. Advanced Loops Restructuring Examples Some early experiments in advanced restructuring were described in a prior paper <ref> [Wol86a] </ref>. Our goals now are somewhat more ambitious. (The program examples in this section are taken from screen dumps of the research tool; the line numbers to the left correspond to source code line numbers). First Example. <p> If the inner loop limits depend on the outer loop index, interchanging will modify the loop limits; Tiny allows triangular as well as general trapezoidal loop limits <ref> [Wol86a] </ref>. Loop interchanging is its own inverse. We have implemented two variations on loop interchanging in Tiny. The first is the ability to interchange non-tightly nested loops. We believe this is the first attempt to implement this potentially powerful transformation.
Reference: [Wol86b] <author> M. Wolfe, </author> <title> Loop Skewing: The Wavefront Method Revisited, </title> <booktitle> Intl J. Parallel Programming 15, </booktitle> <month> 4 (August </month> <year> 1986), </year> <pages> 279-294. </pages>
Reference-contexts: In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in [Wol89b]. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism <ref> [Wol86b] </ref> tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies. <p> It has been shown that the wavefront method can be viewed as nothing more than a combination of loop skewing and interchanging, again combining two elementary loop transformations to achieve a powerful result <ref> [Wol86b] </ref>. Some of these 4 advanced applications of loop interchanging are now making their way into commercial products.
Reference: [Wol89a] <author> M. Wolfe, </author> <title> Iteration Space Tiling for Memory Hierarchies, in Parallel Processing for Scientific Computing, </title> <editor> G. Rodrigue (ed.), </editor> <booktitle> Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia PA, </address> <year> 1989, </year> <pages> 357-361. </pages>
Reference: [Wol89b] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: We present a table of some of these below; In each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is available in <ref> [Wol89b] </ref>. ___________________________________________ transformation enhances reference ___________________________________________ vectorization parallelism [Sch72] parallelization parallelism [AlK82] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86b] tiling memory [AKL81] reversal interchanging [Wol82] alignment parallelism [ACK87] splitting parallelism [Ban79] ___________________________________________L L L L L L L L L L L <p> However, in this program, the distribution of the K loop (for instance) is not legal. Fortunately we have already devised the data dependence tests necessary to check for the cases when non-tightly nested loop can legally be interchanged <ref> [Wol89b] </ref>. <p> Each variable reference in the program is linked to its dependence successors and dependence predecessors by a list of data dependence arcs. The data dependence arcs in Tiny are augmented with a direction vector and a distance vector <ref> [Wol89b] </ref>. For most of the transformations in Tiny, this abstract representation of the dependence relations is precise enough to handle the dependence constraints. However, some transformations need even more precise information, and we will show how Tiny handles these cases. <p> The way to test for this is to compute a direction (or distance) vector element for the to-be-fused loop position, and test for a (&gt;) direction (or negative distance) <ref> [Wol89b] </ref>. Rotation. Loop rotation is useful for mapping loop algorithms onto distributed memory systems [Wol89c].
Reference: [Wol89c] <author> M. Wolfe, </author> <title> Loop Rotation, </title> <type> CS/E 89-004, </type> <institution> Oregon Graduate Institute, Beaverton OR, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: The way to test for this is to compute a direction (or distance) vector element for the to-be-fused loop position, and test for a (&gt;) direction (or negative distance) [Wol89b]. Rotation. Loop rotation is useful for mapping loop algorithms onto distributed memory systems <ref> [Wol89c] </ref>. Loop rotation corresponds to skewing the loop around a torus; given a loop such as: for i = 0 to N-1 computation (i,j) endfor endfor the picture below shows a rotated iteration space where C ijP corresponds to computationP (i,Pj), and N=3, M=4.
Reference: [Wol90] <author> M. Wolfe, </author> <title> Data Dependence and Program Restructuring, </title> <journal> Journal of Supercomputing, </journal> <year> 1990. </year> <month> 19 </month>
Reference-contexts: Each transformation is implemented so that the dependence relations (and sometimes other conditions) are tested before program is transformed. Each transformation also modifies the dependence graph directly, rather than requiring Tiny to recompute the dependence relations. Most of these transformations are described in more detail in <ref> [Wol90] </ref>. Interchanging. The most basic restructuring transformation is loop interchanging, a well known optimization now regularly implemented in commercial compilers for parallel and vector computers.
References-found: 25

