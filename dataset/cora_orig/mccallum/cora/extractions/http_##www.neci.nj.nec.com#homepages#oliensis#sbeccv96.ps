URL: http://www.neci.nj.nec.com/homepages/oliensis/sbeccv96.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/vision/motion.html
Root-URL: 
Email: (oliensis@research.nj.nec.com)  
Title: Rigorous Bounds for Two-Frame Structure from Motion  
Author: John Oliensis 
Keyword: Structure from motion, low level vision, rigorous bounds, nonlinear estimation, multiframe structure from motion.  
Address: 4 Independence Way Princeton, N.J. 08540  
Affiliation: NEC Research Institute  
Abstract: We present an analysis of the problem of recovering motion, particularly rotation, from two image frames. We derive an exact bound on the magnitude of the error in recovering the rotation. With the single weak requirement that the average translational image displacements are smaller than the field of view, we demonstrate rigorously that the error in recovering the rotation is small. A lower bound on the rotation error can be derived which, for reasonable values of the field of view, is very close to the upper bound. Thus the upper bound is in fact a good estimate of the rotation error. We demonstrate the validity of these theoretical claims on synthetic and real images. These results form part of our correctness proof for a recently developed algorithm for recovering structure and motion from a multiple-image sequence. In addition, we argue and demonstrate experimentally that in the complementary domain, when the translation is large, the whole motion can be recovered robustly if also perspective effects are important. Thus it appears that rotation can be robustly recovered over a large domain. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference-contexts: An additional set of 100 trials where the plane normal was allowed to vary randomly near the set of image plane directions produced similar results. These results are consistent with those reported in Table 2. We also report results on two real image sequences: the rocket field sequence <ref> [1, 12] </ref> and the PUMA sequence [9, 10]. The rocket sequence consists of nine images obtained by approximately forward motion in an outdoor environment.
Reference: 2. <author> G. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins Press, </publisher> <address> Baltimore, Mary-land,1983. </address> <month> 29 </month>
Reference-contexts: Then jffiE N j 2b : The proofs of these Theorems are omitted due to lack of space. Theorems similar to these can be found in <ref> [2] </ref> and [11]; however, the bounds stated above, since they deal with the least eigenvalues, improve slightly on the bounds quoted in these references.
Reference: 3. <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7, </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference: 4. <author> R. Hummel and V. Sundareswaran, </author> <title> "Motion parameter estimation from global flow field data," </title> <type> PAMI 15, </type> <pages> 459-476, </pages> <year> 1993. </year>
Reference: 5. <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: bears out our original intuition: the rotation error is scaled by the average size of the translational image displacements. 1 Our experimental work on the large translation domain suports our previous claim [7, 6] that this domain is essentially an easy one: any SFM algorithm, including the notoriously unreliable "8-point" <ref> [5] </ref> algorithm, will work in this domain. In addition, we demonstrate that most of the error in recovering the Euclidean structure is due to a single component of the structure.
Reference: 6. <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> in Proc. Arpa Image Understanding Workshop, </booktitle> <address> Monterey, California, </address> <month> November </month> <year> 1994, </year> <pages> pp. 1225-1231. </pages>
Reference-contexts: 1 Introduction We have demonstrated in <ref> [7, 6] </ref> a new algorithm for structure from motion (SFM) which, in the appropriate domain, provably reconstructs structure and motion correctly. It is the first SFM algorithm for which a rigorous justification exists. <p> The final result bears out our original intuition: the rotation error is scaled by the average size of the translational image displacements. 1 Our experimental work on the large translation domain suports our previous claim <ref> [7, 6] </ref> that this domain is essentially an easy one: any SFM algorithm, including the notoriously unreliable "8-point" [5] algorithm, will work in this domain. In addition, we demonstrate that most of the error in recovering the Euclidean structure is due to a single component of the structure. <p> For this reason, in practice we expect rotation errors significantly smaller than those reported in Table 2. Note that in our experiments the maximum computed rotation error over all trials and all cases is 23:4 ffi ~ :41 radians. In our structure from motion algorithm <ref> [7, 6] </ref>, the first order effects of rotation error are eliminated. <p> The structure can also be recovered accurately except for very distant points. Given a multi-image sequence, the distances of distant points should also be determinable by an algorithm such as <ref> [7, 6] </ref>, by taking advantage of the motion information computed from 2-image pairs. The reasons why the structure and motion can be recovered robustly for large translation from 2 images are straightforward. Most importantly, because of the significant depth variation, translation and rotation are easy to distinguish.
Reference: 7. <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> to appear in the proceedings of the IEEE Workshop on the Representations of Visual Scenes, </booktitle> <address> Boston, </address> <month> June, </month> <year> 1995. </year>
Reference-contexts: 1 Introduction We have demonstrated in <ref> [7, 6] </ref> a new algorithm for structure from motion (SFM) which, in the appropriate domain, provably reconstructs structure and motion correctly. It is the first SFM algorithm for which a rigorous justification exists. <p> The final result bears out our original intuition: the rotation error is scaled by the average size of the translational image displacements. 1 Our experimental work on the large translation domain suports our previous claim <ref> [7, 6] </ref> that this domain is essentially an easy one: any SFM algorithm, including the notoriously unreliable "8-point" [5] algorithm, will work in this domain. In addition, we demonstrate that most of the error in recovering the Euclidean structure is due to a single component of the structure. <p> For this reason, in practice we expect rotation errors significantly smaller than those reported in Table 2. Note that in our experiments the maximum computed rotation error over all trials and all cases is 23:4 ffi ~ :41 radians. In our structure from motion algorithm <ref> [7, 6] </ref>, the first order effects of rotation error are eliminated. <p> The structure can also be recovered accurately except for very distant points. Given a multi-image sequence, the distances of distant points should also be determinable by an algorithm such as <ref> [7, 6] </ref>, by taking advantage of the motion information computed from 2-image pairs. The reasons why the structure and motion can be recovered robustly for large translation from 2 images are straightforward. Most importantly, because of the significant depth variation, translation and rotation are easy to distinguish.
Reference: 8. <author> J. Oliensis and J. I. Thomas, </author> <title> "Incorporating Motion Error in Multi-frame Structure from Motion," </title> <booktitle> in IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991, </year> <pages> pp. 8-13. </pages>
Reference: 9. <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson, </author> <title> A "Description and Reconstruction from Image Trajectories of Rotational Motion", </title> <booktitle> ICCV, </booktitle> <pages> 494-498, </pages> <year> 1990. </year>
Reference-contexts: These results are consistent with those reported in Table 2. We also report results on two real image sequences: the rocket field sequence [1, 12] and the PUMA sequence <ref> [9, 10] </ref>. The rocket sequence consists of nine images obtained by approximately forward motion in an outdoor environment. The maximum translation magnitude, between the first and ninth image, was 7.35 feet, while the depth of the nearest point relative to the first (farthest) camera position was 17.8 feet.
Reference: 10. <author> H.S. Sawhney and A.R. Hanson, </author> <title> "Comparative results of some motion algorithms on real image sequences," </title> <booktitle> IUW, </booktitle> <pages> 307-313, </pages> <year> 1990. </year>
Reference-contexts: These results are consistent with those reported in Table 2. We also report results on two real image sequences: the rocket field sequence [1, 12] and the PUMA sequence <ref> [9, 10] </ref>. The rocket sequence consists of nine images obtained by approximately forward motion in an outdoor environment. The maximum translation magnitude, between the first and ninth image, was 7.35 feet, while the depth of the nearest point relative to the first (farthest) camera position was 17.8 feet.
Reference: 11. <author> G.W. Stewart and J. G. Sun, </author> <title> "Matrix Perturbation Theory," </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: Then jffiE N j 2b : The proofs of these Theorems are omitted due to lack of space. Theorems similar to these can be found in [2] and <ref> [11] </ref>; however, the bounds stated above, since they deal with the least eigenvalues, improve slightly on the bounds quoted in these references.
Reference: 12. <author> J. Inigo Thomas, A. Hanson, and J. Oliensis, </author> <title> "Refining 3D reconstructions: A theoretical and experimental study of the effect of cross-correlations", </title> <journal> CVGIP:IU, </journal> <volume> Vol. 60, </volume> <year> 1994, </year> <pages> pp. 359-370. </pages>
Reference-contexts: An additional set of 100 trials where the plane normal was allowed to vary randomly near the set of image plane directions produced similar results. These results are consistent with those reported in Table 2. We also report results on two real image sequences: the rocket field sequence <ref> [1, 12] </ref> and the PUMA sequence [9, 10]. The rocket sequence consists of nine images obtained by approximately forward motion in an outdoor environment.
Reference: 13. <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference: 14. <author> C. Tomasi and T. Kanade, </author> <title> "Factoring Image Sequences into Shape and Motion," Motion Workshop, </title> <publisher> Princeton, </publisher> <pages> 21-28, </pages> <year> 1991. </year> <month> 30 </month>
References-found: 14

