URL: ftp://ftp.cs.washington.edu/homes/gjb/cpp-aware-c-analyses.ps.gz
Refering-URL: http://www.cs.washington.edu/homes/gjb/doc/resume.html
Root-URL: http://www.cs.washington.edu
Title: A Framework for Preprocessor-Aware C Source Code Analyses  
Author: Greg J. Badros and David Notkin 
Keyword: Parsing, preprocessor, cpp, lexical analysis, syntactic analysis, Perl.  
Note: Do Not Distribute  Draft of paper submitted to ICSE 99.  
Address: Thu  Box 352350, Seattle WA 98195-2350 USA  
Affiliation: gjb Univ. of Washington  Dept. Computer Science Engineering University of Washington  
Email: fgjb,notking@cs.washington.edu  
Phone: +1-206-543-1695  
Date: Aug 20 17:23:01 PDT 1998  
Abstract: Analyses of C source code usually ignore the C preprocessor because of its complexity. Instead, these analyses either define their own approximate parser (or scanner) or else they require that their input already be preprocessed. Neither approach is entirely satisfactory: the first gives up accuracy (or incurs large implementation costs), while the second loses the preprocessor-based abstractions. We describe a framework that permits analyses to be expressed in terms of both preprocessing and parsing actions, allowing the implementer to focus on the analysis of interest while still handling preprocessing information. We discuss an implementation of such a framework that embeds a C preprocessor, a parser, and a Perl interpreter for the action "hooks." Many common software engineering analyses can be implemented surprisingly easily using this framework, replacing numerous ad-hoc tools. The framework's integration of the preprocessor and the parser further enables some analyses that otherwise would be especially difficult to perform. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1986. </year>
Reference: [2] <author> D. C. Atkinson and W. G. Griswold. </author> <title> The design of whole-program analysis tools. </title> <booktitle> In Proceedings of the 18th International Conference on Software Engineering, </booktitle> <pages> pages 16-27, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A strength of our framework is that it lets a tool-builder easily fine-tune the extraction to derive the desired view. For example, we can treat macro expansions as subroutines if we choose: AddHook ("EXPAND_MACRO", sub - $func_calls-$_ <ref> [2] </ref>- = 1; - Given this revised extractor, a macro that expands into code that includes function calls will expose those function calls as callees from the function definition in which the macro was expanded. For some tasks, this may be exactly what we want. <p> permanently 4 gjb Univ. of Washington Thu Aug 20 17:23:01 PDT 1998 Do Not Distribute use pcp3; my %func_calls = (); my $expanding = 0; AddHook ("FUNCTION","&do_function); AddHook ("FUNC_SPEC", sub - %func_calls = (); -); AddHook ("FUNC_CALL", sub - $func_calls-$_ [0]-++ if !$expanding; - ); AddHook ("EXPAND_MACRO", sub - $func_calls-$_ <ref> [2] </ref>-++ if !$expanding; ++$expanding-); AddHook ("MACRO_CLEANUP", sub - --$expanding; -); sub do_function my ($szName) = @_; if (scalar (keys %func_calls) &gt; 0) - print "$szName calls ", join (", ",sort keys %func_calls), ""n"; - changed after the "for analysis only" parsing of the skipped code. <p> To better support reasoning about an entire source code artifact, a database approach similar to CIA++ [10] could be used. Atkinson and Griswold mention the importance of flexibility in allowing the user to select the appropriate balance between precision and performance of a whole-program analysis <ref> [2] </ref>. One could provide this flexibility by extending PCp 3 to reuse persistency machinery to permit specified data structures to be shared among invocations on separate translation units. Better support for versioning would be useful.
Reference: [3] <author> M. A. Ellis and B. Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference: [4] <author> M. Ernst, G. Badros, and D. Notkin. </author> <title> An empirical study of C preprocessor use. </title> <type> Technical Report UW-CSE-97-04-06, </type> <institution> University of Washington, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: Every nontrivial C program uses the preprocessor, and an empirical study of numerous packages written in C demonstrates that the use of cpp constructs is extensive <ref> [4] </ref>. What this means for software tools Because of the preprocessor's textual foundations, unprocessed C source code cannot be parsed directly. For example, identifiers which are macro-expanded may hide important tokens from the parser. Only after preprocessing is a C program in a grammatically usable form. <p> The complexities and subtleties of cpp must be duplicated in each tool. Not surprisingly, our framework is ideal for analyzing preprocessor constructs. Marking Macro Expansions For an empirical study of C preprocessor use <ref> [4] </ref>, we wanted to identify macro expansions in the unprocessed source code. Gris-wold and Atkinson note that counting macro expansions is difficult [11]. Our first approximation was overly conservative: we marked all occurrences of any identifier that was ever #defined to be a macro as an expansion.
Reference: [5] <author> D. Evans. </author> <title> LCLint User's Guide. </title> <institution> MIT Laboratory for Computer Science, </institution> <address> Cam-bridge, MA, v2.2 edition, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: These tools cannot use a straightforward parser or construct an accurate abstract syntax tree because the source is not grammatically-correct C code. Lexical tools such as etags, LSME [17], and font-lock-mode for Emacs and approximate parsers such as Field [20] and LCLint <ref> [5] </ref> use this approach. In general, this technique leads to improved robustness in handling syntax errors and language variants (approximate parsers generally lose the current top level construct at worst, and often do better). <p> For example, a macro argument can be marked that it needs to be side-effect free at an invocation site, and LCLint will generate a warning message if that constraint is violated. Evans's focus is on finding errors, and dealing with macro expansions is largely ignored <ref> [5, Ch. 8] </ref>. Krone and Snelting analyze conditional compilation directives in the context of a lattice-theoretic framework for inferring configuration structures from the source code.
Reference: [6] <author> S. Flisakowski. </author> <title> CTree distribution, </title> <journal> v0.5. </journal> <note> Freely available software package, July 1997. ftp://ftp.kagi.com/flisakow/- ctree 05.tar.gz. </note>
Reference-contexts: Thus, we have named the tool that implements the framework PCppP or PCp 3 . Parser Choosing a parser was difficult as there are many freely available parsers, often tightly coupled to a functional back-end, thus complicating reuse. The parser from CTree <ref> [6] </ref>, a freely available ANSI C front end, was chosen to embed in PCp 3 largely because of its simple implementation and fully-scoped symbol table.
Reference: [7] <author> F. S. </author> <title> Foundation. Bison v1.25 and flex v2.5 distributions. Freely available software package, </title> <address> April 1992,1995. ftp://- prep.ai.mit.edu/pub/. </address>
Reference-contexts: Its lexical analyzer and parser both are mechanically generated by flex and 6 gjb Univ. of Washington Thu Aug 20 17:23:01 PDT 1998 Do Not Distribute bison <ref> [7, 15] </ref> (freely available implementations of lex and yacc, respectively). As CTree parses, it builds a complete abstract syntax tree of the preprocessed code. The implementation of the CTree parser component of PCp 3 is about 5,000 lines of C code and bison and flex specifications.
Reference: [8] <author> F. S. </author> <title> Foundation. GCC distribution, </title> <journal> v2.7.2.2. </journal> <note> Freely available software package, January 1997. </note> <institution> ftp://- prep.ai.mit.edu/pub/gcc-2.7.2.tar.gz. 9 gjb Univ. of Washington Thu Aug 20 17:23:01 PDT 1998 Do Not Distribute </institution>
Reference-contexts: Preprocessor Since it is essential that the framework mimic cpp exactly, the C preprocessing library from the GNU C compiler's (gcc) well-tested (and slightly extended) cpp <ref> [8] </ref> is embedded in PCp 3 . The implementation of cpplib grew from about 7,000 lines of code as distributed with gcc to almost 8,000 lines.
Reference: [9] <author> B. Glickstein. </author> <title> Writing GNU Emacs Extensions. </title> <publisher> O'Reilly & Associates, Inc., </publisher> <address> Se-bastopol, California, </address> <year> 1997. </year>
Reference: [10] <author> J. E. Grass and Y.-F. Chen. </author> <title> The C++ information abstractor. </title> <booktitle> In Proceedings of the USENIX 1992 C++ Conference, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: These extra tools may also be used to combine information derived from various translation units (e.g., marking expansions in a header file that is included by multiple source files). To better support reasoning about an entire source code artifact, a database approach similar to CIA++ <ref> [10] </ref> could be used. Atkinson and Griswold mention the importance of flexibility in allowing the user to select the appropriate balance between precision and performance of a whole-program analysis [2].
Reference: [11] <author> W. G. Griswold, D. C. Atkinson, and C. McCurdy. </author> <title> Fast, flexible syntactic pattern matching and processing. </title> <booktitle> In Proceedings of the IEEE 1996 Workshop on Program Comprehension, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: Griswold and Atkinson studied mistakes in call graph extraction using various tools and found that macro expansion was a major cause of both false positives and false negatives <ref> [11] </ref>. Such approximate tools are inappropriate for software engineering analyses that require exact or conservative information. <p> Additionally, instead of C as the language for the actions, we use a scripting language for writing the hook subroutines. Griswold and Atkinson note that various software tools benefited from using a special-purpose interpreted action language <ref> [11] </ref>. As Ousterhout notes, interpreted languages can significantly speed development time [19]. Example actions include the scanning of preprocessor directives, the creation of a macro definition, the expansion (i.e., use) of a macro name, and the parsing of a variable declaration. <p> Not surprisingly, our framework is ideal for analyzing preprocessor constructs. Marking Macro Expansions For an empirical study of C preprocessor use [4], we wanted to identify macro expansions in the unprocessed source code. Gris-wold and Atkinson note that counting macro expansions is difficult <ref> [11] </ref>. Our first approximation was overly conservative: we marked all occurrences of any identifier that was ever #defined to be a macro as an expansion. Our framework can be used to provide a more accurate analysis. <p> Many analyses involve only a handful of callbacks, and thus execute very quickly. 5 RELATED WORK Numerous tools exist for assisting the software engineer in understanding and manipulating source code. Griswold and Atkinson review a number of them while motivating their TAWK tool <ref> [11] </ref>. TAWK uses C as its action language and matches patterns in the abstract syntax tree. They take significant pains to handle macros correctly, since they use a parser that could otherwise be too fragile.
Reference: [12] <author> S. P. Harbison. </author> <title> C: A Reference Manual. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <note> 3rd edition, </note> <year> 1991. </year>
Reference-contexts: 1 INTRODUCTION More than twenty years ago, Dennis Ritchie designed the C language [13] to include a textual macro preprocessor called cpp <ref> [12, Ch. 3] </ref>. Given the simplicity of the language and the state of the art in compiler technology in the mid-1970s, his decision to provide some language features in this extra-linguistic tool was justified.
Reference: [13] <author> B. W. Kernighan and D. M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, 2nd edition, </address> <year> 1988. </year>
Reference-contexts: 1 INTRODUCTION More than twenty years ago, Dennis Ritchie designed the C language <ref> [13] </ref> to include a textual macro preprocessor called cpp [12, Ch. 3]. Given the simplicity of the language and the state of the art in compiler technology in the mid-1970s, his decision to provide some language features in this extra-linguistic tool was justified.
Reference: [14] <author> M. Krone and G. Snelting. </author> <title> On the inference of configuration structures from source code. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 49-57. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: Another significant disadvantage of preprocessing is that it eliminates conditional compilation directives that are essential to the portability and versatility of the source code <ref> [14] </ref>. Preprocessing forces tools to limit their analysis to a single configuration of the source code, instead of permitting global reasoning about the entire artifact. Some tools choose a different approach and operate instead on the unprocessed source code exactly as the programmer sees it. <p> They study how #if guards depend on and relate to each other, and provide a means of visualizing the 3 Charles Simonyi and Rammoorthy Sridharan, personal conversation. relationships with the goal of improving the programmer's understanding of the structure and properties of the configurations <ref> [14] </ref>. 6 DISCUSSION Our framework provides a flexible infrastructure for exposing C preprocessor manipulations while still performing an accurate parse. It provides an expressive action language and eliminates the need of individual analyses to mimic the preprocessor. Nevertheless several weaknesses of the framework. <p> This would permit future blocks of code that are #ifdefed out to be properly influenced by prior blocks of code using the same guard. Krone and Snelting's work suggests that the number of distinct paths through the source is reasonably bounded <ref> [14] </ref>. A generalized symbol table could track which configurations contain each symbol, and how the type of a variable depends on conditional compilation guards. A similar generalization could be made for the preprocessor name table.
Reference: [15] <author> J. R. Levine. </author> <title> Lex & Yacc. </title> <publisher> O'Reilly & Associates, Inc., </publisher> <address> Sebastopol, California, 2nd edition, </address> <year> 1992. </year>
Reference-contexts: Though similar to the way the yacc parser <ref> [15] </ref> associates actions with parse rule invocation, our framework provides callbacks on both parser and preprocessor actions. Additionally, instead of C as the language for the actions, we use a scripting language for writing the hook subroutines. <p> Its lexical analyzer and parser both are mechanically generated by flex and 6 gjb Univ. of Washington Thu Aug 20 17:23:01 PDT 1998 Do Not Distribute bison <ref> [7, 15] </ref> (freely available implementations of lex and yacc, respectively). As CTree parses, it builds a complete abstract syntax tree of the preprocessed code. The implementation of the CTree parser component of PCp 3 is about 5,000 lines of C code and bison and flex specifications.
Reference: [16] <author> B. Lewis, D. LaLiberte, R. Stallman, </author> <title> and The GNU Manual Group. GNU Emacs Lisp Reference Manual. Free Software Foundation, </title> <address> Cambridge, Massachusetts, 2nd edition, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Since the analysis is meant to be used as an interactive program-understanding tool, we needed to present the extensive information about the mapping in a useful way. To achieve this, we had the tool output Emacs lisp code <ref> [16] </ref> which marks up the unprocessed source using text properties, and then wrote a tool to permit viewing of those annotations (see Figure 3). Other Possibilities Our framework has proven useful for various software engineering analysis. Other ad-hoc tools could benefit from our framework, as well. For example, Emacs's etags [16] <p> <ref> [16] </ref> which marks up the unprocessed source using text properties, and then wrote a tool to permit viewing of those annotations (see Figure 3). Other Possibilities Our framework has proven useful for various software engineering analysis. Other ad-hoc tools could benefit from our framework, as well. For example, Emacs's etags [16] creates a database of function definitions in unprocessed source but can be easily confused by package-specific macros used in function definition headers.
Reference: [17] <author> G. C. Murphy and D. Notkin. </author> <title> Lightweight lexical source model extraction. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 5(3) </volume> <pages> 263-291, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Some tools choose a different approach and operate instead on the unprocessed source code exactly as the programmer sees it. These tools cannot use a straightforward parser or construct an accurate abstract syntax tree because the source is not grammatically-correct C code. Lexical tools such as etags, LSME <ref> [17] </ref>, and font-lock-mode for Emacs and approximate parsers such as Field [20] and LCLint [5] use this approach. In general, this technique leads to improved robustness in handling syntax errors and language variants (approximate parsers generally lose the current top level construct at worst, and often do better).
Reference: [18] <author> G. C. Murphy, D. Notkin, W. G. Gris-wold, and E. S. </author> <title> Lan. An empirical study of static call graph extractors. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 7(2), </volume> <month> April </month> <year> 1998. </year>
Reference-contexts: As Murphy et al. discuss, there are many degrees of freedom for call-graph extractors <ref> [18] </ref>. A strength of our framework is that it lets a tool-builder easily fine-tune the extraction to derive the desired view. <p> All command line options accepted by cpp are also accepted by PCp 3 (this often makes it easier to use the tool in place of a compiler for analyzing complete packages as described by Murphy et al. <ref> [18] </ref>). Additionally, PCp 3 accepts a --noparse option that turns off its parser and the calls to related hooks. There are over currently over forty action hooks provided by PCp 3 .
Reference: [19] <author> J. Ousterhout. </author> <title> Scripting: Higher level programming for the 21st century. Web document, </title> <month> March </month> <year> 1997. </year> <note> http://www.sunlabs.com/people/- john.ousterhout. </note>
Reference-contexts: Additionally, instead of C as the language for the actions, we use a scripting language for writing the hook subroutines. Griswold and Atkinson note that various software tools benefited from using a special-purpose interpreted action language [11]. As Ousterhout notes, interpreted languages can significantly speed development time <ref> [19] </ref>. Example actions include the scanning of preprocessor directives, the creation of a macro definition, the expansion (i.e., use) of a macro name, and the parsing of a variable declaration. Each action callback is passed arguments relevant to the event for which it was invoked.
Reference: [20] <author> S. Reiss. </author> <title> The Field Programming Environment: A Friendly Integrated Environment for Learning and Development. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA, </address> <year> 1995. </year>
Reference-contexts: These tools cannot use a straightforward parser or construct an accurate abstract syntax tree because the source is not grammatically-correct C code. Lexical tools such as etags, LSME [17], and font-lock-mode for Emacs and approximate parsers such as Field <ref> [20] </ref> and LCLint [5] use this approach. In general, this technique leads to improved robustness in handling syntax errors and language variants (approximate parsers generally lose the current top level construct at worst, and often do better).
Reference: [21] <author> C. Simonyi. </author> <title> The intentional programming overview. </title> <type> Technical report, </type> <institution> Microsoft Corporation, </institution> <year> 1996. </year> <note> http://- www.research.microsoft.com/research/- ip/main.htm. </note>
Reference-contexts: For the remaining 8%, they expanded uses before feeding the re sulting tokens to their parser. 7 gjb Univ. of Washington Thu Aug 20 17:23:01 PDT 1998 Do Not Distribute The Intentional Programming group at Mi-crosoft Research <ref> [21] </ref>, headed by Charles Si-monyi, is interested in preserving preprocessor abstractions as they import legacy C code into their system. They developed a novel technique for handling preprocessor directives. 3 Before preprocessing, conditional compilation directives are converted to stylized variable declarations.
Reference: [22] <author> B. Stroustrup. </author> <title> The Design and Evolution of C++. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1994. </year>
Reference-contexts: For the last two decades, C programs have exploited cpp's capabilities for everything from manifest constants and type-less pseudo-inline functions, to modularization and symbol generation. Bjarne Stroustrup, the designer and original implementor of C++, notes that "without the C preprocessor, C itself : : : would have been stillborn" <ref> [22, p. 119] </ref>. Certainly cpp contributes to C's expressiveness and portability, but perhaps at too large a cost. <p> Stroustrup recognizes this tradeoff: Occasionally, even the most extreme uses of cpp are useful, but its facilities are so unstructured and intrusive that they are a constant problem to programmers, maintainers, people porting code, and tool builders <ref> [22, p. 424] </ref>. Why cpp is good : : : and bad The intrinsic problem with cpp is also its fundamental strength: it is a conceptually distinct first pass of textual processing over the source code.
Reference: [23] <author> L. Wall. </author> <title> Perl language, </title> <journal> v5.004. </journal> <note> Freely available software package, June 1997. ftp://ftp.perl.com/pub/perl/src/- CPAN/5.0/perl5.004.tar.gz. </note>
Reference: [24] <author> L. Wall, T. Christiansen, and R. L. Schwartz. </author> <title> Programming Perl. </title> <publisher> O'Reilly & Associates, Inc., </publisher> <address> Sebastopol, Califor-nia, </address> <year> 1996. </year> <month> 10 </month>
References-found: 24

