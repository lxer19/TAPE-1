URL: http://www.cse.ucsc.edu/~manfred/pubs/trackregr.ps
Refering-URL: http://www.cse.ucsc.edu/~manfred/pubs.html
Root-URL: http://www.cse.ucsc.edu
Email: mark@cs.ucsc.edu, manfred@cs.ucsc.edu  
Title: Tracking the Best Regressor  
Author: Mark Herbster and Manfred K. Warmuth 
Note: The authors were supported by the NSF grant CCR-9700201.  
Address: Building Santa Cruz, CA 95064 (USA)  
Affiliation: Department of Computer Science University of California at Santa Cruz Applied Sciences  
Abstract: In most of the on-line learning research the total on-line loss of the algorithm is compared to the total loss of the best off-line predictor u from a comparison class of predictors. We call such bounds static bounds. The interesting feature of these bounds is that they hold for an arbitrary sequence of examples. Recently some work has been done where the comparison vector u t at each trial t is allowed to change with time, and the total online loss of the algorithm is compared to the sum of the losses of u t at each trial plus the total cost for shifting to successive comparison vectors. This is to model situations in which the examples change over time and different predictors from the comparison class are best for different segments of the sequence of examples. We call such bounds shifting bounds. Shifting bounds still hold for arbitrary sequences of examples and also for arbitrary partitions. The algorithm does not know the offline partition and the sequence of predictors that its performance is compared against. Naturally shifting bounds are much harder to prove. The only known bounds are for the case when the comparison class consists of a finite sets of experts or boolean disjunctions. In this paper we develop the methodology for lifting known static bounds to the shifting case. In particular we obtain bounds when the comparison class consists of linear neurons (linear combinations of experts). Our essential technique consists of the following. At the end of each trial we project the hypothesis of the static algorithm into a suitably chosen convex region. This keeps the hypothesis of the algorithm well-behaved and the static bounds can be converted to shifting bounds so that the cost for shifting remains reasonable. 
Abstract-found: 1
Intro-found: 1
Reference: [AW98] <author> P. Auer and M. K. Warmuth. </author> <title> Tracking the best disjunction. </title> <journal> Journal of Machine Learning, </journal> <note> 1998. Special issue on concept drift. </note>
Reference-contexts: The new shifting bounds presented in this paper build on previous work of the authors [HW98] where the loss of the algorithm was compared against the loss of the best shifting expert (see also [Vov97]) or the best shifting disjunction <ref> [AW98] </ref>. The work on shifting experts has been applied to predicting disk idle times [HLS96] as well as load balancing problems [BB97]. In this paper we discuss general methods of lifting static bounds to the more complicated shifting case. <p> In particular, the projection update P ( egu ;D ne ) (w) corresponds to simple weight clipping. Similar updates were used in the Fixed-share Algorithm [HW98], WML [LW94] and the algorithms for tracking disjunctions <ref> [AW98] </ref>. An overview of proof techniques based on projections We have three results. First, we show that if the predictor u from the comparison class lies in the constraint set, then the previous static loss bounds hold for the constraint algorithm.
Reference: [BB97] <author> A. Blum and C. Burch. </author> <title> On-line learning and the metrical task system. </title> <booktitle> In Proc. 10th Annu. Workshop on Comput. Learning Theory. </booktitle> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: The work on shifting experts has been applied to predicting disk idle times [HLS96] as well as load balancing problems <ref> [BB97] </ref>. In this paper we discuss general methods of lifting static bounds to the more complicated shifting case. We focus on a class of algorithms that is characterized by a link function f .
Reference: [Bre67] <author> L.M. Bregman. </author> <title> The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. </title> <journal> USSR Computational Mathematics and Physics, </journal> <volume> 7:200217, </volume> <year> 1967. </year>
Reference-contexts: The generalized gradient descent algorithm for the ln link is the Un-normalized Exponentiated Gradient (EGU) Algorithm [KW97a] (see Figure 1). The key tool for analyzing the update associated with a link function f is a divergence function introduced by Breg-man <ref> [Bre67, CL81, Csi91] </ref>. These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in [KW97b, GLS97, JW98]). <p> Note that this inequality is opposite to the triangle inequality that holds for a (distance) metric. This is the reason that we call D F a divergence instead of a distance. The above theorem has been proven many times under a variety of assumptions, see for instance <ref> [Bre67, Csi91, JB90] </ref>. For the sake of completeness we provide a streamlined proof in the Appendix. The below corollary of the Generalized Pythagorean Theorem will be used repeatedly in the analyses of our algorithms. Corollary 1.3.
Reference: [Byl97] <author> T. Bylander. </author> <title> The binary exponentiated gradient algorithm for learning linear functions. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 184192. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time. <p> w i w i (essentially the negative entropy) gives rise to the logarithm link and the un-normalized relative entropy as the divergence function (see P n w i The divergence functions D F are used as potential functions for proving static loss bounds for the corresponding generalized gradient descent algorithms <ref> [CBLW96, KW97a, HKW95, Byl97, KW97b] </ref>. As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. <p> As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. At the center of all the static proofs <ref> [KW94, HKW95, Byl97, KW97b] </ref> for the generalized gradient descent algorithms lies the following type of inequality: a () L t (w t ) b () L t (u) D F (u; w t ) D F (u; w t+1 ): Here a and b are non-negative functions that depend on the <p> These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms <ref> [KW97a, HKW95, Byl97, KW97b] </ref>, as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper. There were two algorithms for the shifting expert setting.
Reference: [CBLW96] <author> N. Cesa-Bianchi, P. Long, and M.K. Warmuth. </author> <title> Worst-case quadratic loss bounds for on-line prediction of linear functions by gradient descent. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7(2):604619, </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time. <p> w i w i (essentially the negative entropy) gives rise to the logarithm link and the un-normalized relative entropy as the divergence function (see P n w i The divergence functions D F are used as potential functions for proving static loss bounds for the corresponding generalized gradient descent algorithms <ref> [CBLW96, KW97a, HKW95, Byl97, KW97b] </ref>. As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case.
Reference: [CL81] <author> Y. Censor and A. Lent. </author> <title> An iterative row-action method for interval convex programming. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 34(3):321353, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: The generalized gradient descent algorithm for the ln link is the Un-normalized Exponentiated Gradient (EGU) Algorithm [KW97a] (see Figure 1). The key tool for analyzing the update associated with a link function f is a divergence function introduced by Breg-man <ref> [Bre67, CL81, Csi91] </ref>. These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in [KW97b, GLS97, JW98]).
Reference: [Cov91] <author> T. M. </author> <title> Cover. Universal portfolios. </title> <booktitle> Mathematical Finance, </booktitle> <address> 1(1):129, </address> <year> 1991. </year>
Reference-contexts: Thus we need to use a dynamic convex region that we project into at end of each trial. A nice application for the projection update may be made to prediction portfolios on-line <ref> [Cov91, HSSW96] </ref>. In this case linear inequality constraints may be used to express relations that must be maintained between the instruments of the portfolio. Acknowledgments We would like to thank Claudio Gentile, Andrew Klingler, Debra Lewis and Harold Widom for valuable discussions.
Reference: [Csi91] <author> Imre Csiszar. </author> <title> Why least squares and maximum entropy? An axiomatic approach for linear inverse problems. </title> <journal> The Annals of Statistics, </journal> <volume> 19(4):20322066, </volume> <year> 1991. </year>
Reference-contexts: The generalized gradient descent algorithm for the ln link is the Un-normalized Exponentiated Gradient (EGU) Algorithm [KW97a] (see Figure 1). The key tool for analyzing the update associated with a link function f is a divergence function introduced by Breg-man <ref> [Bre67, CL81, Csi91] </ref>. These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in [KW97b, GLS97, JW98]). <p> Note that this inequality is opposite to the triangle inequality that holds for a (distance) metric. This is the reason that we call D F a divergence instead of a distance. The above theorem has been proven many times under a variety of assumptions, see for instance <ref> [Bre67, Csi91, JB90] </ref>. For the sake of completeness we provide a streamlined proof in the Appendix. The below corollary of the Generalized Pythagorean Theorem will be used repeatedly in the analyses of our algorithms. Corollary 1.3.
Reference: [FS97] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 55(1):119 139, </volume> <month> August </month> <year> 1997. </year>
Reference-contexts: These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm <ref> [FS97] </ref>, and various exponentiated gradient algorithms [KW97a, HKW95, Byl97, KW97b], as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper.
Reference: [GLS97] <author> A. J. Grove, N. Littlestone, and D. Schuurmans. </author> <title> General convergence results for linear discriminant updates. </title> <booktitle> In Proc. 8th Annu. Conf. on Com-put. Learning Theory, </booktitle> <pages> pages 171183. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: The general form of these updates was introduced in <ref> [GLS97] </ref> for linear threshold functions and in [JW98, KW97b] for regression problems. We refer to these updates as generalized gradient descent algorithms. For the sake of simplicity we focus on only two link functions in this paper, the identity function and the logarithm function. <p> These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in <ref> [KW97b, GLS97, JW98] </ref>). At this point we introduce the notion of divergence without listing a number of technical conditions specified in the Appendix.
Reference: [HKW95] <author> D. P. Helmbold, J. Kivinen, and M. K. War-muth. </author> <title> Worst-case loss bounds for sigmoided linear neurons. </title> <booktitle> In Proc. 1995 Neural Information Processing Conference, </booktitle> <pages> pages 309315. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time. <p> w i w i (essentially the negative entropy) gives rise to the logarithm link and the un-normalized relative entropy as the divergence function (see P n w i The divergence functions D F are used as potential functions for proving static loss bounds for the corresponding generalized gradient descent algorithms <ref> [CBLW96, KW97a, HKW95, Byl97, KW97b] </ref>. As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. <p> As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. At the center of all the static proofs <ref> [KW94, HKW95, Byl97, KW97b] </ref> for the generalized gradient descent algorithms lies the following type of inequality: a () L t (w t ) b () L t (u) D F (u; w t ) D F (u; w t+1 ): Here a and b are non-negative functions that depend on the <p> These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms <ref> [KW97a, HKW95, Byl97, KW97b] </ref>, as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper. There were two algorithms for the shifting expert setting.
Reference: [HKW97] <author> D. Haussler, J. Kivinen, and M. K. Warmuth. </author> <title> Tight worst-case loss bounds for predicting with expert advice. </title> <journal> IEEE Transactions on Information Theory, </journal> <note> 1997. To appear. </note>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time.
Reference: [HLS96] <author> D.P. Helmbold, D.D.E. Long, and B. Sherrod. </author> <title> A dynamic disk spin-down technique for mobile computing. </title> <booktitle> In Proceedings of the Second Annual ACM International Conference on Mobile Computing and Networking. </booktitle> <address> ACM/IEEE, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: The work on shifting experts has been applied to predicting disk idle times <ref> [HLS96] </ref> as well as load balancing problems [BB97]. In this paper we discuss general methods of lifting static bounds to the more complicated shifting case. We focus on a class of algorithms that is characterized by a link function f .
Reference: [HSSW96] <author> D. Helmbold, R. E. Schapire, Y. Singer, and M. K. Warmuth. </author> <title> On-line portfolio selection using multiplicative updates. </title> <booktitle> In Proc. 13th International Conference on Machine Learning, </booktitle> <pages> pages 243251. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Fran-cisco, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: Thus we need to use a dynamic convex region that we project into at end of each trial. A nice application for the projection update may be made to prediction portfolios on-line <ref> [Cov91, HSSW96] </ref>. In this case linear inequality constraints may be used to express relations that must be maintained between the instruments of the portfolio. Acknowledgments We would like to thank Claudio Gentile, Andrew Klingler, Debra Lewis and Harold Widom for valuable discussions.
Reference: [HW98] <author> M. Herbster and M. K. Warmuth. </author> <title> Tracking the best expert. </title> <journal> Journal of Machine Learning, </journal> <note> 1998. Special issue on concept drift. </note>
Reference-contexts: This is in accord with previous work on worst case loss bounds, where the static bound also grows with a p-norm of the comparison vector. The new shifting bounds presented in this paper build on previous work of the authors <ref> [HW98] </ref> where the loss of the algorithm was compared against the loss of the best shifting expert (see also [Vov97]) or the best shifting disjunction [AW98]. The work on shifting experts has been applied to predicting disk idle times [HLS96] as well as load balancing problems [BB97]. <p> In particular, the projection update P ( egu ;D ne ) (w) corresponds to simple weight clipping. Similar updates were used in the Fixed-share Algorithm <ref> [HW98] </ref>, WML [LW94] and the algorithms for tracking disjunctions [AW98]. An overview of proof techniques based on projections We have three results. First, we show that if the predictor u from the comparison class lies in the constraint set, then the previous static loss bounds hold for the constraint algorithm. <p> predictors in the constraint set egu = [ fl fl ] n to predictors in the larger set [0; n fl ] n : Interestingly, in this case the shifting loss bound obtained via the projection update of this paper is similar to the loss bound of the Fixed-share Algorithm <ref> [HW98] </ref>. For the first part recall that w t is the weight vector at the start of a trial, and w m t the weight vector between the two updates.
Reference: [JB90] <author> L. Jones and C. Byrne. </author> <title> General entropy criteria for inverse problems, with applications to data compression, pattern classification and cluster analysis. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 36(1):2330, </volume> <year> 1990. </year>
Reference-contexts: Note that this inequality is opposite to the triangle inequality that holds for a (distance) metric. This is the reason that we call D F a divergence instead of a distance. The above theorem has been proven many times under a variety of assumptions, see for instance <ref> [Bre67, Csi91, JB90] </ref>. For the sake of completeness we provide a streamlined proof in the Appendix. The below corollary of the Generalized Pythagorean Theorem will be used repeatedly in the analyses of our algorithms. Corollary 1.3.
Reference: [JW98] <author> A. Jagota and M. K. Warmuth. </author> <title> Continuous and discrete time nonlinear gradient descent: relative loss bounds and convergence. </title> <editor> In R. Greiner E. Boros, editor, </editor> <booktitle> Electronic Proceedings of Fifth International Symposium on Artificial Intelligence and Mathematics, </booktitle> <pages> pages . Electronic,http://rutcor.rutgers.edu/~amai, </pages> <year> 1998. </year>
Reference-contexts: The general form of these updates was introduced in [GLS97] for linear threshold functions and in <ref> [JW98, KW97b] </ref> for regression problems. We refer to these updates as generalized gradient descent algorithms. For the sake of simplicity we focus on only two link functions in this paper, the identity function and the logarithm function. <p> These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in <ref> [KW97b, GLS97, JW98] </ref>). At this point we introduce the notion of divergence without listing a number of technical conditions specified in the Appendix.
Reference: [KW94] <author> J. Kivinen and M. Warmuth. </author> <title> Using experts for predicting continuous outcomes. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pages 109120, </pages> <address> Oxford, 1994. </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time. <p> As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. At the center of all the static proofs <ref> [KW94, HKW95, Byl97, KW97b] </ref> for the generalized gradient descent algorithms lies the following type of inequality: a () L t (w t ) b () L t (u) D F (u; w t ) D F (u; w t+1 ): Here a and b are non-negative functions that depend on the
Reference: [KW97a] <author> J. Kivinen and M. K. Warmuth. </author> <title> Additive versus exponentiated gradient updates for linear prediction. Information and Computation, </title> <address> 132(1):164, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: The generalized gradient descent algorithm for the ln link is the Un-normalized Exponentiated Gradient (EGU) Algorithm <ref> [KW97a] </ref> (see Figure 1). The key tool for analyzing the update associated with a link function f is a divergence function introduced by Breg-man [Bre67, CL81, Csi91]. These divergences were previously used in convex programming in connection with generalized maximum entropy methods. <p> w i w i (essentially the negative entropy) gives rise to the logarithm link and the un-normalized relative entropy as the divergence function (see P n w i The divergence functions D F are used as potential functions for proving static loss bounds for the corresponding generalized gradient descent algorithms <ref> [CBLW96, KW97a, HKW95, Byl97, KW97b] </ref>. As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. <p> We use C-GD () and C-EGU () for the example algorithms of this paper. The constraint sets gd and egu chosen for to obtain shifting bounds for GD and EGU, respectively, are intimately related to the static loss bounds proven for the original algorithms. In <ref> [KW97a] </ref> it is observed that the bounds of GD depend on the 2-norm of both the instances x t and the predictor u, while in EGU (as well as EG) the bounds depend on the 1-norm of the instances x t and the 1-norm of the predictor u. <p> These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms <ref> [KW97a, HKW95, Byl97, KW97b] </ref>, as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper. There were two algorithms for the shifting expert setting.
Reference: [KW97b] <author> J. Kivinen and M. K. Warmuth. </author> <title> Relative loss bounds for multidimensional regression problems. </title> <booktitle> In Advances in Neural Information Processing Systems, 11, </booktitle> <address> Cambridge, MA, </address> <year> 1997. </year> <note> MIT Press. To appear. </note>
Reference-contexts: The general form of these updates was introduced in [GLS97] for linear threshold functions and in <ref> [JW98, KW97b] </ref> for regression problems. We refer to these updates as generalized gradient descent algorithms. For the sake of simplicity we focus on only two link functions in this paper, the identity function and the logarithm function. <p> These divergences were previously used in convex programming in connection with generalized maximum entropy methods. In the context of online learning various versions of these divergence functions were first used in <ref> [KW97b, GLS97, JW98] </ref>). At this point we introduce the notion of divergence without listing a number of technical conditions specified in the Appendix. <p> w i w i (essentially the negative entropy) gives rise to the logarithm link and the un-normalized relative entropy as the divergence function (see P n w i The divergence functions D F are used as potential functions for proving static loss bounds for the corresponding generalized gradient descent algorithms <ref> [CBLW96, KW97a, HKW95, Byl97, KW97b] </ref>. As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. <p> As in the previous work in convex programming, we use projections based on these divergences. We now outline how worst-case loss bounds are obtained in the static case. At the center of all the static proofs <ref> [KW94, HKW95, Byl97, KW97b] </ref> for the generalized gradient descent algorithms lies the following type of inequality: a () L t (w t ) b () L t (u) D F (u; w t ) D F (u; w t+1 ): Here a and b are non-negative functions that depend on the <p> These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms <ref> [KW97a, HKW95, Byl97, KW97b] </ref>, as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper. There were two algorithms for the shifting expert setting.
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <booktitle> Machine Learning, </booktitle> <address> 2:285318, </address> <year> 1988. </year>
Reference-contexts: 1 INTRODUCTION Consider the following by now standard on-line learning model which is a generalization of a model introduced by Littlestone <ref> [Lit89, Lit88, LW94] </ref>. Learning proceeds in trials t = 1; 2; : : : ; `. The algorithm maintains a parameter vector (hypothesis), denoted by w t 2 &lt; n . In each trial the algorithm receives an instance x t . <p> We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time. <p> These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms [KW97a, HKW95, Byl97, KW97b], as well as Winnow <ref> [Lit88] </ref>. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper. There were two algorithms for the shifting expert setting.
Reference: [Lit89] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, Technical Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: 1 INTRODUCTION Consider the following by now standard on-line learning model which is a generalization of a model introduced by Littlestone <ref> [Lit89, Lit88, LW94] </ref>. Learning proceeds in trials t = 1; 2; : : : ; `. The algorithm maintains a parameter vector (hypothesis), denoted by w t 2 &lt; n . In each trial the algorithm receives an instance x t .
Reference: [LW94] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. Information and Computation, </title> <address> 108(2):212261, </address> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION Consider the following by now standard on-line learning model which is a generalization of a model introduced by Littlestone <ref> [Lit89, Lit88, LW94] </ref>. Learning proceeds in trials t = 1; 2; : : : ; `. The algorithm maintains a parameter vector (hypothesis), denoted by w t 2 &lt; n . In each trial the algorithm receives an instance x t . <p> In particular, the projection update P ( egu ;D ne ) (w) corresponds to simple weight clipping. Similar updates were used in the Fixed-share Algorithm [HW98], WML <ref> [LW94] </ref> and the algorithms for tracking disjunctions [AW98]. An overview of proof techniques based on projections We have three results. First, we show that if the predictor u from the comparison class lies in the constraint set, then the previous static loss bounds hold for the constraint algorithm. <p> These methods apply to such algorithms as the WM Algorithm <ref> [LW94] </ref>, the Aggregating Algorithm [Vov95], the Hedge Algorithm [FS97], and various exponentiated gradient algorithms [KW97a, HKW95, Byl97, KW97b], as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper.
Reference: [Roc70] <author> R. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <year> 1970. </year>
Reference: [Rud91] <author> W. </author> <title> Rudin. Functional Analysis. </title> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference: [Vov90] <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 371383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: We call such bounds static bounds, because the comparison vector u is any member from the comparison class but it does not change with time. Surprisingly, such bounds are achievable even when there are no probabilistic assumptions made on the sequence of examples <ref> [Lit88, Vov90, HKW97, CBLW96, KW94, Byl97, HKW95] </ref>. In this paper we allow the comparison vector u to shift with time.
Reference: [Vov95] <author> V. G. Vovk. </author> <title> A game of prediction with expert advice. </title> <booktitle> In Proc. 8th Annu. Conf. on Com-put. Learning Theory, </booktitle> <pages> pages 5160. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: These methods apply to such algorithms as the WM Algorithm [LW94], the Aggregating Algorithm <ref> [Vov95] </ref>, the Hedge Algorithm [FS97], and various exponentiated gradient algorithms [KW97a, HKW95, Byl97, KW97b], as well as Winnow [Lit88]. Just the static bounds for the constraint algorithms are already interesting in their own right. A number of detailed applications will be included in the full paper.

References-found: 27

