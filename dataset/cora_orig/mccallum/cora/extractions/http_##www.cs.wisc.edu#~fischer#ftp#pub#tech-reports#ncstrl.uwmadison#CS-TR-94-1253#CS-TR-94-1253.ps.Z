URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1253/CS-TR-94-1253.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1253/
Root-URL: http://www.cs.wisc.edu
Title: DYNAMIC TIME WINDOWS: CONGESTION CONTROL AND AVOIDANCE IN HIGH SPEED NETWORKS  
Author: by THEODORE V. FABER 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1994  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> R. Jain and K. Ramakrishnan, </author> <title> Congestion Avoidance in Computer Networks with a Connectionless Network Layer: Concepts, Goals, and Methodology, </title> <booktitle> Proc. IEEE Symposium on Computer Networks, </booktitle> <pages> pp. 134-143 IEEE, </pages> <year> (1988). </year>
Reference-contexts: Other figures of merit include per-packet delay and packet loss rates. Controlling source behavior so that the system bottleneck is utilized at its capacity, and not beyond it, is congestion avoidance; restoring a congested network to a stable state is congestion control <ref> [1] </ref>. Most networks that address congestion provide both congestion control and avoidance. The avoidance systems operate at all times, and if the avoidance system fails the congestion control system is invoked.
Reference: 2. <author> R. Jain, </author> <title> A Delay Based Approach for Congestion Avoidance in Interconnected Heterogeneous Computer Networks, </title> <journal> Computer Communications Review 19(5) pp. 56-71 ACM SIGCOMM, </journal> <month> (Oct. </month> <year> 1989). </year>
Reference-contexts: A goal of congestion avoidance and control is to maximize some performance measure of the network. Examples of a performance measure include throughput and packet delivery to loss ratio. There are many characterizations of this maximization; finding the knee of the throughput versus load curve <ref> [2, 3] </ref>, saturating the bottleneck switches in a network [4], and maximizing user incentives [5] have all been proposed. Maximizing user incentives involves a pricing scheme including incentives in the network arranged so that users are guided to avoid congestion economically. <p> As we will show, this results in many of the benefits of both feedback and allocation systems being present in it. 1.3.2. Feedback Systems Another approach is taken by the TCP congestion avoidance mechanisms [8] and the DECBit algorithms <ref> [2, 3] </ref>. These systems use feedback to determine the current state of the network, and then utilize that information to modulate some parameter of their source control algorithms. We call systems that control source behavior based on information about the current network state feedback systems. <p> Others have approached the congestion control as a problem in Game Theory. Jain suggests this may be fruitful due to the apparent conflict between a selfish optimum sending rate and a network optimal sending rate <ref> [2] </ref>. Sanders investigates this area, and 27 describes a pricing system whereby rational users will adjust their sending rates based on price incentives [5, 82]. <p> It is a powerful feature that DTW source control enforces this stability under very general conditions. DTW stability reduces the effects of the high latency of control messages on congestion in the network. Consider a switch in a normal packet window-based congestion control method, like the DECbit algorithm <ref> [2] </ref>. In the worst case, as the switch becomes congested, the switch's queue length grows and will continue to grow until the control messages that the switch is sending reach the sources that are flooding it. <p> This period of reduced throughput enforced by Slow Start gives congested switches a chance to clear their queues. We chose to study a system closely modelled on TCP rather than a system like DECbit <ref> [2] </ref> that receives feedback directly from switches because the former is more widely used. In fact, the TCP congestion avoidance and control systems are arguably the most widely used in the world, and we felt it would be instructive to compare DTW to them.
Reference: 3. <author> K. Ramakrishnan and R. Jain, </author> <title> A Binary Feedback Scheme for Congestion Avoidance in Computer Networks with a Connectionless Network Layer, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 303-313 ACM SIGCOMM, </note> <month> (Aug 16-19 </month> <year> 1988). </year>
Reference-contexts: A goal of congestion avoidance and control is to maximize some performance measure of the network. Examples of a performance measure include throughput and packet delivery to loss ratio. There are many characterizations of this maximization; finding the knee of the throughput versus load curve <ref> [2, 3] </ref>, saturating the bottleneck switches in a network [4], and maximizing user incentives [5] have all been proposed. Maximizing user incentives involves a pricing scheme including incentives in the network arranged so that users are guided to avoid congestion economically. <p> As we will show, this results in many of the benefits of both feedback and allocation systems being present in it. 1.3.2. Feedback Systems Another approach is taken by the TCP congestion avoidance mechanisms [8] and the DECBit algorithms <ref> [2, 3] </ref>. These systems use feedback to determine the current state of the network, and then utilize that information to modulate some parameter of their source control algorithms. We call systems that control source behavior based on information about the current network state feedback systems. <p> The smart switches enable DTW to get negative feedback before congestion losses occur. (Some packet window systems share this attribute, e.g., DECBit <ref> [3] </ref> ). Simulations have shown that even if a switch considers itself uncongested until 90% of its buffers are in use, losses are rare.
Reference: 4. <author> Jeffrey Jaffe, </author> <title> Bottleneck Flow Control, </title> <journal> IEEE Transactions on Communications COM-29(7) pp. 954-962 IEEE, </journal> <month> (July </month> <year> 1981). </year>
Reference-contexts: Examples of a performance measure include throughput and packet delivery to loss ratio. There are many characterizations of this maximization; finding the knee of the throughput versus load curve [2, 3], saturating the bottleneck switches in a network <ref> [4] </ref>, and maximizing user incentives [5] have all been proposed. Maximizing user incentives involves a pricing scheme including incentives in the network arranged so that users are guided to avoid congestion economically. <p> In other words, a group of sources avoiding congestion cannot optimize the usage of the enitre network without global knowledge. He also describes a system that uses a centralized system that maximizes power <ref> [4] </ref>. The decentralizability issue is 19 taken up by Selgar, who proposes another definition of power that is decentralizable [32], and puts forth a class of algorithms to maximize it [33]. The above do not probe the network state to determine the state of the network.
Reference: 5. <author> B. Sanders, </author> <title> An Incentive Compatible Flow Control Algorithm for Fair Rate Allocation in Computer/Communication Networks, </title> <journal> IEEE Transactions on Computers 37(9) pp. 314-320 IEEE, </journal> <month> (Sept. </month> <year> 1990). </year>
Reference-contexts: Examples of a performance measure include throughput and packet delivery to loss ratio. There are many characterizations of this maximization; finding the knee of the throughput versus load curve [2, 3], saturating the bottleneck switches in a network [4], and maximizing user incentives <ref> [5] </ref> have all been proposed. Maximizing user incentives involves a pricing scheme including incentives in the network arranged so that users are guided to avoid congestion economically. <p> Jain suggests this may be fruitful due to the apparent conflict between a selfish optimum sending rate and a network optimal sending rate [2]. Sanders investigates this area, and 27 describes a pricing system whereby rational users will adjust their sending rates based on price incentives <ref> [5, 82] </ref>.
Reference: 6. <author> A. G. Fraser, C. R. Kalmanek, A. E. Kaplan, W. T. Marshall, and R. C. Restrick, </author> <title> XUNET 2: A Nationwide Testbed in Gigabit Networking, </title> <booktitle> Proc. IEEE INFOCOM, IEEE, </booktitle> <month> (May 6-8, </month> <year> 1992). </year>
Reference-contexts: Trends in Today's Internet Applications The size and bandwidth of computer networks are increasing. New users are being added to existing networks, such as the Internet, at the same time that the capacity of those networks is being increased. Researchers are investigating new high bandwidth networking technologies <ref> [6, 7] </ref> which promise to continue, if not accelerate, this trend. The increase in available network resources is leading to both an increase in the number of users, and the introduction of new applications. Both of these trends increase the likelihood of congestion in networks. <p> Switches must have control over their buffering policies and be able to monitor their internal state for signs of congestion. They must also be able to send cells into the network. An example of an intelligent switch is the XUNET switch <ref> [6] </ref>, which is described briefly in Chapter 6. The network is connection-oriented and uses virtual circuits. A virtual circuit is a route through the network from source to sink through one or more switches. All traffic associated with a given virtual circuit follows the same route. <p> Since j the amount of buffering that source i will receive in the worst case is b i B. 43 One implementation of the buffering strategy is described below. The per-virtual circuit cell queues are linked lists of cell buffers, as in the XUNET switch <ref> [6] </ref>. Each virtual circuit has a header containing the current allocation of buffers for that circuit, the current number of buffers in use, and a pointer to the first cell in the virtual circuit's queue. <p> and in the investigation of hidden causes, stronger reasons are obtained from experiments and demonstrated arguments than from probable conjectures and the opinions of philosophical speculators of the common sort.'' William Gilbert, De Magnete (On the Magnet) This chapter discusses the prototype implementation of DTW on the XUNET experimental network <ref> [6] </ref>. We begin with a brief overview of the XUNET, and then describe the implementation of DTW on the XUNET switch and XUNET router. The remainder of this chapter describes several experiments that show that the implementation behaves as predicted by simulation. 6.1.
Reference: 7. <author> David Clark, Bruce Davie, David Farber, Inder Gopal, Bharath K. Kadaba, W. David Sincoskie, Jonathan M. Smith, and David Tennenhouse, </author> <title> An Overview of the AURORA Gigabet Testbed, </title> <booktitle> IEEE INFOCOM, </booktitle> <pages> pp. </pages> <note> 569-581 IEEE INFOCOM, </note> <month> (May 6-8, </month> <year> 1992). </year> <month> 194 </month>
Reference-contexts: Trends in Today's Internet Applications The size and bandwidth of computer networks are increasing. New users are being added to existing networks, such as the Internet, at the same time that the capacity of those networks is being increased. Researchers are investigating new high bandwidth networking technologies <ref> [6, 7] </ref> which promise to continue, if not accelerate, this trend. The increase in available network resources is leading to both an increase in the number of users, and the introduction of new applications. Both of these trends increase the likelihood of congestion in networks.
Reference: 8. <author> Van Jacobson, </author> <title> Congestion Avoidance and Control, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 314-329 ACM SIGCOMM, </note> <month> (Aug 16-19 </month> <year> 1988). </year>
Reference-contexts: This application requires a continuous multi-megabit per second stream of data to be delivered over an extended period. The data needs to be delivered quickly and with minimal jitter. These requirements are different from the assumptions made about source requirements by TCP <ref> [8] </ref>, the most common protocol providing congestion control and avoidance in the Internet. TCP expects sources that are maximizing their throughput, and that can adjust their sending patterns. <p> DTW has many characteristics of an allocation system that is tuned by feedback. As we will show, this results in many of the benefits of both feedback and allocation systems being present in it. 1.3.2. Feedback Systems Another approach is taken by the TCP congestion avoidance mechanisms <ref> [8] </ref> and the DECBit algorithms [2, 3]. These systems use feedback to determine the current state of the network, and then utilize that information to modulate some parameter of their source control algorithms. We call systems that control source behavior based on information about the current network state feedback systems. <p> Another interesting packet based feedback system is the TCP/IP system in the Internet [54]. Of primary interest are the congestion control mechanisms added to the BSD UNIX kernel by Van Jacobson <ref> [8] </ref>. The mechanisms detect congestion in the network by detecting packet loss either via an out of order acknowledgement or a timeout mechanism. The timeout mechanism depends on being able to estimate the round trip time for a given connection, and Jacobson presents a moving average method to do so. <p> A source detects congestion whenever it fails to get an acknowledgement of a packet within a preset time, which is twice the round trip time in these simulation. 107 This feedback system also employs a Slow Start mechanism as congestion control <ref> [8] </ref>.
Reference: 9. <author> T.J. Brenners-Lee, R. Cailliau, J-F Groff, and B. Pollermann, </author> <title> World Wide Web : The Information Universe, </title> <journal> Electronic Networking: </journal> <note> Research, Applications and Policy 2(1) pp. 52-58 Meckler Publishing, (Spring 1992). </note>
Reference-contexts: Although TCP's congestion control and avoidance mechanisms are not ideally suited to these applications, they are 5 flourishing due to the amount of free information available in the Internet. World Wide Web viewers, like NCSA Mosaic, <ref> [9] </ref> are an example of applications that are network intensive. Mosaic is a hypermedia browser that is used to view a distributed multimedia database residing on various sites in the Internet. Items in the database range from small ASCII files to multi-megabyte compressed full-motion video clips.
Reference: 10. <author> W. Hibbard, D. Santek, and G. Tripoli, </author> <title> Interactive atmospheric data access via high speed networks., </title> <booktitle> Computer Networks and ISDN Systems 22 pp. </booktitle> <pages> 103-109 </pages> (). 
Reference-contexts: Scientific research applications can also require large amounts of network bandwidth. Distributed simulations of Grand Challenge style problems can require giga-bit per second network bandwidth to solve in a reasonable time <ref> [10] </ref>. These applications must be written with a knowledge of both the network and the problem being attacked, and are highly customized. Because these applications require such large amounts of bandwidth, even for short periods, they can cause a great deal of congestion.
Reference: 11. <author> Lixia Zhang, Stephen Deering, Deborah Estrin, Scott Shenker, and Daniel Zap-pala, RSVP: </author> <title> A New Resource ReSerVation Protocol, </title> <journal> IEEE Network Magazine 9,#4 pp. 8-18 IEEE, </journal> <month> (September </month> <year> 1993). </year>
Reference-contexts: Resource allocation protocols include RSVP <ref> [11] </ref>, and RCAP [12]. These protocols allow sources to request resources in the network by including a source profile in a connection request message, which carries the profile to the network elements that have the resources. The profile is a description of the resources that the source wishes to acquire. <p> The circuit establishment method given here guarantees that the network always remains in a stable configuration. Protocols have been specified for communicating information to switches for call establishment <ref> [11, 12] </ref>, and we assume that one of these protocols is used to transfer the information from a source to switches along the path and to a sink.
Reference: 12. <author> A. Banerjea and B. Mah, </author> <title> The Real Time Channel Administration Protocol, </title> <booktitle> Proc. 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <month> (November </month> <year> 1991). </year>
Reference-contexts: Resource allocation protocols include RSVP [11], and RCAP <ref> [12] </ref>. These protocols allow sources to request resources in the network by including a source profile in a connection request message, which carries the profile to the network elements that have the resources. The profile is a description of the resources that the source wishes to acquire. <p> The circuit establishment method given here guarantees that the network always remains in a stable configuration. Protocols have been specified for communicating information to switches for call establishment <ref> [11, 12] </ref>, and we assume that one of these protocols is used to transfer the information from a source to switches along the path and to a sink.
Reference: 13. <author> J. S. Turner, </author> <title> New Directions in Communications (or Which Way to the Information Age), </title> <journal> IEEE Communications Magazine 24(4) pp. 8-14 IEEE, </journal> <month> (Oct. </month> <year> 1986). </year>
Reference-contexts: A profile contains information such as average and peak sending rates of the source. The most common form of enforcement mechanism is Leaky Bucket <ref> [13] </ref>, or some variation of it [14-16]. Leaky Bucket allows a source to negotiate both a maximum burst size and a maximum sustained average rate. Packets that violate the negotiated parameters may be discarded, marked as violators, or queued to be sent later. <p> By controlling the number of buffers set aside for new packets, the number of new packets entering the network as a whole can be constrained [73]. A popular method of source traffic control is the leaky bucket, proposed by Turner <ref> [13] </ref>. Each source is permitted to send one packet (or number of bits) for each credit it has in a pool. There is a maximum number of credits, and when credits are used, they are replaced at a fixed rate. <p> The Source Control Algorithm We now discuss the implementation of the DTW source control, which ensures that cells are sent in accordance with the time window criterion. The implementation uses a credit method, similar to a Leaky Bucket <ref> [13] </ref>. Credits are in terms of cells of size C. If a 47 source has a credit, it can send a cell, otherwise it must wait until it has a credit. <p> I, ch. 4 This chapter relates analytical results concerning DTW. We begin with an exploration of DTW source control and how it differs from Leaky Bucket <ref> [13] </ref> source control. Then we prove the property that a queue served only by DTW sources empties periodically for the single switch case. This property is called DTW stability. We also prove a bound on a source's effective average rate, mentioned in Chapter 3.
Reference: 14. <author> H. Ahmadi, R. Guerni, and K. Sohraby, </author> <title> Analysis of Leaky Bucket Access Control Mechanism with Batch Arrival Process, </title> <booktitle> Proc. IEEE Globecom, IEEE, </booktitle> <month> (Dec. </month> <pages> 2-5, </pages> <year> 1990). </year>
Reference: 15. <author> K. Bala, I. Cidon, and K. Sohraby, </author> <title> Congestion Control for High Speed Packet Switched Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 520-526 IEEE, </pages> <month> (June 5-7, </month> <year> 1990). </year> <month> 195 </month>
Reference: 16. <author> K. Sohraby and M. Sidi, </author> <title> On the Performance of Bursty and Correlated Sources Subject to Leaky Bucket Rate-Based Access Control Schemes, </title> <booktitle> Proc. IEEE INFOCOM, IEEE, </booktitle> <month> (Apr. </month> <pages> 7-9, </pages> <year> 1991). </year>
Reference: 17. <author> The ATM Forum, </author> <title> ATM User-Network Interface Specification Version 3.0, The ATM Forum, </title> <address> Mountain View, CA (June 1993). </address>
Reference-contexts: Packets that violate the negotiated parameters may be discarded, marked as violators, or queued to be sent later. Leaky Bucket can also be modified to police traffic entering the network, rather than traffic leaving the source <ref> [17] </ref>. Other enforcement mechanisms include Zhang's User Behavior Envelope [18], and a variety of windowing systems [19]. Although the specific mechanisms vary, all of these enforcement policies constrain source behavior to meet the 7 parameters negotiated with the congestion avoidance and control system. <p> The allocation system does not attempt to sense network state in any way. We chose Leaky Bucket as a representative allocative enforcement mechanism since it is often proposed as a congestion control scheme for ATM traffic [76]. For example, the ATM forum suggests it as a policing mechanism <ref> [17] </ref>. 5.6.1. DTW vs. Classic Feedback (Static Network) In order to compare DTW to the TCP-like packet feedback system (called ``the feedback system''), we simulated the two using identically distributed traffic in a static network and recorded several figures of merit.
Reference: 18. <author> L. Zhang, </author> <title> A New Architecture for Packet Switching Network Protocols, </title> <type> Ph.D Thesis, </type> <pages> pp. </pages> <address> 1-135 MIT, </address> <month> (Aug. </month> <year> 1989). </year>
Reference-contexts: Packets that violate the negotiated parameters may be discarded, marked as violators, or queued to be sent later. Leaky Bucket can also be modified to police traffic entering the network, rather than traffic leaving the source [17]. Other enforcement mechanisms include Zhang's User Behavior Envelope <ref> [18] </ref>, and a variety of windowing systems [19]. Although the specific mechanisms vary, all of these enforcement policies constrain source behavior to meet the 7 parameters negotiated with the congestion avoidance and control system. <p> Mor-gan independently verifies the firewalling capabilities of these disciplines [62]. Parekh and Gallagher analyze them extensively, proving many useful properties [63-65]. Virtual Clock is incorporated in Lixia Zhang's flow network, which uses a user behavior envelope based on sources' negotiated parameters to smooth traffic <ref> [18] </ref>. The user behavior envelope allows the source to send only its average rate times its averaging interval bits in any time period of the length of its averaging interval. <p> This algorithm performs the same function as Zhang's User Behavior Envelope <ref> [18] </ref>, but we have modified the terminology and implementation to allow the source's time window to vary, thereby making DTW admission control part of a dynamic control system.
Reference: 19. <author> A. E. Eckberg, A. W. Berger, T. Hou, and D. M. Lucantoni, </author> <title> Performance Characterizations of Traffic Monitoring and Associated Control, mechanisms for Broadband `Packet' Networks, </title> <booktitle> Proc. IEEE Globecom, IEEE, </booktitle> <month> (Dec. </month> <pages> 2-5, </pages> <year> 1990). </year>
Reference-contexts: Leaky Bucket can also be modified to police traffic entering the network, rather than traffic leaving the source [17]. Other enforcement mechanisms include Zhang's User Behavior Envelope [18], and a variety of windowing systems <ref> [19] </ref>. Although the specific mechanisms vary, all of these enforcement policies constrain source behavior to meet the 7 parameters negotiated with the congestion avoidance and control system. The final element in an allocation system is a mechanism in the network to provide the requested resources to traffic. <p> The papers discuss and simulate this and other alternatives. Eckberg, Luan, and Lucatoni use leaky buckets in their Bandwidth Management (BWM) congestion control strategy [74-76]. This choice is the result of the investigation of several policing policies <ref> [19] </ref>. The theme of BWM is that congestion control should be be simple and robust, since many sources in their network environment will be very simple, or unable to devote significant resources to congestion control processing.
Reference: 20. <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> Analysis and Simulation of a Fair Queueing Algorithm, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 1-12 ACM SIGCOMM, </note> <month> (Sept 19-22 </month> <year> 1989). </year>
Reference-contexts: The final element in an allocation system is a mechanism in the network to provide the requested resources to traffic. The most common mechanism is a system of queueing packets at network nodes, like Weighted Fair Queueing <ref> [20] </ref>, Virtual Clock [21, 22], or Stop-and-Go [23]. These queueing disciplines provide each source with a guaranteed rate of service, or a guaranteed amount of another resource. For example, Stop-and-go provides both rate and jitter bounds. All disciplines of this type constrain the way traffic is served in the network. <p> Resource Allocation at Switches Switches allocate resources to ensure fairness among the sources using them, and as the basis for providing service tailoring, which will be discussed in Chapter 7. They use Weighted Fair Queueing <ref> [20] </ref> to allocate their service rates among sources, and a custom buffer allocation system to allocate buffering to sources. We describe WFQ first, and then explain the buffer allocation. 3.3.1.1. <p> Allocation of Switch Service Rate We model a switch in the DTW system as a Weighted Fair Queueing server with deterministic service times. The service times are deterministic because the switch spends a fixed time processing each cell. Fair Queueing <ref> [20] </ref> is a queueing discipline that allocates a switch's service rate equally among the virtual circuits using the switch. Let the switch have rate m, and let it have n circuits established through it. <p> Relaxing the assumption that traffic is continuous adds additional terms to the lower bound in Equation (3.2). These bounds have been calculated by Demers, Keshav, and Shenker <ref> [20] </ref> as well as by Parekh [63]. The additional terms added to Equation (3.2) by relaxing this assumption do not enhance the understanding of the algorithms of DTW, 41 and DTW can be modified to use the more exact bounds.
Reference: 21. <author> L. Zhang, </author> <title> Virtual Clock : A New Traffic Control Algorithm for Packet Switching, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 19-29 ACM SIGCOMM, </note> <month> (Sept 24-27, </month> <year> 1990). </year>
Reference-contexts: The final element in an allocation system is a mechanism in the network to provide the requested resources to traffic. The most common mechanism is a system of queueing packets at network nodes, like Weighted Fair Queueing [20], Virtual Clock <ref> [21, 22] </ref>, or Stop-and-Go [23]. These queueing disciplines provide each source with a guaranteed rate of service, or a guaranteed amount of another resource. For example, Stop-and-go provides both rate and jitter bounds. All disciplines of this type constrain the way traffic is served in the network. <p> A common aspect of these systems is a specification of the queueing disciplines used at intermediate switches. Keshav and Hui Zhang provide an overview of many of 23 these disciplines [61]. Among the most interesting queueing disciplines are Virtual Clock <ref> [21, 22] </ref> and Fair Queueing (including Weighted Fair Queueing)[20]. These both approximate a weighted bitwise round robin service to packets, and Keshav and Hui Zhang claim that the two are equivalent [61]. <p> Virtual cir cuit i is guaranteed a service rate of j = 1 n w i m hhhhhh where w i is a weight attached to each circuit. The Virtual Clock queueing discipline <ref> [21] </ref> implements Weighted Fair Queueing where the weights are assigned based on the negotiated average rates of sources. [61] Virtual Clock guarantees each source a minimum service rate at each switch proportional to that source's negotiated average rate and uses a simpler algorithm to calculate timestamps. <p> Considering the speeds at which busy sources will have their virtual clocks incremented, this idle period need not be very long to achieve the desired effect. Zhang addresses this problem by resetting the virtual clocks with every cell that arrives <ref> [21] </ref>. This maintains the properties of Virtual Clock, but is restrictive of bursty 42 traffic. Since DTW is designed to serve bursty sources, it cannot include a queueing discipline that punishes traffic for exhibiting burstiness.
Reference: 22. <author> L. Zhang, </author> <title> Virtual Clock: A New Traffic Control Algorithm for Packet-Switched Networks, </title> <journal> ACM Transactions on Computer Systems 9(2) pp. 101-124 ACM, </journal> <month> (May </month> <year> 1991). </year>
Reference-contexts: The final element in an allocation system is a mechanism in the network to provide the requested resources to traffic. The most common mechanism is a system of queueing packets at network nodes, like Weighted Fair Queueing [20], Virtual Clock <ref> [21, 22] </ref>, or Stop-and-Go [23]. These queueing disciplines provide each source with a guaranteed rate of service, or a guaranteed amount of another resource. For example, Stop-and-go provides both rate and jitter bounds. All disciplines of this type constrain the way traffic is served in the network. <p> A common aspect of these systems is a specification of the queueing disciplines used at intermediate switches. Keshav and Hui Zhang provide an overview of many of 23 these disciplines [61]. Among the most interesting queueing disciplines are Virtual Clock <ref> [21, 22] </ref> and Fair Queueing (including Weighted Fair Queueing)[20]. These both approximate a weighted bitwise round robin service to packets, and Keshav and Hui Zhang claim that the two are equivalent [61].
Reference: 23. <author> S. J. Golestani, </author> <title> A Stop-and-Go Framework for Congestion Management, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 8-18 ACM SIGCOMM, </note> <month> (Sept 24-27, </month> <year> 1990). </year> <month> 196 </month>
Reference-contexts: The final element in an allocation system is a mechanism in the network to provide the requested resources to traffic. The most common mechanism is a system of queueing packets at network nodes, like Weighted Fair Queueing [20], Virtual Clock [21, 22], or Stop-and-Go <ref> [23] </ref>. These queueing disciplines provide each source with a guaranteed rate of service, or a guaranteed amount of another resource. For example, Stop-and-go provides both rate and jitter bounds. All disciplines of this type constrain the way traffic is served in the network. <p> The policy and framing discipline is referred to as Stop-and-Go queueing <ref> [23, 67-70] </ref>. Under Stop-and-Go, time is divided into frames on both incoming and outgoing links. Packets arriving in an incoming frame are sent in the next nonoverlapping outgoing frame. Incoming and outgoing frames need not be synchronized, and in general are not. <p> Such systems constrain a source's traffic to meet certain criteria, and guarantee that the real-time bounds on the source's traffic will be met through the use of specialized queueing systems. Examples are the Tenet System [90, 91], and Stop-and-Go <ref> [23] </ref>. Such systems are basically tuned allocation congestion control and avoidance systems. The constraints on traffic and associated queueing disciplines in the network combine to ensure that the networks will meet the requested bounds. They suffer from the same shortcoming of other allocation systems, namely underbooking the network.
Reference: 24. <author> J-C Bolot and A. Shankar, </author> <title> Dynamical Behavior of Rate Based Flow Control Systems, </title> <journal> Computer Communications Review 20(2)ACM SIGCOMM, </journal> <month> (Apr. </month> <year> 1990). </year>
Reference-contexts: Since feedback is used for both control and avoidance in this type of system, the time to clear congested queues depends directly on the bandwidth delay product <ref> [24] </ref>. The larger the bandwidth-delay product, the less accurate feedback from the network is about the current state of that network. Noting that from the 1980's to the present the bandwidth delay product has increased by a factor of 1000, feedback systems face a potentially insurmountable challenge. 1.4. <p> Haas uses back to back sampling packets to sense network load, and adjust sending rate by adjusting the minimum interpacket gap [35, 36]. Bolot and Shankar have also investigated rate based flow control in detail <ref> [24, 37] </ref>. They have treated network traffic as a fluid and investigated the properties of feedback-based rate controls mathematically. Their work provides many clear intuitions into the dynamics of such systems. 2.1.2. Window-based Systems As mentioned above, one can set a rate indirectly by setting a window size. <p> Under windowing feedback systems, congestion duration is directly related to the size of window oscillations, which depends on the bandwidth-delay product of the network <ref> [24] </ref>. In summary, DTW is the combination of source control algorithms enforcing the time window criterion and switch algorithms using feedback to adjust the sources' time windows to fully utilize the network. DTW is unique in the extent to which it decouples congestion control and avoidance. <p> The severity of the congestion, specifically the queue length at the bottleneck switch, is directly related to the time required for the control messages to be received and the to bandwidth of the network <ref> [24] </ref>. Once the sources have been throttled back, the network 70 must still remove the excess switch queue buildup in the face of repeated retransmis-sions. This reduces the effectiveness of the congestion messages once they arrive.
Reference: 25. <author> A. Mukherjee, L. Landweber, and T. </author> <title> Faber, Dynamic Time Windows and Generalized Virtual Clock: Combined Closed Loop/Open Loop Congestion Control, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 322-332 IEEE, </pages> <month> (May 6-8, </month> <year> 1992). </year>
Reference-contexts: DTW Work This thesis is not the first published work on Dynamic Time Windows. Early work was done on the system by Mukherjee, Landweber and Faber. They have presented work on the Pulse queueing discipline, which initially used in DTW, and outline the basic concepts of time windows <ref> [25] </ref>. The DTW stability theorem, stated and proven in Chapter 3, was also previously published, along with simulation studies of the DTW feedback system used through one switch [26].
Reference: 26. <author> T. Faber, L. Landweber, and A. Mukherjee, </author> <title> Dynamic Time Windows: Packet Admission Control with Feedback, </title> <booktitle> Proc. ACM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. 124-135 ACM, </pages> <month> (August 17-20, </month> <year> 1992). </year>
Reference-contexts: The DTW stability theorem, stated and proven in Chapter 3, was also previously published, along with simulation studies of the DTW feedback system used through one switch <ref> [26] </ref>. The thesis builds on the lessons learned in that work by extending the queueing discipline to be more general, and adapting the feedback system to more complex networks. It also provides new analytic results, more complex and detailed simulation results, and experimental evidence from a prototype implementation. <p> A congested switch decreases its MTW; an uncong-ested switch increases its MTW. This algorithm is implemented for its simplicity. Many changes could be made to the algorithm including damping oscillations in when the network is perceived to be in a stable state <ref> [26] </ref>. However, implementing this algorithm allowed us to experiment with an algorithm that is a direct analog to a packet window adjustment algorithm.
Reference: 27. <author> Manolis Katevenis, </author> <title> Fast Switching and Fair Control of Congested Flow in Broadband Networks, </title> <journal> IEEE Journal on Selected Areas in Communications SAC-5(8) pp. 1315-1326 IEEE, </journal> <month> (Oct. </month> <year> 1987). </year>
Reference-contexts: Some people have gone so far as to say that the technology of the day, cheap buffer memories, has solved the congestion control problem, since we can buffer as much traffic as we could ever need to deal with <ref> [27] </ref>. Sadly, this is not so, since delaying traffic by putting it in excessively large queues is in many cases as bad as losing it. Jain investigates this and other myths about congestion control [28]. We describe the previous work in three subareas: feedback systems, allocation systems, and others.
Reference: 28. <author> R. Jain, </author> <title> Congestion Control in Computer Networks: Issues and Trends, </title> <journal> IEEE Network 4(3) pp. 24-30 IEEE, </journal> <month> (May </month> <year> 1990). </year>
Reference-contexts: Sadly, this is not so, since delaying traffic by putting it in excessively large queues is in many cases as bad as losing it. Jain investigates this and other myths about congestion control <ref> [28] </ref>. We describe the previous work in three subareas: feedback systems, allocation systems, and others. Feedback systems rely on information from the network, directly or indirectly, to adjust source behavior to meet changing network conditions.
Reference: 29. <author> Andrew S. Tannenbaum, </author> <title> Computer Networks, 2nd ed., </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ (1988). </address>
Reference-contexts: This control works best when the source can always send; that is the acknowledgement for the first packet sent arrives just as the last packet allowed by the window is being sent <ref> [29] </ref>. 2.1.1. Rate-Based Systems Bharath-Kumar and Jaffe provide an extensive analysis of the two virtual circuit case of a rate control system [30]. The system is designed to maximize power, which is source throughput divided by the packet delay raised to a given power. They develop three algorithms.
Reference: 30. <author> Kadaba Bharath-Kumar and Jeffrey Jaffe, </author> <title> A New Approach to Performance-Oriented Flow Control, </title> <journal> IEEE Transactions on Communications COM-29(4) pp. 427-435 IEEE, </journal> <month> (April </month> <year> 1981). </year>
Reference-contexts: Rate-Based Systems Bharath-Kumar and Jaffe provide an extensive analysis of the two virtual circuit case of a rate control system <ref> [30] </ref>. The system is designed to maximize power, which is source throughput divided by the packet delay raised to a given power. They develop three algorithms. The first is a simple greedy maximization of power by each sender in turn.
Reference: 31. <author> Jeffrey Jaffe, </author> <title> Flow Control Power is Nondecentralizable, </title> <journal> IEEE Transactions on Communications COM-29(9) pp. 1301-1306 IEEE, </journal> <month> (Sept. </month> <year> 1981). </year>
Reference-contexts: In all cases, the algorithms assume global knowledge of the network. Jaffe later shows that this performance metric is nondecentralizable, meaning that this metric can be maximized for the entire network only by the use of a centralized server <ref> [31] </ref>. In other words, a group of sources avoiding congestion cannot optimize the usage of the enitre network without global knowledge. He also describes a system that uses a centralized system that maximizes power [4].
Reference: 32. <author> J. Selgar, </author> <title> New Flow Control Power is Decentralizable and Fair, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 87-96 IEEE, </pages> <month> (Apr. </month> <pages> 9-12, </pages> <year> 1984). </year> <month> 197 </month>
Reference-contexts: He also describes a system that uses a centralized system that maximizes power [4]. The decentralizability issue is 19 taken up by Selgar, who proposes another definition of power that is decentralizable <ref> [32] </ref>, and puts forth a class of algorithms to maximize it [33]. The above do not probe the network state to determine the state of the network. The only change in state they detect is the addition or deletion of a source.
Reference: 33. <author> J. M. Selgar, </author> <title> A Class of Flow Control Algorithms that Maximize the New Flow Control Power, </title> <booktitle> Proc. IEEE Globecom, IEEE, </booktitle> <month> (Nov. </month> <pages> 26-29, </pages> <year> 1984). </year>
Reference-contexts: He also describes a system that uses a centralized system that maximizes power [4]. The decentralizability issue is 19 taken up by Selgar, who proposes another definition of power that is decentralizable [32], and puts forth a class of algorithms to maximize it <ref> [33] </ref>. The above do not probe the network state to determine the state of the network. The only change in state they detect is the addition or deletion of a source.
Reference: 34. <author> Jum Matsumoto, </author> <title> Flow Control in Packet-Switched Networks by Gradual Restrictions of Virtual Calls, </title> <journal> IEEE Transactions on Communications COM-29(4) pp. 466-473 IEEE, </journal> <month> (April </month> <year> 1981). </year>
Reference-contexts: Other systems probe the network for information. Matsumoto describes a system where virtual circuits have their throughputs reduced and then cut off altogether based on queue lengths at the switches <ref> [34] </ref>. Haas uses back to back sampling packets to sense network load, and adjust sending rate by adjusting the minimum interpacket gap [35, 36]. Bolot and Shankar have also investigated rate based flow control in detail [24, 37].
Reference: 35. <author> Z. Haas and J. Winters, </author> <title> Congestion Control by Adaptive Admission, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 560-569 IEEE, </pages> <month> (Apr. </month> <pages> 7-9, </pages> <year> 1991). </year>
Reference-contexts: Matsumoto describes a system where virtual circuits have their throughputs reduced and then cut off altogether based on queue lengths at the switches [34]. Haas uses back to back sampling packets to sense network load, and adjust sending rate by adjusting the minimum interpacket gap <ref> [35, 36] </ref>. Bolot and Shankar have also investigated rate based flow control in detail [24, 37]. They have treated network traffic as a fluid and investigated the properties of feedback-based rate controls mathematically. Their work provides many clear intuitions into the dynamics of such systems. 2.1.2.
Reference: 36. <author> Z. Haas, </author> <title> Adaptive Admission Congestion Control, </title> <journal> Computer Communications Review 21(5) pp. 58-76 ACM SIGCOMM, </journal> <month> (Oct. </month> <year> 1991). </year>
Reference-contexts: Matsumoto describes a system where virtual circuits have their throughputs reduced and then cut off altogether based on queue lengths at the switches [34]. Haas uses back to back sampling packets to sense network load, and adjust sending rate by adjusting the minimum interpacket gap <ref> [35, 36] </ref>. Bolot and Shankar have also investigated rate based flow control in detail [24, 37]. They have treated network traffic as a fluid and investigated the properties of feedback-based rate controls mathematically. Their work provides many clear intuitions into the dynamics of such systems. 2.1.2.
Reference: 37. <author> J.-C. Bolot and A. Shankar, </author> <title> Analysis of a Fluid Approximation to Flow Control Dynamics, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 2398-2406 IEEE, </pages> <month> (May 6-8, </month> <year> 1992). </year>
Reference-contexts: Haas uses back to back sampling packets to sense network load, and adjust sending rate by adjusting the minimum interpacket gap [35, 36]. Bolot and Shankar have also investigated rate based flow control in detail <ref> [24, 37] </ref>. They have treated network traffic as a fluid and investigated the properties of feedback-based rate controls mathematically. Their work provides many clear intuitions into the dynamics of such systems. 2.1.2. Window-based Systems As mentioned above, one can set a rate indirectly by setting a window size.
Reference: 38. <author> Peter Harrison, </author> <title> An Analytic Model for Flow Control Schemes in Communication Network Nodes, </title> <journal> IEEE Transactions on Communications COM-32(9) pp. 1013-1019 IEEE, </journal> <month> (Sept. </month> <year> 1984). </year>
Reference-contexts: Harrison describes and analyzes a two mode queueing model designed to force the queue length at a switch to zero after congestion occurs. The system seems effective in controlling congestion, when latencies are low. His work is presented only for one switch <ref> [38] </ref>. Mor-gan gives a concise and intuitive description of the problem of determining optimal window size on a trunked byte stream [39]. He is able to derive a window size that is optimal for throughput, but the system is centralized and does not probe the network state.
Reference: 39. <author> Samuel Morgan, </author> <title> Window Flow Control on a Trunked Byte-Stream Virtual Circuit, </title> <journal> IEEE Transactions on Communications 36(7) pp. 816-825 IEEE, </journal> <month> (July </month> <year> 1988). </year>
Reference-contexts: The system seems effective in controlling congestion, when latencies are low. His work is presented only for one switch [38]. Mor-gan gives a concise and intuitive description of the problem of determining optimal window size on a trunked byte stream <ref> [39] </ref>. He is able to derive a window size that is optimal for throughput, but the system is centralized and does not probe the network state.
Reference: 40. <author> Leonard Kleinrock and Parviz Kermani, </author> <title> Static Window Flow Control in Store-and-Forward Computer Networks, </title> <journal> IEEE Transactions on Communications COM-28(2) pp. 271-278 IEEE, </journal> <month> (Feb. </month> <year> 1980). </year>
Reference-contexts: Klein-rock and Kermani use markovian analysis to model a single source sending to a single 20 destination via window based flow control, in both the case that the window is static, and that it is changed with network state <ref> [40, 41] </ref>. The results provide a thorough understanding of the simple case that they model. Mitra and Seery perform product-form queueing analysis of networks of queues, where the sources are controlled by windows controlled by feedback [42-44]. They provide both analyses and simulations of their work under various configurations.
Reference: 41. <author> Parviz Kermani and Leonard Kleinrock, </author> <title> Dynamic Window Flow Control in Store-and-Forward Computer Networks, </title> <journal> IEEE Transactions on Communications COM-28(2) pp. 263-271 IEEE, </journal> <month> (Feb. </month> <year> 1980). </year> <month> 198 </month>
Reference-contexts: Klein-rock and Kermani use markovian analysis to model a single source sending to a single 20 destination via window based flow control, in both the case that the window is static, and that it is changed with network state <ref> [40, 41] </ref>. The results provide a thorough understanding of the simple case that they model. Mitra and Seery perform product-form queueing analysis of networks of queues, where the sources are controlled by windows controlled by feedback [42-44]. They provide both analyses and simulations of their work under various configurations.
Reference: 42. <author> D. Mitra, </author> <title> Optimal Design of Windows for High Speed Data Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 1156-1163 IEEE, </pages> <month> (June 5-7, </month> <year> 1990). </year>
Reference: 43. <author> D. Mitra and T. Seery, </author> <title> Dynamic Adaptive Windows for High Speed Data Networks: Theory and Simulation, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 30-29 ACM SIGCOMM, </note> <month> (Sept 24-27, </month> <year> 1990). </year>
Reference: 44. <author> D. Mitra and J. Seery, </author> <title> Dynamic Adaptive Windows for High Speed Data Networks with Multiple Paths and Propagation Delays, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 39-48 IEEE, </pages> <month> (Apr. </month> <pages> 7-9, </pages> <year> 1991). </year>
Reference: 45. <author> J. Fernow and M. El-Sayed, </author> <title> Stability of Adaptive Controls in Packet Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 107-114 IEEE, </pages> <month> (Apr. </month> <pages> 18-21, </pages> <year> 1983). </year>
Reference-contexts: They claim that the resulting packet flow rate will have a deterministic component and a stochastic component that depends on the error in measurement, the rate of adjustment, and the magnitude of adjustment <ref> [45, 46] </ref>. Further analysis of win-dowing with feedback has been a common topic, with the common conclusion that it is possible to maximize throughput for small values of the bandwidth-delay product [47-52]. In general, these have been analytic studies where sources are modelled as sending at constant rates.
Reference: 46. <author> J. Fernow and M. El-Sayed, </author> <title> Stability of Adaptive Congestion Controls in Packet Networks, Computer Networks and ISDN Systems 10(1) pp. </title> <booktitle> 7-18 International Council for Computer Communication, </booktitle> <month> (Aug. </month> <year> 1985). </year>
Reference-contexts: They claim that the resulting packet flow rate will have a deterministic component and a stochastic component that depends on the error in measurement, the rate of adjustment, and the magnitude of adjustment <ref> [45, 46] </ref>. Further analysis of win-dowing with feedback has been a common topic, with the common conclusion that it is possible to maximize throughput for small values of the bandwidth-delay product [47-52]. In general, these have been analytic studies where sources are modelled as sending at constant rates.
Reference: 47. <author> S. Pingali, D. Tipper, and J. Hammond, </author> <title> The Performance of Adaptive Window Flow Controls in a Dynamic Environment, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 55-61 IEEE, </pages> <month> (June 5-7, </month> <year> 1991). </year>
Reference: 48. <author> K. Ramakrishnan, </author> <title> Analysis of a Dynamic Window Congestion Control Protocol in Heterogeneous Environments including Satellite Links, </title> <booktitle> Proc. IEEE Symposium on Computer Networks, </booktitle> <pages> pp. 94-104 IEEE, </pages> <year> (1986). </year>
Reference: 49. <author> A. Thomasian and P. </author> <title> Bey, Performance Analysis of Window Flow Control for Multiple Virtual Routes, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 69-80 IEEE, </pages> <month> (Apr. </month> <pages> 9-12, </pages> <year> 1984). </year> <month> 199 </month>
Reference: 50. <author> A. Thomasian, Burroughs, and P. </author> <title> Bey, Analytical Solution of an Integrated Performance Model of a Computer Communication Newtork with Window Flow Control, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 225-233 ACM SIGCOMM, </note> <month> (June 7-8 </month> <year> 1984). </year>
Reference: 51. <author> Wang and Sengupta, </author> <title> Performance Analysis of a Feedback Congestion Control Policy under Non-Negligible Propagation Delay, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 149-158 ACM SIGCOMM, </note> <month> (Sept. </month> <pages> 3-6, </pages> <year> 1991). </year>
Reference: 52. <author> Felix Wong and Jose De Marca, </author> <title> Fairness in Window Flow Controlled Computer Networks, </title> <journal> IEEE Transactions on Communications 37 pp. 475-480 IEEE, </journal> <month> (May </month> <year> 1989). </year>
Reference: 53. <author> D. Chiu and R. Jain, </author> <title> Analysis of the Increase and Decrease Algorithms for Congestion Avoidance in Computer Networks, Computer Networks and ISDN Systems 17(1) pp. 1-14 International Council for Computer Communication, </title> (). 
Reference-contexts: They also confirm Jaffe's earlier observation that without 21 sharing information, it is impossible for sources to converge to an optimal usage of resources for the network. Jain and Chiu also use simulation to investigate several methods of adjusting window size <ref> [53] </ref>. They are able to control congestion effectively using existing protocols and routers. However, their feedback method does not scale particularly well to high speed networks, due to the familiar problem with a large bandwidth delay product.
Reference: 54. <author> J. Nagle, </author> <note> Congestion Control in TCP/IP Internetworks, Computer Communications Review 14(4) pp. 11-17 ACM SIGCOMM, </note> <month> (Oct. </month> <year> 1984). </year>
Reference-contexts: They are able to control congestion effectively using existing protocols and routers. However, their feedback method does not scale particularly well to high speed networks, due to the familiar problem with a large bandwidth delay product. Another interesting packet based feedback system is the TCP/IP system in the Internet <ref> [54] </ref>. Of primary interest are the congestion control mechanisms added to the BSD UNIX kernel by Van Jacobson [8]. The mechanisms detect congestion in the network by detecting packet loss either via an out of order acknowledgement or a timeout mechanism.
Reference: 55. <author> D. Clark, S.Shenker, and L. Zhang, </author> <title> Some Observations on the Dynamics of a Congestion Control Algorithm, </title> <journal> Computer Communications Review 20(5) pp. 30-39 ACM SIGCOMM, </journal> <month> (Oct. </month> <year> 1990). </year>
Reference-contexts: Since the system is deducing the state of the network, it is required to activate congestion control whenever it believes the network state has changed for the worse. Studies have revealed this algorithm to have both desirable and undesirable properties <ref> [55] </ref>. Packets tend to clump with packets from the same source remaining together in the switch queues, and when the network becomes congested, all sources lose packets.
Reference: 56. <author> L. Zhang, S. Shenker, and D. Clark, </author> <title> Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two-Way Traffic, </title> <booktitle> Proc. Symposioum on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 133-148 ACM SIGCOMM, </note> <month> (Sept. 3-6 </month> <year> 1991). </year> <month> 200 </month>
Reference-contexts: Furthermore, due to the FIFO service disciplines of the switching 22 nodes in the Internet, and TCP's use of acknowledgement packets as an implicit clock on senders' rates, the system can exhibit instabilities and packet loss due to acknowledgement compression <ref> [56, 57] </ref>. Wang and Crowcroft propose a variant of the Jacobson congestion controls which seeks to more explicitly find the knee of the throughput/load curve by following the normalized throughput gradient [58]. The normalized throughput gradient is essentially the rate of change of throughput with respect to load.
Reference: 57. <author> J. Mogul, </author> <title> Observing TCP Dynamics in Real Networks, </title> <booktitle> Proc. Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 305-317 ACM SIGCOMM, </note> <month> (August 17-20, </month> <year> 1992). </year>
Reference-contexts: Furthermore, due to the FIFO service disciplines of the switching 22 nodes in the Internet, and TCP's use of acknowledgement packets as an implicit clock on senders' rates, the system can exhibit instabilities and packet loss due to acknowledgement compression <ref> [56, 57] </ref>. Wang and Crowcroft propose a variant of the Jacobson congestion controls which seeks to more explicitly find the knee of the throughput/load curve by following the normalized throughput gradient [58]. The normalized throughput gradient is essentially the rate of change of throughput with respect to load.
Reference: 58. <author> Z. Wang and J. Crowcroft, </author> <title> A New Congestion Control Scheme: Slow-Start and Search, </title> <journal> Computer Communications Review 21(1) pp. 32-43 ACM SICGOMM, </journal> <month> (Jan. </month> <year> 1991). </year>
Reference-contexts: Wang and Crowcroft propose a variant of the Jacobson congestion controls which seeks to more explicitly find the knee of the throughput/load curve by following the normalized throughput gradient <ref> [58] </ref>. The normalized throughput gradient is essentially the rate of change of throughput with respect to load. They also seek to explicitly synchronize changes in source window sizes rather than relying on the implicit synchronization losses induce. Keshav has taken a control theoretic approach to congestion control [59].
Reference: 59. <author> S. Keshav, </author> <title> A Control-Theoretic Approach to Congestion Control, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 3-16 ACM SIGCOMM, </note> <month> (Sept. </month> <pages> 3-6, </pages> <year> 1991). </year>
Reference-contexts: The normalized throughput gradient is essentially the rate of change of throughput with respect to load. They also seek to explicitly synchronize changes in source window sizes rather than relying on the implicit synchronization losses induce. Keshav has taken a control theoretic approach to congestion control <ref> [59] </ref>. He derives a control law for source sending rates based on the rate of the bottleneck server on a given path. He sends packets back to back to probe the service rate at the bottleneck server by measuring the difference in arrival times of their acknowledgements. <p> He requires a fair queueing discipline at all switches in the network to ensure that this is a reasonable estimate. The system works well, but is susceptible to the limitations of feedback systems in high-bandwidth delay product networks <ref> [59, 60] </ref>. 2.2. Allocation Systems Allocation systems are systems that control congestion by reserving resources for sources based on descriptions of their behavior. If sources maintain the negotiated behavior, these systems guarantee that congestion does not occur. <p> This is similar to DTW's packet admission, except that DTW's packet admission system allows the average interval to change as well. Fair Queueing has been simulated and employed in several systems, including Keshav's Packet Pair system <ref> [59] </ref>, and a study of Fair Queueing and TCP [66]. 24 Golestani describes a queueing policy designed to maintain guaranteed jitter, delay, and loss bounds. The policy and framing discipline is referred to as Stop-and-Go queueing [23, 67-70].
Reference: 60. <author> S. Keshav, </author> <title> Congestion Control in Computer Networks, </title> <type> Ph. D Thesis, </type> <pages> pp. </pages> <institution> 1-109 University of California at Berkeley, </institution> <year> (1991). </year>
Reference-contexts: He requires a fair queueing discipline at all switches in the network to ensure that this is a reasonable estimate. The system works well, but is susceptible to the limitations of feedback systems in high-bandwidth delay product networks <ref> [59, 60] </ref>. 2.2. Allocation Systems Allocation systems are systems that control congestion by reserving resources for sources based on descriptions of their behavior. If sources maintain the negotiated behavior, these systems guarantee that congestion does not occur.
Reference: 61. <author> H. Zhang and S. Keshav, </author> <title> Comparison of Rate-Based Service Disciplines, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 133-148 ACM SIGCOMM, </note> <month> (Sept. 3-6 </month> <year> 1991). </year>
Reference-contexts: A common aspect of these systems is a specification of the queueing disciplines used at intermediate switches. Keshav and Hui Zhang provide an overview of many of 23 these disciplines <ref> [61] </ref>. Among the most interesting queueing disciplines are Virtual Clock [21, 22] and Fair Queueing (including Weighted Fair Queueing)[20]. These both approximate a weighted bitwise round robin service to packets, and Keshav and Hui Zhang claim that the two are equivalent [61]. <p> provide an overview of many of 23 these disciplines <ref> [61] </ref>. Among the most interesting queueing disciplines are Virtual Clock [21, 22] and Fair Queueing (including Weighted Fair Queueing)[20]. These both approximate a weighted bitwise round robin service to packets, and Keshav and Hui Zhang claim that the two are equivalent [61]. Both provide a way of fairly allocating switch processor time to multiple sources, in a way that becomes more fair as the packets get smaller. These disciplines approximate the processor sharing discipline from queueing theory at switches in the network. <p> Controls on the source sending rates ensure that the switches can always fit all the traffic from one incoming frame in one outgoing frame. Providing multiple frame sizes allows sources with different requirements to share links. There are questions regarding the tightness of the jitter bounds <ref> [61] </ref> and one must note that the discipline is not work conserving, which makes certain analyses difficult. Traffic admission control and resource reservation, with or without sophisticated queueing, constitute another component of allocation systems. <p> The Virtual Clock queueing discipline [21] implements Weighted Fair Queueing where the weights are assigned based on the negotiated average rates of sources. <ref> [61] </ref> Virtual Clock guarantees each source a minimum service rate at each switch proportional to that source's negotiated average rate and uses a simpler algorithm to calculate timestamps. Under Virtual Clock, switches associate a virtual clock with each queue.
Reference: 62. <author> S. Morgan, </author> <title> Queueing Disciplines and Passive Congestion Control in Byte Stream Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 711-720 IEEE, </pages> <month> (Apr. </month> <pages> 23-24, </pages> <year> 1989). </year>
Reference-contexts: Both also insulate well behaved users from misbehaving ones by guaranteeing each source the agreed upon allocation of switch processor time. Mor-gan independently verifies the firewalling capabilities of these disciplines <ref> [62] </ref>. Parekh and Gallagher analyze them extensively, proving many useful properties [63-65]. Virtual Clock is incorporated in Lixia Zhang's flow network, which uses a user behavior envelope based on sources' negotiated parameters to smooth traffic [18].
Reference: 63. <author> Abhay K. J. Parekh, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks, </title> <publisher> MIT (January 24, </publisher> <year> 1992). </year>
Reference-contexts: and the service rate of the switch be m, the instantaneous service rate of queue i 's traffic is bounded by: (3.2) m of queue i service rate instantaneous S s j s i hhhh m where the index of the summation runs over all virtual circuits using the switch <ref> [63] </ref>. The quantity s i is called the service share of a queue i , and it is negotiated between source and switches when a virtual circuit is established. Each queue in the switch contains traffic from exactly one virtual circuit. <p> Relaxing the assumption that traffic is continuous adds additional terms to the lower bound in Equation (3.2). These bounds have been calculated by Demers, Keshav, and Shenker [20] as well as by Parekh <ref> [63] </ref>. The additional terms added to Equation (3.2) by relaxing this assumption do not enhance the understanding of the algorithms of DTW, 41 and DTW can be modified to use the more exact bounds. <p> However we believe the approximations are justified in a high speed ATM network. Parekh has shown that the deviation from the ideal behavior of WFQ is directly related to the ratio of the cell size to the rate of the switch <ref> [63] </ref>. ATM cells are 66 small compared to the bandwidth of switches in high speed networks. As an example, the ratio of an ATM cell size to the backplane bandwidth of the XUNET switch is 738 ns.
Reference: 64. <author> Abhay Parekh and Robert Gallager, </author> <title> A Generalized Processor Sharing Approach to Flow Control In Integrated Services Networks The Multiple Node Case, </title> <type> Tech Report 2076, </type> <institution> MIT, </institution> <year> (1991). </year> <month> 201 </month>
Reference: 65. <author> Abhay Parekh and Robert Gallager, </author> <title> A Generalized Processor Sharing Approach to Flow Control In Integrated Services Networks The Single Node Case, </title> <booktitle> Proc. IEEE INFOCOM 2 pp. 915-924 IEEE, </booktitle> <month> (May 6-8, </month> <year> 1992). </year>
Reference: 66. <author> J. Darvin and A. Heybey, </author> <title> A Simulation Study of Fair Queueing and Policy Enforcement, </title> <journal> Computer Communication Review 20(5) pp. 23-29 ACM SIGCOMM, </journal> <month> (Oct. </month> <year> 1990). </year>
Reference-contexts: This is similar to DTW's packet admission, except that DTW's packet admission system allows the average interval to change as well. Fair Queueing has been simulated and employed in several systems, including Keshav's Packet Pair system [59], and a study of Fair Queueing and TCP <ref> [66] </ref>. 24 Golestani describes a queueing policy designed to maintain guaranteed jitter, delay, and loss bounds. The policy and framing discipline is referred to as Stop-and-Go queueing [23, 67-70]. Under Stop-and-Go, time is divided into frames on both incoming and outgoing links. <p> All switches implement WFQ, even those used by the TCP-like feedback system described later. It has been shown that WFQ improves TCP performance, so using WFQ in this context does not penalize the TCP-like system <ref> [66] </ref>. In all simulations, sources use equal buffer and service shares with values of 0.05. The AMTW is 50 secs, primarily so that switches can have relatively fine control over source time windows.
Reference: 67. <author> S. J. Golestani, </author> <title> Congestion Free Transmission of Real-Time Traffic in Packet Networks, </title> <booktitle> Proc. INFOCOM, </booktitle> <pages> pp. 527-536 IEEE, </pages> <year> (1990). </year>
Reference: 68. <author> S. Golestani, </author> <title> A Framing Strategy for Congetsion Management, </title> <journal> IEEE Journal on Selected Areas in Communications 9(7) pp. 1064-1077 IEEE, </journal> <month> (Sept. </month> <year> 1991). </year>
Reference: 69. <author> S. Golestani, </author> <title> Congestion-Free Communications in High-Speed Packet Networks, </title> <journal> IEEE Transactions on Communications 39(12) pp. 1802-1812 IEEE, </journal> <month> (Dec. </month> <year> 1991). </year>
Reference: 70. <author> S. Golestani, </author> <title> Duration-Limited Statistical Multiplexing of Delay Sensitive Traffic in Packet Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 323-330 IEEE, </pages> <month> (Apr. </month> <pages> 7-9, </pages> <year> 1991). </year>
Reference: 71. <author> Louis Pouzin, </author> <title> Methods, Tools, and Observations on Flow Control in Packet-Switched Data Networks, </title> <journal> IEEE Transactions on Communications COM-29(4) pp. 413-426 IEEE, </journal> <month> (April </month> <year> 1981). </year>
Reference-contexts: In order to send a packet, a source had to acquire a credit from the network, which was reintroduced when the packet left the network. This system still allowed local points of congestion to occur <ref> [71] </ref>. Giessler, Jagemann, Maser and Hanle proposed controlling congestion by setting aside a number of buffers at each switch labeled by the number of hops a packet had taken.
Reference: 72. <author> Alfred Giessler, Annemarie Jagemann, Ellen Maser, and Jurgen Hanle, </author> <title> Flow Control Based on Buffer Classes, </title> <journal> IEEE Transactions on Communications COM-29(4) pp. 436-443 IEEE, </journal> <month> (April </month> <year> 1981). </year> <month> 202 </month>
Reference-contexts: If a packet arrived at a switch and there were no buffers available labeled with the number of hops it had taken to arrive at this switch, it was discarded <ref> [72] </ref>. This scheme was originally put forward to prevent deadlock in networks, but is also proposed as a 25 congestion control method. Kamoun proposes a similar scheme, but only partitions the buffers into a set for new packets and a set for packets that have been forwarded once.
Reference: 73. <author> Farouk Kamoun, </author> <title> A Drop and Throttle Flow Control Policy for Computer Networks, </title> <journal> IEEE Transactions on Communications COM-29(4) pp. 444-452 IEEE, </journal> <month> (April </month> <year> 1981). </year>
Reference-contexts: By controlling the number of buffers set aside for new packets, the number of new packets entering the network as a whole can be constrained <ref> [73] </ref>. A popular method of source traffic control is the leaky bucket, proposed by Turner [13]. Each source is permitted to send one packet (or number of bits) for each credit it has in a pool.
Reference: 74. <author> D. Luan and D. Lucantoni, </author> <title> Throughput Analysis of a Window Based Flow Control Subject to Bandwidth Management, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 411-417 IEEE, </pages> <month> (Mar. </month> <pages> 29-31, </pages> <year> 1988). </year>
Reference: 75. <author> A. Eckberg, D. Luan, and D. Lucatoni, </author> <title> Bandwidth Management: a Congestion Control Strategy for Broadband Packet Networks Characterizing the Throughput Burstiness Filter, Computer Networks and ISDN Systems 20(1-5) pp. 415-424 International Council for Computer Communication, </title> (). 
Reference: 76. <author> A. Eckberg, D. T. Luan, and D. Lucantoni, </author> <title> Meeting the Challenge: Congestion and Flow Control Strategies for Broadband Information Transport, </title> <booktitle> Proc. IEEE Globecom, IEEE, </booktitle> <year> (1989). </year>
Reference-contexts: The allocation system does not attempt to sense network state in any way. We chose Leaky Bucket as a representative allocative enforcement mechanism since it is often proposed as a congestion control scheme for ATM traffic <ref> [76] </ref>. For example, the ATM forum suggests it as a policing mechanism [17]. 5.6.1. DTW vs.
Reference: 77. <author> G. Ramamurthy and R. Dighe, </author> <title> Distributed Source Control : A Network Access Control for Integrated Broadband Packet Networks, </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <pages> pp. 896-907 IEEE, </pages> <month> (June 5-7, </month> <year> 1990). </year>
Reference: 78. <author> G. Ramamurthy and R. Dighe, </author> <title> Distributed Source Control : A Network Access Control for Integrated Broadband Packet Networks, </title> <journal> IEEE Journal on Selected Areas in Communications 9(7) pp. 990-1001 IEEE, </journal> <month> (Sept. </month> <year> 1991). </year>
Reference: 79. <author> Harry Rudin and Heinrich Mueller, </author> <title> Dynamic Routing and Flow Control, </title> <journal> IEEE Transactions on Communications COM-28(7) pp. 1030-1039 IEEE, </journal> <month> (July </month> <year> 1980). </year>
Reference: 80. <author> G. Stassinopoulos and Panagiotis Konstantopoulos, </author> <title> Optimal Congestion Control in Single Destination Networks, </title> <journal> IEEE Transactions on Communications Com-33(8) pp. 792-800 IEEE, </journal> <month> (Aug. </month> <year> 1985). </year> <month> 203 </month>
Reference: 81. <author> Guatam Thaker and J. Bibb Cain, </author> <title> Interactions Between Routing and Flow Control Algorithms, </title> <journal> IEEE Transactions on Communications COM-34(3) pp. 269-277 IEEE, </journal> <month> (March </month> <year> 1986). </year>
Reference: 82. <author> B. Sanders, </author> <title> An Asynchronous Distributed Flow Control Algorithm for Rate Allocation in Computer Networks, </title> <journal> IEEE Transactions on Computers 37(7) pp. 779-787 IEEE, </journal> (). 
Reference-contexts: Jain suggests this may be fruitful due to the apparent conflict between a selfish optimum sending rate and a network optimal sending rate [2]. Sanders investigates this area, and 27 describes a pricing system whereby rational users will adjust their sending rates based on price incentives <ref> [5, 82] </ref>.
Reference: 83. <author> Williamson and Cheriton, </author> <title> Load-Loss Curves: Support for Rate Based Congestion Control in High Speed Datagram Networks, </title> <booktitle> Proc. SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. </pages> <note> 17-30 ACM SIGCOMM, </note> <month> (Sept. </month> <pages> 3-6, </pages> <year> 1991). </year>
Reference-contexts: Also, the fact that gradient hill climbing is used means that the system is subject to finding false maxima. Williamson and Cheriton propose having the network provide sources with a description of how likely the network is to drop packets based on a source's sending rate <ref> [83, 84] </ref>. What results is essentially a pricing system where the costs are given in terms of the loss performance of the network. Although this is an interesting idea, it also suffers from the same problems as Sanders' work.
Reference: 84. <author> Carey L. Williamson, </author> <title> Optimizing File Transfer Response Time Using the Loss-Load Curve Congestion Control Mechanism, </title> <booktitle> Proceedings of the Symposium on Communications Architectures, Protocols and Applications 23, </booktitle> <pages> #4 pp. </pages> <note> 117-126 ACM SIGCOMM, </note> <month> (September 13-17, </month> <year> 1993). </year>
Reference-contexts: Also, the fact that gradient hill climbing is used means that the system is subject to finding false maxima. Williamson and Cheriton propose having the network provide sources with a description of how likely the network is to drop packets based on a source's sending rate <ref> [83, 84] </ref>. What results is essentially a pricing system where the costs are given in terms of the loss performance of the network. Although this is an interesting idea, it also suffers from the same problems as Sanders' work.
Reference: 85. <author> R. Cruz, </author> <title> A Calculus for Network Delay, Part I, Network Elements in Isolation, </title> <journal> IEEE Transactions on Information Theory 37(1) pp. 114-131 IEEE, </journal> <month> (Jan. </month> <year> 1991). </year>
Reference-contexts: The goal of this analysis is to find conditions under which Theorem 3 holds at interior switches. Another choice would be to try to bound congestion times at switches without trying to apply Theorem 3. This approach has merit, and the work of Cruz <ref> [85, 86] </ref> suggests that success along these lines is possible. Proceeding along those lines does not seem to provide the bound on the distortion presented in Theorem 5, however, so we chose this approach. 71 4.3.1.
Reference: 86. <author> R. Cruz, </author> <title> A Calculus for Network Delay, Part II: Network Analysis, </title> <journal> IEEE Transactions on Information Theory 37(1) pp. 132-141 IEEE, </journal> <month> (Jan. </month> <year> 1991). </year>
Reference-contexts: The goal of this analysis is to find conditions under which Theorem 3 holds at interior switches. Another choice would be to try to bound congestion times at switches without trying to apply Theorem 3. This approach has merit, and the work of Cruz <ref> [85, 86] </ref> suggests that success along these lines is possible. Proceeding along those lines does not seem to provide the bound on the distortion presented in Theorem 5, however, so we chose this approach. 71 4.3.1.
Reference: 87. <author> A. G. Fraser, </author> <title> Datakit A Modular Network for Synchronous and Asynchronous Traffic, </title> <booktitle> Conference Record of IEEE International Conference on Communications, </booktitle> <month> (June </month> <year> 1979). </year>
Reference-contexts: Although XUNET is an ATM network in the sense that it sends 53 byte cells across virtual circuits, it does not conform to the ATM Forum standards nor to the CCITT standards. This has little bearing on our experiments. The XUNET switch is a descendent of the Datakit switch <ref> [87] </ref>. The switch architecture is shown in Figure 6.2. It consists of a fast backplane with several cards attached to it. The cards are used to transmit and receive cells, queue cells, and switch cells.
Reference: 88. <author> Mary Vernon and U. manber, </author> <title> Distributed Round-Robin and First-Come First-Serve Protocols and Their Applications to Multiprocessor Bus Arbitration, </title> <booktitle> 15th IEEE International symposium on Computer Architecture, </booktitle> <month> (May 30 - June 2, 204 </month>
Reference-contexts: The cell is passed to the attached queue card, which queues the cell until it can be switched. Once a queue card has a cell that needs to be switched, it begins participating in a distributed algorithm <ref> [88] </ref> on the arbitration bus with all other queue cards that have cells to be switched. This algorithm determines fairly which queue gets access to the contention bus. The queue card that was granted use of the contention bus puts one cell on it, bound for the translation module.
Reference: 89. <author> Alan Berenbaum, Joe Dixon, Anand Iyengar, and Srinivasan Keshav, </author> <title> A Flexible ATM-Host Interface for XUNET II, </title> <journal> IEEE Network 7(4) pp. </journal> <month> 18-23 (July </month> <year> 1993). </year> <title> Special Issue: End-System Support for High-Speed Networks (Breaking Through the Network I/O Bottleneck) </title>
Reference-contexts: It has a custom kernel, which includes modifications to allow processes to send ATM cells directly. The modified kernel also includes a device driver to communicate with a high speed interface that sends ATM cells suitable for XUNET. This device is known as the Hobbit board <ref> [89] </ref>, named for the AT&T processor used as a DMA engine on it. The Hobbit board and device driver take a buffer of data from the kernel and divide it into ATM cells which are then sent out into the XUNET.
Reference: 90. <author> P. DiGenova, </author> <title> Real-Time Communication on Computer Networks: Introduction and Analysis of the Tenet Approach of Berkeley, </title> <institution> Tesi di Laurea, University of Bologna, </institution> <month> (December </month> <year> 1993). </year>
Reference-contexts: Such systems constrain a source's traffic to meet certain criteria, and guarantee that the real-time bounds on the source's traffic will be met through the use of specialized queueing systems. Examples are the Tenet System <ref> [90, 91] </ref>, and Stop-and-Go [23]. Such systems are basically tuned allocation congestion control and avoidance systems. The constraints on traffic and associated queueing disciplines in the network combine to ensure that the networks will meet the requested bounds.
Reference: 91. <author> Dominico Ferrari, Anindo Banerjea, and H. Zhang, </author> <title> Network Support for Multimedia A Discussion of the Tenet Approach, </title> <type> Technical Report TR-92-072, </type> <institution> International Computer Science Institute, </institution> <month> (October, </month> <year> 1992). </year>
Reference-contexts: Such systems constrain a source's traffic to meet certain criteria, and guarantee that the real-time bounds on the source's traffic will be met through the use of specialized queueing systems. Examples are the Tenet System <ref> [90, 91] </ref>, and Stop-and-Go [23]. Such systems are basically tuned allocation congestion control and avoidance systems. The constraints on traffic and associated queueing disciplines in the network combine to ensure that the networks will meet the requested bounds.

References-found: 91

