URL: http://www.almaden.ibm.com/cs/quest/papers/cg97_expanded.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Time-Series Similarity Problems and Well-Separated Geometric Sets  
Author: Bela Bollobas Gautam Das Dimitrios Gunopulos Heikki Mannila 
Abstract: Given a pair of nonidentical complex objects, defining (and determining) how similar they are to each other is a nontrivial problem. In data mining applications, one frequently needs to determine the similarity between two time series. We analyze a model of time-series similarity that allows outliers, different scaling functions, and variable sampling rates. We present several deterministic and randomized algorithms for computing this notion of similarity. The algorithms are based on nontrivial tools and methods from computational geometry. In particular, we use properties of families of well-separated geometric sets. The randomized algorithm has provably good performance and also works extremely efficiently in practice.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, C. Faloutsos and A. Swami. </author> <title> Efficient Similarity Search in Sequence Databases. </title> <booktitle> In Proc. of the 4th Intl. Conf. on Foundations of Data Organization and Algorithms (FODO'93), </booktitle> <year> 1993. </year>
Reference-contexts: We conclude with some future research directions. 4 Related work: There has been some recent work on the problem of defining similarity between time series; due to lack of space we only give some references. The problem was introduced to the data mining community by papers <ref> [1, 9] </ref>. The similarity measures considered in [2, 7, 13] use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. <p> The problem was introduced to the data mining community by papers [1, 9]. The similarity measures considered in [2, 7, 13] use the concept of longest common subsequence. In <ref> [1] </ref>, a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. In [11], feature extraction techniques are used; see [12] for a general discussion on fingerprinting techniques. <p> It is desirable to have algorithms that preprocess the database so that a linear scan can be avoided at query time. Several solutions exist (see <ref> [1, 2] </ref>), and it is intriguing whether our techniques can be extended to this problem.
Reference: [2] <author> R. Agrawal, K.-I. Lin, H. S. Sawhney and K. Shim. </author> <title> Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases. </title> <booktitle> In Proc. of the 21st Intl. Conf. on Very Large Data Bases (VLDB'95), </booktitle> <pages> pp 490-501. </pages>
Reference-contexts: The problem was introduced to the data mining community by papers [1, 9]. The similarity measures considered in <ref> [2, 7, 13] </ref> use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. <p> It is desirable to have algorithms that preprocess the database so that a linear scan can be avoided at query time. Several solutions exist (see <ref> [1, 2] </ref>), and it is intriguing whether our techniques can be extended to this problem.
Reference: [3] <author> A. V. Aho. </author> <title> Algorithms for Finding Patterns in Strings. </title> <booktitle> In Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, </booktitle> <publisher> Elsevier, </publisher> <year> 1990, </year> <pages> pp. 255-400. </pages>
Reference-contexts: A more symmetric definition of similarity would be to use maxfSim *;ffi (X; Y ), Sim *;ffi (Y; X)g. Given two sequences of length n, the longest common subsequence can be found in O (n 2 ) time by a well known dynamic programming algorithm <ref> [3, 6] </ref>; This algorithm can easily be modified to compute S f;*;ffi (X; Y ) in O (nffi) time where f is a given linear function. Note that this is essentially linear time. We refer to this algorithm as the LCSS algorithm.
Reference: [4] <author> B. Bollobas. </author> <title> Combinatorics. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: A family of finite sets S 2 V is k-separated if for all S i ; S j 2 S, jS i S j j &gt; k. It is known that there exist a k-separated family S where jSj = 2 ffn where ff depends on k=n <ref> [4] </ref>. However, we can get much better bounds if we only consider certain kinds of geometric sets. Consider the following set system. Let R be a fixed set of n line segments on the plane.
Reference: [5] <author> B. Chazelle, L. J. Guibas and D. T. Lee. </author> <title> The Power of Geometric Duality. </title> <booktitle> In Proc. of IEEE FOCS, </booktitle> <year> 1983, </year> <pages> pp. 217-225. </pages>
Reference-contexts: We start with stabbed sets. Consider a well known duality transformation, where a (non-vertical) line y = ax + b in the xy-plane is mapped to the point (a; b) in the ab-plane, and a point (x; y) is mapped to the line b = xa y <ref> [5, 8] </ref>. By this transformation, a line segment (u; v) in the xy-plane (Figure 2 (a)) corresponds to a double-wedge in the ab-plane, where the duals of u and v form the boundaries of the double-wedge (Figure 2 (b)). <p> This gives a total running time of O (n 3 ffi 3 ). This concludes the proof of Theorem 3.1. 2 It is instructive to study the above algorithm from the duality point of view (see <ref> [5, 8] </ref>). Recall that the dual of a line segment is a double-wedge in the ab-plane. Imagine computing 8 the duals of each segment in R, and computing the arrangement, A, of these double-wedges. Any linear function f corresponds to a point in the ab-plane. <p> It then runs LCSS on each function in L 0 , and finally outputs the normalized length of the longest sequence found. Compute the arrangement A as defined in the previous section (this can be done in O (n 2 ffi 2 ) time, see <ref> [5] </ref>). We shall construct the family L 00 as follows. Within each face of A, select a representative point. Build the planar dual graph of A, say Dual (A), where these representative points become vertices. Let P be an initially empty set of points.
Reference: [6] <author> T. H. Cormen, C. E. Leiserson and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1990, </year> <pages> pp. 314-319. </pages>
Reference-contexts: A more symmetric definition of similarity would be to use maxfSim *;ffi (X; Y ), Sim *;ffi (Y; X)g. Given two sequences of length n, the longest common subsequence can be found in O (n 2 ) time by a well known dynamic programming algorithm <ref> [3, 6] </ref>; This algorithm can easily be modified to compute S f;*;ffi (X; Y ) in O (nffi) time where f is a given linear function. Note that this is essentially linear time. We refer to this algorithm as the LCSS algorithm.
Reference: [7] <author> G. Das, D. Gunopulos and H. Mannila. </author> <title> Finding Similar Time Series. </title> <type> Manuscript, </type> <year> 1996. </year> <month> 12 </month>
Reference-contexts: respectively such that 1. for 1 k l 1, i k &lt; i k+1 and j k &lt; j k+1 , 3. for 1 k l, y j k =(1 + *) f (x i k ) y j k (1 + *). 1 and in a preliminary form in <ref> [7] </ref> 2 Let S f;*;ffi (X; Y ) be defined as l=n. Then Sim *;ffi (X; Y ) is defined as max f2L fS f;*;ffi (X; Y )g. Thus, when Sim *;ffi (X; Y ) is close to 1, the two sequences are considered to be very similar. <p> The problem was introduced to the data mining community by papers [1, 9]. The similarity measures considered in <ref> [2, 7, 13] </ref> use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. <p> In [11], feature extraction techniques are used; see [12] for a general discussion on fingerprinting techniques. Essentially the same similarity function as above was investigated in <ref> [7] </ref> (except that ffi was not considered). In that paper, each linear function y = ax + b is treated as a point (a; b) in the dual ab-plane. Using statistical measures, a bounded polygonal region in the ab-plane is computed which is guaranteed to contain all potential transformations. <p> We plan to investigate further some of the practical issues of the implementations. For example, preliminary experiments indicate that a combination of our statistical methods (see <ref> [7] </ref>) with the methods of this paper result in hybrid algorithms that seem to work very well. Interesting fundamental questions still remain. It is not clear whether any of the algorithms are optimal w.r.t. running time.
Reference: [8] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry. </title> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Given any infinite line L, let R L be the set of line segments of R intersected (or stabbed) by L. (If R L = R, then L is known as a transversal of R; refer to <ref> [8] </ref> for interesting combinatorial and algorithmic results on transversals). Let the family S consist of the distinct stabbed sets R L of R, for all possible infinite lines L. <p> Let H be a set of n infinite lines on the plane in general positions (i.e no three line intersect at a point). It is well known that the arrangement A (H) is a planar graph with fi (n 2 ) vertices, edges and faces <ref> [8] </ref>. Let k &gt; 0 be any integer. <p> We start with stabbed sets. Consider a well known duality transformation, where a (non-vertical) line y = ax + b in the xy-plane is mapped to the point (a; b) in the ab-plane, and a point (x; y) is mapped to the line b = xa y <ref> [5, 8] </ref>. By this transformation, a line segment (u; v) in the xy-plane (Figure 2 (a)) corresponds to a double-wedge in the ab-plane, where the duals of u and v form the boundaries of the double-wedge (Figure 2 (b)). <p> This gives a total running time of O (n 3 ffi 3 ). This concludes the proof of Theorem 3.1. 2 It is instructive to study the above algorithm from the duality point of view (see <ref> [5, 8] </ref>). Recall that the dual of a line segment is a double-wedge in the ab-plane. Imagine computing 8 the duals of each segment in R, and computing the arrangement, A, of these double-wedges. Any linear function f corresponds to a point in the ab-plane.
Reference: [9] <author> C. Faloutsos, M. Ranganathan and Y. Manolopoulos. </author> <title> Fast Subsequence Matching in Time-Series Databases. </title> <booktitle> In SIGMOD'94, </booktitle> <year> 1994. </year>
Reference-contexts: We conclude with some future research directions. 4 Related work: There has been some recent work on the problem of defining similarity between time series; due to lack of space we only give some references. The problem was introduced to the data mining community by papers <ref> [1, 9] </ref>. The similarity measures considered in [2, 7, 13] use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared.
Reference: [10] <author> H.V. Jagadish, A. O. Mendelzon and T. Milo. </author> <title> Similarity-Based Queries. </title> <booktitle> In Proc. of 14th Symp. on Principles of Database Systems (PODS'95), </booktitle> <year> 1995, </year> <pages> pp. 36-45. </pages>
Reference-contexts: 1 Introduction Being able to measure the similarity between objects is a crucial issue in many data retrieval and data mining applications; see <ref> [10] </ref> for a general discussion on similarity queries. Typically, the task is to define a function Sim (X; Y ), where X and Y are two objects of a certain class, and the function value represents how "similar" they are to each other.
Reference: [11] <author> H. Shatkay and S. Zdonik. </author> <title> Approximate Queries and Representations for Large Data Sequences. </title> <booktitle> In ICDE'96, </booktitle> <year> 1996. </year>
Reference-contexts: The similarity measures considered in [2, 7, 13] use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. In <ref> [11] </ref>, feature extraction techniques are used; see [12] for a general discussion on fingerprinting techniques. Essentially the same similarity function as above was investigated in [7] (except that ffi was not considered).
Reference: [12] <author> D. A. White and R. Jain. </author> <title> Algorithms and Strategies for Similarity Retrieval. </title> <type> Technical Report VCL-96-101, </type> <institution> Visual Computing Laboratory, UC Davis, </institution> <year> 1996. </year>
Reference-contexts: In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared. In [11], feature extraction techniques are used; see <ref> [12] </ref> for a general discussion on fingerprinting techniques. Essentially the same similarity function as above was investigated in [7] (except that ffi was not considered). In that paper, each linear function y = ax + b is treated as a point (a; b) in the dual ab-plane.
Reference: [13] <author> N. Yazdani and Z. M. Ozsoyoglu. </author> <title> Sequence Matching of Images. </title> <booktitle> In Proc. of the 8th Intl. Conf. on Scientific and Statistical Database Management, </booktitle> <year> 1996, </year> <pages> pp. 53-62. 13 </pages>
Reference-contexts: The problem was introduced to the data mining community by papers [1, 9]. The similarity measures considered in <ref> [2, 7, 13] </ref> use the concept of longest common subsequence. In [1], a fingerprint method is used, where the discrete Fourier transform is employed to reduce the dimensions of each sequence, and the resulting fingerprints are compared.
References-found: 13

