URL: ftp://ftp.research.microsoft.com/pub/ejh/dt.ps
Refering-URL: http://www.research.microsoft.com/users/horvitz/dt.htm
Root-URL: http://www.research.microsoft.com
Title: Decision Theory in Expert Systems and Artificial Intelligence  
Author: Eric J. Horvitz John S. Breese Max Henrion 
Date: July 1988  
Address: Stanford, California 94305  Palo Alto Laboratory 444 High Street Palo Alto, CA 94301  Pittsburgh, PA 15213  
Affiliation: Medical Computer Science Group Knowledge Systems Laboratory Stanford University  Rockwell International Science Center  Department of Engineering and Public Policy Carnegie Mellon University  
Abstract: Despite their different perspectives, artificial intelligence (AI) and the disciplines of decision science have common roots and strive for similar goals. This paper surveys the potential for addressing problems in representation, inference, knowledge engineering, and explanation within the decision-theoretic framework. Recent analyses of the restrictions of several traditional AI reasoning techniques, coupled with the development of more tractable and expressive decision-theoretic representation and inference strategies, have stimulated renewed interest in decision theory and decision analysis. We describe early experience with simple probabilistic schemes for automated reasoning, review the dominant expert-system paradigm, and survey some recent research at the crossroads of AI and decision science. In particular, we present the belief network and influence diagram representations. Finally, we discuss issues that have not been studied in detail within the expert-systems setting, yet are crucial for developing theoretical methods and computational architectures for automated reasoners. fl This is the technical report version of a paper appearing in the International Journal of Approximate Reasoning, 2:247-302, 1988 (Special Issue on Uncertainty in Artificial Intelligence). This work was supported by a NASA Fellowship to Eric Horvitz under Grant NCC-220-51 to Stanford University, by the National Science Foundation under Grant IRI-8703710, and by the National Library of Medicine under Grant R01LM04529. Max Henrion is partially supported by National Science Foundation Grant IST-8603493 to Carnegie-Mellon University. Computing facilities were provided by the SUMEX-AIM Resource under NIH Grant RR-00785. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.M. Agogino and A. Rege. IDES: </author> <title> Influence diagram based expert system. </title> <journal> Mathematical modelling, </journal> <volume> 8 </volume> <pages> 227-233, </pages> <year> 1987. </year>
Reference-contexts: Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [2] <author> J.S. Aikens. </author> <title> Representation of control knowledge in expert systems. </title> <booktitle> In Proceedings of the First Annual National Conference on Artificial Intelligence, </booktitle> <address> Stanford, CA, </address> <pages> pages 121-123. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <address> Palo Alto, CA, </address> ?? <year> 1980. </year>
Reference-contexts: The qualitative influence-diagram research centers on representing probabilistic dependencies qualitatively based on stochastic dominance. Decision theory also has been used for the control of inference. Most AI work on the control of inference has been based on heuristic control techniques <ref> [26, 38, 2] </ref>. Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies [48, 71].
Reference: [3] <author> S. Andreassen, M. Woldbye, B. Falck, and S.K. Andersen. </author> <title> MUNIN|a causal probabilistic network for interpretation of electromyographic findings. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <pages> pages 366-372. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [4] <author> T. </author> <title> Bayes. An essay towards solving a problem in the doctrine of chances. </title> <journal> Biometrika, </journal> <volume> 46 </volume> <pages> 293-298, </pages> <year> 1958. </year> <note> Reprint of Bayes' 1763 manuscript. </note>
Reference-contexts: This bidirectionality is a consequence of Bayes' theorem. 2 FOUNDATIONS 5 Bayes' theorem follows from the last axiom of probability, relating the probability of a joint event (i.e., a conjunction) to conditional probabilities <ref> [4] </ref>.
Reference: [5] <author> M. Ben-Bassat, V.K. Carlson, V.K. Puri, M.D. Davenport, J.A. Schriver, M.M. Latif, R. Smith, E.H. Lipnick, and M.H. Weil. </author> <title> Pattern-based interactive diagnosis of multiple disorders: The MEDAS system. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2 </volume> <pages> 148-160, </pages> <year> 1980. </year> <note> REFERENCES 40 </note>
Reference-contexts: The diagram itself, therefore, is an important tool in knowledge engineering, as well as in computation. In most current applications of influence diagrams and belief networks in expert systems, the model is constructed as part of the knowledge engineering process and is then is used during consultation <ref> [65, 5, 76] </ref>. We expect that, over time, additional components of knowledge engineering decision-theoretic systems will be automated. In the remainder of this section, we briefly review some of the fundamental issues in engineering decision-theoretic systems. <p> explain how evidence affects belief in competing hypotheses in the Glasgow-Dyspepsia expert system for assisting in gastroenterology diagnosis [140], in the Pathfinder system for reasoning about tissue pathology [76], in the Neurex system for diagnosis of neurological findings [124], and in the Medas system for assisting physicians in emergency medicine <ref> [5] </ref>. Likelihood ratios and weights of evidence also have been optionally converted from graphical to qualitative text descriptions in the Pathfinder and Medas projects. Pathfinder developers investigated the explanation of user-specific multiattribute-utility considerations associated with test decisions.
Reference: [6] <author> M. Ben-Bassat and D. Teeni. </author> <title> Human-oriented information acquistion in sequential pattern classification: Part 1 single membership classification. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 14 </volume> <pages> 131-138, </pages> <year> 1984. </year>
Reference-contexts: The hierarchies are used to classify diseases into a set of disease groups that depends on the diagnostic problem at hand [77]. Related research on the naturalness of alternative grouping schemes has been conducted by Ben-Bassat and Teeni <ref> [6] </ref>. Researchers also have investigated the application of decision theory at the metalevel to control the construction of explanations of decision-theoretic inference and of mathematical modeling [70, 104].
Reference: [7] <author> T.O. Binford, T.S. Levitt, and W.B. Mann. </author> <title> Bayesian inference in model-based machine vision. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 73-96. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: The application of influence diagrams in new areas is facilitated by their relatively unconstrained dependency structure at the level of relation. As an example, machine-vision researchers have applied probabilistic inference to perceptual tasks. In recent research, Binford and Levitt <ref> [7] </ref> have used a belief network to assign probabilities to alternative plausible three-dimensional objects, given a two-dimensional projection. Other researchers have examined learning within the decision-theoretic framework. Machine-learning researchers have dwelled almost exclusively on deterministic relationships.
Reference: [8] <author> R.L. Blum. </author> <title> Discovery, confirmation and incorporation of causal relationships from a large time-oriented clinical data base: The RX project. </title> <editor> In W.J. Clancey and E.H. Shortliffe, editors, </editor> <booktitle> Readings in Medical Artificial Intelligence: The First Decade, chapter 17, </booktitle> <pages> pages 399-425. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1984. </year>
Reference-contexts: Decision-theoretic approaches also hold promise for extending AI discovery research. Several research projects have been undertaken to apply probabilistic reasoning to discovery. Within the Radix project <ref> [8] </ref>, probabilistic and logical reasoning were used to control the generation and confir 6 CONCLUSIONS 38 mation of hypotheses about interesting relationships within a large medical database.
Reference: [9] <author> J.S. Breese. </author> <title> An expert system for decision analysis in securities trading. </title> <booktitle> In Proceedings of the First Annual Conference on Expert Systems in Business, </booktitle> <address> New York, </address> <pages> pages 19-26. </pages> ??, <month> October </month> <year> 1987. </year>
Reference-contexts: Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [10] <author> J.S. Breese. </author> <title> Knowledge Representation and Inference in Intelligent Decision Systems. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1987. </year>
Reference-contexts: typically uses rule-based or object-based representations, typically coupling them with some type of deductive inference method, whereas the decision analyst constructs influence diagrams or decision trees for use with decision-theoretic inference methods. 6 The core of decision-analytic knowledge engineering is the construction of an informative, credible, and computable decision basis <ref> [68, 10] </ref>. As we have seen, influence diagrams reduce the complexity of assessing influences by allowing explicit graphical representation of dependencies and independencies. The diagram itself, therefore, is an important tool in knowledge engineering, as well as in computation.
Reference: [11] <author> J.S. Breese and E. Tse. </author> <title> Integrating logical and probabilistic reasoning for decision making. </title> <booktitle> In Proceedings of Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 355-362. </pages> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <address> Mountain View, CA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: At the foundations of any decision model are decisions about the propositions to include within the decision basis, which often are based on logical relationships. Several researchers have examined the automated construction of decision models <ref> [67, 11, 156] </ref>. There are many unanswered questions regarding the automated assembling, pruning, and reasoning about decision models.
Reference: [12] <author> B.G. Buchanan and E.H. Shortliffe, </author> <title> editors. Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: A key feature of the new expert-system paradigm was the application of the production-rule architecture to real-world diagnosis. Production rules had appeal as providing a general and flexible scheme for representing expert knowledge in a declarative and modular form <ref> [12] </ref>. The production rule has the form of logical implication. To apply production rules in real-world diagnosis, investigators found it desirable to extend the representation to represent uncertainty, both about the truth of propositions and about the applicability of each production rule. <p> The two best-known attempts to develop representations of uncertainty as an extension of deterministic rule-based expert systems were the Mycin <ref> [12] </ref> and Prospector [36] projects. Mycin was designed to assist physicians in the diagnosis and treatment of bacterial infections. Mycin introduced the certainty-factor model. <p> In many cases, the inconsistencies and assumptions can lead to costly error [74, 62]. Buchanan and Shortliffe, the creators of the certainty-factor model, have warned against uncritical application of the certainty-factor calculus to other domains <ref> [12] </ref>. However, there has been relatively little discussion about the applicability of these warnings in the popularity of expert systems employing certainty factors (i.e., the widely used derivatives of the Emycin shell) and similar heuristic schemes. <p> Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine <ref> [136, 12, 143, 153, 112] </ref>. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [13] <author> B.G. Buchanan and E.H. Shortliffe. </author> <title> Uncertainty and evidential support. </title> <editor> In B.G. Buchanan and E.H. Shortliffe, editors, </editor> <title> Rule-Based Expert Systems: </title> <booktitle> The MYCIN Experiments of the Stanford Heuristic Programming Project, </booktitle> <pages> pages 209-232. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: Indeed, Mycin and Internist-1 perform at the expert level despite the identified inconsistencies. A formal study by Cooper and Clancey demonstrated that Mycin's performance was fairly insensitive to the precision of the numbers used for certainty factors <ref> [13] </ref>. This view is buttressed by the findings we mentioned, that the early probabilistic expert systems performed well (often better than human experts) despite their simplifying assumptions. It is dangerous, however, to generalize from these results.
Reference: [14] <author> D.M. Buede. </author> <title> Structuring value attributes. </title> <journal> Interfaces, </journal> <volume> 16 </volume> <pages> 52-62, </pages> <year> 1986. </year>
Reference-contexts: An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67].
Reference: [15] <author> A. Bundy. </author> <title> Incidence calculus: A mechanism for probabilistic reasoning. </title> <booktitle> In Proceedings of the Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <pages> pages 177-184. </pages> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <address> Mountain View, CA, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: We can use standard statistical techniques to estimate the error in the approximation from a given sample size, and we can reduce the uncertainty to an arbitrary degree by increasing the sample size. Bundy <ref> [15] </ref> suggested a Monte Carlo sampling approach for computing the probabilities of Boolean combinations of correlated logical variables, which he calls the incidence calculus. Henrion [63] developed an extension of this approach for inference in belief networks, termed probabilistic logic sampling.
Reference: [16] <author> N. Carrol. </author> <title> Expert systems for clinical diagnosis: Are they worth the effort? Behavioral Science, </title> <booktitle> 32 </booktitle> <pages> 274-292, </pages> <year> 1987. </year>
Reference-contexts: There also are fundamental mathematical reasons why simple linear models can be robust approximations to more complex, nonlinear relationships [29]. The relevance of these surprising results to research in expert systems and artificial intelligence has only recently been pointed out <ref> [54, 16] </ref>. Several preconditions for the applicability of the findings have been elucidated.
Reference: [17] <author> P. Cheeseman, J. Kelly, M. Self, and J. Stutz. </author> <title> Automatic Bayesian induction of classes. </title> <booktitle> In Proceedings of the NASA Artificial Intelligence Forum, </booktitle> <address> Palo Alto, CA, </address> <pages> pages 224-239. </pages> <institution> NASA-Ames Research Center, Mountain View, </institution> <address> CA, </address> <month> November </month> <year> 1987. </year> <note> REFERENCES 41 </note>
Reference-contexts: Cheeseman and associates have studied the automatic induction of a useful set of categories from data acquired by sensors on a wandering robot <ref> [17] </ref>. Pearl and Verma [116] described logical methods for reformulating belief networks to suggest plausible causal relationships to explain a set of probabilistic relationships. 6 Conclusions We have reviewed the application of concepts from decision science to AI research.
Reference: [18] <author> H.L. Chin and G.F. Cooper. </author> <title> Bayesian belief network inference using simulation. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 129-148. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: This method is linear in the number of nodes in the network, regardless of the degree of interconnectedness of cycles. Unfortunately, it is exponential in the number of pieces of evidence observed. Chin and Cooper <ref> [18] </ref> have used the logic-sampling approach to generate samples of medical cases for simulation purposes. They avoid the exponential complexity of the general problem by rearranging the direction of the links in the network using Shachter's algorithm, so that all observed variables are inputs (sources) to the network.
Reference: [19] <author> P.R. Cohen. </author> <title> Heuristic Reasoning About Uncertainty: An AI Approach. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: For example, fuzzy-set theory [160] rejects the property of clarity, allowing linguistic imprecision in the definition of propositions. Some AI researchers have also rejected scalar continuity, arguing that a single number is insufficiently rich to represent belief <ref> [19] </ref>. Dempster-Shafer theory [133] rejects completeness, denying that it is possible to assign a belief to every well-defined proposition.
Reference: [20] <author> L.S. Coles, A.M. Robb, P.L. Sinclair, M.H. Smith, and R.R. Sobek. </author> <title> Decision analysis for an experimental robot with unreliable sensors. </title> <booktitle> In Proceedings of the Fourth International Joint Conference on Artificial Intelligence, Georgia, USSR, </booktitle> <pages> pages 749-757. </pages> <booktitle> International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1975. </year>
Reference-contexts: Feldman and Sproull [40] showed how decision theory could be applied to control the application of planning operators in solving the monkey-and-bananas problem. Coles et al. <ref> [20] </ref> and Jacobs [84] used utility theory to evaluate alternative plans for robots immersed in an uncertain world. Langlotz et al. applied decision theory to ranking alternative cancer therapy plans within the Oncocin project [92].
Reference: [21] <author> G.F. Cooper. NESTOR: </author> <title> A Computer-based Medical Diagnostic Aid that Integrates Causal and Probabilistic Knowledge. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> CA, </address> <month> November </month> <year> 1984. </year> <type> Rep. </type> <note> No. STAN-CS-84-48. Also numbered HPP-84-48. </note>
Reference-contexts: The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114]. <p> That is, p (D 1 jE; ~) = p (D 2 j~)p (EjD 2 ; ~) Cooper <ref> [21] </ref> and Peng [118] describe branch-and-bound methods for searching through the space of possible diagnoses, which can identify the most probable diagnoses without examining all possible ones. <p> They sometimes allow us to identify the most probable n diagnoses in a set D without calculating over the total joint probability space. For example, the partial sum of p (D i j~)p (EjD i ; ~) gives a lower bound on p (Ej~). Cooper <ref> [21] </ref> showed how to use this approach to compute upper bounds for absolute posterior probabilities as well. He also gave a related method for computing lower bounds. Inference Within Influence Diagrams So far, we have focused on inference in belief networks. <p> Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [22] <author> G.F. Cooper. </author> <title> An algorithm for computing probabilistic propositions. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 3-14. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Nilsson's probabilistic logic [108] extends the idea of logical entailment to probabilistic domains. Within probabilistic logic, the probability of any sentence in first-order predicate calculus is determined. The probabilities assigned to arbitrary combinations of propositions are based on a logical analysis of alternative possible worlds. In related work, Cooper <ref> [22] </ref> developed an algorithm for calculating the probability of an arbitrary statement in propositional logic when a belief network is used as the representation of uncertainty. There also is ongoing work on the logical analysis of belief networks.
Reference: [23] <author> G.F. Cooper. </author> <title> Probabilistic inference using belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 393-405, </pages> <year> 1990. </year>
Reference-contexts: For example, in the approach of Lauritzen and Spiegelhalter, the joint distribution for each clique must be represented explicitly; thus, the algorithm is exponential in the size of the largest clique. That clique can be very large in a network with many intersecting loops. More generally, Cooper <ref> [23] </ref> has shown recently that the general problem of inference in a belief network is NP-hard, so we should not expect to find an exact method that is computationally efficient for arbitrary networks. Nevertheless, exact methods for the tractable solution of specific classes of belief networks may be possible.
Reference: [24] <author> G.F. Cooper, E.J. Horvitz, and D.E. Heckerman. </author> <title> A model for temporal probabilistic reasoning. </title> <type> Technical Report KSL-88-30, </type> <institution> Stanford University, Section on Medical Informatics, Stanford, California, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: There have been several research projects examining probabilistic approaches to temporal reasoning. Cooper, et al. <ref> [24] </ref> developed and implemented a model of probabilistic temporal reasoning that updates belief in competing hypotheses over time as events are observed. Within this work a set of temporal-locality and conditional-independence assumptions were studied.
Reference: [25] <author> R. Cox. </author> <title> Probability, frequency and reasonable expectation. </title> <journal> American Journal of Physics, </journal> <volume> 14 </volume> <pages> 1-13, </pages> <year> 1946. </year>
Reference-contexts: a "Dutch book"-that is, a combination of bets leading to guaranteed loss under any outcome [96, 134]. 2.2 Probability Is Sufficient for Representing Uncertainty A number of researchers have provided lists of fundamental properties that they consider intuitively desirable for continuous measures of belief in the truth of a proposition <ref> [25, 149, 100] </ref>. A recent reformulation of desirable properties of belief is [75]: 1 Several axiomatizations of probability theory have been proposed. 2 FOUNDATIONS 4 1. Clarity: Propositions should be well defined. 2. <p> Consistency : There will be equal belief in propositions that are logically equivalent. Cox and other researchers have demonstrated that, taken together, these properties logically imply that the measure of belief must satisfy the axioms of probability theory <ref> [25] </ref>. The proof of the necessary relationship between the intuitive properties and the axioms of probability theory is based on an analysis of solutions to the functional forms implied by the intuitive properties.
Reference: [26] <author> R. Davis. </author> <title> Meta-rules: Reasoning about control. </title> <journal> Artificial Intelligence, </journal> <volume> 15 </volume> <pages> 179-222, </pages> <year> 1980. </year>
Reference-contexts: The qualitative influence-diagram research centers on representing probabilistic dependencies qualitatively based on stochastic dominance. Decision theory also has been used for the control of inference. Most AI work on the control of inference has been based on heuristic control techniques <ref> [26, 38, 2] </ref>. Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies [48, 71].
Reference: [27] <author> R. Davis. </author> <title> Consultation, knowledge acquisition, and instruction. </title> <editor> In P. Szolovits, editor, </editor> <booktitle> Artificial Intelligence In Medicine, </booktitle> <pages> pages 57-78. </pages> <publisher> Westview Press, </publisher> <address> Boulder, CO, </address> <year> 1982. </year>
Reference-contexts: They suggest that the mismatch leads to problems both in encoding expertise and in explaining the results of probabilistic inference, so that users could understand and trust them <ref> [144, 27, 51] </ref>. One interesting lesson from the early research on probabilistic reasoning is the distinction between the performance and acceptability of diagnostic systems. In principle, it might seem that none of the objections we have listed should be insuperable in the face of superior diagnostic performance. <p> connected networks into a set of belief network subproblems and for reasoning about the application of combinations of alternative exact and approximate inference methods are promising areas of current investigation [72]. 4.4 Explanation in Decision-Theoretic Expert Systems A frequent criticism of decision-theoretic reasoning is that it is difficult to explain <ref> [144, 27, 119] </ref>. Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance.
Reference: [28] <author> R. Davis. </author> <title> Diagnosis via causal reasoning: Paths of interaction and the locality principle. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsruhe, West Germany, </address> <pages> pages 88-94. </pages> <booktitle> National Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1983. </year>
Reference-contexts: For example, the incoherence destroys the bidi-rectionality of probabilistic inference, obstructing the graceful integration of causal and diagnostic inference. 3.7 Problems with Modularity An often-cited advantage of the rule-based representation scheme is the ability to add or remove rules from a knowledge base without modifying other rules <ref> [28] </ref>. This property has been referred to as modularity. The modularity of rules in a logical production system is a consequence of the monotonicity of logic: Once asserted, the truth of a proposition cannot be changed by other facts.
Reference: [29] <author> R.M. Dawes and B. Corrigan. </author> <title> Linear models in decision making. </title> <journal> Psychological Bulletin, </journal> <volume> 81 </volume> <pages> 95-106, </pages> <year> 1974. </year>
Reference-contexts: more expressive representations of probabilistic dependencies. 3.3 Performance of the Early Probabilistic Systems How well did these early systems perform in terms of diagnostic accuracy? We note that the early probabilistic systems performed within their limited domains at a level comparable to experts, and sometimes at a considerably higher level <ref> [51, 30, 29] </ref>. For example, the system of de Dombal and his colleagues averaged over 90% correct diagnoses of acute abdominal pain, where expert physicians were averaging 65% 80% correct [30]. Patrick's diagnostic aid for chest pain reportedly averaged 80% accuracy, whereas clinicians averaged 51% [113]. <p> In fact, such good performance of simple models based on subjective parameters relative to unaided expert judgment is consistent with well-established experimental results from numerous studies <ref> [29] </ref>. Studies in a wide variety of domains of clinical and other expert judgment have found that simple linear models with subjectively assessed weights do as well as or better than experts. <p> One reason for these results seems to be that the simple formal models are more consistent and reliable than human experts, being less subject to whims, carelessness, or misguided inspiration. There also are fundamental mathematical reasons why simple linear models can be robust approximations to more complex, nonlinear relationships <ref> [29] </ref>. The relevance of these surprising results to research in expert systems and artificial intelligence has only recently been pointed out [54, 16]. Several preconditions for the applicability of the findings have been elucidated.
Reference: [30] <author> F.T. de Dombal, D.J. Leaper, J.C. Horrocks, J.R. Staniland, </author> <title> and A.P. McCain. Human and computer-aided diagnosis of abdominal pain: further report with emphasis on performance. </title> <journal> British Medical Journal, </journal> <volume> 1 </volume> <pages> 376-380, </pages> <year> 1974. </year> <note> REFERENCES 42 </note>
Reference-contexts: more expressive representations of probabilistic dependencies. 3.3 Performance of the Early Probabilistic Systems How well did these early systems perform in terms of diagnostic accuracy? We note that the early probabilistic systems performed within their limited domains at a level comparable to experts, and sometimes at a considerably higher level <ref> [51, 30, 29] </ref>. For example, the system of de Dombal and his colleagues averaged over 90% correct diagnoses of acute abdominal pain, where expert physicians were averaging 65% 80% correct [30]. Patrick's diagnostic aid for chest pain reportedly averaged 80% accuracy, whereas clinicians averaged 51% [113]. <p> For example, the system of de Dombal and his colleagues averaged over 90% correct diagnoses of acute abdominal pain, where expert physicians were averaging 65% 80% correct <ref> [30] </ref>. Patrick's diagnostic aid for chest pain reportedly averaged 80% accuracy, whereas clinicians averaged 51% [113]. These systems certainly qualify as expert systems according to our definition.
Reference: [31] <author> F.T. de Dombal, D.J. Leaper, J.R. Staniland, </author> <title> A.P. McCann, and J.C. Horrocks. Computer-aided diagnosis of acute abdominal pain. </title> <journal> British Medical Journal, </journal> <volume> 2 </volume> <pages> 9-13, </pages> <year> 1972. </year>
Reference-contexts: The simplicity of probabilistic systems based on these two assumptions made the approach popular. Several medical diagnostic systems have been constructed based on the simplified probabilistic scheme [145], including systems for the diagnosis of heart disease [154, 52], and of acute abdominal pain <ref> [31] </ref>. The popularity of the simplified probabilistic inference has led some people to believe that the assumptions are absolute requirements of probabilistic inference. It is a misconception, however, to regard this simplified Bayesian scheme as defining practical probabilistic inference.
Reference: [32] <author> B. de Finetti. </author> <title> Theory of Probability. </title> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Utility theory is based on a set of simple axioms or rules concerning choices under uncertainty. Like the axioms of probability theory, these rules are fairly intuitive. The reader is referred elsewhere for a detailed presentation of different versions of the axioms, their rationale, and implications <ref> [151, 129, 32, 41] </ref>. Here, we only try to give the axioms' flavor. The first set of axioms concerns preferences for outcomes under certainty. The axiom of or-derability asserts that all outcomes are comparable, even if described by many attributes.
Reference: [33] <author> J. de Kleer and B. Williams. </author> <title> Diagnosing multiple faults. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 97-130, </pages> <year> 1987. </year>
Reference-contexts: Much of the pioneering work in analytic expert systems has been done on medical applications, although, more recently, fault diagnosis in electronic components and mechanical devices has been examined <ref> [33, 45] </ref>. In general, three kinds of task are involved.
Reference: [34] <author> T.L. Dean and K. </author> <title> Kanazawa. Probabilistic temporal reasoning. </title> <type> Technical report, </type> <institution> Brown University, </institution> <month> May, </month> <year> 1988. </year>
Reference-contexts: Related research by de Zegher-Geets [35] has explored the use of prototypical temporal belief functions among symptoms and diseases for helping physicians to recognize changes in a patient's condition over time. Dean and Kanazawa <ref> [34] </ref> define a number of temporal predicates and show how functions representing the probability of specified states over time can be used in temporal reasoning.
Reference: [35] <author> I. deZegher Geets. Idefix: </author> <title> Intelligent summarization of a time-oriented medical database. </title> <type> Technical Report KSL-88-34, </type> <institution> Section on Medical Informatics, Stanford University, Stanford, California, </institution> <month> August </month> <year> 1987. </year>
Reference-contexts: Within this work a set of temporal-locality and conditional-independence assumptions were studied. Prototypical functions, representing knowledge about the temporal properties of propositions and about the temporal relationships among propositions considered in the model, are used for updating belief in competing hypotheses over time. Related research by de Zegher-Geets <ref> [35] </ref> has explored the use of prototypical temporal belief functions among symptoms and diseases for helping physicians to recognize changes in a patient's condition over time.
Reference: [36] <author> R. Duda, J. Gaschnig, and P. Hart. </author> <title> Model design in the PROSPECTOR consultant system for mineral exploration. </title> <editor> In D. Michie, editor, </editor> <booktitle> Expert Systems in the Microelectronic Age, </booktitle> <pages> pages 153-167. </pages> <publisher> Edinburg University Press, Edinburgh, </publisher> <address> Scotland, </address> <year> 1979. </year>
Reference-contexts: Dempster-Shafer theory [133] rejects completeness, denying that it is possible to assign a belief to every well-defined proposition. Most heuristic quantitative approaches to representing uncertainty used in AI, even when they use the term probability as in Prospector <ref> [36] </ref>, implicitly violate consistency. 2.3 The Direction of Probabilistic Inference Can Be Reversed Probability theory, and in particular Bayes' theorem, allows us to reverse the direction of inference. <p> The two best-known attempts to develop representations of uncertainty as an extension of deterministic rule-based expert systems were the Mycin [12] and Prospector <ref> [36] </ref> projects. Mycin was designed to assist physicians in the diagnosis and treatment of bacterial infections. Mycin introduced the certainty-factor model. The certainty factor (CF) is a number representing the degree of confirmation (between 0 and 1) or disconfirmation (between 0 and -1) of each proposition or rule.
Reference: [37] <author> C. Elsaesser. </author> <title> Explanation of probabilistic inference. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 387-400. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: The Pathfinder team examined the usefulness of creating qualitative explanations through mapping linguistic modifiers onto probability and utility considerations. A qualitative explanation from Pathfinder justifying an evidence-gathering recommendation is displayed at the bottom of Figure 4. Elsaesser employed a related approach for the qualitative explanation of Bayesian updating <ref> [37] </ref>.
Reference: [38] <author> L. Erman, F. Hayes-Roth, V.R Lesser, and D.R. Reddy. </author> <title> The HEARSAY-II speech understanding system: integrating knowledge to resolve uncertainty. </title> <journal> ACM Computing Surveys, </journal> <volume> 12 </volume> <pages> 213-253, </pages> <year> 1980. </year>
Reference-contexts: The qualitative influence-diagram research centers on representing probabilistic dependencies qualitatively based on stochastic dominance. Decision theory also has been used for the control of inference. Most AI work on the control of inference has been based on heuristic control techniques <ref> [26, 38, 2] </ref>. Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies [48, 71].
Reference: [39] <author> M.R. Fehling and J.S. Breese. </author> <title> A computational model for the decision-theoretic control of problem solving under uncertainty. </title> <type> Technical Report Rockwell Technical Report 837-88-5, </type> <institution> Rockwell International Science Center, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: Russell and Wefald [127] have examined the application of decision theory in search for game playing, building upon earlier work by Good [50]. Other recent research on decision-theoretic control, by Fehling and Breese, centers on the application of decision theory to a problem with robot planning <ref> [39] </ref>, considering the costs and benefits of alternative reasoning strategies to a robot decision maker. Several research projects have examined the representation of the semantics of probabilistic knowledge within predicate calculus. Nilsson's probabilistic logic [108] extends the idea of logical entailment to probabilistic domains.
Reference: [40] <editor> J.A. Feldman and R.F. Sproull. </editor> <booktitle> Decision theory and artificial intelligence ii: the hungry monkey. Cognitive Science, </booktitle> <volume> 1 </volume> <pages> 158-192, </pages> <year> 1975. </year>
Reference-contexts: The decision-theoretic paradigm has been used to define the valuation function and the important uncertainties in a problem, as well as to select the best sequence of actions. Feldman and Sproull <ref> [40] </ref> showed how decision theory could be applied to control the application of planning operators in solving the monkey-and-bananas problem. Coles et al. [20] and Jacobs [84] used utility theory to evaluate alternative plans for robots immersed in an uncertain world.
Reference: [41] <author> P.C. Fishburn. </author> <title> Subjective expected utility: A review of normative theories. </title> <journal> Theory and Decision, </journal> <volume> 13 </volume> <pages> 139-199, </pages> <year> 1981. </year>
Reference-contexts: Utility theory is based on a set of simple axioms or rules concerning choices under uncertainty. Like the axioms of probability theory, these rules are fairly intuitive. The reader is referred elsewhere for a detailed presentation of different versions of the axioms, their rationale, and implications <ref> [151, 129, 32, 41] </ref>. Here, we only try to give the axioms' flavor. The first set of axioms concerns preferences for outcomes under certainty. The axiom of or-derability asserts that all outcomes are comparable, even if described by many attributes.
Reference: [42] <author> A.M. Frisch and P. Haddawy. </author> <title> Probability as a modal operator. </title> <type> Technical report, </type> <institution> Computer Science Department, University of Illinois, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: Decision theory also can be applied to problems involving modal reasoning. Analogous to extensions of first-order predicate calculus to modal reasoning, probabilities can be used to describe the uncertain beliefs that one agent holds about another agent's beliefs <ref> [44, 42] </ref>. Decision analysis can be applied to communication and cooperation issues. Recent research has examined how an autonomous agent might be endowed with the ability to apply utility theory and probability theory to reason about the knowledge and potential behaviors of another agent [125].
Reference: [43] <author> D.G. Fryback. </author> <title> Bayes' theorem and conditional nonindependence of data in medical diagnosis. </title> <journal> Computers and Biomedical Research, </journal> <volume> 11 </volume> <pages> 423-434, </pages> <year> 1978. </year>
Reference-contexts: Fryback discovered that problems with assuming conditional independence can grow as the number of variables represented in a diagnostic model are increased; that is, the potential benefits of considering a larger number of variables can be overwhelmed by the proportional increases in the missing dependencies <ref> [43] </ref>. Problems with the use of an updating scheme making the strong conditional independence assumptions of the CF model were noted in early research on the Pathfinder expert system [76] for diagnosing tissue pathology.
Reference: [44] <author> H. Gaifman. </author> <title> A theory of higher order probabilities. </title> <booktitle> In Proceedings of the 1986 Conference of Theoretical Aspects of Reasoning About Knowledge, </booktitle> ??, <publisher> page ?? Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> ?? <year> 1986. </year> <note> REFERENCES 43 </note>
Reference-contexts: Decision theory also can be applied to problems involving modal reasoning. Analogous to extensions of first-order predicate calculus to modal reasoning, probabilities can be used to describe the uncertain beliefs that one agent holds about another agent's beliefs <ref> [44, 42] </ref>. Decision analysis can be applied to communication and cooperation issues. Recent research has examined how an autonomous agent might be endowed with the ability to apply utility theory and probability theory to reason about the knowledge and potential behaviors of another agent [125].
Reference: [45] <author> M. Genesereth. </author> <title> The use of design descriptions in automated diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 24 </volume> <pages> 311-319, </pages> <year> 1984. </year>
Reference-contexts: Much of the pioneering work in analytic expert systems has been done on medical applications, although, more recently, fault diagnosis in electronic components and mechanical devices has been examined <ref> [33, 45] </ref>. In general, three kinds of task are involved.
Reference: [46] <editor> M.L. Ginsberg. </editor> <booktitle> Readings in Nonmonotonic Logic. </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1987. </year>
Reference-contexts: As we mentioned in the second section of this article, analyses have been carried out in attempts to understand how alternative formalisms for reasoning under uncertainty-such as nonmonotonic reasoning <ref> [46] </ref>, fuzzy set theory [160], and Dempster-Shafer theory [133]-relate to probabilistic reasoning. See Kanal and Lemmer [86, 98] for some detailed analyses of these approaches. The application of influence diagrams in new areas is facilitated by their relatively unconstrained dependency structure at the level of relation.
Reference: [47] <author> I.J. </author> <title> Good. Probability and the Weighing of Evidence. </title> <address> Hafners, New York, </address> <year> 1950. </year>
Reference-contexts: The noisy-OR relationship allows the full conditional distribution to be derived from the individual probabilities of the evidence given each of the hypotheses and so requires only n parameters <ref> [47, 114] </ref>. The basis for this savings is straightforward. Suppose that p i is p (Ej only H i ; ~)-that is, the probability of E given that only H i occurs. <p> The naturalness of weights of evidence for acquiring and making inferences with uncertainty was first pointed out by Peirce in 1878 [117]. I.J. Good popularized the measure among philosophers of science and statisticians <ref> [47] </ref>. Several other researchers, including Turing [47] and Minsky and Selfridge [106], independently found this measure to be useful. The additive property of evidence weights is conducive to producing informative graphical displays that represent the weights as the length of graphical elements to be added or subtracted. <p> The naturalness of weights of evidence for acquiring and making inferences with uncertainty was first pointed out by Peirce in 1878 [117]. I.J. Good popularized the measure among philosophers of science and statisticians <ref> [47] </ref>. Several other researchers, including Turing [47] and Minsky and Selfridge [106], independently found this measure to be useful. The additive property of evidence weights is conducive to producing informative graphical displays that represent the weights as the length of graphical elements to be added or subtracted.
Reference: [48] <author> I.J. </author> <title> Good. Rational decisions. </title> <journal> J. R. Statist. Soc. B, </journal> <volume> 14 </volume> <pages> 107-114, </pages> <year> 1952. </year>
Reference-contexts: Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies <ref> [48, 71] </ref>. Smith [138] and Treitel and Genesereth [148] have applied decision theory to reasoning about the control of logical reasoning. Smith uses expected value notions to select among 5 DECISION-THEORETIC TECHNIQUES IN AI 36 search paths in database queries.
Reference: [49] <author> I.J. </author> <title> Good. Subjective probability as the measure of a non-measureable set. </title> <booktitle> In Logic, Methodology, and Philosophy of Science: Proceedings of the 1960 International Congress, </booktitle> <pages> pages 319-329. </pages> <publisher> Stanford University Press, </publisher> <year> 1962. </year> <title> Also in Good Thinking: The Foundations of Probability and Its Applications, I.J. Good, </title> <publisher> University of Minnesota Press, </publisher> <year> 1983. </year>
Reference-contexts: This discussion of probabilities brings up the issue of the completeness of probability assessment. There is always a tradeoff between assigning a probability based on a current state of understanding and expending additional effort in modeling and introspection to come up with a better estimate <ref> [49, 101] </ref>. And, in practice, the assessor of a probability often is uncertain and uncomfortable about the distribution he is providing. <p> Of course, the probability distribution that we would assess given additional time or effort is an uncertain quantity, and there is no fundamental barrier to using a probabilistic representation to represent this uncertainty (i.e., a second-order probability) <ref> [49, 60] </ref>. However, uncertainty about probabilities often masks the existence of other conditioning events for which the distribution is considered stable.
Reference: [50] <author> I.J. </author> <title> Good. Dynamic probability, computer chess, and the measurement of knowledge. In E.W. </title> <editor> Elcock and Michie D., editors, </editor> <booktitle> Machine Intelligence, </booktitle> <pages> pages 139-150. </pages> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: In this work, alternative reasoning strategies are evaluated through weighing their expected informational benefits with inference-related costs, such as the expense associated with delay. Russell and Wefald [127] have examined the application of decision theory in search for game playing, building upon earlier work by Good <ref> [50] </ref>. Other recent research on decision-theoretic control, by Fehling and Breese, centers on the application of decision theory to a problem with robot planning [39], considering the costs and benefits of alternative reasoning strategies to a robot decision maker.
Reference: [51] <author> G.A. Gorry. </author> <title> Computer-assisted clinical decision making. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 12 </volume> <pages> 45-51, </pages> <year> 1973. </year>
Reference-contexts: However, many AI researchers soon lost interest in decision theory. This disenchantment seems to have arisen, in part, from a perception that decision-theoretic approaches were hopelessly intractable and were inadequate for expressing the rich structure of human knowledge <ref> [51, 144] </ref>. <p> more expressive representations of probabilistic dependencies. 3.3 Performance of the Early Probabilistic Systems How well did these early systems perform in terms of diagnostic accuracy? We note that the early probabilistic systems performed within their limited domains at a level comparable to experts, and sometimes at a considerably higher level <ref> [51, 30, 29] </ref>. For example, the system of de Dombal and his colleagues averaged over 90% correct diagnoses of acute abdominal pain, where expert physicians were averaging 65% 80% correct [30]. Patrick's diagnostic aid for chest pain reportedly averaged 80% accuracy, whereas clinicians averaged 51% [113]. <p> They suggest that the mismatch leads to problems both in encoding expertise and in explaining the results of probabilistic inference, so that users could understand and trust them <ref> [144, 27, 51] </ref>. One interesting lesson from the early research on probabilistic reasoning is the distinction between the performance and acceptability of diagnostic systems. In principle, it might seem that none of the objections we have listed should be insuperable in the face of superior diagnostic performance.
Reference: [52] <author> G.A. Gorry and G.O. Barnett. </author> <title> Experience with a model of sequential diagnosis. </title> <journal> Computers and Biomedical Research, </journal> <volume> 1 </volume> <pages> 490-507, </pages> <year> 1968. </year>
Reference-contexts: The simplicity of probabilistic systems based on these two assumptions made the approach popular. Several medical diagnostic systems have been constructed based on the simplified probabilistic scheme [145], including systems for the diagnosis of heart disease <ref> [154, 52] </ref>, and of acute abdominal pain [31]. The popularity of the simplified probabilistic inference has led some people to believe that the assumptions are absolute requirements of probabilistic inference. It is a misconception, however, to regard this simplified Bayesian scheme as defining practical probabilistic inference.
Reference: [53] <author> B. Grosof. </author> <title> Nonmonotonic reasoning in probabilistic reasoning. </title> <editor> In J.F. Lemmer and L.N. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pages 237-250. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Probability theory assigns a continuous measure of belief and provides mechanisms for updating in light of new information. Several researchers are integrating these perspectives as a means of dealing with incomplete and changing information <ref> [102, 107, 53] </ref>. Decision theory also can be applied to problems involving modal reasoning. Analogous to extensions of first-order predicate calculus to modal reasoning, probabilities can be used to describe the uncertain beliefs that one agent holds about another agent's beliefs [44, 42].
Reference: [54] <author> K.R. Hammond. </author> <title> Towards a unified approach to the study of expert judgment. </title> <editor> In J.L. Mumpower, editor, </editor> <booktitle> Expert Judgment and Expert Systems, </booktitle> <pages> pages 1-16. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, </address> <year> 1987. </year>
Reference-contexts: There also are fundamental mathematical reasons why simple linear models can be robust approximations to more complex, nonlinear relationships [29]. The relevance of these surprising results to research in expert systems and artificial intelligence has only recently been pointed out <ref> [54, 16] </ref>. Several preconditions for the applicability of the findings have been elucidated.
Reference: [55] <author> D.E. Heckerman. </author> <title> Probabilistic interpretations for MYCIN's certainty factors. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 167-196. </pages> <address> North Hol-land, New York, </address> <year> 1986. </year>
Reference-contexts: Now let us apply these ideas in the probabilistic framework. A well-known form of probabilistic update is the likelihood ratio. Heckerman has shown that any probabilistic belief update must be some monotonic transformation of the likelihood ratio <ref> [55] </ref>. If we divide Bayes' theorem for hypothesis H , evidence E, and background evidence ~ by Bayes' theorem for the negation of the hypothesis, :H , we get p (HjE; ~) = p (Ej:H; ~)p (:H j~) This is called the odds-likelihood form of Bayes' theorem.
Reference: [56] <author> D.E. Heckerman. </author> <title> Formalizing heuristic methods for reasoning with uncertainty. </title> <type> Technical Report KSL-88-07, </type> <institution> Medical Computer Science Group, Section on Medical Informatics, Stanford University, Stanford, </institution> <address> CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: The assumption of conditional independence by modular schemes based on the likelihood ratio defines only one set of such assumptions. It is possible to have modular combination functions that dictate more complex default assumptions about patterns of dependency. This is a current area of investigation <ref> [56] </ref>. In summary, like the early probabilistic systems, the popular rule-based method imposes strong restrictions on the kinds of dependence that can be represented effectively. Unlike the explicit assumptions of the simplified probabilistic systems, the restrictive assumptions in the heuristic approaches have been less apparent. <p> We mentioned earlier that there has been recent work on the use of functions that specify patterns of independence. Recently, investigators have suggested methods for streamlining the probability assessment task, by specifying such prototypical functions for the probability distributions <ref> [56, 64, 114] </ref>. One example of a prototypical independence structure is termed the noisy OR-gate. We review this structure as an example of the assessment savings that may be gained through identifying and representing analogous patterns of independence. The noisy-OR structure is a probabilistic generalization of a standard Boolean OR. <p> One means of identifying and assessing conditional probabilities in a perspicuous fashion is an attention-focusing representation called similarity networks <ref> [56] </ref>. A similarity network helps a knowledge engineer to identify sets of evidence that can disambiguate between pairs of hypotheses. The graphical display of these relationships indicates constraints on the conditional probability 4 CURRENT RESEARCH 26 relationships between hypotheses and evidence. <p> There are many unanswered questions regarding the automated assembling, pruning, and reasoning about decision models. There is potential to develop tools for assisting engineers with the construction of influence diagrams in the spirit of recent work by Heckerman on the efficient representation of alternative classes of independence among propositions <ref> [56] </ref>. There have been several research projects examining probabilistic approaches to temporal reasoning. Cooper, et al. [24] developed and implemented a model of probabilistic temporal reasoning that updates belief in competing hypotheses over time as events are observed. Within this work a set of temporal-locality and conditional-independence assumptions were studied. <p> Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [57] <author> D.E. Heckerman. </author> <title> An axiomatic framework for belief updates. </title> <editor> In J.F. Lemmer and L.N. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pages 11-22. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: It has become apparent that the traditional assumption of modularity in rule-based approaches for reasoning under uncertainty has restrictive implications that had not been previously appreciated. To explain this, we must define modularity more precisely in terms of procedures for updating belief in hypotheses <ref> [74, 57] </ref>. First we define the notion of a belief update. Suppose B (H; ~) denotes a scalar degree of belief in hypothesis H given some specific background evidence ~.
Reference: [58] <author> D.E. Heckerman. </author> <title> An empirical comparison of three inference methods. </title> <editor> In R. Shachter T.S. Levitt, J. Lemmer, and L.N. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 4. </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1990. </year> <note> REFERENCES 44 </note>
Reference-contexts: Because it makes decisions without any explicit reference to priors or prevalence rates, it is, in effect, treating all infections as having equal prior probabilities. 3 The Internist-1 and QMR systems make similar assumptions <ref> [58] </ref>. The equal-priors assumption is valid in contexts where diagnoses are believed to be equally likely and in contexts where no information is available about the prior probabilities. Prior beliefs, at some level of precision, frequently are available. <p> Moving to a simplified probabilistic combination scheme, assuming conditional independence of evidence given hypotheses, yielded significant increases in diagnostic performance. The increased performance has been quantified with an evaluation scheme incorporating decision-theoretic and ad hoc measures <ref> [58] </ref>. Wise experimentally compared the performance of six common uncertain inference schemes for small rule sets and found that differences in performance between heuristic and probabilistic schemes depend heavily on the situation [159]. As we might expect, when there was strong evidence in one direction, most schemes performed well.
Reference: [59] <author> D.E. Heckerman and E.J. Horvitz. </author> <title> On the expressiveness of rule-based systems for reasoning under uncertainty. </title> <booktitle> In Proceedings AAAI-87 Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 121-126. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: However, analysis of modularity has demonstrated that uncertain beliefs are intrinsically less modular than beliefs held with certainty, frequently making the rule-based calculi inefficient for reasoning with uncertainty <ref> [59] </ref>. It has become apparent that the traditional assumption of modularity in rule-based approaches for reasoning under uncertainty has restrictive implications that had not been previously appreciated. To explain this, we must define modularity more precisely in terms of procedures for updating belief in hypotheses [74, 57].
Reference: [60] <author> D.E. Heckerman and H. Jimison. </author> <title> A perspective on confidence and its use in focusing attention during knowledge acquisition. </title> <editor> In L. Kanal, T. Levitt, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 123-131. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Of course, the probability distribution that we would assess given additional time or effort is an uncertain quantity, and there is no fundamental barrier to using a probabilistic representation to represent this uncertainty (i.e., a second-order probability) <ref> [49, 60] </ref>. However, uncertainty about probabilities often masks the existence of other conditioning events for which the distribution is considered stable.
Reference: [61] <author> M. Henrion. </author> <title> The Value of Knowing How Little You Know: The advantages of a probabilistic treatment of uncertainty in policy analysis. </title> <type> PhD thesis, </type> <institution> Department of Engineering and Public Policy, Carnegie Mellon University, </institution> <year> 1982. </year>
Reference-contexts: Since the 4 CURRENT RESEARCH 27 probabilistic representation of a variable exacts costs in elicitation, representation, and inference, it is desirable to include only those uncertainties that matter. Henrion introduces the (expected value of including uncertainty) (EVIU) as a sensitivity measure of the importance of uncertainty <ref> [61] </ref>. To date, few people have investigated the automation of sensitivity analysis for probabilistic reasoning. A promising area in this regard is error analysis, the notion of determining the extent to which errors in inputs and assumptions, such as assessed probabilities, affect ultimate conclusions in decision-theoretic models [62].
Reference: [62] <author> M. Henrion. </author> <title> Uncertainty in artificial intelligence: Is probability epistemologically and heuristically adequate? In J.L. Mumpower, editor, </title> <journal> Expert Judgment and Expert Systems, </journal> <pages> pages 105-130. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, </address> <year> 1987. </year>
Reference-contexts: Modular evidence combination and belief updating schemes must make some default assumptions about dependency among pieces of evidence updating the same hypothesis. Henrion has demonstrated that any rule-based scheme for uncertain inference with local updating must make some general assumption about dependence among these convergent lines of evidence <ref> [62] </ref>. The assumption of conditional independence by modular schemes based on the likelihood ratio defines only one set of such assumptions. It is possible to have modular combination functions that dictate more complex default assumptions about patterns of dependency. This is a current area of investigation [56]. <p> Careful examination of the results of a comparison of CFs with probabilistic inference presented in the original paper on CFs [135] shows that, on average, the CF-based system underresponded to the diagnosticity of the data by a factor of two <ref> [159, 62] </ref>. In 25% of the cases, it actually responded to the wrong direction, interpreting evidence that overall supported a conclusion to be disconfirming, or vice versa. <p> The sensitivity of a system's performance to inconsistency, to assumptions of modularity, or to the use of inaccurate measures of belief will depend to a great extent on the task. In many cases, the inconsistencies and assumptions can lead to costly error <ref> [74, 62] </ref>. Buchanan and Shortliffe, the creators of the certainty-factor model, have warned against uncritical application of the certainty-factor calculus to other domains [12]. <p> To date, few people have investigated the automation of sensitivity analysis for probabilistic reasoning. A promising area in this regard is error analysis, the notion of determining the extent to which errors in inputs and assumptions, such as assessed probabilities, affect ultimate conclusions in decision-theoretic models <ref> [62] </ref>. Note that sensitivity is defined with respect to values and decisions and provides insight about the important components of a model.
Reference: [63] <author> M. Henrion. </author> <title> Propagation of uncertainty by probabilistic logic sampling in Bayes' networks. </title> <editor> In J.F. Lemmer and L.N. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pages 149-164. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Bundy [15] suggested a Monte Carlo sampling approach for computing the probabilities of Boolean combinations of correlated logical variables, which he calls the incidence calculus. Henrion <ref> [63] </ref> developed an extension of this approach for inference in belief networks, termed probabilistic logic sampling. In this approach, a belief network is approximately represented by a sample of deterministic cases.
Reference: [64] <author> M. Henrion. </author> <title> Some practical issues in constructing belief networks. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 161-174. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: We mentioned earlier that there has been recent work on the use of functions that specify patterns of independence. Recently, investigators have suggested methods for streamlining the probability assessment task, by specifying such prototypical functions for the probability distributions <ref> [56, 64, 114] </ref>. One example of a prototypical independence structure is termed the noisy OR-gate. We review this structure as an example of the assessment savings that may be gained through identifying and representing analogous patterns of independence. The noisy-OR structure is a probabilistic generalization of a standard Boolean OR.
Reference: [65] <author> M. Henrion and D.R. Cooley. </author> <title> An experimental comparison of knowedge engineering for expert systems and for decision analysis. </title> <booktitle> In Proceedings AAAI-87 Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 471-476. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: The diagram itself, therefore, is an important tool in knowledge engineering, as well as in computation. In most current applications of influence diagrams and belief networks in expert systems, the model is constructed as part of the knowledge engineering process and is then is used during consultation <ref> [65, 5, 76] </ref>. We expect that, over time, additional components of knowledge engineering decision-theoretic systems will be automated. In the remainder of this section, we briefly review some of the fundamental issues in engineering decision-theoretic systems. <p> A new alternative often is worth more than extensive reasoning and analysis. The generation of new alternatives is a synthetic activity focusing on constructing actions or sequences of actions that achieve certain goals. Little research has been done on the knowledge-based generation of decision alternatives. 6 See <ref> [65] </ref> for an experimental comparison of rule-based and decision-analytic paradigms for knowledge engineering. 4 CURRENT RESEARCH 24 There has been work on the problem of dealing with the explosion of decision sequences that occurs when a series of decisions is possible and each decision has several alternatives. <p> Qualititative Explanation Determining the most important rationale for a recommendation allows a system to present an explanation qualitatively. Researchers have suggested that, as people may primarily use qualitative mental representations, it is useful to translate explanations of quantitative reasoning-for example, of decision-analytic models-into more qualitative descriptions <ref> [65] </ref>. Several projects have used this approach. Langlotz and associates [93] constructed a system called QXQ that explains medical decision analysis problems qualitatively. The system identifies the most important factors affecting a decision and applies a set of explanation heuristics. <p> Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [66] <author> M.C. Higgins. </author> <title> NAIVE: A method for representing uncertainty and temporal relationships in an automated reasoner. </title> <booktitle> In Proceedings of Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 140-147. </pages> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <address> Mountain View, CA, </address> <year> 1987. </year>
Reference-contexts: Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [67] <author> S. Holtzman. </author> <title> Intelligent Decision Systems. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1985. </year>
Reference-contexts: Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling <ref> [155, 67] </ref>. Encoding Probabilities One of the central tasks in engineering a decision-theoretic system is that of assessing probabilities. A frequent concern is the availability of probabilities as well as the numbers of probabilities that may be required. <p> Therefore, there is a tradeoff between the benefits of complete, detailed models and those of simplified, more computable models. In decision-theoretic knowledge engineering, we refer to the process of alternately expanding or contracting the model as completeness modulation <ref> [72, 67] </ref>. An attempt is made to produce a model that includes those variables that are most important to a particular set of decisions, in terms of having major influence on the recommendations developed by the model. <p> At the foundations of any decision model are decisions about the propositions to include within the decision basis, which often are based on logical relationships. Several researchers have examined the automated construction of decision models <ref> [67, 11, 156] </ref>. There are many unanswered questions regarding the automated assembling, pruning, and reasoning about decision models. <p> Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [68] <author> S. Holtzman and J.S. Breese. </author> <title> Exact reasoning about uncertainty: On the design of expert systems for decision support. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 339-345. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: typically uses rule-based or object-based representations, typically coupling them with some type of deductive inference method, whereas the decision analyst constructs influence diagrams or decision trees for use with decision-theoretic inference methods. 6 The core of decision-analytic knowledge engineering is the construction of an informative, credible, and computable decision basis <ref> [68, 10] </ref>. As we have seen, influence diagrams reduce the complexity of assessing influences by allowing explicit graphical representation of dependencies and independencies. The diagram itself, therefore, is an important tool in knowledge engineering, as well as in computation.
Reference: [69] <author> E.J. Horvitz. </author> <title> Toward a science of expert systems. </title> <booktitle> Proceedings of the 18th Symposium on the Interface of Computer Science and Statistics, </booktitle> <pages> pages 45-52, </pages> <month> March </month> <year> 1986. </year> <note> REFERENCES 45 </note>
Reference-contexts: a "suboptimal" default or approximate strategy could be preferred to a complete decision-theoretic analysis given the cost of reasoning, and the importance of techniques for gracefully degrading the value of a system's performance from a complete analysis to an approximate one as the costs of representation or reasoning resources increase <ref> [69] </ref>. As we mentioned in the second section of this article, analyses have been carried out in attempts to understand how alternative formalisms for reasoning under uncertainty-such as nonmonotonic reasoning [46], fuzzy set theory [160], and Dempster-Shafer theory [133]-relate to probabilistic reasoning.
Reference: [70] <author> E.J. Horvitz. </author> <title> A multiattribute utility approach to inference understandability and explanation. </title> <type> Technical Report KSL-28-87, </type> <institution> Medical Computer Science Group, Section on Medical Informatics, Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: Related research on the naturalness of alternative grouping schemes has been conducted by Ben-Bassat and Teeni [6]. Researchers also have investigated the application of decision theory at the metalevel to control the construction of explanations of decision-theoretic inference and of mathematical modeling <ref> [70, 104] </ref>. The research has studied the explicit metareasoning about the costs, benefits, and tradeoffs associated with alternative explanations and with the understandability of alternative reasoning methods.
Reference: [71] <author> E.J. Horvitz. </author> <title> Problem-solving design: Reasoning about computational value, tradeoffs, and resources. </title> <booktitle> In Proceedings of the NASA Artificial Intelligence Forum, </booktitle> <address> Palo Alto, CA, </address> <pages> pages 26-43. </pages> <institution> NASA-Ames Research Center, Mountain View, </institution> <address> CA, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies <ref> [48, 71] </ref>. Smith [138] and Treitel and Genesereth [148] have applied decision theory to reasoning about the control of logical reasoning. Smith uses expected value notions to select among 5 DECISION-THEORETIC TECHNIQUES IN AI 36 search paths in database queries.
Reference: [72] <author> E.J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proceedings of Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 429-444, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1987. </year> <journal> American Association for Artificial Intelligence. </journal> <note> To appear in L. </note> <editor> Kanal, T. Levitt, and J. Lemmer, ed., </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <publisher> Elsevier, 1988 (in press). </publisher>
Reference-contexts: Therefore, there is a tradeoff between the benefits of complete, detailed models and those of simplified, more computable models. In decision-theoretic knowledge engineering, we refer to the process of alternately expanding or contracting the model as completeness modulation <ref> [72, 67] </ref>. An attempt is made to produce a model that includes those variables that are most important to a particular set of decisions, in terms of having major influence on the recommendations developed by the model. <p> The development of automated algorithms employing this approach is an interesting area for research. Also, methods for decomposing multiply connected networks into a set of belief network subproblems and for reasoning about the application of combinations of alternative exact and approximate inference methods are promising areas of current investigation <ref> [72] </ref>. 4.4 Explanation in Decision-Theoretic Expert Systems A frequent criticism of decision-theoretic reasoning is that it is difficult to explain [144, 27, 119]. Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance.
Reference: [73] <author> E.J. Horvitz. </author> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proceedings of AAAI-88, Seventh National Conference on Artificial Intelligence, </booktitle> <address> Minneapolis, MN, </address> <pages> pages 111-116. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Smith uses expected value notions to select among 5 DECISION-THEORETIC TECHNIQUES IN AI 36 search paths in database queries. Treitel has explored the costs associated with alternative sequen-tialization strategies in logical theorem proving. Horvitz <ref> [73] </ref> has investigated issues surrounding the use of decision theory to control several computational tasks including decision-theoretic inference itself. In this work, alternative reasoning strategies are evaluated through weighing their expected informational benefits with inference-related costs, such as the expense associated with delay.
Reference: [74] <author> E.J. Horvitz and D.E. Heckerman. </author> <title> The inconsistent use of measures of certainty in artificial intelligence research. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 137-151. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Thus, contrary to most popular interpretations, the CF originally was intended to represent an update or change in belief induced by the evidence, not an absolute degree of belief (such as a probability) <ref> [74] </ref>. It therefore does not explicitly represent the prior or posterior degree of belief in each hypothesis. By representing only updates rather than absolute degrees of belief, it appears to avoid the need for priors. <p> It has become apparent that the traditional assumption of modularity in rule-based approaches for reasoning under uncertainty has restrictive implications that had not been previously appreciated. To explain this, we must define modularity more precisely in terms of procedures for updating belief in hypotheses <ref> [74, 57] </ref>. First we define the notion of a belief update. Suppose B (H; ~) denotes a scalar degree of belief in hypothesis H given some specific background evidence ~. <p> Capturing the effects of arbitrary dependencies in a modular scheme generally requires information that is unavailable to a local combination function. Attempting to generate behavior consistent with complex dependency within a modular updating scheme is an unreasonable pursuit of "something for nothing" behavior <ref> [74] </ref>. Thus, we cannot capture information about arbitrary dependencies with simple scalar functions. Modular evidence combination and belief updating schemes must make some default assumptions about dependency among pieces of evidence updating the same hypothesis. <p> The sensitivity of a system's performance to inconsistency, to assumptions of modularity, or to the use of inaccurate measures of belief will depend to a great extent on the task. In many cases, the inconsistencies and assumptions can lead to costly error <ref> [74, 62] </ref>. Buchanan and Shortliffe, the creators of the certainty-factor model, have warned against uncritical application of the certainty-factor calculus to other domains [12].
Reference: [75] <author> E.J. Horvitz, D.E. Heckerman, </author> <title> and C.P. Langlotz. A framework for comparing alternative formalisms for plausible reasoning. </title> <booktitle> In Proceedings AAAI-86 Fifth National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <pages> pages 210-214. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: A recent reformulation of desirable properties of belief is <ref> [75] </ref>: 1 Several axiomatizations of probability theory have been proposed. 2 FOUNDATIONS 4 1. Clarity: Propositions should be well defined. 2. Scalar continuity: A single real number is both necessary and sufficient for representing a degree of belief in a proposition. 3. <p> Thus, according to Cox's proof, if one accepts these intuitive properties as desirable, one must accept probabilities as a desirable measure of belief. These principles provide a useful framework for comparing alternative formalisms for representing uncertainty, in terms of which of the principles the formalisms reject <ref> [75] </ref>. For example, fuzzy-set theory [160] rejects the property of clarity, allowing linguistic imprecision in the definition of propositions. Some AI researchers have also rejected scalar continuity, arguing that a single number is insufficiently rich to represent belief [19].
Reference: [76] <author> E.J. Horvitz, D.E. Heckerman, B.N. Nathwani, and L.M. Fagan. </author> <title> Diagnostic strategies in the hypothesis-directed Pathfinder system. </title> <booktitle> In Proceedings of the First Conference on Artificial Intelligence Applications, </booktitle> <address> Denver, </address> <publisher> CO, </publisher> <pages> pages 630-636. </pages> <publisher> IEEE, </publisher> <address> Silver Springs, MD, </address> <month> December </month> <year> 1984. </year>
Reference-contexts: Problems with the use of an updating scheme making the strong conditional independence assumptions of the CF model were noted in early research on the Pathfinder expert system <ref> [76] </ref> for diagnosing tissue pathology. Moving to a simplified probabilistic combination scheme, assuming conditional independence of evidence given hypotheses, yielded significant increases in diagnostic performance. The increased performance has been quantified with an evaluation scheme incorporating decision-theoretic and ad hoc measures [58]. <p> The diagram itself, therefore, is an important tool in knowledge engineering, as well as in computation. In most current applications of influence diagrams and belief networks in expert systems, the model is constructed as part of the knowledge engineering process and is then is used during consultation <ref> [65, 5, 76] </ref>. We expect that, over time, additional components of knowledge engineering decision-theoretic systems will be automated. In the remainder of this section, we briefly review some of the fundamental issues in engineering decision-theoretic systems. <p> Sequences of likelihood ratios are used to explain how evidence affects belief in competing hypotheses in the Glasgow-Dyspepsia expert system for assisting in gastroenterology diagnosis [140], in the Pathfinder system for reasoning about tissue pathology <ref> [76] </ref>, in the Neurex system for diagnosis of neurological findings [124], and in the Medas system for assisting physicians in emergency medicine [5]. Likelihood ratios and weights of evidence also have been optionally converted from graphical to qualitative text descriptions in the Pathfinder and Medas projects. <p> Although recent research on the application of decision-science ideas in expert systems seems promising <ref> [1, 3, 9, 21, 56, 65, 66, 67, 76] </ref>, for the most part, only prototype systems have been demonstrated to date. There is urgent need for further research on the sensitivity of various inference schemes to seemingly unrealistic assumptions.
Reference: [77] <author> E.J. Horvitz, D.E. Heckerman, B.N. Nathwani, and L.M. Fagan. </author> <title> The use of a heuristic problem-solving hierarchy to facilitate the explanation of hypothesis-directed reasoning. </title> <booktitle> In Proceedings of Medinfo, </booktitle> <address> Washington, DC, </address> <pages> pages 27-31. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <month> October </month> <year> 1986. </year>
Reference-contexts: A component of explanation research within the Pathfinder project studied the simplification of probabilistic inference through using heuristic abstraction hierarchies to control reasoning. The hierarchies are used to classify diseases into a set of disease groups that depends on the diagnostic problem at hand <ref> [77] </ref>. Related research on the naturalness of alternative grouping schemes has been conducted by Ben-Bassat and Teeni [6]. Researchers also have investigated the application of decision theory at the metalevel to control the construction of explanations of decision-theoretic inference and of mathematical modeling [70, 104].
Reference: [78] <author> R.A. Howard. </author> <title> Decision analysis: Applied decision theory. In D.B. </title> <editor> Hertz and J. Melese, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Operational Research, </booktitle> <pages> pages 55-71. </pages> <publisher> Wiley-Interscience, </publisher> <year> 1966. </year>
Reference-contexts: The discipline of decision analysis emerged in the 1960s; it grew out of a recognition that probability and decision theory, hitherto applied primarily to problems of statistical estimation [129, 122], also could be applied to real-world decision problems <ref> [78, 120] </ref>. Since its inception, decision analysis has grown into an established academic and professional discipline [83, 152, 88]. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients.
Reference: [79] <author> R.A. Howard. </author> <title> The foundations of decision analysis. </title> <journal> IEEE Transactions on Systems Science, and Cybernetics, </journal> <volume> 4 </volume> <pages> 211-219, </pages> <year> 1968. </year> <note> REFERENCES 46 </note>
Reference-contexts: Typically, this information is used to limit effort on construction and refinement of the model. There are several classes of sensitivity analysis that are appropriate at various junctures in the process of building a decision model <ref> [79, 81] </ref>. Sensitivity to risk tolerance, discretization, and uncertainty are routinely performed as part of a professional decision analysis. Since the 4 CURRENT RESEARCH 27 probabilistic representation of a variable exacts costs in elicitation, representation, and inference, it is desirable to include only those uncertainties that matter.
Reference: [80] <author> R.A. Howard. </author> <title> Risk preference. </title> <editor> In R.A. Howard and J.E. Matheson, editors, </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis, volume II, chapter 34,, </booktitle> <pages> pages 629-663. </pages> <institution> Strategic Decisions Group, </institution> <address> Menlo Park, Ca., </address> <year> 1970. </year>
Reference-contexts: Risk aversion is exhibited by many people, when they prefer to receive a monetary prize for certain over a lottery with an identical expected value. Decision theory provides various techniques for eliciting and encoding different attitudes toward risk for supporting decision making under uncertainty <ref> [80] </ref>. <p> An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67].
Reference: [81] <author> R.A. Howard. </author> <title> Proximal decision analysis. </title> <journal> Management Science, </journal> <volume> 17, </volume> <year> 1971. </year>
Reference-contexts: Typically, this information is used to limit effort on construction and refinement of the model. There are several classes of sensitivity analysis that are appropriate at various junctures in the process of building a decision model <ref> [79, 81] </ref>. Sensitivity to risk tolerance, discretization, and uncertainty are routinely performed as part of a professional decision analysis. Since the 4 CURRENT RESEARCH 27 probabilistic representation of a variable exacts costs in elicitation, representation, and inference, it is desirable to include only those uncertainties that matter.
Reference: [82] <author> R.A. Howard and J.E. Matheson. </author> <title> Influence diagrams. </title> <editor> In R.A. Howard and J.E. Matheson, editors, </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis, </booktitle> <volume> volume II, </volume> <pages> pages 721-762. </pages> <institution> Strategic Decisions Group, </institution> <address> Menlo Park, CA, </address> <year> 1981. </year>
Reference-contexts: Influence diagrams and belief networks were designed with precisely these objectives in mind. Influence Diagrams and Belief Networks The influence diagram is a graphical knowledge-representation language that represents the decision basis <ref> [82, 111, 110] </ref>. The influence diagram is an acyclic directed graph containing nodes representing propositions or quantities of interest (i.e., alternatives, states) and arcs representing interactions between the nodes. Nodes representing propositions are associated with a set of mutually exclusive and exhaustive values that represent alternative possible states. <p> The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114]. <p> We use belief networks, as this term is the most popular. Three Levels of Representation The expressiveness and sufficiency of influence diagrams is based in the representation's three levels of specification: relation, function, and number <ref> [82] </ref>. We can express relations at one level without explicitly referring to more specific levels. The relation level captures the qualitative structure of the problem as expressed in the topology of the network. At this level, the arcs and nodes describe dependencies between the values of propositions or variables (nodes).
Reference: [83] <editor> R.A. Howard and J.E. Matheson, editors. </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis. Strategic Decisions Group, </booktitle> <address> Menlo Park, Ca., </address> <year> 1984. </year>
Reference-contexts: Since its inception, decision analysis has grown into an established academic and professional discipline <ref> [83, 152, 88] </ref>. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients. Some large corporations routinely apply decision analysis to scheduling, capital expansion, and research and development decisions. <p> We present various classes of inference techniques that use these representations for propagating evidence and finding optimal decisions. Finally, we review research on explaining the results of decision-theoretic inference. 4.1 Knowledge Representation for Decision-Theoretic Problems Howard has called the complete model of a decision problem the decision basis <ref> [83] </ref>. A comprehensive decision basis consists of components that represent the alternatives, states, preferences, and relationships in a decision situation. Decisions are the alternative courses of action available to the decision maker.
Reference: [84] <author> W. Jacobs and M. Keifer. </author> <title> Robot decisions based on maximizing utility. </title> <booktitle> In Proceedings of the Third International Joint Conference on Artificial Intelligence, </booktitle> ??, <pages> pages 402-411. </pages> <booktitle> International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1973. </year>
Reference-contexts: Feldman and Sproull [40] showed how decision theory could be applied to control the application of planning operators in solving the monkey-and-bananas problem. Coles et al. [20] and Jacobs <ref> [84] </ref> used utility theory to evaluate alternative plans for robots immersed in an uncertain world. Langlotz et al. applied decision theory to ranking alternative cancer therapy plans within the Oncocin project [92].
Reference: [85] <author> D. Kahneman, P. Slovic, and A. Tversky, </author> <title> editors. Judgment Under Uncertainty: Heuristics and Biases. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Indeed, studies have demonstrated that people frequently do not behave in accordance with decision theory <ref> [85] </ref>. <p> Other heuristic systems that explicitly incorporate prior probabilities have difficulties due to incoherence among the probabilities. For example, Prospector uses probabilities to represent prior 3 The handling of priors in the CF model is consistent with studies of how people reason under uncertainty <ref> [85] </ref> that show people tend to ignore priors. 3 EARLY RESEARCH ON EXPERT SYSTEMS 14 degrees of belief in its hypotheses and in its evidential variables. <p> Nonetheless, expressing human knowledge in terms of probabilities is a demanding task. Researchers of human judgment under uncertainty have identified a set of biases and heuristics that tend to distort human decision making and judgments about uncertain events <ref> [85] </ref>. Such biases tend to narrow or skew assessed probability distributions, and interviewing methods emphasize making implicit assumptions explicit and encouraging the subject to consider a full range of information and possibilities.
Reference: [86] <editor> L.N. Kanal and J.F. Lemmer, editors. </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: In recent years, decision-theory has been applied to a number of problems in AI, including planning, control of inference, perception, learning, problem formulation, temporal reasoning, and nonmonotonic reasoning. We review briefly aspects of these research topics. More comprehensive discussions are found in <ref> [86, 98] </ref>. 5.2 Recent Research The earliest and most prominent applications of decision theory in AI were in planning research, much of which centers on the construction of sequences of actions that will achieve a set of goals. <p> As we mentioned in the second section of this article, analyses have been carried out in attempts to understand how alternative formalisms for reasoning under uncertainty-such as nonmonotonic reasoning [46], fuzzy set theory [160], and Dempster-Shafer theory [133]-relate to probabilistic reasoning. See Kanal and Lemmer <ref> [86, 98] </ref> for some detailed analyses of these approaches. The application of influence diagrams in new areas is facilitated by their relatively unconstrained dependency structure at the level of relation. As an example, machine-vision researchers have applied probabilistic inference to perceptual tasks.
Reference: [87] <author> R.L. Keeney. </author> <title> The art of assessing multi-attribute utility functions. Organizational Behavior and Human Performance, </title> <booktitle> 19 </booktitle> <pages> 267-310, </pages> <year> 1977. </year>
Reference-contexts: An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67].
Reference: [88] <author> R.L. Keeney and H. Raiffa. </author> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Since its inception, decision analysis has grown into an established academic and professional discipline <ref> [83, 152, 88] </ref>. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients. Some large corporations routinely apply decision analysis to scheduling, capital expansion, and research and development decisions. <p> Value Structuring and Preference Encoding AI investigators, to date, have placed little emphasis on the preferences or desires of decision makers or reasoning agents. Decision theorists have been studying preference in a subfield of decision analysis that emphasizes multiattribute decision problems <ref> [152, 88] </ref>. A decision-theoretic analysis is driven in large part by the attributes that are important to the decision maker (life duration, life quality, and monetary cost in the heart surgery example) and by the manner in which these attributes are combined in assigning value to alternative outcomes. <p> Von Winterfeldt [152] and Keeney <ref> [88] </ref> present numerous theoretical results on multiattribute value issues and discuss elicitation procedures for assessing the complex preference structures in terms of individual attributes. An additional important component of preference is the encoding of the decision maker's attitude toward risk. <p> An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67].
Reference: [89] <author> J.H. Kim and J. Pearl. </author> <title> A computational model for causal and diagnostic reasoning in inference engines. </title> <booktitle> In Proceedings of the 8th International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsruhe, West Germany, </address> <pages> pages 190-193. </pages> <booktitle> International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1983. </year>
Reference-contexts: The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114]. <p> A variety of methods have been developed, each focusing on particular families of belief-network topology. Kim and Pearl have developed a distributed algorithm for solving singly connected networks, or polytrees <ref> [89] </ref>. The algorithm is linear in the number of variables in the network. In this scheme, each node in the network obtains messages from each of its parent and child nodes, representing all the evidence available from alternative portions of the network.
Reference: [90] <author> D. Klein. </author> <title> Explaining and refining decision-theoretic choices. </title> <type> Technical Report MS-CIS-87-57 (LINC 74), </type> <institution> Dept. of Computer and Information Science, University of Pennsylvania, </institution> <year> 1987. </year>
Reference-contexts: A qualitative explanation from Pathfinder justifying an evidence-gathering recommendation is displayed at the bottom of Figure 4. Elsaesser employed a related approach for the qualitative explanation of Bayesian updating [37]. Recent work by Klein has examined the qualitative explanation of multiattribute utility models <ref> [90] </ref>. 4 CURRENT RESEARCH 34 explanation includes probability and utility considerations associated with additional information acquisition in the Pathfinder system. 5 DECISION-THEORETIC TECHNIQUES IN AI 35 5 Decision-Theoretic Techniques In AI 5.1 Overview In previous sections, we discussed applications of decision theory to AI problems with obvious relationships to expert-systems research;
Reference: [91] <author> C.P. Langlotz, L.M. Fagan, S.W. Tu, B.I. Sikic, and E.H. Shortliffe. </author> <title> Combining artificial intelligence and decision analysis for automated therapy planning assistance. </title> <booktitle> In Proceedings of Medinfo, </booktitle> <address> Washington, DC. </address> <publisher> North Holland, </publisher> <address> New York, </address> <month> October </month> <year> 1986. </year>
Reference-contexts: Each strategy consists of a sequence of decisions that are synergistic, or internally consistent. The strategies then are treated as the alternatives in the decision analysis. Langlotz and colleagues <ref> [91] </ref> propose a similar method and use heuristic search to generate a reduced set of possible medical therapy plans for detailed decision analysis. Value Structuring and Preference Encoding AI investigators, to date, have placed little emphasis on the preferences or desires of decision makers or reasoning agents. <p> Related work within decision science has investigated the application of decision theory to reasoning about the actions of competing decision makers [121, 157, 142]. Decision theory can provide a framework for considering the relationships among alternative inference strategies. Langlotz et al. <ref> [91] </ref> describe an attempt to justify heuristic default strategies with decision theory.
Reference: [92] <author> C.P. Langlotz, L.M. Fagan, S.W. Tu, J. Williams, and B.I. Sikic. ONYX: </author> <title> An architecture for planning in uncertain environments. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <pages> pages 447-449. </pages> <booktitle> International Joint Conference on Artificial Intelligence??, </booktitle> <month> August </month> <year> 1985. </year> <note> REFERENCES 47 </note>
Reference-contexts: Coles et al. [20] and Jacobs [84] used utility theory to evaluate alternative plans for robots immersed in an uncertain world. Langlotz et al. applied decision theory to ranking alternative cancer therapy plans within the Oncocin project <ref> [92] </ref>. Wellman [156] has applied logical theorem-proving techniques to prove the dominance of a set of plans within a qualitative influence-diagram formalism. The qualitative influence-diagram research centers on representing probabilistic dependencies qualitatively based on stochastic dominance. Decision theory also has been used for the control of inference.
Reference: [93] <author> C.P. Langlotz, E.H. Shortliffe, and L.M. Fagan. </author> <title> A methodology for computer-based explanation of decision analysis. </title> <type> Technical Report KSL-86-57, </type> <institution> Stanford University, </institution> <month> November </month> <year> 1986. </year>
Reference-contexts: Researchers have suggested that, as people may primarily use qualitative mental representations, it is useful to translate explanations of quantitative reasoning-for example, of decision-analytic models-into more qualitative descriptions [65]. Several projects have used this approach. Langlotz and associates <ref> [93] </ref> constructed a system called QXQ that explains medical decision analysis problems qualitatively. The system identifies the most important factors affecting a decision and applies a set of explanation heuristics.
Reference: [94] <author> P.S. </author> <title> Laplace. A Philosphical Essay on Probabilities. </title> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1902. </year> <note> Translated from the 6th French Edition, 1812. </note>
Reference: [95] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Fast manipulation of probabilities with local representations with applications to expert systems. </title> <type> Technical Report R-87-7, </type> <institution> Institute of Electronic Systems, Aalborg University, Aalborg, Denmark, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: These nodes must be instantiated with each possible value (or combination of values). The resulting probabilities are averaged over the results from each instantiation, weighted by the prior probabilities of the instantiated variables. Lauritzen and Spiegelhalter suggest a different approach based on a reformulation of the belief network <ref> [95] </ref>. First they "moralize" the graph by adding arcs between all pairs of nodes that have a common successor (i.e., parents with a common child). They then triangulate it, adding arcs so that there are no undirected cycles of more than three nodes without an internal chord.
Reference: [96] <author> R.S. Lehman. </author> <title> On confirmation and rational betting. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 20 </volume> <pages> 251-262, </pages> <year> 1955. </year>
Reference-contexts: Persuasive examples suggest that a rational person would wish to avoid making decisions based on incoherent beliefs. For example, someone willing to bet according to incoherent beliefs would be willing to accept a "Dutch book"-that is, a combination of bets leading to guaranteed loss under any outcome <ref> [96, 134] </ref>. 2.2 Probability Is Sufficient for Representing Uncertainty A number of researchers have provided lists of fundamental properties that they consider intuitively desirable for continuous measures of belief in the truth of a proposition [25, 149, 100].
Reference: [97] <author> J.F. </author> <title> Lemmer. Generalized Bayesian updating of incompletely specified distributions. Large Scale Systems, </title> <type> 5, </type> <year> 1983. </year>
Reference-contexts: The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114].
Reference: [98] <editor> J.F Lemmer and L.N. Kanal, editors. </editor> <booktitle> Uncertainty in Artificial Intelligence 2. </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: In recent years, decision-theory has been applied to a number of problems in AI, including planning, control of inference, perception, learning, problem formulation, temporal reasoning, and nonmonotonic reasoning. We review briefly aspects of these research topics. More comprehensive discussions are found in <ref> [86, 98] </ref>. 5.2 Recent Research The earliest and most prominent applications of decision theory in AI were in planning research, much of which centers on the construction of sequences of actions that will achieve a set of goals. <p> As we mentioned in the second section of this article, analyses have been carried out in attempts to understand how alternative formalisms for reasoning under uncertainty-such as nonmonotonic reasoning [46], fuzzy set theory [160], and Dempster-Shafer theory [133]-relate to probabilistic reasoning. See Kanal and Lemmer <ref> [86, 98] </ref> for some detailed analyses of these approaches. The application of influence diagrams in new areas is facilitated by their relatively unconstrained dependency structure at the level of relation. As an example, machine-vision researchers have applied probabilistic inference to perceptual tasks.
Reference: [99] <author> S. Lichenstein, B. Fishoff, and L.D. Philipps. </author> <title> Calibration of probabilities: The state of the art to 1980. </title> <editor> In D. Kahneman, P. Slovic, and A. Tversky, editors, </editor> <title> Judgement under uncertainty: </title> <booktitle> Heuristics and biases, </booktitle> <pages> pages 275-324. </pages> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: The graphical display of these relationships indicates constraints on the conditional probability 4 CURRENT RESEARCH 26 relationships between hypotheses and evidence. Decision analysts have developed various techniques for eliciting numerical probabilities <ref> [139, 99] </ref>. Some of these assessment techniques ask directly for probabilities, whereas others seek specific values of a variable while holding the probability fixed. A popular method uses a probability wheel, a simple graphical tool consisting of a disk with two adjustable complementary sectors of different colors.
Reference: [100] <author> D.V. Lindley. </author> <title> Scoring rules and the inevitability of probability. </title> <journal> International Statistical Review, </journal> <volume> 50 </volume> <pages> 1-26, </pages> <year> 1982. </year>
Reference-contexts: a "Dutch book"-that is, a combination of bets leading to guaranteed loss under any outcome [96, 134]. 2.2 Probability Is Sufficient for Representing Uncertainty A number of researchers have provided lists of fundamental properties that they consider intuitively desirable for continuous measures of belief in the truth of a proposition <ref> [25, 149, 100] </ref>. A recent reformulation of desirable properties of belief is [75]: 1 Several axiomatizations of probability theory have been proposed. 2 FOUNDATIONS 4 1. Clarity: Propositions should be well defined. 2.
Reference: [101] <author> Logan. </author> <title> The Value of Probability Assessment. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, </institution> <month> March </month> <year> 1985. </year>
Reference-contexts: This discussion of probabilities brings up the issue of the completeness of probability assessment. There is always a tradeoff between assigning a probability based on a current state of understanding and expending additional effort in modeling and introspection to come up with a better estimate <ref> [49, 101] </ref>. And, in practice, the assessor of a probability often is uncertain and uncomfortable about the distribution he is providing.
Reference: [102] <author> R. Loui. </author> <title> Theory and Computation of Uncertain Inference. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1987. </year> <note> Also available as TR-228, </note> <institution> University of Rochester, Department ofComputer Science. </institution>
Reference-contexts: Probability theory assigns a continuous measure of belief and provides mechanisms for updating in light of new information. Several researchers are integrating these perspectives as a means of dealing with incomplete and changing information <ref> [102, 107, 53] </ref>. Decision theory also can be applied to problems involving modal reasoning. Analogous to extensions of first-order predicate calculus to modal reasoning, probabilities can be used to describe the uncertain beliefs that one agent holds about another agent's beliefs [44, 42].
Reference: [103] <author> J. McDermott. </author> <title> R1: A rule-based configurer of computer systems. </title> <journal> Artificial Intelligence, </journal> <volume> 19 </volume> <pages> 39-88, </pages> <year> 1982. </year>
Reference-contexts: Synthetic tasks include the generation of alternatives, design, configuration, and planning. Many of the best-known expert systems address analytic tasks, such as medical diagnosis. However, some of the most successful systems are applied to synthetic problems, such as R1 for computer-hardware configuration <ref> [103] </ref>. Decision theory provides an appealing approach to analytic tasks, particularly to those involving inference and decision making under uncertainty. Consequently, we focus on expert systems for 3 EARLY RESEARCH ON EXPERT SYSTEMS 9 analytic tasks.
Reference: [104] <author> J. Mclaughlin. </author> <title> The utility-directed presentation of graphical simulation. </title> <type> Technical Report TR-87-59, </type> <institution> Stanford University, </institution> <month> December </month> <year> 1987. </year>
Reference-contexts: Related research on the naturalness of alternative grouping schemes has been conducted by Ben-Bassat and Teeni [6]. Researchers also have investigated the application of decision theory at the metalevel to control the construction of explanations of decision-theoretic inference and of mathematical modeling <ref> [70, 104] </ref>. The research has studied the explicit metareasoning about the costs, benefits, and tradeoffs associated with alternative explanations and with the understandability of alternative reasoning methods.
Reference: [105] <author> P. McNamee and J. Celona. </author> <title> Decision Analysis for the Professional with Supertree. </title> <publisher> The Scientific Press, </publisher> <address> Redwood City, </address> <year> 1987. </year>
Reference-contexts: The technique of strategy tables, from decision analysis, involves selecting several representative strategies from the full combinatoric set of possible sequences <ref> [105] </ref>. Each strategy consists of a sequence of decisions that are synergistic, or internally consistent. The strategies then are treated as the alternatives in the decision analysis.
Reference: [106] <author> M. Minsky and O.G. Selfridge. </author> <title> Learning in random nets. </title> <editor> In C. Cherry, editor, </editor> <booktitle> Information Theory, </booktitle> <pages> pages 335-347. </pages> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1961. </year> <note> REFERENCES 48 </note>
Reference-contexts: The naturalness of weights of evidence for acquiring and making inferences with uncertainty was first pointed out by Peirce in 1878 [117]. I.J. Good popularized the measure among philosophers of science and statisticians [47]. Several other researchers, including Turing [47] and Minsky and Selfridge <ref> [106] </ref>, independently found this measure to be useful. The additive property of evidence weights is conducive to producing informative graphical displays that represent the weights as the length of graphical elements to be added or subtracted.
Reference: [107] <author> E. Neufeld and D. Poole. </author> <title> Towards solving the multiple extension problem: Combining defaults and probabilities. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 35-44. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Probability theory assigns a continuous measure of belief and provides mechanisms for updating in light of new information. Several researchers are integrating these perspectives as a means of dealing with incomplete and changing information <ref> [102, 107, 53] </ref>. Decision theory also can be applied to problems involving modal reasoning. Analogous to extensions of first-order predicate calculus to modal reasoning, probabilities can be used to describe the uncertain beliefs that one agent holds about another agent's beliefs [44, 42].
Reference: [108] <author> N. Nilsson. </author> <title> Probabilistic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 71-87, </pages> <year> 1986. </year>
Reference-contexts: Several research projects have examined the representation of the semantics of probabilistic knowledge within predicate calculus. Nilsson's probabilistic logic <ref> [108] </ref> extends the idea of logical entailment to probabilistic domains. Within probabilistic logic, the probability of any sentence in first-order predicate calculus is determined. The probabilities assigned to arbitrary combinations of propositions are based on a logical analysis of alternative possible worlds.
Reference: [109] <author> M.J. Norusis and J.A. Jacquez. </author> <title> Diagnosis 1: Symptom non-independence in mathematical models for diagnosis. </title> <journal> Computers and Biomedical Research, </journal> <volume> 8 </volume> <pages> 156-172, </pages> <year> 1975. </year>
Reference-contexts: Investigators have found that inappropriate assumptions of conditional independence in simpli 3 EARLY RESEARCH ON EXPERT SYSTEMS 17 fied Bayesian systems can lead to noticeable degradation of performance. Norusis found significant improvement in the performance of a medical diagnostic system as the number of dependencies explicitly represented was increased <ref> [109] </ref>. Fryback discovered that problems with assuming conditional independence can grow as the number of variables represented in a diagnostic model are increased; that is, the potential benefits of considering a larger number of variables can be overwhelmed by the proportional increases in the missing dependencies [43].
Reference: [110] <author> S.M. Olmsted. </author> <title> On Representing and Solving Decision Problems. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, </institution> <month> December </month> <year> 1983. </year>
Reference-contexts: Influence diagrams and belief networks were designed with precisely these objectives in mind. Influence Diagrams and Belief Networks The influence diagram is a graphical knowledge-representation language that represents the decision basis <ref> [82, 111, 110] </ref>. The influence diagram is an acyclic directed graph containing nodes representing propositions or quantities of interest (i.e., alternatives, states) and arcs representing interactions between the nodes. Nodes representing propositions are associated with a set of mutually exclusive and exhaustive values that represent alternative possible states. <p> A decision network can always be converted into its corresponding decision tree, but this is not necessarily the best way to analyze it. Olmsted <ref> [110] </ref> and Shachter [130] have developed techniques for operating directly on influence diagrams. The algorithms apply a sequence of operations to the diagram, successively eliminating nodes when their effects have been accounted for through expected value calculations.
Reference: [111] <author> D.L. Owen. </author> <title> The use of influence diagrams in structuring complex decision problems. </title> <editor> In R.A. Howard and J.E. Matheson, editors, </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis, volume II, chapter 38, </booktitle> <pages> pages 763-771. </pages> <institution> Strategic Decisions Group, </institution> <address> Menlo Park, Ca., </address> <year> 1978. </year>
Reference-contexts: Influence diagrams and belief networks were designed with precisely these objectives in mind. Influence Diagrams and Belief Networks The influence diagram is a graphical knowledge-representation language that represents the decision basis <ref> [82, 111, 110] </ref>. The influence diagram is an acyclic directed graph containing nodes representing propositions or quantities of interest (i.e., alternatives, states) and arcs representing interactions between the nodes. Nodes representing propositions are associated with a set of mutually exclusive and exhaustive values that represent alternative possible states.
Reference: [112] <author> R.S. Patil. </author> <title> Causal representation of patient illness for electrolyte and acid-base diagnosis. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Massachusetts Institute of Technology, </institution> <month> October </month> <year> 1981. </year>
Reference-contexts: Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine <ref> [136, 12, 143, 153, 112] </ref>. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [113] <author> E.A. Patrick. </author> <title> Review of pattern recognition in medicine. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 6, </volume> <year> 1977. </year>
Reference-contexts: For example, the system of de Dombal and his colleagues averaged over 90% correct diagnoses of acute abdominal pain, where expert physicians were averaging 65% 80% correct [30]. Patrick's diagnostic aid for chest pain reportedly averaged 80% accuracy, whereas clinicians averaged 51% <ref> [113] </ref>. These systems certainly qualify as expert systems according to our definition.
Reference: [114] <author> J. Pearl. </author> <title> Fusion, propagation, and structuring in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 29 </volume> <pages> 241-288, </pages> <year> 1986. </year>
Reference-contexts: These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks <ref> [114] </ref>. We use belief networks, as this term is the most popular. Three Levels of Representation The expressiveness and sufficiency of influence diagrams is based in the representation's three levels of specification: relation, function, and number [82]. <p> We mentioned earlier that there has been recent work on the use of functions that specify patterns of independence. Recently, investigators have suggested methods for streamlining the probability assessment task, by specifying such prototypical functions for the probability distributions <ref> [56, 64, 114] </ref>. One example of a prototypical independence structure is termed the noisy OR-gate. We review this structure as an example of the assessment savings that may be gained through identifying and representing analogous patterns of independence. The noisy-OR structure is a probabilistic generalization of a standard Boolean OR. <p> The noisy-OR relationship allows the full conditional distribution to be derived from the individual probabilities of the evidence given each of the hypotheses and so requires only n parameters <ref> [47, 114] </ref>. The basis for this savings is straightforward. Suppose that p i is p (Ej only H i ; ~)-that is, the probability of E given that only H i occurs. <p> The Shachter algorithm can be significantly more efficient than the brute-force approach of computing the complete joint probability distribution. The extent of the efficiency gains depend on the topology of the network. Other exact approaches rely on manipulating multiply connected networks to reduce them to singly connected networks <ref> [114] </ref>. The Kim and Pearl algorithm or similar methods can then be applied to the network. Instantiation of nodes within a loop can effectively break the loop; thus Pearl [114] has suggested focusing on determining the minimal cutsets of nodes that could be instantiated to eliminate loops [114]. <p> Other exact approaches rely on manipulating multiply connected networks to reduce them to singly connected networks <ref> [114] </ref>. The Kim and Pearl algorithm or similar methods can then be applied to the network. Instantiation of nodes within a loop can effectively break the loop; thus Pearl [114] has suggested focusing on determining the minimal cutsets of nodes that could be instantiated to eliminate loops [114]. These nodes must be instantiated with each possible value (or combination of values). <p> singly connected networks <ref> [114] </ref>. The Kim and Pearl algorithm or similar methods can then be applied to the network. Instantiation of nodes within a loop can effectively break the loop; thus Pearl [114] has suggested focusing on determining the minimal cutsets of nodes that could be instantiated to eliminate loops [114]. These nodes must be instantiated with each possible value (or combination of values). The resulting probabilities are averaged over the results from each instantiation, weighted by the prior probabilities of the instantiated variables. Lauritzen and Spiegelhalter suggest a different approach based on a reformulation of the belief network [95].
Reference: [115] <author> J. Pearl. </author> <title> Evidential reasoning using stochastic simulation of causal models. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 245-257, </pages> <year> 1987. </year>
Reference-contexts: Unfortunately, this is not a general solution to the problem, because the rearrangement is liable to exponential complexity for highly interconnected networks. Pearl <ref> [115] </ref> has developed a stochastic-sampling scheme that involves direct propagation in both directions along each influence, rather than solely through the encoded direction, as in logic sampling. In this method, the conditional-probability distribution is computed for each node given all the neighbors in its Markov blanket. <p> In related work, Cooper [22] developed an algorithm for calculating the probability of an arbitrary statement in propositional logic when a belief network is used as the representation of uncertainty. There also is ongoing work on the logical analysis of belief networks. Pearl <ref> [115] </ref> has developed logical techniques for reasoning about the allowable decompositions of belief-network problems. Such decomposition techniques focus on issues of relevance among portions of a belief network to reformulate an unwieldy inference problem into a set of smaller independent problems that can be solved more efficiently.
Reference: [116] <author> J. Pearl and T.S. Verma. </author> <title> The logic of representing dependencies by directed graphs. </title> <booktitle> In Proceedings AAAI-87 Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA. </address> <booktitle> American Association for Artificial Intelligence, </booktitle> <address> Palo Alto, CA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114]. <p> Cheeseman and associates have studied the automatic induction of a useful set of categories from data acquired by sensors on a wandering robot [17]. Pearl and Verma <ref> [116] </ref> described logical methods for reformulating belief networks to suggest plausible causal relationships to explain a set of probabilistic relationships. 6 Conclusions We have reviewed the application of concepts from decision science to AI research.
Reference: [117] <author> C.S. </author> <title> Peirce. The probability of induction. </title> <booktitle> In The World of Mathematics, V.2, </booktitle> <pages> pages 1341-1354. </pages> <editor> Simon and Shuster, </editor> <address> New York, </address> <year> 1956. </year>
Reference-contexts: That is, the update in belief corresponding to the combined evidence is just the sum of individual updates. The naturalness of weights of evidence for acquiring and making inferences with uncertainty was first pointed out by Peirce in 1878 <ref> [117] </ref>. I.J. Good popularized the measure among philosophers of science and statisticians [47]. Several other researchers, including Turing [47] and Minsky and Selfridge [106], independently found this measure to be useful.
Reference: [118] <author> Y. Peng. </author> <title> A Formalization of Parsimonious Covering and Probabilistic Reasoning in Abductive Diagnostic Inference. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1986. </year> <month> TR-1615. </month>
Reference-contexts: That is, p (D 1 jE; ~) = p (D 2 j~)p (EjD 2 ; ~) Cooper [21] and Peng <ref> [118] </ref> describe branch-and-bound methods for searching through the space of possible diagnoses, which can identify the most probable diagnoses without examining all possible ones.
Reference: [119] <author> P.E. Politser. </author> <title> Explanations of statistical concepts: Can they penetrate the haze of Bayes? Methods of Information in Medicine, </title> <booktitle> 23 </booktitle> <pages> 99-108, </pages> <year> 1984. </year>
Reference-contexts: connected networks into a set of belief network subproblems and for reasoning about the application of combinations of alternative exact and approximate inference methods are promising areas of current investigation [72]. 4.4 Explanation in Decision-Theoretic Expert Systems A frequent criticism of decision-theoretic reasoning is that it is difficult to explain <ref> [144, 27, 119] </ref>. Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance.
Reference: [120] <author> H. Raiffa. </author> <title> Decision Analysis: Introductory Lectures on Choice Under Uncertainty. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Ma., </address> <year> 1968. </year> <note> REFERENCES 49 </note>
Reference-contexts: The discipline of decision analysis emerged in the 1960s; it grew out of a recognition that probability and decision theory, hitherto applied primarily to problems of statistical estimation [129, 122], also could be applied to real-world decision problems <ref> [78, 120] </ref>. Since its inception, decision analysis has grown into an established academic and professional discipline [83, 152, 88]. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients. <p> A variety of representations for a decision basis have been developed in the decision sciences. These representations include joint probability distributions over variables coupled with a loss function (as used in probability and statistics), and decision trees, which evolved with the development of decision analysis <ref> [120] </ref>. Although these representations are useful and general, they do not 4 CURRENT RESEARCH 19 Face. Dependencies (arcs) link propositions (nodes) that represent states of information (circles), decisions (squares), and patient values (diamond). provide a perspicuous means of representing independence in a manner accessible to both human and machine reasoners.
Reference: [121] <author> H. Raiffa. </author> <title> The Art and Science of Negotiation. </title> <publisher> Belknap Press, </publisher> <address> Cambridge, Ma., </address> <year> 1982. </year>
Reference-contexts: Related work within decision science has investigated the application of decision theory to reasoning about the actions of competing decision makers <ref> [121, 157, 142] </ref>. Decision theory can provide a framework for considering the relationships among alternative inference strategies. Langlotz et al. [91] describe an attempt to justify heuristic default strategies with decision theory.
Reference: [122] <author> H. Raiffa and R. Schlaifer. </author> <title> Applied Statistical Decision Theory. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Ma., </address> <year> 1961. </year>
Reference-contexts: Decision analysis, in contrast, addresses these issues directly in terms of decision making and tractability. The discipline of decision analysis emerged in the 1960s; it grew out of a recognition that probability and decision theory, hitherto applied primarily to problems of statistical estimation <ref> [129, 122] </ref>, also could be applied to real-world decision problems [78, 120]. Since its inception, decision analysis has grown into an established academic and professional discipline [83, 152, 88]. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients.
Reference: [123] <author> J.A. Reggia. </author> <title> Diagnostic expert systems based on a set covering model. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 19 </volume> <pages> 437-460, </pages> <year> 1983. </year>
Reference-contexts: In particular, D should contain, for all E j in E 0 , a hypothesis H i such that c (H i ; E j ). Reggia <ref> [123] </ref> proposed this formulation of the problem of diagnosis and developed set-covering algorithms for finding the minimum set of causes that could explain a set of observations. In the real world, the relationships among hypotheses and evidence generally are uncertain.
Reference: [124] <author> J.A. Reggia and B.T. Perricone. </author> <title> Answer justification in medical decision support systems based on Bayesian classification. </title> <journal> Computers in Biology and Medicine, </journal> <volume> 15 </volume> <pages> 161-167, </pages> <year> 1985. </year>
Reference-contexts: Sequences of likelihood ratios are used to explain how evidence affects belief in competing hypotheses in the Glasgow-Dyspepsia expert system for assisting in gastroenterology diagnosis [140], in the Pathfinder system for reasoning about tissue pathology [76], in the Neurex system for diagnosis of neurological findings <ref> [124] </ref>, and in the Medas system for assisting physicians in emergency medicine [5]. Likelihood ratios and weights of evidence also have been optionally converted from graphical to qualitative text descriptions in the Pathfinder and Medas projects. Pathfinder developers investigated the explanation of user-specific multiattribute-utility considerations associated with test decisions.
Reference: [125] <author> J.S. Rosenschein and J.S. Breese. </author> <title> Communication-free interactions among rational agents: A probabilistic approach. </title> <booktitle> In Proceedings of the 1988 AAAI Workshop on Distributed Artificial Intelligence, </booktitle> ?? <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Decision analysis can be applied to communication and cooperation issues. Recent research has examined how an autonomous agent might be endowed with the ability to apply utility theory and probability theory to reason about the knowledge and potential behaviors of another agent <ref> [125] </ref>. Related work within decision science has investigated the application of decision theory to reasoning about the actions of competing decision makers [121, 157, 142]. Decision theory can provide a framework for considering the relationships among alternative inference strategies.
Reference: [126] <author> W.F. Rousseau. </author> <title> A method for computing probabilities in complex situations. </title> <type> Technical Report 6252-2, </type> <institution> Center for Systems Research, Stanford University, Stanford, </institution> <address> CA, </address> <month> May </month> <year> 1968. </year>
Reference-contexts: The value function (a real-valued scalar function) encapsulates tradeoffs among these attributes for an individual patient, as well as individual preferences about risk and time. Much of the research on representation and inference with these graphical representations has focused on specializations of influence diagrams that contain only chance nodes <ref> [126, 82, 97, 21, 116, 89] </ref>. These express probabilistic relationships among states of the world exclusively, without explicit consideration of decisions and values. Several different terms are used for these representations, including causal networks, Bayesian nets, and belief networks [114].
Reference: [127] <author> S.J. Russell and E. Wefald. </author> <title> Multi-level decision-theoretic search. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Game Playing, </booktitle> <address> Stanford, CA, </address> <pages> pages 3-7. </pages> <publisher> AAAI, </publisher> <month> March </month> <year> 1988. </year>
Reference-contexts: Horvitz [73] has investigated issues surrounding the use of decision theory to control several computational tasks including decision-theoretic inference itself. In this work, alternative reasoning strategies are evaluated through weighing their expected informational benefits with inference-related costs, such as the expense associated with delay. Russell and Wefald <ref> [127] </ref> have examined the application of decision theory in search for game playing, building upon earlier work by Good [50].
Reference: [128] <author> R.K. Sarin. </author> <title> Strength of preference and risky choice. </title> <journal> Operations Research, </journal> <volume> 30 </volume> <pages> 982-997, </pages> <year> 1982. </year>
Reference-contexts: An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67].
Reference: [129] <author> L.J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1972. </year> <note> 2nd edition, First edition 1954. </note>
Reference-contexts: Utility theory is based on a set of simple axioms or rules concerning choices under uncertainty. Like the axioms of probability theory, these rules are fairly intuitive. The reader is referred elsewhere for a detailed presentation of different versions of the axioms, their rationale, and implications <ref> [151, 129, 32, 41] </ref>. Here, we only try to give the axioms' flavor. The first set of axioms concerns preferences for outcomes under certainty. The axiom of or-derability asserts that all outcomes are comparable, even if described by many attributes. <p> Decision analysis, in contrast, addresses these issues directly in terms of decision making and tractability. The discipline of decision analysis emerged in the 1960s; it grew out of a recognition that probability and decision theory, hitherto applied primarily to problems of statistical estimation <ref> [129, 122] </ref>, also could be applied to real-world decision problems [78, 120]. Since its inception, decision analysis has grown into an established academic and professional discipline [83, 152, 88]. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients.
Reference: [130] <author> R.D. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 871-882, </pages> <year> 1986. </year>
Reference-contexts: A decision network can always be converted into its corresponding decision tree, but this is not necessarily the best way to analyze it. Olmsted [110] and Shachter <ref> [130] </ref> have developed techniques for operating directly on influence diagrams. The algorithms apply a sequence of operations to the diagram, successively eliminating nodes when their effects have been accounted for through expected value calculations.
Reference: [131] <author> R.D. Shachter. </author> <title> Probabilistic inference and influence diagrams. </title> <journal> Operations Research, </journal> <volume> 36 </volume> <pages> 589-604, </pages> <year> 1988. </year>
Reference-contexts: Each time a new observation is made, messages are propagated throughout the network to update the probabilities associated with the other variables. Unfortunately, most real networks are multiply connected, so more complex methods are required. One approach, developed by Shachter <ref> [131] </ref>, allows computation of the conditional probability distribution for any function f , of a set of variables X , given evidence E, as p (f (X )jE; ~). This algorithm focuses on a single function of variables rather than on updating the probability of all nodes given evidence.
Reference: [132] <author> R.D. Shachter and D.E. Heckerman. </author> <title> Thinking backward for knowledge acquisition. </title> <journal> AI Magazine, </journal> <volume> 8 </volume> <pages> 55-63, </pages> <year> 1987. </year>
Reference-contexts: If H is a disease and E is an observable symptom, we can express the evidential relationship in the causal direction (i.e., p (EjH; ~)), and then use Bayes' theorem to reverse the inference and reason in the diagnostic direction (i.e., p (H jE; ~)) <ref> [132] </ref>. This bidirectionality is a consequence of Bayes' theorem. 2 FOUNDATIONS 5 Bayes' theorem follows from the last axiom of probability, relating the probability of a joint event (i.e., a conjunction) to conditional probabilities [4].
Reference: [133] <author> G. Shafer. </author> <title> Probability judgment in artificial intelligence. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: For example, fuzzy-set theory [160] rejects the property of clarity, allowing linguistic imprecision in the definition of propositions. Some AI researchers have also rejected scalar continuity, arguing that a single number is insufficiently rich to represent belief [19]. Dempster-Shafer theory <ref> [133] </ref> rejects completeness, denying that it is possible to assign a belief to every well-defined proposition.
Reference: [134] <author> A. Shimony. </author> <title> Coherence and the axioms of confirmation. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 20 </volume> <pages> 1-28, </pages> <year> 1955. </year>
Reference-contexts: Persuasive examples suggest that a rational person would wish to avoid making decisions based on incoherent beliefs. For example, someone willing to bet according to incoherent beliefs would be willing to accept a "Dutch book"-that is, a combination of bets leading to guaranteed loss under any outcome <ref> [96, 134] </ref>. 2.2 Probability Is Sufficient for Representing Uncertainty A number of researchers have provided lists of fundamental properties that they consider intuitively desirable for continuous measures of belief in the truth of a proposition [25, 149, 100].
Reference: [135] <author> E.H. Shortliffe. </author> <title> Computer-based Medical Consultations: MYCIN. </title> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Careful examination of the results of a comparison of CFs with probabilistic inference presented in the original paper on CFs <ref> [135] </ref> shows that, on average, the CF-based system underresponded to the diagnosticity of the data by a factor of two [159, 62]. In 25% of the cases, it actually responded to the wrong direction, interpreting evidence that overall supported a conclusion to be disconfirming, or vice versa.
Reference: [136] <author> E.H. Shortliffe. </author> <title> Explanation capabilities for medical consultation systems. </title> <booktitle> In Proceedings of American Association of Medical Systems and Informatics 1984, Third Spring Joint National Conference, </booktitle> <address> San Francisco, CA, </address> <pages> pages 193-197. </pages> <address> AAMSI, </address> <year> 1984. </year> <note> REFERENCES 50 </note>
Reference-contexts: Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine <ref> [136, 12, 143, 153, 112] </ref>. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [137] <author> H.A. Simon. </author> <title> A behavioral model of rational choice. </title> <journal> Quarterly Journal of Economics, </journal> <volume> 69 </volume> <pages> 99-118, </pages> <year> 1955. </year>
Reference-contexts: Some of the earliest AI research centered on an analysis of the sufficiency of alternative approximation strategies and heuristic methods to accomplish the task of more complex decision-theoretic representation and inference <ref> [137] </ref>. However, many AI researchers soon lost interest in decision theory. This disenchantment seems to have arisen, in part, from a perception that decision-theoretic approaches were hopelessly intractable and were inadequate for expressing the rich structure of human knowledge [51, 144].
Reference: [138] <author> D.E. Smith. </author> <title> Controlling inference. </title> <type> Technical Report STAN-CS-86-1107, </type> <institution> Computer Science Department, Stanford University, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies [48, 71]. Smith <ref> [138] </ref> and Treitel and Genesereth [148] have applied decision theory to reasoning about the control of logical reasoning. Smith uses expected value notions to select among 5 DECISION-THEORETIC TECHNIQUES IN AI 36 search paths in database queries.
Reference: [139] <author> C.S. Spetzler and C.S. Stael von Holstein. </author> <title> Probability encoding in decision analysis. </title> <journal> Management Science, </journal> <volume> 22 </volume> <pages> 340-358, </pages> <year> 1975. </year>
Reference-contexts: Decision analysts have drawn on this research, as well as on professional practice, to develop methods to mitigate the effects of these biases <ref> [139] </ref>. Once we have specified a general dependency structure for a set of probabilistic relationships, we can quantify the influences as conditional and marginal probability distributions. <p> The graphical display of these relationships indicates constraints on the conditional probability 4 CURRENT RESEARCH 26 relationships between hypotheses and evidence. Decision analysts have developed various techniques for eliciting numerical probabilities <ref> [139, 99] </ref>. Some of these assessment techniques ask directly for probabilities, whereas others seek specific values of a variable while holding the probability fixed. A popular method uses a probability wheel, a simple graphical tool consisting of a disk with two adjustable complementary sectors of different colors.
Reference: [140] <author> D.J. Spiegelhalter and R.P. Knill-Jones. </author> <title> Statistical and knowledge-based approaches to clinical decision support systems, with an application in gastroenterology. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 147 </volume> <pages> 35-77, </pages> <year> 1984. </year>
Reference-contexts: However, it is clear that factors other than performance perform a key role in determining 3 EARLY RESEARCH ON EXPERT SYSTEMS 12 acceptance. Such factors may include the poor user interface of many early systems <ref> [140] </ref> and the general lack of attention paid to how the use of such systems might be integrated with the habits and environment of the diagnostic practitioner. 3.5 AI Approaches to Expert Systems Concern about the restrictive assumptions of the simplified probabilistic scheme coupled with the perception that a combinatoric explosion <p> Several expert systems have made use of likelihood ratios and weights of evidence for explaining the relevance of evidence to hypotheses under consideration. Sequences of likelihood ratios are used to explain how evidence affects belief in competing hypotheses in the Glasgow-Dyspepsia expert system for assisting in gastroenterology diagnosis <ref> [140] </ref>, in the Pathfinder system for reasoning about tissue pathology [76], in the Neurex system for diagnosis of neurological findings [124], and in the Medas system for assisting physicians in emergency medicine [5].
Reference: [141] <author> S. </author> <title> Star. Theory-based inductive learning: An integration of symbolic and quantitative methods. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3. </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Other researchers have examined learning within the decision-theoretic framework. Machine-learning researchers have dwelled almost exclusively on deterministic relationships. Concepts developed in learning research, such as bias and explanation-based generalization, might be extended to learning examples of greater complexity through the integration of decision-theoretic notions. Star <ref> [141] </ref> described how explanation-based generalization models for learning might be extended to reason about preferences under uncertainty through the application of decision theory. Decision-theoretic approaches also hold promise for extending AI discovery research. Several research projects have been undertaken to apply probabilistic reasoning to discovery.
Reference: [142] <author> R.S. Strait. </author> <title> Decision Analysis of Strategic Interaction. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, </institution> <year> 1987. </year> <note> Also available as UCRL-53825, </note> <institution> Lawrence Livermore National Laboratory. </institution>
Reference-contexts: Related work within decision science has investigated the application of decision theory to reasoning about the actions of competing decision makers <ref> [121, 157, 142] </ref>. Decision theory can provide a framework for considering the relationships among alternative inference strategies. Langlotz et al. [91] describe an attempt to justify heuristic default strategies with decision theory.
Reference: [143] <author> W. Swartout. XPLAIN: </author> <title> A system for creating and explaining expert consulting systems. </title> <journal> Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 285-325, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine <ref> [136, 12, 143, 153, 112] </ref>. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [144] <author> P. </author> <title> Szolovits. </title> <booktitle> Artificial intelligence in medicine. </booktitle> <editor> In P. Szolovits, editor, </editor> <booktitle> Artificial Intelligence In Medicine, </booktitle> <pages> pages 1-19. </pages> <publisher> Westview Press, </publisher> <address> Boulder, CO, </address> <year> 1982. </year>
Reference-contexts: However, many AI researchers soon lost interest in decision theory. This disenchantment seems to have arisen, in part, from a perception that decision-theoretic approaches were hopelessly intractable and were inadequate for expressing the rich structure of human knowledge <ref> [51, 144] </ref>. <p> statement by Szolovits, a researcher who had investigated the application of decision theory in early medical reasoning systems: "The typical language of probability and utility theory is not rich enough to discuss such complex medical issues, and its extension within the original spirit leads to untenably large decision problems" (Szolovits <ref> [144] </ref>, p. 7). Although similar views are still widespread among AI researchers, there has been a recent resurgence of interest in the application of probability theory, decision theory, and decision analysis to AI. <p> They suggest that the mismatch leads to problems both in encoding expertise and in explaining the results of probabilistic inference, so that users could understand and trust them <ref> [144, 27, 51] </ref>. One interesting lesson from the early research on probabilistic reasoning is the distinction between the performance and acceptability of diagnostic systems. In principle, it might seem that none of the objections we have listed should be insuperable in the face of superior diagnostic performance. <p> connected networks into a set of belief network subproblems and for reasoning about the application of combinations of alternative exact and approximate inference methods are promising areas of current investigation [72]. 4.4 Explanation in Decision-Theoretic Expert Systems A frequent criticism of decision-theoretic reasoning is that it is difficult to explain <ref> [144, 27, 119] </ref>. Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance.
Reference: [145] <author> P. Szolovits and S.G. Pauker. </author> <title> Categorical and probabilistic reasoning in medical diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 115-144, </pages> <year> 1978. </year>
Reference-contexts: The simplicity of probabilistic systems based on these two assumptions made the approach popular. Several medical diagnostic systems have been constructed based on the simplified probabilistic scheme <ref> [145] </ref>, including systems for the diagnosis of heart disease [154, 52], and of acute abdominal pain [31]. The popularity of the simplified probabilistic inference has led some people to believe that the assumptions are absolute requirements of probabilistic inference.
Reference: [146] <author> J.A. Tatman. </author> <title> Knowledge Representation and Inference in Intelligent Decision Systems. </title> <type> PhD thesis, </type> <institution> Department of Engineering-Economic Systems, Stanford University, </institution> <year> 1985. </year>
Reference-contexts: Dean and Kanazawa [34] define a number of temporal predicates and show how functions representing the probability of specified states over time can be used in temporal reasoning. In other work, Tatman&lt; <ref> [146] </ref> made use of the influence 5 DECISION-THEORETIC TECHNIQUES IN AI 37 diagram representation to identify and to solve classes of temporal decision problems amenable to solution with dynamic programming methods.
Reference: [147] <author> R.L. </author> <title> Teach and E.H. Shortliffe. An analysis of physician attitudes regarding computer-based clinical consultation systems. </title> <journal> Computers and Biomedical Research, </journal> <volume> 14 </volume> <pages> 542-558, </pages> <year> 1981. </year>
Reference-contexts: Teach and Shortliffe <ref> [147] </ref> identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine [136, 12, 143, 153, 112].
Reference: [148] <author> R. </author> <title> Treitel and M.R. Genesereth. Choosing directions for rules. </title> <booktitle> In Proceedings AAAI-86 Fifth National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <pages> pages 153-157. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Recent research has focused on the potential for decision theory to be useful in planning a problem-solving approach, in evaluating the costs and benefits of alternative inference methods, and in combining the effort of several strategies [48, 71]. Smith [138] and Treitel and Genesereth <ref> [148] </ref> have applied decision theory to reasoning about the control of logical reasoning. Smith uses expected value notions to select among 5 DECISION-THEORETIC TECHNIQUES IN AI 36 search paths in database queries. Treitel has explored the costs associated with alternative sequen-tialization strategies in logical theorem proving.
Reference: [149] <author> M. </author> <title> Tribus. Rational Descriptions, Decisions, and Designs. </title> <publisher> Pergamon Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: a "Dutch book"-that is, a combination of bets leading to guaranteed loss under any outcome [96, 134]. 2.2 Probability Is Sufficient for Representing Uncertainty A number of researchers have provided lists of fundamental properties that they consider intuitively desirable for continuous measures of belief in the truth of a proposition <ref> [25, 149, 100] </ref>. A recent reformulation of desirable properties of belief is [75]: 1 Several axiomatizations of probability theory have been proposed. 2 FOUNDATIONS 4 1. Clarity: Propositions should be well defined. 2.
Reference: [150] <author> M. </author> <title> Tribus. What do we mean by rational? In Rational Descriptions, </title> <journal> Decisions and Designs, </journal> <pages> pages 1-32. </pages> <publisher> Pergamon Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: However, uncertainty about probabilities often masks the existence of other conditioning events for which the distribution is considered stable. It is the task of the knowledge engineer to draw out those conditioning events and thereby to expand the model (also referred to as extending the conversation <ref> [150] </ref>) to account for the uncertainty in assessment. Model Refinement and Sensitivity Analysis The scope and detail of a decision model are central to determining the ultimate usefulness of an analysis.
Reference: [151] <author> J. von Neumann and O. Morgenstern. </author> <title> Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1947. </year> <note> REFERENCES 51 </note>
Reference-contexts: Utility theory is based on a set of simple axioms or rules concerning choices under uncertainty. Like the axioms of probability theory, these rules are fairly intuitive. The reader is referred elsewhere for a detailed presentation of different versions of the axioms, their rationale, and implications <ref> [151, 129, 32, 41] </ref>. Here, we only try to give the axioms' flavor. The first set of axioms concerns preferences for outcomes under certainty. The axiom of or-derability asserts that all outcomes are comparable, even if described by many attributes.
Reference: [152] <author> D. Von Winterfeldt and W. Edwards. </author> <title> Decision Analysis and Behavioral Research. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Since its inception, decision analysis has grown into an established academic and professional discipline <ref> [83, 152, 88] </ref>. There are a number of commercial consulting and research firms that perform decision analyses for government and private clients. Some large corporations routinely apply decision analysis to scheduling, capital expansion, and research and development decisions. <p> Value Structuring and Preference Encoding AI investigators, to date, have placed little emphasis on the preferences or desires of decision makers or reasoning agents. Decision theorists have been studying preference in a subfield of decision analysis that emphasizes multiattribute decision problems <ref> [152, 88] </ref>. A decision-theoretic analysis is driven in large part by the attributes that are important to the decision maker (life duration, life quality, and monetary cost in the heart surgery example) and by the manner in which these attributes are combined in assigning value to alternative outcomes. <p> A decision-theoretic analysis is driven in large part by the attributes that are important to the decision maker (life duration, life quality, and monetary cost in the heart surgery example) and by the manner in which these attributes are combined in assigning value to alternative outcomes. Von Winterfeldt <ref> [152] </ref> and Keeney [88] present numerous theoretical results on multiattribute value issues and discuss elicitation procedures for assessing the complex preference structures in terms of individual attributes. An additional important component of preference is the encoding of the decision maker's attitude toward risk. <p> An additional important component of preference is the encoding of the decision maker's attitude toward risk. Utility theory deals directly with attitudes toward alternatives that have uncertain outcomes. A substantial literature addresses the theoretical and practical aspects of risk-preference encoding <ref> [152, 88, 80, 128, 87, 14] </ref>. Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling [155, 67]. <p> The size of one colored sector can be adjusted to correspond to the probability to be assessed, as a way of expressing a probability without explicitly mentioning a number. For extremely low or high probabilities, techniques that use odds or log-odds have been shown to be useful <ref> [152] </ref>. This discussion of probabilities brings up the issue of the completeness of probability assessment. There is always a tradeoff between assigning a probability based on a current state of understanding and expending additional effort in modeling and introspection to come up with a better estimate [49, 101].
Reference: [153] <author> J.W. Wallis and E.H. Shortliffe. </author> <title> Explanatory power for medical expert systems: Studies in the representation of causal relationships for clinical consultations. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 21 </volume> <pages> 127-136, </pages> <year> 1982. </year>
Reference-contexts: Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world [158] to medicine <ref> [136, 12, 143, 153, 112] </ref>. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [154] <author> H.R. Warner, A.F. Toronto, L.G. Veasy, and R. Stephenson. </author> <title> A mathematical approach to medical diagnosis: Application to congenital heart disease. </title> <journal> Journal of the American Medical Association, </journal> <volume> 177 </volume> <pages> 177-183, </pages> <year> 1961. </year>
Reference-contexts: The simplicity of probabilistic systems based on these two assumptions made the approach popular. Several medical diagnostic systems have been constructed based on the simplified probabilistic scheme [145], including systems for the diagnosis of heart disease <ref> [154, 52] </ref>, and of acute abdominal pain [31]. The popularity of the simplified probabilistic inference has led some people to believe that the assumptions are absolute requirements of probabilistic inference. It is a misconception, however, to regard this simplified Bayesian scheme as defining practical probabilistic inference.
Reference: [155] <author> M.P. Wellman. </author> <title> Reasoning about preference models. </title> <type> Technical Report MIT/LCS/TR-340, </type> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1985. </year>
Reference-contexts: Most techniques involve asking the decision maker about her or his preferences for various hypothetical gambles and then combining the results and checking for consistency. Several researchers have examined computer aids for value structuring and preference modeling <ref> [155, 67] </ref>. Encoding Probabilities One of the central tasks in engineering a decision-theoretic system is that of assessing probabilities. A frequent concern is the availability of probabilities as well as the numbers of probabilities that may be required.
Reference: [156] <author> M.P. Wellman. </author> <title> Formulation of tradeoffs in planning under uncertainty. </title> <type> Technical Report MIT/LCS/TN-332, </type> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Coles et al. [20] and Jacobs [84] used utility theory to evaluate alternative plans for robots immersed in an uncertain world. Langlotz et al. applied decision theory to ranking alternative cancer therapy plans within the Oncocin project [92]. Wellman <ref> [156] </ref> has applied logical theorem-proving techniques to prove the dominance of a set of plans within a qualitative influence-diagram formalism. The qualitative influence-diagram research centers on representing probabilistic dependencies qualitatively based on stochastic dominance. Decision theory also has been used for the control of inference. <p> At the foundations of any decision model are decisions about the propositions to include within the decision basis, which often are based on logical relationships. Several researchers have examined the automated construction of decision models <ref> [67, 11, 156] </ref>. There are many unanswered questions regarding the automated assembling, pruning, and reasoning about decision models.
Reference: [157] <author> J. Wilson. </author> <title> Subjective probability and the prisoner's dilemma. </title> <journal> Management Science, </journal> <volume> 32 </volume> <pages> 45-55, </pages> <year> 1986. </year>
Reference-contexts: Related work within decision science has investigated the application of decision theory to reasoning about the actions of competing decision makers <ref> [121, 157, 142] </ref>. Decision theory can provide a framework for considering the relationships among alternative inference strategies. Langlotz et al. [91] describe an attempt to justify heuristic default strategies with decision theory.
Reference: [158] <author> T. Winograd. </author> <title> A computer program for understanding natural language. </title> <type> Technical Report TR-17, </type> <institution> Massachusetts Institute of Technology Artificial Intelligence Laboratory, </institution> <year> 1971. </year>
Reference-contexts: Teach and Shortliffe [147] identified the ability of an expert system to explain its reasoning strategies and results to users as an important factor in its acceptance. Researchers have constructed systems that give explanations of logical reasoning for applications spanning the range from blocks world <ref> [158] </ref> to medicine [136, 12, 143, 153, 112]. Unfortunately, relatively little has been done on the explanation of decision-theoretic inference. We shall review some of the ongoing research on techniques for justifying the results of decision-theoretic reasoning strategies.
Reference: [159] <author> B. Wise. </author> <title> An Experimental Comparison of Uncertain Inference Systems. </title> <type> PhD thesis, </type> <institution> The Robotics Institute and Department of Engineering and Public Policy, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Careful examination of the results of a comparison of CFs with probabilistic inference presented in the original paper on CFs [135] shows that, on average, the CF-based system underresponded to the diagnosticity of the data by a factor of two <ref> [159, 62] </ref>. In 25% of the cases, it actually responded to the wrong direction, interpreting evidence that overall supported a conclusion to be disconfirming, or vice versa. <p> The increased performance has been quantified with an evaluation scheme incorporating decision-theoretic and ad hoc measures [58]. Wise experimentally compared the performance of six common uncertain inference schemes for small rule sets and found that differences in performance between heuristic and probabilistic schemes depend heavily on the situation <ref> [159] </ref>. As we might expect, when there was strong evidence in one direction, most schemes performed well. But when the evidence was weak or conflicting, heuristic schemes tended to perform poorly, and in some cases did no better than random.
Reference: [160] <author> L.A. Zadeh. </author> <title> The role of fuzzy logic in the management of uncertainty in expert systems. </title> <journal> Fuzzy Sets and Systems, </journal> <volume> 11 </volume> <pages> 199-227, </pages> <year> 1983. </year>
Reference-contexts: These principles provide a useful framework for comparing alternative formalisms for representing uncertainty, in terms of which of the principles the formalisms reject [75]. For example, fuzzy-set theory <ref> [160] </ref> rejects the property of clarity, allowing linguistic imprecision in the definition of propositions. Some AI researchers have also rejected scalar continuity, arguing that a single number is insufficiently rich to represent belief [19]. <p> As we mentioned in the second section of this article, analyses have been carried out in attempts to understand how alternative formalisms for reasoning under uncertainty-such as nonmonotonic reasoning [46], fuzzy set theory <ref> [160] </ref>, and Dempster-Shafer theory [133]-relate to probabilistic reasoning. See Kanal and Lemmer [86, 98] for some detailed analyses of these approaches. The application of influence diagrams in new areas is facilitated by their relatively unconstrained dependency structure at the level of relation.
References-found: 160

