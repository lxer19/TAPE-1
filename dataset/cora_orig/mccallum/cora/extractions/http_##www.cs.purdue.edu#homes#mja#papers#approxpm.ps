URL: http://www.cs.purdue.edu/homes/mja/papers/approxpm.ps
Refering-URL: http://www.cs.purdue.edu/coast/coast-library.html
Root-URL: http://www.cs.purdue.edu
Email: mja@cs.purdue.edu  Frederic.Chyzak@inria.fr  Philippe.Dumas@inria.fr  
Title: An Algorithm for Estimating all Matches Between Two Strings  
Author: Mikhail J. Atallah Frederic Chyzak Philippe Dumas 
Keyword: Index Terms algorithms, convolution, pattern matching.  
Note: Portions of this work were supported by sponsors of the COAST Laboratory. The second and third authors' work was supported in part by the Long Term Research Project Alcom-IT (#20244) of the European Union.  
Address: West Lafayette, IN 47907 U.S.A.  B.P. 105 78153 Le Chesnay Cedex France  B.P. 105 78153 Le Chesnay Cedex France  
Affiliation: COAST Laboratory and Department of Computer Sciences Purdue University  INRIA Domaine de Voluceau Rocquencourt  INRIA Domaine de Voluceau Rocquencourt  
Abstract: We give a randomized algorithm for estimating the score vector of matches between a text string of length N and a pattern string of length M ; this is the vector obtained when the pattern is slid along the text, and the number of matches is counted for each position. The randomized algorithm takes deterministic time O((N=M )Conv (M )) where Conv (M ) is the time for performing a convolution of two vectors of size M each. The algorithm finds an unbiased estimator of the scores, whose variance is particularly small for scores that are close to M , i.e., for approximate occurrences of the pattern in the text. No assumptions are made about the probabilistic characteristics of the input, or about the number of different symbols appearing in T or P (i.e., the alphabet size need not be much smaller than M ). The solution extends to the weighted case and to higher dimensions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal and J.S. Vitter, </author> <title> "The Input/Output Complexity of Sorting and Related Problems," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 31, </volume> <year> 1988, </year> <pages> pp. 1116-1127. </pages>
Reference-contexts: Now, suppose that one has hardware designed for a p-sized FFT problem, and one wants to use it to solve an n-sized FFT problem, where n &gt; p. Clever techniques for optimally using the p-sized FFT hardware to solve an n-sized FFT were designed by Aggarwal and Vitter <ref> [1] </ref>. However, these methods introduce serious practical complications of their own, such as necessitating multiple uses of the dedicated FFT chip, and the elaborate combining of the answers returned by these multiple uses of the FFT chip. This would involve impractical constant factors. Acknowledgement.
Reference: [2] <author> A. Apostolico and Z. Galil (Eds), </author> <title> Combinatorial Algorithms on Words, </title> <publisher> Springer, </publisher> <year> 1985. </year>
Reference-contexts: However, if the assumption of small alphabet size is dropped, then another approach is needed. This version of the problem (i.e., for possibly large alphabets) was posed by Apostolico and Galil in their book <ref> [2] </ref>, where it is mentioned that a linear time algorithm can be obtained for computing those offsets i at which only a single mismatch prevents the pattern from occurring exactly. (The corresponding entries of C then equal M 1.) The best known deterministic algorithm for computing the vector C is due
Reference: [3] <author> K. Abrahamson, </author> <title> "Generalized String Matching," </title> <journal> SIAM Journal of Computing, </journal> <volume> 16, </volume> <year> 1987, </year> <pages> pp. 1039-1051. </pages>
Reference-contexts: a linear time algorithm can be obtained for computing those offsets i at which only a single mismatch prevents the pattern from occurring exactly. (The corresponding entries of C then equal M 1.) The best known deterministic algorithm for computing the vector C is due independently to Abrahamson and Kosaraju <ref> [3, 11] </ref> and has a time complexity of O p in the arithmetic computational model in which the convolution of two M -length vectors can be done in O (M log M ) time.
Reference: [4] <author> M.J. Atallah, Y. Genin, and W. Szpankowski, </author> <title> "A Pattern Matching Approach to Image Compression," </title> <booktitle> Proceedings of the Third IEEE International Conference on Image Processing, </booktitle> <address> Lausanne, Switzerland, </address> <year> 1996, </year> <pages> pp. 349-356. </pages>
Reference-contexts: The algorithm locates these interesting positions with good accuracy, which is the difficult part of the problem. Approximate pattern matching has many applications, including intrusion detection in a computer system [12], image analysis and data compression <ref> [4] </ref>. In the former, alphabet symbols correspond to events in a system, and since some events are more important than others (from a security point of view) it follows that the definition of the score needs to be weighted by the relative importance of alphabet symbols.
Reference: [5] <author> M.J. Atallah, P. Jacquet, and W. Szpankowski, </author> <title> "A Probabilistic Approach to Pattern Matching with Mismatches," Random Structures and Algorithms, </title> <type> 4, </type> <year> 1993, </year> <pages> pp. 191-213. </pages>
Reference-contexts: Pattern a b a b b a Matches " " between the pattern and the corresponding slice of the text; this gives the score C. probabilistic time O (N log M ) for this problem was given in <ref> [5] </ref>; however, this algorithm depends on some restrictive assumptions on the probabilistic characteristics of the input, namely the Bernoulli model. (An earlier version of [5] erroneously claimed that such an assumption is not needed by that algorithm, whereas in fact it was needed.) A clever O (N (log M ) 3 <p> pattern and the corresponding slice of the text; this gives the score C. probabilistic time O (N log M ) for this problem was given in <ref> [5] </ref>; however, this algorithm depends on some restrictive assumptions on the probabilistic characteristics of the input, namely the Bernoulli model. (An earlier version of [5] erroneously claimed that such an assumption is not needed by that algorithm, whereas in fact it was needed.) A clever O (N (log M ) 3 ) deterministic time algorithm for estimating all the scores of mismatches (rather than of matches) was given by Karloff [10]; although Karloff's estimator is
Reference: [6] <author> R.A. Baeza-Yates and G.H. Gonnet, </author> <title> "A New Approach to Text Searching," </title> <journal> Communications of the ACM, </journal> <volume> 35, </volume> <year> 1992, </year> <pages> pp. 74-82. </pages>
Reference-contexts: The algorithm of Baeza-Yates and Gonnet <ref> [6] </ref> solves the problem in O (N M log M= log N ) time, which is better than O (N log M ) for small M , i.e., if M log N . <p> For the parameters of the above-mentioned first experiment, the program processed roughly 280 bytes per second and was much slower (by a factor of 4) than that of Baeza-Yates and Gonnet <ref> [6] </ref>. As mentioned earlier, we used a soft implementation of FFT (which suffers from large constant factors in its time complexity), and our algorithm should work better with the FFT step performed by dedicated chips.
Reference: [7] <author> R.A. Baeza-Yates and C.H. Perleberg, </author> <title> "Fast and Practical Approximate Pattern Matching," </title> <journal> Information Processing Letters, </journal> <volume> 59, </volume> <year> 1996, </year> <pages> pp. 21-27. </pages>
Reference-contexts: The algorithm of Baeza-Yates and Gonnet [6] solves the problem in O (N M log M= log N ) time, which is better than O (N log M ) for small M , i.e., if M log N . The algorithm of Baeza-Yates and Perleberg <ref> [7] </ref> solves the problem in average time O (N M=) where is the size of the alphabet (i.e., the number of distinct symbols that appear in M ), which is good for large .
Reference: [8] <author> M. Crochemore and W. Rytter, </author> <title> Text Algorithms, </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: Indeed, if N &gt; 2M , we can use the standard technique <ref> [8] </ref> of partitioning the text into O (N=M ) overlapping chunks of length 2M each, and then processing each chunk separately in time O (kM log M ). The overall complexity is then O (kN log M ). <p> We next briefly sketch how this is done. We justify our focus to achieving a time complexity of O (kM log M ) for the case n = 2m by the following standard reduction <ref> [8] </ref> to this case from the general case n &gt; 2m: CoverT with N=M overlapping squares T i;j of size 2m fi 2m each, where T i;j consists of the square submatrix of T of size 2m fi 2m that begins (i.e., has its top-left corner) at position (mi; mj) in <p> The overall time complexity to compute them is O ((N=M )kM log M ) = O (kN log M ), as required. Therefore, we henceforth assume that n = 2m. The extension of the one-dimensional solution to two dimensions works by transforming the two-dimensional problem into a one-dimensional one <ref> [8] </ref>, and in the process introduces "don't care" symbols: that is, if A is the alphabet for the two-dimensional problem, then the corresponding 9 alphabet for the one-dimensional problem is A [ f#g where # is a "don't care" symbol in the sense that, if x or y (or both) equal
Reference: [9] <author> M.J. Fischer and M.S. Paterson, </author> <title> "String Matching and Other Products," Complexity of Computation, </title> <booktitle> SIAM-AMS Proceedings, </booktitle> <volume> 7, </volume> <year> 1974, </year> <pages> pp. 113-125. </pages>
Reference-contexts: The naive algorithm to compute the exact score vector has a time complexity of O ((N M + 1)M ). When the alphabet size is O (1) (hence much smaller than M ), the algorithm of Fisher and Paterson <ref> [9] </ref> uses convolution to solve the problem in O (N log M ) time. However, if the assumption of small alphabet size is dropped, then another approach is needed.
Reference: [10] <author> H. Karloff, </author> <title> "Fast Algorithms for Approximately Counting Mismatches," </title> <journal> Information Processing Letters, </journal> <volume> 48, </volume> <year> 1993, </year> <pages> pp. 53-60. </pages>
Reference-contexts: (An earlier version of [5] erroneously claimed that such an assumption is not needed by that algorithm, whereas in fact it was needed.) A clever O (N (log M ) 3 ) deterministic time algorithm for estimating all the scores of mismatches (rather than of matches) was given by Karloff <ref> [10] </ref>; although Karloff's estimator is biased, it guarantees not to overestimate the number of mismatches by more than a constant multiplicative factor, and the author states that his scheme apparently cannot be modified to estimate the number of matches (rather than mismatches) to within a constant multiplicative bound.
Reference: [11] <author> S.R. Kosaraju, </author> <title> "Efficient String Matching," </title> <type> manuscript, </type> <institution> Johns Hopkins University, </institution> <year> 1987. </year>
Reference-contexts: a linear time algorithm can be obtained for computing those offsets i at which only a single mismatch prevents the pattern from occurring exactly. (The corresponding entries of C then equal M 1.) The best known deterministic algorithm for computing the vector C is due independently to Abrahamson and Kosaraju <ref> [3, 11] </ref> and has a time complexity of O p in the arithmetic computational model in which the convolution of two M -length vectors can be done in O (M log M ) time.
Reference: [12] <author> S. Kumar and E.H. Spafford, </author> <title> "A Pattern-Matching Model for Intrusion Detection," </title> <booktitle> Proceedings of the National Computer Security Conference, </booktitle> <year> 1994, </year> <pages> pp. 11-21. </pages>
Reference-contexts: The algorithm locates these interesting positions with good accuracy, which is the difficult part of the problem. Approximate pattern matching has many applications, including intrusion detection in a computer system <ref> [12] </ref>, image analysis and data compression [4].
Reference: [13] <author> D.E. Knuth, </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. 2: </volume> <booktitle> Seminumerical Algorithms, </booktitle> <publisher> Addison-Wesley, </publisher> <editor> 2nd ed., </editor> <year> 1981, </year> <pages> pp. 290-294. 12 </pages>
References-found: 13

