URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume5/zlotkin96a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/zlotkin96a.html
Root-URL: 
Email: giladz@agentsoft.com  jeff@cs.huji.ac.il  
Title: Mechanisms for Automated Negotiation in State Oriented Domains  
Author: Gilad Zlotkin Jeffrey S. Rosenschein 
Address: P.O. Box 53047 Jerusalem, Israel  Givat Ram, Jerusalem, Israel  
Affiliation: AgentSoft Ltd.  Institute of Computer Science Hebrew University  
Note: Journal of Artificial Intelligence Research 5 (1996) 163-238 Submitted 5/94; published 10/96  
Abstract: This paper lays part of the groundwork for a domain theory of negotiation, that is, a way of classifying interactions so that it is clear, given a domain, which negotiation mechanisms and strategies are appropriate. We define State Oriented Domains, a general category of interaction. Necessary and sufficient conditions for cooperation are outlined. We use the notion of worth in an altered definition of utility, thus enabling agreements in a wider class of joint-goal reachable situations. An approach is offered for conflict resolution, and it is shown that even in a conflict situation, partial cooperative steps can be taken by interacting agents (that is, agents in fundamental conflict might still agree to cooperate up to a certain point). A Unified Negotiation Protocol (UNP) is developed that can be used in all types of encounters. It is shown that in certain borderline cooperative situations, a partial cooperative agreement (i.e., one that does not achieve all agents' goals) might be preferred by all agents, even though there exists a rational agreement that would achieve all their goals. Finally, we analyze cases where agents have incomplete information on the goals and worth of other agents. First we consider the case where agents' goals are private information, and we analyze what goal declaration strategies the agents might adopt to increase their utility. Then, we consider the situation where the agents' goals (and therefore standalone costs) are common knowledge, but the worth they attach to their goals is private information. We introduce two mechanisms, one "strict," the other "tolerant," and ana lyze their affects on the stability and efficiency of negotiation outcomes.
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. F., Kautz, H. A., Pelavin, R. N., & Tenenberg, J. D. </author> <year> (1991). </year> <title> Reasoning About Plans. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California. </address>
Reference-contexts: In this first section, we consider the space of lies that are available in different types of interactions, and with different types of mechanisms. There are several frameworks for dealing with incomplete information, such as incremental goal recognition techniques <ref> (Allen, Kautz, Pelavin, & Tenenberg, 1991) </ref>, but the framework we explore here is that of a "1 negotiation phase" in which agents simultane 202 Mechanisms for Automated Negotiation ously declare private information before beginning the negotiation (this was also introduced elsewhere (Zlotkin & Rosenschein, 1989, 1993a) for the case of TODs).
Reference: <author> Arrow, K. J. </author> <year> (1963). </year> <title> Social Choice and Individual Values. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference-contexts: There is also a social welfare function that rates all those possible social outcomes (e.g., a socially efficient agreement may be rated higher than a non-efficient one) <ref> (Arrow, 1963) </ref>. The question is then, can one design a game such that it has a unique solution (equilibrium strategies), and such that when each individual agent behaves according to this equilibrium strategy, the social behavior will maximize the social welfare function.
Reference: <author> Aumann, R. </author> <year> (1987). </year> <title> Correlated equilibrium as an expression of bayesian rationality. </title> <journal> Econo-metrica, </journal> <volume> 55, </volume> <pages> 1-18. </pages>
Reference-contexts: Aumann introduced the term correlated equilibrium (Aumann, 1974); he defined the correlated equilibrium of a given game to be a Nash equilibrium of some extension of the game, where the players receive private signals before the original game is actually played. Aumann also showed <ref> (Aumann, 1987) </ref> that correlated equilibrium can be defined in terms of Bayesian rationality. Forges extended this approach to games with incomplete information (Forges, 1993).
Reference: <author> Aumann, R. J. </author> <year> (1974). </year> <title> Subjectivity and correlation in randomized strategies. </title> <journal> Journal of Mathematical Economics, </journal> <volume> 1, </volume> <pages> 67-96. </pages>
Reference-contexts: If the mediator's communications are observable by all the players, then the only self-enforcing non-binding contracts are those that randomize among the Nash equilibria of the original game ((Myerson, 1991), pp. 251). Self-enforcing contracts on correlated strategy are called correlated equilibria. Aumann introduced the term correlated equilibrium <ref> (Aumann, 1974) </ref>; he defined the correlated equilibrium of a given game to be a Nash equilibrium of some extension of the game, where the players receive private signals before the original game is actually played.
Reference: <author> Belegrinos, P., & Georgeff, M. P. </author> <year> (1991). </year> <title> A model of events and processes. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 506-511 Sydney, Australia. </address>
Reference: <author> Binmore, K. </author> <year> (1990). </year> <booktitle> Essays on the Foundations of Game Theory. </booktitle> <publisher> Basil Blackwell, </publisher> <address> Cam-bridge, Massachusetts. </address>
Reference: <author> Binmore, K. </author> <year> (1992). </year> <title> Fun and Games, A Text on Game Theory. </title> <editor> D. C. Heath and Company, </editor> <address> Lexington, Massachusetts. </address>
Reference: <author> Bok, S. </author> <year> (1978). </year> <title> Lying: Moral Choice in Public and Private Life. </title> <publisher> Vintage Books, </publisher> <address> New York. </address>
Reference-contexts: The agents will agree to split this joint plan with probability 1 2 , leaving each with an expected utility of 4. 5. Some of these issues, in everyday human contexts, are explored in <ref> (Bok, 1978) </ref>.
Reference: <author> Cammarata, S., McArthur, D., & Steeb, R. </author> <year> (1983). </year> <title> Strategies of cooperation in distributed problem solving. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 767-770 Karlsruhe, West Germany. </address> <note> 229 Zlotkin & Rosenschein Cohen, </note> <author> P. R., & Levesque, H. J. </author> <year> (1987). </year> <title> Intention = choice + commitment. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 410-415 Seattle, Washington. </address>
Reference: <author> Cohen, P. R., & Levesque, H. J. </author> <year> (1990). </year> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 (2-3), </volume> <pages> 213-261. </pages>
Reference: <author> Cohen, P. R., & Levesque, H. J. </author> <year> (1991). </year> <title> Teamwork. </title> <booktitle> Technote 503, SRI International, </booktitle> <address> Menlo Park, California. </address>
Reference-contexts: Axiomatizations, however, might need to deal with how groups of agents could have a joint commitment to accomplishing some goal <ref> (Cohen & Levesque, 1991) </ref>, or how each agent can make interpersonal commitments without the use of such notions (Grosz & Kraus, 1993).
Reference: <author> Cohen, P. R., & Perrault, C. R. </author> <year> (1979). </year> <title> Elements of a plan-based theory of speech acts. </title> <journal> Cognitive Science, </journal> <volume> 3, </volume> <pages> 177-212. </pages>
Reference: <author> Conry, S. E., Meyer, R. A., & Lesser, V. R. </author> <year> (1988). </year> <title> Multistage negotiation in distributed planning. </title> <editor> In Bond, A., & Gasser, L. (Eds.), </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <pages> pp. 367-384. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo. </address>
Reference: <author> Corkill, D. D. </author> <year> (1979). </year> <title> Hierarchical planning in a distributed environment. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 168-175 Tokyo. </address>
Reference-contexts: The synthesis, synchronization, or adjustment process for multiple agent plans thus constitute some of the (varied) foci of DAI planning research. Synchronization through conflict avoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution of a single-agent planner among multiple agents <ref> (Corkill, 1979) </ref>, the use of a centralized multiagent planner (Rosenschein, 223 Zlotkin & Rosenschein 1982), and the use of consensus mechanisms for aggregating subplans produced by multiple agents (Ephrati & Rosenschein, 1993b), have all been explored, as well as related issues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b;
Reference: <author> Corkill, D. D. </author> <year> (1982). </year> <title> A Framework for Organizational Self-Design in Distributed Problem Solving Networks. </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA. </address>
Reference: <author> Decker, K. S., & Lesser, V. R. </author> <year> (1992). </year> <title> Generalizing the partial global planning algorithm. </title> <journal> International Journal of Intelligent Cooperative Information Systems, </journal> <volume> 1(2), </volume> <pages> 319-346. </pages>
Reference-contexts: Thus, for example, Georgeff's early work on multiagent planning assumed that there was no basic conflict among agent goals, and that coordination was all that was necessary to guarantee success (Georgeff, 1983, 1984; Stuart, 1985). Similarly, planning in the context of Lesser, Corkill, Durfee, and Decker's research <ref> (Decker & Lesser, 1992, 1993b, 1993a) </ref> often involves coordination of activities (e.g., sensor network computations) among agents who have no inherent conflict with one another (though surface conflict may exist). "Planning" here means avoidance of redundant or distracting activity, efficient exploration of the search space, etc. <p> Our agents, on the other hand, are motivated to achieve individual goals. Second, unlike our formal approach to mechanism design, Lesser's work has historically been heuristic and experimental, although his more recent work has explored the theoretical basis for system-level phenomena <ref> (Decker & Lesser, 1992, 1993a, 1993b) </ref>. Sycara has examined a model of negotiation that combines case-based reasoning and optimization of multi-attribute utilities (Sycara, 1988, 1989).
Reference: <author> Decker, K. S., & Lesser, V. R. </author> <year> (1993a). </year> <title> An approach to analyzing the need for meta-level communication. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 360-366 Chambery, France. </address>
Reference: <author> Decker, K. S., & Lesser, V. R. </author> <year> (1993b). </year> <title> A one-shot dynamic coordination algorithm for distributed sensor networks. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 210-216 Washington, DC. </address>
Reference: <author> Doyle, J. </author> <year> (1985). </year> <title> Reasoned assumptions and pareto optimality. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 87-90 Los Angeles, California. </address>
Reference-contexts: In contrast to this work, our research employs standard game theory notions of equilibrium and rationality. Other discussions of the use of rationality in general reasoning can be found in Doyle's research <ref> (Doyle, 1985, 1992) </ref>. Another decision theoretic approach, taken by Gmytrasiewicz and Durfee, has been used to model multiagent interactions (Gmytrasiewicz, Durfee, & Wehe, 1991a, 1991b; Gmytrasiewicz & Durfee, 1992, 1993). It assumes no predefined protocol or structure to the interaction (in marked contrast to our research on protocol design).
Reference: <author> Doyle, J. </author> <year> (1992). </year> <title> Rationality and its roles in reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 8 (2), </volume> <pages> 376-409. </pages>
Reference: <author> Durfee, E. H. </author> <year> (1988). </year> <title> Coordination of Distributed Problem Solvers. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston. </address>
Reference: <author> Durfee, E. H., & Lesser, V. R. </author> <year> (1987). </year> <title> Using partial global plans to coordinate distributed problem solvers. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 875-883 Milan. </pages>
Reference: <author> Durfee, E. H., & Lesser, V. R. </author> <year> (1989). </year> <title> Negotiating task decomposition and allocation using partial global planning. </title> <editor> In Gasser, L., & Huhns, M. N. (Eds.), </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> Vol. II, </volume> <pages> pp. 229-243. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address> <note> 230 Mechanisms for Automated Negotiation Durfee, </note> <author> E. H., Lesser, V. R., & Corkill, D. D. </author> <year> (1987). </year> <title> Cooperation through communication in a distributed problem solving network. </title> <editor> In Huhns, M. N. (Ed.), </editor> <booktitle> Distributed Artificial Intelligence, chap. </booktitle> <volume> 2, </volume> <pages> pp. 29-58. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, California. </address>
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1991). </year> <title> The Clarke Tax as a consensus mechanism among automated agents. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 173-178 Anaheim, California. </address>
Reference-contexts: Other work that focuses on the organizational aspects of societies of agents exists (Fox, 1981; Malone, 1986). Ephrati and Rosenschein used the Clarke Tax voting procedure as a consensus mechanism, in essence to avoid the need for classical negotiation <ref> (Ephrati & Rosenschein, 1991, 1992c, 1993a) </ref>. The mechanism assumes the ability to transfer utility explicitly. The Clarke Tax technique assumes (and requires) that agents are able to transfer utility out of the system (taxes that are paid by the agents).
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1992a). </year> <title> Constrained intelligent action: Planning under the influence of a master agent. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 263-268 San Jose, California. </address>
Reference-contexts: In contrast, Multiagent System agents will cooperate only when it is in their best interests to do so (Genesereth, Ginsberg, & Rosenschein, 1986). Still another potential relationship among agents is a modified master-slave relationship, called a "supervisor-supervised" relationship, where non-absolute control is exerted by one agent over another <ref> (Ephrati & Rosenschein, 1992a, 1992b) </ref>. The synthesis, synchronization, or adjustment process for multiple agent plans thus constitute some of the (varied) foci of DAI planning research.
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1992b). </year> <title> Planning to please: Planning while constrained by a master agent. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 77-94 Glen Arbor, Michigan. </address>
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1992c). </year> <title> Reaching agreement through partial revelation of preferences. </title> <booktitle> In Proceedings of the Tenth European Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 229-233 Vienna, Austria. </address>
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1993a). </year> <title> Distributed consensus mechanisms for self-interested heterogeneous agents. </title> <booktitle> In First International Conference on Intelligent and Cooperative Information Systems, </booktitle> <pages> pp. 71-79 Rotterdam. </pages>
Reference: <author> Ephrati, E., & Rosenschein, J. S. </author> <year> (1993b). </year> <title> Multi-agent planning as a dynamic search for social consensus. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 423-429 Chambery, France. </address>
Reference-contexts: Synchronization through conflict avoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution of a single-agent planner among multiple agents (Corkill, 1979), the use of a centralized multiagent planner (Rosenschein, 223 Zlotkin & Rosenschein 1982), and the use of consensus mechanisms for aggregating subplans produced by multiple agents <ref> (Ephrati & Rosenschein, 1993b) </ref>, have all been explored, as well as related issues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b; Kreifelts & von Martial, 1991; Kamel & Syed, 1989; Grosz & Sidner, 1990; Kinny, Ljungberg, Rao, Sonenberg, Tidhar, & Werner, 1992; Ferber & Drogoul, 1992; Kosoresow, 1993).
Reference: <author> Etzioni, O. </author> <year> (1991). </year> <title> Embedding decision-analytic control in a learning architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 49, </volume> <pages> 129-159. </pages>
Reference-contexts: In certain work (Horvitz, 1988; Horvitz, Cooper, & Heck-erma, 1989; Russell & Wefald, 1989), decision-theoretic approaches are used to optimize the value of computation under uncertain and varying resource limitations. Etzioni considered using a decision-theoretic architecture, with learning capabilities, to control problem solving 225 Zlotkin & Rosenschein search <ref> (Etzioni, 1991) </ref>. For an introductory treatment of decision theory itself, see Raiffa's classic text on the subject (Raiffa, 1968). Classical decision theory research considers an agent that is "playing against nature," trying to maximize utility in uncertain circumstances.
Reference: <author> Ferber, J., & Drogoul, A. </author> <year> (1992). </year> <title> Using reactive multi-agent systems in simulation and problem solving. </title> <editor> In Avouris, N. M., & Gasser, L. (Eds.), </editor> <booktitle> Distributed Artificial Intelligence: Theory and Praxis, </booktitle> <pages> pp. 53-80. </pages> <publisher> Kluwer Academic Press. </publisher>
Reference: <author> Forges, F. </author> <year> (1993). </year> <title> Five legitimate definitions of correlated equilibrium in games with incomplete information. </title> <journal> Theory and Decision, </journal> <volume> 35, </volume> <pages> 277-310. </pages>
Reference-contexts: Aumann also showed (Aumann, 1987) that correlated equilibrium can be defined in terms of Bayesian rationality. Forges extended this approach to games with incomplete information <ref> (Forges, 1993) </ref>. Myerson showed that correlated equilibrium is a specific case of a more general concept of equilibrium, which he called communication equilibrium, in games with incomplete information (Myerson, 1982, 1991). Some of the deal types that we have defined above involve coin flipping.
Reference: <author> Fox, M. S. </author> <year> (1981). </year> <title> An organizational view of distributed systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-11 (1), </volume> <pages> 70-80. </pages>
Reference: <author> Fox, M. S., Allen, B., & Strohm, G. </author> <year> (1982). </year> <title> Job-shop scheduling: An investigation of constraint-directed reasoning. </title> <booktitle> In Proceedings of The National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 155-158 Pittsburgh, Pennsylvania. </address>
Reference: <author> Fudenberg, D., & Tirole, J. </author> <year> (1992). </year> <title> Game Theory. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mas-sachusetts. </address> <note> 231 Zlotkin & Rosenschein Gasser, </note> <author> L. </author> <year> (1991). </year> <title> Social conceptions of knowledge and action: DAI foundations and open systems semantics. </title> <journal> Artificial Intelligence, </journal> <volume> 47 (1-3), </volume> <pages> 107-138. </pages>
Reference: <author> Gasser, L. </author> <year> (1993). </year> <title> Social knowledge and social action. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 751-757 Chambery, France. </address>
Reference: <author> Genesereth, M. R., Ginsberg, M. L., & Rosenschein, J. S. </author> <year> (1986). </year> <title> Cooperation without communication. </title> <booktitle> In Proceedings of The National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 51-57 Philadelphia, Pennsylvania. </address>
Reference-contexts: In contrast, Multiagent System agents will cooperate only when it is in their best interests to do so <ref> (Genesereth, Ginsberg, & Rosenschein, 1986) </ref>. Still another potential relationship among agents is a modified master-slave relationship, called a "supervisor-supervised" relationship, where non-absolute control is exerted by one agent over another (Ephrati & Rosenschein, 1992a, 1992b).
Reference: <author> Georgeff, M. P. </author> <year> (1983). </year> <title> Communication and interaction in multi-agent planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 125-129 Washington, D.C. </address>
Reference: <author> Georgeff, M. P. </author> <year> (1984). </year> <title> A theory of action for multi-agent planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 121-125 Austin, Texas. </address>
Reference: <author> Georgeff, M. P. </author> <year> (1987). </year> <title> Actions, processes, and causality. </title> <editor> In Georgeff, M. P., & Lansky, A. L. (Eds.), </editor> <booktitle> Reasoning About Actions & Plans, </booktitle> <pages> pp. 99-122. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, California. </address>
Reference: <author> Georgeff, M. P., & Lansky, A. L. </author> <year> (1987). </year> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 677-682 Seatle, Washington. </address>
Reference: <author> Gmytrasiewicz, P. J., & Durfee, E. H. </author> <year> (1992). </year> <title> A logic of knowledge and belief for recursive modeling: Preliminary report. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 628-634 San Jose, California. </address>
Reference: <author> Gmytrasiewicz, P. J., & Durfee, E. H. </author> <year> (1993). </year> <title> Elements of a utilitarian theory of knowledge and action. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 396-402 Chambery, France. </address>
Reference: <author> Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. </author> <year> (1991a). </year> <title> A decision theoretic approach to coordinating multiagent interaction. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 62-68 Sydney, Australia. </address>
Reference: <author> Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. </author> <year> (1991b). </year> <title> The utility of communication in coordinating intelligent agents. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 166-172. </pages>
Reference: <author> Grosz, B. J., & Kraus, S. </author> <year> (1993). </year> <title> Collaborative plans for group activities. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 367-373 Chambery, France. </address>
Reference-contexts: Axiomatizations, however, might need to deal with how groups of agents could have a joint commitment to accomplishing some goal (Cohen & Levesque, 1991), or how each agent can make interpersonal commitments without the use of such notions <ref> (Grosz & Kraus, 1993) </ref>. Another use for the BDI abstractions is to allow one agent to reason about other agents, and relativize one's intentions in terms of beliefs about other agents' intentions or beliefs. Axiomatic approaches tend to closely link definitions of behavior with internal agent architecture.
Reference: <author> Grosz, B. J., & Sidner, C. </author> <year> (1990). </year> <title> Plans for discourse. </title> <editor> In Cohen, P. R., Morgan, J., & Pollack, M. E. (Eds.), </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference: <author> Gupta, N., & Nau, D. S. </author> <year> (1992). </year> <title> On the complexity of blocks-world planning. </title> <journal> Artificial Intelligence, </journal> <volume> 56 (2-3), </volume> <pages> 223-254. </pages> <note> 232 Mechanisms for Automated Negotiation Harsanyi, </note> <author> J. C. </author> <year> (1956). </year> <title> Approaches to the bargaining problem before and after the theory of games: a critical discussion of Zeuthen's, Hick's and Nash theories. </title> <journal> Econometrica, </journal> <pages> pp. 144-157. </pages>
Reference-contexts: In our husband/wife sharing one car example, however, the coordinated plan may be worse for one or both agents than their stand-alone plans. This is an example of one attribute of State Oriented Domains, namely negative interactions, or what are sometimes called 169 Zlotkin & Rosenschein "deleted-condition interactions" <ref> (Gupta & Nau, 1992) </ref>. This is because taking the car has the side effect of depriving the other agent of the car. Imagine a new situation, that arises during the weekend. The husband is interested in doing carpentry in the garage (currently occupied by the car). <p> This is an example of another typical attribute of State Oriented Domains|accidental achievement of goals, or "enabling-condition interactions" <ref> (Gupta & Nau, 1992) </ref> or "favor relations" (von Martial, 1990) among goals. When agents carry out a joint plan, each one plays some "role." Our theory assumes that there is some way of assessing the cost of each role.
Reference: <author> Horvitz, E., Cooper, G., & Heckerma, D. </author> <year> (1989). </year> <title> Reflection and action under scare resources: Theoretical principles and empirical study. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1121-1127 Detroit, Michigan. </address>
Reference: <author> Horvitz, E. J. </author> <year> (1988). </year> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 111-116. </pages>
Reference: <author> Hughes, G. E., & Cresswell, J. M. </author> <year> (1968). </year> <title> An Introduction to Modal Logic. </title> <publisher> Methuen and Co. Ltd. </publisher>
Reference: <author> Kamel, M., & Syed, A. </author> <year> (1989). </year> <title> An object-oriented multiple agent planning system. </title> <editor> In Gasser, L., & Huhns, M. N. (Eds.), </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> Volume II, </volume> <pages> pp. 259-290. </pages> <publisher> Pitman Publishing/Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Katz, M. J., & Rosenschein, J. S. </author> <year> (1993). </year> <title> Verifying plans for multiple agents. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 5, </volume> <pages> 39-56. </pages>
Reference: <author> Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. </author> <year> (1992). </year> <title> Planned team activity. </title> <booktitle> In Pre-Proceedings of the Fourth European Workshop on Modeling Autonomous Agents in a Multi-Agent World Rome, </booktitle> <address> Italy. </address>
Reference-contexts: Even when looking at multiagent systems, these researchers have examined how a member of a group should be designed|again, looking at how to design an individual agent so that it is a productive group member. For example, in certain work <ref> (Kinny et al., 1992) </ref> axioms are proposed that cause an agent, when he discovers that he will fail to fulfill his role in a joint plan, to notify the other members of his group.
Reference: <author> Kinny, D. N., & Georgeff, M. P. </author> <year> (1991). </year> <title> Commitment and effectiveness of situated agents. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 82-88 Sydney, Australia. </address>
Reference: <author> Konolige, K. </author> <year> (1982). </year> <title> A first-order formalization of knowledge and action for a multi-agent planning system. </title> <journal> Machine Intelligence, </journal> <volume> 10. </volume>
Reference: <author> Konolige, K. </author> <year> (1986). </year> <title> A Deduction Model of Belief. </title> <publisher> Pitman Publishers/Morgan Kaufmann, </publisher> <address> San Matheo, CA. </address>
Reference: <author> Konolige, K., & Nilsson, N. J. </author> <year> (1980). </year> <title> Multiple-agent planning systems. </title> <booktitle> In Proceedings of the First Annual National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 138-142 Stanford, California. </address>
Reference: <author> Kosoresow, A. P. </author> <year> (1993). </year> <title> A fast first-cut protocol for agent coordination. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 237-242 Washington, DC. </address>
Reference: <author> Kraus, S. </author> <year> (1993). </year> <title> Agents contracting tasks in non-collaborative environments. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 243-248. </pages>
Reference-contexts: Axiomatizations, however, might need to deal with how groups of agents could have a joint commitment to accomplishing some goal (Cohen & Levesque, 1991), or how each agent can make interpersonal commitments without the use of such notions <ref> (Grosz & Kraus, 1993) </ref>. Another use for the BDI abstractions is to allow one agent to reason about other agents, and relativize one's intentions in terms of beliefs about other agents' intentions or beliefs. Axiomatic approaches tend to closely link definitions of behavior with internal agent architecture.
Reference: <author> Kraus, S., Ephrati, E., & Lehmann, D. </author> <year> (1991). </year> <title> Negotiation in a non-cooperative environment. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 3 (4), </volume> <pages> 255-282. </pages> <note> 233 Zlotkin & Rosenschein Kraus, </note> <author> S., & Wilkenfeld, J. </author> <year> (1990). </year> <title> The function of time in cooperative negotiations: Extended abstract. </title> <booktitle> In Proceedings of the Tenth Workshop on Distributed Artificial Intelligence Bandera, </booktitle> <address> Texas. </address>
Reference-contexts: These negotiating procedures have included the exchange of Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), the communication of information intended to alter other agents' goals (Sycara, 1988, 1989), and the use of incremental suggestions leading to joint plans of action <ref> (Kraus & Wilkenfeld, 1991) </ref>. Interagent collaboration in Distributed Problem Solving systems has been explored in the ongoing research of Lesser, Durfee, and colleagues.
Reference: <author> Kraus, S., & Wilkenfeld, J. </author> <year> (1991). </year> <title> Negotiations over time in a multi-agent environment: Preliminary report. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 56-61 Sydney. </address>
Reference-contexts: These negotiating procedures have included the exchange of Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), the communication of information intended to alter other agents' goals (Sycara, 1988, 1989), and the use of incremental suggestions leading to joint plans of action <ref> (Kraus & Wilkenfeld, 1991) </ref>. Interagent collaboration in Distributed Problem Solving systems has been explored in the ongoing research of Lesser, Durfee, and colleagues.
Reference: <author> Kraus, S., Wilkenfeld, J., & Zlotkin, G. </author> <year> (1995). </year> <title> Multiagent negotiation under time constraints. </title> <journal> Artificial Intelligence, </journal> <volume> 75 (2), </volume> <pages> 297-345. </pages>
Reference: <author> Kreifelts, T., & von Martial, F. </author> <year> (1991). </year> <title> A negotiation framework for autonomous agents. </title> <editor> In Demazeau, Y., & Muller, J.-P. (Eds.), Decentralized A. I. </editor> <booktitle> 2, Proceedings of the Second European Workshop on Modelling Autonomous Agents in a Multi-Agent World, </booktitle> <pages> pp. 71-88. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> Kuwabara, K., & Lesser, V. R. </author> <year> (1989). </year> <title> Extended protocol for multistage negotiation. </title> <booktitle> In Proceedings of the Ninth Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pp. 129-161 Rosario, </pages> <address> Washington. </address>
Reference: <author> L^aasri, B., L^aasri, H., & Lesser, V. R. </author> <year> (1990). </year> <title> Negotiation and its role in cooperative distributed problem problem solving. </title> <booktitle> In Proceedings of the Tenth International Workshop on Distributed Artificial Intelligence Bandera, </booktitle> <address> Texas. </address> <note> Chapter 8. </note>
Reference: <author> Lesser, V. R., & Corkill, D. D. </author> <year> (1981). </year> <title> Functionally-accurate, cooperative distributed systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-11 (1), </volume> <pages> 81-96. </pages>
Reference: <author> Levesque, H. J., & Cohen, P. R. </author> <year> (1990). </year> <title> On acting together. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 94-99 Boston, Massachusetts. </address>
Reference: <author> Luce, R. D., & Raiffa, H. </author> <year> (1957). </year> <title> Games and Decisions. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York. </address>
Reference: <author> Malone, T. W. </author> <year> (1986). </year> <title> Organizing information processing systems: Parallels between human organizations and computer systems. </title> <editor> In Zacharai, W., Robertson, S., & Black, J. (Eds.), </editor> <title> Cognition, Computation, and Cooperation. </title> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, NJ. </address>
Reference: <author> Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. </author> <year> (1988). </year> <title> Enterprise: A market-like task scheduler for distributed computing environments. </title> <editor> In Huberman, B. A. (Ed.), </editor> <booktitle> The Ecology of Computation, </booktitle> <pages> pp. 177-205. </pages> <publisher> North-Holland Publishing Company, Amsterdam. </publisher>
Reference-contexts: Among the AI work is that of Smith's Contract Net (Smith, 1978, 1980; Sandholm, 1993), Malone's Enterprise system <ref> (Malone et al., 1988) </ref>, and Wellman's WALRAS system (Wellman, 1992). The Contract Net is a high-level communication protocol for a Distributed Problem Solving system. It enables the distribution of the tasks among the nodes that operate in the system. <p> A task that has been assigned to a node can be further decomposed by the contractor. A contract is established by a bidding scheme that includes the announcement of the task by the manager, and bids sent in by the potential contractors. Enterprise <ref> (Malone et al., 1988) </ref> is a system that was built using a variation of the Contract Net protocol. The Distributed Scheduling Protocol locates the best available machine to perform a task. This protocol is similar to the Contract Net, but makes use of more well-defined assignment criteria.
Reference: <author> McArthur, D., Steeb, R., & Cammarata, S. </author> <year> (1982). </year> <title> A framework for distributed problem solving. </title> <booktitle> In Proceedings of The National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 181-184 Pittsburgh, Pennsylvania. </address>
Reference: <author> Morgenstern, L. </author> <year> (1986). </year> <title> A first order theory of planning, knowledge, and action. </title> <editor> In Halpern, J. Y. (Ed.), </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pp. 99-114. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos. </address> <note> 234 Mechanisms for Automated Negotiation Morgenstern, </note> <author> L. </author> <year> (1987). </year> <title> Knowledge preconditions for actions and plans. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 867-874 Milan, Italy. </address>
Reference: <author> Morgenstern, L. </author> <year> (1990). </year> <title> A formal theory of multiple agent nonmonotonic reasoning. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 538-544 Boston, Massachusetts. </address>
Reference: <author> Moses, Y., & Tennenholtz, M. </author> <year> (1990). </year> <title> Artificial social systems part 1: Basic principles. </title> <type> Tech. rep. </type> <institution> CS90-12, Weizmann Institute. </institution>
Reference: <author> Moses, Y., & Tennenholtz, M. </author> <year> (1993). </year> <title> Off-line reasoning for on-line efficiency. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 490-495 Chambery, France. </address>
Reference: <author> Myerson, R. </author> <year> (1982). </year> <title> Optimal coordination mechanisms in generalized principal-agent problems. </title> <journal> Journal of Mathematical Economics, </journal> <volume> 10, </volume> <pages> 67-81. </pages>
Reference-contexts: Forges extended this approach to games with incomplete information (Forges, 1993). Myerson showed that correlated equilibrium is a specific case of a more general concept of equilibrium, which he called communication equilibrium, in games with incomplete information <ref> (Myerson, 1982, 1991) </ref>. Some of the deal types that we have defined above involve coin flipping. This is, of course, directly related to the notion of correlated strategies.
Reference: <author> Myerson, R. </author> <year> (1991). </year> <title> Game Theory: Analysis of Conflict. </title> <publisher> Harvard University Press, </publisher> <address> Cam-bridge, Massachusetts. </address>
Reference: <author> Nash, J. F. </author> <year> (1950). </year> <title> The bargaining problem. </title> <journal> Econometrica, </journal> <volume> 28, </volume> <pages> 155-162. </pages>
Reference-contexts: Nash <ref> (Nash, 1950, 1953) </ref> showed that under some rational behavior assumptions (i.e., individual rational and pareto optimal behavior), and symmetry assumptions, players will 219 Zlotkin & Rosenschein reach an agreement on a deal that maximizes the product of the players' utility (see Section 4.2 for a more complete discussion).
Reference: <author> Nash, J. F. </author> <year> (1953). </year> <title> Two-person cooperative games. </title> <journal> Econometrica, </journal> <volume> 21, </volume> <pages> 128-140. </pages>
Reference: <author> Osborne, M. J., & Rubinstein, A. </author> <year> (1990). </year> <title> Bargaining and Markets. </title> <publisher> Academic Press Inc., </publisher> <address> San Diego, California. </address>
Reference: <author> Pednault, E. P. D. </author> <year> (1987). </year> <title> Formulating multiagent dynamic-world problems in the classical planning framework. </title> <editor> In Georgeff, M. P., & Lansky, A. L. (Eds.), </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pp. </pages> <address> 47-82 San Mateo, California. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pollack, M. E. </author> <year> (1992). </year> <title> The uses of plans. </title> <journal> Artificial Intelligence, </journal> <volume> 57 (1). </volume>
Reference: <author> Pope, R. P., Conry, S. E., & Mayer, R. A. </author> <year> (1992). </year> <title> Distributing the planning process in a dynamic environment. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 317-331 Glen Arbor, Michigan. </address>
Reference: <author> Raiffa, H. </author> <year> (1968). </year> <title> Decision Analysis, Introductory Lectures on Choices under Uncertainty. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts. </address>
Reference-contexts: Etzioni considered using a decision-theoretic architecture, with learning capabilities, to control problem solving 225 Zlotkin & Rosenschein search (Etzioni, 1991). For an introductory treatment of decision theory itself, see Raiffa's classic text on the subject <ref> (Raiffa, 1968) </ref>. Classical decision theory research considers an agent that is "playing against nature," trying to maximize utility in uncertain circumstances. A key assumption is that "nature's" behavior is independent of the decision made by the agent. Of course, this assumption does not hold in a multiagent encounter.
Reference: <author> Raiffa, H. </author> <year> (1982). </year> <title> The Art and Science of Negotiation. </title> <publisher> The Belknap Press of Harvard University Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: in a market, while our work above deals with two-agent encounters; however, other work of ours deals with n-agent negotiation as a coalition formation problem (Zlotkin & Rosenschein, 1994). 9.2.6 Negotiation Negotiation has been a subject of central interest in DAI, as it has been in economics and political science <ref> (Raiffa, 1982) </ref>. The word has been used in a variety of ways, though in general it refers to communication processes that further coordination (Smith, 1978; Lesser & Corkill, 1981; Kuwabara & Lesser, 1989; Conry et al., 1988; Kreifelts & von Martial, 1991; Kraus, Ephrati, & Lehmann, 1991).
Reference: <author> Rao, A. S., & Georgeff, M. P. </author> <year> (1991). </year> <title> Asymmetry thesis and side-effect problems in linear-time and branching-time intention logics. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 498-504 Sydney, Australia. </address> <note> 235 Zlotkin & Rosenschein Rao, </note> <author> A. S., & Georgeff, M. P. </author> <year> (1993). </year> <title> A model-theoretic approach to the verification of situated reasoning systems. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 318-324 Chambery, France. </address>
Reference: <author> Rao, A. S., Georgeff, M. P., & Sonenberg, E. </author> <year> (1991). </year> <title> Social plans: a preliminary report. </title> <booktitle> In Pre-Proceedings of the Third European Workshop on Modeling Autonomous Agents and Multi-Agent Worlds Germany. </booktitle>
Reference: <author> Rasmusen, E. </author> <year> (1989). </year> <title> Games and Information, An Introduction to Game Theory. </title> <publisher> Basil Blackwell, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> Rosenschein, J. S. </author> <year> (1982). </year> <title> Synchronization of multi-agent plans. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 115-119 Pittsburgh, Pennsylvania. </address>
Reference-contexts: The synthesis, synchronization, or adjustment process for multiple agent plans thus constitute some of the (varied) foci of DAI planning research. Synchronization through conflict avoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution of a single-agent planner among multiple agents (Corkill, 1979), the use of a centralized multiagent planner <ref> (Rosenschein, 223 Zlotkin & Rosenschein 1982) </ref>, and the use of consensus mechanisms for aggregating subplans produced by multiple agents (Ephrati & Rosenschein, 1993b), have all been explored, as well as related issues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b; Kreifelts & von Martial, 1991; Kamel & Syed, 1989;
Reference: <author> Rosenschein, J. S. </author> <year> (1986). </year> <title> Rational Interaction: Cooperation Among Intelligent Agents. </title> <type> Ph.D. thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: In contrast, Multiagent System agents will cooperate only when it is in their best interests to do so <ref> (Genesereth, Ginsberg, & Rosenschein, 1986) </ref>. Still another potential relationship among agents is a modified master-slave relationship, called a "supervisor-supervised" relationship, where non-absolute control is exerted by one agent over another (Ephrati & Rosenschein, 1992a, 1992b).
Reference: <author> Rosenschein, J. S. </author> <year> (1993). </year> <title> Consenting agents: Negotiation mechanisms for multi-agent systems. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 792-799 Chambery, France. </address>
Reference: <author> Rosenschein, J. S., & Genesereth, M. R. </author> <year> (1985). </year> <title> Deals among rational agents. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 91-99 Los Angeles, California. </address>
Reference-contexts: Another important issue is the relationship that agents have to one another, e.g., the degree to which they are willing to compromise their goals for one another (assuming that such compromise is necessary). Benevolent Agents are those that, by design, are willing to accommodate one another <ref> (Rosenschein & Genesereth, 1985) </ref>; they have been built to be cooperative, to share information, and to coordinate in pursuit of some (at least implicit) notion of global utility.
Reference: <author> Roth, A. E. </author> <year> (1979). </year> <title> Axiomatic Models of Bargaining. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: The approach taken in this paper is, therefore, strongly based on previous work in game theory, primarily on what is known as "Nash's Bargaining Problem" (Nash, 1950; Luce & Raiffa, 1957) or "Nash's Model of Bargaining" <ref> (Roth, 1979) </ref>, "mechanism design" or "implementation theory" (Binmore, 1992; Fudenberg & Tirole, 1992), and "correlated equilibrium theory" (Aumann, 1974, 1987; Myerson, 1991; Forges, 1993).
Reference: <author> Rubinstein, A. </author> <year> (1982). </year> <title> Perfect equilibrium in a bargaining model. </title> <journal> Econometrica, </journal> <volume> 50 (1), </volume> <pages> 97-109. </pages>
Reference: <author> Rubinstein, A. </author> <year> (1985). </year> <title> Choice of conjectures in a bargaining game with incomplete information. </title> <editor> In Roth, A. E. (Ed.), </editor> <booktitle> Game-theoretic models of bargaining, </booktitle> <pages> pp. 99-114. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, New York. </address>
Reference: <author> Russell, S., & Wefald, E. </author> <year> (1989). </year> <booktitle> Principles of metareasoning. In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 400-411. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Sandholm, T. </author> <year> (1993). </year> <title> An implementation of the contract net protocol based on marginal calculations. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 256-262. </pages>
Reference: <author> Schelling, T. C. </author> <year> (1963). </year> <title> The Strategy of Conflict. </title> <publisher> Oxford University Press, </publisher> <address> New York. </address>
Reference-contexts: The simplest plan to achieve On (White; Gray) has the side effect of achieving Clear (Black). 1. For interesting discussions of the issue of conflict and its role in human encounters, see <ref> (Schelling, 1963, 1984) </ref>. Mechanisms for Automated Negotiation 2.3 Domain Definition Consider a group of agents who co-exist in some environment. Each agent has a goal that it is interested in achieving.
Reference: <author> Schelling, T. C. </author> <year> (1984). </year> <title> Choice and Consequence. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> Shoham, Y., & Tennenholtz, M. </author> <year> (1992a). </year> <title> Emergent conventions in multi-agent systems: initial experimental results and observations (preliminary report). </title> <booktitle> In Principles of knowledge representation and reasoning: Proceedings of the Third International Conference Cambridge, </booktitle> <address> Massachusetts. </address> <note> 236 Mechanisms for Automated Negotiation Shoham, </note> <author> Y., & Tennenholtz, M. </author> <year> (1992b). </year> <title> On the synthesis of useful social laws for artificial agent societies (preliminary report). </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence San Jose, </booktitle> <address> California. </address>
Reference: <author> Shoham, Y., & Tennenholtz, M. </author> <year> (1995). </year> <title> On social laws for artificial agent societies: Off-line design. </title> <journal> Artificial Intelligence. </journal> <note> To appear. </note>
Reference: <author> Smith, R. G. </author> <year> (1978). </year> <title> A Framework for Problem Solving in a Distributed Processing Environment. </title> <type> Ph.D. thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: Smith's Contract Net <ref> (Smith, 1978, 1980) </ref> falls into this category, as does other DAI work (Fox, Allen, & Strohm, 1982; Rosenschein, 1982; Pednault, 1987; Katz & Rosenschein, 1993).
Reference: <author> Smith, R. G. </author> <year> (1980). </year> <title> The contract net protocol: High-level communication and control in a distributed problem solver. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29 (12), </volume> <pages> 1104-1113. </pages>
Reference: <author> Steeb, R., Cammarata, S., Hayes-Roth, F., & Wesson, R. </author> <year> (1980). </year> <title> Distributed intelligence for air fleet control. </title> <type> Tech. rep. </type> <institution> WD-839-ARPA, The Rand Corporation. </institution>
Reference: <author> Stuart, C. J. </author> <year> (1985). </year> <title> An implementation of a multi-agent plan synchronizer. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1031-1035 Los Angeles, California. </address>
Reference: <author> Sycara, K. P. </author> <year> (1988). </year> <title> Resolving goal conflicts via negotiation. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 245-250 St. Paul, Minnesota. </address>
Reference-contexts: These negotiating procedures have included the exchange of Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), the communication of information intended to alter other agents' goals <ref> (Sycara, 1988, 1989) </ref>, and the use of incremental suggestions leading to joint plans of action (Kraus & Wilkenfeld, 1991). Interagent collaboration in Distributed Problem Solving systems has been explored in the ongoing research of Lesser, Durfee, and colleagues. <p> Sycara has examined a model of negotiation that combines case-based reasoning and optimization of multi-attribute utilities <ref> (Sycara, 1988, 1989) </ref>. In particular, while we assume that agents' goals are fixed during the negotiation, Sycara is specifically interested in how agents can influence one another to change their goals through a process of negotiation (information transfer, etc.).
Reference: <author> Sycara, K. P. </author> <year> (1989). </year> <title> Argumentation: Planning other agents' plans. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 517-523 Detroit. </address>

Reference: <author> Wellman, M. P. </author> <year> (1992). </year> <title> A general equilibrium approach to distributed transportation planning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence San Jose, </booktitle> <address> California. </address>
Reference-contexts: Among the AI work is that of Smith's Contract Net (Smith, 1978, 1980; Sandholm, 1993), Malone's Enterprise system (Malone et al., 1988), and Wellman's WALRAS system <ref> (Wellman, 1992) </ref>. The Contract Net is a high-level communication protocol for a Distributed Problem Solving system. It enables the distribution of the tasks among the nodes that operate in the system. <p> The Distributed Scheduling Protocol locates the best available machine to perform a task. This protocol is similar to the Contract Net, but makes use of more well-defined assignment criteria. Another system <ref> (Wellman, 1992) </ref> that takes an economic approach in solving a distributed problem through the use of a price mechanism has been explored by Wellman. Wellman uses the consumer/producer metaphor to establish a market pricing-based mechanism for task redistribution that ensures stability and efficiency.
Reference: <author> Zeuthen, F. </author> <year> (1930). </year> <title> Problems of Monopoly and Economic Walfare. </title> <editor> G. </editor> <publisher> Routledge & Sons, </publisher> <address> London. </address> <note> 237 Zlotkin & Rosenschein Zlotkin, </note> <author> G., & Rosenschein, J. S. </author> <year> (1989). </year> <title> Negotiation and task sharing among autonomous agents in cooperative domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 912-917 Detroit, Michigan. </address>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1990). </year> <title> Negotiation and conflict resolution in noncooperative domains. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 100-105 Boston, Massachusetts. </address>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1991a). </year> <title> Cooperation and conflict resolution via negotiation among autonomous agents in noncooperative domains. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21 (6), </volume> <pages> 1317-1324. </pages>
Reference-contexts: Before, we assumed (since we had a conflict situation) that the final state would be of no benefit to the agent that lost the coin toss. 4. An earlier version of this subsection and the next two appeared in <ref> (Zlotkin & Rosenschein, 1991a) </ref>. <p> Some material in this paper has appeared in preliminary form in AAAI, IJCAI, and ICICIS conference papers (Zlotkin & Rosenschein, 1990, 1991b; Rosenschein, 1993; Zlotkin & Rosenschein, 1993c) and in a journal article <ref> (Zlotkin & Rosenschein, 1991a) </ref> (earlier version of material on the UNP protocol). This research has been partially supported by the Israeli Ministry of Science and Technology (Grant 032-8284) and by the Israel Science Foundation (Grant 032-7517).
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1991b). </year> <title> Incomplete information and deception in multi-agent negotiation. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 225-231 Sydney, Australia. </address>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1991c). </year> <title> Negotiation and goal relaxation. </title> <editor> In Demazeau, Y., & Muller, J.-P. (Eds.), Decentralized A. I. </editor> <booktitle> 2, Proceedings of the Second European Workshop on Modelling Autonomous Agents in a Multi-Agent World, </booktitle> <pages> pp. 273-286. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: An agent will, at the conclusion of the joint plan, either achieve his goal or not achieve his goal. Goals cannot be partially achieved. Domains in which goals can be partially achieved are called Worth Oriented Domains (WODs) and are discussed in detail elsewhere <ref> (Zlotkin & Rosenschein, 1991c, 1996a) </ref>. One thing that we are specifically ruling out in SODs is one agent having a goal that makes reference to another agent's (as yet) unknown goal.
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1993a). </year> <title> A domain theory for task oriented negotiation. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 416-422 Chambery, France. </address>
Reference-contexts: We are not here examining the computational issues that arise in discovering such deals, though the design of efficient, possibly domain-specific, algorithms will constitute an important future phase of this research. Initial work in building a domain theory of negotiation was previously undertaken <ref> (Zlotkin & Rosenschein, 1993a) </ref>, and is expanded and generalized in the current paper.
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1993b). </year> <title> The extent of cooperation in state-oriented domains: Negotiation among tidy agents. </title> <journal> Computers and Artificial Intelligence, </journal> <volume> 12 (2), </volume> <pages> 105-122. </pages>
Reference-contexts: Utility of a deal for an agent was then the difference between the maximum cost he was willing to pay and the agent's part of the deal. When worth is unbounded, however, that linear transformation obviously cannot be used. In other work <ref> (Zlotkin & Rosenschein, 1993b) </ref>, we present an alternative baseline that can satisfy our desire for symmetry, fairness, simplicity, stability, and efficiency. It turns out to constitute the minimum sufficient baseline for agents to reach agreements. <p> We call an agent who is willing to clean up after himself a tidy agent; the formal definition appears elsewhere <ref> (Zlotkin & Rosenschein, 1993b) </ref>. It is shown that in any joint-goal reachable encounter (i.e., there exists a joint plan that achieves both agents' goals), if both agents are tidy, the negotiation set is not empty. 7.
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1993c). </year> <title> Negotiation with incomplete information about worth: Strict versus tolerant mechanisms. </title> <booktitle> In Proceedings of the First International Conference on Intelligent and Cooperative Information Systems, </booktitle> <pages> pp. </pages> <address> 175-184 Rotter-dam, The Netherlands. </address>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1994). </year> <title> Coalition, cryptography, and stability: Mechanisms for coalition formation in task oriented domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 432-437 Seattle, Washington. </address>
Reference-contexts: These plans that include a probabilistic component are called mixed joint plans. Throughout this paper, we limit the bulk of our discussion about mechanisms to two-agent encounters. Initial work on the generalization of these techniques to encounters among more than two agents can be found elsewhere <ref> (Zlotkin & Rosenschein, 1994) </ref>. That research considers issues of coalition formation in n-agent Task Oriented Domains. <p> Second, the economic models can deal with n agents in a market, while our work above deals with two-agent encounters; however, other work of ours deals with n-agent negotiation as a coalition formation problem <ref> (Zlotkin & Rosenschein, 1994) </ref>. 9.2.6 Negotiation Negotiation has been a subject of central interest in DAI, as it has been in economics and political science (Raiffa, 1982).
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1996a). </year> <title> Compromise in negotiation: Exploiting worth functions over states. </title> <journal> Artificial Intelligence, </journal> <volume> 84 (1-2), </volume> <pages> 151-176. </pages>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1996b). </year> <title> Mechanism design for automated negotiation, and its application to task oriented domains. </title> <journal> Artificial Intelligence. </journal> <note> To appear. 238 </note>
References-found: 120

