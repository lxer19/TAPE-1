URL: http://www.cs.washington.edu/research/projects/lis/oetools/www/papers/iccd93.ps
Refering-URL: http://www.cs.washington.edu/research/projects/lis/oetools/www/publications.html
Root-URL: http://www.cs.washington.edu
Title: An Algorithm for Exact Bounds on the Time Separation of Events in Concurrent Systems  
Author: Tod Amon, Henrik Hulgaard, Steven M. Burns, and Gaetano Borriello 
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Abstract: Determining the time separation of events is a fundamental problem in the analysis, synthesis, and optimization of concurrent systems. Applications range from logic optimization of asynchronous digital circuits to evaluation of execution times of programs for real-time systems. We present an efficient algorithm to find exact (tight) bounds on the separation time of events in an arbitrary process graph without conditional behavior. The algorithm is based on a functional decomposition technique that permits the implicit evaluation of an infinitely unfolded process graph. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: 5 summarizes the contributions of this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute [4, 10]; g repeat f Synchronize a; Compute <ref> [1, 2] </ref>; Synchronize b; Compute [1, 6]; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. <p> this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute [4, 10]; g repeat f Synchronize a; Compute [1, 2]; Synchronize b; Compute <ref> [1, 6] </ref>; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. The process graph for the system is shown in Figure 1. <p> We restrict our analysis to well-formed graphs, that is, graphs that are strongly-connected and have "(c) &gt; 0 for all cycles c in the graph, where "(c) is the sum of the " values for all edges in the cycle c. <ref> [1; 2] </ref> [1; 6] b. <p> We restrict our analysis to well-formed graphs, that is, graphs that are strongly-connected and have "(c) &gt; 0 for all cycles c in the graph, where "(c) is the sum of the " values for all edges in the cycle c. [1; 2] <ref> [1; 6] </ref> b. The number of lines drawn through an edge indicates the value of the occurrence index offset. 2.1 Execution Model We denote the k th occurrence of event v 2 E 0 as v k , and refer to k as the occurrence index of v k . <p> The coupling of the pipelines forces one pipeline to wait for the other if it gets too far ahead. a <ref> [1; 2] </ref> c b pipelines. All unspecified delay ranges are [0; 0]. <p> If = 6 then o (a ff ) o (a ff1 ) 8: 1 2 3 4 odd even 4 8 4 8 4 8 f e [; ] d c [3; 3] [3; 3] [3; 3] All unspecified delay ranges are <ref> [1; 1] </ref>. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] <ref> [1; 2] </ref> [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] <ref> [1; 2] </ref> [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] [1; 2] [1; 2] <ref> [1; 3] </ref> Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> Clearly, the startup rules can affect the initial timing behavior of the processes. However, this example demonstrates that the initial startup rules also can determine the maximum separation at every point in the infinite execution. We have two startup rules: root <ref> [ 1 ; 1 ] </ref> 7! b 0 and root [ 2 ; 2 ] 7! d 0 and they determine every ff for o (e ff ) o (a ff ): 0 3 2 1 0 As the process graph is a repetitive system, presumably the ff values will eventually <p> The elements of I, 0 and 1, are the identity elements for function maximization and composition, respectively. We have 0 = fh1; 1ig and 1 = fh0; 1ig (note that 0 is an annihilator for function composition). A matrix closure algorithm <ref> [1] </ref> can be used to compute S fl , the middle part of (6), because in this context, function maximization and composition form a closed semi-ring. This is the key observation that allows us to implicitly compute an infinite number of ff values.
Reference: [2] <author> T. Amon and G. Borriello. </author> <title> An approach to symbolic timing verification. </title> <booktitle> In 29th ACM/IEEE Design Automation Conference, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Loose bounds that may not enable all possible optimizations were obtained by [8]. Both [7] and [10] can only handle acyclic graphs, and <ref> [2] </ref> only supports a limited form of synchronization and concur-rency. This paper is composed of five sections. We follow this introduction with a formalization of the problem, a review of the foundation provided by the solution for finite acyclic graphs, and some examples. <p> 5 summarizes the contributions of this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute [4, 10]; g repeat f Synchronize a; Compute <ref> [1, 2] </ref>; Synchronize b; Compute [1, 6]; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. <p> We restrict our analysis to well-formed graphs, that is, graphs that are strongly-connected and have "(c) &gt; 0 for all cycles c in the graph, where "(c) is the sum of the " values for all edges in the cycle c. <ref> [1; 2] </ref> [1; 6] b. <p> The coupling of the pipelines forces one pipeline to wait for the other if it gets too far ahead. a <ref> [1; 2] </ref> c b pipelines. All unspecified delay ranges are [0; 0]. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] <ref> [1; 2] </ref> [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] <ref> [1; 2] </ref> [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> However, this example demonstrates that the initial startup rules also can determine the maximum separation at every point in the infinite execution. We have two startup rules: root [ 1 ; 1 ] 7! b 0 and root <ref> [ 2 ; 2 ] </ref> 7! d 0 and they determine every ff for o (e ff ) o (a ff ): 0 3 2 1 0 As the process graph is a repetitive system, presumably the ff values will eventually reach a steady state, for example, ff+1 = ff for
Reference: [3] <author> S. M. Burns. </author> <title> Performance Analysis and Optimization of Asynchronous Circuits. </title> <type> Ph.D. thesis, </type> <institution> California Institute of Technology, </institution> <year> 1991. </year> <month> CS-TR-91-1. </month>
Reference-contexts: The process graph for the system is shown in Figure 1. The initial state of the processes is specified by marking the edges that can execute initially. To formalize the problem we use a simple modification of the event-rule system developed in <ref> [3] </ref> 1 . Let G 0 = hE 0 ; R 0 i denote a process graph composed of ffi a finite set of (repeatable) events E 0 , the vertices of the graph. ffi a finite set of rule templates R 0 , the edges of the graph. <p> We root all of the initial occurrences at zero. If = 6 then o (a ff ) o (a ff1 ) 8: 1 2 3 4 odd even 4 8 4 8 4 8 f e [; ] d c <ref> [3; 3] </ref> [3; 3] [3; 3] All unspecified delay ranges are [1; 1]. <p> We root all of the initial occurrences at zero. If = 6 then o (a ff ) o (a ff1 ) 8: 1 2 3 4 odd even 4 8 4 8 4 8 f e [; ] d c <ref> [3; 3] </ref> [3; 3] [3; 3] All unspecified delay ranges are [1; 1]. <p> We root all of the initial occurrences at zero. If = 6 then o (a ff ) o (a ff1 ) 8: 1 2 3 4 odd even 4 8 4 8 4 8 f e [; ] d c <ref> [3; 3] </ref> [3; 3] [3; 3] All unspecified delay ranges are [1; 1]. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c [10; 10] [10; 10][5; 5] [1; 2] [1; 2] <ref> [1; 3] </ref> Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> The size of the representation of a particular function may be as large as the number of paths be tween the two events related by the function. Point 1 is potentially serious, however in most process graphs derived from circuits, " ? = 1 (see <ref> [3] </ref>). k ? is more of a concern because it can be large if there exists a cycle c such that d (c)="(c) is almost equal to r ? . Although of theoretical interest, point 2 is not likely to be of practical concern.
Reference: [4] <author> I. N. Herstein. </author> <title> Topics in Algebra. </title> <publisher> Blaisdell Publishing Company, </publisher> <year> 1964. </year>
Reference-contexts: are presented in Section 4, and finally, Section 5 summarizes the contributions of this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute <ref> [4, 10] </ref>; g repeat f Synchronize a; Compute [1, 2]; Synchronize b; Compute [1, 6]; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> Notice that we use left-to-right function composition <ref> [4] </ref>. <p> Thus, a simple upper bound on " ? is the least common multiple of "(c) for each maximum ratio cycle c. the process graph in Figure 1. Both k ? and " ? are values specific to a particular process graph. For example, changing the delays <ref> [4; 10] </ref> and [5; 20] to [999,1000] and [1000,1000], respectively, changes k ? from 3 to 998.
Reference: [5] <author> E. L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute [4, 10]; g repeat f Synchronize a; Compute [1, 2]; Synchronize b; Compute [1, 6]; g repeat f Synchronize b; Compute <ref> [5, 20] </ref>; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. The process graph for the system is shown in Figure 1. <p> The next section characterizes the be-havior of the m-values that allows us to utilize this decomposition effectively. 3.3 Repetition of the m-values Since the m-values are constructed from a repetitive system (the process graph) the values eventually are determined by the maximum ratio cycles in the process graph (see <ref> [5] </ref>). <p> Thus, a simple upper bound on " ? is the least common multiple of "(c) for each maximum ratio cycle c. the process graph in Figure 1. Both k ? and " ? are values specific to a particular process graph. For example, changing the delays [4; 10] and <ref> [5; 20] </ref> to [999,1000] and [1000,1000], respectively, changes k ? from 3 to 998.
Reference: [6] <author> A.J. Martin, S.M. Burns, T.K. Lee, D. Borkovic, and P.J. Hazewindus. </author> <title> The design of an asynchronous microprocessor. </title> <editor> In C.L. Seitz, editor, </editor> <booktitle> Advanced Research in VLSI: Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <pages> pages 351-373, </pages> <address> Cambridge, MA, 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute [4, 10]; g repeat f Synchronize a; Compute [1, 2]; Synchronize b; Compute <ref> [1, 6] </ref>; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. The process graph for the system is shown in Figure 1. <p> We restrict our analysis to well-formed graphs, that is, graphs that are strongly-connected and have "(c) &gt; 0 for all cycles c in the graph, where "(c) is the sum of the " values for all edges in the cycle c. [1; 2] <ref> [1; 6] </ref> b. The number of lines drawn through an edge indicates the value of the occurrence index offset. 2.1 Execution Model We denote the k th occurrence of event v 2 E 0 as v k , and refer to k as the occurrence index of v k . <p> Clearly, being able to obtain tight bounds potentially enables the removal of more edges. One of the examples in [8] is a memory management unit (MMU) designed to interface to the Cal-tech Asynchronous Microprocessor <ref> [6] </ref>. The process graph (for one of the possible execution modes of the MMU) consists of 16 events and 23 edges. For the chosen delay intervals, k ? = 1 and " ? = 1. <p> The analysis results in the removal of six edges from the process graph or equivalently, the removal of six transistors from the circuit. This is the same result as in [8]. 4.2 Asynchronous Microprocessor A subset of the Caltech Asynchronous Microprocessor <ref> [6] </ref> has been modelled and analyzed using the techniques described in this paper. The process graph for this simplified model consists of 60 events and 127 edges, and has " ? = 1 and k ? 3.
Reference: [7] <author> K. McMillan and D. L. Dill. </author> <title> Algorithms for interface timing verification. </title> <booktitle> In 1992 IEEE International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: Other approaches to the problem of finding bounds on the separation in time of two events have either been inexact or based on a more restrictive graph topology. Loose bounds that may not enable all possible optimizations were obtained by [8]. Both <ref> [7] </ref> and [10] can only handle acyclic graphs, and [2] only supports a limited form of synchronization and concur-rency. This paper is composed of five sections. <p> Thus, E = v k fi o [ frootg : The set R consists of the rules generated by instantiating each rule template of R 0 at each occurrence 1 [8] introduced a similarly modified system. The model can also be viewed as an extension of <ref> [7] </ref> and [10], where we consider cyclic max-only or type-2 graphs. 2 The occurrence index offset is used to specify how much the occurrence index is incremented when the edge is executed|see Section 2.1. index, R = u k" 7! v k fi [d;D];" oe Special startup rules are included in <p> problem of finding the maximum separation, since ffi can be obtained from o (s ff ) o (t ff (fi) ) ffi. 2.3 Algorithm for a Finite Unfolded Pro- cess Graph We build our solution to this problem on a variation of a graph algorithm developed by McMillan and Dill <ref> [7] </ref> that applies only to finite unfolded graphs. In Section 3 we will generalize this algorithm to infinite unfolded graphs.
Reference: [8] <author> C. Myers and T. H.-Y. Meng. </author> <title> Synthesis of timed asynchronous circuits. </title> <booktitle> In 1992 IEEE International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: Other approaches to the problem of finding bounds on the separation in time of two events have either been inexact or based on a more restrictive graph topology. Loose bounds that may not enable all possible optimizations were obtained by <ref> [8] </ref>. Both [7] and [10] can only handle acyclic graphs, and [2] only supports a limited form of synchronization and concur-rency. This paper is composed of five sections. <p> Thus, E = v k fi o [ frootg : The set R consists of the rules generated by instantiating each rule template of R 0 at each occurrence 1 <ref> [8] </ref> introduced a similarly modified system. <p> This idea can be used to remove redundant circuitry in asynchronous circuits given (conservative) bounds on the actual delays of a speed-independent design. Superfluous edges can be removed by analyzing the process graph corresponding to the circuit. This approach has been taken by Myers and Meng <ref> [8] </ref> who use an inexact timing analysis algorithm, i.e., the algorithm doesn't necessarily give tight bounds on separation times. Clearly, being able to obtain tight bounds potentially enables the removal of more edges. One of the examples in [8] is a memory management unit (MMU) designed to interface to the Cal-tech <p> This approach has been taken by Myers and Meng <ref> [8] </ref> who use an inexact timing analysis algorithm, i.e., the algorithm doesn't necessarily give tight bounds on separation times. Clearly, being able to obtain tight bounds potentially enables the removal of more edges. One of the examples in [8] is a memory management unit (MMU) designed to interface to the Cal-tech Asynchronous Microprocessor [6]. The process graph (for one of the possible execution modes of the MMU) consists of 16 events and 23 edges. For the chosen delay intervals, k ? = 1 and " ? = 1. <p> The analysis results in the removal of six edges from the process graph or equivalently, the removal of six transistors from the circuit. This is the same result as in <ref> [8] </ref>. 4.2 Asynchronous Microprocessor A subset of the Caltech Asynchronous Microprocessor [6] has been modelled and analyzed using the techniques described in this paper. The process graph for this simplified model consists of 60 events and 127 edges, and has " ? = 1 and k ? 3.
Reference: [9] <author> C.-Y. Park and A. C. Shaw. </author> <title> Experiments with a program timing tool based on source-level timing schema. </title> <journal> IEEE Computer, </journal> <volume> 25(5) </volume> <pages> 48-57, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: These and similar computations can be used to determine the real-time properties of the asynchronous microprocessor. For example, to bound the execution time of a code fragment, we can use the minimum and maximum separation in cycle period of each instruction type <ref> [9] </ref>.
Reference: [10] <author> P. Vanbekbergen, G. Goossens, and H. De Man. </author> <title> Specification and analysis of timing constraints in signal transition graphs. </title> <booktitle> In European Design Automation Conference, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Other approaches to the problem of finding bounds on the separation in time of two events have either been inexact or based on a more restrictive graph topology. Loose bounds that may not enable all possible optimizations were obtained by [8]. Both [7] and <ref> [10] </ref> can only handle acyclic graphs, and [2] only supports a limited form of synchronization and concur-rency. This paper is composed of five sections. We follow this introduction with a formalization of the problem, a review of the foundation provided by the solution for finite acyclic graphs, and some examples. <p> are presented in Section 4, and finally, Section 5 summarizes the contributions of this paper. 2 Problem Formalization Consider a simple concurrent system consisting of three processes that synchronize over two channels a and b, and do some internal computation (delay ranges specified in brackets): repeat f Synchronize a; Compute <ref> [4, 10] </ref>; g repeat f Synchronize a; Compute [1, 2]; Synchronize b; Compute [1, 6]; g repeat f Synchronize b; Compute [5, 20]; g We represent the system as a directed graph, called the process graph, where the vertices represent events (synchronizations) and the edges are annotated with delay information. <p> Thus, E = v k fi o [ frootg : The set R consists of the rules generated by instantiating each rule template of R 0 at each occurrence 1 [8] introduced a similarly modified system. The model can also be viewed as an extension of [7] and <ref> [10] </ref>, where we consider cyclic max-only or type-2 graphs. 2 The occurrence index offset is used to specify how much the occurrence index is incremented when the edge is executed|see Section 2.1. index, R = u k" 7! v k fi [d;D];" oe Special startup rules are included in the set <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> We call the infinite directed graph constructed from the vertex set E and the edge set R the unfolded process graph. Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> Figure 2 shows the unfolded process graph for the example in Figure 1. root a 0 a 1 a 2 a 3 [0, 0] <ref> [4, 10] </ref> [4, 10] [4, 10] [4, 10] [1,6][1,6][1,6] [1,6] the process graph in Figure 1. Two startup edges have been added, specifying that both a 0 and b 0 must occur after root . An execution of a process graph is the consistent assignment of time values to event occurrences. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c <ref> [10; 10] </ref> [10; 10][5; 5] [1; 2] [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> If we change = 9 then o (a ff ) o (a ff1 ) 9: 1 2 3 4 5 6 7 8 &gt;8 b d c <ref> [10; 10] </ref> [10; 10][5; 5] [1; 2] [1; 2] [1; 3] Our final example, in Figure 6, corresponds to two simple processes that synchronize at the event c. Clearly, the startup rules can affect the initial timing behavior of the processes. <p> Thus, a simple upper bound on " ? is the least common multiple of "(c) for each maximum ratio cycle c. the process graph in Figure 1. Both k ? and " ? are values specific to a particular process graph. For example, changing the delays <ref> [4; 10] </ref> and [5; 20] to [999,1000] and [1000,1000], respectively, changes k ? from 3 to 998.
References-found: 10

