URL: http://polaris.cs.uiuc.edu/reports/1338.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Restructuring Fortran Programs for Cedar  
Author: Rudolf Eigenmann, Jay Hoeflinger, Greg Jaxon, Zhiyuan Li, David Padua 
Address: Urbana, Illinois 61801  
Affiliation: Center for Supercomputing Research Development University of Illinois at Urbana-Champaign  
Abstract: This paper reports on the status of the Fortran translator for the Cedar computer at the end of March, 1991. A brief description of the Cedar Fortran language is followed by a discussion of the for-tran77 to Cedar Fortran parallelizer that describes the techniques currently being implemented. A collection of experiments illustrate the effectiveness of the current implementation, and point toward new ap proaches to be incorporated into the system in the near future.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: The parallel reduction transformation turned out to be important for the routines BDNA, DYFESM, MDG, MG3D, and SPEC77. In MDG, very little speedup is possible without it. 4.1.4 Generalized induction variables In Fortran DO loops, array subscripts often use the values of induction variables <ref> [1] </ref> which are updated in each iteration in the form of V = f (V, K), where the values produced by f are monotonically increasing (e.g. V = V + 1). Such a recursive assignment causes cross-iteration flow dependences.
Reference: [2] <author> William Blume and Rudolf Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks TM Programs. </title> <journal> IEEE Transactions of Parallel and Distributed Systems, </journal> <month> November </month> <year> 1992. </year>
Reference-contexts: We modified KAP, as discussed in Section 3, to take into account those architectural characteristics of Cedar that distinguish it from other shared-memory multiprocessors. As discussed in Section 4, we are in the process of evaluating the present version of the parallelizer <ref> [2] </ref> and studying approaches to make it more effective.
Reference: [3] <author> M. Booth and K. Misegades. </author> <title> Microtasking: A New Way to Harness Multiprocessors. </title> <journal> Cray Channels, </journal> <pages> pages 24-27, </pages> <year> 1986. </year>
Reference-contexts: The Cedar Fortran language is fully described in [16]. 6 2.2 Implementing Cedar Fortran on Cedar 2.2.1 Parallel loops The parallel loops of Cedar Fortran are all self-scheduled, by default, through a technique called microtasking <ref> [3] </ref>. CDO loops use microtasking supported by special concurrency hardware within the Alliant FX/8. This hardware is used for dispatching iterations of CDO loops and for synchronizing between iterations of CDOACROSS loops. SDOALL and XDOALL loops use microtasking supported by the Cedar Fortran runtime library.
Reference: [4] <author> David Callahan and Ken Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2(2) </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: On one cluster the speed is less than the global-data version, but then it achieves a near-linear speedup through four clusters. We intend to implement some data partitioning scheme in our compiler. This area of research is not mature and the practical value of proposed techniques is yet unclear <ref> [4, 9, 29, 11] </ref>. More experiments are needed. We have found that the Cedar architecture is a useful testbed for this purpose. It allows us to combine shared-memory and distributed-memory programming schemes.
Reference: [5] <author> S. C. Chen and D. J. Kuck. </author> <title> Time and Parallel Processor Bounds for Linear Recurrence Systems. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-24(7):701-717, </volume> <month> July, </month> <year> 1975. </year>
Reference-contexts: The payoff comes from the wealth of algebraic and programming insight that library authors use to reduce operation counts and memory references <ref> [5, 8] </ref>. Loops where different iterations may use the same storage cell can usually be concurrentized as DOACROSS loops. Uses of the shared location (s) are serialized by the await and advance functions in the concurrency control hardware, while the rest of the loop executes in parallel.
Reference: [6] <author> Rudolf Eigenmann. </author> <title> Towards a methodology of optimizing programs for high-performance computers. </title> <type> Technical Report 1178, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomp. R&D, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: The methodology we used, in general, was to present the original serial programs to the restructurer, then hand-modify the resulting parallelized form. We built many tools to assist us in this very time-consuming and tedious work. Some of them are described in <ref> [6, 14] </ref>. Preliminary results from our experiment are encouraging.
Reference: [7] <author> Rudolf Eigenmann, Jay Hoeflinger, Zhiyuan Li, and David Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> 23 Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: This section is divided into two parts. In the first part we study the general ability of the restructurer to detect parallelism. This is a summary of work we have reported in <ref> [7] </ref>, plus some new results. The transformations in this part are suitable for any parallel machine. <p> Analyzing the restructured codes by hand, we have found that many of the difficulties result from the general weakness of the existing restructuring technology and not from the target architecture or the algorithms used. In our hand analysis <ref> [7] </ref>, we examined the loops of the restructured program.
Reference: [8] <author> K. A. Gallivan, R. J. Plemmons, and A. H. Sameh. </author> <title> Parallel Algorithms for Dense Linear Algebra Computations. </title> <journal> SIAM Review, </journal> <volume> 32(1) </volume> <pages> 54-135, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The payoff comes from the wealth of algebraic and programming insight that library authors use to reduce operation counts and memory references <ref> [5, 8] </ref>. Loops where different iterations may use the same storage cell can usually be concurrentized as DOACROSS loops. Uses of the shared location (s) are serialized by the await and advance functions in the concurrency control hardware, while the rest of the loop executes in parallel.
Reference: [9] <author> Kyle Gallivan, William Jalby, and Dennis Gannon. </author> <title> On the problem of optimizing data transfers for complex memory systems. </title> <booktitle> Proc. of 1988 Int'l. Conf. on Supercomputing, </booktitle> <address> St. Malo, France, </address> <pages> pages 238-253, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: On one cluster the speed is less than the global-data version, but then it achieves a near-linear speedup through four clusters. We intend to implement some data partitioning scheme in our compiler. This area of research is not mature and the practical value of proposed techniques is yet unclear <ref> [4, 9, 29, 11] </ref>. More experiments are needed. We have found that the Cedar architecture is a useful testbed for this purpose. It allows us to combine shared-memory and distributed-memory programming schemes.
Reference: [10] <author> Edward H. Gornish, Elana D. Granston, and Alexander V. Veidenbaum. </author> <title> Compiler-directed Data Prefetching in Multiprocessors with Memory Hierarchies . Proceedings of ICS'90, </title> <booktitle> Amsterdam, The Netherlands, </booktitle> <volume> 1 </volume> <pages> 342-353, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: There are many additional issues related to prefetching that we plan to study in the near future. For example, what is the effect of an aggressive floating of prefetching instructions <ref> [10] </ref>? The strategy used today in the Cedar Fortran compiler is to generate prefetch code to precede each vector register load from global memory without any code motion optimizations. 4.2.2 Data privatization Prefetching data reduces the latency for reading global data, but the latency still exists.
Reference: [11] <author> M. Gupta and P. Banerjee. </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 179-193, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: On one cluster the speed is less than the global-data version, but then it achieves a near-linear speedup through four clusters. We intend to implement some data partitioning scheme in our compiler. This area of research is not mature and the practical value of proposed techniques is yet unclear <ref> [4, 9, 29, 11] </ref>. More experiments are needed. We have found that the Cedar architecture is a useful testbed for this purpose. It allows us to combine shared-memory and distributed-memory programming schemes.
Reference: [12] <author> Mark D. Guzzi, David A. Padua, Jay P. Hoeflinger, and Duncan H. Lawrie. </author> <title> Cedar Fortran and other vector and parallel Fortran dialects. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 37-62, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The result is a language with minor syntactic extensions to fortran77, yet with the expressive power to make full use of the architectural features of the Cedar machine <ref> [12] </ref>. Cedar Fortran has many features in common with the ANSI Technical Committee X3H5 standard for parallel Fortran (whose basis was PCF Fortran, developed by the Parallel Computing Forum), including parallel loops, loop-local data declarations, declarations for the visibility of data, and constructs to support post/wait synchronization.
Reference: [13] <author> W. Ludwell Harrison, III and David Padua. </author> <title> PARCEL: Project for the Automatic Restructuring and Concurrent Evaluation of Lisp. </title> <booktitle> Proceedings of 1988 Int'l. Conf. on Supercomputing, </booktitle> <address> St. Malo, France, </address> <pages> pages 527-538, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Therefore, some effort has been devoted to the implementation and study of the behavior of parallel symbolic programs and more work in this area is planned. To support this effort we are developing parallelizing compilers for symbolic computing languages such as LISP <ref> [13] </ref> and PROLOG, as well as for C. Our Fortran translation system, which is shown in Figure 2, consists of two components.
Reference: [14] <author> Jay Hoeflinger. </author> <title> Interval libraries for program analysis. </title> <type> Technical Report 1224, </type> <institution> Center for Supercomputing Research and Development, </institution> <year> 1992. </year>
Reference-contexts: The methodology we used, in general, was to present the original serial programs to the restructurer, then hand-modify the resulting parallelized form. We built many tools to assist us in this very time-consuming and tedious work. Some of them are described in <ref> [6, 14] </ref>. Preliminary results from our experiment are encouraging.
Reference: [15] <author> Jay Hoeflinger. </author> <title> Run-time dependence testing by integer sequence analysis. </title> <type> Technical Report 1194, </type> <institution> Center for Supercomputing Research and Development, </institution> <year> 1992. </year>
Reference-contexts: The test determines whether the indicated array is being indexed in a way which makes it a linearized version of a multi-dimensional array <ref> [15] </ref>.
Reference: [16] <author> Jay Hoeflinger. </author> <title> Cedar Fortran Programmer's Handbook. </title> <type> Technical report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> October </month> <year> 1991. </year> <note> CSRD Report No. 1157. </note>
Reference-contexts: The CLUSTER and COMMON statements declare data that is visible to all processors on a single cluster. A separate copy of this data exists in each cluster participating in the execution of the program. The Cedar Fortran language is fully described in <ref> [16] </ref>. 6 2.2 Implementing Cedar Fortran on Cedar 2.2.1 Parallel loops The parallel loops of Cedar Fortran are all self-scheduled, by default, through a technique called microtasking [3]. CDO loops use microtasking supported by special concurrency hardware within the Alliant FX/8.
Reference: [17] <author> Christopher Alan Huson. </author> <title> An In-Line Subroutine Expander for Parafrase. </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Sci., </institution> <month> Dec., </month> <year> 1982. </year>
Reference-contexts: The rest of this section discusses some of the techniques we applied by hand to obtain the improved performance shown in Table 2. We believe that most of these techniques can be automated. 4.1.1 Compiling in the presence of interprocedural information Our compiler currently relies on inlining <ref> [17] </ref> for interprocedural analysis. Inlining replaces call statements with the text of the called subroutine. However, in many of the Perfect programs, inlining fails. Sometimes subroutine calls are so deeply nested that inlining causes the compiler to run out of memory for its data structures.
Reference: [18] <author> International Business Machines Corporation. </author> <title> Parallel FORTRAN: Language and Library Reference, </title> <year> 1988. </year> <month> SC23-0431-0. </month>
Reference-contexts: This hardware is used for dispatching iterations of CDO loops and for synchronizing between iterations of CDOACROSS loops. SDOALL and XDOALL loops use microtasking supported by the Cedar Fortran runtime library. The library starts a requested number of helper tasks ("implicit tasks" in IBM terminology <ref> [18] </ref>) which remain idle until an SDOALL or XDOALL loop starts. At that time, the helper tasks begin competing with the main task for iterations of the loop. 2.2.2 Tasking Subroutine-level tasking is also supported by the Cedar Fortran runtime library.
Reference: [19] <author> William Jalby, </author> <year> 1991. </year> <title> Private communication. </title>
Reference-contexts: The fusion of the outer loops (variant c) was made possible by replicating the code between the original outer loops on all clusters, adding redundant computations to the program. This technique has been applied successfully in other areas of the code, as well <ref> [19] </ref>. The parallel loops were stripmined into CDOALL / vector loops for the Alliant FX/80 and into SDOALL / CDOALL / vector loops for Cedar.
Reference: [20] <institution> Kuck & Associates, Inc., Champaign, Illinois. </institution> <note> KAP User's Guide, 1988. 24 </note>
Reference-contexts: Some are embedded within machine-specific compilers whereas others, notably VAST from Pacific Sierra Research, and KAP from Kuck & Associates, Inc. <ref> [20] </ref>, are machine independent and have been targeted for many different machines. These parallelizers convert sequential programs into vector/concurrent code that in some cases runs significantly faster than the original version.
Reference: [21] <author> D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence Graphs and Compiler Optimizations. </title> <booktitle> Proceedings of the 8th ACM Symp. on Principles of Programming Languages (POPL), </booktitle> <pages> pages 207-218, </pages> <month> Jan., </month> <year> 1981. </year>
Reference-contexts: The back-end compiler generates 7 a prefetch instruction for 32 elements before each vector register load instruction whose source is in global memory. 3 Automatic Parallelization More than two decades of research in parallelization <ref> [21, 25] </ref> have produced many commercially available parallelizers. Some are embedded within machine-specific compilers whereas others, notably VAST from Pacific Sierra Research, and KAP from Kuck & Associates, Inc. [20], are machine independent and have been targeted for many different machines.
Reference: [22] <author> David B. Loveman. </author> <title> Program Improvement by Source-to-Source Transformation. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 121-145, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: In order to exploit all levels of parallelism in Cedar, the iteration space may be strip-mined <ref> [22, 25] </ref> so that in each iteration a separate strip of data is processed in vector form.
Reference: [23] <author> Ulrike Meier and Rudolf Eigenmann. </author> <title> Parallelization and Performance of Conjugate Gradient Algorithms on the Cedar Hierarchical-Memory Multiprocessor. </title> <booktitle> Proceedings of the 3rd ACM Sigplan Symp. on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <pages> pages 178-188, </pages> <month> April 21-24, </month> <year> 1991. </year>
Reference-contexts: For example, a dot product can be distributed to all Cedar processors, its partial results being summed up in two steps: within each cluster, then across the clusters. When a parallel dotproduct routine was used in the Conjugate Gradient algorithm <ref> [23] </ref>, it cut the execution time of the whole program in half compared to the version of the program that used dotproduct vectorized on one processor only. <p> The initial results were encouraging. Table 1 shows the speedup results for a set of linear algebra routines. The first routine is a conjugate gradient algorithm <ref> [23] </ref>; the other routines are from Numerical Recipes [27]. The data size shown in the second column in most cases represents the number of rows and columns of the input matrices. <p> In Cedar Fortran a natural program entity that refers to a block of data is the vector operation. Section 2.2.3 described how the compiler inserts prefetch instructions for vector operations. Figure 6 shows the effects of this optimization in two programs, the Conjugate Gradient (CG) Algorithm <ref> [23] </ref> and the Perfect code TRFD. Although there is an improvement of up to 100% in CG, TRFD exhibits only a 15% gain, primarily because vector lengths are large in CG and small in TRFD.
Reference: [24] <author> Samuel Midkiff and David Padua. </author> <title> Compiler Algorithms for Synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1485-1495, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Uses of the shared location (s) are serialized by the await and advance functions in the concurrency control hardware, while the rest of the loop executes in parallel. The Cedar restructurer inserts the smallest set of synchronization instructions that will suffice <ref> [24] </ref>. When considering a DOACROSS loop version, the restructurer lowers its estimate of the benefit owing to parallel execution by a synchronization delay factor.
Reference: [25] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced Compiler Optimizations for Supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: The back-end compiler generates 7 a prefetch instruction for 32 elements before each vector register load instruction whose source is in global memory. 3 Automatic Parallelization More than two decades of research in parallelization <ref> [21, 25] </ref> have produced many commercially available parallelizers. Some are embedded within machine-specific compilers whereas others, notably VAST from Pacific Sierra Research, and KAP from Kuck & Associates, Inc. [20], are machine independent and have been targeted for many different machines. <p> In order to exploit all levels of parallelism in Cedar, the iteration space may be strip-mined <ref> [22, 25] </ref> so that in each iteration a separate strip of data is processed in vector form.
Reference: [26] <author> M. Berry; D. Chen; P. Koss; D. Kuck; L. Pointer, S. Lo; Y. Pang; R. Roloff; A. Sameh; E. Clementi, S. Chin; D. Schneider; G. Fox; P. Messina; D. Walker, C. Hsiung; J. Schwarzmeier; K. Lue; S. Orszag; F. Seidl, O. Johnson; G. Swan-son; R. Goodrum, and J. Martin. </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers. </title> <booktitle> Int'l. Journal of Supercomputer Applications, Fall 1989, </booktitle> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: number of near-optimal ones; this should allow us to keep the heuristics simple and still be confident of finding a good translation of a loop. 4 Experiments In this section we discuss some of the experience we have accumulated in the automatic parallelization of the Perfect Benchmarks R fl programs <ref> [26] </ref> and some linear algebra routines from Numerical Recipes [27].
Reference: [27] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vet-terling. </author> <title> Numerical Recipes: The Art of Scientific Computing (FORTRAN Version). </title> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: keep the heuristics simple and still be confident of finding a good translation of a loop. 4 Experiments In this section we discuss some of the experience we have accumulated in the automatic parallelization of the Perfect Benchmarks R fl programs [26] and some linear algebra routines from Numerical Recipes <ref> [27] </ref>. The work reported below is part of an ongoing study whose goal is to learn about the limitations of the current version of the parallelizer as well as to develop new automatic techniques that, once incorporated in the parallelizer, would overcome these limitations. <p> The initial results were encouraging. Table 1 shows the speedup results for a set of linear algebra routines. The first routine is a conjugate gradient algorithm [23]; the other routines are from Numerical Recipes <ref> [27] </ref>. The data size shown in the second column in most cases represents the number of rows and columns of the input matrices. The speedup values refer to the increase in speed of the parallelized version run on Cedar versus the serial (scalar) form.
Reference: [28] <author> Michael J. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <type> PhD thesis, </type> <institution> University of Illinois, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: Privatization is related to scalar expansion <ref> [28] </ref> which expands a scalar into an array if all references to the scalar in iteration i of the loop can be replaced by references to the i th element of the array. Privatizing expands the storage for the scalar to one cell per processor.
Reference: [29] <author> Hans P. Zima and Michael Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year> <month> 25 </month>
Reference-contexts: On one cluster the speed is less than the global-data version, but then it achieves a near-linear speedup through four clusters. We intend to implement some data partitioning scheme in our compiler. This area of research is not mature and the practical value of proposed techniques is yet unclear <ref> [4, 9, 29, 11] </ref>. More experiments are needed. We have found that the Cedar architecture is a useful testbed for this purpose. It allows us to combine shared-memory and distributed-memory programming schemes.
References-found: 29

