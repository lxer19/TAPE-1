URL: http://www.isi.edu/teamcore/tambe/papers/93/mask-final.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Email: e-mail: tambe@cs.cmu.edu e-mail: rosenbloom@isi.edu  
Title: On the Masking Effect provide a solution, the problem-solver may miss an Abstract alternative solution
Author: Milind Tambe Paul S. Rosenbloom 
Note: involves  Knowledge-compilation  However, by relying on its learned knowledge to This  it is referred to as Einstellung (Luchins, 1942). Modeling  
Address: 5000 Forbes Avenue  Pittsburgh, Pa 15213 4676 Admiralty Way Marina del Rey, CA 90292  
Affiliation: School of Computer Science Information Sciences Institute Carnegie Mellon University Computer Science Department  University of Southern California  
Abstract: problem-solving knowledge. For instance, in a planning improve the performance of problem-solvers by storing solutions to previously solved problems in an efficient, domain, the problem-solver may miss the derivation of a generalized form. The problem-solver retrieves these learned higher-quality plan, if a lower-quality plan has been solutions in appropriate later situations to obtain results more learned earlier. The following example from the efficiently. However, by relying on its learned knowledge to Groundworld domain (Stobie et al., 1992) illustrates this provide a solution, the problem-solver may miss an alternative agent simulation domain in which both space and time are using the original (non-learned) problem-solving knowledge. represented as continuous quantities. The principal This phenomenon is referred to as the masking effect of learning. features in this world are walls, which block both In this paper, we examine a sequence of possible solutions for movement and vision. Currently, our task in Groundworld the masking effect. Each solution refines and builds on the The evasion agent's task is to reach its destination from When learned knowledge is retrieved, these filters alert the its starting point, without getting caught by the pursuit system about the inappropriateness of this knowledge so that the agent, and to do so as quickly as possible. The pursuit system can then derive a better alternative solution. We analyze agent's task is to catch the evasion agent. Both agents conditions under which this solution will perform better than the have a limited range of vision. When the two agents are in others, and present experimental data supportive of the analysis. This investigation is based on a simulated robot domain called visual range, the pursuit agent starts chasing, while the 1 Groundworld. evasion agent attempts to escape by hiding behind some wall, from where it replans to reach its destination. 1. Introduction problem-solvers/planners by utilizing their past Here, the two agents are within visual range. To avoid experiences. Some examples of these knowledge- capture, the evasion agent uses a map to create a plan compilation techniques are explanation-based (shown by dashed lines) to hide behind a wall. The plan generalization (EBG/EBL) (DeJong and Mooney, 1986, is stored in learned rules, to be retrieved and reused in Mitchell, Keller, and Kedar-Cabelli, 1986), chunking similar later situations. The situation in Figure 1-1-b is (Laird, Rosenbloom, and Newell, 1986a), production similar and the learned rules directly provide a plan to the composition (Anderson, 1983, Lewis, 1978), macro- hiding spot. However, by relying on these learned rules, operator learning (Fikes, Hart, and Nilsson, 1972, Shell the evasion agent misses a closer hiding spot (denoted by and Carbonell, 1989), and analogical and case-based X). If the evasion agent had confronted the problem in reasoning (Carbonell, 1986, Hammond, 1986). These Figure 1-1-b without its previously learned rules, it would techniques store experiences from previously solved have planned a path to the closer hiding spot. However, problems in an efficient, generalized form. The problem- due to its learned rules, the evasion agent follows a low solver then retrieves these learned experiences in quality plan. While the lower-quality plan allows it to appropriate later situations so as to obtain results more hide successfully, there is a significant delay in its hiding, efficiently, and thus improve its performance. which in turn delays it in reaching its real destination. 1 Einstellung in computer simulations is an important This research was supported under subcontract to Carnegie Mellon University and the University of Southern California from the University of Michigan as part of aspect of capturing human skill acquisition (Lewis, 1978). contract N00014-92-K-2015 from the Defense Advanced Research Projects Agency More recently, Clarke and Holte (Clark and Holte, 1992) (DARPA) and the Naval Research Laboratory (NRL). The Groundworld simulator report this effect in the context of a Prolog/EBG system, used in this paper was developed by Charles Dolan of Hughes AI center. The simulated robots in Groundworld were developed in collaboration with Iain Stobie of where they call it the masking effect, because the learned the University of Southern California. phenomenon. Groundworld is a two-dimensional, multi-solution of higher quality one that could have been generated
Abstract-found: 1
Intro-found: 1
Reference: <institution> ii </institution>
References-found: 1

