URL: http://pine.cs.yale.edu:4201/home/dagstuhl96.ps
Refering-URL: http://pine.cs.yale.edu:4201/home/dagstuhl96-abstract.html
Root-URL: http://www.cs.yale.edu
Title: Competitive Analysis of Distributed Algorithms  
Author: James Aspnes 
Affiliation: Yale University, Department of Computer Science  
Abstract: Most applications of competitive analysis have involved online problems where a candidate on-line algorithm must compete on some input sequence against an optimal off-line algorithm that can in effect predict future inputs. Efforts to apply competitive analysis to fault-tolerant distributed algorithms require accounting for not only this input nondeterminism but also system nondeterminism that arises in distributed systems prone to asynchrony and failures. This paper surveys recent efforts to adapt competitive analysis to distributed systems, and suggests how these adaptations might in turn be useful in analyzing a wider variety of systems. These include tools for building competitive algorithms by composition, and for obtaining more meaningful competitive ratios by limiting the knowledge of the off-line algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [AADW94] <author> M. Ajtai, J. Aspnes, C. Dwork, and O. Waarts. </author> <title> A theory of competitive analysis for distributed algorithms. </title> <booktitle> In Proc. 35th Symp. of Foundations of Computer Science, </booktitle> <pages> pages 401-411, </pages> <year> 1994. </year>
Reference-contexts: An algorithm A is traditionally k-competitive if there exists a constant c such that for all A fl in A, I in I, and E in E , cost (A; I; E) k cost (A fl ; I; E) + c: 2 These terms were suggested by <ref> [AADW94] </ref>. Worst-Case vs. Best-Case Inputs. A more useful measure arises if one assumes that the inputs are not shared between the candidate and the champion. <p> Section 6.3 discusses why competitiveness is a useful tool for analyzing the performance of collect algorithms. The following sections describe how it has been applied to such algorithms and the consequences of doing so. Some of the material in theses sections is adapted from <ref> [AADW94] </ref>, [AW96], and [AH96]. 6.1 Collects: A Fundamental Problem When a process starts a task in the wait-free model, it has no means of knowing what has happened in the system since it last woke up. <p> Without the single-writer restriction, the one-shot collect would be isomorphic to the problem of Certified Write-All, in which n processes have to write to n locations while individually being able to certify that all writes have occurred (indeed, the collect algorithm of Ajtai et al. <ref> [AADW94] </ref> is largely based on a Certified Write-All algorithm of Anderson and Woll [AW91]). <p> The repeated collect problem appears at the heart of a wide variety of shared-memory distributed algorithms (an extensive list is given in <ref> [AADW94] </ref>). What makes it appealing as a target for competitive analysis is that the worst-case performance of any repeated collect algorithm is never better than that of the naive algorithm. The reason for this is the strong assumptions about scheduling. <p> Update T to include the most recent timestamps for each process. Set p to the successor field. fl Write out the new S and T . ReturnS. Fig. 2. Repeated Collect Algorithm The performance of this algorithm is characterized by its collective latency <ref> [AADW94] </ref>, an upper bound on the total amount of work needed to complete all collects in progress at some time t: 4 Theorem 5. Fix a starting time t. Fix 9. <p> Neither difficulty is impossible to overcome. In the following sections we describe two measures of competitive performance for distributed algorithms that do so. 6.4 A Traditional Approach: Latency Competitiveness The competitive latency model of Ajtai et al. <ref> [AADW94] </ref> uses competitive analysis in its traditional form, in which all nondeterminism in a system is under the control of the adversary and is shared between both the candidate and champion algorithms. <p> Though this result is stated only for deterministic algorithms, as observed in [AH96] it can be made to apply equally well to randomized algorithms given a bound L on the expected collective latency. The essential idea of the proof in <ref> [AADW94] </ref> of the relationship between collective latency and competitive latency is to divide an execution into segments and show that for each such segment, the candidate algorithm carries out at most L + n operations and the champion carries out at least n operations. <p> It is worth noting that this result is very strong; it holds even against an adaptive off-line adversary [BDBK + 90], which is allowed to choose the champion algorithm after seeing a complete execution of the candidate. In contrast, the best known lower bound is (log n) <ref> [AADW94] </ref>. It is still open whether or not an equally good deterministic algorithm exists. The best known deterministic algorithm, from [AADW94], has a competitive latency of O (n 1=2 log 2 n). 6.5 A Semicompetitive Approach: Throughput Competitiveness Fig. 4. Throughput model. <p> In contrast, the best known lower bound is (log n) <ref> [AADW94] </ref>. It is still open whether or not an equally good deterministic algorithm exists. The best known deterministic algorithm, from [AADW94], has a competitive latency of O (n 1=2 log 2 n). 6.5 A Semicompetitive Approach: Throughput Competitiveness Fig. 4. Throughput model. New high-level operations (ovals) start as soon as previous operations end. Adversary controls only timing of low-level operations (filled circles). <p> Information that the champion algorithm is not allowed to use can be made part of the input that is assumed to be worst-case for both champion and candidate. 9 Acknowledgments Some of the material in this survey has been adapted from <ref> [AADW94] </ref>, [AW96], and [AH96]. None of this work would have been possible without the efforts of my co-authors Miklos Ajtai, Cynthia Dwork, Will Hurwood, and Orli Waarts. 7 The technique of comparative analysis [KP94] might seem to be the right answer to these problems.
Reference: [AB96] <author> Y. Aumann and M.A. Bender. </author> <title> Efficient asynchronous consensus with the value-oblivious adversary scheduler. </title> <booktitle> In Proc. 23rd International Colloquium on Automata, Languages, and Programming, </booktitle> <year> 1996. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [Abr88] and was used in the consensus paper of Chor, Israeli, and Li [CIL94]. In general, the weak model in its various incarnations permits much better algorithms (e.g., <ref> [AB96, Cha96] </ref>) for such problems as consensus than the best known algorithms in the more fashionable "strong model" (in which the adversary can stop a process in between generating a random value and writing it out).
Reference: [Abr88] <author> K. Abrahamson. </author> <title> On achieving consensus using a shared memory. </title> <booktitle> In Proceedings of the Seventh ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 291-302, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The Follow-the-Bodies algorithm assumes that a process can generate a random value and write it out as a single atomic operation. This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson <ref> [Abr88] </ref> and was used in the consensus paper of Chor, Israeli, and Li [CIL94].
Reference: [AH96] <author> J. Aspnes and W. Hurwood. </author> <title> Spreading rumors rapidly despite an adversary. </title> <booktitle> In Proc. 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 143-151, </pages> <year> 1996. </year>
Reference-contexts: Section 6.3 discusses why competitiveness is a useful tool for analyzing the performance of collect algorithms. The following sections describe how it has been applied to such algorithms and the consequences of doing so. Some of the material in theses sections is adapted from [AADW94], [AW96], and <ref> [AH96] </ref>. 6.1 Collects: A Fundamental Problem When a process starts a task in the wait-free model, it has no means of knowing what has happened in the system since it last woke up. <p> it is plausible that a competitive approach would be useful. 6.2 A Randomized Algorithm for Repeated Collects Before jumping into the question of how one would apply competitive analysis to collects, let us illustrate some of the issues by considering a particular collect algorithm, the "Follow the Bodies" algorithm of <ref> [AH96] </ref>. As is often the case in distributed computing, one must be very precise about what assumptions one makes about the powers of the adversary. The Follow-the-Bodies algorithm assumes that a process can generate a random value and write it out as a single atomic operation. <p> The Follow-the-Bodies algorithm has the property that it spreads information through the processes' registers rapidly regardless of the behavior of the adversary. In <ref> [AH96] </ref> it is shown that: Theorem 4. Suppose that in some starting configuration the register of each process p contains the information K p and that the successor fields are set arbitrarily. <p> The proof of the theorem is a bit involved, and the interested reader should consult <ref> [AH96] </ref> for details. <p> After O (ln n) of these phases some process knows everything, and it is not long before the other processes read its register and learn everything as well. (The extra log factor comes from the need to read ln n registers during each pass through the loop). In <ref> [AH96] </ref> it is shown how to convert this rumor-spreading algorithm to a repeated-collect algorithm by adding a simple timestamp scheme. Upon starting a collect a process writes out a new timestamp. Timestamps spread through the process's registers in parallel with register values. <p> With this condition, Ajtai et al. show that if an algorithm has a maximum collective latency of L at all times, then its competitive ratio in the latency model is at most L=n + 1. Though this result is stated only for deterministic algorithms, as observed in <ref> [AH96] </ref> it can be made to apply equally well to randomized algorithms given a bound L on the expected collective latency. <p> Information that the champion algorithm is not allowed to use can be made part of the input that is assumed to be worst-case for both champion and candidate. 9 Acknowledgments Some of the material in this survey has been adapted from [AADW94], [AW96], and <ref> [AH96] </ref>. None of this work would have been possible without the efforts of my co-authors Miklos Ajtai, Cynthia Dwork, Will Hurwood, and Orli Waarts. 7 The technique of comparative analysis [KP94] might seem to be the right answer to these problems.
Reference: [AR93] <author> H. Attiya and O. Rachman. </author> <title> Atomic snapshots in o(n log n) operations. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 29-40, </pages> <year> 1993. </year>
Reference-contexts: There are many known wait-free algorithms for snapshot (a list is given in [AW96]). The best algorithm currently known in terms of the asymptotic work required for a single snapshot is the algorithm of Attiya and Rachman <ref> [AR93] </ref>, in which each process uses O (log n) alternating writes and collects in order to complete a single scan-update operation. (The reason why a scan-update requires several rounds of collects is that the processes must negotiate with each other to ensure that the snapshots they compute are consistent.) If the
Reference: [AW91] <author> R. Anderson and H. Woll. </author> <title> Wait-free parallel algorithms for the union-find problem. </title> <booktitle> In Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <pages> pages 370-380, </pages> <year> 1991. </year>
Reference-contexts: be isomorphic to the problem of Certified Write-All, in which n processes have to write to n locations while individually being able to certify that all writes have occurred (indeed, the collect algorithm of Ajtai et al. [AADW94] is largely based on a Certified Write-All algorithm of Anderson and Woll <ref> [AW91] </ref>).
Reference: [AW96] <author> J. Aspnes and O. Waarts. </author> <title> Modular competitiveness for distributed algorithms. </title> <booktitle> In Proc. 28th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 237-246, </pages> <year> 1996. </year>
Reference-contexts: In particular it allows the modular construction of competitive algorithms, as described below in Section 5. The definition of k-competitiveness given above is based on the "throughput model" of <ref> [AW96] </ref>. The use of the term "k-competitiveness" for this measure is justified by several practical considerations. First, the semicompetitive definition is stronger than the traditional definition. <p> Consequently, k-optimality is a weaker notion than k-competitiveness; however, it may still be a useful measure in contexts where k-competitiveness tells us little about the actual performance of an algorithm. An example is given in Section 7. The definition of k-optimality given above was suggested by <ref> [AW96] </ref> by analogy to their semicompetitive definition of k-competitiveness. It also corresponds very closely to an earlier measure used by Patt-Shamir and Rajsbaum in their work on clock synchronization [PSR94]. 4.1 Relations Between the Measures There is a nice relationship between semicompetitive analysis and traditional competitive analysis: Theorem 1. <p> Fortunately, by treating the input to a subroutine separately from its environment, it is possible to recover the ability to compose algorithm while retaining the advantages of competitive analysis. The key is the notion of relative competitiveness defined by <ref> [AW96] </ref>. Relative competitiveness is a measure of how well an algorithm A uses a competitive subroutine B, which takes into account not only how large A's cost is relative to B but also whether or not the decision to use B was a good idea in the first place. <p> Again, it is required that payoff B is never zero; however, in the payoff model it is in fact possible to drop this requirement without causing too many difficulties (for details see <ref> [AW96] </ref>). It is also possible to define relative optimality for both the cost and payoff models. <p> For relative optimality, the inputs I fl A and I fl B are chosen to maximize the costs (minimize the payoffs) of A fl and B fl ; there are no other differences. 5.2 The Composition Theorem The usefulness of relative competitiveness is captured in Composition Theorem of <ref> [AW96] </ref>. The theorem as given here is taken more-or-less directly from [AW96], where it was first stated in a slightly less general form. The version given here has been adapted slightly to fit into the more general framework used in this survey. <p> I fl B are chosen to maximize the costs (minimize the payoffs) of A fl and B fl ; there are no other differences. 5.2 The Composition Theorem The usefulness of relative competitiveness is captured in Composition Theorem of <ref> [AW96] </ref>. The theorem as given here is taken more-or-less directly from [AW96], where it was first stated in a slightly less general form. The version given here has been adapted slightly to fit into the more general framework used in this survey. <p> Then A ffi B is kl-competitive. Proof. The proof given here is adapted from <ref> [AW96] </ref>. Let us consider only the case of costs; the case of payoffs is nearly identical and in any case has been covered elsewhere [AW96]. The proof involves only simple algebraic manipulation, but it is instructive to see where the technical condition (3) is needed. <p> Then A ffi B is kl-competitive. Proof. The proof given here is adapted from <ref> [AW96] </ref>. Let us consider only the case of costs; the case of payoffs is nearly identical and in any case has been covered elsewhere [AW96]. The proof involves only simple algebraic manipulation, but it is instructive to see where the technical condition (3) is needed. <p> Section 6.3 discusses why competitiveness is a useful tool for analyzing the performance of collect algorithms. The following sections describe how it has been applied to such algorithms and the consequences of doing so. Some of the material in theses sections is adapted from [AADW94], <ref> [AW96] </ref>, and [AH96]. 6.1 Collects: A Fundamental Problem When a process starts a task in the wait-free model, it has no means of knowing what has happened in the system since it last woke up. <p> Adversary controls only timing of low-level operations (filled circles). Payoff to algorithm is number of high-level operations completed. A semicompetitive approach of the sort discussed in Section 4 is used in the competitive throughput model of Aspnes and Waarts <ref> [AW96] </ref>. In this model, the adversary no longer controls the starting time of collects; instead, both the candidate and the champion try to complete as many collects as possible in the time available (see Figure 4). <p> A general bound on throughput competitiveness based on these two parameters is given in <ref> [AW96] </ref>; plugging in the values for Follow-the-Bodies gives: Theorem 7. The competitive throughput of the Follow-the-Bodies algorithm is O (n 1=2 log n). The proof of this bound is quite complex and it would be difficult even to try to summarize it here. <p> The mechanism used for this division is a potential function taking into account many fine details of the execution. The interested reader can find the complete argument in the full version of <ref> [AW96] </ref>. It might be surprising that the competitive ratio for essentially the same algorithm is much larger in the throughput model than in the latency model. The reason for the difference is the increased restrictions placed on the champion by the latency model. <p> By contrast, in the throughput model it is possible to construct schedules in which the champion has a huge advantage. An example (taken from <ref> [AW96] </ref>) is given in the following section. 6.6 Lower Bound on Throughput Competitiveness of Collect To illustrate some of the difficulties that arise in the throughput model, consider the following theorem and its proof: Theorem 8. <p> No cooperative collect protocol has a throughput competitiveness less than ( p Proof. (This proof is taken directly from <ref> [AW96] </ref>.) Because of the additive term in the definition of competitive ratio, it is not enough to exhibit a single schedule on which a given collect algorithm fails. <p> Several examples of this approach are given in <ref> [AW96] </ref>; one simple case is reproduced below, in order to make more concrete how one might actually show that an algorithm is competitive relative to some class of subroutines. A snapshot algorithm, like a collect algorithm, simulates an array of n single-writer registers. <p> In practice, this means that process P cannot be shown an older value than process Q in one register and a newer value in a different register. There are many known wait-free algorithms for snapshot (a list is given in <ref> [AW96] </ref>). <p> In addition, since almost any operation is stronger than write-collect in the wait-free model, a similar argument works for a wide variety of algorithms that use collects. Some additional examples are given in <ref> [AW96] </ref>. 7 Example: Guessing Your Location in a Metric Space So far we have seen examples of analyzing distributed problems using both the traditional definition of competitiveness and the semicompetitive definition of competitiveness from Section 4. <p> Very little has been done to study how competitive analysis can be used to analyze how algorithms respond to hostile system behavior in these models. Non-distributed applications of relative competitiveness. Relative competitiveness and the composition theorem were defined in <ref> [AW96] </ref> to analyze a class of problems that arise in a particular model of distributed systems. However, as the authors of [AW96] point out, when viewed abstractly there is nothing about relative competitiveness that depends on having a distributed system. <p> Non-distributed applications of relative competitiveness. Relative competitiveness and the composition theorem were defined in <ref> [AW96] </ref> to analyze a class of problems that arise in a particular model of distributed systems. However, as the authors of [AW96] point out, when viewed abstractly there is nothing about relative competitiveness that depends on having a distributed system. <p> Information that the champion algorithm is not allowed to use can be made part of the input that is assumed to be worst-case for both champion and candidate. 9 Acknowledgments Some of the material in this survey has been adapted from [AADW94], <ref> [AW96] </ref>, and [AH96]. None of this work would have been possible without the efforts of my co-authors Miklos Ajtai, Cynthia Dwork, Will Hurwood, and Orli Waarts. 7 The technique of comparative analysis [KP94] might seem to be the right answer to these problems.
Reference: [BDBK + 90] <author> S. Ben-David, A. Borodin, R. Karp, G. Tardos, and A. Widgerson. </author> <title> On the power of randomization in on-line algorithms. </title> <booktitle> In Proc. 22nd Symposium on Theory of Algorithms, </booktitle> <pages> pages 379-386, </pages> <year> 1990. </year>
Reference-contexts: It follows that: Theorem 6. The competitive latency of the Follow-the-Bodies algorithm is O (log n). It is worth noting that this result is very strong; it holds even against an adaptive off-line adversary <ref> [BDBK + 90] </ref>, which is allowed to choose the champion algorithm after seeing a complete execution of the candidate. In contrast, the best known lower bound is (log n) [AADW94]. It is still open whether or not an equally good deterministic algorithm exists.
Reference: [Cha96] <author> T. Chandra. </author> <title> Polylog randomized wait-free consensus. </title> <booktitle> In Proc. 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [Abr88] and was used in the consensus paper of Chor, Israeli, and Li [CIL94]. In general, the weak model in its various incarnations permits much better algorithms (e.g., <ref> [AB96, Cha96] </ref>) for such problems as consensus than the best known algorithms in the more fashionable "strong model" (in which the adversary can stop a process in between generating a random value and writing it out).
Reference: [CIL94] <author> B. Chor, A. Israeli, and M. Li. </author> <title> Wait-free consensus using asynchronous hardware. </title> <journal> SIAM J. Comput., </journal> <volume> 23(4) </volume> <pages> 701-712, </pages> <month> August </month> <year> 1994. </year> <booktitle> Preliminary version appears in Proceedings of the 6th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 86-97, </pages> <year> 1987. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [Abr88] and was used in the consensus paper of Chor, Israeli, and Li <ref> [CIL94] </ref>.
Reference: [EM89] <author> S. Even and B. Monien. </author> <title> On the number of rounds needed to disseminate information. </title> <booktitle> In Proc. 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1989. </year>
Reference-contexts: One can also think of the collect problem as an asynchronous version of the well-known gossip problem <ref> [EM89] </ref>, in which n persons wish to distribute n rumors among themselves with a mini-mum number of telephone calls; however, in the gossip problem, which persons communicate at each time is fixed in advance by the designer of the algorithm; with an adversary controlling timing this ceases to be possible.
Reference: [Her91] <author> Maurice Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: B ffi C, B is competitive relative to C, and C is competitive, then A is competitive (assuming the appropriate technical conditions hold). 6 Example: The Wait-Free Shared Memory Model In this section we describe some recent approaches to applying competitive analysis to problems in the wait-free shared memory model <ref> [Her91] </ref>. In this model, a collection of n processes communicate only indirectly through a set of single-writer atomic registers. A protocol for carrying out some task or sequence of tasks is wait-free if each process can finish its current task regardless of the relative speeds of the other processes.
Reference: [KP94] <author> E. Koutsoupias and C. Papadimitriou. </author> <title> Beyond competitive analysis. </title> <booktitle> In Proc. 25th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 394-400, </pages> <year> 1994. </year>
Reference-contexts: None of this work would have been possible without the efforts of my co-authors Miklos Ajtai, Cynthia Dwork, Will Hurwood, and Orli Waarts. 7 The technique of comparative analysis <ref> [KP94] </ref> might seem to be the right answer to these problems. Comparative analysis measures the value of information by comparing the best algorithms in two "information regimes" (e.g., paging algorithms with l-lookahead versus paging algorithms with no lookahead).
Reference: [PSR94] <author> B. Patt-Shamir and S. Rajsbaum. </author> <title> A theory of clock synchronization. </title> <booktitle> In Proc. 26th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 810-819, </pages> <year> 1994. </year>
Reference-contexts: An example is given in Section 7. The definition of k-optimality given above was suggested by [AW96] by analogy to their semicompetitive definition of k-competitiveness. It also corresponds very closely to an earlier measure used by Patt-Shamir and Rajsbaum in their work on clock synchronization <ref> [PSR94] </ref>. 4.1 Relations Between the Measures There is a nice relationship between semicompetitive analysis and traditional competitive analysis: Theorem 1. If an algorithm is k-competitive, then it is traditionally k-competitive. If an algorithm is traditionally k-competitive, it is k-optimal. Proof. <p> This example has been abstracted almost to the point of triviality, but it does illustrate issues that have been studied in the context of real distributed systems. The example is inspired by work on clock synchronization by Patt-Shamir and Rajsbaum <ref> [PSR94] </ref>; in this work, the goal of a clock synchronization algorithm is to make a good estimate of the offsets between different clocks in a distributed system based on data piggybacked on the messages sent by some underlying algorithm. <p> The interested reader will find algorithms for solving several interesting variants of the problem in <ref> [PSR94] </ref>. 8 Conclusions The preceding sections have concentrated on how the techniques of competitive analysis have been useful for analyzing fault-tolerant distributed algorithms, where the primary source of difficulty is not unpredictable inputs but unpredictable behavior in the underlying system.
Reference: [SSW91] <author> Michael Saks, Nir Shavit, and Heather Woll. </author> <title> Optimal time randomized consensus | making resilient algorithms fast in practice. </title> <booktitle> In Proceedings of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 351-362, </pages> <year> 1991. </year>
Reference-contexts: Thus to solve almost all non-trivial problems a process must be able to carry out a collect, an operation in which it learns some piece of information from each of the other processes. The collect problem was first abstracted by Saks, Shavit, and Woll <ref> [SSW91] </ref>. The essential idea is that each process owns a single-writer multi-reader atomic register, and would like to be able carry out write operations on its own register and collect operations in which it learns the values in all the registers.
Reference: [ST85] <author> D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 202-208, </pages> <year> 1985. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: As a consequence, the worst-case performance of many algorithms can be very bad, and may have little correspondence to performance in more typical cases. It is not surprising that the technique of competitive analysis <ref> [ST85] </ref> should be useful for taming the excesses of worst-case analysis of distributed algorithms. Of course, new opportunities and complications arise in trying to apply competitive analysis directly to fault-tolerant distributed systems. <p> This schedule is just as unpredictable (and is often assumed to be just as adversarial) as the input. 3 Competitive Analysis. Competitive analysis <ref> [ST85] </ref> compares the performance of a general-purpose algorithm given particular inputs against specialized algorithms optimized for each of those inputs.
References-found: 16

