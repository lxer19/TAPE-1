URL: http://www.almaden.ibm.com/cs/quest/papers/sigmod98_dbi.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: sunita@almaden.ibm.com sthomas@cise.ufl.edu ragrawal@almaden.ibm.com  
Title: Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications  
Author: Sunita Sarawagi Shiby Thomas Rakesh Agrawal 
Address: 650 Harry Road, San Jose, CA 95120  
Affiliation: IBM Almaden Research Center  
Abstract: Data mining on large data warehouses is becoming increasingly important. In support of this trend, we consider a spectrum of architectural alternatives for coupling mining with database systems. These alternatives include: loose-coupling through a SQL cursor interface; encapsulation of a mining algorithm in a stored procedure; caching the data to a file system on-the-fly and mining; tight-coupling using primarily user-defined functions; and SQL implementations for processing in the DBMS. We comprehensively study the option of expressing the mining algorithm in the form of SQL queries using Association rule mining as a case in point. We consider four options in SQL-92 and six options in SQL enhanced with object-relational extensions (SQL-OR). Our evaluation of the different architectural alternatives shows that from a performance perspective, the Cache-Mine option is superior, although the performance of the SQL-OR option is within a factor of two. Both the Cache-Mine and the SQL-OR approaches incur a higher storage penalty than the loose-coupling approach which performance-wise is a factor of 3 to 4 worse than Cache-Mine. The SQL-92 implementations were too slow to qualify as a competitive option. We also compare these alternatives on the basis of qualitative factors like automatic parallelization, development ease, portability and inter-operability. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, A. Arning, T. Bollinger, M. Mehta, J. Shafer, and R. Srikant. </author> <title> The Quest Data Mining System. </title> <booktitle> In Proc. of the 2nd Int'l Conference on Knowledge Discovery in Databases and Data Mining, </booktitle> <address> Port-land, Oregon, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Coupling with database systems was at best loose, and access fl Current affiliation: Dept. of Computer & Information Science & Engineering, University of Florida, Gainesville to data in a DBMS was provided through an ODBC or SQL cursor interface (e.g. <ref> [14, 1, 9, 12] </ref>). Researchers of late have started to focus on issues related to integrating mining with databases. There have been language proposals to extend SQL to support mining operators.
Reference: [2] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This option can be viewed as an extreme case of the SQL-OR approach where UDFs do all the processing. 1.2 Methodology We do both quantitative and qualitative comparisons of the architectures stated above with respect to the problem of discovering Association rules <ref> [2] </ref> against IBM DB2 Universal Server [11]. For the loose-coupling and Stored-procedure architectures, we use the implementation of the Apriori algorithm [3] for finding association rules provided with the IBM data mining product, Intelligent Miner [14]. <p> We present conclusions in Section 7. This paper is an abbreviated version of the full paper that appears in [21]. 2 Background 2.1 Association Rules Given a set of transactions, where each transaction is a set of items, an association rule <ref> [2] </ref> is an expression X!Y , where X and Y are sets of items. The intuitive meaning of such a rule is that the transactions that contain the items in X tend to also contain the items in Y . <p> Here 30% is called the confidence of the rule, and 2% the support of the rule. The problem of mining association rules is to find all rules that satisfy a user-specified minimum support and minimum confidence. The association rule mining problem can be decomposed into two subproblems <ref> [2] </ref>: * Find all combinations of items, called frequent item-sets, whose support is greater than minimum support. * Use the frequent itemsets to generate the desired rules.
Reference: [3] <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. </author> <title> Fast Discovery of Association Rules. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, chapter 12, </booktitle> <pages> pages 307-328. </pages> <publisher> AAAI/MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The objective was to avoid one-at-a-time record retrieval from the database, saving both the copying and process context switching costs. The SETM algorithm [10] for finding association rules was expressed in the form of SQL queries. However, as shown in <ref> [3] </ref>, SETM is not efficient and there are no results reported on running it against a relational DBMS. Recently, the problem of expressing the association rules algorithm in SQL has been explored in [20]. <p> For the loose-coupling and Stored-procedure architectures, we use the implementation of the Apriori algorithm <ref> [3] </ref> for finding association rules provided with the IBM data mining product, Intelligent Miner [14]. For the Cache-Mine architecture, we used the "space" option provided in Intelligent Miner that caches the data in a binary format after the first pass. <p> The first part on generation of frequent itemsets is the most time-consuming part and we concentrate on this part in the paper. In [21] we also discuss rule generation. 2.2 Apriori Algorithm We use the Apriori algorithm <ref> [3] </ref> as the basis for our presentation. There are recent proposals for improving the Apri-ori algorithm by reducing the number of data passes [24, 6]. They all have the same basic dataflow structure as the Apri-ori algorithm. <p> We will refer to this extended table function as Gather-Cnt. The candidate 2-itemset C 2 is represented as a two dimensional array (as suggested in <ref> [3] </ref>) inside function Gather-Cnt. Instead of outputting the 2-item combinations, the function uses the combinations to directly update support counts in memory and outputs only the frequent 2-itemsets, F 2 and their support after the last transaction. The attraction of this otion is the absence of the outer grouping. <p> We validated this observation further by running experiments on synthetic datasets for varying values of the number of frequent items per transaction. We used the synthetic dataset generator described in <ref> [3] </ref> for this purpose. We varied the transaction length, the number of transactions and the support values while keeping the total number of records and the number of frequent items fixed. In Figure 9 we show the total time spent in pass 2 of the Vertical and GatherJoin approaches. <p> UDF and Loose-coupling have similar scale-up behavior as Stored-procedure, therefore we do not show these approaches in the figure. We used a dataset with 10 average number of items per transaction, 100 thousand total items and a default pattern length (defined in <ref> [3] </ref>) of 4. Thus, the size of the dataset is 10 times the number of transactions. As the number of transactions is increased from 10K to 3000K the time taken increases proportionately. The largest frequent itemset was 5 long.
Reference: [4] <author> R. Agrawal and J. Shafer. </author> <title> Parallel mining of association rules. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8(6), </volume> <month> December </month> <year> 1996. </year>
Reference-contexts: On a MPP machine, although one could rely on the DBMS to come up with a data partitioning strategy, it might be possible to better tune performance if the application could provide hints about the best partitioning <ref> [4] </ref>. Further experiments are required to assess how the performance of these automatic parallelizations would compare with algorithm-specific parallelizations (e.g [4]). The development time and code size using SQL could be shorter if one can get efficient implementations out of expressing the mining algorithms declaratively using a few SQL statements. <p> rely on the DBMS to come up with a data partitioning strategy, it might be possible to better tune performance if the application could provide hints about the best partitioning <ref> [4] </ref>. Further experiments are required to assess how the performance of these automatic parallelizations would compare with algorithm-specific parallelizations (e.g [4]). The development time and code size using SQL could be shorter if one can get efficient implementations out of expressing the mining algorithms declaratively using a few SQL statements.
Reference: [5] <author> R. Agrawal and K. Shim. </author> <title> Developing tightly-coupled data mining applications on a relational database system. </title> <booktitle> In Proc. of the 2nd Int'l Conference on Knowledge Discovery in Databases and Data Mining, </booktitle> <address> Port-land, Oregon, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Query flocks for association rule mining using a generate-and-test model has been proposed in [25]. The issue of tightly coupling a mining algorithm with a relational database system from the systems point of view was addressed in <ref> [5] </ref>. This proposal makes use of user-defined functions (UDFs) in SQL statements to selectively push parts of the computation into the database system. The objective was to avoid one-at-a-time record retrieval from the database, saving both the copying and process context switching costs. <p> One is the loose-coupling approach where the DBMS runs in a different address space from the mining process. This is the approach followed by most existing mining systems. A potential problem with this approach is the high context switching cost between the DBMS and the mining process <ref> [5] </ref>. In spite of the block-read optimization present in many systems (e.g. Oracle [18], DB2 [7]) where a block of tuples is read at a time, the performance could suffer. <p> Little use is made of the query processing capability of the DBMS. The UDFs are run in the unfenced mode (same address space as the database). Such an implementation was presented in <ref> [5] </ref>. The main attraction of this method over Stored-procedure is performance since passing tuples to a stored procedure is slower than passing it to a UDF. Otherwise, the processing happens in almost the same manner as in the stored procedure case. <p> Otherwise, the processing happens in almost the same manner as in the stored procedure case. The main disadvantage is the development cost since the entire mining algorithm has to be written as UDFs involving significant code rewrites <ref> [5] </ref>. This option can be viewed as an extreme case of the SQL-OR approach where UDFs do all the processing. 1.2 Methodology We do both quantitative and qualitative comparisons of the architectures stated above with respect to the problem of discovering Association rules [2] against IBM DB2 Universal Server [11]. <p> For the Cache-Mine architecture, we used the "space" option provided in Intelligent Miner that caches the data in a binary format after the first pass. For the UDF architecture, we use the UDF implementation of the Apriori algorithm described in <ref> [5] </ref>. For the SQL-architecture, we consider two classes of implementations: one uses only the features supported in SQL-92 and the other uses object-relational extensions to SQL (henceforth referred to as SQL-OR). We consider four different implementations in the first case and six in the second. <p> This difference did not impact performance much on DB2, therefore we will often be basing our comparisons on the Stored-procedure approach. For the UDF-architecture, we use the UDF implementation of the Apriori algorithm described in <ref> [5] </ref>. In this implementation, first a UDF is used to initialize state and allocate memory for candidate itemsets. Next, for each pass a collection of UDFs are used for generating candidates, counting support, and checking for termination.
Reference: [6] <author> S. Brin, R. Motwani, J. D. Ullman, and S. Tsur. </author> <title> Dynamic itemset counting and implication rules for market basket data. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: In [21] we also discuss rule generation. 2.2 Apriori Algorithm We use the Apriori algorithm [3] as the basis for our presentation. There are recent proposals for improving the Apri-ori algorithm by reducing the number of data passes <ref> [24, 6] </ref>. They all have the same basic dataflow structure as the Apri-ori algorithm. Our goal in this work is to understand how best to integrate this basic structure within a database system. In [21], we discuss how our conclusions extrapolate to these algorithms. <p> Between Stored-procedure and Cache-Mine, the performance difference is a function of the number of passes made on the data | if we make four passes of the data the Stored-procedure approach is four times slower than Cache-Mine. Some of the recent proposals <ref> [24, 6] </ref> that attempt to minimize the number of data passes to 2 or 3 might be useful in reducing the gap between the Cache-Mine and the Stored-procedure approach. In terms of space requirements, the Cache-Mine and the SQL approach loose to the UDF or the Stored-procedure approach. <p> Both these approaches require additional storage for caching, however. The Stored-procedure approach does not require any extra space (except possibly for initially sorting the data in the DBMS) and can perhaps be made to be within a factor of two to three of Cache-Mine with the recent algorithms <ref> [24, 6] </ref>. The UDF approach is a factor of 0.3 to 0.5 faster than Stored-procedure but is significantly harder to code. The SQL approach offers some secondary advantages like easier development and maintenance and potential for automatic parallelization.
Reference: [7] <author> D. Chamberlin. </author> <title> Using the New DB2: IBM's Object-Relational Database System. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: This is the approach followed by most existing mining systems. A potential problem with this approach is the high context switching cost between the DBMS and the mining process [5]. In spite of the block-read optimization present in many systems (e.g. Oracle [18], DB2 <ref> [7] </ref>) where a block of tuples is read at a time, the performance could suffer. The second is the stored-procedure approach where the mining algorithm is encapsulated as a stored procedure [7] that runs in the same address space as the DBMS. <p> In spite of the block-read optimization present in many systems (e.g. Oracle [18], DB2 <ref> [7] </ref>) where a block of tuples is read at a time, the performance could suffer. The second is the stored-procedure approach where the mining algorithm is encapsulated as a stored procedure [7] that runs in the same address space as the DBMS. The main advantage of both these approaches is greater programming flexibility and no extra storage requirement. The mined results are stored back into the DBMS. <p> The disadvantage is that it requires additional disk space for caching. Note that the permanent data continues to be managed by the DBMS. User-defined function (UDF): The mining algorithm is expressed as a collection of user-defined functions (UDFs) <ref> [7] </ref> that are appropriately placed in SQL data scan queries. Most of the processing happens in the UDF and the DBMS is used primarily to provide tuples to the UDFs. Little use is made of the query processing capability of the DBMS.
Reference: [8] <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI/MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: However, it might not be as portable as the Cache-Mine approach across different database management systems. The work presented in this paper points to several directions for future research. A natural next step is to experiment with other kinds of mining operations (e.g. clustering and classification <ref> [8] </ref>) to verify if our conclusions about associations hold for these other cases too. We experimented with generalized association rules [22] and sequential patterns [23] problems and found similar results. In some ways associations is the easiest to integrate as the frequent item-sets can be viewed as generalized group-bys.
Reference: [9] <author> J. Han, Y. Fu, K. Koperski, W. Wang, and O. Zaiane. DMQL: </author> <title> A data mining query language for relational datbases. </title> <booktitle> In Proc. of the 1996 SIGMOD workshop on research issues on data mining and knowledge discovery, </booktitle> <address> Montreal, Canada, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Coupling with database systems was at best loose, and access fl Current affiliation: Dept. of Computer & Information Science & Engineering, University of Florida, Gainesville to data in a DBMS was provided through an ODBC or SQL cursor interface (e.g. <ref> [14, 1, 9, 12] </ref>). Researchers of late have started to focus on issues related to integrating mining with databases. There have been language proposals to extend SQL to support mining operators. <p> Researchers of late have started to focus on issues related to integrating mining with databases. There have been language proposals to extend SQL to support mining operators. For instance, the query language DMQL <ref> [9] </ref> extends SQL with a collection of operators for mining characteristic rules, discriminant rules, classification rules, association rules, etc. The M-SQL language [13] extends SQL with a special unified operator Mine to generate and query a whole set of propositional rules.
Reference: [10] <author> M. Houtsma and A. Swami. </author> <title> Set-oriented mining of association rules. </title> <booktitle> In Int'l Conference on Data Engineering, </booktitle> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: This proposal makes use of user-defined functions (UDFs) in SQL statements to selectively push parts of the computation into the database system. The objective was to avoid one-at-a-time record retrieval from the database, saving both the copying and process context switching costs. The SETM algorithm <ref> [10] </ref> for finding association rules was expressed in the form of SQL queries. However, as shown in [3], SETM is not efficient and there are no results reported on running it against a relational DBMS.
Reference: [11] <author> IBM Corporation. </author> <title> DB2 Universal Database Application programming guide Version 5, </title> <year> 1997. </year>
Reference-contexts: This option can be viewed as an extreme case of the SQL-OR approach where UDFs do all the processing. 1.2 Methodology We do both quantitative and qualitative comparisons of the architectures stated above with respect to the problem of discovering Association rules [2] against IBM DB2 Universal Server <ref> [11] </ref>. For the loose-coupling and Stored-procedure architectures, we use the implementation of the Apriori algorithm [3] for finding association rules provided with the IBM data mining product, Intelligent Miner [14].
Reference: [12] <author> T. Imielinski and H. Mannila. </author> <title> A database perspective on knowledge discovery. </title> <journal> Communication of the ACM, </journal> <volume> 39(11) </volume> <pages> 58-64, </pages> <month> Nov </month> <year> 1996. </year>
Reference-contexts: Coupling with database systems was at best loose, and access fl Current affiliation: Dept. of Computer & Information Science & Engineering, University of Florida, Gainesville to data in a DBMS was provided through an ODBC or SQL cursor interface (e.g. <ref> [14, 1, 9, 12] </ref>). Researchers of late have started to focus on issues related to integrating mining with databases. There have been language proposals to extend SQL to support mining operators.
Reference: [13] <author> T. Imielinski, A. Virmani, and A. Abdulghani. </author> <title> Discovery Board Application Programming Interface and Query Language for Database Mining. </title> <booktitle> In Proc. of the 2nd Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: There have been language proposals to extend SQL to support mining operators. For instance, the query language DMQL [9] extends SQL with a collection of operators for mining characteristic rules, discriminant rules, classification rules, association rules, etc. The M-SQL language <ref> [13] </ref> extends SQL with a special unified operator Mine to generate and query a whole set of propositional rules. Another example is the mine rule [17] operator for a generalized version of the association rule discovery problem.
Reference: [14] <institution> Internationl Business Machines. </institution> <note> IBM Intelligent Miner User's Guide, Version 1 Release 1, SH12-6213-00 edition, </note> <month> July </month> <year> 1996. </year>
Reference-contexts: Coupling with database systems was at best loose, and access fl Current affiliation: Dept. of Computer & Information Science & Engineering, University of Florida, Gainesville to data in a DBMS was provided through an ODBC or SQL cursor interface (e.g. <ref> [14, 1, 9, 12] </ref>). Researchers of late have started to focus on issues related to integrating mining with databases. There have been language proposals to extend SQL to support mining operators. <p> For the loose-coupling and Stored-procedure architectures, we use the implementation of the Apriori algorithm [3] for finding association rules provided with the IBM data mining product, Intelligent Miner <ref> [14] </ref>. For the Cache-Mine architecture, we used the "space" option provided in Intelligent Miner that caches the data in a binary format after the first pass. For the UDF architecture, we use the UDF implementation of the Apriori algorithm described in [5]. <p> The Loose-coupling, Stored-procedure and Cache-Mine implementations are derived from IBM's Intelligent Miner <ref> [14] </ref> code as discussed in Section 1.2. The only difference between Loose-coupling and Stored-procedure approaches is that the former in run in a seperate address space whereas the latter is run in the same address space as the database server.
Reference: [15] <author> K. Kulkarni. </author> <title> Object oriented extensions in SQL3: a status report. </title> <booktitle> Sigmod record, </booktitle> <year> 1994. </year>
Reference-contexts: A preprocessor will generate appropriate SQL translation for this operation. We consider translations that can be executed on a SQL-92 [16] relational engine, as well as translations that require some of the newer object-relational capabilities being designed for SQL <ref> [15] </ref>. Specifically, we assume availability of blobs, user-defined functions, and table functions [19]. We compare the performance of the above SQL architecture with the following alternatives: Read directly from DBMS: Data is read tuple by tuple from the DBMS to the mining kernel using a cursor interface.
Reference: [16] <author> J. Melton and A. Simon. </author> <title> Understanding the new SQL: A complete guide. </title> <publisher> Morgan Kauffman, </publisher> <year> 1992. </year>
Reference-contexts: We visualize that the desired mining operation will be expressed in some extension of SQL or a graphi cal language. A preprocessor will generate appropriate SQL translation for this operation. We consider translations that can be executed on a SQL-92 <ref> [16] </ref> relational engine, as well as translations that require some of the newer object-relational capabilities being designed for SQL [15]. Specifically, we assume availability of blobs, user-defined functions, and table functions [19].
Reference: [17] <author> R. Meo, G. Psaila, and S. Ceri. </author> <title> A new SQL like operator for mining association rules. </title> <booktitle> In Proc. of the 22nd Int'l Conference on Very Large Databases, </booktitle> <address> Bombay, India, </address> <month> Sep </month> <year> 1996. </year>
Reference-contexts: The M-SQL language [13] extends SQL with a special unified operator Mine to generate and query a whole set of propositional rules. Another example is the mine rule <ref> [17] </ref> operator for a generalized version of the association rule discovery problem. Query flocks for association rule mining using a generate-and-test model has been proposed in [25]. The issue of tightly coupling a mining algorithm with a relational database system from the systems point of view was addressed in [5].
Reference: [18] <author> Oracle. </author> <title> Oracle RDBMS Database Administrator's Guide Volumes I, II (Version 7.0), </title> <month> May </month> <year> 1992. </year>
Reference-contexts: This is the approach followed by most existing mining systems. A potential problem with this approach is the high context switching cost between the DBMS and the mining process [5]. In spite of the block-read optimization present in many systems (e.g. Oracle <ref> [18] </ref>, DB2 [7]) where a block of tuples is read at a time, the performance could suffer. The second is the stored-procedure approach where the mining algorithm is encapsulated as a stored procedure [7] that runs in the same address space as the DBMS.
Reference: [19] <author> H. Pirahesh and B. Reinwald. </author> <title> SQL table function open architecture and data access middleware. </title> <booktitle> In SIGMOD, </booktitle> <year> 1998. </year>
Reference-contexts: We consider translations that can be executed on a SQL-92 [16] relational engine, as well as translations that require some of the newer object-relational capabilities being designed for SQL [15]. Specifically, we assume availability of blobs, user-defined functions, and table functions <ref> [19] </ref>. We compare the performance of the above SQL architecture with the following alternatives: Read directly from DBMS: Data is read tuple by tuple from the DBMS to the mining kernel using a cursor interface. Data is never copied to a file system. We consider two variations of this approach. <p> We consider two different categories of SQL implementations: (A) The first one is based purely on SQL-92. We discuss four approaches in this category in Section 4. (B) The second utilizes object-relational extensions like UDFs, BLOBs (Binary large objects) and table functions. Table functions <ref> [19] </ref> are virtual tables associated with a user defined function which generate tuples on the fly. They have pre-defined schemas like any other table. The function associated with a table function can be implemented as a UDF.
Reference: [20] <author> K. Rajamani, B. Iyer, and A. Chaddha. </author> <title> Using DB/2's object relational extensions for mining associations rules. </title> <type> Technical Report TR 03,690., </type> <institution> Santa Teresa Laboratory, IBM Corporation, </institution> <month> sept </month> <year> 1997. </year>
Reference-contexts: However, as shown in [3], SETM is not efficient and there are no results reported on running it against a relational DBMS. Recently, the problem of expressing the association rules algorithm in SQL has been explored in <ref> [20] </ref>. We discuss this work later in the paper. 1.1 Goal This paper is an attempt to understand implications of various architectural alternatives for coupling data mining with relational database systems. <p> The algorithm terminates when F k or C k+1 becomes empty. 2.3 Input format The transaction table T has two column attributes: transaction identifier (tid) and item identifier (item). The number of items per tid is variable and unknown during table creation time. Thus, alternatives such as <ref> [20] </ref>, where all items of a tid appear as different columns of a single tuple, may not be practical. Often the number of items per transaction can be more than the maximum number of columns that the DBMS supports. <p> A problem with this approach is the increased coding complexity of the table function. Horizontal: This is another variation of GatherJoin that first uses the Gather function to transform the data to the horizontal format but is otherwise similar to the Gather-Join approach. Rajamani et al. <ref> [20] </ref> propose finding associations using a similar approach augmented with some pruning based on a variation of the GatherPrune approach. Their results assume that the data is already in a horizontal format which is often not true in practice.
Reference: [21] <author> S. Sarawagi, S. Thomas, and R. Agrawal. </author> <title> Integrating association rule mining with relational database systems: Alternatives and implications. </title> <type> Research Report RJ 10107 (91923), </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA 95120, </address> <month> March </month> <year> 1998. </year> <note> Available from http://www.almaden.ibm.com/cs/quest. </note>
Reference-contexts: In Section 6 we present a qualitative and quantitative comparison of the different architectural alternatives. We present conclusions in Section 7. This paper is an abbreviated version of the full paper that appears in <ref> [21] </ref>. 2 Background 2.1 Association Rules Given a set of transactions, where each transaction is a set of items, an association rule [2] is an expression X!Y , where X and Y are sets of items. <p> Note that the rule will have minimum sup port because ABCD is frequent. The first part on generation of frequent itemsets is the most time-consuming part and we concentrate on this part in the paper. In <ref> [21] </ref> we also discuss rule generation. 2.2 Apriori Algorithm We use the Apriori algorithm [3] as the basis for our presentation. There are recent proposals for improving the Apri-ori algorithm by reducing the number of data passes [24, 6]. <p> They all have the same basic dataflow structure as the Apri-ori algorithm. Our goal in this work is to understand how best to integrate this basic structure within a database system. In <ref> [21] </ref>, we discuss how our conclusions extrapolate to these algorithms. The Apriori algorithm for finding frequent itemsets makes multiple passes over the data. In the kth pass it finds all itemsets having k items called the k-itemsets. Each pass consists of two phases. <p> UDFs in this approach are light weight and do not require extensive memory allocations and coding unlike the UDF architectural option (Section 1.1). 4 Support counting using SQL-92 We studied four approaches in this category we present the two better ones here. The other two are discussed in <ref> [21] </ref>. 4.1 K-way joins In each pass k, we join the candidate itemsets C k with k transaction tables T and follow it up with a group by on the itemsets as shown in Figure 3. The figure 3 also shows a tree diagram of the query. <p> Tree diagram for Subquery Q l 4.3 Performance comparison of SQL-92 approaches We now briefly compare the different SQL-92 approaches; detailed results are available in <ref> [21] </ref>. Our experiments were performed on Version 5 of IBM DB2 Universal Server installed on a RS/6000 Model 140 with a 200 MHz CPU, 256 MB main memory and a 9 GB disk with a measured transfer rate of 8 MB/sec. <p> We first consider an approach we call GatherJoin and its three variants in Section 5.1. Next we present a very different approach called Vertical in Section 5.2. We do not discuss the sixth approach called SBF based on SQL-bodied functions because of its inferior performance (see <ref> [21] </ref>). For each approach, we also outline a cost-based analysis of the execution time to choose between these different approaches. <p> Cost formulas for the GatherPrune and Horizontal approaches can be derived similarly and appear in <ref> [21] </ref>. 5.2 Vertical We first transform the data table into a vertical format by creating for each item a BLOB containing all tids that contain that item (Tid-list creation phase) and then count the support of itemsets by merging together these tid-lists (support counting phase). <p> Details on how to do this conversion for SQL is presented in <ref> [21] </ref>. 6.3 Summary of comparison between different architec tures We present a summary of the pros and cons of the different architectures on each of the following yardsticks: (a) performance (execution time); (b) storage overhead; (c) potential for automatic parallelization; (d) development and maintenance ease; (e) portability (f) inter-operability.
Reference: [22] <author> R. Srikant and R. Agrawal. </author> <title> Mining Generalized Association Rules. </title> <booktitle> In Proc. of the 21st Int'l Conference on Very Large Databases, </booktitle> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: A natural next step is to experiment with other kinds of mining operations (e.g. clustering and classification [8]) to verify if our conclusions about associations hold for these other cases too. We experimented with generalized association rules <ref> [22] </ref> and sequential patterns [23] problems and found similar results. In some ways associations is the easiest to integrate as the frequent item-sets can be viewed as generalized group-bys.
Reference: [23] <author> R. Srikant and R. Agrawal. </author> <title> Mining Sequential Patterns: Generalizations and Performance Improvements. </title> <booktitle> In Proc. of the Fifth Int'l Conference on Extending Database Technology (EDBT), </booktitle> <address> Avignon, France, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: A natural next step is to experiment with other kinds of mining operations (e.g. clustering and classification [8]) to verify if our conclusions about associations hold for these other cases too. We experimented with generalized association rules [22] and sequential patterns <ref> [23] </ref> problems and found similar results. In some ways associations is the easiest to integrate as the frequent item-sets can be viewed as generalized group-bys.
Reference: [24] <author> H. Toivonen. </author> <title> Sampling large databases for association rules. </title> <booktitle> In Proc. of the 22nd Int'l Conference on Very Large Databases, </booktitle> <pages> pages 134-145, </pages> <address> Mumbai (Bombay), India, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: In [21] we also discuss rule generation. 2.2 Apriori Algorithm We use the Apriori algorithm [3] as the basis for our presentation. There are recent proposals for improving the Apri-ori algorithm by reducing the number of data passes <ref> [24, 6] </ref>. They all have the same basic dataflow structure as the Apri-ori algorithm. Our goal in this work is to understand how best to integrate this basic structure within a database system. In [21], we discuss how our conclusions extrapolate to these algorithms. <p> Between Stored-procedure and Cache-Mine, the performance difference is a function of the number of passes made on the data | if we make four passes of the data the Stored-procedure approach is four times slower than Cache-Mine. Some of the recent proposals <ref> [24, 6] </ref> that attempt to minimize the number of data passes to 2 or 3 might be useful in reducing the gap between the Cache-Mine and the Stored-procedure approach. In terms of space requirements, the Cache-Mine and the SQL approach loose to the UDF or the Stored-procedure approach. <p> Both these approaches require additional storage for caching, however. The Stored-procedure approach does not require any extra space (except possibly for initially sorting the data in the DBMS) and can perhaps be made to be within a factor of two to three of Cache-Mine with the recent algorithms <ref> [24, 6] </ref>. The UDF approach is a factor of 0.3 to 0.5 faster than Stored-procedure but is significantly harder to code. The SQL approach offers some secondary advantages like easier development and maintenance and potential for automatic parallelization.
Reference: [25] <author> D. Tsur, S. Abiteboul, C. Clifton, R. Motwani, and S. Nestorov. </author> <title> Query flocks: A generalization of association rule mining. </title> <booktitle> In SIGMOD, </booktitle> <year> 1998. </year> <note> to appear. </note>
Reference-contexts: Another example is the mine rule [17] operator for a generalized version of the association rule discovery problem. Query flocks for association rule mining using a generate-and-test model has been proposed in <ref> [25] </ref>. The issue of tightly coupling a mining algorithm with a relational database system from the systems point of view was addressed in [5]. This proposal makes use of user-defined functions (UDFs) in SQL statements to selectively push parts of the computation into the database system. <p> k and t 1 .tid = t 2 .tid and t k1 .tid = t k .tid group by item 1 ,item 2 . . . item k having count (*) &gt; :minsup This SQL computation, when merged with the candidate generation step, is similar to the one proposed in <ref> [25] </ref> as a possible mechanism to implement query flocks. For pass-2 we use a special optimization where instead of materializing C 2 , we replace it with the 2-way joins between the F 1 s as shown in the candidate generation phase in section 3.1.
Reference: [26] <author> M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. </author> <title> New Algorithms for Fast Discovery of Association Rules. </title> <booktitle> In Proc. of the 3rd Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <address> Newport Beach, Cal-ifornia, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: This approach is similar to the approaches in <ref> [26] </ref>. For creating the Tid-lists we use a table function Gather. This is the same as the Gather function in GatherJoin except that we create the tid-list for each frequent item. The data table T is scanned in the (item,tid) order and passed to the function Gather.
References-found: 26

