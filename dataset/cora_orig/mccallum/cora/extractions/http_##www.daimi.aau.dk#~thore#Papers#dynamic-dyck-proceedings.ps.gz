URL: http://www.daimi.aau.dk/~thore/Papers/dynamic-dyck-proceedings.ps.gz
Refering-URL: http://www.daimi.aau.dk/~thore/Papers/dyck.html
Root-URL: http://www.daimi.aau.dk
Title: Dynamic Algorithms for the Dyck Languages  
Author: Gudmund Skovbjerg Frandsen Thore Husfeldt, Peter Bro Miltersen Theis Rauhe, and Soren Skyum 
Address: Ny Munkegade, DK-8000 Arhus C, Denmark  
Affiliation: BRICS, Department of Computer Science, University of Aarhus,  
Abstract: We study Dynamic Membership problems for the Dyck languages, the class of strings of properly balanced parentheses. We also study the Dynamic Word problem for the free group. We present deterministic algorithms and data structures which maintain a string under replacements of symbols, insertions, and deletions of symbols, and language membership queries. Updates and queries are handled in poly-logarithmic time. We also give both Las Vegas- and Monte Carlo-type randomised algorithms to achieve better running times, and present lower bounds on the complexity for variants of the problems. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Paul F. Dietz. </author> <title> Optimal algorithms for list indexing and subset rank. </title> <editor> In F. Dehne, J.-R. Sack, and N. Santoro, editors, </editor> <booktitle> Proc. First Workshop on Algorithms and Data Structures (WADS), volume 382 of Lecture Notes in Computer Science, </booktitle> <pages> pages 39-46. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: We leave it to the reader to prove a logarithmic upper bound. Using an algorithm by Dietz <ref> [1] </ref> a solution with an O (log n= log log n) upper bound on the amortised complexity for the extended set of operations can also be found. Proposition 2. The Dynamic Membership problem for D 1 can be done in time O (log n) per operation. Proof.
Reference: 2. <author> Gudmund Skovbjerg Frandsen, Peter Bro Miltersen, and Sven Skyum. </author> <title> Dynamic word problems. </title> <booktitle> In Proc 34th Ann. Symp. on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 470-479, </pages> <year> 1993. </year>
Reference-contexts: indeed separate the complexity of the two problems: for D 1 , we prove a lower bound of (log n= log log n) by a technique of Fredman [3], while we can bound the complexity of D 0 1 from above by O (log log n) using a construction of <ref> [2] </ref>. The latter bound is shown to be tight by a reduction from the Dynamic Word problem for the monoid (f0; 1g; _), for which a lower bound is given in [2]. <p> can bound the complexity of D 0 1 from above by O (log log n) using a construction of <ref> [2] </ref>. The latter bound is shown to be tight by a reduction from the Dynamic Word problem for the monoid (f0; 1g; _), for which a lower bound is given in [2]. The upper bound for D 1 is O (log n log log n), not quite matching the lower bound. These results are only valid for the restricted set of operations (and are only of theoretical interest anyway). The table below summarises these results. <p> One can phrase this even stronger in terms of circuit complexity: all Dyck languages are complete for TC 0 under AC 0 -reductions, (this appears to be folklore). Dynamic Word and Prefix problems for finite monoids are studied in <ref> [2, 11] </ref>. The free group of k generators studied in the present paper is infinite. Turning from context-free to regular languages, it is easy to find logarithmic time algorithms for the Dynamic Membership problem for the latter class. <p> The free group of k generators studied in the present paper is infinite. Turning from context-free to regular languages, it is easy to find logarithmic time algorithms for the Dynamic Membership problem for the latter class. The results from <ref> [2] </ref> give better upper bounds depending on the language's syntactic monoid M (L). One earlier paper has considered dynamic algorithms for the Dyck languages.
Reference: 3. <author> Michael L. Fredman. </author> <title> The complexity of maintaining an array and computing its partial sums. </title> <journal> Journal of the ACM, </journal> <volume> 29 </volume> <pages> 250-260, </pages> <year> 1982. </year>
Reference-contexts: more restricted model for dynamic algorithms, namely the cell probe model with cell size 1 (the bit probe model ), we can indeed separate the complexity of the two problems: for D 1 , we prove a lower bound of (log n= log log n) by a technique of Fredman <ref> [3] </ref>, while we can bound the complexity of D 0 1 from above by O (log log n) using a construction of [2].
Reference: 4. <author> Michael L. Fredman and Michael E. Saks. </author> <title> The cell probe complexity of dynamic data structures. </title> <booktitle> In Proc. 21st Ann. Symp. on Theory of Computing (STOC), </booktitle> <pages> pages 345-354, </pages> <year> 1989. </year>
Reference-contexts: If instead we allow insertion and deletion, a lower bound of (log n= log log n) can be derived from a result of Fredman and Saks <ref> [4] </ref>. The same lower bound holds if we replace member by match in the restricted set of operations (for one-sided languages). The proofs of these results are omitted in this version of the paper, due to lack of space. Table 2: Lower bounds for logarithmic word size.
Reference: 5. <author> Leo J. Guibas and Robert Sedgewick. </author> <title> A dichromatic framework for balanced trees. </title> <booktitle> In Proc. 19th Ann. Symp. on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 8-21. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1978. </year>
Reference-contexts: Most complicated are the insert and delete operations. To accommodate these, we have to maintain balance in the tree using any scheme for balancing dynamic search trees, e.g. red-black trees <ref> [5] </ref>. We will not comment on such extensions any further; the reader can check that they are also possible for all the algorithms in Sects. 3 and 4.
Reference: 6. <author> Michael A. Harrison. </author> <title> Introduction to Formal Language Theory. </title> <publisher> Addison-Wesley, </publisher> <year> 1978. </year>
Reference-contexts: For example, a 1 a 2 a 2 a 1 2 D 0 2 because a 1 1 a 2 a 1 2 a 1 evaluates to unity. The Dyck languages are covered in detail in Harrison's classical treatment <ref> [6] </ref>. 1.2 The Dynamic Membership Problem In this paper we consider the problem of maintaining membership in D k or D 0 k of a string from (A [ A) n dynamically. <p> Ritchie and Springsteel [14] showed that the one-sided Dyck languages are in deterministic logspace, Lipton and Zalcstein [8] extended this to the two-sided case (see also <ref> [6, Exercises 22 and 23] </ref>). One can phrase this even stronger in terms of circuit complexity: all Dyck languages are complete for TC 0 under AC 0 -reductions, (this appears to be folklore). Dynamic Word and Prefix problems for finite monoids are studied in [2, 11]. <p> All logarithms are base two. We call a string reduced if it contains no neighbouring pair of matching parentheses. So, for the one-sided case, ([ ]) is not reduced but [ )( is. In the two-sided case, the latter is not reduced. To formalise this (following Harrison <ref> [6] </ref>), we introduce two mappings 1 ; 2 : (A [ A) fl ! (A [ A) fl : We want 1 (u) and 2 (u) to be the reduced form of u using one- and two-sided cancellation, respectively.
Reference: 7. <author> Richard M. Karp and Michael O. Rabin. </author> <title> Efficient randomised pattern-matching algorithms. </title> <journal> IBM J. Res. Develop., </journal> <volume> 31(2) </volume> <pages> 249-260, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: We achieve better bounds for Monte Carlo-style algorithms. Using the fingerprint method of Karp and Rabin <ref> [7] </ref>, where strings are represented by (nonunique) fingerprints in the form of a matrix product modulo a small randomly chosen prime, D k can be done in time O (log 2 n) and D 0 k in time O (log n). <p> We use the well-known fingerprint string matching technique of Karp and Rabin <ref> [7] </ref>. Proposition 6. The Dynamic Membership problem for D 0 k can be done in time O (log n) per operation such that the probability of an erroneous answer in any sequence of n updates is O ( 1 n ). Proof. <p> This suggests a randomised algorithm in the spirit of <ref> [7] </ref>: compute h (x) modulo a randomly chosen prime p and check whether the result is the identity matrix. For the dynamic version we need to maintain h (x) mod p under updates to x; we write n for jxj.
Reference: 8. <author> Richard J. Lipton and Yechezkel Zalcstein. </author> <title> Word problems solvable in logspace. </title> <journal> Journal of the ACM, </journal> <volume> 24(3) </volume> <pages> 522-526, </pages> <year> 1977. </year>
Reference-contexts: Ritchie and Springsteel [14] showed that the one-sided Dyck languages are in deterministic logspace, Lipton and Zalcstein <ref> [8] </ref> extended this to the two-sided case (see also [6, Exercises 22 and 23]). One can phrase this even stronger in terms of circuit complexity: all Dyck languages are complete for TC 0 under AC 0 -reductions, (this appears to be folklore). <p> Following Lipton and Zalcstein <ref> [8] </ref> (see also [9, Problem 2.3.13]), we represent (A [ A) fl = as a group of 2 fi 2 integer matrices using the group homomorphism h: (A [ A) fl = ! M 2 (Z) given by h (a 1 ) = 0 1 and h (a 2 ) =
Reference: 9. <author> Wilhelm Magnus, Abraham Karrass, and Donald Solitar. </author> <title> Combinatorial Group Theory, </title> <booktitle> volume 13 of Pure and Applied Mathematics. </booktitle> <publisher> Interscience Publishers, </publisher> <year> 1966. </year>
Reference-contexts: Following Lipton and Zalcstein [8] (see also <ref> [9, Problem 2.3.13] </ref>), we represent (A [ A) fl = as a group of 2 fi 2 integer matrices using the group homomorphism h: (A [ A) fl = ! M 2 (Z) given by h (a 1 ) = 0 1 and h (a 2 ) = 2 1 : <p> Indeed, if for 1 i k we put c i = g i 1 g i 2 then c 1 ; : : : ; c k generate a free group, see <ref> [9, Problem 1.4.12] </ref>. ut 4.2 The One-Sided Case The algorithm for D k is somewhat more difficult. We will combine the tree-structure we used for the deterministic algorithm for D k (Prop. 5) with the Monte Carlo algorithm for D 0 k from the last proposition.
Reference: 10. <author> K. Mehlhorn, R. Sundar, and C. Uhrig. </author> <title> Maintaining dynamic sequences under equality-tests in polylogarithmic time. </title> <booktitle> In Proc. 5th Ann. Symp. on Discrete Algorithms (SODA), </booktitle> <pages> pages 213-222. ACM-SIAM, </pages> <year> 1994. </year>
Reference-contexts: Our main result is that the Dynamic Membership problem for all Dyck languages can be solved in polylogarithmic time per operation, the exact bound is O (log 3 n log fl n). We use a technique for maintaining dynamic sequences under equality tests by Mehlhorn, Sundar, and Uhrig <ref> [10] </ref>, which also gives (Las Vegas-style) randomised algorithms that run in slightly better expected time: O (log 3 n). We achieve better bounds for Monte Carlo-style algorithms. <p> At each node, we store entire sequences (rather than just a tuple as above) that are formed from the sequences stored at its children. To this end we first need a recent surprising construction for dynamically maintaining sequences. 3.1 A Data Structure for String Equality Mehlhorn, Sundar, and Uhrig <ref> [10] </ref> present a data structure for dynamically maintaining a family of strings under equality tests. We use a slightly modified set of updates that is better suited to our problem. <p> The techniques from <ref> [10] </ref> can easily be modified to cope with the above updates. The time bounds are summarised in the following lemma: Lemma 3 [10]. <p> The techniques from <ref> [10] </ref> can easily be modified to cope with the above updates. The time bounds are summarised in the following lemma: Lemma 3 [10]. <p> This completes the proof. ut The upper bounds from the last two propositions can be improved to expected time O (log 3 n) by using the Las Vegas variant of the algorithm described in Sect. 3.1, see <ref> [10] </ref>. 4 Monte Carlo Algorithms 4.1 The Two-Sided Case We begin with D 0 k , which is quite simple. We use the well-known fingerprint string matching technique of Karp and Rabin [7]. Proposition 6.
Reference: 11. <author> Peter Bro Miltersen. </author> <title> Lower bounds for union-split-find related problems on random access machines. </title> <booktitle> In Proc. 26th Ann. Symp. on Theory of Computing (STOC), </booktitle> <pages> pages 625-634. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: However, if the prefix-operation is added, we can get a weak lower bound of (log log n= log log log n) using a result of Beame and Fich (personal communication, improving <ref> [11] </ref>); obviously, the same bound holds with the mismatch query instead. If instead we allow insertion and deletion, a lower bound of (log n= log log n) can be derived from a result of Fredman and Saks [4]. <p> One can phrase this even stronger in terms of circuit complexity: all Dyck languages are complete for TC 0 under AC 0 -reductions, (this appears to be folklore). Dynamic Word and Prefix problems for finite monoids are studied in <ref> [2, 11] </ref>. The free group of k generators studied in the present paper is infinite. Turning from context-free to regular languages, it is easy to find logarithmic time algorithms for the Dynamic Membership problem for the latter class.
Reference: 12. <author> Mark H. Overmars. </author> <title> The design of dynamic data structures, </title> <booktitle> volume 156 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: Choosing p n 4 randomly and choosing a new p for every n operations by the global rebuilding technique of Overmars <ref> [12] </ref> we guarantee that the probability of an erroneous answer in a sequence of n consecutive queries is bounded by O ( 1 n ).
Reference: 13. <author> Sushant Patnaik and Neil Immerman. </author> <title> Dyn-FO: A parallel, dynamic comlexity class. </title> <booktitle> In Proc. 13th ACM Symp. on Principles of Database Systems (PODS), </booktitle> <pages> pages 210-221, </pages> <year> 1994. </year>
Reference-contexts: The results from [2] give better upper bounds depending on the language's syntactic monoid M (L). One earlier paper has considered dynamic algorithms for the Dyck languages. In <ref> [13] </ref>, algorithms with update and query operations in AC 0 are constructed, but no non-trivial sequential upper bounds follow from this. 1.5 Preliminaries and Notation Strings will be denoted by lower-case letters u; v; x; : : :: We let u i denote the ith letter of string u and we
Reference: 14. <author> R. W. Ritchie and F. N. Springsteel. </author> <title> Language recognition by marking automata. </title> <journal> Information and Control, </journal> <volume> 20 </volume> <pages> 313-330, </pages> <year> 1972. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Language Operations Upper bound Lower bound D 1 change, member O (log n log log n) log n 1 change, member fi (log log n) 1.4 Related Results It is interesting that all Dyck languages seem to be equally hard in most non-dynamic computational models. Ritchie and Springsteel <ref> [14] </ref> showed that the one-sided Dyck languages are in deterministic logspace, Lipton and Zalcstein [8] extended this to the two-sided case (see also [6, Exercises 22 and 23]).
References-found: 14

