URL: ftp://ftp.isds.duke.edu/pub/WorkingPapers/96-09.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Sequential Importance Sampling for Nonparametric Bayes Models: The Next Generation Running Title: SIS for Nonparametric Bayes  
Author: Steven N. MacEachern, Merlise Clyde, and Jun S. Liu Jun S. Liu, 
Keyword: Key words and phrases: Beta-binomial, Dirichlet process, Gibbs sampler, importance sampling, MCMC, posterior distribution, Rao-Blackwellization, Sequential Imputation.  
Address: Stanford, CA 94305-4065, USA.  
Affiliation: Department of Statistics, Sequoia Hall,Stanford University,  
Note: AMS 1991 subject classifications:  Address for Correspondence:  
Email: Email: jliu@stat.stanford.edu  
Phone: Telephone: 415-723-2623. Fax: 415-725-8977.  
Web: 62C10, 62G07.  
Abstract: There are two generations of Gibbs sampling methods for semi-parametric models involving the Dirichlet process. The first generation suffered from a severe drawback; namely that the locations of the clusters, or groups of parameters, could essentially become fixed, moving only rarely. Two strategies that have been proposed to create the second generation of Gibbs samplers are integration and appending a second stage to the Gibbs sampler wherein the cluster locations are moved. We show that these same strategies are easily implemented for the sequential importance sampler, and that the first strategy dramatically improves results. As in the case of Gibbs sampling, these strategies are applicable to a much wider class of models. They are shown to provide more uniform importance sampling weights and lead to additional Rao-Blackwellization of estimators. Steve MacEachern is Associate Professor, Department of Statistics, Ohio State University, Merlise Clyde is Assistant Professor, Institute of Statistics and Decision Sciences, Duke University, and Jun Liu is Assistant Professor, Department of Statistics, Stanford University. The work of the second author was supported in part by the National Science Foundation grants DMS-9305699 and DMS-9626135, and that of the last author by the National Science Foundation grants DMS-9406044, DMS-9501570, and the Terman Fellowship. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Antoniak, C.E. </author> <year> (1974). </year> <title> Mixtures of Dirichlet processes with applications to Bayesian nonpara-metric problems. </title> <journal> Ann. Statist. </journal> <pages> 2 1152-1174. </pages>
Reference-contexts: 1 Introduction Nonparametric and semi-parametric hierarchical Bayes methods have enjoyed a resurgence of interest with the development of modern Monte Carlo techniques. One popular class of models is based on the Dirichlet process (Ferguson, 1973), and has become known as mixture of Dirichlet process (MDP) models <ref> (Antoniak, 1974) </ref>. The advantage of a MDP model over a standard parametric hierarchical model as in Lindley and Smith (1972) is that it allows for more flexibility through the incorporation of a nonparametric hierarchical distribution.
Reference: <author> Beckett, L. and Diaconis, P. </author> <year> (1994). </year> <title> Spectral analysis for discrete longitudinal data. </title> <journal> Adv. in Math. </journal> <pages> 103 107-128. </pages>
Reference: <author> Berry, D.A. and Christensen, R. </author> <year> (1979). </year> <title> Empirical Bayes estimation of a binomial parameter via mixture of Dirichlet processes. </title> <journal> Ann. Statist. </journal> <pages> 7 558-568. </pages>
Reference-contexts: Each component of the mixture corresponds to a partition of into clusters, and the number of components in the mixture grows exponentially. Because of the analytic intractability of this type of model, early investigators developed approximations <ref> (see Berry and Christensen, 1979) </ref> or simulation methods (see Kuo, 1986).
Reference: <author> Berzuini, C., Best, N.G., Gilks, W.R., and Larizza, C. </author> <year> (1996). </year> <title> Dynamic graphical models and Markov chain Monte Carlo methods. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 91, </volume> <pages> forthcoming. </pages>
Reference: <author> Blackwell, D. and MacQueen, J.B. </author> <year> (1973). </year> <title> Ferguson distributions via Polya urn schemes. </title> <journal> Ann. Statist. </journal> <pages> 1 353-355. </pages>
Reference-contexts: We may obtain estimates of all of these quantities on the basis of the simulation techniques that we present. The Polya urn scheme representation of the Dirichlet process <ref> (Blackwell and MacQueen, 1973) </ref> provides the basis for most modern computational strategies: for exceptions, see Doss (1994), Gelfand and Kuo (1991), and Kuo and Smith (1992).
Reference: <author> Bush, C.A. and MacEachern, S.N. </author> <year> (1996). </year> <title> A semi-parametric Bayesian model for randomized block designs. </title> <type> Biometrika 83 275-285. 16 Doss, H. </type> <year> (1994). </year> <title> Bayesian nonparametric estimation for incomplete data via successive substi-tution sampling. </title> <journal> Ann. Statist. </journal> <pages> 22 1763-1786. </pages>
Reference: <author> Escobar, M.D. </author> <year> (1994). </year> <title> Estimating normal means with a Dirichlet process prior. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 89, </volume> <pages> 268-277. </pages>
Reference-contexts: We note that the probabilities needed in Step (A) must be evaluated in order to generate values of (s i ; i ) in step (B). Thus, finding the weights requires almost no additional computational effort. Gibbs sampler <ref> (Escobar, 1994) </ref>: Each i is, in turn, viewed as the last observation (of n) from a Polya urn scheme. The remaining n 1 observations form k clusters with locations fl 1 ; : : : ; fl k .
Reference: <author> Escobar, M.D. and West, M. </author> <year> (1995). </year> <title> Bayesian density estimation and inference using mixtures. </title>
Reference: <author> J. </author> <title> Amer. </title> <journal> Statist. Assoc. </journal> <volume> 90, </volume> <pages> 577-588. </pages>
Reference: <author> Ferguson, T.S. </author> <year> (1973). </year> <title> A Bayesian analysis of some nonparametric problems. </title> <journal> Ann. Statist. </journal> <pages> 1 209-230. </pages>
Reference-contexts: 1 Introduction Nonparametric and semi-parametric hierarchical Bayes methods have enjoyed a resurgence of interest with the development of modern Monte Carlo techniques. One popular class of models is based on the Dirichlet process <ref> (Ferguson, 1973) </ref>, and has become known as mixture of Dirichlet process (MDP) models (Antoniak, 1974). The advantage of a MDP model over a standard parametric hierarchical model as in Lindley and Smith (1972) is that it allows for more flexibility through the incorporation of a nonparametric hierarchical distribution.
Reference: <author> Gelfand, A.E. and Kuo, L. </author> <year> (1991). </year> <title> Nonparametric Bayesian bioassay including ordered polyto-mous response. </title> <type> Biometrika 78 657-666. </type>
Reference: <author> Gopalan, R. </author> <year> (1994). </year> <type> Unpublished Ph.D. dissertation, </type> <institution> Institute of Statistics and Decision Sciences, Duke University. </institution>
Reference: <author> Kong, A., Liu, J.S. and Wong, W.H. </author> <year> (1994). </year> <title> Sequential imputations and Bayesian missing data problems. </title> <journal> J. Amer. Statist. Assoc. </journal> <note> 89 278-288 Kuo, </note> <author> L. </author> <year> (1986). </year> <title> Computations of mixtures of Dirichlet processes. </title> <journal> SIAM J. Sci. Statist. Comput. </journal> <pages> 7 60-71. </pages>
Reference: <author> Kuo, L. and Smith, A.F.M. </author> <year> (1992). </year> <title> Bayesian computations in survival models via the Gibbs sampler. In Survival Analysis: State of the Art, </title> <editor> ed. J.P. Klein and P.K. </editor> <booktitle> Goel, </booktitle> <pages> 11-22. </pages>
Reference: <author> Lindley, D.V. and Smith, A.F.M. </author> <year> (1972). </year> <title> Bayes estimates for the linear model (with discussion). </title>
Reference: <author> J. R. </author> <title> Statist. </title> <journal> Soc. </journal> <volume> B 34 1-42. </volume>
Reference: <author> Liu, J.S. </author> <year> (1994). </year> <title> The collapsed Gibbs sampler in Bayesian computations with application to a gene regulation problem. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 89, </volume> <pages> 958-966. </pages> | <year> (1996). </year> <title> Nonparametric hierarchical Bayes via sequential imputations. </title> <journal> Ann. Statist., </journal> <volume> 24, </volume> <pages> 910-930. </pages>
Reference: <author> Liu, J.S. and Chen, R. </author> <year> (1997). </year> <title> Monte Carlo methods for dynamic systems. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference: <author> MacEachern, S.N. </author> <year> (1994). </year> <title> Estimating normal means with a conjugate style Dirichlet process prior. </title> <journal> Commun. Statist. Simulation and Computation 23, </journal> <pages> 727-741. </pages>
Reference: <author> MacEachern, S.N. and Muller, P. </author> <year> (1994). </year> <title> Estimating mixtures of Dirichlet process models. </title> <type> ISDS Discussion Paper, </type> <institution> Duke University. </institution>
Reference: <author> West, M., Muller, P. and Escobar, M.D. </author> <year> (1994). </year> <title> Hierarchical priors and mixture models, with application in regression and density estimation. In Aspects of Uncertainty: A tribute to D.V. Lindley, </title> <editor> ed. A.F.M. Smith and P. </editor> <publisher> Freeman, </publisher> <month> 363-368. </month> <title> 17 M = :1 M = 1 based on 10,000 iterations of the sequential importance sampler S2. 18 M = :1 M = 1 based on 10000 iterations of the sequential importance sampler S2. 19 M = :1 M = 1 values of M . Ten batches based on 1000 iterations of the sequential importance sampler S2 were used to estimate the densities. </title> <type> 20 </type>
References-found: 21

