URL: http://cobar.cs.umass.edu/pubfiles/sigir97.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: ravela@cs.umass.edu  manmatha@cs.umass.edu  
Title: Image Retrieval by Appearance  
Author: S. Ravela and R. Manmatha 
Address: Amherst  Amherst  
Affiliation: Computer Vision Research Lab., Multimedia Indexing and Retrieval Group Center for Intelligent Information Retrieval, University of Massachusetts at  Multimedia Indexing and Retrieval Group Center for Intelligent Information Retrieval, University of Massachusetts at  
Abstract: A system to retrieve images using a syntactic description of appearance is presented. A multi-scale invariant vector representation is obtained by first filtering images in the database with Gaussian derivative filters at several scales and then computing low order differential invariants. The multi-scale representation is indexed for rapid retrieval. Queries are designed by the users from an example image by selecting appropriate regions. The invariant vectors corresponding to these regions are matched with those in the database both in feature space as well as in coordinate space and a match score is obtained for each image. The results are then displayed to the user sorted by the match score. From experiments conducted with over 1500 images it is shown that images similar in appearance and whose viewpoint is within 25 degrees of the query image can be retrieved with an average precision of 57.4% 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bimbo, A. D., and Pala, P. </author> <title> Image-indexing using shape-based visual features. </title> <booktitle> In Proc. IEEE Int. Conf. Patt. Recog. (1996), </booktitle> <volume> vol. 3, </volume> <pages> pp. 351-355. </pages>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape <ref> [16; 1; 18; 24; 30] </ref> and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> The earliest general image retrieval systems were designed by [2; 20]. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves <ref> [1; 18; 24; 30] </ref>. Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper.
Reference: [2] <author> Flickner, M., Sawhney, H., Niblack, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Lee, D., Petkovix, D., Steele, D., and Yanker, P. </author> <title> Query by image and video content: The qbic system. </title> <journal> IEEE Computer Magazine 28, </journal> <month> 9 (September </month> <year> 1995), </year> <pages> 23-30. </pages>
Reference-contexts: Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof <ref> [2; 7; 20] </ref>. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> Schmid and Mohr apply their algorithm primarily to the problem of object recognition, do not allow for the user to determine saliency and therefore have not applied their algorithm to retrieving similar images. The earliest general image retrieval systems were designed by <ref> [2; 20] </ref>. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves [1; 18; 24; 30]. <p> Schmid and Mohr apply their algorithm primarily to the problem of object recognition, do not allow for the user to determine saliency and therefore have not applied their algorithm to retrieving similar images. The earliest general image retrieval systems were designed by [2; 20]. In <ref> [2] </ref> the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves [1; 18; 24; 30]. <p> Of particular interest is work by [13] who use Gabor filters to retrieve texture similar images, without user interaction to determine region saliency. There have been attempts to combine different attributes. Shape, color and texture have been combined in <ref> [2; 20] </ref>. This combination is not transparent to the user; instead she must decide how to weight the different attributes. In [7] color and shape are combined by defining a composite metric over both. 3.
Reference: [3] <author> Florack, L. M. J. </author> <title> The Syntactic Structure of Scalar Images. </title> <type> PhD thesis, </type> <institution> University of Utrecht, </institution> <year> 1993. </year> <title> 16 Image Retrieval by Appearance </title>
Reference-contexts: The proposed representation is also syntactic. This is because the filter responses are obtained solely from the signal content and without the use of "global context" or "symbolic interpretation". Further, the family of Gaussian filters are unique in their ability to describe the scale-space or deep structure <ref> [9; 11; 28; 3] </ref> of a function. Consequently, the change in appearance of an image due to a change in the viewing geometry can be computed by equivalently deforming the filter [14; 15]. <p> In this paper an indexable strategy for image retrieval is developed using feature vectors that are constructed using combinations of the derivative filter outputs. These combinations yield a set of differential invariants <ref> [3] </ref> that are invariant to two-dimensional rigid transformations. Retrieval is achieved in two computational steps. During the off-line computation phase each image in the database is first filtered at sampled locations and then filter responses across the entire database are indexed. <p> That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by <ref> [3] </ref>. In [21] tracking is done by using a vector of Gaussian derivatives which are indexed. [23] use use indexed differential invariants for object recognition. We also use index on differential invariants but there are several differences between the approach presented here and theirs. <p> A full review of scale-space is beyond the scope of this paper and the reader is referred to <ref> [31; 9; 3; 11; 28] </ref> for a study. Here some of the important consequences of incorporating scale space are considered. For increasing values of the Gaussian filter admits a narrowing band of frequencies and I will appear smoother. <p> This issue is partially addressed by transforming the multi-scale feature vector so that it is invariant to 2D rigid transformations. Given the derivatives of an image I irreducible differential invariants, that are invariant under the group of displacements can be computed in a systematic manner <ref> [3] </ref>. The term irreducible is used because other invariants can be reduced to a 8 Image Retrieval by Appearance combination of the irreducible set. The value of these entities independent of the choice of coordinate frame (up to rotations) for the low orders (two here) terms are enumerated.
Reference: [4] <author> Gorkani, M. M., and Picard, R. W. </author> <title> Texture orientation for sorting photos 'at a glance'. </title> <booktitle> In Proc. 12th Int. Conf. on Pattern Recognition (October 1994), </booktitle> <pages> pp. </pages> <month> A459-A464. </month>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features <ref> [12; 4; 20; 13] </ref>, shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. <p> Texture based image retrieval is also related to the appearance based work presented in this paper. Using Wold modeling, in [12] the authors try to classify the entire Brodatz texture and in <ref> [4] </ref> attempt to classify scenes, such as city and country. Of particular interest is work by [13] who use Gabor filters to retrieve texture similar images, without user interaction to determine region saliency. There have been attempts to combine different attributes.
Reference: [5] <author> Gudivada, V. N., and Raghavan, V. V. </author> <title> Content-based image retrieval systems. </title> <journal> IEEE Computer Magazine 28, </journal> <month> 9 (September </month> <year> 1995), </year> <pages> 18-21. </pages>
Reference-contexts: The application potential for fast and effective image retrieval is enormous; ranging from database management in museums and medicine, architecture and interior design, image archiving, to constructing multi-media documents or presentations <ref> [5] </ref>. There are, however, several issues that must be understood before image retrieval is viable. Foremost among these is an understanding of what 'retrieval of relevant images' means. Relevance, for users of a retrieval system, is most likely associated with semantics.
Reference: [6] <author> Hancock, P. J. B., Bradley, R. J., and Smith, L. S. </author> <title> The principal components of natural images. </title> <booktitle> Network 3 (1992), </booktitle> <pages> 61-70. </pages>
Reference-contexts: use of Gaussian derivative filters to represent appearance is motivated by their use in describing the spatial structure [10] and its uniqueness in representing the scale-space of a function [11; 9; 31; 28] and the fact that the principal component of images are best described as Gaussians and their derivatives <ref> [6] </ref>. That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3].
Reference: [7] <author> Jain, A. K., and Vailaya, A. </author> <title> Image retrieval using color and shape. </title> <booktitle> Pattern Recognition 29 (1996), </booktitle> <pages> 1233-1244. </pages>
Reference-contexts: Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof <ref> [2; 7; 20] </ref>. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> There have been attempts to combine different attributes. Shape, color and texture have been combined in [2; 20]. This combination is not transparent to the user; instead she must decide how to weight the different attributes. In <ref> [7] </ref> color and shape are combined by defining a composite metric over both. 3. SYNTACTIC REPRESENTATION OF APPEARANCE This section begins by making explicit the notion of appearance and the uniqueness of Gaussian derivative filters therein.
Reference: [8] <author> Kirby, M., and Sirovich, L. </author> <title> Application of the kruhnen-loeve procedure for the characterization of human faces. </title> <journal> IEEE Trans. Patt. Anal. and Mach. Intel. </journal> <volume> 12, </volume> <month> 1 (January </month> <year> 1990), </year> <pages> 103-108. </pages>
Reference-contexts: That is, objects that appear to be visually similar can be retrieved by a characterization of the shape of the intensity surface. Different representations of appearance have been used in object recognition [19; 23] and have been applied to specific types of retrieval such as face recognition <ref> [8; 29] </ref>. To the best of our knowledge the system presented here is the first attempt to characterize appearance to retrieve similar images and in this paper the development of Synapse (Syntactic Appearance Search Engine), an image database search engine, is documented. <p> This space is constructed by treating the image as a fixed length vector, and then computing the principal components across the entire database. The images therefore have to be size and intensity normalized, segmented and trained. Similarly, using principal component representations described in <ref> [8] </ref> face recognition is performed in [29]. In [27] the traditional eigen representation is augmented by using most discriminant features and is applied to image retrieval. The authors apply eigen representation to retrieval of several classes of objects.
Reference: [9] <author> Koenderink, J. J. </author> <title> The structure of images. </title> <booktitle> Biological Cybernetics 50 (1984), </booktitle> <pages> 363-396. </pages>
Reference-contexts: The proposed representation is also syntactic. This is because the filter responses are obtained solely from the signal content and without the use of "global context" or "symbolic interpretation". Further, the family of Gaussian filters are unique in their ability to describe the scale-space or deep structure <ref> [9; 11; 28; 3] </ref> of a function. Consequently, the change in appearance of an image due to a change in the viewing geometry can be computed by equivalently deforming the filter [14; 15]. <p> The use of Gaussian derivative filters to represent appearance is motivated by their use in describing the spatial structure [10] and its uniqueness in representing the scale-space of a function <ref> [11; 9; 31; 28] </ref> and the fact that the principal component of images are best described as Gaussians and their derivatives [6]. That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3]. <p> A full review of scale-space is beyond the scope of this paper and the reader is referred to <ref> [31; 9; 3; 11; 28] </ref> for a study. Here some of the important consequences of incorporating scale space are considered. For increasing values of the Gaussian filter admits a narrowing band of frequencies and I will appear smoother.
Reference: [10] <author> Koenderink, J. J., and van Doorn, A. J. </author> <title> Representation of local geometry in the visual system. </title> <booktitle> Biological Cybernetics 55 (1987), </booktitle> <pages> 367-375. </pages>
Reference-contexts: This set or vector of responses, called a feature vector, when computed with filters at a certain scale, and up to order N, completely and uniquely characterize the local jet <ref> [10] </ref> of order N, at that scale. Since the local jet generalizes to the Taylor series expansion of the underlying local intensity function, it is, therefore, argued that the local appearance of the intensity Image Retrieval by Appearance 3 function is represented to the order of expansion. <p> Further the method presented uses no learning, does not depend on constant sized images and deals with embedded backgrounds and heterogeneous collections of images using local representations of appearance. The use of Gaussian derivative filters to represent appearance is motivated by their use in describing the spatial structure <ref> [10] </ref> and its uniqueness in representing the scale-space of a function [11; 9; 31; 28] and the fact that the principal component of images are best described as Gaussians and their derivatives [6]. That is there is a natural decomposition of images into Gaussians and their derivatives.
Reference: [11] <author> Lindeberg, T. </author> <title> Scale-Space Theroy in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: The proposed representation is also syntactic. This is because the filter responses are obtained solely from the signal content and without the use of "global context" or "symbolic interpretation". Further, the family of Gaussian filters are unique in their ability to describe the scale-space or deep structure <ref> [9; 11; 28; 3] </ref> of a function. Consequently, the change in appearance of an image due to a change in the viewing geometry can be computed by equivalently deforming the filter [14; 15]. <p> The use of Gaussian derivative filters to represent appearance is motivated by their use in describing the spatial structure [10] and its uniqueness in representing the scale-space of a function <ref> [11; 9; 31; 28] </ref> and the fact that the principal component of images are best described as Gaussians and their derivatives [6]. That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3]. <p> A full review of scale-space is beyond the scope of this paper and the reader is referred to <ref> [31; 9; 3; 11; 28] </ref> for a study. Here some of the important consequences of incorporating scale space are considered. For increasing values of the Gaussian filter admits a narrowing band of frequencies and I will appear smoother.
Reference: [12] <author> Liu, F., and Picard, R. W. </author> <title> Periodicity, directionality, and randomness: Wold features for image modeling and retrieval. </title> <journal> IEEE Trans. </journal> <volume> PAMI 18, </volume> <month> 7 (July </month> <year> 1996), </year> <pages> 722-733. </pages>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features <ref> [12; 4; 20; 13] </ref>, shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. <p> Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper. Using Wold modeling, in <ref> [12] </ref> the authors try to classify the entire Brodatz texture and in [4] attempt to classify scenes, such as city and country. Of particular interest is work by [13] who use Gabor filters to retrieve texture similar images, without user interaction to determine region saliency.
Reference: [13] <author> Ma, W. Y., and Manjunath, B. S. </author> <title> Texture-based pattern retrieval from image databases. </title> <booktitle> Multimedia Tools and Applications 2, </booktitle> <month> 1 (January </month> <year> 1996), </year> <pages> 35-51. </pages>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features <ref> [12; 4; 20; 13] </ref>, shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. <p> Texture based image retrieval is also related to the appearance based work presented in this paper. Using Wold modeling, in [12] the authors try to classify the entire Brodatz texture and in [4] attempt to classify scenes, such as city and country. Of particular interest is work by <ref> [13] </ref> who use Gabor filters to retrieve texture similar images, without user interaction to determine region saliency. There have been attempts to combine different attributes. Shape, color and texture have been combined in [2; 20].
Reference: [14] <author> Manmatha, R. </author> <title> Measuring affine transformations using gaussian filters. </title> <booktitle> In Proc. European Conference on Computer Vision (1994), </booktitle> <volume> vol. 2, </volume> <pages> pp. 159-164. </pages>
Reference-contexts: Further, the family of Gaussian filters are unique in their ability to describe the scale-space or deep structure [9; 11; 28; 3] of a function. Consequently, the change in appearance of an image due to a change in the viewing geometry can be computed by equivalently deforming the filter <ref> [14; 15] </ref>. In previous work it was demonstrated that feature vectors constructed using Gaussian derivative filters can be used to retrieve objects that are not only scaled versions of each other but also similar (in appearance) and within small view variations of one another [22]. <p> Without loss of generality assume that the scaling is centered at the origin. That is I 0 (p) = I 1 (sp) Then the following relations hold 1 I yx = I xy and is therefore dropped Image Retrieval by Appearance 7 <ref> [14; 15] </ref> I 0 (p) ? g (k) (; ) = I 1 (sp) ? g (k) (; s) where, g (k) (; t) = t k g i 1 :::i k (; t) (3) These equations state that if the image I s is a scaled version of I 0
Reference: [15] <author> Manmatha, R., and Oliensis, J. </author> <title> Measuring affine transform i, scale and rotation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop (Washington D.C., </booktitle> <year> 1993), </year> <pages> pp. 449-458. </pages>
Reference-contexts: Further, the family of Gaussian filters are unique in their ability to describe the scale-space or deep structure [9; 11; 28; 3] of a function. Consequently, the change in appearance of an image due to a change in the viewing geometry can be computed by equivalently deforming the filter <ref> [14; 15] </ref>. In previous work it was demonstrated that feature vectors constructed using Gaussian derivative filters can be used to retrieve objects that are not only scaled versions of each other but also similar (in appearance) and within small view variations of one another [22]. <p> Without loss of generality assume that the scaling is centered at the origin. That is I 0 (p) = I 1 (sp) Then the following relations hold 1 I yx = I xy and is therefore dropped Image Retrieval by Appearance 7 <ref> [14; 15] </ref> I 0 (p) ? g (k) (; ) = I 1 (sp) ? g (k) (; s) where, g (k) (; t) = t k g i 1 :::i k (; t) (3) These equations state that if the image I s is a scaled version of I 0
Reference: [16] <author> Mehrotra, R., and Gary, J. E. </author> <title> Similar-shape retrieval in shape data management. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 9 (September </month> <year> 1995), </year> <pages> 57-62. </pages>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape <ref> [16; 1; 18; 24; 30] </ref> and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> The earliest general image retrieval systems were designed by [2; 20]. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons <ref> [16] </ref> and curves [1; 18; 24; 30]. Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper.
Reference: [17] <author> Mehtre, B. M., Kankanhalli, M. S., Narasimhalu, A. D., and Man, G. C. </author> <title> Color matching for image retrieval. </title> <journal> Pattern Recognition Letters 16, </journal> <month> 3 (March </month> <year> 1995), </year> <pages> 325-331. </pages>
Reference-contexts: In particular, images are annotated with text and then retrieved using a text retrieval engine. This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color <ref> [26; 25; 17] </ref>, texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects.
Reference: [18] <author> Mokhtarian, F., Abbasi, S., and Kittler, J. </author> <title> Efficient and robust retrieval by shape content through curvature scale-space. </title> <booktitle> In First International Workshop on Image Databases and Multi-media Search (August 1996). </booktitle>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape <ref> [16; 1; 18; 24; 30] </ref> and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> The earliest general image retrieval systems were designed by [2; 20]. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves <ref> [1; 18; 24; 30] </ref>. Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper.
Reference: [19] <author> Nayar, S. K., Murase, H., and Nene, S. A. </author> <title> Parametric appearance representation. In Early Visual Learning. </title> <publisher> Oxford University Press, </publisher> <month> February </month> <year> 1996. </year>
Reference-contexts: The experiments conducted in this paper verify this association. That is, objects that appear to be visually similar can be retrieved by a characterization of the shape of the intensity surface. Different representations of appearance have been used in object recognition <ref> [19; 23] </ref> and have been applied to specific types of retrieval such as face recognition [8; 29]. <p> Finally, experimental results containing examples, recall, precision and execution time are presented in Section 5. 2. RELATED WORK Several authors have tried to characterize the appearance of an object via a description of the intensity surface. In the context of object recognition <ref> [19] </ref> represent 4 Image Retrieval by Appearance Fig. 1. Allowing the user to construct queries by selecting the box shown the appearance of an object using a parametric eigen space description.
Reference: [20] <author> Pentland, A., Picard, R. W., and Sclaroff, S. Photobook: </author> <title> Tools for content-based manipulation of databases. </title> <booktitle> In Proc. Storafe and Retrieval of Image and Video Databases II (1994), </booktitle> <volume> vol. 2, </volume> <booktitle> SPIE, </booktitle> <pages> pp. 34-47. </pages>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features <ref> [12; 4; 20; 13] </ref>, shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. <p> Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof <ref> [2; 7; 20] </ref>. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> Schmid and Mohr apply their algorithm primarily to the problem of object recognition, do not allow for the user to determine saliency and therefore have not applied their algorithm to retrieving similar images. The earliest general image retrieval systems were designed by <ref> [2; 20] </ref>. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves [1; 18; 24; 30]. <p> Of particular interest is work by [13] who use Gabor filters to retrieve texture similar images, without user interaction to determine region saliency. There have been attempts to combine different attributes. Shape, color and texture have been combined in <ref> [2; 20] </ref>. This combination is not transparent to the user; instead she must decide how to weight the different attributes. In [7] color and shape are combined by defining a composite metric over both. 3.
Reference: [21] <author> Rao, R., and Ballard, D. </author> <title> Object indexing using an iconic sparse distributed memory. </title> <booktitle> In Proc. International Conference on Computer Vision (1995), IEEE, </booktitle> <pages> pp. 24-31. </pages>
Reference-contexts: That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3]. In <ref> [21] </ref> tracking is done by using a vector of Gaussian derivatives which are indexed. [23] use use indexed differential invariants for object recognition. We also use index on differential invariants but there are several differences between the approach presented here and theirs.
Reference: [22] <author> Ravela, S., Manmatha, R., and Riseman, E. M. </author> <title> Image retrieval using scale-space matching. </title> <booktitle> In Computer Vision - ECCV '96 (Cambridge, </booktitle> <address> U.K., </address> <month> April </month> <year> 1996), </year> <editor> B. Buxton and R. Cipolla, Eds., </editor> <volume> vol. </volume> <booktitle> 1 of Lecture Notes in Computer Science, 4th European Conf. Computer Vision, </booktitle> <publisher> Springer. </publisher>
Reference-contexts: In previous work it was demonstrated that feature vectors constructed using Gaussian derivative filters can be used to retrieve objects that are not only scaled versions of each other but also similar (in appearance) and within small view variations of one another <ref> [22] </ref>. In this paper an indexable strategy for image retrieval is developed using feature vectors that are constructed using combinations of the derivative filter outputs. These combinations yield a set of differential invariants [3] that are invariant to two-dimensional rigid transformations. Retrieval is achieved in two computational steps. <p> In practice the zeroth order terms are dropped to achieve invariance to constant intensity changes. A measure of similarity between two multi-scale vectors can be obtained by correlating them or computing the distance between the vectors. In earlier work <ref> [22] </ref> it was shown that multi-scale vectors can be used to retrieve images that are not only scaled versions of each other but also ones that are similar to the query. This was achieved by correlating the derivative feature vectors across scales using the scale shifting theorem presented above. <p> These images are also observed to be visually similar and we posit that this method has good potential for image retrieval. While a discussion of matching objects across different sizes was presented and has been implemented elsewhere <ref> [22] </ref>, in this paper, the multi-scale invariant vector was used only to robustly characterize appearance. The next immediate step is to explicitly incorporate matching across size variations.
Reference: [23] <author> Schmid, C., and Mohr, R. </author> <title> Combining greyvalue invariants with local constraints for object recognition. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition (June 1996), IEEE. </booktitle>
Reference-contexts: The experiments conducted in this paper verify this association. That is, objects that appear to be visually similar can be retrieved by a characterization of the shape of the intensity surface. Different representations of appearance have been used in object recognition <ref> [19; 23] </ref> and have been applied to specific types of retrieval such as face recognition [8; 29]. <p> That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3]. In [21] tracking is done by using a vector of Gaussian derivatives which are indexed. <ref> [23] </ref> use use indexed differential invariants for object recognition. We also use index on differential invariants but there are several differences between the approach presented here and theirs.
Reference: [24] <author> Sclaroff, S. </author> <title> Encoding deformable shape categories for efficient content-based search. </title> <booktitle> In Proc. First International Workshop on Image Databases and Multi-Media Search (August 1996). </booktitle>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape <ref> [16; 1; 18; 24; 30] </ref> and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> The earliest general image retrieval systems were designed by [2; 20]. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves <ref> [1; 18; 24; 30] </ref>. Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper.
Reference: [25] <author> Strickler, M., and Orengo, M. </author> <title> Similarity of color images. In Storage and Retrieval for Image and Video Databases III (1995), </title> <booktitle> vol. 2420 of SPIE Proceedings Series, </booktitle> <pages> pp. 318-192. </pages>
Reference-contexts: In particular, images are annotated with text and then retrieved using a text retrieval engine. This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color <ref> [26; 25; 17] </ref>, texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects.
Reference: [26] <author> Swain, M., and Ballard, D. </author> <title> Color indexing. </title> <booktitle> Int. Jrnl. Comput. Vision 7, 1 (1991), </booktitle> <pages> 11-32. </pages>
Reference-contexts: In particular, images are annotated with text and then retrieved using a text retrieval engine. This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color <ref> [26; 25; 17] </ref>, texture features [12; 4; 20; 13], shape [16; 1; 18; 24; 30] and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects.
Reference: [27] <author> Swets, D. L., and Weng, J. </author> <title> Using discriminant eigen features for retrieval. </title> <journal> IEEE Trans. Patt. Anal. and Mach. </journal> <volume> Intel. </volume> <month> 18 (August </month> <year> 1996), </year> <pages> 831-836. </pages> <note> [28] ter Har Romeny, </note> <author> B. M. </author> <title> Geometry Driven Diffusion in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year> <title> Image Retrieval by Appearance 17 </title>
Reference-contexts: The images therefore have to be size and intensity normalized, segmented and trained. Similarly, using principal component representations described in [8] face recognition is performed in [29]. In <ref> [27] </ref> the traditional eigen representation is augmented by using most discriminant features and is applied to image retrieval. The authors apply eigen representation to retrieval of several classes of objects. The issue however is that these classes are manually determined and training must be performed on each.
Reference: [29] <author> Turk, M., and Pentland, A. </author> <title> Eigen faces for recognition. </title> <journal> Jrnl. Cognitive Neuroscience 3 (1991), </journal> <pages> 71-86. </pages>
Reference-contexts: That is, objects that appear to be visually similar can be retrieved by a characterization of the shape of the intensity surface. Different representations of appearance have been used in object recognition [19; 23] and have been applied to specific types of retrieval such as face recognition <ref> [8; 29] </ref>. To the best of our knowledge the system presented here is the first attempt to characterize appearance to retrieve similar images and in this paper the development of Synapse (Syntactic Appearance Search Engine), an image database search engine, is documented. <p> This space is constructed by treating the image as a fixed length vector, and then computing the principal components across the entire database. The images therefore have to be size and intensity normalized, segmented and trained. Similarly, using principal component representations described in [8] face recognition is performed in <ref> [29] </ref>. In [27] the traditional eigen representation is augmented by using most discriminant features and is applied to image retrieval. The authors apply eigen representation to retrieval of several classes of objects. The issue however is that these classes are manually determined and training must be performed on each.
Reference: [30] <author> Vailaya, A., Zhong, Y., and Jain, A. K. </author> <title> A hierarchical system for efficient image retrieval. </title> <booktitle> In Proc. Int. Conf. on Patt. </booktitle> <address> Recog. </address> <month> (August </month> <year> 1996). </year>
Reference-contexts: This solution is limited because the variability and richness of images cannot be effectively captured by annotations within any reasonable effort. Recent work has focused directly on image content such as color [26; 25; 17], texture features [12; 4; 20; 13], shape <ref> [16; 1; 18; 24; 30] </ref> and combinations thereof [2; 7; 20]. In this paper images are retrieved using a characterization of the visual appearance of objects. Intuitively an object's visual appearance in an image is closely related to a description of the shape of its intensity surface. <p> The earliest general image retrieval systems were designed by [2; 20]. In [2] the shape queries require prior manual segmentation of the database which is undesirable and not practical for most applications. There has been other work on shape using a description of polygons [16] and curves <ref> [1; 18; 24; 30] </ref>. Of particular interest is work by Mokhtarian et. al. where they use the curvature scale-space to represent shape. Texture based image retrieval is also related to the appearance based work presented in this paper.
Reference: [31] <author> Witkin, A. P. </author> <title> Scale-space filtering. </title> <booktitle> In Proc. Intl. Joint Conf. Art. Intell. </booktitle> <year> (1983), </year> <pages> pp. 1019-1023. </pages>
Reference-contexts: The use of Gaussian derivative filters to represent appearance is motivated by their use in describing the spatial structure [10] and its uniqueness in representing the scale-space of a function <ref> [11; 9; 31; 28] </ref> and the fact that the principal component of images are best described as Gaussians and their derivatives [6]. That is there is a natural decomposition of images into Gaussians and their derivatives. The use of invariant transformations of Gaussians is borrowed from descriptions provided by [3]. <p> A full review of scale-space is beyond the scope of this paper and the reader is referred to <ref> [31; 9; 3; 11; 28] </ref> for a study. Here some of the important consequences of incorporating scale space are considered. For increasing values of the Gaussian filter admits a narrowing band of frequencies and I will appear smoother.
References-found: 30

