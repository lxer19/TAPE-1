URL: http://polaris.cs.uiuc.edu/reports/1399.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Email: tu,padua@csrd.uiuc.edu  
Title: Gated SSA-Based Demand-Driven Symbolic Analysis for Parallelizing Compilers  
Author: Peng Tu and David Padua 
Address: 1308 W. Main Street, Urbana, Illinois 61801-2307  
Affiliation: Center for Supercomputing Research and Development Coordinated Science Laboratory, University of Illinois at Urbana-Champaign  
Abstract: In this paper, we present a GSA-based technique that performs more efficient and more precise symbolic analysis of predicated assignments, recurrences and index arrays. The efficiency is improved by using a backward substitution scheme that performs resolution of assertions on-demand and uses heuristics to limit the number of substitution. The precision is increased by utilizing the gating predicate information embedded in the GSA and the control dependence information in the program flow graph. Examples from array privatization are used to illustrate how the technique aids loop parallelization. 
Abstract-found: 1
Intro-found: 1
Reference: [ABCF88] <author> F. Allen, M. Burke, R. Cytron, and J. Ferrante. </author> <title> An overview of the ptran analysis system for multiprocessing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> (5):617-640, October 1988. 
Reference-contexts: If the recurrence can be transformed into an equivalent expression that only depends on the loop index, replacing the induction variable with the equivalent expression enables the loop to be executed in parallel. Various techniques have been developed for linear induction variable recognition [Ken81] [ASU86] <ref> [ABCF88] </ref>. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities [BE94b].
Reference: [AH90] <author> Z. Ammarguellat and W. L. Harrison. </author> <title> Automatic recognition of induction variables and recurrence relations by abstract interpretation. </title> <booktitle> In Proc. of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 283-295. </pages> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: They use a join function to compute the intersection of possible values at the confluence nodes of the flow graph to cut down the amount of information to be maintained. Again the predicated conditional information is lost in the join function. Abstract interpretation has also been used in <ref> [AH90] </ref> for induction variable substitution. Most systems use symbolic global forward substitution or propagation to compute values and conditions at all points in the program.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the U. S. Army or government. To appear in the 1995 ACM International Conference on Supercomputing in each iteration of a loop <ref> [ASU86] </ref>. If a loop contains an induction variable in the form of a recurrence, it cannot be executed in parallel due to the flow dependence in the recurrence. <p> If the recurrence can be transformed into an equivalent expression that only depends on the loop index, replacing the induction variable with the equivalent expression enables the loop to be executed in parallel. Various techniques have been developed for linear induction variable recognition [Ken81] <ref> [ASU86] </ref> [ABCF88]. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities [BE94b]. <p> Given a CF G = (N; E) and its DT , edges in E from descendents to ancestors in DT are called back edges. Given a back edge n ! d, the natural loop <ref> [ASU86] </ref> of the edge are the subgraph of d plus the set of nodes that can reach n without going through d. Node d is the header of the loop.
Reference: [AWZ88] <author> B. Alpern, M. N. Wegman, and F. K. Zadeck. </author> <title> Detecting equality of variables in programs. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-11, </pages> <year> 1988. </year>
Reference-contexts: In symbolic analysis, we sometimes need to compare these expressions. Alpern, Wegman, and Zadeck <ref> [AWZ88] </ref> define a congruence relation between expressions containing -assignments. The congruent variables are shown to have equivalent values under structural isomorphism, i.e., if they can be mapped to the same canonical form. <p> Using the GSA sparse representation and the demand-driven approach, our approach can do more aggressive analysis only on demand. The SSA form has been used to determine the equivalence of symbolic variables and construct global value graph in a program <ref> [AWZ88] </ref> [RWZ88]. Nascent [Wol92] uses SSA to do a comprehensive analysis of recurrences. Their representation does not include the gating predicate. The SSA representation in Nascent is through an explicit use-def chain which they called a demand-driven form of SSA.
Reference: [BE94a] <author> William Blume and Rudolf Eigenmann. </author> <title> The range test: A dependence test for symbolic, non-linear expressions. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: The examples illustrate how these techniques improve the effectiveness of array privatization. The techniques are also useful in improving the accuracy of dependence analysis <ref> [BE94b, BE94a] </ref>. The main task when performing privatization of an array A is to determine whether in all iterations of the do loop each access to an element of A is dominated by an assignment to the same element.
Reference: [BE94b] <author> William Blume and Rudolf Eigenmann. </author> <title> Symbolic analysis techniques needed for the effective parallelization of the perfect benchmarks. </title> <type> Technical Report 1332, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities <ref> [BE94b] </ref>. These techniques include analysis of the possible values of variables to prove independent array accesses for dependence analysis, induction and reduction recognition to transform flow dependence, and scalar and array privatization to eliminate memory-related dependences. <p> The examples illustrate how these techniques improve the effectiveness of array privatization. The techniques are also useful in improving the accuracy of dependence analysis <ref> [BE94b, BE94a] </ref>. The main task when performing privatization of an array A is to determine whether in all iterations of the do loop each access to an element of A is dominated by an assignment to the same element.
Reference: [BEF + 94] <author> Bill Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, Bill Pottenger, Lawrence Rauchw-erger, Peng Tu, and Stephen Weatherford. Po-laris: </author> <title> The next generation in parallelizing compilers. </title> <booktitle> In Proc. 7th Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Recent developments in parallelizing compilers have resulted in the increased use of the symbolic analysis technique to facilitate parallelism detection and program transformation. Several research compilers such as Parafrase-2 [HP92] and Nascent [GSW] use symbolic analysis to identify and transform induction variables. In the Polaris <ref> [BEF + 94] </ref> restructuring compiler, symbolic analysis is also used for dependence analysis, symbolic range propagation and array privatization [BEF + 94] [TP93]. Simple symbolic analysis techniques are used regularly in the traditional optimizing compilers. Constant propagation detects symbolic variables that are equivalent to constants. <p> Several research compilers such as Parafrase-2 [HP92] and Nascent [GSW] use symbolic analysis to identify and transform induction variables. In the Polaris <ref> [BEF + 94] </ref> restructuring compiler, symbolic analysis is also used for dependence analysis, symbolic range propagation and array privatization [BEF + 94] [TP93]. Simple symbolic analysis techniques are used regularly in the traditional optimizing compilers. Constant propagation detects symbolic variables that are equivalent to constants. Also, common subexpression elimination determines the equivalence of two symbolic expressions to avoid redundant computation.
Reference: [BMO90] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proceedings of the SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This paper presents a new symbolic analysis technique for parallelizing compilers. It is based on Static Single Assignment (SSA) representation [CFR + 91] of program. We use a more elaborate version of the SSA known as the Gated Single Assignment (GSA) form <ref> [BMO90] </ref>. The value of a symbolic variable is represented by a symbolic expression involving other symbolic variables, constants, and pseudo-functions in the GSA. We present algorithms to build and analyze the symbolic expressions. It combines the demand-driven interpretation of GSA and the path conditions to analyze complicated symbolic expressions. <p> The function selects the last value of X computed by the loop. The function, as defined in <ref> [BMO90] </ref>, handles loops with a zero-trip count awkwardly. <p> The most widely used algorithm to construct the SSA form is presented in [CFR + 91]. For GSA construction, the original algorithm in <ref> [BMO90] </ref> uses an SSA representation and the Program Dependence Graph (PDG). Another algorithm in [Hav93] uses SSA and the program control flow graph. These two algorithms can only handle reducible control flow graphs. <p> GSA has also been used in Parascope to build the global value graph [Hav93]. Our demand-driven backward substitution in GSA and using control dependences to project values are unique. The currently most used algorithm for building SSA form is given in [CFR + 91]. GSA was introduced in <ref> [BMO90] </ref> as 8 a part of the Program Dependence Web (PDW) which is an extension of the Program Dependence Graph (PDG) [FOW87]. An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. <p> GSA was introduced in <ref> [BMO90] </ref> as 8 a part of the Program Dependence Web (PDW) which is an extension of the Program Dependence Graph (PDG) [FOW87]. An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. Havlak [Hav93] develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. Control dependence was introduced in [FOW87] as part of PDG.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Again, we need symbolic analysis to prove that JLOW is less than or equal to 2 and JUP is greater than or equal to (JMAX-1). This paper presents a new symbolic analysis technique for parallelizing compilers. It is based on Static Single Assignment (SSA) representation <ref> [CFR + 91] </ref> of program. We use a more elaborate version of the SSA known as the Gated Single Assignment (GSA) form [BMO90]. The value of a symbolic variable is represented by a symbolic expression involving other symbolic variables, constants, and pseudo-functions in the GSA. <p> The (I &gt; N; X 1 ) in the assignment above can be refined to (I = N + 1; X 1 ) because the step of I is 1 and N is an integer variable. The most widely used algorithm to construct the SSA form is presented in <ref> [CFR + 91] </ref>. For GSA construction, the original algorithm in [BMO90] uses an SSA representation and the Program Dependence Graph (PDG). Another algorithm in [Hav93] uses SSA and the program control flow graph. These two algorithms can only handle reducible control flow graphs. <p> We can use the GSA representation to find out the value of JPLUS (J) at statement U. To this end, we use an extension of the SSA representation to include arrays in the following way <ref> [CFR + 91] </ref>: 1. Create a new array name for each array assignment. 2. Use the subscript to identify which element is assigned. 3. Replace the assignment with an update function ff (array; subscript; value). <p> GSA has also been used in Parascope to build the global value graph [Hav93]. Our demand-driven backward substitution in GSA and using control dependences to project values are unique. The currently most used algorithm for building SSA form is given in <ref> [CFR + 91] </ref>. GSA was introduced in [BMO90] as 8 a part of the Program Dependence Web (PDW) which is an extension of the Program Dependence Graph (PDG) [FOW87]. An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. <p> Havlak [Hav93] develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. Control dependence was introduced in [FOW87] as part of PDG. The SSA construction paper <ref> [CFR + 91] </ref> also has an algorithm for building control dependences. The algorithm in [CFR + 91] for building iterative dominance frontiers can be used on the reverse flow graph to build the iterative post-dominance frontiers (iterative control dependences) used in this paper. 8 Conclusion Symbolic analysis is important to parallelizing <p> Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. Control dependence was introduced in [FOW87] as part of PDG. The SSA construction paper <ref> [CFR + 91] </ref> also has an algorithm for building control dependences. The algorithm in [CFR + 91] for building iterative dominance frontiers can be used on the reverse flow graph to build the iterative post-dominance frontiers (iterative control dependences) used in this paper. 8 Conclusion Symbolic analysis is important to parallelizing compilers.
Reference: [CH78] <author> P. Cousot and N. Halbwachs. </author> <title> Automatic discovery of linear restraints among variables of a program. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 84-97, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: Constant propagation detects symbolic variables that are equivalent to constants. Also, common subexpression elimination determines the equivalence of two symbolic expressions to avoid redundant computation. Symbolic analysis has also been used to prove assertions for program verification and debugging <ref> [CH78] </ref>. Recent experiments on the effectiveness of parallelizing compilers have found that symbolic variables present problems for dependence analysis and parallelization transformations. <p> We also use the iterative control dependences to represent path conditions. Symbolic analysis is also related to the problem of automatic proof of invariant assertions in program. Symbolic execution can be considered as abstract interpretation [CH92]. In <ref> [CH78] </ref>, abstract interpretation is used to discover the linear relationships between variables. It can be used to propagate symbolic linear expressions as possible values for symbolic variables. However, the predicate guarding the conditional possible values is not included in the representation and cannot be propagated.
Reference: [CH92] <author> P. Cousot and N. Halbwachs. </author> <title> Abstract interpretation and application to logic programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 13(2-3):103-179, </volume> <year> 1992. </year>
Reference-contexts: We also use the iterative control dependences to represent path conditions. Symbolic analysis is also related to the problem of automatic proof of invariant assertions in program. Symbolic execution can be considered as abstract interpretation <ref> [CH92] </ref>. In [CH78], abstract interpretation is used to discover the linear relationships between variables. It can be used to propagate symbolic linear expressions as possible values for symbolic variables. However, the predicate guarding the conditional possible values is not included in the representation and cannot be propagated.
Reference: [CHT79] <author> T. E. Cheatham, G. H. Holloway, and J. A. Townley. </author> <title> Symbolic evaluation and the analysis of programs. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 5(4) </volume> <pages> 402-417, </pages> <year> 1979. </year>
Reference-contexts: Corresponding to each path there is a path condition, a boolean expression that is true if the path is executed [CR85] <ref> [CHT79] </ref>. These techniques have exponential time and space requirements which limit their applicability in practical situations. The GSA representation of symbolic expression in this paper is a new way to represent predicated path values. With GSA, the condition and value is represented in a compact way.
Reference: [CKPK90] <author> George Cybenko, Lyle Kipp, Lynn Pointer, and David Kuck. </author> <title> Supercomputer performance evaluation and the perfect benchmarks. </title> <booktitle> In Proceedings of ICS, </booktitle> <address> Amsterdam, Netherlands, </address> <pages> pages 162-174, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Various techniques have been developed for linear induction variable recognition [Ken81] [ASU86] [ABCF88]. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks <ref> [CKPK90] </ref>, the compiler needs more symbolic analysis capabilities [BE94b]. These techniques include analysis of the possible values of variables to prove independent array accesses for dependence analysis, induction and reduction recognition to transform flow dependence, and scalar and array privatization to eliminate memory-related dependences.
Reference: [CR85] <author> L. A. Clarke and D. J. Richardson. </author> <title> Applications of symbolic evaluation. </title> <journal> Journal of Systems and Software, </journal> <volume> 5(1) </volume> <pages> 15-35, </pages> <year> 1985. </year>
Reference-contexts: Some of the techniques designed in the past proceed by computing path values, the set of symbolic values of a variable on all possible paths reaching a program point. Corresponding to each path there is a path condition, a boolean expression that is true if the path is executed <ref> [CR85] </ref> [CHT79]. These techniques have exponential time and space requirements which limit their applicability in practical situations. The GSA representation of symbolic expression in this paper is a new way to represent predicated path values. With GSA, the condition and value is represented in a compact way.
Reference: [FOW87] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependency graph and its uses in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The currently most used algorithm for building SSA form is given in [CFR + 91]. GSA was introduced in [BMO90] as 8 a part of the Program Dependence Web (PDW) which is an extension of the Program Dependence Graph (PDG) <ref> [FOW87] </ref>. An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. Havlak [Hav93] develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. <p> Havlak [Hav93] develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. Control dependence was introduced in <ref> [FOW87] </ref> as part of PDG. The SSA construction paper [CFR + 91] also has an algorithm for building control dependences.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of the NP-Completeness. </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: Incorporating the path condition in the analysis provides us with more power than GSA or SSA alone. 3.1 Bounds of Symbolic Expression The problem of determining whether P C P is undecidable in general and NP-Complete <ref> [GJ79] </ref> when all the conditions are boolean variables. Fortunately, path projection is most useful when the path condition obviously implies the predicates in the symbolic expressions. When the number of boolean variables in P C and SE is small, the cost of computing the path projection is also small.
Reference: [GSW] <author> M. P. Gerlek, E. Stoltz, and M. Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven ssa form. </title> <note> to appear on, ACM TPLAS. 9 </note>
Reference-contexts: 1 Introduction Recent developments in parallelizing compilers have resulted in the increased use of the symbolic analysis technique to facilitate parallelism detection and program transformation. Several research compilers such as Parafrase-2 [HP92] and Nascent <ref> [GSW] </ref> use symbolic analysis to identify and transform induction variables. In the Polaris [BEF + 94] restructuring compiler, symbolic analysis is also used for dependence analysis, symbolic range propagation and array privatization [BEF + 94] [TP93]. Simple symbolic analysis techniques are used regularly in the traditional optimizing compilers.
Reference: [Hav93] <author> Paul Havlak. </author> <title> Construction of thinned gated single-assignment form. </title> <booktitle> In Proc. 6rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: The most widely used algorithm to construct the SSA form is presented in [CFR + 91]. For GSA construction, the original algorithm in [BMO90] uses an SSA representation and the Program Dependence Graph (PDG). Another algorithm in <ref> [Hav93] </ref> uses SSA and the program control flow graph. These two algorithms can only handle reducible control flow graphs. Recently, we developed a more efficient algorithm that constructs GSA directly from program control flow graphs without going through the SSA conversion step [TP95]. <p> Their approach for constructing strongly connected regions for recurrences in the graph is similar to our backward substitution of names. GSA has also been used in Parascope to build the global value graph <ref> [Hav93] </ref>. Our demand-driven backward substitution in GSA and using control dependences to project values are unique. The currently most used algorithm for building SSA form is given in [CFR + 91]. <p> GSA was introduced in [BMO90] as 8 a part of the Program Dependence Web (PDW) which is an extension of the Program Dependence Graph (PDG) [FOW87]. An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. Havlak <ref> [Hav93] </ref> develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph [TP95]. Control dependence was introduced in [FOW87] as part of PDG.
Reference: [HP92] <author> M. R. Haghighat and C. D. Polychronopoulos. </author> <title> Symbolic program analysis and optimization for parallelizing compilers. </title> <booktitle> In Proc. 5rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Recent developments in parallelizing compilers have resulted in the increased use of the symbolic analysis technique to facilitate parallelism detection and program transformation. Several research compilers such as Parafrase-2 <ref> [HP92] </ref> and Nascent [GSW] use symbolic analysis to identify and transform induction variables. In the Polaris [BEF + 94] restructuring compiler, symbolic analysis is also used for dependence analysis, symbolic range propagation and array privatization [BEF + 94] [TP93]. <p> Various techniques have been developed for linear induction variable recognition [Ken81] [ASU86] [ABCF88]. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables <ref> [HP92] </ref> [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities [BE94b].
Reference: [Ken81] <author> K. Kennedy. </author> <title> A survey of data flow analysis techniques. </title> <editor> In S. Muchnick and N. Jones, editors, </editor> <title> Program Flow Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: If the recurrence can be transformed into an equivalent expression that only depends on the loop index, replacing the induction variable with the equivalent expression enables the loop to be executed in parallel. Various techniques have been developed for linear induction variable recognition <ref> [Ken81] </ref> [ASU86] [ABCF88]. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] [Wol92]. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities [BE94b].
Reference: [MW77] <author> J. H. Morris and B. Wegbreit. </author> <title> Subgoal induction. </title> <journal> Communication of ACM, </journal> <volume> 20(4) </volume> <pages> 209-222, </pages> <year> 1977. </year>
Reference-contexts: However, the restricted information may not be accurate enough to be of any use. The demand-driven approach in this paper is a special case of the more general approach of Subgoal Induction <ref> [MW77] </ref>.
Reference: [RWZ88] <author> B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Global value numbers and redundant computation. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 12-27, </pages> <year> 1988. </year>
Reference-contexts: Using the GSA sparse representation and the demand-driven approach, our approach can do more aggressive analysis only on demand. The SSA form has been used to determine the equivalence of symbolic variables and construct global value graph in a program [AWZ88] <ref> [RWZ88] </ref>. Nascent [Wol92] uses SSA to do a comprehensive analysis of recurrences. Their representation does not include the gating predicate. The SSA representation in Nascent is through an explicit use-def chain which they called a demand-driven form of SSA.
Reference: [TP93] <author> Peng Tu and David Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proc. 6rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Several research compilers such as Parafrase-2 [HP92] and Nascent [GSW] use symbolic analysis to identify and transform induction variables. In the Polaris [BEF + 94] restructuring compiler, symbolic analysis is also used for dependence analysis, symbolic range propagation and array privatization [BEF + 94] <ref> [TP93] </ref>. Simple symbolic analysis techniques are used regularly in the traditional optimizing compilers. Constant propagation detects symbolic variables that are equivalent to constants. Also, common subexpression elimination determines the equivalence of two symbolic expressions to avoid redundant computation. <p> Therefore, the compiler can determine the loop assigns to the array section A (1:N) and uses the array section A (N+1:2*N). Because these two sections do not overlap, the loop is parallel. In our experience, Array privatization is also very important to eliminate memory-related dependences <ref> [TP93] </ref>.
Reference: [TP95] <author> Peng Tu and David Padua. </author> <title> Efficient building and placing of gating functions. </title> <booktitle> In Proc. of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Another algorithm in [Hav93] uses SSA and the program control flow graph. These two algorithms can only handle reducible control flow graphs. Recently, we developed a more efficient algorithm that constructs GSA directly from program control flow graphs without going through the SSA conversion step <ref> [TP95] </ref>. It can be extended to handle irreducible flow graphs. After converting a program into GSA form, we can use the symbolic expression with the pseudo gating functions to represent symbolic values of program variables. 2.3 Demand-Driven Backward Substitution Traditional symbolic analysis propagates symbolic expressions by forward substitution. <p> An algorithm for constructing GSA from PDG and SSA is given in [BMO90]. Havlak [Hav93] develops another algorithm for building GSA from a program control flow graph and SSA. Recently, we developed a new algorithm to efficiently construct the GSA directly from the control flow graph <ref> [TP95] </ref>. Control dependence was introduced in [FOW87] as part of PDG. The SSA construction paper [CFR + 91] also has an algorithm for building control dependences.
Reference: [Wol92] <author> Michael Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> Proc. the SIGPLAN'92 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1992. </year> <month> 10 </month>
Reference-contexts: Various techniques have been developed for linear induction variable recognition [Ken81] [ASU86] [ABCF88]. Recently, more aggressive symbolic analysis techniques have been developed to detect and replace nonlinear induction variables [HP92] <ref> [Wol92] </ref>. However, to successfully parallelize a broad range of application programs such as the Perfect Benchmarks [CKPK90], the compiler needs more symbolic analysis capabilities [BE94b]. <p> When P is always true and A is a linear reference to an array, for example X (i), J 1 (i) is a reduction sum over X. Wolfe and others <ref> [Wol92] </ref> developed a comprehensive technique to classify and solve recurrence sequences using a graph representation of SSA. In this graph representation, a recurrence is characterized by a Strongly Connected Region (SCR) of use-def chains. The backward substitution technique for functions is equivalent to Wolfe's SCR approach. <p> Using the GSA sparse representation and the demand-driven approach, our approach can do more aggressive analysis only on demand. The SSA form has been used to determine the equivalence of symbolic variables and construct global value graph in a program [AWZ88] [RWZ88]. Nascent <ref> [Wol92] </ref> uses SSA to do a comprehensive analysis of recurrences. Their representation does not include the gating predicate. The SSA representation in Nascent is through an explicit use-def chain which they called a demand-driven form of SSA.
References-found: 25

