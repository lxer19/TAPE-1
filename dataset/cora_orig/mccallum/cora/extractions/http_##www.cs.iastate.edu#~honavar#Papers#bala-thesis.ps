URL: http://www.cs.iastate.edu/~honavar/Papers/bala-thesis.ps
Refering-URL: http://www.cs.iastate.edu/~honavar/aigroup2.html
Root-URL: http://www.cs.iastate.edu
Title: Biologically inspired computational structures and processes for autonomous agents and robots  
Author: by Karthik Balakrishnan Major Professor: Vasant G. Honavar 
Degree: A dissertation submitted to the graduate faculty in partial fulfillment of the requirements for the degree of DOCTOR OF PHILOSOPHY Major: Computer Science  
Note: Copyright c Karthik Balakrishnan, 1998. All rights reserved.  
Date: 1998  
Address: Ames, Iowa  
Affiliation: Iowa State University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Ackley, David H., & Littman, Michael L. </author> <year> (1991). </year> <title> Interactions between Learning and Evolution. </title> <booktitle> Pages 487-509 of: Proceedings of the Second International Conference on Artificial Life. </booktitle>
Reference-contexts: While learning operates on individuals, evolution works over entire populations (or species). Further, learning operates during the lifetime of the individual and is presumably aided by long lifespans, while evolution works over generations, well beyond an individual's effective lifespan <ref> (Ackley & Littman, 1991) </ref>. Despite these apparent differences, evolution and learning work synergistically to produce animals capable of surviving and functioning in diverse environments.
Reference: <author> Albus, J. </author> <year> (1981). </year> <title> Brains, Behavior, and Robotics. </title> <publisher> Peterborough, NH: McGraw Hill. </publisher>
Reference: <author> Anand, D., & Zmood, R. </author> <year> (1995). </year> <title> Introduction to Control Systems. </title> <publisher> Oxford: Butterworth-Heinemann. </publisher>
Reference-contexts: Examples of such representations include PI, PD, and PID controllers used extensively in the control of industrial robots, robotic arms, etc., <ref> (Anand & Zmood, 1995) </ref>. However, these 15 approaches require the transfer function to be known and appropriately implemented, which is often difficult in practice. In addition, these control mechanisms are rather inflexible and reprogramming the robot for a different behavior or task may entail extensive changes.
Reference: <author> Anderson, E. </author> <year> (1983). </year> <title> Animals as Navigators. </title> <address> New York, NY: </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference: <author> Arbib, M. </author> <year> (1966). </year> <title> Simple Self-Reproducing Universal Automata. </title> <journal> Information and Control, </journal> <volume> 9, </volume> <pages> 177-189. </pages>
Reference: <author> Ayache, N., & Faugeras, O. </author> <year> (1987). </year> <title> Maintaining Representation of the Environment of a Mobile Robot. </title> <booktitle> In: Proceedings of the International Symposium on Robotics Research. </booktitle>
Reference-contexts: In our model, we suggested the possibility that these aliasing problems in CA3 are resolved by CA1 using dead-reckoning information. It appears that we can use another tool from robotics to elegantly make such distinctions, namely, the Mahalanobis distance <ref> (Ayache & Faugeras, 1987) </ref>. Mahalanobis distance is a metric that computes the difference between predicted and observed values and normalizes them by their covariance. <p> Since there is no perceptual aliasing with sensor range of 30 units, the number of CA3 units equal the number of CA1 units. for building 3D maps of the environment <ref> (Ayache & Faugeras, 1987) </ref>. The idea here was to use a Taylor-series expansion of the non-linear function and truncate it at the first derivative, thereby obtaining a linear approximation of the original function.
Reference: <author> Bachelder, I., & Waxman, A. </author> <year> (1994). </year> <title> Mobile Robot Visual Mapping and Localization: A View-Based Neurocomputational Architecture that Emulates Hippocampal Place Learning. </title> <booktitle> Neural Networks, </booktitle> <volume> 7, </volume> <pages> 1083-1099. </pages>
Reference: <author> Back, T., Rudolph, G., & Schwefel, H-P. </author> <year> (1993). </year> <title> Evolutionary Programming and Evolution Strategies: Similarities and Differences. </title> <booktitle> In: Proceedings of the Second Annual Conference on Evolutionary Programming. </booktitle>
Reference: <author> Balakrishna, R., & Ghosal, A. </author> <year> (1995). </year> <title> Modeling of Slip for Wheeled Mobile Robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11(1), </volume> <pages> 126-132. </pages>
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1995a). </year> <title> Evolutionary Design of Neural Architectures | A Preliminary Taxonomy and Guide to Literature. </title> <type> Tech. rept. CS TR 95-01. </type> <institution> Department of Computer Science, Iowa State University, Ames, IA. </institution> <note> 248 Balakrishnan, </note> <author> K., & Honavar, V. </author> <year> (1995b). </year> <title> Properties of Genetic Representations of Neural Architectures. </title> <booktitle> In: Proceedings of the World Congress on Neural Networks. </booktitle>
Reference-contexts: They have been successfully applied to a variety of difficult optimization problems including the synthesis of artificial neural networks for specific applications (see <ref> (Balakrishnan & Honavar, 1995a) </ref> for a bibliography). In this dissertation research, we have made the following contributions to the field of evolutionary design of neural architectures. 1. <p> Based on our knowledge of the field, we suggested a preliminary taxonomy that characterized each research endeavor along four axes defined by: encoding scheme, network topology, variables of evolution, and application domain <ref> (Balakrishnan & Honavar, 1995a) </ref>. <p> The final category, application domain, tagged each of the approaches with the kinds of problems that were addressed using the approach (e.g., toy problems such as XOR and encoder-decoder, face 7 recognition, traveling salesperson problem, etc.) <ref> (Balakrishnan & Honavar, 1995a) </ref>. Not only did this taxonomy allow us to distinguish between different approaches, but also helped us identify potential research directions. For instance, we found that no one had addressed the evolution of activation functions in neural architectures. <p> Several researchers have recently begun to investigate evolutionary techniques for designing such neural architectures (see <ref> (Balakrishnan & Honavar, 1995a) </ref> for a bibliography). 26 Probably the distinguishing feature of an evolutionary approach to network synthesis is that unlike neural network learning algorithms that typically determine weights within a-priori fixed architectures, they can co-design the neural architecture as well as the network weights.
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1996a). </year> <title> Analysis of Neurocontrollers Designed by Simulated Evolution. </title> <booktitle> In: Proceedings of IEEE International Conference on Neural Networks ICNN'96. </booktitle>
Reference-contexts: Importantly, unlike Teller, we were able to analyze the evolved neural structures and determine precisely how our agents achieved their high fitnesses. This led to an important insight into the kinds of behaviors that would intuitively work well given the constraints of the robot task <ref> (Balakrishnan & Honavar, 1996a) </ref>. These results are presented in Sections 3.3.2 and 3.3.3. 2. We also showed that these high-fitness behaviors are truly characteristic of the properties 9 and constraints of the environment. <p> This was done by manipulating the coding of the outputs of the neurocontrollers, which changed the way the robots interpreted their output actions. We found that in each case evolution discovered neurocontroller structures that were functionally (behaviorally) equivalent to the earlier designs <ref> (Balakrishnan & Honavar, 1996a) </ref>. These results appear in Section 3.3.6. 3. By relaxing the environmental constraints in controlled ways, we also demonstrated that evolution produces high fitness designs that exploit these environmental changes (Balakr-ishnan & Honavar, 1996a; Balakrishnan & Honavar, 1996c). <p> For instance, when provided with a simple form of feedback, robots engaged in futile pushing demonstrate radically different behaviors and exploit the feedback mechanism to improve their performance on the box-pushing task <ref> (Balakrishnan & Honavar, 1996a) </ref>. These results are presented in Section 4.1. 4. We also showed that artificial evolution can be used in the design of robot sensory systems by allowing it to choose the numbers, placement, and ranges of the sensors (Balakrishnan & Honavar, 1996b). <p> Even though the robots in the earlier experiments worked in smaller environments (6fi 6), they only had 80 time steps for box-pushing when compared to the 500 time steps allowed for the robots in the current experiment. We have shown elsewhere <ref> (Balakrishnan & Honavar, 1996a) </ref> that an increase in the time allowed to push boxes, leads to an increase in robot fitness. <p> However, we also showed that fitness does not increase indefinitely, and the fitness curve flattens out after approximately O (N 3 ) of simulation time (where N fi N is the size of the arena). We also provided an intuitive explanation for this observation <ref> (Balakrishnan & Honavar, 1996a) </ref>. It can be observed from Table 5.1 that though these robots demonstrate high fitness behaviors, they are rather extravagant in their use of resources. For instance, the average neu-rocontroller uses 4.7 hidden units while the average robot employs 11.7 sensors. <p> Unlike 233 other researchers (Teller, 1994), we also analyzed the evolved neural structures and determined precisely how our agents achieved their high fitnesses. This led to important insights into the kinds of behaviors that would intuitively work well given the constraints of the robot task <ref> (Balakrishnan & Honavar, 1996a) </ref>. 3. By manipulating the coding of the outputs of the neurocontrollers we also demonstrated that the behaviors of successful agents did not change in principle. We additionally showed that evolution discovered radically different neural structures, each producing the same robot behavior. <p> We additionally showed that evolution discovered radically different neural structures, each producing the same robot behavior. We used this to argue that the evolved behaviors were truly characteristic of the properties and constraints of the environment <ref> (Balakrishnan & Honavar, 1996a) </ref>. 4. We also relaxed and modified the environmental constraints in controlled ways and showed that evolution produced high fitness designs that exploited these changes (Bal-akrishnan & Honavar, 1996a; Balakrishnan & Honavar, 1996c). <p> For instance, when we provided a simple form of feedback to robots engaged in futile pushing, radically different behaviors emerged that exploited the feedback mechanism to confer the robots with high fitnesses <ref> (Balakrishnan & Honavar, 1996a) </ref>. 5. We showed that artificial evolution could be used in the design of robot sensory systems by allowing it to choose the number, placement, and ranges of the sensors (Balakrishnan & Honavar, 1996b).
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1996b). </year> <title> On Sensor Evolution in Robotics. </title> <booktitle> In: Proceedings of Genetic Programming Conference - GP-96. </booktitle>
Reference-contexts: These results are presented in Section 4.1. 4. We also showed that artificial evolution can be used in the design of robot sensory systems by allowing it to choose the numbers, placement, and ranges of the sensors <ref> (Balakrishnan & Honavar, 1996b) </ref>. An important, and somewhat surprising, discovery was the fact that having more sensors was detrimental to the fitness of the robot, possibly due to sensory conflicts or confusion caused by too much sensory information. <p> Since evolutionary techniques are already being used quite successfully in the design of neurocontrollers for robots, we would like to explore the use of evolution in the design of the sensory systems <ref> (Balakrishnan & Honavar, 1996b) </ref>. The experiments reported in this section are an effort in this direction. 4.2.1 Multi-Resolution Representation of Sensory Inputs As in our earlier studies, the experiments in the following sections assume that the robot has visual sensors. <p> We have observed similar results with the use of BR and AD output coding strategies. Results using the latter approach appear in <ref> (Balakrishnan & Honavar, 1996b) </ref>, which also discusses the effect of increasing the range of the sensors. <p> We showed that artificial evolution could be used in the design of robot sensory systems by allowing it to choose the number, placement, and ranges of the sensors <ref> (Balakrishnan & Honavar, 1996b) </ref>. We discovered that having more sensors was potentially detrimental to the fitness of the robot, possibly due to conflicts or confusion caused by excess sensory information. 6.
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1996c). </year> <title> Some Experiments in the Evolutionary Synthesis of Robotic Neurocontrollers. </title> <booktitle> Pages 1035-1040 of: Proceedings of the World Congress on Neural Networks. </booktitle>
Reference-contexts: Evolution is also capable of discovering robust and noise-tolerant designs. For instance, when the sensors were assumed to be faulty (as is the case with many contemporary robot sensors (Everett, 1995)), evolution discovered designs with multiple sensors in key sensing directions around the robot <ref> (Balakrishnan & Honavar, 1996c) </ref>. We also found that evolution often exploits noise to overcome other system limitations that contribute to low fitnesses. For instance, evolution exploits noise to improve the fitnesses of feed-forward neurocontrollers, as explained in Section 4.3. 10 6. <p> Since the sensors are faulty, one may infer that evolution discovers robust designs that involve duplication of the faulty resource, namely sensors, in the critical sensing position in front of the robot. We 89 have shown similar results with the Action-Direction output coding strategy <ref> (Balakrishnan & Honavar, 1996c) </ref>. In addition to this design feature, it can also be observed that 81.3% of the robot sensors (3.63 sensors) are tuned to cells on the front and sides of the robot, as shown in Figure 4.7. <p> When the sensors were assumed to be noisy (as is the case with many contemporary robot sensors (Everett, 1995)) we found that evolution of sensory systems led to robust, fault-tolerant designs that involved duplication of sensory resources along critical dimensions <ref> (Balakrishnan & Honavar, 1996c) </ref>. For instance, most of the evolved robots made use of two or more sensors placed to sense the key cell immediately ahead of the robot. In these designs even if one sensor failed, the others would provide reliable sensor readings. 7.
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1998). </year> <title> Intelligent Diagnosis Systems. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 8(3/4). </volume> <publisher> (In press). </publisher>
Reference: <author> Balakrishnan, K., & Honavar, V. </author> <year> (1999). </year> <title> Some Experiments in Evolutionary Neuro-robotics. </title>
Reference-contexts: Given these constraints, instead of using decision-theoretic mechanisms, we let evolution optimize agent designs across these multiple dimensions. Indeed, evolution produces high fitness agents with a few key sensors and almost no hidden units in their neurocontrollers <ref> (Balakrishnan & Honavar, 1999) </ref>. We present these results in Section 5.6. To the best of our knowledge, we are the first to adopt this approach in the evolutionary robotics area. 7. We have also evolved spatially adaptive agent designs. <p> In these cases, evolution produced high fitness agents with a few sensors in key positions and neurocontrollers with no hidden units <ref> (Balakrishnan & Honavar, 1999) </ref>. 8. We also demonstrated the increased complexity in the designs of the energy-constrained robots when they had access to a spatial learning mechanism to learn, remember, and navigate to power sources within the environment.
Reference: <editor> In: Patel, M., Honavar, V., & Balakrishnan, K. (eds), </editor> <booktitle> Evolutionary Synthesis of Neural Systems. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. (To appear). </publisher>
Reference: <author> Balakrishnan, K., Bousquet, O., & Honavar, V. </author> <year> (1997). </year> <title> Spatial Learning and Localization in Animals: A Computational Model and its Implications for Mobile Robots. </title> <type> Tech. rept. CS TR 97-20. </type> <institution> Department of Computer Science, Iowa State University, Ames, IA. </institution> <note> (To appear in Adaptive Behavior). </note>
Reference-contexts: It also provides a mechanism for distinguishing between perceptually similar places in the environment (also known as perceptual aliasing in robotics), by using the Mahalanobis distance and the robot's dead-reckoning position estimates <ref> (Balakrishnan et al., 1997) </ref>. 1.4 Summary In this dissertation we have drawn inspiration from structures and processes employed in the design of animals, and have tried to use them in the design of artificial agents and robots. <p> We have shown elsewhere that our spatial learning and localization system allows the kidnapped robot (or animat) to localize reliably <ref> (Balakrishnan et al., 1997) </ref>. When kidnapped and reintroduced in the environment, the animat moves randomly until it recognizes a place that was visited earlier and which is a part of its place map. It then localizes using the Kalman filter based updates described above. <p> The robot was then allowed to perform an a-priori fixed number of sensing, learning, and action steps. At each such step, the robot obtained sensory inputs as described earlier and executed a movement action. Elsewhere we have shown results of a robot following a circular trajectory <ref> (Balakrishnan et al., 1997) </ref>. In the experiments reported here, the robot executed a random-walk, i.e., it turned in a random direction and moved forward in that direction by motionStep = 1 unit. <p> To the best of our knowledge, none of the other hippocampal models of spatial learning have addressed this issue of information fusion and localization from uncertain sources <ref> (Balakrishnan et al., 1997) </ref>. 11. We drew a parallel between the posited hippocampal function and probabilistic localization approaches used in contemporary robotics (e.g., Kalman filter). <p> <ref> (Balakrishnan et al., 1997) </ref>. 11. We drew a parallel between the posited hippocampal function and probabilistic localization approaches used in contemporary robotics (e.g., Kalman filter). Based on this parallel, we developed a Kalman filtering framework for hippocampal spatial localization with update expressions that could be shown to be stochastically optimal (Balakrishnan et al., 1997). 12. We extended the framework to support incremental map learning and learning of goal locations. This made it possible to learn local metric maps and fuse them into global ones in a consistent manner. <p> We also provided a mechanism for distinguishing between perceptually similar places in the environment (also known as perceptual aliasing in robotics), by using the Mahalanobis distance and the robot's dead-reckoning estimates <ref> (Balakrishnan et al., 1997) </ref>. 11.1 Directions for Future Work This dissertation research has opened up many other interesting avenues of research.
Reference: <author> Balakrishnan, K., Bhatt, R., & Honavar, V. </author> <year> (1998a). </year> <title> A Computational Model of Rodent Spatial Learning and Some Behavioral Experiments. </title> <booktitle> In: Proceedings of the Twentieth Annual Meeting of the Cognitive Science Society. </booktitle>
Reference-contexts: This made it possible to learn local metric maps and fuse them into global ones in a consistent manner. We also developed a framework for learning, representing, and navigating to multiple goal locations in the environment <ref> (Balakrishnan et al., 1998a) </ref>. 13. We used the model to simulate a number of behavioral experiments, primarily the gerbil experiments of (Collett et al., 1986) and the water-maze task of (Morris, 1981).
Reference: <author> Balakrishnan, K., Bhatt, R., & Honavar, V. </author> <year> (1998b). </year> <title> Spatial Learning and Localization in Animals: A Computational Model and Behavioral Experiments. </title> <booktitle> Pages 112-119 of: Proceedings of the Second European Conference on Cognitive Modelling. </booktitle>
Reference: <author> Balakrishnan, K., Bhatt, R., & Honavar, V. </author> <year> (1998c). </year> <title> Spatial Learning in the Rodent Hippocam-pus: A Computational Model and Some Behavioral Results. </title> <note> (In preparation). 249 Barnes, </note> <author> C., McNaughton, B., Mizumori, S., Leonard, B., & Lei-Huey, L. </author> <year> (1990). </year> <title> Comparison of Spatial and Temporal Characteristics of Neuronal Activity in Sequential Stages of Hippocampal Processing. </title> <booktitle> Progress in Brain Research, </booktitle> <volume> 83, </volume> <pages> 287-299. </pages>
Reference-contexts: In their simulations of behavioral experiments (Redish & Touretzky, 1996), the animats do not navigate. The animats are simply placed at different positions in the environment and learn places based on accurate position estimates provided by the user. Our behavioral simulations on the other hand, have navigating animats <ref> (Balakrishnan et al., 1998c) </ref>. Finally, in their simulations goals are assumed to coincide with the origin of the coordinate framework.
Reference: <author> Barto, A., & Sutton, R. </author> <year> (1981). </year> <title> Associative Search Network: A Reinforcement Learning Associative Memory. </title> <journal> Biological Cybernetics, </journal> <volume> 40, </volume> <pages> 201-211. </pages>
Reference: <author> Bennett, A. </author> <year> (1993a). </year> <title> Remembering Landmarks. </title> <journal> Nature, </journal> <volume> 364, </volume> <pages> 293-294. </pages>
Reference-contexts: Further, simply increasing the number of landmarks in the environment also does not help. The researchers concluded that spatial learning is critically influenced by stable relationships rather than merely the number or salience of landmarks (Biegler & Morris, 1996). Similar results have also been reported by <ref> (Bennett, 1993a) </ref>.
Reference: <author> Bennett, A. </author> <year> (1993b). </year> <title> Spatial Memory in a Food Storing Corvid. I. Near Tall Landmarks are Primarily Used. </title> <journal> Journal of Comparative Physiology A, </journal> <volume> 173, </volume> <pages> 193-207. </pages>
Reference-contexts: Similar results have also been reported by (Bennett, 1993a). Other experimental manipulations have led to findings that short landmarks are often not remembered by the animals possibly because they tend to become obscured by intervening taller objects <ref> (Bennett, 1993b) </ref>. 135 6.4.1 Theories of Animal Spatial Learning and Navigation It is clear from the above discussion that many aspects of sensory stimuli processing have been studied in rodents via controlled experiments and their consequent effect on behavior.
Reference: <author> Bennett, A. </author> <year> (1996). </year> <title> Do Animals have Cognitive Maps. </title> <journal> The Journal of Experimental Biology, </journal> <month> 199(1), </month> <pages> 219-224. </pages>
Reference: <author> Biegler, R., & Morris, R. </author> <year> (1996). </year> <title> Landmark Stability: Studies Exploring Whether the Perceived Stability of the Environment Influences Spatial Representation. </title> <journal> The Journal of Experimental Biology, </journal> <month> 199(1), </month> <pages> 187-193. </pages>
Reference-contexts: the stability of stimuli (landmarks) is critical for spatial learning, i.e., even if a goal is constantly and reliably associated with a landmark, rats fail to capture this relationship if the landmark (and the goal) are unstable, i.e., they are moved to different locations in each of the learning trials <ref> (Biegler & Morris, 1996) </ref>. Further, simply increasing the number of landmarks in the environment also does not help. The researchers concluded that spatial learning is critically influenced by stable relationships rather than merely the number or salience of landmarks (Biegler & Morris, 1996). <p> are moved to different locations in each of the learning trials <ref> (Biegler & Morris, 1996) </ref>. Further, simply increasing the number of landmarks in the environment also does not help. The researchers concluded that spatial learning is critically influenced by stable relationships rather than merely the number or salience of landmarks (Biegler & Morris, 1996). Similar results have also been reported by (Bennett, 1993a).
Reference: <author> Blair, H., & Sharp, P. </author> <year> (1995). </year> <title> Anticipatory Firing of Anterior Thalamic Head Direction Cells: Evidence for a Thalamocortical Circuit that Computes Head Direction in the Rat. </title> <journal> Journal of Neuroscience, </journal> <volume> 15, </volume> <pages> 6260-6270. </pages>
Reference: <author> Blum, K., & Abbott, L. </author> <year> (1996). </year> <title> A Model of Spatial Map Formation in the Hippocampus of the Rat. </title> <journal> Neural Computation, </journal> <volume> 8, </volume> <pages> 85-93. </pages>
Reference: <author> Bousquet, O., Balakrishnan, K., & Honavar, V. </author> <year> (1998). </year> <title> Is the Hippocampal Formation a Kalman Filter? In: </title> <booktitle> Proceedings of the Pacific Symposium on Biocomputing. </booktitle>
Reference: <author> Bradshaw, J. (ed). </author> <year> (1997). </year> <title> Software Agents. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Softbots are being increasingly used in automated tools for diagnosis, evaluation, and optimization, information gathering and retrieval, data mining, electronic commerce, news, mail and information filtering, etc., <ref> (Bradshaw, 1997) </ref>. In general, an agent can be characterized by two elements: its program and its architecture.
Reference: <author> Braitenberg, V. </author> <year> (1984). </year> <title> Vehicles: Experiments in Synthetic Psychology. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Table 3.1 Left-Forward-Right output coding strategy. Unit L Unit F Unit R Robot Action +1 -1 -1 Turn Left -1 +1 -1 Move Forward -1 -1 +1 Turn Right Some of our experiments have also used an output coding strategy suggested by Braitenberg <ref> (Braitenberg, 1984) </ref>. This strategy, labeled Braitenberg (BR), uses two output units that compute bipolar-threshold functions. The two output units are considered to be directly connected to the two wheels of the robot (assuming the robot has one wheel on either side).
Reference: <author> Brooks, R. </author> <year> (1985). </year> <title> Visual Map Making for a Mobile Robot. </title> <booktitle> In: Proceedings of the IEEE Conference on Robotics and Automation. </booktitle> <volume> 250 Brown, </volume> <editor> M., & Sharp, P. </editor> <year> (1995). </year> <title> Simulation of Spatial Learning in the Morris Water Maze by a Neural Network Model of the Hippocampal Formation and Nucleus Accumbens. </title> <journal> Hippocampus, </journal> <volume> 5, </volume> <pages> 189-197. </pages>
Reference-contexts: This map can thus be thought of as a graph where nodes represent distinct places and the edges denote the relationship between them <ref> (Brooks, 1985) </ref>. <p> Such relation-based approaches produce a compact world representation since they only represent distinctive places and not the entire environment. Further, they are robust to global movement errors as they only represent local relationships between places <ref> (Brooks, 1985) </ref>.
Reference: <author> Burgess, N., & O'Keefe, J. </author> <year> (1996). </year> <title> Neuronal computations underlying the firing of place cells and their role in navigation. </title> <journal> Hippocampus, </journal> <volume> 6, </volume> <pages> 749-762. </pages>
Reference: <author> Burgess, N., Recce, M., & O'Keefe, J. </author> <year> (1994). </year> <title> A Model of Hippocampal Function. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(6/7), </volume> <pages> 1065-1081. </pages>
Reference: <author> Burgess, N., Recce, M., & O'Keefe, J. </author> <year> (1995). </year> <title> Hippocampus Spatial Models. Pages 468-472 of: Arbib, </title> <editor> M. (ed), </editor> <booktitle> The Handbook of Brain Theory and Neural Networks. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Buzsaki, G. </author> <year> (1989). </year> <title> Two-State Model of Memory Trace Formation: A Role for "Noisy" Brain States. </title> <journal> Neuroscience, </journal> <volume> 31, </volume> <pages> 551-570. </pages>
Reference-contexts: In rats, theta waves (low amplitude 4-8 Hz) have been observed during exploratory behaviors like sniffing, walking, rearing, and during REM sleep (dreaming). Sharp waves, on the other hand, are observed when the rats are sitting quietly, drinking, eating, grooming, or deeply asleep <ref> (Buzsaki, 1989) </ref>. The subiculum receives input from the entorhinal cortex and projects to the pre and post-subiculum, the deep layers of the entorhinal cortex, and to the hypothalamus, septum, anterior thalamus and the cingulate cortex (Churchland & Sejnowski, 1992).
Reference: <editor> Cecconi, F., Menczer, F., & Belew, R. </editor> <booktitle> (1995). Maturation and Evolution of Imitative Learning in Artificial Organisms. Adaptive Behavior, </booktitle> <volume> 4(1), </volume> <pages> 179-198. </pages>
Reference-contexts: Their results suggested that delayed maturation evolved due to its benefits of learning, even though it imposed a cost on the mother <ref> (Cecconi et al., 1995) </ref>. Although a very interesting study, this work implemented an extremely simple form of neural learning. In contrast, the need for spatial learning in our box-pushing agents is much more complex. <p> In contrast, the need for spatial learning in our box-pushing agents is much more complex. Further, as we have mentioned earlier, effective box-pushing behaviors are hard to develop manually, unlike the survival task used in the experiment of <ref> (Cecconi et al., 1995) </ref>. 5.11 Discussion In this chapter we have explored a number of avenues related to the design of energy-efficient robots. In contrast to the robots evolved in earlier chapters, these robots have to make do with a battery of limited capacity.
Reference: <author> Chalmers, David J. </author> <year> (1990). </year> <title> The Evolution of Learning: An Experiment in Genetic Connectionism. </title> <booktitle> Pages 81-90 of: Proceedings of the 1990 Connectionist Models Summer School. </booktitle>
Reference-contexts: Further, the evolutionary algorithm may be easily extended to automatically adapt other parameters of the network like the individual activation functions of the units (Juedes & Balakrishnan, 1996), rates of mutation (Schwefel, 1987) and learning (Salomon, 1991), and even the learning algorithm <ref> (Chalmers, 1990) </ref>.
Reference: <author> Chapuis, A., & Droz, E. </author> <year> (1956). </year> <institution> The Jaquet-Droz Mechanical Puppets. Neuchatel, Switzerland: Neuchatel Historical Museum. </institution>
Reference: <author> Chen, L., Lin, L-H., Green, E., Barnes, C., & McNaughton, B. </author> <year> (1994b). </year> <title> Head-Direction Cells in the Rat Posterior Cortex. I. Anatomical Distribution and Behavioral Modulation. </title> <journal> Experimental Brain Research, </journal> <volume> 101, </volume> <pages> 8-23. </pages>
Reference: <author> Chen, L., Lin, L-H., Barnes, C., & McNaughton, B. </author> <year> (1994a). </year> <title> Head-Direction Cells in the Rat Posterior Cortex. II. Contributions of Visual and Ideothetic Information to the Directional Firing. </title> <journal> Experimental Brain Research, </journal> <volume> 101, </volume> <pages> 24-34. </pages>
Reference: <author> Chown, E., Kaplan, S., & Kortenkamp, D. </author> <year> (1995). </year> <title> Prototypes, Location and Associative Networks (PLAN): Towards a Unified Theory of Cognitive Mapping. </title> <journal> The Journal of Cognitive Science, </journal> <volume> 19(1). 251 Churchland, </volume> <editor> P., & Sejnowski, T. </editor> <year> (1992). </year> <title> The Computational Brain. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This cognitive spatial learning architecture was implemented on a simulated robot NX (Kuipers & Byun, 1991) and later extended to physical robots (Kuipers et al., 1993). Kortenkamp's RPLAN is an implementation of the PLAN (Prototypes, Location and Associative Networks) model of human cognitive mapping <ref> (Chown et al., 1995) </ref>. In his implementation, sonar-based detection of gateways and vision-based detection of scenes are combined using a Bayesian network to provide robust definitions of place.
Reference: <author> Cliff, D., Husbands, P., & Harvey, I. </author> <year> (1993a). </year> <title> Analysis of Evolved Sensory-Motor Controllers. </title> <booktitle> In: Second European Conference on Artificial Life. </booktitle>
Reference: <author> Cliff, D., Harvey, I., & Husbands, P. </author> <year> (1993b). </year> <title> Explorations in Evolutionary Robotics. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 2, </volume> <pages> 73-110. </pages>
Reference: <author> Cohen, M., & Drabkin, I. </author> <year> (1948). </year> <title> Source Book in Greek Science. </title> <address> New York, NY: </address> <publisher> McGraw Hill. </publisher>
Reference: <author> Cohen, N., & Eichenbaum, H. </author> <year> (1993). </year> <title> Memory, </title> <booktitle> Amnesia, and the Hippocampal System. </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: formation since they shed more light on the neural structures and processes used in rodent spatial learning and localization. 7.1.1 Anatomy of the Hippocampal Formation The hippocampal formation is an association area of the brain that receives highly processed sensory information from the major associational areas of the cerebral cortex <ref> (Cohen & Eichenbaum, 1993) </ref>. As shown in Figure 7.1, these inputs arrive at a convergence area called the entorhinal cortex (EC), which itself is a part of a major convergence area called the parahippocampal cortical area (Squire et al., 1989). <p> Declarative memory theory According to this theory the hippocampus plays a critical role in the accumulation of facts and data derived from the learning experiences of the animal <ref> (Cohen & Eichenbaum, 1993) </ref>. Importantly, the nature of this representation is relational, i.e., the hippocampus represents relationships between objects such as relative size, color, texture, shapes, positions, etc., as well as higher-order temporally-contiguous relationships between objects and events.
Reference: <author> Collett, T., Cartwright, B., & Smith, B. </author> <year> (1986). </year> <title> Landmark Learning and Visuo-Spatial Memories in Gerbils. </title> <journal> Journal of Neurophysiology A, </journal> <volume> 158, </volume> <pages> 835-851. </pages>
Reference-contexts: This system is also capable of learning and representing multiple goal locations, and has been augmented with algo rithms for goal selection and goal-directed navigation. 5. The model has been used to simulate a number of behavioral experiments, primarily the gerbil experiments of <ref> (Collett et al., 1986) </ref> and the water-maze task of (Morris, 1981). In either case, the behaviors demonstrated by our animats 2 are largely similar to those observed by the researchers in their experiments with rodents. <p> Experiments with gerbils have led to the suggestion that these animals compute and store vectors to landmarks from the goal location. Further, independent vectors appear to be computed for each of the landmarks <ref> (Collett et al., 1986) </ref>. <p> Researchers have also found some evidence for the grounding of internal spatial representations in a locomotion-based metric system in non-homing behaviors <ref> (Collett et al., 1986) </ref>. It is strongly suspected that these metric estimates are provided by the dead-reckoning system (McNaughton et al., 1995; McNaughton et al., 1996). Dead-reckoning mechanisms are also used in robot navigation and a wide range of devices have been developed for this purpose (Everett, 1995). <p> Each animal was given between 6 and 12 individual training trials everyday, 6 days a week. 207 The researchers observed that over roughly 150 such trials (i.e., one month of training), the animals learned to directly approach the seed when released into the environment <ref> (Collett et al., 1986) </ref>. Once the gerbils were trained to satisfaction, they were subjected to testing trials intermingled with training ones in a ratio of 1:6. In the test trials, the gerbils were released into the arena which contained landmarks but no seed. <p> The gerbils thus appear to possess some means for also learning something 208 about the geometrical relations between the landmarks in the environment and show themselves capable of extracting these spatial relations of landmarks from their representations <ref> (Collett et al., 1986) </ref>. 10.2 Simulation of Experiments of Collett et al. We have reproduced a number of experiments of (Collett et al., 1986), using the computational model of spatial learning developed in Chapter 8. <p> means for also learning something 208 about the geometrical relations between the landmarks in the environment and show themselves capable of extracting these spatial relations of landmarks from their representations <ref> (Collett et al., 1986) </ref>. 10.2 Simulation of Experiments of Collett et al. We have reproduced a number of experiments of (Collett et al., 1986), using the computational model of spatial learning developed in Chapter 8. In this section we present results of these experiments. 10.2.1 Simulation Details In our simulations we used a circular arena of radius 10 units. <p> They found that well-trained gerbils ran directly to the seed when introduced into the environment. Further, in testing trials the gerbils were found to concentrate their search efforts at the expected location of the seed even though the seed was absent (Figure 1 in <ref> (Collett et al., 1986) </ref>). In our simulation of this experiment, the goal location was 4 units to the south of a single landmark, as shown in Figure 10.1 (Left). <p> The corresponding search histogram is shown in most of their time searching in regions near the expected position of the goal. This search histogram compares rather well with the observations of <ref> (Collett et al., 1986) </ref>. 10.2.2.2 Two Landmark Experiments In the next set of experiments, Collett et al. trained gerbils to locate a sunflower seed placed to the south of a line connecting two identical landmarks. The seed was equidistant 211 goal location in a fixed relationship to a single landmark. <p> Figure 10.2 (Right) shows the search effort of the animats in test trials when the goal was removed. As can be observed, the animats concentrate their search to a region close to the position of the goal in the training trials. This figure compares well with Figure 7b in <ref> (Collett et al., 1986) </ref>. two landmarks and the goal equidistant from the two. Right: Search histogram of the animats during tests with goal re moved. <p> When trained on the two landmark task and tested them with one landmark removed, Collett et al. found that the gerbils searched on both sides of the sole landmark, apparently matching it to either the left or the right landmark of the original configuration (Figure 7c in <ref> (Collett et al., 1986) </ref>). Our animats demonstrated a similar behavior as seen by their search 212 distribution in Figure 10.3 (Left). <p> Also, when the gerbils were trained with two landmarks and tested with the distance between the landmarks doubled, Collett et al. found that the gerbils searched predominantly at the two interior locations, each at the correct distance and orientation from one of the landmarks (Figure 7d in <ref> (Collett et al., 1986) </ref>). Results from similar experiments with our animats are shown in Figure 10.3 (Right). It can be observed that our animats too search predominantly at the interior locations. <p> This compares favorably with Figure 6b in <ref> (Collett et al., 1986) </ref>. Collett et al. also trained the gerbils on the three landmark task and tested them in environments with one or two of the landmarks removed. <p> Middle: Search distribution of the animats when tested in the three landmark environment. Right: Search distribution when tested with one of the three landmarks removed. the two remaining landmarks (Figure 6c in <ref> (Collett et al., 1986) </ref>). It can be observed from With two of the three landmarks removed during testing, Collett et al. found that the gerbils distributed their search time between three sites, one for each of the three possible matches of the sole landmark (Figure 6d in their report). <p> Similarly, when gerbils were trained on the three landmark task but tested with one landmark distance doubled, they were found to search at a goal location at the correct distance and bearing from the two unmoved landmarks (Figure 8 in <ref> (Collett et al., 1986) </ref>). The result of this experiment with our animats is shown in Figure 10.5 (Middle). <p> search histograms of animats with sensing and dead-reckoning errors better match the search distributions of the gerbils, one might strongly suspect that similar errors must also exist in animal spatial learning systems. 10.2.3.1 Related Work To the best of our knowledge the only other computational simulation of the experiments of <ref> (Collett et al., 1986) </ref>, is the work of Redish and Touretzky (1996). Their model was described earlier in Section 8.6. <p> We feel that a number of behavioral experiments can be designed to address this issue to satisfaction. Experiment 1: The gerbils could be trained in an environment with two identical landmarks, as in the two landmark task of <ref> (Collett et al., 1986) </ref>. However, instead of placing the sunflower seed equidistant from the two landmarks, it could be placed closer to one (and consequently farther away from the other). Once trained in this environment, the gerbils could be tested with the landmark distance doubled. <p> We have presented simulation results for the one, two, and three landmark experiments of 231 Collett et al. In each case, we have shown the search histograms generated by our animats. These histograms compare extremely well to the observations of <ref> (Collett et al., 1986) </ref>. In addition to the simulation results, we have also identified a number of behavioral experiments that can be performed to answer a number of questions regarding the processing of landmark information. <p> We also developed a framework for learning, representing, and navigating to multiple goal locations in the environment (Balakrishnan et al., 1998a). 13. We used the model to simulate a number of behavioral experiments, primarily the gerbil experiments of <ref> (Collett et al., 1986) </ref> and the water-maze task of (Morris, 1981). In either 235 case, the behaviors demonstrated by our animats were largely similar to those observed with rodents (Balakrishnan et al., 1998b; Balakrishnan et al., 1998a). 14.
Reference: <author> Collins, R., & Jefferson, D. </author> <year> (1990). </year> <title> An Artificial Neural Network Representation for Artificial Organisms. </title> <booktitle> Pages 259-263 of: Proceedings of the Conference on Parallel Problem Solving from Nature. </booktitle>
Reference: <author> Collins, R., & Jefferson, D. </author> <year> (1991). </year> <title> AntFarm: Towards Simulated Evolution. </title> <booktitle> In: Proceedings of the Second International Conference on Artificial Life. </booktitle>
Reference: <author> Colombetti, M., & Dorigo, M. </author> <year> (1992). </year> <title> Learning to Control an Autonomous Robot by Distributed Genetic Algorithms. </title> <booktitle> In: From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference-contexts: Tasks in Evolutionary Robotics Most of the robot tasks used in evolutionary robotics studies have been simple variants of basic navigation behaviors like obstacle avoidance (Floreano & Mondada, 1994; Reynolds, 1994a), goal approaching (Harvey et al., 1994), wall following (Reynolds, 1994b; Yamauchi 42 & Beer, 1994), light or target following <ref> (Colombetti & Dorigo, 1992) </ref>, feeding (Menczer & Belew, 1994; Walker, 1995), homing, maze or trail learning (Koza, 1991; Collins & Jefferson, 1991), simple exploration (Lewis et al., 1992; Miglino et al., 1994), etc. <p> Thus, evolution might provide the robot with a set of innate behaviors that the robot might alter based on its experiences in the environment in which it is currently operating <ref> (Colombetti & Dorigo, 1992) </ref>. For example, reinforcement learning is a paradigm of machine learning that is inspired by such conditioning mechanisms in animals (Barto & Sutton, 1981; Sutton & Barto, 1998).
Reference: <author> Connell, J., & Mahadevan, S. </author> <year> (1993a). </year> <title> Rapid Task Learning for Real Robots. </title> <journal> Chap. </journal> <volume> 5, </volume> <pages> pages 105-140 of: </pages> <editor> Connell, J., & Mahadevan, S. (eds), </editor> <title> Robot Learning. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic. </publisher>
Reference-contexts: Culbertson suggested ways of designing artificial neural circuitry for generating non-deterministic behavior from deterministic neural components. Extensions of this idea are used in contemporary reinforcement learning systems (Sutton & Barto, 1998), often applied to robot learning <ref> (Connell & Mahadevan, 1993a) </ref>. In the following sections, we study the evolution of robust and reliable robot behaviors that overcome (or even exploit) noise in the robot components. 4.3.1 Kinds of Noise In our work, we are concerned with manifestations of noise in the system components.
Reference: <author> Connell, J., & Mahadevan, S. (eds). </author> <year> (1993b). </year> <title> Robot Learning. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic. </publisher>
Reference-contexts: For example, reinforcement learning is a paradigm of machine learning that is inspired by such conditioning mechanisms in animals (Barto & Sutton, 1981; Sutton & Barto, 1998). Owing to its ability to operate in feedback-impoverished environments, reinforcement learning has found applica 236 tion in robot learning <ref> (Connell & Mahadevan, 1993b) </ref>.
Reference: <author> Cox, I., & Wilfong, G. (eds). </author> <year> (1990). </year> <title> Autonomous Robot Vehicles. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher> <address> 252 Crowley, J. </address> <year> (1995). </year> <title> Mathematical Foundations of Navigation and Perception for an Autonomous Mobile Robot. </title> <booktitle> Pages 9-51 of: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference: <author> Culbertson, J. </author> <year> (1957). </year> <title> Robots and Automata: A Brief History. </title> <journal> Computers and Automation, </journal> <volume> 6(3/4), </volume> <month> 32-37/28-35. </month>
Reference: <author> Culbertson, J. </author> <year> (1963). </year> <title> The Minds of Robots: Sense Data, Memory Images, and Behavior in Conscious Automata. </title> <institution> Urbana-Champaign, IL: University of Illinois Press. </institution>
Reference-contexts: In addition to the use of noise in developing robust behaviors in simulation, noise in the form of non-deterministic or probabilistic actions has other applications in robotics. For instance, Culbertson suggested the use of noisy actions in overcoming problems associated with robots getting caught in fixed-cycle paths <ref> (Culbertson, 1963) </ref>. For example, a robot might be moving towards a goal and might deviate from its path owing to the presence of an obstacle. <p> The net effect of this mechanism is to provide noise in the actions being chosen by the robot. However, this noise can be potentially benefi 88 cial, as argued by Culbertson <ref> (Culbertson, 1963) </ref>, with the robots using such alternate actions to escape from fixed-cyclic paths and stuck states.
Reference: <author> Dasgupta, Dipankar, & McGregor, Douglas. </author> <year> (1992). </year> <title> Designing Application-Specific Neural Networks using the Structured Genetic Algorithm. </title> <booktitle> Pages 87-96 of: Proceedings of the International Conference on Combinations of Genetic Algorithms and Neural Networks. </booktitle>
Reference-contexts: The neurocontrollers thus derive input from eight sensors that are fixed to sense the eight cells immediately around the robot. Our genetic representation also assumes the existence of second-level or modifier genes which control the expression of entire sequences of other genes <ref> (Dasgupta & McGregor, 1992) </ref>. In our representation, these modifier genes control the expression of hidden units and robot sensors. For instance, in Figure 3.3 only the modifier genes corresponding to sensors 0, 4, and 6 are ON.
Reference: <author> Dayhoff, J. </author> <year> (1990). </year> <title> Neural Network Architectures: An Introduction. </title> <address> New York: </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference: <author> Dean, T., Allen, J., & Aloimonos, Y. </author> <year> (1995). </year> <booktitle> Artificial Intelligence Theory and Practice. </booktitle> <address> Redwood City, CA: </address> <publisher> Benjamin Cummings. </publisher>
Reference: <author> Douglas, R. </author> <year> (1972). </year> <title> Pavlovian Conditioning and the Brain. Pages 529-549 of: </title> <editor> Boakes, R., & Halliday, M. (eds), </editor> <booktitle> Inhibition and Learning. </booktitle> <address> London: </address> <publisher> Academic Press. </publisher>
Reference: <author> Douglas, R., & Pribram, K. </author> <year> (1966). </year> <title> Learning and Limbic Lesions. </title> <journal> Neuropsychologia, </journal> <volume> 4, </volume> <pages> 197-220. </pages>
Reference: <author> Dudek, G., Romanik, K., & Whitesides, S. </author> <year> (1995). </year> <title> Localizing a Robot with Minimum Travel. </title> <booktitle> Pages 437-446 of: Proceedings of the 6th Annual ACM-SIAM Symposium on Discrete Algorithms. </booktitle>
Reference: <author> Durkin, J. </author> <year> (1994). </year> <title> Expert Systems Design and Development. </title> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference: <author> Elfes, A. </author> <year> (1989). </year> <title> Occupancy Grids: A Probabilistic Framework for Robot Perception and Navigation. </title> <type> Ph.D. thesis, </type> <institution> Electrical and Computer Engineering Department, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: Each grid cell corresponds to a portion of the environment and adjacent grid cells represent adjacent physical regions in the environment. The grid cells are associated with a figure of merit called 131 the probability of occupancy, which is updated based on sensory inputs and appropriate sensor models <ref> (Elfes, 1989) </ref>. Since grid cells correspond to regions of physical space, the probability of occupancy is an indicator of the presence or absence of objects in the corresponding region of physical space.
Reference: <author> Elfes, A. </author> <year> (1992). </year> <title> Dynamic Control of Robot Perception Using Multi-Property Inference Grids. </title> <booktitle> In: Proceedings of the 1992 IEEE International Conference on Robotics and Automation. </booktitle> <volume> 253 Elfes, </volume> <editor> A. </editor> <year> (1995). </year> <title> Robot Navigation: Integrating Perception, Environmental Constraints and Task Execution Within a Probabilistic Framework. </title> <booktitle> Pages 93-130 of: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference-contexts: accuracy of representation but results in a quadratic (for 2D maps) increase in the number of grid cells required for the same Decreasing the grid-resolution, on the other hand, reduces the computational burden on the update algorithm but results in a loss of information and a consequent increase in uncertainty <ref> (Elfes, 1992) </ref>. 6.3.2 Topological Maps for Representing Spatial Information A popular example of relation-based spatial representations is the topological map which only represents distinctive places in the environment along with the local relationships between them (Kuipers, 1978).
Reference: <author> Engelson, S. </author> <year> (1994). </year> <title> Passive Map Learning and Visual Place Recognition. </title> <type> Ph.D. thesis, </type> <institution> New Haven, CT, Department of Computer Science, Yale University. </institution>
Reference-contexts: This situation is referred to as the kidnapped robot problem in robotics, where the robot is kidnapped (or removed) from one place in its environment and reintroduced at another <ref> (Engelson, 1994) </ref>. We have shown elsewhere that our spatial learning and localization system allows the kidnapped robot (or animat) to localize reliably (Balakrishnan et al., 1997).
Reference: <author> Etienne, A. </author> <year> (1985). </year> <title> The Control of Short-Distance Homing in the Golden Hamster. Pages 233-251 of: </title> <editor> Ellen, P., & Thinus-Blanc, C. (eds), </editor> <booktitle> Cognitive Processes and Spatial Orientation in Animals and Man. </booktitle> <address> Boston, MA: </address> <publisher> Martinus Nijhoff. </publisher>
Reference: <author> Etienne, A. </author> <year> (1992). </year> <title> Navigation of a Small Mammal by Dead Reckoning and Local Cues. </title> <booktitle> Current Directions in Psychological Science, </booktitle> <volume> 1(2), </volume> <pages> 48-52. </pages>
Reference: <author> Etienne, A., Teroni, V., Hurni, C., & Portenier, V. </author> <year> (1990). </year> <title> The Effect of A Single Light Cue on Homing Behaviour of the Golden Hamster. Animal Behavior, </title> <booktitle> 39, </booktitle> <pages> 17-41. </pages>
Reference-contexts: It has also been shown experimentally that in conflict situations between distant but familiar visual references and path-integration, the animals appear to give priority to stable visual references <ref> (Etienne et al., 1990) </ref>. Researchers have also found some evidence for the grounding of internal spatial representations in a locomotion-based metric system in non-homing behaviors (Collett et al., 1986).
Reference: <author> Etienne, A., Maurer, R., & Seguinot, V. </author> <year> (1996). </year> <title> Path Integration in Mammals and its Interaction with Visual Landmarks. </title> <journal> The Journal of Experimental Biology, </journal> <month> 199(1), </month> <pages> 201-209. </pages>
Reference-contexts: This has led to the suggestion that in the absence of visual information, path-integration appears to be useful only for short exploratory excursions from a known site <ref> (Etienne et al., 1996) </ref>. It has also been shown experimentally that in conflict situations between distant but familiar visual references and path-integration, the animals appear to give priority to stable visual references (Etienne et al., 1990).
Reference: <author> Everett, H. </author> <year> (1995). </year> <title> Sensors for Mobile Robots: Theory and Application. </title> <address> Wellesley, MA: </address> <publisher> A. K. </publisher>
Reference-contexts: Evolution is also capable of discovering robust and noise-tolerant designs. For instance, when the sensors were assumed to be faulty (as is the case with many contemporary robot sensors <ref> (Everett, 1995) </ref>), evolution discovered designs with multiple sensors in key sensing directions around the robot (Balakrishnan & Honavar, 1996c). We also found that evolution often exploits noise to overcome other system limitations that contribute to low fitnesses. <p> As will be clarified in Section 6.5, there is considerable evidence that animals use such dead-reckoning mechanisms to learn and navigate between places (Gallistel, 1990). In addition to animals, contemporary robotics also offers a variety of devices that enable robots to detect motion and perform dead-reckoning <ref> (Everett, 1995) </ref>. Odometric techniques that make use of inexpensive optical and magnetic wheel encoders are popular mechanisms for obtaining rough estimates of robot position. Other more expensive (and accurate) approaches are described in Appendix A. Thus, both animals as well robots are capable of detecting self-motion. <p> For instance, sonar sensors can be used quite reliably to differentiate between walls and empty 100 spaces (barring some problems posed by specular reflections) <ref> (Everett, 1995) </ref>. However, differentiating between walls and boxes is much harder, and may even be impossible using simple sonar sensing. One may need to use other aspects like shape, color, surface texture, reflection properties, etc., to perform this distinction. <p> For instance, sonar sensors emit an 133 ultrasonic pulse of energy and measure the time required for the pulse to reach a reflecting object and echo back to the receiver <ref> (Everett, 1995) </ref>. Although these sensors can detect the presence of objects they are not capable of differentiating between (or recognizing) different kinds of objects. Further, they can only obtain rough estimates of the distances to objects, this estimate often being corrupted by specular (or false) reflections (Everett, 1995). <p> back to the receiver <ref> (Everett, 1995) </ref>. Although these sensors can detect the presence of objects they are not capable of differentiating between (or recognizing) different kinds of objects. Further, they can only obtain rough estimates of the distances to objects, this estimate often being corrupted by specular (or false) reflections (Everett, 1995). Thus, a robot equipped only with sonar sensors cannot identify individual objects in a scene, rather it is forced to learn the boundaries of objects in the environment. <p> It is strongly suspected that these metric estimates are provided by the dead-reckoning system (McNaughton et al., 1995; McNaughton et al., 1996). Dead-reckoning mechanisms are also used in robot navigation and a wide range of devices have been developed for this purpose <ref> (Everett, 1995) </ref>. As with animals, dead-reckoning is usually involved in homing behaviors, where the robot returns to its home-base after executing its spatial task. However, dead-reckoning input has also been used in the building of metric spatial maps, with the dead-reckoning system providing a Cartesian coordinate representation of space. <p> However, this range sensing was assumed to be error-prone, and the error was modeled as a zero-mean Gaussian with standard deviation S = 0:01 per unit distance. This range error of 1% per unit distance was chosen to be compatible with contemporary sonar-based distance ranging <ref> (Everett, 1995) </ref>. As described earlier, the sensory information pertaining to the range and allocentric bearings (hence vectors) of detected landmarks were provided as input to the EC layer. The activations of the EC, CA3, and CA1 layers were then computed using the algorithms described earlier. <p> We discovered that having more sensors was potentially detrimental to the fitness of the robot, possibly due to conflicts or confusion caused by excess sensory information. 6. When the sensors were assumed to be noisy (as is the case with many contemporary robot sensors <ref> (Everett, 1995) </ref>) we found that evolution of sensory systems led to robust, fault-tolerant designs that involved duplication of sensory resources along critical dimensions (Balakrishnan & Honavar, 1996c). <p> Since the odometric approaches derive their navigational parameters from wheel rotation, they are subject to problems arising from slippage, tread wear, and/or improper tire inflation (Balakrishna & Ghosal, 1995; Everett, 1995). However, Doppler and inertial navigation systems can often be used to considerably reduce these sources of errors 241 <ref> (Everett, 1995) </ref>. Doppler navigation systems operate on the principle of the Doppler shift in frequency, observed when radiated energy reflects off a surface that is moving with respect to the emitter. <p> These are then integrated over time to yield velocity and position. Such systems, although capable of producing reasonably precise dead-reckoning, currently have limited applications owing to their prohibitive cost <ref> (Everett, 1995) </ref>. However, with advances in technology, it is conceivable that accurate and affordable dead-reckoning devices will soon become available, making our approach quite practical. 3. Maintaining correlations With probabilistic localization approaches like the Kalman filter, it is imperative that the correlations between the state variables be maintained correctly.
Reference: <institution> Peters Ltd. </institution>
Reference: <editor> Feigenbaum, J., & Rolls, E. </editor> <booktitle> (1991). Allocentric and Egocentric Spatial Information Processing in the Hippcampal Formation of the Behaving Primate. Psychobiology, </booktitle> <volume> 19, </volume> <pages> 21-40. </pages>
Reference: <author> Fenton, A., & Bures, J. </author> <year> (1994). </year> <title> Interhippocampal Transfer of Place Navigation Monocularly Acquired by Rats During Unilateral Functional Ablation of the Dorsal Hippocampus and Visual Cortex with Lidocaine. </title> <journal> Neuroscience, </journal> <volume> 58, </volume> <pages> 481-491. </pages>
Reference: <author> Floreano, D., & Mondada, F. </author> <year> (1994). </year> <title> Automatic Creation of an Autonomous Agent: Genetic Evolution of a Neural-Network Driven Robot. </title> <booktitle> Pages 421-430 of: From Animals to An-imats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference: <author> Fogel, D. </author> <year> (1994). </year> <title> Asymptotic Convergence Properties of Genetic Algorithms and Evolutionary Programming: Analysis and Experiments. </title> <journal> Cybernetics and Systems: An International Journal, </journal> <volume> 25, </volume> <pages> 389-407. </pages> <note> 254 Fonseca, </note> <author> C., & Fleming, P. </author> <year> (1995). </year> <title> An Overview of Evolutionary Algorithms in Multi-Objective Optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 3(1), </volume> <pages> 1-16. </pages>
Reference-contexts: Both these paradigms perform evolutionary search via genetic operators of crossover and mutation. Evolutionary programming, on the other hand, allows complex structures in the genotypes but only uses a mutation operator <ref> (Fogel, 1994) </ref>. Evolution strategies are typically used for parameter optimization (Schwefel, 1981; Back et al., 1993). They employ recombination and mutation, and also permit self-learning (or evolutionary adaptation) of strategy parameters (e.g., variance of the Gaussian mutations).
Reference: <author> Foster, T., Castro, C., & McNaughton, B. </author> <year> (1989). </year> <title> Spatial Selectivity of Rat Hippocampal Neurons: Dependence on Preparedness for movement. </title> <journal> Science, </journal> <volume> 244, </volume> <pages> 1580-1582. </pages>
Reference-contexts: Experiments have shown that the motor system plays a critical role in the firing of place and head-direction cells. For instance, with restraints on active motion, both hippocampal place cell activity <ref> (Foster et al., 1989) </ref> as well thalamic head-direction cell activity (Knierim et al., 1995) have been observed to cease.
Reference: <author> Freund, J. </author> <year> (1992). </year> <institution> Mathematical Statistics. </institution> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Gallant, S. </author> <year> (1993). </year> <title> Neural Network Learning and Expert Systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Much of the research on neural network synthesis has focused on algorithms that modify the weights within an otherwise fixed network architecture <ref> (Gallant, 1993) </ref>. This essentially 22 entails a search for a setting of the weights that endows the network with the desired input-output behavior.
Reference: <author> Gallistel, C. </author> <year> (1990). </year> <title> The Organization of Learning. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This process of maintaining an estimate of one's own position based on knowledge of distance, direction, and time of self-motion is referred to as dead-reckoning 76 or path-integration <ref> (Gallistel, 1990) </ref>. As will be clarified in Section 6.5, there is considerable evidence that animals use such dead-reckoning mechanisms to learn and navigate between places (Gallistel, 1990). In addition to animals, contemporary robotics also offers a variety of devices that enable robots to detect motion and perform dead-reckoning (Everett, 1995). <p> maintaining an estimate of one's own position based on knowledge of distance, direction, and time of self-motion is referred to as dead-reckoning 76 or path-integration <ref> (Gallistel, 1990) </ref>. As will be clarified in Section 6.5, there is considerable evidence that animals use such dead-reckoning mechanisms to learn and navigate between places (Gallistel, 1990). In addition to animals, contemporary robotics also offers a variety of devices that enable robots to detect motion and perform dead-reckoning (Everett, 1995). Odometric techniques that make use of inexpensive optical and magnetic wheel encoders are popular mechanisms for obtaining rough estimates of robot position.
Reference: <author> Gallistel, C., & Cramer, A. </author> <year> (1996). </year> <title> Computations on Metric Maps in Mammals: Getting Oriented and Choosing a Multi-Destination Route. </title> <journal> The Journal of Experimental Biology, </journal> <month> 199(1), </month> <pages> 211-217. </pages>
Reference-contexts: Our behavioral simulations on the other hand, have navigating animats (Balakrishnan et al., 1998c). Finally, in their simulations goals are assumed to coincide with the origin of the coordinate framework. Since animals commonly remember multiple goal locations and often plan and execute multi-destination routes <ref> (Gallistel & Cramer, 1996) </ref>, it is not clear how this goal representation will scale up to such tasks. In our model goals are represented in terms of dead-reckoning coordinates and multiple goals can be easily represented, as we have shown in Section 8.5.1.
Reference: <author> Gelb, A. </author> <year> (1974). </year> <title> Applied Optimal Estimation. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This is the sensory input (or observation) the robot expects to receive at its new position. Based on actual measurement (or observation) z k the Kalman filter updates the state estimate and covariance matrix as follows (refer to <ref> (Gelb, 1974) </ref> for details of the derivation): ^x + k + K k (z k ^z k ) (8.3) k = (I K k H k )P where K k = P k H T k H T k + R k ) 1 is referred to as the Kalman gain
Reference: <author> Ginsberg, M. </author> <year> (1993). </year> <booktitle> Essentials of Artificial Intelligence. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Goldberg, D. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning. </booktitle> <address> Reading, MA: </address> <publisher> Addison Wesley. </publisher>
Reference-contexts: We used binary tournament selection to choose parents for mating in each step <ref> (Goldberg, 1989) </ref>. Our experiments made use of two genetic operators: crossover and mu 50 tation. We used uniform crossover with the probability of crossover set at 0.5. In uniform crossover each gene in the offspring has a uniform chance of coming from either of its parents (Syswerda, 1989).
Reference: <author> Grier, J., & Burk, T. </author> <year> (1992). </year> <title> Biology of Animal Behavior. </title> <type> 2 edn. </type> <address> New York, NY: </address> <publisher> Mosley-Year Book. </publisher>
Reference-contexts: However, this is not really a problem since evolution has equipped these creatures with active vision systems. These fishes produce and emit their own light, and use it to detect obstacles, prey, etc. This vision system is unlike any seen on surface-dwelling organisms <ref> (Grier & Burk, 1992) </ref>. Apart from evolution, learning is another biological process that allows animals to successfully adapt to their environments. <p> When the eggs hatch, the young automatically crawl to the water without any kind of parental supervision. They appear to be genetically programmed to interpret cues emanating from large bodies of water or patches of sky over them <ref> (Grier & Burk, 1992) </ref>. Animals are also capable of learning the spatial attributes of novel environments. For instance, as will become apparent 5 in Chapter 6, rodents have an immense capacity to learn and successfully navigate through complex mazes (Tolman, 1948; O'Keefe & Nadel, 1978). <p> Similar results using the AD output coding mechanism are presented in (Balakrishnan & Honavar, 1996a; Balakrishnan & Honavar, 1996c). 4.2 Sensory System Design Biological organisms employ a variety of sensory systems like mechanoreceptors, photore-ceptors, thermoreceptors, electroreceptors, chemoreceptors, etc., <ref> (Grier & Burk, 1992) </ref>. One possible reason for this variety is that each such sensory modality endows the organism with a survival advantage in the niche that it occupies. For example, the vision system of most animals is passive, designed to detect natural light reflected from objects. <p> For example, the vision system of most animals is passive, designed to detect natural light reflected from objects. However, certain species of deep-water marine life, for example flashlight fish (photoblepharon palpebratus), possess an active vision system <ref> (Grier & Burk, 1992) </ref>. They generate and emit their own light, and 79 detect objects by appropriately sensing the reflected light. Since surface light hardly reaches the ocean depths that these fish inhabit, evolution seems to have found this novel design to enable these fishes to overcome this severe handicap. <p> Finally, the physical environment provides many raw materials that can be used to make up signals: molecules, light waves, electrical and mechanical fields, vibrations, etc., <ref> (Grier & Burk, 1992) </ref>. However, in order to exploit some or all of these signals, the organism should not only have sensors capable of detecting them, but the sensors should also be tuned into these signals.
Reference: <author> Gruau, Frederic. </author> <year> (1994). </year> <title> Genetic Micro Programming of Neural Networks. </title> <editor> In: Kinnear, Kim (ed), </editor> <booktitle> Advances in Genetic Programming. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Harvey, I., Husbands, P., & Cliff, D. </author> <year> (1992). </year> <booktitle> Issues in Evolutionary Robotics. In: From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference: <author> Harvey, I., Husbands, P., & Cliff, D. </author> <year> (1994). </year> <title> Seeing the Light: Artificial Evolution, Real Vision. </title> <booktitle> In: From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference-contexts: later, through our analysis we have been able to characterize successful box-pushing behaviors. 3.1.2 Comparison to Other Tasks in Evolutionary Robotics Most of the robot tasks used in evolutionary robotics studies have been simple variants of basic navigation behaviors like obstacle avoidance (Floreano & Mondada, 1994; Reynolds, 1994a), goal approaching <ref> (Harvey et al., 1994) </ref>, wall following (Reynolds, 1994b; Yamauchi 42 & Beer, 1994), light or target following (Colombetti & Dorigo, 1992), feeding (Menczer & Belew, 1994; Walker, 1995), homing, maze or trail learning (Koza, 1991; Collins & Jefferson, 1991), simple exploration (Lewis et al., 1992; Miglino et al., 1994), etc.
Reference: <author> Hassoun, M. H. </author> <year> (1995). </year> <booktitle> Fundamentals of Artificial Neural Networks. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. 255 Haykin, </publisher> <editor> S. </editor> <booktitle> (1994). Neural Networks. </booktitle> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference: <author> Hebb, D. </author> <year> (1949). </year> <title> The Organization of Behavior. </title> <address> New York, NY: </address> <publisher> John Wiley. </publisher>
Reference-contexts: A large fraction of this effort has been devoted to the study of rodent navigation because experiments have indicated that space plays a dominant role in their behavior, making them relatively more willing subjects in spatial learning tasks <ref> (Hebb, 1949) </ref>. An important aspect of rodent spatial learning appears to be their tendency to learn places rather than individual stimuli. For instance, Hebb (1949) trained rats to run to a dish of food located at the edge of an open table. <p> In another experiment, rats were trained to jump from one platform to another to obtain a food reward. Once trained, the rats were found to jump into space when the second platform was moved to a different location <ref> (Hebb, 1949) </ref>. Similar results confirming place-learning (as opposed to cue-learning) have also been observed by (O'Keefe & Nadel, 1978). Experiments have also revealed that rats are capable of detour behaviors and latent learning. <p> Experiments have also provided many insights into the processing of sensory stimuli. For instance, it appears that rats give more importance to remote sensory cues than to local ones, possibly because remote cues are the least-variable objects in the environment <ref> (Hebb, 1949) </ref>.
Reference: <author> Hebert, P., Betge-Brezetz, S., & Chatila, R. </author> <year> (1995). </year> <title> Probabilistic Map Learning: Necessity and Difficulties. </title> <booktitle> Pages 307-321 of: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference-contexts: A good discussion of Kalman filtering approaches for robot localization can be found in (Crowley, 1995), while the necessity and difficulties associated with maintaining correlations of the state variables of a stochastic map are detailed in <ref> (Hebert et al., 1995) </ref>. Kalman filtering approaches for robot localization require a sensor model of the environment in the measurement function. This sensor model provides the sensory inputs (or measurement) that the robot would receive when in any given position. <p> Estimating and maintaining these correlations is often difficult owing to the approximation errors stemming from linearizing the (usually) non-linear system and measurement functions, biases on the robot position, and the computational complexity associated with updating state vectors containing a large number of elements <ref> (Hebert et al., 1995) </ref>. However, these correlations and variances cannot be neglected since doing so will lead to inconsistencies on the uncertainties (Hebert et al., 1995). In our model, we ignore the autocorrelation of the measurement noise. <p> linearizing the (usually) non-linear system and measurement functions, biases on the robot position, and the computational complexity associated with updating state vectors containing a large number of elements <ref> (Hebert et al., 1995) </ref>. However, these correlations and variances cannot be neglected since doing so will lead to inconsistencies on the uncertainties (Hebert et al., 1995). In our model, we ignore the autocorrelation of the measurement noise.
Reference: <author> Hertz, J., Krogh, A., & Palmer, R. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. </title> <address> Redwood City, CA: </address> <publisher> Addison Wesley. </publisher>
Reference-contexts: This process of updating the activations of the units is repeated 21 for an a-priori fixed interval of time called the bound. At the end of this time interval, the activations of the output units are taken to be the response of the network <ref> (Hertz et al., 1991) </ref>. In our work, we use this mode of activation propagation for both feed-forward and recurrent networks, with the fixed time-bound being the delay associated with the computation of the activation of one unit.
Reference: <author> Holland, J. </author> <year> (1975). </year> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor: </address> <publisher> The University of Michigan Press. </publisher>
Reference: <author> Honavar, V. </author> <year> (1990). </year> <title> Generative Learning Structures and Processes for Generalized Connectionist Networks. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of Wisconsin, Madison, WI. </institution>
Reference: <author> Honavar, V. </author> <year> (1994). </year> <title> Toward Learning Systems That Integrate Different Strategies and Representations. Pages 561-580 of: Honavar, </title> <editor> V., & Uhr, L. (eds), </editor> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference-contexts: of Artificial Neural Networks As may be inferred, the input-output mapping realized by an artificial neural network is a function of the numbers of units, the functions they compute, the topology of their connectivity, the strength of their connections (weights), the control algorithm for propagating activations through the network, etc., <ref> (Honavar, 1994) </ref>. Thus, to create a neural network with a desired input-output mapping, one has to appropriately design these different components of the network.
Reference: <author> Honavar, V., & Uhr, L. </author> <year> (1993). </year> <title> Generative Learning Structures and Processes for Generalized Connectionist Networks. </title> <journal> Information Sciences, </journal> <volume> 70, </volume> <pages> 75-108. </pages>
Reference: <author> Horn, J., & Nafpliotis, N. </author> <year> (1993). </year> <title> Multiobjetive Optimization Using the Niched Pareto Genetic Algorithm. </title> <type> IlliGAL Technical Report 93005. </type> <institution> University of Illinois, Urbana-Champaign, IL. </institution>
Reference: <author> Hull, C. </author> <year> (1934a). </year> <title> The Concept of Habit-Family Hierarchy and Maze Learning. I. </title> <journal> Psychological Review, </journal> <volume> 41, </volume> <pages> 33-54. </pages>
Reference: <author> Hull, C. </author> <year> (1934b). </year> <title> The Concept of Habit-Family Hierarchy and Maze Learning. II. </title> <journal> Psychological Review, </journal> <volume> 41, </volume> <pages> 134-152. </pages>
Reference: <author> Hull, C. </author> <year> (1943). </year> <booktitle> Principles of Behavior. </booktitle> <address> New York, NY: Appleton-Century-Crofts. </address>
Reference: <author> Hull, C. </author> <year> (1951). </year> <title> Essentials of Behavior. </title> <address> Westport, CT: </address> <publisher> Greenwood Press. </publisher> <address> 256 Hull, C. </address> <year> (1952). </year> <title> A Behavior System. </title> <address> New Haven, CT: </address> <publisher> Yale University Press. </publisher>
Reference-contexts: specification, and Tolman provided little detail about the properties of such cognitive maps or the way animals build them. 6.4.1.2 Habit-Family Hierarchy of Hull In contrast to Tolman's cognitive maps, Hull developed a rigorous and non-verbal mathematical extension of Thorndikian learning and used it to characterize maze learning in rodents <ref> (Hull, 1951) </ref>. He proposed a further extension of this formalism that could explain detour behavior. According to this theory rats used Thorndikian learning to associate specific responses with stimuli, thereby learning one habit. <p> This, he claimed, was sufficient to learn S-R associations, although rather weakly. Later, when a reward is presented in the goal box, the incentive motivation changes abruptly, improving the goal-directed navigation behavior of the rat <ref> (Hull, 1951) </ref>. 137 6.4.1.3 Locale and Taxon Hypotheses of O'Keefe and Nadel O'Keefe and Nadel (1978) suggested that rats possibly use two spatial representation schemes (along with their associated navigation mechanisms): the locale system and the taxon system.
Reference: <author> Hummel, R. </author> <year> (1995). </year> <title> Uncertainty Reasoning in Object Recognition by Image Processing. </title> <booktitle> Pages 131-145 of: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference: <author> Husbands, P., Harvey, I., & Cliff, D. </author> <year> (1993). </year> <title> Analysing Recurrent Dynamical Networks Evolved for Robot Control. </title> <booktitle> In: Proceedings of the 3rd IEE International Conference on Artificial Neural Networks. </booktitle>
Reference: <author> Hwang, Y., & Ahuja, N. </author> <year> (1992). </year> <title> Gross Motion Planning A Survey. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3), </volume> <pages> 219-291. </pages>
Reference: <author> Jakobi, N., Husbands, P., & Harvey, I. </author> <year> (1995). </year> <title> Noise and the Reality Gap: </title> <booktitle> The Use of Simulation in Evolutionary Robotics. In: Proceedings of the Third European Conference on Artificial Life. </booktitle>
Reference: <author> James, W. </author> <title> (1890). </title> <booktitle> The Principles of Psychology. </booktitle> <address> New York, NY: </address> <publisher> Holt, Rinehart and Winston. </publisher>
Reference: <author> Jarrard, L. </author> <year> (1993). </year> <booktitle> On the Role of the Hippocampus in Learning and Memory in the Rat. Behavioral Neural Biology, </booktitle> <volume> 3, </volume> <pages> 279-287. </pages>
Reference: <author> Jazwinski, A. </author> <year> (1970). </year> <title> Stochastic Processes and Filtering Theory. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference-contexts: However, it turns out that this error is autocorrelated and hence is not a white sequence (Proposition 5). This autocorrelation is difficult to measure, and though we could use extended state vectors to estimate this correlation, leading to augmented Kalman filtering (pp 212, <ref> (Jazwinski, 1970) </ref>), we choose to ignore it. The justification for this is provided by the navigation behavior of the animat .
Reference: <author> Jensen, O., & Lisman, J. </author> <year> (1996). </year> <title> Hippocampal CA3 Region Predicts Memory Sequences: Accounting for the Phase Precession of Place Cells. </title> <booktitle> Learning and Memory, </booktitle> <volume> 3, </volume> <pages> 279-287. </pages>
Reference: <author> Johnson, R., & Bhattacharyya, G. </author> <year> (1996). </year> <title> Statistics: </title> <booktitle> Principles and Methods. </booktitle> <address> New York, NY: </address> <publisher> John Wiley. </publisher>
Reference-contexts: Given the number of degrees of freedom, we can determine the value of the distribution ( 2 ff ) such that the area under the curve to the right of it is ff <ref> (Johnson & Bhattacharyya, 1996) </ref>. Since the Mahalanobis distance has a chi-square distribution, we can choose a value of the distance such that the area to the right of it is, say, 10%. <p> Since the covariance matrix of the Mahalanobis test shown in proposition 7 has a rank of 2, we determine the value of the chi-square distribution with 2 degrees of freedom such that the area to the right of it is 10%. This value is 4:61 <ref> (Johnson & Bhattacharyya, 1996) </ref>. Thus, in our model, if we compute the Mahalanobis distance and declare that the match is correct if this distance happens to be less than 4.61, then we can be 90% confident of not rejecting actually correct matches.
Reference: <author> Juedes, D., & Balakrishnan, K. </author> <year> (1996). </year> <title> Generalized Neural Networks, Computational Differentiation, and Evolution. </title> <editor> In: Berz, M., Bischof, C., Corliss, G., & Griewank, A. (eds), </editor> <title> Computational Differentiation: Applications, Techniques, and Tools. </title> <address> Philadelphia, PA: </address> <publisher> SIAM Press. </publisher>
Reference-contexts: Not only did this taxonomy allow us to distinguish between different approaches, but also helped us identify potential research directions. For instance, we found that no one had addressed the evolution of activation functions in neural architectures. This allowed us to explore this area fruitfully <ref> (Juedes & Balakrishnan, 1996) </ref>. 2. The genetic representation chosen in an EDNA system not only dictates the kinds of target neural networks that the system can possibly evolve, but also determines the amount of resources expended in this effort. <p> Further, the evolutionary algorithm may be easily extended to automatically adapt other parameters of the network like the individual activation functions of the units <ref> (Juedes & Balakrishnan, 1996) </ref>, rates of mutation (Schwefel, 1987) and learning (Salomon, 1991), and even the learning algorithm (Chalmers, 1990).
Reference: <author> Jung, M., & McNaughton, B. </author> <year> (1993). </year> <title> Spatial Selectivity of Unit Activity in the Hippocampal Granular Layer. </title> <journal> Hippocampus, </journal> <volume> 3, </volume> <pages> 165-182. </pages> <note> 257 Kalman, </note> <author> R. </author> <year> (1960). </year> <title> A New Approach to Linear Filtering and Prediction Problems. </title> <journal> Transactions of the ASME, </journal> <volume> 60. </volume>
Reference-contexts: Since their initial discovery, cells with such location-specific firing have been found in almost every major region of the hippocampal system, including the entorhinal cortex (Quirk et al., 1992), the dentate gyrus <ref> (Jung & McNaughton, 1993) </ref>, the hip-pocampus proper (O'Keefe & Dostrovsky, 1971; O'Keefe, 1976), the subiculum (Barnes et al., 1990; Sharp & Green, 1994), and the postsubiculum (Sharp, 1996). In addition to place cells, head-direction cells have also been discovered in the hippocampal region.
Reference: <author> Kaplan, S. </author> <year> (1973a). </year> <title> Cognitive Maps, Human Needs, and the Designed Environment. </title> <editor> In: Preiser, W. (ed), </editor> <booktitle> Environmental Design Research, Vol 1. </booktitle> <address> New York, NY: Dowden, </address> <publisher> Hutchinson, and Ross. </publisher>
Reference: <author> Kaplan, S. </author> <year> (1973b). </year> <title> Cognitive Maps in Perception and Thought. </title> <editor> In: Downs, M., & Stea, D. (eds), </editor> <booktitle> Image and Environment. </booktitle> <address> New York, NY: </address> <publisher> Aldine Publishing Company. </publisher>
Reference: <author> Keeney, R., & Raiffa, H. </author> <year> (1976). </year> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <address> New York, NY: </address> <publisher> John Wiley. </publisher>
Reference-contexts: However, these extra units are a drain on the limited power resources of the robot. One way to perform such tradeoffs is to map or evaluate the different objectives in terms of a common currency, for example, utility <ref> (Keeney & Raiffa, 1976) </ref>, and choose options that maximize the expected utility (von Neumann & Morgenstern, 1944). We have adopted a similar, but simpler, approach by mapping the different components of our agent into the common currency of power consumption (Mc-Farland & Bosser, 1993).
Reference: <author> Keith, J., & McVety, K. </author> <year> (1988). </year> <title> Latent Place Learning in a Novel Environment and the Influences of Prior Training in Rats. </title> <journal> Psychobiology, </journal> <volume> 16(2), </volume> <pages> 146-151. </pages>
Reference-contexts: Other related experiments have established that the rats appear to know how visual scenes are transformed by locomotion and are capable of computing approach trajectories using inverse transformations <ref> (Keith & McVety, 1988) </ref>. Experiments with gerbils have led to the suggestion that these animals compute and store vectors to landmarks from the goal location. Further, independent vectors appear to be computed for each of the landmarks (Collett et al., 1986).
Reference: <author> Kimble, D. </author> <year> (1968). </year> <title> Hippocampus and Internal Inhibition. </title> <journal> Psychological Bulletin, </journal> <volume> 70, </volume> <pages> 285-295. </pages>
Reference: <author> Knierim, J., Kudrimoti, H., & McNaughton, B. </author> <year> (1995). </year> <title> Hippocampal Place Fields, the Internal Compass, and the Learning of Landmark Stability. </title> <journal> Journal of Neuroscience, </journal> <volume> 15, </volume> <pages> 1648-1659. </pages>
Reference-contexts: Experiments have shown that the motor system plays a critical role in the firing of place and head-direction cells. For instance, with restraints on active motion, both hippocampal place cell activity (Foster et al., 1989) as well thalamic head-direction cell activity <ref> (Knierim et al., 1995) </ref> have been observed to cease. Since the dead-reckoning system presumably receives input from the motor system (e.g., in the form of a motor efference copy) these experiments further implicate dead-reckoning in place and head-direction cell firing (McNaughton et al., 1996). <p> Rats have also been found to develop stable, unique associations between visual stimuli and the cells of the path-integration system, which presumably allows them to realign the dead-reckoning system when mismatches occur <ref> (Knierim et al., 1995) </ref>. In summary, place cells and head-direction cells respond to sensory as well as dead-reckoning inputs. These cells are active in multiple environments and also active in multiple places in the same environment.
Reference: <author> Koenig, S., Goodwin, R., & Simmons, R. </author> <year> (1995). </year> <title> Robot Navigation with Markov Models: A Framework for Path Planning and Learning with Limited Computational Resources. </title> <booktitle> Pages 322-337 of: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference: <author> Kolodner, J. </author> <year> (1993). </year> <title> Case-Based Reasoning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kortenkamp, D. </author> <year> (1993). </year> <title> Cognitive Maps for Mobile Robots: A Representation for Mapping and Navigation. </title> <type> Ph.D. thesis, </type> <institution> Electrical Engineering and Computer Science Department, University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: In his implementation, sonar-based detection of gateways and vision-based detection of scenes are combined using a Bayesian network to provide robust definitions of place. The system then uses these place definitions to construct routes, networks of routes, and global spatial representations involving many such networks <ref> (Kortenkamp, 1993) </ref>. Such multi-level spatial representations are also found in Qualnav (Levitt & Lawton, 1990). This simulated robot represents regions of space called viewframes at the lowest level. Viewframes are composed of relative angles and estimated distances to landmarks visible from the current place.
Reference: <author> Kortenkamp, D., & Weymouth, T. </author> <year> (1994). </year> <title> Topological Mapping for Mobile Robots Using a Combination of Sonar and Vision Sensing. </title> <booktitle> In: AAAI-94: Proceedings of the American Association of Artificial Intelligence. 258 Koza, J. </booktitle> <year> (1991). </year> <title> Genetic Evolution and Co-Evolution of Computer Programs. </title> <booktitle> In: Proceedings of the Second International Conference on Artificial Life. </booktitle>
Reference: <author> Koza, John R. </author> <year> (1992). </year> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The literature broadly distinguishes between four different classes of evolutionary approaches: genetic algorithms, genetic programming, evolutionary programming, and evolution strategies. While genetic algorithms typically use binary (or bit) strings to represent genotypes (Holland, 1975; Goldberg, 1989), genetic programming evolves programs in some given language <ref> (Koza, 1992) </ref>. Both these paradigms perform evolutionary search via genetic operators of crossover and mutation. Evolutionary programming, on the other hand, allows complex structures in the genotypes but only uses a mutation operator (Fogel, 1994). Evolution strategies are typically used for parameter optimization (Schwefel, 1981; Back et al., 1993).
Reference: <author> Kubie, J., & Ranck, J. </author> <year> (1983). </year> <title> Sensory-Behavioral Correlates in Individual Hippocampus Neurons in Three Situations: Space and Context. Pages 433-447 of: Seifert, </title> <editor> W. (ed), </editor> <booktitle> Neurobiology of the Hippocampus. </booktitle> <address> London: </address> <publisher> Academic Press. </publisher>
Reference: <author> Kuipers, B. </author> <year> (1978). </year> <title> Modeling Spatial Knowledge. </title> <journal> Cognitive Science, </journal> <volume> 2, </volume> <pages> 129-153. </pages>
Reference-contexts: update algorithm but results in a loss of information and a consequent increase in uncertainty (Elfes, 1992). 6.3.2 Topological Maps for Representing Spatial Information A popular example of relation-based spatial representations is the topological map which only represents distinctive places in the environment along with the local relationships between them <ref> (Kuipers, 1978) </ref>. This map can thus be thought of as a graph where nodes represent distinct places and the edges denote the relationship between them (Brooks, 1985).
Reference: <author> Kuipers, B., & Byun, Y-T. </author> <year> (1991). </year> <title> A Robot Exploration and Mapping Strategy Based on a Semantic Hierarchy of Spatial Representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <pages> 8. </pages>
Reference-contexts: Local relationships usually represented in such maps include the directional relationship between places (Nehmzow, 1995) or the directional relationship compounded with distance information <ref> (Kuipers & Byun, 1991) </ref>. Some topological schemes also 132 represent metric information pertaining to the distinctive place (e.g., length), which is useful if the place represents a wall or a corridor (Mataric, 1992). <p> The next higher level creates a topological representation by linking distinctive places by travel edges and the highest level in the hierarchy contains a geometric representation of the robot's sensory environment <ref> (Kuipers & Byun, 1991) </ref>. This cognitive spatial learning architecture was implemented on a simulated robot NX (Kuipers & Byun, 1991) and later extended to physical robots (Kuipers et al., 1993). <p> The next higher level creates a topological representation by linking distinctive places by travel edges and the highest level in the hierarchy contains a geometric representation of the robot's sensory environment <ref> (Kuipers & Byun, 1991) </ref>. This cognitive spatial learning architecture was implemented on a simulated robot NX (Kuipers & Byun, 1991) and later extended to physical robots (Kuipers et al., 1993). Kortenkamp's RPLAN is an implementation of the PLAN (Prototypes, Location and Associative Networks) model of human cognitive mapping (Chown et al., 1995).
Reference: <author> Kuipers, B., Froom, R., Lee, W., & Pierce, D. </author> <year> (1993). </year> <title> The Semantic Hierarchy in Robot Learning. </title> <journal> Chap. </journal> <volume> 6, </volume> <pages> pages 141-170 of: </pages> <editor> Connell, J., & Mahadevan, S. (eds), </editor> <title> Robot Learning. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic. </publisher>
Reference-contexts: This cognitive spatial learning architecture was implemented on a simulated robot NX (Kuipers & Byun, 1991) and later extended to physical robots <ref> (Kuipers et al., 1993) </ref>. Kortenkamp's RPLAN is an implementation of the PLAN (Prototypes, Location and Associative Networks) model of human cognitive mapping (Chown et al., 1995). In his implementation, sonar-based detection of gateways and vision-based detection of scenes are combined using a Bayesian network to provide robust definitions of place.
Reference: <author> Kung, S. Y. </author> <year> (1993). </year> <title> Digital Neural Networks. </title> <address> New York, NY: </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Langley, P. </author> <year> (1995). </year> <title> Elements of Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kauffman. </publisher>
Reference: <author> Langley, P., & Pfleger, K. </author> <year> (1995). </year> <title> Acquisition of Place Knowledge Through Case-Based Learning. </title> <booktitle> In: Proceedings of the International Conference on Machine Learning. </booktitle>
Reference: <author> Latombe, J-C. </author> <year> (1991). </year> <title> Robot Motion Planning. </title> <address> New York, NY: </address> <publisher> Kluwer Academic. </publisher>
Reference: <author> Leonard, J., & Durrant-Whyte, H. </author> <year> (1992). </year> <title> Dynamic Map Building for and Autonomous Mobile Robot. </title> <journal> International Journal of Robotics Research, </journal> <volume> 11(4). </volume>
Reference: <author> Levine, D. </author> <year> (1991). </year> <title> Introduction to Neural and Cognitive Modeling. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Earlbaum Associates. </publisher>
Reference: <author> Levitt, T., & Lawton, D. </author> <year> (1990). </year> <title> Qualitative Navigation for Mobile Robots. </title> <journal> Artificial Intelligence, </journal> <volume> 44(3), </volume> <pages> 305-360. </pages>
Reference-contexts: The system then uses these place definitions to construct routes, networks of routes, and global spatial representations involving many such networks (Kortenkamp, 1993). Such multi-level spatial representations are also found in Qualnav <ref> (Levitt & Lawton, 1990) </ref>. This simulated robot represents regions of space called viewframes at the lowest level. Viewframes are composed of relative angles and estimated distances to landmarks visible from the current place.
Reference: <author> Levy, W. </author> <year> (1989). </year> <title> A Computational Approach to Hippocampal Function. </title> <journal> The Psychology of Learning and Motivation, </journal> <volume> 23, </volume> <pages> 243-305. </pages> <note> 259 Lewis, </note> <editor> F., Abdallah, C., & Dawson, D. (eds). </editor> <year> (1993). </year> <title> Control of Robot Manipulators. </title> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference: <author> Lewis, H., & Papadimitriou, C. </author> <year> (1981). </year> <title> Elements of the Theory of Computation. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Lewis, M., Fagg, A., & Sodium, A. </author> <year> (1992). </year> <title> Genetic Programming Approach to the Construction of a Neural Network for Control of a Walking Robot. </title> <booktitle> In: Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle>
Reference: <author> Li, M., & Vitanyi, P. </author> <year> (1997). </year> <title> An Introduction to Kolmogorov Complexity and Its Applications. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: probably best to think of complexity using several different notions including: structural complexity of genotypes, decoding complexity, computational (space/time) complexity of each of the components of the system (including decoding of genotypes, fitness evaluation, reproduction, etc.), and perhaps even other measures inspired by information theory (e.g., entropy, Kolmogorov complexity, etc.) <ref> (Li & Vitanyi, 1997) </ref>.
Reference: <author> Linsker, R. </author> <year> (1990). </year> <title> Perceptual Neural Organization: Some Approaches Based on Network Models and Information Theory. </title> <journal> Annual Review of Neurosciences, </journal> <volume> 13, </volume> <pages> 257-281. </pages>
Reference: <author> Lund, H., & Parisi, D. </author> <year> (1995). </year> <title> Preadaptations in Populations of Neural Networks Evolving in a Changing Environment. </title> <journal> Artificial Life, </journal> <volume> 2(2), </volume> <pages> 179-198. </pages>
Reference: <author> Lund, H., Hallam, J., & Lee, W-P. </author> <year> (1997). </year> <title> Evolving Robot Morphology. </title> <booktitle> In: Proceedings of IEEE Fourth International Conference on Evolutionary Computation. </booktitle>
Reference: <author> Mackintosh, N. </author> <year> (1983). </year> <title> Conditioning and Associative Learning. </title> <address> New York, NY: </address> <publisher> Clarendon. </publisher>
Reference: <author> Maes, P. </author> <year> (1997). </year> <title> Agents That Reduce Work and Information Overload. </title> <editor> In: Bradshaw, J. (ed), </editor> <booktitle> Software Agents. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Marr, D. </author> <year> (1971). </year> <title> Simple Memory: A Theory for Archicortex. </title> <journal> Philosophical Transactions of the Royal Society of London, </journal> <volume> 176, </volume> <pages> 23-81. </pages>
Reference: <author> Mataric, M. </author> <year> (1992). </year> <title> Integration of Representation into Goal-Driven Behavior-Based Robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3). </volume>
Reference-contexts: Some topological schemes also 132 represent metric information pertaining to the distinctive place (e.g., length), which is useful if the place represents a wall or a corridor <ref> (Mataric, 1992) </ref>. Such relation-based approaches produce a compact world representation since they only represent distinctive places and not the entire environment. Further, they are robust to global movement errors as they only represent local relationships between places (Brooks, 1985). <p> Thus, a robot equipped only with sonar sensors cannot identify individual objects in a scene, rather it is forced to learn the boundaries of objects in the environment. Consequently, such a robot can only process its sensory inputs in the form of a signature <ref> (Mataric, 1992) </ref> and its spatial representation can only use information of this form. Since animal spatial learning must also contend with similar issues, it is natural to ask how animals acquire, represent, and use spatial information.
Reference: <author> Maybeck, P. </author> <year> (1990). </year> <title> The Kalman Filter: An Introduction to Concepts. </title> <editor> In: Cox, I.J., & Wilfong, G. T. (eds), </editor> <title> Autonomous Robot Vehicle. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> McCurdy, E. </author> <year> (1948). </year> <title> The Mind of Leonardo da Vinci. </title> <address> New York, NY: </address> <publisher> Dodd, Mead, and Co. </publisher>
Reference: <author> McFarland, D. </author> <year> (1993). </year> <title> Animal Behavior. </title> <publisher> Essex, </publisher> <address> England: </address> <publisher> Longman Scientific and Technical. 260 McFarland, </publisher> <editor> D., & Bosser, T. </editor> <booktitle> (1993). Intelligent Behavior in Animals and Robots. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Not only are specific sensor traits critical to the behavior produced, interactions between different sensors are also highly important. For example, echolocation in bats is a successful behavior because the ultrasonic emitters and receptors act in tandem. One without the other would prove disastrous for the otherwise blind bats <ref> (McFarland, 1993) </ref>. Thus, determining the right combination of sensors is an equally hard, yet important issue. Another dimension in sensory system design is the number and placement of the sensors. For example, two eyes are a common configuration in animals. <p> This requires a big lens. However, to maintain the image in focus on the retina, increased lens size requires a corresponding increase in the lens curvature. Thus, many nocturnal animals have large lenses which produce small, bright images, while diurnal animals have smaller lenses which produce larger retinal images <ref> (McFarland & Bosser, 1993) </ref>. Finally, the physical environment provides many raw materials that can be used to make up signals: molecules, light waves, electrical and mechanical fields, vibrations, etc., (Grier & Burk, 1992). <p> The auditory system of these moths consists of two extremely simple ears. These ears are specifically tuned to recognize the ultrasonic cries of hunting bats. Further the neural circuitry is so arranged as to resort to different evasive measures depending on the proximity of the approaching bat 80 <ref> (McFarland & Bosser, 1993) </ref>. Without their systems tuned to detect ultrasonic frequencies, the moths would lose their survival edge. <p> The problem then is to determine the right utility functions that will allow the animals to engage in rational decision-making (von Neumann & Morgenstern, 1944). It has been suggested that these utility functions are pre-programmed by evolution and possibly adapted by the experiences of the animal <ref> (McFarland & Bosser, 1993) </ref>. We are exploring the use of such utility-based decision making mechanisms in our autonomous agents. A related research direction is in the evolution of reward systems for self-guided learning.
Reference: <author> McNaughton, B., & Nadel, L. </author> <year> (1989). </year> <title> Hebb-Marr Networks and the Neurobiological Representation of Action in Space. Pages 1-63 of: </title> <editor> Gluck, M., & Rumelhart, D. (eds), </editor> <title> Neuroscience and Connectionist Theory. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Earlbaum Associates. </publisher>
Reference: <author> McNaughton, B., & Nadel, L. </author> <year> (1990). </year> <title> Hebb-Marr Networks and the Neurobiological Representation of Action in Space. Pages 1-63 of: </title> <editor> Gluck, M., & Rumelhart, D. (eds), </editor> <title> Neuroscience and Connectionist Theory. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Earlbaum Associates. </publisher>
Reference: <author> McNaughton, B., Leonard, B., & Chen, L. </author> <year> (1989). </year> <title> Cortical-hippocampal Interactions and Cognitive Mapping: A Hypothesis Based on Reintegration of the Parietal and Inferotemporal Pathways for Visual Processing. </title> <journal> Psychobiology, </journal> <volume> 17(3), </volume> <pages> 230-235. </pages>
Reference: <author> McNaughton, B., Knierim, J., & Wilson, M. </author> <year> (1995). </year> <title> Vector Encoding and the Vestibular Foundations of Spatial Cognition: A Neurophysiological and Computational Hypothesis. Chap. 37 of: </title> <editor> Gazzaniga, M. (ed), </editor> <booktitle> The Cognitive Neurosciences. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> McNaughton, B., Barnes, C., Gerrard, J., Gothard, K., Jung, M., Knierim, J., Kudrimoti, H., Qin, Y., Skaggs, W., Suster, M., & Weaver, K. </author> <year> (1996). </year> <title> Deciphering the Hippocampal Polyglot: the Hippocampus as a Path-Integration System. </title> <journal> The Journal of Experimental Biology, </journal> <month> 199(1), </month> <pages> 173-185. </pages>
Reference-contexts: Since the dead-reckoning system presumably receives input from the motor system (e.g., in the form of a motor efference copy) these experiments further implicate dead-reckoning in place and head-direction cell firing <ref> (McNaughton et al., 1996) </ref>. Rats have also been found to develop stable, unique associations between visual stimuli and the cells of the path-integration system, which presumably allows them to realign the dead-reckoning system when mismatches occur (Knierim et al., 1995).
Reference: <author> Menczer, F., & Belew, R. </author> <year> (1994). </year> <title> Evolving Sensors in Environments of Controlled Complexity. </title> <booktitle> In: Proceedings of the Fourth International Conference on Artificial Life. </booktitle>
Reference: <author> Menczer, F., & Belew, R. </author> <year> (1995). </year> <title> Latent Energy Environments. </title> <editor> In: Belew, R., & Mitchell, M. (eds), </editor> <title> Adapting Individuals in Evolving Populations. </title> <address> Reading, MA: </address> <publisher> Addison Wesley. </publisher>
Reference: <author> Miglino, O., Nafasi, K., & Taylor, C. </author> <year> (1994). </year> <title> Selection for Wandering Behavior in a Small Robot. </title> <journal> Artificial Life, </journal> <volume> 2(1), </volume> <pages> 101-116. </pages>
Reference-contexts: Neurocontrollers were evolved to successfully avoid these obstacles in simulation and were then tested on actual Khepera robots. Despite using a simulation model built from a real Khepera, the researchers found considerable differences between fitnesses in simulation and on real robots. As with <ref> (Miglino et al., 1994) </ref>, the researchers found that the addition of conservative noise in the simulations led to robust designs that performed well even when transferred onto real robots. Walker (1995) studied a variation of a foraging task where the robots had to locate and approach radiative energy sources.
Reference: <author> Miglino, O., Lund, H., & Nolfi, S. </author> <year> (1995). </year> <title> Evolving Mobile Robots in Simulated and Real Environments. </title> <journal> Artificial Life, </journal> <volume> 2(4), </volume> <pages> 417-434. </pages> <note> 261 Miller, G.F., </note> <author> Todd, P.M., & Hegde, S.U. </author> <year> (1989). </year> <title> Designing Neural Networks Using Genetic Algorithms. </title> <booktitle> Pages 379-384 of: Proceedings of the Third International Conference on Genetic Algorithms. </booktitle>
Reference: <author> Minai, A., & Levy, W. </author> <year> (1993). </year> <title> The Dynamics of Sparse Random Networks. </title> <journal> Biological Cybernetics, </journal> <volume> 70, </volume> <pages> 177-187. </pages>
Reference: <author> Minsky, M. </author> <year> (1967). </year> <title> Computation: Finite and Infinite Machines. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Mitchell, M. </author> <year> (1996). </year> <title> An Introduction to Genetic Algorithms. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Mitchell, T. </author> <year> (1997). </year> <title> Machine Learning. </title> <address> New York, NY: </address> <publisher> McGraw Hill. </publisher>
Reference: <author> Mitchell, T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. </author> <year> (1994). </year> <title> Experience With a Learning Personal Assistant. </title> <journal> Communications of the ACM, </journal> <volume> 37(7). </volume>
Reference: <author> Mittelstaedt, H., & Mittelstaedt, M. </author> <year> (1982). </year> <title> Homing by Path Integration in a Mammal. Pages 290-297 of: </title> <editor> Papi, F., & Wallraff, H. (eds), Avian Navigation, </editor> <volume> vol. </volume> <pages> 67. </pages> <address> Berlin: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Mittelstaedt, M., & Mittelstaedt, H. </author> <year> (1980). </year> <title> Homing by Path Integration in a Mammal. </title> <journal> Naturwissenschaften, </journal> <volume> 67, </volume> <pages> 566-567. </pages>
Reference: <author> Mizumori, S., & Williams, J. </author> <year> (1993). </year> <title> Directionally Selective Mnemonic Properties of Neurons in the Lateral Dorsal Nucleus of the Thalamus of Rats. </title> <journal> Journal of Neuroscience, </journal> <volume> 13, </volume> <pages> 4015-4028. </pages>
Reference-contexts: Since then, such directional cells have also been discovered in the retrosplenial cortex (Chen et al., 1994a; Chen et al., 1994b), the anterior thalamus (Taube, 1995; Blair & Sharp, 1995), and the laterodorsal thalamus <ref> (Mizumori & Williams, 1993) </ref>. A number of experiments have been performed in order to determine the properties of the place and head-direction cells.
Reference: <author> Mondada, F., Franzi, E., & Ienne, P. </author> <year> (1993). </year> <title> Mobile Robot Miniaturization: A Tool for Investigation in Control Algorithms. </title> <booktitle> In: Proceedings of the Third International Symposium on Experimental Robotics. </booktitle>
Reference-contexts: We now present some work in evolutionary robotics that is closely related to our work described earlier. 3.4 Related Approaches for the Evolution of Neurocontrollers Floreano and Mondada (1994) evolved a neural network controller for the Khepera robot <ref> (Mondada et al., 1993) </ref> to demonstrate navigation and obstacle avoidance behaviors. They used a neurocontroller with 8 inputs and two outputs. The output units computed a sigmoid activation function and could have recurrent links between themselves.
Reference: <author> Moravec, H., & Elfes, A. </author> <year> (1985). </year> <title> High Resolution Maps from Wide Angle Sonar. </title> <booktitle> Pages 116-121 of: Proceedings of the 1985 IEEE International Conference on Robotics and Automation. </booktitle>
Reference: <author> Morris, R. </author> <year> (1981). </year> <title> Spatial Localization Does Not Require the Presence of Local Cues. </title> <journal> Learning and Motivation, </journal> <volume> 12, </volume> <pages> 239-261. </pages> <note> 262 Morris, </note> <editor> R., Garrud, P., Rawlins, J., & O'Keefe, J. </editor> <year> (1982). </year> <title> Place Navigation Impaired in Rats with Hippocampal Lesions. </title> <journal> Nature, </journal> <volume> 297, </volume> <pages> 681-683. </pages>
Reference-contexts: The model has been used to simulate a number of behavioral experiments, primarily the gerbil experiments of (Collett et al., 1986) and the water-maze task of <ref> (Morris, 1981) </ref>. In either case, the behaviors demonstrated by our animats 2 are largely similar to those observed by the researchers in their experiments with rodents. <p> Rats have also been found to successfully swim to a submerged platform in a milky pool of water, thereby demonstrating an ability to compute trajectories to hidden goal locations <ref> (Morris, 1981) </ref>. Other related experiments have established that the rats appear to know how visual scenes are transformed by locomotion and are capable of computing approach trajectories using inverse transformations (Keith & McVety, 1988). <p> Importantly, groups Cue-only and Cue + Place did not differ (in a statistical sense) in their ability to escape to the visible platform. However, their escape latencies were slightly smaller than those of the rats in the Place experiment <ref> (Morris, 1981) </ref>. Results of Test A indicated that the animals in the Place experiment show a strong bias for their training quadrant and spend considerable amount of time searching in that quadrant. This effect was also present, albeit much weaker, in animals of group Cue + Place. <p> it was kept constant across trials), with the result that the Place-Random animats could directly approach the goal as their counterparts in the Place experiment had done earlier. 228 10.4.3 Discussion We have used the computational model of spatial learning developed in Chapter 8 to simulate the behavioral experiments of <ref> (Morris, 1981) </ref>. It may be observed that our results are rather similar to those in the experiments of Morris. Thus, a metric spatial representation hypothesis, as underlies our hippocampal model, can be used to explain the water-maze behaviors of rats. <p> This led to the association of motor responses with appropriate sensory stimuli, such that sequences of motor actions, triggered by sensory stimuli, would lead the animat to the goal location. Although their results closely match those of <ref> (Morris, 1981) </ref>, is not clear how multiple goals were incorporated in the system (for the Place-Random experiment) or how the animat navigated (did it use a deterministic strategy or a non-deterministic mechanism to choose the action to perform). <p> We also developed a framework for learning, representing, and navigating to multiple goal locations in the environment (Balakrishnan et al., 1998a). 13. We used the model to simulate a number of behavioral experiments, primarily the gerbil experiments of (Collett et al., 1986) and the water-maze task of <ref> (Morris, 1981) </ref>. In either 235 case, the behaviors demonstrated by our animats were largely similar to those observed with rodents (Balakrishnan et al., 1998b; Balakrishnan et al., 1998a). 14.
Reference: <author> Moutarlier, P., & Chatila, R. </author> <year> (1989). </year> <title> Stochastic Multisensory Data Fusion for Mobile Robot Location and Environment Modeling. </title> <booktitle> In: The Fifth International Symposium on Robotics Research. </booktitle>
Reference-contexts: We now briefly consider our current understanding of how these processes of spatial learning and localization are realized by contemporary robots and animals. 130 6.3 Representation of Spatial Information in Robots Contemporary robots represent spatial information in one of two broad ways: location-based (metric) or relation-based <ref> (Moutarlier & Chatila, 1989) </ref>, although some recent approaches have attempted to combine merits of the two (Levitt & Lawton, 1990; Kuipers & Byun, 1991; Kortenkamp, 1993; Thrun, 1996). In location-based schemes places (or locations of objects) are all represented in the same coordinate frame with a global origin.
Reference: <author> Muller, R., & Kubie, J. </author> <year> (1987). </year> <title> The Effects of Changes in the Environment on the Spatial Firing of Hippocampal Complex-Spike Cells. </title> <journal> Journal of Neuroscience, </journal> <volume> 7, </volume> <pages> 1951-1968. </pages>
Reference: <author> Muller, R., Kubie, J., & Ranck, J. </author> <year> (1987). </year> <title> Spatial Firing Patterns of Hippocampus Complex-Spike Cells in a Fixed Environment. </title> <journal> Journal of Neuroscience, </journal> <volume> 7, </volume> <pages> 1935-1950. </pages>
Reference: <author> Muller, R., Kubie, J., & Saypoff, R. </author> <year> (1991). </year> <title> The Hippocampus as a Cognitive Graph. </title> <journal> Hip-pocampus, </journal> <volume> 1(3), </volume> <pages> 243-246. </pages>
Reference: <author> Nadel, L. </author> <year> (1996). </year> <title> The Hippocampus: Selective Functions in Memory. Pages 305-317 of: Ono, </title> <editor> T., McNaughton, B., Molotchnikoff, S., Rolls, E., & Nishijo, H. (eds), </editor> <booktitle> Perception, Memory, and Emotion: Frontiers in Neuroscience. </booktitle> <address> New York, NY: </address> <publisher> Pergamon Press. </publisher>
Reference-contexts: Importantly, they hypothesized that the locale system resides within the hippocampus and is affected by hippocampal lesions, while the taxon system lies largely outside the hippocampal area. This viewpoint is 146 now popularly referred to as the cognitive map theory of hippocampal function. <ref> (Nadel, 1996) </ref>. They also outlined the possibility of parallel learning by the locale and taxon systems, with the former rapidly learning flexible representations and the latter slowly converging to relatively inflexible ones. <p> the hippocampal formation is involved in novelty or discrepancy driven exploratory behaviors, neural representation of spatial maps and episodes (or events) in specific environments or contexts, the updating of these representations based on detected discrepancies, and the use of these spatial maps in the generation of routine or novel trajectories <ref> (Nadel, 1996) </ref>. Although O'Keefe and Nadel justified this hypothesis by pooling extensive data from cellular and lesion studies, they did not provide any computational implementation of this cognitive map theory. <p> Thus, this theory predicts that hippocampal lesions or damage will result in deficits in exploration, place learning and behavior, reaction to novelty, and the ability to recognize contexts and episodes <ref> (Nadel, 1996) </ref>. 3. Working memory theory This memory hypothesis forwarded by Olton (1986)suggests that the hippocampus is involved in learning and remembering spatio-temporal aspects of the environment that vary from trial to trial.
Reference: <author> Nehmzow, U. </author> <year> (1995). </year> <title> Animal and Robot Navigation. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 15, </volume> <pages> 71-81. </pages>
Reference-contexts: Local relationships usually represented in such maps include the directional relationship between places <ref> (Nehmzow, 1995) </ref> or the directional relationship compounded with distance information (Kuipers & Byun, 1991). Some topological schemes also 132 represent metric information pertaining to the distinctive place (e.g., length), which is useful if the place represents a wall or a corridor (Mataric, 1992).
Reference: <author> Nolfi, S., & Parisi, D. </author> <year> (1995). </year> <title> Evolving Non-Trivial Behaviors on Real Robots: An Autonomous Agent that Picks up Objects. </title> <type> Tech. rept. TR 95-03. </type> <institution> Institute of Psychology, C.N.R, Rome, Italy. </institution>
Reference: <author> Nolfi, S., Floreano, D., Miglino, O., & Mondada, F. </author> <year> (1994a). </year> <title> How to Evolve Autonomous Robots: </title> <booktitle> Different Approaches in Evolutionary Robotics. In: Proceedings of the Fourth International Conference on Artificial Life. </booktitle>
Reference: <author> Nolfi, S., Elman, J., & Parisi, D. </author> <year> (1994b). </year> <title> Learning and Evolution in Neural Networks. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 3(1), </volume> <pages> 5-28. </pages>
Reference-contexts: The box-pushing task differs from this work in a few critical ways. As we have argued earlier, the box-pushing task is more complex than food-approaching. Also, the box-pushing robots had extremely limited sensory ranges, unlike the foraging robots in the experiments of <ref> (Nolfi et al., 1994b) </ref>. Indeed, if the location of the nearest food element is directly available, a simple, manually developed program can guide the robot to the food element.
Reference: <author> Nwana, H. </author> <year> (1996). </year> <title> Software Agents: An Overview. </title> <journal> Knowledge Engineering Review, </journal> <volume> 11(3). </volume>
Reference: <author> O'Keefe, J. </author> <year> (1976). </year> <title> Place Units in the Hippocampus of the Freely Moving Rat. </title> <journal> Experimental Neurology, </journal> <volume> 51, </volume> <pages> 78-109. </pages> <note> 263 O'Keefe, J. </note> <year> (1989). </year> <title> Computations the Hippocampus Might Perform. Pages 225-284 of: </title> <editor> Nadel, L., Cooper, L., Culicover, P., & Harnish, R. (eds), </editor> <title> Neural Connections, Mental Computation. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> O'Keefe, J., & Dostrovsky, J. </author> <year> (1971). </year> <title> The Hippocampus as a Spatial Map: Preliminary Evidence from Unit Activity in the Freely Moving Rat. </title> <journal> Brain Research, </journal> <volume> 34, </volume> <pages> 171-175. </pages>
Reference: <author> O'Keefe, J., & Nadel, L. </author> <year> (1978). </year> <title> The Hippocampus as a Cognitive Map. </title> <publisher> Oxford, UK: Clarendon. </publisher>
Reference: <author> O'Keefe, J., & Speakman, A. </author> <year> (1987). </year> <title> Single Unit Activity in the Rat Hippocampus During a Spatial Memory Task. </title> <journal> Experimental Brain Research, </journal> <volume> 68, </volume> <pages> 1-27. </pages>
Reference: <editor> Omidvar, O., & van der Smagt, P. (eds). </editor> <booktitle> (1997). Neural Systems for Robotics. </booktitle> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: <author> Pagac, D., Nebot, E., & Durrant-Whyte, H. </author> <year> (1995). </year> <title> An Evidential Approach to Probabilistic Map-Building. </title> <booktitle> In: Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics. </booktitle>
Reference: <author> Parekh, R. </author> <year> (1998). </year> <title> Constructive Learning: Inducing Grammars and Neural Networks. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, Iowa State University, Ames, IA. </institution>
Reference-contexts: Thus, not only do these approaches synthesize network architectures, but also entertain the possibility of discovering compact (or minimal) networks. A number of such constructive and destructive learning algorithms have been developed, each offering its own characteristic bias. Some of these algorithms are discussed in <ref> (Parekh, 1998) </ref>. In addition to these approaches, evolutionary algorithms (to be described shortly) have also been used to search the space of neural architectures for near-optimal designs (see (Bal-akrishnan & Honavar, 1998) for a bibliography).
Reference: <author> Prepscius, C., & Levy, W. </author> <year> (1994). </year> <title> Sequence Prediction and Cognitive Mapping by a Biologically Plausible Neural Network. </title> <booktitle> Pages 164-169 of: Proceedings of the World Congress on Neural Networks. </booktitle>
Reference: <author> Prescott, T. </author> <year> (1995). </year> <title> Spatial Representations for Navigation in Animats. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 4(2), </volume> <pages> 85-123. </pages>
Reference: <author> Prescott, T., & Mayhew, J. </author> <year> (1992). </year> <title> Building Long-Range Cognitive Maps Using Local Landmarks. </title> <booktitle> Pages 233-242 of: Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference: <author> Quirk, G., Muller, R., & Kubie, J. </author> <year> (1990). </year> <title> The Firing of Hippocampal Place Cells in the Dark Depends on the Rat's Recent Experience. </title> <journal> Journal of Neuroscience, </journal> <volume> 10, </volume> <pages> 2008-2017. </pages> <note> 264 Quirk, </note> <author> G., Muller, R., Kubie, J., & Ranck, J. </author> <year> (1992). </year> <title> The Positional Firing Properties of Medial Entorhinal Neurons: Description and Comparison with Hippocampal Place Cells. </title> <journal> Journal of Neuroscience, </journal> <volume> 12(5), </volume> <pages> 1945-1963. </pages>
Reference: <author> Ranck, J. </author> <year> (1984). </year> <title> Head Direction Cells in the Deep Cell Layer of Dorsal Presubiculum in Freely Moving Rats. </title> <journal> Society for Neuroscience Abstracts, </journal> <volume> 10, </volume> <pages> 599. </pages>
Reference: <author> Recce, M., & Harris, K. </author> <year> (1996). </year> <title> Memory for Places: A Navigational Model in Support of Marr's Theory of Hippocampal Function. </title> <journal> Hippocampus, </journal> <volume> 6, </volume> <pages> 735-748. </pages>
Reference: <author> Redish, A., & Touretzky, D. </author> <year> (1996). </year> <title> Navigating with Landmarks: Computing Goal Locations from Place Codes. </title> <editor> In: Ikeuchi, K., & Veloso, M. (eds), </editor> <booktitle> Symbolic Visual Learning. </booktitle> <address> New York, NY: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: To borrow a term from the robotics literature, the hippocampus must be capable of probabilistic localization. Although several hippocampal models of spatial learning have been proposed, some of them closely related to our own <ref> (Redish & Touretzky, 1996) </ref>, none of them explicitly address the question of handling uncertainty in data. In order to satisfactorily characterize hippocampal spatial learning, we need a probabilistic framework for addressing uncertain information fusion. <p> and Updating Goal Locations Since our computational model allows the animat to learn places in a metric framework, goals encountered by the animat can also be remembered in terms of their metric positions. 172 This idea of computing and remembering goal locations from metric place estimates was first developed in <ref> (Redish & Touretzky, 1996) </ref>. In our work, the animats compute goal positions based on their current dead-reckoning estimates and the estimated distance to the goal. Thus, goals are represented in the same coordinate frame as the place field centers. <p> Importantly, our model includes a novel mechanism for handling perceptual aliasing problems using the CA1 layer. Also, their model includes a mechanism for learning and initializing the head-direction estimates of the animat. Our model is yet to incorporate this feature. In their simulations of behavioral experiments <ref> (Redish & Touretzky, 1996) </ref>, the animats do not navigate. The animats are simply placed at different positions in the environment and learn places based on accurate position estimates provided by the user. Our behavioral simulations on the other hand, have navigating animats (Balakrishnan et al., 1998c). <p> Thus, the ability to update not only the robot's position estimate but also the estimated positions of the different places, is an important advantage offered by our computational model. Although other hippocampal models in the literature support metric spatial learning <ref> (Redish & Touretzky, 1996) </ref>, they do not have mechanisms to update place field centers. 9.2.4.3 Effect of Range Sensing Errors on the Numbers of Units In this experiment, we explored the effect of increased sensing error on the numbers of EC, CA3, and CA1 units required in our model. <p> If some of these trajectories happened to conflict, i.e., led to radically different goal positions, the researchers suggested that the gerbils followed coincident trajectories that led to the same goal and ignored outriders. Although this vector voting hypothesis <ref> (Redish & Touretzky, 1996) </ref> explained some elements of goal-directed behavior, it failed to explain the ability of gerbils to relocalize or reorient themselves when the training configuration of landmarks was changed during test trials. <p> Once the animat had localized, it could predict the goal location, which was simply the origin of the coordinate frame with respect to its current localized position. This process was repeated a number times and a histogram of predicted goal positions was computed <ref> (Redish & Touretzky, 1996) </ref>. Although the results obtained by Redish and Touretzky were quite similar to the observations of Collett et al., a few relevant issues must be clarified. First, the position estimates used to label places were explicitly provided to the animats. Additionally, these estimates were considered error-free. <p> Second, goal locations in their model corresponded to the origin of the position estimate framework. It is unclear how the animats would represent multiple goals locations if they had to. Third, the animats used in their simulations did not explicitly move. Consequently, the histograms reported in <ref> (Redish & Touretzky, 1996) </ref> correspond to predictions of the goal position rather than the time spent by the animat in different regions of the environment. <p> We would also like to extend our model to incorporate a head-direction reset system. As mentioned earlier, such a mechanism has already been developed by <ref> (Redish & Touretzky, 1996) </ref>. With such a system the animat can also initialize its orientation, in addition to just localizing to a place. <p> Recently, Redish and Touretzky (1998) have provided a comprehensive account of rodent spatial learning and memory by suggesting that the hippocampus participates in both locale as well as route-based learning of space. While the locale-based learning component is rather similar to the one in their earlier work <ref> (Redish & Touretzky, 1996) </ref>, the route-based learning component is a new addition. This extension uses the CA3 recurrent collaterals to store specific paths (routes) traversed by the animat, and plays an important role in transferring these routes to long-term storage via slow cortical learning.
Reference: <author> Redish, A., & Touretzky, D. </author> <year> (1998). </year> <title> The Role of the Hippocampus in Solving the Morris Water Maze. </title> <journal> Neural Computation, </journal> <volume> 10, </volume> <pages> 73-111. </pages>
Reference-contexts: We also suspect that the place cells recently discovered in the subiculum encode ego-centric information, making it possible to initialize and reset head-direction estimates in the postsubicular area. These regions can thus be thought of as encoding a directional-map of the environment. Some researchers have begun exploring similar hypotheses <ref> (Redish & Touretzky, 1998) </ref>. Our model makes several key neurobiological and behavioral predictions. For instance, our model predicts that perceptually identical places in the same environment will excite the same population of cells in the CA3 layer but different populations in the CA1 layer.
Reference: <author> Reynolds, C. </author> <year> (1994a). </year> <title> Evolution of Corridor Following Behavior in a Noisy World. </title> <booktitle> In: From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference: <author> Reynolds, C. </author> <year> (1994b). </year> <title> Evolution of Obstacle Avoidance Behavior: Using Noise to Promote Robust Solutions. </title> <editor> In: Kinnear, K. (ed), </editor> <booktitle> Advances in Genetic Programming. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Rich, E., & Knight, K. </author> <year> (1991). </year> <booktitle> Aritificial Intelligence. </booktitle> <address> New York, NY: </address> <publisher> McGraw Hill. </publisher>
Reference: <author> Ripley, B. </author> <year> (1996). </year> <title> Pattern Recognition and Neural Networks. </title> <address> New York, NY: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Rolls, E. </author> <year> (1989a). </year> <title> Functions of Neuronal Networks in the Hippocampus and Neocortex in Memory. Pages 240-265 of: Byrne, </title> <editor> J., & Berry, W. (eds), </editor> <title> Neural Models of Plasticity: Theoretical and Empirical Approaches. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Rolls, E. </author> <year> (1989b). </year> <title> The Representation and Storage of Information in Neuronal Networks in the Primate Cerebral Cortex and Hippocampus. Pages 125-159 of: Durbin, </title> <editor> R., Miall, C., & Mitchison, G. (eds), </editor> <booktitle> The Computing Neuron. </booktitle> <address> Wokingham, UK: </address> <publisher> Addison Wesley. 265 Rolls, E. </publisher> <year> (1990). </year> <title> Functions of the Primate Hippocampus in Spatial Processing and Memory. </title>
Reference: <editor> Pages 339-362 of: Kesner, R., & Olton, D. (eds), </editor> <title> Neurobiology of Comparative Cognition. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Earlbaum Associates. </publisher>
Reference: <author> Rolls, E. </author> <year> (1996). </year> <title> The Representation of Space in the Primate Hippocampus and Episodic Memory. Pages 375-400 of: Ono, </title> <editor> T., McNaughton, B., Molotchnikoff, S., Rolls, E., & Nishijo, H. (eds), </editor> <booktitle> Perception, Memory, and Emotion: Frontiers in Neuroscience. </booktitle> <address> New York, NY: </address> <publisher> Pergamon Press. </publisher>
Reference-contexts: Recently, place cells have also been discovered in the subiculum (Sharp, 1996), although not much is known about them yet. There is also some evidence that the entorhinal cortex projects back to many of the 143 cortical association areas from which it receives input and mediates information storage there <ref> (Rolls, 1996) </ref>. However, these mechanisms are not well understood. We will now consider some physiological properties of hippocampal cells, that have been identified through intricate cellular recordings. <p> These episodes correspond to event sequences in the temporal domain and spatial scenes in purely spatial contexts, with most real-world environments leading to hybrid spatio-temporal representations <ref> (Rolls, 1996) </ref>. This theory has been mapped to a sequence of computational models of the hippocampus, which include specific roles assigned to the different hip 154 pocampal regions (Rolls, 1989a; Rolls, 1989b; Treves & Rolls, 1992; Treves & Rolls, 1994; Rolls, 1996).
Reference: <author> Rudy, J., & Sutherland, R. </author> <year> (1989). </year> <title> The Hippocampal Formation is Necessary for Rats to Learn and Remember Configural Discriminations. </title> <journal> Behavioral Brain Research, </journal> <volume> 34, </volume> <pages> 97-109. </pages>
Reference: <editor> Rumelhart, D. E., & McClelland, J. L. (eds). </editor> <booktitle> (1986). Parallel Distributed Processing, Vol I-II. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The system thus evolves purely feed-forward networks. Next, all the connections in the network are set to small random values and trained for a fixed number of epochs on a given set of training examples, using the back-propagation algorithm <ref> (Rumelhart & McClelland, 1986) </ref>. The total sum squared error (E) of the network, at the end of the training phase, is used as the fitness measure, with low values of E corresponding to better performance and hence a higher fitness label for the corresponding genotype.
Reference: <author> Russell, S., & Norvig, P. </author> <year> (1995). </year> <title> Artificial Intelligence A Modern Approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: In very simplistic terms, an agent may be defined as an entity that perceives its environment through sensors and acts upon it through its effectors <ref> (Russell & Norvig, 1995) </ref>. However, for the agents to be useful, they must also be capable of interpreting perceptions, reasoning, and choosing actions autonomously and in ways suited to achieving their intended goals. <p> The agent program is a mapping that determines the actions of the agent in response to its sensory inputs, while architecture refers to the computing and physical medium on which this agent program is executed <ref> (Russell & Norvig, 1995) </ref>. For example, a mail filtering agent might be programmed in a language such as C++ and executed on a computer, or a robot might be programmed to move about and collect empty soda cans using its gripper arm.
Reference: <author> Salomon, R. </author> <year> (1991). </year> <title> Improved Convergence Rate of Back-Propagation with Dynamic Adaptation of the Learning Rate. </title> <booktitle> Pages 269-273 of: Proceedings of the First International Conference on Parallel Problem Solving from Nature. </booktitle>
Reference-contexts: Further, the evolutionary algorithm may be easily extended to automatically adapt other parameters of the network like the individual activation functions of the units (Juedes & Balakrishnan, 1996), rates of mutation (Schwefel, 1987) and learning <ref> (Salomon, 1991) </ref>, and even the learning algorithm (Chalmers, 1990).
Reference: <author> Sarton, G. </author> <year> (1936). </year> <title> The Study of the History of Science. </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Schmajuk, N., & Thieme, A. </author> <year> (1992). </year> <title> Purposive Behavior and Cognitive Mapping: A Neural Network Model. </title> <journal> Biological Cybernetics, </journal> <volume> 67, </volume> <pages> 165-174. </pages>
Reference: <author> Scholkopf, B., & Mallot, H. </author> <year> (1995). </year> <title> View-Based Cognitive Mapping and Path Planning. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 3(3), </volume> <pages> 311-348. </pages>
Reference: <author> Schone, H. </author> <year> (1984). </year> <title> Spatial Orientation: </title> <booktitle> The Spatial Control of Behavior in Animals and Man. </booktitle> <address> Princeton, NJ: </address> <publisher> Princeton University Press. </publisher>
Reference: <author> Schuierer, S. </author> <year> (1997). </year> <title> Efficient Robot Self-Localization in Simple Polygons. </title> <booktitle> Pages 20-22 of: Proceedings of the 13th European Workshop on Computational Geometry. 266 Schwefel, </booktitle> <editor> H-P. (ed). </editor> <year> (1981). </year> <title> Numerical Optimization of Computer Models. </title> <address> Chichester, UK: </address> <publisher> John Wiley. </publisher> <editor> Schwefel, H-P. </editor> <year> (1987). </year> <title> Collective Phenomena in Evolutionary Systems. </title> <booktitle> Pages 1025-1033 of: Proceedings of 31st Annual Meeting of the International Society for General System Research. </booktitle>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1992). </year> <title> Adaptive 3D Object Recognition from Multiple Views. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14, </volume> <pages> 107-124. </pages>
Reference: <author> Shannon, C. </author> <year> (1952). </year> <title> Presentation of a Maze-Solving Machine. </title> <booktitle> In: Transactions of the 8th Cybernetics Conference. </booktitle>
Reference: <author> Sharp, P. </author> <year> (1991). </year> <title> Computer Simulations of Hippocampal Place Cells. </title> <journal> Psychobiology, </journal> <volume> 19, </volume> <pages> 103-115. </pages>
Reference-contexts: Remember that the EC layer cells encode vectors to specific landmarks. If some landmarks move or are removed from the environment, our spatial learning model cannot adapt to the changed sensory conditions. We have developed a simple extension (that uses a variation of the competitive Hebbian learning employed in <ref> (Sharp, 1991) </ref>), to adapt the representation of place in the CA3 layer based on the sensory inputs available in the EC layer. This extension allows the spatial learning system to cope with dynamic environments, in which objects move.
Reference: <author> Sharp, P. </author> <year> (1996). </year> <title> Multiple Spatial/Behavioral Correlates for Cells in the Rat Postsubiculum: Multiple Regression Analysis and Comparison to Other Hippocampal Areas. </title> <journal> Cerebral Cortex, </journal> <volume> 6, </volume> <pages> 238-259. </pages>
Reference-contexts: The subiculum receives input from the entorhinal cortex and projects to the pre and post-subiculum, the deep layers of the entorhinal cortex, and to the hypothalamus, septum, anterior thalamus and the cingulate cortex (Churchland & Sejnowski, 1992). Recently, place cells have also been discovered in the subiculum <ref> (Sharp, 1996) </ref>, although not much is known about them yet. There is also some evidence that the entorhinal cortex projects back to many of the 143 cortical association areas from which it receives input and mediates information storage there (Rolls, 1996). However, these mechanisms are not well understood. <p> firing have been found in almost every major region of the hippocampal system, including the entorhinal cortex (Quirk et al., 1992), the dentate gyrus (Jung & McNaughton, 1993), the hip-pocampus proper (O'Keefe & Dostrovsky, 1971; O'Keefe, 1976), the subiculum (Barnes et al., 1990; Sharp & Green, 1994), and the postsubiculum <ref> (Sharp, 1996) </ref>. In addition to place cells, head-direction cells have also been discovered in the hippocampal region. These cells appear to respond to particular directions of the animal's head, irrespective of its location in the environment.
Reference: <author> Sharp, P., & Green, C. </author> <year> (1994). </year> <title> Spatial Correlates of Firing Patterns of Single Cells in the Subiculum of the Freely Moving Rat. </title> <journal> Journal of Neuroscience, </journal> <volume> 14, </volume> <pages> 2339-2356. </pages>
Reference: <author> Sharp, P., Kubie, J., & Muller, R. </author> <year> (1990). </year> <title> Firing Properties of Hippocampal Neurons in a Visually Symmetrical Environment: Contributions of Multiple Sensory Cues and Mnemonic Properties. </title> <journal> Journal of Neuroscience, </journal> <volume> 10, </volume> <pages> 2339-2356. </pages>
Reference: <author> Sharp, P., Blair, H., & Brown, M. </author> <year> (1996). </year> <title> Neural Network Modeling of the Hippocampal Formation Spatial Signals and Their Possible Role in Navigation: A Modular Approach. </title> <journal> Hippocampus, </journal> <volume> 6, </volume> <pages> 720-734. </pages>
Reference-contexts: The subiculum receives input from the entorhinal cortex and projects to the pre and post-subiculum, the deep layers of the entorhinal cortex, and to the hypothalamus, septum, anterior thalamus and the cingulate cortex (Churchland & Sejnowski, 1992). Recently, place cells have also been discovered in the subiculum <ref> (Sharp, 1996) </ref>, although not much is known about them yet. There is also some evidence that the entorhinal cortex projects back to many of the 143 cortical association areas from which it receives input and mediates information storage there (Rolls, 1996). However, these mechanisms are not well understood. <p> firing have been found in almost every major region of the hippocampal system, including the entorhinal cortex (Quirk et al., 1992), the dentate gyrus (Jung & McNaughton, 1993), the hip-pocampus proper (O'Keefe & Dostrovsky, 1971; O'Keefe, 1976), the subiculum (Barnes et al., 1990; Sharp & Green, 1994), and the postsubiculum <ref> (Sharp, 1996) </ref>. In addition to place cells, head-direction cells have also been discovered in the hippocampal region. These cells appear to respond to particular directions of the animal's head, irrespective of its location in the environment.
Reference: <author> Simon, H. A. </author> <year> (1983). </year> <title> Why should machines learn? In: </title> <editor> Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (eds), </editor> <booktitle> Machine Learning AnArtificial Intelligence Approach. </booktitle> <address> Palo Alto, CA: </address> <publisher> Tioga. </publisher>
Reference: <author> Skaggs, W., & McNaughton, B. </author> <year> (1996). </year> <title> Replay of Neuronal Firing Sequence in Rat Hippocam-pus During Sleep Following Spatial Experience. </title> <journal> Science, </journal> <volume> 271, </volume> <pages> 1870-1873. </pages> <note> 267 Smith, </note> <author> R., Self, M., & Cheeseman, P. </author> <year> (1990). </year> <title> Estimating Uncertain Spatial Relationships in Robotics. </title> <editor> In: Cox, I., & Wilfong, G. (eds), </editor> <title> Autonomous Robot Vehicles. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Smythies, J. </author> <year> (1966). </year> <title> Brain Mechanisms and Behavior. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Squire, L. </author> <year> (1986). </year> <title> Mechanisms of Memory. </title> <journal> Science, </journal> <volume> 232, </volume> <pages> 1612-1619. </pages>
Reference-contexts: In general, memory refers to the persistence of acquired information, usually through learning, in a state that can be revealed at a later time <ref> (Squire, 1986) </ref>. Our discussions so far have focused on the role of the hippocampus in the realization of one form of memory, namely spatial memory. However, it has been proposed that the hippocampus is involved in a wide variety of other memory processes as well.
Reference: <author> Squire, L., Shimamura, A., & Amaral, D. </author> <year> (1989). </year> <title> Memory and the Hippocampus. Pages 208-239 of: Byrne, </title> <editor> J., & Berry, W. (eds), </editor> <title> Neural Models of Plasticity: Theoretical and Empirical Approaches. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference-contexts: As shown in Figure 7.1, these inputs arrive at a convergence area called the entorhinal cortex (EC), which itself is a part of a major convergence area called the parahippocampal cortical area <ref> (Squire et al., 1989) </ref>. The hippocampal formation is composed of the dentate gyrus (Dg), and areas CA3 and CA1 of Ammon's horn. The dentate gyrus contains granule cells that receive input from the entorhinal cortex via the perforant path, and output to the CA3 via the mossy fibers.
Reference: <editor> Steels, L., & Brooks, R. (eds). </editor> <year> (1995). </year> <title> The Artificial Life Route to Artificial Intelligence: Building Embodied, Situated Agents. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Earlbaum Associates. </publisher>
Reference: <author> Sutherland, R., Whishaw, I., & Kolb, B. </author> <year> (1982). </year> <title> A Behavioural Analysis of Spatial Localization Following Electrolytic, Kainate- or Colchicine-Induced Damage to the Hippocampal Formation in the Rat. </title> <journal> Behavioural Brain Research, </journal> <volume> 7, </volume> <pages> 133-153. </pages>
Reference: <author> Sutton, R., & Barto, A. </author> <year> (1998). </year> <title> Reinforcement Learning: An Introduction. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Culbertson suggested ways of designing artificial neural circuitry for generating non-deterministic behavior from deterministic neural components. Extensions of this idea are used in contemporary reinforcement learning systems <ref> (Sutton & Barto, 1998) </ref>, often applied to robot learning (Connell & Mahadevan, 1993a).
Reference: <author> Syswerda, G. </author> <year> (1989). </year> <title> Uniform Crossover in Genetic Algorithms. </title> <booktitle> In: Proceedings of the Third International Conference on Genetic Algorithms. </booktitle>
Reference-contexts: Our experiments made use of two genetic operators: crossover and mu 50 tation. We used uniform crossover with the probability of crossover set at 0.5. In uniform crossover each gene in the offspring has a uniform chance of coming from either of its parents <ref> (Syswerda, 1989) </ref>. This requires a random coin-toss at each of the gene positions to determine the parent the offspring inherits that particular gene from. Some commonly used crossover strategies are contrasted in Figure 3.5.
Reference: <author> Tanimoto, S. L. </author> <year> (1995). </year> <title> Elements of Artificial Intelligence Using Common Lisp. </title> <address> New York, NY: </address> <publisher> Computer Science Press. </publisher>
Reference: <author> Taube, J. </author> <year> (1995). </year> <title> Head-Direction Cells Recorded in the Anterior Thalamic Nuclei of Freely Moving Rats. </title> <journal> Journal of Neuroscience, </journal> <volume> 15, </volume> <pages> 70-86. </pages>
Reference: <author> Taube, J., Muller, R., & Ranck, J. </author> <year> (1990a). </year> <title> Head Direction Cells Recorded from the Post-subiculum in Freely Moving Rats: I. Description and Quantitative Analysis. </title> <journal> Journal of Neuroscience, </journal> <volume> 10, </volume> <pages> 420-435. </pages>
Reference: <author> Taube, J., Muller, R., & Ranck, J. </author> <year> (1990b). </year> <title> Head Direction Cells Recorded from the Post-subiculum in Freely Moving Rats: II. Effects of Environmental Manipulations. </title> <journal> Journal of Neuroscience, </journal> <volume> 10, </volume> <pages> 436-447. </pages> <note> 268 Teller, </note> <author> A. </author> <year> (1994). </year> <title> The Evolution of Mental Models. Pages 199-219 of: </title> <editor> Kinnear, Kim (ed), </editor> <booktitle> Advances in Genetic Programming. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Thorndike, E. </author> <title> (1898). Animal Intelligence: An Experimental Study of the Associative Processes in Animals. Psychological Monographs, </title> <publisher> 2,4. </publisher>
Reference: <author> Thrun, S. </author> <year> (1996). </year> <title> A Bayesian Approach to Landmark Discovery and Active Perception in Mobile Robot Navigation. </title> <type> Tech. </type> <institution> rept. CMU-CS-96-122. Carnegie Mellon University, </institution> <address> Pitts-burgh, PA. </address>
Reference: <author> Tolman, E. </author> <year> (1932). </year> <title> Purposive Behavior in Animals and Men. </title> <address> New York, NY: </address> <publisher> Irvington Publishers. </publisher>
Reference: <author> Tolman, E. </author> <year> (1948). </year> <title> Cognitive Maps in Rats and Men. </title> <journal> Psychological Review, </journal> <volume> 55, </volume> <pages> 189-208. </pages>
Reference-contexts: The proposed model is a computational realization of the cognitive-mapping theory of <ref> (Tolman, 1948) </ref> who suggested that animals learn a metric representation of space, and is based on the thesis of (O'Keefe & Nadel, 1978) who suggested that the hip-pocampal formation (a part of the brain) is involved in the formation of such cognitive maps. <p> With such Thorndikian learning spatial navigation is then simply a matter of recognizing the place (given by sensory stimuli S) and performing the associated response R. 6.4.1.1 Cognitive Maps of Tolman Based on extensive experiments with rodents Tolman concluded that animals demonstrate abilities for detour behaviors and latent learning <ref> (Tolman, 1948) </ref>. He pointed out that Thorndikian framework of spatial learning falls short of explaining these behaviors in rodents. For instance, Thorndikian spatial learning requires a reinforcement at the goal location in order to learn the S-R associations. <p> Tolman developed an alternate view of spatial representation and suggested that animals learn expectancies of the form S 1 RS 2 which captures the transformation of stimuli based on responses <ref> (Tolman, 1948) </ref>. Unlike Thorndikian learning, Tolman argued that rewards are not necessary for learning these associations, which are simply learned based on temporal contiguity. <p> Further, Tolman proposed the existence of an inference process that could combine and collate a large number of these expectancies into a semantic structure which he called a cognitive 136 map <ref> (Tolman, 1948) </ref>. Since Tolman's thesis was that learning of space progresses devoid of rewards, the cognitive map theory implicitly supports latent learning. Further, it is clear from the structure of these expectancies that the animals not only associate responses with stimuli but also learn the effect of responses on stimuli. <p> In their purest form, these approaches provide one realization of Tolman's S 1 R S 2 expectancies discussed earlier, thereby providing one implementation of his cognitive map idea <ref> (Tolman, 1948) </ref>. These schemes allow for latent learning, demonstrating an ability to learn topological place maps in the absence of explicit goals. Once such relationships have been captured, goal-directed navigation reduces to determining a path from the current place to the place that houses the goal.
Reference: <author> Tolman, E., & Honzik, C. </author> <year> (1930). </year> <note> "Insight" in Rats. </note> <institution> University of California Publications in Psychology, </institution> <month> 4(14), </month> <pages> 215-232. </pages>
Reference: <author> Tolman, E., Ritchie, B., & Kalish, D. </author> <year> (1946). </year> <title> Studies in Spatial Learning. I. Orientation and the Short-Cut. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 36, </volume> <pages> 13-24. </pages>
Reference: <author> Traub, R., & Miles, R. </author> <year> (1991). </year> <title> Neuronal Networks of the Hippocampus. </title> <address> New York, NY: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: has led researchers to suggest that the dentate gyrus provides a context (Rolls, 1990) or reference frame (O'Keefe, 1989) for spatio-temporal associations in the CA3. 142 The CA3 region of the hippocampus primarily contains pyramidal (or complex-spike) cells along with inhibitory interneurons like basket cells, chandelier cells, and mossy cells <ref> (Traub & Miles, 1991) </ref>. These CA3 cells receive inputs from the entorhinal cortex through the perforant path, the dentate gyrus via mossy fibers, and recurrent inputs from other CA3 pyramidals.
Reference: <author> Treves, A., & Rolls, E. </author> <year> (1991). </year> <title> What Determines the Capacity of Autoassociative Memories in the Brain? Network, </title> <booktitle> 2, </booktitle> <pages> 371-397. </pages>
Reference: <author> Treves, A., & Rolls, E. </author> <year> (1992). </year> <title> Computational Constraints Suggest the Need for Two Distinct Input Systems to the Hippocampal CA3 Network. </title> <journal> Hippocampus, </journal> <volume> 2, </volume> <pages> 189-199. </pages>
Reference: <author> Treves, A., & Rolls, E. </author> <year> (1994). </year> <title> A Computational Analysis of the Role of the Hippocampus in Memory. </title> <journal> Hippocampus, </journal> <volume> 4, </volume> <pages> 374-391. </pages>
Reference: <author> Trullier, O., Wiener, S., Berthoz, A., & Meyer, J-A. </author> <year> (1997). </year> <title> Biologically-based Artificial Navigation Systems: Review and Prospects. </title> <booktitle> Progress in Neurobiology, </booktitle> <volume> 51, </volume> <pages> 483-544. </pages>
Reference: <author> Tsuji, S., & Li, S. </author> <year> (1993). </year> <title> Memorizing and Representing Route Scenes. </title> <booktitle> In: Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <volume> 269 Uhr, </volume> <editor> L., & Honavar, V. </editor> <year> (1994). </year> <title> Introduction. </title> <editor> In: Honavar, V., & Uhr, L. (eds), </editor> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Usually, distinctive places are characterized using sonar signatures (Kuipers & Byun, 1991; Mataric, 1992; Kortenkamp, 1993), image signatures (Kortenkamp, 1993; Kortenkamp & Weymouth, 1994; Engelson, 1994), panoramic views <ref> (Tsuji & Li, 1993) </ref>, local occupancy grids (Langley & Pfleger, 1995; Yamauchi & Langley, 1997), etc., depending on the kinds of sensors the corresponding robots possess.
Reference: <author> Valavanis, K., & Saridis, G. </author> <year> (1992). </year> <title> Intelligent Robotic Systems: Theory, Design, and Applications. </title> <address> New York: </address> <publisher> Kluwer Academic. </publisher>
Reference: <author> Vinogradova, O. </author> <year> (1975). </year> <title> Functional Organization of the Limbic System in the Process of Registration of Information: Facts and Hypothesis. Pages 3-69 of: Isaacson, </title> <editor> R., & Pribram, K. (eds), </editor> <booktitle> The Hippocampus. </booktitle> <address> New York, NY: </address> <publisher> Plenum Press. </publisher> <editor> von Neumann, J. </editor> <year> (1956). </year> <title> Probabilistic Logics and the Synthesis of Reliable Organisms from Unreliable Components. Pages 43-98 of: </title> <editor> Shannon, C., & McCarthy, J. (eds), </editor> <booktitle> Automata Studies. </booktitle> <address> Princeton, NJ: </address> <publisher> Princeton University Press. </publisher> <editor> von Neumann, J., & Morgenstern, O. </editor> <year> (1944). </year> <title> Theory of Games and Economic Behavior. </title> <publisher> Princeton, </publisher> <address> NJ: </address> <publisher> Princeton University Press. </publisher>
Reference: <author> Walker, J. </author> <year> (1995). </year> <title> Evolution of Simple Virtual Robots Using Genetic Algorithms. M.Phil. </title> <type> thesis, </type> <institution> Department of Mechanical Engineering, Iowa State University, Ames, IA. </institution>
Reference: <author> Walter, W. </author> <year> (1950). </year> <title> An Imitation of Life. </title> <journal> Scientific American, </journal> <volume> 182(5), </volume> <pages> 42-45. </pages>
Reference: <author> Walter, W. </author> <year> (1951). </year> <title> A Machine That Learns. </title> <journal> Scientific American, </journal> <volume> 185(2), </volume> <pages> 60-63. </pages>
Reference: <author> Wan, H., Touretzky, D., & Redish, A. </author> <year> (1994). </year> <title> Towards a Computational Theory of Rat Navigation. </title> <booktitle> Pages 11-19 of: Proceedings of the 1993 Connectionist Models Summer School. </booktitle>
Reference: <author> Wilson, M., & McNaughton, B. </author> <year> (1993). </year> <title> Dynamics of the Hippocampal Ensemble Code for Space. </title> <journal> Science, </journal> <volume> 261, </volume> <pages> 1055-1058. </pages>
Reference-contexts: Further, places appear to be represented in the hippocampus using an ensemble code, i.e., a set of place cells appear to code for a place <ref> (Wilson & McNaughton, 1993) </ref>. Experiments have also revealed that when the animal is introduced into a familiar environment, place fields are initialized based on visual cues and landmarks in the environment (Muller & Kubie, 1987; Muller et al., 1987; Sharp et al., 1990). <p> To keep the discussion simple we will henceforth assume that place codes in CA3 and CA1 are represented by single units, although in reality ensembles of units are known to code for place <ref> (Wilson & McNaughton, 1993) </ref>.
Reference: <author> Winston, P. </author> <year> (1992). </year> <booktitle> Artificial Intelligence. </booktitle> <address> New York, NY: </address> <publisher> Addison Wesley. </publisher>
Reference: <author> Wooldridge, M., & Jennings, N. </author> <year> (1995). </year> <title> Intelligent Agents: </title> <journal> Theory and Practice. Knowledge Engineering Review, </journal> <volume> 10(2), </volume> <pages> 115-152. </pages>
Reference: <author> Worden, R. </author> <year> (1992). </year> <title> Navigation by Fragment Fitting: A Theory of Hippocampal Function. </title> <journal> Hippocampus, </journal> <volume> 2(2), </volume> <pages> 165-188. </pages> <note> 270 Yamauchi, </note> <author> B., & Beer, R. </author> <year> (1994). </year> <title> Integrating Reactive, Sequential, and Learning Behavior Using Dynamical Neural Networks. </title> <booktitle> In: From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior. </booktitle>
Reference: <author> Yamauchi, B., & Beer, R. </author> <year> (1996). </year> <title> Spatial Learning for Navigation in Dynamic Environments. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics Part B, Special Issue on Robot Learning, </journal> <volume> 26. </volume>
Reference-contexts: Thus, it does not require a sensor-model which is often difficult to specify in conventional Kalman filtering (see Section 8.2.1). Finally, unlike pure sensor-based systems, the model allows the robot to disambiguate between perceptually similar places, and unlike pure dead-reckoning based systems <ref> (Yamauchi & Beer, 1996) </ref>, it can relocalize after being kidnapped. Although we have not shown any results to that effect in this chapter, goal-directed navigation can be easily realized in our system.
Reference: <author> Yamauchi, B., & Langley, P. </author> <year> (1997). </year> <title> Place recognition in Dynamic Environments. </title> <journal> Journal of Robotic Systems, Special Issue on Mobile Robots, </journal> <volume> 14(2), </volume> <pages> 107-120. </pages>
Reference: <author> Yang, J., & Honavar, V. </author> <year> (1998). </year> <title> Feature Subset Selection Using a Genetic Algorithm. </title> <editor> In: Motoda, & Liu (eds), </editor> <title> Feature Extraction, Construction and Selection A Data Mining Perspective. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic. </publisher>
Reference-contexts: This is reminiscent of the feature-subset selection problem often encountered in the data-mining community, where the goal is to discard redundant, uninformative, or useless features (inputs, variables, attributes, etc.) and choose a subset of them for analysis <ref> (Yang & Honavar, 1998) </ref>. 5. Evolution is also capable of discovering robust and noise-tolerant designs. <p> In our case, the robot is allowed to use many sensors, but the evolutionary design system chooses to use just a few that somehow translate into performance gains on the box-pushing task. Thus, evolutionary approaches are attractive options for the feature selection problem, as has also been demonstrated by <ref> (Yang & Honavar, 1998) </ref>. 4.3 Role of Noise Noise plays a very important role in robotics research largely because of the noise inherent in real-world environments and robot components.
Reference: <author> Yang, J., Parekh, R., & Honavar, V. </author> <year> (1998). </year> <title> DistAl: An Inter-Pattern Distance-Based Constructive Learning Algorithm. Intelligent Data Analysis. </title> <note> (To appear). </note>
Reference-contexts: This is reminiscent of the feature-subset selection problem often encountered in the data-mining community, where the goal is to discard redundant, uninformative, or useless features (inputs, variables, attributes, etc.) and choose a subset of them for analysis <ref> (Yang & Honavar, 1998) </ref>. 5. Evolution is also capable of discovering robust and noise-tolerant designs. <p> In our case, the robot is allowed to use many sensors, but the evolutionary design system chooses to use just a few that somehow translate into performance gains on the box-pushing task. Thus, evolutionary approaches are attractive options for the feature selection problem, as has also been demonstrated by <ref> (Yang & Honavar, 1998) </ref>. 4.3 Role of Noise Noise plays a very important role in robotics research largely because of the noise inherent in real-world environments and robot components.
Reference: <editor> Zalzala, A., & Morris, A. (eds). </editor> <year> (1996). </year> <title> Neural Networks for Robotic Control: Theory and Applications. </title> <address> New York, NY: </address> <publisher> Ellis Horwood. </publisher>
Reference: <author> Zipser, D. </author> <year> (1986). </year> <title> Biologically Plausible Models of Place Recognition and Place Location. </title>
Reference-contexts: Since these approaches only require recognition of a place, the animat's response can be determined quickly and such behaviors are presumably fast to execute. For instance, Zipser proposed a neural model in which each place cell was tuned to the distance, bearing, and identities of three landmarks <ref> (Zipser, 1986) </ref>. Place cells were also associated with a goal cell, which encoded a vector to the goal location from that place. Incoming sensory inputs activated appropriate place cells, signaling recognition of the current place.
Reference: <editor> Pages 432-470 of: Rumelhart, D., McClelland, J., </editor> & <booktitle> the PDP Research Group (eds), Parallel Distributed Processing: Explorations in the Micro-Structure of Cognition, Volume 2. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
References-found: 257

