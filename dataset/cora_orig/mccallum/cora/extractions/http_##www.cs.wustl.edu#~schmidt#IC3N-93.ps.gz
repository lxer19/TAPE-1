URL: http://www.cs.wustl.edu/~schmidt/IC3N-93.ps.gz
Refering-URL: http://www.cs.wustl.edu/~schmidt/resume.html
Root-URL: 
Email: schmidt@ics.uci.edu and suda@ics.uci.edu  
Title: ADAPTIVE A Framework for Experimenting with High-Performance Transport System Process Architectures  
Author: Douglas C. Schmidt and Tatsuya Suda 
Address: Irvine, California 92717  
Affiliation: Department of Information and Computer Science University of California,  
Abstract: An earlier version of this paper appeared in the proceedings of the second International Conference on Computer Communication Networks in San Diego, California, June 1993. Abstract Recent advances in VLSI and fiber optic technology are shifting application performance bottlenecks from the underlying networks to the transport system and higher-layer communication protocols. Developing process architectures that effectively utilize multi-processing is one promising technique for alleviating these performance bottlenecks. This paper describes a flexible framework called ADAPTIVE that supports the development of, and experimentation with, process architectures for multi-processor platforms. ADAPTIVE provides a modular, object-oriented framework that generates application-tailored protocol configurations and maps these configurations onto suitable process architectures that satisfy multimedia application performance requirements on high-speed networks. This paper describes several alternative process architectures and outlines the techniques used in ADAPTIVE to support controlled experimentation with these alternatives. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. D. Clark, </author> <title> Modularity and Efficiency in Protocol Implementation, Network Information Center RFC 817, </title> <journal> pp. </journal> <volume> 126, </volume> <month> July </month> <year> 1982. </year>
Reference-contexts: Application performance is significantly affected by the process architecture of the transport system <ref> [1, 2, 3] </ref>. A process architecture binds certain communication protocol en tities (such as layers, tasks, connections, and/or messages) together with logical and/or physical processing elements. This paper describes a flexible framework called ADAPTIVE that supports, among other things, development and controlled experimentation with alternative process architectures. <p> A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds.
Reference: [2] <author> J. Jain, M. Schwartz, and T. Bashkow, </author> <title> Transport Protocol Processing at GBPS Rates, </title> <booktitle> in Proceedings of the Symposium on Communications Architectures and Protocols (SIG-COMM), </booktitle> <address> (Philadelphia, PA), </address> <pages> pp. 188199, </pages> <publisher> ACM, </publisher> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Application performance is significantly affected by the process architecture of the transport system <ref> [1, 2, 3] </ref>. A process architecture binds certain communication protocol en tities (such as layers, tasks, connections, and/or messages) together with logical and/or physical processing elements. This paper describes a flexible framework called ADAPTIVE that supports, among other things, development and controlled experimentation with alternative process architectures. <p> The ADAPTIVE framework also facilitates experimentation with the various process architecture alternatives. Several studies have compared the advantages and disadvantages of these process architectures via qualitative analysis <ref> [2, 12] </ref>. However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches [7, 9, 13, 14]. <p> between separate PEs, (2) load balancing is difficult, and (3) non-standard, de-layered communication models are typically required to increase the number of tasks available for parallel execution [10, 16]. 4.2 Vertical Process Architectures Vertical process architectures associate OS processes with connections and messages rather than with protocol layers or tasks <ref> [2, 7] </ref>. This approach assigns a separate process to escort incoming and outgoing messages through the protocol stack, delivering messages down to network interfaces or up to applications.
Reference: [3] <author> G. Chesson, </author> <title> XTP/PE Design Considerations, </title> <booktitle> in Proceedings of the 1st International Workshop on High-Speed Networks, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: Application performance is significantly affected by the process architecture of the transport system <ref> [1, 2, 3] </ref>. A process architecture binds certain communication protocol en tities (such as layers, tasks, connections, and/or messages) together with logical and/or physical processing elements. This paper describes a flexible framework called ADAPTIVE that supports, among other things, development and controlled experimentation with alternative process architectures. <p> A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds.
Reference: [4] <author> D. D. Clark, V. Jacobson, J. Romkey, and H. Salwen, </author> <title> An Analysis of TCP Processing Overhead, </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 27, </volume> <pages> pp. 2329, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: factors including (1) process management (such as context switching, synchronization, and scheduling overhead), (2) message management (such as memory-to-memory copying and dynamic buffer allocation), (3) multiplexing and demultiplexing, (4) protocol processing tasks (such as checksumming, segmentation, reassembly, retransmission timer, flow control, connection management, and routing), and (5) network interface hardware <ref> [4, 5] </ref>. A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead [1, 3, 5, 6, 7, 8].
Reference: [5] <author> D. D. Clark and D. L. Tennenhouse, </author> <title> Architectural Considerations for a New Generation of Protocols, </title> <booktitle> in Proceedings of the Symposium on Communications Architectures and Protocols (SIGCOMM), </booktitle> <address> (Philadelphia, PA), </address> <pages> pp. </pages> <address> 200208, </address> <publisher> ACM, </publisher> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: factors including (1) process management (such as context switching, synchronization, and scheduling overhead), (2) message management (such as memory-to-memory copying and dynamic buffer allocation), (3) multiplexing and demultiplexing, (4) protocol processing tasks (such as checksumming, segmentation, reassembly, retransmission timer, flow control, connection management, and routing), and (5) network interface hardware <ref> [4, 5] </ref>. A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead [1, 3, 5, 6, 7, 8]. <p> A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds.
Reference: [6] <author> R. W. Watson and S. A. Mamrak, </author> <title> Gaining Efficiency in Transport Services by Appropriate Design and Implementation Choices, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 5, </volume> <pages> pp. 97120, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds.
Reference: [7] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> The x-kernel: An Architecture for Implementing Network Protocols, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 17, </volume> <pages> pp. 6476, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds. <p> However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches <ref> [7, 9, 13, 14] </ref>. Moreover, these empirical studies typically do not control for critical confounding factors such as hardware platform, operating system, and protocol implementation. By not controlling for these factors, it is difficult to isolate and accurately assess the performance impacts of a particular process architecture. <p> between separate PEs, (2) load balancing is difficult, and (3) non-standard, de-layered communication models are typically required to increase the number of tasks available for parallel execution [10, 16]. 4.2 Vertical Process Architectures Vertical process architectures associate OS processes with connections and messages rather than with protocol layers or tasks <ref> [2, 7] </ref>. This approach assigns a separate process to escort incoming and outgoing messages through the protocol stack, delivering messages down to network interfaces or up to applications.
Reference: [8] <author> T. F. L. Porta and M. Schwartz, </author> <title> Architectures, Features, and Implementation of High-Speed Transport Protocols, </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 1422, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: A number of empirical studies have demonstrated that process management and message management are responsible for a significant percentage of the total transport system performance overhead <ref> [1, 3, 5, 6, 7, 8] </ref>. In general, these sources of transport system overhead have become a 1 throughput preservation problem as VLSI and fiber optic technologies continually increase network channel speeds.
Reference: [9] <author> M. Zitterbart, </author> <title> High-Speed Transport Components, </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 5463, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: In particular, the bandwidth available from high-speed networks is often reduced by an order of magnitude by the time it is actually delivered to applications <ref> [9] </ref>. Furthermore, this problem persists despite an increase in computer CPU speeds and memory bandwidth [10]. <p> However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches <ref> [7, 9, 13, 14] </ref>. Moreover, these empirical studies typically do not control for critical confounding factors such as hardware platform, operating system, and protocol implementation. By not controlling for these factors, it is difficult to isolate and accurately assess the performance impacts of a particular process architecture. <p> This approach utilizes multiple PEs to perform many protocol processing tasks in parallel via a pipeline <ref> [9] </ref>. Common protocol tasks include (1) connection management (e.g., connection establishment and termination), (2) header composition and decomposition (e.g., address resolution and demultiplexing), (3) PDU-level and bit-level error protection (e.g., detecting, reporting, and retransmitting out-of-sequence PDUs and computing checksums), (4) segmentation and reassembly, (5) routing, and (6) flow control.
Reference: [10] <author> Z. Haas, </author> <title> A Protocol Structure for High-Speed Communication Over Broadband ISDN, </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 6470, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: In particular, the bandwidth available from high-speed networks is often reduced by an order of magnitude by the time it is actually delivered to applications [9]. Furthermore, this problem persists despite an increase in computer CPU speeds and memory bandwidth <ref> [10] </ref>. <p> These services manage the layer-to-layer tasks (such as message management, multiplexing and demultiplexing, and layer-to-layer flow control) that exchange PDUs between the protocol layers (and transport system boundaries) on a local host. In addition, protocol family architecture services also supports de-layered communication models (such as those described in <ref> [10, 16, 17] </ref>). In this case, the protocol family architecture services operate between the application interface, de-layered transport system, and network interface. Applications, session architecture services, and protocol family architecture services all execute within a process environment provided by services in the kernel architecture. <p> However, the disadvantages are that (1) careful programming is required to minimize the memory contention and synchronization overhead resulting from the communication between separate PEs, (2) load balancing is difficult, and (3) non-standard, de-layered communication models are typically required to increase the number of tasks available for parallel execution <ref> [10, 16] </ref>. 4.2 Vertical Process Architectures Vertical process architectures associate OS processes with connections and messages rather than with protocol layers or tasks [2, 7].
Reference: [11] <author> P. Druschel, M. B. Abbott, M. Pagels, and L. L. Peterson, </author> <title> Network subsystem design, </title> <journal> IEEE Network (Special Issue on End-System Support for High Speed Networks), </journal> <volume> vol. 7, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: channel speeds have increased by 5 or 6 orders of magnitude (from kbps to Gbps), whereas CPU speeds and memory bandwidth have increased by 2 or 3 orders of magnitude (from 1 MIP up to 100 MIPS for CPUs and 100ns down to 10ns access times for high-speed cache memory) <ref> [11] </ref>. Developing process architectures that effectively utilize multi-processing is a promising technique for alleviating the throughput preservation problem. However, designing and implementing transport systems that utilize parallelism efficiently is a complex, challenging task.
Reference: [12] <author> D. C. Schmidt and T. Suda, </author> <title> Transport System Architecture Services for High-Performance Communications Systems, </title> <journal> IEEE Journal on Selected Areas in Communication, </journal> <volume> vol. 11, </volume> <pages> pp. 489506, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The ADAPTIVE framework also facilitates experimentation with the various process architecture alternatives. Several studies have compared the advantages and disadvantages of these process architectures via qualitative analysis <ref> [2, 12] </ref>. However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches [7, 9, 13, 14]. <p> This section outlines the distinguishing features of four process architectures supported by ADAPTIVE. These process architectures fall into three general categories: horizontal, vertical, and hybrid <ref> [12] </ref>. Although each process architecture has different structural and performance characteristics, it is possible to implement the same protocol family functionality (such as the OSI, TCP/IP, and F-CSS [16]) with any approach. 4.1 Horizontal Process Architectures Horizontal process architectures associate PEs with protocol layers or protocol tasks.
Reference: [13] <author> T. L. Porta and M. Schwartz, </author> <title> Performance Analysis of MSP: a Feature-Rich High-Speed Transport Protocol, </title> <booktitle> in Proceedings of the Conference on Computer Communications (INFO-COM), </booktitle> <address> (San Francisco, California), </address> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches <ref> [7, 9, 13, 14] </ref>. Moreover, these empirical studies typically do not control for critical confounding factors such as hardware platform, operating system, and protocol implementation. By not controlling for these factors, it is difficult to isolate and accurately assess the performance impacts of a particular process architecture.
Reference: [14] <author> Mats Bjorkman and Per Gunningberg, </author> <title> Locking Strategies in Multiprocessor Implementations of Protocols, </title> <booktitle> in Proceedings of the Symposium on Communications Architectures and Protocols (SIGCOMM), </booktitle> <address> (San Francisco, California), </address> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: However, few studies have quantitatively compared the performance of the alternative process architectures via controlled, empirical experimentation. In particular, existing research that measures the performance of process architectures focuses on only one or two approaches <ref> [7, 9, 13, 14] </ref>. Moreover, these empirical studies typically do not control for critical confounding factors such as hardware platform, operating system, and protocol implementation. By not controlling for these factors, it is difficult to isolate and accurately assess the performance impacts of a particular process architecture.
Reference: [15] <author> D. C. Schmidt, D. F. Box, and T. Suda, </author> <title> ADAPTIVE: A Dynamically Assembled Protocol Transformation, Integration, and eValuation Environment, </title> <journal> Journal of Concurrency: Practice and Experience, </journal> <volume> vol. 5, </volume> <pages> pp. 269286, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: To enhance performance, the generated protocols may execute in parallel on several target platforms such as shared memory and message-passing multi-processors. This paper focuses primarily on ADAPTIVE's process architecture support; other aspects of ADAPTIVE are described in <ref> [15] </ref>. in ADAPTIVE's architecture. Multimedia applications that generate and receive various types of synchronized and independent traffic (such as voice, video, text, and image) access ADAPTIVE's services via an interface between the transport system and the end-user applications.
Reference: [16] <author> M. Zitterbart, B. Stiller, and A. Tantawy, </author> <title> A Model for High-Performance Communication Subsystems, </title> <journal> IEEE Journal on Selected Areas in Communication, </journal> <volume> vol. 11, </volume> <pages> pp. 507519, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: These services manage the layer-to-layer tasks (such as message management, multiplexing and demultiplexing, and layer-to-layer flow control) that exchange PDUs between the protocol layers (and transport system boundaries) on a local host. In addition, protocol family architecture services also supports de-layered communication models (such as those described in <ref> [10, 16, 17] </ref>). In this case, the protocol family architecture services operate between the application interface, de-layered transport system, and network interface. Applications, session architecture services, and protocol family architecture services all execute within a process environment provided by services in the kernel architecture. <p> These process architectures fall into three general categories: horizontal, vertical, and hybrid [12]. Although each process architecture has different structural and performance characteristics, it is possible to implement the same protocol family functionality (such as the OSI, TCP/IP, and F-CSS <ref> [16] </ref>) with any approach. 4.1 Horizontal Process Architectures Horizontal process architectures associate PEs with protocol layers or protocol tasks. Each PE performs certain protocol operations on PDUs that are then exchanged with neighboring PEs. <p> The primary advantages of this approach are (1) the potential performance improvements from using multiple PEs and (2) the ability to substitute alternative mechanisms for certain protocol tasks <ref> [16] </ref>. <p> However, the disadvantages are that (1) careful programming is required to minimize the memory contention and synchronization overhead resulting from the communication between separate PEs, (2) load balancing is difficult, and (3) non-standard, de-layered communication models are typically required to increase the number of tasks available for parallel execution <ref> [10, 16] </ref>. 4.2 Vertical Process Architectures Vertical process architectures associate OS processes with connections and messages rather than with protocol layers or tasks [2, 7].
Reference: [17] <author> D. C. Schmidt, B. Stiller, T. Suda, A. Tantawy, and M. Zit-terbart, </author> <title> Language Support for Flexible, Application-Tailored Protocol Configuration, </title> <booktitle> in Proceedings of the 18 th Conference on Local Computer Networks, (Minneapolis, Min-nesota), </booktitle> <pages> pp. 369378, </pages> <publisher> IEEE, </publisher> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: These services manage the layer-to-layer tasks (such as message management, multiplexing and demultiplexing, and layer-to-layer flow control) that exchange PDUs between the protocol layers (and transport system boundaries) on a local host. In addition, protocol family architecture services also supports de-layered communication models (such as those described in <ref> [10, 16, 17] </ref>). In this case, the protocol family architecture services operate between the application interface, de-layered transport system, and network interface. Applications, session architecture services, and protocol family architecture services all execute within a process environment provided by services in the kernel architecture.
Reference: [18] <author> D. Ritchie, </author> <title> A Stream InputOutput System, </title> <journal> AT&T Bell Labs Technical Journal, </journal> <volume> vol. 63, </volume> <pages> pp. 311324, </pages> <month> Oct. </month> <year> 1984. </year>
Reference-contexts: ADAPTIVE's modularity also increases its portability, allowing it to run in multiple underlying kernel architectures (such as UNIX, Mach, and transputer platforms) and protocol family architectures (such as STREAMS and x-kernel). This paper focuses primarily on a version of ADAPTIVE that is hosted the UNIX STREAMS environment <ref> [18] </ref>. An alternative approach that describes hosting ADAPTIVE in the x-kernel is presented in [19]. 4 Process Architecture Models To address the throughput preservation problem, ADAPTIVE provides a flexible framework for developing and experimenting with alternative process architectures. <p> This enables protocol machines to adapt dynamically to changes in application requirements, transport sys tem resources, and network characteristics [26]. 5.2 Process Architecture Components This section focuses on techniques for implementing ADAPTIVE's process architecture framework within the protocol family architecture and kernel architecture provided by STREAMS <ref> [18] </ref>. To avoid extraneous development effort, ADAPTIVE is initially being hosted in several existing operating environments including STREAMS in UNIX. The generation and execution components described in Section 5.1 utilize various STREAMS features and capabilities. <p> The remainder of this section briefly summarizes the primary components in STREAMS and explains how the ADAPTIVE components described in Section 5.1 are implemented by the STREAMS components. 5.2.1 Overview of STREAMS STREAMS provides ADAPTIVE with modular protocol family and kernel architectures that possess components with uniform interfaces <ref> [18] </ref>. As shown in Figure 5, STREAMS components include STREAM heads, STREAM modules, STREAM multiplexors, and STREAM drivers. STREAM heads provide a queueing point that segments and reassem-bles application data into discrete messages.
Reference: [19] <author> D. C. Schmidt, </author> <title> Hosting the ADAPTIVE System in the x-Kernel and System V STREAMS, </title> <booktitle> in Proceedings of the x-kernel Workshop, </booktitle> <address> (Tucson, Arizona), </address> <month> November </month> <year> 1992. </year>
Reference-contexts: This paper focuses primarily on a version of ADAPTIVE that is hosted the UNIX STREAMS environment [18]. An alternative approach that describes hosting ADAPTIVE in the x-kernel is presented in <ref> [19] </ref>. 4 Process Architecture Models To address the throughput preservation problem, ADAPTIVE provides a flexible framework for developing and experimenting with alternative process architectures. A process architecture binds communication protocol entities to logical and/or physical processing elements (PE). Protocol entities include abstractions such as layers, tasks, connections, and/or messages.
Reference: [20] <author> J. Eykholt, S. Kleiman, S. Barton, R. Faulkner, A. Shivalin-giah, M. Smith, D. Stein, J. Voll, M. Weeks, and D. Williams, </author> <title> Beyond Multiprocessing... Multithreading the SunOS Kernel, </title> <booktitle> in Proceedings of the Summer USENIX Conference, </booktitle> <address> (San Antonio, Texas), </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Messages flow through the layers in a coarse-grain pipelined manner. Inter-layer buffering, flow control, and 1 The term process is used in this paper to refer to a thread of control executing within an address space. Other systems use different terminology (such as lightweight processes <ref> [20] </ref> or threads [21]) to denote essentially the same concept. 3 stage balancing [22] are typically necessary since the processing activities at each layer may not execute at the same rate. <p> Recent implementations of STREAMS <ref> [20] </ref> utilize shared memory multi-processors and support various types of parallelism, ranging from fine-grain parallelism controlled by explicit use of kernel synchronization primitives to various synchronization models that are supported automatically by the STREAMS framework. <p> We are currently designing and implementing a prototype implementation of ADAPTIVE written in C++. To experiment with alternative process architectures, this prototype is hosted in the STREAMS framework on a multi-processor 8 UNIX platform <ref> [20] </ref>. The multi-processing framework of STREAMS in UNIX provides the basis for developing a number of different process architectures and determining the impact on application and transport system performance in a controlled manner.
Reference: [21] <author> A. Tevanian, R. Rashid, D. Golub, D. Black, E. Cooper, and M. Young, </author> <title> Mach Threads and the Unix Kernel: The Battle for Control, </title> <booktitle> in Proceedings of the USENIX Summer Conference, USENIX Association, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Messages flow through the layers in a coarse-grain pipelined manner. Inter-layer buffering, flow control, and 1 The term process is used in this paper to refer to a thread of control executing within an address space. Other systems use different terminology (such as lightweight processes [20] or threads <ref> [21] </ref>) to denote essentially the same concept. 3 stage balancing [22] are typically necessary since the processing activities at each layer may not execute at the same rate. The primary advantage of Layer Parallelism is the simplicity of its design, which corresponds closely to standard layered communication architecture specifications [23].
Reference: [22] <author> O. Koufopavlou, A. N. Tantawy, and M. Zitterbart, </author> <title> Analysis of TCP/IP for High Performance Parallel Implementations, </title> <booktitle> in 17th Conference on Local Computer Networks, </booktitle> <address> (Minneapo-lis, Minnesota), </address> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Inter-layer buffering, flow control, and 1 The term process is used in this paper to refer to a thread of control executing within an address space. Other systems use different terminology (such as lightweight processes [20] or threads [21]) to denote essentially the same concept. 3 stage balancing <ref> [22] </ref> are typically necessary since the processing activities at each layer may not execute at the same rate. The primary advantage of Layer Parallelism is the simplicity of its design, which corresponds closely to standard layered communication architecture specifications [23]. <p> Note that there are hybrid approaches that combine horizontal and vertical process architectures. For instance, it is possible to assign multiple PEs to each connection, thereby combining Task Parallelism and Connectional Parallelism <ref> [22] </ref>. <p> However, careful programming and stage balancing may be required to efficiently coordinate and minimize the overhead of managing the multiple communicating processes <ref> [22] </ref>. As with the Connectional Parallelism example, it is possible to modify these protocol machines to utilize a more coarse-grain Layer Parallelism process architecture.
Reference: [23] <author> M. S. Atkins, </author> <title> Experiments in SR with Different Upcall Program Structures, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 6, </volume> <pages> pp. 365392, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: The primary advantage of Layer Parallelism is the simplicity of its design, which corresponds closely to standard layered communication architecture specifications <ref> [23] </ref>. In addition, it is also suitable for systems that possess a limited number of PEs.
Reference: [24] <author> D. D. Clark, </author> <title> The Structuring of Systems Using Upcalls, </title> <booktitle> in Proceedings of the 10 th Symposium on Operating System Principles, (Shark Is., </booktitle> <address> WA), </address> <year> 1985. </year>
Reference-contexts: The advantages of Connectional Parallelism are (1) inter-layer communication overhead is reduced (since moving between protocol layers may not require a context switch), (2) synchronization and communication overhead is relatively low within a given connection (since synchronous intra-process subroutine calls and upcalls <ref> [24] </ref> may be used to communicate between the protocol layers), and (3) the amount of available parallelism is determined dynamically (rather than statically) since it is a function of the number of active con 4 nections rather than the number of layers or tasks.
Reference: [25] <author> J. C. Mogul, R. F. Rashid, and M. J. Accetta, </author> <title> The Packet Filter: an Efficient Mechanism for User-level Network Code, </title> <booktitle> in Proceedings of the 11 th Symposium on Operating System Principles (SOSP), </booktitle> <month> November </month> <year> 1987. </year>
Reference-contexts: For instance, it is possible to assign multiple PEs to each connection, thereby combining Task Parallelism and Connectional Parallelism [22]. This composite approach requires a large number of PEs, special contention-free memory, and careful programming to significantly improve performance, however. 2 Packet filters <ref> [25] </ref> are devices that allow applications and higher-level protocols to program the network interface so that particular types of incoming PDUs are demultiplexed directly to them, rather than passing through a series of intervening protocol layers first. 5 Process Architecture Support in ADAPTIVE This section describes the various components available in
Reference: [26] <author> H. K. Huang, T. Suda, G. Takeuchi, and Y. Ogawa, </author> <title> Protocol Reconfiguration: a Study of Error Handling Mecha nisms, </title> <booktitle> in Proceedings of the 2 nd International Conference on Computer Communication Networks, </booktitle> <address> (San Diego, Califor-nia), </address> <publisher> ISCA, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: In the execution stage, applications invoke the previously generated protocol machines to perform their data transport activities efficiently. In addition, if the preconfigured collection of protocol machines is inadequate, applications may adaptively fine-tune protocol machine functionality at run-time using ADAPTIVE's reconfiguration services <ref> [26] </ref>. The primary resources and tools used in the generation and execution stages are described below. 5.1.1 Protocol Machine Generation Stage As shown in Figure 4 (1), the generation stage transforms descriptions of protocol machine functionality (called protocol machine configurations) into executable protocol machine instantiations. <p> If applications or the transport system reconfigure the functionality of a protocol machine at run-time, the mapping tools are invoked to perform the necessary modifications. This enables protocol machines to adapt dynamically to changes in application requirements, transport sys tem resources, and network characteristics <ref> [26] </ref>. 5.2 Process Architecture Components This section focuses on techniques for implementing ADAPTIVE's process architecture framework within the protocol family architecture and kernel architecture provided by STREAMS [18]. To avoid extraneous development effort, ADAPTIVE is initially being hosted in several existing operating environments including STREAMS in UNIX.
Reference: [27] <author> D. F. Box, D. C. Schmidt, and T. Suda, </author> <title> ADAPTIVE: An Object-Oriented Framework for Flexible and Adaptive Com munication Protocols, </title> <booktitle> in Proceedings of the 4 th IFIP Conference on High Performance Networking, (Liege, </booktitle> <address> Belgium), </address> <pages> pp. 367382, </pages> <publisher> IFIP, </publisher> <year> 1993. </year> <month> 9 </month>
Reference-contexts: The protocol processing mechanisms in each protocol machine may be customized for (1) the quantitative and qualitative require 5 ments of the application and (2) the underlying network capabilities <ref> [27] </ref>. 5.1.2 Protocol Machine Execution Phase run-time. As shown in the upper half of the figure, applications open certain communication devices (such as an FDDI controller) and dynamically insert and/or configure protocol machines (such as a machine that implements a Remote Procedure Call (RPC) protocol) via ADAPTIVE's application service interface.
References-found: 27

