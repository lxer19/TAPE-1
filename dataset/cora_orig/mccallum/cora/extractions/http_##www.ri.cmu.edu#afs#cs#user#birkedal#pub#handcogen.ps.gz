URL: http://www.ri.cmu.edu/afs/cs/user/birkedal/pub/handcogen.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/user/birkedal/www/papers.html
Root-URL: 
Email: e-mail: birkedal@diku.dk terra@diku.dk  
Title: Hand-Writing Program Generator Generators  
Author: Lars Birkedal Morten Welinder 
Address: DK -2100 Copenhagen Denmark  
Affiliation: DIKU, Department of Computer Science University of Copenhagen  
Abstract: In this paper we argue that hand-writing a program generator generator has a number of advantages compared to generating a program generator generator by self-application of a partial evaluator. We show the basic principles of how to construct a program generator generator by presenting a program generator generator for a skeletal language, and we argue that it is not more difficult to use the direct approach than the indirect approach. Moreover, we report on some promising experiments made with a prototype implementation of a program generator generator for most of the Standard ML Core Language. To the best of our knowledge, our prototype is the first succesfully implemented hand-written program generator generator for a statically typed language.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Lars Ole Andersen. </author> <title> C program specialization. </title> <type> Technical Report 92/14, </type> <institution> DIKU, Department of Computer Science, University of Copenhagen, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Experience shows that nave double-encoding is prohibitively expensive for self-application [23]. There are ways out of the double-coding problem. In <ref> [1] </ref> and [23] the trick is to enhance the universal type with a subtype, program, at the same level as the ground types instead of having programs represented as constructed values. <p> But then, of course, the implementation language must be dynamically typed. The use of the described encoding gives rise to another problem in traditional partial evaluation: some unnecessary encoding and decoding operations may be left in the residual program. As an example <ref> [1, Section 6.1] </ref> consider specialization of a self-interpreter with respect to the power function which can be defined as follows in SML. fun pow (n:int) (x:int) = if n=0 then 1 else (x * pow (n-1) x) We might end up with something like this fun pow (n:Val) (x:Val) : Val <p> To overcome this problem, an untagging analysis is created in <ref> [1] </ref>. 1 So if we used the above data type it would simply be the Int tag. 2 Which with the above data type would be (fn (Int i) =&gt; i). Recall that any traditional partial evaluator has an embedded self-interpreter.
Reference: 2. <author> Lars Ole Andersen. </author> <title> Program Analysis and Specialization for the C Programming Language. </title> <type> PhD thesis, </type> <institution> DIKU, Department fo Computer Science, University of Copenhagen, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The specialization process in the direct approach, see equation (7), is likely to be faster than the corresponding specialization process in the indirect approach, see equation (3). This is because the former corresponds to running a compiled program while the latter corresponds to interpreting a program. Andersen <ref> [2] </ref> reports the difference to be an order of magnitude. 6. When using the direct approach, there is no need to write a self-interpreter, as in the indirect approach.
Reference: 3. <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: We have deliberately chosen not to include a post-processing phase in our prototype since such simple optimizations can just as well be done by the SML compiler used when the residual program is run (see <ref> [3] </ref> for a description of optimizations included in the most widely used SML compiler, SML/NJ). Running the ML-code, using the values 1234567 and 7654321 is 125 times faster than running the interpreted program! Optimizations on the interpreter lower this factor to 85.
Reference: 4. <author> Lennart Beckman, Anders Haraldson, Osten Oskarsson, and Erik Sandewall. </author> <title> A partial evaluator and its use as a programming tool. </title> <booktitle> In Artificial Intelligence 7, </booktitle> <pages> pages 319-357. </pages> <publisher> North-Holland Publishing Company, </publisher> <year> 1976. </year>
Reference-contexts: Moreover, we shall see that there are other benefits with the direct approach to program generator generators. The idea of hand-writing cogen instead of writing a partial evaluator mix seems to have originated with <ref> [4] </ref> in which the authors report on a so-called partial evaluation compiler, RedCompile, which is a hand-written compiler generator for a subset of Lisp. RedCompile is semi-automatic: it relies on user annotation of functions to ensure preservation of semantics.
Reference: 5. <author> Lars Birkedal, Nick Rothwell, Mads Tofte, and David N. Turner. </author> <title> The ML Kit, </title> <type> Version 1. Technical Report 93/14, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1993. </year> <note> The ML Kit is obtainable by anonymous ftp from ftp.diku.dk directory pub/diku/users/birkedal. This technical report is distributed along with the ML Kit. </note>
Reference-contexts: Andersen [2] reports the difference to be an order of magnitude. 6. When using the direct approach, there is no need to write a self-interpreter, as in the indirect approach. This is important in practice because it requires some effort to write a self-interpreter for realistic languages like SML <ref> [5] </ref>. 3 Program Generator Generators | How We have now argued that it is advantageous to use the direct approach and handwrite a program generator generator. In this section we will demonstrate that it is in fact not much more difficult to hand-write a cogen than to hand-write a specializer. <p> We have made a prototype implementation based on The ML Kit <ref> [5] </ref>, an implementation of SML written in SML. The implementation includes an efficient binding-time analysis, an annotation phase, and a program generator generator. The implemented program generator generator treats general user defined monomorphic data types, partially static structures and arity raising, and general pattern matching.
Reference: 6. <author> Lars Birkedal and Morten Welinder. </author> <title> Partial evaluation of Standard ML. </title> <type> Technical Report 93/22, </type> <institution> DIKU, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: The observations scale well to larger languages, although it is a bit more complicated to deal with more sofisticated specialization techniques, such as partially static structures and arity raising <ref> [6] </ref>. 3.3 Example In this section we give an example of how the shown program generator generator can turn a Two-level Mini ML version of the Ackermann function into a generating extension written in SML, which when executed can specialize the Ackermann function. <p> f1 1 and f1 0 = 1 + 1 To obtain the value of (ack 3 8) we can now evaluate (f3 8). 4 A Program Generator Generator for SML The principles presented above have been extended to cover most of the language features of the Standard ML Core Language <ref> [6] </ref>. We have made a prototype implementation based on The ML Kit [5], an implementation of SML written in SML. The implementation includes an efficient binding-time analysis, an annotation phase, and a program generator generator.
Reference: 7. <author> Anders Bondorf. </author> <title> Self-Applicable Partial Evaluation. </title> <type> PhD thesis, </type> <institution> DIKU, Department of Computer Science, University of Copenhagen, Universitetsparken 1, DK-2100 Copenhagen , Denmark, </institution> <month> December </month> <year> 1990. </year>
Reference: 8. <author> Anders Bondorf. </author> <title> Automatic autoprojection of higher order recursive equations. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 17 </volume> <pages> 3-34, </pages> <month> March </month> <year> 1991. </year>
Reference: 9. <author> Anders Bondorf. </author> <title> Improving binding times without explicit CPS-conversion. </title> <booktitle> In 1992 ACM Conference in Lisp and Functional Programming, </booktitle> <address> San Francisco, California. </address> <booktitle> (Lisp Pointers, </booktitle> <volume> vol. V, no. 1, </volume> <year> 1992), </year> <pages> pages 1-10. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: At first sight this example is not as nice as one would usually expect from a partial evaluator, as some simple inlining and unfolding seemingly could improve the residual program. In existing partial evaluators a post-processing phase is often employed to do these simple optimizations, see, e.g., <ref> [9] </ref>. <p> Another path of future work is to make the specialization phase stronger in the program generator generator for SML. It would be interesting to extend the prototype with continuation-based specialization <ref> [9] </ref>. Likewise, constructor spe-cialization [29] might be considered, but the method suggested by Mogensen seems incompatible with the direct approach. Acknowledgements We wish to express our thanks for help with this article and with the work behind it to Peter Lee, Peter Sestoft, and Professor Neil D.
Reference: 10. <author> Anders Bondorf, Neil D. Jones, Torben Mogensen, and Peter Sestoft. </author> <title> Binding time analysis and the taming of self-application. </title> <type> Draft, </type> <pages> 18 pages, </pages> <institution> DIKU, University of Copenhagen, Denmark, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: This is done by a binding-time analysis. The partial evaluators described in [7,15,2,23] are all off-line and self-applicable. It has been argued that off-line specialization is superior when the goal is self-application of the specializer <ref> [10] </ref>. It is in fact the case that most successfully implemented self-applicable partial evaluators have been off-line. In this section we shall only be concerned with self-applicable partial evaluation as our goal is to be able to obtain a program generator generator.
Reference: 11. <author> Anders Bondorf and Jesper Jtrgensen. </author> <title> Efficient analyses for realistic off-line partial evaluation. </title> <journal> Journal of Functional Programming, special issue on partial evaluation, </journal> <volume> 3, </volume> <month> July </month> <year> 1993. </year>
Reference: 12. <author> Anne de Niel. </author> <title> Self-applicable Partial Evaluation of Polymorphically Typed Functional Languages. </title> <type> PhD thesis, </type> <institution> Katholieke Universiteit Leuven, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: There are ways out of the double-coding problem. In [1] and [23] the trick is to enhance the universal type with a subtype, program, at the same level as the ground types instead of having programs represented as constructed values. In <ref> [12] </ref> the trick is to treat all values (and thus programs as well) as having one and the same "black-box" type inherited from the implementation language of the partial evaluator. But then, of course, the implementation language must be dynamically typed.
Reference: 13. <author> Y. Futamura. </author> <title> Partial evaluation of computation process an approach to a compiler-compiler. </title> <journal> Systems, Computers, Controls, </journal> <volume> 2(5) </volume> <pages> 45-50, </pages> <year> 1971. </year>
Reference-contexts: We will assume that the function p 7! p Prg is injective, i.e., that we can remove the representation when we need to. An Equational Specification of the Indirect Approach. We now reformulate the Futamura projections <ref> [13] </ref>, in the setting of a statically typed language in order to explain the above mentioned problems. This has also been done by Andersen [1,2] and Launchbury [23].
Reference: 14. <author> Carsten K. Gomard. </author> <title> Higher order partial evaluation | HOPE for the lambda cal-culus. </title> <type> Master's thesis, </type> <institution> DIKU, Universitetsparken 1, DK-2100 Copenhagen , Den-mark, </institution> <year> 1989. </year>
Reference-contexts: The body of the residual function is the result of the inner let-expression. The dynamic variable x i is bound to a fresh variable as usual in program specializers, see e.g. <ref> [14] </ref>, to avoid name-clashes in the residual program. As seen in the definition of C 2exp , we generate the code d ....... vare for dynamic variables bound in specialization functions.
Reference: 15. <author> Carsten K. Gomard and Neil D. Jones. </author> <title> A partial evaluator for the untyped lambda-calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: 2exp 1 @ 2exp 2 j 2exp 1 op 2exp 2 j 2exp 1 op 2exp 2 j lift 2exp 2match ::= 2mrule h | 2matchi j 2mrule h | 2matchi 2mrule ::= 2pat =&gt; 2exp j 2pat =&gt; 2exp 2pat ::= var j var j i j i programs <ref> [15] </ref>. Type rules for checking well-annotatedness are simple to write down (see e.g., [15,6]) and have been omitted for space reasons. 3.2 A Program Generator Generator for Two-level Mini ML Let us begin with two simple examples. First consider the Two-level Mini ML expression 2 + 3.
Reference: 16. <author> Fritz Henglein. </author> <title> Efficient type inference for higher-order binding-time analysis. </title> <editor> In John Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1991. </year> <booktitle> (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 448-472. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: 17. <author> Carsten Kehler Holst. </author> <title> Syntactic currying. </title> <type> Student report, </type> <institution> DIKU, </institution> <year> 1989. </year>
Reference-contexts: RedCompile is semi-automatic: it relies on user annotation of functions to ensure preservation of semantics. In <ref> [17] </ref> Carsten Kehler Holst describes what he calls "syntactic currying." It is basically the same as hand-writing a program generator generator. The language used is a minimal subset of Scheme without higher-order functions and side effects. The system is implemented in Scheme using macros.
Reference: 18. <author> Carsten Kehler Holst and John Launchbury. </author> <title> Handwriting cogen to avoid problems with static typing. </title> <note> Working Note, </note> <month> October </month> <year> 1992. </year>
Reference-contexts: The system is implemented in Scheme using macros. Perhaps due to the choice of language, Holst did not realize the real value of his findings when used on a typed language. However, he and Launchbury did that later in the working note <ref> [18] </ref> where it was argued that hand-writing cogen and performing partial evaluation in two stages is advantageous when it comes to partial evaluation of statically typed languages.
Reference: 19. <author> Neil D. Jones. </author> <title> Automatic program specialization: A re-examination from basic principles. </title> <editor> In D. Bjorner, A. P. Ershov, and Neil D. Jones, editors, </editor> <booktitle> Partial Evaluation and Mixed Computation, </booktitle> <pages> pages 225-282. </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Given an interpreter, cogen produces a compiler. The Futamura projections are more thoroughly studied, albeit in an untyped setting, in <ref> [19] </ref>. The cogen obtained by self-application can, of course, be used not only on interpreters but also on other programs, so we have now seen how a program generator generator can be obtained by self-applying a partial evaluator.
Reference: 20. <author> Neil D. Jones. </author> <title> Efficient algebraic operations on programs. </title> <booktitle> In AMAST: Algebraic Methodology and Software Technology, </booktitle> <pages> pages 245-267. </pages> <institution> University of Iowa, USA, </institution> <year> 1991. </year>
Reference: 21. <author> Neil D. Jones, Carsten K. Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Program Generation. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: The first one which describes the particular problem we call static, the other we call dynamic. The situation can then be pictured as in Figure 1, which is borrowed from <ref> [21] </ref>. The cogen program accepts a general program p, and turns it into a static input in1 p-gen p-gen is Ershov's `generating extension' for p general program p t - cogen - dynamic input in2 - specialized program p in1 t output - program generator, p-gen. <p> Notice how the one-stage program p has been turned into a two-stage program p-gen. The two-stage program p-gen is called the generating extension of p. In their recent book <ref> [21, Page 11] </ref> Jones, Gomard, and Sestoft remark that It would be wonderful to have a program generator generator, but it is far from clear how to construct one. <p> We will call the hand-writing of cogen for the direct approach to program generator generators. Traditionally, the cogen and p-gen boxes in Figure 1 have been merged into one box, called mix. The reason has been to simplify matters <ref> [21] </ref>. The mix program is called a partial evaluator and in fact it is possible to obtain a program generator generator indirectly by self-application of mix [13,22]. We will call this for the indirect approach to program generator generators. <p> int_to_val 1 else int_to_val (val_to_int x * where int_to_val injects an integer into the universal type 1 and val_to_int is its partial inverse. 2 We would have liked the resulting power program to be essentially the same as the original as it would have been for an optimal mix, see <ref> [21, Section 6.4] </ref>. To overcome this problem, an untagging analysis is created in [1]. 1 So if we used the above data type it would simply be the Int tag. 2 Which with the above data type would be (fn (Int i) =&gt; i). <p> C 2pat [[2pat]] =&gt; .......................... C 2exp [[2exp]]e C 2pat : 2pat ! pat=pat C 2pat [[var]] = d ....... vare C 2pat [[i]] = i done-list in partial evaluation <ref> [21] </ref>. For efficiency reasons it is best to have one list for each sp-function rather than a global list; it saves the use of a tag which would otherwise be needed in order to distinguish between different sp-functions, and makes the lookup operations in the list faster. <p> In this section we report on some experiments with our prototype. 4.1 Interpreter for Imperative Language A navely written interpreter for a small imperative language appears in <ref> [21, Figure 3.3] </ref>. We have used this interpreter to test our prototype.
Reference: 22. <author> Neil D. Jones, Peter Sestoft, and Harald Stndergaard. </author> <title> Mix: A self-applicable partial evaluator for experiments in compiler generation. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 2(1) </volume> <pages> 9-50, </pages> <year> 1989. </year>
Reference: 23. <author> John Launchbury. </author> <title> A strongly-typed self-applicable partial evaluator. </title> <editor> In John Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science. ACM, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: An Equational Specification of the Indirect Approach. We now reformulate the Futamura projections [13], in the setting of a statically typed language in order to explain the above mentioned problems. This has also been done by Andersen [1,2] and Launchbury <ref> [23] </ref>. <p> Experience shows that nave double-encoding is prohibitively expensive for self-application <ref> [23] </ref>. There are ways out of the double-coding problem. In [1] and [23] the trick is to enhance the universal type with a subtype, program, at the same level as the ground types instead of having programs represented as constructed values. <p> Experience shows that nave double-encoding is prohibitively expensive for self-application <ref> [23] </ref>. There are ways out of the double-coding problem. In [1] and [23] the trick is to enhance the universal type with a subtype, program, at the same level as the ground types instead of having programs represented as constructed values.
Reference: 24. <author> Mark Leone and Peter Lee. </author> <title> Deferred compilation: The automation of run-time code generation. </title> <type> Technical Report CMU-CS-93-225, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: When computing the value of (ack 3 8) and then (f3 8) we observed a speed-up factor of 6.8. 5 Related Work Earlier work on hand-writing cogen has been described in Section 2.2. Recently, Mark Leone and Peter Lee <ref> [24] </ref> have investigated an alternative and complement approach to compile-time program analysis and optimization, termed deferred compilation. They have written a code generator for stage-annotated terms, which permits them to consider very low-level optimizations including, e.g., register allocation.
Reference: 25. <author> Morten Marquard and Bjarne Steensgaard. </author> <title> Partial evaluation of an object-oriented imperative language. </title> <type> Master's thesis, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1992. </year>
Reference: 26. <author> U. Meyer. </author> <title> Techniques for partial evaluation of imperative languages. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, Connecticut. </title> <journal> (Sigplan Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 94-105. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference: 27. <author> Robin Milner and Mads Tofte. </author> <title> Commentary on Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: 28. <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: 29. <author> Torben . Mogensen. </author> <title> Constructor specialization. </title> <booktitle> In Proceedings of the ACM SIG-PLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 22-33, </pages> <year> 1993. </year>
Reference-contexts: Another path of future work is to make the specialization phase stronger in the program generator generator for SML. It would be interesting to extend the prototype with continuation-based specialization [9]. Likewise, constructor spe-cialization <ref> [29] </ref> might be considered, but the method suggested by Mogensen seems incompatible with the direct approach. Acknowledgements We wish to express our thanks for help with this article and with the work behind it to Peter Lee, Peter Sestoft, and Professor Neil D.
Reference: 30. <author> Hanne Riis Nielson and Flemming Nielson. </author> <title> Automatic binding time analysis for a typed -calculus. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 10 </volume> <pages> 139-176, </pages> <year> 1988. </year>
Reference: 31. <author> D. Weise, R. Conybeare, E. Ruf, and S. Seligman. </author> <title> Automatic online partial evaluation. </title> <editor> In John Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1991. </year> <booktitle> (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 165-191. </pages> <publisher> ACM, Springer-Verlag, </publisher> <year> 1991. </year>
References-found: 31

