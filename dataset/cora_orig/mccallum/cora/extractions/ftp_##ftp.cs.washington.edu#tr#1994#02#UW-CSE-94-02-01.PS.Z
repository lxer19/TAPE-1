URL: ftp://ftp.cs.washington.edu/tr/1994/02/UW-CSE-94-02-01.PS.Z
Refering-URL: http://www.cs.washington.edu/homes/zahorjan/homepage/listof.htm
Root-URL: 
Title: Restructuring Arrays for Efficient Parallel Loop Execution  
Author: Shun-Tak Leung and John Zahorjan 
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Technical Report 94-02-01 February 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. J. Berger and S. H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):570-580, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: There is greater flexibility in the allocation of iterations of a given wavefront to processors. There are in fact sophisticated algorithms that partition array elements 5 (and thereby iterations of parallel loops operating on these elements) across processors so as to minimize inter-processor communication <ref> [10, 1] </ref>. Unfortunately, the existence of loop-carried dependences limits, if not precludes, the possibility of adapting them for use in our case.
Reference: [2] <author> Dimitri P. Bertsekas and John N. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1989. </year>
Reference-contexts: There are loop-carried flow dependences, but no antidependences or output dependences. If, however, the matrix is not lower triangular, the same loop may be viewed as one iteration of successive overrelaxation (SOR), which is an iterative algorithm for solving linear systems <ref> [2] </ref>. In this case, both flow dependences and antidependences exist, although output dependences are absent.
Reference: [3] <author> Henry III Burkhardt, Steven Frank, Bruce Knobe, and James Rothnie. </author> <title> Overview of the KSR1 computer system. </title> <type> Technical Report KSR-TR-9202001, </type> <institution> Kendall Square Research, </institution> <address> Boston, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: read a [25] read nzColumns [25] read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b <ref> [3] </ref> read firstNz [3] read firstNz [4] read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] <p> read nzColumns [25] read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b <ref> [3] </ref> read firstNz [3] read firstNz [4] read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns <p> [4] read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz <ref> [3] </ref> firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 Data alignment requirements on many architectures add a <p> read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz <ref> [3] </ref> firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 Data alignment requirements on many architectures add a minor complication. <p> A second equally important question is the size of the preprocessing and postprocessing overheads discussed in Section 3.1 and Section 3.2. If these overheads are too large, they may outweigh the benefits. The experiments were performed on a Kendall Square Research KSR1 distributed shared-memory multiprocessor <ref> [3] </ref> running OSF/1. The machine is configured with 64 processors in two 32-processor rings. Communication between any pair of processors within the same ring is equally expensive, while communication between two processors on different rings is significantly more costly than intra-ring communication.
Reference: [4] <institution> Kendall Square Research Corporation. </institution> <note> Principles of Operations, chapter 5. Revision 6.0 edition, </note> <month> October </month> <year> 1992. </year>
Reference-contexts: In many architectures, the two are the same, but this is not necessarily the case. In KSR1, for example, the unit of coherence is a subpage (128 bytes) while the unit of allocation is a page (consisting of 128 subpages) <ref> [4] </ref>. 3 We assume here that a cache line is larger than an array element. The larger the ratio of their sizes, the more serious is the false sharing problem. <p> read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b [3] read firstNz [3] read firstNz <ref> [4] </ref> read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] <p> a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz <ref> [4] </ref> firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 Data alignment requirements on many architectures add a minor complication.
Reference: [5] <author> Shun-Tak Leung and John Zahorjan. </author> <title> Improving the performance of runtime parallelization. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 83-91, </pages> <month> May </month> <year> 1993. </year> <month> 17 </month>
Reference-contexts: The problems described above result from parallel execution of a sequential loop without a corresponding change in the way data are structured. In this paper, we are particularly concerned about these problems in the context of runtime parallelization <ref> [8, 9, 5] </ref>, a technique to automatically parallelize loops containing loop-carried dependences that cannot be fully determined by the compiler. Since the parallel schedule, and hence the data access pattern, is not determined until run time, any restructuring of the data can also be done only at run time. <p> In effect, the sequential source loop is transformed into a sequence of parallel loops, each containing some of the original loop's iterations. If the parallel schedule thus computed can be reused many times, or if it can be computed in parallel <ref> [5] </ref>, the overhead of running the inspector will be more than compensated for by the savings of parallel loop execution. Implementation of the executor on a shared-memory multiprocessor can be very straightforward. It has an outer loop that goes through the wavefronts one by one.
Reference: [6] <author> Shun-Tak Leung and John Zahorjan. </author> <title> Handling general dependences in runtime parallelization. </title> <type> Tech--nical report, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <year> 1994. </year> <note> In preparation. </note>
Reference-contexts: The problem is harder if multiple iterations may write the same element. (In fact, parallelization of the source loop is much harder because of the more complex dependence pattern <ref> [6] </ref>. How read-write restructuring can handle this is therefore overshadowed by the more fundamental problem.) Given an assignment of iterations to processors and an array element written by multiple iterations, the question is which iteration the array element should "follow" when we decide where to place it.
Reference: [7] <author> Evangelos P. Markatos and Thomas J. LeBlanc. </author> <title> Using processor affinity in loop scheduling on shared-memory multiprocessors. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 104-113, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Doing so not only allows processors to keep reading data consecutively for as long as possible, but also simplifies implementation. read b <ref> [7] </ref> read firstNz [7] read firstNz [8] read a [23] read nzColumns [23] read a [24] read nzColumns [24] read a [25] read nzColumns [25] read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz <p> Doing so not only allows processors to keep reading data consecutively for as long as possible, but also simplifies implementation. read b <ref> [7] </ref> read firstNz [7] read firstNz [8] read a [23] read nzColumns [23] read a [24] read nzColumns [24] read a [25] read nzColumns [25] read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz <p> read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b [3] read firstNz [3] read firstNz [4] read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz <ref> [7] </ref> firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 <p> [25] nzColumns [78] firstNz <ref> [7] </ref> firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 Data alignment requirements on many architectures add a minor complication. For example, the KSR1 hardware requires eight-byte data to be aligned on eight-byte boundary. <p> Therefore, the overall strategy is to compute a static schedule and follow it as closely as possible but depart from it when dictated by, say, load imbalance. (One such scheduling policy is affinity scheduling <ref> [7] </ref>.) In this way, restructuring can yield significant benefits in the common case, without precluding more dynamic scheduling policies when necessary. Also, so far we have assumed that each iteration writes one element of one restructured read-write array. Conversely, each element is written by at most one iteration.
Reference: [8] <author> Joel Saltz, Harry Berryman, and Janet Wu. </author> <title> Multiprocessors and runtime compilation. </title> <booktitle> In Proceedings of International Workshop on Compilers for Parallel Computers, </booktitle> <address> Paris, </address> <year> 1990. </year>
Reference-contexts: The problems described above result from parallel execution of a sequential loop without a corresponding change in the way data are structured. In this paper, we are particularly concerned about these problems in the context of runtime parallelization <ref> [8, 9, 5] </ref>, a technique to automatically parallelize loops containing loop-carried dependences that cannot be fully determined by the compiler. Since the parallel schedule, and hence the data access pattern, is not determined until run time, any restructuring of the data can also be done only at run time. <p> One possible reason is that they depend on the contents of indirection arrays which are known only at run time. Sparse matrix problems, such as our example in Figure 1, are typical examples. To address this problem, runtime parallelization has been proposed <ref> [8, 9] </ref>. Instead of producing a parallel schedule directly, the compiler generates two pieces of code: the inspector and the executor . At run time, the inspector computes a valid schedule, and the executor executes iterations in parallel according to the computed schedule. <p> Let us call the sequential loop that we want to parallelize the source loop. The form of source loops we consider in this paper is shown in Figure 4 (adapted from <ref> [8] </ref>). Since different iterations may read and write the same element of the array x, the loop may contain loop-carried dependences, thus preventing completely parallel execution. <p> Doing so not only allows processors to keep reading data consecutively for as long as possible, but also simplifies implementation. read b [7] read firstNz [7] read firstNz <ref> [8] </ref> read a [23] read nzColumns [23] read a [24] read nzColumns [24] read a [25] read nzColumns [25] read b [13] read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a <p> [56] read nzColumns [56] read a [57] read nzColumns [57] read b [3] read firstNz [3] read firstNz [4] read a [11] read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz <ref> [8] </ref> firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 <p> This occurs, for example, in some iterative solvers for sparse linear systems, where the same triangular system is solved many times with different right-hand sides <ref> [8] </ref>. Similarly, the indirection table needs not be rebuilt if the schedule has not changed. Thus, the cost of building the indirection table from the schedule and, more importantly, that of restructuring this table can be amortized like the cost of computing the schedule itself.
Reference: [9] <author> Joel H. Saltz, Ravi Mirchandaney, and Kay Crowley. </author> <title> Runtime parallelization and scheduling of loops. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(5) </volume> <pages> 603-612, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The problems described above result from parallel execution of a sequential loop without a corresponding change in the way data are structured. In this paper, we are particularly concerned about these problems in the context of runtime parallelization <ref> [8, 9, 5] </ref>, a technique to automatically parallelize loops containing loop-carried dependences that cannot be fully determined by the compiler. Since the parallel schedule, and hence the data access pattern, is not determined until run time, any restructuring of the data can also be done only at run time. <p> One possible reason is that they depend on the contents of indirection arrays which are known only at run time. Sparse matrix problems, such as our example in Figure 1, are typical examples. To address this problem, runtime parallelization has been proposed <ref> [8, 9] </ref>. Instead of producing a parallel schedule directly, the compiler generates two pieces of code: the inspector and the executor . At run time, the inspector computes a valid schedule, and the executor executes iterations in parallel according to the computed schedule.
Reference: [10] <author> H. Simon. </author> <title> Partitioning of unstructured mesh problems for parallel processing. </title> <booktitle> In Proceedings of the Conference on Parallel Methods on Large Scale Structural Analysis and Physics Applications, </booktitle> <year> 1991. </year>
Reference-contexts: There is greater flexibility in the allocation of iterations of a given wavefront to processors. There are in fact sophisticated algorithms that partition array elements 5 (and thereby iterations of parallel loops operating on these elements) across processors so as to minimize inter-processor communication <ref> [10, 1] </ref>. Unfortunately, the existence of loop-carried dependences limits, if not precludes, the possibility of adapting them for use in our case.
Reference: [11] <author> Daniel Windheiser, Eric L. Boyd, Eric Hao, Santosh G. Abraham, and Edward S. Davidson. </author> <title> KSR1 multiprocessor: Analysis of latency hiding techniques in a sparse solver. </title> <booktitle> In Proceedings of International Parallel Processing Symposium 1993, </booktitle> <month> April </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: Thus, one cache line leads to one invalidation and (possibly) some misses in each loop execution. In fact, a latency hiding feature of the KSR1 (on which we have implemented our techniques) further reduces misses <ref> [11] </ref>: when a copy of a subpage travels through the memory system, processors that have an outdated copy will update their copies even if they have no outstanding requests for the subpage. <p> read firstNz [13] read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b [3] read firstNz [3] read firstNz [4] read a <ref> [11] </ref> read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz <p> read firstNz [14] read a [77] read nzColumns [77] read a [78] read nzColumns [78] read b [12] read firstNz [12] read firstNz [13] read a [56] read nzColumns [56] read a [57] read nzColumns [57] read b [3] read firstNz [3] read firstNz [4] read a <ref> [11] </ref> read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] <p> read b [3] read firstNz [3] read firstNz [4] read a <ref> [11] </ref> read nzColumns [11] read a [12] read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns [11] nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 <p> read nzColumns [12] read a [13] read nzColumns [13] nzColumns [77] nzColumns [23] nzColumns [24] nzColumns [25] nzColumns [78] firstNz [7] firstNz [8] firstNz [13] firstNz [14] 4-byte data nzColumns [56] nzColumns <ref> [11] </ref> nzColumns [12] nzColumns [13] nzColumns [57] firstNz [3] firstNz [4] firstNz [12] firstNz [13] 4-byte data a [11] a [13] a [56] b [3] 8-byte data a [23] a [25] a [77] b [7] 8-byte data Iteration 7 Iteration 13 Iteration 3 Iteration 12 p4 p8 Processor 1 Processor 2 Data alignment requirements on many architectures add a minor complication.
References-found: 11

