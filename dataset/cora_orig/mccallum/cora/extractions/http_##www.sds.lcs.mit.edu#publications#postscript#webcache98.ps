URL: http://www.sds.lcs.mit.edu/publications/postscript/webcache98.ps
Refering-URL: http://www.sds.lcs.mit.edu/publications/webcache98.html
Root-URL: 
Email: fulana,guttagg@lcs.mit.edu  
Title: Using Network-level Support to Improve Cache Routing  
Author: Ulana Legedza and John Guttag 
Web: http://www.sds.lcs.mit.edu/  
Affiliation: Software Devices and Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Date: June 1998  
Note: To be presented at the 3rd International WWW Caching Workshop, Manchester, England,  
Abstract: We present the design of a new distributed Web caching infrastructure that uses network-level mechanisms to provide routing of Web requests to caches. Our work is motivated by the need to provide effective caching not only for the small number of extremely popular Web documents, but also for the large number of documents of only intermediate popularity. In currently existing and proposed systems, requests for less popular documents suffer from long latency stemming from the inefficiencies of routing through an application-level overlay network. We combat this problem by integrating cache routing into the network layer, which results in shorter search paths and fewer application-level checks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Chankuntod, P. B. Danzig, and C. Neerdaels. </author> <title> A hierarchical internet object cache. </title> <booktitle> In Proceedings of 1996 USENIX, </booktitle> <year> 1996. </year>
Reference-contexts: This can introduce two significant sources of latency: repeated transitions between application and network layers and, since cache placement is independent of network topology, a large number of network hops. Most currently deployed distributed Web caching systems are manually configured hierarchical systems based on Harvest/Squid <ref> [1, 10] </ref>, such as the NLANR hierarchy in the U.S. [11]. Caches joining such a hierarchy may represent individual client sites, geographical regions, or countries. Requests for Web documents are forwarded up the hierarchy in search of a cached copy.
Reference: [2] <institution> National Laboratory for Applied Network Research (NLANR). Hierarchical caching system usage statistics. </institution> <note> http://ircache.nlanr.net/Cache/Statistics/Hierarchy/, 1998. </note>
Reference-contexts: While very popular documents can usually be found quickly, the search for less popular documents may follow a long and circuitous path of numerous failed checks. The impact of this is substantial since, as seen in <ref> [2] </ref>, the hit rate on web caches is typically less than 50%, indicating a large number of documents of only low to moderate popularity.
Reference: [3] <author> James Gwertzman and Margo Seltzer. </author> <title> The case for geographical push-caching. </title> <booktitle> In HotOS-V, </booktitle> <year> 1995. </year> <note> http://www.eecs.harvard.edu/~vino/web/hotos.ps. </note>
Reference-contexts: Using this tree, the server figures out where most of the traffic is concentrated, and where caching would be most useful. The server then sends a message to the appropriate node (s) to enable caching there. This scheme can be viewed as a new implementation of the push-caching <ref> [3] </ref> approach. The network support we provide allows us to gather better information on the sources of demand for each document (using network paths rather than geographical and zip code information) and to implement push-caching in a simpler way. <p> Since any application-level implementation would have to route requests through an overlay network, it would exhibit the same inefficiencies as the other approaches. In a different approach, push-caching <ref> [3] </ref>, Gwertzman and Seltzer propose having each server track geographical access information and mirror its data accordingly. For example, if a server in California is overloaded, and a large percentage of requests is coming from the East Coast, then a mirror site is set up on the East Coast.
Reference: [4] <author> Katia Obraczka, Peter Danzig, Solos Arthachinda, and Muhammad Yousuf. </author> <title> Scalable, highly available web caching. </title> <note> NLANR Web cache workshop http://ircache.nlanr.net/Cache/Workshop97/Papers/Obraczka/obraczka.ps, June 1997. </note>
Reference-contexts: Also, our redirection pointers will intercept requests from the East Coast and redirect them to the mirror automatically, avoiding the cross-continental latency otherwise required to find out about possible mirrors. Both Cisco's Cache Engine [7] and USC's translucent caching <ref> [4] </ref> are similar to our approach in that they provide network-level support for redirecting Web requests to an appropriate application-level cache. The Cache Engine router simply redirects all incoming Web traffic to its associated cache. It does not provide a scheme for managing a network of such caches.
Reference: [5] <author> Rina Panigrahy. </author> <title> Relieving hot spots on the World Wide Web. </title> <type> Master's thesis, </type> <institution> MIT EECS, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: Like Squid/NLANR, Povey and Harrison [6] construct a manually-configured hierarchy that must be traversed by all requests. Their scheme is promising in that it reduces load on top-level caches by only keeping location pointers in the hierarchy, but it suffers from the same inefficiencies for less popular documents. Panigrahy <ref> [5] </ref> describes a theoretically-based technique for constructing per-server distribution trees with good load balancing properties. However, since server load is not taken into account when determining tree size, the trees for small and/or lightly-loaded servers may be too big, resulting in many useless application-level checks.
Reference: [6] <author> Dean Povey and John Harrison. </author> <title> A distributed Internet cache. </title> <booktitle> In 20th Australian Computer Science Conference, </booktitle> <month> February </month> <year> 1997. </year> <note> http://www.psy.uq.edu.au:8080/~dean/project/. </note>
Reference-contexts: Section 2 described why this is the case for multicast-based Adaptive Web Caching [13] and hierarchical approaches like Squid/NLANR [11]. Here we provide several more examples. Like Squid/NLANR, Povey and Harrison <ref> [6] </ref> construct a manually-configured hierarchy that must be traversed by all requests. Their scheme is promising in that it reduces load on top-level caches by only keeping location pointers in the hierarchy, but it suffers from the same inefficiencies for less popular documents.
Reference: [7] <author> Cisco Systems. </author> <title> Cisco Cache Engine. </title> <address> http://www.cisco.com/warp/public/751/cache/cds ov.htm, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: As an alternative to significant change in network infrastructure, we have also developed a variant of our approach that does not have as many benefits, but can be deployed much more easily. It leverages existing router technology - specifically, Cisco Cache Engine routers <ref> [7] </ref>, which can be configured to redirect all incoming Web traffic to a nearby cache. We use these routers to create a Web caching infrastructure that keeps requests on paths closely resembling the shortest paths to the home server, but does require numerous (but simple) application-level cache checks. <p> Also, our redirection pointers will intercept requests from the East Coast and redirect them to the mirror automatically, avoiding the cross-continental latency otherwise required to find out about possible mirrors. Both Cisco's Cache Engine <ref> [7] </ref> and USC's translucent caching [4] are similar to our approach in that they provide network-level support for redirecting Web requests to an appropriate application-level cache. The Cache Engine router simply redirects all incoming Web traffic to its associated cache.
Reference: [8] <author> David Tennenhouse, Jonathan Smith, David Sincoskie, David Wetherall, and Gary Minden. </author> <title> A survey of active network research. </title> <journal> IEEE Communications Magazine, </journal> <month> January </month> <year> 1997. </year>
Reference-contexts: Incorporating such a scheme into the current Internet would require replacing a large number of routers (though not all). Instead of attempting that, we are using Active Network <ref> [8] </ref> technology as a deployment mechanism. An active router is one that can be dynamically extended to provide many different types of services beyond conventional IP routing and forwarding. This extensibility makes it possible to deploy new services while avoiding the difficulty of modifying existing routers.
Reference: [9] <author> Zheng Wang and Jon Crowcroft. Cachemesh: </author> <title> A distributed cache system for the World Wide Web. </title> <note> NLANR Web cache workshop http://ircache.nlanr.net/Cache/Workshop97/agenda.html, June 1997. </note>
Reference-contexts: Also, since trees are random, the client-server paths through them are likely to be much longer than the regular routing path from client to server. Wang and Crowcroft <ref> [9] </ref> describe a preliminary plan to put cache routing tables in caches to specify, for each page or server, where to look next if the local cache does not hold the document. A default route for some documents would help keep table size reasonable.
Reference: [10] <author> Duane Wessels. Squid and ICP: </author> <title> Past, present, and future. </title> <booktitle> AUUG Conference, </booktitle> <month> September </month> <year> 1997. </year> <note> http://www.nlanr.net/%7ewessels/Papers/auug-keynote.ps.gz. </note>
Reference-contexts: This can introduce two significant sources of latency: repeated transitions between application and network layers and, since cache placement is independent of network topology, a large number of network hops. Most currently deployed distributed Web caching systems are manually configured hierarchical systems based on Harvest/Squid <ref> [1, 10] </ref>, such as the NLANR hierarchy in the U.S. [11]. Caches joining such a hierarchy may represent individual client sites, geographical regions, or countries. Requests for Web documents are forwarded up the hierarchy in search of a cached copy.
Reference: [11] <author> Duane Wessels and Kim Claffy. </author> <title> Evolution of the NLANR cache hierarchy: Global configuration challenges. </title> <note> http://www.nlanr.net/Papers/Cache96, November 1996. </note>
Reference-contexts: Most currently deployed distributed Web caching systems are manually configured hierarchical systems based on Harvest/Squid [1, 10], such as the NLANR hierarchy in the U.S. <ref> [11] </ref>. Caches joining such a hierarchy may represent individual client sites, geographical regions, or countries. Requests for Web documents are forwarded up the hierarchy in search of a cached copy. In an attempt to keep from overloading caches at the root, caches query their siblings before passing requests upwards. <p> A recurring problem in most application-level distributed Web caching systems is the long latency incurred by requests for objects that are cached in very few places, if anywhere. Section 2 described why this is the case for multicast-based Adaptive Web Caching [13] and hierarchical approaches like Squid/NLANR <ref> [11] </ref>. Here we provide several more examples. Like Squid/NLANR, Povey and Harrison [6] construct a manually-configured hierarchy that must be traversed by all requests.
Reference: [12] <author> David Wetherall, John Guttag, and David Tennen-house. </author> <title> ANTS: A toolkit for building and dynamically deploying network protocols. </title> <booktitle> In Proceedings of IEEE OPENARCH, </booktitle> <address> San Francisco, CA, </address> <month> April </month> <year> 1998. </year>
Reference-contexts: An active router is one that can be dynamically extended to provide many different types of services beyond conventional IP routing and forwarding. This extensibility makes it possible to deploy new services while avoiding the difficulty of modifying existing routers. In an ANTS-style <ref> [12] </ref> active network, a packet specifies a particular service routine to be loaded and run on its behalf on each active router it encounters. This routine can perform arbitrary (but short) computation, store information in soft-state, and create and send packets back out into the network.
Reference: [13] <author> Lixia Zhang, Sally Floyd, and Van Jacobson. </author> <title> Adaptive Web caching. </title> <note> NLANR Web cache workshop http://ircache.nlanr.net/Cache/Workshop97/agenda.html, June 1997. 6 </note>
Reference-contexts: This approach lengthens the duration of each check. As the hierarchy grows to accommodate more users and more documents, there is an adverse impact on the numerous requests for objects that are not very popular. Also, as described in <ref> [13] </ref>, in upper levels of the hierarchy, requests can be deflected far away from their original route to the home server. Some of these problems are addressed in Adaptive Web Caching [13] in which a mesh of caches is used, and distribution trees for each server are built in the mesh. <p> Also, as described in <ref> [13] </ref>, in upper levels of the hierarchy, requests can be deflected far away from their original route to the home server. Some of these problems are addressed in Adaptive Web Caching [13] in which a mesh of caches is used, and distribution trees for each server are built in the mesh. The caches in the mesh are organized into overlapping multi-cast groups through which a request travels in search of a cached document. <p> A recurring problem in most application-level distributed Web caching systems is the long latency incurred by requests for objects that are cached in very few places, if anywhere. Section 2 described why this is the case for multicast-based Adaptive Web Caching <ref> [13] </ref> and hierarchical approaches like Squid/NLANR [11]. Here we provide several more examples. Like Squid/NLANR, Povey and Harrison [6] construct a manually-configured hierarchy that must be traversed by all requests.
References-found: 13

