URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/SchKarKroGro94.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: &lt;gerard@fwi.uva.nl&gt;  
Title: Optimal Attitude Control of Satellites by Artificial Neural Networks: a Pilot Study  
Author: G. Schram L. Karsten B.J.A. Krose F.C.A. Groen 
Keyword: self-adapting systems, reinforcement learning, neural networks.  
Address: Kruislaan 403, NL-1098 SJ Amsterdam.  Newtonweg 1, NL-2333 CP Leiden  
Affiliation: yFaculty of Mathematics and Computer Science, University of Amsterdam  zFokker Space Systems B.V.,  
Abstract: A pilot study is described on the practical application of artificial neural networks. The limit cycle of the attitude control of a satellite is selected as the test case. One of the sources of the limit cycle is a position dependent error in the observed attitude. A Reinforcement Learning method is selected, which is able to adapt a controller such that a cost function is optimised. An estimate of the cost function is learned by a neural `critic'. In our approach, the estimated cost function is directly represented as a function of the parameters of a linear controller. The critic is implemented as a CMAC network. Results from simulations show that the method is able to find optimal parameters without unstable behaviour. In particular in the case of large discontinuities in the attitude measurements, the method shows a clear improvement compared to the conventional approach: the RMS attitude error decreases approximately 30%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Albus JS (1975). </author> <title> A new approach to manipulator control: the Cerebellar Model Articulation Controller (CMAC). </title> <journal> Journal of Dynamic Systems, Measurement and Control, </journal> <volume> vol G97, no 3, </volume> <pages> pp 220-227. </pages>
Reference-contexts: cost function J (~x k ; ~u k ; k) of the system as the expected value of a discounted sum of future costs: J (~x k ; ~u k ; k) = E 1 X fl r (~x i ; ~u i ; i) (1) in which fl 2 <ref> [0; 1] </ref> is the discount factor. The task of the critic is to give an estimate ^ J of the cost function. <p> Local networks are characterized by local generalization: a small part of the network is used to determine the corresponding output. Not the entire mapping will be changed if a part of the network is adapted. An example of a local network is the Cerebellar Model Articulation Controller (CMAC) <ref> [1] </ref>. The CMAC is a kind of look-up table: a discrete input the piece-wise linear controller are chosen according to: w1 if e 0 &gt; 0, otherwise w2; w3 if _e 0 &gt; 0, otherwise w4.
Reference: [2] <author> Barto AG, </author> <title> Sutton RS, Anderson CW (1983). Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol SMC-13, no 5, </volume> <pages> pp 834-846. </pages>
Reference-contexts: Therefore a learning process is chosen that does not rely on learning a model of the plant: reinforcement learning. The idea of reinforcement learning is that the controller is adapted such that the system performance is optimised <ref> [2] </ref>. 2. The ISO The Infrared Space Observatory (ISO) is meant for astronomical observations of infrared-emitting objects. The control system consists of a computer, three reactionwheels, gyroscopes (GYR) for measuring the angular velocity, and a startracker (STR) which provides attitude information by measuring the position of a guide star. <p> The `reinforcement' signal r is often delayed since it is a result of previous control actions. This temporal credit assignment problem is solved by using a cost function J which predicts futural performance as a function of system state ~x and control action ~u <ref> [2] </ref>. An approximate of the cost function is learned by a `critic' network. The critic is used to update the weights of a second ANN which acts as controller. The controller generates control action ~u as a function of system state ~x.
Reference: [3] <author> Luenen WTC, de Jager PJ, van Amerongen J, </author> <title> Franken HM (1993). Limitations of adaptive critic control schemes. </title> <booktitle> In: Proceedings of ICANN'93. </booktitle> <address> Amsterdam, </address> <publisher> the Netherlands. </publisher> <editor> Eds. Gielen S, Kappen B. </editor> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For adapting the weights of the controller, a method is selected which deals with a continuous mapping from system states to control actions <ref> [3, 6] </ref>. Suppose the cost function J (~x k ; ~u k ; k) is predicted accurately. Then the gradient with respect to the controller command u k can be calculated, assuming that the critic network is differentiable. <p> The critic will estimate this long-term average of the cost function: ^ J (k) ^ J (k + 1) mean (r)=(1 fl) with r being e 0 2 (see also <ref> [3] </ref>). The long-term average is independent of the errors which are used as inputs. This also accounts for the controller command, the third input of the critic, since the command is a quasi-linear function of the errors. Consequently, the critic does not provide appropri ate gradients to adapt the controller.
Reference: [4] <author> Miller WT, </author> <title> Sutton RS, Werbos PJ (1990). Neural Networks for Control. </title> <publisher> MIT Press. </publisher>
Reference-contexts: 1. Introduction Artificial neural networks (ANNs) have been presented as adaptive controllers in situations in which a one-to-one, but unknown relationship exists between the state of a system and appropriate control actions. An overview is given in <ref> [4, 6] </ref>. In this study, we focuss on the attitude control of the Infrared Space Observatory (ISO). ISO is one of the major science satellite projects of the European Space Agency. The task of the satellite is pointing to scientifically interesting, infrared emitting celestial objects. <p> A detailed report is available on request. adapt itself on-line in order to maintain a smaller limit cycle. In many applications, an accurate (neural) model of the system is used to adapt a neural controller <ref> [4, 6] </ref>. However, in our application, all external disturbances and noise sources which affect the control of the satellite are more or less random in nature, and can not be modelled accurately.
Reference: [5] <editor> Rumelhart DE, McClelland JL, </editor> <booktitle> PDP Research Group (1986). Parallel Distributed Processing, explorations in the Microstructure of Cognitron. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Instead, the performance was estimated directly as a function of the controller weights (direct approach). The results of both meth ods are discussed below. An indirect approach The critic is implemented as a Multi-Layer Perceptron (MLP) <ref> [5] </ref>. The cost function ^ J is represented as a function of attitude error e, angular velocity error _e and torque request T . The controller is implemented as a piece-wise linear controller. The weights can be considered as multipliers of the controller gains K p and K d .
Reference: [6] <author> Sofge DA, </author> <title> White DA (1992). Handbook of Intelligent Control, Neural, Fuzzy, and Adaptive Approaches. </title> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: 1. Introduction Artificial neural networks (ANNs) have been presented as adaptive controllers in situations in which a one-to-one, but unknown relationship exists between the state of a system and appropriate control actions. An overview is given in <ref> [4, 6] </ref>. In this study, we focuss on the attitude control of the Infrared Space Observatory (ISO). ISO is one of the major science satellite projects of the European Space Agency. The task of the satellite is pointing to scientifically interesting, infrared emitting celestial objects. <p> A detailed report is available on request. adapt itself on-line in order to maintain a smaller limit cycle. In many applications, an accurate (neural) model of the system is used to adapt a neural controller <ref> [4, 6] </ref>. However, in our application, all external disturbances and noise sources which affect the control of the satellite are more or less random in nature, and can not be modelled accurately. <p> For adapting the weights of the controller, a method is selected which deals with a continuous mapping from system states to control actions <ref> [3, 6] </ref>. Suppose the cost function J (~x k ; ~u k ; k) is predicted accurately. Then the gradient with respect to the controller command u k can be calculated, assuming that the critic network is differentiable. <p> The conventional controller is obtained when the two controller weights are both 1. space is mapped to a set of weights, corresponding to table entries. A differential CMAC is introduced in <ref> [6] </ref>. The CMAC is extended with a sharing function: instead of just one weight or table entry, a collection of weights is used to determine the output. In our study, a Gaussian function is applied.
Reference: [7] <author> Sutton RS (1988). </author> <title> Learning to predict by the methods of Temporal Differences. </title> <journal> Machine Learning, </journal> <volume> no 3, </volume> <pages> pp 9-44. </pages>
Reference-contexts: The critic is used to update the weights of a second ANN which acts as controller. The controller generates control action ~u as a function of system state ~x. A diagram of the overall system is shown in figure 1. The critic is trained by a temporal difference algorithm <ref> [7] </ref>. Suppose the immediate cost of the system at time step k is measured by r (~x k ; ~u k ; k), as a function of system states ~x k and control actions ~u k .
References-found: 7

