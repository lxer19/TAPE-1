URL: http://www.cs.brown.edu/people/mph/lincount.ps
Refering-URL: http://www.cs.brown.edu/people/mph/lincount.html
Root-URL: http://www.cs.brown.edu/
Email: herlihy@cs.brown.edu  shanir@cs.tau.ac.il  waarts@cs.berkeley.edu  
Title: Linearizable Counting Networks  
Author: Maurice Herlihy Nir Shavit Orli Waarts 
Note: A preliminary version of this work appeared in the Proceedings of the 32nd Annual Symposium on Founda  pp. 526-535. [16] Research partly supported by ONR N00014-91-J-4052, ARPA Order 8225. Parts of this work were performed while at the MIT Lab. for Computer Science, supported by DARPA contracts N00014-89-J-1988 and N00014-87-K-0825 and by a Rothschild postdoctoral fellowship Research supported in part by an NSF Postdoctoral Fellowship. Part of this work was done while the author was at Stanford University and supported by NSF grant CCR-8814921, U.S. Army Research Office Grant DAAL-03-91-G-0102, ONR contract N00014-88-K-0166, and IBM fellowship.  
Date: August 4, 1995  October 1991,  
Address: Providence, RI 02912  Tel Aviv, Israel 69978  Berkeley  San Juan, Puerto Rico,  
Affiliation: Computer Science Department Brown University  Tel-Aviv University  Computer Science Division University of California at  tions of Computer Science,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. Aharonson and H. Attiya. </author> <title> Counting networks with arbitrary fan out. </title> <booktitle> In Proceedings of the 3 rd Symposium on Discrete Algorithms, </booktitle> <address> Orlando, Florida, </address> <month> January </month> <year> 1992. </year> <title> Also: </title> <type> Technical Report 679, </type> <institution> The Technion, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: In [4], Aspnes, Herlihy and Shavit introduced counting networks and presented two O (log 2 n) depth counting network designs. Aharonson and Attiya <ref> [1] </ref> and Busch and Mavronicolas [26] proved several fan-in/out tradeoffs and cyclicity properties of such networks. The effects of high balancer fan-out were studied in [21]. <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value. <p> The time bound is more significant: in a low-contention non-waiting network, any process must traverse an average of (n) balancers before choosing a value. There exist non-linearizable counting networks with polylogarithmic depth <ref> [1, 4, 18] </ref>, and therefore non waiting linearizable counting networks will always have lower latency than their non-waiting non-linearizable counterparts. 5 The trivial counting network consists of a single balancer. 13 5.1 Lower Bounds on Size We first show that the only non-blocking linearizable counting network of finite width is the
Reference: [2] <author> A. Agarwal and M. Cherian. </author> <title> Adaptive backoff synchronization techniques. </title> <booktitle> In Proceedings of the 16th international symposium on computer architecture, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware <ref> [2, 11, 12, 20, 29] </ref> and in software [3, 9, 10, 27, 32]. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [3] <author> T.E. Anderson. </author> <title> The performance implications of spin-waiting alternatives for shared-memory multiprocessors. </title> <type> Technical Report 89-04-03, </type> <institution> University of Washington, </institution> <address> Seat-tle, WA 98195, </address> <month> April </month> <year> 1989. </year> <note> To appear, IEEE Transactions on Parallel and Distributed Systems. </note>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware [2, 11, 12, 20, 29] and in software <ref> [3, 9, 10, 27, 32] </ref>. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access. <p> This algorithm has low latency (a single variable), it eschews waiting (the read-modify-write is assumed to be atomic), but has very high contention. (For more complete documentation of the performance problems of the single-variable solution see Anderson et al. <ref> [3] </ref> and Graunke and Thakkar [13].) Elsewhere [4], Aspnes, Herlihy, and Shavit have proposed low-contention solutions to the (non-linearizable) counting problem based on a new class of data structures called 1 A read-modify-write operation [12] atomically reads the value of a memory location, modifies it, writes it back, and returns the
Reference: [4] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <title> Counting Networks. </title> <journal> Journal of the ACM, </journal> <volume> Vol. 41, No. </volume> <month> 5 (September </month> <year> 1994), </year> <pages> pp. 1020-1048. </pages>
Reference-contexts: This algorithm has low latency (a single variable), it eschews waiting (the read-modify-write is assumed to be atomic), but has very high contention. (For more complete documentation of the performance problems of the single-variable solution see Anderson et al. [3] and Graunke and Thakkar [13].) Elsewhere <ref> [4] </ref>, Aspnes, Herlihy, and Shavit have proposed low-contention solutions to the (non-linearizable) counting problem based on a new class of data structures called 1 A read-modify-write operation [12] atomically reads the value of a memory location, modifies it, writes it back, and returns the location's old value. 2 counting networks. <p> Finally, we prove that these trade-offs are a fundamental aspect of linearizable counting: any low-contention network that does not rely on waiting must have depth (n), where n is the number of processes. Since non-linearizable counting does have ideal solutions <ref> [4] </ref> with low contention, polylogarithmic depth, and no waiting, this result establishes a substantial complexity gap between linearizable and non-linearizable counting. 1.1 Background A counting network, like a sorting network [6], is a directed acyclic graph whose nodes are simple computing elements called balancers, and whose edges are called wires. <p> Counting networks are constructed to achieve a high level of throughput by decomposing interactions among processes into pieces that can be performed in parallel, effectively reducing memory contention. In <ref> [4] </ref>, Aspnes, Herlihy and Shavit introduced counting networks and presented two O (log 2 n) depth counting network designs. Aharonson and Attiya [1] and Busch and Mavronicolas [26] proved several fan-in/out tradeoffs and cyclicity properties of such networks. The effects of high balancer fan-out were studied in [21]. <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value. <p> In other words, linearizability comes at a cost. 2 A Brief Introduction to Counting Networks This section introduces counting networks. Our model for multiprocessor computation follows [17, 25]. The network definitions and examples are taken from <ref> [4] </ref>, where a more complete discussion of the properties of counting networks can be found. <p> To illustrate this property, consider an execution in which tokens traverse the network sequentially, one completely after another. Figure 2 shows such an execution on the Bitonic <ref> [4] </ref> network defined in [4]. As can be seen, the network moves input tokens to output wires in increasing order modulo w. A balancing network having this property is called a counting network, because it can easily be adapted to count the number of tokens that have entered the network. <p> To illustrate this property, consider an execution in which tokens traverse the network sequentially, one completely after another. Figure 2 shows such an execution on the Bitonic <ref> [4] </ref> network defined in [4]. As can be seen, the network moves input tokens to output wires in increasing order modulo w. A balancing network having this property is called a counting network, because it can easily be adapted to count the number of tokens that have entered the network. <p> The time bound is more significant: in a low-contention non-waiting network, any process must traverse an average of (n) balancers before choosing a value. There exist non-linearizable counting networks with polylogarithmic depth <ref> [1, 4, 18] </ref>, and therefore non waiting linearizable counting networks will always have lower latency than their non-waiting non-linearizable counterparts. 5 The trivial counting network consists of a single balancer. 13 5.1 Lower Bounds on Size We first show that the only non-blocking linearizable counting network of finite width is the <p> After each process chooses a value, the protocol returns to a quiescent state, and the same argument applies. If we define a low-contention algorithm to be one where c is constant, then any low-contention linearizable counting protocol has linear latency. This theorem has further implications for counting networks. Elsewhere, <ref> [4] </ref> we have shown that the set of balancers traversed by a set of tokens in a counting network does not depend on how transitions are interleaved, which implies: 15 Corollary 5.5 In any execution of a counting network, the average number of balancers traversed by every token is (n=c). 5.3
Reference: [5] <author> B. Aiello, R. Venkatesan, and M. Yung. </author> <title> Coins, Weights and Contention in Balancing Networks. </title> <booktitle> In Thirteenth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1994, </year> <pages> pp. 193-214. </pages>
Reference-contexts: Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value.
Reference: [6] <author> T.H. Cormen, C.E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1990. </year>
Reference-contexts: Since non-linearizable counting does have ideal solutions [4] with low contention, polylogarithmic depth, and no waiting, this result establishes a substantial complexity gap between linearizable and non-linearizable counting. 1.1 Background A counting network, like a sorting network <ref> [6] </ref>, is a directed acyclic graph whose nodes are simple computing elements called balancers, and whose edges are called wires. Each token (input item) enters on one of the network's w n input wires, traverses a sequence of balancers, and leaves on an output wire.
Reference: [7] <author> C. Dwork, M. P. Herlihy, and O. Waarts. </author> <title> Contention in shared memory algorithms. </title> <booktitle> In Proceedings of the 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 174-183, </pages> <month> May </month> <year> 1993. </year> <note> Expanded version: Digital Equipment Corporation Technical Report CRL 93/12. </note>
Reference-contexts: This result was recently improved by Klugerman [19] to a constructive O (log n) network. Aiello, Venkatesan and Yung have shown randomized O (log n) constructions, and Shavit and Zemach have introduced highly efficient O (log n) depth networks called diffracting trees O (log n). Dwork, Herlihy, and Waarts <ref> [7] </ref> have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions [1, 4, 5, 18, 19, 21, 26, 31] are not linearizable. <p> Low capacity clearly implies low contention, but not vice versa. Subsequent to our work, Dwork, Herlihy and Waarts provided a more detailed complexity model for contention in multiprocessors <ref> [7] </ref>. Our notion of capacity is closely related to their notion of variable-contention, defined as the worst case number of concurrent accesses to any single variable occurring during an execution of the algorithm. <p> Variable-contention can also be viewed as the contribution of a single variable to the overall contention of the algorithm. <ref> [7] </ref> consider a model in which simultaneous accesses to a single memory location are serialized: only one operation succeeds at a time, and other pending operations must stall. <p> Consequently Lemma 5.3, Theorem 5.4 and Corollary 5.5 also hold when c is the variable-contention. It follows that in any non-waiting protocol, whether based on a counting network or not, variable-contention and latency are inversely related. For more details the reader is referred to <ref> [7] </ref>. 6 Conclusion The following joke circulated in Italy during the 1920's. Mussolini claims that the ideal citizen is intelligent, honest, and Fascist.
Reference: [8] <author> C.S. Ellis and T.J. Olson. </author> <title> Algorithms for parallel memory allocation. </title> <journal> Journal of Parallel Programming, </journal> <volume> 17(4) </volume> <pages> 303-345, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Linearizable counting lies at the heart of a number of basic problems, such as concurrent time-stamp generation, concurrent implementations of shared counters, FIFO buffers, and similar data structures (e.g. <ref> [8, 12, 22, 32] </ref>). The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability [17]. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms.
Reference: [9] <author> D. Gawlick. </author> <title> Processing 'hot spots' in high performance systems. </title> <booktitle> In Proceedings COMPCON'85, </booktitle> <year> 1985. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware [2, 11, 12, 20, 29] and in software <ref> [3, 9, 10, 27, 32] </ref>. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [10] <author> J. Goodman, M. Vernon, and P. Woest. </author> <title> A set of efficient synchronization primitives for a large-scale shared-memory multiprocessor. </title> <booktitle> In Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware [2, 11, 12, 20, 29] and in software <ref> [3, 9, 10, 27, 32] </ref>. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [11] <author> A. Gottlieb, R. Grishman, C.P. Kruskal, K.P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU ultracomputer designing an MIMD parallel computer. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(2):175-189, </volume> <month> February </month> <year> 1984. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware <ref> [2, 11, 12, 20, 29] </ref> and in software [3, 9, 10, 27, 32]. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [12] <author> A. Gottlieb, B.D. Lubachevsky, and L. Rudolph. </author> <title> Basic techniques for the efficient coordination of very large numbers of cooperating sequential processors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 164-189, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: Linearizable counting lies at the heart of a number of basic problems, such as concurrent time-stamp generation, concurrent implementations of shared counters, FIFO buffers, and similar data structures (e.g. <ref> [8, 12, 22, 32] </ref>). The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability [17]. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms. <p> Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware <ref> [2, 11, 12, 20, 29] </ref> and in software [3, 9, 10, 27, 32]. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access. <p> (For more complete documentation of the performance problems of the single-variable solution see Anderson et al. [3] and Graunke and Thakkar [13].) Elsewhere [4], Aspnes, Herlihy, and Shavit have proposed low-contention solutions to the (non-linearizable) counting problem based on a new class of data structures called 1 A read-modify-write operation <ref> [12] </ref> atomically reads the value of a memory location, modifies it, writes it back, and returns the location's old value. 2 counting networks. In this paper, we show how counting networks can be adapted to solve linearizable counting.
Reference: [13] <author> G. Graunke and S. Thakkar, </author> <title> Synchronization algorithms for shared-memory multiprocessors., </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 60-70, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: This algorithm has low latency (a single variable), it eschews waiting (the read-modify-write is assumed to be atomic), but has very high contention. (For more complete documentation of the performance problems of the single-variable solution see Anderson et al. [3] and Graunke and Thakkar <ref> [13] </ref>.) Elsewhere [4], Aspnes, Herlihy, and Shavit have proposed low-contention solutions to the (non-linearizable) counting problem based on a new class of data structures called 1 A read-modify-write operation [12] atomically reads the value of a memory location, modifies it, writes it back, and returns the location's old value. 2 counting
Reference: [14] <author> M.P. Herlihy. </author> <title> A methodology for implementing highly concurrent data structures. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 197-206, </pages> <address> Seattle, WA, </address> <month> March 14-16 </month> <year> 1990. </year>
Reference-contexts: This set could be implemented with a short critical section (which intro duces a small likelihood of blocking) or it could be implemented without blocking using read-modify-write operations as discussed elsewhere <ref> [14] </ref>. 5 Lower Bounds We now show that it is impossible to construct an ideal linearizable counting algorithm, one with low contention, low latency, and without waiting. We give two results.
Reference: [15] <author> M.P. Herlihy, B-H. Lim, and N. Shavit. </author> <title> Scalable Concurrent Counting. </title> <journal> ACM Transactions on Computer Systems, </journal> <note> to appear. 17 </note>
Reference-contexts: On a distributed memory architecture, however, the Waiting network had substantially lower throughput than its counting network component alone <ref> [15] </ref>. The Waiting-filter is similar to a barrier. After traversing the counting network, the Waiting-filter forces tokens with lower values to "catch up." A token leaves the filter only when all lower values have been assigned, guaranteeing that every token that enters the network later will receive a higher value.
Reference: [16] <author> M.P. Herlihy, N. Shavit, and O. Waarts. </author> <title> Linearizable Counting Networks. </title> <booktitle> In Pro--ceedings of the 32 nd Annual Symposium on Foundations of Computer Science, </booktitle> <address> San Juan, Puerto Rico, </address> <month> October </month> <year> 1991, </year> <pages> pp. 526-535. </pages> <note> Detailed version with empirical results appeared as MIT/LCS technical manuscript 459, </note> <month> November </month> <year> 1991. </year>
Reference-contexts: Nevertheless, on a cache-coherent bus-based multiprocessor, the Waiting network was observed to have contention and latency not much higher than that of its counting network component alone <ref> [16] </ref>, probably because the serializing effect of the bus masks the serializing effects of the filter. On a distributed memory architecture, however, the Waiting network had substantially lower throughput than its counting network component alone [15]. The Waiting-filter is similar to a barrier.
Reference: [17] <author> M.P. Herlihy and J.M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In the counting problem, n asynchronous concurrent processes repeatedly assign themselves successive values, such as integers or locations in memory. The linearizable counting problem requires that the order of the values assigned reflects the real-time order in which they were requested <ref> [17, 24] </ref>. For example, if k values are requested, then values 0 : : : k 1 should be assigned, and if process P is assigned a value before process Q requests one, then P 's value must be less than Q's. <p> The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability <ref> [17] </ref>. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms. As discussed in more detail elsewhere [17], the notion of lin-earizability generalizes and unifies a number of ad-hoc correctness conditions in the literature, and it is related to <p> The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability <ref> [17] </ref>. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms. As discussed in more detail elsewhere [17], the notion of lin-earizability generalizes and unifies a number of ad-hoc correctness conditions in the literature, and it is related to (but not identical with) correctness criteria such as sequential consistency [23] and strict serializability [28]. <p> Our results therefore establish a substantial complexity gap between linearizable and non-linearizable data structures for counting. In other words, linearizability comes at a cost. 2 A Brief Introduction to Counting Networks This section introduces counting networks. Our model for multiprocessor computation follows <ref> [17, 25] </ref>. The network definitions and examples are taken from [4], where a more complete discussion of the properties of counting networks can be found. <p> an interleaving model of computation [25], where there is no "global clock,"and where the execution of an operation A is said to precede that of operation B according to the real-time order, if every atomic operation in the implementation of A precedes every atomic operation in the implementation of B <ref> [17, 24] </ref>. 4 Counting networks belong to a larger class of networks called balancing networks, con-structed from wires and computing elements called balancers. <p> Though outside the scope of this paper, this definition can easily be shown to meet the linearizability definition of <ref> [17] </ref>. 3 2 Note that the width and depth of the network do not need to depend on the number of concurrent processes. 3 Informally, this would amount to showing that the history of all process's requests (of values) and replies is equivalent to a sequential history which is consistent with
Reference: [18] <author> M. Klugerman and C. Greg Plaxton, </author> <title> Small-Depth Counting Networks. </title> <booktitle> In ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1992 </year>
Reference-contexts: Aharonson and Attiya [1] and Busch and Mavronicolas [26] proved several fan-in/out tradeoffs and cyclicity properties of such networks. The effects of high balancer fan-out were studied in [21]. Klugerman and Plaxton <ref> [18] </ref> have shown an explicit network construction of depth O (c log fl n log n) for some small constant c, and an existential proof of a network of depth O (log n). This result was recently improved by Klugerman [19] to a constructive O (log n) network. <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value. <p> In Section 5, we prove that the tradeoffs among our constructions is inherent. In any low-contention linearizable counting network, a token must traverse an average of (n) gates before taking a value. In <ref> [18, 19] </ref> it was shown that there exist width-n non-linearizable counting networks in which each token traverses at most O (log n) balancers. Our results therefore establish a substantial complexity gap between linearizable and non-linearizable data structures for counting. <p> The time bound is more significant: in a low-contention non-waiting network, any process must traverse an average of (n) balancers before choosing a value. There exist non-linearizable counting networks with polylogarithmic depth <ref> [1, 4, 18] </ref>, and therefore non waiting linearizable counting networks will always have lower latency than their non-waiting non-linearizable counterparts. 5 The trivial counting network consists of a single balancer. 13 5.1 Lower Bounds on Size We first show that the only non-blocking linearizable counting network of finite width is the
Reference: [19] <author> M. Klugerman, </author> <title> Small-Depth Counting Networks. </title> <type> Ph.D. Thesis, </type> <institution> MIT, </institution> <year> 1994. </year>
Reference-contexts: Klugerman and Plaxton [18] have shown an explicit network construction of depth O (c log fl n log n) for some small constant c, and an existential proof of a network of depth O (log n). This result was recently improved by Klugerman <ref> [19] </ref> to a constructive O (log n) network. Aiello, Venkatesan and Yung have shown randomized O (log n) constructions, and Shavit and Zemach have introduced highly efficient O (log n) depth networks called diffracting trees O (log n). <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value. <p> In Section 5, we prove that the tradeoffs among our constructions is inherent. In any low-contention linearizable counting network, a token must traverse an average of (n) gates before taking a value. In <ref> [18, 19] </ref> it was shown that there exist width-n non-linearizable counting networks in which each token traverses at most O (log n) balancers. Our results therefore establish a substantial complexity gap between linearizable and non-linearizable data structures for counting.
Reference: [20] <author> C.P. Kruskal, L. Rudolph, and M. Snir. </author> <title> Efficient synchronization on multiprocessors with shared memory. </title> <booktitle> In Fifth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware <ref> [2, 11, 12, 20, 29] </ref> and in software [3, 9, 10, 27, 32]. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [21] <author> Felten, Lamarca, and Ladner. </author> <title> Building Counting Networks from Larger Balancers. </title> <institution> University of Washington, </institution> <month> April </month> <year> 1993. </year> <note> TR 93-04-09 </note> . 
Reference-contexts: In [4], Aspnes, Herlihy and Shavit introduced counting networks and presented two O (log 2 n) depth counting network designs. Aharonson and Attiya [1] and Busch and Mavronicolas [26] proved several fan-in/out tradeoffs and cyclicity properties of such networks. The effects of high balancer fan-out were studied in <ref> [21] </ref>. Klugerman and Plaxton [18] have shown an explicit network construction of depth O (c log fl n log n) for some small constant c, and an existential proof of a network of depth O (log n). <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value.
Reference: [22] <author> L. Lamport. </author> <title> A new solution of Dijkstra's concurrent programming problem. </title> <journal> Communications of the ACM, </journal> <volume> 17(8) </volume> <pages> 453-455, </pages> <month> August </month> <year> 1974. </year>
Reference-contexts: Linearizable counting lies at the heart of a number of basic problems, such as concurrent time-stamp generation, concurrent implementations of shared counters, FIFO buffers, and similar data structures (e.g. <ref> [8, 12, 22, 32] </ref>). The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability [17]. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms.
Reference: [23] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multi-process programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9), </volume> <month> September </month> <year> 1979 </year>
Reference-contexts: As discussed in more detail elsewhere [17], the notion of lin-earizability generalizes and unifies a number of ad-hoc correctness conditions in the literature, and it is related to (but not identical with) correctness criteria such as sequential consistency <ref> [23] </ref> and strict serializability [28]. Linearizable counting algorithms can be judged by three criteria: * Contention: Because of limitations on processor-to-memory bandwidth, performance suffers when too many processes attempt to access the same memory location at the same time.
Reference: [24] <author> L. Lamport. </author> <title> The mutual exclusion problem, Part I: A Theory of interprocess communication. </title> <journal> In Journal of the ACM, </journal> <volume> Vol. 33, No. 2, </volume> <pages> pp. 313-326, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction In the counting problem, n asynchronous concurrent processes repeatedly assign themselves successive values, such as integers or locations in memory. The linearizable counting problem requires that the order of the values assigned reflects the real-time order in which they were requested <ref> [17, 24] </ref>. For example, if k values are requested, then values 0 : : : k 1 should be assigned, and if process P is assigned a value before process Q requests one, then P 's value must be less than Q's. <p> an interleaving model of computation [25], where there is no "global clock,"and where the execution of an operation A is said to precede that of operation B according to the real-time order, if every atomic operation in the implementation of A precedes every atomic operation in the implementation of B <ref> [17, 24] </ref>. 4 Counting networks belong to a larger class of networks called balancing networks, con-structed from wires and computing elements called balancers.
Reference: [25] <author> N.A. Lynch and M.R. Tuttle. </author> <title> Hierarchical Correctness Proofs for Distributed Algorithms. </title> <booktitle> In Sixth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1987, </year> <pages> pp. 137-151. </pages> <note> Full version available as MIT Technical Report MIT/LCS/TR-387. </note>
Reference-contexts: Our results therefore establish a substantial complexity gap between linearizable and non-linearizable data structures for counting. In other words, linearizability comes at a cost. 2 A Brief Introduction to Counting Networks This section introduces counting networks. Our model for multiprocessor computation follows <ref> [17, 25] </ref>. The network definitions and examples are taken from [4], where a more complete discussion of the properties of counting networks can be found. <p> Our model for multiprocessor computation follows [17, 25]. The network definitions and examples are taken from [4], where a more complete discussion of the properties of counting networks can be found. The following discussion assumes an interleaving model of computation <ref> [25] </ref>, where there is no "global clock,"and where the execution of an operation A is said to precede that of operation B according to the real-time order, if every atomic operation in the implementation of A precedes every atomic operation in the implementation of B [17, 24]. 4 Counting networks belong <p> Although balancer transitions can occur concurrently, it is convenient to model them using an interleaving semantics in the style of Lynch and Tuttle <ref> [25] </ref>.
Reference: [26] <author> C. Busch and M. Mavronicolas. </author> <title> A Combinatorial Treatment of Balancing Networks. </title> <booktitle> In Thirteenth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1994, </year> <pages> pp. 206-215. </pages>
Reference-contexts: In [4], Aspnes, Herlihy and Shavit introduced counting networks and presented two O (log 2 n) depth counting network designs. Aharonson and Attiya [1] and Busch and Mavronicolas <ref> [26] </ref> proved several fan-in/out tradeoffs and cyclicity properties of such networks. The effects of high balancer fan-out were studied in [21]. <p> Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value.
Reference: [27] <author> J.M. Mellor-Crummey and M.L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <type> Technical Report Technical C. </type> <institution> Busch and M. </institution> <month> Mavron-icolas. </month> <title> A Combinatorial Treatment of Balancing Networks. </title> <booktitle> In Thirteenth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1994, </year> <pages> pp. </pages> <address> 206-215.Report 342, </address> <institution> University of Rochester, Rochester, </institution> <address> NY 14627, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware [2, 11, 12, 20, 29] and in software <ref> [3, 9, 10, 27, 32] </ref>. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [28] <author> C.H. Papadimitriou. </author> <title> The serializability of concurrent database updates. </title> <journal> Journal of the ACM, </journal> <volume> 26(4) </volume> <pages> 631-653, </pages> <month> October </month> <year> 1979. </year>
Reference-contexts: As discussed in more detail elsewhere [17], the notion of lin-earizability generalizes and unifies a number of ad-hoc correctness conditions in the literature, and it is related to (but not identical with) correctness criteria such as sequential consistency [23] and strict serializability <ref> [28] </ref>. Linearizable counting algorithms can be judged by three criteria: * Contention: Because of limitations on processor-to-memory bandwidth, performance suffers when too many processes attempt to access the same memory location at the same time.
Reference: [29] <author> G.H. Pfister et al. </author> <title> The IBM research parallel processor prototype (RP3): introduction and architecture. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <year> 1985. </year>
Reference-contexts: Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware <ref> [2, 11, 12, 20, 29] </ref> and in software [3, 9, 10, 27, 32]. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
Reference: [30] <author> G.H. Pfister and A. Norton. </author> <title> `hot spot' contention and combining in multistage interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(11):933-938, </volume> <month> November </month> <year> 1985. </year>
Reference: [31] <author> N. Shavit and A. Zemach. </author> <title> Diffracting Trees. </title> <booktitle> In Proceedings of the Annual Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: Dwork, Herlihy, and Waarts [7] have recently devised a theoretical model for multiprocessor contention and used it to evaluate the properties of various counting networks. 3 Unfortunately, all known counting network constructions <ref> [1, 4, 5, 18, 19, 21, 26, 31] </ref> are not linearizable. It is even possible for a process to shepherd two tokens through a network, one after the other, and by suitable overtaking, have the second token receive the lesser value.
Reference: [32] <author> H.S. Stone. </author> <title> Database applications of the fetch-and-add instruction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(7):604-612, </volume> <month> July </month> <year> 1984. </year> <month> 18 </month>
Reference-contexts: Linearizable counting lies at the heart of a number of basic problems, such as concurrent time-stamp generation, concurrent implementations of shared counters, FIFO buffers, and similar data structures (e.g. <ref> [8, 12, 22, 32] </ref>). The requirement that the values chosen reflect the real-time order in which they were requested is called linearizability [17]. The use of linearizable data abstractions greatly simplifies both the specification and the proofs of multiple instruction/multiple data (MIMD) shared memory algorithms. <p> Such "hot-spot" contention is well-documented, and has been the subject of extensive research both in hardware [2, 11, 12, 20, 29] and in software <ref> [3, 9, 10, 27, 32] </ref>. * Latency: The time needed to choose a value is strongly affected by the number of variables a process must access.
References-found: 32

