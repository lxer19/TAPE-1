URL: http://www.cs.colorado.edu/~richard/Inpt.ps
Refering-URL: http://www.cs.colorado.edu/~richard/Home.html
Root-URL: http://www.cs.colorado.edu
Title: A Trust Region Method Based on Interior Point Techniques for Nonlinear Programming  
Author: Richard H. Byrd Jean Charles Gilbert Jorge Nocedal 
Keyword: Key words: constrained optimization, interior point method, large-scale optimization, non linear programming, primal method, primal-dual method, SQP iteration, barrier method, trust region method.  
Note: 80309. This author was supported by NSF grant CCR-9101795, ARO grant DAAH04-94-0228, and AFOSR grant F49620-94-1-0101.  60208. This author was supported by National Science Foundation Grants CCR-9400881 and ASC-9213149, and by Department of Energy Grant DE FG02-87ER25047-A004.  
Address: Boulder CO  Rocquencourt, B.P. 105, 78153 Le Chesnay Cedex (France).  Evanston Il  
Affiliation: Computer Science Department, University of Colorado,  INRIA  ECE Department, Northwestern University,  
Date: August 14, 1998  
Abstract: An algorithm for minimizing a nonlinear function subject to nonlinear inequality constraints is described. It applies sequential quadratic programming techniques to a sequence of barrier problems, and uses trust regions to ensure the robustness of the iteration and to allow the direct use of second order derivatives. This framework permits primal and primal-dual steps, but the paper focuses on the primal version of the new algorithm. An analysis of the convergence properties of this method is presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Blanchon, J.-C. Dodu, A. Renaud, and M. </author> <title> Bouhtou (1996). "Implementation of a primal-dual interior-point method applied to the planning of reactive power compensation devices". </title> <booktitle> Proceedings of the 12th Power Systems Computation Conference, </booktitle> <month> August 19-23, </month> <year> 1996, </year> <pages> Dresden. </pages>
Reference-contexts: Preliminary computational experience with simple adaptations of primal-dual interior point methods have given encouraging results on some classes on nonlinear problems (see for example <ref> [27, 14, 29, 1] </ref>). In this paper we describe and analyze an algorithm for large-scale nonlinear programming that uses ideas from interior point methods and sequential quadratic programming.
Reference: [2] <author> K.M. Anstreicher and J.-P. </author> <title> Vial (1994). "On the convergence of an infeasible primal-dual interior-point method for convex programming". </title> <journal> Optimization Methods and Software, </journal> <volume> Vol. 3, </volume> <pages> pp. 273-283. </pages>
Reference-contexts: We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits [15], Anstreicher and Vial <ref> [2] </ref>, Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [3] <author> R.H. </author> <title> Byrd (1987). "Robust trust region methods for constrained optimization". </title> <note> Talk given at the SIAM Conference on Optimization, </note> <institution> Houston, TX, </institution> <year> 1987. </year>
Reference-contexts: Several strategies have been proposed to make the constraints consistent [7, 6, 24], and in this paper we follow the approach of Byrd <ref> [3] </ref> and Omojokun [20], which we have found suitable for solving large problems [18].
Reference: [4] <author> R.H. Byrd, M.E. Hribar and J. </author> <title> Nocedal (1997). "An interior point method for large scale nonlinear programming", </title> <type> Report OTC-97/04, </type> <institution> Optimization Technology Center, Northwestern University. </institution> <month> 34 </month>
Reference-contexts: One of its unique features is the use of a trust region framework that allows for the direct use of second derivatives and the inaccurate solution of subproblems. The algorithm is well suited for handling equality constraints (see <ref> [4] </ref>), but for simplicity of exposition we will only consider here inequality constrained problems of the form min f (x) subject to g (x) 0; (1.1) where f : R n ! R and g : R n ! R m are smooth functions. <p> This framework suggests how to generate steps with primal or primal-dual characteristics, and is well suited for large problems. Numerical experiments with an implementation of the new method have been performed by Byrd, Hribar and Nocedal <ref> [4] </ref>, and show that this approach holds much promise. <p> Since this submatrix is positive definite and diagonal, it seems to be the best scale at the current point; see also <ref> [4] </ref> for a discussion of how this scaling is beneficial when using a conjugate gradient iteration to compute the step. <p> the form c (z) = g E (x) ! The Jacobian matrix ^ A then takes the form ^ A (z) &gt; = A E (x) &gt; 0 ! where A E and A I denote the matrices of constraint gradients corresponding to g E and g I ; see <ref> [4] </ref> for a detailed discussion on the treatment of equality constraints in our new method. 5 In x2 we discuss in more detail when to accept or reject a step, and how to update the trust region. This will allow us to give a complete description of the algorithm. <p> This is because near the solution point, the quadratic subproblem (1:11) will be convex and the tolerances of the procedure for solving (1:11) subject to the trust region constraint, will be set so that, asymptotically, it is solved exactly <ref> [4] </ref>. Moreover, as the iterates converge to the solution we expect the trust region constraint to become inactive, provided a second order correction is incorporated in the algorithm. <p> it is straightforward to show [18] that (2:9) has a solution in the range of S k : (2.10) Even when the lower bounds are active, keeping u in the range of (2:10) will prevent u from being unreasonably long, and in the implementation of the new method described in <ref> [4] </ref>, u is chosen always in this space. A condition of this type is necessary since, if u is unnecessarily long, the objective function value could get worse, making the job of the tangential step more difficult. <p> The important question of what choices of B k and k are most effective is not addressed here, and we refer the reader to <ref> [4] </ref> for some possibilities. 3 Well-posedness of Algorithm I The purpose of this section is to show that, if an iterate (x k ; s k ) is not a stationary point of the barrier problem, then the trust region radius cannot shrink to zero and prevent the algorithm from moving <p> In this paper we have focused on primal methods because they are easier to analyze and we have devoted much attention to their global convergence properties because the analysis provides important clues on how to design the algorithms. Computational experience with the primal interior point method is given in <ref> [16, 4] </ref>; those papers also provide computational results with primal-dual methods. Another question to be dealt with is how to ensure that a good rate of convergence is obtained. <p> We should also mention that since our merit function is non-differentiable, getting fast convergence may necessitate use of a second-order correction or a watch-dog strategy to avoid the Maratos effect. Our computational experience <ref> [18, 4] </ref> indicates that use of a second-order correction can be an efficient strategy for this purpose. Acknowledgements. The authors are thankful to Clovis Gonzaga and Sanjay Mehro-tra for numerous discussions on interior point methods that help guide this work.
Reference: [5] <author> R.H. Byrd, G. Liu and J. </author> <title> Nocedal (1997). "On the Local Behavior of an Interior Point Method for Nonlinear Programming", in Numerical Analysis 1997, </title> <editor> D.F. Griffiths and D.J. Higham, eds, pp.37-56, </editor> <publisher> Addison Wesley Longman. </publisher>
Reference-contexts: Another question to be dealt with is how to ensure that a good rate of convergence is obtained. This requires, among other things, a careful strategy for updating the barrier parameter and deciding how accurately to solve the barrier subproblems <ref> [5] </ref>. We should also mention that since our merit function is non-differentiable, getting fast convergence may necessitate use of a second-order correction or a watch-dog strategy to avoid the Maratos effect.
Reference: [6] <author> R.H. Byrd, R.B. Schnabel, </author> <title> and G.A. Schultz (1987). "A trust region algorithm for nonlinearly constrained optimization". </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> Vol. 24, </volume> <pages> pp. 1152-1170. </pages>
Reference-contexts: It is well known [26] that the constraints in (1:16) can be incompatible since the steps d satisfying the linear constraints may not lie within the trust region. Several strategies have been proposed to make the constraints consistent <ref> [7, 6, 24] </ref>, and in this paper we follow the approach of Byrd [3] and Omojokun [20], which we have found suitable for solving large problems [18].
Reference: [7] <author> M.R. Celis, J.E. Dennis, and R.A. </author> <title> Tapia (1985). "A trust region strategy for nonlinear equality constrained optimization", in Numerical Optimization 1984, P.T. Boggs, R.H. Byrd, </title> <editor> R.B. Schnabel, eds., </editor> <publisher> SIAM, Philadelphia, </publisher> <pages> pp. 71-82. </pages>
Reference-contexts: It is well known [26] that the constraints in (1:16) can be incompatible since the steps d satisfying the linear constraints may not lie within the trust region. Several strategies have been proposed to make the constraints consistent <ref> [7, 6, 24] </ref>, and in this paper we follow the approach of Byrd [3] and Omojokun [20], which we have found suitable for solving large problems [18].
Reference: [8] <author> T.F. Coleman and Y. </author> <month> Li </month> <year> (1993). </year> <title> "An interior trust region approach for nonlinear minimization subject to bounds", </title> <type> Tech. Rep. </type> <institution> TR93-1342, Department of Computer Science, Cornell University, </institution> <note> to appear in SIAM Journal on Optimization. </note>
Reference-contexts: Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li <ref> [8] </ref>, Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25). In some of these studies r 2 xx L is either assumed positive definite on the whole space or a subspace, or is modified to be so.
Reference: [9] <author> J.E. Dennis, M. Heinkenschloss, </author> <title> and L.N. Vicente (1994). "Trust-region interior-point SQP algorithms for a class of nonlinear programming problems", </title> <type> Tech. Report TR94-45, </type> <institution> Department of Computational and Applied Mathematics, Rice University. </institution>
Reference-contexts: Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente <ref> [9] </ref>, have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25). In some of these studies r 2 xx L is either assumed positive definite on the whole space or a subspace, or is modified to be so.
Reference: [10] <author> A.S. El-Bakry, R.A. Tapia, T. Tsuchiya, and Y. </author> <title> Zhang (1995). "On the formulation and theory of the Newton interior-point method for nonlinear programming". </title> <journal> J. Optim. Theory App. </journal> <volume> 89, </volume> <pages> pp. 507-545. </pages>
Reference-contexts: We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang <ref> [10] </ref>, Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [11] <author> R. </author> <title> Fletcher (1987). Practical Methods of Optimization (second edition). </title> <publisher> John Wiley & Sons (New York). </publisher>
Reference-contexts: 1 Introduction Sequential Quadratic Programming (SQP) methods have proved to be very efficient for solving medium-size nonlinear programming problems <ref> [12, 11] </ref>. They require few iterations and function evaluations, but since they need to solve a quadratic subproblem at every step, the cost of their iteration is potentially high for problems with large numbers of variables and constraints. <p> : (1.7) To facilitate the derivation of the new algorithm we define z = x ! m X ln s (i) ; (1.8) and rewrite the barrier problem (1.2) as min '(z) subject to c (z) = 0: (1.10) We now apply the sequential quadratic programming method (see for example <ref> [12, 11] </ref>) to this problem. <p> We now digress to discuss the relationship between our approach and other interior point methods. This discussion makes use of the well-known fact that Sequential Quadratic Programming, in at least one formulation, is equivalent to Newton's method applied to the optimality conditions of a nonlinear program <ref> [11] </ref>. 1.1 KKT systems The KKT conditions for the equality constrained barrier problem (1.2) give rise to the following system of nonlinear equations in x; s; (see (1.4), (1.5)) 0 @ S 1 e + 1 A = 0: (1.22) Applying Newton's method to this system we obtain the iteration 0
Reference: [12] <author> P. E. Gill, W. Murray, and M. H. </author> <title> Wright (1981). Practical Optimization. </title> <publisher> Academic Press (London). </publisher>
Reference-contexts: 1 Introduction Sequential Quadratic Programming (SQP) methods have proved to be very efficient for solving medium-size nonlinear programming problems <ref> [12, 11] </ref>. They require few iterations and function evaluations, but since they need to solve a quadratic subproblem at every step, the cost of their iteration is potentially high for problems with large numbers of variables and constraints. <p> : (1.7) To facilitate the derivation of the new algorithm we define z = x ! m X ln s (i) ; (1.8) and rewrite the barrier problem (1.2) as min '(z) subject to c (z) = 0: (1.10) We now apply the sequential quadratic programming method (see for example <ref> [12, 11] </ref>) to this problem.
Reference: [13] <author> C.C. </author> <title> Gonzaga (1992). "Path-following methods for linear programming". </title> <journal> SIAM Review, </journal> <volume> Vol. 34, </volume> <pages> pp. 167-224. </pages>
Reference-contexts: Following the strategy of interior point methods (see for example <ref> [13, 28, 19] </ref>) we associate with (1.1) the following barrier problem in the variables x and s min f (x) i=1 subject to g (x) + s = 0; (1.2) where &gt; 0 and where the vector of slack variables s = (s (1) ; : : : ; s (m)
Reference: [14] <author> S. </author> <title> Granville (1994). "Optimal reactive dispatch through interior point methods". </title> <journal> IEEE Transactions on Power Systems, </journal> <volume> Vol. 9, </volume> <pages> pp. 136-146. </pages>
Reference-contexts: Preliminary computational experience with simple adaptations of primal-dual interior point methods have given encouraging results on some classes on nonlinear problems (see for example <ref> [27, 14, 29, 1] </ref>). In this paper we describe and analyze an algorithm for large-scale nonlinear programming that uses ideas from interior point methods and sequential quadratic programming.
Reference: [15] <author> J. </author> <title> Herskovits (1993). "An interior points technique for nonlinear optimization". </title> <type> Technical Report, </type> <institution> COPPE, Federal University of Rio de Janeiro. </institution>
Reference-contexts: We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits <ref> [15] </ref>, Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [16] <author> M.B. </author> <month> Hribar </month> <year> (1997). </year> <title> "Methods for Large-Scale Nonlinear Programming and Nonlinear Systems of Equations", </title> <type> Ph.D. Dissertation, </type> <institution> EECS Department, Northwestern University. </institution>
Reference-contexts: In this paper we have focused on primal methods because they are easier to analyze and we have devoted much attention to their global convergence properties because the analysis provides important clues on how to design the algorithms. Computational experience with the primal interior point method is given in <ref> [16, 4] </ref>; those papers also provide computational results with primal-dual methods. Another question to be dealt with is how to ensure that a good rate of convergence is obtained.
Reference: [17] <author> F. Jarre and M. </author> <title> Saunders (1995). "A Practical Interior-point Method for Convex Programming". </title> <journal> SIAM Journal on Optimization, </journal> <volume> Vol. 5, </volume> <pages> pp. 149-171. </pages>
Reference-contexts: We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits [21], Yamashita [27], Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders <ref> [17] </ref>, El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [18] <author> M. Lalee, J. Nocedal, and T. </author> <month> Plantenga </month> <year> (1993). </year> <title> "On the Implementation of an Algorithm for Large-Scale Equality Constrained Optimization". </title> <institution> Northwestern University, EECS Dept., </institution> <type> Rep. NAM 08, </type> <note> to appear in SIAM Journal on Optimization. 35 </note>
Reference-contexts: Several strategies have been proposed to make the constraints consistent [7, 6, 24], and in this paper we follow the approach of Byrd [3] and Omojokun [20], which we have found suitable for solving large problems <ref> [18] </ref>. The strategy of Byrd and Omojokun consists of first taking a normal (or transversal) step v that lies well inside the trust region and that attempts to satisfy the linear constraints in (1.16) as well as possible. <p> Lalee, Nocedal and Plantenga <ref> [18] </ref> describe direct and iterative methods for approximately solving (1:18) when the number of variables is large. <p> x = v x ; u s = S 1 so that problem (2:6) becomes min kg k + s k + A &gt; s.t. k (u x ; u s )k ~ k (2.9) In the case where the lower bound constraints are inactive it is straightforward to show <ref> [18] </ref> that (2:9) has a solution in the range of S k : (2.10) Even when the lower bounds are active, keeping u in the range of (2:10) will prevent u from being unreasonably long, and in the implementation of the new method described in [4], u is chosen always in <p> We should also mention that since our merit function is non-differentiable, getting fast convergence may necessitate use of a second-order correction or a watch-dog strategy to avoid the Maratos effect. Our computational experience <ref> [18, 4] </ref> indicates that use of a second-order correction can be an efficient strategy for this purpose. Acknowledgements. The authors are thankful to Clovis Gonzaga and Sanjay Mehro-tra for numerous discussions on interior point methods that help guide this work.
Reference: [19] <author> I.J. Lustig, R.E. Marsten, and D.F. </author> <title> Shanno (1994). "Interior point methods for linear programming: Computational state of the art". </title> <journal> ORSA Journal on Computing, </journal> <volume> 6, </volume> <pages> pp. 1-14. </pages>
Reference-contexts: Following the strategy of interior point methods (see for example <ref> [13, 28, 19] </ref>) we associate with (1.1) the following barrier problem in the variables x and s min f (x) i=1 subject to g (x) + s = 0; (1.2) where &gt; 0 and where the vector of slack variables s = (s (1) ; : : : ; s (m)
Reference: [20] <author> E.O. </author> <month> Omojokun </month> <year> (1991). </year> <title> "Trust region algorithms for optimization with nonlinear equality and inequality constraints", </title> <type> Ph.D dissertation, </type> <institution> University of Colorado. </institution>
Reference-contexts: Several strategies have been proposed to make the constraints consistent [7, 6, 24], and in this paper we follow the approach of Byrd [3] and Omojokun <ref> [20] </ref>, which we have found suitable for solving large problems [18]. The strategy of Byrd and Omojokun consists of first taking a normal (or transversal) step v that lies well inside the trust region and that attempts to satisfy the linear constraints in (1.16) as well as possible.
Reference: [21] <author> E.R. Panier, A.L. Tits, and J.N. </author> <title> Herskovits (1988). "A QP-free, globally convergent, locally superlinearly convergent algorithm for inequality constrained optimization". </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> Vol. 26, </volume> <pages> pp. 788-811. </pages>
Reference-contexts: We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits <ref> [21] </ref>, Yamashita [27], Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [22] <author> T.D. </author> <month> Plantenga </month> <year> (1995). </year> <title> "A trust region method for nonlinear programming based on primal interior point techniques", </title> <note> to appear in SIAM J. Scient. Computing. </note>
Reference-contexts: For example, B could be updated by the BFGS or SR1 quasi-Newton formulae. This generality is possible by the trust region framework described in the previous section. Plantenga <ref> [22] </ref> describes an algorithm that has some common features with the algorithm presented here, but his approach has also important differences.
Reference: [23] <author> M.J.D. </author> <title> Powell (1975). "Convergence properties of a class of minimization algorithms", in Nonlinear Programming 2, </title> <editor> O. Mangasarian, R. Meyer, S. Robinson, </editor> <booktitle> eds., </booktitle> <pages> pp. 1-27. </pages>
Reference-contexts: First we will find it useful to establish this generalization of the one-dimensional version of a result by Powell <ref> [23] </ref>. Lemma 2.1. Consider the one dimensional problem min (z) 1 s.t. z t; where b 0 and t &gt; 0. Then the optimal value fl satisfies fl 2 b Proof. Consider first the case when a &gt; 0. Then b a 0 is the unconstrained minimizer of .
Reference: [24] <author> M.J.D. Powell and Y. </author> <title> Yuan (1991). "A trust region algorithm for equality constrained optimization". </title> <journal> Mathematical Programming, Series A, </journal> <volume> Vol. 49, </volume> <pages> pp. 189-211. </pages>
Reference-contexts: It is well known [26] that the constraints in (1:16) can be incompatible since the steps d satisfying the linear constraints may not lie within the trust region. Several strategies have been proposed to make the constraints consistent <ref> [7, 6, 24] </ref>, and in this paper we follow the approach of Byrd [3] and Omojokun [20], which we have found suitable for solving large problems [18].
Reference: [25] <author> T. </author> <title> Steihaug (1993). "The conjugate gradient method and trust regions in large scale optimization". </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> Vol. 20, </volume> <pages> pp. 626-637. </pages>
Reference-contexts: Both conditions are also satisfied if the step is chosen by truncated conjugate gradient iterations in the variable u on the objective of (2:9) (see Steihaug <ref> [25] </ref>), and the results are transformed back into the original variables. <p> The tangential Cauchy decrease condition is clearly satisfied by the optimal solution of (2:29). It is also satisfied if the step is chosen by truncated conjugate gradient iterations in the variable p on the objective of (2:29) (see Steihaug <ref> [25] </ref>). Note also that since = 0 is a feasible solution to (2:32), hpred k (h k ) 0: (2.33) The following result establishes a lower bound on the tangential predicted reduction hpred k (h k ) for a step satisfying the tangential Cauchy decrease condition. 14 Lemma 2.3.
Reference: [26] <author> A. </author> <title> Vardi (1985). "A trust region algorithm for equality constrained minimization: convergence properties and implementation". </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> Vol. 22, </volume> <pages> pp. 575-591. </pages>
Reference-contexts: It is well known <ref> [26] </ref> that the constraints in (1:16) can be incompatible since the steps d satisfying the linear constraints may not lie within the trust region.
Reference: [27] <author> H. </author> <title> Yamashita (1992). "A globally convergent primal-dual interior point method for constrained optimization". </title> <type> Technical Report, </type> <institution> Mathematical Systems Institute Inc., </institution> <address> Tokyo, Japan. </address> <note> (Revised in March 1994) </note>
Reference-contexts: Preliminary computational experience with simple adaptations of primal-dual interior point methods have given encouraging results on some classes on nonlinear problems (see for example <ref> [27, 14, 29, 1] </ref>). In this paper we describe and analyze an algorithm for large-scale nonlinear programming that uses ideas from interior point methods and sequential quadratic programming. <p> Therefore the SQP approach (1.11) with W given by (1:13) is equivalent to a primal interior point iteration on the barrier subproblem, under the convexity assumption just stated. Several researchers, including Yamashita <ref> [27] </ref> have noted this relationship. It is also possible to establish a correspondence between primal-dual interior point methods and the SQP approach. <p> We note, however, that much of our analysis could be extended to the primal-dual approach based on (1:27) if appropriate safeguards are applied. Many authors, among them Panier, Tits, and Herskovits [21], Yamashita <ref> [27] </ref>, Her-skovits [15], Anstreicher and Vial [2], Jarre and Saunders [17], El-Bakry, Tapia, Tsuchiya, and Zhang [10], Coleman and Li [8], Dennis, Heinkenschloss and Vicente [9], have proposed interior point methods for nonlinear programming based on iterations of the form (1.23) or (1.25).
Reference: [28] <author> M. H. </author> <title> Wright (1992). "Interior methods for constrained optimization". </title> <booktitle> Acta Numerica 1992, </booktitle> <pages> pp. 341-407. </pages>
Reference-contexts: Following the strategy of interior point methods (see for example <ref> [13, 28, 19] </ref>) we associate with (1.1) the following barrier problem in the variables x and s min f (x) i=1 subject to g (x) + s = 0; (1.2) where &gt; 0 and where the vector of slack variables s = (s (1) ; : : : ; s (m) <p> Since it is not desirable to impede progress of the iteration by employing small trust regions, we explicitly bound the slack variables away from zero by imposing the well-known fraction to the boundary rule <ref> [28] </ref> s + d s (1 t )s; where the parameter t 2 (0; 1) is chosen close to 1.
Reference: [29] <author> Y.-C. Wu, </author> <title> A.S. Debs, and R.E. Marsten (1994). "A direct nonlinear predictor-corrector primal-dual interior point algorithm for optimal power flows". </title> <journal> IEEE Transactions on Power Systems, </journal> <volume> Vol. 9, </volume> <pages> pp. 876-883. 36 </pages>
Reference-contexts: Preliminary computational experience with simple adaptations of primal-dual interior point methods have given encouraging results on some classes on nonlinear problems (see for example <ref> [27, 14, 29, 1] </ref>). In this paper we describe and analyze an algorithm for large-scale nonlinear programming that uses ideas from interior point methods and sequential quadratic programming.
References-found: 29

