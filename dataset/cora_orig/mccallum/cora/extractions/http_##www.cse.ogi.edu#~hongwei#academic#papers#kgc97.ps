URL: http://www.cse.ogi.edu/~hongwei/academic/papers/kgc97.ps
Refering-URL: http://www.cse.ogi.edu/~hongwei/academic/publications.html
Root-URL: http://www.cse.ogi.edu
Email: Email: hwxi@cs.cmu.edu  
Phone: Telephone: +1 412 268-1439 Fax: +1 412 268-6380  
Title: Upper Bounds for Standardizations and an Application  
Author: Hongwei Xi 
Address: 5000 Forbes Avenue Pittsburgh, PA 15213  
Affiliation: Department of Mathematical Sciences Carnegie Mellon University  
Abstract: We first present a new proof for the standardization theorem, a fundamental theorem in -calculus. Since our proof is largely built upon structural induction on lambda terms, we can extract some bounds for the number of fi-reduction steps in the standard fi-reduction sequences obtained from transforming any given fi-reduction sequences. This result sharpens the standardization theorem and establishes a link between lazy and eager evaluation orders in the context of computational complexity. As an application, we establish a superexponential bound for the number of fi-reduction steps in fi-reduction sequences from any given simply typed -terms. 
Abstract-found: 1
Intro-found: 1
Reference: [And71] <author> P.B. </author> <title> Andrews (1971), Resolution in type theory, </title> <journal> J. Symbolic Logic 36, </journal> <pages> pp. 414-432. </pages>
Reference-contexts: In order to get a tighter bound, the key is to find shorter normalization sequences. We start with a weak normalization proof due to Turing according to [Gan80], which can also be found in many other literatures such as <ref> [And71] </ref> and [GLT89]. Definition 23 The rank (T ) of a simple type T is defined as follows. (T ) = 0 if T is atomic; 1 + maxf (T 0 ); (T 1 )g if T = T 0 ! T 1 .
Reference: [Bar76] <editor> H.P. Barendregt et al. </editor> <year> (1976), </year> <title> Some notes on lambda reduction, </title> <type> Preprint No. 22, </type> <institution> University of Utrecht, Department of mathematics, </institution> <note> pp. 13-53. </note>
Reference: [Bar84] <author> H.P. </author> <title> Barendregt (1984), The Lambda Calculus: Its Syntax And Semantics, </title> <publisher> North-Holland publishing company, Amsterdam. </publisher>
Reference-contexts: In fact, a syntactic proof of the sequentiality theorem can be given with the help of the standardization theorem. There have been many proofs of the standardization theorem in the literature such as the ones in [Mit79], [Klo80], <ref> [Bar84] </ref> and [Tak95]. In the presented proof we intend to find a bound for standardizations, namely, to measure the number of steps in the standard fi-reduction sequence obtained from a given fi-reduction sequence. This method presents a concise and more accurate formulation of the standardization theorem. <p> Finally, some related work is mentioned and a few remarks are drawn in Section 6. 2 Preliminaries We give a brief explanation on the notations and terminology used in this paper. Most details not included here appear in <ref> [Bar84] </ref>. <p> Rigorous definitions are omitted here. We assume some basic properties on substitution such as the substitution lemma (Lemma 2.1.16 <ref> [Bar84] </ref>). <p> Proof Please see Section 8.3 <ref> [Bar84] </ref> for proofs. 3 The Proof of Standardization Theorem Standardization theorem of Curry and Feys [CF58] states that any fi-reduction sequence can be standardized in the following sense. <p> Proof The proof proceeds by induction on j s j and the structure of t, lexicographically ordered. By Corollary 8.3.8 <ref> [Bar84] </ref>, t is of form x 1 : : : x m :t 0 (t 1 ) : : : (t n ), where m; n 0, and t 0 is either a variable or an -abstraction. We have two cases. * s + [r] contains no head fi-reduction. <p> we have ([jt]j) &lt; tower (k + 1; j [jt]jj) tower (k + 1; (2k + 3)jtj): This yields (t) &lt; tower (k + 1; (2k + 3)jtj) by Proposition 30 (3). 6 Related Work and Conclusion For those who know the strong equivalence relation ~ = on fi-reductions in <ref> [Bar84] </ref>, originally due to Berry and Levy, it can be verified that ~ = std () for all fi-reduction sequences . There is a short proof of the standardization theorem due to Mitschke [Mit79], which analyses the relation between head and internal fi-reductions.
Reference: [Ber78] <author> G. Berry (1978), Sequentialite de l'evaluation formelle des -expressions, </author> <booktitle> Proc. 3-e Colloque International sur la Programmation, </booktitle> <address> Paris. </address>
Reference-contexts: The importance of lazy evaluation in functional programming languages largely comes from the normalization theorem. Moreover, the standardization theorem can be viewed as a syntactic version of sequentiality theorem in <ref> [Ber78] </ref>. For instance, it can be readily argued that parallel or is inexpressible in -calculus by using the standardization theorem. In fact, a syntactic proof of the sequentiality theorem can be given with the help of the standardization theorem.
Reference: [Chu41] <author> A. Church, </author> <year> (1941), </year> <title> The calculi of lambda conversion, </title> <publisher> Princeton University Press, Princeton. </publisher>
Reference: [CF58] <author> H.B. Curry and R. </author> <title> Feys (1958), Combinatory Logic, </title> <publisher> North-Holland Publishing Company, Am-sterdam. </publisher>
Reference-contexts: 1 Introduction The standardization theorem of Curry and Feys <ref> [CF58] </ref> is a very useful result, stating that if u reduces to v for -terms u and v, then there is a standard fi-reduction from u to v. <p> Proof Please see Section 8.3 [Bar84] for proofs. 3 The Proof of Standardization Theorem Standardization theorem of Curry and Feys <ref> [CF58] </ref> states that any fi-reduction sequence can be standardized in the following sense.
Reference: [dV85] <author> R. </author> <title> de Vrijer (1985), A direct proof of the finite developments theorem, </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 339-343. </pages>
Reference-contexts: As a matter of fact, Theorem 14 can be modified to show that all developments are finite, following the application in the next section. We will not pursue in this direction since the work in <ref> [dV85] </ref> has produced an exact bound for finiteness of developments. Given : t!! fi u, we can also give a bound on jstd ()j in terms of jj and the size of t defined below. <p> It seems in the author's opinion - that such involvedness is not only unnecessary but also obscures the merits in Schwichtenberg's proof. In addition, the proof of finiteness of developments theorem by de Vrijer <ref> [dV85] </ref> yields an exact bound for the lengths of developments, and thus, is casually related to our proof of the standardization theorem with bound. In Gentzen's sequent calculus, there exists a similar bound for the sizes of cut-free proofs obtained from cut elimination.
Reference: [Gan80] <author> R.O. </author> <title> Gandy (1980), An early proof of normalization by A.M. Turing, To: H.B. Curry: Essays on combinatory logic, lambda calculus and formalism, edited by J.P. </title> <editor> Seldin and J.R. Hindley, </editor> <publisher> Academic press, </publisher> <pages> pp. 453-456. </pages>
Reference-contexts: In order to get a tighter bound, the key is to find shorter normalization sequences. We start with a weak normalization proof due to Turing according to <ref> [Gan80] </ref>, which can also be found in many other literatures such as [And71] and [GLT89].
Reference: [Gan80a] <author> R.O. </author> <title> Gandy (1980), Proofs of Strong Normalization, To: H.B. Curry: Essays on Combinatory logic, lambda calculus and formalism, edited by J.P. </title> <editor> Seldin and J.R. Hindley, </editor> <publisher> Academic press, </publisher> <pages> pp. 457-478. </pages>
Reference-contexts: We first show for simply typed -terms t that -(t) is not an elementary. This can bring us some feeling on how tight our upper bound on (t) is. Among various proofs showing the strong normalization property of ! , some proofs such as the ones in <ref> [Gan80a] </ref> and [Sch91] can yield superexponential upper bounds on (t). Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and [Kah95]. <p> This can bring us some feeling on how tight our upper bound on (t) is. Among various proofs showing the strong normalization property of ! , some proofs such as the ones in <ref> [Gan80a] </ref> and [Sch91] can yield superexponential upper bounds on (t). Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. <p> This is a desirable result since (t), the length of a longest fi-reduction sequence from t, can often be used as an induction order in many proofs. Gandy mentions a similar bound in <ref> [Gan80a] </ref> but details were left out. His semantic method, which aims at giving strong normalization proofs, is quite different from ours. Schwichtenberg presents a similar bound in [Sch91] using an approach adopted from [How80].
Reference: [GLM92] <author> G. Gonthier, J.J. Levy and P.-A. </author> <month> Mellies </month> <year> (1992), </year> <title> An abstract standardization theorem, </title> <booktitle> in Proceedings of Logic in Computer Science, </booktitle> <pages> pp. 72-81. </pages>
Reference: [GLT89] <author> J.-Y. Girard et al. </author> <year> (1989), </year> <title> Proofs and types, </title> <publisher> Cambridge Press, </publisher> <pages> 176 pp. </pages>
Reference-contexts: In order to get a tighter bound, the key is to find shorter normalization sequences. We start with a weak normalization proof due to Turing according to [Gan80], which can also be found in many other literatures such as [And71] and <ref> [GLT89] </ref>. Definition 23 The rank (T ) of a simple type T is defined as follows. (T ) = 0 if T is atomic; 1 + maxf (T 0 ); (T 1 )g if T = T 0 ! T 1 .
Reference: [Hue94] <author> Gerard Huet (1994), </author> <title> Residual Theory in -Calculus: A Formal Development, </title> <journal> Journal of Functional Programming Vol. </journal> <volume> 4, </volume> <pages> pp. 371-394. </pages>
Reference-contexts: Before moving forward, let us introduce the concept of residuals of fi-redexes. The rigorous definition of this notion can be found in <ref> [Hue94] </ref>. Let R be a set of fi-redexes in a term t, r = (x:u)(v) in R, and t ! fi t 0 . This fi-reduction step affects fi-redexes r 0 in R in the following way.
Reference: [Hin78] <author> J.R. </author> <title> Hindley (1978), Reductions of residuals are finite, </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 240, </volume> <pages> pp. 345-361. </pages>
Reference: [How80] <author> W. </author> <title> Howard (1980), Ordinal analysis of terms of finite type, </title> <journal> Journal of Symbolic Logic, </journal> <volume> 45(3) </volume> <pages> 493-504. </pages>
Reference-contexts: Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from <ref> [How80] </ref>, which bases on cut elimination in intuitionistic logic. Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound. <p> Gandy mentions a similar bound in [Gan80a] but details were left out. His semantic method, which aims at giving strong normalization proofs, is quite different from ours. Schwichtenberg presents a similar bound in [Sch91] using an approach adopted from <ref> [How80] </ref>. His method of transforming ! -terms into ! I-terms closely relates to our presented method but is very much involved. It seems in the author's opinion - that such involvedness is not only unnecessary but also obscures the merits in Schwichtenberg's proof.
Reference: [Hyl73] <author> J.M.E. </author> <title> Hyland (1973), A simple proof of the Church-Rosser theorem, </title> <publisher> Typescript, Oxford University, </publisher> <pages> 7 pp. </pages>
Reference: [Kah95] <author> Stefan Kahrs (1995), </author> <title> Towards a Domain Theory for Termination Proofs, </title> <institution> Laboratory for Foundation of Computer Science, 95-314, Department of Computer Science, The University of Edinburgh. </institution>
Reference-contexts: Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and <ref> [Kah95] </ref>. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound.
Reference: [Klo80] <author> J.W. </author> <title> Klop (1980), Combinatory reduction systems, </title> <type> Ph.D. thesis, </type> <institution> CWI, Amsterdam, Mathematical center tracts, </institution> <note> No. 127. </note>
Reference-contexts: In fact, a syntactic proof of the sequentiality theorem can be given with the help of the standardization theorem. There have been many proofs of the standardization theorem in the literature such as the ones in [Mit79], <ref> [Klo80] </ref>, [Bar84] and [Tak95]. In the presented proof we intend to find a bound for standardizations, namely, to measure the number of steps in the standard fi-reduction sequence obtained from a given fi-reduction sequence. This method presents a concise and more accurate formulation of the standardization theorem. <p> In this respect, our proof resembles a proof in [Tak95], where Takahashi exploited the notion of parallel fi-reduction to show the termination of the commutation process. There are also two proofs due to Klop <ref> [Klo80] </ref>, to which the present proof bears some connection. Though all these proofs aim at commuting the contracted leftmost fi-redexes to the front, our proof uses a different strategy to show the termination of such commutations.
Reference: [Lev78] <author> J.-J. Levy (1978), </author> <title> Reductions correctes et optimales dans le lambda calcul, </title> <institution> These de doctorat d'etat, Universite Paris VII. </institution>
Reference: [Min79] <author> G.E. </author> <title> Mints (1979), A primitive recursive bound of strong normalization for predicate calculus (in Russian with English abstract), </title> <address> Zapiski Naucnyh Seminarov Leningradskogo Otdelenija Matematiceskogo Instituta im V.A. </address> <publisher> Steklova Akademii Nauk SSSR (LOMI) 88, </publisher> <pages> pp. 131-135. </pages>
Reference-contexts: In Gentzen's sequent calculus, there exists a similar bound for the sizes of cut-free proofs obtained from cut elimination. Mints <ref> [Min79] </ref> (of which I have only learned the abstract) showed a way of computing the maximum length of a fi-reduction from the length of a standard fi-reduction sequence.
Reference: [Mit79] <author> G. </author> <month> Mitschke </month> <year> (1979), </year> <title> The standardization theorem for the -calculus, </title> <journal> Z. Math. Logik Grundlag. Math. </journal> <volume> 25, </volume> <pages> pp. 29-31. </pages>
Reference-contexts: In fact, a syntactic proof of the sequentiality theorem can be given with the help of the standardization theorem. There have been many proofs of the standardization theorem in the literature such as the ones in <ref> [Mit79] </ref>, [Klo80], [Bar84] and [Tak95]. In the presented proof we intend to find a bound for standardizations, namely, to measure the number of steps in the standard fi-reduction sequence obtained from a given fi-reduction sequence. This method presents a concise and more accurate formulation of the standardization theorem. <p> There is a short proof of the standardization theorem due to Mitschke <ref> [Mit79] </ref>, which analyses the relation between head and internal fi-reductions. It shows any fi-reduction sequence can be transformed into one which starts with head fi-reductions followed by internal fi-reductions. In this formulation, it is not easy to extract a bound directly from the proof.
Reference: [Pol94] <author> J. van de Pol (1994), </author> <title> Strict functionals for termination proofs, </title> <booktitle> Lecture Notes in Computer Science 902, edited by J. Heering, </booktitle> <pages> pp. 350-364. </pages>
Reference-contexts: Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], <ref> [Pol94] </ref> and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound.
Reference: [Sta79] <author> Richard Statman (1979), </author> <title> The typed -calculus is not elementary, </title> <booktitle> Theoretical Computer Science 9, </booktitle> <pages> pp. 73-81. </pages>
Reference-contexts: On the other hand, Theorem 22 suggests that a lower bound for (t) have a similar superexponential form, and this makes it a challenging task to sharpen our presented bound for (t), although it seems to be somewhat exaggerated. Also Statman proved that ! is not elementary <ref> [Sta79] </ref>. 7 Acknowledgement I gratefully acknowledge Richard Statman's efforts on reading the paper and providing his comments. I also thank Frank Pfenning and Peter Andrews for their support and for providing me a nice work environment.
Reference: [Sch82] <author> H. </author> <title> Schwichtenberg (1982), Complexity of normalization in the pure typed lambda-calculus, The L.E.J. Brouwer Centenary Symposium, edited by A.S. </title> <editor> Troelstra and D. van Dalen, </editor> <publisher> North-Holland publishing company, </publisher> <pages> pp. 453-457. </pages>
Reference-contexts: Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as <ref> [Sch82] </ref>, [Pol94] and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound.
Reference: [Sch91] <author> H. </author> <title> Schwichtenberg (1991), An upper bound for reduction sequences in the typed lambda-calculus, </title> <journal> Archive for Mathematical Logic, </journal> <volume> 30 </volume> <pages> 405-408. </pages>
Reference-contexts: We first show for simply typed -terms t that -(t) is not an elementary. This can bring us some feeling on how tight our upper bound on (t) is. Among various proofs showing the strong normalization property of ! , some proofs such as the ones in [Gan80a] and <ref> [Sch91] </ref> can yield superexponential upper bounds on (t). Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. <p> strong normalization property of ! , some proofs such as the ones in [Gan80a] and <ref> [Sch91] </ref> can yield superexponential upper bounds on (t). Gandy invented a semantic approach in [Gan80a], which is called functional interpretations and has its traces in many following papers such as [Sch82], [Pol94] and [Kah95]. In [Sch91], Schwichtenberg adopted a syntactic approach from [How80], which bases on cut elimination in intuitionistic logic. Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound. <p> Compared with other related methods in the literature, our following syntactic method is not only innovative but also yields a quite intelligible and tight bound. It also exhibits a nice way in ! to transform strong normalization into weak normalization, simplifying a much involved transformation in <ref> [Sch91] </ref>. Therefore, the new transformation has its own value in this respect. <p> Gandy mentions a similar bound in [Gan80a] but details were left out. His semantic method, which aims at giving strong normalization proofs, is quite different from ours. Schwichtenberg presents a similar bound in <ref> [Sch91] </ref> using an approach adopted from [How80]. His method of transforming ! -terms into ! I-terms closely relates to our presented method but is very much involved. It seems in the author's opinion - that such involvedness is not only unnecessary but also obscures the merits in Schwichtenberg's proof.
Reference: [Tak95] <author> Masako Takahashi (1995), </author> <title> Parallel Reductions in -Calculus, </title> <booktitle> Information and Computation 118, </booktitle> <pages> pp. 120-127. </pages>
Reference-contexts: In fact, a syntactic proof of the sequentiality theorem can be given with the help of the standardization theorem. There have been many proofs of the standardization theorem in the literature such as the ones in [Mit79], [Klo80], [Bar84] and <ref> [Tak95] </ref>. In the presented proof we intend to find a bound for standardizations, namely, to measure the number of steps in the standard fi-reduction sequence obtained from a given fi-reduction sequence. This method presents a concise and more accurate formulation of the standardization theorem. <p> Unlike many earlier proofs in the literature, our proof of the standardization theorem does not use the finiteness of developments theorem (FD). In this respect, our proof is similar to the one in <ref> [Tak95] </ref>. We remark that the uses of FD in other proofs are inessential in general and can be avoided in proper ways. As a matter of fact, Theorem 14 can be modified to show that all developments are finite, following the application in the next section. <p> Our proof is a variant of Mitschke's proof. Lemma 11 simplifies the process which commutes head fi-reduction with internal fi-reductions, illuminating on why this process halts eventually. In this respect, our proof resembles a proof in <ref> [Tak95] </ref>, where Takahashi exploited the notion of parallel fi-reduction to show the termination of the commutation process. There are also two proofs due to Klop [Klo80], to which the present proof bears some connection.
Reference: [Wad76] <author> C.P. </author> <title> Wadsworth (1976), The relation between computational and denotational properties for Scott's D 1 -models of -calculus, </title> <journal> SIAM Journal of Computing, </journal> <volume> 5(3) </volume> <pages> 488-521. </pages>
Reference: [Xi96a] <author> H. </author> <title> Xi (1996), An induction measure on -terms and its applications, </title> <type> Technical report 96-192, </type> <institution> Department of Mathematical Sciences, Carnegie Mellon University, Pittsburgh. </institution>
Reference: [Xi96b] <author> H. </author> <title> Xi (1996), Separating developments in -calculus, Manuscripts. </title> <type> 12 </type>
References-found: 28

