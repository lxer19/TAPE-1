URL: http://diva.eecs.berkeley.edu/~ljilja/ATM_Forum/ATM_Forum.0194.ps
Refering-URL: http://diva.eecs.berkeley.edu/~ljilja/
Root-URL: 
Email: Email: ljilja@thumper.bellcore.com  
Phone: Phone: 201 829-4531 FAX: 201 829-2504  
Title: ATM FORUM: Technical Committee Working Group ATM Forum/94-0077 (TM SWG) SOURCE: Bellcore DISTRIBUTION TO: ATM
Author: Ljiljana Trajkovic 
Keyword: TITLE: Buffer Requirements in ATM Networks with Leaky Buckets, FIFOs, and Weighted Fair Queuing Scheduling Mechanisms  
Date: January 17-20, 1994  
Note: DATE:  NOTICE  
Address: St. Morristown, NJ 07962-1910  
Affiliation: 445 South  
Abstract: In this contribution we present two studies on buffer allocation requirements in ATM networks. We first illustrate, by constructing a worst case deterministic scenario, that the buffer allocation requirements at various hops through the network may grow unexpectedly high if no cell loss is required even if the traffic patterns entering an ATM network are well regulated and conform to the agreed rates. We then present simulation examples comparing per VC buffer overflows in a node with FIFO and a node with a Weighted Fair Queueing (WFQ) scheme. Our simulation results illustrate that the WFQ scheme distributes losses (due to finite buffers) among traffic streams of various burstiness more fairly than the FIFO scheme. This contribution has been prepared to assist the ATM Forum. This document is offered to the ATM Forum as a basis for discussion and is not a binding proposal on Bell Communications Research, Inc. (Bellcore) or its clients. The statements are subject to change in form and content after more study. Bellcore specifically reserves the right to add to, amend, or withdraw the statements contained herein. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Kurose, </author> <title> "Open Issues and Challenges in Providing Quality of Service Guarantees in High-Speed Networks," </title> <address> CCR, </address> <month> Jan. </month> <year> 1993, </year> <pages> pp. 6-15. </pages>
Reference-contexts: 1 Introduction High speed packet networks will support diverse traffic such as voice, data, image, and real time video. In such a heterogeneous environment, different services will demand a range of Quality of Services (QoS) <ref> [1] </ref>. Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter.
Reference: [2] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> "Analysis and Simulation of a Fair Queueing Algorithm," </title> <booktitle> Proc. ACM SIGCOMM 89, </booktitle> <month> Sept. </month> <year> 1989, </year> <journal> Computer Communications Review, </journal> <volume> vol. 19, no. 4, </volume> <year> 1989, </year> <pages> pp. 1-12, </pages> <note> and Journal of Internetworking Research and Experience, </note> <month> Sept. </month> <year> 1990, </year> <pages> pp. 3-26. </pages>
Reference-contexts: Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter. One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) <ref> [2] </ref>, [3], [4], [5], [6], [7], [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations.
Reference: [3] <author> D. Ferrari and D. C. Verma, </author> <title> "A Scheme for Real-Time Channel Establishment in Wide-Area Networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> April </month> <year> 1990, </year> <pages> pp 368-379. </pages>
Reference-contexts: Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter. One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], <ref> [3] </ref>, [4], [5], [6], [7], [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations.
Reference: [4] <author> S. J. Golestani, </author> <title> "A Stop-and-Go Queueing Framework for Congestion Management," </title> <booktitle> Proc. ACM SIGCOMM 90, </booktitle> <address> Sept. 1990, Philadelphia, PA, </address> <pages> pp. 8-18. </pages>
Reference-contexts: Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter. One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], <ref> [4] </ref>, [5], [6], [7], [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. <p> The ATM network will support video, image, voice, and data traffic that will require vastly different bandwidths, and will, therefore, require substantial buffering for a zero loss QoS [13], <ref> [4] </ref>, [5]. For example, in the case of MUXing a video application requiring 74.88 Mbps and a voice application requiring 64 Kbps bandwidth, we can calculate that the buffer allocation required for zero loss service. The calculation is performed by following the same argument as illustrated in the above example.
Reference: [5] <author> S. J. Golestani, </author> <title> "A Framing Strategy for Congestion Management," </title> <journal> IEEE JSAC, </journal> <volume> vol. 9, no. 7, </volume> <pages> pp. 1064-1077, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter. One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], <ref> [5] </ref>, [6], [7], [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA). <p> The ATM network will support video, image, voice, and data traffic that will require vastly different bandwidths, and will, therefore, require substantial buffering for a zero loss QoS [13], [4], <ref> [5] </ref>. For example, in the case of MUXing a video application requiring 74.88 Mbps and a voice application requiring 64 Kbps bandwidth, we can calculate that the buffer allocation required for zero loss service. The calculation is performed by following the same argument as illustrated in the above example.
Reference: [6] <author> D. C. Verma, H. Zhang, and D. Ferrari, </author> <title> "Delay Jitter Control for Real-Time Communications in a Packet Switching Network," </title> <booktitle> Proc. TriComm '91, </booktitle> <address> Chapel Hill, NC, </address> <month> April </month> <year> 1991, </year> <pages> pp. 35-43. </pages>
Reference-contexts: Some applications require no packet loss, while others are sensitive to packet delay or to packet delay-jitter. One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], [5], <ref> [6] </ref>, [7], [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA).
Reference: [7] <author> L. Zhang, "VirtualClock: </author> <title> A New Traffic Control Algorithm for Packet Switching Networks," </title> <booktitle> Proc. SIGCOMM 90, </booktitle> <address> Philadelphia, PA, </address> <month> Sept. </month> <pages> 24-27, </pages> <year> 1990, </year> <pages> pp. 19-29. </pages>
Reference-contexts: One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], [5], [6], <ref> [7] </ref>, [8], [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA).
Reference: [8] <author> C. R. Kalmanek and H. Kanakia, </author> <title> "Rate Controlled Servers for Very High-Speed Networks," </title> <booktitle> Proc. GLOBECOM, </booktitle> <address> San Diego, CA, </address> <month> Dec. </month> <year> 1990, </year> <pages> pp. 12-20. 4 </pages>
Reference-contexts: One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], [5], [6], [7], <ref> [8] </ref>, [9], [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA).
Reference: [9] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A Generalized Processor Sharing Approach to Flow Con--trol in Integrated Services Networks|The Single Node Case," </title> <booktitle> Proc. IEEE INFOCOM '92, </booktitle> <address> Florence, Italy, </address> <month> May </month> <year> 1992, </year> <pages> pp. 915-924. </pages>
Reference-contexts: One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], [5], [6], [7], [8], <ref> [9] </ref>, [10]. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA).
Reference: [10] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks|The Multiple Node Case," </title> <booktitle> Proc. IEEE INFOCOM '93, </booktitle> <address> San Francisco, </address> <month> May </month> <year> 1993, </year> <pages> pp. 521-530. </pages>
Reference-contexts: One of the goals of a good admission control scheme for ATM 1 networks is to guarantee contracted performance for heterogeneous services while optimally using network resources (bandwidth) [2], [3], [4], [5], [6], [7], [8], [9], <ref> [10] </ref>. An ATM network with guaranteed QoS may support Virtual Channels of various bandwidth allocations. We assume that the sources on the outskirts of the network have pre-shaped traffic patterns that conform to the Connection Traffic Descriptor specified by the Generic Cell Rate Algorithm (GCRA).
Reference: [11] <author> CCITT, </author> <title> "Recommendation I.371: Traffic Control and Congestion Control in B-ISDN," </title> <address> Geneva, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: One ATM layer QoS that a network will provide is guaranteed service. This service will guaranty agreed upon low losses for customers who adhere to agreed Peak Cell Rates (PCR) defined by the GCRA <ref> [11] </ref>, [12].
Reference: [12] <author> The ATM Forum, </author> <title> "ATM User-Network Interface Specification," </title> <note> Version 2.2, June 21, </note> <year> 1993. </year>
Reference-contexts: One ATM layer QoS that a network will provide is guaranteed service. This service will guaranty agreed upon low losses for customers who adhere to agreed Peak Cell Rates (PCR) defined by the GCRA [11], <ref> [12] </ref>.
Reference: [13] <author> A. I. Elwalid and D. Mitra, </author> <title> "Analysis and Design of Rate-Based Congestion Control of High Speed Networks, I: Stochastic Fluid Models, Access Regulation," </title> <journal> Queueing Systems, </journal> <volume> vol. 9, </volume> <year> 1991, </year> <pages> pp. 29-64. </pages>
Reference-contexts: The ATM network will support video, image, voice, and data traffic that will require vastly different bandwidths, and will, therefore, require substantial buffering for a zero loss QoS <ref> [13] </ref>, [4], [5]. For example, in the case of MUXing a video application requiring 74.88 Mbps and a voice application requiring 64 Kbps bandwidth, we can calculate that the buffer allocation required for zero loss service.
Reference: [14] <author> J. S. Turner, </author> <title> "New Directions in Communications (or Which Way to the Information Age?)," </title> <journal> IEEE Comm. Magazine, Oct. 1986, </journal> <volume> Vol. 24, No. 10, </volume> <month> pp.8-15. </month>
Reference-contexts: The sources on the outskirts of the network have shaped traffic patterns with parameters that conform to a leaky bucket <ref> [14] </ref> traffic control scheme. We show that the buffer allocation requirements at various hops through the network may grow unexpectedly high for a zero loss QoS even if the traffic entering the network is well regulated and conforms to the agreed rates.
Reference: [15] <author> A. Fraser, </author> <title> "Designing a Public Data Network," </title> <journal> IEEE Comm. Magazine, </journal> <month> Oct. </month> <year> 1991, </year> <pages> pp. 31-35. </pages>
Reference-contexts: Interleaving fast and slow cells in the MUXing points would prevent clustering of fast cells. This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) <ref> [15] </ref>, [16], [17], [18], [19], [20] of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5.
Reference: [16] <author> E. L. Hahne, C. R. Kalmanek, and S. P. Morgan, </author> <title> "Fairness and Congestion Control on a Large ATM Data Network With Dynamically Adjustable Windows," Proceedings Telletraffic and Datatraffic, in a Period of Change, </title> <editor> ITC-13, A. Jensen and V. B. Iversen (Eds.), </editor> <publisher> North-Holland, </publisher> <year> 1991, </year> <pages> pp. 867-872. </pages>
Reference-contexts: Interleaving fast and slow cells in the MUXing points would prevent clustering of fast cells. This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) [15], <ref> [16] </ref>, [17], [18], [19], [20] of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5.
Reference: [17] <author> S. Floyd, </author> <title> "Congestion with Multiple Congested Gateways in Packet-Switched Networks, Part I: One-Way Traffic," </title> <address> CCR, </address> <month> Oct. </month> <year> 1991, </year> <pages> pp. 30-47. </pages>
Reference-contexts: Interleaving fast and slow cells in the MUXing points would prevent clustering of fast cells. This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) [15], [16], <ref> [17] </ref>, [18], [19], [20] of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5.
Reference: [18] <author> S. Floyd and V. Jacobson, </author> <title> "Random Early Detection Gateways for Congestion Avoidance," </title> <note> available by anonymous ftp from ftp.ee.lbl.gov. </note>
Reference-contexts: Interleaving fast and slow cells in the MUXing points would prevent clustering of fast cells. This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) [15], [16], [17], <ref> [18] </ref>, [19], [20] of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5. Each source generates bursty traffic, with a geometric distribution of active and idle periods.
Reference: [19] <author> T. E. Anderson, S. S. Owicki, J. B. Saxe, and C. P. Thacker, </author> <title> "High Speed Switch Scheduling for Local Area Networks," </title> <booktitle> Proceedings ASPLOS 92, </booktitle> <year> 1992, </year> <pages> pp. 98-110. </pages>
Reference-contexts: Interleaving fast and slow cells in the MUXing points would prevent clustering of fast cells. This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) [15], [16], [17], [18], <ref> [19] </ref>, [20] of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5. Each source generates bursty traffic, with a geometric distribution of active and idle periods.
Reference: [20] <author> D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting Real-Time Applications in an Integrated Services Packet Network: Architecture and Mechanisms," </title> <booktitle> ACM Proc. SIGCOMM 92, </booktitle> <address> Baltimore, MA, </address> <year> 1992, </year> <pages> pp. </pages> <month> 14-26. </month> <title> stream and multiple (five) B streams. Time scale arbitrarily starts at t 1 in increments of one cell time for stream A (5.66 sec). 6 time for stream L (2.83 sec). 7 arrows show the buffering process of arriving cells before they can be transmitted. Time scale starts at t 3 in increments of one cell time for stream L (2.83 sec). </title> <type> 8 9 10 11 12 13 14 </type>
Reference-contexts: This, in turn, will alleviate the need for buffering the fast cells in the DMUX network pints. One way to implement such interleaving would be a Weighted Fair Queueing (WFQ) [15], [16], [17], [18], [19], <ref> [20] </ref> of cells belonging to VCs of different bandwidths. 4 Simulation of FIFO and WFQ Schemes in a Network with Bursty Traffic We simulated a network node with ten sources shown in Figure 5. Each source generates bursty traffic, with a geometric distribution of active and idle periods.
References-found: 20

