URL: ftp://ftp.cs.arizona.edu/reports/1995/TR95-01.ps.Z
Refering-URL: http://www.cs.arizona.edu/people/filament/hpfc.html
Root-URL: http://www.cs.arizona.edu
Title: fsc: A Sisal Compiler for Both Distributed- and Shared-Memory Machines  
Author: Vincent W. Freeh Gregory R. Andrews 
Note: TR 95-01  
Abstract-found: 0
Intro-found: 1
Reference: [Can92a] <author> David Cann. </author> <title> Retire Fortran? A debate rekindled. </title> <journal> CACM, </journal> <volume> 35(8) </volume> <pages> 81-89, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The main challenges are to implement functional programs both efficiently and portably on a variety of machines. Sisal is a functional language [M + 85] that has proven useful for programming numerically intensive scientific applications, especially parallel applications <ref> [Can92a] </ref>. The optimizing Sisal compiler, osc, creates code for many different shared-memory and vector processors (e.g., SGI, Sequent, Encore Multimax, Cray X-MP, and Cray 2) [Can92b]. It does not, however, create code for distributed-memory machines.
Reference: [Can92b] <author> David C. Cann. </author> <title> The optimizing SISAL compiler. </title> <type> Report UCRL-MA-110080, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Sisal is a functional language [M + 85] that has proven useful for programming numerically intensive scientific applications, especially parallel applications [Can92a]. The optimizing Sisal compiler, osc, creates code for many different shared-memory and vector processors (e.g., SGI, Sequent, Encore Multimax, Cray X-MP, and Cray 2) <ref> [Can92b] </ref>. It does not, however, create code for distributed-memory machines. This paper describes a prototype compiler, fsc, that supports distributed-memory multiprocessors as well as other machines. <p> Because an expression can be evaluated as soon as all its operands have been determined, the compiler can schedule expression evaluation in any order|including concurrently|that preserves the data dependencies. Version 12 of the optimizing Sisal compiler (osc) creates efficient code for execution on various sequential, vector, and shared-memory machines <ref> [Can92b] </ref>. (This compiler does not support distributed memory, although the majority of the new supercomputers have distributed memory architectures.) The osc compiler translates Sisal source into C or Fortran code, which is then linked with the osc runtime system.
Reference: [EAL93] <author> Dawson R. Engler, Gregory R. Andrews, and David K. Lowenthal. </author> <title> Shared Filaments: Efficient support for fine-grain parallelism on shared-memory multiprocessors. </title> <type> TR 93-13, </type> <institution> Dept. of Computer Science, University of Arizona, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: It does so by modifying the back end of osc to use the Filaments package, a subroutine library that provides efficient fine-grain parallelism and a shared-memory programming model using only standard hardware and software <ref> [EAL93, FLA94] </ref>. Additionally, the prototype supports recursive parallelism, which is not supported by osc even though it is implicitly available in Sisal itself. The prototype was produced in about three months of work by a single programmer. <p> It has been designed to support parallel scientific applications and is intended to be a target for a compiler. The package is relatively small (less than 7,000 lines of C code), simple (about 20 subroutine calls), and efficient <ref> [EAL93, FLA94] </ref>. Filaments has two key abstractions: fine-grain threads and shared memory. The fine-grain execution model can be thought of as the least common denominator for concurrency, because it supports coarse- and medium-grain tasks as well as fine-grain ones. <p> Third, the package employs techniques such as inlining and pruning to reduce the overhead of executing filaments. Finally, a reliable datagram protocol is used to reduce buffering and copying of message data (DSM pages) and to provide scalability. These features are discussed below and discussed in detail in <ref> [EAL93] </ref> and [FLA94]. A filament does not have a private stack; it consists only of a code pointer and state (usually just the arguments). Consequently, context-switching is inexpensive, filaments can be created quickly, and very little space is used. <p> Like fsc, the P-RISC model uses fine-grain execution. However, it uses a distributed-memory model and hence explicit communication; also, it has not been implemented. There is a lot of work regarding fine-grain parallelism and distributed shared memory systems that is related to the Filaments package. See <ref> [EAL93, FLA94] </ref> for details. 9 6 Conclusions The fsc prototype was created in a very short time (approximately three person-months). Unlike osc, it executes on distributed-memory machines as well as shared-memory machines. The Filaments package provides this architecture-independence. <p> Performance of many of the test programs is very good. However, fsc does not perform as well as expected, particularly in the Jacobi iteration tests. Previously, we have demonstrated that a hand-coded Filaments program can execute these applications efficiently on a shared-memory multiprocessor <ref> [EAL93] </ref> and a cluster of workstations [FLA94]. Therefore, we believe poor performance is not an inherent limitation of the approach. Acknowledgements Dave Lowenthal gave much advice and encouragement during the project. Then he spent many hours reviewing the paper and provided many invaluable comments.
Reference: [FCO90] <author> John T. Feo, David C. Cann, and Rodney R. Oldehoeft. </author> <title> A report on the SISAL language project. </title> <journal> J. of Par. and Dist. Computing, </journal> <volume> 10(4) </volume> <pages> 349-366, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The Filaments protocol eliminates at least three copies relative to TCP|two on sending and one on receiving|because TCP buffers all messages. 2 3 Details of the fsc Compiler Sisal is a general purpose functional language <ref> [FCO90] </ref>. It is probably best described as a dataflow language because the order of program execution is determined not by the static ordering of expressions in the source code but rather by the availability of the data.
Reference: [FLA94] <author> Vincent W. Freeh, David K. Lowenthal, and Gregory R. Andrews. </author> <title> Distributed Filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <booktitle> In First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 201-213, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: It does so by modifying the back end of osc to use the Filaments package, a subroutine library that provides efficient fine-grain parallelism and a shared-memory programming model using only standard hardware and software <ref> [EAL93, FLA94] </ref>. Additionally, the prototype supports recursive parallelism, which is not supported by osc even though it is implicitly available in Sisal itself. The prototype was produced in about three months of work by a single programmer. <p> It has been designed to support parallel scientific applications and is intended to be a target for a compiler. The package is relatively small (less than 7,000 lines of C code), simple (about 20 subroutine calls), and efficient <ref> [EAL93, FLA94] </ref>. Filaments has two key abstractions: fine-grain threads and shared memory. The fine-grain execution model can be thought of as the least common denominator for concurrency, because it supports coarse- and medium-grain tasks as well as fine-grain ones. <p> Finally, a reliable datagram protocol is used to reduce buffering and copying of message data (DSM pages) and to provide scalability. These features are discussed below and discussed in detail in [EAL93] and <ref> [FLA94] </ref>. A filament does not have a private stack; it consists only of a code pointer and state (usually just the arguments). Consequently, context-switching is inexpensive, filaments can be created quickly, and very little space is used. On each processor a server thread executes filaments, one at a time. <p> The fsc program implicitly transmits one page (4096 bytes) of data to each neighbor using two messages per neighbor. This is not an inherent limitation of the approach, because a hand-coded Filaments program performs within 10% of the C program <ref> [FLA94] </ref>. 4.3 Adaptive Quadrature Adaptive quadrature approximates the integral Z b f (x)dx by dividing the interval into subintervals. The area of each subinterval is approximated (using a method like the trapezoidal rule), then the approximations are added together to obtain the approximation for the area of the entire interval. <p> Like fsc, the P-RISC model uses fine-grain execution. However, it uses a distributed-memory model and hence explicit communication; also, it has not been implemented. There is a lot of work regarding fine-grain parallelism and distributed shared memory systems that is related to the Filaments package. See <ref> [EAL93, FLA94] </ref> for details. 9 6 Conclusions The fsc prototype was created in a very short time (approximately three person-months). Unlike osc, it executes on distributed-memory machines as well as shared-memory machines. The Filaments package provides this architecture-independence. <p> Performance of many of the test programs is very good. However, fsc does not perform as well as expected, particularly in the Jacobi iteration tests. Previously, we have demonstrated that a hand-coded Filaments program can execute these applications efficiently on a shared-memory multiprocessor [EAL93] and a cluster of workstations <ref> [FLA94] </ref>. Therefore, we believe poor performance is not an inherent limitation of the approach. Acknowledgements Dave Lowenthal gave much advice and encouragement during the project. Then he spent many hours reviewing the paper and provided many invaluable comments.
Reference: [Gol88] <author> Benjamin Goldberg. </author> <title> Multiprocessor execution of functional programs. </title> <journal> International J. of Parallel Programming, </journal> <volume> 17(5) </volume> <pages> 425-473, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Data are transferred between processors using explicit communication operations. Significant analysis is required both to insert and minimize the communication between processors. Two systems for executing ALFL programs on shared- and distributed-memory machines are described in <ref> [Gol88] </ref>. An ALFL program and its data are represented as a graph. In these systems a graph reduction "engine" exhaustively applies "reductions" to the nodes in the graph. The shared-memory system has nearly linear speedup; the distributed-memory system gets very poor speedup.
Reference: [HB92] <author> Matthew Haines and Wim Bohm. </author> <title> Software multithreading in a conventional distributed memory multiprocessor. </title> <type> Technical Report CS-92-126, </type> <institution> Colorado State University, </institution> <month> Septem-ber </month> <year> 1992. </year>
Reference-contexts: Compared to the osc time, the speedup is not super-linear. 5 Related Work Two other systems have compiled Sisal for execution on distributed-memory machines. Distributed Memory Sisal from Colorado State University <ref> [HB92] </ref> is closely related to fsc. It uses a DSM, but employs coarse-grain execution. Additionally, their DSM does not achieve as much overlap of communication and computation as fsc, because of the lack of many fine-grain tasks and the use of a stack to hold faulted threads.
Reference: [LA94] <author> David K. Lowenthal and Gregory R. Andrews. </author> <title> Adaptive data placement for distributed-memory machines. </title> <type> TR 94-33, </type> <institution> University of Arizona, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Lastly, having many small tasks also makes it easier to perform load balancing and data partitioning, allowing dynamic and adaptive systems to perform both (for example, see the Adapt system <ref> [LA94] </ref>). Obviously, creating fsc from osc has some advantages but there is a downside, too. In particular, there is some cost in translating from the fine-grain model of Sisal to the coarse-grain model 1 Every processor reads the top-level array; the rows, however, are often read by only one processor.
Reference: [M + 85] <author> James R. McGraw et al. </author> <title> SISAL language reference manual version 1.2. </title> <type> Technical Report M-146, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> March </month> <year> 1985. </year> <month> 10 </month>
Reference-contexts: In addition, functional programs have an abundance of implicit concurrency, because loop iterations and independent expressions can be evaluated in parallel. The main challenges are to implement functional programs both efficiently and portably on a variety of machines. Sisal is a functional language <ref> [M + 85] </ref> that has proven useful for programming numerically intensive scientific applications, especially parallel applications [Can92a]. The optimizing Sisal compiler, osc, creates code for many different shared-memory and vector processors (e.g., SGI, Sequent, Encore Multimax, Cray X-MP, and Cray 2) [Can92b].
Reference: [Nik89] <author> Rishiyur S. Nikhil. </author> <title> The parallel programming language Id and its compilation for parallel machines. </title> <booktitle> In Proc. Workshop on Massive Parallelism: Hardware, Programming nad Applications, </booktitle> <month> October </month> <year> 1989. </year>
Reference-contexts: The shared-memory system has nearly linear speedup; the distributed-memory system gets very poor speedup. Because both systems use graph reduction, they have very large overhead and are not competitive with imperative programs. The paper <ref> [Nik89] </ref> shows how Id can be translated to dataflow graphs, then to P-RISC (Parallel-RISC) code, and finally to machine code. The target machine can be a shared- or a distributed-memory machine. The main similarity of this to fsc is the architecture-independent intermediate form (P-RISC).
Reference: [PAM94] <author> Santosh S. Pande, Dharma P. Agrawal, and Jon Mauney. </author> <title> Compiling functional parallelism on distrbuted-memory systems. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <pages> pages 64-76, </pages> <month> Spring </month> <year> 1994. </year> <month> 11 </month>
Reference-contexts: Additionally, their DSM does not achieve as much overlap of communication and computation as fsc, because of the lack of many fine-grain tasks and the use of a stack to hold faulted threads. The distributed-memory Sisal compiler from North Carolina State University uses a coarse-grain, explicit message passing model <ref> [PAM94] </ref>. Data are transferred between processors using explicit communication operations. Significant analysis is required both to insert and minimize the communication between processors. Two systems for executing ALFL programs on shared- and distributed-memory machines are described in [Gol88]. An ALFL program and its data are represented as a graph.
References-found: 11

