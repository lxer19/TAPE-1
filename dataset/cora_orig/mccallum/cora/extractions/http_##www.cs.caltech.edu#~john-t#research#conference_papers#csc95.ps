URL: http://www.cs.caltech.edu/~john-t/research/conference_papers/csc95.ps
Refering-URL: http://www.cs.caltech.edu/~john-t/research/conference_papers/
Root-URL: http://www.cs.caltech.edu
Email: john-t@cs.caltech.edu  
Title: Declarative Ada: Parallel Dataflow Programming in a Familiar Context  
Author: John Thornley 
Address: Pasadena, California 91125, U.S.A.  
Affiliation: Computer Science Department California Institute of Technology  
Abstract: Declarative parallel programming languages express and control parallelism at a high level of abstraction| through implicit dataflow, rather than explicit communication and synchronization operations. However, most declarative languages are esoteric, mathematically-inspired notations with syntax, control constructs, and data types very different from popular sequential imperative languages. We present Declarative Ada, a parallel dataflow programming language with the same syntax as a simple Pascal-like subset of Ada. The difference between Declarative Ada and a sequential language is that all variables are single-assignment and all loops and compositions of statements are parallel by default. Declarative Ada programs implicitly express parallelism at all levels of granularity, yet can be constructed to be identical to equivalent sequential programs. We believe that Declarative Ada is an ideal language for learning a high-level, dataflow approach to parallel program design. A user-friendly, portable Declarative Ada compiler has been developed specifically for experimental and instructional use. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gregory R. Andrews. </author> <title> Concurrent Programming: </title> <booktitle> Principles and Practice. </booktitle> <address> Benjamin/Cummings, Redwood City, California, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Most parallel programming languages are imperative languages with explicitly declared parallel processes and explicit communication and synchronization operations. A comprehensive review of parallel imperative languages and methods is given by Andrews <ref> [1] </ref>. The complication of expressing and controlling concurrency makes parallel imperative programs inherently more difficult to develop than equivalent sequential programs. This difficulty is an obstacle to the more widespread application and teaching of parallel programming.
Reference: [2] <author> Paul Hudak. </author> <title> Conception, evolution, and application of functional programming languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 359-411, </pages> <month> Septem-ber </month> <year> 1989. </year>
Reference-contexts: Parallel execution is controlled by the dataflow implicit in the program. In principle, parallel declarative programming is no more difficult than sequential programming. Many parallel declarative languages have been proposed, e.g., see <ref> [2] </ref>, [3] and [4]. However, the form of these languages is usually very different from that of popular sequential imperative languages. Typically, the syntax is mathematically-inspired and only a few data types are supported, e.g., lists and tuples.
Reference: [3] <author> Ehud Shapiro. </author> <title> The family of concurrent logic programming languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 413-510, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Parallel execution is controlled by the dataflow implicit in the program. In principle, parallel declarative programming is no more difficult than sequential programming. Many parallel declarative languages have been proposed, e.g., see [2], <ref> [3] </ref> and [4]. However, the form of these languages is usually very different from that of popular sequential imperative languages. Typically, the syntax is mathematically-inspired and only a few data types are supported, e.g., lists and tuples. Emphasis is often placed on esoteric concepts such as higher-order functions and meta-programming.
Reference: [4] <editor> Boleslaw K. Szymanski, editor. </editor> <booktitle> Parallel Functional Languages and Compilers. </booktitle> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year>
Reference-contexts: Parallel execution is controlled by the dataflow implicit in the program. In principle, parallel declarative programming is no more difficult than sequential programming. Many parallel declarative languages have been proposed, e.g., see [2], [3] and <ref> [4] </ref>. However, the form of these languages is usually very different from that of popular sequential imperative languages. Typically, the syntax is mathematically-inspired and only a few data types are supported, e.g., lists and tuples. Emphasis is often placed on esoteric concepts such as higher-order functions and meta-programming.
Reference: [5] <author> American National Standards Institute, Inc. </author> <title> The Programming Language Ada Reference Manual. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1983. </year> <month> ANSI/MIL-STD-1815A. </month>
Reference-contexts: Emphasis is often placed on esoteric concepts such as higher-order functions and meta-programming. For many programmers, these features are unfamiliar and discourage learning and experimentation with parallel declarative programming. We present Declarative Ada, a parallel dataflow programming language based on a Pascal-like subset of Ada <ref> [5] </ref>. Declarative Ada includes familiar features such as: procedures and functions; strong typing; numeric, Boolean, string, array, record, and pointer data types; assignment, if-then-else, and for-loop statements. The difference between Declarative Ada and a sequential language is that all variables are single-assignment. <p> The initial version of the compiler emits PCN [10][12] object code. We are considering retargeting the compiler to emit Ada with standard tasking constructs <ref> [5, Chapter 9] </ref>, using the transformations defined in [13]. Another possibility is to emit C code with calls to a thread library. The compiler was designed and built with three principle goals: 1. Portability: The compiler is written in ANSI C.
Reference: [6] <author> John Thornley. </author> <title> The programming language Declarative Ada reference manual. </title> <type> Technical Report CS-TR-93-04, </type> <institution> Computer Science Department, Califor-nia Institute of Technology, </institution> <year> 1993. </year> <note> Available by anonymous ftp from ftp.cs.caltech.edu. </note>
Reference-contexts: The complete language definition is given in <ref> [6] </ref>. 2.1 Language Summary Program Structure and Declarations: A program consists of a sequence of constant, type, and subprogram (procedure and function) declarations. Parameters of subprograms can be of in, out, and in out modes. Subprograms can contain local variable declarations. <p> In [7, Section 6], we summarize some of the important issues. The compiler is available on the World-Wide Web at URL http://www.cs.caltech.edu/~john-t/. Three reports accompany the compiler: the language reference manual <ref> [6] </ref>, a programming overview [7], and a collection of example programs [8]. 7 Conclusion We have presented Declarative Ada, a language that integrates parallel declarative programming with the syntax, control constructs, and data types of a familiar sequential imperative language.
Reference: [7] <author> John Thornley. </author> <title> Parallel programming with Declarative Ada. </title> <type> Technical Report CS-TR-93-03, </type> <institution> Computer Science Department, California Institute of Technology, </institution> <year> 1993. </year> <note> Available by anonymous ftp from ftp.cs.caltech.edu. </note>
Reference-contexts: These examples are discussed in more detail in <ref> [7] </ref> and a larger collection of example programs are presented in [8]. 3.1 Mergesort Our first example program is a function, Sort, that takes as input, Unsorted, a linked list of integers, and returns a linked list of integers that is a permutation of the elements of Unsorted in ascending order. <p> Some problems require nondeterministic behavior to interact in a timely manner with their environment. In these cases, some source of nondeterminacy|e.g., a fair merge|must be imported from outside of the language. Nondeterministic programming with Declarative Ada is discussed in <ref> [7, Section 5] </ref>. 5 Sequential Input and Output Supporting sequential input and output is a source of difficulty for some parallel declarative languages. Declarative Ada includes input and output to standard files and provides sequential statements to ensure deterministic ordering. <p> Parallel and sequential compositions of statements and parallel and sequential for-loop statements can be nested arbitrarily. In the above program, sequential for-loop statements and sequential compositions of statements are nested. In <ref> [7, Section 4] </ref>, we explain that input and output files are specific instances of multiple-assignment variables, and that sequential ordering is required for deterministic operations on multiple-assignment variables. 6 A Compiler We have developed a Declarative Ada compiler for experimental and instructional purposes. <p> The handwritten lexical analyzer and parser enable precise placement of helpful error-specific messages. The initial version of the compiler was not designed to emit very efficient object code. Translation of declarative programs to efficient code is a subject of active ongoing research, e.g., as discussed in [14]. In <ref> [7, Section 6] </ref>, we summarize some of the important issues. The compiler is available on the World-Wide Web at URL http://www.cs.caltech.edu/~john-t/. <p> In [7, Section 6], we summarize some of the important issues. The compiler is available on the World-Wide Web at URL http://www.cs.caltech.edu/~john-t/. Three reports accompany the compiler: the language reference manual [6], a programming overview <ref> [7] </ref>, and a collection of example programs [8]. 7 Conclusion We have presented Declarative Ada, a language that integrates parallel declarative programming with the syntax, control constructs, and data types of a familiar sequential imperative language.
Reference: [8] <author> John Thornley. </author> <title> A collection of Declarative Ada example programs. </title> <type> Technical Report CS-TR-93-05, </type> <institution> Computer Science Department, California Institute of Technology, </institution> <year> 1993. </year> <note> Available by anonymous ftp from ftp.cs.caltech.edu. </note>
Reference-contexts: These examples are discussed in more detail in [7] and a larger collection of example programs are presented in <ref> [8] </ref>. 3.1 Mergesort Our first example program is a function, Sort, that takes as input, Unsorted, a linked list of integers, and returns a linked list of integers that is a permutation of the elements of Unsorted in ascending order. An example is shown in Figure 1. <p> In [7, Section 6], we summarize some of the important issues. The compiler is available on the World-Wide Web at URL http://www.cs.caltech.edu/~john-t/. Three reports accompany the compiler: the language reference manual [6], a programming overview [7], and a collection of example programs <ref> [8] </ref>. 7 Conclusion We have presented Declarative Ada, a language that integrates parallel declarative programming with the syntax, control constructs, and data types of a familiar sequential imperative language.
Reference: [9] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: An example is shown in Figure 1. The program is implemented using a parallel version of the mergesort algorithm <ref> [9, pages 294-295] </ref>. Parallel mergesort of lists is also discussed in [10, pages 52-54]. The mergesort program demonstrates parallelism from composition of statements, parallelism from functional composition, parallelism from recursion, and communication and synchronization using linked lists. <p> The graph is required to have no cycles of negative length, and the weight of the edge from a vertex to itself is required to be zero, for all vertices. An example is shown in version of the Floyd-Warshall algorithm <ref> [9, pages 208-210] </ref>. Parallel all-pairs shortest path is also discussed in [11, Chapter 5]. a weighted directed graph. The all-pairs shortest path program demonstrates parallelism from for-loop statements and communication and synchronization using arrays. As with the mergesort example, the program is identical to an equivalent sequential Ada program.
Reference: [10] <author> K. Mani Chandy and Stephen Taylor. </author> <title> An Introduction to Parallel Programming. </title> <publisher> Jones and Bartlett, </publisher> <address> Boston, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: An example is shown in Figure 1. The program is implemented using a parallel version of the mergesort algorithm [9, pages 294-295]. Parallel mergesort of lists is also discussed in <ref> [10, pages 52-54] </ref>. The mergesort program demonstrates parallelism from composition of statements, parallelism from functional composition, parallelism from recursion, and communication and synchronization using linked lists.
Reference: [11] <author> K. Mani Chandy and Jayadev Misra. </author> <title> Parallel Program Design. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1988. </year>
Reference-contexts: An example is shown in version of the Floyd-Warshall algorithm [9, pages 208-210]. Parallel all-pairs shortest path is also discussed in <ref> [11, Chapter 5] </ref>. a weighted directed graph. The all-pairs shortest path program demonstrates parallelism from for-loop statements and communication and synchronization using arrays. As with the mergesort example, the program is identical to an equivalent sequential Ada program. <p> The program is implemented as a network of processes with feedback in the communication between processes. Hamming's problem and a derivation of this method of solution are described in <ref> [11, pages 180-183] </ref>. The Hamming's problem program demonstrates that Declarative Ada is more than a single-assignment restriction on a sequential subset of Ada.
Reference: [12] <author> Ian Foster and Steven Tuecke. </author> <title> Parallel programming with PCN. </title> <type> Technical Report ANL-91/32 Rev. 2, </type> <institution> Argonne National Laboratory, </institution> <year> 1993. </year>
Reference: [13] <author> John Thornley. </author> <title> Integrating parallel dataflow programming with the Ada tasking model. </title> <booktitle> In Proceedings of ACM TRI-Ada `94, </booktitle> <pages> pages 417-428, </pages> <address> Balti-more, Maryland, </address> <month> November 6-11 </month> <year> 1994. </year>
Reference-contexts: The initial version of the compiler emits PCN [10][12] object code. We are considering retargeting the compiler to emit Ada with standard tasking constructs [5, Chapter 9], using the transformations defined in <ref> [13] </ref>. Another possibility is to emit C code with calls to a thread library. The compiler was designed and built with three principle goals: 1. Portability: The compiler is written in ANSI C. Translation consists of three stages: parse tree construction, parse tree transformation, and object code generation.
Reference: [14] <author> D. Cann. </author> <title> Retire Fortran? A debate rekindled. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 81-89, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The handwritten lexical analyzer and parser enable precise placement of helpful error-specific messages. The initial version of the compiler was not designed to emit very efficient object code. Translation of declarative programs to efficient code is a subject of active ongoing research, e.g., as discussed in <ref> [14] </ref>. In [7, Section 6], we summarize some of the important issues. The compiler is available on the World-Wide Web at URL http://www.cs.caltech.edu/~john-t/.
References-found: 14

