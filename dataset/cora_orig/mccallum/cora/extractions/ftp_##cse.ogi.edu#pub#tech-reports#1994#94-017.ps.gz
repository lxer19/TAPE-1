URL: ftp://cse.ogi.edu/pub/tech-reports/1994/94-017.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Email: o@ipncls.in2p3.fr  otto@cse.ogi.edu  
Title: Partitioning of Unstructured Meshes for Load Balancing  
Author: Olivier C. Martin martin and Steve W. Otto 
Date: January 19, 1994  
Address: Orsay CEDEX 91406 France  20000 NW Walker Rd, PO Box 91000 Portland, Oregon, USA 97291-1000  
Affiliation: Division de Physique Theorique Institut de Physique Nucleaire,  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: Many large-scale engineering and scientific calculations involve repeated updating of variables on an unstructured mesh. To do these types of computations on distributed memory parallel computers, it is necessary to partition the mesh among the processors so that the load balance is maximized and inter-processor communication time is minimized. This can be approximated by the problem of partitioning a graph so as to obtain a minimum cut, a well-studied combinatorial optimization problem. Graph partitioning is NP complete, so for real world applications, one resorts to heuristics, i.e., algorithms that give good but not necessarily optimum solutions. These algorithms include local search methods such as Kernighan-Lin, recursive spectral bisection, and more general purpose methods such as simulated annealing. We show that a general procedure enables us to combine simulating annealing with Kernighan-Lin. The resulting algorithm is both very fast and extremely effective. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B.W. Kernighan. </author> <title> Some graph partitioning problems related to program segmentation, 1969. </title> <type> Ph.D. Thesis. </type>
Reference-contexts: An edge E i;j is cut if i and j belong to different subsets. The GPP has many practical applications. It was used to segment program text <ref> [1] </ref>, and is a major ingredient in the problem of cell placement for VLSI [2, 3]. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [2] <author> K. Shahookar and P. Mazumder. </author> <title> VLSI cell placement techniques. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(2) </volume> <pages> 143-220, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: An edge E i;j is cut if i and j belong to different subsets. The GPP has many practical applications. It was used to segment program text [1], and is a major ingredient in the problem of cell placement for VLSI <ref> [2, 3] </ref>. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [3] <author> M. Hanan and J.M. Kertzberg. </author> <title> A review of the placement and quadratic assignment problems. </title> <journal> SIAM Review, </journal> <volume> 14, No. 2:324, </volume> <year> 1972. </year>
Reference-contexts: An edge E i;j is cut if i and j belong to different subsets. The GPP has many practical applications. It was used to segment program text [1], and is a major ingredient in the problem of cell placement for VLSI <ref> [2, 3] </ref>. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [4] <author> S. Barnard and H. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 6(1), </volume> <month> February </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Parallel implementations on distributed-memory computers require the partitioning of the mesh amongst the processors, thereby leading to a graph partitioning problem where G=(V,E) is given directly by the mesh <ref> [4, 5, 6, 7, 8] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G. <p> This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. The paper goes on to compare C-L-O against other effective heuristics <ref> [10, 4] </ref>, for both synthetically generated graphs and for graphs from real-world unstructured meshes. <p> Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection <ref> [7, 4] </ref>. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> The line initialization is not possible for such graphs, nor is compaction of much use. 5 Performance on unstructured meshes Barnard and Simon <ref> [4] </ref> studied recursive spectral bisection on several unstructured meshes that arise in mesh-mapping problems. This section benchmarks L-K-L and C-L-O on these same problems provided by H. Simon.
Reference: [5] <author> J. Flower, S. Otto, and M. Salama. </author> <title> A preprocessor for finite element problems. </title> <booktitle> In Symposium on Parallel Computations and Their Impact on Mechanics. American Society of Mechanical Engineers. ASME Winter Meeting, </booktitle> <month> Dec. </month> <pages> 14-16, </pages> <address> 1987, Boston, Mass. </address>
Reference-contexts: Parallel implementations on distributed-memory computers require the partitioning of the mesh amongst the processors, thereby leading to a graph partitioning problem where G=(V,E) is given directly by the mesh <ref> [4, 5, 6, 7, 8] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [6] <author> C. Farhat. </author> <title> On the mapping of massively parallel processors onto finite element graphs. </title> <journal> Computers and Structures, </journal> <volume> 32(2) </volume> <pages> 347-53, </pages> <year> 1989. </year> <month> 11 </month>
Reference-contexts: Parallel implementations on distributed-memory computers require the partitioning of the mesh amongst the processors, thereby leading to a graph partitioning problem where G=(V,E) is given directly by the mesh <ref> [4, 5, 6, 7, 8] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [7] <author> A. Pothen, H. Simon, and K.P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 430-52, </pages> <year> 1990. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the partitioning of the mesh amongst the processors, thereby leading to a graph partitioning problem where G=(V,E) is given directly by the mesh <ref> [4, 5, 6, 7, 8] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G. <p> Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection <ref> [7, 4] </ref>. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L.
Reference: [8] <author> V. Venkatakrishnan, H. Simon, and T. Barth. </author> <title> A MIMD implementation of a parallel Euler solver for unstructured grids. </title> <journal> The Journal of Supercomputing, </journal> <volume> 6(2) </volume> <pages> 117-27, </pages> <year> 1992. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the partitioning of the mesh amongst the processors, thereby leading to a graph partitioning problem where G=(V,E) is given directly by the mesh <ref> [4, 5, 6, 7, 8] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [9] <author> B. Kernighan and S. Lin. </author> <title> An effective heuristic procedure for partitioning graphs. </title> <institution> Bell Syst. Tech. J., 49:291, </institution> <year> 1970. </year>
Reference-contexts: In what follows, we quickly summarize a number of solution methods for the GPP, and stress particularly the heuristic champion, the Kernighan-Lin local search algorithm <ref> [9] </ref>. After this, we explain our method of combining local search methods, such as Kernighan-Lin, with simulated annealing. This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. <p> Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin <ref> [9, 15] </ref>, which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. <p> It turns out that 1-opt is a mediocre algorithm, and that going to higher n-opt (i.e., looking at all possible n-exchanges) is very costly and does not lead to much improvement. The Kernighan-Lin (K-L) algorithm <ref> [9] </ref> is a variable, n-exchange algorithm that is much more effective than either 1-opt or 2-opt while being quite fast. "Variable" n means that some n-exchanges for n large are done, but not necessarily all of them.
Reference: [10] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part I (graph partitioning). </title> <type> Oper. </type> <institution> Res., 37:865, </institution> <year> 1989. </year>
Reference-contexts: This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. The paper goes on to compare C-L-O against other effective heuristics <ref> [10, 4] </ref>, for both synthetically generated graphs and for graphs from real-world unstructured meshes. <p> Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster <ref> [10] </ref>. Nevertheless, it is necessary to enhance K-L for it to be competitive with special purpose methods such as recursive spectral bisection. <p> For sparse graphs, K-L is fast, requiring O (N ln (N )) operations per sweep. As shown by Johnson et al., it is much faster than simulated annealing, and also gives smaller cut sizes <ref> [10] </ref>. However, K-L gives erratic results from run to run. In particular, for unstructured meshes, it is beaten by the recursive spectral bisection and coordinate bisection methods. Thus, for such graphs, it is necessary to run K-L many times from different random starts or to find ways to enhance K-L. <p> A simple, yet effective, starting partition can be obtained by coordinate bisection [16]. Since the coordinate-bisection of two-dimensional meshes uses a dividing line with a random orientation, the algorithm is named L-K-L for "Line K-L" <ref> [10] </ref>. L-K-L gives as good results as a hierarchical compaction approach but is simpler and is more effective than simulated annealing or K-L from random starts. <p> Neglecting edge effects, one has, on average, d = R 2 N : (1) Johnson et al. did a thorough comparison of several algorithms and concluded that for such geometric graphs, K-L from random starts was better than simulated annealing, but that the best heuristic was L-K-L <ref> [10] </ref>. We first compare the performance of C-L-O with K-L from random starts. Figure 3 contains the results of a run on a geometric graph of N = 1000 and average degree d = 6. <p> For each instance, we ran L-K-L 2000 times, and we ran C-L-O 20 times, each run consisting of 100 kick/K-L steps. From the 2000 L-K-L data points, we followed the method described in <ref> [10] </ref> to derive the distribution of the best cut found in 100 independent trials. The mean was then compared with the corresponding mean of the best found in each of the 20 C-L-O runs. <p> In comparing various algorithms, we need not consider simulated annealing since it has been shown that K-L performs better than S-A on such sparse graphs <ref> [10] </ref>. We consider the four graphs in turn. Spiral has the geometry of a spiral, so the use of the line algorithm (i.e., coordinate bisection) leads to a fragmented partition.
Reference: [11] <author> A. L. Beguelin, J. J. Dongarra, A. Geist, R. J. Manchek, and V. S. Sunderam. </author> <title> Heterogeneous network computing. </title> <booktitle> In Sixth SIAM Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: The paper goes on to compare C-L-O against other effective heuristics [10, 4], for both synthetically generated graphs and for graphs from real-world unstructured meshes. Finally, we describe the implementation of the C-L-O algorithm on a parallel network of workstations running PVM <ref> [11, 12] </ref>. 2 Graph Partitioning Heuristics Since the GPP is NP-complete, it comes as no surprise that exact methods are slow. An integer linear programming formulation of the GPP has recently been given by Barahona [13]. <p> Thus, we only consider implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed-memory architecture and have implemented the codes on a network of workstations under PVM <ref> [11, 12] </ref>. The simplest way to parallelize chained local optimization is to have each processor run independent C-L-O chains. This is equivalent to running multiple random starts on a single processor. If we have P processors, at any given time we have a population of at least P configurations.
Reference: [12] <author> Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <booktitle> Computers in Physics, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The paper goes on to compare C-L-O against other effective heuristics [10, 4], for both synthetically generated graphs and for graphs from real-world unstructured meshes. Finally, we describe the implementation of the C-L-O algorithm on a parallel network of workstations running PVM <ref> [11, 12] </ref>. 2 Graph Partitioning Heuristics Since the GPP is NP-complete, it comes as no surprise that exact methods are slow. An integer linear programming formulation of the GPP has recently been given by Barahona [13]. <p> Thus, we only consider implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed-memory architecture and have implemented the codes on a network of workstations under PVM <ref> [11, 12] </ref>. The simplest way to parallelize chained local optimization is to have each processor run independent C-L-O chains. This is equivalent to running multiple random starts on a single processor. If we have P processors, at any given time we have a population of at least P configurations.
Reference: [13] <author> F. Barahona and A. Casari. </author> <title> On the magnetisation of the ground states in two dimensional Ising spin glasses. </title> <journal> Comp. Phys. Communications, </journal> <volume> 49:417, </volume> <year> 1988. </year>
Reference-contexts: An integer linear programming formulation of the GPP has recently been given by Barahona <ref> [13] </ref>. Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L).
Reference: [14] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> Optimization by simulated annealing. </title> <booktitle> Science, </booktitle> <address> 220:671, </address> <year> 1983. </year>
Reference-contexts: An integer linear programming formulation of the GPP has recently been given by Barahona [13]. Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing <ref> [14] </ref>, and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4].
Reference: [15] <author> C.M. Fiduccia and R.M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> In Proceedings 19'th Design Automation Workshop, </booktitle> <pages> page 175, </pages> <year> 1982. </year>
Reference-contexts: Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin <ref> [9, 15] </ref>, which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20].
Reference: [16] <author> M. Berger and S. Bokhari. </author> <title> A partitioning strategy for non-uniform problems on multiprocessors. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-36(5):570, </volume> <year> 1987. </year>
Reference-contexts: Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection <ref> [16] </ref>, compaction methods [17], and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> This approach, if used on multiple levels in a hierarchical manner, is well suited to unstructured meshes. The second approach consists of using something besides a random starting partition for the K-L. A simple, yet effective, starting partition can be obtained by coordinate bisection <ref> [16] </ref>. Since the coordinate-bisection of two-dimensional meshes uses a dividing line with a random orientation, the algorithm is named L-K-L for "Line K-L" [10]. L-K-L gives as good results as a hierarchical compaction approach but is simpler and is more effective than simulated annealing or K-L from random starts. <p> The reason for the poor results of K-L can be understood by looking at typical partitions: they are almost always fragmented as mentioned in section 3. Better results would be obtained by simply partitioning the vertices according to their coordinates, i.e., by using coordinate bisection <ref> [16] </ref>. For geometric graphs, this bisection can be obtained by choosing a random direction in space and partitioning the graph by a line parallel to this direction; this corresponds to the line algorithm discussed in section 2.
Reference: [17] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton. </author> <title> Improving the performance of the Kernighan-Lin and simulated annealing graph bisection algorithms. </title> <booktitle> In 26'th ACM/IEEE Design Automation Conference, </booktitle> <pages> page 775, </pages> <year> 1989. </year>
Reference-contexts: Two important, general-purpose heuristics are simulated annealing [14], and a variable depth, local search originally due to Kernighan and Lin [9, 15], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods <ref> [17] </ref>, and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> Thus, for such graphs, it is necessary to run K-L many times from different random starts or to find ways to enhance K-L. Enhancements to Kernighan-Lin for Unstructured Meshes There are two commonly used approaches for improving K-L. The first, called compaction <ref> [17] </ref>, consists of contracting the graph by merging nearby vertices, partitioning the smaller graph via K-L, undoing the merging procedure, and reapplying K-L. This approach, if used on multiple levels in a hierarchical manner, is well suited to unstructured meshes.
Reference: [18] <author> R. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(5) </volume> <pages> 457-81, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4]. Williams <ref> [18] </ref> compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations [19, 20]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [10].
Reference: [19] <author> N. Mansour. </author> <title> Physical Optimization Algorithms for Mapping Data to Distributed-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Syracuse University, </institution> <year> 1992. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations <ref> [19, 20] </ref>. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [10].
Reference: [20] <author> J.E. Savage and M.G. Wloka. </author> <title> On parallelizing graph-partitioning heuristics. </title> <booktitle> In Proceedings of the ICALP'90, </booktitle> <pages> page 476, </pages> <year> 1990. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [16], compaction methods [17], and recursive spectral bisection [7, 4]. Williams [18] compares some of these methods, and Mansour, Savage, and Wloka give parallel implementations <ref> [19, 20] </ref>. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [10].
Reference: [21] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the traveling salesman problem. </title> <journal> J. Complex Syst., </journal> <volume> 5:3:299, </volume> <year> 1991. </year>
Reference-contexts: In view of this, we restrict ourselves to presenting comparisons of our algorithm, C-L-O, to L-K-L only. 3 3 Chained Local Optimization Martin, Otto and Felten <ref> [21] </ref> introduced a new meta-heuristic for optimization by combining local search methods with simulated annealing. The important realization is that simulated annealing needlessly explores all configurations. For most optimization problems, there are local search methods that quickly give good approximate solutions. <p> The resulting algorithm is termed "Chained Local Optimization" (C-L-O). It is a general purpose algorithm that improves upon both simulated annealing and local search methods (it necessarily beats local search, since it incorporates local search in the inner-most loop of the algorithm). We did <ref> [21, 22] </ref> an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973. <p> A symmetry property known as detailed balance is violated by C-L-O and this means that it does not correspond to the true "annealing" of some "physical" system <ref> [21] </ref>. 4 procedure used in chained local optimization. To implement C-L-O for an arbitrary combinatorial optimization problem, one requires two things: a good local search heuristic, and a choice for the kick adapted to the optimization problem.
Reference: [22] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the TSP incorporating local search heuristics. </title> <journal> Oper. Res. Lett., </journal> <volume> 11 </volume> <pages> 219-24, </pages> <year> 1992. </year>
Reference-contexts: The resulting algorithm is termed "Chained Local Optimization" (C-L-O). It is a general purpose algorithm that improves upon both simulated annealing and local search methods (it necessarily beats local search, since it incorporates local search in the inner-most loop of the algorithm). We did <ref> [21, 22] </ref> an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973.
Reference: [23] <author> O. Martin and S. Otto. </author> <title> Combining simulated annealing with local search heuristics. </title> <editor> In G. Laporte and I. Osman, editors, </editor> <booktitle> Metaheuristics in Combinatorial Optimization. </booktitle> <pages> 12 </pages>
Reference-contexts: We did [21, 22] an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973. More generally, as discussed by Martin and Otto <ref> [23] </ref>, C-L-O should perform well on a wide class of problems which includes the GPP. For the purpose of this paper, important features of C-L-O include the following. * It is general purpose, so it can be applied to general graphs.
References-found: 23

