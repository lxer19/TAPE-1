URL: http://www.cs.princeton.edu/~wass/publications/SIGACT.ps.gz
Refering-URL: http://www.cs.princeton.edu/~wass/publications.html
Root-URL: http://www.cs.princeton.edu
Title: A Survey of Line  ar Programming in Randomized Subexponential Time  
Author: Michael Goldwasser 
Date: 96-104, 1995  
Note: SIGACT News 26 no. 2, pp.  
Abstract: It is remarkable to see how different paths have led to rather similar results so close in time." - Kalai, 1992 ([8]). Three papers were published in 1992, each providing a combinatorial, randomized algorithm solving linear programming in subexponential expected time. Bounds on independent algorithms were proven, one by Kalai, and the other by Matousek, Sharir, and Welzl. Results by Gartner combined techniques from these papers to solve a much more general optimization problem in similar time bounds. Although the algorithms by Kalai and Sharir-Welzl seem remarkably different in style and evolution, this paper demonstrates that one of the variants of Kalai's algorithm is identical (although dual) to the algorithm of Sharir-Welzl. Also the implication of Gartner's framework on future improvements is examined more carefully.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Chvatal. </author> <title> Linear Programming. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, NY, </address> <year> 1983. </year>
Reference-contexts: The reader is refered to [18] for a detailed discussion of linear programming theory, background, and recent results. Also <ref> [1] </ref> provides an excellent introduction to linear programming and the simplex method. The recent book [17] provides a comprehensive discussion of the analysis of randomized algorithms, including specific analysis of several of the LP algorithms discussed here.
Reference: [2] <author> K. L. Clarkson. </author> <title> Linear programming in O(n3 d 2 ) time. </title> <journal> Inform. Process. Lett., </journal> <volume> 22 </volume> <pages> 21-24, </pages> <year> 1986. </year>
Reference-contexts: For linear programs in fixed dimensions, Megiddo (1983) was first to give a deterministic algorithm whose dependence on n is linear [16]. The dependence on d was further improved in 1986 by Dyer [5] and then Clarkson <ref> [2] </ref>. Clarkson used random sampling techniques in 1988 to develop a simple algorithm which solves linear programming by solving O (d 2 log n) smaller linear programs with O (d 2 ) constraints and d variables [3].
Reference: [3] <author> K. L. Clarkson. </author> <title> A Las Vegas algorithm for linear programming when the dimension is small. </title> <booktitle> In Proc. 29th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 452-456, </pages> <year> 1988. </year>
Reference-contexts: Clarkson used random sampling techniques in 1988 to develop a simple algorithm which solves linear programming by solving O (d 2 log n) smaller linear programs with O (d 2 ) constraints and d variables <ref> [3] </ref>. By using a standard simplex algorithm as a subroutine for solving these small programs, Clarkson's algorithm is still exponential, however the best current bounds are realized by using one of these recent subexponential algorithms as a subroutine.
Reference: [4] <author> G. B. Dantzig. </author> <title> Linear Programming and Extensions. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1963. </year>
Reference-contexts: 1 Introduction Linear programming has long been an important problem in computer science. Since 1950, when the simplex method was introduced by Dantzig <ref> [4] </ref>, thousands of papers have been published regarding linear programming. The simplex method is a simple combinatorial algorithm widely used (and praised) in practice, however its analysis in respect to theoretical efficiency turned out to be rather difficult. <p> A superpolynomial lower bound on (d; n) would eliminate the possibility of a polynomial pivot rule, however there is a long-running conjecture of Hirsch <ref> [4] </ref> that (d; n) = O (n + d) for bounded polyhedra. Until recently though, the best upper bounds had been exponential. Kalai gave the first subexponential bound [9], and this bound was improved by Kalai and Kleitman [10] to prove (d; n) = O (n log d+2 ).
Reference: [5] <author> M. E. Dyer. </author> <title> On a multidimensional search technique and its application to the Euclidean one-center problem. </title> <journal> SIAM J. Comput., </journal> <volume> 15 </volume> <pages> 725-738, </pages> <year> 1986. </year>
Reference-contexts: For linear programs in fixed dimensions, Megiddo (1983) was first to give a deterministic algorithm whose dependence on n is linear [16]. The dependence on d was further improved in 1986 by Dyer <ref> [5] </ref> and then Clarkson [2]. Clarkson used random sampling techniques in 1988 to develop a simple algorithm which solves linear programming by solving O (d 2 log n) smaller linear programs with O (d 2 ) constraints and d variables [3].
Reference: [6] <author> B. Gartner. </author> <title> A subexponential algorithm for abstract optimization problems. </title> <booktitle> In Proc. 33rd Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 464-472, </pages> <year> 1992. </year>
Reference-contexts: However this bound does not necessarily hold for other optimization problems in their framework. Gartner then combined a technique used by Kalai with the Sharir-Welzl algorithm, to provide another subexponential algorithm <ref> [6] </ref>. More importantly this algorithm was designed in a much more general framework of optimization problems, and thereby showed that few of the specific properties of linear programming were necessary in proving the subexponential running time. <p> g (d; n i) Analyzing this recurrence leads to the subexponential results [8]. 3.6 Gartner's Framework A powerful result was provided by Gartner when he created a very generalized framework including LP, and displayed that the above algorithms could be adapted to produce subexponential expected running time in this framework <ref> [6] </ref>. He defines an Abstract Optimization Problem (AOP) as a triple (H; &lt;; ), where H is a finite set, &lt; is a linear order on 2 H , and an oracle. <p> For a complete description of the algorithm, the reader is referred to <ref> [6] </ref>, however the general algorithm is modeled after the algorithm of Sharir-Welzl, borrowing one trick from Kalai. <p> That gives a direct bound on the running time of the Sharir-Welzl algorithm, and most recent bound given in [15] matches this, with the exception of the constant in the exponent. 5 Implications of AOP results The amazing realization that falls out of Gartner's result <ref> [6] </ref> is that little of the structure of linear programming is being relied on to prove the subexponential bound on the number of oracle calls. Given any linear program, it is simple to translate the values of all the bases to create an instance of AOP. <p> Also, Developing a non-trivial randomized lower bound for AOP would be a useful result. It is quite possible that a superpolynomial lower bound can be constructed for AOP, in fact any progress in closing the gap between the upper bound of <ref> [6] </ref> would be useful. Such a lower bound would probably not apply to a linear order realizable as an LP program, and so developing such a lower bound would be instructive in improving a specialized linear program algorithm.
Reference: [7] <author> B. Gartner and G. Ziegler. </author> <title> Randomized simplex algorithms on klee-minty cubes. </title> <booktitle> In Proc. 35th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 502-510, </pages> <year> 1994. </year>
Reference-contexts: That is, given the current vertex, simply choose a pivot rule uniformly at random from all incident edges which improve the objective function. Gartner and Ziegler have recently analyzed this algorithm's performance of the Klee-Minty cubes <ref> [7] </ref>, and established quadratic upper bounds on the expected number of steps for this instance. The expected time for this algorithm can be modeled as the time it takes for a random walk on a directed acyclic graph to reach a unique sink.
Reference: [8] <author> G. Kalai. </author> <title> A subexponential randomized simplex algorithm. </title> <booktitle> In Proc. 24th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 475-482, </pages> <year> 1992. </year>
Reference-contexts: This algorithm was presented in a generalized framework that included linear programming and several other optimization problems. Stemming from the study of the diameter of polytopes, Kalai developed a randomized simplex algorithm in 1992, and proved the first subexponential bound for linear programming <ref> [8] </ref>. Following this, Matousek joined Sharir and Welzl to tighten the analysis and to prove that their previous algorithm, unchanged, also had a subexponential expected running time for linear programming [15]. However this bound does not necessarily hold for other optimization problems in their framework. <p> Of course this does not provide a lower bound for the running time of the algorithm on LP, since there may be properties of LP other than the above axioms which limit the running time. 3.5 Kalai's Algorithm The algorithm of Kalai <ref> [8] </ref> emerged from the study of the diameter problem for graphs of polyhedra. Given a linear program O, and its polyhedron P , the graph G (P ) is the one-shell of the polyhedron. <p> Until recently though, the best upper bounds had been exponential. Kalai gave the first subexponential bound [9], and this bound was improved by Kalai and Kleitman [10] to prove (d; n) = O (n log d+2 ). These proofs led to the development of the subexponential algorithm in <ref> [8] </ref>. Before describing the algorithm we define the concept of an active facet. A facet F is active with respect to a vertex v, if maxf (x) : x 2 F g &gt; (v), where (x) denotes the value of the objective function at point x. <p> Although there are many variants of this algorithm, this leads to the general recursion, g (d; n) g (d 1; n 1) + i=d n=2 X g (d; n i) Analyzing this recurrence leads to the subexponential results <ref> [8] </ref>. 3.6 Gartner's Framework A powerful result was provided by Gartner when he created a very generalized framework including LP, and displayed that the above algorithms could be adapted to produce subexponential expected running time in this framework [6]. <p> However, this fact falls apart in the AOP framework since there are no assumptions made about the candidate subsets F . Therefore, Gartner borrows a trick from <ref> [8] </ref>. If the set of candidates, S = H F is determined to be too small, he expands it. He starts running the algorithm on a subproblem until it finds the overall optimal min (w H ), or it provides a new candidate that was not previously in S. <p> By repeating this process, the set S can be expanded as desired leaving enough candidates for the randomization to be effective. 6 The analysis is based on what he terms freedom, a concept very similar to the active facets of <ref> [8] </ref> or enforcing constraints of [15]. This results in a recurrence quite similar to that of [8]. 4 Duality of Algorithms In this section we consider the implications of the duality theorem of linear programming. <p> S can be expanded as desired leaving enough candidates for the randomization to be effective. 6 The analysis is based on what he terms freedom, a concept very similar to the active facets of <ref> [8] </ref> or enforcing constraints of [15]. This results in a recurrence quite similar to that of [8]. 4 Duality of Algorithms In this section we consider the implications of the duality theorem of linear programming. More specifically, we show that the algorithm of Sharir-Welzl and variant S 0 of Kalai's algorithm are exactly dual to each other. <p> More specifically, we show that the algorithm of Sharir-Welzl and variant S 0 of Kalai's algorithm are exactly dual to each other. The relation between these two algorithms was suggested by Kalai in <ref> [8] </ref>, however the exactness of the parallelism was not noted. From Section 2 our goal is to solve the linear program maxf cx j Ax b g. By the duality theorem of linear programming, the dual of this program is minf yb j yA = c; y i 0 g. <p> The only step of the parallelism which is obscure is step four in the above table, and the obscurity is due the following apparent lapse in the description of the S 0 algorithm in <ref> [8] </ref>. It is evident through duality throwing out a random constraint of H C is identical to tightening a random constraint in the dual, of those incident to the current vertex. The only question is how the two algorithms continue once the subproblem is solved. <p> In this case, there exists only one edge leaving B that improves the objective function, and that edge is taken by pivoting away from the inactive facet. Therefore any simplex 7 method must take that edge once at B. Variant S 0 in <ref> [8] </ref> is defined as the algorithm resulting when parameter r = d. However it was loosely stated that this algorithm simply picks one of the d facets incident to a vertex. <p> Therefore the bag of d random choices used by both algorithms are identical, and hence the algorithms are exactly dual. This relation between the algorithms corroborates an interesting point in the analysis of <ref> [8] </ref>. For the most efficient version of their algorithm, they prove subexponential bounds on f (d; n), f (d; 2d), and f (d; d + m), however for variant S 0 , they could only bound f 0 (d; d + m). <p> The key question is what properties of the graph are necessary to give reasonable upper or lower bounds on the maximum over all starting vertices. Clearly, the height of a polytope studied in <ref> [8] </ref>, is an important property, however other properties might also prove valuable in bounding the complexity. Acknowledgments: The author wishes to thank Rajeev Motwani, Leo Guibas and Bernd Gartner for their helpful discussions. 8
Reference: [9] <author> G. Kalai. </author> <title> Upper bounds for the diameter of graphs of convex polygopes. </title> <journal> Discrete Comput. Geom., </journal> <note> 7:to appear, </note> <year> 1992. </year>
Reference-contexts: Until recently though, the best upper bounds had been exponential. Kalai gave the first subexponential bound <ref> [9] </ref>, and this bound was improved by Kalai and Kleitman [10] to prove (d; n) = O (n log d+2 ). These proofs led to the development of the subexponential algorithm in [8]. Before describing the algorithm we define the concept of an active facet.
Reference: [10] <author> G. Kalai and D. J. Kleitman. </author> <title> A quasi-polynomial bound for diameter of graphs of polyhedra. </title> <journal> Bulletin of the American Math. Soc., </journal> <volume> 24 </volume> <pages> 315-316, </pages> <year> 1992. </year>
Reference-contexts: Until recently though, the best upper bounds had been exponential. Kalai gave the first subexponential bound [9], and this bound was improved by Kalai and Kleitman <ref> [10] </ref> to prove (d; n) = O (n log d+2 ). These proofs led to the development of the subexponential algorithm in [8]. Before describing the algorithm we define the concept of an active facet.
Reference: [11] <author> N. Karmarkar. </author> <title> A new polynomial-time algorithm for linear programming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1984. </year>
Reference-contexts: Although many felt that the simplex method was polynomial in the worst case, Klee and Minty provided counterexamples in 1972, requiring exponential time for a common pivot rule [13]. The first polynomial algorithms for linear programming were given by Khachiyan [12] and Karmarkar <ref> [11] </ref> in the 1980's, however these algorithms are not strongly polynomial, that is their running times depended on the size of the coefficients representing the constraints, and not solely on n, the number of constraints, and d the number of variables.
Reference: [12] <author> L. G. Khachiyan. </author> <title> Polynomial algorithm in linear programming. </title> <journal> U.S.S.R. Comput. Math. and Math. Phys., </journal> <volume> 20 </volume> <pages> 53-72, </pages> <year> 1980. </year>
Reference-contexts: Although many felt that the simplex method was polynomial in the worst case, Klee and Minty provided counterexamples in 1972, requiring exponential time for a common pivot rule [13]. The first polynomial algorithms for linear programming were given by Khachiyan <ref> [12] </ref> and Karmarkar [11] in the 1980's, however these algorithms are not strongly polynomial, that is their running times depended on the size of the coefficients representing the constraints, and not solely on n, the number of constraints, and d the number of variables.
Reference: [13] <author> V. Klee and G. J. Minty. </author> <title> How good is the simplex algorithm? In O. </title> <editor> Shisha, editor, </editor> <booktitle> Inequalities III, </booktitle> <pages> pages 159-175. </pages> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: Although many felt that the simplex method was polynomial in the worst case, Klee and Minty provided counterexamples in 1972, requiring exponential time for a common pivot rule <ref> [13] </ref>.
Reference: [14] <author> J. Matousek. </author> <title> Lower bound for a subexponential optimization algorithm. </title> <type> Technical Report B-92-15, </type> <institution> Fachbereich Mathematik, Freie Universitat Berlin, </institution> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: Of course this does not necessarily prove a lower bound on the running time of the algorithm on linear programming, since different analysis may provide a better recurrence. However more recent results in <ref> [14] </ref> discuss lower bounds for this algorithm. 3.4 Matousek/Sharir/Welzl Framework The algorithm in [15] is actually presented in a more general framework that includes LP. They define LP-type problems as follows. <p> Also, given a basis B and a constraint h, a basis computation computes a basis for (B [ fhg). The bounds in the previous section hold for any basis-regular LP-type problem. Also, the results in <ref> [14] </ref> provide an example of an LP-type problem of combinatorial dimension d with 2d constraints for which their algorithm requires (e p 4 p d). This lower bounds the running time of their algorithm on LP-type problems.
Reference: [15] <author> J. Matousek, M. Sharir, and E. Welzl. </author> <title> A subexponential bound for linear programming. </title> <booktitle> In Proc. 8th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 1-8, </pages> <year> 1992. </year>
Reference-contexts: Following this, Matousek joined Sharir and Welzl to tighten the analysis and to prove that their previous algorithm, unchanged, also had a subexponential expected running time for linear programming <ref> [15] </ref>. However this bound does not necessarily hold for other optimization problems in their framework. Gartner then combined a technique used by Kalai with the Sharir-Welzl algorithm, to provide another subexponential algorithm [6]. <p> The candidate vertex v is thrown away, even though it seems reasonable that constraints defining v are more likely to also define the true optimal vertex. This idea is brought out by the algorithm Matousek, Sharir, Welzl [20] <ref> [15] </ref>. To maintain extra information, they add a second parameter to the algorithm. The LP program is called with two sets, the set of constraints H, and a basis C H. <p> The solution to this results in the subexponential bound, f (k; n) min O (2 k n); exp 2 k ln ( p ) + O ( k + ln n) They prove a lower bound on f (k; n) which almost matches this <ref> [15] </ref>, showing that their solution to this recurrence is tight. Of course this does not necessarily prove a lower bound on the running time of the algorithm on linear programming, since different analysis may provide a better recurrence. <p> Of course this does not necessarily prove a lower bound on the running time of the algorithm on linear programming, since different analysis may provide a better recurrence. However more recent results in [14] discuss lower bounds for this algorithm. 3.4 Matousek/Sharir/Welzl Framework The algorithm in <ref> [15] </ref> is actually presented in a more general framework that includes LP. They define LP-type problems as follows. <p> For any given F G H, the oracle will determine if F = min (2 G ) and if not, returns a witness set with smaller value. The goal of the problem is to find min (2 H ). In terms of the framework in <ref> [15] </ref>, the linear order is exactly W, and the oracle can be efficiently implemented if F is a basis by simply searching for a violating constraint, and if one exists, making a basis computation by adding that constraint. <p> By repeating this process, the set S can be expanded as desired leaving enough candidates for the randomization to be effective. 6 The analysis is based on what he terms freedom, a concept very similar to the active facets of [8] or enforcing constraints of <ref> [15] </ref>. This results in a recurrence quite similar to that of [8]. 4 Duality of Algorithms In this section we consider the implications of the duality theorem of linear programming. <p> Although they could not bound the running time of variant S 0 on the primal polytope, they prove that the variant is indeed subexponential when run on the dual polytope. That gives a direct bound on the running time of the Sharir-Welzl algorithm, and most recent bound given in <ref> [15] </ref> matches this, with the exception of the constant in the exponent. 5 Implications of AOP results The amazing realization that falls out of Gartner's result [6] is that little of the structure of linear programming is being relied on to prove the subexponential bound on the number of oracle calls.
Reference: [16] <author> N. Megiddo. </author> <title> Linear programming in linear time when the dimension is fixed. </title> <journal> J. ACM, </journal> <volume> 31 </volume> <pages> 114-127, </pages> <year> 1984. </year>
Reference-contexts: For linear programs in fixed dimensions, Megiddo (1983) was first to give a deterministic algorithm whose dependence on n is linear <ref> [16] </ref>. The dependence on d was further improved in 1986 by Dyer [5] and then Clarkson [2].
Reference: [17] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: The reader is refered to [18] for a detailed discussion of linear programming theory, background, and recent results. Also [1] provides an excellent introduction to linear programming and the simplex method. The recent book <ref> [17] </ref> provides a comprehensive discussion of the analysis of randomized algorithms, including specific analysis of several of the LP algorithms discussed here. Throughout this paper, we will make several assumptions which can be removed by standard techniques.
Reference: [18] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> Wiley-Interscience, </publisher> <year> 1986. </year>
Reference-contexts: Geometrically, this is equivalent to finding a vertex x fl extreme in some direction c within the polyhedron P defined by the intersection of a set H of n closed halfspaces in R d . The reader is refered to <ref> [18] </ref> for a detailed discussion of linear programming theory, background, and recent results. Also [1] provides an excellent introduction to linear programming and the simplex method.
Reference: [19] <author> R. Seidel. </author> <title> Small-dimensional linear programming and convex hulls made easy. </title> <journal> Discrete Comput. Geom., </journal> <volume> 6 </volume> <pages> 423-434, </pages> <year> 1991. </year>
Reference-contexts: By using a standard simplex algorithm as a subroutine for solving these small programs, Clarkson's algorithm is still exponential, however the best current bounds are realized by using one of these recent subexponential algorithms as a subroutine. Seidel introduced a simple, randomized, incremental algorithm in 1991 <ref> [19] </ref> which has an expected running time of O (d!n). In 1992, Sharir and Welzl made a simple improvement on this algorithm [20] and proved an expected running fl Department of Computer Science, Stanford University, Stanford, CA, 94305. E-mail: wass@cs.stanford.edu.
Reference: [20] <author> M. Sharir and E. Welzl. </author> <title> A combinatorial bound for linear programming and related problems. </title> <booktitle> In Proc. 9th Sympos. Theoret. Aspects Comput. Sci., volume 577 of Lecture Notes in Computer Science, </booktitle> <pages> pages 569-579. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <month> 9 </month>
Reference-contexts: Seidel introduced a simple, randomized, incremental algorithm in 1991 [19] which has an expected running time of O (d!n). In 1992, Sharir and Welzl made a simple improvement on this algorithm <ref> [20] </ref> and proved an expected running fl Department of Computer Science, Stanford University, Stanford, CA, 94305. E-mail: wass@cs.stanford.edu. <p> The candidate vertex v is thrown away, even though it seems reasonable that constraints defining v are more likely to also define the true optimal vertex. This idea is brought out by the algorithm Matousek, Sharir, Welzl <ref> [20] </ref> [15]. To maintain extra information, they add a second parameter to the algorithm. The LP program is called with two sets, the set of constraints H, and a basis C H. <p> So far this is exactly the same as the algorithm of <ref> [20] </ref>. The efficiency of the randomization relies on the fact that there are enough choices in H F . In [20], they rely on the basis-regular property of LP, and so every candidate F they encounter has cardinality exactly d. <p> So far this is exactly the same as the algorithm of <ref> [20] </ref>. The efficiency of the randomization relies on the fact that there are enough choices in H F . In [20], they rely on the basis-regular property of LP, and so every candidate F they encounter has cardinality exactly d.
References-found: 20

