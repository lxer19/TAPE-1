URL: http://vis-www.cs.umass.edu/vislib/Text/zzhang/91-35.ps.Z
Refering-URL: http://vis-www.cs.umass.edu/vislib/Text/zzhang/files.html
Root-URL: 
Email: NetAd zzhang@cs.umass.EDU  
Phone: Phone (413)545-0528  
Title: SEGMENT-BASED MATCHING FOR VISUAL NAVIGATION  
Author: Zhongfei Zhang Richard Weiss Edward M. Riseman 
Date: May 15, 1994  
Address: Amherst, MA 01003  
Affiliation: Computer and Information Science Department University of Massachusetts  
Abstract: The imaging system involves an image produced from a reflection by a spherical mirror to produce a 360 ffi projection of the environment. This paper extends previous work on an image-based navigation system in which the 360 ffi view is compressed into a circular waveform. A navigation task is specified as a sequence of homing tasks on target locations. This is accomplished by matching landmarks from the current view with the next target view. This paper provides a new method for matching using qualitative geometric features of each of the waveforms. In addition, a geometric analysis allows us to do 3D reasoning about the environment, which is sufficient for computing the rotation and translation between the current location and the target location. It may eventually allow acquisition of a 3D model of the environment. We show that the system performs reliably in an indoor environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Subbarao. </author> <title> Interpretation of Visual Motion: A computational Study, </title> <publisher> Pitman Publishing, </publisher> <address> Lodon, </address> <year> 1988. </year>
Reference-contexts: 1. INTRODUCTION The problem of mobile robot navigation has many approaches including methods of motion analysis <ref> [1] </ref>, associative homing [2], and model-based navigation [3]. This paper extends the work of Hong, Tan, et al [4] on navigation through image-based local homing. Homing is a navigation task in which the goal is one of a fixed set of target locations known to the robot.
Reference: [2] <author> D. Zipser. </author> <title> "Biologically plausible models of place recognition and goal location", Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 2: Psychological and Biological Models, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: 1. INTRODUCTION The problem of mobile robot navigation has many approaches including methods of motion analysis [1], associative homing <ref> [2] </ref>, and model-based navigation [3]. This paper extends the work of Hong, Tan, et al [4] on navigation through image-based local homing. Homing is a navigation task in which the goal is one of a fixed set of target locations known to the robot. <p> Moreover, the error after the robot has homed to each target is not accumulated in the navigation process provided the final pose in each homing stage is a valid initial pose of the next homing stage. Other work on homing includes a system built by Zipser <ref> [2] </ref> in which every current view is compared with every stored view; then an averaged motion vector, weighted by the degree-of-match to each of its corresponding views, is computed to guide the homing process.
Reference: [3] <author> C. Fennema, A. Hanson, E. Riseman, J. Beveridge and R. Kumar. </author> <title> "Model-Directed Mobile Robot Navigation", </title> <journal> To appear in IEEE Transactions on Systems, Man and Cybernetics. </journal>
Reference-contexts: 1. INTRODUCTION The problem of mobile robot navigation has many approaches including methods of motion analysis [1], associative homing [2], and model-based navigation <ref> [3] </ref>. This paper extends the work of Hong, Tan, et al [4] on navigation through image-based local homing. Homing is a navigation task in which the goal is one of a fixed set of target locations known to the robot. <p> Both methods are classified as associative homing, because the actions are associated or derived in some manner from the stored set of patterns. Biological systems utilize associative processing and it is a natural paradigm for parallel hardware. Fennema et al <ref> [3] </ref> use three-dimensional models to generate projections of landmarks expected to 1 be seen from the estimated current location; the robot then servoes directly on the image features, tracking them via correlation. <p> They applied this technique to successfully drive a vehicle at high speeds on the autobahn. The difference between their system and the one used by Fennema et al <ref> [3] </ref> is that the former accomplishes servoing by tracking image features based on an implicit model of the road whereas in the latter system, the tracked features are constructed from landmarks which have been selected from an explict 3D model.
Reference: [4] <author> J. Hong, X. Tan, B. Pinette, R. Weiss and E. Riseman. </author> <title> "Image-Based Navigation Using 360 ffi Views", </title> <booktitle> Proceedings of Image Understanding Workshop 1990, </booktitle> <address> Pittsburg, Pennsylvania, </address> <year> 1990. </year>
Reference-contexts: 1. INTRODUCTION The problem of mobile robot navigation has many approaches including methods of motion analysis [1], associative homing [2], and model-based navigation [3]. This paper extends the work of Hong, Tan, et al <ref> [4] </ref> on navigation through image-based local homing. Homing is a navigation task in which the goal is one of a fixed set of target locations known to the robot. Unlike most homing systems, the navigation problem is treated here as a sequence of homing tasks. <p> The system used local correlation to match between location signatures. That was accomplished under the assumption that there was no rotation and the step distance (i.e., the distance between two adjacent target steps) was small. The system worked well when this condition was satisfied. <ref> [4] </ref> showed an experiment in which the robot successfully moved 17 steps along a hallway. The current work uses the same framework except that the location signature is represented symbolically as a sequence of segments, where each segment is one of three types: increasing, decreasing, and constant. <p> Moreover, they did not compress the image so that their system could only be used in an environment rich in vertical landmarks. In this paper, we continue our previous work on navigation <ref> [4] </ref> by presenting a more robust matching algorithm based on the waveform of signatures and incorporating 3D geometrical reasoning into the system. 2 2. SYSTEM OVERVIEW The physical set-up of the navigation system presented in this paper is shown in Fig. 2 (a) and has been described in [4], with the <p> on navigation <ref> [4] </ref> by presenting a more robust matching algorithm based on the waveform of signatures and incorporating 3D geometrical reasoning into the system. 2 2. SYSTEM OVERVIEW The physical set-up of the navigation system presented in this paper is shown in Fig. 2 (a) and has been described in [4], with the exception that now the camera, together with the spherical mirror, is put on top of the rotation platform of the robot instead of originally being put aside the platform. <p> This will serve to allow some immunity to noise and encross in calibration of the location of the horizon circle <ref> [4] </ref>. The summation of the grey-levels of the 5 pixels along each radial slice results in a waveform that serves as a one-dimensional location signature as depicted in Figs. 6 - 8. <p> Thus, it is possible to compute the current pose (position and orientation) of the robot with respect to the target pose. In other words, we can compute the translation and rotation that will take the robot to the target location. This contrasts with our previous approach in <ref> [4] </ref>, where the rotation was assumed to be very small and only the direction of translation was determined 3 The problem of computing the motion parameters is simplified in the case of a 360 ffi view. <p> It can been seen from the experiments that the correct feature matching rate is around 90%. This represents a significant improvement over the previous approach <ref> [4] </ref> involving only individual normalized segments. Furthermore, the current system works for general planar motion and computes distance to landmarks. 4 Empirically the final error of the derotation is about 3 ffi to 5 ffi . Hence we set 5 ffi as the threshold 14 8.
Reference: [5] <author> R. Nelson. </author> <title> "Visual Homing Using an Associative Memory", </title> <booktitle> Proceedings of Image Understanding Workshop 1989, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> California, </address> <year> 1989. </year>
Reference-contexts: Other work on homing includes a system built by Zipser [2] in which every current view is compared with every stored view; then an averaged motion vector, weighted by the degree-of-match to each of its corresponding views, is computed to guide the homing process. Nelson <ref> [5] </ref> developed a similar system for homing but differed in that it computed the motion associated with the view that best matched its current view. Both methods are classified as associative homing, because the actions are associated or derived in some manner from the stored set of patterns.
Reference: [6] <author> J. R. Beveridge, R. Weiss and E. M. Riseman. </author> <title> "Combinatorial Optimization Applied to Variable Scale 2D Model Matching", </title> <booktitle> Proceedings of the Tenth International Conference on Pattern Recognition, </booktitle> <address> At-lantic City, New Jersey, </address> <month> June, </month> <year> 1990. </year>
Reference-contexts: This kind of 3D model-based navigation has the advantage that it can use precise information about the environment to guide the robot. Beveridge <ref> [6] </ref> and Kumar [7] in related work use 2D matches of projected landmarks to update the 3D location of the robot. Mechanisms have been developed to detect incorrect matches (i.e., outliers) so that the system can remain robust in real scenes. Line tracking techniques have been applied to robot navigation.
Reference: [7] <author> R. Kumar and A. R. Hanson. </author> <title> "Robust Estimation of Camera Location and Orientation from Noisy Data Having Outliers", </title> <booktitle> Proceedings of the Workshop on Interpretation of 3D Scenes, </booktitle> <address> Austin, TX, </address> <month> Nov., </month> <year> 1989. </year>
Reference-contexts: This kind of 3D model-based navigation has the advantage that it can use precise information about the environment to guide the robot. Beveridge [6] and Kumar <ref> [7] </ref> in related work use 2D matches of projected landmarks to update the 3D location of the robot. Mechanisms have been developed to detect incorrect matches (i.e., outliers) so that the system can remain robust in real scenes. Line tracking techniques have been applied to robot navigation.
Reference: [8] <author> E. Dickmanns and V. Graefe. </author> <title> "Dynamic Monocular Machine Vision", Machine Vision and Applications, </title> <type> Vol.1, </type> <year> 1988. </year> <pages> pp. 223-240. </pages>
Reference-contexts: Ayache and Faugeras [10] developed a scheme by using an extended Kalman filter to build visual maps involved in a sequence of images. While this is an important research direction, there are significant difficulties in accurately recovering motion parameters and structure from motion [11, 12]. Dickmanns and Graefe <ref> [8, 9] </ref> also applieded Kalman filters to developing a technique for using image features in a real-time feedback control loop to control the motion of a vehicle. They applied this technique to successfully drive a vehicle at high speeds on the autobahn.
Reference: [9] <author> E. Dickmanns and V. Graefe. </author> <title> "Applications of Dynamic Monocular Machine Vision", Machine Vision and Applications, </title> <type> Vol.1, </type> <year> 1988. </year> <pages> pp. 241-292. </pages>
Reference-contexts: Ayache and Faugeras [10] developed a scheme by using an extended Kalman filter to build visual maps involved in a sequence of images. While this is an important research direction, there are significant difficulties in accurately recovering motion parameters and structure from motion [11, 12]. Dickmanns and Graefe <ref> [8, 9] </ref> also applieded Kalman filters to developing a technique for using image features in a real-time feedback control loop to control the motion of a vehicle. They applied this technique to successfully drive a vehicle at high speeds on the autobahn.
Reference: [10] <author> N. Ayache and Faugeras. </author> <title> "Building, Registrating, and Fusing Noisy Visual Maps", </title> <booktitle> The International Jornal of Robotics Research, </booktitle> <address> Vol.7, No.6, Dec. 1988, </address> <publisher> MIT Press. </publisher>
Reference-contexts: Mechanisms have been developed to detect incorrect matches (i.e., outliers) so that the system can remain robust in real scenes. Line tracking techniques have been applied to robot navigation. Ayache and Faugeras <ref> [10] </ref> developed a scheme by using an extended Kalman filter to build visual maps involved in a sequence of images. While this is an important research direction, there are significant difficulties in accurately recovering motion parameters and structure from motion [11, 12].
Reference: [11] <author> G. Adiv. </author> <title> "Inherent Ambiguities in Recovering 3-D Motion and Structure from a Noisy Flow Field", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.11, </journal> <volume> No.5, </volume> <month> May, </month> <year> 1989. </year>
Reference-contexts: Ayache and Faugeras [10] developed a scheme by using an extended Kalman filter to build visual maps involved in a sequence of images. While this is an important research direction, there are significant difficulties in accurately recovering motion parameters and structure from motion <ref> [11, 12] </ref>. Dickmanns and Graefe [8, 9] also applieded Kalman filters to developing a technique for using image features in a real-time feedback control loop to control the motion of a vehicle. They applied this technique to successfully drive a vehicle at high speeds on the autobahn.
Reference: [12] <author> R. Dutta and M. A. Snyder. </author> <title> "Robustness of Correspondence-Based Structure from Motion", </title> <booktitle> Proceedings of Third International Conference on Computer Vision, </booktitle> <address> Osaka, Japan, </address> <month> Dec., </month> <year> 1990. </year>
Reference-contexts: Ayache and Faugeras [10] developed a scheme by using an extended Kalman filter to build visual maps involved in a sequence of images. While this is an important research direction, there are significant difficulties in accurately recovering motion parameters and structure from motion <ref> [11, 12] </ref>. Dickmanns and Graefe [8, 9] also applieded Kalman filters to developing a technique for using image features in a real-time feedback control loop to control the motion of a vehicle. They applied this technique to successfully drive a vehicle at high speeds on the autobahn.
Reference: [13] <author> J. Zheng and S. Tsuji. </author> <title> "Panoramic Representations of Scenes for Route Understanding", </title> <booktitle> Proceedings of Tenth International Conference on Pattern Recognition, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: Recently, several omnidirectional (i.e., 360 ffi view) image-based navigation techniques have been developed in order to reduce the difficulties in 2D image-based correspondence. An omnidirectional image has the potential advantage in that landmarks do not disappear because of the orientation of the camera or the vehicle. Zheng and Tsuji <ref> [13] </ref> presented an approach to landmark-based navigation in which they use a rotating slit scanner to produce a 360 ffi panoramic view.
Reference: [14] <author> Y. Yagi and S. Kawato. </author> <title> "Panorama Scene Analysis with Conic Projection", </title> <booktitle> Proceedings of IEEE International Workshop on Intelligent Robots and Systems, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: Zheng and Tsuji [13] presented an approach to landmark-based navigation in which they use a rotating slit scanner to produce a 360 ffi panoramic view. Yagi and Kawato <ref> [14] </ref> developed a similar imaging system to ours except that they used a conical mirror instead of a spherical one, and are using the system to attempt reconstruction of a full 3D model of environment.
Reference: [15] <author> E. H. Land and J. J. </author> <title> McCann. </title> <journal> "Lightness and Retinex Theory", Journal of the Optical Society of America, Vol.61, </journal> <volume> No.1, </volume> <year> 1971. </year> <pages> pp. 1-11. </pages>
Reference-contexts: That is, v i ;; = medianfv ; i2 ; v ; i ; v ; i+2 g i = 1; :::; 360 (10) Piecewise fitting is accomplished with the Land-McCann retinex algorithm <ref> [15, 16, 17] </ref> as follows: v i ( ;; ;; ;; ;; i1 otherwise i = 1; :::; 360 (11) where v ;; is a threshold determined dynamically as the standard deviation of v ;; .
Reference: [16] <author> E. H. Land. </author> <title> "Recent Advances in Retinex Theory and Some Implications for Cortical Computations: Color Vision and the Natural Image", </title> <booktitle> Proceedings of National Academy of Sciences, </booktitle> <address> Vol.80, No.16, </address> <year> 1983. </year> <pages> pp. 5163-5169. </pages>
Reference-contexts: That is, v i ;; = medianfv ; i2 ; v ; i ; v ; i+2 g i = 1; :::; 360 (10) Piecewise fitting is accomplished with the Land-McCann retinex algorithm <ref> [15, 16, 17] </ref> as follows: v i ( ;; ;; ;; ;; i1 otherwise i = 1; :::; 360 (11) where v ;; is a threshold determined dynamically as the standard deviation of v ;; .
Reference: [17] <author> B. K. P. Horn. </author> <title> Robot Vision, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year> <pages> pp. 185-200. </pages>
Reference-contexts: That is, v i ;; = medianfv ; i2 ; v ; i ; v ; i+2 g i = 1; :::; 360 (10) Piecewise fitting is accomplished with the Land-McCann retinex algorithm <ref> [15, 16, 17] </ref> as follows: v i ( ;; ;; ;; ;; i1 otherwise i = 1; :::; 360 (11) where v ;; is a threshold determined dynamically as the standard deviation of v ;; .
Reference: [18] <author> R. Y. Tsai and T. S. Huang. </author> <title> "Uniqueness and Estimation of Three-Dimensional Motion Parameters of Rigid Objects with Curved Surfaces", </title> <journal> IEEE Transaction on Pattern Analysis and Machine Intelligence, </journal> <volume> No.6, </volume> <pages> pp. 13 - 26. </pages>
Reference-contexts: The first step of the analysis is to estimate the rotation parameter. 6.2 Estimation of rotation In a general motion model, it has been proved that the rotation and the translation are linearly separable <ref> [18] </ref>, i.e., the rotation and translation can be solved sequentially. This property is also valid in our system, where an image is taken from the reflection off a spherical mirror. Let us consider Fig. 12 again.

References-found: 18

