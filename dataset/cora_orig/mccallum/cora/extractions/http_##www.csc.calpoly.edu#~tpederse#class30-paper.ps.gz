URL: http://www.csc.calpoly.edu/~tpederse/class30-paper.ps.gz
Refering-URL: http://www.csc.calpoly.edu/~tpederse/pubs.html
Root-URL: http://www.csc.calpoly.edu
Email: pedersen@seas.smu.edu  
Title: A Probabilistic Classifier Using Decomposable Models a probabilistic classifier designed for use with decomposable models.
Author: Ted Pedersen 
Date: August 1997  
Address: Dallas, TX 75275-0122 USA  
Affiliation: Department of Computer Science and Engineering Southern Methodist University  
Note: Class.3.0  Class.3.0 is  This document is a tutorial  
Abstract: TECHNICAL REPORT 97-CSE-14 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Badsberg. </author> <title> An Environment for Graphical Models. </title> <type> PhD thesis, </type> <institution> Aalborg University, </institution> <year> 1995. </year>
Reference-contexts: The class of decomposable models was introduced in [3] and described in detail in [4]. 2 Using Class.3.0 Class.3.0 is designed to be used in conjunction with the public-domain program CoCo <ref> [1] </ref> that performs model selection. Each model selected by CoCo is used by Class.3.0 as a probabilistic classifier. Class.3.0 also allows the user to bypass CoCo and input their own decomposable model to use as a classifier. Both modes of operation will be described in this paper.
Reference: [2] <author> R. Bruce and J. Wiebe. </author> <title> Word-sense disambiguation using decomposable models. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 139-146, </pages> <year> 1994. </year>
Reference-contexts: This classifier is designed for supervised learning experiments. It has been used in a series of published studies (e.g., [5], [6],[7]). All of this work used the class of decomposable probabilistic models as classifiers for word sense disambiguation as proposed in <ref> [2] </ref>. The class of decomposable models was introduced in [3] and described in detail in [4]. 2 Using Class.3.0 Class.3.0 is designed to be used in conjunction with the public-domain program CoCo [1] that performs model selection. Each model selected by CoCo is used by Class.3.0 as a probabilistic classifier.
Reference: [3] <author> J. Darroch, S. Lauritzen, and T. </author> <title> Speed. Markov fields and log-linear interaction models for contingency tables. </title> <journal> The Annals of Statistics, </journal> <volume> 8(3) </volume> <pages> 522-539, </pages> <year> 1980. </year>
Reference-contexts: It has been used in a series of published studies (e.g., [5], [6],[7]). All of this work used the class of decomposable probabilistic models as classifiers for word sense disambiguation as proposed in [2]. The class of decomposable models was introduced in <ref> [3] </ref> and described in detail in [4]. 2 Using Class.3.0 Class.3.0 is designed to be used in conjunction with the public-domain program CoCo [1] that performs model selection. Each model selected by CoCo is used by Class.3.0 as a probabilistic classifier.
Reference: [4] <author> S. Lauritzen. </author> <title> Graphical Models. </title> <publisher> Oxford University Press, </publisher> <address> New York, NY, </address> <year> 1996. </year>
Reference-contexts: It has been used in a series of published studies (e.g., [5], [6],[7]). All of this work used the class of decomposable probabilistic models as classifiers for word sense disambiguation as proposed in [2]. The class of decomposable models was introduced in [3] and described in detail in <ref> [4] </ref>. 2 Using Class.3.0 Class.3.0 is designed to be used in conjunction with the public-domain program CoCo [1] that performs model selection. Each model selected by CoCo is used by Class.3.0 as a probabilistic classifier.
Reference: [5] <author> T. Pedersen. </author> <title> Naive mixes for word sense disambiguation. </title> <booktitle> In Proceedings of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <pages> page 841, </pages> <address> Providence, RI, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: 1 Introduction This is a general overview of the probabilistic classifier Class.3.0. This classifier is designed for supervised learning experiments. It has been used in a series of published studies (e.g., <ref> [5] </ref>, [6],[7]). All of this work used the class of decomposable probabilistic models as classifiers for word sense disambiguation as proposed in [2]. <p> The file SAMPLEALL.MIXTURE shows the results of "mixing" all the probabilities for all the models found and using that mixture as the basis of classification. The mixture created is known as the Naive Mix and is described in detail in <ref> [5] </ref> and [6]. The file SAMPLEALL.RUNALL shows the series of classify dat cond and grep commands that are used to create the faccuracy,precision,recallg results. This file also shows the actual form of the models selected.
Reference: [6] <author> T. Pedersen and R. Bruce. </author> <title> A new supervised learning algorithm for word sense disambiguation. </title> <booktitle> In Proceedings of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 604-609, </pages> <address> Providence, RI, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: The file SAMPLEALL.MIXTURE shows the results of "mixing" all the probabilities for all the models found and using that mixture as the basis of classification. The mixture created is known as the Naive Mix and is described in detail in [5] and <ref> [6] </ref>. The file SAMPLEALL.RUNALL shows the series of classify dat cond and grep commands that are used to create the faccuracy,precision,recallg results. This file also shows the actual form of the models selected.
Reference: [7] <author> T. Pedersen, R. Bruce, and J. Wiebe. </author> <title> Sequential model selection for word sense disambiguation. </title> <booktitle> In Proceedings of the Fifth Conference on Applied Natural Language Processing, </booktitle> <pages> pages 388-395, </pages> <address> Washington, DC, </address> <month> April </month> <year> 1997. </year> <month> 5 </month>
References-found: 7

