URL: http://www.cs.columbia.edu/~simonb/papers/bw.ps.gz
Refering-URL: http://www.cs.columbia.edu/~simonb/
Root-URL: http://www.cs.columbia.edu
Title: Design and Evaluation of Feature Detectors  
Author: Simon Baker 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences  
Date: 1998  
Affiliation: Columbia University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> I.E. Abdou and W.K. Pratt. </author> <title> Quantitative design and evaluation of enhancement/thresholding edge detectors. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 67(5) </volume> <pages> 753-763, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: In Cartesian coordinates, this corresponds to using the weighting function w (x; y) = 1=(x 2 + y 2 ) 1=2 . Another example of the use of non-uniformly weighted L 2 norms is <ref> [1] </ref>. In this paper, Abdou and Pratt mention that weighting the pixels so as to reduce the influence of pixels that are distant from the center pixel improves Pratt's Figure of Merit [100], but few details are given. <p> Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], <ref> [1] </ref>, [80], [103], and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], <ref> [1] </ref>, [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> These measures have also been widely studied, including in [31], <ref> [1] </ref>, [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge [20] [27]. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. <p> There are at least four ways of estimating the measures in the absence of ground truth: Mathematical Analysis: If the feature detection algorithm is simple enough, it is sometimes possible to derive analytical expressions for some of the performance measures. For example, Abdou and Pratt <ref> [1] </ref> analyze the robustness of several simple edge detectors, Berzins [11] analyzes the localization estimation of a Laplacian edge detector, and Ramesh and Haralick [103] analyze the robustness and parameter estimation accuracy of two different detectors. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], <ref> [1] </ref>, [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap. <p> After computing the coefficients c ij for every manifold sample point using the method described above, I randomly generated a sequence of ideal feature instances. The normalized parameters A and B of the feature were generated uniformly at random in the interval <ref> [0; 1] </ref>. To generate the unnormalized parameters, a point on the manifold was chosen uniformly at random and its un-normalized parameters used. Then I generated the ideal feature using the feature and sensor models described above. <p> One example is FDR p fi CPE 1p , where p 2 <ref> [0; 1] </ref> is a number that can be used to adjust the relative importance of feature detection robustness and parameter estimation accuracy.
Reference: [2] <author> J.F. Abramatic. </author> <title> Why the simplest "Hueckel" edge detector is a Roberts operator. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 17 </volume> <pages> 79-83, </pages> <year> 1981. </year>
Reference-contexts: Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld [107] and Abramatic <ref> [2] </ref> studied the Hueckel [50] and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator.
Reference: [3] <author> A.C. Aitken. </author> <title> On least squares and linear combinations of observations. </title> <journal> Proceedings of the Royal Society of Edinburgh A, </journal> <volume> 55 </volume> <pages> 42-47, </pages> <year> 1934. </year>
Reference-contexts: So, finding the optimal weighting function corresponds to selecting the weighting function that gives the best linear unbiased estimate of the solution to a weighted least squares problem [63] [99]. The answer to this problem was found by Aitken in <ref> [3] </ref>. The optimal weighting function is: w (n; m) = Var [(n; m)] where Var [(n; m)] = E [ 2 (n; m)] E [(n; m)] 2 is the variance of the noise in pixel (n; m). This result assumes that the noise in each pixel in independent.
Reference: [4] <author> S. Baker and S.K. Nayar. </author> <title> Algorithms for pattern rejection. </title> <booktitle> In Proceedings of the 13th International Conference on Pattern Recognition, volume II Track B, </booktitle> <pages> pages 869-874, </pages> <address> Vienna, Austria, </address> <month> August </month> <year> 1996. </year> <month> IAPR. </month>
Reference-contexts: Further, the search does not need to be performed at every pixel. Amongst other techniques, I use a pattern rejection algorithm <ref> [4] </ref> [5] to eliminate a vast majority of pixels without even needing to project fully into the low dimensional subspace. Such a rejection scheme is effective since most pixels in an image will typically not exhibit the feature of interest. <p> Since the distance from the subspace 59 is approximately a lower bound on the distance from the manifold, the pixel can be eliminated if the input is too far from the subspace. Finally, using the pattern rejection techniques in <ref> [4] </ref> and [5], it is even possible to eliminate most of the cost of computing the distance to the K-L subspace. Parallel Implementation: Feature detection is inherently a parallelizable task because a detector can be applied to each pixel independently.
Reference: [5] <author> S. Baker and S.K. Nayar. </author> <title> Pattern rejection. </title> <booktitle> In Proceedings of the 1996 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 544-549, </pages> <address> San Francisco, California, June 1996. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Further, the search does not need to be performed at every pixel. Amongst other techniques, I use a pattern rejection algorithm [4] <ref> [5] </ref> to eliminate a vast majority of pixels without even needing to project fully into the low dimensional subspace. Such a rejection scheme is effective since most pixels in an image will typically not exhibit the feature of interest. <p> Since the distance from the subspace 59 is approximately a lower bound on the distance from the manifold, the pixel can be eliminated if the input is too far from the subspace. Finally, using the pattern rejection techniques in [4] and <ref> [5] </ref>, it is even possible to eliminate most of the cost of computing the distance to the K-L subspace. Parallel Implementation: Feature detection is inherently a parallelizable task because a detector can be applied to each pixel independently.
Reference: [6] <author> S. Baker, S.K. Nayar, and H. Murase. </author> <title> Parametric feature detection. </title> <journal> International Journal of Computer Vision, </journal> <volume> 27(1) </volume> <pages> 27-50, </pages> <year> 1998. </year> <month> 154 </month>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in <ref> [6] </ref>. <p> Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], [95], [80], and <ref> [6] </ref>. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap.
Reference: [7] <author> D.F. Barbe. </author> <title> Charge-Coupled Devices. </title> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular <ref> [7] </ref> [85], the averaging function is simply the rectangular function [15]: a (x; y) = w x w y 1 x; w y where w x and w y are the x and y dimensions of the pixel. Second, the pixels are sampled.
Reference: [8] <author> P.R. Beaudet. </author> <title> Rotational invariant image operators. </title> <booktitle> In Proceedings of the 4th International Conference on Pattern Recognition, </booktitle> <pages> pages 579-583, </pages> <address> Tokyo, Japan, </address> <year> 1978. </year>
Reference-contexts: Perhaps the first differential invariant corner detector was the Beaudet detector <ref> [8] </ref>.
Reference: [9] <author> S. Becker and Jr. </author> <title> V.M. Bove. Semiautomatic 3-D model extraction from uncalibrated 2-D camera views. </title> <booktitle> In Proceedings of SPIE Visual Data Exploration and Analysis II, </booktitle> <volume> volume 2410, </volume> <pages> pages 447-461, </pages> <address> San Jose, California, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: If a shorter focal length was ever needed, Tsai's algorithm could easily be used to compensate for any noticeable radial distortion. Finally, note that measures 123 similar to my global measures of coherence have actually been used in the past to perform camera calibration for the radial distortion <ref> [9] </ref> [18]. 6.3.2 Efficient Computation using Monte Carlo Since the number of detected edges is usually at most n = 10 3 , it is possible to compute the first three measures by simply enumerating all pairs of edges.
Reference: [10] <author> F. Bergholm. </author> <title> Edge focusing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(6) </volume> <pages> 726-741, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: The primary goal of scale space theory, at least as far as feature detection is concerned, is to combine the outputs of operators at multiple scales in a coherent manner [79]. A number of attempts have been made at studying the output of detectors across scales, including, <ref> [10] </ref>, [61], and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. <p> A number of attempts have been made at studying the output of detectors across scales, including, <ref> [10] </ref>, [61], and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions.
Reference: [11] <author> V. Berzins. </author> <title> Accuracy of Laplacian edge detectors. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 27 </volume> <pages> 195-210, </pages> <year> 1984. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy <ref> [11] </ref> [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], [1], <ref> [11] </ref>, [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> For example, Abdou and Pratt [1] analyze the robustness of several simple edge detectors, Berzins <ref> [11] </ref> analyzes the localization estimation of a Laplacian edge detector, and Ramesh and Haralick [103] analyze the robustness and parameter estimation accuracy of two different detectors. <p> Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. He proceeded to show how the systematic bias of the Laplacian of Gaussian can be corrected. A related study, with somewhat different goals, is that of Berzins <ref> [11] </ref>. A very important issue related to that of scale is the information content of edges. One of the major reasons for detecting edges is their supposedly high information content [70].
Reference: [12] <author> R.A. Boie, I.J. Cox, and P. Rehak. </author> <title> On optimum edge recognition using matched filters. </title> <booktitle> In Proceedings of the 1986 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 100-108, </pages> <year> 1986. </year>
Reference-contexts: Canny's first two criteria correspond directly to these aspects of performance: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non edge points (ie. false positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Therefore, he used the SNR as his first optimality criterion. Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. <p> positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Therefore, he used the SNR as his first optimality criterion. Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. In [20], Canny initially tried to optimize the product of these first two criteria. <p> In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. Hence, Canny introduced a third optimality criteria to address this problem: Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" <ref> [12] </ref>. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. 18 2.3.2 Deriving the Optimal Filter There are various different ways of combining Canny's three criteria. <p> The most well known are the three criteria proposed by Canny in [20]: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non-edge points (ie. false positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Hence, he used the SNR as his first optimality criterion. 90 Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. <p> <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Hence, he used the SNR as his first optimality criterion. 90 Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. <p> edge" <ref> [12] </ref>. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. <p> "only one response to a single edge" <ref> [12] </ref>. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [13] <author> M. Born and E. Wolf. </author> <title> Principles of Optics. </title> <publisher> Permagon Press, </publisher> <year> 1965. </year>
Reference-contexts: Hence, I develop an approach that can handle spatially varying blur. The defocus factor can be approximated by a pillbox function 36 <ref> [13] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [13], and the blurring due to imperfections in the feature by a Gaussian [60]. <p> Hence, I develop an approach that can handle spatially varying blur. The defocus factor can be approximated by a pillbox function 36 <ref> [13] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [13], and the blurring due to imperfections in the feature by a Gaussian [60].
Reference: [14] <author> A.C. Bovik, T.S. Huang, and D.C. Munson Jr. </author> <title> Nonparametric tests for edge detection in noise. </title> <journal> Pattern Recognition, </journal> <volume> 19(3) </volume> <pages> 209-219, </pages> <year> 1986. </year>
Reference-contexts: In [42], Haralick proposed an edge detector using the F -statistic to test the statistical significance of the difference between the parameters of the best fitting sloped surfaces in neighboring pixels. Bovik et al. <ref> [14] </ref> proposed three different statistical tests for edge detection, two based upon linear rank sums and one based upon fitting order statistics.
Reference: [15] <author> R.N. Bracewell. </author> <title> The Fourier Transform and Its Applications. </title> <address> McGraw Hill, </address> <note> second edition edition, 1978. 155 </note>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular [7] [85], the averaging function is simply the rectangular function <ref> [15] </ref>: a (x; y) = w x w y 1 x; w y where w x and w y are the x and y dimensions of the pixel. Second, the pixels are sampled.
Reference: [16] <author> M. Brady. </author> <title> Computational approaches to image understanding. </title> <journal> Computing Surveys, </journal> <volume> 14(1) </volume> <pages> 2-71, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady <ref> [16] </ref>. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors.
Reference: [17] <author> M.J. Brooks. </author> <title> Rationalizing edge detectors. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 8 </volume> <pages> 277-285, </pages> <year> 1978. </year>
Reference-contexts: Such papers include [117], [71], and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" <ref> [17] </ref>. The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. <p> Such papers include [117], [71], and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" <ref> [17] </ref>. The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. <p> In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. Both Brooks <ref> [17] </ref> and Haralick [42] tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115].
Reference: [18] <author> D.C. Brown. </author> <title> Close-range camera calibration. </title> <booktitle> In Symposium on close-range photogrametry, </booktitle> <address> Urbana, Illinois, </address> <month> January </month> <year> 1971. </year>
Reference-contexts: If a shorter focal length was ever needed, Tsai's algorithm could easily be used to compensate for any noticeable radial distortion. Finally, note that measures 123 similar to my global measures of coherence have actually been used in the past to perform camera calibration for the radial distortion [9] <ref> [18] </ref>. 6.3.2 Efficient Computation using Monte Carlo Since the number of detected edges is usually at most n = 10 3 , it is possible to compute the first three measures by simply enumerating all pairs of edges.
Reference: [19] <author> D.J. Bryant and D.W. Bouldin. </author> <title> Evaluation of edge operators using relative and absolute grading. </title> <booktitle> In Proceedings of the IEEE Conference on Pattern Recognition and Image Processing, </booktitle> <pages> pages 138-145, </pages> <address> Chicago, IL, </address> <year> 1979. </year>
Reference-contexts: An alternative approach is to apply a number of detectors and use the consensus as the ground truth <ref> [19] </ref>. However, the assumption that the consensus gives a good estimate of the ground ruth is questionable.
Reference: [20] <author> J. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(6) </volume> <pages> 679-698, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: However, the window could be approximately circular, and might contain anywhere from 4 to 100 pixels. In particular, I explicitly rule out all feature aggregation and adaptive thresholding algorithms. The most well known example of such a technique is Canny's hysteresis <ref> [20] </ref>. Many such techniques dramatically improve the performance of all feature detectors. Here, I am solely interested in how well feature detection can be performed without them. <p> Various optimality criteria have been proposed in the literature, however the most well known and thoroughly studied are the three criteria proposed by Canny in <ref> [20] </ref>. The remainder of this section is organized as follows. I begin in Section 2.3.1 by describing Canny's three optimality criteria. In Section 2.3.2, I discuss the various ways that these criteria have been combined and the alternative approaches that have be used to optimize them. <p> Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. In <ref> [20] </ref>, Canny initially tried to optimize the product of these first two criteria. The optimal filter is the matched filter, or difference of boxes operator [35]. Unfortunately, this detector is well known to perform quite poorly. <p> Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge <ref> [20] </ref> [27]. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. <p> Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. Further, Torre and Poggio also examined the relationship between Laplacian edge detectors such as [70] and second directional derivative operators such as <ref> [20] </ref> and [42]. 2.6.2 Sensor Modeling and Sub-Pixel Localization Most of the previous work on feature detection has assumed that the artifacts introduced by the imaging system are negligible and can be ignored. One exception is [94]. <p> Nalwa simply suggested that the image is sub-sampled. Another example of sensor modeling is [97]. Petrou and Kittler argue that ideal step edges do not occur in real images. Instead, real edges are actually ramp edges. They follow the approach of Canny <ref> [20] </ref> and derive optimal filters for ramp edges, which they claim yield better performance than filters designed for ideal step edges. <p> In particular, in their Laplacian of Gaussian detector, the standard deviation of the Guassian is used to control the scale by changing the amount of blurring. Later, Canny used the same technique to define the scale of his detector <ref> [20] </ref>. Moreover, an entire theory of scale space has been developed, beginning with the work of Witken [118] and then of Koenderink [60]. These initial papers established the desirable properties of the Gaussian smoothing for scale space. <p> In Section 3.4, I describe the detection al 34 gorithm in detail. In particular, I describe manifold sampling, the coarse-to-fine search, and the use of rejection techniques. In the following chapter, I present experimental results obtained for the five example features, including comparisons with a Canny-like operator <ref> [20] </ref> and the Nalwa-Binford [80] detector. 3.2 Parametric Feature Representation I begin this section by first introducing the notion of a parametric scene feature. I then describe my model of the imaging system, and how this model leads to imaged features being represented as parametric manifolds. <p> In both cases, I compare the step edge detector developed in the previous chapter with a Canny-like operator <ref> [20] </ref> and the Nalwa-Binford [80] detector. In doing so, the aim is to demonstrate that the parametric manifold step edge detector performs comparably to these well known and highly regarded detectors. I also compare the performance of the parametric manifold technique across the five example features. <p> This implementation is publically available on the Web from the URL http://www.cs.curtin.edu.au/ ~ geoff/. Geoff West's implementation only computes the Gaussian smoothed gradient, which I simply threshold to detect edges. For simplicity, I do not find the zero crossing of the second directional derivative. Neither do I perform hysteresis <ref> [20] </ref> since it uses information derived from neighboring windows, something I explicitly outlawed in this thesis. 64 false negatives parameterized by the appropriate threshold. The closer a curve lies to the origin in Figure 4.1, the better the performance. <p> The most well known are the three criteria proposed by Canny in <ref> [20] </ref>: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non-edge points (ie. false positives)" [12]. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). <p> In Section 5.3.3, I discuss how these three optimality criteria can be combined. I do not consider the "Few Multiple Responses" criterion in this paper since its introduction in <ref> [20] </ref> was for technical reasons, rather than 91 because it is a fundamental element of feature detection performance. 5.3.1 Feature Detection Robustness Feature detection is not robust, both when the detector misses features (false negatives), and when the detector mistakenly detects features that are not present (false positives). <p> After taking into account both parameter normalization and dimension reduction, the optimality criteria become extremely complex. Even Canny resorted to a numerical algorithm to optimize his relatively simple optimality criterion for arbitrary features <ref> [20] </ref>. Here, I follow the same approach. If there are N pixels in the discrete feature window S, the optimization is N 1 dimensional rather than N dimensional because the optimality criteria are unchanged if the weighting function is multiplied by a positive constant. <p> The optimal weighting function for the parameter estimation accuracy of the sub-pixel localization of the step edge is presented in Figure 5.1 (a). The overall form of this optimal weighting function is as expected. Intuitively, the center-most pixels are the most important when estimating sub-pixel localization <ref> [20] </ref>. Hence, it is to be expected that they should be given more weight. The results in Figure 5.1 (c) for the combined parameter estimation accuracy of the corner are also in agreement with intuition. Here, the central pixels do not change much as the parameters of the corner vary. <p> have been used in a number of model matching detectors (see Section 2.1.3), and (2) the 105 of the noise across the pixels. 5.5.2 Relationship with Canny I now discuss the relationship between the approach described in this chapter and the optimal filtering approach to edge detection best exemplified by <ref> [20] </ref>. <p> On the other hand, Canny <ref> [20] </ref> studied the selection of the filter f (x) that optimizes the performance of a 1-D step edge detector that declares edges at local maxima of: Z +W I (a + x) f (x) dx (5.28) where I (x) is the continuous 1-D input image and W is the width of <p> So, if there is a sub-pixel localization parameter, model matching implicitly performs the same local non-maximum suppression that the Canny detector does. If there is a rotation parameter, model matching also optimizes over it. There is no equivalent in <ref> [20] </ref> because the formulation is entirely 1-D. Note, however, that steerable filters provide a way of optimizing over the rotation parameter [37]. A final difference is the normalization of the image data. <p> A number of post-processing and feature aggregation algorithms have been proposed in the literature, perhaps the most well known being Canny's adaptive thresholding technique, hysteresis <ref> [20] </ref>. In this thesis, I focused exclusively on how well feature detection can be performed without using such techniques.
Reference: [21] <author> S. Castan, J. Zhao, and J. Shen. </author> <title> New edge detection methods based on exponential filter. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pages 709-711, </pages> <year> 1990. </year>
Reference-contexts: For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. <ref> [21] </ref> used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. Hashimoto and Sklansky [41] and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se.
Reference: [22] <author> J.S. Chen, A. Huertas, and G. Medioni. </author> <title> Fast convolution with Laplacian-of-Gaussian masks. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(4) </volume> <pages> 584-590, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency <ref> [22] </ref> [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. <ref> [22] </ref>, a technique that was later refined by Sotak and Boyer [54]. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. <ref> [22] </ref>, a technique that was later refined by Sotak and Boyer [54]. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference.
Reference: [23] <author> K. Cho, P. Meer, and J. Cabrera. </author> <title> Performance assessment through bootstrap. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(11) 1185-1198, November 1997. 
Reference-contexts: A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. <ref> [23] </ref>, is to use a statistical technique known as bootstrap. Bootstrap, although it can be applied to real image data, still makes several 23 strong assumptions about the nature of a feature and the noise processes.
Reference: [24] <author> C. Coehlo, A. Heller, J.L. Mundy, D.A. Forsyth, and A. Zisserman. </author> <title> An experimental evaluation of projective invariants. </title> <editor> In J.L Mundy and A. Zisserman, </editor> <title> 156 editors, Geometric Invariants for Machine Vision, </title> <booktitle> chapter 4, </booktitle> <pages> pages 87-104. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants <ref> [24] </ref>, object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121].
Reference: [25] <author> J.B. Conway. </author> <title> A Course in Functional Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: I now introduce weighted L 2 norms as a class of possible matching functions to choose from. Every measure w on the pixels leads to a different L 2 norm, denoted by either L 2 (w) or k k w <ref> [25] </ref>. A measure is defined by the weight w = w (n; m) 0 that it assigns to each of the pixels (n; m) 2 S.
Reference: [26] <author> L.S. Davis. </author> <title> A survey of edge detection techniques. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 248-270, </pages> <year> 1975. </year>
Reference-contexts: In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis <ref> [26] </ref> and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors.
Reference: [27] <author> D. Demigny and T. Kamle. </author> <title> A discrete expression for Canny's criteria for step edge detector performance evaluation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(11) 1199-1211, November 1997. 
Reference-contexts: Another optimal (IIR) filter is the Sarkar-Boyer detector [109]. Rather than using Canny's third criterion, Sarkar and Boyer used a slightly different criterion designed to measure the likelihood of spurious responses to noise. Finally, Demigny and Kamle <ref> [27] </ref> derived discrete versions of Canny's three criteria and used them to compare the performance of various step edge detectors. 2.3.3 Other Optimality Criteria Several other optimality criteria have been proposed. <p> Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge [20] <ref> [27] </ref>. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. <p> Instead, real edges are actually ramp edges. They follow the approach of Canny [20] and derive optimal filters for ramp edges, which they claim yield better performance than filters designed for ideal step edges. Finally, Demigny and Kamle <ref> [27] </ref> derived discrete (ie. pixel based) versions of Canny's three optimality criteria. 25 They used these criteria to compare the performance of various edge detectors. 2.6.3 Efficient Filtering There are a number of techniques that can be used to implement 2-D filtering operations efficiently.
Reference: [28] <author> R. Deriche. </author> <title> Optimal edge detection using recursive filtering. </title> <booktitle> In Proceedings of the First International Conference on Computer Vision, </booktitle> <pages> pages 501-505, </pages> <year> 1987. </year>
Reference-contexts: Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], <ref> [28] </ref>, [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [29] <author> R. Deriche. </author> <title> Using Canny's criteria to derive a recursively implemented optimal edge detector. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 167-187, </pages> <year> 1987. </year>
Reference-contexts: As discussed by Faugeras in [35], this method naturally corresponds to the use of a filter with finite extent. On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity <ref> [29] </ref>. The result is a filter with a better value for the product of Canny's first two optimality criteria [35]. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. <p> infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity <ref> [29] </ref>. The result is a filter with a better value for the product of Canny's first two optimality criteria [35]. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. A number of other authors have studied Canny's three criteria, and variants thereof. Rather than considering the product of the first two criteria while keeping the third one fixed, Spacek chose to optimize the product of all three criteria [113]. <p> If the z-transform of the filter also happens to be of this form, it can be implemented using the recursive relationship. A constant amount of computation is needed per pixel to implement these recursive relationships. For example, the infinite Deriche filter <ref> [29] </ref> can be implemented with 5 additions and 5 multiplications per pixel [35]. <p> Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], <ref> [29] </ref>, [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [30] <author> R. Deriche and G. Giraudon. </author> <title> A computational approach for corner and vertex detection. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(2) </volume> <pages> 101-124, </pages> <year> 1993. </year>
Reference-contexts: Nevatia found that using a subspace with too low a dimension does indeed reduce the performance of a detector. 2.2 Differential Invariant Feature Detectors The second major class of feature detectors consists of those based upon differential invariants. Well known examples include the Deriche corner detector <ref> [30] </ref>, the Haralick step edge detector [44], and the Marr-Hildreth step edge detector [70]. As indicated by the name, these detectors base their detection decisions upon differential invariants estimated from the image data. <p> Invariant Corner Detectors Whereas much of the literature on edge detection has concentrated on how to compute the three major differential invariants (the gradient, the Laplacian, and the second directional derivative in the direction of the gradient), the work on corner detection has largely focused on the differential invariants themselves <ref> [30] </ref>. Perhaps the first differential invariant corner detector was the Beaudet detector [8]. <p> A number of attempts have been made at studying the output of detectors across scales, including, [10], [61], and <ref> [30] </ref>. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. <p> of attempts have been made at studying the output of detectors across scales, including, [10], [61], and <ref> [30] </ref>. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. He proceeded to show how the systematic bias of the Laplacian of Gaussian can be corrected. A related study, with somewhat different goals, is that of Berzins [11]. <p> Most existing corner detectors are based upon differential invariant based measures of curvature <ref> [30] </ref>, but Rohr [106] recently proposed a parametric model matching approach to corner detection. The simplest way to think about a corner is as the intersection of two non-parallel step edges.
Reference: [31] <author> E.S. Deutsch and J.R. Fram. </author> <title> A quantitative study of the orientation bias of some edge detector schemes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 27(3) </volume> <pages> 205-213, </pages> <month> March </month> <year> 1978. </year>
Reference-contexts: These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in <ref> [31] </ref>, [1], [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], <ref> [31] </ref>, [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap.
Reference: [32] <author> S. Dougherty and K.W. Bowyer. </author> <title> Objective evaluation of edge detectors using a formally defined framework. </title> <booktitle> In Proceedings of the 1998 Workshop on 157 Empirical Evaluation Techniques in Computer Vision, </booktitle> <pages> pages 211-234, </pages> <address> Santa Barbara, California, June 1998. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], [1], [80], [103], and <ref> [32] </ref> Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> In fact, in a recent paper in which this approach is taken, Dougherty and Bowyer allowed the human to mask out any regions for which it was too difficult for the human to say which pixels contain edges <ref> [32] </ref>. An alternative approach is to apply a number of detectors and use the consensus as the ground truth [19]. However, the assumption that the consensus gives a good estimate of the ground ruth is questionable. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including <ref> [32] </ref>, [47], [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently. <p> In this section, I describe how one of these thresholds can be left unset. The performance of each edge detector is then characterized by a curve parameterized by the free threshold. In <ref> [32] </ref>, Dougherty and Bowyer used a generalization of this technique to allow more than one threshold to be left unspecified. <p> In fact, in a recent paper in which edge detectors are evaluated by getting a human to mark the edges in an image by hand, Dougherty and Bowyer allowed the human to mask out certain regions as too difficult for the human to say which pixels contain edges <ref> [32] </ref>. The three major advantages of using global measures of coherence are: 1. They use a very large number of real images.
Reference: [33] <author> L. Dreschler and H.H. Nagel. </author> <title> On the selection of critical points and local curvature extrema of region boundaries for interframe matching. </title> <booktitle> In Proceedings of the 6th International Conference on Pattern Recognition, </booktitle> <pages> pages 542-544, </pages> <year> 1982. </year>
Reference-contexts: Two corner detectors closely related to the Kitchen-Rosenfeld detector are the Dreschler-Nagel detector <ref> [33] </ref> and the Zuniga-Haralick detector [123]. Nagel 15 showed that the Dreschler-Nagel detector and the Kitchen-Rosenfeld detector are equivalent if the heuristic of nonmaximum suppression along the gradient is applied to the gradient before multiplying by the gradient magnitude [76].
Reference: [34] <author> J. Elder and S. Zucker. </author> <title> Scale space localization blur and contour-based image coding. </title> <booktitle> In Proceedings of the 1996 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 27-34, </pages> <address> San Francisco, California, June 1996. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69]. In spite of this result, a number of algorithms have been proposed to invert the edge detection process that work very well in practice [69] <ref> [34] </ref>. 29 Chapter 3 Parametric Feature Detection 3.1 Introduction As can be seen from the literature survey in Chapter 2, the most frequently studied image feature is the step edge.
Reference: [35] <author> O.D. Faugeras. </author> <title> Three-dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Introduction Feature detection is one of the fundamental tasks in computer vision. It has received widespread coverage in both the research literature and in vision textbooks such as [48], <ref> [35] </ref>, and [79]. Some of the major applications of feature detection include: Stereo: One of the most popular methods of performing correspondence matching along epipolar lines consists of matching detected edge features. Object Recognition: Many object recognition algorithms start by detecting edge or corner features. <p> In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras <ref> [35] </ref>. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors. From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. <p> This filtering step 13 can be regarded as implicitly interpolating the image data to create a continuous surface. For this reason, there is a close relationship with surface fitting differential invariant detectors. As pointed out by Faugeras in <ref> [35] </ref>, surface fitting can also be regarded as another form of regularization To design a filtering differential invariant detector, decisions must be made on two major points: (1) the shape of the filter, and (2) the differential invariant. <p> The second method of computing the differential invariants in the previous section was by filtering. Optimal filtering edge detectors operate by declaring edges at local "extrema in the output of the convolution of the image with a [filter]" of an appropriate shape <ref> [35] </ref>. Then, the key question for optimal filtering detectors is the shape of filter. <p> In [20], Canny initially tried to optimize the product of these first two criteria. The optimal filter is the matched filter, or difference of boxes operator <ref> [35] </ref>. Unfortunately, this detector is well known to perform quite poorly. In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. <p> The optimal filter is the matched filter, or difference of boxes operator <ref> [35] </ref>. Unfortunately, this detector is well known to perform quite poorly. In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. Hence, Canny introduced a third optimality criteria to address this problem: Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. <p> Canny himself optimized the product of the first two criteria, while keeping the third one fixed. As discussed by Faugeras in <ref> [35] </ref>, this method naturally corresponds to the use of a filter with finite extent. On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity [29]. <p> On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity [29]. The result is a filter with a better value for the product of Canny's first two optimality criteria <ref> [35] </ref>. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. A number of other authors have studied Canny's three criteria, and variants thereof. <p> One example of a paper that uses the fast Fourier transform to implement a filtering operation efficiently is Shanmugam et al. [111]. Another technique, that can often be even more efficient than Fourier domain processing, is recursive filtering [100] <ref> [35] </ref>. Perhaps even more importantly, recursive filtering can be used to implement certain infinite impulse response (IIR) filters, which otherwise could only be truncated and approximated as a finite input response (FIR) filter. Recursive filtering is based upon a recursive relationship between the filtered image and the input image. <p> A constant amount of computation is needed per pixel to implement these recursive relationships. For example, the infinite Deriche filter [29] can be implemented with 5 additions and 5 multiplications per pixel <ref> [35] </ref>. Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer [54]. <p> Given just one of the detected edges e i = (x i ; y i ; i ) 2 E, it is possible to estimate the line that of all the edges lie on. In the projective geometric notation of <ref> [35] </ref>, the vector representation of this line is: L i l 1 i ; l 3 T = ( sin i ; cos i ; x i sin i y i cos i ) : (6.2) A minor difficulty that needs to be addressed at this point is that equality is <p> i ; l 3 T = ( sin i ; cos i ; x i sin i y i cos i ) : (6.2) A minor difficulty that needs to be addressed at this point is that equality is only defined up to a constant multiplicative factor in projective spaces <ref> [35] </ref>. There are two aspects to this problem: Sign of L i : Adding 180 ffi to i does not change the line, but reverses the sign of L i . <p> 0 (6.18) where x = (x; y; 1) T is a homogeneous vector of image coordinates, and: A = B B B @ 1 1 1 1 1 1 1 C C C (6.19) is a 3 fi 3 symmetric matrix, as usual only defined up to a scale factor <ref> [35] </ref>. So, the matrix A has just five independent parameters.
Reference: [36] <author> J.R. Fram and E.S. Deutsch. </author> <title> On the quantitative evaluation of edge detection schemes and their comparison with human performance. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 24(6) </volume> <pages> 616-628, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in <ref> [36] </ref>, [1], [80], [103], and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, <ref> [36] </ref>, [31], [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap. <p> Although nearly all feature detection papers do this, they typically do it in a very informal manner. It is possible to perform such a comparison in a more formal way, as was done in <ref> [36] </ref> and [47]. Even when done scientifically, such techniques still have the inherent weakness that they rely upon the subjective opinion of humans who can bring higher level processing to bear.
Reference: [37] <author> W.T. Freeman and E.H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: If there is a rotation parameter, model matching also optimizes over it. There is no equivalent in [20] because the formulation is entirely 1-D. Note, however, that steerable filters provide a way of optimizing over the rotation parameter <ref> [37] </ref>. A final difference is the normalization of the image data.
Reference: [38] <author> K. Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition. </title> <publisher> Academic Press, </publisher> <year> 1990. </year> <month> 158 </month>
Reference-contexts: 2 10 norms were used to define the best fitting polynomial surface that is subsequently differentiated to estimate the differential invariants. 2.1.4 Dimension Reduction Since weighted L 2 norms are derived from underlying Hilbert spaces, it is possible to apply dimension reduction techniques, such as the Karhunen-Loeve (K-L) expansion [89] <ref> [38] </ref>, to improve the efficiency of feature detection. The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. <p> This idea was first explored by Hummel [52] and later by Lenz [64]. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion <ref> [38] </ref> [89] yields the optimal subspace. The covariance matrix C = E q [(F E q [F ])(F E q [F ]) T ] represents the correlation between the pixels in the different feature instances.
Reference: [39] <author> M. Gennert. </author> <title> Detecting half-edges and vertices in images. </title> <booktitle> In Proceedings of the 1986 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 552-557, </pages> <year> 1986. </year>
Reference-contexts: Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. A final example of a filtering based differential invariant detector is the half edge and vertex detector of <ref> [39] </ref>. Here, Gennert uses a modified directional derivative of a Gaussian operator to create an edge detector that performs more robustly at vertices and corners.
Reference: [40] <author> A.K. Griffith. </author> <title> Mathematical models for automatic line detection. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 62-80, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: A decision rule is then used to decide whether to detect the feature or not. Probably the first statistical feature detector is that of Griffith <ref> [40] </ref>. The Griffith detector was designed to detect boundary features, which can be either simple lines or simple edges. The non-features modeled include homogeneous regions, skewed lines, and parts of lines.
Reference: [41] <author> M. Hahsimoto and J. Sklansky. </author> <title> Multiple-order derivatives for detecting local image characteristics. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 39 </volume> <pages> 28-55, </pages> <year> 1987. </year>
Reference-contexts: Afterwards, in Section 2.2.3, I discuss differential invariant approaches to corner detection. Finally, note that a small number of papers have focused on how to estimate the partial derivatives required by differential invariant feature detectors, rather than on feature detection itself. Such papers include [117], [71], and <ref> [41] </ref>. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" [17]. <p> Naturally, other choices are possible. For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. [21] used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. Hashimoto and Sklansky <ref> [41] </ref> and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. <p> Hashimoto and Sklansky <ref> [41] </ref> and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. A final example of a filtering based differential invariant detector is the half edge and vertex detector of [39].
Reference: [42] <author> R.M. Haralick. </author> <title> Edge and region analysis for digital image data. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 12 </volume> <pages> 60-73, </pages> <year> 1980. </year>
Reference-contexts: The non-features modeled include homogeneous regions, skewed lines, and parts of lines. Later, Nahi and Jahanshahi developed an edge detector using a replacement processes to model image formation as the replacement of a background process with an object process [77]. In <ref> [42] </ref>, Haralick proposed an edge detector using the F -statistic to test the statistical significance of the difference between the parameters of the best fitting sloped surfaces in neighboring pixels. <p> In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. Both Brooks [17] and Haralick <ref> [42] </ref> tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. <p> Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. Further, Torre and Poggio also examined the relationship between Laplacian edge detectors such as [70] and second directional derivative operators such as [20] and <ref> [42] </ref>. 2.6.2 Sensor Modeling and Sub-Pixel Localization Most of the previous work on feature detection has assumed that the artifacts introduced by the imaging system are negligible and can be ignored. One exception is [94]. In this paper, Pedersini et al. are interested in maximizing the sub-pixel localization accuracy.
Reference: [43] <author> R.M. Haralick. </author> <title> Ridges and valleys on digital images. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 22 </volume> <pages> 28-38, </pages> <year> 1983. </year>
Reference-contexts: These zero crossings correspond to local maxima of the first order directional derivative taken in the direction of the gradient and are computed from the best fitting cubic surface. In a related paper <ref> [43] </ref>, Haralick used a surface fitting approach to estimate the zero crossings of the first directional derivative in the direction that extremizes the second directional derivative. Haralick argues that these feature points correspond to ridges and valleys.
Reference: [44] <author> R.M. Haralick. </author> <title> Digital step edges from zero crossing of second directional derivatives. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(1) </volume> <pages> 58-68, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Well known examples include the Deriche corner detector [30], the Haralick step edge detector <ref> [44] </ref>, and the Marr-Hildreth step edge detector [70]. As indicated by the name, these detectors base their detection decisions upon differential invariants estimated from the image data. <p> For example, Haralick proposed an edge detector that detects edges at negatively slopped zero crossings of the second directional derivative, taken in the direction of the gradient <ref> [44] </ref>. These zero crossings correspond to local maxima of the first order directional derivative taken in the direction of the gradient and are computed from the best fitting cubic surface.
Reference: [45] <author> C. Harris. </author> <title> Determination of ego-motion from matched points. </title> <booktitle> In Proceddings of the 3rd Alvey Vision Conference, </booktitle> <address> Cambridge, UK, </address> <year> 1987. </year>
Reference-contexts: Shah and Jain showed that the Zuniga-Haralick detector is the same as the Kitchen-Rosenfeld detector divided by the magnitude of the gradient [110]. Finally, another corner detector is the Plessey corner detector <ref> [45] </ref>. The Plessey detector is based upon first order invariants of a smoothed image. An explanation of the Plessey detector in terms of differential geometry was later provided by Nobel [84]. 2.3 Optimal Filtering Feature Detectors In the previous section, I discussed differential invariant approaches to feature detection.
Reference: [46] <author> R. </author> <title> Hartley. A Gaussian-weighted multiresolution edge detector. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 30 </volume> <pages> 70-83, </pages> <year> 1985. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including [88], [52], [74], and <ref> [46] </ref>. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. Morgenthaler [74] generalized the approach of Hummel to detect step edges superimposed on a low order polynomial, rather than on a constant function. Finally, Hartley <ref> [46] </ref> redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of [51]. Probably the most sophisticated model matching edge detector is the Nalwa-Binford detector [80]. <p> In [51], the weighting function remains the same to allow a closed form solution for the best fitting parameters. In the appendix, however, Hueckel suggests that a Gaussian weighting function may be more appropriate. Few other detectors actually use non-uniform weighting functions. An exception is Hartley <ref> [46] </ref>, who followed Hueckel's suggestion and used a Gaussian weighting function. Lenz [64] concentrates on the Euclidean L 2 norm, but extends some of his results to the uniformly weighted L 2 norm in polar coordinates. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley <ref> [46] </ref>, and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64].
Reference: [47] <author> M.D. Heath, S. Sarkar, T. Sanocki, and K.W. Bowyer. </author> <title> A robust visual method for assessing the relative performance of edge-detection algorithms. </title> <journal> IEEE 159 Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(12) 1338-1359, December 1997. 
Reference-contexts: In the second part, I describe how the measures can be evaluated. For a slightly different categorization of previous work on the evaluation of feature detectors, the reader is referred to <ref> [47] </ref>. 2.5.1 Performance Measures Most of the measures of performance can be placed into one of five categories: Feature Detection Robustness: The first category consists of measures that attempt to characterize how likely the detector is to miss a feature that appears in the image (a false negative), and those that <p> Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition <ref> [47] </ref>, structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121]. <p> Although nearly all feature detection papers do this, they typically do it in a very informal manner. It is possible to perform such a comparison in a more formal way, as was done in [36] and <ref> [47] </ref>. Even when done scientifically, such techniques still have the inherent weakness that they rely upon the subjective opinion of humans who can bring higher level processing to bear. <p> Of the four evaluation methodologies described in Section 2.5.2, the only one that has actually been used by a significant number of authors is subjective human evaluation. In particular, <ref> [47] </ref> contains a survey of recent articles on edge detection. None of the twenty-one papers considered used any other method of performance evaluation. Subjective human comparison consists of simply applying the detectors to a small number of images and then displaying the output edge maps for evaluation by a human. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], <ref> [47] </ref>, [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently. <p> For a measure of performance to be useful, there must be a marked difference between the performance of the best and worst detectors. One criticism that could be made of several recent performance evaluation papers such as <ref> [47] </ref> is that by only testing supposedly good detectors, the full range of performance was never completely sampled. The results presented in [47] show that the detectors perform fairly similarly. <p> One criticism that could be made of several recent performance evaluation papers such as <ref> [47] </ref> is that by only testing supposedly good detectors, the full range of performance was never completely sampled. The results presented in [47] show that the detectors perform fairly similarly. It is then unclear whether this is because the detectors are similar in quality, or whether the evaluation methodology is incapable of ever widely separating good detectors from bad ones.
Reference: [48] <author> B.K.P. Horn. </author> <title> Robot Vision. </title> <publisher> McGraw Hill, </publisher> <year> 1996. </year>
Reference-contexts: Introduction Feature detection is one of the fundamental tasks in computer vision. It has received widespread coverage in both the research literature and in vision textbooks such as <ref> [48] </ref>, [35], and [79]. Some of the major applications of feature detection include: Stereo: One of the most popular methods of performing correspondence matching along epipolar lines consists of matching detected edge features. Object Recognition: Many object recognition algorithms start by detecting edge or corner features. <p> It is known that irradiance on the image plane is proportional to scene radiance <ref> [48] </ref>.
Reference: [49] <author> J.S. Huang and D.H. Tseng. </author> <title> Statistical theory of edge detection. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 43 </volume> <pages> 337-346, </pages> <year> 1988. </year>
Reference-contexts: Bovik et al. [14] proposed three different statistical tests for edge detection, two based upon linear rank sums and one based upon fitting order statistics. Finally, Huang and Tseng <ref> [49] </ref> proposed a statistical theory of edge detection based upon the change-point problem. 20 2.5 Evaluation of Feature Detectors In the first part of this section, I present the various measures of performance that have been proposed in the literature, without discussing how, or even whether, they can actually be evaluated.
Reference: [50] <author> M.H. Hueckel. </author> <title> An operator which locates edges in digitized pictures. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 18(1) </volume> <pages> 113-125, </pages> <month> January </month> <year> 1971. </year>
Reference-contexts: From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as <ref> [50] </ref>, [51], [80], and [106], are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> Sometimes the choice of the matching function is an explicit part of the feature definition, whereas for other detectors the choice is simply implicit in the final design of the detector. 2.1.1 Model Matching Step Edge Detectors The first model matching detector was Hueckel's step edge detector <ref> [50] </ref>. The most important issue for Hueckel was to find a closed form solution for the model parameters that give the closest match to the image data. <p> This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed <ref> [50] </ref>, including [88], [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed <ref> [50] </ref>, including [88], [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. <p> For example, Hueckel [51] generalized his step edge detector of <ref> [50] </ref> to detect a six parameter line in addition to the original four parameter step edge. Another example is Rohr's corner and Y-junction detector [106]. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], [74], [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel <ref> [50] </ref>. In the continuous domain of [50], Hueckel used the weighting function w (x; y) = [1 (x 2 + y 2 )] 1=2 ; where (x; y) are coordinates relative to the center of a circular window with unit radius. <p> Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel <ref> [50] </ref>. In the continuous domain of [50], Hueckel used the weighting function w (x; y) = [1 (x 2 + y 2 )] 1=2 ; where (x; y) are coordinates relative to the center of a circular window with unit radius. <p> The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel <ref> [50] </ref>, but also including Morgenthaler [74]. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in [82]. <p> Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld [107] and Abramatic [2] studied the Hueckel <ref> [50] </ref> and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel <ref> [50] </ref>, and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. <p> The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel <ref> [50] </ref> and Hummel [52] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold. To make their derivations possible, they used simplified feature models and completely neglected sensing effects. <p> Dramatic dimension reduction is possible because most features have significant structure and inherent symmetries. In practice, the dimension of the subspace required turns out to be in the range 5-15. Dimension reduction was first used in feature detection by Hueckel <ref> [50] </ref>. See Section 2.1.4 for a review of the use of dimension reduction in feature detection. To perform the search for the closest point on the manifold, I use a coarse-to-fine algorithm that exploits the local smoothness of the feature manifolds to find the closest sample point very quickly. <p> Parametric models of step edges date back to the work of Hueckel <ref> [50] </ref>. Since then, the edge has been studied in more depth than any other visual feature. See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. <p> See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in <ref> [50] </ref>, [52], and [64]. It is closest to the one used by Nalwa and Binford [80] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects. <p> This figure is by no means the best that can be achieved in terms of efficiency: Pattern Rejection: The coarse-to-fine search does not need to be applied at every pixel in the image. This observation is almost as old as edge detection itself and is explicitly mentioned in <ref> [50] </ref>. Combining a variety of techniques, I have already reduced the time to process a 512 fi 480 image to less than a minute. I first threshold on the total coordinate variance -2 computed during parameter normalization.
Reference: [51] <author> M.H. Hueckel. </author> <title> A local visual operator which recognizes edges and lines. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(4) </volume> <pages> 634-647, </pages> <month> October </month> <year> 1973. </year>
Reference-contexts: From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as [50], <ref> [51] </ref>, [80], and [106], are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> Finally, Hartley [46] redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of <ref> [51] </ref>. Probably the most sophisticated model matching edge detector is the Nalwa-Binford detector [80]. Nalwa and Binford used a much more realistic edge model than previous detectors. <p> The six masks can be regarded as a very simple edge model, and selecting the mask with the strongest response as finding the best fitting model instance. 2.1.2 Other Model Matching Detectors Model matching detectors have been proposed for several other types of features. For example, Hueckel <ref> [51] </ref> generalized his step edge detector of [50] to detect a six parameter line in addition to the original four parameter step edge. Another example is Rohr's corner and Y-junction detector [106]. <p> The justifications provided for this choice were: (1) the weighting function 9 should be continuous, including at the periphery of the window, and (2) the value of the weighting function should decrease monotonically with distance from the center of the window. In <ref> [51] </ref>, the weighting function remains the same to allow a closed form solution for the best fitting parameters. In the appendix, however, Hueckel suggests that a Gaussian weighting function may be more appropriate. Few other detectors actually use non-uniform weighting functions. <p> This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel <ref> [51] </ref> applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. <p> The projection onto the first two eigenvectors is similar; it is approximately a circle in both cases. 3.3.3 The Symmetric Line A line can be thought of as a pair of parallel step edges separated by a short distance w, the width of the line <ref> [51] </ref>. The line model which I used is illustrated in the line is symmetric. It is possible to generalize this model to lines with different intensities on the two sides of the line by adding one more parameter [51]. <p> edges separated by a short distance w, the width of the line <ref> [51] </ref>. The line model which I used is illustrated in the line is symmetric. It is possible to generalize this model to lines with different intensities on the two sides of the line by adding one more parameter [51].
Reference: [52] <author> R.A. Hummel. </author> <title> Feature detection using basis functions. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 40-55, </pages> <year> 1979. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including [88], <ref> [52] </ref>, [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> A number of similar approaches and enhancements followed [50], including [88], <ref> [52] </ref>, [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. <p> Instead they used a numerical algorithm. Step edges can occur in 3-D volumetric data as well as in 2-D images. Zucker and Hummel [122] generalized Hummel's 2-D step edge detector <ref> [52] </ref> to detect step edges in volumetric data. Some of Lenz's results in [64] concerning the application of the Karhunen-Loeve expansion are also applicable to 3-D edge models. Finally, note that the Nevatia-Babu detector [83] can be regarded as a primitive kind of model matching detector. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], <ref> [52] </ref>, [74], [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> The use of the K-L expansion was first proposed for feature detection by Hummel <ref> [52] </ref>. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel <ref> [52] </ref>, Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. <p> The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel [50] and Hummel <ref> [52] </ref> both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold. To make their derivations possible, they used simplified feature models and completely neglected sensing effects. My view of feature detection is radically different. <p> This idea was first explored by Hummel <ref> [52] </ref> and later by Lenz [64]. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion [38] [89] yields the optimal subspace. <p> See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in [50], <ref> [52] </ref>, and [64]. It is closest to the one used by Nalwa and Binford [80] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects. <p> Moreover, to avoid the unnecessary non-linearities induced by a square window, I used a disc shaped one. In Figure 3.1 (c), I display the eight most prominent eigenvectors, ordered by their eigenvalues. The similarity between the first four eigenvectors and the ones derived analytically by Hummel in <ref> [52] </ref> is immediate. Notice, however, that while the eigenvectors of [52] are radially symmetric, the ones in Figure 3.1 (c) are not. This is to be expected since the introduction of the parameters and breaks the radial symmetry of Hummel's edge model. <p> In Figure 3.1 (c), I display the eight most prominent eigenvectors, ordered by their eigenvalues. The similarity between the first four eigenvectors and the ones derived analytically by Hummel in <ref> [52] </ref> is immediate. Notice, however, that while the eigenvectors of [52] are radially symmetric, the ones in Figure 3.1 (c) are not. This is to be expected since the introduction of the parameters and breaks the radial symmetry of Hummel's edge model. While the eigenvectors in 45 A and A + B. <p> The step edge manifold is parameterized by orientation and sub-pixel localization for a fixed blurring value and is displayed in a 3-D subspace constructed using the first three K-L eigenvectors. 46 <ref> [52] </ref> are optimal for the edge model used there, Figure 3.1 (c) shows that they are not optimal for my, more realistic, edge model. <p> To reduce the residual to 10% three eigenvectors are needed, and to reduce it further to 2% eight eigenvectors must be used. These results represent a compression factor in the range 5-15. As a result, the efficiency of feature detection is greatly enhanced. In <ref> [52] </ref>, Hummel derives the result that the eigenvalues for his continuous step edge model should decay like 1=n 2 . The results in Figure 3.1 (d) are consistent with this prediction. <p> By plotting n against n on logarithmic scales and fitting a straight line to the curve, I found that the eigenvalues initially decay like 1=n 2 . However, because I am working in R N rather than the infinite dimensional continuous domain considered in <ref> [52] </ref>, the rate of decay increases for larger n. The step edge manifold is displayed in Figure 3.1 (e). Naturally, I only display a projection of it into a 3-D subspace. The subspace chosen is the one spanned by the three most prominent eigenvectors.
Reference: [53] <author> B.F. Logan Jr. </author> <title> Information in the zero crossings of bandpass signals. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 56(4) </volume> <pages> 487-510, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: A number of positive results have been found in which it has been shown that the zero crossings at multiple scales are complete for large classes of images <ref> [53] </ref> [120] [115]. However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69].
Reference: [54] <author> G.E. Sotak Jr. and K.L. Boyer. </author> <title> The Laplacian-of-Gaussian kernal: A formal analysis and design procedure for fast, accurate convolution and full-frame output. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 48 </volume> <pages> 147-189, </pages> <year> 1989. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] <ref> [54] </ref>, accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] <ref> [54] </ref>, accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer <ref> [54] </ref>. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference.
Reference: [55] <author> G. </author> <title> Kanizsa. Subjective contours. </title> <journal> Scientific American, </journal> <volume> 234(4) </volume> <pages> 48-52, </pages> <year> 1976. </year>
Reference-contexts: unsuitable because: (1) it is a tedious task and hence error prone, and (2) humans can bring higher level processing to bear, and so there is no guarantee that what is perceived is actually present in the local image data, as is demonstrated 22 by phenomena such as subjective contours <ref> [55] </ref>. In fact, in a recent paper in which this approach is taken, Dougherty and Bowyer allowed the human to mask out any regions for which it was too difficult for the human to say which pixels contain edges [32].
Reference: [56] <author> T. Kanungo, M.Y. Jaisimha, J. Palmer, and R.M. Haralick. </author> <title> A methodology for quantitative performance evaluation of detection algorithms. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 4(12) </volume> <pages> 1667-1673, </pages> <month> December </month> <year> 1995. </year> <month> 160 </month>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction <ref> [56] </ref> [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121].
Reference: [57] <author> L. Kitchen and A. Rosenfeld. </author> <title> Edge evaluation using local edge coherence. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 11(9) </volume> <pages> 597-605, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness <ref> [57] </ref> [95] [121]. Such properties are particularly important for applications that first aggregate individual features into groups before performing any subsequent processing. 2.5.2 Evaluation Techniques If ground truth data existed for a large collection of images, estimating any of the measures would be straightforward. <p> Direct Computation from Real Images: Some performance measures do not rely upon ground truth and can be computed directly from the detector output, for example, the local measures of coherence proposed in <ref> [57] </ref> and [121]. The major weakness of these approaches is that the output could totally misrepresent the structure of the scene and still be rated highly. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], [47], [121], and <ref> [57] </ref>. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently.
Reference: [58] <author> L. Kitchen and A. Rosenfeld. </author> <title> Gray-level corner detection. </title> <journal> Pattern Recognition Letters, </journal> <volume> 1 </volume> <pages> 95-102, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: A slightly different choice was made by Kitchen and Rosenfeld <ref> [58] </ref>, that being to use the rate of change of the gradient direction multiplied by the gradient magnitude, a measure which simplifies to: K = y + I yy I 2 I 2 y Torre and Poggio [115] later showed that this expression is also the second direc tional derivative in
Reference: [59] <author> D.E. Knuth. </author> <title> The Art of Computer Programming, Volume II: Seminumerical Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1981. </year>
Reference-contexts: On the other hand, if the closest sample point is too far away, the feature is not detected. Finding the nearest neighbor amongst a fixed set of points to a given novel point is a well studied problem that was first posed by Knuth <ref> [59] </ref>. A recent paper by Yanilos [119] contains a comprehensive survey of algorithms developed since then. The task of finding the closest sample point on the manifold has more structure than the general nearest neighbor problem since the sample points lie on the manifold.
Reference: [60] <author> J.J. Koenderink. </author> <title> The structure of images. </title> <journal> Biological Cybernetics, </journal> <volume> 50 </volume> <pages> 363-370, </pages> <year> 1984. </year>
Reference-contexts: Later, Canny used the same technique to define the scale of his detector [20]. Moreover, an entire theory of scale space has been developed, beginning with the work of Witken [118] and then of Koenderink <ref> [60] </ref>. These initial papers established the desirable properties of the Gaussian smoothing for scale space. Koenderink [60] also pointed out that smoothing the image with a Gaussian is equivalent to solving the heat equation, also known as the diffusion equation. 27 Much later, this fact lead Perona and Malik to propose <p> Moreover, an entire theory of scale space has been developed, beginning with the work of Witken [118] and then of Koenderink <ref> [60] </ref>. These initial papers established the desirable properties of the Gaussian smoothing for scale space. Koenderink [60] also pointed out that smoothing the image with a Gaussian is equivalent to solving the heat equation, also known as the diffusion equation. 27 Much later, this fact lead Perona and Malik to propose anisotropic diffusion as a mechanism to detect edges [96]. <p> The defocus factor can be approximated by a pillbox function 36 [13], the optical transfer function by the square of the first-order Bessel function of the first kind [13], and the blurring due to imperfections in the feature by a Gaussian <ref> [60] </ref>.
Reference: [61] <author> A.L. Korn. </author> <title> Towards a symbolic representation of intensity changes in images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(5) </volume> <pages> 610-625, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The primary goal of scale space theory, at least as far as feature detection is concerned, is to combine the outputs of operators at multiple scales in a coherent manner [79]. A number of attempts have been made at studying the output of detectors across scales, including, [10], <ref> [61] </ref>, and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. <p> A number of attempts have been made at studying the output of detectors across scales, including, [10], <ref> [61] </ref>, and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. He proceeded to show how the systematic bias of the Laplacian of Gaussian can be corrected.
Reference: [62] <author> J. Krumm. </author> <title> Eigenfeatures for planar pose measurement of partially occluded objects. </title> <booktitle> In Proceedings of the 1996 Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Francisco, California, June 1996. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Features could also be constructed from imaged features by writing a defining function that appropriately transforms (e.g. interpolates, scales, rotates, shifts, and blurs) the image data. A similar approach to object recognition was recently proposed by Krumm <ref> [62] </ref>.
Reference: [63] <editor> C.L. Lawson and R.J. Hanson. </editor> <title> Solving Least Squares Problems. </title> <publisher> Prentice-Hall, </publisher> <year> 1974. </year>
Reference-contexts: For linear manifolds, finding the closest point on the manifold is simply a weighted least squares problem. So, finding the optimal weighting function corresponds to selecting the weighting function that gives the best linear unbiased estimate of the solution to a weighted least squares problem <ref> [63] </ref> [99]. The answer to this problem was found by Aitken in [3]. The optimal weighting function is: w (n; m) = Var [(n; m)] where Var [(n; m)] = E [ 2 (n; m)] E [(n; m)] 2 is the variance of the noise in pixel (n; m).
Reference: [64] <author> R. Lenz. </author> <title> Optimal filters for the detection of linear patterns in 2-D and higher dimensional image. </title> <journal> Pattern Recognition, </journal> <volume> 20(2) </volume> <pages> 163-172, </pages> <year> 1987. </year>
Reference-contexts: Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz <ref> [64] </ref>. Morgenthaler [74] generalized the approach of Hummel to detect step edges superimposed on a low order polynomial, rather than on a constant function. <p> Instead they used a numerical algorithm. Step edges can occur in 3-D volumetric data as well as in 2-D images. Zucker and Hummel [122] generalized Hummel's 2-D step edge detector [52] to detect step edges in volumetric data. Some of Lenz's results in <ref> [64] </ref> concerning the application of the Karhunen-Loeve expansion are also applicable to 3-D edge models. Finally, note that the Nevatia-Babu detector [83] can be regarded as a primitive kind of model matching detector. <p> In the appendix, however, Hueckel suggests that a Gaussian weighting function may be more appropriate. Few other detectors actually use non-uniform weighting functions. An exception is Hartley [46], who followed Hueckel's suggestion and used a Gaussian weighting function. Lenz <ref> [64] </ref> concentrates on the Euclidean L 2 norm, but extends some of his results to the uniformly weighted L 2 norm in polar coordinates. In Cartesian coordinates, this corresponds to using the weighting function w (x; y) = 1=(x 2 + y 2 ) 1=2 . <p> The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz <ref> [64] </ref>, and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. <p> Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz <ref> [64] </ref>. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel [50] and Hummel [52] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold. <p> This idea was first explored by Hummel [52] and later by Lenz <ref> [64] </ref>. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion [38] [89] yields the optimal subspace. <p> See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in [50], [52], and <ref> [64] </ref>. It is closest to the one used by Nalwa and Binford [80] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects.
Reference: [65] <author> T. Lindenberg. </author> <title> Scale-Space Theory in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year> <month> 161 </month>
Reference-contexts: It turns out that the complexity of this algorithm actually decreases as the standard deviation of the Gaussian increases. 2.6.4 Scale and Information Content Scale has become an important issue in edge detection and has received a great deal of attention [79] <ref> [65] </ref>. The notion of the scale of an edge detector dates back to the Marr-Hildreth detector [70]. In particular, in their Laplacian of Gaussian detector, the standard deviation of the Guassian is used to control the scale by changing the amount of blurring.
Reference: [66] <author> W.H.H. Lunscher. </author> <title> The assymptotic optimal frequency domain filter for edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(6) </volume> <pages> 678-680, </pages> <month> November </month> <year> 1983. </year>
Reference-contexts: These include the energy in the vicinity of the edge studied by Shanmugam et al. [111] and by Lunscher <ref> [66] </ref>, and the Discriminative Signal to Noise Ratio studied by Rao and Ben-Arie [104]. 19 2.4 Statistical Feature Detectors A small number of feature detectors have been proposed that are based upon statistical techniques. <p> Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] <ref> [66] </ref> [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection. All of the above optimality criteria were developed for feature detectors based on filtering rather than for the model matching detectors considered in this thesis.
Reference: [67] <author> W.H.H.J. Lunscher and M.P. Beddoes. </author> <title> Optimal edge detector design 1: Parameter selection and noise effects. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(2) </volume> <pages> 164-177, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: For example, both Rosenfeld [107] and Abramatic [2] studied the Hueckel [50] and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. In <ref> [67] </ref> and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. <p> Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] <ref> [67] </ref> [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection. All of the above optimality criteria were developed for feature detectors based on filtering rather than for the model matching detectors considered in this thesis.
Reference: [68] <author> W.H.H.J. Lunscher and M.P. Beddoes. </author> <title> Optimal edge detector design 2: Coefficient quantization. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(2) </volume> <pages> 178-187, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: For example, both Rosenfeld [107] and Abramatic [2] studied the Hueckel [50] and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. In [67] and <ref> [68] </ref>, Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. <p> Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] <ref> [68] </ref> and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection. All of the above optimality criteria were developed for feature detectors based on filtering rather than for the model matching detectors considered in this thesis.
Reference: [69] <author> S. Mallat and S. Zhong. </author> <title> Characterization of signals from multiscale edges. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(7) </volume> <pages> 710-732, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy [11] [54], information content <ref> [69] </ref> [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in <ref> [69] </ref>. In spite of this result, a number of algorithms have been proposed to invert the edge detection process that work very well in practice [69] [34]. 29 Chapter 3 Parametric Feature Detection 3.1 Introduction As can be seen from the literature survey in Chapter 2, the most frequently studied image <p> However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in <ref> [69] </ref>. In spite of this result, a number of algorithms have been proposed to invert the edge detection process that work very well in practice [69] [34]. 29 Chapter 3 Parametric Feature Detection 3.1 Introduction As can be seen from the literature survey in Chapter 2, the most frequently studied image feature is the step edge.
Reference: [70] <author> D. Marr and E. Hildreth. </author> <title> Theory of edge detection. </title> <journal> Proceedings of the Royal Society of London, Series B, </journal> <volume> 207 </volume> <pages> 187-217, </pages> <year> 1980. </year>
Reference-contexts: Well known examples include the Deriche corner detector [30], the Haralick step edge detector [44], and the Marr-Hildreth step edge detector <ref> [70] </ref>. As indicated by the name, these detectors base their detection decisions upon differential invariants estimated from the image data. <p> Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector <ref> [70] </ref>. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector <ref> [70] </ref>. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> For example, one way to detect step edges is to apply the Laplacian operator and declare edges at its zero crossings <ref> [70] </ref>. The major goal of the work surveyed in that section was to compute the differential invariants as accurately as possible. <p> They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector <ref> [70] </ref> and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. <p> Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. Further, Torre and Poggio also examined the relationship between Laplacian edge detectors such as <ref> [70] </ref> and second directional derivative operators such as [20] and [42]. 2.6.2 Sensor Modeling and Sub-Pixel Localization Most of the previous work on feature detection has assumed that the artifacts introduced by the imaging system are negligible and can be ignored. One exception is [94]. <p> Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator <ref> [70] </ref> into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference. <p> The notion of the scale of an edge detector dates back to the Marr-Hildreth detector <ref> [70] </ref>. In particular, in their Laplacian of Gaussian detector, the standard deviation of the Guassian is used to control the scale by changing the amount of blurring. Later, Canny used the same technique to define the scale of his detector [20]. <p> A related study, with somewhat different goals, is that of Berzins [11]. A very important issue related to that of scale is the information content of edges. One of the major reasons for detecting edges is their supposedly high information content <ref> [70] </ref>. The most important question in this context is whether certain edge maps provide a complete representation of the image, in the sense that the image could be uniquely recovered from the edge map. As early as the work of Marr and Hildreth [70], it was conjectured that the zero crossings <p> edges is their supposedly high information content <ref> [70] </ref>. The most important question in this context is whether certain edge maps provide a complete representation of the image, in the sense that the image could be uniquely recovered from the edge map. As early as the work of Marr and Hildreth [70], it was conjectured that the zero crossings of the Laplacian of the Gaussian do provide a complete representation. A number of positive results have been found in which it has been shown that the zero crossings at multiple scales are complete for large classes of images [53] [120] [115].
Reference: [71] <author> P. Meer and I. Weiss. </author> <title> Smoothed differentiation filters for images. </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> 3(1) </volume> <pages> 58-72, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: A related approach is that of Parida et al. in [91]. Non-uniformly weighted L 2 norms have also been used in a number of differential invariant feature detectors that use the surface fitting approach described in Section 2.2.1. For instance, in <ref> [71] </ref> both unweighted and Guassian weighted L 2 10 norms were used to define the best fitting polynomial surface that is subsequently differentiated to estimate the differential invariants. 2.1.4 Dimension Reduction Since weighted L 2 norms are derived from underlying Hilbert spaces, it is possible to apply dimension reduction techniques, such <p> Afterwards, in Section 2.2.3, I discuss differential invariant approaches to corner detection. Finally, note that a small number of papers have focused on how to estimate the partial derivatives required by differential invariant feature detectors, rather than on feature detection itself. Such papers include [117], <ref> [71] </ref>, and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" [17]. <p> Just as for model matching detectors, the unweighted least squares fit is the usual choice. There are a few exceptions, however. For example, in <ref> [71] </ref> both unweighted and Guassian weighted L 2 norms were used to define the best fitting surface. 2.2.2 Filtering Differential Invariant Detectors The other way of computing the partial derivatives of the image is by filtering.
Reference: [72] <author> J.W. Modestino and R.W. Fries. </author> <title> Edge detection in noisy images using recursive digital filtering. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 6 </volume> <pages> 409-433, </pages> <year> 1977. </year>
Reference-contexts: Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. For example, Modestino and Fries <ref> [72] </ref> investigated least mean square filters for the Laplacian, and Castan et al. [21] used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. <p> A constant amount of computation is needed per pixel to implement these recursive relationships. For example, the infinite Deriche filter [29] can be implemented with 5 additions and 5 multiplications per pixel [35]. Other examples of recursive filtering include the Modestino and Fries detector <ref> [72] </ref> and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer [54].
Reference: [73] <author> H.P. Moravec. </author> <title> Towards automatic visual obstacle avoidance. </title> <booktitle> In Proceedings of the Fifth Internation Joint Conference on Artificial Intelligence, </booktitle> <year> 1977. </year> <month> 162 </month>
Reference-contexts: I first threshold on the total coordinate variance -2 computed during parameter normalization. Avoiding feature windows with small total variance in this way is similar to the use of the interest operator <ref> [73] </ref> to assess the reliability of potential stereo correspondence matches. Next, I threshold on the distance of the input from the K-L subspace.
Reference: [74] <author> D.G. Morgenthaler. </author> <title> A new hybrid edge detector. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 16 </volume> <pages> 166-176, </pages> <year> 1981. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including [88], [52], <ref> [74] </ref>, and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. Morgenthaler <ref> [74] </ref> generalized the approach of Hummel to detect step edges superimposed on a low order polynomial, rather than on a constant function. Finally, Hartley [46] redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of [51]. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], <ref> [74] </ref>, [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler <ref> [74] </ref>. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in [82].
Reference: [75] <author> D.G. Morgenthaler and A. Rosenfeld. </author> <title> Multidimensional edge detection by hypersurface fitting. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 3(4) </volume> <pages> 482-486, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Later, Prewitt's approach was extended by Morgenthaler and Rosenfeld to detect edges in 3-D volumetric data <ref> [75] </ref>. Once a polynomial surface has been fit to the image data, almost any differential invariant can be computed, be it the gradient, Laplacian, or higher order 12 invariant.
Reference: [76] <author> H.H. Nagel. </author> <title> Displacement vectors derived from second-order intensity variations in image sequences. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 21 </volume> <pages> 85-117, </pages> <year> 1983. </year>
Reference-contexts: Nagel 15 showed that the Dreschler-Nagel detector and the Kitchen-Rosenfeld detector are equivalent if the heuristic of nonmaximum suppression along the gradient is applied to the gradient before multiplying by the gradient magnitude <ref> [76] </ref>. Shah and Jain showed that the Zuniga-Haralick detector is the same as the Kitchen-Rosenfeld detector divided by the magnitude of the gradient [110]. Finally, another corner detector is the Plessey corner detector [45]. The Plessey detector is based upon first order invariants of a smoothed image.
Reference: [77] <author> N.E. Nahi and M.H. Jahanshahi. </author> <title> Image boundary estimation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 26(8) </volume> <pages> 772-781, </pages> <month> August </month> <year> 1977. </year>
Reference-contexts: The non-features modeled include homogeneous regions, skewed lines, and parts of lines. Later, Nahi and Jahanshahi developed an edge detector using a replacement processes to model image formation as the replacement of a background process with an object process <ref> [77] </ref>. In [42], Haralick proposed an edge detector using the F -statistic to test the statistical significance of the difference between the parameters of the best fitting sloped surfaces in neighboring pixels.
Reference: [78] <author> V.S. Nalwa. </author> <title> Edge detector resolution improvement by image interpolation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(3) </volume> <pages> 446-451, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: They claim that to do so, the details of the imaging system must be taken into consideration. In particular, they model image formation as non-linear radial distortion, followed by low-pass filtering, and then ideal sampling. A simpler approach to sub-pixel localization was proposed by Nalwa <ref> [78] </ref>. Nalwa simply suggested that the image is sub-sampled. Another example of sensor modeling is [97]. Petrou and Kittler argue that ideal step edges do not occur in real images. Instead, real edges are actually ramp edges.
Reference: [79] <author> V.S. Nalwa. </author> <title> A Guided Tour of Computer Vision. </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Introduction Feature detection is one of the fundamental tasks in computer vision. It has received widespread coverage in both the research literature and in vision textbooks such as [48], [35], and <ref> [79] </ref>. Some of the major applications of feature detection include: Stereo: One of the most popular methods of performing correspondence matching along epipolar lines consists of matching detected edge features. Object Recognition: Many object recognition algorithms start by detecting edge or corner features. <p> In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa <ref> [79] </ref>, and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors. From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. <p> Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as [50], [51], [80], and [106], are one of the predominant types of detector, as categorized by Nalwa <ref> [79] </ref>. The basis of a model matching detector is an ideal parametric model of the feature. For example, 6 the ideal model of a step edge would normally include parameters such as the orientation of the edge and the intensity levels on the two sides of the edge. <p> Examples include the Robert's cross operator [105] for which the detection decision is based upon the gradient of the best fitting plane, and the Prewitt operator [102] for which the decision is based upon the gradient of the best fitting quadratic surface <ref> [79] </ref>. Later, Prewitt's approach was extended by Morgenthaler and Rosenfeld to detect edges in 3-D volumetric data [75]. Once a polynomial surface has been fit to the image data, almost any differential invariant can be computed, be it the gradient, Laplacian, or higher order 12 invariant. <p> It turns out that the complexity of this algorithm actually decreases as the standard deviation of the Gaussian increases. 2.6.4 Scale and Information Content Scale has become an important issue in edge detection and has received a great deal of attention <ref> [79] </ref> [65]. The notion of the scale of an edge detector dates back to the Marr-Hildreth detector [70]. In particular, in their Laplacian of Gaussian detector, the standard deviation of the Guassian is used to control the scale by changing the amount of blurring. <p> The primary goal of scale space theory, at least as far as feature detection is concerned, is to combine the outputs of operators at multiple scales in a coherent manner <ref> [79] </ref>. A number of attempts have been made at studying the output of detectors across scales, including, [10], [61], and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. <p> If it was possible to visualize a higher dimensional projection, these apparent singularities would disappear. 3.3.2 The Roof Edge Unlike the step edge, the roof edge has not been studied much in the past despite having been acknowledged as a pertinent feature <ref> [79] </ref>. The only difference between the two edge models is that the step discontinuity in the step edge is replaced by a uniform intensity slope in the roof edge, as is shown in Figure 3.2 (a). <p> Another difficult issue is the lack of a model for a window of data not containing a feature <ref> [79] </ref>. I resolve this issue, as was done in [80], by taking a constant intensity window as the characteristic non-feature. During my investigation into the selection of optimal weighting functions in Chapter 5, I generalize this notion of what is not a feature. <p> The third is the step edge detector developed in Chapter 3. The final two are the Roberts' cross operator [105] and the Sobel operator [98], both of which are described in texts such as <ref> [79] </ref> and [100]. The Canny and Nalwa-Binford detectors are relatively modern and 127 highly regarded. The Roberts' cross and Sobel operators were amongst the first few edge detectors proposed, and are regarded as relatively poor detectors.
Reference: [80] <author> V.S. </author> <title> Nalwa and T.O. Binford. On detecting edges. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(6) </volume> <pages> 699-814, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as [50], [51], <ref> [80] </ref>, and [106], are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> Finally, Hartley [46] redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of [51]. Probably the most sophisticated model matching edge detector is the Nalwa-Binford detector <ref> [80] </ref>. Nalwa and Binford used a much more realistic edge model than previous detectors. Their edge model incorporated both sub-pixel localization and image blur, whereas most previous detectors simply assumed a pure discontinuity passing directly through the center of a pixel. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], [74], [122], <ref> [80] </ref>, and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], [1], <ref> [80] </ref>, [103], and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], [95], <ref> [80] </ref>, and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford <ref> [80] </ref> for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. <p> Typically the sampling will result in the order of 10 5 points, which lie in a space of dimension N = 25-100. Further, the search for the closest manifold point must be repeated for each each pixel in the image. Nalwa and Binford <ref> [80] </ref> and Rohr [106] also used more realistic feature models than Hueckel and Hummel. Likewise, they used numerical algorithms to find the parameters of their models that best fit the image data. <p> In particular, I describe manifold sampling, the coarse-to-fine search, and the use of rejection techniques. In the following chapter, I present experimental results obtained for the five example features, including comparisons with a Canny-like operator [20] and the Nalwa-Binford <ref> [80] </ref> detector. 3.2 Parametric Feature Representation I begin this section by first introducing the notion of a parametric scene feature. I then describe my model of the imaging system, and how this model leads to imaged features being represented as parametric manifolds. <p> Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in [50], [52], and [64]. It is closest to the one used by Nalwa and Binford <ref> [80] </ref> in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects. <p> As described in <ref> [80] </ref>, substantially larger values of could be used but represent an edge at a much higher scale. Such cases require the use of a larger image window. The intensity parameters A and B are free to take any value. <p> In both cases, I compare the step edge detector developed in the previous chapter with a Canny-like operator [20] and the Nalwa-Binford <ref> [80] </ref> detector. In doing so, the aim is to demonstrate that the parametric manifold step edge detector performs comparably to these well known and highly regarded detectors. I also compare the performance of the parametric manifold technique across the five example features. <p> The goal of this second comparison is to demonstrate the generality of the algorithm by showing that the performance is similar for all five features. In the remainder of this section, I largely follow the expermental approach taken by Nalwa and Binford in <ref> [80] </ref>. 4.1.1 Feature Detection Robustness The statistical test for feature detection robustness consists of two phases. In the first one, I generate a large number of ideal features, add zero-mean Gaussian noise to them, and then apply the detectors. <p> Another difficult issue is the lack of a model for a window of data not containing a feature [79]. I resolve this issue, as was done in <ref> [80] </ref>, by taking a constant intensity window as the characteristic non-feature. During my investigation into the selection of optimal weighting functions in Chapter 5, I generalize this notion of what is not a feature. <p> The closer a curve lies to the origin in Figure 4.1, the better the performance. Hence, my detector and the Canny detector perform comparably, with my algorithm doing slightly better. The results for the Nalwa-Binford detector are consistent with those presented in <ref> [80] </ref>. I did not use step 2)' of the algorithm. The percentage of false positives for the Nalwa-Binford detector never exceeds about 32%. This is in agreement with Figure 8 of [80]. <p> The results for the Nalwa-Binford detector are consistent with those presented in <ref> [80] </ref>. I did not use step 2)' of the algorithm. The percentage of false positives for the Nalwa-Binford detector never exceeds about 32%. This is in agreement with Figure 8 of [80]. Secondly, for S.N.R. of 1.0 the number of false negatives in Figure 4.1 never drops below about 56%, whereas in Figure 9 of [80] its lowest level is 77%. <p> The percentage of false positives for the Nalwa-Binford detector never exceeds about 32%. This is in agreement with Figure 8 of <ref> [80] </ref>. Secondly, for S.N.R. of 1.0 the number of false negatives in Figure 4.1 never drops below about 56%, whereas in Figure 9 of [80] its lowest level is 77%. These two numerical results are slightly different because: (1) I use a different model to generate the ideal step edges, and (b) my definition of S.N.R. yields a slightly lower value than the definition in [80] due to blurred and off-center edges. <p> drops below about 56%, whereas in Figure 9 of <ref> [80] </ref> its lowest level is 77%. These two numerical results are slightly different because: (1) I use a different model to generate the ideal step edges, and (b) my definition of S.N.R. yields a slightly lower value than the definition in [80] due to blurred and off-center edges. Comparing the results with those in Figure 9 of [80], it can be seen that the curve in Figure 4.1 corresponds to a curve somewhere between S.N.R. 1.0 and 2.0. <p> two numerical results are slightly different because: (1) I use a different model to generate the ideal step edges, and (b) my definition of S.N.R. yields a slightly lower value than the definition in <ref> [80] </ref> due to blurred and off-center edges. Comparing the results with those in Figure 9 of [80], it can be seen that the curve in Figure 4.1 corresponds to a curve somewhere between S.N.R. 1.0 and 2.0. <p> The reason that the Nalwa-Binford detector performs qualitatively differently to the Canny and parametric manifold detectors is its inherent conservatism, as enforced by steps 4) and 5) of the algorithm. See page 704 of <ref> [80] </ref>. In Figure 4.2, I compare the feature detection robustness of the five example features introduced in Chapter 3. In the figure, the curves are all plotted for S.N.R. 1.0 and for a disc shaped window containing 61 pixels. <p> Evaluating the robustness of a feature detector is known to be difficult, amongst other reasons because of the lack of a characteristic model of a "non-feature" <ref> [80] </ref> [103]. Canny avoided this problem when defining his optimality criteria by using the signal to noise ratio, which he claimed to be correlated with robustness. Both Nalwa and Binford [80] and Ramesh and Haralick [103] simply used a constant intensity vector as their characteristic non-feature. <p> detector is known to be difficult, amongst other reasons because of the lack of a characteristic model of a "non-feature" <ref> [80] </ref> [103]. Canny avoided this problem when defining his optimality criteria by using the signal to noise ratio, which he claimed to be correlated with robustness. Both Nalwa and Binford [80] and Ramesh and Haralick [103] simply used a constant intensity vector as their characteristic non-feature. <p> I therefore conclude that the 132 Nalwa-Binford detector suffers from a relatively high percentage of false negatives. This fact is totally consistent with Figure 4.1 in the Statistical Tests section of Chapter 4. It is also consistent with the results presented in <ref> [80] </ref>. The results for the second (unknown orientation) variant of the first global measure of coherence displayed in Figure 6.3 are somewhat different. First, note that the scale on the ordinate has changed.
Reference: [81] <author> D. Nandy, Z. Wang, J. Ben-Arie, K. Raghunath Rao, and N. Jojic. </author> <title> A generalized feature extractor using expansion matching and the karhunen-loeve transform. </title> <booktitle> In Proceedings of the 1996 DARPA Image Understanding Workshop, </booktitle> <pages> pages 969-972, </pages> <address> Palm Springs, CA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and <ref> [81] </ref>. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in [82].
Reference: [82] <author> R. Nevatia. </author> <title> Evaluation of a simplified Hueckel edge-line detector. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 6 </volume> <pages> 582-588, </pages> <year> 1977. </year> <month> 163 </month>
Reference-contexts: More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in <ref> [82] </ref>. Nevatia found that using a subspace with too low a dimension does indeed reduce the performance of a detector. 2.2 Differential Invariant Feature Detectors The second major class of feature detectors consists of those based upon differential invariants.
Reference: [83] <author> R. Nevatia and K.R. Babu. </author> <title> Linear feature extraction and description. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 13 </volume> <pages> 257-269, </pages> <year> 1980. </year>
Reference-contexts: Zucker and Hummel [122] generalized Hummel's 2-D step edge detector [52] to detect step edges in volumetric data. Some of Lenz's results in [64] concerning the application of the Karhunen-Loeve expansion are also applicable to 3-D edge models. Finally, note that the Nevatia-Babu detector <ref> [83] </ref> can be regarded as a primitive kind of model matching detector. The Nevatia-Babu detector operates by convolving the image with six edge masks, each oriented in a different direction.
Reference: [84] <author> J.A. Nobel. </author> <title> Finding corners. </title> <journal> Image and Vision Computing, </journal> <volume> 6(2) </volume> <pages> 121-127, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Finally, another corner detector is the Plessey corner detector [45]. The Plessey detector is based upon first order invariants of a smoothed image. An explanation of the Plessey detector in terms of differential geometry was later provided by Nobel <ref> [84] </ref>. 2.3 Optimal Filtering Feature Detectors In the previous section, I discussed differential invariant approaches to feature detection. For example, one way to detect step edges is to apply the Laplacian operator and declare edges at its zero crossings [70]. <p> This fact follows from the following symmetry in the line model: F L (n; m; A; B; + 180 ffi ; ; w; ) = F L (n; m; A; B; ; ; w; ): (3.20) 3.3.4 The Corner The corner is a common and important feature <ref> [84] </ref>. Most existing corner detectors are based upon differential invariant based measures of curvature [30], but Rohr [106] recently proposed a parametric model matching approach to corner detection. The simplest way to think about a corner is as the intersection of two non-parallel step edges.
Reference: [85] <author> H.N. Norton. </author> <title> Sensor and Analyzer Handbook. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular [7] <ref> [85] </ref>, the averaging function is simply the rectangular function [15]: a (x; y) = w x w y 1 x; w y where w x and w y are the x and y dimensions of the pixel. Second, the pixels are sampled.
Reference: [86] <author> The Museum of Modern Art. </author> <title> The Museum of Modern Art New York: The History and the Collection. </title> <editor> Harry N. Abrams, </editor> <year> 1984. </year>
Reference-contexts: The only difference between the detectors is the parametric model of the feature used to build the detector. the noise actually found in real images. Here, I present results on synthetic images in Section 4.2.1, on images scanned from <ref> [86] </ref> in Section 4.2.2, and on images taken from the INRIA image database in Section 4.2.3. 4.2.1 Application to Synthetic Images In Figures 4.11 (b)-(f), I display the results of applying my five example detectors to the noisy synthetic image in Figure 4.11 (a). <p> The original images were all scanned from <ref> [86] </ref> using an Envisions 6600S scanner at 200dpi. (Note that the image formation process for a scanner is somewhat different to that for a camera. Hence, the image formation model described in Section 3.2.2 should be regarded as only an approximation. <p> One slight change was made to the raw feature maps for clarity of presentation. To make the detected 76 (a) Original image (b) Distance to step edge manifold (c) Distance to corner manifold (d) Distance to line manifold of "Schroder House," by Gerrit Rietveld, 1924, scanned from <ref> [86] </ref>. These results convey the richness of information obtained when multiple feature detectors are applied to an image, as well as the similarities in some of the feature definitions for extreme parameter values.
Reference: [87] <institution> American Society of Photogrammetry. Manual of Photogrammetry. American Society of Photogrammetry, </institution> <note> fourth edition edition, </note> <year> 1980. </year>
Reference-contexts: An ideal pinhole camera should be linear, however, the use of a lens may introduce various nonlinear distortions, the two major types being radial and tangential <ref> [87] </ref>. Both types of distortion can be modeled, but in practice the tangential component is negligible, and only the radial distortion is actually compensated for [116].
Reference: [88] <author> F. O'Gorman. </author> <title> Edge detection using Walsh functions. </title> <journal> Artificial Intelligence, </journal> <volume> 10 </volume> <pages> 215-223, </pages> <year> 1978. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including <ref> [88] </ref>, [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including <ref> [88] </ref>, [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including <ref> [88] </ref>, [52], [74], [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman <ref> [88] </ref>, Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners.
Reference: [89] <author> E. Oja. </author> <title> Subspace Methods of Pattern Recognition. </title> <publisher> Research Studies Press, </publisher> <year> 1983. </year>
Reference-contexts: A number of similar approaches and enhancements followed [50], including [88], [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion <ref> [89] </ref> instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. Morgenthaler [74] generalized the approach of Hummel to detect step edges superimposed on a low order polynomial, rather than on a constant function. <p> L 2 10 norms were used to define the best fitting polynomial surface that is subsequently differentiated to estimate the differential invariants. 2.1.4 Dimension Reduction Since weighted L 2 norms are derived from underlying Hilbert spaces, it is possible to apply dimension reduction techniques, such as the Karhunen-Loeve (K-L) expansion <ref> [89] </ref> [38], to improve the efficiency of feature detection. The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. <p> This normalization causes no significant loss of information or reduction in the signal to noise ratio. Next, I apply the 33 Karhunen-Loeve expansion <ref> [89] </ref> as a dimension reduction technique, which enables me to improve the efficiency by projecting the feature manifold into a low dimensional subspace. Dramatic dimension reduction is possible because most features have significant structure and inherent symmetries. <p> This idea was first explored by Hummel [52] and later by Lenz [64]. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion [38] <ref> [89] </ref> yields the optimal subspace. The covariance matrix C = E q [(F E q [F ])(F E q [F ]) T ] represents the correlation between the pixels in the different feature instances.
Reference: [90] <author> P.L. Palmer, H. Dabis, and J. Kittler. </author> <title> A performance measure for boundary detection algorithms. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 63(3) </volume> <pages> 476-494, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] <ref> [90] </ref>. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121].
Reference: [91] <author> L. Parida, D. Geiger, and R. Hummel. Kona: </author> <title> A mulie-junction detector and classifier. </title> <booktitle> In Proceedings of the International Conference on Energy Minimization in Computer Vision and Pattern Recognition, </booktitle> <address> Venice, Italy, </address> <year> 1997. </year>
Reference-contexts: A related approach is that of Parida et al. in <ref> [91] </ref>. Non-uniformly weighted L 2 norms have also been used in a number of differential invariant feature detectors that use the surface fitting approach described in Section 2.2.1.
Reference: [92] <author> K. Paton. </author> <title> Picture description using Legendre polynomials. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 40-54, </pages> <year> 1975. </year> <month> 164 </month>
Reference-contexts: In this paper, Abdou and Pratt mention that weighting the pixels so as to reduce the influence of pixels that are distant from the center pixel improves Pratt's Figure of Merit [100], but few details are given. Finally, Paton <ref> [92] </ref> proposed a number of non-uniform weighting functions, although he never actually used any of them.
Reference: [93] <author> D.A. Patterson and J.L. Hennessy. </author> <title> Computer Architecture: A Quantitive Approach. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: The first method is subjective. The second does not use real images. It seems exceedingly unlikely that there is a single, simple method of "fairly" evaluating a feature detector. Even in a field as mature as computer architecture, 4 there is no universally agreed upon way of measuring performance <ref> [93] </ref>. Instead, the usual approach is to apply a large number of benchmarks, each of which is designed to be typical of a certain range of applications. The overall performance on the benchmarks is then used to compare the different architectures. <p> It seems exceedingly unlikely that there is a single, simple method of "fairly" evaluating an edge detector. Even in a field as mature as computer architecture, there is no universally agreed upon way of measuring performance <ref> [93] </ref>. Instead, the usual approach is to apply a large number of simple benchmark tests, each of which is designed to be typical of a range applications. The overall performance on the benchmarks is then used to compare the architectures.
Reference: [94] <author> F. Pedersini, A. Sarti, and S. Tubaro. </author> <title> Estimation and compensation of sub-pixel edge localization error. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(11) 1278-1284, November 1997. 
Reference-contexts: These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], [1], [11], <ref> [94] </ref>, and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> One exception is <ref> [94] </ref>. In this paper, Pedersini et al. are interested in maximizing the sub-pixel localization accuracy. They claim that to do so, the details of the imaging system must be taken into consideration. In particular, they model image formation as non-linear radial distortion, followed by low-pass filtering, and then ideal sampling.
Reference: [95] <author> T. Peli and D. Malah. </author> <title> A study of edge detectional algorithms. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 20 </volume> <pages> 1-21, </pages> <year> 1982. </year>
Reference-contexts: Perhaps the most well known example is Pratt's Figure of Merit [1] <ref> [95] </ref>. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge [20] [27]. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. <p> Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] <ref> [95] </ref> [121]. Such properties are particularly important for applications that first aggregate individual features into groups before performing any subsequent processing. 2.5.2 Evaluation Techniques If ground truth data existed for a large collection of images, estimating any of the measures would be straightforward. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], <ref> [95] </ref>, [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap.
Reference: [96] <author> P. Perona and J. Malik. </author> <title> Scale-space and edge detection using anisotropic diffusion. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(7) </volume> <pages> 629-639, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Koenderink [60] also pointed out that smoothing the image with a Gaussian is equivalent to solving the heat equation, also known as the diffusion equation. 27 Much later, this fact lead Perona and Malik to propose anisotropic diffusion as a mechanism to detect edges <ref> [96] </ref>. Diffusion is discouraged in the direction of large image gradients, thereby encouraging the formation of a small number of uniform intensity regions separated by boundaries with large gradient magnitude.
Reference: [97] <author> M. Petrou and J. Kittler. </author> <title> Optimal edge detectors for ramp edges. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5) </volume> <pages> 483-491, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Rather than considering the product of the first two criteria while keeping the third one fixed, Spacek chose to optimize the product of all three criteria [113]. Later, Petrou and Kittler used Spacek's approach to derive optimal filters for ramp edges <ref> [97] </ref>. Another optimal (IIR) filter is the Sarkar-Boyer detector [109]. Rather than using Canny's third criterion, Sarkar and Boyer used a slightly different criterion designed to measure the likelihood of spurious responses to noise. <p> In particular, they model image formation as non-linear radial distortion, followed by low-pass filtering, and then ideal sampling. A simpler approach to sub-pixel localization was proposed by Nalwa [78]. Nalwa simply suggested that the image is sub-sampled. Another example of sensor modeling is <ref> [97] </ref>. Petrou and Kittler argue that ideal step edges do not occur in real images. Instead, real edges are actually ramp edges. They follow the approach of Canny [20] and derive optimal filters for ramp edges, which they claim yield better performance than filters designed for ideal step edges. <p> Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and <ref> [97] </ref>. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [98] <author> K.K. Pingle. </author> <title> Visual perception by a computer. </title> <editor> In A. Grasselli, editor, </editor> <booktitle> Automatic Interpretation and Classification of Images, </booktitle> <pages> pages 277-284. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: The first two are the Canny-like operator and the Nalwa-Binford detector that were considered in Chapter 4. The third is the step edge detector developed in Chapter 3. The final two are the Roberts' cross operator [105] and the Sobel operator <ref> [98] </ref>, both of which are described in texts such as [79] and [100]. The Canny and Nalwa-Binford detectors are relatively modern and 127 highly regarded. The Roberts' cross and Sobel operators were amongst the first few edge detectors proposed, and are regarded as relatively poor detectors.
Reference: [99] <author> R.L. Plackett. </author> <title> Principles of Regression Analysis. </title> <publisher> Oxford Univeristy Press, </publisher> <year> 1960. </year>
Reference-contexts: For linear manifolds, finding the closest point on the manifold is simply a weighted least squares problem. So, finding the optimal weighting function corresponds to selecting the weighting function that gives the best linear unbiased estimate of the solution to a weighted least squares problem [63] <ref> [99] </ref>. The answer to this problem was found by Aitken in [3]. The optimal weighting function is: w (n; m) = Var [(n; m)] where Var [(n; m)] = E [ 2 (n; m)] E [(n; m)] 2 is the variance of the noise in pixel (n; m). <p> It is possible to generalize this result to the non-independent case, but it requires that the weighting function w (n; m) be replaced with a positive definite quadratic form. The optimal choice for the positive definite quadratic form is the inverse of the covariance matrix of the noise <ref> [99] </ref>. See Section 5.5.1 for a discussion of the use of positive definite quadratic forms in feature detection.
Reference: [100] <author> W.K. Pratt. </author> <title> Digital Image Processing. </title> <publisher> Wiley-Interscience, </publisher> <year> 1991. </year>
Reference-contexts: In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt <ref> [100] </ref>, Nalwa [79], and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors. From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. <p> Another example of the use of non-uniformly weighted L 2 norms is [1]. In this paper, Abdou and Pratt mention that weighting the pixels so as to reduce the influence of pixels that are distant from the center pixel improves Pratt's Figure of Merit <ref> [100] </ref>, but few details are given. Finally, Paton [92] proposed a number of non-uniform weighting functions, although he never actually used any of them. <p> See any good image processing text such as <ref> [100] </ref> for a survey. Perhaps the most well known and simplest example is separability. <p> One example of a paper that uses the fast Fourier transform to implement a filtering operation efficiently is Shanmugam et al. [111]. Another technique, that can often be even more efficient than Fourier domain processing, is recursive filtering <ref> [100] </ref> [35]. Perhaps even more importantly, recursive filtering can be used to implement certain infinite impulse response (IIR) filters, which otherwise could only be truncated and approximated as a finite input response (FIR) filter. Recursive filtering is based upon a recursive relationship between the filtered image and the input image. <p> The third is the step edge detector developed in Chapter 3. The final two are the Roberts' cross operator [105] and the Sobel operator [98], both of which are described in texts such as [79] and <ref> [100] </ref>. The Canny and Nalwa-Binford detectors are relatively modern and 127 highly regarded. The Roberts' cross and Sobel operators were amongst the first few edge detectors proposed, and are regarded as relatively poor detectors.
Reference: [101] <author> W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> second edition, </address> <year> 1992. </year> <month> 165 </month>
Reference-contexts: This result assumes the use of an orthonormal basis, but orthonormality can easily be obtained using Gram-Schmidt <ref> [101] </ref>. So, the weighted L 2 norm can be computed with exactly the same cost as the Euclidean L 2 norm: ie. using 3 d 1 arithmetic operations. <p> I decided to use an optimization algorithm that does not evaluate the partial derivatives of the optimality criterion. The partial derivatives are so complicated that probably the only way to estimate them would be numerically anyway. I implemented Powell's Method directly from Chapter 10.5 of <ref> [101] </ref>. Powell's Method works by repeatedly performing 1-dimensional optimizations though the current best estimate of the minimum. <p> Each 1-dimensional optimization is performed using Brent's Method, which iteratively samples the optimality criterion 3 times, performs a parabolic fit, and then replaces one of the sample points with the minimum of the parabola <ref> [101] </ref>. After each application of Brent's Method, the best estimate of the minimum is updated and a new direction is chosen. The key decision in Powell's Method is how to choose and update the set of directions in which the 1-dimensional optimizations are performed. I used the technique suggested in [101] <p> <ref> [101] </ref>. After each application of Brent's Method, the best estimate of the minimum is updated and a new direction is chosen. The key decision in Powell's Method is how to choose and update the set of directions in which the 1-dimensional optimizations are performed. I used the technique suggested in [101] of starting with the basis vectors and "discarding the direction of largest decrease." As noted several times, my criteria are very complex; even evaluating them can be time-consuming. <p> ; 1)A (x i ; y i ; 1) T = 0: (6.20) 120 Since this constraint is linear in the six unknowns (a 11 ; a 12 ; a 13 ; a 22 ; a 23 , and a 33 ), the ellipse can be recovered using Gauss-Jordan elimination <ref> [101] </ref> if the locations of five edges on the ellipse are known. Since the vector of ellipse parameters is only determined up to a scale factor, the problem that appeared in Section 6.2.1 of setting the sign and scale of the vector of parameters also arises here. <p> The fourth measure, however, requires all quintuples of edges on the ellipse to be enumerated. Doing so will, in general, be intractable. So, to compute the fourth measure I use a Monte Carlo algorithm <ref> [101] </ref>. Quite simply, I sample the set of quintuples of edges randomly a fixed number of times, typically around 1000 times. I then compute the variance over the samples and use it as an estimate of the variance over the the entire set of quintuples.
Reference: [102] <author> J.M. Prewitt. </author> <title> Object enhancement and extraction. </title> <editor> In B.S. Lipkin and A. Rosenfeld, editors, </editor> <booktitle> Picture Processing and Psychopictorics. </booktitle> <publisher> Academic Press, </publisher> <year> 1970. </year>
Reference-contexts: The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. Examples include the Robert's cross operator [105] for which the detection decision is based upon the gradient of the best fitting plane, and the Prewitt operator <ref> [102] </ref> for which the decision is based upon the gradient of the best fitting quadratic surface [79]. Later, Prewitt's approach was extended by Morgenthaler and Rosenfeld to detect edges in 3-D volumetric data [75]. <p> Also, note the resemblance of the first two eigenvectors to the first-order spatial derivative operators that constitute the basis of many simple edge detectors, such as the Sobel operator <ref> [102] </ref>. In Figure 3.1 (d), the decay of the Karhunen-Loeve residual is plotted as a function of the number of eigenvectors. As can be seen, the first two eigenvec-tors capture about 80% of the information.
Reference: [103] <author> V. Ramesh and R.M. Haralick. </author> <title> Performance characterization of edge detectors. </title> <booktitle> SPIE Applications of Artificial Intelligence: Machine Vision and Robotics, </booktitle> <volume> 1708 </volume> <pages> 252-266, </pages> <year> 1992. </year>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], [1], [80], <ref> [103] </ref>, and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> For example, Abdou and Pratt [1] analyze the robustness of several simple edge detectors, Berzins [11] analyzes the localization estimation of a Laplacian edge detector, and Ramesh and Haralick <ref> [103] </ref> analyze the robustness and parameter estimation accuracy of two different detectors. <p> Evaluating the robustness of a feature detector is known to be difficult, amongst other reasons because of the lack of a characteristic model of a "non-feature" [80] <ref> [103] </ref>. Canny avoided this problem when defining his optimality criteria by using the signal to noise ratio, which he claimed to be correlated with robustness. Both Nalwa and Binford [80] and Ramesh and Haralick [103] simply used a constant intensity vector as their characteristic non-feature. <p> difficult, amongst other reasons because of the lack of a characteristic model of a "non-feature" [80] <ref> [103] </ref>. Canny avoided this problem when defining his optimality criteria by using the signal to noise ratio, which he claimed to be correlated with robustness. Both Nalwa and Binford [80] and Ramesh and Haralick [103] simply used a constant intensity vector as their characteristic non-feature.
Reference: [104] <author> K. Raghunath Rao and J. Ben-Arie. </author> <title> Optimal edge detection using expansion matching and restoration. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(12) </volume> <pages> 1169-1182, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: These include the energy in the vicinity of the edge studied by Shanmugam et al. [111] and by Lunscher [66], and the Discriminative Signal to Noise Ratio studied by Rao and Ben-Arie <ref> [104] </ref>. 19 2.4 Statistical Feature Detectors A small number of feature detectors have been proposed that are based upon statistical techniques. Although the results obtained using these detectors are on the whole quite poor, statistical feature detectors constitute a significant subclass of feature detectors. <p> See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio <ref> [104] </ref>. See Section 2.3 for more discussion of optimal edge detection. All of the above optimality criteria were developed for feature detectors based on filtering rather than for the model matching detectors considered in this thesis.
Reference: [105] <author> L.G. Roberts. </author> <title> Machine perception of three-dimensional solids. </title> <editor> In J.T. Trippit, D.A. Berkowitz, L.C. Chapp, C.J. Koester, and A. Vanderburgh, editors, </editor> <booktitle> Optical and Electro-Optical Information Processing, </booktitle> <pages> pages 159-197. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1965. </year>
Reference-contexts: The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. Examples include the Robert's cross operator <ref> [105] </ref> for which the detection decision is based upon the gradient of the best fitting plane, and the Prewitt operator [102] for which the decision is based upon the gradient of the best fitting quadratic surface [79]. <p> Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld [107] and Abramatic [2] studied the Hueckel [50] and Roberts <ref> [105] </ref> detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. <p> The first two are the Canny-like operator and the Nalwa-Binford detector that were considered in Chapter 4. The third is the step edge detector developed in Chapter 3. The final two are the Roberts' cross operator <ref> [105] </ref> and the Sobel operator [98], both of which are described in texts such as [79] and [100]. The Canny and Nalwa-Binford detectors are relatively modern and 127 highly regarded.
Reference: [106] <author> K. Rohr. </author> <title> Recognizing corners by fitting parametric models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(3) </volume> <pages> 213-230, </pages> <year> 1992. </year>
Reference-contexts: Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as [50], [51], [80], and <ref> [106] </ref>, are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> For example, Hueckel [51] generalized his step edge detector of [50] to detect a six parameter line in addition to the original four parameter step edge. Another example is Rohr's corner and Y-junction detector <ref> [106] </ref>. In Rohr's detector, the model parameters that give the closest match between the feature model and the image data are found in a two stage process. First, initial estimates are made based upon the output of applying an edge detector in the immediate vicinity. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], [74], [122], [80], and <ref> [106] </ref>. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr <ref> [106] </ref> used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. <p> Typically the sampling will result in the order of 10 5 points, which lie in a space of dimension N = 25-100. Further, the search for the closest manifold point must be repeated for each each pixel in the image. Nalwa and Binford [80] and Rohr <ref> [106] </ref> also used more realistic feature models than Hueckel and Hummel. Likewise, they used numerical algorithms to find the parameters of their models that best fit the image data. At first glance, applying a high dimensional search for every pixel in an image seems inefficient to the point of impracticality. <p> Most existing corner detectors are based upon differential invariant based measures of curvature [30], but Rohr <ref> [106] </ref> recently proposed a parametric model matching approach to corner detection. The simplest way to think about a corner is as the intersection of two non-parallel step edges.
Reference: [107] <author> A. Rosenfeld. </author> <title> The max Roberts operator is a Hueckel-type edge detector. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 3(1) </volume> <pages> 101-103, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld <ref> [107] </ref> and Abramatic [2] studied the Hueckel [50] and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator.
Reference: [108] <author> A. Rosenfeld, R.A. Hummel, </author> <title> and S.W. Zucker. Scene labeling by relaxation operations. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 6 </volume> <pages> 420-433, </pages> <year> 1976. </year> <month> 166 </month>
Reference-contexts: In particular, I assumed that the decision of whether to detect a feature is based solely upon the distribution of the pixel intensity values in the feature window, and independently of whether features are detected in neighboring windows. Existing post-processing and feature aggregation algorithms, such as relax 151 ation <ref> [108] </ref>, typically assume that a single feature detector has been applied to the image. Not surprisingly, the feature detector is usually a step edge detector.
Reference: [109] <author> S. Sarkar and K.L. Boyer. </author> <title> On optimal infinite impulse response edge detection filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(11) </volume> <pages> 1154-1171, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Later, Petrou and Kittler used Spacek's approach to derive optimal filters for ramp edges [97]. Another optimal (IIR) filter is the Sarkar-Boyer detector <ref> [109] </ref>. Rather than using Canny's third criterion, Sarkar and Boyer used a slightly different criterion designed to measure the likelihood of spurious responses to noise. <p> For example, the infinite Deriche filter [29] can be implemented with 5 additions and 5 multiplications per pixel [35]. Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector <ref> [109] </ref>. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer [54]. <p> Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], <ref> [109] </ref>, and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [110] <author> M.A. Shah and R. Jain. </author> <title> Detecting time-varying corners. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 28 </volume> <pages> 345-355, </pages> <year> 1984. </year>
Reference-contexts: Shah and Jain showed that the Zuniga-Haralick detector is the same as the Kitchen-Rosenfeld detector divided by the magnitude of the gradient <ref> [110] </ref>. Finally, another corner detector is the Plessey corner detector [45]. The Plessey detector is based upon first order invariants of a smoothed image.
Reference: [111] <author> K.S. Shanmugam, </author> <title> F.M. Dickey, and J.A. Green. An optimal frequency domain filter for edge detection in digital pictures. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 1(1) </volume> <pages> 37-49, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: These include the energy in the vicinity of the edge studied by Shanmugam et al. <ref> [111] </ref> and by Lunscher [66], and the Discriminative Signal to Noise Ratio studied by Rao and Ben-Arie [104]. 19 2.4 Statistical Feature Detectors A small number of feature detectors have been proposed that are based upon statistical techniques. <p> In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. <ref> [111] </ref>. Other authors have attempted to unify entire classes of detectors. Both Brooks [17] and Haralick [42] tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. <p> Another example is processing in the Fourier transform domain, where a convolution can be implemented as a multiplication. One example of a paper that uses the fast Fourier transform to implement a filtering operation efficiently is Shanmugam et al. <ref> [111] </ref>. Another technique, that can often be even more efficient than Fourier domain processing, is recursive filtering [100] [35]. <p> Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge <ref> [111] </ref> [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection. All of the above optimality criteria were developed for feature detectors based on filtering rather than for the model matching detectors considered in this thesis.
Reference: [112] <author> M.C. Shin, D. Goldgof, and K.W. Bowyer. </author> <title> An objective comparison methodology of edge detection algorithms using a structure from motion task. </title> <booktitle> In Proceedings of the 1998 Workshop on Empirical Evaluation Techniques in Computer Vision, </booktitle> <pages> pages 235-254, </pages> <address> Santa Barbara, California, June 1998. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion <ref> [112] </ref>, industrial inspection [114], and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121]. <p> Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], [47], [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion <ref> [112] </ref> and industrial inspection [114], have been proposed recently. Each of my benchmarks is based upon a constraint on the edges in the scene, for example, that they are colinear. To capture the benchmark images, I carefully create a scene for which the constraint holds.
Reference: [113] <author> L.A. Spacek. </author> <title> Edge detection and motion estimation. </title> <journal> Image and Vision Computing, </journal> <volume> 4 </volume> <pages> 43-56, </pages> <year> 1986. </year>
Reference-contexts: See Section 2.6.3 for more details. A number of other authors have studied Canny's three criteria, and variants thereof. Rather than considering the product of the first two criteria while keeping the third one fixed, Spacek chose to optimize the product of all three criteria <ref> [113] </ref>. Later, Petrou and Kittler used Spacek's approach to derive optimal filters for ramp edges [97]. Another optimal (IIR) filter is the Sarkar-Boyer detector [109]. Rather than using Canny's third criterion, Sarkar and Boyer used a slightly different criterion designed to measure the likelihood of spurious responses to noise. <p> Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], <ref> [113] </ref>, [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [114] <author> C. Steeger. </author> <title> Analytical and empirical performance evaluation of subpixel line and edge detection. </title> <booktitle> In Proceedings of the 1998 Workshop on Empirical Evaluation Techniques in Computer Vision, </booktitle> <pages> pages 188-210, </pages> <address> Santa Barbara, Cali-fornia, June 1998. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], [1], [11], [94], and <ref> [114] </ref>. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection <ref> [114] </ref>, and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121]. <p> Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], [47], [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection <ref> [114] </ref>, have been proposed recently. Each of my benchmarks is based upon a constraint on the edges in the scene, for example, that they are colinear. To capture the benchmark images, I carefully create a scene for which the constraint holds.
Reference: [115] <author> V. Torre and T.A. Poggio. </author> <title> On edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(2) </volume> <pages> 147-163, </pages> <month> March </month> <year> 1986. </year> <month> 167 </month>
Reference-contexts: For example, in [71] both unweighted and Guassian weighted L 2 norms were used to define the best fitting surface. 2.2.2 Filtering Differential Invariant Detectors The other way of computing the partial derivatives of the image is by filtering. As pointed out by Torre and Poggio <ref> [115] </ref>, the differentiation of a discrete image is an ill posed problem that needs to be regularized. One way to regularize the problem is by filtering, or smoothing, the image before differentiation. This filtering step 13 can be regarded as implicitly interpolating the image data to create a continuous surface. <p> Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties <ref> [115] </ref> have all been investigated. Naturally, other choices are possible. For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. [21] used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. <p> A slightly different choice was made by Kitchen and Rosenfeld [58], that being to use the rate of change of the gradient direction multiplied by the gradient magnitude, a measure which simplifies to: K = y + I yy I 2 I 2 y Torre and Poggio <ref> [115] </ref> later showed that this expression is also the second direc tional derivative in the direction orthogonal to the gradient. Two corner detectors closely related to the Kitchen-Rosenfeld detector are the Dreschler-Nagel detector [33] and the Zuniga-Haralick detector [123]. <p> Both Brooks [17] and Haralick [42] tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. Torre and Poggio presented a unified theory of differential invariant detector through regularization theory <ref> [115] </ref>. <p> A number of positive results have been found in which it has been shown that the zero crossings at multiple scales are complete for large classes of images [53] [120] <ref> [115] </ref>. However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69].
Reference: [116] <author> R.Y. Tsai. </author> <title> An efficient and accurate camera callibration technique for 3D machine vision. </title> <booktitle> In Proceedings of the 1986 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 364-374, </pages> <year> 1986. </year>
Reference-contexts: Both types of distortion can be modeled, but in practice the tangential component is negligible, and only the radial distortion is actually compensated for <ref> [116] </ref>. I applied Tsai's algorithm [116] to estimate the radial distortion, but found it also to be negligible ( 1 2:0 fi 10 6 pixels 2 ) for the focal length that I used. <p> Both types of distortion can be modeled, but in practice the tangential component is negligible, and only the radial distortion is actually compensated for <ref> [116] </ref>. I applied Tsai's algorithm [116] to estimate the radial distortion, but found it also to be negligible ( 1 2:0 fi 10 6 pixels 2 ) for the focal length that I used. So, I assumed the camera to be linear for the experiments described in Sections 6.4 and 6.5.
Reference: [117] <author> I. Weiss. </author> <title> High-order differential filters that work. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(7) </volume> <pages> 734-739, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Afterwards, in Section 2.2.3, I discuss differential invariant approaches to corner detection. Finally, note that a small number of papers have focused on how to estimate the partial derivatives required by differential invariant feature detectors, rather than on feature detection itself. Such papers include <ref> [117] </ref>, [71], and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" [17]. <p> For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. [21] used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. Hashimoto and Sklansky [41] and Weiss <ref> [117] </ref> both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. <p> Hashimoto and Sklansky [41] and Weiss <ref> [117] </ref> both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. A final example of a filtering based differential invariant detector is the half edge and vertex detector of [39].
Reference: [118] <author> A.P. Witken. </author> <title> Scale-space filtering. </title> <booktitle> In Proceedings of the 8th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1019-1022, </pages> <address> Karlsruhe, Ger-many, </address> <month> August </month> <year> 1983. </year>
Reference-contexts: Later, Canny used the same technique to define the scale of his detector [20]. Moreover, an entire theory of scale space has been developed, beginning with the work of Witken <ref> [118] </ref> and then of Koenderink [60]. These initial papers established the desirable properties of the Gaussian smoothing for scale space.
Reference: [119] <author> P.N. Yianilos. </author> <title> Data structures and algorithms for nearest neighbor search in general metric spaces. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993. </year>
Reference-contexts: Finding the nearest neighbor amongst a fixed set of points to a given novel point is a well studied problem that was first posed by Knuth [59]. A recent paper by Yanilos <ref> [119] </ref> contains a comprehensive survey of algorithms developed since then. The task of finding the closest sample point on the manifold has more structure than the general nearest neighbor problem since the sample points lie on the manifold.
Reference: [120] <author> A.L. Yuille and T.A. Poggio. </author> <title> Scaling theorems for zero crossings. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <year> 1986. </year>
Reference-contexts: A number of positive results have been found in which it has been shown that the zero crossings at multiple scales are complete for large classes of images [53] <ref> [120] </ref> [115]. However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69].
Reference: [121] <author> Q. Zhu. </author> <title> Efficient evaluation of edge connectivity and width uniformity. </title> <journal> Image and Vision Computing, </journal> <volume> 14 </volume> <pages> 21-34, </pages> <year> 1996. </year>
Reference-contexts: Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] <ref> [121] </ref>. Such properties are particularly important for applications that first aggregate individual features into groups before performing any subsequent processing. 2.5.2 Evaluation Techniques If ground truth data existed for a large collection of images, estimating any of the measures would be straightforward. <p> Direct Computation from Real Images: Some performance measures do not rely upon ground truth and can be computed directly from the detector output, for example, the local measures of coherence proposed in [57] and <ref> [121] </ref>. The major weakness of these approaches is that the output could totally misrepresent the structure of the scene and still be rated highly. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], [47], <ref> [121] </ref>, and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently.
Reference: [122] <author> S.W. Zucker and R.A. Hummel. </author> <title> A three-dimensional edge operator. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 3(3) </volume> <pages> 324-331, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: Due to the complexity of their edge model, Nalwa and Binford were unable to find a closed form solution for the best fitting parameters. Instead they used a numerical algorithm. Step edges can occur in 3-D volumetric data as well as in 2-D images. Zucker and Hummel <ref> [122] </ref> generalized Hummel's 2-D step edge detector [52] to detect step edges in volumetric data. Some of Lenz's results in [64] concerning the application of the Karhunen-Loeve expansion are also applicable to 3-D edge models. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], [74], <ref> [122] </ref>, [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as <ref> [122] </ref> and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in [82]. <p> Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel <ref> [122] </ref> and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel [50] and Hummel [52] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold.
Reference: [123] <author> O.A. Zuniga and R.M. Haralick. </author> <title> Corner detection using the facet model. </title> <booktitle> In Proceedings of the 1983 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 30-37. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1983. </year>
Reference-contexts: Two corner detectors closely related to the Kitchen-Rosenfeld detector are the Dreschler-Nagel detector [33] and the Zuniga-Haralick detector <ref> [123] </ref>. Nagel 15 showed that the Dreschler-Nagel detector and the Kitchen-Rosenfeld detector are equivalent if the heuristic of nonmaximum suppression along the gradient is applied to the gradient before multiplying by the gradient magnitude [76].
References-found: 123

