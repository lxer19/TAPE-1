URL: http://www.irisa.fr/EXTERNE/projet/lande/consel/papers/rt-spec.ps.gz
Refering-URL: http://www.cs.washington.edu/research/projects/unisw/DynComp/www/Related/papers.html
Root-URL: 
Email: fconsel,fnoelg@irisa.fr  
Title: A General Approach for Run-Time Specialization and its Application to C focusing on run-time specialization
Author: Charles Consel Fran~cois Noel 
Note: Run-time specialization is being actively investigated in a variety of areas. For example, recently, major operating system research projects have been  
Address: 35042 Rennes Cedex, France  
Affiliation: University of Rennes Irisa Campus Universitaire de Beaulieu  
Abstract: This paper describes a general approach to run-time specialization. For a given program and a declaration of its run-time invariants, it automatically produces source templates at compile time, and transforms them so that they can be processed by a standard compiler. At run time, only minor operations need to be performed: selecting and copying templates, filling holes with run-time values, and relocating jump targets. As a consequence, run-time specialization is performed very efficiently and thus does not require the specialized code to be executed many times before its cost is amortized. Our approach improves on previous work in that: (1) templates are automatically produced from the source program and its invariants, (2) the approach is not machine dependent, (3) it is formally defined and proved correct, (4) it is efficient, as shown by our implementation for the C language. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Chambers and D. Ungar. </author> <title> Customization: optimiz ing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In ACM SIG-PLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-160, </pages> <year> 1989. </year>
Reference-contexts: If the program fragments to be processed offer good opportunities for specialization, the run-time specialization process will likely be amortized and performance should improve, provided the specialized code is executed many times. Techniques to specialize object-oriented programs at run time have also been developed <ref> [1] </ref>. They are aimed at optimizing frequently executed code sections.
Reference: [2] <author> C. Consel and O. Danvy. </author> <title> From interpreting to compil ing binding times. </title> <editor> In N. D. Jones, editor, ESOP'90, </editor> <booktitle> 3 rd European Symposium on Programming, </booktitle> <pages> pages 88-105, </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: While the binding-time analysis determines what to do for each syntactic construct in a program, the action analysis determines how to do it <ref> [2] </ref>. In other words, binding-time information is used to determine what specialization action (i.e., program transformation) should be performed. A small subset of the actions used for the C language is presented in Section 4. Once the actions of a program are produced, various back-ends can exploit this information.
Reference: [3] <author> C. Consel and O. Danvy. </author> <booktitle> Tutorial notes on partial eval uation. In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <year> 1993. </year>
Reference-contexts: Our run-time specialization approach is based, in part, on partial evaluation technology <ref> [8, 3] </ref>. In fact, it is integrated in a complete partial evaluation system for C programs that performs compile-time specialization as well as run-time specialization [4]; this aspect is further discussed in Section 2. This system has been applied to various kinds of programs such as operating system code. Plan. <p> Section 5 then discusses the related work. Finally, Section 6 gives some concluding remarks, and outlines the future directions of this work. 2 Partial Evaluation Partial evaluation is a program transformation technique aimed at specializing a program with respect to some parts of its input <ref> [8, 3] </ref>. There are two main strategies to perform partial evaluation. The first strategy, called on-line, consists of specializing a program in a single pass. As the program gets processed, the program transformations are determined and performed.
Reference: [4] <author> C. Consel, L. Hornof, F. Noel, J. Noye, and N. Volan schi. </author> <title> A Uniform Approach for Compile-Time and Run-Time Specialization. </title> <type> Technical Report, </type> <institution> University of Rennes/Inria, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: Our run-time specialization approach is based, in part, on partial evaluation technology [8, 3]. In fact, it is integrated in a complete partial evaluation system for C programs that performs compile-time specialization as well as run-time specialization <ref> [4] </ref>; this aspect is further discussed in Section 2. This system has been applied to various kinds of programs such as operating system code. Plan. In Section 2, the underlying concepts of partial evaluation are reviewed. <p> In this paper, we introduce an approach that goes beyond this view. We propose to use partial evaluation as a basis for run-time specialization. In fact, this work is part of a complete partial evaluation system which specializes C programs at compile time as well as at run time <ref> [4] </ref>. Let us briefly outline the salient features of this system. Our partial evaluation system is based on an off-line strategy. The preprocessing phase mainly consists of an alias analysis, a binding-time analysis, and an action analysis.
Reference: [5] <author> C. Consel and S.C. Khoo. </author> <title> On-line & Off-line Par tial Evaluation: Semantic Specifications and Correctness Proofs. </title> <type> Research Report, </type> <institution> Yale University, </institution> <address> New Haven, Connecticut, USA, </address> <year> 1993. </year> <note> Extended version. To appear in Journal of Functional Programming. </note>
Reference-contexts: Lastly, it is important to notice that the actions of a given program are assumed to be correct. Proving the correctness of actions is outside the scope of this paper. This issue is addressed by Consel and Khoo in the context of a functional language <ref> [5] </ref>. 4.4 Generating Run-time Specializers Given that the semantics of actions are defined, the remaining step is aimed at generating the run-time specializer from an action-analyzed program.
Reference: [6] <author> D. R. Engler and T. A. Proebsting. </author> <title> DCG: an efficient, retargetable dynamic code generation system. </title> <booktitle> In ACM Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <year> 1994. </year>
Reference-contexts: While the idea of run-time specialization is certainly attractive, considering the degree of improvement it can yield, the approaches explored so far have fundamental drawbacks. * They are manual. Usually templates are written by the programmer either directly in some low level language, or using some syntactic facilities <ref> [6] </ref>. * They are not clearly defined. Although existing ap proaches have shown their effectiveness, the process of run-time specialization has always been presented as a black-box; only the functionalities were described not the techniques. * They are not portable. <p> )]] = ([[Call (o; e rhs 1 ; e rhs where (e rhs 1 ; c 1 ) = E a 1 ]] 2 ; c 2 ) = E a 2 ]] 5 Related Work Recently two approaches to run-time code generation have been reported by Engler and Proebsting <ref> [6] </ref>, and by Leone and Lee [11]. These approaches include some aspects of run-time specialization and address issues related to compiling code at run time. <p> In contrast, our approach enables the compiler to process program fragments globally in that it is applied to the possible combinations of templates which can be constructed at run-time. Because the compiler processes large code fragments it is able to produce efficient code. Many existing approaches (e.g., <ref> [11, 6] </ref>) emphasize the need to perform elaborate optimizations at run time based on the fact that much more information is available then.
Reference: [7] <author> C. W. Fraser and D. R. Hanson. </author> <title> A code generation in terface for ANSI C. </title> <journal> Software Practice and Experience, </journal> <volume> 21(9) </volume> <pages> 963-988, </pages> <year> 1991. </year>
Reference-contexts: These approaches include some aspects of run-time specialization and address issues related to compiling code at run time. Engler and Proebsting's approach consists of providing the programmer with operations to construct templates manually in the intermediate representation of the LCC compiler (a form of register transfer language) <ref> [7] </ref>. Then, at run time, the operations to construct templates are executed, and a fast code generator is invoked to compile templates into binary code.
Reference: [8] <author> N. D. Jones, C. K. Gomard, and P. Sestoft. </author> <title> Par tial Evaluation and Automatic Program Generation. </title> <booktitle> Prentice-Hall International, </booktitle> <year> 1993. </year>
Reference-contexts: Our run-time specialization approach is based, in part, on partial evaluation technology <ref> [8, 3] </ref>. In fact, it is integrated in a complete partial evaluation system for C programs that performs compile-time specialization as well as run-time specialization [4]; this aspect is further discussed in Section 2. This system has been applied to various kinds of programs such as operating system code. Plan. <p> Section 5 then discusses the related work. Finally, Section 6 gives some concluding remarks, and outlines the future directions of this work. 2 Partial Evaluation Partial evaluation is a program transformation technique aimed at specializing a program with respect to some parts of its input <ref> [8, 3] </ref>. There are two main strategies to perform partial evaluation. The first strategy, called on-line, consists of specializing a program in a single pass. As the program gets processed, the program transformations are determined and performed. <p> Once the actions of a program are produced, various back-ends can exploit this information. Firstly, they can be interpreted; this situation corresponds to a specializer. Secondly, they can be compiled to produce a dedicated special-izer (also called a generating extension <ref> [8] </ref>). Finally, actions can be used to achieve run-time specialization. The last alternative comes from the fact that actions define program transformations and thus can be used as a basis to determine what specialized programs an action-analyzed program can yield.
Reference: [9] <author> D. Keppel, S. Eggers, and R. Henry. </author> <title> A Case for Run time Code Generation. </title> <type> Technical Report, </type> <institution> University of Washington, </institution> <address> Seattle, Washington, </address> <year> 1991. </year>
Reference-contexts: They report speedup factors that range from 2 to 40 depending on the system component considered [13]. Although various forms of run-time specializations have undoubtedly been shown to improve substantially the performance of programs, the specialization process has always been done manually <ref> [9] </ref>. The usual approach consists of defining code templates, that is, code fragments parameterized with respect to run-time values. Then at run time, templates are linked together depending on the control flow, and holes (i.e., template parameters) are filled with run-time values [10].
Reference: [10] <author> D. Keppel, S. Eggers, and R. Henry. </author> <title> Evaluating Run time Compiled Value-Specific Optimizations. </title> <type> Technical Report 93-11-02, </type> <institution> University of Washington, </institution> <address> Seattle, Washington, </address> <year> 1993. </year>
Reference-contexts: The usual approach consists of defining code templates, that is, code fragments parameterized with respect to run-time values. Then at run time, templates are linked together depending on the control flow, and holes (i.e., template parameters) are filled with run-time values <ref> [10] </ref>. To minimize the cost of run-time specialization, templates are often represented in a binary form to avoid invoking an assembler, or even more expensive, a complete compiler, at run time. <p> In this section we present a transformation process aimed at converting these right-hand sides into source code fragments parameterized with run-time values. We call these fragments source templates. Template parameters are often called holes in the literature <ref> [10] </ref>. At run time, part of the specialization process consists of physically replacing these parameters by values. In other words, template holes are filled with run-time values. The resulting object is called an instance of the template.
Reference: [11] <author> M. Leone and P. Lee. </author> <title> Lightweight run-time code gen eration. </title> <booktitle> In ACM Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 97-106, </pages> <year> 1994. </year>
Reference-contexts: 1 ; e rhs where (e rhs 1 ; c 1 ) = E a 1 ]] 2 ; c 2 ) = E a 2 ]] 5 Related Work Recently two approaches to run-time code generation have been reported by Engler and Proebsting [6], and by Leone and Lee <ref> [11] </ref>. These approaches include some aspects of run-time specialization and address issues related to compiling code at run time. Engler and Proebsting's approach consists of providing the programmer with operations to construct templates manually in the intermediate representation of the LCC compiler (a form of register transfer language) [7]. <p> In contrast, our approach enables the compiler to process program fragments globally in that it is applied to the possible combinations of templates which can be constructed at run-time. Because the compiler processes large code fragments it is able to produce efficient code. Many existing approaches (e.g., <ref> [11, 6] </ref>) emphasize the need to perform elaborate optimizations at run time based on the fact that much more information is available then.
Reference: [12] <author> B. N. Locanthi. </author> <title> Fast bitblt with asm() and cpp. </title> <booktitle> In European Unix Users Group Conference Proceedings (EUUG), </booktitle> <year> 1987. </year>
Reference-contexts: In fact, various forms of run-time specializations have been studied on practical systems, and substantial improvements have been reported. Locanthi et al., for example, applied specialization to the bitblit procedure <ref> [14, 12] </ref>; their specialized code ran about 4 times faster than a generic implementation. In the area of operating system, Massalin and Pu designed an operating system which utilized run-time specialization as a fundamental technique to optimize a wide variety of system components.
Reference: [13] <author> H. Massalin and C. Pu. </author> <title> Threads and input/output in the Synthesis kernel. </title> <booktitle> In ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 191-201, </pages> <year> 1989. </year>
Reference-contexts: In the area of operating system, Massalin and Pu designed an operating system which utilized run-time specialization as a fundamental technique to optimize a wide variety of system components. They report speedup factors that range from 2 to 40 depending on the system component considered <ref> [13] </ref>. Although various forms of run-time specializations have undoubtedly been shown to improve substantially the performance of programs, the specialization process has always been done manually [9]. The usual approach consists of defining code templates, that is, code fragments parameterized with respect to run-time values.
Reference: [14] <author> R. Pike, B. N. Locanthi, and J.F. Reiser. </author> <title> Hard ware/software trade-offs for bitmap graphics on the blit. </title> <journal> Software Practice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Specializing programs at run time with respect to dynamic invariants is an optimization technique that has already been explored in various areas such as operating systems [16] and graphics <ref> [14] </ref>. This technique is aimed at adapting programs to execution contexts by using run-time invariants. In the context of file system operations, examples of run-time invariants include the type of the file being opened, the device where it resides, and whether it is exclusively read. <p> In fact, various forms of run-time specializations have been studied on practical systems, and substantial improvements have been reported. Locanthi et al., for example, applied specialization to the bitblit procedure <ref> [14, 12] </ref>; their specialized code ran about 4 times faster than a generic implementation. In the area of operating system, Massalin and Pu designed an operating system which utilized run-time specialization as a fundamental technique to optimize a wide variety of system components.
Reference: [15] <author> C. Pu, T. Autrey, A. Black, C. Consel, C. Cowan, J. Inouye, L. Kethana, J. Walpole, and K. Zhang. </author> <title> Optimistic incremental specialization: streamlining a commercial operating system. </title> <booktitle> In ACM Symposium on Operating Systems Principles, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: When a file is being opened, at run time, invariants become available and can be exploited to specialize read and/or write routines. As reported by Pu et al. this specializa tion eliminates redundant interpretation of data structures and yields significant improvements <ref> [15] </ref>. In fact, various forms of run-time specializations have been studied on practical systems, and substantial improvements have been reported. Locanthi et al., for example, applied specialization to the bitblit procedure [14, 12]; their specialized code ran about 4 times faster than a generic implementation.
Reference: [16] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> ACM Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Specializing programs at run time with respect to dynamic invariants is an optimization technique that has already been explored in various areas such as operating systems <ref> [16] </ref> and graphics [14]. This technique is aimed at adapting programs to execution contexts by using run-time invariants. In the context of file system operations, examples of run-time invariants include the type of the file being opened, the device where it resides, and whether it is exclusively read.
References-found: 16

