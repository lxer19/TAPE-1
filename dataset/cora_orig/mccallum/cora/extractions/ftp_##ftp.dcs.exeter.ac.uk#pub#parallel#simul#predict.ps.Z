URL: ftp://ftp.dcs.exeter.ac.uk/pub/parallel/simul/predict.ps.Z
Refering-URL: http://www.dcs.exeter.ac.uk/reports/reports.html
Root-URL: 
Email: Email: [ferschajjohnson]@ani.univie.ac.at Email: steve@atlas.ex.ac.uk  
Title: Early Performance Prediction of Parallel Simulation Protocols  
Author: Alois Ferscha, James Johnson Stephen J. Turner 
Keyword: Parallel Simulation, Performance Prediction, Time Warp, CMB, Factorial Design.  
Address: Lenaugasse 2/8, A-1080 Vienna, AUSTRIA Exeter EX4 4PT, ENGLAND  
Affiliation: Institut fur Angewandte Informatik Department of Computer Science Universitat Wien University of Exeter  
Abstract: The performance of logical process based parallel simulation (PS) protocols like Time Warp and Chandy/Misra/Bryant is influenced by a variety of factors such as the event structure underlying in the simulation model, the partitioning into submodels, the performance characteristics of the execution platform, the implementation of the simulation engine and optimizations related to the protocols. The mutual performance effects of parameters exhibit a prohibitively complex degree of interweaving, giving analytical performance investigations only relative importance. Nevertheless, performance analysis is of utmost practical interest for the simulationist who wants to decide on the suitability of a certain PS protocol for a specific simulation model before substantial efforts are invested in developing sophisticated PS codes. Since PS performance prediction based on analytical models appears doubtful with respect to adequacy and accuracy, this work presents a prediction methodology based on the simulated execution of skeletal implementations of PS protocols. Appropriate statistical methods and a simulation tool for PS protocols have been developed for PS performance prediction, supporting the simulationist in three types of decision problems: (i) given a simulation problem and parallel execution platform, which PS protocol promises best performance, (ii) given a simulation model and a PS strategy, which execution platform is appropriate from the performance viewpoint, and (iii) what class of simulation models is best executed on a given multiprocessor using a certain PS protocol. Methodologically, skeletons of the most important variations of PS protocols are developed and executed in the N-MAP performance prediction environment, and performance data is collected creating a full factorial design. The design predictor variables are used to explain PS performance. 
Abstract-found: 1
Intro-found: 1
Reference: [Akyi 93] <author> I. F. Akyildiz, L. Chen, R. Das, R. M. Fujimoto, and R. F. Serfozo. </author> <title> "The Effect of Memory Capacity on Time Warp Performance". </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 18, No. 4, </volume> <pages> pp. 411-422, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: For the purpose of prediction, "classical" (analytical) performance analysis techniques using formalisms like stochastic (e.g. Markovian) processes, queueing network models, Petri nets, etc. serve to abstract the simulation model, the PS protocol and target platform characteristics into models (examples are <ref> [Gupt 91, Akyi 93] </ref>).
Reference: [Ayan 93] <author> R. Ayani and B. Berkman. </author> <title> "Parallel Discrete Event Simulation on SIMD Computers". </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 18, No. 4, </volume> <pages> pp. 501-508, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: This event is evidently safe to process. As with the GVT calculation of optimistic protocols, this involves a global reduction over all the timestamps of all unprocessed events. With synchronous algorithms (e.g. <ref> [Ayan 93] </ref>), the simulation proceeds in cycles, where each cycle consists of a processing phase, followed by a global synchronization to determine the set of safe events to be processed in the next cycle.
Reference: [Bain 88] <author> W. L. Bain and D. S. Scott. </author> <title> "An Algorithm for Time Synchronization in Distributed Discrete Event Simulation". </title> <editor> In: B. Unger and D. Jefferson, Eds., </editor> <booktitle> Proceedings of the SCS Multiconfer-ence on Distributed Simulation, </booktitle> <volume> 19 (3), </volume> <pages> pp. 30-33, </pages> <publisher> SCS, </publisher> <month> February </month> <year> 1988. </year>
Reference-contexts: Deadlock avoidance algorithms such as CMB involve the use of null messages for synchronization purposes. An important variation of the deadlock avoidance approach is to send null messages on demand <ref> [Bain 88] </ref> rather than after each event. This strategy helps to reduce the number of null messages exchanged between LPs, but leads to a longer delay 6 because a request message must now be transmitted for each null message.
Reference: [Chan 79] <author> K. M. Chandy and J. Misra. </author> <title> "Distributed Simulation: A Case Study in Design and Verification of Distributed Programs". </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-5, No. 5, </volume> <pages> pp. 440-452, </pages> <month> Sep. </month> <year> 1979. </year>
Reference-contexts: Presumably more than 1500 research papers have appeared (since the pioneering works by Chandy and Misra <ref> [Chan 79] </ref> and Jefferson [Jeff 85]) which have significantly contributed in the scientific sense, but nevertheless failed to bring the field also to an industrial and/or commercial success.
Reference: [Das 94] <author> S. R. Das and R. M. Fujimoto. </author> <title> "An Adaptive Memory Management Protocol for Time Warp Parallel Simulation". </title> <booktitle> In: Proc. of the 1994 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <address> Nashville, </address> <year> 1994, </year> <pages> pp. 201-210, </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference: [Fers 95] <author> A. Ferscha and J. Johnson. "N-MAP: </author> <title> A Virtual Processor Discrete Event Simulation Tool for Performance Predicition in CAPSE". </title> <booktitle> In: Proceedings of the HICSS-28, </booktitle> <pages> pp. 276-285, </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year> <month> 19 </month>
Reference-contexts: In the sequel we present a particular choice for the level of abstraction reflecting PS simulation strategies and simulation model characteristics in a set of attributes, whereas for the platform characterization (again for space reasons) we refer the reader to our previous work <ref> [Fers 95] </ref>. <p> Another aspect of the implementation is to preserve the comparability of predicted performance for the various protocols, and most importantly, to preserve the preliminary coding efforts for the final implementation. The N-MAP <ref> [Fers 95, Fers 96b] </ref> toolset meets these requirements: first it supports an incremental coding process, i.e. a repetitive refinement of a preliminary code 7 skeleton eventually yields the full implementation which allows for performance prediction at any level of completeness of the skeleton.
Reference: [Fers 96a] <author> A. Ferscha. </author> <title> "Parallel and Distributed Simulation of Discrete Event Systems". </title> <editor> In: A. Y. Zomaya, Ed., </editor> <booktitle> Parallel and Distributed Computing Handbook, </booktitle> <pages> pp. 1003 - 1041, </pages> <publisher> McGraw-Hill, </publisher> <year> 1996. </year>
Reference-contexts: This pathological behavior is basically due to the "unlimited" optimism assumption underlying TW, and has often been referred to as rollback thrashing. Overall, no general rule of superiority of the two strategies can be formulated <ref> [Fers 96a] </ref>, nor can performance improvement be assured through protocol optimizations such as lazy cancelation (TW), adaptive state saving (TW), optimism control mechanisms (TW), receiver initiated lookahead propagation (CMB), deadlock detection and recovery (CMB). 1.2 Performance prediction is hard but indispensable In his reflections on the parallel simulation research "survival" discussion <p> As a shorthand notation, we write the four cases of interest as [-SI, -GVT], [-SI, +GVT], [+SI, -GVT] and [+SI, +GVT]. Important factors of TW are the cancelation policy and the state saving mechanism, as demonstrated by the number of papers published describing implementations of these mechanisms (see <ref> [Fers 96a] </ref> for a survey). While it is impossible to include all variations, a representative set of strategies should include both aggressive and lazy cancelation and full and incremental state saving. <p> The sensitivity of all the CMB protocols to model attributes (NU, HP) is comparably small (274.5 for NU and -117.4 for HP at 32 LPs), verifying a general observation for conservative protocols <ref> [Fers 96a] </ref> for this data set. The first level interactions show significance mostly when the sender initiated protocol (+SI) is involved, but the contribution to the event rate is of relative importance only.
Reference: [Fers 96b] <author> A. Ferscha and J. Johnson. </author> <title> "Concurrent Execution of Timed Petri Nets". </title> <editor> In: J. M. Charnes, D. J. Morrice, D. T. Brunner, and J. J. Swain, Eds., </editor> <booktitle> Proceedings of the 1996 Winter Simulation Conference, </booktitle> <pages> pp. 637 - 644, </pages> <year> 1996. </year>
Reference-contexts: Another aspect of the implementation is to preserve the comparability of predicted performance for the various protocols, and most importantly, to preserve the preliminary coding efforts for the final implementation. The N-MAP <ref> [Fers 95, Fers 96b] </ref> toolset meets these requirements: first it supports an incremental coding process, i.e. a repetitive refinement of a preliminary code 7 skeleton eventually yields the full implementation which allows for performance prediction at any level of completeness of the skeleton.
Reference: [Fers 96c] <author> A. Ferscha and J. Johnson. </author> <title> "Performance Prototyping of Parallel Applications in N-MAP". </title> <editor> In: , Ed., </editor> <booktitle> ICA 3 PP96, Proceedings of the 2 nd Internat. Conf. on Algorithms and Architectures for Parallel Processing, </booktitle> <address> June 11-13, 1996, Singapore, </address> <pages> pp. 84 - 91, </pages> <publisher> IEEE Cs Press, </publisher> <year> 1996. </year>
Reference-contexts: We have chosen a performance prototyping method, where an implementation skeleton of an LP simulation protocol serves directly as the performance model. A performance prediction testbed, N-MAP <ref> [Fers 96c] </ref>, has been developed to support performance engineering endeavors 4 from the early design phase of PS protocols in order to avoid late and costly re-engineering.
Reference: [Fuji 90] <author> R. M. Fujimoto. </author> <title> "Parallel Discrete Event Simulation". </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. 10, </volume> <pages> pp. 30-53, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: 1 Motivation Parallel discrete event simulation techniques <ref> [Fuji 90] </ref> in their traditional sense aim at an acceleration of the execution of a selfcontained simulation model by the spatial decomposition of that model and the concurrent simulation of the submodels by so called logical processes (LPs). <p> Among the huge variety of protocols and respective incremental optimizations that appeared in the literature, only a few represent basic corner-stones in parallel simulation. The identification of those is the goal of this section. Conservative protocols can be divided into three main approaches <ref> [Fuji 90] </ref> (i) deadlock avoidance algorithms, (ii) deadlock detection and recovery algorithms, and (iii) synchronous algorithms. Deadlock avoidance algorithms such as CMB involve the use of null messages for synchronization purposes.
Reference: [Fuji 93] <author> R. M. Fujimoto. </author> <title> "Parallel Discrete Event Simulation: Will the Field Survive?". </title> <journal> ORSA Journal of Computing, </journal> <volume> Vol. 5, No. 3, </volume> <pages> pp. 218-230, </pages> <year> 1993. </year>
Reference-contexts: This pessimism has also diffused into the community and has led to an existential discussion on the chances of survival as reflected in a collection of papers following Fujimoto's position statement in <ref> [Fuji 93] </ref>.
Reference: [Gupt 91] <author> A. Gupta, I. Akyildiz, and R. Fujimoto. </author> <title> "Performance Analysis of Time Warp With Multiple Homogeneous Processors". </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 17, No. 10, </volume> <pages> pp. 1013 - 1027, </pages> <year> 1991. </year>
Reference-contexts: For the purpose of prediction, "classical" (analytical) performance analysis techniques using formalisms like stochastic (e.g. Markovian) processes, queueing network models, Petri nets, etc. serve to abstract the simulation model, the PS protocol and target platform characteristics into models (examples are <ref> [Gupt 91, Akyi 93] </ref>).
Reference: [Jeff 85] <author> D. A. Jefferson. </author> <title> "Virtual Time". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 7, No. 3, </volume> <pages> pp. 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Presumably more than 1500 research papers have appeared (since the pioneering works by Chandy and Misra [Chan 79] and Jefferson <ref> [Jeff 85] </ref>) which have significantly contributed in the scientific sense, but nevertheless failed to bring the field also to an industrial and/or commercial success.
Reference: [Lamp 78] <author> L. Lamport. </author> <title> "Time, Clocks, and the Ordering of Events in Distributed Systems". </title> <journal> Communications of the ACM, </journal> <volume> Vol. 21, No. 7, </volume> <pages> pp. 558 - 565, </pages> <month> Jul </month> <year> 1978. </year>
Reference-contexts: Causal correctness is defined in terms of timestamps of discrete events, and a simulation sample path is considered consistent if each event t that happens before some other event s in the real system, is generated into the simulation's sample path before s <ref> [Lamp 78] </ref>. Presumably more than 1500 research papers have appeared (since the pioneering works by Chandy and Misra [Chan 79] and Jefferson [Jeff 85]) which have significantly contributed in the scientific sense, but nevertheless failed to bring the field also to an industrial and/or commercial success.
Reference: [Lin 93a] <author> Y.-B. Lin. </author> <title> "Will Parallel Simulation Research Survive?". </title> <journal> ORSA Journal of Computing, </journal> <volume> Vol. 5, No. 3, </volume> <pages> pp. 236-238, </pages> <year> 1993. </year>
Reference-contexts: assured through protocol optimizations such as lazy cancelation (TW), adaptive state saving (TW), optimism control mechanisms (TW), receiver initiated lookahead propagation (CMB), deadlock detection and recovery (CMB). 1.2 Performance prediction is hard but indispensable In his reflections on the parallel simulation research "survival" discussion ("Will Parallel Simulation Research Survive?"), Lin <ref> [Lin 93a] </ref> contributes the following: . . . It is important to predict the performance of parallel simulation before a simu-lationist invests a substantial effort in developing parallel codes.
Reference: [Lin 93b] <author> Y.-B. Lin, B. Preiss, W. Loucks, and E. Lazowska. </author> <title> "Selecting the Checkpoint Interval in Time Warp Simulation". </title> <editor> In: R. Bagrodia and D. Jefferson, Eds., </editor> <booktitle> Proc. of the 7 th Workshop on Parallel and Distributed Simulation, </booktitle> <pages> pp. 3-10, </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: The rollback procedure in turn relies on the reconstructability of past states which can be guaranteed by a systematic state saving policy and corresponding state reconstruction procedures where space complexity is interchangeable with computational complexity (at least to some extent) <ref> [Lin 93b] </ref>. The related state saving overheads are not present in CMB protocols, but the strict adherence to time-stamp-order event 3 processing makes these protocols prone to deadlock due to cyclic waiting for safe-to-process con-cessions.
Reference: [Lin 96] <author> J. Y.-B. Lin. </author> <title> "Will Parallel Simulation Come to an End?". </title> <booktitle> Simulation Digest, </booktitle> <volume> Vol. 25, No. 3, </volume> <pages> pp. 11 - 12, </pages> <year> 1996. </year>
Reference-contexts: the Prophet, evidently the Prophet must go to the mountain." [Nico 95], expressing the hope that simulation practitioners and simulationists in industry would at least meet "half way" [Nico 95] on their way to integrating parallel simulation techniques into commercial/industrial simulators in a transparent way, this discussion has not stopped <ref> [Lin 96] </ref>. We see several reasons for this: * The coinfluence of the parallel simulation strategy, the execution platform and the simulation model on performance is not understood as of today.
Reference: [Luba 91] <author> B. D. Lubachevsky, A. Weiss, and A. Shwartz. </author> <title> "An Analysis of Rollback-Based Simulation". </title> <journal> ACM Transactions on Modeling and Computer Simulation, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 154-193, </pages> <month> April </month> <year> 1991. </year>
Reference: [Nico 95] <author> D. M. Nicol and P. Heidelberger. </author> <title> "On Extending Parallelism to Serial Simulators". </title> <booktitle> In: Proc. of the 9 th Workshop on Parallel and Distributed Simulation, </booktitle> <pages> pp. 60-67, </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1995. </year>
Reference-contexts: Despite successful attempts to escape from this image in the spirit of "As the mountain is not coming to the Prophet, evidently the Prophet must go to the mountain." <ref> [Nico 95] </ref>, expressing the hope that simulation practitioners and simulationists in industry would at least meet "half way" [Nico 95] on their way to integrating parallel simulation techniques into commercial/industrial simulators in a transparent way, this discussion has not stopped [Lin 96]. <p> Despite successful attempts to escape from this image in the spirit of "As the mountain is not coming to the Prophet, evidently the Prophet must go to the mountain." <ref> [Nico 95] </ref>, expressing the hope that simulation practitioners and simulationists in industry would at least meet "half way" [Nico 95] on their way to integrating parallel simulation techniques into commercial/industrial simulators in a transparent way, this discussion has not stopped [Lin 96].
Reference: [Turn 92] <author> S. Turner and M. Xu. </author> <title> "Performance Evaluation of the Bounded Time Warp Algorithm". </title> <booktitle> In: Proceedings of the 6 th Workshop on Parallel and Distributed Simulation, </booktitle> <pages> pp. 117-128, </pages> <publisher> SCS, </publisher> <month> January </month> <year> 1992. </year> <month> 20 </month>
Reference-contexts: A factor that must therefore be considered in any analysis of TW protocols is the use of an optimism control mechanism. Although a number of mechanisms have been published, they differ mainly in how the constraints on optimism are expressed. Examples include windowing mechanisms (e.g. <ref> [Turn 92] </ref>) and memory management techniques ([Das 94]). A consideration of the important factors of an optimistic protocol thus leads to eight representative strategies.
References-found: 20

