URL: http://www.cs.indiana.edu/l/www/pub/shirley/der.ps
Refering-URL: http://www.cs.indiana.edu/l/www/pub/shirley/
Root-URL: http://www.cs.indiana.edu
Title: Density Estimation Radiosity elements for interactive walk-throughs, or ray-traced pixels for higher-quality still frames. The
Author: Peter Shirley Bretton Wade Philip M. Hubbard David Zareski Bruce Walter Donald P. Greenberg 
Note: Display output can be either Gouraud-shaded polygonal  that have been processed by previous  
Affiliation: Program of Computer Graphics Cornell University  
Abstract: This paper presents a new global-illumination algorithm for highly complex static environments containing both diffuse and non-diffuse surfaces. The algorithm accounts for all types of surface reflection, accommodates textured surfaces, and supports coarse-grained parallelism. A key to this method is a novel decomposition of the problem into a sequence of three loosely-coupled phases. The first phase consists of Monte Carlo particle tracing in which power-carrying particles are emitted from each luminaire, and tracked through the environment until they are absorbed. A list of particle "hit points" is kept for each surface. In the second phase, called the "density-estimation" phase, the stored hit points are used to construct an approximate irra-diance function for each surface. In the final phase, called the "meshing" phase, each surface irradiance function is approximated by a piecewise-linear function. Note to the reviewers: high-resolution color versions of the images in this paper are available at the following URL: http://www.graphics.cornell.edu/~bwade/der/ 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John M. Airey and Ming Ouh-young. </author> <title> Two adaptive techniques let progressive radiosity outperform the traditional radiosity algorithm. </title> <type> Technical Report TR89-20, </type> <institution> University of North Car-olina at Chapel Hill, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> A Monte Carlo shooting approach also allows for more general specular transport [16], and possesses inherent parallelism, as each shot can be processed independently. Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes <ref> [1, 22, 18, 17] </ref>, there has been little success generating adaptive computational meshes. Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection. <p> Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey <ref> [1] </ref> extended Arvo's technique to account for diffuse interreflection. Heckbert [12] extended Airey's work to include adaptive meshing, and was the first to observe that this was a form of density-estimation. <p> To make it easier to customize a kernel to a given set of samples, we can develop a "canonical" kernel that is non-zero in <ref> [1; 1] </ref> 2 and zero elsewhere. We can then use a scaling parameter h to widen or narrow the filter. <p> We plan on extending our implementation to allow triangles in the input geometry as well. We have chosen to use Silverman's k 2 kernel function [25]: k 2 (u; v) = 2 2 The function k 2 is a canonical kernel function that is nonzero only on <ref> [0; 1] </ref> 2 , has continuous first derivatives. and is relatively inexpensive to compute, requiring only a few additions amd multiplications. It also has a continuous second derivative, which can be exploited in the future 5 .
Reference: [2] <author> A. Appel. </author> <title> Some techniques for shading machine renderings of solids. </title> <booktitle> In AFIPS 1968 Spring Joint Computing Conference, </booktitle> <pages> pages 37-49, </pages> <year> 1968. </year>
Reference-contexts: Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes [1, 22, 18, 17], there has been little success generating adaptive computational meshes. Appel <ref> [2] </ref> traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection.
Reference: [3] <author> James Arvo. </author> <title> Backward ray tracing. </title> <booktitle> Developments in Ray Tracing, </booktitle> <pages> pages 259-263, </pages> <year> 1986. </year> <note> ACM Siggraph '86 Course Notes. </note>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes [1, 22, 18, 17], there has been little success generating adaptive computational meshes. Appel [2] traced particles from the source to estimate direct lighting. Arvo <ref> [3] </ref> extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection. Heckbert [12] extended Airey's work to include adaptive meshing, and was the first to observe that this was a form of density-estimation. <p> It is important to note that surfaces that receive fewer particles will get wider kernels and coarser meshes. This avoids the under-sampling problems of traditional illumination ray tracing <ref> [3] </ref> in a manner similar to Collins [6]. Unlike Collins, we do not require any coherence between adjacent particle paths, so we can choose appropriate kernel sizes for data that includes diffuse interreflection.
Reference: [4] <author> Shenchang Eric Chen, Holly Rushmeier, Gavin Miller, and Dou-glass Turner. </author> <title> A progressive multi-pass method for global illumination. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 165-174, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection. Heckbert [12] extended Airey's work to include adaptive meshing, and was the first to observe that this was a form of density-estimation. Chen et al. <ref> [4] </ref> used a kernel-based density-estimation technique to deal with caustic maps, and our density-estimation work can be considered an extension of their caustic map techniques to account for all illumination effects in a scene.
Reference: [5] <author> Micheal F. Cohen, Donald P. Greenberg, David S. Immel, and Philip J. Brock. </author> <title> An efficient radiosity approach for realistic image synthesis. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 6(2) </volume> <pages> 26-35, </pages> <year> 1986. </year>
Reference: [6] <author> Steven Collins. </author> <title> Adaptive splatting for specular to diffuse light transport. </title> <booktitle> In Proceedings of the Fifth Eurographics Workshop on Rendering, </booktitle> <pages> pages 119-135, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> An example kernel estimate is shown in Figure 3. Using kernel functions on the hit points is analogous to the idea of "splatting" in volume rendering [30], and is similar to the illumination ray tracing of Collins <ref> [6] </ref>. Silverman [25] notes that whatever properties the derivatives of k 1 have will be shared by f , so we can ensure a smooth estimate for f by choosing a smooth k 1 . <p> It is important to note that surfaces that receive fewer particles will get wider kernels and coarser meshes. This avoids the under-sampling problems of traditional illumination ray tracing [3] in a manner similar to Collins <ref> [6] </ref>. Unlike Collins, we do not require any coherence between adjacent particle paths, so we can choose appropriate kernel sizes for data that includes diffuse interreflection.
Reference: [7] <author> Robert L. Cook and Kennneth E. Torrance. </author> <title> A reflectance model for computer graphics. </title> <journal> Computer Graphics, </journal> <volume> 15(3) </volume> <pages> 307-316, </pages> <month> August </month> <year> 1981. </year> <booktitle> ACM Siggraph '81 Conference Proceedings. </booktitle>
Reference-contexts: Given the angle between the incoming particle and the surface normal (see Figure 4), then the reflectance is R () = R 0 + (1 R 0 )(1 cos ) 5 ) (similar to the models of Cook and Torrance <ref> [7] </ref> and Schlick [20]). If ~ &lt; R () then a new particle is generated and reflected in the specular direction. If s &lt; 1 then the reflected ray is perturbed using the technique for luminaire ray generation.
Reference: [8] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> P.v.m. 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: In each program, the master task is started first, and then spawns the user-specified number of worker tasks. For implementing the intertask communication, we chose the PVM 3 (Parallel Virtual Machine version 3) message passing library, which is developed and distributed by Oak Ridge National Laboratory <ref> [8] </ref>. 4.5 Sample results Figures 7 and 8 show ray-traced images of two view-independent density-estimation radiosity solutions of an environment with sixteen light sources forming a compact lattice to the left of the images.
Reference: [9] <author> Reid Gershbein, Peter Schroder, and Pat Hanrahan. </author> <title> Textures and radiosity: Controlling emission and reflection with texture maps. </title> <journal> Computer Graphics, </journal> <pages> pages 51-58, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Sig-graph '94 Conference Proceedings. </booktitle>
Reference-contexts: It is easy to get these two problems confused, but they are very different. Ironically, the strategy of placing kernels at the hit points is very similar, but in density-estimation the kernels are not scaled. 4 See the recent texturing work of Gershbein et al. <ref> [9] </ref> for a more detailed analysis. 3 Silverman p.14) This equation implies that we can store the irradiance and reflectance at each point and later reconstruct the radiance. <p> These ideas are based upon the "patch-element" radiosity work of Cohen et al.[5], Ward's Radiance system [29], and the texturing work of Gershbein et al. <ref> [9] </ref>. For a given surface, a list of hit points (u j ; v j ) is stored, each with an associated power of . The irradiance function represented by this list is a set of "delta" functions where a finite amount of power strikes an infinitely small area.
Reference: [10] <author> Andrew S. Glassner. </author> <title> A model for fluorescence and phospheres-cence. </title> <booktitle> In Proceedings of the Fifth Eurographics Workshop on Rendering, </booktitle> <pages> pages 57-68, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: This would be more expensive than our implementation, but would improve shadow detail. Because our energy transport is based on particle transport, previous work could be directly used to model dispersion and polarization [27], and time-dependent effects such as fluorescence and phosphorescence <ref> [10] </ref>. Our current implementation needs to sort all particle hit points for a single channel by surface id. Sorting billions of hit points in real memory would not be feasible. There are, however, sorting algorithms that do not require the entire data set to be memory-resident at one time (e.g.
Reference: [11] <author> E. Bruce Goldstein. </author> <title> Sensation and Perception. </title> <publisher> Wadsworth Publishing Co., </publisher> <address> Belmont, California, </address> <year> 1980. </year>
Reference-contexts: We scale the "brightness" dimension by using z = R (x; y)H (x; y)= 1=3 where R (x; y) is photometric reflectance, H (x; y) is illuminance, w 0 is the white-point, and the exponent is due to Stevens Law <ref> [11] </ref>. We clamp z to 1.0, and choose w 0 so that z = * corresponds to the largest allowable "brightness" error. In practice, determining the scaling parameters requires some trial and error. Fortunately, in our experience we found useful parameter values after only two or three attempts.
Reference: [12] <author> Paul S. Heckbert. </author> <title> Adaptive radiosity textures for bidirectional ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 24(3) </volume> <pages> 145-154, </pages> <month> August </month> <year> 1990. </year> <booktitle> ACM Siggraph '90 Conference Proceedings. </booktitle>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection. Heckbert <ref> [12] </ref> extended Airey's work to include adaptive meshing, and was the first to observe that this was a form of density-estimation. <p> It seems logical to guess a reasonable irradiance from the local denseness or sparseness of these hit points. For example, where the density of these points is high, we expect a high irradiance. As pointed out by Heckbert <ref> [12] </ref>, this is a classic density estimation problem, where we attempt to guess a plausible density function given a set of non-uniform random samples 3 .
Reference: [13] <author> David S. Immel, Michael F. Cohen, and Donald P. Greenberg. </author> <title> A radiosity method for non-diffuse environments. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 133-142, </pages> <month> August </month> <year> 1986. </year> <booktitle> ACM Siggraph '86 Conference Proceedings. </booktitle>
Reference-contexts: has the same emitted radiance distribution at each point on its surface (i.e. we can write L e (!) instead of L e (x; !)), and that at a given point, the probability density function for emission is a "Phong function" such as the one used by Immel et al. <ref> [13] </ref>: p (; ') = 2 e This implies that the radiance of a luminaire with total power i is: L (; ') = 2A To generate an emitted ray, we first pick a uniform random point on the surface of the luminaire, then pick a uniform metal/dielectric particle reflection. random
Reference: [14] <author> Donald Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Volume 1. </volume> <publisher> Addison-Wesley, </publisher> <address> New York, N.Y., </address> <year> 1981. </year>
Reference-contexts: Sorting billions of hit points in real memory would not be feasible. There are, however, sorting algorithms that do not require the entire data set to be memory-resident at one time (e.g. Knuth's two-tape sorting methods <ref> [14] </ref>). The mesh-decimation phase of our current algorithm could also be improved. For example, the mesh-decimation parameters could possibly be computed automatically, or eliminated altogether.
Reference: [15] <author> Dani Lischinski, Filippo Tampieri, and Donald P. Greenberg. </author> <title> Combining hierarchical radiosity and discontinuity meshing. </title> <journal> Computer Graphics, </journal> <pages> pages 199-208, </pages> <month> August </month> <year> 1993. </year> <booktitle> ACM Sig-graph '93 Conference Proceedings. </booktitle>
Reference-contexts: Teller et al. argue that the reason for these surprisingly small limits is the high memory overhead of the data structures associated with the computational mesh [28]. To solve this problem, we draw on an observation by Lischinski et al. <ref> [15] </ref>, that the computational mesh and the display mesh have different purposes and characteristics and therefore should be decoupled. <p> Textured surfaces could have the irradiance function multiplied into the texture, so that no mesh elements are needed to describe irradiance. This method does not specifically incorporate the prior research done on discontinuity meshing <ref> [15] </ref>, so shadows will not have the same quality as those with explicit discontinuity meshing. For value (D 0 ) discontinuities, the hit points could be reflected across the discontinuity segment, just as they are reflected across surface boundaries.
Reference: [16] <author> Thomas J. V. Malley. </author> <title> A shading method for computer generated images. </title> <type> Master's thesis, </type> <institution> University of Utah, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> Handling local complexity in sub-quadratic time suggests either a clustering approach [26] or a Monte Carlo shooting approach 2 . A Monte Carlo shooting approach also allows for more general specular transport <ref> [16] </ref>, and possesses inherent parallelism, as each shot can be processed independently. Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes [1, 22, 18, 17], there has been little success generating adaptive computational meshes.
Reference: [17] <author> Laszlo Neumann, Martin Feda, Manfred Kopp, and Werner Pur-gathofer. </author> <title> A new stochastic radiosity method for highly complex scenes. </title> <booktitle> In Proceedings of the Fifth Eurographics Workshop on Rendering, </booktitle> <pages> pages 195-206, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Typically, a single representation is used for both the computational and display meshes (e.g. the static mesh used by Neumann et al. <ref> [17] </ref> and the adaptive mesh used by Teller et al. [28]). Very few display mesh solutions have been produced for environments with more than a few thousand initial surfaces. <p> A Monte Carlo shooting approach also allows for more general specular transport [16], and possesses inherent parallelism, as each shot can be processed independently. Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes <ref> [1, 22, 18, 17] </ref>, there has been little success generating adaptive computational meshes. Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection.
Reference: [18] <author> S. N. Pattanaik. </author> <title> Computational Methods for Global Illumination and Visualization of Complex 3D Environments. </title> <type> PhD thesis, </type> <institution> Birla Institute of Technology & Science, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> These limitations need to be overcome in a single system if the use of global illumination solutions are to become widespread. Keeping the memory overhead low favors a Monte Carlo particle-shooting approach <ref> [18] </ref>, which only requires a ray-tracing acceleration structure. Handling local complexity in sub-quadratic time suggests either a clustering approach [26] or a Monte Carlo shooting approach 2 . <p> A Monte Carlo shooting approach also allows for more general specular transport [16], and possesses inherent parallelism, as each shot can be processed independently. Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes <ref> [1, 22, 18, 17] </ref>, there has been little success generating adaptive computational meshes. Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection.
Reference: [19] <author> Holly E. Rushmeier. </author> <title> Realistic Image Synthesis for Scenes with Radiatively Participating Media. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: Any algorithm that computes interactions between all pairs of N objects will require at least O (N 2 ) time. This limits their util ity in dealing with large models. * "Ideal" specular effects. Many radiosity algorithms can only use the "virtual image method" <ref> [19] </ref>, which is practical for solving models with only a limited number of ideal, planar, specular objects. Real models have windows, gloss paint, and metal luminaire-reflectors, and in general, non-diffuse surfaces. * Lack of parallelism.
Reference: [20] <author> Christophe Schlick. </author> <title> A customizable reflectance model for everyday rendering. </title> <booktitle> In Proceedings of the Fourth Eurographics Workshop on Rendering, </booktitle> <pages> pages 73-84, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Given the angle between the incoming particle and the surface normal (see Figure 4), then the reflectance is R () = R 0 + (1 R 0 )(1 cos ) 5 ) (similar to the models of Cook and Torrance [7] and Schlick <ref> [20] </ref>). If ~ &lt; R () then a new particle is generated and reflected in the specular direction. If s &lt; 1 then the reflected ray is perturbed using the technique for luminaire ray generation.
Reference: [21] <author> William J. Schroeder, Jonathan A. Zarge, and William E. Lorensen. </author> <title> Decimation of triangle meshes. </title> <editor> In Edwin E. Catmull, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '92 Proceedings), </booktitle> <volume> volume 26, </volume> <pages> pages 65-70, </pages> <month> July </month> <year> 1992. </year>
Reference: [22] <author> Peter Shirley. </author> <title> A ray tracing algorithm for global illumination. </title> <booktitle> In Graphics Interface '90, </booktitle> <pages> pages 205-212, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> A Monte Carlo shooting approach also allows for more general specular transport [16], and possesses inherent parallelism, as each shot can be processed independently. Although Monte Carlo radiosity schemes have been applied with great success using a priori computational meshes <ref> [1, 22, 18, 17] </ref>, there has been little success generating adaptive computational meshes. Appel [2] traced particles from the source to estimate direct lighting. Arvo [3] extended this idea to include illumination reflecting from mirrors before striking surfaces. Airey [1] extended Arvo's technique to account for diffuse interreflection.
Reference: [23] <author> Peter Shirley. </author> <title> Time complexity of monte carlo radiosity. </title> <booktitle> In Eu-rographics '91, </booktitle> <pages> pages 459-466, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Our strategy is similar to Heckbert's, but differs in that the meshing is delayed until all Monte Carlo particle tracing 2 No global illumination algorithm has been proven to be sub-quadratic, but there is empirical evidence that both Monte Carlo shooting algorithms <ref> [23] </ref> and clustering algorithms [26] are sub quadratic for reasonably "well-behaved" environments. 2 has been completed. This allows us to use all the information collected for estimating surface irradiances to generate a good display mesh.
Reference: [24] <author> Fran~cois X. Sillion and Claude Puech. </author> <title> A general two-pass method integrating specular and diffuse reflection. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 335-344, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data [25]. Unlike previous "from the light" particle-tracing methods <ref> [3, 16, 24, 1, 22, 12, 4, 18, 6] </ref>, our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known.
Reference: [25] <author> B. W. Silverman. </author> <title> Density Estimation for Statistics and Data Analysis. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: Non-diffuse surfaces in this mesh will be portrayed accurately if displayed in a view-dependent second pass. An example solution from our three-phase method is shown in Figure 1. Our algorithm draws on the extensive experience of researchers who use density-estimation techniques to estimate the density function from observed data <ref> [25] </ref>. Unlike previous "from the light" particle-tracing methods [3, 16, 24, 1, 22, 12, 4, 18, 6], our method's direct use of density-estimation allows decisions about the display mesh to be delayed until all of the information about particle hits is known. <p> An example kernel estimate is shown in Figure 3. Using kernel functions on the hit points is analogous to the idea of "splatting" in volume rendering [30], and is similar to the illumination ray tracing of Collins [6]. Silverman <ref> [25] </ref> notes that whatever properties the derivatives of k 1 have will be shared by f , so we can ensure a smooth estimate for f by choosing a smooth k 1 . Good choices for k 1 are similar to the choices used for splatting or pixel filtering. <p> A more complex form would be needed to conserve energy on more complex surfaces. One potential problem with this method is the drop off of the function near the surface boundary. This drop-off can be eliminated by using the reflection method <ref> [25] </ref>, where extra sample points are generated outside the surface by reflecting each point across the boundary. This effectively adds extra points outside the boundary to compensate for the lack of samples there. <p> We use triangles as mesh elements instead of rectangles because it simplifies the mesh-decimation algorithm. We plan on extending our implementation to allow triangles in the input geometry as well. We have chosen to use Silverman's k 2 kernel function <ref> [25] </ref>: k 2 (u; v) = 2 2 The function k 2 is a canonical kernel function that is nonzero only on [0; 1] 2 , has continuous first derivatives. and is relatively inexpensive to compute, requiring only a few additions amd multiplications. <p> To avoid edge darkening problems caused by a lack of hitpoints beyond a polygon edge, we use the reflection method <ref> [25] </ref> where each vertex is "reflected" across each polygon boundary. This is similar to the technique in Fourier analysis of tiling reflected copies of a finite function over all of space. <p> spent in each of the three programs was: * Particle-tracing: 49% * Density-estimation and initial-meshing: 29% * Mesh-decimation: 22% flector (e = 100, ray-traced). display mesh (hardware z-buffered). 8 mesh (hardware z-buffered). 5 Future Work As noted earlier, we have barely scratched the surface in terms of applying density-estimation techniques <ref> [25] </ref> to the problem of global illumination. As with any application of existing technology in a new field, there is great potential for further enhancement. Our current mesh-generation strategy could be improved by using intrinsic properties of the density estimate such as curvature or even estimated shadow boundaries.
Reference: [26] <author> Brian E. Smits, James R. Arvo, and Donald P. Greenberg. </author> <title> A clustering algorithm for radiosity in complex environments. </title> <journal> Computer Graphics, </journal> <volume> 28(3) </volume> <pages> 435-442, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: Most traditional radiosity algorithms also use a computational mesh to represent intermediate results in the light transport calculation (e.g., the piecewise-constant global solution of Smits et fl 580 Engineering Theory Center Building, Ithaca, NY 14853, email: shirley@graphics.cornell.edu al. <ref> [26] </ref>). Typically, a single representation is used for both the computational and display meshes (e.g. the static mesh used by Neumann et al. [17] and the adaptive mesh used by Teller et al. [28]). <p> Keeping the memory overhead low favors a Monte Carlo particle-shooting approach [18], which only requires a ray-tracing acceleration structure. Handling local complexity in sub-quadratic time suggests either a clustering approach <ref> [26] </ref> or a Monte Carlo shooting approach 2 . A Monte Carlo shooting approach also allows for more general specular transport [16], and possesses inherent parallelism, as each shot can be processed independently. <p> Our strategy is similar to Heckbert's, but differs in that the meshing is delayed until all Monte Carlo particle tracing 2 No global illumination algorithm has been proven to be sub-quadratic, but there is empirical evidence that both Monte Carlo shooting algorithms [23] and clustering algorithms <ref> [26] </ref> are sub quadratic for reasonably "well-behaved" environments. 2 has been completed. This allows us to use all the information collected for estimating surface irradiances to generate a good display mesh.
Reference: [27] <author> David C. Tannenbaum, Peter Tannenbaum, and Michael J. Wozney. </author> <title> Polarization and birefringency considerations in rendering. </title> <journal> Computer Graphics, </journal> <pages> pages 221-222, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: This would be more expensive than our implementation, but would improve shadow detail. Because our energy transport is based on particle transport, previous work could be directly used to model dispersion and polarization <ref> [27] </ref>, and time-dependent effects such as fluorescence and phosphorescence [10]. Our current implementation needs to sort all particle hit points for a single channel by surface id. Sorting billions of hit points in real memory would not be feasible.
Reference: [28] <author> Seth Teller, Celeste Fowler, Thomas Funkhouser, and Pat Han-rahan. </author> <title> Partitioning and ordering large radiosity calculations. </title> <journal> Computer Graphics, </journal> <volume> 28(3) </volume> <pages> 443-450, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: Typically, a single representation is used for both the computational and display meshes (e.g. the static mesh used by Neumann et al. [17] and the adaptive mesh used by Teller et al. <ref> [28] </ref>). Very few display mesh solutions have been produced for environments with more than a few thousand initial surfaces. The only implementation we are aware of that has produced a display mesh for more than 10,000 initial surfaces is the system by Teller et al. [28], which was run on a <p> used by Teller et al. <ref> [28] </ref>). Very few display mesh solutions have been produced for environments with more than a few thousand initial surfaces. The only implementation we are aware of that has produced a display mesh for more than 10,000 initial surfaces is the system by Teller et al. [28], which was run on a model with approximately 40,000 initial surfaces. Teller et al. argue that the reason for these surprisingly small limits is the high memory overhead of the data structures associated with the computational mesh [28]. <p> more than 10,000 initial surfaces is the system by Teller et al. <ref> [28] </ref>, which was run on a model with approximately 40,000 initial surfaces. Teller et al. argue that the reason for these surprisingly small limits is the high memory overhead of the data structures associated with the computational mesh [28]. To solve this problem, we draw on an observation by Lischinski et al. [15], that the computational mesh and the display mesh have different purposes and characteristics and therefore should be decoupled. <p> The real-memory overhead is kept low by storing the large number of hit points sequentially on disk. By "local complexity" we mean that there are many nearby, mutually-visible surfaces, which is consistent with the definition given by Teller et al. <ref> [28] </ref>. This type of complexity defeats methods based on visibility preprocessing. In Section 2 we review the shortcomings of current physically-based global illumination technology and provide motivation for the approach presented in this paper. <p> A probability density function is a density function associated with the likelihood of a random variable taking certain values. * High intermediate complexity (memory overhead). Current radiosity methods use large data structures to accelerate visibility computations, which is usually the limiting factor in performing large radiosity simulations <ref> [28] </ref>. In practice, an algorithm that stores more than a few hundred bytes per polygon in physical memory will not be practical. * Difficulty with local complexity. <p> In cases where the model has a very high "global complexity" (large numbers of surfaces), but a limited "local complexity" (only small subsets of surfaces are mutually visible), partitioning can be used to decompose the model into subsets which can be solved separately <ref> [28] </ref>. But if any subset has a high local complexity, then partitioning may not reduce the subproblems to a solvable size. This is a problem in an environment such as a hotel atrium. * Quadratic time complexity.
Reference: [29] <author> Gregory J. Ward. </author> <title> The radiance lighting simulation and rendering system. </title> <journal> Computer Graphics, </journal> <volume> 28(2) </volume> <pages> 459-472, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: This is convenient because the reflectance may change quickly, while the irradiance may change slowly, allowing the irradiance to be stored in a coarse mesh. These ideas are based upon the "patch-element" radiosity work of Cohen et al.[5], Ward's Radiance system <ref> [29] </ref>, and the texturing work of Gershbein et al. [9]. For a given surface, a list of hit points (u j ; v j ) is stored, each with an associated power of . <p> The contributions of the reflected hit points would be applied only to grid points on the appropriate side of the discontinuity. If better shadow detail is needed, the irradiance mesh could store only indirect light (like the Radiance program <ref> [29] </ref>) and use an image-space direct lighting calculation to compute the remaining irradiance. This would be more expensive than our implementation, but would improve shadow detail.
Reference: [30] <author> Lee Westover. </author> <title> Footprint evaluation for volume randering. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 367-376, </pages> <month> August </month> <year> 1990. </year> <booktitle> ACM Siggraph '90 Conference Proceedings. </booktitle>
Reference-contexts: An example kernel estimate is shown in Figure 3. Using kernel functions on the hit points is analogous to the idea of "splatting" in volume rendering <ref> [30] </ref>, and is similar to the illumination ray tracing of Collins [6]. Silverman [25] notes that whatever properties the derivatives of k 1 have will be shared by f , so we can ensure a smooth estimate for f by choosing a smooth k 1 .
Reference: [31] <author> Andrew Woo. </author> <title> Ray tracing polygons using spatial subdivision. </title> <booktitle> In Proceedings of Graphics Interface '92, </booktitle> <pages> pages 184-191, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: This means we can store approximately 125 million hit points on a one gigabyte disk. This code is run once for each of the red, green, and blue channels. The only memory overhead in the particle-tracing phase is the uniform-subdivision ray-tracing efficiency structure <ref> [31] </ref> (approximately 140 bytes per patch in our implementation, or about 7 million patches per gigabyte).

References-found: 31

