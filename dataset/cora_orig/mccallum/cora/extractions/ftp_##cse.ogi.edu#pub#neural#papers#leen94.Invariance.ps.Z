URL: ftp://cse.ogi.edu/pub/neural/papers/leen94.Invariance.ps.Z
Refering-URL: http://www.cse.ogi.edu/~tleen/
Root-URL: http://www.cse.ogi.edu
Email: tleen@cse.ogi.edu  
Title: From Data Distributions to Regularization in Invariant Learning  
Author: Todd K. Leen 
Address: 20000 N.W. Walker Rd Beaverton, Oregon 97006  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science and Technology  
Note: Appears in Advances in Neural Information Processing Systems, 7, Tesauro, Touretzky, and Leen (eds.), The MIT Press, 1995.  
Abstract: Ideally pattern recognition machines provide constant output when the inputs are transformed under a group G of desired invariances. These invariances can be achieved by enhancing the training data to include examples of inputs transformed by elements of G, while leaving the corresponding targets unchanged. Alternatively the cost function for training can include a regularization term that penalizes changes in the output when the input is transformed under the group. This paper relates the two approaches, showing precisely the sense in which the regularized cost function approximates the result of adding transformed (or distorted) examples to the training data. The cost function for the enhanced training set is equivalent to the sum of the original cost function plus a regularizer. For unbiased models, the regularizer reduces to the intuitively obvious choice - a term that penalizes changes in the output when the inputs are transformed under the group. For infinitesimal transformations, the coefficient of the regularization term reduces to the variance of the distortions introduced into the training data. This correspondence provides a simple bridge between the two approaches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Le Cun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, and L.D. Jackel. </author> <title> Handwritten digit recognition with a back-propagation network. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 2, </volume> <pages> pages 396-404. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: In neural nets, there are several ways to achieve this invariance 1. In neural networks, the invariance can be hard-wired by weight sharing in the case of summation nodes <ref> [1] </ref> or by constraints similar to weight sharing in higher-order nodes [2]. 2. One can enhance the training ensemble by adding examples of inputs transformed under the desired invariance group, while maintaining the same targets as for the raw data. 3.
Reference: [2] <author> C.L. Giles, R.D. Griffin, and T. Maxwell. </author> <title> Encoding geometric invariances in higher-order neural networks. </title> <editor> In D.Z.Anderson, editor, </editor> <booktitle> Neural Information Processing Systems, </booktitle> <pages> pages 301-309. </pages> <institution> American Institute of Physics, </institution> <year> 1988. </year>
Reference-contexts: In neural nets, there are several ways to achieve this invariance 1. In neural networks, the invariance can be hard-wired by weight sharing in the case of summation nodes [1] or by constraints similar to weight sharing in higher-order nodes <ref> [2] </ref>. 2. One can enhance the training ensemble by adding examples of inputs transformed under the desired invariance group, while maintaining the same targets as for the raw data. 3.
Reference: [3] <author> Patrice Simard, Bernard Victorri, Yann Le Cun, and John Denker. </author> <title> Tanget prop a formalism for specifying selected invariances in an adaptive network. </title> <editor> In John E. Moody, Steven J. Hanson, and Richard P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 895-903. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: One can add to the cost function a regularizer that penalizes changes in the output when the input is transformed by elements of the group <ref> [3, 4] </ref>. Intuitively one expects the approaches in 3 and 4 to be intimately linked. This paper develops that correspondence in detail. 2 The Distortion-Enhanced Input Ensemble Let the input data x be distributed according to the density function p (x). <p> The magnitude of the regularization term is just the variance of the distribution of distortion parameters. This is precisely the form of the regularizer given by Simard et al. in their tangent prop algorithm <ref> [3] </ref>. This derivation shows the equivalence (to O ( 2 )) between the tangent prop regularizer and the alternative of modifying the input distribution. <p> For infinitesimal transformations, the regularizer is equivalent (up to terms linear in the variance of the transformation parameters) to the tangent prop form given by Simard et al. <ref> [3] </ref>, with regularization coefficient equal to the variance of the transformation parameters. In the special case that the group transformations are limited to random translations of the input, the regularizer reduces to a standard smoothing regularizer.
Reference: [4] <author> Yasar S. Abu-Mostafa. </author> <title> A method for learning from hints. </title> <editor> In S. Hanson, J. Cowan, and C. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 5, </volume> <pages> pages 73-80. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: One can add to the cost function a regularizer that penalizes changes in the output when the input is transformed by elements of the group <ref> [3, 4] </ref>. Intuitively one expects the approaches in 3 and 4 to be intimately linked. This paper develops that correspondence in detail. 2 The Distortion-Enhanced Input Ensemble Let the input data x be distributed according to the density function p (x). <p> This is exactly the form one would intuitively apply in order to insure that the network output not change under the transformation x ! g (x; ff). Indeed this is the similar to the form of the invariance "hint" proposed by Abu-Mostafa <ref> [4] </ref>. The difference here is that there is no arbitrary parameter multiplying the term. Instead the strength of the regularizer is governed by the average over the density p (ff). The term E H measures the error in satisfying the invariance hint.
Reference: [5] <author> D.H. Sattinger and O.L. Weaver. </author> <title> Lie Groups and Algebras with Applications to Physics, Geometry and Mechanics. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: These 1 We assume that the set forms a group. 2 See for example <ref> [5] </ref>. transformations form a six-parameter Lie group 3 . By adding distorted input examples we alter the original density p (x). To describe the new density, we introduce a probability density for the transformation parameters p (ff).
Reference: [6] <author> Chris M. Bishop. </author> <title> Training with noise is equivalent to Tikhonov regularization. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 108-116, </pages> <year> 1995. </year>
Reference-contexts: We derived this equivalence to illuminate mechanisms for obtaining invariant pattern recognition. The technique for dealing with infinitesimal transformations in section x3.1 was used by Bishop <ref> [6] </ref> to show the equivalence between added input noise and smoothing reg-ularizers. Bishop's results, though they preceded our own, are a special case of the results presented here.
References-found: 6

