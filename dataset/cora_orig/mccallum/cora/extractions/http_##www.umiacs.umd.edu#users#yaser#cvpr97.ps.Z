URL: http://www.umiacs.umd.edu/users/yaser/cvpr97.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/yaser/publications.html
Root-URL: 
Email: black@parc.xerox.com, yaser@cs.umd.edu, jepson@vis.toronto.edu, fleet@qucis.queensu.ca  
Title: Learning Parameterized Models of Image Motion  
Author: Michael J. Black Yaser Yacoob Allan D. Jepson David J. Fleet 
Address: 3333 Coyote Hill Road, Palo Alto, CA 94304  College Park, MD 20742  Toronto, Toronto, Ontario M5S 1A4  Ontario K7L 3N6  
Affiliation: Xerox Palo Alto Research Center,  Computer Vision Laboratory, University of Maryland,  Department of Computer Science, University of  Department of Computing and Information Science, Queen's University, Kingston,  
Abstract: A framework for learning parameterized models of optical flow from image sequences is presented. A class of motions is represented by a set of orthogonal basis flow fields that are computed from a training set using principal component analysis. Many complex image motions can be represented by a linear combination of a small number of these basis flows. The learned motion models may be used for optical flow estimation and for model-based recognition. For optical flow estimation we describe a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives. As examples we consider learning motion discontinuities, non-rigid motion of human mouths, and articulated human motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Barron, D. Fleet, and S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <journal> IJCV, </journal> <volume> 12(1), </volume> <year> 1994. </year>
Reference: [2] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> ECCV'94, </booktitle> <pages> pp. 299-308. </pages>
Reference-contexts: These methods have not been applied to the mod eling of image motion in natural scenes. Related work has focused on learning the deformation of curves or parameterized curve models <ref> [2, 16] </ref>. Sclaroff and Pentland [16] estimated modes of deformation for sillo-hettes of non-rigid objects. They interpolated a sparse set of correspondences between sillohette boundaries in consecutive frames to produce a basis set of flows, much like those learned in this paper. <p> SVD was performed on the 350-image training set. The first nine basis vectors account for 90% of variance in the training data and are used in our experiments (see Fig. 11.) Note that the first component essentially encodes the scissors-like expansion/contraction of the legs (cf. <ref> [2] </ref>). 1 2 3 4 nine-parameter learned model for a 200-image training sequence (Walk-2) and a 200-image test sequence (Walk-4). Each sequence contains approximately seven complete cycles of the motion. Note the similarity of the two plots for the first coefficient (a 1 ).
Reference: [3] <author> D. Beymer. </author> <title> Feature correspondence by interleaving shape and texture computations. </title> <booktitle> CVPR'96, </booktitle> <pages> pp. 921-928. </pages>
Reference-contexts: then one can also use the estimated coefficients of the model for subsequent recognition/interpretation of the image motion. 2 Related Work Much of the recent work on learning parameterized models of image deformation has occurred in the face recognition literature to model the deformations between the faces of different people <ref> [3, 9, 11, 13, 18] </ref>. Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object [13].
Reference: [4] <author> M. J. Black and P. Anandan. </author> <title> Constraints for the early detection of discontinuity from motion. </title> <booktitle> AAAI'90, </booktitle> <pages> pp. 1060-1066. </pages>
Reference-contexts: This application is similar to modeling step edges in static scenes by learning a parameterized model from examples of edges [14]. It differs from previous attempts to detect motion discontinuities that applied edge detectors to optical flow, checked for bimodality in local flow estimates, or used energy-based methods <ref> [4, 15, 17] </ref>. 3 Learning Parameterized Flow Models Learning a parameterized model for a particular class of motions requires that we have a training set of flow fields containing representative samples of the class. For relatively simple classes such as motion discontinuities we can generate this training set synthetically.
Reference: [5] <author> M. J. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields. </title> <journal> CVIU, </journal> <volume> 63(1) </volume> <pages> 75-104, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: For more complex motions of natural objects we will need to estimate the image motion for training sequences. Since training is done off-line, we can afford to use a computationally expensive robust optical flow algorithm <ref> [5] </ref>. In either case, the training set from which we learn a model of image motion is a set of p optical flow fields. For images with s = n fi m pixels, each flow field contains 2s quantities (i.e., horizontal and vertical elements of the flow at each pixel). <p> The influence of these outliers can be reduced through the use of an appropriate robust error norm . For the experiments below we take to be (r; ) = r 2 =( 2 + r 2 ) ; which was used successfully for flow estimation in <ref> [5] </ref>. <p> The particular optimization scheme is a straightforward extension of that used by Black and Anandan <ref> [5] </ref> for estimating optical flow with affine and planar motion models. This involves a coarse-to-fine iteration strategy, where the motion parameters ~a j determined at a coarser scale are used in the estimation of ~ E ( ~ b; ~a j+1 ) at the next finer scale. <p> Unlike the previous example, we did not have ground-truth optical flow from which to learn a model of mouth motion. Instead, we used the optical flow method in <ref> [5] </ref> to estimate dense flow fields between consecutive pairs of frames.
Reference: [6] <author> M. J. Black and A. D. Jepson. EigenTracking: </author> <title> Robust matching and tracking of articulated objects using a view-based representation, </title> <note> to appear, IJCV. </note>
Reference-contexts: The approach can also be used to learn object-specific models (e.g. mouth motion) that are applied in specific image regions, and which may be useful for motion-based recognition. Alignment of these models with the image is important and it may be possible to refine this alignment automatically (see <ref> [6] </ref>). A number of other research issues remain unanswered. Learned models are particularly useful in situations where optical flow is hard to estimate, but in these situations it is difficult to compute reliable training data. This problem is compounded by the sensitivity of PCA to outliers.
Reference: [7] <author> M. J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motions. </title> <booktitle> ICCV'95, </booktitle> <pages> pp. 374-381. </pages>
Reference-contexts: Likewise, the small number of parameters provides a concise description of the image motion that can be used for explanation or recognition. For example, parameterized flow models have been used to recognize facial expressions from motion <ref> [7] </ref>. There are two main problems with parameterized motion models. First, many image regions contain multiple image motions because of moving occlusion boundaries, transparency, reflections, or independently moving objects. A great deal of work has been devoted to extending parameterized models to cope with these situations. <p> Unlike our approach, they did not learn the basis flows from optical flow data, and did not use them to estimate image motion. In addition to optical flow estimation, we are interested in the use of parameterized models for motion-based recognition. Black and Yacoob <ref> [7] </ref> modeled the motion of a human face and facial features using parameterized flow models (planar, affine, and affine+curvature). They showed how simple models could represent a rich variety of image motions, and how the motion parameters could be used to recognize facial expressions. However, their motion models were hand-coded. <p> Second, learned motion models are applied to a specific object in a known location. We consider examples of human mouths and legs where it is assumed that regions of interest have been found by tracking of the face or torso (see <ref> [7, 12] </ref>). 5.1 Motion Discontinuities The learned motion-discontinuity model is applied to a textured moving disk in Fig. 4. Nine basis vectors were used and the motion coefficients were estimated in 32 fi 32-pixel regions centered on each pixel in the image. <p> A high correlation indicates the presence of a vertical occlusion boundary (shown as white in Fig. 5 (c)) and a negative correlation indicates a disocclusion boundary (black in Fig. 5 (c)). 5.2 Non-Rigid Motion Black and Yacoob <ref> [7] </ref> described a method for recognizing human facial expressions from the coefficients of a parameterized model. They modeled the face as a plane and used its motion to stabilize the image sequence. <p> In this case, 90% of the variance in the training flow fields is accounted for by the first seven components (shown in Fig. 7). In contrast the seven-parameter model in <ref> [7] </ref> only accounted for 62% of the variance. We evaluate the learned model with a 150-image test sequence in which the subject smiles and speaks the word from the training set. A sample of the images from the smile portion of the sequence are shown in Fig. 8. <p> Below each image is the estimated flow using the learned 7-parameter model. The value of the first four coefficients of the model at each frame are plotted above the images. Notice the similarity between the training smile and the test smile. Similar plots were used for recognition in <ref> [7] </ref>. test utterance. Speech, unlike expression, is characterized by large, rapidly changing motions. Without a highly constrained model such as the one learned here, it can be difficult to estimate motions of this kind.
Reference: [8] <author> M. J. Black, Y. Yacoob, and D. J. </author> <title> Fleet. Modelling appearance change in image sequences. 3rd Int. Work. on Visual Form, </title> <address> Capri, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: It should be noted that the estimation of mouth motion is difficult since the lips are not highly textured, they deform and move large distances between frames, and the appearance/disappearance of teeth, tongue, and mouth cavity violates the brightness constancy assumption (see <ref> [8] </ref>). We also note that estimation of the dense training flow takes twice as long to compute as the direct estimation using the learned models.
Reference: [9] <author> T. Ezzat and T. Poggio. </author> <title> Facial analysis and synthesis using image-based models. </title> <booktitle> Int. Conf. on Auto. Face and Gesture Recog., </booktitle> <pages> pp. 116-121, </pages> <year> 1996. </year>
Reference-contexts: then one can also use the estimated coefficients of the model for subsequent recognition/interpretation of the image motion. 2 Related Work Much of the recent work on learning parameterized models of image deformation has occurred in the face recognition literature to model the deformations between the faces of different people <ref> [3, 9, 11, 13, 18] </ref>. Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object [13].
Reference: [10] <author> G. D. Hager and P. N. Belhumeur. </author> <title> Real-time tracking of image regions with changes in geometry and illumination. </title> <booktitle> CVPR'96, </booktitle> <pages> pp. 403-410. </pages>
Reference-contexts: In fact, the image gradient in (6) can be pre-multiplied by the basis flows since these quantities will not change during the minimization of ~ E ( ~ b; ~a j ). Hager and Belhuemer <ref> [10] </ref> used this fact for real-time affine tracking. 5 Experimental Results We now present experiments to illustrate the use of learned models in two different applications. First, the models are used to estimate dense optical flow. Second, learned motion models are applied to a specific object in a known location.
Reference: [11] <author> P. Hallinan. </author> <title> A deformable model for the recognition of human faces under arbitrary illumination. </title> <type> PhD thesis, </type> <institution> Harvard Univ., </institution> <address> Cambridge, MA, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: then one can also use the estimated coefficients of the model for subsequent recognition/interpretation of the image motion. 2 Related Work Much of the recent work on learning parameterized models of image deformation has occurred in the face recognition literature to model the deformations between the faces of different people <ref> [3, 9, 11, 13, 18] </ref>. Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object [13]. <p> In some cases this involved learning the parameters of a physically-based deformable object [13]. In other cases a basis set of deformation vectors was obtained (e.g., see the work of Hallinan <ref> [11] </ref> on learning Eigen-Warps). These methods have not been applied to the mod eling of image motion in natural scenes. Related work has focused on learning the deformation of curves or parameterized curve models [2, 16]. Sclaroff and Pentland [16] estimated modes of deformation for sillo-hettes of non-rigid objects.
Reference: [12] <author> S. Ju, M. Black, and Y. Yacoob. </author> <title> Cardboard people: A parameterized model of articulated motion. </title> <booktitle> Int. Conf. Auto. Face and Gesture Recog., </booktitle> <pages> pp. 38-44, </pages> <year> 1996. </year>
Reference-contexts: Second, learned motion models are applied to a specific object in a known location. We consider examples of human mouths and legs where it is assumed that regions of interest have been found by tracking of the face or torso (see <ref> [7, 12] </ref>). 5.1 Motion Discontinuities The learned motion-discontinuity model is applied to a textured moving disk in Fig. 4. Nine basis vectors were used and the motion coefficients were estimated in 32 fi 32-pixel regions centered on each pixel in the image.
Reference: [13] <author> C. Nastar, B. Moghaddam, and A. Pentland. </author> <title> Generalized image matching: </title> <journal> Statistical learning of physically-based deformations. </journal> <volume> ECCV'96, </volume> <pages> pp. 589-598. </pages>
Reference-contexts: then one can also use the estimated coefficients of the model for subsequent recognition/interpretation of the image motion. 2 Related Work Much of the recent work on learning parameterized models of image deformation has occurred in the face recognition literature to model the deformations between the faces of different people <ref> [3, 9, 11, 13, 18] </ref>. Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object [13]. <p> Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object <ref> [13] </ref>. In other cases a basis set of deformation vectors was obtained (e.g., see the work of Hallinan [11] on learning Eigen-Warps). These methods have not been applied to the mod eling of image motion in natural scenes.
Reference: [14] <author> S. Nayar, S. Baker, and H. Murase. </author> <title> Parametric feature detection. </title> <booktitle> CVPR'96, </booktitle> <pages> pp. 471-477. </pages>
Reference-contexts: Another application examined below is the learning of motion models for the detection of motion discontinuities. This application is similar to modeling step edges in static scenes by learning a parameterized model from examples of edges <ref> [14] </ref>. <p> Note that the basis set can also approximate translational motion since the random training data contains flow fields in which ~u 0 is close to ~u 1 . Note the similarity between the basis vectors for a motion discontinuity and those learned for an intensity edge in <ref> [14] </ref>. 4 Direct Estimation of Motion Parameters Given a learned set of basis flows, we now consider the problem of estimating the optical flow in an arbitrary image region, R, using the parameterized model.
Reference: [15] <author> S. A. Niyogi. </author> <title> Detecting kinetic occlusion. </title> <booktitle> ICCV'95, </booktitle> <pages> pp. 1044-1049. </pages>
Reference-contexts: This application is similar to modeling step edges in static scenes by learning a parameterized model from examples of edges [14]. It differs from previous attempts to detect motion discontinuities that applied edge detectors to optical flow, checked for bimodality in local flow estimates, or used energy-based methods <ref> [4, 15, 17] </ref>. 3 Learning Parameterized Flow Models Learning a parameterized model for a particular class of motions requires that we have a training set of flow fields containing representative samples of the class. For relatively simple classes such as motion discontinuities we can generate this training set synthetically.
Reference: [16] <author> S. Sclaroff and A. Pentland. </author> <title> Physically-based combinations of views: Representing rigid and nonrigid motion. Work. </title> <booktitle> Motion of Non-rigid & Articulated Objects, </booktitle> <pages> pp. 158-164, </pages> <year> 1994. </year>
Reference-contexts: These methods have not been applied to the mod eling of image motion in natural scenes. Related work has focused on learning the deformation of curves or parameterized curve models <ref> [2, 16] </ref>. Sclaroff and Pentland [16] estimated modes of deformation for sillo-hettes of non-rigid objects. They interpolated a sparse set of correspondences between sillohette boundaries in consecutive frames to produce a basis set of flows, much like those learned in this paper. <p> These methods have not been applied to the mod eling of image motion in natural scenes. Related work has focused on learning the deformation of curves or parameterized curve models [2, 16]. Sclaroff and Pentland <ref> [16] </ref> estimated modes of deformation for sillo-hettes of non-rigid objects. They interpolated a sparse set of correspondences between sillohette boundaries in consecutive frames to produce a basis set of flows, much like those learned in this paper. <p> The quality of the approximation provided by the first k columns of M is easily characterized in terms of the fraction of the variance of the training set that is accounted for by the and detected with a linear combination of a small number of the basis motions (cf. <ref> [16] </ref>). selected components.
Reference: [17] <author> A. Spoerri and S. Ullman. </author> <title> The early detection of motion boundaries. </title> <booktitle> ICCV'87, </booktitle> <pages> pp. 209-218. </pages>
Reference-contexts: This application is similar to modeling step edges in static scenes by learning a parameterized model from examples of edges [14]. It differs from previous attempts to detect motion discontinuities that applied edge detectors to optical flow, checked for bimodality in local flow estimates, or used energy-based methods <ref> [4, 15, 17] </ref>. 3 Learning Parameterized Flow Models Learning a parameterized model for a particular class of motions requires that we have a training set of flow fields containing representative samples of the class. For relatively simple classes such as motion discontinuities we can generate this training set synthetically.
Reference: [18] <author> T. Vetter. </author> <title> Learning novel views to a single face image. </title> <booktitle> Int. Conf. Auto. Face & Gesture Recog., </booktitle> <pages> pp. 22-27, </pages> <year> 1996. </year>
Reference-contexts: then one can also use the estimated coefficients of the model for subsequent recognition/interpretation of the image motion. 2 Related Work Much of the recent work on learning parameterized models of image deformation has occurred in the face recognition literature to model the deformations between the faces of different people <ref> [3, 9, 11, 13, 18] </ref>. Correspondences between different faces were obtained either by hand or by an optical flow method, and were then used to learn a lower-dimensional model. In some cases this involved learning the parameters of a physically-based deformable object [13].
References-found: 18

