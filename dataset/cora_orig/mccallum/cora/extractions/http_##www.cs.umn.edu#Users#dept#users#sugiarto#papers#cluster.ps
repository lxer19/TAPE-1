URL: http://www.cs.umn.edu/Users/dept/users/sugiarto/papers/cluster.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/sugiarto/papers/
Root-URL: http://www.cs.umn.edu
Title: Cluster Placement: A Data Placement Scheme for A Mass Storage System of A Video-On-Demand Server  
Author: Horng-Juing Lee and David Du 
Keyword: Multimedia, Video on demand, Mass storage system, Disk array, Data Placement.  
Date: January 5, 1995  
Address: Minneapolis, MN 55455  
Affiliation: Distributed Multimedia Center 1 University of Minnesota  
Abstract: This paper proposes a data placement scheme called Cluster Placement for a mass storage system of a Video-On-Demand (VOD) server. The cluster placement divides disk cylinders into equal-size clusters and stores video data across clusters. An admission scheduling process synchronizes retrieval requests such that video data accesses are within a cluster range. Disk seek overheads can be reduced from the whole disk area to a cluster area and, consequently, reduces the buffer space. Contiguous placement becomes a special case of the cluster placement when the number of clusters equals to one. We also identify several design issues associated with the cluster placement scheme; one issue is the underlying disk heads scheduling policy while storing video data across over clusters. We illustrate the effectiveness of the cluster placement by applying NTSC quality video into an array of eight disks under FIFO, C-SCAN, and GSS disk scheduling schemes. The analysis results showed that the buffer space can be reduced under all three different disk heads scheduling schemes when compared to the contiguous placement. The buffer reduction can range from 3% to 40% depending on the cluster size and disk scheduling. The trade-off of the cluster placement is longer time for the worst case initial response time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dan A., Sitaram D., Shahabuddin P., </author> <title> "Scheduling Policies for an On-Demand Video Server with 20 Batching", </title> <booktitle> Proc. of ACM Multimedia, </booktitle> <year> 1994, </year> <pages> pp 15-23. </pages>
Reference: [2] <author> Ghandeharizadeh D., Ramos L., </author> <title> "Continuous Retrieval of Multimedia Data Using Parallelism", </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> vol. 5, no. 4, </volume> <month> August </month> <year> 1993, </year> <pages> pp 658-669. </pages>
Reference-contexts: The figures show that more clusters means longer worst case initial response time. 6 Related Work Ghandeharizadeh and Ramous used the replication approach to provide parallelism for continuous retrieval of video streams <ref> [2] </ref>. Lougher and Shepherd designed and implemented a file server specially for continuous media [5]. The system considered temporal relations between media streams and clustered media streams which are recorded at the same time. For each stream, it is stored contiguously.
Reference: [3] <author> Hsieh J., Lin M., Liu J.C.L., Du D.H.C., </author> <title> Ruwart T.M., "Performance of A Mass Storage System for Video-On-Demand", </title> <institution> Technical Report of Computer Science Dept., University of Minnesota, </institution> <year> 1994. </year> <note> To appear in IEEE INFOCOM'95, </note> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Introduction A VOD server consists of three components: an interface to a mass storage system, a video processing unit, and a network interface <ref> [3] </ref>. The interface to a storage system supports concurrent I/O accesses and provides guaranteed bandwidth. The video processing unit requires fast processing speed, large memory space, and an enormous system bus bandwidth to handle in/out traffic between the storage system and the network. <p> The access time of a read request then becomes the longest access time among all A fi D sub-requests. One example of the hierarchical RAIDs system used in a VOD server has been reported in <ref> [3] </ref> where a utility called logical volume in SGI ONYX manages 32 level-3 RAIDs. Each level-3 RAID is controlled by a Ciprico controller. <p> As pointed out by [9], a larger block size can reduce the impact of disk overheads. However, in the mean time, a larger block consumes more main memory. The size may also bounded by the constraints of a underlying operating system <ref> [3] </ref>. The study of the block size trade-off is one of the major concerns in this paper and will be discussed in Section 4. * Issue 3: Data placement schemes across clusters? The only requirement for data placement is to ensure a cluster contains video blocks from all video files.
Reference: [4] <author> Liu J., Du D.H.C., Schnepf J., </author> <title> "Supporting Random Access on the Retrieval of Digital Continuous media", </title> <note> To appear in Journal of Computer Communication: Special Issue on Multimedia etorage and Databases, </note> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: A fi D N cluster Number of clusters S cluster Number of cylinders in a cluster = b N cylinder N cluster c Table 1: Parameters and their Definitions 4.1 FIFO We assume two-buffer scheme is used; one buffer holds data frames for display and the other one for prefetch <ref> [4] </ref>. 4.1.1 Analysis For serving the first request of a set of N user requests, disk heads must first move from previous cluster to the cluster which the first request asked.
Reference: [5] <author> Lougher P.K., Shepherd D., </author> <title> "The Design of a Storage Server for Contiguous Media", </title> <journal> Computer Journal, </journal> <volume> vol. 36 no. 1, </volume> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: A mass storage system of a Video-On-Demand (VOD) server needs to support the retrieval of video data to satisfy the continuous playback requirement (i.e., jitter-free playback). Many issues have been investigated in areas of disk heads scheduling schemes and multiple disks architecture to support jitter-free playback <ref> [7, 5, 11, 13] </ref>. Most of this work assumed either a contiguous placement scheme or no data placement scheme (i.e., randomly placed) at all. In this paper, we study the impact of the placement scheme in terms of the buffer size and number of users which can be supported. <p> The figures show that more clusters means longer worst case initial response time. 6 Related Work Ghandeharizadeh and Ramous used the replication approach to provide parallelism for continuous retrieval of video streams [2]. Lougher and Shepherd designed and implemented a file server specially for continuous media <ref> [5] </ref>. The system considered temporal relations between media streams and clustered media streams which are recorded at the same time. For each stream, it is stored contiguously. Rangan and Vin proposed a storage pattern to guarantee continuous retrieval of media streams [7].
Reference: [6] <author> Paterson D.A., Gibson G., Katz R.H., </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)", </title> <booktitle> Proc. SIGMOD , 1988. </booktitle>
Reference-contexts: In this paper, we discuss the data placement issues on the disk devices. It is commonly agreed that a single disk cannot provide the required bandwidth and capacity needed by applications which manipulate continuous media. An alternative is to use the Redundant Arrays of Inexpensive Disks (RAID) architecture <ref> [6] </ref>. An array of fast, small form-factor, low-power drives can provide larger capacity and higher bandwidth. Five levels of RAID architectures have been proposed which differ on the parity-checking scheme and data stripping scheme [6]. <p> An alternative is to use the Redundant Arrays of Inexpensive Disks (RAID) architecture <ref> [6] </ref>. An array of fast, small form-factor, low-power drives can provide larger capacity and higher bandwidth. Five levels of RAID architectures have been proposed which differ on the parity-checking scheme and data stripping scheme [6]. One feature of the RAID system is that it can be considered as an array of synchronized disks where data is stripped over all data disks. Therefore, a read request to a RAID will be transformed by the RAID controller into concurrent read operations to the constituent physical disks.
Reference: [7] <author> Rangan P.V., Vin H.M., </author> <title> "Designing File Systems for Digital Video and Audio", </title> <journal> Operating Systems Review, </journal> <volume> vol. 25, no. 5, </volume> <year> 1991, </year> <pages> pp 69-79. </pages>
Reference-contexts: A mass storage system of a Video-On-Demand (VOD) server needs to support the retrieval of video data to satisfy the continuous playback requirement (i.e., jitter-free playback). Many issues have been investigated in areas of disk heads scheduling schemes and multiple disks architecture to support jitter-free playback <ref> [7, 5, 11, 13] </ref>. Most of this work assumed either a contiguous placement scheme or no data placement scheme (i.e., randomly placed) at all. In this paper, we study the impact of the placement scheme in terms of the buffer size and number of users which can be supported. <p> In other words, the prefetched data must be available before the current buffer is completely consumed. Therefore, a designer must, for example, consider the worst case seek time overheads incurred between retrievals in Fist-In-First-Out (FIFO) disk scheduling <ref> [7] </ref>. Disk retrieval time is increased, as a result, a larger buffer space is desired to compensate the long seek time. The cluster placement divides disk cylinders into equal-size clusters. A cluster is a disk area containing a set of consecutive disk cylinders. <p> The system considered temporal relations between media streams and clustered media streams which are recorded at the same time. For each stream, it is stored contiguously. Rangan and Vin proposed a storage pattern to guarantee continuous retrieval of media streams <ref> [7] </ref>. The model is related to disk and device characteristics to the playback requirements of media streams. Tobagi and etc. described a disk array management for video files [11]. They addressed the issues of disk scheduling, memory requirement, and start-up latency.
Reference: [8] <author> Rangan P.V., Vin H.M., </author> <title> "Efficient Storage Techniques for Digital Continuous Multimedia", </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> vol. 5, no. 4, </volume> <month> August </month> <year> 1993, </year> <pages> pp 564-573. </pages>
Reference: [9] <author> Reddy A.L.N., </author> <title> Wyllie J.C., "I/O Issues in a Multimedia System", </title> <journal> IEEE Computer, </journal> <volume> vol. 27 no. 3 1994, </volume> <pages> pp 69-74. </pages>
Reference-contexts: Its value is used to partition a video file. As pointed out by <ref> [9] </ref>, a larger block size can reduce the impact of disk overheads. However, in the mean time, a larger block consumes more main memory. The size may also bounded by the constraints of a underlying operating system [3].
Reference: [10] <author> Ruemmler C., Wilkes J., </author> <title> "An Introduction to Disk Drive Modeling", </title> <journal> IEEE Computer, </journal> <volume> vol. 27 no. 3 1994, </volume> <pages> pp 17-28. </pages>
Reference-contexts: The playback rate is 30 fps (frames per second), therefore, a display duration for a frame (i.e., T frame playback ) is 33.33 ms. Table 3 lists the characteristics of a HP 97560 disk <ref> [10] </ref>. Therefore, for transfer a frame of data (i.e., 100Kbits), it takes 100Kbits R transfer = 4.25 ms. there are nonlinear. Therefore, dividing a disk area into 2 clusters does not imply it can cut the disk seek time in half. In fact, only 33% reduction.
Reference: [11] <author> Tobagi F.A., Pang J., Baird R., Gang M., </author> <title> "Streaming RAID: A Disk Array Management System for Video Files", </title> <booktitle> Proc. of ACM Multimedia, </booktitle> <year> 1993, </year> <pages> pp 393-400. </pages>
Reference-contexts: A mass storage system of a Video-On-Demand (VOD) server needs to support the retrieval of video data to satisfy the continuous playback requirement (i.e., jitter-free playback). Many issues have been investigated in areas of disk heads scheduling schemes and multiple disks architecture to support jitter-free playback <ref> [7, 5, 11, 13] </ref>. Most of this work assumed either a contiguous placement scheme or no data placement scheme (i.e., randomly placed) at all. In this paper, we study the impact of the placement scheme in terms of the buffer size and number of users which can be supported. <p> For each stream, it is stored contiguously. Rangan and Vin proposed a storage pattern to guarantee continuous retrieval of media streams [7]. The model is related to disk and device characteristics to the playback requirements of media streams. Tobagi and etc. described a disk array management for video files <ref> [11] </ref>. They addressed the issues of disk scheduling, memory requirement, and start-up latency. However, they did not mention the kind of data placement scheme which was used in the paper. 19 7 Conclusion We proposed a data organization strategy called Cluster Placement for homogeneous video files in a playback-only environment.
Reference: [12] <author> Vin H., Rangan V., </author> <title> "Designing a Multiuser HDTV Storage Server", </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 1, </volume> <month> Jan. </month> <year> 1993, </year> <pages> pp 153-164. </pages>
Reference: [13] <author> Yu P.S., Chen M.S., </author> <title> Kandlur D.D., "Grouped Sweeping Scheduling for DASD-based Multimedia Storage Management", </title> <journal> Multimedia Systems, </journal> <volume> vol. 1, no. 3, </volume> <year> 1993, </year> <pages> pp 99-109. 21 </pages>
Reference-contexts: A mass storage system of a Video-On-Demand (VOD) server needs to support the retrieval of video data to satisfy the continuous playback requirement (i.e., jitter-free playback). Many issues have been investigated in areas of disk heads scheduling schemes and multiple disks architecture to support jitter-free playback <ref> [7, 5, 11, 13] </ref>. Most of this work assumed either a contiguous placement scheme or no data placement scheme (i.e., randomly placed) at all. In this paper, we study the impact of the placement scheme in terms of the buffer size and number of users which can be supported. <p> The analysis used NTSC quality video and an array of eight disks under FIFO, C-SCAN, and GSS <ref> [13] </ref> disk scheduling schemes. The results showed that using the cluster placement scheme: 1. Buffer sizes are reduced up to 40% in FIFO scheme. 2. Buffer sizes are reduced up to 8% in C-SCAN scheme. 3. <p> Different scheduling policies such as FIFO or C-SCAN can be applied here. 4 Analysis and Results We analyze the impact of the cluster placement under FIFO, C-SCAN, and GSS disk scheduling schemes <ref> [13] </ref>. The performance evaluation is based on two parameters: Number of Users Supported (N user ) and Buffer Size (B). For FIFO and C-SCAN schemes, we define the disk access models. For GSS, we adopt the disk access model proposed by Yu and et al. [13]. <p> and GSS disk scheduling schemes <ref> [13] </ref>. The performance evaluation is based on two parameters: Number of Users Supported (N user ) and Buffer Size (B). For FIFO and C-SCAN schemes, we define the disk access models. For GSS, we adopt the disk access model proposed by Yu and et al. [13]. We illustrate the effectiveness of the cluster placement by applying the characteristics 11 of NTSC quality video and an array of eight disks into our analysis. The analysis is based on the cluster placement scheme shown in Figure 2 and 3 (a). <p> It results in buffer size reduction from 8.27% to 3.1%. 4.3 GSS We applied the cluster placement scheme into a disk scheduling scheme called Grouped Sweeping Scheduling (GSS) proposed by Yu and et al. <ref> [13] </ref>. The GSS provided a framework for minimizing buffer space. For n requests, they are divided into g groups. Groups are served in fixed order and requests within a group are served in SCAN scheme.
References-found: 13

