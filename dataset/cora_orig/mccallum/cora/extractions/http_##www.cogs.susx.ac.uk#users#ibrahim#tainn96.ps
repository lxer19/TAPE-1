URL: http://www.cogs.susx.ac.uk/users/ibrahim/tainn96.ps
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: ibrahim@cogs.susx.ac.uk  
Title: Simple Genetic Programming for Supervised Learning Problems  
Author: Ibrahim Kuscu 
Keyword: Supervised Learning, Genetic Programming, Monk's Problems  
Address: Brighton, UK BN1 9QH  
Affiliation: Cognitive and Computing Sciences University of Sussex  
Abstract: This paper presents an evolutionary approach to finding learning rules to several supervised tasks. In this approach potential solutions are represented as variable length mathematical LISP S-expressions. Thus, it is similar to Genetic Programming (GP) but it employs a fixed set of non-problem-specific functions to solve a variety of problems. In this paper three Monk's and parity problems are tested. The results indicate the usefulness of the encoding schema in discovering learning rules for supervised learning problems with the emphasis on hard learning problems. The problems and future research directions are discussed within the context of GP practices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Clark and C. Thornton. </author> <title> Trading spaces: Computation, representation and the limits of uninformed learning. Behavioral and Brain Sciences, </title> <publisher> Forthcoming. </publisher>
Reference-contexts: In the simplest form, there is a direct correlation between particular input values and particular output values. However, sometimes the rule may not refer to particular values of variables. Rather, it may refer to possible relationships among input values. It has been shown <ref> [1] </ref> that learning behaviors based on some training sets involving a relationship among values of the input variables can be extremely difficult (named as type-2 learning problems).
Reference: [2] <author> S. Thrun et al. </author> <title> The monk's problems a performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> School of Computer Science, Carnegie-Mellon University., USA, </institution> <year> 1991. </year>
Reference-contexts: Thus, the experiments in this paper all use training and testing sets to better evaluate the success of a GP based learning model. The three Monk's problems are used to compare the performance of different symbolic and non-symbolic learning techniques <ref> [2] </ref> including AQ17-DCI, AQ17-FCLS, AQ14-NT, AQ15-GA, Assistant Professional, mFOIL, ID5R-hat, TDIDT, ID3, AQR, CN2, CLASSWEB, ECOBVEB, PRISM, Backpropagation and Cascade Correlation. The results of the comparison have shown that only Backpropagation, Backpropagation with decay, cascade correlation and AQ17-DCI had 100 percent performance on Monk 2 problem. <p> RESULTS Original Coding Binary Coding Problems Training Testing Training Testing MONK 1 91 88 MONK 2 74 68 79 69 MONK 3 93 98 93.5 97 Table 1: Best performances in percentages The results obtained are better than some of the learning algorithms used in the comparison experiment of Thrun <ref> [2] </ref>. The performance on MONK 1 and MONK 3 is at the level of competing with most of the algorithms. Although the performance on MONK 2 is very low, this is not surprising and similar to the results obtained by Thrun.
Reference: [3] <author> J. Koza. </author> <title> Genetic Programming:On the programming of computers by means of natural selection. </title> <publisher> MIT press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: In [5] evolution has been shown to be useful in finding solution to several simple supervised tasks. The aim is to see whether evolution would produce the specific learning rule for a problem in hand. Although the representation schema is very similar to the one used by Koza <ref> [3] </ref> [4] in Genetic Programming (GP) paradigm, introducing prior knowledge into the representation of initial solutions using problem-specific functions is minimal, if any at all. <p> In GP practice, however, user defined functions introduces excessively high prior domain knowledge (human intervention) into the model such that the degree of learning to be achieved is excessively low. Although the step of selecting user defined functions has been claimed to be common to several other learning paradigms <ref> [3] </ref> p.88, the amount of domain knowledge introduced in this step by GP and other paradigms is not compared.
Reference: [4] <editor> J. Koza. </editor> <booktitle> Genetic Programming II. </booktitle> <publisher> MIT press, </publisher> <year> 1994. </year>
Reference-contexts: In [5] evolution has been shown to be useful in finding solution to several simple supervised tasks. The aim is to see whether evolution would produce the specific learning rule for a problem in hand. Although the representation schema is very similar to the one used by Koza [3] <ref> [4] </ref> in Genetic Programming (GP) paradigm, introducing prior knowledge into the representation of initial solutions using problem-specific functions is minimal, if any at all.
Reference: [5] <author> I. Kuscu. </author> <title> Evolution of learning rules for supervised tasks i: Simple learning problems. </title> <type> Technical Report CSRP-394, Uni. </type> <institution> of Sussex, COGS, </institution> <year> 1995. </year>
Reference-contexts: The major aim of the research presented here is to see whether evolution can be useful fl This research is funded by Middle East Technical University, Ankara, Turkey. in finding solutions for hard-to-learn supervised tasks (type-2 problems). In <ref> [5] </ref> evolution has been shown to be useful in finding solution to several simple supervised tasks. The aim is to see whether evolution would produce the specific learning rule for a problem in hand. <p> The results of the experiments in <ref> [5] </ref> and being able to discover or re-represent solutions to Monk 1 and Monk 3 problems in this paper provided evidence in support of the first hypothesis. Failing to find a successful solution for Monk 2 seems a poor support for the second hypothesis.
Reference: [6] <author> I. Kuscu. </author> <title> Incrementally learning the rules for supervised tasks: Monk's problems. </title> <type> Technical Report CSRP-396, Uni. </type> <institution> of Sussex, COGS, </institution> <year> 1995. </year>
Reference-contexts: The performance on MONK 1 and MONK 3 is at the level of competing with most of the algorithms. Although the performance on MONK 2 is very low, this is not surprising and similar to the results obtained by Thrun. Moreover, in a recent extension of the experiments <ref> [6] </ref> where the representation is improved and the performance in learning, especially on the MONK 2 problem, is increased. The results emphasise how the encoding can enable us to evolve learning rules for these problems with fixed, general and non-problem-specific set of functions.
Reference: [7] <author> I. Kuscu. </author> <title> Evolution of learning rules for hard learning problems. </title> <booktitle> In the Proceedings of The Fifth Annual Conference on Evolutionary Programming, </booktitle> <publisher> forthcoming. </publisher>
Reference-contexts: The MONK2 and Parity problems are similar in that the learning rule describing either refers to some kind of relationship among the input variables. The general rule for parity problems states that the output is true if there are even number of true values among the input values. In <ref> [7] </ref> I have presented the experiments and results that the model can code for the solutions to the parity problems where the learning rule describes a relationship among the input variables. <p> For each of the parity problems the fixed set of functions are capable of coding at least for OR, AND and NOT. 100 percent success level is reached up to three-bit-parity and 94 percent success is reached on the four-bit-parity problems <ref> [7] </ref>. However, when the problem gets larger and more complex (5 bit-parity or higher) it becomes more difficult for the model to code for the solution.
Reference: [8] <author> I. Kuscu and C. Thornton. </author> <title> Design of artificial neural networks using genetic algorithms:review and prospect. </title> <editor> In C. et al Bozsahin, editor, </editor> <booktitle> Proceedings of Third Turkish Syposium on artificial Intelligence and Neural Networks, </booktitle> <pages> pages 411-420, </pages> <year> 1994. </year>
Reference-contexts: Moreover, in the light of substantial research on automatising the topological structure and parameter selection of artificial neural networks <ref> [8] </ref>, any claim that neural networks and GP require a similar level of human intervention would be even less convincing.
Reference: [9] <author> D. Rumelhart, G. Hinton, and R. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. Rumelhart, J. McClelland, </editor> <title> and the PDP Research Group, editors, Parallel Distributed Processing: Explorations in the Micro-structures of Cognition. Vols I and II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1986. </year>
Reference-contexts: Since the target outputs are in the range of 0 to 1, the values, once obtained after the evaluation of the expressions, are mapped to values between 0 and 1 by using a squashing function. Several functions have been tested in this mapping including logistic activation function used in <ref> [9] </ref>.
Reference: [10] <author> C. Thornton. </author> <title> Measuring the difficulty of specific learning problems. </title> <journal> Connection Science, </journal> <volume> 7(1), </volume> <year> 1995. </year>
Reference-contexts: Rather, it may refer to possible relationships among input values. It has been shown [1] that learning behaviors based on some training sets involving a relationship among values of the input variables can be extremely difficult (named as type-2 learning problems). In one of the studies <ref> [10] </ref> well-known learning algorithms such as ID3, back-propagation and classifier systems are tested on a type-2 problem and all showed poor results.
Reference: [11] <author> D. Whitley. </author> <title> The genitor algorithm and why rank based-based allocation of reproductive trials is best. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-123. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Select expressions to reproduce more: In this step Whitley's <ref> [11] </ref> function for rank based selection is used. 4. Apply genetic operators to create new population: The internal representation of expressions in the system is tree representations. In order to choose a point in this tree two different probabilities are used.
References-found: 11

