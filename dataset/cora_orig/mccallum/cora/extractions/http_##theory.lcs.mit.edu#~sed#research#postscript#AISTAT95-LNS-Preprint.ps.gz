URL: http://theory.lcs.mit.edu/~sed/research/postscript/AISTAT95-LNS-Preprint.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~sed/research/AISTATS95-abs.html
Root-URL: 
Title: 25 Learning in Hybrid Noise Environments Using Statistical Queries  
Author: Scott E. Decatur 
Note: 25.1 Introduction  
Address: Cambridge, MA 02138  
Affiliation: Aiken Computation Laboratory Division of Applied Sciences Harvard University  
Abstract: We consider formal models of learning from noisy data. Specifically, we focus on learning in the probability approximately correct model as defined by Valiant. Two of the most widely studied models of noise in this setting have been classification noise and malicious errors. However, a more realistic model combining the two types of noise has not been formalized. We define a learning environment based on a natural combination of these two noise models. We first show that hypothesis testing is possible in this model. We next describe a simple technique for learning in this model, and then describe a more powerful technique based on statistical query learning. We show that the noise tolerance of this improved technique is roughly optimal with respect to the desired learning accuracy and that it provides a smooth tradeoff between the tolerable amounts of the two types of noise. Finally, we show that statistical query simulation yields learning algorithms for other combinations of noise models, thus demonstrating that statistical query specification truly An important goal of research in machine learning is to determine which tasks can be automated, and for those which can, to determine their information and computation requirements. One way to answer these questions is through the development and investigation of formal models of machine learning which capture the task of learning under plausible assumptions. In this work, we consider the formal model of learning from examples called "probably approximately correct" (PAC) learning as defined by Valiant [Val84]. In this setting, a learner attempts to approximate an unknown target concept simply by viewing positive and negative examples of the concept. An adversary chooses, from some specified function class, a hidden f0; 1g-valued target function defined over some specified domain of examples and chooses a probability distribution over this domain. The goal of the learner is to output in both polynomial time and with high probability, an hypothesis which is "close" to the target function with respect to the distribution of examples. The learner gains information about the target function and distribution by interacting with an example oracle. At each request by the learner, this oracle draws an example randomly according to the hidden distribution, labels it according to the hidden target function, and returns the labelled example to the learner. A class of functions F is said to be PAC learnable if captures the generic fault tolerance of a learning algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [AD93] <author> Javed Aslam and Scott Decatur. </author> <title> General bounds on statistical query learning and PAC learning with noise via hypothesis boosting. </title> <booktitle> In Proceedings of the 34 th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 282-291, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Aslam and Decatur <ref> [AD93] </ref> have shown that for any class learnable by SQ, the dependence of t on " is ("= log (1=")). Therefore, the dependence of fi on and " need never be worse than ( " log (1=") (1=2 )).
Reference: [AD94] <author> Javed Aslam and Scott Decatur. </author> <title> Improved noise-tolerant learning and generalized statistical queries. </title> <type> Technical Report TR-17-94, </type> <institution> Harvard University, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: When discussing asymptotics related to , we consider ! 1=2, or correspondingly (1=2 ) 1 ! 1. Learning in Hybrid Noise Environments Using Statistical Queries 263 Proof: By generalizing a technique of Laird [Lai88], Aslam and Decatur <ref> [AD94] </ref> effectively show that two important parameters determine the number of labelled examples sufficient to perform hypothesis testing by any type of example oracle. <p> The additional accuracy is required to accommodate error introduced by the malicious error examples. The quantities we use to estimate P are based on the classification noise alone simulation of SQ algorithms of Aslam and Decatur <ref> [AD94] </ref>. For each query [; t ], we wish to estimate to within t the value P , the probability that a labelled example drawn from EX (f; D) satisfies . <p> Yet, by using unequally spaced noise rate guesses, it is possible to construct a set of O ( 1 t log 1 ) guesses with this same property <ref> [AD94] </ref>. We compare the hypotheses generated by all of the different runs and output the one with smallest empirical error on a random sample. Corollary 2 can be used to determine the sample size sufficient to ensure with high probability that this hypothesis is "-good.
Reference: [AL88] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: In order to combat this deficiency, variations of PAC learning have been introduced which formalize the types of noise that might occur in a real training environment. Two of the most widely studied models of noise in computational learning theory have been classification noise <ref> [AL88] </ref> and malicious errors [Val85]. The classification noise model allows for common random occurrences (approaching 50% the time) of mislabelled examples, while the malicious error model allows for rare occurrences of adversarial corruption of the entire labelled example. <p> Yet, all models still require the learner to output, with probability at least 1 ffi, an hypothesis h which is "-close to f on D, i.e. with respect to noise-free labelled examples. Angluin and Laird <ref> [AL88] </ref> introduced the model of PAC learning with classification noise in which the learner has access to a noisy example oracle EX CN (f; D). When a labelled example is requested from this oracle, an example is chosen according to distribution D, and returned.
Reference: [Ang92] <author> Dana Angluin. </author> <title> Computational learning theory: Survey and selected bibliography. </title> <booktitle> In Proceedings of the 24 th Annual ACM Symposium on the Theory of Computing, </booktitle> <year> 1992. </year>
Reference-contexts: These differences found in the PAC model seem to better reflect the requirements of learning in the real world. The PAC model has been widely adopted and there has been extensive research in providing algorithms and showing hardness results for this model (see <ref> [Ang92] </ref> for a survey). However, one criticism of the PAC model is that the data used for learning is assumed to be noise free.
Reference: [AV79] <author> Dana Angluin and Leslie G. Valiant. </author> <title> Fast probabilistic algorithms for Hamil-tonian circuits and matchings. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18(2) </volume> <pages> 155-193, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: Using standard Chernoff bounds <ref> [AV79] </ref> and uniform convergence results [VC71], to ensure that (with probability 1 ffi=2) both conditions hold, it is sufficient to use a sample of size m = O ( 1 jQj ffi ) if the query space Q is finite or a sample of size m = O ( q 2
Reference: [Dec93] <author> Scott Decatur. </author> <title> Statistical queries and faulty PAC oracles. </title> <booktitle> In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 262-268. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1993. </year>
Reference-contexts: Kearns [Kea93] has shown that if a class has an SQ algorithm, then it is learnable with any amount of classification noise &lt; 1=2. Decatur <ref> [Dec93] </ref> has shown that if a class has an SQ algorithm with tolerance t , then it is learnable with malicious error fi = fi (t ). 2 Both results are based on the simulation of SQ algorithms in the respective noise models. <p> We may instead define hybrid noise environments based on other types of noise models. Two other such "noise" models are distribution shift and distribution restricted learning <ref> [Dec93] </ref>. In both of these models, the examples are labelled correctly, but the distribution of examples is somehow modified. We show that any combination of these noise models, along with classification noise and/or malicious errors, define a hybrid noise environment in which we can efficiently simulate any statistical query algorithm. <p> If F is PAC learnable, then it is learnable with distribution shift if and only if = O (") <ref> [Dec93] </ref>. In distribution restricted learning, a learner is promised that the distribution of examples belongs to a specified class of distributions D. We can use a distribution restricted SQ algorithm to learn on distributions outside of the promised class of distributions D. <p> The larger class of distributions on which learning is possible is determined by the tolerance t of the SQ algorithm. Specifically, the larger class of distributions is composed of all distributions within distance O (t ) of some distribution in D <ref> [Dec93] </ref>. 25.4.2 The Hybrid Noise Model The model which combines all four of these individual noise models is described by the following learning environment.
Reference: [Dec95] <author> Scott Decatur. </author> <title> Efficient Learning from Faulty Data. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <year> 1995. </year>
Reference-contexts: Alternatively, one could use a separate sample for each of the N queries made by all runs of the algorithm, thus using a total of m = O ( N ffi ) examples. (See <ref> [Dec95] </ref> for a more complete discussion of sample sizes.) 2 25.3.4 Optimality of CAM Tolerance Theorem 3 states that any class which is SQ learnable is PAC learnable with CAM for all &lt; 1 1=2 ).
Reference: [DG95] <author> Scott Decatur and Rosario Gennaro. </author> <title> On learning from noisy and incomplete examples. </title> <booktitle> In Proceedings of the Eighth Annual ACM Workshop on Computational Learning Theory. </booktitle> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference-contexts: Thus, the tolerance of the SQ algorithm quantifies 268 Scott E. Decatur the generic fault tolerance of the algorithm. Additionally, statistical queries have been used to learn in a different hybrid noise environment which incorporates both attribute noise and classification noise <ref> [DG95] </ref>. 25.4.1 Individual Noise Models In the model of distribution shift, the learning algorithm is given access to an example oracle which draws examples according to a distribution which differs from the distribution on which it will be tested, yet examples are always labelled correctly.
Reference: [HSW92] <author> David Helmbold, Robert Sloan, and Manfred K. Warmuth. </author> <title> Learning integer lattices. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(2) </volume> <pages> 240-266, </pages> <year> 1992. </year>
Reference-contexts: This problem is illustrated by the class of parity functions. The class of parity functions has a malicious error tolerant algorithm (yielded by the technique of "multiple-runs" [KL88] discussed below, on the noise-free algorithm for learning parity functions <ref> [HSW92] </ref>), yet it is not known how to learn parity functions even in the presence of classification noise alone. Conversely, such a transformation does exist when starting with an algorithm which tolerates classification noise.
Reference: [Kea93] <author> Michael Kearns. </author> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proceedings of the 25 th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 392-401, </pages> <address> San Diego, </address> <year> 1993. </year>
Reference-contexts: We next show a different technique for generating CAM-tolerant learning algorithms which tolerate strictly more noise. This technique is based on simulating statistical query (SQ) algorithms. In the SQ model of learning <ref> [Kea93] </ref>, the learner may no longer view labelled examples, but instead may ask for estimates of the values of various statistics based on the distribution of labelled examples. <p> Most classes which have PAC algorithms also have SQ algorithms and these SQ algorithms can be easily derived from their corresponding PAC algorithms <ref> [Kea93] </ref>. Thus, we show that all of these classes are learnable in the presence of simultaneous classification noise and malicious error. Our technique provides a smooth tradeoff between the amount of tolerable classification noise and malicious error. <p> Kearns and Li [KL88] showed that for "distinct" classes (virtually all interesting classes are distinct), it is impossible to tolerate a malicious error rate of fi " 1+" . The statistical query (SQ) model <ref> [Kea93] </ref>, a further variant of the noise-free PAC model, has been a useful tool in the construction of noise-tolerant PAC algorithms. In the SQ model, the PAC example oracle EX (f; D) is replaced by a statistics oracle STAT (f; D). <p> Kearns <ref> [Kea93] </ref> has shown that if a class has an SQ algorithm, then it is learnable with any amount of classification noise &lt; 1=2.
Reference: [KL88] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the 20 th Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: We say that a class is learnable with classification noise if it is learnable for some constant classification noise rate &gt; 0. The PAC model with malicious errors was introduced by Valiant [Val85] and studied further by Kearns and Li <ref> [KL88] </ref>. In this model, the learner has access to an example oracle EX fi MAL (f; D). <p> However, with probability fi, a malicious adversary selects any example it chooses and labels it either positive or negative. Kearns and Li <ref> [KL88] </ref> showed that for "distinct" classes (virtually all interesting classes are distinct), it is impossible to tolerate a malicious error rate of fi " 1+" . <p> Given an algorithm which tolerates malicious errors, no transformation is known which adds the ability to tolerate classification noise. This problem is illustrated by the class of parity functions. The class of parity functions has a malicious error tolerant algorithm (yielded by the technique of "multiple-runs" <ref> [KL88] </ref> discussed below, on the noise-free algorithm for learning parity functions [HSW92]), yet it is not known how to learn parity functions even in the presence of classification noise alone. Conversely, such a transformation does exist when starting with an algorithm which tolerates classification noise. Kearns and Li [KL88] describe a <p> of "multiple-runs" <ref> [KL88] </ref> discussed below, on the noise-free algorithm for learning parity functions [HSW92]), yet it is not known how to learn parity functions even in the presence of classification noise alone. Conversely, such a transformation does exist when starting with an algorithm which tolerates classification noise. Kearns and Li [KL88] describe a technique that takes a PAC algorithm with sample complexity m which does not tolerate malicious errors, and by running it many times, converts it into one which tolerates a malicious error rate fi = fi ( log m m ). <p> Proof: For fixed &lt; 1 2 , fi = !(") g 2 (1=2 ) = !("). However, as stated above, Kearns and Li <ref> [KL88] </ref> have shown that no distinct class is learnable with fi " 1+" = fi ("). 2 For many commonly studied classes (such as conjunctions, decision lists, and k-DNF) t = fi ("=VCDim (F)), in which case the malicious error tolerable is fi = fi ("(1=2)=VCDim (F)).
Reference: [Lai88] <author> Philip D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year> <note> 270 Scott E. Decatur </note>
Reference-contexts: We define ~ similarly for some constant c 0 and analogously define ~ fi; ~o; ~!. When discussing asymptotics related to , we consider ! 1=2, or correspondingly (1=2 ) 1 ! 1. Learning in Hybrid Noise Environments Using Statistical Queries 263 Proof: By generalizing a technique of Laird <ref> [Lai88] </ref>, Aslam and Decatur [AD94] effectively show that two important parameters determine the number of labelled examples sufficient to perform hypothesis testing by any type of example oracle.
Reference: [Sim93] <author> Hans Ulrich Simon. </author> <title> General bounds on the number of examples needed for learning probabilistic concepts. </title> <booktitle> In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 402-411. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: We can take an algorithm which tolerates classification noise, and use this technique to create one which tolerates CAM error. The amount of CAM error which can be tolerated using these techniques may be upper bounded by using lower bounds on the sample complexity of classification noise learning. Simon <ref> [Sim93] </ref> has shown that any algorithm for function class F which tolerates classification noise must have sample complexity at least m = ( VCDim (F) "(1=2) 2 ). 4 In fact, most known classification noise algorithms have sample complexity at least m = ( VCDim (F) " 2 (1=2) 2 ).
Reference: [Val84] <author> Leslie Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: One way to answer these questions is through the development and investigation of formal models of machine learning which capture the task of learning under plausible assumptions. In this work, we consider the formal model of learning from examples called "probably approximately correct" (PAC) learning as defined by Valiant <ref> [Val84] </ref>. In this setting, a learner attempts to approximate an unknown target concept simply by viewing positive and negative examples of the concept. <p> The generality of the usefulness of statistical query specification demonstrates its ability to capture the Learning in Hybrid Noise Environments Using Statistical Queries 261 fault tolerance intrinsic to a learning problem. 25.2 Learning Models In Valiant's PAC model of learning from labelled examples <ref> [Val84] </ref>, an adversary selects both the hidden target f0; 1g-valued function f from a known class of functions F and the hidden probability distribution D which is defined over the domain of f . The domain of f constitutes the set of possible examples.
Reference: [Val85] <author> Leslie Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: In order to combat this deficiency, variations of PAC learning have been introduced which formalize the types of noise that might occur in a real training environment. Two of the most widely studied models of noise in computational learning theory have been classification noise [AL88] and malicious errors <ref> [Val85] </ref>. The classification noise model allows for common random occurrences (approaching 50% the time) of mislabelled examples, while the malicious error model allows for rare occurrences of adversarial corruption of the entire labelled example. <p> We say that a class is learnable with classification noise if it is learnable for some constant classification noise rate &gt; 0. The PAC model with malicious errors was introduced by Valiant <ref> [Val85] </ref> and studied further by Kearns and Li [KL88]. In this model, the learner has access to an example oracle EX fi MAL (f; D).
Reference: [VC71] <author> V.N. Vapnik and A.Ya. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theor. Probability Appl., </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: Theorem 3 Given an SQ learning algorithm for F with minimum tolerance t , one can construct a PAC learning algorithm for F which can tolerate CAM for all &lt; 1=2 and fi fi fl = fi (t (1=2 )). 4 The VC-dimension <ref> [VC71] </ref>, or VCDim, of a class F is a combinatorial measure which is commonly used to characterize the required sample complexity for learning F. Note that VCDim (F) 1. <p> Using standard Chernoff bounds [AV79] and uniform convergence results <ref> [VC71] </ref>, to ensure that (with probability 1 ffi=2) both conditions hold, it is sufficient to use a sample of size m = O ( 1 jQj ffi ) if the query space Q is finite or a sample of size m = O ( q 2 log 1 2 log 1
References-found: 16

