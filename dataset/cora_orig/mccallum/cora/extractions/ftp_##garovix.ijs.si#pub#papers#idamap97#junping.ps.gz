URL: ftp://garovix.ijs.si/pub/papers/idamap97/junping.ps.gz
Refering-URL: http://www-ai.ijs.si/ailab/activities/idamap97.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: junping@daimi.aau.dk brian@daimi.aau.dk  
Title: Applications of machine learning: a medical follow up study  
Author: Du Junping K. L. Rasmussen J. Aagaard Brian H. Mayoh Tom Srensen 
Address: Denmark  Denmark  
Affiliation: Computer Science Department, Aarhus University,  Department of Obstetrics and Gynaecology, Aarhus University Hospital,  
Abstract: This paper describes preliminary work that aims to apply some learning strategies to a medical follow-up study. An investigation of the application of three machine learning algorithms-1R, FOIL and InductH to identify risk factors that govern the colposuspension cure rate has been made. The goal of this study is to induce a generalised description or explanation of the classification attribute, colposuspension cure rate (completely cured, improved, unchanged and worse) from the 767 examples in the questionnaires. We looked for a set of rules that described which risk factors result in differences of cure rate. The results were encouraging, and indicate that machine learning can play a useful role in large scale medical problem solving.
Abstract-found: 1
Intro-found: 1
Reference: [Fayyard et al., 1996] <editor> Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy.G. </editor> <title> Advances in Knowledge discovery and data mining . AAAI Press / The MIT Press, </title> <address> Menlo Park, CA. </address> <year> 1996. </year>
Reference-contexts: Knowledge discovery can be defined as the extraction of implicit, previously unknown, and potentially useful information from data, and can be built upon a variety of technologies of which machine learning is one of the most important <ref> [Fayyard et al., 1996; Piatetsky-Shapiro and Frawley, 1991] </ref>.
Reference: [Gaines, 1991] <author> Gaines, B.R. </author> <title> The tradeoff between knowledge and data in knowledge acquisition. </title> <editor> In Piatetsky-Shapiro and Frawley. </editor> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference: [Holmes et al., 1994] <author> Holmes, G., Donkin, A., and Witten, I. H. Weka: </author> <title> A machine learning workbench. </title> <booktitle> Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems, </booktitle> <pages> pages 357-361, </pages> <address> Brisbane, Australia, </address> <year> 1994. </year>
Reference-contexts: One of the most important features of the WEKA workbench is that it allows many different schemes to be run on the same dataset and for the output of each scheme to be evaluated in a consistent fashion <ref> [Holmes et al., 1994] </ref>. The WEKA machine learning workbench is used to produce rules and decision trees based on the current dataset. With it, we are able to derive knowledge from datasets that are far too large to be analysed by hand.
Reference: [Holte, 1993] <author> Holte, </author> <title> R.C. Very simple classification rules perform well on most commonly-used datasets. </title> <booktitle> Machine Learning. 1993; 11: </booktitle> <pages> 63-91. </pages>
Reference-contexts: Macintosh spreadsheet package (EXCEL), saving the file in comma separated form, then loading it into our UNIX machine with WEKA installed. 2.4 The Machine Learning Schemes The machine learning tools used for our analysis were primarily FOIL [Quinlan, 1990; Quinlan, 1991; Quinlan, 1993], InductH [McQueen et al., 1994]. and 1R <ref> [Holte, 1993] </ref>. These are supervised learning schemes that produce useful rules that describe a classification based on combinations of attribute tests. Supervised learning is when a desired class is assigned to each example in the dataset, and the aim is to induce rules that classify unseen examples.
Reference: [McQueen et al., 1994] <author> McQueen, R.J., Neal, D., De War, R. and Garner. </author> <title> Preparing and processing relational data through the WEKA machine learning workbench. </title> <type> Working paper, </type> <institution> Department of Computer Science, University of Waikato, Hamilton, </institution> <address> New Zealand. </address> <year> 1994. </year>
Reference-contexts: WEKA, the Waikato environment for knowledge analysis, is an experimental software workbench incorporating several standard machine learning techniques <ref> [McQueen et al., 1994; Witten et al., 1993] </ref>. One of the most important features of the WEKA workbench is that it allows many different schemes to be run on the same dataset and for the output of each scheme to be evaluated in a consistent fashion [Holmes et al., 1994]. <p> includes loading original data onto a Macintosh spreadsheet package (EXCEL), saving the file in comma separated form, then loading it into our UNIX machine with WEKA installed. 2.4 The Machine Learning Schemes The machine learning tools used for our analysis were primarily FOIL [Quinlan, 1990; Quinlan, 1991; Quinlan, 1993], InductH <ref> [McQueen et al., 1994] </ref>. and 1R [Holte, 1993]. These are supervised learning schemes that produce useful rules that describe a classification based on combinations of attribute tests.
Reference: [Michie, 1991] <author> Michie, D. </author> <title> Methodologies from machine learning in data analysis and software. </title> <journal> The Computer Journal, </journal> <volume> 34(6): </volume> <pages> 559-565, </pages> <year> 1991. </year>
Reference-contexts: It encompasses a wide variety of techniques used for the discovery of rules, patterns and relationships in sets of data and produces a generalisation of these relationships that can be used to interpret new, unseen data <ref> [Michie, 1991; Pazzani and Kibler, 1992] </ref>. WEKA, the Waikato environment for knowledge analysis, is an experimental software workbench incorporating several standard machine learning techniques [McQueen et al., 1994; Witten et al., 1993].
Reference: [Michie, 1991; Pazzani and Kibler 1992] <author> Pazzani, M. and Kibler, D. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9(1): </volume> <pages> 57-94, </pages> <year> 1992. </year>
Reference: [Piatetsky-Shapiro and Frawley 1991] <author> Piatetsky-Shapiro, G. and Frawley, W.J. </author> <title> Knowledge discovery in databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference: [Quinlan, 1990] <author> Quinlan, J.R. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5: </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Converting the dataset to an ARFF includes loading original data onto a Macintosh spreadsheet package (EXCEL), saving the file in comma separated form, then loading it into our UNIX machine with WEKA installed. 2.4 The Machine Learning Schemes The machine learning tools used for our analysis were primarily FOIL <ref> [Quinlan, 1990; Quinlan, 1991; Quinlan, 1993] </ref>, InductH [McQueen et al., 1994]. and 1R [Holte, 1993]. These are supervised learning schemes that produce useful rules that describe a classification based on combinations of attribute tests.
Reference: [Quinlan, 1991] <author> Quinlan, J.R. </author> <title> Determinate Literals in Inductive Logic Programming. </title> <booktitle> Proceedings 12th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 746-750, </pages> <year> 1991. </year>
Reference-contexts: Converting the dataset to an ARFF includes loading original data onto a Macintosh spreadsheet package (EXCEL), saving the file in comma separated form, then loading it into our UNIX machine with WEKA installed. 2.4 The Machine Learning Schemes The machine learning tools used for our analysis were primarily FOIL <ref> [Quinlan, 1990; Quinlan, 1991; Quinlan, 1993] </ref>, InductH [McQueen et al., 1994]. and 1R [Holte, 1993]. These are supervised learning schemes that produce useful rules that describe a classification based on combinations of attribute tests.
Reference: [Quinlan, 1993] <author> Quinlan, J.R. and Cameron-Jones, </author> <title> R.M. FOIL: a midterm report. </title> <booktitle> Proceeding European Conference on Machine Learning, </booktitle> <address> p3-20, </address> <year> 1993. </year>
Reference-contexts: Converting the dataset to an ARFF includes loading original data onto a Macintosh spreadsheet package (EXCEL), saving the file in comma separated form, then loading it into our UNIX machine with WEKA installed. 2.4 The Machine Learning Schemes The machine learning tools used for our analysis were primarily FOIL <ref> [Quinlan, 1990; Quinlan, 1991; Quinlan, 1993] </ref>, InductH [McQueen et al., 1994]. and 1R [Holte, 1993]. These are supervised learning schemes that produce useful rules that describe a classification based on combinations of attribute tests.
Reference: [Witten et al., 1993] <author> Witten, I.H., Cunningham, S.J., Holmes, G., McQueen, R., and Smith, L. </author> <title> Practical machine learning and its application to problems in agriculture. </title> <booktitle> Proceedings of the New Zealand Computer Society Conference, </booktitle> <pages> pages 308-325, </pages> <address> Auckland, New Zealand, </address> <year> 1993. </year>
Reference-contexts: WEKA, the Waikato environment for knowledge analysis, is an experimental software workbench incorporating several standard machine learning techniques <ref> [McQueen et al., 1994; Witten et al., 1993] </ref>. One of the most important features of the WEKA workbench is that it allows many different schemes to be run on the same dataset and for the output of each scheme to be evaluated in a consistent fashion [Holmes et al., 1994].
References-found: 12

