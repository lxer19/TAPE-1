URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1994/GIT-CC-94-27.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.94.html
Root-URL: 
Title: Parallel Discrete Event Simulation Using Space-Time Memory  
Author: Kaushik Ghosh and Richard M. Fujimoto 
Note: This work was supported by Innovative Science and Technology contract number DASG60-90-C-0147 provided by the Strategic Defense Initiative Office and managed through the Strategic Defense Command Advanced Technology Directorate Processing Division, and by NSF grant number CCR-8902362.  
Date: January 10, 1991  January 10, 1991  
Address: Atlanta, GA, 30332.  Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  School of Information and Computer Science Georgia Institute of Technology  
Pubnum: GIT-ICS-94/27  
Abstract: An abstraction called space-time memory is discussed that allows parallel discrete event simulation programs using the Time Warp mechanism to be written using shared memory constructs. A few salient points concerning the implementation and use of space-time memory in parallel simulation are discussed. It is argued that this abstraction is useful from a programming standpoint for certain applications, and can yield good performance. Initial performance measurements of a prototype implementation of the abstraction on a shared-memory multiprocessor are described, and compared with a conventional, message-based implementation of Time Warp. 
Abstract-found: 1
Intro-found: 1
Reference: [BL90] <author> Rajive. L. Bagrodia and Wen-Toh Liao. </author> <title> Parallel simulation of the sharks world problem. </title> <booktitle> Proceedings of the 1990 Winter Simulation Conference, </booktitle> <pages> pages 191-198, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Similarly, a write rolls back events that wrote versions with higher timestamps. Hence, a writing event that copied data from an incorrect version will not be committed. 5 The Sharks World Benchmark In this section we discuss the use of STM in a well known benchmark|the Sharks World <ref> [CCU90, BL90, PRB90, NR90] </ref>. The Sharks World benchmark was designed as a simulation that captures the essence of certain problems of practical interest, e.g., military applications. This benchmark simulates a toroidal ocean, containing sharks and fish. Sharks move in straight lines and eat fish, but do not attack each other.
Reference: [CCU90] <author> Darrel Conklin, John Cleary, and Brian Unger. </author> <title> The sharks world (a study in distrtibuted simulation design). </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 22(2) </volume> <pages> 157-160, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Similarly, a write rolls back events that wrote versions with higher timestamps. Hence, a writing event that copied data from an incorrect version will not be committed. 5 The Sharks World Benchmark In this section we discuss the use of STM in a well known benchmark|the Sharks World <ref> [CCU90, BL90, PRB90, NR90] </ref>. The Sharks World benchmark was designed as a simulation that captures the essence of certain problems of practical interest, e.g., military applications. This benchmark simulates a toroidal ocean, containing sharks and fish. Sharks move in straight lines and eat fish, but do not attack each other.
Reference: [CS89] <author> K. M. Chandy and R. Sherman. </author> <title> Space, time, and simulation. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 21(2) </volume> <pages> 53-57, </pages> <month> March </month> <year> 1989. </year> <month> 12 </month>
Reference-contexts: More closely related to our work is the space-time simulation method proposed by Chandy and Sherman <ref> [CS89] </ref>. As in our work, they view the simulator state as a two-dimensional space-time graph. However, they then partition this graph into regions, and assign each region to a process that is responsible for computing the values of state variables in that region.
Reference: [Fuj89a] <author> R. M. Fujimoto. </author> <title> Time Warp on a shared memory multiprocessor. </title> <journal> Transactions of the Society for Computer Simulation, </journal> <volume> 6(3) </volume> <pages> 211-239, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: be used much as the file descriptor returned by a file-open for reading or writing is used, without needing to `open the file' every time a file read/write is done.) 3.2 Implementation An implementation of the STM abstraction has been added to an existing Time Warp discrete event simulation testbed <ref> [Fuj89a] </ref> on a GP1000 BBN Butterfly shared-memory multiprocessor. Every event contains a list of pointers to versions that it has read. The versions that an event has written are similarly maintained. Each version includes a list of pointers to events that have read it. <p> All experiments were performed on a GP1000 BBN Butterfly multiprocessor. The message-based version is optimized to execute efficiently on a shared memory multiprocessor, and uses direct cancellation <ref> [Fuj89a] </ref>. 128 256 384 512 Number of creatures 0.9 1.3 Ratio of execution times . .. .. .. ... .. .. ... .. .. .. ... .. .. .. ... .. .. .. ... .. .. ... .. .. .. ... .. .. .. ... .. .. .. ... .. ..
Reference: [Fuj89b] <author> R. M. Fujimoto. </author> <title> The virtual time machine. </title> <booktitle> International Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 199-208, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The mechanism that we use does not rely on processes, though processes can be (and have been) added where desired. The underlying simulation mechanism used here is event-oriented rather than process-oriented. Finally, the space-time memory abstraction discussed here was originally proposed in <ref> [Fuj89b] </ref>. There, space-time memory is used in the context of a parallel computer architecture that utilizes rollback for 1 Here, we ignore the possibility of distinct events containing the same timestamp. 1 synchronization.
Reference: [Fuj90] <author> R. M. Fujimoto. </author> <title> Parallel discrete event simulation. </title> <journal> Communications of the ACM, </journal> <volume> 33(10) </volume> <pages> 30-53, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The parallel computation should yield the same results as if the events were processed sequentially in non-decreasing timestamp order. 1 Several successes have been reported in using the Time Warp mechanism to parallelize discrete event simulation programs in a variety of applications <ref> [Fuj90] </ref>. Most existing parallel discrete event simulation mechanisms assume a process-oriented view where the simulation is assumed to consist of a collection of logical processes that communicate exclusively by exchanging timestamped event messages [Fuj90]. <p> in using the Time Warp mechanism to parallelize discrete event simulation programs in a variety of applications <ref> [Fuj90] </ref>. Most existing parallel discrete event simulation mechanisms assume a process-oriented view where the simulation is assumed to consist of a collection of logical processes that communicate exclusively by exchanging timestamped event messages [Fuj90]. This paradigm forbids the use of shared memory to hold state variables, for reasons that will be discussed later. In this paper, we investigate extensions to the Time Warp mechanism that allow the use of shared state.
Reference: [JCRB89] <author> D. W. Jones, C-C. Chou, D. Renk, and S. C. Bruell. </author> <title> Experience with concurrent simulation. </title> <booktitle> 1989 Winter Simulation Conference Proceedings, </booktitle> <pages> pages 756-764, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: There has been some work based on computation models utilizing shared-memory. Jones was perhaps the first to propose such an approach <ref> [JCRB89, Jon86] </ref>. Our work differs from his in that he utilizes a conservative simulation protocol, while we use an optimistic one.
Reference: [Jef85] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: While conservative synchronization mechanisms rely on blocking to avoid violations of dependence constraints, optimistic methods rely on detecting synchronization errors at runtime, and recovering using a rollback mechanism. Here, we are concerned with extensions to the optimistic Time Warp mechanism <ref> [Jef85] </ref>. Synchronization plays an especially important role when executing discrete event simulation programs on a parallel computer because these simulations are often irregular, and exhibit highly data dependent behavior.
Reference: [Jon86] <author> D. W. Jones. </author> <title> Concurrent simulation: An alternative to distributed simulation. </title> <booktitle> 1986 Winter Simulation Conference Proceedings, </booktitle> <pages> pages 417-423, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: There has been some work based on computation models utilizing shared-memory. Jones was perhaps the first to propose such an approach <ref> [JCRB89, Jon86] </ref>. Our work differs from his in that he utilizes a conservative simulation protocol, while we use an optimistic one.
Reference: [LH89] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: It should be noted that the STM abstraction is not restricted to shared-memory multiprocessors. The abstraction can be implemented on message-based multicomputers in much the same way as distributed shared memory <ref> [LH89] </ref>. 3 The Abstraction and Its Implementation 3.1 Abstraction The basic unit of the shared STM system is an object. To the programmer, an object is simply a collection of state variables. In actuality, however, each object contains successive versions of the state variables mapped to that object.
Reference: [NR90] <author> David M. Nicol and Scott E. Riffe. </author> <title> A `conservative' approach to parallelizing the sharks world simulation. </title> <booktitle> Proceedings of the 1990 Winter Simulation Conference, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: Similarly, a write rolls back events that wrote versions with higher timestamps. Hence, a writing event that copied data from an incorrect version will not be committed. 5 The Sharks World Benchmark In this section we discuss the use of STM in a well known benchmark|the Sharks World <ref> [CCU90, BL90, PRB90, NR90] </ref>. The Sharks World benchmark was designed as a simulation that captures the essence of certain problems of practical interest, e.g., military applications. This benchmark simulates a toroidal ocean, containing sharks and fish. Sharks move in straight lines and eat fish, but do not attack each other.
Reference: [PRB90] <author> Matthew T. Presley, Peter L. Reiher, and Steven Bellenot. </author> <title> A time warp implementation of sharks world. </title> <booktitle> Proceedings of the 1990 Winter Simulation Conference, </booktitle> <pages> pages 199-203, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Similarly, a write rolls back events that wrote versions with higher timestamps. Hence, a writing event that copied data from an incorrect version will not be committed. 5 The Sharks World Benchmark In this section we discuss the use of STM in a well known benchmark|the Sharks World <ref> [CCU90, BL90, PRB90, NR90] </ref>. The Sharks World benchmark was designed as a simulation that captures the essence of certain problems of practical interest, e.g., military applications. This benchmark simulates a toroidal ocean, containing sharks and fish. Sharks move in straight lines and eat fish, but do not attack each other. <p> Although time did not permit us to report speedup figures relative to a sequential simulation, others have shown that message-based Time Warp achieves good speedups for this problem <ref> [PRB90] </ref>. Increasing the number of processors increases contention for the shared data structures used by the space-time memory version. Since we use spin locks in our current implementation, this means that processors spend more time waiting on locks, resulting in somewhat reduced performance.
Reference: [RBJ91] <author> Peter Reiher, Steven Bellenot, and David Jefferson. </author> <title> Temporal decomposition of simulations under the time warp operating system. </title> <booktitle> Proceedings of the 1991 Workshop on Parallel and Distributed Simulation, </booktitle> <pages> pages 47-54, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: However, they then partition this graph into regions, and assign each region to a process that is responsible for computing the values of state variables in that region. The computation proceeds until a fixed point is achieved. Reiher et. al. use a similar "temporal" decomposition for load management purposes <ref> [RBJ91] </ref>. The mechanism that we use does not rely on processes, though processes can be (and have been) added where desired. The underlying simulation mechanism used here is event-oriented rather than process-oriented. Finally, the space-time memory abstraction discussed here was originally proposed in [Fuj89b].
Reference: [WJ89] <author> F. Wieland and D. R. Jefferson. </author> <title> Case studies in serial and parallel simulation. </title> <booktitle> Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <volume> Vol. 3, </volume> <pages> pages 255-258, </pages> <month> August </month> <year> 1989. </year> <month> 13 </month>
Reference-contexts: It is also convenient to use logical processes to model certain components of the simulation that persist from one event to another. For many simulations, it is convenient and natural to utilize state variables that can be accessed by distinct logical processes. For example, consider a combat simulation <ref> [WJ89] </ref>. Assume that there are two armies, each consisting of some number of combat units, fighting on some terrain. <p> This type of communication, often called pull processing <ref> [WJ89] </ref>, produces many messages. Another method of communication without the use of space-time memory would be to replicate shared data at the several LPs that may need such data. This would require no message passing for reading shared data. <p> This would require no message passing for reading shared data. However, modification of shared data would require updates at all LPs that hold a copy of the data. In general, such push processing <ref> [WJ89] </ref>, reduces the number of messages required for communication, and alleviates serial bottlenecks at the LP whose memory contents are being read, but it substantially complicates the coding of the application because of the need to keep replicated data up to date. <p> Finally, a sector-leaving event is scheduled for the shark. This basic scenario is repeated for the length of the simulation. 5.2 Sharks World Using Messages The message-based implementation of the Sharks World uses pull processing. However, unlike <ref> [WJ89] </ref>, our pull processing is event driven and not time driven. In the absence of shared objects, the arrival of a shark at a sector is modeled as a message from the LP of the source sector to that of the destination sector.
References-found: 14

