URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1996/UM-CS-1996-020.ps
Refering-URL: http://www.cs.umass.edu/~potter/LC/spring96.doc.html
Root-URL: 
Title: Bucket Skip Merge Join: A Scalable Algorithm for Join Processing in Very Large Databases using Indexes  
Keyword: Join Processing, Merge Join, Query Optimization, Performance, Information Re trieval, Digital Libraries, Decision Support Systems, Data Warehousing  
Note: Supported by NSF grant IRI-9314376 and a grant from Sun Microsystems Labs  
Abstract: Mohan Kamath and Krithi Ramamritham Computer Science Technical Report 96-20 Department of Computer Science University of Massachusetts Amherst MA 01003 fkamath,krithig@cs.umass.edu Abstract Join processing algorithms play a critical role in efficient query processing. Popular join processing algorithms like merge join and hash join typically access all the data items in the datasets to be joined. In this paper we present a new join algorithm called bucket skip merge join which does not always access all the data items of the join sets. The basic idea is to divide the datasets into buckets that contain monotonically increasing values and maintain high and low values for each bucket. During join processing, the algorithm uses these values to skip a whole bucket or parts of a bucket when it can be determined that a match will not be found for the rest of the data items in the bucket. This considerably reduces the number of memory accesses, disk accesses and CPU time. Results of the performance tests on a prototype system indicates that our algorithm outperforms other popular join algorithms. Specifically, they scale better with the size of the database and the degree of join. Hence our algorithm will be very useful for applications like information retrieval, data warehousing and decision support systems that access very large databases. 
Abstract-found: 1
Intro-found: 1
Reference: [BE76] <author> M. W. Blasgen and K. P. Eswaran. </author> <title> On the evaluation of queries in a database system. </title> <type> Technical report, </type> <institution> RJ-1745, International Business Machines (IBM), </institution> <address> San Jose, </address> <month> April </month> <year> 1976. </year> <month> 22 </month>
Reference-contexts: These factors have prompted us to explore new join techniques that can scale and perform better than techniques in vogue. Early query processing schemes were based either on nested loop join or merge join <ref> [BE76] </ref>. Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. <p> Section 9 concludes the paper with a summary. 2 Related Work and Motivation To motivate the need for new join algorithms, we now trace through previous work in join processing. 2 One of the first studies on join processing algorithms <ref> [BE76] </ref> recommended merge join as the most optimal scheme for large databases. In merge join, the join inputs are first sorted on the join attribute and tuples that match are determined efficiently by simultaneously scanning both inputs.
Reference: [BM90] <author> J. A. Blakeley and N. L. Martin. </author> <title> Join index, materialized view, and hybrid-hash join: A performance analysis. </title> <booktitle> In Proc. IEEE CS Intl. Conf. No. 6 on Data Engineering, </booktitle> <month> February </month> <year> 1990. </year>
Reference-contexts: However when the database is appended frequently, join indexes incur a lot of overheads. The performance of join indices have also been compared with other schemes in <ref> [BM90] </ref>. This study concludes that join indices are good when the join selectivity is low and updates/appends are not frequent. Join schemes for relational databases have also been adapted for object-oriented database systems [SC90, DLM93]. Several issues related to join processing are surveyed in [ME92].
Reference: [Bra84] <author> K. Bratbergsengen. </author> <title> Hashing methods and relational algebra operations. </title> <booktitle> In Proceedings of the 10th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Singapore, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. Hence hash join was proposed as a better alternative and has since been enhanced to improve performance <ref> [Bra84, DKO + 84, NKT88, KNT89, Sha86] </ref>. Query processing schemes in commercial products currently use both merge join or hash join. <p> However sort is an expensive operation. Hash indices were already being used for quick access to data [SWKH76, FNPS79]. This sparked interest in hash join schemes as an alternative to merge join schemes <ref> [Bra84, DKO + 84] </ref>. The basic principle is to build an in-memory hash table for the smaller of the join inputs and probe this table for items in the large input.
Reference: [Bro95] <author> E.W. Brown. </author> <title> Fast Evaluation of Structured Queries for Information Retrieval. </title> <booktitle> In Proc. of SIGIR Intl. Conf. on Research and Development in Information Retrieval, </booktitle> <year> 1995. </year>
Reference-contexts: The documents are sorted based on the scores and the top few documents are returned to the user. The documents returned need not contain all the keywords specified in the query. Also to cut down the query execution time, optimization schemes have been proposed <ref> [Bro95] </ref> where a best list for each keyword is maintained that contains document IDs of the top 1000 documents that have the maximum occurrences that keyword.
Reference: [BS96] <author> C. Bontempo and C. Saracco. </author> <title> Join processing: The relational embrace. </title> <journal> Database Programming and Design Magazine, </journal> <volume> 9(1), </volume> <month> January </month> <year> 1996. </year>
Reference-contexts: In such applications, the read to write ratio of data items is very high. Hence indexes are to be maintained to speed up accesses. Also a recent article focusing on join facilities offered by commercial products for data warehousing and decision support systems applications <ref> [BS96] </ref>, emphasizes the cost efficiency of join algorithms and motivates the need for exploring new join schemes for emerging applications. These factors have prompted us to explore new join techniques that can scale and perform better than techniques in vogue.
Reference: [CHH + 91] <author> J. Cheng, D. Haderle, R. Hedges, B. R. Iyer, T. Messinger, C. Mohan, and Y. Wang. </author> <title> An efficient hybrid join algorithm: A DB2 prototype. </title> <booktitle> In Proc. IEEE Int'l. Conf. on Data Eng., </booktitle> <pages> page 171, </pages> <address> Kobe, Japan, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes [Gra94, GLS94]. Commercial database products currently support both the merge join and hash join schemes <ref> [CHH + 91] </ref>.
Reference: [Chr83] <author> S. Christodoulakis. </author> <title> Estimating block transfers and join sizes. </title> <booktitle> In Proc. ACM SIG-MOD Conf., </booktitle> <pages> page 40, </pages> <address> San Jose, CA, </address> <month> May </month> <year> 1983. </year>
Reference-contexts: We do not discuss parallelism issues in the rest of the paper since it is orthogonal to the main focus of our work. There has also been a lot of interest in improving buffer management and page fetching schemes for join processing <ref> [MKY81, Chr83, GP89, Omi89] </ref>. The schemes typically try to avoid duplicating page fetches when the pages that are to be brought into memory for performing the join is known. To improve the efficiency of joins, use of special index structures called join indices [Val87] has been studied.
Reference: [DDS + 95] <author> S. DeFazio, A. Daoud, L. Smith, J. Srinivasan, B. Croft, and J. Callan. </author> <title> Integrating IR and RDBMS Using Cooperative Indexing. </title> <booktitle> In Proc. of SIGIR Intl. Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 84-92, </pages> <year> 1995. </year>
Reference-contexts: Since joins are analogous to the AND operation, we focus only on AND queries, i:e:; queries that have AND connectors between the keywords. The techniques we describe here are important, especially with the current trend to integrate information retrieval (IR) systems with DBMSs <ref> [DDS + 95] </ref>. It is also important in the case of image-databases (and digital-libraries), where a join might have to be performed on several attributes (color, texture, shape, patterns) to locate images that match a specified query.
Reference: [DG85] <author> D. J. DeWitt and Gerber.R. </author> <title> Multiprocessor hash-based join algorithms. </title> <booktitle> In Proceedings of the 11th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Stockholm, </address> <year> 1985. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort [Men86, LY89, STG + 90, DNS91b] and hash <ref> [DG85, FKT86, SD90] </ref> based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [DKO + 84] <author> D. J. DeWitt, R. H Katz, F. Ohlken, L. D. Shapiro, M. R. Stonebraker, and D. Wood. </author> <title> Implementation techniques for main memory databases. </title> <booktitle> In ACM SIGMOD, </booktitle> <month> July </month> <year> 1984. </year> <note> Also published in/as: UCB, Elec.Res.Lab, Memo No.84-5, Jan.1984. </note>
Reference-contexts: Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. Hence hash join was proposed as a better alternative and has since been enhanced to improve performance <ref> [Bra84, DKO + 84, NKT88, KNT89, Sha86] </ref>. Query processing schemes in commercial products currently use both merge join or hash join. <p> However sort is an expensive operation. Hash indices were already being used for quick access to data [SWKH76, FNPS79]. This sparked interest in hash join schemes as an alternative to merge join schemes <ref> [Bra84, DKO + 84] </ref>. The basic principle is to build an in-memory hash table for the smaller of the join inputs and probe this table for items in the large input. <p> To overcome the memory size limitation while handling large inputs (table size greater than the size of the memory available), the hash join scheme was enhanced into the partition or hybrid hash join schemes <ref> [DKO + 84, NKT88, KNT89, Sha86] </ref> where both inputs are first partitioned into disjoint subsets, and pairs of subsets, one from each relation, are matched using the basic hash join scheme.
Reference: [DLM93] <author> D. DeWitt, D. Lieuwen, and M. Mehta. </author> <title> Pointer-based join techniques for object-oriented databases. </title> <booktitle> In PDIS-93, </booktitle> <address> San Diego, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: The performance of join indices have also been compared with other schemes in [BM90]. This study concludes that join indices are good when the join selectivity is low and updates/appends are not frequent. Join schemes for relational databases have also been adapted for object-oriented database systems <ref> [SC90, DLM93] </ref>. Several issues related to join processing are surveyed in [ME92]. The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes [Gra94, GLS94].
Reference: [DNS91a] <author> D. DeWitt, J. Naughton, and D. Schneider. </author> <title> An evaluation of non-equijoin algorithms. </title> <booktitle> In Proc. Int'l. Conf. on Very Large Data Bases, </booktitle> <pages> pages 443-452, </pages> <year> 1991. </year>
Reference-contexts: This considerably reduces the number of memory accesses, disk accesses and CPU time. Buckets can be created and managed easily if an index like B+ tree exists. The join fields need not be numeric. Our scheme works differently from the partition band join scheme proposed in <ref> [DNS91a] </ref> and is intended for general purpose joins rather than band joins. To handle datasets that do not have indexes, we have also developed extensions to the BSMJ algorithm. We illustrate the use of the BSMJ 1 algorithm for join processing in relational databases and query processing in text databases. <p> The dataset partitioning scheme and the BSMJ algorithm are different from the partition band join <ref> [DNS91a] </ref> scheme. In band joins, the join attribute of the first input should fall in a specified range above or below the values in the join attribute of the other input.
Reference: [DNS91b] <author> D. DeWitt, J. Naughton, and D. Schneider. </author> <title> Parallel sorting on a shared-nothing architecture using probabilistic splitting. </title> <booktitle> In Proc. Int'l. Conf. on Parallel and Distr. Inf. Sys., </booktitle> <address> Miami Beach, FL, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort <ref> [Men86, LY89, STG + 90, DNS91b] </ref> and hash [DG85, FKT86, SD90] based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [FKT86] <author> S. Fushimi, M. Kitsuregawa, and H. Tanaka. </author> <title> An overview of the systems software of a parallel relatational database machine: GRACE". </title> <booktitle> In Proceedings of the 12th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Kyoto, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort [Men86, LY89, STG + 90, DNS91b] and hash <ref> [DG85, FKT86, SD90] </ref> based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [FNPS79] <author> R. Fagin, J. Nievergelt, N. Pippenger, and H. R. </author> <title> Strong. Extendible hashing | A fast access method for dynamic files. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(3), </volume> <month> September </month> <year> 1979. </year> <note> Also published in/as: </note> <institution> IBM, Res.R. RJ2305, Jul.1978. </institution>
Reference-contexts: Since this scheme loads pages from both the inputs sequentially as necessary, it does not require much memory and is also independent of the input sizes. However sort is an expensive operation. Hash indices were already being used for quick access to data <ref> [SWKH76, FNPS79] </ref>. This sparked interest in hash join schemes as an alternative to merge join schemes [Bra84, DKO + 84]. The basic principle is to build an in-memory hash table for the smaller of the join inputs and probe this table for items in the large input.
Reference: [GLS94] <author> G. Graefe, A. Linville, and L. D. Shapiro. </author> <title> Sort versus hash revisited. </title> <journal> IEEE Trans. on Knowledge and Data Eng., </journal> <year> 1994. </year>
Reference-contexts: Several issues related to join processing are surveyed in [ME92]. The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes <ref> [Gra94, GLS94] </ref>. Commercial database products currently support both the merge join and hash join schemes [CHH + 91]. <p> If a leaf split/merge occurs then an additional row is added/deleted in the bucket table and the low and high values of the old and the new nodes are changed accordingly. Handling data skew is an important consideration in join algorithms <ref> [GLS94] </ref>. Since the B+ tree is balanced, in our case data skew does not have an effect on bucket maintenance. Note that the overhead for maintaining buckets via the bucket table is very minimal compared to the cost of maintaining the B+ tree itself. <p> If a match is also found in the third dataset, a match is attempted in the fourth dataset and so on. Notice that there is no need to store the data items in a temporary table. Here data is effectively pipelined from one join to the next <ref> [GLS94] </ref> and we refer to this method as piplelined join in this paper.
Reference: [GP89] <author> D. Gardy and C. Puech. </author> <title> On the effect of join operations on relation sizes. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 14(4), </volume> <month> December </month> <year> 1989. </year>
Reference-contexts: We do not discuss parallelism issues in the rest of the paper since it is orthogonal to the main focus of our work. There has also been a lot of interest in improving buffer management and page fetching schemes for join processing <ref> [MKY81, Chr83, GP89, Omi89] </ref>. The schemes typically try to avoid duplicating page fetches when the pages that are to be brought into memory for performing the join is known. To improve the efficiency of joins, use of special index structures called join indices [Val87] has been studied.
Reference: [Gra94] <author> G. Graefe. Sort-merge-join: </author> <title> An idea whose time has(h) passed? In Proc. </title> <booktitle> IEEE Int'l. Conf. on Data Eng., </booktitle> <pages> page 406, </pages> <address> Houston, TX, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: Several issues related to join processing are surveyed in [ME92]. The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes <ref> [Gra94, GLS94] </ref>. Commercial database products currently support both the merge join and hash join schemes [CHH + 91].
Reference: [HFBYL92] <author> D. Harman, E. Fox, R. Baeza-Yates, and W. Lee. </author> <title> Information Retrieval: Data Structures & Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year> <month> 23 </month>
Reference-contexts: Text Databases Now we discuss the use of the BSMJ algorithm for processing queries in text databases. In text databases, documents are usually retrieved by specifying a set of keywords connected by logical operators like AND and OR <ref> [HFBYL92] </ref>; of these, AND queries are the most popular form of queries in any search system. Since joins are analogous to the AND operation, we focus only on AND queries, i:e:; queries that have AND connectors between the keywords. <p> Although boolean query processing has been used in IR systems, the probabilistic query processing approach has become popular more recently <ref> [HFBYL92] </ref>. Each keyword is associated with an index entry called inverted list, which contains the document IDs of the documents that contain that keyword. During query processing this index entry is used to determine the documents that qualify for a query.
Reference: [HNSS93] <author> P. J. Haas, J. F. Naughton, S. Seshadri, and A. N. Swami. </author> <title> Fixed-precision esti-mation of join selectivity. </title> <booktitle> In Proc. ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Sys., </booktitle> <pages> page 190, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The query optimizer can then choose the BSMJ scheme over the merge join and hash join scheme whenever indexes are available. Even if indexes are not available, if the join selectivity <ref> [HNSS93] </ref> can be determined not to be high, the BSMJ algorithm should be preferred over the hash join scheme.
Reference: [HR96] <author> E.P. Harris and K. Ramamohanarao. </author> <title> Join algorithm costs revisited. </title> <journal> VLDB Journal, </journal> <volume> 5(1), </volume> <month> January </month> <year> 1996. </year>
Reference-contexts: In contrast, our work focuses at a more fundamental level to reduce the number of data items to be considered for join by using ordering information in the datasets. Recently, <ref> [HR96] </ref> has emphasized the need to consider disk seek time, data transfer time and CPU time rather than merely considering the number of I/Os for determining the cost of join processing. Hence accessing all the data items can create a lot of unnecessary overheads.
Reference: [KNT89] <author> M. Kitsuregawa, M. Nakayama, and M. Takagi. </author> <title> The effect of bucket size tuning in the dynamic hybrid GRACE hash join method. </title> <booktitle> In Proceedings of the 15th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Amsterdam, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. Hence hash join was proposed as a better alternative and has since been enhanced to improve performance <ref> [Bra84, DKO + 84, NKT88, KNT89, Sha86] </ref>. Query processing schemes in commercial products currently use both merge join or hash join. <p> To overcome the memory size limitation while handling large inputs (table size greater than the size of the memory available), the hash join scheme was enhanced into the partition or hybrid hash join schemes <ref> [DKO + 84, NKT88, KNT89, Sha86] </ref> where both inputs are first partitioned into disjoint subsets, and pairs of subsets, one from each relation, are matched using the basic hash join scheme.
Reference: [LY89] <author> R. A. Lorie and H. C. Young. </author> <title> A low communication sort algorithm for a parallel database machine. </title> <booktitle> In Proceedings of the 15th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Amsterdam, </address> <month> August </month> <year> 1989. </year> <note> Also published in/as: IBM TR RJ 6669, Feb.1989. </note>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort <ref> [Men86, LY89, STG + 90, DNS91b] </ref> and hash [DG85, FKT86, SD90] based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [ME92] <author> P. Mishra and M. Eich. </author> <title> Join processing in relational databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(1) </volume> <pages> 63-113, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: This study concludes that join indices are good when the join selectivity is low and updates/appends are not frequent. Join schemes for relational databases have also been adapted for object-oriented database systems [SC90, DLM93]. Several issues related to join processing are surveyed in <ref> [ME92] </ref>. The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes [Gra94, GLS94].
Reference: [Men86] <author> J. Menon. </author> <title> A study of sort algorithms for multiprocessor DB machines. </title> <booktitle> In Proceedings of the 12th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Kyoto, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort <ref> [Men86, LY89, STG + 90, DNS91b] </ref> and hash [DG85, FKT86, SD90] based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [MKY81] <author> T. H. Merrett, Y. Kambayashi, and H. Yasura. </author> <title> Scheduling of page-fetches in join operations. </title> <booktitle> In Proceedings of the 7th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kaufman pubs. </publisher> <address> (Los Altos CA), Zaniolo and Delobel(eds), </address> <month> September </month> <year> 1981. </year>
Reference-contexts: We do not discuss parallelism issues in the rest of the paper since it is orthogonal to the main focus of our work. There has also been a lot of interest in improving buffer management and page fetching schemes for join processing <ref> [MKY81, Chr83, GP89, Omi89] </ref>. The schemes typically try to avoid duplicating page fetches when the pages that are to be brought into memory for performing the join is known. To improve the efficiency of joins, use of special index structures called join indices [Val87] has been studied.
Reference: [NKT88] <author> M. Nakayama, M. Kitsuregawa, and M. Takagi. </author> <title> Hash-partitioned join method using dynamic destaging strategy. </title> <booktitle> In Proc. Int'l. Conf. on Very Large Data Bases, </booktitle> <pages> page 468, </pages> <address> Los Angeles, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. Hence hash join was proposed as a better alternative and has since been enhanced to improve performance <ref> [Bra84, DKO + 84, NKT88, KNT89, Sha86] </ref>. Query processing schemes in commercial products currently use both merge join or hash join. <p> To overcome the memory size limitation while handling large inputs (table size greater than the size of the memory available), the hash join scheme was enhanced into the partition or hybrid hash join schemes <ref> [DKO + 84, NKT88, KNT89, Sha86] </ref> where both inputs are first partitioned into disjoint subsets, and pairs of subsets, one from each relation, are matched using the basic hash join scheme.
Reference: [Omi89] <author> Edward R. Omiecinski. </author> <title> Heuristics for join processing using nonclustered indexes. </title> <journal> IEEE Transactions on Software Engineering (SE), ; ACM CR 8912-0899, </journal> <volume> 15(1), </volume> <month> January </month> <year> 1989. </year>
Reference-contexts: We do not discuss parallelism issues in the rest of the paper since it is orthogonal to the main focus of our work. There has also been a lot of interest in improving buffer management and page fetching schemes for join processing <ref> [MKY81, Chr83, GP89, Omi89] </ref>. The schemes typically try to avoid duplicating page fetches when the pages that are to be brought into memory for performing the join is known. To improve the efficiency of joins, use of special index structures called join indices [Val87] has been studied.
Reference: [SC90] <author> E. J. Shekita and M. J. Carey. </author> <title> A performance evaluation of pointer-based joins. </title> <booktitle> In Proc of ACM SIGMOD Conf. on the Management of Data, </booktitle> <address> Atlantic City, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The performance of join indices have also been compared with other schemes in [BM90]. This study concludes that join indices are good when the join selectivity is low and updates/appends are not frequent. Join schemes for relational databases have also been adapted for object-oriented database systems <ref> [SC90, DLM93] </ref>. Several issues related to join processing are surveyed in [ME92]. The issue of which one is the better among merge join and hash join was debated a lot until a recent comprehensive study concluded that there exist dualities between the two schemes [Gra94, GLS94].
Reference: [SD89] <author> D. Schneider and D. DeWitt. </author> <title> A performance evaluation of four parallel join algorithms in a shared-nothing multiprocessor environment. </title> <booktitle> In Proc. ACM SIGMOD Conf., </booktitle> <pages> page 110, </pages> <address> Portland, OR, </address> <month> May-June </month> <year> 1989. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort [Men86, LY89, STG + 90, DNS91b] and hash [DG85, FKT86, SD90] based join schemes. Comparisons of various parallel join schemes has also been performed <ref> [SD89] </ref>. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance. We do not discuss parallelism issues in the rest of the paper since it is orthogonal to the main focus of our work.
Reference: [SD90] <author> D. A. Schneider and D. J. DeWitt. </author> <title> Tradeoffs in processing complex join queries via hashing in multiprocessor database machines. </title> <booktitle> In Proc. Int'l. Conf. on Very Large Data Bases, </booktitle> <pages> page 469, </pages> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort [Men86, LY89, STG + 90, DNS91b] and hash <ref> [DG85, FKT86, SD90] </ref> based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [Sha86] <author> L. D. Shapiro. </author> <title> Join processing in database systems with large main memories. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(3), </volume> <month> October </month> <year> 1986. </year>
Reference-contexts: Both these schemes are expensive since nested loop join performs a lot of disk I/Os and merge join requires sorting of data prior to the join. Hence hash join was proposed as a better alternative and has since been enhanced to improve performance <ref> [Bra84, DKO + 84, NKT88, KNT89, Sha86] </ref>. Query processing schemes in commercial products currently use both merge join or hash join. <p> To overcome the memory size limitation while handling large inputs (table size greater than the size of the memory available), the hash join scheme was enhanced into the partition or hybrid hash join schemes <ref> [DKO + 84, NKT88, KNT89, Sha86] </ref> where both inputs are first partitioned into disjoint subsets, and pairs of subsets, one from each relation, are matched using the basic hash join scheme.
Reference: [STG + 90] <author> B. Salzberg, A. Tsukerman, J. Gray, M. Stewart, S. Uren, and B. Vaughan. Fastsort: </author> <title> An distributed single-input single-output external sort. </title> <booktitle> In Proc. ACM SIGMOD Conf., </booktitle> <pages> page 94, </pages> <address> Atlantic City, NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: With the advent of parallel processing, there has been growing interest in exploiting parallelism for sort <ref> [Men86, LY89, STG + 90, DNS91b] </ref> and hash [DG85, FKT86, SD90] based join schemes. Comparisons of various parallel join schemes has also been performed [SD89]. Just like all other join schemes, parallelism can be exploited for the schemes we are proposing in this paper to achieve better performance.
Reference: [SWKH76] <author> M. Stonebraker, E. Wong, P. Kreps, and G. </author> <title> Held. The design and implementation of INGRES. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 1(3), </volume> <month> September </month> <year> 1976. </year> <note> Also published in/as: UCB, Elec.Res.Lab, Memo No.ERL-M577, Jan.1976. </note>
Reference-contexts: Since this scheme loads pages from both the inputs sequentially as necessary, it does not require much memory and is also independent of the input sizes. However sort is an expensive operation. Hash indices were already being used for quick access to data <ref> [SWKH76, FNPS79] </ref>. This sparked interest in hash join schemes as an alternative to merge join schemes [Bra84, DKO + 84]. The basic principle is to build an in-memory hash table for the smaller of the join inputs and probe this table for items in the large input.
Reference: [Val87] <author> Patrick Valduriez. </author> <title> Join indices. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(2), </volume> <month> June </month> <year> 1987. </year> <month> 24 </month>
Reference-contexts: The schemes typically try to avoid duplicating page fetches when the pages that are to be brought into memory for performing the join is known. To improve the efficiency of joins, use of special index structures called join indices <ref> [Val87] </ref> has been studied. The elements of a join index are tuples that store the surrogate (tuple ID) pairs of the tuples which match on the join attribute. However when the database is appended frequently, join indexes incur a lot of overheads.
References-found: 35

