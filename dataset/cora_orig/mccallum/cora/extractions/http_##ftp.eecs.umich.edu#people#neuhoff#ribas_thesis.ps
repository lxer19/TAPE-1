URL: http://ftp.eecs.umich.edu/people/neuhoff/ribas_thesis.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/
Root-URL: http://www.eecs.umich.edu
Title: OPTIMIZING THE MOTION VECTOR ACCURACIES IN BLOCK-BASED VIDEO CODING  
Author: by Jordi Ribas-Corbera Associate Professor Alfred O. Hero III 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Doctoral Committee: Professor David L. Neuhoff, Chair Assistant Professor Jeffrey A. Fessler  Assistant Professor Sang W. Lee Professor Matthew O'Donnell  
Date: 1996  
Affiliation: (Electrical Engineering: Systems) in The University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 144 145 BIBLIOGRAPHY </institution>
Reference: [1] <author> A. Netravali and B. </author> <title> Haskell, Digital pictures. Representation and Compression, </title> <publisher> Plenum Press, </publisher> <year> 1988. </year>
Reference-contexts: For example, only 2 minutes of VHS-quality digital video occupy about one gigabyte (8 10 9 bits), the equivalent total memory in one of today's top-of-the-line personal computers. As a result, the efficient coding or compression of digital video has become a major topic of research <ref> [1, 2, 3] </ref>. In recent years, a wide variety of video coding strategies have been proposed and a joint effort between industry and academia has lead to video coding standards such as MPEG [6] and H.263 [9]. <p> However, if there is significant motion in the video scene (e.g., moving objects, camera panning, etc.), the correlation among successive frames is reduced. To compensate for this effect, advanced video coders estimate and use motion parameters to improve the prediction of the current frame <ref> [1, 2, 3] </ref>. Then, the difference frame and the motion parameters must be encoded with bits. <p> video coders that achieve high levels of compression without being too computationally complex. 1.3 The Bit Allocation Problem in Block-based Video Cod ing: Finding the Optimal Motion Vector Accuracies Block-based video coders have become widely popular in industry and academia because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], and H.261 [7, 8] are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> Finally, Section 2.8 presents the conclusions for this chapter. For additional background information, the early work in video coding is reviewed in a paper by Musmann et al. [5] and in several books on image processing and compression <ref> [1, 2] </ref>. More recent books [3, 4] tend to focus more on current coding techniques. 2.1 Video Coding with and without Motion Compensation In Section 1.2 of the introduction, we motivated the use of motion parameters for the efficient (lossless or lossy) encoding of digital video. <p> Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders. As a result, there has been much interest in trying to understand the best ways to estimate and use motion parameters to reduce the bit rate <ref> [1, 2, 3, 4] </ref>. Many types of motion-compensation methods and motion and difference frame coders have been studied in the literature, but the tradeoffs that appear with the introduction of motion information are difficult to model mathematically and are usually not analyzed. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 [7, 8] and H.263 [9] are all of this type. <p> Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements <ref> [40, 1, 2, 3, 4] </ref>. This technique is particularly appropriate for block-based video coders because in this type of coding all of the pixels in an image block are assumed to move with the same velocity, indicated by a motion vector.
Reference: [2] <author> A.K. Jain, </author> <title> Fundamentals of digital image processing, </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: For example, only 2 minutes of VHS-quality digital video occupy about one gigabyte (8 10 9 bits), the equivalent total memory in one of today's top-of-the-line personal computers. As a result, the efficient coding or compression of digital video has become a major topic of research <ref> [1, 2, 3] </ref>. In recent years, a wide variety of video coding strategies have been proposed and a joint effort between industry and academia has lead to video coding standards such as MPEG [6] and H.263 [9]. <p> However, if there is significant motion in the video scene (e.g., moving objects, camera panning, etc.), the correlation among successive frames is reduced. To compensate for this effect, advanced video coders estimate and use motion parameters to improve the prediction of the current frame <ref> [1, 2, 3] </ref>. Then, the difference frame and the motion parameters must be encoded with bits. <p> video coders that achieve high levels of compression without being too computationally complex. 1.3 The Bit Allocation Problem in Block-based Video Cod ing: Finding the Optimal Motion Vector Accuracies Block-based video coders have become widely popular in industry and academia because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], and H.261 [7, 8] are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> Finally, Section 2.8 presents the conclusions for this chapter. For additional background information, the early work in video coding is reviewed in a paper by Musmann et al. [5] and in several books on image processing and compression <ref> [1, 2] </ref>. More recent books [3, 4] tend to focus more on current coding techniques. 2.1 Video Coding with and without Motion Compensation In Section 1.2 of the introduction, we motivated the use of motion parameters for the efficient (lossless or lossy) encoding of digital video. <p> A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. Not surprisingly, early video coding methods such as frame repetition, resolution exchange, conditional replenishment and adaptive predictive coding do not use motion information <ref> [2] </ref>. For example, conditional replenishment detects and encodes only the regions of a frame that present significant intensity changes respect to the previous frame. <p> Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders. As a result, there has been much interest in trying to understand the best ways to estimate and use motion parameters to reduce the bit rate <ref> [1, 2, 3, 4] </ref>. Many types of motion-compensation methods and motion and difference frame coders have been studied in the literature, but the tradeoffs that appear with the introduction of motion information are difficult to model mathematically and are usually not analyzed. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 [7, 8] and H.263 [9] are all of this type. <p> Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements <ref> [40, 1, 2, 3, 4] </ref>. This technique is particularly appropriate for block-based video coders because in this type of coding all of the pixels in an image block are assumed to move with the same velocity, indicated by a motion vector.
Reference: [3] <author> R.J. Clarke, </author> <title> Digital compression of still images and video, </title> <publisher> Academic Press, </publisher> <year> 1995. </year>
Reference-contexts: For example, only 2 minutes of VHS-quality digital video occupy about one gigabyte (8 10 9 bits), the equivalent total memory in one of today's top-of-the-line personal computers. As a result, the efficient coding or compression of digital video has become a major topic of research <ref> [1, 2, 3] </ref>. In recent years, a wide variety of video coding strategies have been proposed and a joint effort between industry and academia has lead to video coding standards such as MPEG [6] and H.263 [9]. <p> However, if there is significant motion in the video scene (e.g., moving objects, camera panning, etc.), the correlation among successive frames is reduced. To compensate for this effect, advanced video coders estimate and use motion parameters to improve the prediction of the current frame <ref> [1, 2, 3] </ref>. Then, the difference frame and the motion parameters must be encoded with bits. <p> video coders that achieve high levels of compression without being too computationally complex. 1.3 The Bit Allocation Problem in Block-based Video Cod ing: Finding the Optimal Motion Vector Accuracies Block-based video coders have become widely popular in industry and academia because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], and H.261 [7, 8] are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> Finally, Section 2.8 presents the conclusions for this chapter. For additional background information, the early work in video coding is reviewed in a paper by Musmann et al. [5] and in several books on image processing and compression [1, 2]. More recent books <ref> [3, 4] </ref> tend to focus more on current coding techniques. 2.1 Video Coding with and without Motion Compensation In Section 1.2 of the introduction, we motivated the use of motion parameters for the efficient (lossless or lossy) encoding of digital video. <p> Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders. As a result, there has been much interest in trying to understand the best ways to estimate and use motion parameters to reduce the bit rate <ref> [1, 2, 3, 4] </ref>. Many types of motion-compensation methods and motion and difference frame coders have been studied in the literature, but the tradeoffs that appear with the introduction of motion information are difficult to model mathematically and are usually not analyzed. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity <ref> [1, 2, 3] </ref>. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 [7, 8] and H.263 [9] are all of this type. <p> Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements <ref> [40, 1, 2, 3, 4] </ref>. This technique is particularly appropriate for block-based video coders because in this type of coding all of the pixels in an image block are assumed to move with the same velocity, indicated by a motion vector.
Reference: [4] <author> V. Bhaskaran, K. Konstantinides, </author> <title> Image and Video Compression Standards. Algorithms and Architectures, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Finally, Section 2.8 presents the conclusions for this chapter. For additional background information, the early work in video coding is reviewed in a paper by Musmann et al. [5] and in several books on image processing and compression [1, 2]. More recent books <ref> [3, 4] </ref> tend to focus more on current coding techniques. 2.1 Video Coding with and without Motion Compensation In Section 1.2 of the introduction, we motivated the use of motion parameters for the efficient (lossless or lossy) encoding of digital video. <p> The benefit of investing bits in motion is that the sum of motion bits plus those used to describe the difference frame is significantly less than the number required to describe the difference frame obtained without motion compensation. The positive results obtained by theoretical studies on motion compensation <ref> [4, 55] </ref> and the widespread success in industry of motion-compensated video coders [6, 7, 8, 9, 10] are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. <p> Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders. As a result, there has been much interest in trying to understand the best ways to estimate and use motion parameters to reduce the bit rate <ref> [1, 2, 3, 4] </ref>. Many types of motion-compensation methods and motion and difference frame coders have been studied in the literature, but the tradeoffs that appear with the introduction of motion information are difficult to model mathematically and are usually not analyzed. <p> Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements <ref> [40, 1, 2, 3, 4] </ref>. This technique is particularly appropriate for block-based video coders because in this type of coding all of the pixels in an image block are assumed to move with the same velocity, indicated by a motion vector.
Reference: [5] <author> H.G. Musmann, P. Pirsch, and H. Grallert, </author> <title> "Advances in picture coding", </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 73, </volume> <pages> pp. 523-548, </pages> <month> Apr. </month> <year> 1985. </year>
Reference-contexts: Finally, Section 2.8 presents the conclusions for this chapter. For additional background information, the early work in video coding is reviewed in a paper by Musmann et al. <ref> [5] </ref> and in several books on image processing and compression [1, 2].
Reference: [6] <author> D. Le Gall, </author> <title> "MPEG: A video compression standard for multimedia applications," </title> <journal> Commun. ACM, </journal> <volume> Vol. 34, </volume> <pages> pp. 47-58, </pages> <month> Apr. 91. </month>
Reference-contexts: In recent years, a wide variety of video coding strategies have been proposed and a joint effort between industry and academia has lead to video coding standards such as MPEG <ref> [6] </ref> and H.263 [9]. Remarkably, the appearance of the first digital video products based on these standards has further increased the appetite for compression in industry. <p> In fact, the recent video coding standards MPEG <ref> [6] </ref>, MPEG-2 [10], and H.261 [7, 8] are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. The block size is the same for all of the blocks in the image. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> In Chapter V we follow a similar approach to obtain rate expressions for more interesting, lossy video coders, in which the motion vectors are encoded with DPCM and variable-length coding and the difference frame is encoded with either scalar quantization plus entropy coding or transform coding (as in MPEG <ref> [6] </ref>). The rate expressions obtained for these lossless and lossy coders are the first that indicate the effect of the block's motion vector accuracies on the total encoding rate, and could potentially be generalized to other types of video coders. <p> The positive results obtained by theoretical studies on motion compensation [4, 55] and the widespread success in industry of motion-compensated video coders <ref> [6, 7, 8, 9, 10] </ref> are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity [1, 2, 3]. In fact, the recent video coding standards MPEG <ref> [6] </ref>, MPEG-2 [10], H.261 [7, 8] and H.263 [9] are all of this type. As a result, these coders are used in a wide variety of applications for a wide range of bit rates, such as in multimedia, video conferencing and HDTV. <p> In this work we only use the (decoded) previous frame as the reference for simplicity, but other frames could be used. For example, MPEG <ref> [6] </ref> can use a past or future frame, or a linear combination of both, as the reference, on a block-by-block basis. The process to create a prediction is illustrated in Figure 2.2. Specifically, this process can be described as follows: 1. <p> Studies have shown that losslessly encoding the quantized motion vectors f ^ V i g with predictive coding techniques produces good results [38]. (Lossy coding of the motion vectors has also been considered [39].) For example, in MPEG <ref> [6] </ref> the previous motion vector (in a raster scan order) is used to predict the value of the current vector, and the prediction error is encoded with a simple variable-length coder. The performance of the motion vector coder is measured by the motion rate R D . <p> Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets [41, 42]. Current standards have selected the DCT coding approach <ref> [6, 7, 8, 9, 10] </ref>. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> To confirm this, we implement video coders with two types of difference frame coding: uniform scalar quantization with entropy coding (for which our analysis is based) and DCT coding (similar to MPEG's <ref> [6] </ref>). In Section 5.8 we present experimental results on a wide variety of video sequences. Our results include rate-distortion curves for the typical motion vector accuracies (1 and 1/2 pixel) and for our optimal accuracies, and rate-accuracy curves for several levels of distortion. <p> In fact, this technique is adopted by the current video coding standards <ref> [6, 7, 8, 9, 10] </ref>. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order. <p> For example, MPEG <ref> [6] </ref> uses a block-by-block DCT, which gives better rate-distortion performance and also exploits the response of the human visual system. The rates of those more advanced coders are expected to be lower than those of "Coder 1" by approximately a constant. <p> To confirm this, we implemented a second coder that uses a block-by-block DCT coder for the difference frame and hence this new block-based video coder is similar to MPEG <ref> [6] </ref>. We refer to this coder as "Coder 2". 5.8 Experimental Results We present results of the performance of our two video coders on synthetic and real video sequences. The two synthetic sequences "low texture" and "high texture" are a moving low-frequency and high-frequency sinusoids, respectively. <p> These figures illustrate how the curves change depending on scene texture and compression level. "Coder 2" at a PSNR (5.7) of approximately 33 dB (accordingly, we used Q = 20 in our formulas). Every fifth frame was intracoded by a JPEG coder [65] (as in MPEG <ref> [6] </ref>) at the same distortion and its rate is not included in the results. <p> In Section 6.4, we implement two video coders with different types of difference frame coding: uniform scalar quantization with entropy coding (for which our analysis is based) and DCT coding similar to MPEG's <ref> [6] </ref> (for which our block-adaptive method can also be used), and present experimental results on real video sequences. <p> For example, MPEG <ref> [6] </ref> uses a block-by-block DCT, which gives better rate-distortion performance and also exploits the response of the human visual system. 112 The rates of those more advanced coders are expected to be lower than that of "Coder 1" by a constant, as we explained in Section 5.7. <p> To confirm this, we implemented a second coder that uses a block-by-block DCT coder for the difference frame and hence this new block-based video coder is similar to MPEG <ref> [6] </ref>. We refer to this coder as "Coder 2". 6.4 Experimental Results We present results of the performance of our two video coders "Coder 1" and "Coder 2" on synthetic and real video sequences. <p> This property is exploited in transform coding of images <ref> [40, 6] </ref>. Here, it indicates that the product w x;m w y;m will be zero or very small, because the dominant sinc's will commonly be either on the f x axis or on the f y axis.
Reference: [7] <author> M. Liou, </author> <title> "Overview of the px64 kbit/s video coding standard," </title> <journal> Commun. ACM, </journal> <volume> Vol. 34, </volume> <pages> pp. 59-63, </pages> <month> Apr. 91. </month>
Reference-contexts: In fact, the recent video coding standards MPEG [6], MPEG-2 [10], and H.261 <ref> [7, 8] </ref> are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. The block size is the same for all of the blocks in the image. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> The positive results obtained by theoretical studies on motion compensation [4, 55] and the widespread success in industry of motion-compensated video coders <ref> [6, 7, 8, 9, 10] </ref> are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity [1, 2, 3]. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 <ref> [7, 8] </ref> and H.263 [9] are all of this type. As a result, these coders are used in a wide variety of applications for a wide range of bit rates, such as in multimedia, video conferencing and HDTV. <p> Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets [41, 42]. Current standards have selected the DCT coding approach <ref> [6, 7, 8, 9, 10] </ref>. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> In fact, this technique is adopted by the current video coding standards <ref> [6, 7, 8, 9, 10] </ref>. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order.
Reference: [8] <author> ITU-T Recommendations H.261, </author> <title> Video Codec for Audiovisual Services at px64 Kbits. </title>
Reference-contexts: In fact, the recent video coding standards MPEG [6], MPEG-2 [10], and H.261 <ref> [7, 8] </ref> are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. The block size is the same for all of the blocks in the image. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> The positive results obtained by theoretical studies on motion compensation [4, 55] and the widespread success in industry of motion-compensated video coders <ref> [6, 7, 8, 9, 10] </ref> are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity [1, 2, 3]. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 <ref> [7, 8] </ref> and H.263 [9] are all of this type. As a result, these coders are used in a wide variety of applications for a wide range of bit rates, such as in multimedia, video conferencing and HDTV. <p> Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets [41, 42]. Current standards have selected the DCT coding approach <ref> [6, 7, 8, 9, 10] </ref>. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> In fact, this technique is adopted by the current video coding standards <ref> [6, 7, 8, 9, 10] </ref>. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order.
Reference: [9] <author> ITU-T/SG15, </author> <title> Video codec test model, </title> <journal> TMN5, Telenor Research, </journal> <month> Jan. 95. </month>
Reference-contexts: In recent years, a wide variety of video coding strategies have been proposed and a joint effort between industry and academia has lead to video coding standards such as MPEG [6] and H.263 <ref> [9] </ref>. Remarkably, the appearance of the first digital video products based on these standards has further increased the appetite for compression in industry. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> The positive results obtained by theoretical studies on motion compensation [4, 55] and the widespread success in industry of motion-compensated video coders <ref> [6, 7, 8, 9, 10] </ref> are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity [1, 2, 3]. In fact, the recent video coding standards MPEG [6], MPEG-2 [10], H.261 [7, 8] and H.263 <ref> [9] </ref> are all of this type. As a result, these coders are used in a wide variety of applications for a wide range of bit rates, such as in multimedia, video conferencing and HDTV. <p> For example, overlapped motion compensation [16] uses several neighboring blocks to reduce the prediction error and these artifacts, and has been adopted in the recent (block-based) standard for very low bit rates H.263 <ref> [9] </ref>. In this thesis, we focus on optimizing the performance of block-based video coders mainly because of their popularity and good encoding performance for a wide variety of bit rates. <p> Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets [41, 42]. Current standards have selected the DCT coding approach <ref> [6, 7, 8, 9, 10] </ref>. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> In fact, this technique is adopted by the current video coding standards <ref> [6, 7, 8, 9, 10] </ref>. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order.
Reference: [10] <author> S. Eckart and C. Fogg, </author> <title> "ISO/IEC MPEG-2 software video codec," </title> <booktitle> Proc. SPIE Dig. Video Compr.: Alg. and Tech. </booktitle> <year> 1995, </year> <pages> pp. 100-109, </pages> <address> San Jose, </address> <month> Feb. 95. </month>
Reference-contexts: In fact, the recent video coding standards MPEG [6], MPEG-2 <ref> [10] </ref>, and H.261 [7, 8] are all of this type. In block-based video coding, motion-compensation is done by assigning a displacement or motion vector to every image block in the current frame. The block size is the same for all of the blocks in the image. <p> In fact, the number of bits allocated to the motion vectors in block-based video coding is based on heuristics and empirical experiments, and typically is just large enough to encode the motion vectors with =1 or =1/2 pixel accuracy (i.e., 1 or 1/2 the pixel spacing, respectively) <ref> [1, 2, 3, 6, 7, 8, 9, 10] </ref>. All vectors are ordinarily encoded with the same accuracy. <p> The positive results obtained by theoretical studies on motion compensation [4, 55] and the widespread success in industry of motion-compensated video coders <ref> [6, 7, 8, 9, 10] </ref> are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. A problem with motion compensation is that the estimation of the motion parameters is usually com-putationally expensive. <p> Block-based video coders have become widely popular because of their good coding performance and relatively low complexity [1, 2, 3]. In fact, the recent video coding standards MPEG [6], MPEG-2 <ref> [10] </ref>, H.261 [7, 8] and H.263 [9] are all of this type. As a result, these coders are used in a wide variety of applications for a wide range of bit rates, such as in multimedia, video conferencing and HDTV. <p> Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets [41, 42]. Current standards have selected the DCT coding approach <ref> [6, 7, 8, 9, 10] </ref>. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> In fact, this technique is adopted by the current video coding standards <ref> [6, 7, 8, 9, 10] </ref>. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order.
Reference: [11] <author> D. Taubman and A. Zakhor, </author> <title> "Multi-rate 3-D subband coding of video," </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> Vol. 3, </volume> <pages> pp. 572-588, </pages> <month> Sept. 94. </month>
Reference-contexts: Fortunately, today's computers and DSP processors can compute high-quality motion parameters in real time and complexity is becoming less of an issue. Recently, scalable video coders based on 3-D subband coding that do not use motion compensation have been proposed in the literature <ref> [11, 12] </ref>. These subband coders can easily adapt to lower bit rates by dropping the high frequency components of the video data.
Reference: [12] <author> D. Taubman and A. Zakhor, </author> <title> "A common framework for rate and distortion based scaling of highly scalable compressed video," </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> Vol. 6, </volume> <pages> pp. 329-354, </pages> <month> Aug. 96. </month>
Reference-contexts: Fortunately, today's computers and DSP processors can compute high-quality motion parameters in real time and complexity is becoming less of an issue. Recently, scalable video coders based on 3-D subband coding that do not use motion compensation have been proposed in the literature <ref> [11, 12] </ref>. These subband coders can easily adapt to lower bit rates by dropping the high frequency components of the video data.
Reference: [13] <author> T. Naveen and J.W. Woods, </author> <title> "Motion compensated multiresolution transmission of high definition video", </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> Vol. 4, </volume> <pages> pp. 29-41, </pages> <month> Feb. 94. </month>
Reference-contexts: However, scalable video coders that use motion compensation have also shown some promise for these adaptive environments and are also being considered <ref> [13, 14] </ref>. 2.2 Motion-Compensated Video Coding: Object-Based Cod ing vs. Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders.
Reference: [14] <author> M. Nakamura and K. Sawada, </author> <title> "Scalable coding schemes based on DCT and MC Prediction," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 2, </volume> <pages> pp. 575-578, </pages> <address> Washington, D.C., </address> <month> Oct. </month> <pages> 95. 146 </pages>
Reference-contexts: However, scalable video coders that use motion compensation have also shown some promise for these adaptive environments and are also being considered <ref> [13, 14] </ref>. 2.2 Motion-Compensated Video Coding: Object-Based Cod ing vs. Block-Based Coding In general, motion-compensated coders have demonstrated superior coding performance and are by far the most popular type of video coders.
Reference: [15] <author> J.G. Apostolopoulos, P.A. Monta, J.J. Nicolas and J.S. Lim, </author> <title> "Designing a video compression system for high definition television," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 110-113, </pages> <address> Minneapolis, </address> <month> Apr. 93. </month>
Reference: [16] <author> M.T. Orchard and G. Sullivan, </author> <title> "Overlapped block motion compensation: an estimation-theoretic approach," </title> <journal> IEEE Trans. Image Processing, </journal> <volume> Vol. 3, </volume> <pages> pp. 693-699, </pages> <month> Sept. 94. </month>
Reference-contexts: But block-based coders can still compete at low bit rates if the blocking artifacts are somehow reduced. For example, overlapped motion compensation <ref> [16] </ref> uses several neighboring blocks to reduce the prediction error and these artifacts, and has been adopted in the recent (block-based) standard for very low bit rates H.263 [9].
Reference: [17] <author> H.G. Musmann, </author> <title> "Object-oriented analysis-synthesis coding based on source models of moving 2D- and 3D-objects", </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 99-102, </pages> <address> Minneapolis, </address> <month> Apr. 93. </month>
Reference-contexts: F F F F ... ... &lt; 64 Kbits/sec (very low bit rate) Block parameters at each F - Block motion - Block prediction error Encode: 17 to an object model with parameters for shape, location, and texture information <ref> [18, 19, 17] </ref>. The parameters of the model for each object are sent to the receiver, where each frame is synthesized from the decoded object parameters.
Reference: [18] <author> M. Hotter, </author> <title> "Object-oriented analysis-synthesis coding based on moving two-dimensional objects", Signal Processing: </title> <journal> Image Communication, </journal> <volume> Vol. 2, </volume> <pages> pp. 409-428, </pages> <year> 1990. </year>
Reference-contexts: F F F F ... ... &lt; 64 Kbits/sec (very low bit rate) Block parameters at each F - Block motion - Block prediction error Encode: 17 to an object model with parameters for shape, location, and texture information <ref> [18, 19, 17] </ref>. The parameters of the model for each object are sent to the receiver, where each frame is synthesized from the decoded object parameters.
Reference: [19] <author> M. Hotter, </author> <title> "Optimization and efficiency of an object-oriented analysis-synthesis coder," </title> <journal> IEEE Trans. Cir. and Syst. Video Tech., </journal> <volume> Vol. 4, </volume> <pages> pp. 181-194, </pages> <month> Apr. 94. </month>
Reference-contexts: Ito and Farvardin [58] performed a simple analysis of difference frame energy in the context of subband coding, which was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. In another interesting work, Hotter <ref> [19] </ref> designed an advanced object-oriented coder and found the best accuracy of a fixed set using empirical experiments. 1.4 Our Contribution In this dissertation, we perform an analysis of the fundamental tradeoff between motion and difference frame bits in block-based video coding, and derive a theoretical framework that makes it possible <p> F F F F ... ... &lt; 64 Kbits/sec (very low bit rate) Block parameters at each F - Block motion - Block prediction error Encode: 17 to an object model with parameters for shape, location, and texture information <ref> [18, 19, 17] </ref>. The parameters of the model for each object are sent to the receiver, where each frame is synthesized from the decoded object parameters. <p> In other related work, Ito and Farvardin [58] performed a simple analysis of difference frame energy in the context of subband coding, which did not contribute rate or energy models, but was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. Recently, Hotter <ref> [19] </ref> designed an advanced object-oriented coder and found the best (classical) motion accuracy within a given set of accuracies using empirical experiments. 2.8 Conclusions In this chapter, we reviewed background material on motion-compensated video coding with an emphasis on block-based video coding. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>, as we mentioned in Chapter II. <p> Also, larger blocks will require higher motion vector accuracies if the texture increase in the blocks is superior to the increase of the noise floor. Some of these relationships have previously been observed <ref> [19, 56, 21, 58] </ref>. For example, Girod's study [56] indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin [58] showed that higher frequency images 101 required higher motion vector accuracies.
Reference: [20] <author> J. Ostermann, </author> <title> "Differences between an object-based analysis-synthesis coder and a block-based hybrid coder," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 2, </volume> <pages> pp. 398-401, </pages> <address> Wash-ington, D.C., </address> <month> Oct. 95. </month>
Reference-contexts: Object-based video coders are currently designed for applications in the 15 range of 10-30 kilobits per second. In general, these coders are more complex than block-based coders, but do not introduce blocking artifacts at those very low bit rates (see Ostermann <ref> [20] </ref> for a recent comparison). But block-based coders can still compete at low bit rates if the blocking artifacts are somehow reduced.
Reference: [21] <author> B. Girod, </author> <title> "Rate-constrained motion compensation," </title> <booktitle> Proc. SPIE Visual Com-mun. and Image Proc., </booktitle> <pages> pp. 1026-1034, </pages> <address> Chicago, </address> <month> Sept. 94. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>, as we mentioned in Chapter II. <p> Also, larger blocks will require higher motion vector accuracies if the texture increase in the blocks is superior to the increase of the noise floor. Some of these relationships have previously been observed <ref> [19, 56, 21, 58] </ref>. For example, Girod's study [56] indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin [58] showed that higher frequency images 101 required higher motion vector accuracies. <p> Based on these analyses and empirical experiments, some heuristic conclusions on the best motion vector accuracies have been taken and used in the design of video coders. For example, Girod chooses to encode the motion vectors with either 1/2 pixel or 1/4 pixel accuracy <ref> [56, 21] </ref>. Those may be good choices for a variety of scenes, but our equations and results indicate that lower accuracies can be good enough for low textured frames encoded at large distortion, and higher accuracies are better for high textured images at low distortion.
Reference: [22] <author> N. Diehl, </author> <title> "Object-oriented motion estimation and segmentation in image sequences," Signal Processing: </title> <journal> Image Communication, </journal> <volume> Vol. 3, </volume> <pages> pp. 23-56, </pages> <month> Feb. 91. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions.
Reference: [23] <author> H. Zheng and S.D. </author> <title> Blostein "Application of the minimum description length principle to object-oriented video image compression," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 2, </volume> <pages> pp. 400-404, </pages> <address> Austin, </address> <month> Oct. 94. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [24] <author> P. Strobach, </author> <title> "Tree-structured scene adaptive coder," </title> <journal> IEEE Trans. Communications, </journal> <volume> Vol. 38, </volume> <month> Apr. 90. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [25] <author> G. J. Sullivan and R.L. Baker, </author> <title> "Rate-distortion optimized motion compensation for video compression using fixed or variable size blocks," </title> <booktitle> Proc. GLOBECOM, </booktitle> <pages> pp. 85-90, </pages> <month> Nov. 91 </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [26] <author> G. J. Sullivan and R.L. Baker, </author> <title> "Efficient quadtree coding of images and video," </title> <journal> IEEE Trans. Image Processing, </journal> <volume> Vol. 3, </volume> <pages> pp. 327-331, </pages> <month> May 94. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [27] <author> J. Lee, </author> <title> "Optimal quadtree for variable block size motion estimation," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 3, </volume> <pages> pp. 480-483, </pages> <address> Washington, D.C., </address> <month> Oct. 95. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [28] <author> G.R. Martin, R.A. Packwood, I. Rhee, </author> <title> "Variable size block matching motion estimation with minimal error," </title> <booktitle> Proc. SPIE Dig. Video Compr.: Alg. and Tech., </booktitle> <pages> pp. 324-333, </pages> <address> San Jose, Jan-Feb 96. </address> <month> 147 </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [29] <author> G.M. Schuster and A.K. Katsaggelos, </author> <title> "A video compression scheme with optimal bit allocation between displacement vector field and displaced frame difference," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 4, </volume> <pages> pp. 1967-1970, </pages> <address> Atlanta, </address> <month> May 96. </month>
Reference-contexts: This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding.
Reference: [30] <author> K. Aizawa and T.S. Huang, </author> <title> "Model-based image coding: Advanced video coding techniques for very low bit-rate applications," </title> <journal> Proc. of the IEEE: </journal> <note> Special Issue on Digital Television, </note> <author> (Y.-Q. Zhang, W. Li, </author> <title> and M.L. Liou, </title> <editor> eds.), </editor> <volume> Vol. 83, </volume> <pages> pp. 259-271, </pages> <month> Feb. 95. </month>
Reference-contexts: These coders are often more complex than block-based coders but have shown superior results particularly at low bit rates. Wire-frame or model-based video coders are becoming popular for video telephone <ref> [30, 31, 32] </ref>. These techniques fit a generic wire-frame to a subject's head and shoulders using either several images or range data obtained by a 3D scanner.
Reference: [31] <author> C.S. Choi, K. Aizawa, H. Harashima and T. Takebe, </author> <title> "Analysis and synthesis of facial image sequences in model-based image coding," </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> Vol. 4, </volume> <pages> pp. 257-275, </pages> <month> June 94. </month>
Reference-contexts: These coders are often more complex than block-based coders but have shown superior results particularly at low bit rates. Wire-frame or model-based video coders are becoming popular for video telephone <ref> [30, 31, 32] </ref>. These techniques fit a generic wire-frame to a subject's head and shoulders using either several images or range data obtained by a 3D scanner.
Reference: [32] <author> L. Strub and J. Robinson, </author> <title> "Automated facial conformation for model-based videophone coding," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 2, </volume> <pages> pp. 587-590, </pages> <address> Washington, D.C., </address> <month> Oct. 95. </month>
Reference-contexts: These coders are often more complex than block-based coders but have shown superior results particularly at low bit rates. Wire-frame or model-based video coders are becoming popular for video telephone <ref> [30, 31, 32] </ref>. These techniques fit a generic wire-frame to a subject's head and shoulders using either several images or range data obtained by a 3D scanner.
Reference: [33] <author> Y. Nakaya, and H. Harashima, </author> <title> "Motion compensation based on spatial transformations," </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> Vol. 4, </volume> <pages> pp. 339-356, </pages> <month> June 94. </month>
Reference-contexts: Mesh-based video coders are similar to model-based video coders in that they use a wire-frame model but only in two-dimensions and typically compute and encode the difference frames <ref> [33, 34] </ref>. Another interesting video compression technique is interframe interpolation. With this technique, only a subset of the video frames are encoded and sent to the receiver, and the skipped frames are reconstructed by interpolation at the decoder using the remaining frames.
Reference: [34] <author> Y. Altunbasak, A.M. Tekalp, and G. Bozdagi, </author> <title> "Two-dimensional object-based coding using a content-based mesh and affine motion parameterization," </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 2, </volume> <pages> pp. 394-397, </pages> <address> Washington, D.C., </address> <month> Oct. 95. </month>
Reference-contexts: Mesh-based video coders are similar to model-based video coders in that they use a wire-frame model but only in two-dimensions and typically compute and encode the difference frames <ref> [33, 34] </ref>. Another interesting video compression technique is interframe interpolation. With this technique, only a subset of the video frames are encoded and sent to the receiver, and the skipped frames are reconstructed by interpolation at the decoder using the remaining frames.
Reference: [35] <author> C. Cafforio, F. Rocca, and S. Tubaro, </author> <title> "Motion compensated image interpolation", </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. 38, no. 2, </volume> <pages> pp. 215-222, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: This technique has shown some interesting results for video scenes with low motion and nearly stationary background <ref> [35, 36, 37] </ref>. 2.4 Block-Based Video Coders In block-based video coders, a prediction for the current frame to be encoded is formed by decomposing the current frame into blocks and replacing these blocks by their best matches in a reference frame. <p> This field is called the optical flow of the frame, and the motion vectors indicate how the image pixels moved or shifted to their locations either in a past frame (backward optical flow) or in a future frame (forward optical flow) <ref> [35] </ref>. Estimating motion in video sequences has applications in many areas such as object tracking and recognition, robot vision, medical angiography, and video 24 compression, to name a few. As a result, many motion estimation techniques have been proposed in the literature [43, 44, 45].
Reference: [36] <author> R. Thoma and M. Bierling, </author> <title> "Motion compensating interpolation considering covered and uncovered background", Signal Processing: </title> <journal> Image Communication, </journal> <volume> Vol. 1, </volume> <pages> pp. 191-212, </pages> <year> 1989. </year>
Reference-contexts: This technique has shown some interesting results for video scenes with low motion and nearly stationary background <ref> [35, 36, 37] </ref>. 2.4 Block-Based Video Coders In block-based video coders, a prediction for the current frame to be encoded is formed by decomposing the current frame into blocks and replacing these blocks by their best matches in a reference frame.
Reference: [37] <author> J. Ribas-Corbera and J. Sklansky, </author> <title> "Interframe interpolation of cinematic sequences", </title> <journal> Journal of Visual Communications and Image Representation, </journal> <volume> vol. 4, No. 4, </volume> <pages> pp. 392-406, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: This technique has shown some interesting results for video scenes with low motion and nearly stationary background <ref> [35, 36, 37] </ref>. 2.4 Block-Based Video Coders In block-based video coders, a prediction for the current frame to be encoded is formed by decomposing the current frame into blocks and replacing these blocks by their best matches in a reference frame.
Reference: [38] <author> P. Guillotel and C. Chevance, </author> <title> "Comparison of motion vector coding techniques," </title> <booktitle> Proc. SPIE Visual Commun. and Image Proc., </booktitle> <pages> pp. 1594-1604, </pages> <address> Chicago, </address> <month> Sept. 94. </month>
Reference-contexts: Studies have shown that losslessly encoding the quantized motion vectors f ^ V i g with predictive coding techniques produces good results <ref> [38] </ref>. (Lossy coding of the motion vectors has also been considered [39].) For example, in MPEG [6] the previous motion vector (in a raster scan order) is used to predict the value of the current vector, and the prediction error is encoded with a simple variable-length coder. <p> Our experimental results indicate that more advanced methods to encode the motion vectors <ref> [38] </ref> would only reduce the optimal total lossless rate slightly (up to 5 percent) and hence the simple USQ choice is reasonable. The scalar quantizers have support [V m ; V m ], where V m is the anticipated maximum interframe displacement. <p> VECTORS DECODED PREVIOUS FRAME Q ENTROPY CODERS FIRST-ORDER FRAME DIFFERENCE PREDICTION (bits/pixel) CURRENT FRAMEFRAME PREVIOUS QUANTIZED MOTION VECTORS 82 5.3 Motion Vector Coding and Rate R M DPCM with variable-length coding is a popular technique for encoding the motion vectors, since it has been shown to perform well in practice <ref> [38] </ref>. In fact, this technique is adopted by the current video coding standards [6, 7, 8, 9, 10]. In our scheme, each motion vector is predicted by the quantized version of the previous vector, in scan order.
Reference: [39] <author> M. Sipitca and V. Madisetti, </author> <title> "Lossy techniques for motion vector encoding," </title> <booktitle> Proc. SPIE Visual Commun. and Image Proc., </booktitle> <pages> pp. 387-393, </pages> <address> Orlando, </address> <month> Mar. 96. </month>
Reference-contexts: Studies have shown that losslessly encoding the quantized motion vectors f ^ V i g with predictive coding techniques produces good results [38]. (Lossy coding of the motion vectors has also been considered <ref> [39] </ref>.) For example, in MPEG [6] the previous motion vector (in a raster scan order) is used to predict the value of the current vector, and the prediction error is encoded with a simple variable-length coder.
Reference: [40] <author> J.R. Jain and A.K. Jain, </author> <title> "Interframe adaptative data compression techniques for images", </title> <type> Tech. Rep. </type> <institution> Signal and Image Proc. Lab., UC Davis, </institution> <year> 1979. </year>
Reference-contexts: Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) <ref> [40] </ref> and wavelets [41, 42]. Current standards have selected the DCT coding approach [6, 7, 8, 9, 10]. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments. <p> gradient-based techniques, which use space-time derivatives of image intensity [47, 48, 49], 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures <ref> [52, 53, 40] </ref>. Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements [40, 1, 2, 3, 4]. <p> Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements <ref> [40, 1, 2, 3, 4] </ref>. This technique is particularly appropriate for block-based video coders because in this type of coding all of the pixels in an image block are assumed to move with the same velocity, indicated by a motion vector. <p> This property is exploited in transform coding of images <ref> [40, 6] </ref>. Here, it indicates that the product w x;m w y;m will be zero or very small, because the dominant sinc's will commonly be either on the f x axis or on the f y axis.
Reference: [41] <author> S.G. Mallat, </author> <title> "A theory for multiresolution signal decomposition: the wavelet representation,", </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 11, </volume> <pages> pp. 674-693, </pages> <month> July 89. 148 </month>
Reference-contexts: Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets <ref> [41, 42] </ref>. Current standards have selected the DCT coding approach [6, 7, 8, 9, 10]. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments.
Reference: [42] <author> M. Antonini, M. Barlaud, P. Mathieu, and I. Daubechies, </author> <title> "Image coding using wavelet transform," </title> <journal> IEEE Trans. Image Processing, </journal> <volume> Vol. 1., </volume> <pages> pp. 205-220, </pages> <month> April 92. </month>
Reference-contexts: Good difference frame coders have low rate R D and low distortion. Advanced difference frame coders being considered in industry and academia include coders based on the discrete cosine transform (DCT) [40] and wavelets <ref> [41, 42] </ref>. Current standards have selected the DCT coding approach [6, 7, 8, 9, 10]. A fundamental questions that arises in block-based video coding is how to select 23 the motion vector accuracies f i g, which in practice is done based on heuristics and empirical experiments.
Reference: [43] <author> J.K. Aggarwal and N. Nandhakumar, </author> <title> "On the computation of motion from sequences of images a review," </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 76, </volume> <pages> pp. 917-935, </pages> <month> August 88. </month>
Reference-contexts: Estimating motion in video sequences has applications in many areas such as object tracking and recognition, robot vision, medical angiography, and video 24 compression, to name a few. As a result, many motion estimation techniques have been proposed in the literature <ref> [43, 44, 45] </ref>.
Reference: [44] <author> J.L. Barron, </author> <title> D.J. Fleet, and S.S. Beauchemin, "Performance of optical flow techniques," </title> <journal> Intern. Journal of Computer Vision, </journal> <volume> Vol. 12, </volume> <pages> pp. 43-47, </pages> <month> Feb. 94. </month>
Reference-contexts: Estimating motion in video sequences has applications in many areas such as object tracking and recognition, robot vision, medical angiography, and video 24 compression, to name a few. As a result, many motion estimation techniques have been proposed in the literature <ref> [43, 44, 45] </ref>.
Reference: [45] <author> F. Dufaux and F. Moscheni, </author> <title> "Motion estimation techniques for digital TV: a review and a new contribution," </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 83, </volume> <pages> pp. 858-876, </pages> <month> June 95. </month>
Reference-contexts: Estimating motion in video sequences has applications in many areas such as object tracking and recognition, robot vision, medical angiography, and video 24 compression, to name a few. As a result, many motion estimation techniques have been proposed in the literature <ref> [43, 44, 45] </ref>. <p> For example, Moscheni et al. <ref> [59, 45] </ref> found an expression for the difference frame rate R D of a simple lossy coder as a function of the difference frame energy oe 2 . <p> The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images <ref> [59, 45, 62, 63] </ref>. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered [62, 63, 64]. In any case, our final equations are not too sensitive to the choice of the distribution for p (d).
Reference: [46] <author> J.O. Limb and J.A. Murphy, </author> <title> "Measuring the speed of moving objects from TV signals", </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. 23, </volume> <pages> pp. 474-478, </pages> <year> 1975. </year>
Reference: [47] <author> B.K.P Horn and B.G. Schunck, </author> <title> "Determining optical flow," </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 17, </volume> <pages> pp. 185-203, </pages> <year> 1981. </year>
Reference-contexts: As a result, many motion estimation techniques have been proposed in the literature [43, 44, 45]. There are three major kinds of such techniques: 1) gradient-based techniques, which use space-time derivatives of image intensity <ref> [47, 48, 49] </ref>, 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures [52, 53, 40].
Reference: [48] <author> B.G. Schunck, </author> <title> "Image flow segmentation and estimation by constraint line clustering," </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 11, </volume> <pages> pp. 1010-1026, </pages> <month> Oct. 89. </month>
Reference-contexts: As a result, many motion estimation techniques have been proposed in the literature [43, 44, 45]. There are three major kinds of such techniques: 1) gradient-based techniques, which use space-time derivatives of image intensity <ref> [47, 48, 49] </ref>, 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures [52, 53, 40].
Reference: [49] <author> H.H. Nagel, </author> <title> "On a constraint equation for the estimation of displacement rates in image sequences," </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 11, </volume> <pages> pp. 13-30, </pages> <year> 1989. </year>
Reference-contexts: As a result, many motion estimation techniques have been proposed in the literature [43, 44, 45]. There are three major kinds of such techniques: 1) gradient-based techniques, which use space-time derivatives of image intensity <ref> [47, 48, 49] </ref>, 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures [52, 53, 40].
Reference: [50] <author> D.J. Heeger, </author> <title> "A model for the extraction of image flow", </title> <journal> J. Optical Soc. America, </journal> <volume> vol. A4(8), </volume> <pages> pp. 1455-1471, </pages> <year> 1987. </year>
Reference-contexts: There are three major kinds of such techniques: 1) gradient-based techniques, which use space-time derivatives of image intensity [47, 48, 49], 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy <ref> [50] </ref> or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures [52, 53, 40].
Reference: [51] <author> D.J. Fleet and A.D. Jepson, </author> <title> "Computation of component image velocity from local phase information", </title> <journal> Intern. Journal of Computer Vision, </journal> <volume> vol. 5, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 77-104, </pages> <year> 1990. </year>
Reference-contexts: There are three major kinds of such techniques: 1) gradient-based techniques, which use space-time derivatives of image intensity [47, 48, 49], 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase <ref> [51] </ref> of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures [52, 53, 40].
Reference: [52] <author> P. Anandan, </author> <title> "A computational framework nd an algorithm for the measurement of visual motion", </title> <journal> Intern. Journal of Computer Vision, </journal> <volume> vol. 2, </volume> <pages> pp. 283-310, </pages> <year> 1989. </year>
Reference-contexts: gradient-based techniques, which use space-time derivatives of image intensity [47, 48, 49], 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures <ref> [52, 53, 40] </ref>. Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements [40, 1, 2, 3, 4].
Reference: [53] <author> A. Singh, </author> <title> "Incremental estimation of image-flow using a Kalman filter", </title> <booktitle> Proc. Workshop on Visual Motion, IEEE Computer Society, </booktitle> <address> (Princeton, N.J.), </address> <pages> pp. 36-43, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: gradient-based techniques, which use space-time derivatives of image intensity [47, 48, 49], 2) frequency-based techniques, which compute motion in 3D Fourier space by measuring the energy [50] or phase [51] of the spectrum of the video signal, and 3) correlation-based techniques, which find pixel correspondences between frames using correlation measures <ref> [52, 53, 40] </ref>. Block matching is a correlation-based technique that has become widely used in video coding because it produces good motion vector estimates even for large inter-frame pixel displacements [40, 1, 2, 3, 4].
Reference: [54] <author> D.T. Hoang, P.M. Long, and J.S. Vitter, </author> <title> "Explicit bit minimization for motion-compensated video coding," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <pages> pp. 175-184, </pages> <note> Snow Bird, 94. </note>
Reference: [55] <author> B. Girod, </author> <title> "The efficiency of motion-compensating prediction for hybrid coding of video sequences," </title> <journal> IEEE J. Sel. Areas Commun., </journal> <volume> Vol. 5, </volume> <pages> pp. 1140-1154, </pages> <month> Aug. </month> <pages> 87. 149 </pages>
Reference-contexts: The mathematical models proposed in the literature for the relationship between motion and difference frame bits are fairly complex <ref> [55, 56, 59] </ref>, and there has been no analysis of the optimal number of bits to spend in motion (or equivalently the optimal fl ) so that the total number of bits is minimized. <p> Some researchers have addressed the effect of the motion accuracy on difference frame energy and total bit rate. Girod <ref> [55, 56] </ref> found expressions for the difference frame energy as a function of motion vector error distribution, and the spectrum of the current frame and that of the interframe noise. <p> Under some reasonable assumptions, we discover that the energy in a block of the difference frame is approximately quadratic in the block's motion vector accuracies. Our energy-accuracy formula is fairly simple, accurate, and more general than Girod's <ref> [55, 56] </ref>, and could be used for different types of applications such as motion estimation or texture analysis. In the next four chapters, we use the energy-accuracy formula for modeling the encoding rate and finding the optimal motion vector accuracies in a wide variety of block-based video coders. <p> The benefit of investing bits in motion is that the sum of motion bits plus those used to describe the difference frame is significantly less than the number required to describe the difference frame obtained without motion compensation. The positive results obtained by theoretical studies on motion compensation <ref> [4, 55] </ref> and the widespread success in industry of motion-compensated video coders [6, 7, 8, 9, 10] are testimony to the value of this strategy. On the other hand, motion-compensated video coders experience some difficulties and alternative strategies have been considered in the literature. <p> Then, the rate is the entropy of the Q-quantized Laplacian distribution: R D (oe 2 ) = 1 e Q p 2oe 2 sinh Q 2 8 : (log 2 sinh Q 2 1 p 2Q 2e oe p 2Q 9 ; Girod <ref> [55, 56] </ref> found expressions for the difference frame energy as a function of the motion vector error distribution p (x; y) (which depends on ), the spectra of the current frame s (! x ; ! y ) and the interframe noise n (! x ; ! y ), and the <p> Such a coder is an adequate choice because of the low correlation between pixel values in the difference frame <ref> [55, 56, 59] </ref>. Since image pixels take integer values in (0; 255) the difference frame pixels take integer values in (255; 255). <p> Such a coder is an adequate choice for this study because of the low correlation between the pixel values in the difference frame <ref> [55, 56, 59] </ref>.
Reference: [56] <author> B. Girod, </author> <title> "Motion-compensating prediction with fractional-pel accuracy," </title> <journal> IEEE Trans. Communications, </journal> <volume> Vol. 41, </volume> <pages> pp. 604-612, </pages> <month> Apr. 93. </month>
Reference-contexts: The mathematical models proposed in the literature for the relationship between motion and difference frame bits are fairly complex <ref> [55, 56, 59] </ref>, and there has been no analysis of the optimal number of bits to spend in motion (or equivalently the optimal fl ) so that the total number of bits is minimized. <p> Some researchers have addressed the effect of the motion accuracy on difference frame energy and total bit rate. Girod <ref> [55, 56] </ref> found expressions for the difference frame energy as a function of motion vector error distribution, and the spectrum of the current frame and that of the interframe noise. <p> Vandendorpe et al. [57] presented work similar to that of Girod <ref> [56] </ref>, but for interlaced video frames. Ito and Farvardin [58] performed a simple analysis of difference frame energy in the context of subband coding, which was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. <p> Under some reasonable assumptions, we discover that the energy in a block of the difference frame is approximately quadratic in the block's motion vector accuracies. Our energy-accuracy formula is fairly simple, accurate, and more general than Girod's <ref> [55, 56] </ref>, and could be used for different types of applications such as motion estimation or texture analysis. In the next four chapters, we use the energy-accuracy formula for modeling the encoding rate and finding the optimal motion vector accuracies in a wide variety of block-based video coders. <p> Then, the rate is the entropy of the Q-quantized Laplacian distribution: R D (oe 2 ) = 1 e Q p 2oe 2 sinh Q 2 8 : (log 2 sinh Q 2 1 p 2Q 2e oe p 2Q 9 ; Girod <ref> [55, 56] </ref> found expressions for the difference frame energy as a function of the motion vector error distribution p (x; y) (which depends on ), the spectra of the current frame s (! x ; ! y ) and the interframe noise n (! x ; ! y ), and the <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>. <p> Such a coder is an adequate choice because of the low correlation between pixel values in the difference frame <ref> [55, 56, 59] </ref>. Since image pixels take integer values in (0; 255) the difference frame pixels take integer values in (255; 255). <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>, as we mentioned in Chapter II. <p> Such a coder is an adequate choice for this study because of the low correlation between the pixel values in the difference frame <ref> [55, 56, 59] </ref>. <p> Also, larger blocks will require higher motion vector accuracies if the texture increase in the blocks is superior to the increase of the noise floor. Some of these relationships have previously been observed <ref> [19, 56, 21, 58] </ref>. For example, Girod's study [56] indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin [58] showed that higher frequency images 101 required higher motion vector accuracies. <p> Also, larger blocks will require higher motion vector accuracies if the texture increase in the blocks is superior to the increase of the noise floor. Some of these relationships have previously been observed [19, 56, 21, 58]. For example, Girod's study <ref> [56] </ref> indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin [58] showed that higher frequency images 101 required higher motion vector accuracies. <p> Based on these analyses and empirical experiments, some heuristic conclusions on the best motion vector accuracies have been taken and used in the design of video coders. For example, Girod chooses to encode the motion vectors with either 1/2 pixel or 1/4 pixel accuracy <ref> [56, 21] </ref>. Those may be good choices for a variety of scenes, but our equations and results indicate that lower accuracies can be good enough for low textured frames encoded at large distortion, and higher accuracies are better for high textured images at low distortion.
Reference: [57] <author> L. Vandendorpe, L. Cuvelier and B. Maison, </author> <title> "Statistical properties of prediction error images in motion compensated interlaced image coding", </title> <journal> Proc. IEEE ICIP, </journal> <volume> Vol. 3, </volume> <pages> pp. 192-195, </pages> <address> Washington, D.C., </address> <month> Oct. 95. </month>
Reference-contexts: He reached some interesting 8 conclusions from this analysis, but unfortunately it cannot be used to adapt the accuracies on a block-by-block basis, and even for an entire frame the resulting expressions are too complex to be used to analytically derive fl . Vandendorpe et al. <ref> [57] </ref> presented work similar to that of Girod [56], but for interlaced video frames. Ito and Farvardin [58] performed a simple analysis of difference frame energy in the context of subband coding, which was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. <p> These energy-accuracy curves were obtained using empirical measurements of the energy for different values of and not using (2.8). He found that the energy- curves became fairly flat for smaller than 1/2 in two video phone sequences, and for smaller than 1/4 in two TV sequences. Vandendorpe et al. <ref> [57] </ref> presented work similar to that of Girod, but for interlaced video frames.
Reference: [58] <author> H. Ito and N. Farvardin, </author> <title> "On motion compensation of wavelet coefficients," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 4, </volume> <pages> pp. 2161-2164, </pages> <address> Detroit, </address> <month> May 95. </month>
Reference-contexts: Vandendorpe et al. [57] presented work similar to that of Girod [56], but for interlaced video frames. Ito and Farvardin <ref> [58] </ref> performed a simple analysis of difference frame energy in the context of subband coding, which was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. <p> Hence, new analysis or theory is needed to obtain effective and more general models to be able to find the optimal classical fl and adaptive f fl i g motion vector accuracies. In other related work, Ito and Farvardin <ref> [58] </ref> performed a simple analysis of difference frame energy in the context of subband coding, which did not contribute rate or energy models, but was sufficient to conclude that the motion vectors of higher frequency subbands require more accurate encoding. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>. <p> Some of these relationships have been previously observed and heuristically used in the design of video coders <ref> [19, 56, 21, 58] </ref>, as we mentioned in Chapter II. <p> Also, larger blocks will require higher motion vector accuracies if the texture increase in the blocks is superior to the increase of the noise floor. Some of these relationships have previously been observed <ref> [19, 56, 21, 58] </ref>. For example, Girod's study [56] indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin [58] showed that higher frequency images 101 required higher motion vector accuracies. <p> Some of these relationships have previously been observed [19, 56, 21, 58]. For example, Girod's study [56] indicated that lower motion accuracies were needed for larger interframe noise, and Ito and Farvardin <ref> [58] </ref> showed that higher frequency images 101 required higher motion vector accuracies. Based on these analyses and empirical experiments, some heuristic conclusions on the best motion vector accuracies have been taken and used in the design of video coders.
Reference: [59] <author> F. Moscheni, F. Dufaux and H. Nicolas, </author> <title> "Entropy criterion for optimal bit allocation between motion and prediction error information," </title> <booktitle> Proc. SPIE Visual Commun. Image Proc., </booktitle> <pages> pp. 235-242, </pages> <month> Nov. 93. </month>
Reference-contexts: The mathematical models proposed in the literature for the relationship between motion and difference frame bits are fairly complex <ref> [55, 56, 59] </ref>, and there has been no analysis of the optimal number of bits to spend in motion (or equivalently the optimal fl ) so that the total number of bits is minimized. <p> This method has achieved promising results for video telephone and video conferencing, but the object extraction and model-fitting procedures are computationally complex. Region-based and quadtree-based coders <ref> [21, 22, 23, 59, 24, 25, 26, 27, 28, 29] </ref> are similar to the previous method in that they approximately decompose the current frame into moving objects or regions. In the quadtree case, they find the quadtree that best fits the moving regions. <p> Another important question not addressed here is how to select the block size for the motion predictor. This is considered in [68] using the methods of this thesis and in other work <ref> [24, 25, 26, 59, 23, 27, 28, 29] </ref>. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding. <p> For example, Moscheni et al. <ref> [59, 45] </ref> found an expression for the difference frame rate R D of a simple lossy coder as a function of the difference frame energy oe 2 . <p> Such a coder is an adequate choice because of the low correlation between pixel values in the difference frame <ref> [55, 56, 59] </ref>. Since image pixels take integer values in (0; 255) the difference frame pixels take integer values in (255; 255). <p> To do this we assume that p (d) is the discrete version of a Laplacian distribution <ref> [59] </ref> with variance oe 2 , and that oe is large enough that the entropy of p (d) is approximately equal to the differential entropy of the Laplacian [69], H (p) 2 In Figure 4.3, the discrete distribution illustrates a possible p (d) for small (integer) values of d and the <p> The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images <ref> [59, 45, 62, 63] </ref>. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered [62, 63, 64]. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). <p> Such a coder is an adequate choice for this study because of the low correlation between the pixel values in the difference frame <ref> [55, 56, 59] </ref>.
Reference: [60] <author> X. Li and C. Gonzales, </author> <title> "A locally quadratic model fo the motion estimation error criterion function and its application to subpixel interpolations," </title> <journal> IEEE Trans. Circuits and Systems for Video Technology, </journal> <volume> Vol. 6, </volume> <pages> pp. 123-126, </pages> <month> Feb. 96. </month>
Reference-contexts: For example, recently Li and Gonzales <ref> [60] </ref> used the quadratic energy-error formula for a block (3.33) to design a subpixel-accurate motion estimation technique. They did not derive (3.33) analytically, but hypothesized it after observing empirically-measured energy-error curves for different image blocks. <p> Some examples are: * The quadratic formulas for the difference frame energy can be used in other difference rate models, motion estimation, and texture analysis. For instance, Li and Gonzales <ref> [60] </ref> recently used the quadratic energy-error formula to design a subpixel-accurate motion estimation technique. * Hierarchical and fast-search motion estimation techniques can use our adaptive accuracies to constraint the vector search in velocity space on a block-by-block basis, and further save computational complexity and bit rate. * Our rate models can
Reference: [61] <author> J.S. Lim, </author> <title> Two-dimensional signal and image processing, </title> <publisher> Prentice Hall Signal Processing Series, </publisher> <year> 1990. </year>
Reference-contexts: is reasonable to assume that P can be approximately represented with that limited orthonormal set because ideally the lens of a camera acts as an antialiasing filter of cutoff frequency 1/2, and also significant frequency components outside of the diamond-shaped region in Figure A.4 are not common in real images <ref> [61] </ref>. <p> y ! x;m ! y;m ) T x T y : (A.37) To further simplify (A.37), observe that the frequency components of typical images have most of their energy concentrated in a small region in the frequency domain, near the origin and along the f x and f y axis <ref> [61] </ref>. This property is exploited in transform coding of images [40, 6]. Here, it indicates that the product w x;m w y;m will be zero or very small, because the dominant sinc's will commonly be either on the f x axis or on the f y axis.
Reference: [62] <author> F. Mueller, </author> <title> "On the motion compensated prediction error using true motion fields," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 781-785, </pages> <address> Austin, </address> <month> Oct. 94. </month>
Reference-contexts: The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images <ref> [59, 45, 62, 63] </ref>. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered [62, 63, 64]. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). <p> The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images [59, 45, 62, 63]. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered <ref> [62, 63, 64] </ref>. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). In fact, the same equations can be obtained assuming that p (d) is Gaussian.
Reference: [63] <author> S. Liu and M. Hayes, </author> <title> "Video compression using quadtree segmentation and component quantization," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 5, </volume> <pages> pp. 429-432, </pages> <address> Minneapolis, </address> <month> Apr. 93. </month>
Reference-contexts: The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images <ref> [59, 45, 62, 63] </ref>. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered [62, 63, 64]. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). <p> The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images [59, 45, 62, 63]. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered <ref> [62, 63, 64] </ref>. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). In fact, the same equations can be obtained assuming that p (d) is Gaussian.
Reference: [64] <author> W. Li and F.-X. </author> <title> Mateo, "Segmentation based coding of motion compensated prediction error images," </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> Vol. 5, </volume> <pages> pp. 357-360, </pages> <address> Minneapolis, </address> <month> Apr. 93. </month>
Reference-contexts: The Laplacian assumption is fairly common and is motivated by a large number of studies on difference frame images [59, 45, 62, 63]. Other types of Generalized Gaussian 64 s 2 variance ... ... 0 1 2 3 4-1-2-3-4 d distributions have also been considered <ref> [62, 63, 64] </ref>. In any case, our final equations are not too sensitive to the choice of the distribution for p (d). In fact, the same equations can be obtained assuming that p (d) is Gaussian.
Reference: [65] <author> G.K. Wallace, </author> <title> "The JPEG still picture compression standard," </title> <journal> Commun. ACM, </journal> <volume> Vol. 34, </volume> <pages> pp. 30-44, </pages> <month> Apr. 91 </month>
Reference-contexts: These figures illustrate how the curves change depending on scene texture and compression level. "Coder 2" at a PSNR (5.7) of approximately 33 dB (accordingly, we used Q = 20 in our formulas). Every fifth frame was intracoded by a JPEG coder <ref> [65] </ref> (as in MPEG [6]) at the same distortion and its rate is not included in the results. <p> In Figure 6.6, we show the histogram of the x;i and y;i values for the optimized "adaptive mode" in the 5 frames of "caltrain". more advanced "Coder 2". Every fifth frame was intracoded by a JPEG coder <ref> [65] </ref> also at 31 dB, and its rate is not included in the results.
Reference: [66] <author> M. Ghanbari, </author> <title> "The cross-search algorithm for motion estimation," </title> <journal> IEEE Trans. Communications, </journal> <volume> Vol. 38, </volume> <pages> pp. 950-953, </pages> <year> 1990. </year>
Reference-contexts: Other match measures such as adding the squared pixel differences could also be considered <ref> [66] </ref>. The plane of candidate motion vectors ( ~ V x ; ~ V y ) 2 R 2 is called the velocity space (R is the set of real numbers). <p> For example, a hierarchical motion estimator [67] or a fast block-matching estimator <ref> [66] </ref> could use equations (6.5) and (6.6) to constrain the motion vector search. CHAPTER VII Conclusions In this section, we summarize the contributions and conclusions of this dissertation. The major contributions are presented in Section 7.1 and other important conclusions are given in Section 7.2.
Reference: [67] <author> M. Bierling, </author> <title> "Displacement estimation by hierarchical block matching," </title> <booktitle> Proc. SPIE Visual Commun. and Image Process, </booktitle> <address> Cambridge, </address> <month> Nov. 88. </month>
Reference-contexts: Our technique can be applied to other coding schemes (e.g., object-based or variable block-size motion compensation), and can also be easily incorporated into any motion estimation procedure of a block-based video coder to further save complexity and total bit rate. For example, a hierarchical motion estimator <ref> [67] </ref> or a fast block-matching estimator [66] could use equations (6.5) and (6.6) to constrain the motion vector search. CHAPTER VII Conclusions In this section, we summarize the contributions and conclusions of this dissertation.
Reference: [68] <author> J. Ribas-Corbera and D.L. Neuhoff, </author> <title> "On the optimal block size for block-based, motion-compensated video coders," </title> <booktitle> submitted to Proc. SPIE Visual Commun. Image Proc., </booktitle> <address> San Jose, </address> <month> Jan-Feb 97. </month>
Reference-contexts: The main objective of this dissertation is to answer this interesting question for any choice of motion vector and difference frame coder. Another important question not addressed here is how to select the block size for the motion predictor. This is considered in <ref> [68] </ref> using the methods of this thesis and in other work [24, 25, 26, 59, 23, 27, 28, 29]. In Section 2.6, we will intuitively look at the effect of the motion vector accuracies f i g in block-based video coding. <p> multiresolution video coders, in which the optimization could be done at each subband. * A variation of our procedures could be used to derive the best block size for the motion predictor, or even to find the best quadtree or object decomposition. 126 The former problem has been explored in <ref> [68] </ref> using the methods of this thesis. 7.3.1 Final Remark In this dissertation, we have answered the fundamental and so far intractable question of which are the optimal motion vector accuracies in block-based video coding.
Reference: [69] <author> A. Gersho and R.M. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: On the other hand, if the difference frame coder is lossy, the decoded frame will be an approximation to the original. The distortion in the lossy decoded frame is commonly measured as the mean squared error (MSE) between the original and the decoded frame <ref> [69] </ref>. (Note that the MSE distortion of the decoded current frame is the same as the MSE distortion of the decoded difference frame.) Many coders for the motion vectors and difference frame have been proposed and 22 DIFFERENCE FRAME DECODER - V -i PREDICTION PREDICTION CURRENT BITS DIFFERENCE FRAME MOTION MOTION <p> In the next section, we describe the difference frame coder and find an expression for the difference frame rate R D as a function of the 63 4.4 Difference Frame Coding and Rate R D The difference frame pixels are losslessly encoded by a first-order entropy code <ref> [69] </ref>, where the code is adapted to that particular difference frame. Such a coder is an adequate choice because of the low correlation between pixel values in the difference frame [55, 56, 59]. <p> Letting p (d) denote the frequency of the value d in the difference frame, then the rate (in bits/pixel) produced when encoding a particular difference frame is approximately given by the entropy <ref> [69] </ref>, R D d 4 Therefore, the total rate to encode the current frame is R = R D + R M H (p) + P i=1 To make an optimal rate allocation, i.e. to minimize the expression for R in (4.4), the encoder must be able to predict H (p). <p> To do this we assume that p (d) is the discrete version of a Laplacian distribution [59] with variance oe 2 , and that oe is large enough that the entropy of p (d) is approximately equal to the differential entropy of the Laplacian <ref> [69] </ref>, H (p) 2 In Figure 4.3, the discrete distribution illustrates a possible p (d) for small (integer) values of d and the dashed curve shows a Laplacian distribution of variance oe 2 . <p> For o oe S it can be shown <ref> [69] </ref> that H (C ) h (S) log 2 ; (5.2) 83 V x,i-1 ...... H bits V x,i N s x,i Uniform Scalar Quantizer Entropy Coder where h (S) is the differential entropy of S, but this value will actually not be needed for the optimization.

References-found: 70

