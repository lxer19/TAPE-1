URL: http://www.cs.wustl.edu/cs/techreports/1994/wucs-94-25.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Title: Design of a Large Scale Multimedia Server  
Author: Milind M. Buddhikot, Guru Parulkar, Jerome R. Cox, Jr. wucs-- 
Note: This work was supported in part by the ARPA, National Science Foundation, and an industrial consortium of Ascom Timeplex, Bellcore, BNR,  
Address: Campus Box 1045  One Brookings Drive St. Louis, MO 63130-4899  
Affiliation: Department of Computer Science  Washington University  Goldstar, NEC, NTT, SynOptics, and Tektronix.  
Date: November 14, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] |-, <author> "Storage Concepts, </author> <title> Concept 810-SW real-time RAID," Product Description, Storage Con cepts, </title> <publisher> Inc. </publisher> <address> Irvine, CA. </address>
Reference-contexts: Though very high throughputs have been demonstrated under certain access patterns, these commercial high performance implementations are expensive custom solutions for mainframes and supercomputers. Recently, some vendors have announced affordable small capacity raid products, but most of them use proprietary buses and custom hardware to achieve high performance <ref> [1] </ref>. In short, none of these raid implementations cost-effectively satisfy requirements 1, 2, 3, and 5 discussed earlier. Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia [21, 30].
Reference: [2] <author> Buddhikot, M., Parulkar, G. and Cox, J., </author> <title> "Scheduling, Data Layout and Playout Control in a Large Scale Multimedia Storage Server," </title> <note> Technical Report in preparation, </note> <institution> Department of Computer Science, Washington University in St. Louis, </institution> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Before we discuss the details of the storage node, we will briefly describe the data layout and the scheduling schemes. It must be noted that the Large Scale Multimedia Servers 9 architecture, data layout and scheduling interact very strongly and detailed discussion of the same can be found in <ref> [2] </ref>. Here, we outline only one of the many possible data layout schemes that satisfy real-time playout requirements and allow a large number of concurrent accesses to the same or different data in a retrieval environment. The periodic nature of multimedia data is well suited to spatial distribution or striping.
Reference: [3] <author> Buddhikot, M., Parulkar, G. and Cox. J. </author> <title> "Distributed Layout, Scheduling, and Playout Control in a Multimedia Storage Server," </title> <booktitle> To appear in the Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: The scheduling schemes employed by the node are a topic of our on-going research <ref> [3] </ref> and one such example scheduling scheme is described in subsequent sections of this paper. * Compute support: A large amount of computing power can be provided by using sophis ticated media processors such as the mvp [14] at each storage node.
Reference: [4] <author> Buddhikot, M., Parulkar, G., and Cox, Jerome, R. Jr., </author> <title> "Design of a Large Scale Multimedia Storage Server," </title> <booktitle> Proceedings of the INET'94/JENC5, Conference of the Internet Society and the Joint European Networking Conference, </booktitle> <address> Prague, </address> <month> June, </month> <year> 1994. </year>
Reference: [5] <author> Cao, Pei, et al., </author> <title> "The TickerTAIP Parallel RAID Architecture," </title> <booktitle> Proceedings of the 1993 Inter national Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Also, it has not been demonstrated to be suitable for real-time multimedia, where the application needs are different than the needs of supercomputer applications. In short, this solution does not satisfy requirements 1, 4, and 5 mentioned before. Several commercial implementations of raid <ref> [5, 18] </ref> have been reported in the literature. Though very high throughputs have been demonstrated under certain access patterns, these commercial high performance implementations are expensive custom solutions for mainframes and supercomputers.
Reference: [6] <author> Chen, P., et al., </author> <title> "RAID: High-performance, Reliable Secondary Storage," </title> <note> submitted to ACM Computing Surveys. </note>
Reference-contexts: On the other hand, the rate of improvement in the storage density of magnetic disks [29, 13] indicates that magnetic storage will be cost-effective in meeting the storage capacity requirements of future multimedia applications. Large Scale Multimedia Servers 3 However, as reported in <ref> [6] </ref>, the rate of improvements in seek time (8% a year), rotational latency (practically no improvements) and transfer speeds (22% a year) will be very modest. This suggests that a large capacity disk storage used naively will not deliver the throughput required by future applications .
Reference: [7] <author> Chervenak, </author> <title> A, "Performance Measurements of the First RAID Prototype," </title> <type> Technical Report, </type> <institution> Department of Computer Science, University of California, Berkeley, </institution> <year> 1990. </year> <title> Large Scale Multimedia Servers 17 </title>
Reference-contexts: The other type, commonly used to characterize distributed computing and transaction processing applications, requires very frequent but small data accesses [20]. However, measurements on the first raid prototype at the University of California, Berkeley revealed poor performance and less than expected linear speedup for large data transfers <ref> [7] </ref>. The excessive memory copying overhead due to interaction of caching and dma transfers, and restricted i/o interconnect (vme bus) bandwidth were cited to be the primary reasons of poor performance. Also, it is recognized now that large raid disk arrays do not scale very well in terms of throughput.
Reference: [8] <author> Daigle, S., </author> <title> "Disk Scheduling for Continuous Media Data Streams," </title> <type> Master's Thesis, </type> <institution> Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia [21, 30]. Daigle et al. <ref> [8] </ref>, Yu et al. [31], Reddy et al. [22] report disk scheduling techniques to support real-time retrieval of multimedia streams. <p> Thus, 27 compressed hdtv clients can be supported simultaneously. Similar calculations show that approximately 110 mpeg compressed ntsc quality clients can be supported in this setup. It must be noted that the disk and array level scheduling policies <ref> [8] </ref> are required to guarantee retrieval of data for all active connections during the prefetching period.
Reference: [9] <author> Dailianas, A., and Bovopoulos, A., </author> <title> "Real-time Admission Control Algorithms with Delay and Loss Guarantees in ATM Networks," </title> <journal> Proceedings of IEEE INFOCOM'94, </journal> <volume> Vol. 3, </volume> <pages> pp. 1065-1072, </pages> <month> June, </month> <year> 1994. </year>
Reference-contexts: The resource reservation and admission algorithms used to accomplish this will be similar to the ones proposed in the context of the atm networks and the end systems <ref> [9, 11, 28] </ref>. * Scheduling support: Each node, completely manages real-time scheduling of local data read and write functions for each active stream.
Reference: [10] <author> Dittia, Z., Cox., J., and Parulkar, G., </author> <title> "Catching up with the networks: Host I/O at gigabit rates," </title> <type> Technical Report WUCS-94-11, </type> <institution> Department of Computer Science, Washington Univer sity in St. Louis, </institution> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The discussion of apic internals is beyond the scope of this paper, but can be found in <ref> [10] </ref>. 3.2.2. Data Layout and Scheduling. Before we discuss the details of the storage node, we will briefly describe the data layout and the scheduling schemes.
Reference: [11] <author> Golestani, J., </author> <title> "Congestion-Free Communication in High-Speed Packet Networks," </title> <journal> IEEE Trans actions on Communications, </journal> <volume> Vol. 39, No. 12, </volume> <pages> pp. 1802-1812, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: The resource reservation and admission algorithms used to accomplish this will be similar to the ones proposed in the context of the atm networks and the end systems <ref> [9, 11, 28] </ref>. * Scheduling support: Each node, completely manages real-time scheduling of local data read and write functions for each active stream.
Reference: [12] <author> Haskins, R., </author> <title> "The Shark Continuous-Media File Server," </title> <booktitle> Proceedings of IEEE Compcon'93, </booktitle> <address> San Francisco CA, </address> <month> Feb. </month> <year> 1993. </year>
Reference: [13] <author> Hylton, Todd., Coffey., K., Parker, A., and Kent, H., </author> <title> "AdStaR Scientists Detect Giant Magne toresistance in Small Magnetic Fields, Using Easy to Make Sensor," </title> <booktitle> SCIENCE, </booktitle> <month> August, </month> <year> 1993. </year>
Reference-contexts: In spite of the promise of all-optical technologies such as holographic storage, inexpensive availability of such storage in the near future is unlikely. On the other hand, the rate of improvement in the storage density of magnetic disks <ref> [29, 13] </ref> indicates that magnetic storage will be cost-effective in meeting the storage capacity requirements of future multimedia applications. <p> Background Given that the storage densities of present magnetic disks are about four orders of magnitude smaller than the theoretically possible maximum, with no insurmountable obstacles in sight, inexpensive magnetic storage devices with capacity in excess of 100 gigabytes (gbs) will become available in the foreseeable future <ref> [29, 13] </ref>. A large number of such disks can be used to easily meet the terabytes of storage requirement of multimedia servers. However, satisfying the large storage and network throughput requirement will not be as easy.
Reference: [14] <author> Guttag, K., Gove, R., and Aken, V., </author> <title> "A Single-Chip Multiprocessor for Multimedia: </title> <journal> The MVP," IEEE Computer Graphics and Applications, </journal> <pages> pp. 53-64, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: For example, a movie server may have to convert (transcode) a native mpeg compressed movie to h.261 format that some of the customers may use. Such transcoding techniques are normally very compute and memory bandwidth intensive and unless specialized computing power <ref> [14] </ref> is available their real-time software implementations are difficult. Thus, the aforementioned requirements of future storage servers are radically different, and there fore designing such servers is a challenging task that requires significant architectural innovation. To this end, this paper reports our project the Massively-parallel And Real-time Storage (mars) architecture. <p> scheduling schemes employed by the node are a topic of our on-going research [3] and one such example scheduling scheme is described in subsequent sections of this paper. * Compute support: A large amount of computing power can be provided by using sophis ticated media processors such as the mvp <ref> [14] </ref> at each storage node. Such processors will be embedded on the path between the storage and the network, and can be used to perform media processing functions such as transcoding, speech recognition, image processing, and character recognition required by future multimedia applications.
Reference: [15] <author> Lee, E., et al., </author> " <title> RAID-II: A Scalable Storage Architecture for High-Bandwidth Network File Service," </title> <type> Technical Report UCB//CSD-92-672, </type> <institution> Department of Computer Science, University of California at Berkeley, </institution> <month> Oct., </month> <year> 1992. </year>
Reference-contexts: The recent work on raid-ii at the University of California, Berkeley has attempted to use the lessons learned from the raid prototype implementation to develop high bandwidth storage servers by interconnecting several disk arrays through a high speed HIPPI network backplane <ref> [15] </ref>. The raid-ii operates in two modes: a standard mode to support low latency request through a fddi connection and a high bandwidth mode to support large transfers.
Reference: [16] <author> Little, T., D., et al., </author> <title> "A Digital On-demand Video Service Supporting Content-based Queries," </title> <booktitle> Proceedings of ACM Multimedia'93, </booktitle> <address> Anaheim, CA, </address> <pages> pp 427-436, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Lougher et al. [17] and Tobagi et al. [25] report a small scale multimedia server based on disk arrays, but they do not attempt to satisfy requirements 1, 2, and 3 mentioned earlier. Little et al. <ref> [16] </ref>, Miller et al. [19], and Rowe et al. [23] explore issues in the design of video browsing interfaces, authoring systems, metadata indices, and metadata databases. However, none of them address the more pressing problems of supporting large storage throughput and a large number of clients. <p> In addition, it may support advanced database functions, such as the ones proposed by several research groups <ref> [16, 23, 19] </ref>, for efficient browsing and content based searching of multimedia information. * Admission Control: Each storage node keeps track of usage of local resources such as storage and interconnect bandwidth and performs local admission control.
Reference: [17] <author> Lougher, P., and Shepherd, D., </author> <title> "The Design of a Storage Server for Continuous Media," </title> <journal> The Computer Journal, </journal> <volume> Vol. 36, No. 1, </volume> <pages> pp. 32-42, </pages> <year> 1993. </year>
Reference-contexts: This model is clearly unrealistic as the limited throughput of a single disk cannot support hundreds of concurrent clients accessing the same document stored on it. Lougher et al. <ref> [17] </ref> and Tobagi et al. [25] report a small scale multimedia server based on disk arrays, but they do not attempt to satisfy requirements 1, 2, and 3 mentioned earlier.
Reference: [18] <author> LoVerso, S., Isman, M., et al. "sfs: </author> <title> A Parallel File System for the CM-5," </title> <booktitle> Proceedings of USENIX Summer Conference, </booktitle> <month> June, </month> <year> 1993. </year>
Reference-contexts: Also, it has not been demonstrated to be suitable for real-time multimedia, where the application needs are different than the needs of supercomputer applications. In short, this solution does not satisfy requirements 1, 4, and 5 mentioned before. Several commercial implementations of raid <ref> [5, 18] </ref> have been reported in the literature. Though very high throughputs have been demonstrated under certain access patterns, these commercial high performance implementations are expensive custom solutions for mainframes and supercomputers.
Reference: [19] <author> Miller, G., Baber, G., and Gilliland, M., </author> <title> "News On-Demand for Multimedia Networks," </title> <booktitle> Pro ceedings of ACM Multimedia'93, </booktitle> <address> Anaheim, CA, </address> <pages> pp. 383-392, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Lougher et al. [17] and Tobagi et al. [25] report a small scale multimedia server based on disk arrays, but they do not attempt to satisfy requirements 1, 2, and 3 mentioned earlier. Little et al. [16], Miller et al. <ref> [19] </ref>, and Rowe et al. [23] explore issues in the design of video browsing interfaces, authoring systems, metadata indices, and metadata databases. However, none of them address the more pressing problems of supporting large storage throughput and a large number of clients. <p> In addition, it may support advanced database functions, such as the ones proposed by several research groups <ref> [16, 23, 19] </ref>, for efficient browsing and content based searching of multimedia information. * Admission Control: Each storage node keeps track of usage of local resources such as storage and interconnect bandwidth and performs local admission control.
Reference: [20] <author> Patteson, D., et al., </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)," </title> <booktitle> Proceedings of the 1988 ACM Conference on Management of Data (SIGMOD), </booktitle> <address> Chicago IL, </address> <pages> pp. 109-116, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: However, very large disk arrays suffer from poor reliability. This fact together with the observation that small inexpensive disks outperform expensive high-performance disks in price vs. performance, led Patterson et al. to introduce the concept of Redundant Array of Inexpensive Disks (raid) <ref> [20] </ref>. A raid is essentially an array of small disks with simple parity based error detection and correction capabilities that guarantee continuous operation in the event of a single disk failure in a group of disks. The raid was expected to perform well for two diverse types of workloads. <p> One type, representative of supercomputer applications such as large simulations, requires infrequent transfers of very large data sets. The other type, commonly used to characterize distributed computing and transaction processing applications, requires very frequent but small data accesses <ref> [20] </ref>. However, measurements on the first raid prototype at the University of California, Berkeley revealed poor performance and less than expected linear speedup for large data transfers [7].
Reference: [21] <author> Rangan, V., and Vin, H., </author> <title> "Designing File Systems for Digital Video and Audio," </title> <booktitle> Proceedings of the 13 th Symposium on Operating System Principles, Operating Systems Review, </booktitle> <pages> pp. 81-94, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: In short, none of these raid implementations cost-effectively satisfy requirements 1, 2, 3, and 5 discussed earlier. Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia <ref> [21, 30] </ref>. Daigle et al. [8], Yu et al. [31], Reddy et al. [22] report disk scheduling techniques to support real-time retrieval of multimedia streams. <p> If the storage device is just a set of high capacity disks, the entire frame is stored on a single disk. In both cases the actual data layout on the surface of the disk may follow a constrained allocation policy, similar to the one discussed in <ref> [21] </ref>, to ensure bounded seek and rotational latencies in retrieving consecutive blocks. In addition to the data layout scheme, appropriate scheduling policies must be used at all levels in the path of the data retrieval and transmission. In particular, data reads and writes from multiple 10 Buddhikot M.
Reference: [22] <author> Reddy, N. and Wyllie, J., </author> <title> "Disk Scheduling in a Multimedia I/O System," </title> <booktitle> Proceedings of ACM Multimedia'93, </booktitle> <address> Anaheim, CA, </address> <pages> pp. 225-233, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia [21, 30]. Daigle et al. [8], Yu et al. [31], Reddy et al. <ref> [22] </ref> report disk scheduling techniques to support real-time retrieval of multimedia streams.
Reference: [23] <author> Rowe, L., Boreczky, J., and Eadds, C., </author> <title> "Indexes for User Access to Large Video Databases," </title> <booktitle> IS & / SPIE Symposium on Electronic Imaging Science and Technology, Conference 2185, </booktitle> <year> 1994. </year>
Reference-contexts: Lougher et al. [17] and Tobagi et al. [25] report a small scale multimedia server based on disk arrays, but they do not attempt to satisfy requirements 1, 2, and 3 mentioned earlier. Little et al. [16], Miller et al. [19], and Rowe et al. <ref> [23] </ref> explore issues in the design of video browsing interfaces, authoring systems, metadata indices, and metadata databases. However, none of them address the more pressing problems of supporting large storage throughput and a large number of clients. <p> In addition, it may support advanced database functions, such as the ones proposed by several research groups <ref> [16, 23, 19] </ref>, for efficient browsing and content based searching of multimedia information. * Admission Control: Each storage node keeps track of usage of local resources such as storage and interconnect bandwidth and performs local admission control.
Reference: [24] <author> Salem, K., and Garcia-Molina, H., </author> <title> "Disk Striping," </title> <booktitle> IEEE International Conference on Data Engineering, </booktitle> <year> 1986. </year> <note> 18 Buddhikot M. M. </note>
Reference-contexts: A well known way to increase the effective storage throughput is to operate a large number of disks in parallel (an organization commonly called a disk array) and physically distribute (stripe) the data over the disks <ref> [24] </ref>. However, very large disk arrays suffer from poor reliability. This fact together with the observation that small inexpensive disks outperform expensive high-performance disks in price vs. performance, led Patterson et al. to introduce the concept of Redundant Array of Inexpensive Disks (raid) [20].
Reference: [25] <author> Tobagi, F., Pang, J., Baird, R., and Gang, M., </author> " <title> Streaming RAID A Disk Array Management System for Video Files," </title> <booktitle> Proceedings of ACM Multimedia'93, </booktitle> <address> Anaheim, CA, </address> <pages> pp. 393-400, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: This model is clearly unrealistic as the limited throughput of a single disk cannot support hundreds of concurrent clients accessing the same document stored on it. Lougher et al. [17] and Tobagi et al. <ref> [25] </ref> report a small scale multimedia server based on disk arrays, but they do not attempt to satisfy requirements 1, 2, and 3 mentioned earlier.
Reference: [26] <author> Turner, J., </author> <title> "An Optimal Nonblocking Multicast Virtual Circuit Switch," </title> <journal> Proceedings of IEEE INFOCOM94, </journal> <volume> Vol. 1, </volume> <pages> pp. 298-305, </pages> <month> June, </month> <year> 1994. </year>
Reference-contexts: A Scalable Extension The Cluster Based Storage (cbs) architecture, which is a scalable extension of the prototype im plementation discussed earlier, is illustrated in Figure 7. It consists of a set of independent clusters 14 Buddhikot M. M. interconnected through a fast multicast atm switch, such as <ref> [26, 27] </ref>. Each of the clusters resem bles our prototype implementation architecture. The apic at the end of the daisy chain in a cluster transparently interfaces to one port of an atm switch. Each cluster has a local cluster manager.
Reference: [27] <author> Turner, J., </author> <title> "A Gigabit Multicast Switch: System Architecture Document," </title> <institution> Applied Research Laboratory, Washington University in St. Louis, </institution> <month> Feb., </month> <year> 1994. </year>
Reference-contexts: A Scalable Extension The Cluster Based Storage (cbs) architecture, which is a scalable extension of the prototype im plementation discussed earlier, is illustrated in Figure 7. It consists of a set of independent clusters 14 Buddhikot M. M. interconnected through a fast multicast atm switch, such as <ref> [26, 27] </ref>. Each of the clusters resem bles our prototype implementation architecture. The apic at the end of the daisy chain in a cluster transparently interfaces to one port of an atm switch. Each cluster has a local cluster manager.
Reference: [28] <author> Turner, J., </author> <title> "Bandwidth Management in ATM Networks Using Fast Buffer Reservation," </title> <journal> IEEE Networks Magazine, </journal> <volume> Vol. 6, No. 5, </volume> <month> Sept. </month> <year> 1992, </year> <pages> pp. 50-58. </pages>
Reference-contexts: The resource reservation and admission algorithms used to accomplish this will be similar to the ones proposed in the context of the atm networks and the end systems <ref> [9, 11, 28] </ref>. * Scheduling support: Each node, completely manages real-time scheduling of local data read and write functions for each active stream.
Reference: [29] <author> Venkatramani, C., and Chiueh, T., </author> <title> "Survey of Near-Line Storage Technologies: Devices and Systems," Experimental Computer Systems Laboratory, </title> <type> Technical Report #2, </type> <institution> Department of Computer Science, SUNY Stony Brook, </institution> <address> NY, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: In spite of the promise of all-optical technologies such as holographic storage, inexpensive availability of such storage in the near future is unlikely. On the other hand, the rate of improvement in the storage density of magnetic disks <ref> [29, 13] </ref> indicates that magnetic storage will be cost-effective in meeting the storage capacity requirements of future multimedia applications. <p> Background Given that the storage densities of present magnetic disks are about four orders of magnitude smaller than the theoretically possible maximum, with no insurmountable obstacles in sight, inexpensive magnetic storage devices with capacity in excess of 100 gigabytes (gbs) will become available in the foreseeable future <ref> [29, 13] </ref>. A large number of such disks can be used to easily meet the terabytes of storage requirement of multimedia servers. However, satisfying the large storage and network throughput requirement will not be as easy.
Reference: [30] <author> Vin, H., and Rangan, V., </author> <title> "Design of a Multi-user hdtv Storage Server," </title> <journal> IEEE Journal on Selected Areas in Communication, Special issue on High Definition Television and Digital Video Communication, </journal> <volume> Vol. 11, No. 1, </volume> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: Large storage capacity: Given the storage intensive nature of multimedia data, the collective storage requirements for thousands of multimedia documents may exceed tens of terabytes. For example, a movie server with two hundread hdtv quality 20 Mbps <ref> [30, 32] </ref> 2-hour-long movies will require roughly 3.6 terabytes (tbs) of storage. Similarly, a multimedia storage server that stores a large number of multimedia documents each composed of multiple media streams, will require a comparable storage capacity. 3. <p> In short, none of these raid implementations cost-effectively satisfy requirements 1, 2, 3, and 5 discussed earlier. Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia <ref> [21, 30] </ref>. Daigle et al. [8], Yu et al. [31], Reddy et al. [22] report disk scheduling techniques to support real-time retrieval of multimedia streams.
Reference: [31] <author> Yu, P., Chen., M., and Kandlur, D., </author> <title> "Grouped Sweeping Scheduling for DASD based Storage Management," Multimedia Systems, </title> <publisher> Springer-Verlag, </publisher> <pages> pp. 99-109, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: Several recent proposals for filesystems and servers have attempted to address the special re quirements of multimedia streams. In particular, Rangan et al. study data layout techniques for multimedia [21, 30]. Daigle et al. [8], Yu et al. <ref> [31] </ref>, Reddy et al. [22] report disk scheduling techniques to support real-time retrieval of multimedia streams.
Reference: [32] <author> Zou, W., Y., </author> <title> "Digital hdtv Compression Techniques for Terrestrial Broadcasting," </title> <journal> High Defi nition (HD) World Review, </journal> <volume> Vol. 3, No. 3, </volume> <pages> pp. 4-10, </pages> <year> 1992. </year>
Reference-contexts: Large storage capacity: Given the storage intensive nature of multimedia data, the collective storage requirements for thousands of multimedia documents may exceed tens of terabytes. For example, a movie server with two hundread hdtv quality 20 Mbps <ref> [30, 32] </ref> 2-hour-long movies will require roughly 3.6 terabytes (tbs) of storage. Similarly, a multimedia storage server that stores a large number of multimedia documents each composed of multiple media streams, will require a comparable storage capacity. 3.
References-found: 32

