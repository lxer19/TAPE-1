URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/Preprints/pub49.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/ccd-preprints.html
Root-URL: http://www.cs.yale.edu
Title: Caching in with Multigrid Algorithms: Problems in Two Dimensions  
Author: Craig C. Douglas 
Keyword: Key words: multigrid, cache, sparse matrix, iterative methods, domain decomposition.  
Address: Yorktown Heights, NY, USA;  New Haven, CT, USA.  
Affiliation: 1 IBM T. J. Watson Research Center,  Computer Science Department, Yale University,  
Abstract: Multigrid methods combine a number of standard sparse matrix techniques. Usual implementations separate the individual components (e.g., an iterative methods, residual computation, and interpolation between grids) into nicely structured routines. However, many computers today employ quite sophisticated and potentially large caches whose correct use are instrumental in gaining much of the peak performance of the processors. We investigate when it makes sense to combine several of the multigrid components into one, using block oriented algorithms. We determine how large (or small) the blocks must be in order for the data in the block to just fit into the processor's primary cache. By re-using the data in cache several times, a potential savings in run time can be predicted. This is analyzed for a set of examples. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. H. Bailey, E. Barszcz, J. T. Barton, D. S. Browning, R. L. Carter, L. Dagum, R. A. Fatoohi, S. Fineberg, P. O. Frederickson, T. A. Lasinski, R. S. Schreiber, H. D. Simon, V. Venkatakrish-nan, and S. K. Weeratunga. </author> <title> The NAS parallel benchmarks (94). </title> <type> Technical Report RNR-94-007, </type> <institution> NASA Ames, Ames, </institution> <address> CA, </address> <year> 1994. </year> <note> To obtain the latest version of this document, send e-mail to npb@nas.nasa.gov. </note>
Reference-contexts: ACKNOWLEDGMENTS The author would like to thank Jim Shearer and Uli Rude for helpful discussions. The author became interested in this topic while working on IBM's multigrid entry for the NAS benchmarks (see <ref> [1] </ref> and [2]) in March, 1994.
Reference: [2] <author> D. H. Bailey, E. Barszcz, J. T. Barton, D. S. Browning, R. L. Carter, L. Dagum, R. A. Fatoohi, P. O. Frederickson, T. A. Lasinski, R. S. Schreiber, H. D. Simon, V. Venkatakrishnan, and S. K. Weeratunga. </author> <title> The NAS parallel benchmarks. </title> <journal> Inter. J. Supercomputer Appl., </journal> <volume> 5 </volume> <pages> 63-73, </pages> <year> 1991. </year> <month> 8 </month>
Reference-contexts: ACKNOWLEDGMENTS The author would like to thank Jim Shearer and Uli Rude for helpful discussions. The author became interested in this topic while working on IBM's multigrid entry for the NAS benchmarks (see [1] and <ref> [2] </ref>) in March, 1994.
Reference: [3] <author> R. E. Bank and C. C. Douglas. </author> <title> Sharp estimates for multigrid rates of convergence with general smoothing and acceleration. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 </volume> <pages> 617-633, </pages> <year> 1985. </year>
Reference-contexts: Hence, level 1 is the real problem; all other levels are approximations to this. The linear systems result from discretizing a partial differential equation over a given grid i . The discretization can be any standard finite element, difference, volume, or wavelet approach (see <ref> [3] </ref> and [8] for examples of this approach). In this paper, A i is assumed to be a sparse matrix. A typical multigrid method is based on a V cycle multigrid method is given in Figure 1.
Reference: [4] <author> A. Brandt. </author> <title> Multi-level adaptive solutions to boundary-value problems. </title> <journal> Math. Comp., </journal> <volume> 31 </volume> <pages> 333-390, </pages> <year> 1977. </year>
Reference-contexts: 1 INTRODUCTION In this paper, we investigate the effect computer caches (see [13]) can have on tailored multigrid algorithms (see <ref> [4] </ref>). This topic is timely since larger caches with many cache lines are becoming quite common on computer processors. By the term cache, we mean a fast memory unit closely coupled to the processor. <p> The cache is well balanced if a cache line can be filled from or stored back to memory in a small number of processor cycles. 3 CACHE AWARE ALGORITHMS In this section, a multigrid algorithm (see <ref> [4] </ref>, [5], [9], and [10]) is transformed into a set of cache aware algorithms. An analysis is provided which shows how useful this is for reducing computing time.
Reference: [5] <author> W. L. Briggs. </author> <title> A Multigrid Tutorial. </title> <publisher> SIAM Books, </publisher> <address> Philadelphia, </address> <year> 1987. </year>
Reference-contexts: The cache is well balanced if a cache line can be filled from or stored back to memory in a small number of processor cycles. 3 CACHE AWARE ALGORITHMS In this section, a multigrid algorithm (see [4], <ref> [5] </ref>, [9], and [10]) is transformed into a set of cache aware algorithms. An analysis is provided which shows how useful this is for reducing computing time.
Reference: [6] <author> W. L. Briggs, L. Hart, S. F. McCormick, and D. Quinlan. </author> <title> Multigrid methods on a hypercube. </title> <editor> In S. F. McCormick, editor, </editor> <title> Multigrid Methods: Theory, </title> <booktitle> Applications, and Supercomputing, volume 110 of Lecture Notes in Pure and Applied Mathematics, </booktitle> <pages> pages 63-83. </pages> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: On both serial and parallel computers it also reduces the cost of the prolongation procedure since only the black points need to be corrected. See <ref> [6] </ref>, [7], [11], [12] for more details. Gauss-Seidel with either of these orderings can be made cache aware, but will no longer necessarily have the exact same ordering. Consider the grid in Figure 2, where the boundary points are included in the grid.
Reference: [7] <author> T. F. Chan and R. S. Tuminaro. </author> <title> Design and implementation of parallel multigrid algorithms. </title> <editor> In S. F. McCormick, editor, </editor> <booktitle> Proceedings of the Third Copper Mountain Conference on Multigrid Methods, </booktitle> <pages> pages 101-115, </pages> <address> New York, 1987. </address> <publisher> Marcel Dekker. </publisher>
Reference-contexts: On both serial and parallel computers it also reduces the cost of the prolongation procedure since only the black points need to be corrected. See [6], <ref> [7] </ref>, [11], [12] for more details. Gauss-Seidel with either of these orderings can be made cache aware, but will no longer necessarily have the exact same ordering. Consider the grid in Figure 2, where the boundary points are included in the grid.
Reference: [8] <author> C. C. Douglas. </author> <title> Multi-grid algorithms with applications to elliptic boundary-value problems. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 21 </volume> <pages> 236-254, </pages> <year> 1984. </year>
Reference-contexts: Hence, level 1 is the real problem; all other levels are approximations to this. The linear systems result from discretizing a partial differential equation over a given grid i . The discretization can be any standard finite element, difference, volume, or wavelet approach (see [3] and <ref> [8] </ref> for examples of this approach). In this paper, A i is assumed to be a sparse matrix. A typical multigrid method is based on a V cycle multigrid method is given in Figure 1. Implementing a W Cycle or some hybrid is a straight forward extension to this definition.
Reference: [9] <author> C. C. Douglas and J. Douglas. </author> <title> A unified convergence theory for abstract multigrid or multilevel algorithms, serial and parallel. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 30 </volume> <pages> 136-158, </pages> <year> 1993. </year>
Reference-contexts: The cache is well balanced if a cache line can be filled from or stored back to memory in a small number of processor cycles. 3 CACHE AWARE ALGORITHMS In this section, a multigrid algorithm (see [4], [5], <ref> [9] </ref>, and [10]) is transformed into a set of cache aware algorithms. An analysis is provided which shows how useful this is for reducing computing time.
Reference: [10] <author> C. C. Douglas, J. Douglas, and D. E. Fyfe. </author> <title> A multigrid unified theory for non-nested grids and/or quadrature. </title> <editor> E. W. J. </editor> <title> Numer. </title> <journal> Math., </journal> <volume> 2 </volume> <pages> 285-294, </pages> <year> 1994. </year>
Reference-contexts: The cache is well balanced if a cache line can be filled from or stored back to memory in a small number of processor cycles. 3 CACHE AWARE ALGORITHMS In this section, a multigrid algorithm (see [4], [5], [9], and <ref> [10] </ref>) is transformed into a set of cache aware algorithms. An analysis is provided which shows how useful this is for reducing computing time. Consider solving the following set of problems: A i u i = f i ; 1 i k; where u i 2 IR n i .
Reference: [11] <author> S. F. McCormick. </author> <title> Multigrid Methods, </title> <booktitle> volume 3 of Frontiers in Applied Mathematics. </booktitle> <publisher> SIAM Books, </publisher> <address> Philadelphia, </address> <year> 1987. </year>
Reference-contexts: On both serial and parallel computers it also reduces the cost of the prolongation procedure since only the black points need to be corrected. See [6], [7], <ref> [11] </ref>, [12] for more details. Gauss-Seidel with either of these orderings can be made cache aware, but will no longer necessarily have the exact same ordering. Consider the grid in Figure 2, where the boundary points are included in the grid.
Reference: [12] <author> S. V. Parter. </author> <title> Estimates for multigrid methods based on red-black Gauss-Seidel smoothings. </title> <journal> Numer. Math., </journal> <volume> 52 </volume> <pages> 701-723, </pages> <year> 1988. </year>
Reference-contexts: On both serial and parallel computers it also reduces the cost of the prolongation procedure since only the black points need to be corrected. See [6], [7], [11], <ref> [12] </ref> for more details. Gauss-Seidel with either of these orderings can be made cache aware, but will no longer necessarily have the exact same ordering. Consider the grid in Figure 2, where the boundary points are included in the grid.
Reference: [13] <author> D. A. Patterson and J. L. Hennessy. </author> <title> Computer Architecture: A Quantative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <month> 9 </month>
Reference-contexts: 1 INTRODUCTION In this paper, we investigate the effect computer caches (see <ref> [13] </ref>) can have on tailored multigrid algorithms (see [4]). This topic is timely since larger caches with many cache lines are becoming quite common on computer processors. By the term cache, we mean a fast memory unit closely coupled to the processor. <p> In x3, cache aware algorithms are developed and analyzed. 1 2 A CACHE MODEL A complete description of all of the types of caches currently in use by the computer industry is beyond the scope of this paper (see <ref> [13] </ref> for an extensive description). However, a model is developed in this section that will be used to analyze the cache aware algorithms in x3. Some processors have several levels of caches. In this paper, only the primary cache is studied.
References-found: 13

