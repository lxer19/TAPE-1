URL: ftp://ftp.cs.huji.ac.il/users/transis/framework.ps
Refering-URL: http://www.cs.huji.ac.il/labs/transis/abstracts95.html
Root-URL: http://www.cs.huji.ac.il
Title: A Framework for Partitionable Membership Service  
Author: Danny Dolev Dalia Malki Ray Strong 
Address: Jerusalem, Israel  San Jose, USA  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  IBM Almaden Research Center,  
Pubnum: Technical Report CS95-4  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. </author> <title> Membership Algorithms for Multicast Communication Groups. </title> <booktitle> In 6th Intl. Workshop on Distributed Algorithms proceedings (WDAG-6), (LCNS, </booktitle> <volume> 647), </volume> <pages> pages 292-312, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Through these applications, we demonstrate the usability and benefits of the methodology we developed, and in particular, of partitionable operation. Several membership protocols that implement a partitionable methodology have been developed: The Transis system originally incorporated the protocol published in <ref> [1] </ref>. This protocol satisfies most but not all of the requisites we propose for a membership service. Later, the Transis system converted to the protocol in [8], which satisfies our entire definition.
Reference: [2] <author> Y. Amir, D. Dolev, P. M. Melliar-Smith, and L. E. Moser. </author> <title> Robust and Efficient Replication using Group Communication. </title> <type> Technical Report CS94-20, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: This protocol, called E3PH, enhances the well known three-phase commit protocol [18] at no additional cost. * Yet another algorithm for providing a long-term consistent replication service in a partitionable environment is provided in <ref> [2] </ref>. This algorithm is novel in providing consistent fault tolerant replication without need to log updates onto non-volatile storage before performing them. It requires end-to-end acknowledgment only on membership changes, and not on each update message. <p> The main justification we currently find for Requisite M.6 is the need to maintain an ordered sequence of primary components, which is evident in the works of Keidar et al. [10, 11] and the work of Amir et al. <ref> [2] </ref>. In these algorithms, every component remains active and may perform asynchronous update requests (i.e., without waiting for result). Only one component (the primary) may decide on the order of updates and perform them. Later, the order decisions diffuse throughout the system.
Reference: [3] <author> Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, and P. Ciarfella. </author> <title> Fast Message Ordering and Membership Using a Logical Token-Passing Ring. </title> <booktitle> In Intl. Conference on Distributed Computing Systems, </booktitle> <pages> pages 551-560, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Later, the Transis system converted to the protocol in [8], which satisfies our entire definition. The Totem system contains a different version of the membership protocol, suitable for establishing a view with an ordered ring of machines <ref> [3] </ref>. The Horus system partially implements our framework [19]. The membership service of the Amoeba system [9] allows the system to partition, but does not provide any solution for merging operational components upon reconnection. The system allows the user some flexibility in specifying whether the system may partition or not. <p> We note that the causal communication properties C.1, C.2, C.3, and C.4, are currently supported in many systems, e.g. <ref> [3, 5, 13, 16, 19] </ref>. 5 The Membership Module The membership module maintains a local view of the system configuration, and reports about changes in the view via M-install events. <p> i.e. q also reports of a possibly hidden membership installation of , or * crash q 2 H. 6 Experience with the Partitionable Framework The definition of a partitionable membership service as presented above has evolved through practical experiments in the Transis project [13], as well as the Totem project <ref> [3] </ref> and the Horus project [19]. Several applications and algorithms have already been developed with our partitionable methodology: * The CoRel replication service [10] operates in an environment prone both to machine crashes and to network partitions.
Reference: [4] <author> K. P. Birman and T. Joseph. </author> <title> Exploiting Virtual Synchrony in Distributed Systems. </title> <booktitle> In 11th Ann. Symp. Operating Systems Principles, </booktitle> <pages> pages 123-138, </pages> <month> Nov 87. </month>
Reference-contexts: Changes to the membership are coordinated with the delivery of regular messages in the system. This valuable approach was presented in <ref> [4] </ref> in the context of a primary-partition system, and is extended here for partitionable systems. Its importance is in providing the distributed application builder with a virtually synchronous programming environment. <p> However, the local view is coordinated with the local views of other members of the view, so that a synchronous environment is simulated, and the participants cannot distinguish it from their environment. This principle is called virtual synchrony <ref> [4] </ref>, and is extended in this paper to partitionable environments. We model the operation of the system as a sequence of events that take place in different modules and at different machines. Each such sequence of events is called a history. <p> Using this approach, the task of a distributed application designer is made easier: Coordinated decisions can be made based solely on the current membership view, and the contents of received messages, without need for further interaction. This valuable principle, termed virtual synchrony, is defined in <ref> [4] </ref>. The next requisite expresses the demands on the relative order of message delivery and view installations: Requisite M.3 (Virtual-Synchrony) (1) The first event in the history of every process is of type M-install. (2) Messages are M-delivered in an order that preserves causality.
Reference: [5] <author> K. P. Birman and R. van Renesse. </author> <title> Reliable Distributed Computing with the Isis Toolkit. </title> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: We note that the causal communication properties C.1, C.2, C.3, and C.4, are currently supported in many systems, e.g. <ref> [3, 5, 13, 16, 19] </ref>. 5 The Membership Module The membership module maintains a local view of the system configuration, and reports about changes in the view via M-install events.
Reference: [6] <author> T. D. Chandra and S. Toueg. </author> <title> Unreliable Failure Detectors for Asynchronous Systems. </title> <booktitle> In proc. 10th annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 325-340, </pages> <year> 1991. </year>
Reference-contexts: In practice, this deficiency does not limit our approach, since failure-detection in asynchronous environments is inaccurate anyway. However, adding such restrictions would allow us to analyze the framework in environments extended with failure detectors (e.g. the failure detectors discussed in <ref> [6] </ref>). We are currently investigating the extension of our framework to incorporate such restrictions. 13 7 Conclusions In a world of growing dependency on computers, the ability to continue operation in a dynamic environment is crucial.
Reference: [7] <author> F. Cristian. </author> <title> Reaching agreement on processor group membership in synchronous distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 4(4) </volume> <pages> 175-187, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The problem of maintaining a consistent view of the reachable operational machines is fundamental to the design of fault tolerant distributed systems. Cristian provides a formal definition of the membership problem in a synchronous environment in <ref> [7] </ref>. For an asynchronous environment, Ricciardi et al. define the membership problem in [17]. In this paper, we address three issues that are not adequately addressed by prior work in the extensive literature on the membership problem: 1. Partition. <p> The next requirement specifies what should happen when a machine installs a certain membership view. The requisite below is at the heart of the definition of the partitionable membership, and distinguishes it from traditional primary partition approaches: Primary partition membership services (e.g. <ref> [7, 17] </ref>) require that only one system view exists. In case of a view installation by any member of the view, all the other members are required to eventually install it, or give up.
Reference: [8] <author> D. Dolev, D. Malki, and H. R. </author> <title> Strong. An Asynchronous Membership Protocol that Tolerates Partitions. </title> <note> submitted for publication. Available as CS TR94-6, </note> <institution> Institute of Computer Science, the Hebrew University of Jerusalem, </institution> <year> 1994. </year>
Reference-contexts: Several membership protocols that implement a partitionable methodology have been developed: The Transis system originally incorporated the protocol published in [1]. This protocol satisfies most but not all of the requisites we propose for a membership service. Later, the Transis system converted to the protocol in <ref> [8] </ref>, which satisfies our entire definition. The Totem system contains a different version of the membership protocol, suitable for establishing a view with an ordered ring of machines [3]. The Horus system partially implements our framework [19].
Reference: [9] <author> M. F. Kaashoek and A. S. Tanenbaum. </author> <title> Group Communication in the Amoeba Distributed Operating System. </title> <booktitle> In 11th Intl. Conference on Distributed Computing Systems, </booktitle> <pages> pages 882-891, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The Totem system contains a different version of the membership protocol, suitable for establishing a view with an ordered ring of machines [3]. The Horus system partially implements our framework [19]. The membership service of the Amoeba system <ref> [9] </ref> allows the system to partition, but does not provide any solution for merging operational components upon reconnection. The system allows the user some flexibility in specifying whether the system may partition or not.
Reference: [10] <author> I. Keidar. </author> <title> A Highly Available Paradigm for Consistent Object Replication. </title> <type> Master's thesis, </type> <institution> Inst. of Computer Science, The Hebrew University of Jerusalem, </institution> <year> 1994. </year> <note> Also available as Technical Report CS95-5. submitted for publication. </note>
Reference-contexts: Our framework differs from EVS in providing a clean separation of the (causal) communication subsystem from membership maintenance. EVS does not provide information about possibly hidden membership installations, that is required in applications like CoRel <ref> [10] </ref> (discussed below). The EVS model introduces transient membership changes that enable the delivery of safe messages upon failures. <p> Several applications and algorithms have already been developed with our partitionable methodology: * The CoRel replication service <ref> [10] </ref> operates in an environment prone both to machine crashes and to network partitions. CoRel allows multiple components in a partitioned network to be active, and eventually converges all components to order updates in a consistent manner. <p> The main justification we currently find for Requisite M.6 is the need to maintain an ordered sequence of primary components, which is evident in the works of Keidar et al. <ref> [10, 11] </ref> and the work of Amir et al. [2]. In these algorithms, every component remains active and may perform asynchronous update requests (i.e., without waiting for result). Only one component (the primary) may decide on the order of updates and perform them.
Reference: [11] <author> I. Keidar and D. Dolev. </author> <title> Increasing the Resilience of Atomic Commit, at No Additional Cost. </title> <booktitle> In Symp. on Prin. of Database Systems, </booktitle> <month> May </month> <year> 1995. </year> <note> to appear. Previous version available as Technical Report CS94-18, </note> <institution> The Hebrew University, Jerusalem, Isreal. </institution>
Reference-contexts: To the best of our knowledge, no other replication algorithm has this property. * Using similar ideas to CoRel, it was shown in <ref> [11] </ref> how to provide an atomic commitment protocol (ACP) that never blocks a majority. This protocol, called E3PH, enhances the well known three-phase commit protocol [18] at no additional cost. * Yet another algorithm for providing a long-term consistent replication service in a partitionable environment is provided in [2]. <p> The main justification we currently find for Requisite M.6 is the need to maintain an ordered sequence of primary components, which is evident in the works of Keidar et al. <ref> [10, 11] </ref> and the work of Amir et al. [2]. In these algorithms, every component remains active and may perform asynchronous update requests (i.e., without waiting for result). Only one component (the primary) may decide on the order of updates and perform them. <p> Exactly how the hidden view information is used is application dependent. For example, the atomic commitment protocol in <ref> [11] </ref> simply maintains an additional context-counter, that is incremented upon hidden installations. Using this counter in the scenario above, A can determine that it represents a more recent primary component than C.
Reference: [12] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Comm. ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July 78. </month>
Reference-contexts: Note that this is a different event from the install event (below) that establishes a new membership view without q. Let H be a history of the events in the system. Following Lamport <ref> [12] </ref>, we define the causal order of messages as the reflexive, transitive closure of: (1) m cause ! m 0 if m 0 is sent by some machine q after it had delivered m, i.e. if C-deliver q (m) H ! C-multicast q (m 0 ; fl). (2) m cause !
Reference: [13] <author> D. Malki, Y. Amir, D. Dolev, and S. Kramer. </author> <title> The Transis Approach to High Availability Cluster Communication. </title> <type> TR 94-14, </type> <institution> Inst. of Comp. Sci., The Hebrew University of Jerusalem, </institution> <month> June </month> <year> 1994. </year> <month> 15 </month>
Reference-contexts: We note that the causal communication properties C.1, C.2, C.3, and C.4, are currently supported in many systems, e.g. <ref> [3, 5, 13, 16, 19] </ref>. 5 The Membership Module The membership module maintains a local view of the system configuration, and reports about changes in the view via M-install events. <p> the following events: * M-hidden q (), i.e. q also reports of a possibly hidden membership installation of , or * crash q 2 H. 6 Experience with the Partitionable Framework The definition of a partitionable membership service as presented above has evolved through practical experiments in the Transis project <ref> [13] </ref>, as well as the Totem project [3] and the Horus project [19]. Several applications and algorithms have already been developed with our partitionable methodology: * The CoRel replication service [10] operates in an environment prone both to machine crashes and to network partitions.
Reference: [14] <author> D. Malki and R. van Renesse. </author> <title> The Replication Service Layer. </title> <type> internal manuscript, </type> <year> 1994. </year>
Reference-contexts: It requires end-to-end acknowledgment only on membership changes, and not on each update message. The algorithm requires certain properties of the EVS model [15]. 11 * A general purpose message logging and replaying service is given in the Persistent Replication Service Layer (PRSL) of Horus <ref> [14] </ref>. Unlike the above applications, the order of messages in this application is unimportant, and the goal is to diffuse messages throughout the system despite failures and partitions. The PRSL performs automatic merging of detached components upon recovery.
Reference: [15] <author> L. E. Moser, Y. Amir, P. M. Melliar-Smith, and D. A. Agarwal. </author> <title> Extended virtual synchrony. </title> <booktitle> In Proceedings of the Fourteenth Intl. Conference on Distributed Computing Systems, </booktitle> <pages> pages 56-65, </pages> <address> Poznan, Poland, </address> <month> June </month> <year> 1994. </year> <note> IEEE. Also available as technical report ECE93-22, </note> <institution> Department of Electrical and Computer Engineering, University of California, Santa Barbara, </institution> <address> CA. </address>
Reference-contexts: The system allows the user some flexibility in specifying whether the system may partition or not. The work of Moser et al. on Extended Virtual Synchrony (EVS) <ref> [15] </ref> models the delivery of totally ordered uniform broadcast messages (called safe messages) in a partitionable environment. Our framework differs from EVS in providing a clean separation of the (causal) communication subsystem from membership maintenance. <p> This algorithm is novel in providing consistent fault tolerant replication without need to log updates onto non-volatile storage before performing them. It requires end-to-end acknowledgment only on membership changes, and not on each update message. The algorithm requires certain properties of the EVS model <ref> [15] </ref>. 11 * A general purpose message logging and replaying service is given in the Persistent Replication Service Layer (PRSL) of Horus [14]. Unlike the above applications, the order of messages in this application is unimportant, and the goal is to diffuse messages throughout the system despite failures and partitions.
Reference: [16] <author> L. L. Peterson, N. C. Buchholz, and R. D. Schlichting. </author> <title> Preserving and Using Context Information in Interprocess Communication. </title> <journal> ACM Trans. Comput. Syst., </journal> <volume> 7(3) </volume> <pages> 217-246, </pages> <month> August 89. </month>
Reference-contexts: We note that the causal communication properties C.1, C.2, C.3, and C.4, are currently supported in many systems, e.g. <ref> [3, 5, 13, 16, 19] </ref>. 5 The Membership Module The membership module maintains a local view of the system configuration, and reports about changes in the view via M-install events.
Reference: [17] <author> A. M. Ricciardi and K. P. Birman. </author> <title> Using Process Groups to Implement Failure Detection in Asynchronous Environments. </title> <booktitle> In proc. annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 341-352, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Cristian provides a formal definition of the membership problem in a synchronous environment in [7]. For an asynchronous environment, Ricciardi et al. define the membership problem in <ref> [17] </ref>. In this paper, we address three issues that are not adequately addressed by prior work in the extensive literature on the membership problem: 1. Partition. Most prior work focuses on the maintenance of a primary component membership service. <p> The next requirement specifies what should happen when a machine installs a certain membership view. The requisite below is at the heart of the definition of the partitionable membership, and distinguishes it from traditional primary partition approaches: Primary partition membership services (e.g. <ref> [7, 17] </ref>) require that only one system view exists. In case of a view installation by any member of the view, all the other members are required to eventually install it, or give up. <p> In this case, q will not be able to install the view, because it lacks support from the other members. On the other hand, q has created the possibility for other members to install the view, because they may get q's support along with all the others. In <ref> [17] </ref>, this situation is called hidden membership installation. First, let us discuss how primary partition services handle hidden installations. When a view-installation attempt fails in a primary partition membership service, some kind of a recovery protocol is performed.
Reference: [18] <author> D. Skeen. </author> <title> Nonblocking Commit Protocols. </title> <booktitle> In SIGMOD Intl. Conf. Management of Data, </booktitle> <year> 1981. </year>
Reference-contexts: To the best of our knowledge, no other replication algorithm has this property. * Using similar ideas to CoRel, it was shown in [11] how to provide an atomic commitment protocol (ACP) that never blocks a majority. This protocol, called E3PH, enhances the well known three-phase commit protocol <ref> [18] </ref> at no additional cost. * Yet another algorithm for providing a long-term consistent replication service in a partitionable environment is provided in [2]. This algorithm is novel in providing consistent fault tolerant replication without need to log updates onto non-volatile storage before performing them.
Reference: [19] <author> R. van Renesse, K. P. Birman, B. Glade, K. Guo, M. Hayden, T. M. Hickey, D. Malki, A. Vaysburd, and W. Vogels. </author> <title> The Design and Performance of Horus: A Flexible Group Communication System. </title> <note> Submitted for publication. Previous version available as technical report 94-1442, </note> <institution> dept. of comp. sci., Cornell U., </institution> <month> March </month> <year> 1995. </year> <month> 16 </month>
Reference-contexts: Later, the Transis system converted to the protocol in [8], which satisfies our entire definition. The Totem system contains a different version of the membership protocol, suitable for establishing a view with an ordered ring of machines [3]. The Horus system partially implements our framework <ref> [19] </ref>. The membership service of the Amoeba system [9] allows the system to partition, but does not provide any solution for merging operational components upon reconnection. The system allows the user some flexibility in specifying whether the system may partition or not. <p> Note that additional modules may be placed in the transport layer for added functionality. For example, the Transis and Horus systems contain message ordering modules and a lightweight process group module. We leave out of the current discussion other layers, and refer the interested reader to <ref> [19] </ref>. As shown in Figure 1, messages sent by the user application travel down the protocol hierarchy until finally they are transmitted on the network. Similarly, intercepted messages 3 are passed up the protocol hierarchy until they are delivered to the user application. <p> We note that the causal communication properties C.1, C.2, C.3, and C.4, are currently supported in many systems, e.g. <ref> [3, 5, 13, 16, 19] </ref>. 5 The Membership Module The membership module maintains a local view of the system configuration, and reports about changes in the view via M-install events. <p> a possibly hidden membership installation of , or * crash q 2 H. 6 Experience with the Partitionable Framework The definition of a partitionable membership service as presented above has evolved through practical experiments in the Transis project [13], as well as the Totem project [3] and the Horus project <ref> [19] </ref>. Several applications and algorithms have already been developed with our partitionable methodology: * The CoRel replication service [10] operates in an environment prone both to machine crashes and to network partitions.
References-found: 19

