URL: ftp://ftp.ics.uci.edu/pub/machine-learning-papers/publications/Domingos-TAI-94-RISE.ps.Z
Refering-URL: http://www.ics.uci.edu/AI/ML/MLAbstracts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The RISE System: Conquering Without Separating  
Author: Pedro Domingos 
Address: Irvine, California 92717, U.S.A.  
Affiliation: Department of Information and Computer Science University of California, Irvine  
Abstract: Current rule induction systems (e.g. CN2) typically rely on a "separate and conquer" strategy, learning each rule only from still-uncovered examples. This results in a dwindling number of examples being available for learning successive rules, adversely affecting the system's accuracy. An alternative is to learn all rules simultaneously, using the entire training set for each. This approach is implemented in the Rise 1.0 system. Empirical comparison of Rise with CN2 suggests that "conquering without separating" performs similarly to its counterpart in simple domains, but achieves increasingly substantial gains in accuracy as the domain difficulty grows. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Buntine and T. Niblett, </author> <title> "A further comparison of splitting rules for decision tree induction," </title> <journal> Machine Learning, </journal> <volume> Vol. 8, </volume> <pages> pp. 75-86, </pages> <year> 1992. </year>
Reference-contexts: p (r) is the number of examples covered by the rule whose consequents are identical to the rule's ("positive" examples) , n (r) is the number of examples covered by the rule whose consequents are different from the rule's ("negative" ones), S is the sample (training set) size, and 2 <ref> [0; 1] </ref> is a noise tolerance coefficient. The idea behind is that in noisier domains rules should be allowed to cover a greater proportion of negative examples; in noiseless domains this proportion should be 0. <p> Removing this attribute causes the difficulty of the domain to increase 1 Right tail if the difference was positive, left one if negative. 50 60 70 80 90 100 Accuracy (%) No. examples RISE CN2 BCD _ CDA _ DAB, with 6 irrelevant attributes. substantially <ref> [1] </ref>, making possible an evaluation of performance variation with difficulty while holding other factors constant. Ten-fold cross-validation was performed for Rise and CN2, using the same training and test sets for the two at each step.
Reference: [2] <author> P. Clark and R. Boswell, </author> <title> "Rule induction with CN2: Some recent improvements," </title> <booktitle> Proc. EWSL-91, </booktitle> <pages> pp. 151-163, </pages> <year> 1991. </year>
Reference-contexts: CN2 [3] was chosen for this purpose because it is probably the most extensively evaluated noise-tolerant algorithm of this type. A recent, enhanced version was used <ref> [2] </ref>. All options were set so as to maximize similarity to Rise; all save the star size (set to 1) are the defaults.
Reference: [3] <author> P. Clark and T. Niblett, </author> <title> "The CN2 induction algorithm," </title> <journal> Machine Learning, </journal> <volume> Vol. 3, </volume> <pages> pp. 261-283, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction and motivation Current machine learning approaches to the induction of concept definitions from examples fall mainly into two categories: "divide and conquer" [8] and "separate and conquer" <ref> [6, 3] </ref>. The former recursively partition the instance space until regions of roughly uniform class membership are obtained. The latter induce one rule at a time, removing the newly covered examples from the training set after each step. <p> In the remainder of this paper Rise is described and then empirically compared with CN2 <ref> [3] </ref>. 2 The RISE algorithm The Rise 1.0 system induces a set of rules (the hypothesis) from a set of examples (the training set). Rules and examples have a similar representation: a conjunction of attribute values (the antecedents), and a predicted class. <p> Simple computations show that RISE's worst-case time complexity is quadratic in the number of examples and cubic in the number of attributes, which is competitive with e.g. CN2. (Note that the computations in <ref> [3] </ref> are only for the basic step of the algorithm.) With numeric attributes, RISE's worst-case running time also depends linearly on the average number of observed values per attribute. <p> See [4] for details. 3 Empirical evaluation With the goal of empirically evaluating the usefulness of the "conquering without separating" strategy, Rise was compared with a current "separate-and-conquer" rule induction algorithm on a number of natural and artificial domains. CN2 <ref> [3] </ref> was chosen for this purpose because it is probably the most extensively evaluated noise-tolerant algorithm of this type. A recent, enhanced version was used [2]. All options were set so as to maximize similarity to Rise; all save the star size (set to 1) are the defaults. <p> The other observation comes from the trio of medical domains (lymphography, breast cancer, and primary tumor) where CN2 was originally tested <ref> [3] </ref> and that is probably the most widely used in the machine learning literature: there is no significant difference in the "easier" ones, but Rise is significantly better in the "harder" one (primary tumor).
Reference: [4] <author> P. Domingos, </author> <title> "Design and Evaluation of the RISE 1.0 Learning System", </title> <type> Technical Report 94-34, </type> <institution> UCI, Dept. ICS, </institution> <address> Irvine, CA, </address> <year> 1994. </year>
Reference-contexts: CN2. (Note that the computations in [3] are only for the basic step of the algorithm.) With numeric attributes, RISE's worst-case running time also depends linearly on the average number of observed values per attribute. See <ref> [4] </ref> for details. 3 Empirical evaluation With the goal of empirically evaluating the usefulness of the "conquering without separating" strategy, Rise was compared with a current "separate-and-conquer" rule induction algorithm on a number of natural and artificial domains. <p> This behavior may be attributable to the fact that harder domains typically contain a greater number of disjuncts, each covering fewer examples, worsening the splintering and small disjuncts problems. Conversely, the presence of fewer large disjuncts reduces their masking effect on non-separating algorithms, improving their relative performance. See <ref> [4] </ref> for further discussion and future work. Acknowledgments This work was partly supported by JNICT/Programa Ci^encia and Fulbright scholarships. The author is grateful to Dennis Kibler and Mike Pazzani for many helpful comments and suggestions, to Peter Clark for supplying CN2, and to M. Zwitter and M.
Reference: [5] <author> R. C. Holte, L. E. Acker, and B. W. Porter, </author> <title> "Concept learning and the problem of small disjuncts," </title> <booktitle> Proc. IJCAI-89, </booktitle> <pages> pp. 813-818, </pages> <year> 1989. </year>
Reference-contexts: As a result, it may not be possible to reliably induce some rules to their full length, causing either overly general or incorrect rules to be produced, and negatively affecting accuracy. A related problem, first identified by Holte and coworkers <ref> [5] </ref>, is that of small disjuncts. While covering relatively few examples, small disjuncts tend to be responsible for a disproportionate share of the clas sification errors committed. Many of these disjuncts undoubtedly represent actual small disjuncts in the domain.
Reference: [6] <author> R. S. Michalski, </author> <title> "A theory and methodology of inductive learning," </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 20, </volume> <pages> pp. 111-161, </pages> <year> 1983. </year>
Reference-contexts: 1 Introduction and motivation Current machine learning approaches to the induction of concept definitions from examples fall mainly into two categories: "divide and conquer" [8] and "separate and conquer" <ref> [6, 3] </ref>. The former recursively partition the instance space until regions of roughly uniform class membership are obtained. The latter induce one rule at a time, removing the newly covered examples from the training set after each step.
Reference: [7] <author> P. M. Murphy and D. W. Aha, </author> <title> UCI repository of machine learning databases, machine-readable data repository, </title> <institution> UCI, Dept. ICS, </institution> <address> Irvine, CA, </address> <year> 1992. </year>
Reference-contexts: In the hardest concept (Fig. 3) this difference is even more pronounced, leading to the hypothesis that conquering without separating becomes more advantageous as domain difficulty increases. 3.2 Natural domains Tests were conducted in 16 domains from the UCI repository <ref> [7] </ref> to determine if this behavior is observable in practical situations (see Table 2). The voting domain was tried in two forms: with and without the "physician fee freeze" attribute.
Reference: [8] <author> J. R. Quinlan, </author> <title> "Induction of decision trees," </title> <journal> Machine Learning, </journal> <volume> Vol. 1, </volume> <pages> pp. 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction and motivation Current machine learning approaches to the induction of concept definitions from examples fall mainly into two categories: "divide and conquer" <ref> [8] </ref> and "separate and conquer" [6, 3]. The former recursively partition the instance space until regions of roughly uniform class membership are obtained. The latter induce one rule at a time, removing the newly covered examples from the training set after each step.
Reference: [9] <author> L. Rendell and H. Ragavan, </author> <title> "Improving the design of induction methods by analyzing algorithm functionality and data-based concept complexity," </title> <booktitle> Proc. IJCAI-93, </booktitle> <pages> pp. 952-958, </pages> <year> 1993. </year>
Reference-contexts: domains the results reported here for CN2 are the best ever. 50 60 70 80 90 100 Accuracy (%) No. examples RISE CN2 BC _ DEF _ GHIJ. 3.1 Artificial domains Rise and CN2 were tested on three boolean functions of varying degrees of difficulty according to the blurring measure <ref> [9] </ref>. Learning was carried out on sets of 16, 32, 64, 128, 256 and 512 examples, randomly chosen with uniform probability from the 1024 possible, and the induced rules were tested on the remaining examples. This procedure was repeated 20 times for each domain.
References-found: 9

