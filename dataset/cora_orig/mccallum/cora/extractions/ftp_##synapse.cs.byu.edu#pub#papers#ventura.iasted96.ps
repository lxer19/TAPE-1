URL: ftp://synapse.cs.byu.edu/pub/papers/ventura.iasted96.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Title: Concerning a General Framework for the Development of Intelligent Systems  
Author: Dan Ventura Tony R. Martinez 
Keyword: Key Words: Cognition, Hybrid Systems, Connectionism, Symbolism  
Address: Provo, Utah 84602  
Affiliation: Computer Science Department, Brigham Young University,  
Note: Proceedings of the IASTED International Conference on Expert Systems, Artificial Intelligence, and Neural Networks, pp.  
Email: e-mail: dan@axon.cs.byu.edu, martinez@cs.byu.edu  
Date: 44-47, 1996  
Abstract: There exists ongoing debate between Connectionism and Symbolism as to the nature of and approaches to cognition. Many viewpoints exist and various issues seen as important have been raised. This paper suggests that a combination of these methodologies will lead to a better overall model. The paper reviews and assimilates the opinions and viewpoints of these diverse fields and provides a cohesive list of issues thought to be critical to the modeling of intelligence. Further, this list results in a framework for the development of a general, unified theory of cognition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rumelhart, David E., McClelland, James L. </author> <title> and the PDP Research Group, Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: 1. Introduction Developing artificial models of cognition is a challenging field that has roots in such diverse fields as cognitive psychology, computer science, linguistics, neurophysiology, and mathematics. Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism <ref> [1] </ref> [2], Symbolic Artificial Intelligence [3], Fuzzy Logic [4], Machine Learning [5] and Genetic Algorithms [6], to name a few.
Reference: [2] <author> Wasserman, Philip D., </author> <title> Advanced Methods in Neural Computing, </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1993. </year>
Reference-contexts: 1. Introduction Developing artificial models of cognition is a challenging field that has roots in such diverse fields as cognitive psychology, computer science, linguistics, neurophysiology, and mathematics. Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism [1] <ref> [2] </ref>, Symbolic Artificial Intelligence [3], Fuzzy Logic [4], Machine Learning [5] and Genetic Algorithms [6], to name a few.
Reference: [3] <author> Russel, Stuart and Norvig, Peter, </author> <title> Artificial Intelligence: A Modern Approach, </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism [1] [2], Symbolic Artificial Intelligence <ref> [3] </ref>, Fuzzy Logic [4], Machine Learning [5] and Genetic Algorithms [6], to name a few.
Reference: [4] <author> Zadeh, L. A., </author> <title> Fuzzy Logic, </title> <booktitle> IEEE Computer, </booktitle> <pages> 83-93, </pages> <year> 1988. </year>
Reference-contexts: Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism [1] [2], Symbolic Artificial Intelligence [3], Fuzzy Logic <ref> [4] </ref>, Machine Learning [5] and Genetic Algorithms [6], to name a few. Each of these approaches to modeling cognition (or, more accurately, some aspect thereof) has various strengths and weaknesses that are becoming better understood, and each claims some fairly impressive successes as well as some disheartening failures.
Reference: [5] <editor> Shavlik, Jude W. and Diettrich, Thomas G. (eds.), </editor> <booktitle> Readings in Machine Learning, </booktitle> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism [1] [2], Symbolic Artificial Intelligence [3], Fuzzy Logic [4], Machine Learning <ref> [5] </ref> and Genetic Algorithms [6], to name a few. Each of these approaches to modeling cognition (or, more accurately, some aspect thereof) has various strengths and weaknesses that are becoming better understood, and each claims some fairly impressive successes as well as some disheartening failures.
Reference: [6] <author> Goldberg, David E., </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Due at least in part to this fact, vastly differing theories for explaining and/or imitating cognitive capabilities have been developed including Connectionism [1] [2], Symbolic Artificial Intelligence [3], Fuzzy Logic [4], Machine Learning [5] and Genetic Algorithms <ref> [6] </ref>, to name a few. Each of these approaches to modeling cognition (or, more accurately, some aspect thereof) has various strengths and weaknesses that are becoming better understood, and each claims some fairly impressive successes as well as some disheartening failures.
Reference: [7] <editor> Barndan, John A. and Pollack, J. B. (eds.), </editor> <title> Advances in Connectionist and Neural Computation Theory 1, High-level Connectionist Models, </title> <publisher> Ablex, </publisher> <year> 1991. </year>
Reference-contexts: Efforts in this direction have variously been referred to as Hybrid Systems, High-Level Connectionism, Symbolic Connectionism, Symbol Processing Connectionist Systems and the like. Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties <ref> [7] </ref> [8], a proliferation of new books on the subject ([9] [10] [11] [12], for example) indicates its increasing importance.
Reference: [8] <author> Hinton, G. E. (ed.), </author> <title> Connectionist Symbol Processing, </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Efforts in this direction have variously been referred to as Hybrid Systems, High-Level Connectionism, Symbolic Connectionism, Symbol Processing Connectionist Systems and the like. Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] <ref> [8] </ref>, a proliferation of new books on the subject ([9] [10] [11] [12], for example) indicates its increasing importance.
Reference: [9] <editor> Goonatilake, Suran and Khebbal, Sukhdev (eds.), </editor> <title> Intelligent Hybrid Systems, </title> <publisher> John Wiley & Sons, </publisher> <year> 1995. </year>
Reference-contexts: Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject (<ref> [9] </ref> [10] [11] [12], for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of a formal theory for the integration of Connectionism with Symbolism and thus for a general theory of (artificial) intelligence.
Reference: [10] <author> Honavar, Vasant, and Uhr, Leonard (eds.), </author> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] <ref> [10] </ref> [11] [12], for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the <p> Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] <ref> [10] </ref> [11] [12], for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of a formal theory for the integration of Connectionism with Symbolism and thus for a general theory of (artificial) intelligence. <p> Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] [20] [21] [22], while others argue for their equivalence and cite performance issues as the main concern [23] <ref> [10] </ref>. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25].
Reference: [11] <author> Levine, Daniel S. and Aparicio, Manuel (eds.), </author> <title> Neural Networks for Knowledge Representation and Inference, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1994. </year>
Reference-contexts: Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] [10] <ref> [11] </ref> [12], for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development <p> work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] [10] <ref> [11] </ref> [12], for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of a formal theory for the integration of Connectionism with Symbolism and thus for a general theory of (artificial) intelligence.
Reference: [12] <author> Sun, Ron and Bookman, Lawrence (eds.), </author> <title> Computational Architectures Integrating Neural and Symbolic Processes: A Perspective on the State of the Art, </title> <publisher> Kluwer Academic, </publisher> <year> 1995. </year>
Reference-contexts: Though work in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] [10] [11] <ref> [12] </ref>, for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of <p> in this area has been ongoing since the resurgence of Connectionism in the late eighties [7] [8], a proliferation of new books on the subject ([9] [10] [11] <ref> [12] </ref>, for example) indicates its increasing importance. To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] [13], and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of a formal theory for the integration of Connectionism with Symbolism and thus for a general theory of (artificial) intelligence.
Reference: [13] <author> Shibata, Takanori and Fukuda, Toshio, </author> <title> Hierarchical Intelligent Control for Robotic Motion, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, no. 5, </volume> <pages> 823-32, </pages> <year> 1994. </year>
Reference-contexts: To date, the field of Hybrid Systems has produced some interesting applications [9] [10] [11] [12] <ref> [13] </ref>, and some ground work has been laid concerning the proper integration of various approaches to modeling cognition; however, the critical next step must be the development of a formal theory for the integration of Connectionism with Symbolism and thus for a general theory of (artificial) intelligence.
Reference: [14] <author> Fodor, J. A. and Pylyshyn, Z.W., </author> <title> Connectionism and Cognitive Architecture: A Critical Analysis, </title> <journal> Cognition, </journal> <volume> vol 28, </volume> <pages> 3-71, </pages> <year> 1988. </year>
Reference-contexts: Other than this extremely basic commonality, there is little else involving the issue of Connectionism and Symbolism that enjoys any kind of majority consent. Some researchers argue that Connectionism is fatally flawed as a model of cognition <ref> [14] </ref> or that while Connectionism may play a minor though important role, Symbolism represents the heart of any realistic model [15]. On the other hand, cases are presented for the desirability of Connectionism over Symbolism [16] and that the eventual dominance of Connectionism is only a matter of time [17]. <p> Many people agree that cognition can and should be described at different levels and that care should be taken to compare and contrast only those explanations/models/theories that exist on the same level [23] <ref> [14] </ref> [16]. However, others feel that an explanation of cognition should not or can not be completely differentiated from the biological implementation of cognition that we know as the brain [22][24] [17]. Tables 1 and 2 attempt to assimilate these views from two different angles. <p> A good example of this is Fodor and Pylyshyns denunciation of Connectionism on the basis that it lacks compositionality and systematicity (basically, the ability to represent complex structures and the existence of structure sensitive operations, respectively) <ref> [14] </ref>. 3.
Reference: [15] <author> Harnad, Stevan, </author> <title> The Symbol Grounding Problem, </title> <journal> Physica D, </journal> <volume> vol. 42, </volume> <pages> 335-46, </pages> <year> 1990. </year>
Reference-contexts: Some researchers argue that Connectionism is fatally flawed as a model of cognition [14] or that while Connectionism may play a minor though important role, Symbolism represents the heart of any realistic model <ref> [15] </ref>. On the other hand, cases are presented for the desirability of Connectionism over Symbolism [16] and that the eventual dominance of Connectionism is only a matter of time [17]. <p> The symbol grounding problem is interesting in that it does not directly oppose a strength of Connectionism, per se, (though Connectionism does not suffer from it and this may be thought of as a strength) and is treated in <ref> [15] </ref>. There are those, of course, who will point to one or another of one of the methods weaknesses and argue that it is insurmountable and thus that the method is untenable. <p> Because semantic structure is closely related to syntactic structure (by compositionality), this reflects the truism that if A and B exist (are true), then certainly A exists (is true). 3.4 Grounding This consideration is due to Harnad <ref> [15] </ref> and addresses the problem in pure symbol systems of the lack of intrinsic meaning in the system. Though such a system possesses a rich symbol structure, that structure is purely internal and completely arbitrary. It is not grounded to anything in reality.
Reference: [16] <author> Barnden, John A., </author> <title> On Using Analogy to Reconcile Connections and Symbols, Neural Networks for Knowledge Representation and Inference, </title> <editor> eds. Daniel S. Levine and Manuel Aparicio, </editor> <publisher> Lawrence Erlbaum, </publisher> <pages> 27-64, </pages> <year> 1994. </year>
Reference-contexts: Some researchers argue that Connectionism is fatally flawed as a model of cognition [14] or that while Connectionism may play a minor though important role, Symbolism represents the heart of any realistic model [15]. On the other hand, cases are presented for the desirability of Connectionism over Symbolism <ref> [16] </ref> and that the eventual dominance of Connectionism is only a matter of time [17]. <p> Many people agree that cognition can and should be described at different levels and that care should be taken to compare and contrast only those explanations/models/theories that exist on the same level [23] [14] <ref> [16] </ref>. However, others feel that an explanation of cognition should not or can not be completely differentiated from the biological implementation of cognition that we know as the brain [22][24] [17]. Tables 1 and 2 attempt to assimilate these views from two different angles.
Reference: [17] <author> McKenna, Thomas M., </author> <title> The Role of Interdisciplinary Research Involving Neuroscience in the Development of Intelligent Systems, Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <editor> eds. Vasant Honavar and Leonard Uhr, </editor> <publisher> Academic Press, </publisher> <pages> 75-92, </pages> <year> 1994. </year>
Reference-contexts: On the other hand, cases are presented for the desirability of Connectionism over Symbolism [16] and that the eventual dominance of Connectionism is only a matter of time <ref> [17] </ref>. Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] [20] [21] [22], while others argue for their equivalence and cite performance issues as the main concern [23] [10]. <p> However, others feel that an explanation of cognition should not or can not be completely differentiated from the biological implementation of cognition that we know as the brain [22][24] <ref> [17] </ref>. Tables 1 and 2 attempt to assimilate these views from two different angles. One common thread that runs through any discussion of Connectionism vs. Symbolism, either implicitly or explicitly is the dual nature of the two. <p> For this to succeed, as McKenna points out, we must resist the temptation to critique one discipline by the specialized criteria of another <ref> [17] </ref>. It should be reiterated that although the theory may evolve in an eclectic manner, the final product cannot be a hodgepodge of techniques, partial models and explanations. It must be cohesive, formalized, and elegant and it must address the issues discussed here whether by subsumption or refutation.
Reference: [18] <editor> Goonatilake, Suran and Khebbal, Sukhdev, </editor> <title> Intelligent Hybrid Systems: Issues, Classifications and Future Directions, Intelligent Hybrid Systems, </title> <editor> eds. Suran Goontalilake and Sukhdev Khebbal, </editor> <publisher> John Wiley & Sons, </publisher> <pages> 1-20, </pages> <year> 1995. </year>
Reference-contexts: On the other hand, cases are presented for the desirability of Connectionism over Symbolism [16] and that the eventual dominance of Connectionism is only a matter of time [17]. Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit <ref> [18] </ref> [19] [20] [21] [22], while others argue for their equivalence and cite performance issues as the main concern [23] [10].
Reference: [19] <author> Sun, Ron, </author> <title> An Introduction: On Symbolic Processing in Neural Networks, Computational Architectures Integrating Neural and Symbolic Processes: A Perspective on the State of the Art, </title> <editor> eds. Ron Sun and Lawrence A. Bookman, </editor> <publisher> Kluwer Academic, </publisher> <pages> 1-18, </pages> <year> 1995. </year>
Reference-contexts: Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] <ref> [19] </ref> [20] [21] [22], while others argue for their equivalence and cite performance issues as the main concern [23] [10]. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25].
Reference: [20] <author> Boden, Margaret, </author> <title> Horses of a Different Colour?, Aritificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <editor> eds. Vasant Honavar and Leonard Uhr, </editor> <publisher> Academic Press, </publisher> <pages> 3-19, </pages> <year> 1994. </year>
Reference-contexts: Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] <ref> [20] </ref> [21] [22], while others argue for their equivalence and cite performance issues as the main concern [23] [10]. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25]. <p> Serial computation is argued to be necessary for some kinds of cognition including ordered problem solving, logical reasoning, generalized thinking involving variable binding, and certain types of structural aspects of language <ref> [20] </ref>. Not surprisingly, the weaknesses of the respective approaches often seem to be the negation of a strength of the opposing method. For example, the difficulty in interpretation of Connectionist networks is in direct opposition to the strong explanation abilities of Symbolism.
Reference: [21] <author> Oden, Gregg C., </author> <title> Why the Difference between Connectionism and Anything Else Is More Than You Might Think but Less Than You Might Hope, Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <editor> eds. Vasant Honavar and Leonard Uhr, </editor> <publisher> Academic Press Inc., </publisher> <pages> 93-103, </pages> <year> 1994. </year>
Reference-contexts: Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] [20] <ref> [21] </ref> [22], while others argue for their equivalence and cite performance issues as the main concern [23] [10]. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25]. <p> These are all prototypical generalizations, of course, and as is pointed out in, for example <ref> [21] </ref>, the boundary dividing Connectionist models and Symbolic models is ill-defined at best. In fact Oden suggests that models that should be taken seriously will almost always exist in this fuzzy boundary region. Connectionism vs.
Reference: [22] <author> Aparicio, Manuel and Levine, Daniel S., </author> <title> Why are Neural Networks Relevant to Higher Cognitive Function?, Neural Networks for Knowledge Representation and Inference, </title> <editor> eds. Daniel S. Levine and Manuel Aparicio, </editor> <publisher> Lawrence Erlbaum, </publisher> <pages> 1-26, </pages> <year> 1994. </year>
Reference-contexts: Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] [20] [21] <ref> [22] </ref>, while others argue for their equivalence and cite performance issues as the main concern [23] [10]. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25].
Reference: [23] <author> Honavar, Vasant, </author> <title> Symbolic Artificial Intelligence and Numeric Artificial Neural Networks: Towards a Resolution of the Dichotomy, Computational Architectures Integrating Neural and Symbolic Processes: A Perspective on the State of the Art, </title> <editor> eds. Ron Sun and Lawrence A. Bookman, </editor> <publisher> Kluwer Academic, 351-88,1995. </publisher>
Reference-contexts: Some see the two as complimentary or dualistic in nature and are optimistic that their combination will bear productive fruit [18] [19] [20] [21] [22], while others argue for their equivalence and cite performance issues as the main concern <ref> [23] </ref> [10]. Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless [25]. <p> Many people agree that cognition can and should be described at different levels and that care should be taken to compare and contrast only those explanations/models/theories that exist on the same level <ref> [23] </ref> [14] [16]. However, others feel that an explanation of cognition should not or can not be completely differentiated from the biological implementation of cognition that we know as the brain [22][24] [17]. Tables 1 and 2 attempt to assimilate these views from two different angles.
Reference: [24] <author> Chandrasekaran, B. and Josephson, Susan G., </author> <title> Architecture of Intelligence: The Problems and Current Approaches to Solutions, Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <editor> eds. Vasant Honavar and Leonard Uhr, </editor> <publisher> Academic Press, 21-50,1994. </publisher>
Reference-contexts: Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be <ref> [24] </ref>, and some claim that the entire idea of modeling cognition as computation is hopeless [25].
Reference: [25] <author> Penrose, Roger, </author> <title> Shadows of the Mind, </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: Still others are more pessimistic as how intelligent a Connectionist-Symbolic hybrid will ever be [24], and some claim that the entire idea of modeling cognition as computation is hopeless <ref> [25] </ref>. Many people agree that cognition can and should be described at different levels and that care should be taken to compare and contrast only those explanations/models/theories that exist on the same level [23] [14] [16].
Reference: [26] <author> Ventura, Dan and Martinez, Tony, </author> <title> An Empirical Comparison of Discretization Methods, </title> <booktitle> Proceedings of the Tenth International Symposium on Computer and Information Sciences, </booktitle> <pages> 443-50, </pages> <year> 1995. </year>
Reference-contexts: On the other hand, we often process in discrete quantities as well, content to know that it is a cool day rather than that it is 63.7 F. Discretization, though far from satisfactory, is one approach to reconciling the two <ref> [26] </ref>. 3.7.2 Numerical and symbolic. The argument here is related to the previous one. Clearly, we explicitly and consciously perform symbolic computation at least in language. Perhaps we perform some numerical computation in mathematical endeavors, though mathematics is by its very nature symbolic.
Reference: [27] <author> Arbib, Michael, </author> <title> Schema Theory: Cooperative Computation for Brain Theory and Distributed AI, Aritificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <editor> eds. Vasant Honavar and Leonard Uhr, </editor> <publisher> Academic Press, </publisher> <pages> 51-74, </pages> <year> 1994. </year>
Reference-contexts: The difference comes in the order they are tackled. 4. Toward a General Theory As the issues above are confronted and resolved, a general, unified theory of (artificial) intelligence will emerge, and some good preliminary efforts have been made. For example, both Arbibs Schema Theory <ref> [27] </ref> [28] and Michalskis Multistrategy Task-adaptive Learning [29] give good accounts of many of the aspects of knowledge, complex symbols and learning.
Reference: [28] <author> Arbib, M. A., </author> <title> Schema Theory, </title> <booktitle> The Encyclopedia of Artificial Intelligence, 2nd edition, </booktitle> <editor> ed. S. Shapiro, </editor> <publisher> Wiley-Interscience, </publisher> <pages> 1427-43, </pages> <year> 1992. </year>
Reference-contexts: The difference comes in the order they are tackled. 4. Toward a General Theory As the issues above are confronted and resolved, a general, unified theory of (artificial) intelligence will emerge, and some good preliminary efforts have been made. For example, both Arbibs Schema Theory [27] <ref> [28] </ref> and Michalskis Multistrategy Task-adaptive Learning [29] give good accounts of many of the aspects of knowledge, complex symbols and learning.
Reference: [29] <author> Michalski, Ryszard S., </author> <title> Toward a Unified Theory of Learning: Multistrategy Task-adaptive Learning, Readings in Knowledge Acquisition and Learning, </title> <editor> eds. B. G. Buchanan and D. C. Wilkins, </editor> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: Toward a General Theory As the issues above are confronted and resolved, a general, unified theory of (artificial) intelligence will emerge, and some good preliminary efforts have been made. For example, both Arbibs Schema Theory [27] [28] and Michalskis Multistrategy Task-adaptive Learning <ref> [29] </ref> give good accounts of many of the aspects of knowledge, complex symbols and learning.
References-found: 29

