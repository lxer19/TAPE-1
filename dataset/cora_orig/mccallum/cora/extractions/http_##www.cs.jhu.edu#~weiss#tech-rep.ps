URL: http://www.cs.jhu.edu/~weiss/tech-rep.ps
Refering-URL: http://www.cs.jhu.edu/~weiss/ir.html
Root-URL: http://www.cs.jhu.edu
Email: brillg@cs.jhu.edu  
Title: Text Classification in USENET Newsgroups: A Progress Report  
Author: Scott A. Weiss Simon Kasif Eric Brill fweiss, kasif, 
Date: April 7, 1997  
Affiliation: Department of Computer Science The Johns Hopkins University  
Abstract: We report on our investigations into topic classification with USENET newsgroups. Our framework is to determine the newsgroup that a new document should be posted to. We train our system by forming "metadocuments" that represent each topic. We discuss our experiments with this method, and provide evidence that choosing particular documents or words to use in these models degrades classification accuracy. We demonstrate SMART's deficiencies in retrieving documents from a newsgroup, and compare humans and SMART on a simple similarity task. We then describe a technique called classification-based retrieval for finding documents similar to a query document. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Armstrong, D. Freitag, T. Joachims, and T. Mitchell. Webwatcher: </author> <title> A learning apprentice for the world wide web. </title> <booktitle> Proceedings of the 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: 1 A Domain For Text Classification As the heralded "information superhighway" continues to expand, the need for useful methods of navigating it becomes greater. There are already a number of applications that aid the user. These include the WebWatcher at CMU <ref> [1] </ref>, the LIRA system at Stanford [2], and the Webhunter and Letizia projects at the MIT Media Lab [8]. The Softbot project at UW [3] and the FAQ Finder at the University of Chicago [5] both make use of Internet resources to answer natural-language user queries.
Reference: [2] <author> M Balabanovic and Y Shoham. </author> <title> Learning information retrieval agents: Experiments with automated web browsing. </title> <booktitle> In Proc. 1995 AAAI Spring Symp. on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <address> Stanford, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: 1 A Domain For Text Classification As the heralded "information superhighway" continues to expand, the need for useful methods of navigating it becomes greater. There are already a number of applications that aid the user. These include the WebWatcher at CMU [1], the LIRA system at Stanford <ref> [2] </ref>, and the Webhunter and Letizia projects at the MIT Media Lab [8]. The Softbot project at UW [3] and the FAQ Finder at the University of Chicago [5] both make use of Internet resources to answer natural-language user queries.
Reference: [3] <author> O. Etzioni and D. Weld. </author> <title> A softbot-based interface to the internet. </title> <journal> Communications of the ACM, </journal> <month> July </month> <year> 1994. </year>
Reference-contexts: There are already a number of applications that aid the user. These include the WebWatcher at CMU [1], the LIRA system at Stanford [2], and the Webhunter and Letizia projects at the MIT Media Lab [8]. The Softbot project at UW <ref> [3] </ref> and the FAQ Finder at the University of Chicago [5] both make use of Internet resources to answer natural-language user queries. The large amounts of new data that appear daily on the Internet bring a number of challenges. This data cannot be easily processed by humans.
Reference: [4] <author> Jeffrey Goldberg. Cdm: </author> <title> An approach to learning in text categorization. </title> <booktitle> In Proc. of TAI 95, 7th IEEE International Conference on Tools with Artificial Intelligence, </booktitle> <month> August </month> <year> 1995. </year> <month> 14 </month>
Reference-contexts: This value can be interpreted as the probability that the term is used when describing the topic. We are really interested in the probability that we are describing a particular topic given a term. We compute this using a minor variant on cue validity as used by Jeffrey Goldberg <ref> [4] </ref>. Here we estimate the probability of a newsgroup G given a term W as: P (G j W ) = P (1) If this probability is higher than some chosen threshold, then the term could be a good discriminator.
Reference: [5] <author> K. Hammond, R. Burke, C. Martin, and S Lytinen. </author> <title> Faq finder: A case-based approach to knowledge navigation. </title> <booktitle> In Proc. 1995 AAAI Spring Symp. on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <address> Stanford, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: These include the WebWatcher at CMU [1], the LIRA system at Stanford [2], and the Webhunter and Letizia projects at the MIT Media Lab [8]. The Softbot project at UW [3] and the FAQ Finder at the University of Chicago <ref> [5] </ref> both make use of Internet resources to answer natural-language user queries. The large amounts of new data that appear daily on the Internet bring a number of challenges. This data cannot be easily processed by humans.
Reference: [6] <author> Tim Honkela, Samuel Kaski, Krista Lagus, and Teuvo Kohonen. </author> <title> Newsgroup exploration with websom method and browsing interface. </title> <type> Technical Report A32, </type> <institution> Helsinki University of Technology, </institution> <year> 1996. </year>
Reference-contexts: It then uses new documents as queries on the profiles. At CMU, the Newsweeder project [7] has users rate new documents in terms of relevance, and attempts to learn these ratings for classifying future documents. The WEBSOM project <ref> [6] </ref> at the Helsinki University of Technology has a different focus. They use a self-organizing map to automatically group similar documents into a two-dimensional space. If a user finds one document relevant, she can look at other documents close to it to find other interesting articles.
Reference: [7] <author> K. Lang. Newsweeder: </author> <title> Learning to filter netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 331-339, </pages> <address> Tahoe City, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Newsgroups have been studied in other projects. Mostly there has been work done in filtering. The SIFT project at Stanford [12] has users submit profiles for their interest. It then uses new documents as queries on the profiles. At CMU, the Newsweeder project <ref> [7] </ref> has users rate new documents in terms of relevance, and attempts to learn these ratings for classifying future documents. The WEBSOM project [6] at the Helsinki University of Technology has a different focus. They use a self-organizing map to automatically group similar documents into a two-dimensional space.
Reference: [8] <author> Y Lashkari, M Metral, and P Maes. </author> <title> Collaborative interface agents. </title> <booktitle> In Conference of the American Association for Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: There are already a number of applications that aid the user. These include the WebWatcher at CMU [1], the LIRA system at Stanford [2], and the Webhunter and Letizia projects at the MIT Media Lab <ref> [8] </ref>. The Softbot project at UW [3] and the FAQ Finder at the University of Chicago [5] both make use of Internet resources to answer natural-language user queries. The large amounts of new data that appear daily on the Internet bring a number of challenges.
Reference: [9] <author> David Dolan Lewis. </author> <title> Representation and Learning in Information Retrieval. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, University of Massachusetts, </institution> <year> 1992. </year>
Reference-contexts: Here we are primarily interested in the problem of classification: given a document to be posted, determine the most appropriate topic labels for it. Most work in classification has involved articles taken off of a newswire, or from a medical database <ref> [9] </ref>. In these cases, the "correct" topic labels are given by human experts. The domain of USENET newsgroup postings provides another interesting testbed for classification. The "labels" here are just the newsgroups to which the documents were originally posted.
Reference: [10] <editor> J. Prange, editor. </editor> <booktitle> TIPSTER Text Phase II, </booktitle> <year> 1995. </year>
Reference-contexts: The large amounts of new data that appear daily on the Internet bring a number of challenges. This data cannot be easily processed by humans. Hence, relevance judgments, such as those provided in the Tipster collection <ref> [10] </ref>, will not be readily available. More data means more documents, which means more words and terms to analyze. We will need some way to pick out the terms and phrases that carry meaning. Also there is a large amount of data that is essentially meaningless.
Reference: [11] <author> G. Salton. </author> <title> The SMART Retrieval System Experiments in Automatic Document Processing. </title> <publisher> Prentice Hall, </publisher> <year> 1971. </year>
Reference-contexts: The underlying system is SMART, developed by Salton <ref> [11] </ref>. SMART indexes a collection of text documents by first removing stopwords, and then stemming words to join those with similar meanings. It then creates a vector for each document whose features represent the remaining terms. The features are assigned numeric values by a process known as term weighting.
Reference: [12] <author> T. Yan and H. Garcia-Molina. </author> <title> Sift a tool for wide-area information dissemination. </title> <booktitle> Proceedings of the 1995 USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <year> 1995. </year> <month> 15 </month>
Reference-contexts: These may share none of the same terms, but they are all "about" AI. Newsgroups have been studied in other projects. Mostly there has been work done in filtering. The SIFT project at Stanford <ref> [12] </ref> has users submit profiles for their interest. It then uses new documents as queries on the profiles. At CMU, the Newsweeder project [7] has users rate new documents in terms of relevance, and attempts to learn these ratings for classifying future documents.
References-found: 12

