URL: http://www.cs.washington.edu/homes/jdreese/diss.ps
Refering-URL: http://www.cs.washington.edu/homes/jdreese/
Root-URL: http://www.cs.washington.edu
Title: Software Deviation Analysis  
Author: Jon Damon Reese Professor Nancy G. Leveson Professor Debra J. Richardson 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Information and Computer Science by  Committee in charge: Professor John King, Chair  
Date: 1996  
Affiliation: UNIVERSITY OF CALIFORNIA IRVINE  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Aho, Sethi, and Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1985. </year>
Reference-contexts: However, they do not encode enough information about the nature of causal relationships to be useful for a software hazard analysis. A dependency graph is a type of directed graph that indicates the "interdependencies among the inherited and synthesized attributes at the nodes in a parse tree." <ref> [1] </ref> The relationships are restricted to type, and thus are basically limited to analysis of structural causality. In contrast, pipe-and-process and block diagrams show sequential causality but generally lack structural causality.
Reference: [2] <author> Richard C. Booten Jr. and Simon Ramo. </author> <title> The development of systems engineering. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> AES-20(4), </volume> <month> July </month> <year> 1984. </year>
Reference: [3] <author> W.C. Bowman, G.H. Archinoff, V.M. Raina, D.R. Tremaine, and N.G. Leveson. </author> <title> An application of fault tree analysis to safety-critical software at ontario hydro. </title> <booktitle> In Conference on Probabilistic Safety Assessment and Management (PSAM), </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: The SFTA templates have been defined for the programming language Ada, and hence for most algorithmic programming language statements. It has been used extensively, including for shutdown software at Ontario Hydro nuclear reactor <ref> [3] </ref> and the University of California, Berkeley FIREWHEEL spacecraft [17]. The methodology has also been extended to the Statecharts specification language [23, 24], showing 18 -1 +1 REVERSED VALVE ACTION 0 VALVE STUCK the applicability of mini-fault tree analysis, and especially SFTA, to the analysis of software requirements.
Reference: [4] <author> R.W. Butler and G.B. Finelli. </author> <title> The infeasibility of experimental quantification of life-critical software reliability. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(1) </volume> <pages> 3-12, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: introduction into many new applications. Thus larger and more complex systems are being designed. <ref> [4] </ref> The additional complexity is compounded by the nature of control software. While conventional technologies exhibit typically continuous behaviors (consider, for example, the sawtooth-shaped voltage of an overdriven capacitor or the deflection of a stressed beam) software typically exhibits discrete reactions to its inputs. <p> Even if operational testing can be performed, there are probably insufficient resources (including time) to obtain a high enough statistical confidence in the software. For example, "ultra-reliable" software with an expected failure rate of 10 10 per hour would require approximately 114 years testing of 10,000 replicates <ref> [4] </ref>. About one-third of all software errors do not appear until after 5,000 operation years [20]. These figures do not include the added burden of testing in the presence of failures of other components.
Reference: [5] <author> Yue-Lung Cheng, Hsiu-Chuan Wei, and John Yuan. </author> <title> On establishment of i/o tables in automation of a fault tree synthesis. Reliability Engineering and System Safety, </title> <booktitle> 40 </booktitle> <pages> 311-318, </pages> <year> 1993. </year>
Reference-contexts: FTA is used extensively in safety programs in the nuclear power and weapons industries. It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses. They can require much time and effort to construct <ref> [5, 9, 14, 33] </ref>. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. <p> They can require much time and effort to construct [5, 9, 14, 33]. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other <ref> [5, 15, 33] </ref>. Several algorithms have been developed to alleviate problems with the manual construction of fault trees. One family of algorithms is based on the technique of "mini-fault trees." The other family of algorithms uses "digraphs." 1 A variation of FTA is the Management Oversight and Risk Tree (MORT).
Reference: [6] <institution> Federal Aviation Administration, </institution> <address> 800 Independence Avenue, S.W., Washington, D.C., </address> <year> 20591. </year> <title> TCAS II Collision Avoidance System (CAS) System Requirements Specification, change 6.00 edition, </title> <month> March </month> <year> 1993. </year>
Reference: [7] <author> Peter Fenelon and John A. McDermid. </author> <title> An integrated tool set for software safety analysis. </title> <journal> Journal Systems Software, </journal> <volume> 21 </volume> <pages> 279-290, </pages> <year> 1993. </year> <pages> 160 161 </pages>
Reference-contexts: Algorithms exist to produce a fault tree's cut sets automatically. Thus the fault tree is very useful in determining the causative relationship between primal events and the top event [14]. FTA is traditionally a probabilistic methodology <ref> [7] </ref>. A quantitative analysis can be performed if probabilities are provided for the primal events, although the 14 analysis is complicated by non-independent events. However, the validity of probabilistic methods has been called into question. <p> relationships between variables. 2.2 Forward Search Techniques Forward search techniques focus on whether or how a normal or failure state can cause a hazard. 2.2.1 Failure Modes, Effects, and Criticality Analysis Failure modes and effects analysis (FMEA) is employed to determine the effects of single failures on a system's performance <ref> [7] </ref> (contrasted with fault tree analysis, for example, which allows the consideration of multiple failures.) FMEA was developed 22 Potential Risk Part name Failure Mode Potential effect of failure mode Priority Positive input Open circuit No screenwash 108 wire to pump Short to ground This might (should) blow a fuse 72 <p> If a failure rate is sufficiently high and the effect is sufficiently serious, 23 then the system must be redesigned [25]. A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry <ref> [7] </ref>. It is most appropriate as a detailed analysis of a single, standard component [16]. FMEA is described as a slow and tedious procedure [7, 25, 28]. <p> A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component [16]. FMEA is described as a slow and tedious procedure <ref> [7, 25, 28] </ref>. There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA [28]. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts [25].
Reference: [8] <author> Tom Forester and Perry Morrison. </author> <title> Computer unreliability and social vulnerability. </title> <booktitle> Futures, </booktitle> <pages> pages 462-474, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Peter Neumann has compiled a list of over 400 cases in which computers contributed to an accident or near-accident, some of which resulted in loss of life. Some incidents are due to computer hardware failures. However, the majority are due to some sort of software error <ref> [8] </ref>. Computers have contributed to an increasing number of medical equipment recalls by the U.S. Food and Drug Administration. For example, the number of recalls doubled between the years of 1982 and 1984 [13]. According to Forrester and Morrison [8], failures are common in telephone switching software, air traffic control systems, <p> However, the majority are due to some sort of software error <ref> [8] </ref>. Computers have contributed to an increasing number of medical equipment recalls by the U.S. Food and Drug Administration. For example, the number of recalls doubled between the years of 1982 and 1984 [13]. According to Forrester and Morrison [8], failures are common in telephone switching software, air traffic control systems, bank automated teller machines, electronic funds transfer systems, industrial robots, and police computers. One proposed solution to the problem of unsafe software is to remove the computer from safety-critical systems altogether [8]. <p> According to Forrester and Morrison <ref> [8] </ref>, failures are common in telephone switching software, air traffic control systems, bank automated teller machines, electronic funds transfer systems, industrial robots, and police computers. One proposed solution to the problem of unsafe software is to remove the computer from safety-critical systems altogether [8]. Similarly, the problem may sometimes be avoided by not building the system at all. These options should seriously be considered; however, it is unrealistic to expect such rules to be applied categorically. Computer software has many strengths, and sometimes it is the best alternative.
Reference: [9] <author> Sergio Guarro and David Okrent. </author> <title> The logic flowgraph: A new approach to process failure modeling and diagnosis for disturbance analysis applications. </title> <journal> Nuclear Technology, </journal> <volume> 67, </volume> <month> December </month> <year> 1984. </year>
Reference-contexts: FTA is used extensively in safety programs in the nuclear power and weapons industries. It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses. They can require much time and effort to construct <ref> [5, 9, 14, 33] </ref>. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. <p> In this case, all but one of the edges are qualified with failure conditions. The condition may be considered external to the model (as all conditions are in the Lapp and Powers version) or it may be a predicate of other variable values, as in the logic flowgraph <ref> [9] </ref>. <p> Additionally, the nature of the sequential causality is not described, so only the most rudimentary hazard analysis may be performed automatically. Digraphs (section 2.1.2) encode sequential causality as a partial derivative. However, with the exception of the Logic Flowgraph Method (LFM) <ref> [9] </ref>, interaction between causes is not represented.
Reference: [10] <author> David Harel. Statecharts: </author> <title> A visual formalism for complex systems. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 8 </volume> <pages> 231-274, </pages> <year> 1987. </year>
Reference-contexts: RSML is a graphical, state-based requirements specification. RSML specifications are composed of interconnected system components. Each component is composed of a heirarchical state definition, a useful state abstraction originally developed for the Statecharts specification language <ref> [10] </ref>. Please refer to [11] for a presentation of RSML.
Reference: [11] <author> Mats Per Erik Heimdahl. </author> <title> Static Analysis of State-based Requirements. </title> <type> PhD thesis, </type> <institution> University of California, Irvine, </institution> <year> 1994. </year>
Reference-contexts: RSML is a graphical, state-based requirements specification. RSML specifications are composed of interconnected system components. Each component is composed of a heirarchical state definition, a useful state abstraction originally developed for the Statecharts specification language [10]. Please refer to <ref> [11] </ref> for a presentation of RSML. <p> In RSML and similar languages, events are a sort of communication between states. Events are also used to synchronize state transitions. In this capacity they may be thought of as similar to the parentheses of an equation <ref> [11] </ref>. Events can be produced by state transitions, input interfaces, output variable transitions, and output interfaces|all of which are types of component transition. Since the same event can be produced by multiple transitions, an event is simply an or function of the various transitions that can produce it.
Reference: [12] <author> Danial Hernandez. </author> <title> Reasoning with qualitative representations: Exploiting the structure of space. </title> <booktitle> In QUARDET '93: III IMACS International Workshop on Qualitative Reasoning and Decision Technologies, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Another language may necessitate different quantitative domains. In general, the values in a qualitative domain are chosen to distinguish as minimally as possible between meaningful alternatives <ref> [12] </ref>. This goal applies to both the value and deviation parts. The simplest calculus, sign algebra, was described above. Sign algebra as applied to the deviation part describes whether the value part is too high, too low, or correct. The value-part functions are independent of the deviation part.
Reference: [13] <author> Jonathan Jacky. </author> <title> Safety-critical computing: hazards, practices, standards and regulation. </title> <editor> In C. Dunlop and R. Kling, editors, Computerization and controversy, </editor> <volume> chapter 5, </volume> <pages> pages 612-631. </pages> <publisher> Academic Press, </publisher> <year> 1991. </year>
Reference-contexts: However, the majority are due to some sort of software error [8]. Computers have contributed to an increasing number of medical equipment recalls by the U.S. Food and Drug Administration. For example, the number of recalls doubled between the years of 1982 and 1984 <ref> [13] </ref>. According to Forrester and Morrison [8], failures are common in telephone switching software, air traffic control systems, bank automated teller machines, electronic funds transfer systems, industrial robots, and police computers. One proposed solution to the problem of unsafe software is to remove the computer from safety-critical systems altogether [8].
Reference: [14] <author> Stephen A. Lapp and Gary J. </author> <title> Powers. Computer-aided synthesis of fault-trees. </title> <journal> IEEE Transactions on Reliability, </journal> <pages> pages 2-13, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: Like any backward analysis method, it is most suited for a relatively small number of hazardous states [18]. 2.1.2 Fault Tree Analysis Fault tree analysis (FTA) was developed by Bell Laboratories in 1961 for the Minuteman missile project <ref> [14] </ref>. The analysis begins with the identification of some undesired event, called the "top event." The analyst determines the conditions that could comprise the top event and places them in a graphical layout similar to that shown in figure 2.2. <p> Fault trees may be used qualitatively to determine whether or how a particular top event is possible by inspecting "cut sets." A cut set is a set of primal events such that all of the events are necessary and sufficient to cause the top event <ref> [14] </ref>. Algorithms exist to produce a fault tree's cut sets automatically. Thus the fault tree is very useful in determining the causative relationship between primal events and the top event [14]. FTA is traditionally a probabilistic methodology [7]. <p> a set of primal events such that all of the events are necessary and sufficient to cause the top event <ref> [14] </ref>. Algorithms exist to produce a fault tree's cut sets automatically. Thus the fault tree is very useful in determining the causative relationship between primal events and the top event [14]. FTA is traditionally a probabilistic methodology [7]. A quantitative analysis can be performed if probabilities are provided for the primal events, although the 14 analysis is complicated by non-independent events. However, the validity of probabilistic methods has been called into question. <p> FTA is used extensively in safety programs in the nuclear power and weapons industries. It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses. They can require much time and effort to construct <ref> [5, 9, 14, 33] </ref>. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. <p> It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses. They can require much time and effort to construct [5, 9, 14, 33]. Also, they are subject to logical errors and omissions <ref> [14] </ref>. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. Several algorithms have been developed to alleviate problems with the manual construction of fault trees. <p> The basic procedure for producing a fault-tree using a digraph is to first convert the system description into a digraph and then traverse the digraph backward (i.e., in the opposite direction of the edges.) The conversion of specification to digraph can be automated if standard components are used <ref> [14] </ref>. For example, figure 2.7 (a) shows a simple pipe-and-process diagram. Figure 2.7 (b) is a description of the standard failure behavior of one of its components, a valve. Figure 2.7 (c) shows a portion of the resulting digraph based on the failure behavior in (b). <p> Figure 2.7 (c) shows a portion of the resulting digraph based on the failure behavior in (b). Digraphs can be augmented by specifying the type of influence a failed variable can have on another variable. Lapp and Powers <ref> [14] </ref> allow the set of values f10, 1, 0, +1, +10g to appear on digraph edges.
Reference: [15] <author> Nancy G. Leveson. </author> <title> Software safety: Why, what, and how. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(2) </volume> <pages> 125-163, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: This behavior can be dangerous since small perturbations of software inputs often result in huge deviations in the outputs <ref> [15, 26] </ref>. 1 Additionally, the mathematics governing programming languages are not as well understood, nor as easily calculated, as those for analog systems [15]. Software engineering is a relatively new discipline, and there is very little historical data on its use as compared to other fields of engineering. <p> This behavior can be dangerous since small perturbations of software inputs often result in huge deviations in the outputs [15, 26]. 1 Additionally, the mathematics governing programming languages are not as well understood, nor as easily calculated, as those for analog systems <ref> [15] </ref>. Software engineering is a relatively new discipline, and there is very little historical data on its use as compared to other fields of engineering. The products of software have very unpredictable failure modes and rates compared to, say, metallurgy, solid state electronics, or chemistry. <p> They can require much time and effort to construct [5, 9, 14, 33]. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other <ref> [5, 15, 33] </ref>. Several algorithms have been developed to alleviate problems with the manual construction of fault trees. One family of algorithms is based on the technique of "mini-fault trees." The other family of algorithms uses "digraphs." 1 A variation of FTA is the Management Oversight and Risk Tree (MORT).
Reference: [16] <author> Nancy G. Leveson. Safeware: </author> <title> System Safety and Computers. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Probably the most useful definition is that of <ref> [16] </ref>: a hazard is a state or set of conditions of a system ... that together with other conditions in the environment of the system ... will lead to an accident (loss event). <p> Note that this definition differentiates between the system and its environment. A useful working definition of the system is the controller and the part of its environment over which it has some control <ref> [16] </ref> (thus dividing the controller's environment into "system" and "environment.") For example, consider an autopilot on an aircraft. The autopilot is the controller. It exercises at least partial control over the entire aircraft, but not over anything external to the aircraft. <p> chapter are divided into backward searches, forward searches, and combined approaches. 11 2.1 Backward Search Techniques 2.1.1 State Machine Hazard Analysis State Machine Hazard Analysis (SMHA) is an algorithmic procedure developed specifically for the analysis of software requirements [18], although the method can be adapted to any stage of design <ref> [16] </ref>. SMHA was originally defined for a timed Petri net language [18]. It has been adapted to Statecharts [23, 24] and an effort is underway to adapt it to RSML. The algorithm takes as input a model of the system described in a formal, state-based language. <p> The tree is finished when all the leaves are "primal events," which are considered to occur stochastically or are otherwise resistant to a logical analysis. The decision of when to stop is at the discretion of the analyst <ref> [16] </ref>, subject to the information available. <p> One family of algorithms is based on the technique of "mini-fault trees." The other family of algorithms uses "digraphs." 1 A variation of FTA is the Management Oversight and Risk Tree (MORT). MORT is guided by a 1500-item questionnaire related to system management, human behavior, and environmental factors <ref> [16] </ref>. <p> The second column lists failures modes, the third column failure effects, and the last column lists criticality ratings. Taken from [28]. as an aid to reliability analysis, but a variant known as Failure Modes, Effects and Criticality analysis (FMECA) has been used to identify potential hazards <ref> [16] </ref>. FMEA is basically an ad-hoc procedure based on a tabular form (see figure 2.8 for an example.) The first step of the procedure is to list all of the components of the system. Next the analyst lists all of the possible failure modes and failure rates for each component. <p> Next the analyst lists all of the possible failure modes and failure rates for each component. All these data are entered into the FMEA forms. The analyst then determines and describes all the possible effects for each failure <ref> [16] </ref>. For a FMECA this information includes hazard severity, the likelihood of detection, and frequency of occurrence. If a failure rate is sufficiently high and the effect is sufficiently serious, 23 then the system must be redesigned [25]. <p> A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component <ref> [16] </ref>. FMEA is described as a slow and tedious procedure [7, 25, 28]. There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA [28]. <p> In particular, the method leaves to the analyst the burden of investigating many similar failure patterns [28] (or recognizing that such patterns exist.) Another weakness of FMEA is its concentration on single failures. In contrast to methods like HAZOP, they do not treat hazards arising in component interfaces <ref> [16] </ref>. Finally, FMEA's lack of structure with respect to identifying failure modes or searching for effects is problematic for a software hazard analysis. As discussed in chapter 1, control software behavior is often complex and disjointed. Analysts can be overwhelmed by the multitude of variable interactions. <p> Finally, and most seriously, the probabilistic analysis becomes quite complicated if events are not independent. Unfortunately, it is difficult to prove (and dangerous to assume) that two events are independent. 26 ETA is appropriate only at the detailed design stage and afterward <ref> [16] </ref>. <p> More seriously, CCA cannot represent feedback directly. All components involved in a feedback loop must be collected into a single component for purposes of analysis. Finally, the diagrams can become "unwieldy." <ref> [16] </ref> 2.3.2 Hazard and Operability Study Hazard and operability analysis (HAZOP) is a semi-formal review procedure developed for the chemical industry to cope with potential hazards and other disturbances in operations. <p> Rather, the HAZOP leader hypothesizes an abnormal condition and analysis proceeds in both directions determining whether and how the condition is possible and what effects it has on the system. The analysis follows a systems theory model of accidents <ref> [16] </ref>, in that it concentrates on the hazards that can result from component interaction, i.e., accidents are caused by deviations in component behavior. The basic document that a HAZOP draws from is a pipe-and-process diagram. Each pipe has certain process parameters, such as pressure, temperature, and chemical composition. <p> LESS Not enough of a parameter. AS WELL AS Unintended activity or material. PART OF Parts of the parameter are missing. REVERSE Parameter's value is opposite of intended value. OTHER THAN Something other than the intended result happens. Table 2.1: HAZOP guide words (adapted from <ref> [16] </ref>.) the two questions "What is the effect of pipe A's temperature being too high?" and "How can pipe A's temperature get too high?" Since the questions center around pipe parameters, HAZOP has been characterized as a "flow-based" analysis [22]. <p> HAZOP has been used extensively in the chemical, nuclear and food processing industries [22]. The success of HAZOP may be attributed to several factors. The hypothetical nature of HAZOP questions encourages creative thinking <ref> [16] </ref>. Also, HAZOP studies are typically performed by a team of analysts, led by a HAZOP expert, resulting in a potentially very useful exchange of information and opinions. As a result, the HAZOP procedure is almost uniquely capable of systematically identifying new hazards in a proposed design. <p> Since the procedure focuses on flow at the exclusion of component functionality, a preliminary HAZOP can be performed early in system design, though the results will likely be quite preliminary. HAZOP has several limitations. It is time- and labor-intensive <ref> [16] </ref>, in large part due to its reliance on group discussions. HAZOP analyzes causes and effects 30 OMISSION Intended output is missing. COMMISSION Unintended output is generated. EARLY Output is generated sooner than intended. LATE Output is generated later than intended. COARSE INCORRECT Output's value is wrong. <p> In practice, compromises must be made between the costs of constructing and analyzing the system model and the quality of the results <ref> [16] </ref>. The particular balance struck depends in part on the stage of development. The system model typically begins as a coarse, incomplete description of the problem and is amended and refined as the solution develops. Accordingly, analysis should be an iterative process [16]. <p> system model and the quality of the results <ref> [16] </ref>. The particular balance struck depends in part on the stage of development. The system model typically begins as a coarse, incomplete description of the problem and is amended and refined as the solution develops. Accordingly, analysis should be an iterative process [16]. To wit, preliminary analysis should readily provide coarse results for incomplete information and final testing should yield conclusive results for an operational system. <p> Chapter 6 A Forward Search Algorithm As stated in chapter 2, the goal of this thesis is to develop a forward-search algorithm for the purpose of hazard analysis of computer-controlled systems. The goals of hazard analysis are to identify hazards, identify their causal factors, and evaluate risk <ref> [16] </ref>. Since a forward search works from cause to effect, a forward-searching hazard analysis would tackle the task of identifying potential hazards. The algorithms in this chapter assume the following items are available: * causality diagram, * forward, backward, and conditional function mappings * initial state, * stopping criteria.
Reference: [17] <author> Nancy G. Leveson and Peter R. Harvey. </author> <title> Analyzing software safety. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(5):569-579, </volume> <month> September </month> <year> 1983. </year>
Reference-contexts: A state transition table is defined for each standard component mapping an input variable event ("pressure becomes high") and a component state to a new state or output event. The mini-fault trees are constructed from these tables. See figure 2.4 for an example. Leveson and Harvey <ref> [17] </ref> define software fault tree analysis (SFTA). The goal of SFTA is either to prove that the software cannot cause a particular event or to show the circumstances under which the the event can occur. <p> The SFTA templates have been defined for the programming language Ada, and hence for most algorithmic programming language statements. It has been used extensively, including for shutdown software at Ontario Hydro nuclear reactor [3] and the University of California, Berkeley FIREWHEEL spacecraft <ref> [17] </ref>. The methodology has also been extended to the Statecharts specification language [23, 24], showing 18 -1 +1 REVERSED VALVE ACTION 0 VALVE STUCK the applicability of mini-fault tree analysis, and especially SFTA, to the analysis of software requirements.
Reference: [18] <author> Nancy G. Leveson and Janice L. Stolzy. </author> <title> Safety analysis using petri nets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(3):386-397, </volume> <month> March </month> <year> 1987. </year> <month> 162 </month>
Reference-contexts: The techniques presented in this chapter are divided into backward searches, forward searches, and combined approaches. 11 2.1 Backward Search Techniques 2.1.1 State Machine Hazard Analysis State Machine Hazard Analysis (SMHA) is an algorithmic procedure developed specifically for the analysis of software requirements <ref> [18] </ref>, although the method can be adapted to any stage of design [16]. SMHA was originally defined for a timed Petri net language [18]. It has been adapted to Statecharts [23, 24] and an effort is underway to adapt it to RSML. <p> 11 2.1 Backward Search Techniques 2.1.1 State Machine Hazard Analysis State Machine Hazard Analysis (SMHA) is an algorithmic procedure developed specifically for the analysis of software requirements <ref> [18] </ref>, although the method can be adapted to any stage of design [16]. SMHA was originally defined for a timed Petri net language [18]. It has been adapted to Statecharts [23, 24] and an effort is underway to adapt it to RSML. The algorithm takes as input a model of the system described in a formal, state-based language. <p> Thus the algorithm facilitates the removal of the hazards under inspection. SMHA must be performed after the hazard identification phase since it takes the hazardous states as input. Like any backward analysis method, it is most suited for a relatively small number of hazardous states <ref> [18] </ref>. 2.1.2 Fault Tree Analysis Fault tree analysis (FTA) was developed by Bell Laboratories in 1961 for the Minuteman missile project [14].
Reference: [19] <author> Peter Lewycky. </author> <title> Notes toward an understanding of accident causes. </title> <type> Hazard Prevention, </type> <month> March/April </month> <year> 1987. </year>
Reference-contexts: The chapter closes with a description of how RSML specifications may be translated to causality diagrams. 4.1 Definitions Before investigating the ways in which the causal information may be represented, it may be helpful to define the concept of "cause." Lewycky <ref> [19] </ref> describes philosophers' attempts through the ages to define cause, and shows how difficult the task is, if it is possible at all. Part of the problem lies in differentiating causation from correlation.
Reference: [20] <author> Bev Littlewood and Lorenzo Strigini. </author> <title> The risks of software. </title> <journal> Scientific American, </journal> <volume> 267(5) </volume> <pages> 38-43, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: For example, "ultra-reliable" software with an expected failure rate of 10 10 per hour would require approximately 114 years testing of 10,000 replicates [4]. About one-third of all software errors do not appear until after 5,000 operation years <ref> [20] </ref>. These figures do not include the added burden of testing in the presence of failures of other components. It is difficult, if not impossible, to test the software under all failure modes of the system. <p> Especially with respect to software, numbers can be very difficult to obtain. In order to complete a probabilistic analysis, the analyst must assign arbitrary values for software failures. In light of this dilemma, the FAA specifically excludes software from any quantitative analysis requirements <ref> [20] </ref>. FTA is used extensively in safety programs in the nuclear power and weapons industries. It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses.
Reference: [21] <author> Robyn R. Lutz. </author> <title> Analyzing software requirements errors in safety-critical, embedded systems. </title> <booktitle> In Proceedings of the IEEE international symposium on requirements eng ineering, </booktitle> <pages> pages 35-46, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Hazard analyses may conceivably be performed at any stage of system development. However, there is evidence that the earliest stages of development may benefit most from a hazard analysis. In a study limited to the causes of safety-related software errors <ref> [21] </ref>, Lutz found that the errors that persist until integration and system testing are usually due to difficulties with the software requirements.
Reference: [22] <author> J.A. McDermid and D.J. Pumfrey. </author> <title> A development of hazard analysis to aid software design, </title> <year> 1994. </year>
Reference-contexts: The leader poses a battery of questions to the experts in an attempt to elicit potential system hazards. A HAZOP is basically an exploratory analysis, as neither potential faults nor hazards have been identified beforehand <ref> [22] </ref>. Rather, the HAZOP leader hypothesizes an abnormal condition and analysis proceeds in both directions determining whether and how the condition is possible and what effects it has on the system. <p> Table 2.1: HAZOP guide words (adapted from [16].) the two questions "What is the effect of pipe A's temperature being too high?" and "How can pipe A's temperature get too high?" Since the questions center around pipe parameters, HAZOP has been characterized as a "flow-based" analysis <ref> [22] </ref>. A deviation that can occur and can lead to a hazard is a meaningful deviation [22]. Often, this definition is modified to be probabilistic, i.e., a deviation that can occur with sufficiently high probability and can lead to a hazard with sufficiently high probability. <p> is the effect of pipe A's temperature being too high?" and "How can pipe A's temperature get too high?" Since the questions center around pipe parameters, HAZOP has been characterized as a "flow-based" analysis <ref> [22] </ref>. A deviation that can occur and can lead to a hazard is a meaningful deviation [22]. Often, this definition is modified to be probabilistic, i.e., a deviation that can occur with sufficiently high probability and can lead to a hazard with sufficiently high probability. HAZOP has been used extensively in the chemical, nuclear and food processing industries [22]. <p> lead to a hazard is a meaningful deviation <ref> [22] </ref>. Often, this definition is modified to be probabilistic, i.e., a deviation that can occur with sufficiently high probability and can lead to a hazard with sufficiently high probability. HAZOP has been used extensively in the chemical, nuclear and food processing industries [22]. The success of HAZOP may be attributed to several factors. The hypothetical nature of HAZOP questions encourages creative thinking [16]. Also, HAZOP studies are typically performed by a team of analysts, led by a HAZOP expert, resulting in a potentially very useful exchange of information and opinions. <p> Thus it may help a manual analysis to hypothesize component deviations. Software HAZOP Since a HAZOP concentrates on physical properties of the system [31], it is not directly applicable to analyzing computer input and output. McDermid and Pumfrey <ref> [22] </ref> outline a manual technique for adapting HAZOP to software design. The procedure taken is essentially identical to a standard HAZOP, except that the pipe-and-process diagram and guide words are changed. The pipe-and-process diagram is replaced by a MASCOT diagram.
Reference: [23] <author> Bonnie E. Melhart. </author> <title> Specification and Analysis of the Requirements for Embedded Software with an External Interaction Model. </title> <type> PhD thesis, </type> <institution> University of California, Irvine, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: SMHA was originally defined for a timed Petri net language [18]. It has been adapted to Statecharts <ref> [23, 24] </ref> and an effort is underway to adapt it to RSML. The algorithm takes as input a model of the system described in a formal, state-based language. The algorithm also requires the system state space to be partitioned into complementary "hazardous " and "safe" states. <p> It has been used extensively, including for shutdown software at Ontario Hydro nuclear reactor [3] and the University of California, Berkeley FIREWHEEL spacecraft [17]. The methodology has also been extended to the Statecharts specification language <ref> [23, 24] </ref>, showing 18 -1 +1 REVERSED VALVE ACTION 0 VALVE STUCK the applicability of mini-fault tree analysis, and especially SFTA, to the analysis of software requirements. Digraphs The other method of automating fault tree analysis is the use of directed graphs, referred to as digraphs in the literature.
Reference: [24] <author> Bonnie E. Melhart and Nancy G. Leveson. </author> <title> A specification model for safety analysis of embedded software. </title> <type> Technical report, </type> <institution> University of California, Irvine, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: However, it is common-place for there to be a highly non-linear relationship between software inputs and outputs. 4 enabled by software. Process-control software is especially difficult to characterize, as designs generally result in "frontier software," which tests the limits of programming practice <ref> [24] </ref>. As we place more faith in computers, we become more vulnerable to their failures. Peter Neumann has compiled a list of over 400 cases in which computers contributed to an accident or near-accident, some of which resulted in loss of life. Some incidents are due to computer hardware failures. <p> SMHA was originally defined for a timed Petri net language [18]. It has been adapted to Statecharts <ref> [23, 24] </ref> and an effort is underway to adapt it to RSML. The algorithm takes as input a model of the system described in a formal, state-based language. The algorithm also requires the system state space to be partitioned into complementary "hazardous " and "safe" states. <p> It has been used extensively, including for shutdown software at Ontario Hydro nuclear reactor [3] and the University of California, Berkeley FIREWHEEL spacecraft [17]. The methodology has also been extended to the Statecharts specification language <ref> [23, 24] </ref>, showing 18 -1 +1 REVERSED VALVE ACTION 0 VALVE STUCK the applicability of mini-fault tree analysis, and especially SFTA, to the analysis of software requirements. Digraphs The other method of automating fault tree analysis is the use of directed graphs, referred to as digraphs in the literature.
Reference: [25] <author> A.R.T. Ormsby, J.E. Hunt, and M.H. Lee. </author> <title> Towards an automated fmea assistant. </title> <booktitle> In Applications of Artificial Intelligence in Engineering VI, </booktitle> <pages> pages 739-752. </pages> <publisher> Elsevier Applied Science, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: For a FMECA this information includes hazard severity, the likelihood of detection, and frequency of occurrence. If a failure rate is sufficiently high and the effect is sufficiently serious, 23 then the system must be redesigned <ref> [25] </ref>. A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component [16]. <p> A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component [16]. FMEA is described as a slow and tedious procedure <ref> [7, 25, 28] </ref>. There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA [28]. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts [25]. <p> There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA [28]. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts <ref> [25] </ref>. In particular, the method leaves to the analyst the burden of investigating many similar failure patterns [28] (or recognizing that such patterns exist.) Another weakness of FMEA is its concentration on single failures. In contrast to methods like HAZOP, they do not treat hazards arising in component interfaces [16].
Reference: [26] <author> Charles Perrow. </author> <title> Normal Accidents. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: This behavior can be dangerous since small perturbations of software inputs often result in huge deviations in the outputs <ref> [15, 26] </ref>. 1 Additionally, the mathematics governing programming languages are not as well understood, nor as easily calculated, as those for analog systems [15]. Software engineering is a relatively new discipline, and there is very little historical data on its use as compared to other fields of engineering.
Reference: [27] <author> Henry Petroski. </author> <title> Galileo and the marble column: A paradigm of human error in design. Structural Safety, </title> <booktitle> 11 </booktitle> <pages> 1-11, </pages> <year> 1991. </year>
Reference-contexts: A quantitative analysis can be performed if probabilities are provided for the primal events, although the 14 analysis is complicated by non-independent events. However, the validity of probabilistic methods has been called into question. Actual rates of failure in practice have exceeded calculated values by several orders of magnitude <ref> [27] </ref>. Probability densities are usually ignored [30]. Consequently, no statistical confidence can be attached to the top event's probability, severely restricting its usefulness. Especially with respect to software, numbers can be very difficult to obtain.
Reference: [28] <author> C.J. Price, J.E. Hunt, M.H. Lee, and A.R.T. Ormsby. </author> <title> A model-based approach to the automation of failure mode effects analysis for design. </title> <booktitle> In Proceedings of the Institution of Mechanical Engineers Vol. </booktitle> <volume> 206, </volume> <year> 1992. </year> <month> 163 </month>
Reference-contexts: The second column lists failures modes, the third column failure effects, and the last column lists criticality ratings. Taken from <ref> [28] </ref>. as an aid to reliability analysis, but a variant known as Failure Modes, Effects and Criticality analysis (FMECA) has been used to identify potential hazards [16]. <p> If a failure rate is sufficiently high and the effect is sufficiently serious, 23 then the system must be redesigned [25]. A search for failure causes is not a part of the FMEA procedure <ref> [28] </ref>. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component [16]. FMEA is described as a slow and tedious procedure [7, 25, 28]. <p> A search for failure causes is not a part of the FMEA procedure [28]. FMEA has been used extensively and is well-understood by industry [7]. It is most appropriate as a detailed analysis of a single, standard component [16]. FMEA is described as a slow and tedious procedure <ref> [7, 25, 28] </ref>. There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA [28]. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts [25]. <p> FMEA is described as a slow and tedious procedure [7, 25, 28]. There are no tools to lessen the analyst's burden of investigating many similar effects, and there has been little research into the automation of FMEA <ref> [28] </ref>. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts [25]. In particular, the method leaves to the analyst the burden of investigating many similar failure patterns [28] (or recognizing that such patterns exist.) Another weakness of FMEA is its concentration on single <p> investigating many similar effects, and there has been little research into the automation of FMEA <ref> [28] </ref>. The amount of labor involved causes FMEA's to be expensive, since they must be performed by experts [25]. In particular, the method leaves to the analyst the burden of investigating many similar failure patterns [28] (or recognizing that such patterns exist.) Another weakness of FMEA is its concentration on single failures. In contrast to methods like HAZOP, they do not treat hazards arising in component interfaces [16].
Reference: [29] <author> Philip Schaefer. </author> <title> Analytic solution of qualitative differential equations. </title> <booktitle> In Proceedings Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 830-835. </pages> <publisher> AAAI Press, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: The solid line is the same function with "sharp" shape. Qualitative mathematics is not limited to algebraic functions. For example, Schaefer constructs an interesting model for a family of nonlinear oscillating functions <ref> [29] </ref>. The parameters of the functions are the envelope, period of oscillation, and "shape" of the function. Figure 5.1 shows an example of a qualitative oscillating function. Schaeffer has developed an algorithm for qualitatively solving the derivatives of this family of functions. Please see [29] for a detailed treatment of this <p> a family of nonlinear oscillating functions <ref> [29] </ref>. The parameters of the functions are the envelope, period of oscillation, and "shape" of the function. Figure 5.1 shows an example of a qualitative oscillating function. Schaeffer has developed an algorithm for qualitatively solving the derivatives of this family of functions. Please see [29] for a detailed treatment of this calculus. Qualitative mathematics has the advantage of being efficient to calculate and relatively easy to understand. Similar values can be grouped and treated collectively by the qualitative functions.
Reference: [30] <author> Roland Schinzinger. </author> <title> Technological hazards and the engineer. </title> <journal> IEEE Technology and Society Magazine, </journal> <pages> pages 12-16, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Even if the definition is interpreted to include indirect releases of energy, it excludes other dangerous situations. For example, a non-operational patient monitoring system can lead to an accident in which no energy is released, controlled or otherwise. Another definition of hazard, suggested by <ref> [30] </ref>, is a "peril, danger, or risk." While this captures the intuitive notion of a hazard, and certainly cannot be proven 7 8 to exclude any cases, it is too ambiguous to serve as a technical definition. <p> However, the validity of probabilistic methods has been called into question. Actual rates of failure in practice have exceeded calculated values by several orders of magnitude [27]. Probability densities are usually ignored <ref> [30] </ref>. Consequently, no statistical confidence can be attached to the top event's probability, severely restricting its usefulness. Especially with respect to software, numbers can be very difficult to obtain. In order to complete a probabilistic analysis, the analyst must assign arbitrary values for software failures.
Reference: [31] <author> Jouko Suokas. </author> <title> The role of safety analysis in accident prevention. </title> <journal> Accident Analysis and Prevention, </journal> <volume> 20(1) </volume> <pages> 67-85, </pages> <year> 1988. </year>
Reference-contexts: Hazard analyses were first developed in the fields of nuclear power and weaponry, aviation, and space technology <ref> [31] </ref>. As is shown in chapter 2, there are a variety of hazard analysis procedures, but few can handle the complexities of software. In particular, there is a lack of forward search methods for the analysis of software requirements. <p> The goal of a HAZOP is to identify operational deviations from intended performance and study their impact on the system's safety <ref> [31] </ref>. The HAZOP procedure is carried out by a HAZOP expert (the leader) and a team of system experts. The leader poses a battery of questions to the experts in an attempt to elicit potential system hazards. <p> Since HAZOP is a flow-based analysis, deviations that originate from within components are not inspected directly. Rather, a deviation within a component (as well as a human error or other environmental perturbation) is assumed to be manifested as a disturbed flow <ref> [31] </ref>. This assumption may be problematic both for manual and automated procedures. A basic strength of the manual HAZOP is the way in which it engenders investigative thought processes. A purely flow-oriented approach may cause the analyst to neglect component-related malfunctions and hazards in favor of pipe-related causes and effects. <p> A purely flow-oriented approach may cause the analyst to neglect component-related malfunctions and hazards in favor of pipe-related causes and effects. Thus it may help a manual analysis to hypothesize component deviations. Software HAZOP Since a HAZOP concentrates on physical properties of the system <ref> [31] </ref>, it is not directly applicable to analyzing computer input and output. McDermid and Pumfrey [22] outline a manual technique for adapting HAZOP to software design. The procedure taken is essentially identical to a standard HAZOP, except that the pipe-and-process diagram and guide words are changed.
Reference: [32] <author> J.R. Taylor. </author> <title> Sequential effects in failure mode analysis. In Reliability and fault Tree Analysis, </title> <address> pages 881-894, </address> <year> 1975. </year>
Reference-contexts: The algorithm then traces forward to find the effects, constructing the decision graph. As a manual technique, CCA is a systematic analysis of system block diagrams that results in a notation in which sequence is shown explicitly <ref> [32] </ref>. As a semi-automated technique, it has several shortcomings. The analyst must decide when a particular search path will not lead to a hazard. Also, contrasted with HAZOP (presented in the next section) the algorithm does not automatically identify failure modes.
Reference: [33] <author> J.R. Taylor. </author> <title> An algorithm for fault-tree construction. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> R-31(2):137-146, </volume> <month> June </month> <year> 1982. </year>
Reference-contexts: FTA is used extensively in safety programs in the nuclear power and weapons industries. It has also gained widespread acceptance in other industries. 1 Although FTA has proven useful in practice, manually-constructed fault trees suffer from several weaknesses. They can require much time and effort to construct <ref> [5, 9, 14, 33] </ref>. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. <p> They can require much time and effort to construct [5, 9, 14, 33]. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" <ref> [33] </ref>, different analysts often produce fault trees that are inconsistent with each other [5, 15, 33]. Several algorithms have been developed to alleviate problems with the manual construction of fault trees. <p> They can require much time and effort to construct [5, 9, 14, 33]. Also, they are subject to logical errors and omissions [14]. Because of this, and because FTA "is an art, rather than a science" [33], different analysts often produce fault trees that are inconsistent with each other <ref> [5, 15, 33] </ref>. Several algorithms have been developed to alleviate problems with the manual construction of fault trees. One family of algorithms is based on the technique of "mini-fault trees." The other family of algorithms uses "digraphs." 1 A variation of FTA is the Management Oversight and Risk Tree (MORT). <p> Taylor describes an algorithm based on a process flow sheet of the plant, such as a piping and instrumentation diagram <ref> [33] </ref>. The system is assumed to be a set of standard components, such as valves and pumps, inter-connected by ports. Each port has process variables defined for it, such as pressure and temperature.
References-found: 33

