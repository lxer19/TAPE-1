URL: http://polaris.cs.uiuc.edu/reports/827.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: The PERFECT Club Benchmarks: Effective Performance Evaluation of Supercomputers The PERFECT 1 Club:  
Author: M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, L. Pointer, R. Roloff, A. Sameh E. Clementi, S. Chin, D. Schneider G. Fox, P. Messina, D. Walker C. Hsiung, J. Schwarzmeier K. Lue, S. Orszag, F. Seidl O. Johnson R. Goodrum J. Martin 
Date: July 18, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [ArMi 74] <author> Arakawa, A., and Mintz, Y., </author> <year> 1974, </year> <title> The UCLA Atmospheric Circulation Model, </title> <institution> Dept. of Meteorology, University of Califor-nia. </institution>
Reference-contexts: Only the forecast module of the NMC code is used in the benchmarking. The formulation of the model is based on expressing the unknown functions in terms of their spherical harmonic expansions in the horizontal direction. In the vertical direction, the quadratic conserving finite difference formula of <ref> [ArMi 74] </ref> is used. A semi-implicit, backward time integration scheme is applied, and initial conditions are obtained from a spectral Hough operational analysis [Flat 67].
Reference: [BaBa 85] <author> Bailey, D., and Barton, J., </author> <year> 1985, </year> <title> The NAS Kernel Benchmark Program, </title> <type> NASA Technical Memorandum 86711, </type> <institution> Moffett Field, CA, Ames Research Center, National Aeronautics and Space Administration. </institution>
Reference-contexts: A number of benchmark collections have been developed previously. In particular, the more well-known sets include the Livermore Fortran Kernels [McMa 88], the Argonne LINPACK measurements [Dong 87], the Los Alamos benchmarks [Lube 88], and the NAS kernels from NASA/Ames <ref> [BaBa 85] </ref>. One of the more troubling aspects of the state of benchmark-ing relative to these collections is that there is no well-defined relationship among their results.
Reference: [BaSP 79] <author> Bartlett, R., Shavitt, I., and Purvis, G., </author> <year> 1979, </year> <institution> J. Chem. Phys., 71:281. </institution>
Reference-contexts: The total potential is the sum of the intra- and inter- molecular potentials. The intramolecular potential used is that denoted by DMBPT (1) in the double-excitation infinity-order many-body perturbation theory calculations of Bartlett, Shavitt and Purvis <ref> [BaSP 79] </ref>. The intermolecular potential used is the MCY potential. MG3D. This seismic migration code (see [ReKe 89]), which was written for a CRAY X-MP by Reshef and Kessler at Tel Aviv University, Tel Aviv, Israel, is used to investigate the geological structure of the Earth.
Reference: [BeWa 76] <author> Beam, R., and Warming, R., </author> <year> 1976, </year> <title> An Implicit Finite Difference Algorithm for Hyperbolic Systems in Conservative Law Form, </title> <journal> J. Comp. Phys., 22:87. </journal>
Reference-contexts: In addition, ARC3D can be run on any smoothly-varying curvilinear mesh, and vectorizes well. The equations are discretized onto a curvilinear mesh, and a Beam-Warming <ref> [BeWa 76] </ref> method is used to cast the equations in implicit form. Three-point central difference approximations are used, leading to a penta-diagonal system of equations. Numerical dissipation terms are added to improve stability, and a turbulent viscosity model is used to produce the steady-state flow field.
Reference: [Bour 74] <author> Bourke, W., </author> <year> 1974, </year> <title> A Multi-Level Spectral Model. Formulation and Hemispheric Integrations, Monthly Weather Review, </title> <publisher> 102:687. </publisher>
Reference-contexts: The spectral method of solving PDE's was pioneered by Orszag and Eliasen and co-workers (see [Orsz 70] and [ElMR 70]), and <ref> [Bour 74] </ref> subsquently showed how to apply it to atmospheric modeling. Only the forecast module of the NMC code is used in the benchmarking. The formulation of the model is based on expressing the unknown functions in terms of their spherical harmonic expansions in the horizontal direction.
Reference: [BFJO 84] <author> Brooks, E., Fox, G., Johnson, M., Otto, S., Stolorz, P., Athas, W., DeBenedictis, E., Faucette, R., Seitz, C., and Stack, J., </author> <year> 1984, </year> <title> Pure Gauge SU(3) Lattice Gauge Theory on an Array of 42 Computers, </title> <journal> Phys. Rev. Lett., </journal> <note> 52:2324, Caltech Report C 3 P--65. </note>
Reference: [CaMa 82] <author> Cabbibo, N.,and Marinari, E., </author> <year> 1982, </year> <title> A New Method of Updating SU(N) Matrices in Computer Simulations of Gauge Theories, </title> <journal> Phys. Lett., 119B:387. </journal>
Reference-contexts: A major component of the QCD code involves updating these matrices. A number of different methods have been proposed for updating the SU (3) matrices (see [OBDA 87] for a summary). The PERFECT 8 Club QCD benchmark uses the Cabbibo-Marinari pseudo heat-bath algo-rithm <ref> [CaMa 82] </ref> to update the SU (3) matrices on the lattice links. This algorithm uses a Monte Carlo technique to generate a chain of configurations which are distributed with a probability proportional to exp (S (U )), where S (U ) is the action of configuration U .
Reference: [Chri 86] <author> Christidis, Z., </author> <year> 1986, </year> <title> Hydrodynamic Mesoscale Modeling of Atmospheric Transport And Pollutant Deposition in the Vicinity of a Lake, </title> <type> Ph. D. thesis, </type> <institution> Atmospheric and Oceanic Science Department, University of Michigan, </institution> <address> Ann Arbor. </address>
Reference-contexts: This three-dimensional code supplied by the IBM Kingston group simulates pollutant concentration and deposition patterns in lakeshore environments by solving the complete system of hydrodynamic equations. The 4 code was developed by Christidis at the Atmospheric and Oceanic Science Department of the University of Michigan <ref> [Chri 86] </ref> and was subsequently ported to the LCAP system at IBM Kingston [ChSo 87]. The advection-diffusion equation for the transport, diffusion, and deposition of pollutants is also included in the model. Model variables are integrated using a time-splitting method.
Reference: [ChSo 87] <author> Christidis, Z., and Sonnad, V., </author> <year> 1987, </year> <title> Parallel Implementation of a Pseudospectral Method on a Loosely Coupled Array of Processors, IBM Kingston, </title> <type> Technical Report KGN-143. </type>
Reference-contexts: The 4 code was developed by Christidis at the Atmospheric and Oceanic Science Department of the University of Michigan [Chri 86] and was subsequently ported to the LCAP system at IBM Kingston <ref> [ChSo 87] </ref>. The advection-diffusion equation for the transport, diffusion, and deposition of pollutants is also included in the model. Model variables are integrated using a time-splitting method.
Reference: [CHLO 84] <author> Curry, J., Herring, J., Loncaric, J., and Orszag, S., </author> <year> 1984, </year> <title> Order and Disorder in Two- and Three-Dimensional Benard Convection, </title> <journal> J. Fluid. Mech., 174:1. </journal>
Reference-contexts: Data from 1500 time values were Fourier-transformed and a frequency cutoff was employed in order to reduce the problem size in the 7 frequency domain. OCEAN. This code, which solves the dynamical equations of a two-dimensional Boussinesq fluid layer (see <ref> [CHLO 84] </ref>), was submitted by the Princeton group. This code is needed in order to study the chaotic behavior of free-slip Rayleigh-Benard convection, [Lore 63].
Reference: [DeAd 88] <author> Denning, J., and Adams, G., </author> <year> 1988, </year> <title> Research Questions for Performance Analysis of Supercomputers, Performance Evaluation of Supercomputers:403, </title> <editor> J. Martin, editor, </editor> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: For example, Denning and Adams have noted the particular difficulty that arises when comparing different architectures and have urged the development of a benchmark methodology for this purpose <ref> [DeAd 88] </ref>. Nevertheless, bench-marking continues to provide one of the few recognized means of acquiring useful performance information about complex systems running complex tasks [Jami 88].
Reference: [Dong 87] <author> Dongarra, J., </author> <year> 1987, </year> <title> Performance of Various Computers Using Standard Linear Equations Software in a Fortran Environment, </title> <institution> Argonne National Laboratory Technical Report MCS-RM-23, Argonne, IL. </institution>
Reference-contexts: A number of benchmark collections have been developed previously. In particular, the more well-known sets include the Livermore Fortran Kernels [McMa 88], the Argonne LINPACK measurements <ref> [Dong 87] </ref>, the Los Alamos benchmarks [Lube 88], and the NAS kernels from NASA/Ames [BaBa 85]. One of the more troubling aspects of the state of benchmark-ing relative to these collections is that there is no well-defined relationship among their results.
Reference: [DoMW 87] <author> Dongarra, J., Martin, J., and Worlton, J., </author> <year> 1987, </year> <title> Computer Benchmarking: Paths and Pitfalls, </title> <journal> IEEE SPECTRUM, July:38. </journal>
Reference-contexts: How much of that power can be harnessed is the central theme of performance evaluation. A significant body of literature documenting the use of benchmarking as a means for evaluating supercomputer performance has developed [LuMM 85], [MWGe 82], [UhrL 84], <ref> [DoMW 87] </ref>, [NeSi 87]. Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process [MaRi 88].
Reference: [DWVH 88] <author> Dupuis, M., Watts, J., Villar, H., and Hurst, G., </author> <year> 1988, </year> <note> HONDO: Version 7.0 Documentation, IBM Kingston Technical Report KGN-169, and Quantum Chemistry Program Exchange Bulletin 8:2. </note>
Reference: [ElMR 70] <author> Eliasen, E., Machenhauer, B., and Rasmusen, E., </author> <year> 1970, </year> <title> On a Numerical Method for Integration of the Hydrodynamic Equations with a Spectral Representation of the Horizontal Fields, </title> <booktitle> In 43 stitute for Theoretical Meteorology, </booktitle> <institution> University of Copenhagen, </institution> <note> Report no. 2. </note>
Reference-contexts: The spectral method of solving PDE's was pioneered by Orszag and Eliasen and co-workers (see [Orsz 70] and <ref> [ElMR 70] </ref>), and [Bour 74] subsquently showed how to apply it to atmospheric modeling. Only the forecast module of the NMC code is used in the benchmarking. The formulation of the model is based on expressing the unknown functions in terms of their spherical harmonic expansions in the horizontal direction.
Reference: [Flat 67] <author> Flattery, T., </author> <year> 1967, </year> <title> Hough Functions, </title> <institution> Dept. of Geophysical Sciences, University of Chicago, </institution> <type> Technical Report 20. </type>
Reference-contexts: In the vertical direction, the quadratic conserving finite difference formula of [ArMi 74] is used. A semi-implicit, backward time integration scheme is applied, and initial conditions are obtained from a spectral Hough operational analysis <ref> [Flat 67] </ref>. The ocean interacts with the atmosphere by means of evaporation and sensible heating, and the moisture cycle consists of large-scale precipitation, and Kuo-type convection [KuoH 65]. SPICE.
Reference: [GaJM 87] <author> Gallivan, Jalby, W., and Meier, U., </author> <year> 1987, </year> <title> The Use of BLAS3 in Linear Algebra on a Parallel Processor with a Hierarchical Memory, </title> <note> SIAM J. </note> <institution> Sci. Stat. Comput. 8:6:1079. </institution>
Reference-contexts: In Table 6, we list the specific transformations from Table 3 as recorded in diaries for the Alliant FX/8, CRAY X-MP/416 4 , and IBM 3090-600S 4 . We note the use of optimized matrix-vector (BLAS2) and matrix-matrix (BLAS3) kernels (see <ref> [GaJM 87] </ref>) as well as an efficient Cholesky algorithm (for solving symmetric positive definite linear systems) on all three machines.
Reference: [Gear 71] <author> Gear, C., </author> <year> 1971, </year> <title> Numerical Initial Value Problems in Ordinary Differential Equations, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference-contexts: MDG can be used to predict a wide variety of static and dynamic properties of liquid water. The code solves the Newtonian equations of motion for 343 water molecules in a cubical box using Gear's sixth-order predictor-corrector method <ref> [Gear 71] </ref>. The total potential is the sum of the intra- and inter- molecular potentials. The intramolecular potential used is that denoted by DMBPT (1) in the double-excitation infinity-order many-body perturbation theory calculations of Bartlett, Shavitt and Purvis [BaSP 79]. The intermolecular potential used is the MCY potential. MG3D.
Reference: [Gott 87] <author> Gottschalk, T., </author> <year> 1987, </year> <title> A New Multi-Target Tracking Model, </title> <booktitle> to appear in Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications, ACM, </booktitle> <address> New York, N.Y., </address> <note> Caltech Report C 3 P-480. </note>
Reference-contexts: In a multi-target scenario, sensor data points are associated with tracks by means of the track splitting algorithm described in <ref> [Gott 87] </ref>. In general this association will not be unique, and a single sensor point may at some stage of processing be associated with more than one track. This is particularly true at the early stages of processing when the number of possible valid tracks may be large.
Reference: [Gott 88] <author> Gottschalk, T., </author> <year> 1988, </year> <title> Concurrent Multiple Target Tracking to appear in Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications, </title> <publisher> ACM, </publisher> <address> New York, N.Y., </address> <note> Caltech Report C 3 P-567. </note>
Reference-contexts: TRACK. The TRACK code was developed at Caltech by Gottschalk and co-workers to determine the course of a set of an unknown number of targets, such as rocket boosters, from observations of the targets taken by sensors at regular time intervals (see <ref> [Gott 88] </ref> and references therein). The targets may be launched from a number of different sites. Gottschalk's code was originally written in C for the Caltech/JPL Mark II and III hyper-cubes. The sequential Fortran version used in the PERFECT benchmarks was written by Gottschalk at the start of 1988.
Reference: [Infa 86] <author> Infante, E., (Committee Chairman), </author> <year> 1986, </year> <title> An Agenda for Improved Evaluation of Supercomputer Performance, </title> <type> (58 pp.), </type> <institution> Energy Engineering Board, Commission on Engineering and Technical Systems, National Research Council, </institution> <address> 2101 Constitution Avenue, N.W., Washington DC, 20418. </address>
Reference-contexts: A report prepared by the National Research Council of the National Academy of Sciences, considering the importance of supercomputing to the development of science and the deficiencies inherent in the techniques currently used, encouraged an emphasis on the methodology and metrics applied to the evaluation of supercomputing systems <ref> [Infa 86] </ref>. A number of benchmark collections have been developed previously. In particular, the more well-known sets include the Livermore Fortran Kernels [McMa 88], the Argonne LINPACK measurements [Dong 87], the Los Alamos benchmarks [Lube 88], and the NAS kernels from NASA/Ames [BaBa 85].
Reference: [Jame 83] <author> Jameson, A., </author> <year> 1983, </year> <title> Solution of the Euler Equations for a Two-Dimensional Transonic Flow by a Multigrid Method, </title> <journal> Applied Math. and Comp., 13:327. </journal>
Reference-contexts: This code has been previously used for determining the reponse of laminated anisotropic shallow panels having quadrilateral planforms. FLO52Q. FLO52Q, provided by the Princeton group, was developed by Jameson at Princeton University (see <ref> [Jame 83] </ref> and references therein) to analyse the transonic inviscid flow past an airfoil by solving the unsteady Euler equations. The two-dimensional domain is discretized into quadrilateral cells. In the case considered there were 128 intervals around the profile, and 32 radially.
Reference: [Jami 88] <author> Jamieson, L., </author> <year> 1988, </year> <title> Using Algorithm Characteristics to Evaluate Parallel Architectures, Performance Evaluation of Supercomputers:21, </title> <editor> J. Martin, editor, </editor> <publisher> North-Holland, Amster-dam. </publisher>
Reference-contexts: Nevertheless, bench-marking continues to provide one of the few recognized means of acquiring useful performance information about complex systems running complex tasks <ref> [Jami 88] </ref>.
Reference: [KuSa 87] <author> Kuck, D., and Sameh, A., </author> <year> 1987, </year> <title> A Supercomputing Performance Evaluation Plan, </title> <booktitle> Proceedings of First Int'l. Conf. on Supercomputing, </booktitle> <address> Athens, Greece. </address> <month> 44 </month>
Reference-contexts: Without solid grounding even in specific cases, generalizing the results beyond the environments in which they were developed becomes significantly more problematic. The general approach followed by the PERFECT Club develops ideas that have been described elsewhere <ref> [KuSa 87] </ref>, [MaMW 87]. We have chosen to focus on applications, since it is the users of supercomputers, the developers of large-scale applications, who drive the need for ever increasing processing power.
Reference: [KuoH 65] <author> Kuo, H., </author> <year> 1965, </year> <title> On Formation and Intensification of Tropical Cyclones Through Latent Heat Release by Cumulus Convection, </title> <institution> J. Atmos. Sci., 22:40. </institution>
Reference-contexts: A semi-implicit, backward time integration scheme is applied, and initial conditions are obtained from a spectral Hough operational analysis [Flat 67]. The ocean interacts with the atmosphere by means of evaporation and sensible heating, and the moisture cycle consists of large-scale precipitation, and Kuo-type convection <ref> [KuoH 65] </ref>. SPICE. This code is a general-purpose circuit simulation program for non-linear DC, non-linear transient, and linear AC analysis developed by the Integrated Circuits Group of the Electronics Research Laboratory and the Department of Electrical Engineering and Computer Science at UC Berke-ley, [Nage 75].
Reference: [LiCl 86] <author> Lie, G., and Clementi, E., </author> <year> 1986, </year> <title> Molecular Dynamics Simulation of Liquid Water With an ab initio Flexible Water-Water Interaction Potential, </title> <journal> Phys. Rev., A33:2679. </journal>
Reference-contexts: MDG. This code was developed by the IBM Kingston group. MDG performs a molecular dynamics calculation of 343 water molecules in the liquid state at room temperature and pressure. The code, written by Lie and Clementi of IBM <ref> [LiCl 86] </ref>, uses the MCY configuration interaction potential for rigid water-water interactions [MaCY 76], and extends it to include the effects of intra-molecular vibration. MDG can be used to predict a wide variety of static and dynamic properties of liquid water.
Reference: [Lore 63] <author> Lorenz, E., </author> <year> 1963, </year> <title> Deterministic Non-Periodic Flow, </title> <institution> J. Atmos. Sci., 20:130. </institution>
Reference-contexts: OCEAN. This code, which solves the dynamical equations of a two-dimensional Boussinesq fluid layer (see [CHLO 84]), was submitted by the Princeton group. This code is needed in order to study the chaotic behavior of free-slip Rayleigh-Benard convection, <ref> [Lore 63] </ref>.
Reference: [Lube 88] <author> Lubeck, O., </author> <year> 1988, </year> <title> Supercomputer Performance: The Theory, Practice, and Results, </title> <institution> Los Alamos National Laboratory Technical Report LA-11204-MS, </institution> <address> Los Alamos, New Mexico. </address>
Reference-contexts: A number of benchmark collections have been developed previously. In particular, the more well-known sets include the Livermore Fortran Kernels [McMa 88], the Argonne LINPACK measurements [Dong 87], the Los Alamos benchmarks <ref> [Lube 88] </ref>, and the NAS kernels from NASA/Ames [BaBa 85]. One of the more troubling aspects of the state of benchmark-ing relative to these collections is that there is no well-defined relationship among their results.
Reference: [LuMM 85] <author> Lubeck, O., Moore, J., and Mendez, R., </author> <year> 1985, </year> <title> A Benchmark Comparison of Three Supercomputers: </title> <type> Fujitsu VP-200, </type> <institution> Hitachi S810/20, and Cray X-MP/2, Computer 18:12. </institution>
Reference-contexts: How much of that power can be harnessed is the central theme of performance evaluation. A significant body of literature documenting the use of benchmarking as a means for evaluating supercomputer performance has developed <ref> [LuMM 85] </ref>, [MWGe 82], [UhrL 84], [DoMW 87], [NeSi 87]. Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process [MaRi 88].
Reference: [MaMW 87] <author> Martin, J., and Mueller-Wichards, D., </author> <year> 1987, </year> <title> Supercomputer Performance Evaluation: Status and Directions, </title> <journal> The Journal of Supercomputing 1:87. </journal>
Reference-contexts: Without solid grounding even in specific cases, generalizing the results beyond the environments in which they were developed becomes significantly more problematic. The general approach followed by the PERFECT Club develops ideas that have been described elsewhere [KuSa 87], <ref> [MaMW 87] </ref>. We have chosen to focus on applications, since it is the users of supercomputers, the developers of large-scale applications, who drive the need for ever increasing processing power.
Reference: [MaRi 88] <author> Martin, J., and Riganati, J., </author> <year> 1988, </year> <title> On Benchmarking Standards for High Performance Computing, </title> <publisher> IEEE Computer 21:9:68. </publisher>
Reference-contexts: Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process <ref> [MaRi 88] </ref>. If benchmarking is to mature sufficiently to meet the requirements of system architects as well as application and algorithm developers, it must address standardization issues as well as various caveats and specific considerations that can reduce general applicability.
Reference: [MaCY 76] <author> Matsuoka, O., Clementi, E., and Yoshimine, M., </author> <year> 1976, </year> <institution> J. Chem. Phys., 64:1351. </institution>
Reference-contexts: BDNA was developed by Swamy and Clementi of IBM 5 Kingston [SwCl 87b], and is based on an earlier molecular dynamics code by Laaksonen. The Matsuoka-Clementi-Yoshimine (MCY) potential function is used to describe the water-water interaction <ref> [MaCY 76] </ref>. Atom-atom potential functions of the form, u ij (R) = R 12 R 6 + C R are used to describe water-ion, water-nucleic acid and ion-ion interactions. The translational equation of motion of each molecule is solved by a Gear fifth-order predictor-corrector method. <p> This code was developed by the IBM Kingston group. MDG performs a molecular dynamics calculation of 343 water molecules in the liquid state at room temperature and pressure. The code, written by Lie and Clementi of IBM [LiCl 86], uses the MCY configuration interaction potential for rigid water-water interactions <ref> [MaCY 76] </ref>, and extends it to include the effects of intra-molecular vibration. MDG can be used to predict a wide variety of static and dynamic properties of liquid water.
Reference: [McMa 88] <author> McMahon, F., </author> <year> 1988, </year> <title> The Livermore Fortran Kernels Test of the Numerical Performance Range, Performance Evaluation of Supercomputers:143, </title> <editor> J. Martin, editor, </editor> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: A number of benchmark collections have been developed previously. In particular, the more well-known sets include the Livermore Fortran Kernels <ref> [McMa 88] </ref>, the Argonne LINPACK measurements [Dong 87], the Los Alamos benchmarks [Lube 88], and the NAS kernels from NASA/Ames [BaBa 85]. One of the more troubling aspects of the state of benchmark-ing relative to these collections is that there is no well-defined relationship among their results.
Reference: [MWGe 82] <author> Mueller-Wichards, D., and Gentzsch, W., </author> <year> 1982, </year> <title> Performance Comparisons Among Several Parallel and Vector Computers on a Set of Fluid Flow Problems, </title> <type> DFVLR Technical Report IB 262 - 82 R01. </type>
Reference-contexts: How much of that power can be harnessed is the central theme of performance evaluation. A significant body of literature documenting the use of benchmarking as a means for evaluating supercomputer performance has developed [LuMM 85], <ref> [MWGe 82] </ref>, [UhrL 84], [DoMW 87], [NeSi 87]. Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process [MaRi 88].
Reference: [Nage 75] <author> Nagel, L., </author> <year> 1975, </year> <title> SPICE2: A Computer Program to Simulate Semiconductor Circuits, </title> <institution> Memorandum ERL-M520, Electronics Research Laboratory, College of Engineering, University of Cal-ifornia, Berkeley. </institution> <month> 45 </month>
Reference-contexts: SPICE. This code is a general-purpose circuit simulation program for non-linear DC, non-linear transient, and linear AC analysis developed by the Integrated Circuits Group of the Electronics Research Laboratory and the Department of Electrical Engineering and Computer Science at UC Berke-ley, <ref> [Nage 75] </ref>. The CSRD group submitted the SPICE version, SPICE2G.6, used in the PERFECT Club benchmarking suite. SPICE is widely used in 9 industry, and is one of the most important CAD tools in the design of inte-grated circuits. Within SPICE, problems are formulated as stiff differential-algebraic equations.
Reference: [NeSi 87] <author> Neves, K., and Simon, H., </author> <year> 1987, </year> <title> Supercomputer Performance Evaluation: Benchmarking Applications on Supercomputers, </title> <booktitle> Proceedings of the Second Int'l. Conf. on Supercomputing:374. </booktitle>
Reference-contexts: How much of that power can be harnessed is the central theme of performance evaluation. A significant body of literature documenting the use of benchmarking as a means for evaluating supercomputer performance has developed [LuMM 85], [MWGe 82], [UhrL 84], [DoMW 87], <ref> [NeSi 87] </ref>. Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process [MaRi 88].
Reference: [NeSa 83] <author> Newton, R., and Sangiovanni-Vincentelli, A., </author> <year> 1983, </year> <title> Relaxation-Based Circuit Simulation, </title> <journal> IEEE Trans. </journal> <note> on ED, ED-30:9:1184. </note>
Reference-contexts: Within SPICE, problems are formulated as stiff differential-algebraic equations. The numerical methods of solution include sti*y stable numerical integration algorithms, the Newton-Raphson method for solving the non-linear algebraic equations, and sparse linear system solvers (see <ref> [NeSa 83] </ref>). TRACK. The TRACK code was developed at Caltech by Gottschalk and co-workers to determine the course of a set of an unknown number of targets, such as rocket boosters, from observations of the targets taken by sensors at regular time intervals (see [Gott 88] and references therein).
Reference: [NoCa 76] <author> Noor, A., and Camin R., </author> <year> 1976, </year> <title> Symmetry Considerations for Anisotropic Shells, </title> <journal> Comp. </journal> <note> Methods in Appl. </note> <institution> Mech. and Eng., 9:31. </institution>
Reference-contexts: One complete helical turn of B-DNA consisting of ten base pairs is considered. DYFESM. This code, submitted by the CSRD group, is a two-dimensional, dynamic, finite element code for the analysis of symmetric anisotropic structures (see <ref> [NoCa 76] </ref> and [NoPe 85]) developed by Noor and Peters at the NASA Langley Research Center, Hampton VA, for the CRAY X-MP. An explicit leap-frog temporal method with substructuring is used to solve for the displacements and stresses, along with the velocities and accelerations at each time step.
Reference: [NoPe 85] <author> Noor, A., and Peters J., </author> <year> 1985, </year> <title> Model-Size Reduction Techniques for the Analysis of Symmetric Anisotropic Structures, </title> <journal> Eng. Comp., 2:4:285. </journal>
Reference-contexts: One complete helical turn of B-DNA consisting of ten base pairs is considered. DYFESM. This code, submitted by the CSRD group, is a two-dimensional, dynamic, finite element code for the analysis of symmetric anisotropic structures (see [NoCa 76] and <ref> [NoPe 85] </ref>) developed by Noor and Peters at the NASA Langley Research Center, Hampton VA, for the CRAY X-MP. An explicit leap-frog temporal method with substructuring is used to solve for the displacements and stresses, along with the velocities and accelerations at each time step.
Reference: [Orsz 70] <author> Orszag, S., </author> <year> 1970, </year> <title> Transform Methods for Calculation of Vector Coupled Sums: Application to the Spectral Form of the Vorticity Equations, </title> <institution> J. Atmos. Sci., 27:890. </institution>
Reference-contexts: The spectral method of solving PDE's was pioneered by Orszag and Eliasen and co-workers (see <ref> [Orsz 70] </ref> and [ElMR 70]), and [Bour 74] subsquently showed how to apply it to atmospheric modeling. Only the forecast module of the NMC code is used in the benchmarking.
Reference: [Orsz 71] <author> Orszag, S., </author> <year> 1971, </year> <title> Numerical Simulation of Incompressible Flows Within Simple Boundaries, Galerkin (Spectral) Representations, </title> <journal> Stud. Appl. Math., 50:293. </journal>
Reference-contexts: A spectral method (see <ref> [Orsz 71] </ref>) is used to solve equations (Eq 1)-(Eq 3). The nonlinear terms are evaluated by fast-transform methods with aliasing terms removed. Time-stepping is done by a leapfrog scheme for the nonlinear terms, and an implicit scheme (Crank-Nicolson or backwards Euler method) for the viscous terms.
Reference: [OBDA 87] <author> Otto, S., Baillie, C., Ding, H-Q., Apostolakis, J., Gupta, R., Kilcup, G., Patel, A., and Sharpe, S., </author> <year> 1987, </year> <title> Lattice Gauge Theory Benchmarks, Caltech Report C 3 P-405R. </title>
Reference-contexts: The gluons are represented by SU (3) matrices, which are a particular type of 3fi3 complex matrix. A major component of the QCD code involves updating these matrices. A number of different methods have been proposed for updating the SU (3) matrices (see <ref> [OBDA 87] </ref> for a summary). The PERFECT 8 Club QCD benchmark uses the Cabbibo-Marinari pseudo heat-bath algo-rithm [CaMa 82] to update the SU (3) matrices on the lattice links.
Reference: [PuSt 80] <author> Pulliam, T., and Steger, J., </author> <year> 1980, </year> <title> Implicit Finite-Difference Simulations of Three-Dimensional Compressible Flow,AIAA J., </title> <publisher> 18:159. </publisher>
Reference: [PuSt 85] <author> Pulliam, T., and Steger, J., </author> <year> 1985, </year> <title> Recent Improvements in Efficiency, Accuracy, and Convergence for Implicit Approximate Factorization Algorithms, </title> <booktitle> AIAA-85-0360 23rd Aerospace Science Meeting, </booktitle> <month> January 14-17, </month> <year> 1985, </year> <title> Reno, </title> <address> Nevada. </address>
Reference: [ReKe 89] <author> Reshef, M., and Kessler, D., </author> <year> 1989, </year> <title> Practical Implementation of Three-Dimensional Post-Stack Depth Migration, </title> <note> to appear in Geophysics, </note> <month> March </month> <year> 1989. </year> <month> 46 </month>
Reference-contexts: The intramolecular potential used is that denoted by DMBPT (1) in the double-excitation infinity-order many-body perturbation theory calculations of Bartlett, Shavitt and Purvis [BaSP 79]. The intermolecular potential used is the MCY potential. MG3D. This seismic migration code (see <ref> [ReKe 89] </ref>), which was written for a CRAY X-MP by Reshef and Kessler at Tel Aviv University, Tel Aviv, Israel, is used to investigate the geological structure of the Earth.
Reference: [Sela 80] <author> Sela, J., </author> <year> 1980, </year> <title> Spectral Modeling at the National Meterological Center, Monthly Weather Review, </title> <publisher> 180:1279. </publisher>
Reference-contexts: The lattice size for the benchmark was taken as 8 4 . SPEC77. This global spectral model for simulating atmospheric flow, which was submitted by the CSRD group, was originally developed at the National Meteorological Center (NMC) for a CDC CYBER 205, and is described in detail in <ref> [Sela 80] </ref> and [Sela 82]. The spectral method of solving PDE's was pioneered by Orszag and Eliasen and co-workers (see [Orsz 70] and [ElMR 70]), and [Bour 74] subsquently showed how to apply it to atmospheric modeling. Only the forecast module of the NMC code is used in the benchmarking.
Reference: [Sela 82] <author> Sela, J., </author> <year> 1982, </year> <title> The NMC Spectral Model, </title> <note> NOAA Technical Report NWS 30 (May 1982). </note>
Reference-contexts: SPEC77. This global spectral model for simulating atmospheric flow, which was submitted by the CSRD group, was originally developed at the National Meteorological Center (NMC) for a CDC CYBER 205, and is described in detail in [Sela 80] and <ref> [Sela 82] </ref>. The spectral method of solving PDE's was pioneered by Orszag and Eliasen and co-workers (see [Orsz 70] and [ElMR 70]), and [Bour 74] subsquently showed how to apply it to atmospheric modeling. Only the forecast module of the NMC code is used in the benchmarking.
Reference: [SwCl 87a] <author> Swamy, K., and Clementi, E., </author> <year> 1987, </year> <title> BIOMOL AMolecular Dynamics Simulation Package for Nucleic Acid Hydration, </title> <institution> IBM Kingston Report KGN-97. </institution>
Reference-contexts: The ARC3D code was supplied to the PERFECT Club by the Cray Research group. BDNA. The BDNA code makes use of the BIOMOL package <ref> [SwCl 87a] </ref> for performing molecular dynamics simulations of biomolecules in water. This package aims at an understanding of the hydration, structure, and dynamics of nucleic acids and, more broadly, the role of water in the operation of biological systems.
Reference: [SwCl 87b] <author> Swamy, K., and Clementi, E., </author> <year> 1987, </year> <title> Hydration Structure and the Dynamics of Band Z-DNA in the Presence of Counterions via Molecular Dynamics Simulations, </title> <institution> IBM Kingston Report KGN-94. </institution>
Reference-contexts: This package aims at an understanding of the hydration, structure, and dynamics of nucleic acids and, more broadly, the role of water in the operation of biological systems. BDNA was developed by Swamy and Clementi of IBM 5 Kingston <ref> [SwCl 87b] </ref>, and is based on an earlier molecular dynamics code by Laaksonen. The Matsuoka-Clementi-Yoshimine (MCY) potential function is used to describe the water-water interaction [MaCY 76].
Reference: [UhrL 84] <author> Uhr, L., </author> <year> 1984, </year> <title> On Benchmarks: Dynamically Improving Experimental Comparisons, </title> <note> Computer Sciences Technical Report No. 571, </note> <institution> University of Wisconsin-Madison, Madison, WI. </institution>
Reference-contexts: How much of that power can be harnessed is the central theme of performance evaluation. A significant body of literature documenting the use of benchmarking as a means for evaluating supercomputer performance has developed [LuMM 85], [MWGe 82], <ref> [UhrL 84] </ref>, [DoMW 87], [NeSi 87]. Unfortunately, much of the literature focuses on ad hoc approaches to evaluation of systems rather than on potential standardization of the benchmark process [MaRi 88].
Reference: [WaDu 87] <author> Watts, J., and Dupuis, M., </author> <year> 1987, </year> <title> Towards Efficient Parallel Computation of Correlated Wave Functions. Implementation of the Two-Electron Integral Transformation on the LCAP Parallel Supercomputer, </title> <type> IBM Kingston Technical Report KGN-100. 47 </type>
References-found: 51

