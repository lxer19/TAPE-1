URL: http://graphics.lcs.mit.edu/~satyan/pubs/MIT-LCS-TM-568.ps.Z
Refering-URL: http://graphics.lcs.mit.edu/~satyan/pubs.html
Root-URL: 
Title: Acquisition of a Large Pose-Mosaic Dataset  
Author: Satyan Coorg Neel Master Seth Teller 
Note: This technical memorandum (TM) has been made available free of charge from the MIT Laboratory for Computer Science, at www.lcs.mit.edu.  
Date: January, 1998  
Affiliation: Computer Graphics Group  
Pubnum: MIT LCS TM-568  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> F. J. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Trans PAMI, </journal> <volume> 8(6) </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: 00 = x 0 z 0 4 y 0 3 2 x 1 5 = KR 0 R 1 K 1 4 y 3 the derivatives are computed as follows (the rotation-matrix derivative is given in the appendix): @v 0 = KR 0 ( @q where v = K 1 <ref> [x; y; 1] </ref> T . <p> Fortunately, as we are interested primarily in recovering accurate pose for each node, very few correspondences are necessary (five points [7] per mosaic). Thus, our system allows a user to manually correspond points computed by intersecting adjacent straight edges obtained by using the Canny edge detector <ref> [1] </ref>. The user's task is further simplified by our system, which uses the available pose information to generate matches automatically in most cases. The matching technique is described in Section 3.2, after the optimization described in Section 3.1. 3.1 Optimization Formally, the pose refinement problem is as follows.
Reference: [2] <author> R. Collins. </author> <title> A space-sweep approach to true multi-image matching. </title> <booktitle> In CVPR96, </booktitle> <pages> pages 358-363, </pages> <year> 1996. </year>
Reference-contexts: The basic idea, similar to that proposed by Collins <ref> [2] </ref>, is as follows. If any sparse set of points in a set of nodes is projected into 3-D rays, regions with high incidence of rays correspond to likely locations of 3-D features.
Reference: [3] <author> R. Collins, C. Jaynes, F. Stolle, X. Wang, Y. Cheng, A. Hanson, and E. Riseman. </author> <title> A system for automated site model acquisition. </title> <booktitle> In SPIE Proceedings Vol. </booktitle> <volume> 7617, </volume> <year> 1995. </year>
Reference-contexts: 1 Introduction Reconstruction of textured 3D CAD models representing urban environments is an important goal of computer vision systems, and more recently of computer graphics systems. Existing approaches employ semi-automatic (human-assisted) reconstruction strategies [5], or assume aerial imagery for which external camera calibration is given <ref> [3] </ref>. Developing a system that automatically performs 3-D reconstruction from high-resolution ground-based imagery will require the acquisition and management of a suitable dataset. <p> Thus, we have developed a variety of "pose-refinement" algorithms which revise the pose-estimates based on correlation and correspondence among two or more images. 1.1 Related Work Our work builds upon many fundamental techniques from photogrammetry and computer vision: * Aerial imagery <ref> [3, 4] </ref>: Photogrammetric systems that analyze aerial imagery use pose obtained by a combination of instrumentation, manual input, and "bundle-adjustment" optimization.
Reference: [4] <author> J. D. M. McKeown, C. McGlone, S. D. Cochran, Y. C. Hsieh, M. Roux, and J. Shufelt. </author> <title> Automatic cartographic feature extraction using photogrammetric principles. </title> <booktitle> In Digital Photogrammetry, </booktitle> <pages> pages 195-212. </pages> <address> ASPRS, </address> <year> 1997. </year>
Reference-contexts: Thus, we have developed a variety of "pose-refinement" algorithms which revise the pose-estimates based on correlation and correspondence among two or more images. 1.1 Related Work Our work builds upon many fundamental techniques from photogrammetry and computer vision: * Aerial imagery <ref> [3, 4] </ref>: Photogrammetric systems that analyze aerial imagery use pose obtained by a combination of instrumentation, manual input, and "bundle-adjustment" optimization.
Reference: [5] <author> P. E. Debevec, C. J. Taylor, and J. Malik. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach. </title> <booktitle> In SIGGRAPH 96 Conference Proceedings, </booktitle> <pages> pages 11-20, </pages> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Reconstruction of textured 3D CAD models representing urban environments is an important goal of computer vision systems, and more recently of computer graphics systems. Existing approaches employ semi-automatic (human-assisted) reconstruction strategies <ref> [5] </ref>, or assume aerial imagery for which external camera calibration is given [3]. Developing a system that automatically performs 3-D reconstruction from high-resolution ground-based imagery will require the acquisition and management of a suitable dataset.
Reference: [6] <author> R. </author> <title> Hartley. Self-calibration of stationary cameras. </title> <journal> IJCV, </journal> <volume> 22(1) </volume> <pages> 5-23, </pages> <year> 1997. </year>
Reference-contexts: As depth/parallax effects do not occur across images taken from a single node, a constrained 2-D projective transformation (collineation) describes the relation between any such pair of images <ref> [6] </ref>. Computing and refining the projective transformations using correlation of pixel-values is the basis of our approach to refine orientation estimates. Our approach is closely related to the mosaicing algorithm proposed by Szeliski [14] and extended to cylindrical panoramas by McMillan [8]. <p> The result of the optimization is a spherical mosaic, a composite of all images corresponding to a single node. The basis of the optimization is the 2-D projective transformation P 12 between two images (labeled 1 and 2) taken from the same camera <ref> [6] </ref>: P 12 = KR 2 R 1 which maps pixels from image 1 to pixels in image 2 by a 2-D projective transformation ( ~ = denotes projective equality): 2 4 y 2 3 2 x 1 1 5 where (x 1 ; y 1 ) and (x 2 ;
Reference: [7] <author> B. K. P. Horn. </author> <title> Relative orientation revisited. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 8(10) </volume> <pages> 1630-1638, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Initial orientation estimates for each node were obtained by manual pointing of the pan-tilt head at some other node (marked by a second tripod and orange ball). These orientation estimates are expressed and manipulated as quaternions, which possess useful stability properties for optimization <ref> [7] </ref>. 2 1.3 Overview The rest of the paper is organized as follows. Section 2 describes an automatic spherical mosaicing algorithm that accurately computes relative rotations between images taken from the same position using a quaternion-based correlation maximization algorithm. <p> Third, from a practical standpoint, it is much easier to visualize and debug (using computer graphics) algorithms operating in 3-D than algorithms that operate in projective space. For two views, registration is equivalent to computing relative orientation as in classical photogram metry <ref> [7] </ref>. While this technique performs well for pairs of images, a disadvantage of using this approach 2 Sparse matrix techniques can be used to improve the speed of the solver. <p> In addition, different nodes are acquired in very different lighting conditions, further accentuating the dissimilarity. Fortunately, as we are interested primarily in recovering accurate pose for each node, very few correspondences are necessary (five points <ref> [7] </ref> per mosaic). Thus, our system allows a user to manually correspond points computed by intersecting adjacent straight edges obtained by using the Canny edge detector [1]. The user's task is further simplified by our system, which uses the available pose information to generate matches automatically in most cases.
Reference: [8] <author> L. McMillan and G. Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In SIGGRAPH 95 Conference Proceedings, </booktitle> <pages> pages 39-46, </pages> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Computing and refining the projective transformations using correlation of pixel-values is the basis of our approach to refine orientation estimates. Our approach is closely related to the mosaicing algorithm proposed by Szeliski [14] and extended to cylindrical panoramas by McMillan <ref> [8] </ref>. Unlike McMillan [8], who computes a cylindrical panoramic image from a set of images taken with rotation around a single axis, we compute a spherical panoramic image. Szeliski & Shum in their recent papers [12, 16] also compute full-view panoramas. <p> Computing and refining the projective transformations using correlation of pixel-values is the basis of our approach to refine orientation estimates. Our approach is closely related to the mosaicing algorithm proposed by Szeliski [14] and extended to cylindrical panoramas by McMillan <ref> [8] </ref>. Unlike McMillan [8], who computes a cylindrical panoramic image from a set of images taken with rotation around a single axis, we compute a spherical panoramic image. Szeliski & Shum in their recent papers [12, 16] also compute full-view panoramas.
Reference: [9] <author> R. Mohr, F. Veillon, and L. Quan. </author> <title> Relative 3D reconstruction using multiple uncalibrated images. </title> <booktitle> In CVPR93, </booktitle> <pages> pages 543-548, </pages> <year> 1993. </year> <month> 8 </month>
Reference-contexts: The input to this stage is a set of nodes with estimated camera orientations and positions in a global coordinate system. In contrast to techniques that work in projective space (e.g., <ref> [9] </ref>), we designed our algorithm to operate in Euclidean space for the following reasons. First, this makes full use of available camera-calibration and pose information. Second, the use of the Euclidean framework decreases the complexity of the optimization by eliminating extra projective variables.
Reference: [10] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing (2nd ed.). </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year>
Reference-contexts: This function is minimized by computing derivatives with respect to the orientations and using Levenberg-Marquadt nonlinear optimization <ref> [10] </ref> starting from the initial orientations and internal parameters. The optimization involves updating these unknowns with increments computed using the gradient G and (an approximation to) the Hessian H of the objective function, until convergence is achieved. The various steps in the computation are described in greater detail below. <p> In an unconstrained optimization, the increments would be computed as H 1 G <ref> [10] </ref>.
Reference: [11] <author> S. Seitz and C. Dyer. </author> <title> Photorealistic scene reconstruction by voxel coloring. </title> <booktitle> In CVPR97, </booktitle> <pages> pages 1067-1073, </pages> <year> 1997. </year>
Reference-contexts: Second, pose information provides useful geometric constraints that can potentially aid the reconstruction process (e.g., <ref> [11] </ref>).
Reference: [12] <author> H.-Y. Shum and R. Szeliski. </author> <title> Panoramic image mosaics. </title> <type> Technical Report MSR-TR-97-23, </type> <institution> Microsoft Research, </institution> <year> 1997. </year>
Reference-contexts: Unlike McMillan [8], who computes a cylindrical panoramic image from a set of images taken with rotation around a single axis, we compute a spherical panoramic image. Szeliski & Shum in their recent papers <ref> [12, 16] </ref> also compute full-view panoramas. However, their global alignment algorithm requires a combination of both correlation-based and feature-based optimization. In contrast, we directly optimize correlation to perform global alignment, avoiding the step of identifying suitable features.
Reference: [13] <author> C. Slama. </author> <title> Manual of Photogrammetry. </title> <journal> American Society of Photogrammetry and Remote Sensing, </journal> <year> 1980. </year>
Reference-contexts: The objective function O is simply the sum of the squared magnitudes of the residual vectors: O = i=1 j=1 To perform the optimization, we use an approach similar to "bundle-adjustment" in photogrammetry <ref> [13] </ref> that alternately refines 3-D positions and pose estimates. The advantage of this method is that fixing the 3-D positions of point features decouples the optimization of the various camera poses, each of which can be independently updated (and vice-versa).
Reference: [14] <author> R. Szeliski. </author> <title> Video mosaics for virtual environments. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 16(2) </volume> <pages> 22-30, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Acquiring similar ground-based imagery poses additional challenges: to provide a large field-of-view to capture all visible features and to refine initial pose estimates to predict nearby features accurately. * Mosaicing <ref> [14, 20] </ref>: These techniques seamlessly stitch together multiple images taken from the same viewpoint. While such mosaics are typically used in virtual environments, we apply mosaicing techniques to refine our pose estimates and to provide a much larger field-of-view than would a single image. <p> Computing and refining the projective transformations using correlation of pixel-values is the basis of our approach to refine orientation estimates. Our approach is closely related to the mosaicing algorithm proposed by Szeliski <ref> [14] </ref> and extended to cylindrical panoramas by McMillan [8]. Unlike McMillan [8], who computes a cylindrical panoramic image from a set of images taken with rotation around a single axis, we compute a spherical panoramic image. Szeliski & Shum in their recent papers [12, 16] also compute full-view panoramas.
Reference: [15] <author> R. Szeliski and S. B. Kang. </author> <title> Recovering 3D shape and motion from image streams using non-linear least squares. </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> 5(1) </volume> <pages> 10-28, </pages> <year> 1994. </year>
Reference-contexts: While such mosaics are typically used in virtual environments, we apply mosaicing techniques to refine our pose estimates and to provide a much larger field-of-view than would a single image. In addition, we consider the problem of registering multiple mosaics in a global coordinate system. * Structure from Motion <ref> [15, 17, 18] </ref>: These techniques recover both scene structure and camera motion by analyzing correspondences in a closely-spaced image sequence (e.g., frames from a video sequence). While these techniques correlate nearby images in the sequence, significant analysis must be performed to relate images that are farther apart. <p> Instead, we use global opti-mization to refine pose estimates, similar to the techniques proposed in structure-from-motion <ref> [15, 17] </ref>. These approaches use correspondences (either manually specified [17] or obtained by tracking [15]) between image features to set up a global objective function, and perform an optimization using non-linear methods. <p> Instead, we use global opti-mization to refine pose estimates, similar to the techniques proposed in structure-from-motion [15, 17]. These approaches use correspondences (either manually specified [17] or obtained by tracking <ref> [15] </ref>) between image features to set up a global objective function, and perform an optimization using non-linear methods. Though the problem of automatically generating correspondences is well studied in computer vision, the process tends to be very fragile, especially across disparate images.
Reference: [16] <author> R. Szeliski and H. Shum. </author> <title> Creating full-view panoramic mosaics and texture-mapped 3D models. </title> <booktitle> In SIGGRAPH 97 Conference Proceedings, </booktitle> <pages> pages 251-258, </pages> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: Unlike McMillan [8], who computes a cylindrical panoramic image from a set of images taken with rotation around a single axis, we compute a spherical panoramic image. Szeliski & Shum in their recent papers <ref> [12, 16] </ref> also compute full-view panoramas. However, their global alignment algorithm requires a combination of both correlation-based and feature-based optimization. In contrast, we directly optimize correlation to perform global alignment, avoiding the step of identifying suitable features.
Reference: [17] <author> C. J. Taylor and D. J. Kriegman. </author> <title> Structure and motion from line segments in multiple images. </title> <journal> PAMI, </journal> <volume> 17(11) </volume> <pages> 1021-1032, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: While such mosaics are typically used in virtual environments, we apply mosaicing techniques to refine our pose estimates and to provide a much larger field-of-view than would a single image. In addition, we consider the problem of registering multiple mosaics in a global coordinate system. * Structure from Motion <ref> [15, 17, 18] </ref>: These techniques recover both scene structure and camera motion by analyzing correspondences in a closely-spaced image sequence (e.g., frames from a video sequence). While these techniques correlate nearby images in the sequence, significant analysis must be performed to relate images that are farther apart. <p> Instead, we use global opti-mization to refine pose estimates, similar to the techniques proposed in structure-from-motion <ref> [15, 17] </ref>. These approaches use correspondences (either manually specified [17] or obtained by tracking [15]) between image features to set up a global objective function, and perform an optimization using non-linear methods. <p> Instead, we use global opti-mization to refine pose estimates, similar to the techniques proposed in structure-from-motion [15, 17]. These approaches use correspondences (either manually specified <ref> [17] </ref> or obtained by tracking [15]) between image features to set up a global objective function, and perform an optimization using non-linear methods. Though the problem of automatically generating correspondences is well studied in computer vision, the process tends to be very fragile, especially across disparate images.
Reference: [18] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9 </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: While such mosaics are typically used in virtual environments, we apply mosaicing techniques to refine our pose estimates and to provide a much larger field-of-view than would a single image. In addition, we consider the problem of registering multiple mosaics in a global coordinate system. * Structure from Motion <ref> [15, 17, 18] </ref>: These techniques recover both scene structure and camera motion by analyzing correspondences in a closely-spaced image sequence (e.g., frames from a video sequence). While these techniques correlate nearby images in the sequence, significant analysis must be performed to relate images that are farther apart.
Reference: [19] <author> R. Tsai. </author> <title> A versatile camera calibration technique for high accuracy 3D machine vision metrology using off-the-shelf TV cameras and lenses. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(4), </volume> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: The approach we follow is to optimize a global correlation function defined for adjacent images with respect to all orientations (represented as quaternions). In addition, the algorithm also revises internal camera parameters (camera focal length and image center initially estimated using Tsai's calibration algorithm <ref> [19] </ref>) to maximize correlation. The result of the optimization is a spherical mosaic, a composite of all images corresponding to a single node.
Reference: [20] <author> I. Zoghiami, O. Faugeras, and R. Deriche. </author> <title> Using geometric corners to build a 2D mosaic from a set of images. </title> <booktitle> In CVPR97, </booktitle> <pages> pages 420-425, </pages> <year> 1997. </year>
Reference-contexts: Acquiring similar ground-based imagery poses additional challenges: to provide a large field-of-view to capture all visible features and to refine initial pose estimates to predict nearby features accurately. * Mosaicing <ref> [14, 20] </ref>: These techniques seamlessly stitch together multiple images taken from the same viewpoint. While such mosaics are typically used in virtual environments, we apply mosaicing techniques to refine our pose estimates and to provide a much larger field-of-view than would a single image.
References-found: 20

