URL: http://www.cis.udel.edu/~decker/courses/889a/KE-REVIEW-95.ps
Refering-URL: http://www.cis.udel.edu/~decker/courses/889a.html
Root-URL: http://www.cis.udel.edu
Email: M.Wooldridge@doc.mmu.ac.uk  N.R.Jennings@qmw.ac.uk  
Title: Intelligent Agents: Theory and Practice  
Author: Michael Wooldridge Nicholas R. Jennings 
Date: October 1994. Revised January 1995.  
Note: Submitted to Knowledge Engineering Review,  
Address: Chester Street, Manchester M1 5GD United Kingdom  Mile End Road, London E1 4NS United Kingdom  
Affiliation: Department of Computing Manchester Metropolitan University  Department of Electronic Engineering Queen Mary Westfield College  
Abstract-found: 0
Intro-found: 1
Reference: <author> Adorni, G. and Poggi, A. </author> <year> (1993). </year> <title> An object-oriented language for distributed artificial intelligence. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 38 </volume> <pages> 435-453. </pages>
Reference-contexts: Two examples are AGENTSPEAK and DAISY. AGENTSPEAK is loosely based on the PRS agent architecture, and incorporates aspects of concurrent-object technology (Weerasooriya et al., 1995). In contrast, DAISY is based on the concurrent-object language CUBL <ref> (Adorni and Poggi, 1993) </ref>, and incorporates aspects of the agent-oriented proposal (Poggi, 1995). Other languages of interest include OZ (Henz et al., 1993) and IC PROLOG II (Chu, 1993).
Reference: <author> Agha, G. </author> <year> (1986). </year> <title> ACTORS: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Agha, G., Wegner, P., and Yonezawa, A., </author> <title> editors (1993). Research Directions in Concurrent Object-Oriented Programming. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Agents in Concurrent METATEM, however, are not defined in terms of mentalistic constructs. For a discussion on the relationship between Concurrent METATEM and AGENT0-like languages, see (Fisher, 1995). 4.b Further Reading A recent collection of papers on concurrent object systems is <ref> (Agha et al., 1993) </ref>. Various languages have been proposed that marry aspects of object-based systems with aspects of Shoham's agent-oriented proposal. Two examples are AGENTSPEAK and DAISY. AGENTSPEAK is loosely based on the PRS agent architecture, and incorporates aspects of concurrent-object technology (Weerasooriya et al., 1995).
Reference: <author> Agre, P. and Chapman, D. </author> <year> (1987). </year> <title> PENGI: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence (AAAI-87), </booktitle> <pages> pages 268-272, </pages> <address> Seattle, WA. </address>
Reference-contexts: Crudely, the idea is that as most decisions are routine, they can be encoded into a low-level structure (such as a digital circuit), which only needs periodic updating, perhaps to handle new kinds of problems. His approach was illustrated with the celebrated PENGI system <ref> (Agre and Chapman, 1987) </ref>. PENGI is a simulated computer game, with the central character controlled using a scheme such as that outlined above. 28 Rosenschein and Kaelbling situated automata Another sophisticated approach is that of Rosenschein and Kaelbling (Rosenschein, 1985; Ro-senschein and Kaelbling, 1986; Kaelbling and Rosenschein, 1990; Kaelbling, 1991).
Reference: <author> Allen, J. F. </author> <year> (1984). </year> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23(2) </volume> <pages> 123-154. </pages>
Reference: <editor> Allen, J. F., Hendler, J., and Tate, A., editors (1990). </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address> <note> 44 Allen, </note> <author> J. F., Kautz, H., Pelavin, R., and Tenenberg, J. </author> <year> (1991). </year> <title> Reasoning About Plans. </title> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: For a detailed discussion of intentionality and the intentional stance, see (Dennett, 1978; Dennett, 1987). A number of papers on AI treatments of agency may be found in <ref> (Allen et al., 1990) </ref>. For an introduction to modal logic, see (Chellas, 1980); a slightly older, though more wide ranging introduction, may be found in (Hughes and Cresswell, 1968). <p> Again, introductory textbooks provide the stock criticisms and replies. There is a wealth of material on planning and planning agents. See (Georgeff, 1987) for an overview of the state of the art in planning (as it was in 1987), <ref> (Allen et al., 1990) </ref> for a thorough collection of papers on planning, (many of the papers cited above are included), and (Wilkins, 1988) for a detailed description of SIPE, a sophisticated planning system used in a real-world 35 application (the control of a brewery!) Another important collection of planning papers is
Reference: <author> Ambros-Ingerson, J. and Steel, S. </author> <year> (1988). </year> <title> Integrating planning, execution and monitoring. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> pages 83-88, </pages> <address> St. Paul, MN. </address>
Reference: <author> Austin, J. L. </author> <year> (1962). </year> <title> How to Do Things With Words. </title> <publisher> Oxford University Press: Oxford, </publisher> <address> England. </address>
Reference-contexts: He then gave examples of how these logics could be used in the specification and verification of protocols for cooperative action. 2.g Communication Formalisms for representing communication in agent theory have tended to be based on speech act theory, as originated by Austin <ref> (Austin, 1962) </ref>, and further developed by Searle (Searle, 1969) and others (Cohen and Perrault, 1979; Cohen and Levesque, 1990a). Briefly, the key axiom of speech act theory is that communicative utterances are actions, in just the sense that physical actions are.
Reference: <author> Aylett, R. and Eustace, D. </author> <year> (1994). </year> <title> Multiple cooperating robots combining planning and behaviours. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the 1993 Workshop on Cooperating Knowledge Based Systems (CKBS-93), </booktitle> <pages> pages 3-11. </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference: <author> Baecker, R. M., </author> <title> editor (1993). Readings in Groupware and Computer-Supported Cooperative Work. </title> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: There is much related work being done by the computer supported cooperative work (CSCW) community. CSCW is informally defined by Baecker to be `computer assisted coordinated activity such as problem solving and communication carried out by a group of collaborating individuals' <ref> (Baecker, 1993, p1) </ref>. The primary emphasis of CSCW is on the development of (hardware and) software tools to support collaborative human work the term groupware has been coined to describe such tools. Various authors have proposed the use of agent technology in groupware. <p> For example, in his participant systems proposal, Chang suggests systems in which humans collaborate with not only other humans, but also with artificial agents (Chang, 1987). We refer the interested reader to the collection of papers edited by Baecker <ref> (Baecker, 1993) </ref> and the article by Greif (Greif, 1994) for more details on CSCW.
Reference: <author> Barringer, H., Fisher, M., Gabbay, D., Gough, G., and Owens, R. </author> <year> (1989). </year> <title> METATEM: A framework for programming in temporal logic. </title> <booktitle> In REX Workshop on Stepwise Refinement of Distributed Systems: Models, Formalisms, Correctness (LNCS Volume 430), </booktitle> <pages> pages 94-129. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Execution of the agent program corresponds to iteratively building a logical model for the temporal agent specification. It is possible to prove that the procedure used to execute an agent specification is correct, in that if it is possible to satisfy the specification, then the agent will do so <ref> (Barringer et al., 1989) </ref>. The logical semantics of Concurrent METATEM are closely related to the semantics of temporal logic itself. This means that, amongst other things, the specification and verification 38 of Concurrent METATEM systems is a realistic proposition (Fisher and Wooldridge, 1993).
Reference: <author> Barwise, J. and Perry, J. </author> <year> (1983). </year> <title> Situations and Attitudes. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Bates, J. </author> <year> (1994). </year> <title> The role of emotion in believable agents. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 122-125. </pages>
Reference-contexts: users the experience of living in (not merely watching) dramatically rich worlds that include moderately competent, emotional agents.' (Bates et al., 1992b, p1) In order to construct such simulated worlds, one must first develop believable agents: agents that `provide the illusion of life, thus permitting the audience's suspension of disbelief' <ref> (Bates, 1994, p122) </ref>. A key component of such agents is emotion: agents should not be represented in a computer game or animated film as the flat, featureless characters that appear in current computer games. <p> They need to show emotions; to act and react in a way that resonates in tune with our empathy and understanding of human behaviour. The Oz group have investigated various architectures for emotion (Bates et al., 1992a), and have developed at least one prototype implementation of their ideas <ref> (Bates, 1994) </ref>. 6 Concluding Remarks This paper has reviewed the main concepts and issues associated with the theory and practice of intelligent agents.
Reference: <author> Bates, J., Bryan Loyall, A., and Scott Reilly, W. </author> <year> (1992a). </year> <title> An architecture for action, emotion, and social behaviour. </title> <type> Technical Report CMU-CS-92-144, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: They need to show emotions; to act and react in a way that resonates in tune with our empathy and understanding of human behaviour. The Oz group have investigated various architectures for emotion <ref> (Bates et al., 1992a) </ref>, and have developed at least one prototype implementation of their ideas (Bates, 1994). 6 Concluding Remarks This paper has reviewed the main concepts and issues associated with the theory and practice of intelligent agents.
Reference: <author> Bates, J., Bryan Loyall, A., and Scott Reilly, W. </author> <year> (1992b). </year> <title> Integrating reactivity, goals, and emotion in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: The Oz project 6 was initiated to develop: ` artistically interesting, highly interactive, simulated worlds to give users the experience of living in (not merely watching) dramatically rich worlds that include moderately competent, emotional agents.' <ref> (Bates et al., 1992b, p1) </ref> In order to construct such simulated worlds, one must first develop believable agents: agents that `provide the illusion of life, thus permitting the audience's suspension of disbelief' (Bates, 1994, p122).
Reference: <author> Bell, J. </author> <year> (1995). </year> <title> Changing attitudes. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 40-55. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference: <author> Belnap, N. </author> <year> (1991). </year> <title> Backwards and forwards in the modal logic of agency. </title> <journal> Philosophy and Phenomenological Research, LI(4):777-807. </journal>
Reference: <author> Belnap, N. and Perloff, M. </author> <year> (1988). </year> <title> Seeing to it that: a canonical form for agentives. </title> <journal> Theoria, </journal> <volume> 54 </volume> <pages> 175-199. </pages>
Reference: <editor> Bond, A. H. and Gasser, L., editors (1988). </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: We have deliberately avoided discussing what might be called the macro aspects of agent technology (i.e., those issues relating to the agent society, rather than the individual (Gasser, 1991)), as these issues are reviewed more thoroughly elsewhere (see <ref> (Bond and Gasser, 1988, pp1-56) </ref> and (Chaib-draa et al., 1992)). Thirdly, we wish to reiterate that agent technology is, at the time of writing, one of the most active areas of research in AI and computer science generally. Thus, work on agent theories, architectures, and languages is very much ongoing. <p> The classic reference to DAI is <ref> (Bond and Gasser, 1988) </ref>, which includes both a comprehensive review article and a collection of significant papers from the field; a more recent review article is (Chaib-draa et al., 1992).
Reference: <author> Bratman, M. E. </author> <year> (1987). </year> <title> Intentions, Plans, and Practical Reason. </title> <publisher> Harvard University Press: </publisher> <address> Cambridge, MA. </address>
Reference-contexts: For an introduction to temporal logics and related topics, see (Goldblatt, 1987; Emerson, 1990). A non-formal discussion of intention may be found in <ref> (Bratman, 1987) </ref>, or more briefly (Bratman, 1990). Further work on modelling intention may be found in (Grosz and Sidner, 1990; Sadek, 1992; Goldman and Lang, 1991; Konolige and Pollack, 1993; Bell, 1995; Dongha, 1995).
Reference: <author> Bratman, M. E. </author> <year> (1990). </year> <title> What is intention? In Cohen, </title> <editor> P. R., Morgan, J. L., and Pollack, M. E., editors, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 15-32. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference-contexts: This is not a desirable property: one might have a goal of going to the dentist, with the necessary consequence of suffering pain, without having a goal of suffering pain. The problem is discussed, (in the context of intentions), in <ref> (Bratman, 1990) </ref>. The basic possible worlds model has been adapted by some researchers in an attempt to overcome this problem (Wainer, 1994). <p> For an introduction to temporal logics and related topics, see (Goldblatt, 1987; Emerson, 1990). A non-formal discussion of intention may be found in (Bratman, 1987), or more briefly <ref> (Bratman, 1990) </ref>. Further work on modelling intention may be found in (Grosz and Sidner, 1990; Sadek, 1992; Goldman and Lang, 1991; Konolige and Pollack, 1993; Bell, 1995; Dongha, 1995).
Reference: <author> Bratman, M. E., Israel, D. J., and Pollack, M. E. </author> <year> (1988). </year> <title> Plans and resource-bounded practical reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 349-355. </pages>
Reference-contexts: Bratman, Israel and Pollack IRMA In section 2, we saw that some researchers have considered frameworks for agent theory based on beliefs, desires, and intentions (Rao and Georgeff, 1991b). Some researchers have also developed agent architectures based on these attitudes. One example is the Intelligent Resource-bounded Machine Architecture (IRMA) <ref> (Bratman et al., 1988) </ref>. This architecture has four key symbolic data structures: a plan library, and explicit representations of beliefs, desires, and intentions.
Reference: <author> Brooks, R. A. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1) </volume> <pages> 14-23. </pages>
Reference-contexts: In a 1985 paper, he outlined an alternative architecture for building agents, the so called subsumption architecture <ref> (Brooks, 1986) </ref>. The review of alternative approaches begins with Brooks' work. In recent papers, (Brooks, 1990; Brooks, 1991b; Brooks, 1991a), Brooks has propounded three key theses: 1. Intelligent behaviour can be generated without explicit representations of the kind that symbolic AI proposes. 27 2.
Reference: <author> Brooks, R. A. </author> <year> (1990). </year> <title> Elephants don't play chess. </title> <editor> In Maes, P., editor, </editor> <booktitle> Designing Autonomous Agents, </booktitle> <pages> pages 3-15. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Brooks, R. A. </author> <year> (1991a). </year> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pages 569-595, </pages> <address> Sydney, Australia. </address>
Reference: <author> Brooks, R. A. </author> <year> (1991b). </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159. </pages>
Reference: <author> Burmeister, B. and Sundermeyer, K. </author> <year> (1992). </year> <title> Cooperative problem solving guided by intentions and perception. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 77-92. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Bussmann, S. and Demazeau, Y. </author> <year> (1994). </year> <title> An agent model combining reactive and cognitive capabilities. </title> <booktitle> In Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS-94), </booktitle> <address> Munich, Germany. </address>
Reference: <author> Castelfranchi, C. </author> <year> (1990). </year> <title> Social power. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized AI Proceedings of the First European Workshop on Modelling Autonomous Agents in Multi-Agent Worlds (MAAMAW-89), </booktitle> <pages> pages 49-62. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Castelfranchi, C. </author> <year> (1995). </year> <title> Guarantees for autonomy in cognitive agent architecture. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 56-70. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: the most general way in which the term agent is used is to denote a hardware or (more usually) software-based computer system that enjoys the following properties: autonomy: agents operate without the direct intervention of humans or others, and have some kind of control over their actions and internal state <ref> (Castelfranchi, 1995) </ref>; social ability: agents interact with other agents (and possibly humans) via some kind of agent-communication language (Genesereth and Ketchpel, 1994); reactivity: agents perceive their environment, (which may be the physical world, a user via a graphical user interface, a collection of other agents, the INTERNET, or perhaps all of
Reference: <author> Castelfranchi, C., Miceli, M., and Cesta, A. </author> <year> (1992). </year> <title> Dependence relations among autonomous agents. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent 46 Worlds (MAAMAW-91), </booktitle> <pages> pages 215-231. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Catach, L. </author> <year> (1988). </year> <title> Normal multimodal logics. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> pages 491-495, </pages> <address> St. Paul, MN. </address>
Reference-contexts: More generally, the kinds of logics used in agent theory tend to be rather elaborate, typically containing many modalities which interact with each other in subtle ways. Very little work has yet been carried out on the theory underlying such logics (perhaps the only notable exception is <ref> (Catach, 1988) </ref>). Until the general principles and limitations of such multi-modal logics become understood, we might expect that progress with using such logics will be slow. One area in which work is likely to be done in the near future is theorem proving techniques for multi-modal logics.
Reference: <author> Chaib-draa, B., Moulin, B., Mandiau, R., and Millot, P. </author> <year> (1992). </year> <journal> Trends in distributed artificial intelligence. Artificial Intelligence Review, </journal> <volume> 6 </volume> <pages> 35-66. </pages>
Reference: <author> Chang, E. </author> <year> (1987). </year> <title> Participant systems. </title> <editor> In Huhns, M., editor, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <pages> pages 311-340. </pages> <publisher> Pitman Publishing: London and Morgan Kaufmann: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Various authors have proposed the use of agent technology in groupware. For example, in his participant systems proposal, Chang suggests systems in which humans collaborate with not only other humans, but also with artificial agents <ref> (Chang, 1987) </ref>. We refer the interested reader to the collection of papers edited by Baecker (Baecker, 1993) and the article by Greif (Greif, 1994) for more details on CSCW.
Reference: <author> Chapman, D. </author> <year> (1987). </year> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-378. </pages>
Reference-contexts: Two major innovations were hierarchical and non-linear planning (Sacerdoti, 1974; Sacerdoti, 1975). However, in the mid 1980s, Chapman established some theoretical results which indicate that even such refined techniques will ultimately turn out to be unusable in any time-constrained system <ref> (Chapman, 1987) </ref>. These results have had a profound influence 25 on subsequent AI planning research; perhaps more than any other, they have caused some researchers to question the whole symbolic AI paradigm, and have thus led to the work on alternative approaches that we discuss in section 3.b. <p> Crudely, the idea is that as most decisions are routine, they can be encoded into a low-level structure (such as a digital circuit), which only needs periodic updating, perhaps to handle new kinds of problems. His approach was illustrated with the celebrated PENGI system <ref> (Agre and Chapman, 1987) </ref>. PENGI is a simulated computer game, with the central character controlled using a scheme such as that outlined above. 28 Rosenschein and Kaelbling situated automata Another sophisticated approach is that of Rosenschein and Kaelbling (Rosenschein, 1985; Ro-senschein and Kaelbling, 1986; Kaelbling and Rosenschein, 1990; Kaelbling, 1991).
Reference: <author> Chapman, D. and Agre, P. </author> <year> (1986). </year> <title> Abstract reasoning as emergent from concrete activity. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning About Actions & Plans Proceedings of the 1986 Workshop, </booktitle> <pages> pages 411-424. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Together with his co-worker Agre, he began to explore alternatives to the AI planning paradigm <ref> (Chapman and Agre, 1986) </ref>. Agre observed that most everyday activity is `routine' in the sense that it requires little if any new abstract reasoning. Most tasks, once learned, can be accomplished in a routine way, with little variation.
Reference: <author> Chellas, B. </author> <year> (1980). </year> <title> Modal Logic: An Introduction. </title> <publisher> Cambridge University Press: </publisher> <address> Cambridge, England. </address>
Reference-contexts: Possible worlds semantics have an associated correspondence theory which makes them an attractive mathematical tool to work with <ref> (Chellas, 1980) </ref>. However, they also have many associated difficulties, notably the well-known logical omniscience problem, which implies that agents are perfect reasoners (we discuss this problem in more detail below). <p> For a detailed discussion of intentionality and the intentional stance, see (Dennett, 1978; Dennett, 1987). A number of papers on AI treatments of agency may be found in (Allen et al., 1990). For an introduction to modal logic, see <ref> (Chellas, 1980) </ref>; a slightly older, though more wide ranging introduction, may be found in (Hughes and Cresswell, 1968). As for the use of modal logics to model knowledge and belief, see (Halpern and Moses, 1992), which includes complexity results and proof procedures.
Reference: <author> Chu, D. </author> <year> (1993). </year> <title> I.C. PROLOG II: A language for implementing multi-agent systems. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the 1992 Workshop on Cooperating Knowledge Based Systems (CKBS-92), </booktitle> <pages> pages 61-74. </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference-contexts: In contrast, DAISY is based on the concurrent-object language CUBL (Adorni and Poggi, 1993), and incorporates aspects of the agent-oriented proposal (Poggi, 1995). Other languages of interest include OZ (Henz et al., 1993) and IC PROLOG II <ref> (Chu, 1993) </ref>.
Reference: <author> Cohen, P. R., Greenberg, M. L., Hart, D. M., and Howe, A. E. </author> <year> (1989). </year> <title> Trial by fire: Understanding the design requirements for agents in complex environments. </title> <journal> AI Magazine, </journal> <volume> 10(3) </volume> <pages> 32-48. </pages>
Reference-contexts: system has planning agents operating in a highly dynamic environment (a traffic simulation) (Wood, 1993); Etzioni has built `softbots' that can plan and act in a UNIX environment (Etzioni et al., 1994); and finally, Cohen's PHEONIX system includes planner-based agents that operate in the domain of simulated forest fire management <ref> (Cohen et al., 1989) </ref>. Bratman, Israel and Pollack IRMA In section 2, we saw that some researchers have considered frameworks for agent theory based on beliefs, desires, and intentions (Rao and Georgeff, 1991b). Some researchers have also developed agent architectures based on these attitudes.
Reference: <author> Cohen, P. R. and Levesque, H. J. </author> <year> (1990a). </year> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261. </pages>
Reference-contexts: Critiques of the formalism (and attempts to improve on it) may be found in (Morgenstern, 1987; Lesperance, 1989). Cohen and Levesque intention One of the best-known and most influential contributions to the area of agent theory is due to Cohen and Levesque <ref> (Cohen and Levesque, 1990a) </ref>. Their formalism was originally used to develop a theory of intention (as in `I intend to'), which the authors required as a pre-requisite for a theory of speech acts (Cohen and Levesque, 1990b). <p> Agents need not intend all the expected side effects of their intentions. Given these criteria, Cohen and Levesque adopt a two-tiered approach to the problem of formalizing intention. First, they construct a logic of rational agency, `being careful to sort out the relationships among the basic modal operators' <ref> (Cohen and Levesque, 1990a, p221) </ref>. Over this 18 framework, they introduce a number of derived constructs, which constitute a `partial theory of rational action' (Cohen and Levesque, 1990a, p221); intention is one of these constructs. The first major derived construct is the persistent goal. <p> First, they construct a logic of rational agency, `being careful to sort out the relationships among the basic modal operators' <ref> (Cohen and Levesque, 1990a, p221) </ref>. Over this 18 framework, they introduce a number of derived constructs, which constitute a `partial theory of rational action' (Cohen and Levesque, 1990a, p221); intention is one of these constructs. The first major derived construct is the persistent goal. An agent has a persistent goal of j iff: 1. It has a goal that j eventually becomes true, and believes that j is not currently true. 2. <p> Within AI, perhaps the main emphasis of subsequent work has been on attempting to develop formalisms that capture the relationship between the various elements that comprise an agent's cognitive state; the paradigm example of this work is the well-known theory of intention developed by Cohen and Levesque <ref> (Cohen and Levesque, 1990a) </ref>. Despite the very real progress that has been made, there still remain many fairly fundamental problems and issues still outstanding. On a technical level, we can identify a number of issues that remain open.
Reference: <author> Cohen, P. R. and Levesque, H. J. </author> <year> (1990b). </year> <title> Rational interaction as the basis for communication. </title> <editor> In Cohen, P. R., Morgan, J., and Pollack, M. E., editors, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 221-256. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Their formalism was originally used to develop a theory of intention (as in `I intend to'), which the authors required as a pre-requisite for a theory of speech acts <ref> (Cohen and Levesque, 1990b) </ref>.
Reference: <author> Cohen, P. R. and Perrault, C. R. </author> <year> (1979). </year> <title> Elements of a plan based theory of speech acts. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 177-212. </pages>
Reference: <author> Connah, D. and Wavish, P. </author> <year> (1990). </year> <title> An experiment in cooperation. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized AI Proceedings of the First European Workshop on Modelling Autonomous Agents in Multi-Agent Worlds (MAAMAW-89), </booktitle> <pages> pages 197-214. </pages>
Reference: <institution> Elsevier Science Publishers B.V.: </institution> <address> Amsterdam, The Netherlands. </address> <note> 47 Cutkosky, </note> <author> M. R., Engelmore, R. S., Fikes, R. E., Genesereth, M. . R., Gruber, T., Mark, W. S., Tenenbaum, J. M., and Weber, J. C. </author> <year> (1993). </year> <title> PACT: An experiment in integrating concurrent engineering systems. </title> <journal> IEEE Computer, </journal> <volume> 26(1) </volume> <pages> 28-37. </pages>
Reference: <author> Davies, N. J. </author> <year> (1993). </year> <title> Truth, Modality, and Action. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Essex, </institution> <address> Colchester, UK. </address>
Reference-contexts: However, there have been some fairly successful meta-language formalisms, including those by Konolige (Konolige, 1982), Haas (Haas, 1986), Morgenstern (Morgenstern, 1987), and Davies <ref> (Davies, 1993) </ref>.
Reference: <author> Dean, T. L. and Wellman, M. P. </author> <year> (1991). </year> <title> Planning and Control. </title> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference: <author> Dennett, D. C. </author> <year> (1978). </year> <title> Brainstorms. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Dennett, D. C. </author> <year> (1987). </year> <title> The Intentional Stance. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address> <note> des Rivieres, </note> <author> J. and Levesque, H. J. </author> <year> (1986). </year> <title> The consistency of syntactical treatments of knowledge. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 115-130. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The attitudes employed in such folk psychological descriptions are called the intentional notions. The philosopher Daniel Dennett has coined the term intentional system to describe entities `whose behaviour can be predicted by the method of attributing belief, desires and rational acumen' <ref> (Dennett, 1987, p49) </ref>. Dennett identifies different `grades' of intentional system: `A first-order intentional system has beliefs and desires (etc.) but no beliefs and desires about beliefs and desires. <p> A second-order intentional system is more sophisticated; it has beliefs and desires (and no doubt other intentional states) about beliefs and desires (and other intentional states) both those of others and its own'. <ref> (Dennett, 1987, p243) </ref> One can carry on this hierarchy of intentionality as far as required. An obvious question is whether it is legitimate or useful to attribute beliefs, desires, and so on, to artificial agents.
Reference: <author> Devlin, K. </author> <year> (1991). </year> <title> Logic and Information. </title> <publisher> Cambridge University Press: </publisher> <address> Cambridge, England. </address>
Reference: <author> Dongha, P. </author> <year> (1995). </year> <title> Toward a formal model of commitment for resource-bounded agents. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 86-101. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Ger-many. </address>
Reference-contexts: Some preliminary work in this area is (Norman and Long, 1995). Similarly, little work has yet been done into the management and scheduling of multiple, possibly conflicting goals; some preliminary work is reported in <ref> (Dongha, 1995) </ref>. Finally, we turn to the relationship between agent theories and agent architectures.
Reference: <author> Downs, J. and Reichgelt, H. </author> <year> (1991). </year> <title> Integrating classical and reactive planning within an architecture for autonomous agents. </title> <editor> In Hertzberg, J., editor, </editor> <booktitle> European Workshop on Planning (LNAI Volume 522), </booktitle> <pages> pages 13-26. </pages>
Reference: <author> Doyle, J., Shoham, Y., and Wellman, M. P. </author> <year> (1991). </year> <title> A logic of relative desire. </title> <editor> In Ras, Z. W. and Zemankova, M., editors, </editor> <booktitle> Methodologies for Intelligent Systems Sixth International Symposium, ISMIS-91 (LNAI Volume 542). </booktitle> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference: <author> Emerson, E. A. </author> <year> (1990). </year> <title> Temporal and modal logic. </title> <editor> In van Leeuwen, J., editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 996-1072. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Ams-terdam, The Netherlands. </address>
Reference-contexts: However, at the time of writing, the theoretical limitations of the approach are not well understood; there are similarities with the automatic synthesis of programs from temporal logic specifications, a complex area of much ongoing work in mainstream computer science (see the comments in <ref> (Emerson, 1990) </ref>). 29 Maes Agent Network Architecture Pattie Maes has developed an agent architecture in which an agent is defined as a set of competence modules (Maes, 1989; Maes, 1990b; Maes, 1991). These modules loosely resemble the behaviours of Brooks' subsumption architecture (above).
Reference: <author> Emerson, E. A. and Halpern, J. Y. </author> <year> (1986). </year> <title> `Sometimes' and `not never' revisited: on branching time versus linear time temporal logic. </title> <journal> Journal of the ACM, </journal> <volume> 33(1) </volume> <pages> 151-178. </pages>
Reference-contexts: In related work, Rao and Georgeff have developed a logical framework for agent theory based on three primitive modalities: beliefs, desires, and intentions (Rao and Georgeff, 1991b; Rao and Georgeff, 1991a; Rao and Georgeff, 1993). Their formalism is based on a branching model of time, (cf. <ref> (Emerson and Halpern, 1986) </ref>), in which belief-, desire- and intention-accessible worlds are themselves branching time structures. They are particularly concerned with the notion of realism the question of how an agent's beliefs about the future affect its desires and intentions. <p> Comparatively little work has yet been done on formally comparing the suitability of these various combinations. One might draw a parallel with the use of temporal logics in mainstream computer science, where the 21 expressiveness of specification languages is by now a well-understood research area <ref> (Emerson and Halpern, 1986) </ref>. Perhaps the obvious requirement for the short term is experimentation with real agent specifications, in order to gain a better understanding of the relative merits of different formalisms.
Reference: <author> Etzioni, O., Lesh, N., and Segal, R. </author> <year> (1994). </year> <title> Building softbots for UNIX. </title> <editor> In Etzioni, O., editor, </editor> <booktitle> Software Agents Papers from the 1994 Spring Symposium (Technical Report SS-94-03), </booktitle> <pages> pages 9-16. </pages> <note> AAAI Press. 48 Fagin, </note> <author> R. and Halpern, J. Y. </author> <year> (1985). </year> <title> Belief, awareness, and limited reasoning. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence (IJCAI-85), </booktitle> <pages> pages 480-490, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: A softbot's effectors are commands (e.g., UNIX shell commands such as mv or compress) meant to change the external environment's state. A softbot's sensors are commands (e.g., pwd or ls in UNIX) meant to provide information.' <ref> (Etzioni et al., 1994, p10) </ref> A Stronger Notion of Agency For some researchers particularly those working in AI the term `agent' has a stronger and more specific meaning than that sketched out above. <p> example: the Integrated Planning, Execution and Monitoring (IPEM) system is based on a sophisticated non-linear planner (Ambros-Ingerson and Steel, 1988); Wood's AUTODRIVE system has planning agents operating in a highly dynamic environment (a traffic simulation) (Wood, 1993); Etzioni has built `softbots' that can plan and act in a UNIX environment <ref> (Etzioni et al., 1994) </ref>; and finally, Cohen's PHEONIX system includes planner-based agents that operate in the domain of simulated forest fire management (Cohen et al., 1989).
Reference: <author> Fagin, R., Halpern, J. Y., and Vardi, M. Y. </author> <year> (1992). </year> <title> What can machines know? on the properties of knowledge in distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 39(2) </volume> <pages> 328-376. </pages>
Reference: <author> Ferguson, I. A. </author> <year> (1992a). </year> <title> TouringMachines: An Architecture for Dynamic, Rational, Mobile Agents. </title> <type> PhD thesis, Clare Hall, </type> <institution> University of Cambridge, UK. </institution> <note> (Also available as Technical Report No. 273, </note> <institution> University of Cambridge Computer Laboratory). </institution>
Reference-contexts: Often, the reactive component is given some kind of precedence over the deliberative one, so that it can provide a rapid response to important environmental events. This kind of structuring leads naturally to the idea of a layered architecture, of which TOURINGMACHINES <ref> (Ferguson, 1992a) </ref> and INTERRAP (Muller and Pischel, 1994) are good examples. (These architectures are described below.) In such an architecture, an agent's control subsystems are arranged into a hierarchy, with higher layers dealing with information at increasing levels of abstraction. <p> agent's activity can be situationally determined; (ii) that the agent has no global task constraints which need to be reasoned about at run time; and (iii) that the agent's goal or desire system is capable of being represented implicitly in the agent's structure according to a fixed, pre-compiled ranking scheme.' <ref> (Ferguson, 1992a, pp29-30) </ref> Hybrid architectures, such as the PRS, TOURINGMACHINES, INTERRAP, and COSY, are currently a very active area of work, and arguably have some advantages over both purely deliberative and purely reactive architectures.
Reference: <author> Ferguson, I. A. </author> <year> (1992b). </year> <title> Towards an architecture for adaptive, rational, mobile agents. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 249-262. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Neth-erlands. </address>
Reference: <author> Fikes, R. E. and Nilsson, N. </author> <year> (1971). </year> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 189-208. </pages>
Reference-contexts: Within the symbolic AI community, it has long been assumed that some form of AI planning system will be a central component of any artificial agent. Perhaps the best-known early planning system was STRIPS <ref> (Fikes and Nilsson, 1971) </ref>. This system takes a symbolic description of both the world and a desired goal state, and a set of action descriptions, which characterise the pre- and post-conditions associated with various actions. <p> This component manipulates a set of patterns of behaviour (PoB). A PoB is a structure containing a pre-condition that defines when the PoB is to be activated, various conditions that define the circumstances under which the PoB is considered to have succeeded or failed, a post-condition (a la STRIPS <ref> (Fikes and Nilsson, 1971) </ref>), and an executable body, that defines what action should be performed if the PoB is executed. (The action may be a primitive, resulting in a call on the agent's world interface, or may involve calling on a higher-level layer to generate a plan.) Above the behaviour-based component
Reference: <author> Firby, J. A. </author> <year> (1987). </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <pages> pages 202-206, </pages> <address> Milan, Italy. </address>
Reference-contexts: Another proposal for building `reactive planners' involves the use of reactive action packages <ref> (Firby, 1987) </ref>.
Reference: <author> Fischer, K., Kuhn, N., Muller, H. J., Muller, J. P., and Pischel, M. </author> <year> (1993). </year> <title> Sophisticated and distributed: The transportation domain. </title> <booktitle> In Proceedings of the Fifth European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-93), </booktitle> <address> Neuchatel, Switzerland. </address>
Reference-contexts: et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval (Mukhopadhyay et al., 1986), patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management <ref> (Fischer et al., 1993) </ref>, job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control (Mori et al., 1988).
Reference: <author> Fisher, M. </author> <year> (1994). </year> <title> A survey of Concurrent METATEM the language and its applications. </title> <editor> In Gabbay, D. M. and Ohlbach, H. J., editors, </editor> <booktitle> Temporal Logic Proceedings of the First International Conference (LNAI Volume 827), </booktitle> <pages> pages 480-505. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: The Concurrent METATEM language developed by Fisher can make a stronger claim in this respect <ref> (Fisher, 1994) </ref>. A Concurrent METATEM system contains a number of concurrently executing agents, each of which is able to communicate with its peers via asynchronous broadcast message passing. Each agent is programmed by giving it a temporal logic specification of the behaviour that it is intended the agent should exhibit.
Reference: <author> Fisher, M. </author> <year> (1995). </year> <title> Representing and executing agent-based systems. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 307-323. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Agents in Concurrent METATEM, however, are not defined in terms of mentalistic constructs. For a discussion on the relationship between Concurrent METATEM and AGENT0-like languages, see <ref> (Fisher, 1995) </ref>. 4.b Further Reading A recent collection of papers on concurrent object systems is (Agha et al., 1993). Various languages have been proposed that marry aspects of object-based systems with aspects of Shoham's agent-oriented proposal. Two examples are AGENTSPEAK and DAISY.
Reference: <author> Fisher, M. and Wooldridge, M. </author> <year> (1993). </year> <title> Specifying and verifying distributed intelligent systems. </title> <editor> In Filgueiras, M. and Damas, L., editors, </editor> <booktitle> Progress in Artificial Intelligence Sixth Portuguese Conference on Artificial Intelligence (LNAI Volume 727), </booktitle> <pages> pages 13-28. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address> <note> 49 Galliers, </note> <author> J. R. </author> <year> (1988a). </year> <title> A strategic framework for multi-agent cooperative dialogue. </title> <booktitle> In Pro--ceedings of the Eighth European Conference on Artificial Intelligence (ECAI-88), </booktitle> <pages> pages 415-420, </pages> <institution> Munich, Federal Republic of Germany. </institution>
Reference-contexts: The logical semantics of Concurrent METATEM are closely related to the semantics of temporal logic itself. This means that, amongst other things, the specification and verification 38 of Concurrent METATEM systems is a realistic proposition <ref> (Fisher and Wooldridge, 1993) </ref>. At the time of writing, only prototype implementations of the language are available; full implementations are expected soon.
Reference: <author> Galliers, J. R. </author> <year> (1988b). </year> <title> A Theoretical Framework for Computer Models of Cooperative Dialogue, Acknowledging Multi-Agent Conflict. </title> <type> PhD thesis, </type> <institution> Open University, UK. </institution>
Reference-contexts: For example: mobility is the ability of an agent to move around an electronic network (White, 1994); veracity is the assumption that an agent will not knowingly communicate false inform ation <ref> (Galliers, 1988b, pp159-164) </ref>; benevolence is the assumption that agents do not have conflicting goals, and that every agent will therefore always try to do what is asked of it (Rosenschein and Genesereth, 1985, p91); and rationality is (crudely) the assumption that an agent will act in order to achieve its goals, <p> do what is asked of it (Rosenschein and Genesereth, 1985, p91); and rationality is (crudely) the assumption that an agent will act in order to achieve its goals, and will not act in such a way as to prevent its goals being achieved at least insofar as its beliefs permit <ref> (Galliers, 1988b, pp49-54) </ref>. (A discussion of some of these notions is given below; various other attributes of agency are formally defined in (Goodwin, 1993).) 1.b The Structure of this Article Now that we have at least a preliminary understanding of what an agent is, we can embark on a more detailed
Reference: <author> Gasser, L. </author> <year> (1991). </year> <title> Social conceptions of knowledge and action: DAI foundations and open systems semantics. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 107-138. </pages>
Reference-contexts: We have deliberately avoided discussing what might be called the macro aspects of agent technology (i.e., those issues relating to the agent society, rather than the individual <ref> (Gasser, 1991) </ref>), as these issues are reviewed more thoroughly elsewhere (see (Bond and Gasser, 1988, pp1-56) and (Chaib-draa et al., 1992)). Thirdly, we wish to reiterate that agent technology is, at the time of writing, one of the most active areas of research in AI and computer science generally.
Reference: <author> Gasser, L., Braganza, C., and Hermann, N. </author> <year> (1987). </year> <title> MACE: A flexible testbed for distributed AI research. </title> <editor> In Huhns, M., editor, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <pages> pages 119-152. </pages> <publisher> Pitman Publishing: London and Morgan Kaufmann: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Bussmann and Demazeau, 1994). 4 Agent Languages As agent technology becomes more established, we might expect to see a variety of software tools become available for the design and construction of agent-based systems; the need for software support tools in this area was identified as long ago as the mid-1980s <ref> (Gasser et al., 1987) </ref>. The emergence of a number of prototypical agent languages is one sign that agent technology is becoming more widely used, and that many more agent-based applications are likely to be developed in the near future.
Reference: <author> Gasser, L. and Briot, J. P. </author> <year> (1992). </year> <booktitle> Object-based concurrent programming and DAI. In Distributed Artificial Intelligence: Theory and Praxis, </booktitle> <pages> pages 81-108. </pages> <publisher> Kluwer Academic Publishers: </publisher> <address> Boston, MA. </address>
Reference-contexts: The earliest concurrent object framework was Hewitt's Actor model (Hewitt, 1977; Agha, 1986); another well-known example is the ABCL system (Yonezawa, 1990). For a discussion on the relationship between agents and concurrent object programming, see <ref> (Gasser and Briot, 1992) </ref>. Shoham agent-oriented programming Yoav Shoham has proposed a `new programming paradigm, based on a societal view of computation' (Shoham, 1990, p4),(Shoham, 1993).
Reference: <author> Geissler, C. and Konolige, K. </author> <year> (1986). </year> <title> A resolution method for quantified modal logics of knowledge and belief. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 309-324. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Konolige went on to examine the properties of the deduction model at some length, and developed a variety of proof methods for his logics, including resolution and tableau systems <ref> (Geissler and Konolige, 1986) </ref>. The deduction model is undoubtedly simple; however, as a direct model of the belief systems of AI agents, it has much to commend it. Meta-languages and syntactic modalities A meta-language is one in which it is possible to represent the properties of another language.
Reference: <author> Genesereth, M. R. and Ketchpel, S. P. </author> <year> (1994). </year> <title> Software agents. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 48-53. </pages>
Reference-contexts: usually) software-based computer system that enjoys the following properties: autonomy: agents operate without the direct intervention of humans or others, and have some kind of control over their actions and internal state (Castelfranchi, 1995); social ability: agents interact with other agents (and possibly humans) via some kind of agent-communication language <ref> (Genesereth and Ketchpel, 1994) </ref>; reactivity: agents perceive their environment, (which may be the physical world, a user via a graphical user interface, a collection of other agents, the INTERNET, or perhaps all of these combined), and respond in a timely fashion to changes that occur in it; 1 At the thirteenth <p> While agents can be as simple as subroutines, typically they are larger entities with some sort of persistent control.' <ref> (Genesereth and Ketchpel, 1994, p48) </ref> A softbot (software robot) is a kind of agent: `A softbot is an agent that interacts with a software environment by issuing commands and interpreting the environment's feedback. <p> Although not directly based on work in speech acts, (and arguably more to do with architectures than theories), we shall here mention work on agent communication languages <ref> (Genesereth and Ketchpel, 1994) </ref>. The best known work on agent communication languages is that by the ARPA knowledge sharing effort (Patil et al., 1992). This work has been largely devoted to developing two related languages: the knowledge query and manipulation language (KQML) and the knowledge interchange format (KIF).
Reference: <author> Genesereth, M. R. and Nilsson, N. </author> <year> (1987). </year> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The next step is to investigate methods for representing and reasoning about intentional notions. 2.b Representing Intentional Notions Suppose one wishes to reason about intentional notions in a logical framework. Consider the following statement (after <ref> (Genesereth and Nilsson, 1987, pp210-211) </ref>): Janine believes Cronos is the father of Zeus. (1) A naive attempt to translate (1) into first-order logic might result in the following: Bel (Janine, Father (Zeus, Cronos)) (2) Unfortunately, this naive translation does not work, for two reasons. <p> It is a short step from the notion of a physical symbol system to McCarthy's dream of a sentential processing automaton, or deliberative agent. (The term `deliberative agent' seems to have derived from Genesereth's use of the term `deliberate agent' to mean a specific type of symbolic architecture <ref> (Genesereth and Nilsson, 1987, pp325-327) </ref>.) We define a deliberative agent or agent architecture to be one that contains an explicitly represented, symbolic model of the world, and in which decisions (for example about what actions to perform) are made via logical (or at least pseudo-logical) reasoning, based on pattern matching and
Reference: <author> Georgeff, M. P. </author> <year> (1987). </year> <title> Planning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 2 </volume> <pages> 359-400. </pages>
Reference-contexts: A key problem in such architectures is what kind control framework to embed the agent's subsystems in, to manage the interactions 30 between the various layers. Georgeff and Lansky PRS One of the best-known agent architectures is the Procedural Reasoning System (PRS), developed by Georgeff and Lansky <ref> (Georgeff and Lansky, 1987) </ref>. Like IRMA, (see above), the PRS is a belief-desire-intention architecture, which includes a plan library, as well as explicit symbolic representations of beliefs, desires, and intentions. Beliefs are facts, either about the external world or the system's internal state. <p> There are many objections to the symbolic AI paradigm, in addition to those we have outlined above. Again, introductory textbooks provide the stock criticisms and replies. There is a wealth of material on planning and planning agents. See <ref> (Georgeff, 1987) </ref> for an overview of the state of the art in planning (as it was in 1987), (Allen et al., 1990) for a thorough collection of papers on planning, (many of the papers cited above are included), and (Wilkins, 1988) for a detailed description of SIPE, a sophisticated planning system
Reference: <author> Georgeff, M. P. and Ingrand, F. F. </author> <year> (1989). </year> <title> Decision-making in an embedded reasoning system. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 972-978, </pages> <address> Detroit, MI. </address>
Reference-contexts: These various data structures are manipulated by a system interpreter, which is responsible for updating beliefs, invoking KAs, and executing actions. The PRS has been evaluated in a simulation of maintenance procedures for the space shuttle, as well as other domains <ref> (Georgeff and Ingrand, 1989) </ref>. Ferguson TOURINGMACHINES For his 1992 Doctoral thesis, Ferguson developed the TOURINGMACHINES hybrid agent architecture (Ferguson, 1992b; Ferguson, 1992a) 5 .
Reference: <author> Georgeff, M. P. and Lansky, A. L., </author> <title> editors (1986). </title> <booktitle> Reasoning About Actions & Plans Proceedings of the 1986 Workshop. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: et al., 1990) for a thorough collection of papers on planning, (many of the papers cited above are included), and (Wilkins, 1988) for a detailed description of SIPE, a sophisticated planning system used in a real-world 35 application (the control of a brewery!) Another important collection of planning papers is <ref> (Georgeff and Lansky, 1986) </ref>. The book by Dean and Wellman and the book by Allen et al. contain much useful related material (Dean and Wellman, 1991; Allen et al., 1991). There is now a regular international conference on planning; the proceedings of the first were published as (Hendler, 1992).
Reference: <author> Georgeff, M. P. and Lansky, A. L. </author> <year> (1987). </year> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence (AAAI-87), </booktitle> <pages> pages 677-682, </pages> <address> Seattle, WA. </address>
Reference-contexts: A key problem in such architectures is what kind control framework to embed the agent's subsystems in, to manage the interactions 30 between the various layers. Georgeff and Lansky PRS One of the best-known agent architectures is the Procedural Reasoning System (PRS), developed by Georgeff and Lansky <ref> (Georgeff and Lansky, 1987) </ref>. Like IRMA, (see above), the PRS is a belief-desire-intention architecture, which includes a plan library, as well as explicit symbolic representations of beliefs, desires, and intentions. Beliefs are facts, either about the external world or the system's internal state. <p> There are many objections to the symbolic AI paradigm, in addition to those we have outlined above. Again, introductory textbooks provide the stock criticisms and replies. There is a wealth of material on planning and planning agents. See <ref> (Georgeff, 1987) </ref> for an overview of the state of the art in planning (as it was in 1987), (Allen et al., 1990) for a thorough collection of papers on planning, (many of the papers cited above are included), and (Wilkins, 1988) for a detailed description of SIPE, a sophisticated planning system
Reference: <author> Ginsberg, M. </author> <year> (1993). </year> <booktitle> Essentials of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address> <note> 50 Gmytrasiewicz, </note> <author> P. and Durfee, E. H. </author> <year> (1993). </year> <title> Elements of a utilitarian theory of knowledge and action. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 396-402, </pages> <address> Chambery, France. </address>
Reference-contexts: This is likely to make it difficult to generalise and reproduce results in varying domains. 3.e Further Reading Most introductory textbooks on AI discuss the physical symbol system hypothesis; a good recent example of such a text is <ref> (Ginsberg, 1993) </ref>. A detailed discussion of the way that this hypothesis has affected thinking in symbolic AI is provided in (Shardlow, 1990). There are many objections to the symbolic AI paradigm, in addition to those we have outlined above. Again, introductory textbooks provide the stock criticisms and replies.
Reference: <author> Goldblatt, R. </author> <year> (1987). </year> <title> Logics of Time and Computation. </title> <booktitle> Centre for the Study of Language and Information Lecture Notes Series. </booktitle> <publisher> (Distributed by Chicago University Press). </publisher>
Reference: <author> Goldman, R. P. and Lang, R. R. </author> <year> (1991). </year> <title> Intentions in time. </title> <type> Technical Report TUTR 93-101, </type> <institution> Tulane University. </institution>
Reference: <author> Goodwin, R. </author> <year> (1993). </year> <title> Formalizing properties of agents. </title> <type> Technical Report CMU-CS-93-159, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: in order to achieve its goals, and will not act in such a way as to prevent its goals being achieved at least insofar as its beliefs permit (Galliers, 1988b, pp49-54). (A discussion of some of these notions is given below; various other attributes of agency are formally defined in <ref> (Goodwin, 1993) </ref>.) 1.b The Structure of this Article Now that we have at least a preliminary understanding of what an agent is, we can embark on a more detailed look at their properties, and how we might go about constructing them.
Reference: <author> Greif, I. </author> <year> (1994). </year> <title> Desktop agents in group-enabled products. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 100-105. </pages>
Reference-contexts: For example, in his participant systems proposal, Chang suggests systems in which humans collaborate with not only other humans, but also with artificial agents (Chang, 1987). We refer the interested reader to the collection of papers edited by Baecker (Baecker, 1993) and the article by Greif <ref> (Greif, 1994) </ref> for more details on CSCW.
Reference: <author> Grosz, B. J. and Sidner, C. L. </author> <year> (1990). </year> <title> Plans for discourse. </title> <editor> In Cohen, P. R., Morgan, J., and Pollack, M. E., editors, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 417-444. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Gruber, T. R. </author> <year> (1991). </year> <title> The role of common ontology in achieving sharable, reusable knowledge bases. </title> <editor> In Fikes, R. and Sandewall, E., editors, </editor> <booktitle> Proceedings of Knowledge Representation and Reasoning (KR&R-91). </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference: <author> Guha, R. V. and Lenat, D. B. </author> <year> (1994). </year> <title> Enabling agents to work together. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 127-142. </pages>
Reference-contexts: Despite the immense volume of work that these problems have generated, most researchers would accept that neither is anywhere near solved. Even seemingly trivial problems, such as commonsense reasoning, have turned out to be extremely difficult (cf. the CYC project <ref> (Guha and Lenat, 1994) </ref>).
Reference: <author> Haas, A. </author> <year> (1986). </year> <title> A syntactic theory of belief and knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28(3) </volume> <pages> 245-292. </pages>
Reference-contexts: Unfortunately, meta-language formalisms have their own package of problems, not the least of which is that they tend to fall prey to inconsistency (Montague, 1963; Thomason, 1980). However, there have been some fairly successful meta-language formalisms, including those by Konolige (Konolige, 1982), Haas <ref> (Haas, 1986) </ref>, Morgenstern (Morgenstern, 1987), and Davies (Davies, 1993).
Reference: <author> Haddadi, A. </author> <year> (1994). </year> <title> A hybrid architecture for multi-agent systems. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the 1993 Workshop on Cooperating Knowledge Based Systems (CKBS-93), </booktitle> <pages> pages 13-26, </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference-contexts: Of the remaining two components, the intention component contains `long-term goals, attitudes, responsibilities and the like the control elements taking part in the reasoning and decision-making of the cognition component' <ref> (Haddadi, 1994, p15) </ref>, and the cognition component is responsible for mediating between the intentions of the agent and its beliefs about the world, and choosing an appropriate action to perform.
Reference: <author> Halpern, J. Y. </author> <year> (1986). </year> <title> Reasoning about knowledge: An overview. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 1-18. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In related work, Rao and Georgeff have developed a logical framework for agent theory based on three primitive modalities: beliefs, desires, and intentions (Rao and Georgeff, 1991b; Rao and Georgeff, 1991a; Rao and Georgeff, 1993). Their formalism is based on a branching model of time, (cf. <ref> (Emerson and Halpern, 1986) </ref>), in which belief-, desire- and intention-accessible worlds are themselves branching time structures. They are particularly concerned with the notion of realism the question of how an agent's beliefs about the future affect its desires and intentions. <p> Comparatively little work has yet been done on formally comparing the suitability of these various combinations. One might draw a parallel with the use of temporal logics in mainstream computer science, where the 21 expressiveness of specification languages is by now a well-understood research area <ref> (Emerson and Halpern, 1986) </ref>. Perhaps the obvious requirement for the short term is experimentation with real agent specifications, in order to gain a better understanding of the relative merits of different formalisms.
Reference: <author> Halpern, J. Y. </author> <year> (1987). </year> <title> Using reasoning about knowledge to analyze distributed systems. </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 2 </volume> <pages> 37-68. </pages>
Reference-contexts: See (Hughes and Cresswell, 1968, pp351-352) for a comparison and discussion of the two techniques. 4 This example was adapted from <ref> (Halpern, 1987) </ref>. 12 it has two advantages. First, it remains neutral on the subject of the cognitive structure of agents. It certainly doesn't posit any internalized collection of possible worlds. It is just a convenient way of characterizing belief.
Reference: <author> Halpern, J. Y. and Moses, Y. </author> <year> (1992). </year> <title> A guide to completeness and complexity for modal logics of knowledge and belief. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 319-379. </pages> <note> 51 Halpern, </note> <author> J. Y. and Vardi, M. Y. </author> <year> (1989). </year> <title> The complexity of reasoning about knowledge and time. I. Lower bounds. </title> <journal> Journal of Computer and System Sciences, </journal> 38:195-237. 
Reference-contexts: For an introduction to modal logic, see (Chellas, 1980); a slightly older, though more wide ranging introduction, may be found in (Hughes and Cresswell, 1968). As for the use of modal logics to model knowledge and belief, see <ref> (Halpern and Moses, 1992) </ref>, which includes complexity results and proof procedures. Related work on modelling knowledge has been done by the distributed systems community, who give the worlds in possible worlds semantics a precise interpretation; for an introduction and further references, see (Halpern, 1987; Fagin et al., 1992).
Reference: <author> Harel, D. </author> <year> (1984). </year> <title> Dynamic logic. </title> <editor> In Gabbay, D. and Guenther, F., editors, </editor> <booktitle> Handbook of Philosophical Logic Volume II Extensions of Classical Logic, </booktitle> <pages> pages 497-604. </pages> <address> D. </address> <publisher> Reidel Publishing Company: </publisher> <address> Dordrecht, The Netherlands. (Synthese library Volume 164). </address>
Reference-contexts: He formalised a model of ability in a logic containing a modality for knowledge, and a dynamic logic-like apparatus for modelling action (cf. <ref> (Harel, 1984) </ref>). This formalism allowed for the possibility of an agent having incomplete information about how to achieve some goal, and performing actions in order to find out how to achieve it. Critiques of the formalism (and attempts to improve on it) may be found in (Morgenstern, 1987; Lesperance, 1989). <p> Good starting points for AI treatments of action are (Allen, 1984; Allen et al., 1990; Allen et al., 1991). Other treatments of action in agent logics are based on formalisms borrowed from mainstream computer science, notably dynamic logic (originally developed to reason about computer programs) <ref> (Harel, 1984) </ref>.
Reference: <author> Haugeneder, H. </author> <year> (1994). </year> <note> IMAGINE final project report. </note>
Reference-contexts: At the time of writing, only prototype implementations of the language are available; full implementations are expected soon. The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL <ref> (Haugeneder et al., 1994) </ref> are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE (Haugeneder, 1994). The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL (Haugeneder et al., 1994) are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE <ref> (Haugeneder, 1994) </ref>. The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> In contrast, the MAIL language provides a rich collection of pre-defined abstractions, including plans and multi-agent plans. APRIL was originally envisaged as the implementation language for MAIL. The MAIL system has been used to implement several prototype multi-agent systems, including an urban traffic management scenario <ref> (Haugeneder and Steiner, 1994) </ref>. General Magic, Inc. TELESCRIPT TELESCRIPT is a language-based environment for constructing agent societies that has been developed by General Magic, Inc.: it is perhaps the first commercial agent language.
Reference: <author> Haugeneder, H. and Steiner, D. </author> <year> (1994). </year> <title> A multi-agent approach to cooperation in urban traffic. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the 1993 Workshop on Cooperating Knowledge Based Systems (CKBS-93), </booktitle> <pages> pages 83-98. </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference-contexts: At the time of writing, only prototype implementations of the language are available; full implementations are expected soon. The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL <ref> (Haugeneder et al., 1994) </ref> are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE (Haugeneder, 1994). The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL (Haugeneder et al., 1994) are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE <ref> (Haugeneder, 1994) </ref>. The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> In contrast, the MAIL language provides a rich collection of pre-defined abstractions, including plans and multi-agent plans. APRIL was originally envisaged as the implementation language for MAIL. The MAIL system has been used to implement several prototype multi-agent systems, including an urban traffic management scenario <ref> (Haugeneder and Steiner, 1994) </ref>. General Magic, Inc. TELESCRIPT TELESCRIPT is a language-based environment for constructing agent societies that has been developed by General Magic, Inc.: it is perhaps the first commercial agent language.
Reference: <author> Haugeneder, H., Steiner, D., and M c Cabe, F. G. </author> <year> (1994). </year> <title> IMAGINE: A framework for building multi-agent systems. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the 1994 International Working Conference on Cooperating Knowledge Based Systems (CKBS-94), </booktitle> <pages> pages 31-64, </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference-contexts: At the time of writing, only prototype implementations of the language are available; full implementations are expected soon. The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL <ref> (Haugeneder et al., 1994) </ref> are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE (Haugeneder, 1994). The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> The IMAGINE Project APRIL and MAIL APRIL (M c Cabe and Clark, 1995) and MAIL (Haugeneder et al., 1994) are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE <ref> (Haugeneder, 1994) </ref>. The two languages are intended to fulfill quite different roles. APRIL was designed to provide the core features required to realise most agent architectures and systems. <p> In contrast, the MAIL language provides a rich collection of pre-defined abstractions, including plans and multi-agent plans. APRIL was originally envisaged as the implementation language for MAIL. The MAIL system has been used to implement several prototype multi-agent systems, including an urban traffic management scenario <ref> (Haugeneder and Steiner, 1994) </ref>. General Magic, Inc. TELESCRIPT TELESCRIPT is a language-based environment for constructing agent societies that has been developed by General Magic, Inc.: it is perhaps the first commercial agent language.
Reference: <author> Hayes-Roth, B. </author> <year> (1990). </year> <title> Architectural foundations for real-time performance in intelligent agents. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 2 </volume> <pages> 99-125. </pages>
Reference: <editor> Hendler, J., editor (1992). </editor> <booktitle> Artificial Intelligence Planning: Proceedings of the First International Conference. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The book by Dean and Wellman and the book by Allen et al. contain much useful related material (Dean and Wellman, 1991; Allen et al., 1991). There is now a regular international conference on planning; the proceedings of the first were published as <ref> (Hendler, 1992) </ref>. The collection of papers edited by Maes (Maes, 1990a) contains many interesting papers on alternatives to the symbolic AI paradigm. Kaelbling (Kaelbling, 1986) presents a clear discussion of the issues associated with developing resource-bounded rational agents, and proposes an agent architecture somewhat similar to that developed by Brooks.
Reference: <author> Henz, M., Smolka, G., and Wuertz, J. </author> <year> (1993). </year> <title> Oz a programming language for multi-agent systems. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 404-409, </pages> <address> Chambery, France. </address>
Reference-contexts: AGENTSPEAK is loosely based on the PRS agent architecture, and incorporates aspects of concurrent-object technology (Weerasooriya et al., 1995). In contrast, DAISY is based on the concurrent-object language CUBL (Adorni and Poggi, 1993), and incorporates aspects of the agent-oriented proposal (Poggi, 1995). Other languages of interest include OZ <ref> (Henz et al., 1993) </ref> and IC PROLOG II (Chu, 1993). <p> It has drawn together a very wide range of material, and has hopefully 6 Not to be confused with the OZ programming language <ref> (Henz et al., 1993) </ref>. 43 provided an insight into what an agent is, how the notion of an agent can be formalised, how appropriate agent architectures can be designed and implemented, how agents can be programmed, and the types of applications for which agent-based solutions have been proposed.
Reference: <author> Hewitt, C. </author> <year> (1977). </year> <title> Viewing control structures as patterns of passing messages. </title> <journal> Artificial Intelligence, </journal> <volume> 8(3) </volume> <pages> 323-364. </pages>
Reference: <author> Hintikka, J. </author> <year> (1962). </year> <title> Knowledge and Belief. </title> <publisher> Cornell University Press: </publisher> <address> Ithaca, NY. </address>
Reference-contexts: We begin with a close look at the basic possible worlds model for logics of knowledge (epistemic logics) and logics of belief (doxastic logics). 2.c Possible Worlds Semantics The possible worlds model for logics of knowledge and belief was originally proposed by Hintikka <ref> (Hintikka, 1962) </ref>, and is now most commonly formulated in a normal modal logic using the techniques developed by Kripke (Kripke, 1963) 3 . Hintikka's insight was to see that an agent's beliefs could be characterized as a set of possible worlds, in the following way. <p> KIF provides a syntax for message content KIF is essentially the first-order predicate calculus, recast in a LISP-like syntax. 2.h Discussion Formalisms for reasoning about agents have come a long way since Hintikka's pioneering work on logics of knowledge and belief <ref> (Hintikka, 1962) </ref>.
Reference: <author> Houlder, V. </author> <year> (1994). </year> <title> Special agents. In Financial Times, </title> <month> 15 August </month> <year> 1994, </year> <pages> page 12. </pages>
Reference-contexts: A British national daily paper recently predicted that: 3 `Agent-based computing (ABC) is likely to be the next significant breakthrough in software development.' (Sargent, 1992) Moreover, the UK-based consultancy firm Ovum has predicted that the agent technology industry would be worth some US$3.5 billion worldwide by the year 2000 <ref> (Houlder, 1994) </ref>.
Reference: <author> Huang, J., Jennings, N. R., and Fox, J. </author> <year> (1995). </year> <title> An agent architecture for distributed medical care. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 219-232. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: DAI researchers have applied agent technology in a variety of areas. Example applications include power systems management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval (Mukhopadhyay et al., 1986), patient care <ref> (Huang et al., 1995) </ref>, telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control (Mori et al., 1988).
Reference: <author> Hughes, G. E. and Cresswell, M. J. </author> <year> (1968). </year> <title> Introduction to Modal Logic. </title> <publisher> Methuen and Co., </publisher> <address> Ltd. </address> <note> 52 Huhns, </note> <author> M. N., Jacobs, N., Ksiezyk, T., Shen, W. M., Singh, M. P., and Cannata, P. E. </author> <year> (1992). </year> <title> Integrating enterprise information models in Carnot. </title> <booktitle> In Proceedings of the International Conference on Intelligent and Cooperative Information Systems, </booktitle> <pages> pages 32-42, </pages> <address> Rotterdam, The Netherlands. </address>
Reference-contexts: On a first reading, this seems a peculiarly roundabout way of characterizing belief, but 3 In Hintikka's original work, he used a technique based on `model sets', which is equivalent to Kripke's formalism, though less elegant. See <ref> (Hughes and Cresswell, 1968, pp351-352) </ref> for a comparison and discussion of the two techniques. 4 This example was adapted from (Halpern, 1987). 12 it has two advantages. First, it remains neutral on the subject of the cognitive structure of agents. It certainly doesn't posit any internalized collection of possible worlds. <p> A number of papers on AI treatments of agency may be found in (Allen et al., 1990). For an introduction to modal logic, see (Chellas, 1980); a slightly older, though more wide ranging introduction, may be found in <ref> (Hughes and Cresswell, 1968) </ref>. As for the use of modal logics to model knowledge and belief, see (Halpern and Moses, 1992), which includes complexity results and proof procedures.
Reference: <author> Israel, D. J. </author> <year> (1993). </year> <title> The role(s) of logic in artificial intelligence. </title> <editor> In Gabbay, D. M., Hogger, C. J., and Robinson, J. A., editors, </editor> <booktitle> Handbook of Logic in Artificial Intelligence and Logic Programming, </booktitle> <pages> pages 1-29. </pages> <publisher> Oxford University Press: Oxford, </publisher> <address> England. </address>
Reference-contexts: What is clear is that it is important to be precise about the role one expects an agent theory to play. 2.i Further Reading For a recent discussion on the role of logic and agency, which lays out in more detail some contrasting views on the subject, see <ref> (Israel, 1993, pp17-24) </ref>. For a detailed discussion of intentionality and the intentional stance, see (Dennett, 1978; Dennett, 1987). A number of papers on AI treatments of agency may be found in (Allen et al., 1990).
Reference: <author> Jennings, N. R. </author> <year> (1992). </year> <title> On being responsible. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 93-102. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: The cooperation layer is composed of three generic modules: a control module which interfaces to the domain level system, a situation assessment module and a cooperation module. The assessment and cooperation modules provide an implementation of a model of joint responsibility <ref> (Jennings, 1992) </ref>, which specifies how agents should act both locally and towards other agents whilst engaged in cooperative problem solving.
Reference: <author> Jennings, N. R. </author> <year> (1993a). </year> <title> Commitments and conventions: The foundation of coordination in multi-agent systems. </title> <journal> Knowledge Engineering Review, </journal> <volume> 8(3) </volume> <pages> 223-250. </pages>
Reference: <author> Jennings, N. R. </author> <year> (1993b). </year> <title> Specification and implementation of a belief desire joint-intention architecture for collaborative problem solving. </title> <journal> Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 2(3) </volume> <pages> 289-318. </pages>
Reference-contexts: The agent has a 26 limited episodic memory, and using this, is able to answer questions about its past experiences. Jennings GRATE* GRATE* is a layered architecture in which the behaviour of an agent is guided by the mental attitudes of beliefs, desires, intentions and joint intentions <ref> (Jennings, 1993b) </ref>. Agents are divided into two distinct parts: a domain level system and a cooperation and control layer. The former solves problems for the organisation; be it in the domain of industrial control, finance or transportation. <p> Perhaps most importantly, many symbolic AI techniques (such as rule-based systems) carry with them an associated technology and methodology that is becoming familiar to mainstream computer scientists and software engineers. Despite the well-documented problems with symbolic AI systems, this makes symbolic AI agents (such as GRATE* <ref> (Jennings, 1993b) </ref>) an attractive proposition when compared to reactive systems, which have as yet no associated methodology. The need for a development methodology seems to be one of the most pressing requirements for reactive systems.
Reference: <author> Jennings, N. R. </author> <year> (1995). </year> <title> Controlling cooperative problem solving in industrial multi-agent systems using joint intentions. </title> <journal> Artificial Intelligence, </journal> <note> 74(2). (To appear). </note>
Reference-contexts: The performance of a GRATE* community has been evaluated against agents which only have individual intentions, and agents which behave in a selfish manner, in the domain of electricity transportation management. A significant improvement was noted when the situation became complex and dynamic <ref> (Jennings, 1995) </ref>. 3.b Alternative Approaches: Reactive Architectures As we observed above, there are many unsolved (some would say insoluble) problems associated with symbolic AI. These problems have led some researchers to question the viability of the whole paradigm, and to the development of what are generally know as reactive architectures.
Reference: <author> Jennings, N. R., Varga, L. Z., Aarnts, R. P., Fuchs, J., and Skarek, P. </author> <year> (1993). </year> <title> Transforming standalone expert systems into a community of cooperating agents. </title> <journal> International Journal of Engineering Applications of Artificial Intelligence, </journal> <volume> 6(4) </volume> <pages> 317-331. </pages>
Reference-contexts: DAI researchers have applied agent technology in a variety of areas. Example applications include power systems management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control <ref> (Jennings et al., 1993) </ref>, intelligent document retrieval (Mukhopadhyay et al., 1986), patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling
Reference: <author> Kaelbling, L. P. </author> <year> (1986). </year> <title> An architecture for intelligent reactive systems. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning About Actions & Plans Proceedings of the 1986 Workshop, </booktitle> <pages> pages 395-410. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In his doctoral thesis, Seel showed that even very simple, automata-like objects can be consistently ascribed intentional descriptions (Seel, 1989); similar work by Rosenschein and Kaelbling, (albeit with a different motivation), arrived at a similar conclusion <ref> (Rosenschein and Kaelbling, 1986) </ref>. <p> There is now a regular international conference on planning; the proceedings of the first were published as (Hendler, 1992). The collection of papers edited by Maes (Maes, 1990a) contains many interesting papers on alternatives to the symbolic AI paradigm. Kaelbling <ref> (Kaelbling, 1986) </ref> presents a clear discussion of the issues associated with developing resource-bounded rational agents, and proposes an agent architecture somewhat similar to that developed by Brooks. A proposal by Nilsson for teleo reactive programs goal directed programs that nevertheless respond to their environment is described in (Nilsson, 1992). <p> the time of writing, Shoham has only published results on the first two components. (In (Shoham, 1990, p12) he wrote that `the third is still somewhat mysterious to me', though later in the paper he indicated that he was thinking along the lines of Rosenschein and Kaelbling's situated automata paradigm <ref> (Rosenschein and Kaelbling, 1986) </ref>.) Shoham's first attempt at an AOP language was the AGENT0 system. The logical component of this system is a quantified multi-modal logic, allowing direct reference to time. No semantics are given, but the logic appears to be based on (Thomas et al., 1991).
Reference: <author> Kaelbling, L. P. </author> <year> (1991). </year> <title> A situated automata approach to the design of embedded agents. </title> <journal> SIGART Bulletin, </journal> <volume> 2(4) </volume> <pages> 85-88. </pages>
Reference-contexts: A more abstract view of an architecture is as a general methodology for designing particular modular decompositions for particular tasks.' <ref> (Kaelbling, 1991, p86) </ref> The classical approach to building agents is to view them as a particular type of knowledge-based system. <p> The programmer then specifies the desired semantics for the output (if this bit is on, the ground is wet), and the compiler [synthesises] a circuit whose output will have the correct semantics. All that declarative knowledge has been reduced to a very simple circuit. <ref> (Kaelbling, 1991, p86) </ref> The GAPPS program takes as its input a set of goal reduction rules, (essentially rules that encode information about how goals can be achieved), and a top level goal, and generates a program that can be translated into a digital circuit in order to realise the goal.
Reference: <author> Kaelbling, L. P. and Rosenschein, S. J. </author> <year> (1990). </year> <title> Action and planning in embedded agents. </title> <editor> In Maes, P., editor, </editor> <booktitle> Designing Autonomous Agents, </booktitle> <pages> pages 35-48. </pages> <publisher> The MIT Press: </publisher> <address> Cam-bridge, MA. </address>
Reference-contexts: terms of the states of an automaton: `[An agent] x is said to carry the information that p in world state s, written s |= K (x, p), if for all world states in which x has the same value as it does in s, the proposition p is true.' <ref> (Kaelbling and Rosenschein, 1990, p36) </ref> An agent is specified in terms of two components: perception and action. Two programs are then used to synthesise agents: RULER is used to specify the perception component of an agent; GAPPS is used to specify the action component.
Reference: <author> Kinny, D., Ljungberg, M., Rao, A. S., Sonenberg, E., Tidhar, G., and Werner, E. </author> <year> (1992). </year> <title> Planned team activity. </title> <editor> In Castelfranchi, C. and Werner, E., editors, </editor> <booktitle> Artificial Social Systems Selected Papers from the Fourth European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds, </booktitle> <volume> MAAMAW-92 (LNAI Volume 830), </volume> <pages> pages 226-256. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address> <note> 53 Kiss, </note> <author> G. and Reichgelt, H. </author> <year> (1992). </year> <title> Towards a semantics of desires. </title> <editor> In Werner, E. and De--mazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 115-128. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Konolige, K. </author> <year> (1982). </year> <title> A first-order formalization of knowledge and action for a multi-agent planning system. </title> <editor> In Hayes, J. E., Michie, D., and Pao, Y., editors, </editor> <booktitle> Machine Intelligence 10, </booktitle> <pages> pages 41-72. </pages> <publisher> Ellis Horwood: </publisher> <address> Chichester, England. </address>
Reference-contexts: Unfortunately, meta-language formalisms have their own package of problems, not the least of which is that they tend to fall prey to inconsistency (Montague, 1963; Thomason, 1980). However, there have been some fairly successful meta-language formalisms, including those by Konolige <ref> (Konolige, 1982) </ref>, Haas (Haas, 1986), Morgenstern (Morgenstern, 1987), and Davies (Davies, 1993).
Reference: <author> Konolige, K. </author> <year> (1986a). </year> <title> A Deduction Model of Belief. </title> <publisher> Pitman Publishing: London and Morgan Kaufmann: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Recall, from the discussion above, that there are two problems to be addressed in developing a logical formalism for intentional notions: a syntactic one, and a semantic one. It follows that any formalism can be characterized in terms of two independent attributes: its language of formulation, and semantic model <ref> (Konolige, 1986a, p83) </ref>. There are two fundamental approaches to the syntactic problem. The first is to use a modal language, which contains non-truth-functional modal operators, which are applied to formulae. <p> In this scheme, beliefs are viewed as symbolic formulae explicitly represented in a data structure associated with an agent. An agent then believes j if j is present in its belief data structure. Despite its simplicity, the sentential model works well under certain circumstances <ref> (Konolige, 1986a) </ref>. In the subsections that follow, we discuss various approaches in some more detail. <p> Knowledge is thus often defined as true belief: i knows j if i believes j and j is true. So defined, knowledge satisfies T. Axiom 4 is called the positive introspection axiom. Introspection is the process of examining one's own beliefs, and is discussed in detail in <ref> (Konolige, 1986a, Chapter 5) </ref>. The positive introspection axiom says that an agent is aware of what it knows. Similarly, axiom 5 is the negative introspection axiom, which says that an agent is aware of what it doesn't know. <p> However, this proposal has itself been criticised by some (Konolige, 1986b). Konolige the deduction model A more radical approach to modelling resource bounded believers was proposed by Konolige <ref> (Konolige, 1986a) </ref>. His deduction model of belief is, in essence, a direct attempt to model the `beliefs' of symbolic AI systems. <p> Although the logic contains modalities for representing beliefs and intentions, the semantics of these modalities are given in terms of the agent architecture itself, and the problems associated with possible worlds do not, therefore, arise; this work builds closely on Konolige's models of the beliefs of symbolic AI systems <ref> (Konolige, 1986a) </ref>. However, more work needs to be done using this technique to model more complex architectures, before the limitations and advantages of the approach are well-understood. Like purely deliberative architectures, some reactive systems are also underpinned by a relatively transparent theory.
Reference: <author> Konolige, K. </author> <year> (1986b). </year> <title> What awareness isn't: A sentential view of implicit and explicit belief (position paper). </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 241-250. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In an effort to recover from this last negative result, Fagin and Halpern have developed a `logic of general awareness', based on a similar idea to Levesque's but with a very much simpler semantics (Fagin and Halpern, 1985). However, this proposal has itself been criticised by some <ref> (Konolige, 1986b) </ref>. Konolige the deduction model A more radical approach to modelling resource bounded believers was proposed by Konolige (Konolige, 1986a). His deduction model of belief is, in essence, a direct attempt to model the `beliefs' of symbolic AI systems.
Reference: <author> Konolige, K. and Pollack, M. E. </author> <year> (1993). </year> <title> A representationalist theory of intention. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 390-395, </pages> <address> Chambery, France. </address>
Reference: <author> Kraus, S. and Lehmann, D. </author> <year> (1988). </year> <title> Knowledge, belief and time. </title> <journal> Theoretical Computer Science, </journal> <volume> 58 </volume> <pages> 155-174. </pages>
Reference: <author> Kripke, S. </author> <year> (1963). </year> <title> Semantical analysis of modal logic. </title> <journal> Zeitschrift fur Mathematische Logik und Grundlagen der Mathematik, </journal> <volume> 9 </volume> <pages> 67-96. </pages>
Reference-contexts: for logics of knowledge (epistemic logics) and logics of belief (doxastic logics). 2.c Possible Worlds Semantics The possible worlds model for logics of knowledge and belief was originally proposed by Hintikka (Hintikka, 1962), and is now most commonly formulated in a normal modal logic using the techniques developed by Kripke <ref> (Kripke, 1963) </ref> 3 . Hintikka's insight was to see that an agent's beliefs could be characterized as a set of possible worlds, in the following way. Consider an agent playing a card game such as poker 4 . <p> The next step is to show how possible worlds may be incorporated into the semantic framework of a logic. Epistemic logics are usually formulated as normal modal logics using the semantics developed by Kripke <ref> (Kripke, 1963) </ref>. Before moving on to explicitly epistemic logics, we consider a simple normal modal logic. This logic is essentially classical propositional logic, extended by the addition of two operators: ` ' (necessarily), and `-' (possibly). Let Prop = fp, q, g be a countable set of atomic propositions.
Reference: <author> Lakemeyer, G. </author> <year> (1991). </year> <title> A computationally attractive first-order logic of belief. </title> <booktitle> In JELIA-90: Proceedings of the European Workshop on Logics in AI (LNAI Volume 478), </booktitle> <pages> pages 333-347. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: The semantics of the implicit belief operator were given in terms of a standard possible worlds approach. A number of objections have been raised to Levesque's model (Reichgelt, 1989b, p135): first, it does not allow quantification this drawback has been rectified by Lakemeyer <ref> (Lakemeyer, 1991) </ref>; second, it does not seem to allow for nested beliefs; third, the notion of a situation, which underlies Levesque's logic is, if anything, more mysterious than the notion of a world in possible worlds; and fourth, under 15 certain circumstances, Levesque's proposal still makes unrealistic predictions about agent's reasoning
Reference: <author> Lesperance, Y. </author> <year> (1989). </year> <title> A formal account of self knowledge and action. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 868-874, </pages> <address> Detroit, MI. </address>
Reference: <author> Levesque, H. J. </author> <year> (1984). </year> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the Fourth National Conference on Artificial Intelligence (AAAI-84), </booktitle> <pages> pages 198-202, </pages> <address> Austin, TX. </address>
Reference-contexts: In the subsections that follow, we examine some of these attempts. Levesque belief and awareness In a 1984 paper, Levesque proposed a solution to the logical omniscience problem that involves making a distinction between explicit and implicit belief <ref> (Levesque, 1984) </ref>. Crudely, the idea is that an agent has a relatively small set of explicit beliefs, and a very much larger (infinite) set of implicit beliefs, which includes the logical consequences of the explicit beliefs.
Reference: <author> Levesque, H. J., Cohen, P. R., and Nunes, J. H. T. </author> <year> (1990). </year> <title> On acting together. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 94-99, </pages> <address> Boston, MA. </address>
Reference: <author> Levy, A. Y., Sagiv, Y., and Srivastava, D. </author> <year> (1994). </year> <title> Towards efficient information gathering agents. </title> <editor> In Etzioni, O., editor, </editor> <booktitle> Software Agents Papers from the 1994 Spring Symposium (Technical Report SS-94-03), </booktitle> <pages> pages 64-70. </pages> <publisher> AAAI Press. </publisher> <address> 54 Mack, D. </address> <year> (1994). </year> <title> A new formal model of belief. </title> <booktitle> In Proceedings of the Eleventh European Conference on Artificial Intelligence (ECAI-94), </booktitle> <pages> pages 573-577, </pages> <address> Amsterdam, The Neth-erlands. </address>
Reference: <author> Maes, P. </author> <year> (1989). </year> <title> The dynamics of action selection. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 991-997, </pages> <address> Detroit, MI. </address>
Reference: <author> Maes, P., </author> <title> editor (1990a). Designing Autonomous Agents. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference-contexts: There is now a regular international conference on planning; the proceedings of the first were published as (Hendler, 1992). The collection of papers edited by Maes <ref> (Maes, 1990a) </ref> contains many interesting papers on alternatives to the symbolic AI paradigm. Kaelbling (Kaelbling, 1986) presents a clear discussion of the issues associated with developing resource-bounded rational agents, and proposes an agent architecture somewhat similar to that developed by Brooks.
Reference: <author> Maes, P. </author> <year> (1990b). </year> <title> Situated agents can have goals. </title> <editor> In Maes, P., editor, </editor> <booktitle> Designing Autonomous Agents, </booktitle> <pages> pages 49-70. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Maes, P. </author> <year> (1991). </year> <title> The agent network architecture (ANA). </title> <journal> SIGART Bulletin, </journal> <volume> 2(4) </volume> <pages> 115-120. </pages>
Reference-contexts: An architecture encompasses techniques and algorithms that support this methodology.' <ref> (Maes, 1991, p115) </ref>. Kaelbling considers an agent architecture to be: `[A] specific collection of software (or hardware) modules, typically designated by boxes with arrows indicating the data and control flow among the modules.
Reference: <author> Maes, P. </author> <year> (1994a). </year> <title> Agents that reduce work and information overload. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 31-40. </pages>
Reference-contexts: scenarios are just around the corner, but serious academic research is underway into similar applications: air-traffic control has long been a research domain in distributed artificial intelligence (DAI) (Steeb et al., 1988); various types of information manager, that filter and obtain information on behalf of their users, have been prototyped <ref> (Maes, 1994a) </ref>; and systems such as those that appear in the third scenario are discussed in (McGregor, 1992; Levy et al., 1994). The key computer-based components that appear in each of the above scenarios are known as agents. <p> pointless anthropomorphism, it should be noted that there are good arguments in favour of designing and building agents in terms of human-like mental states see section 2.) Another way of giving agents human-like attributes is to represent them visually, perhaps by using a cartoon-like graphical icon or an animated face <ref> (Maes, 1994a, p36) </ref> for obvious reasons, such agents are of particular importance to those interested in human-computer interfaces. 5 Other Attributes of Agency Various other attributes are sometimes discussed in the context of agency. <p> metaphor is that of a personal assistant who is collaborating with the user in the same work environment.' (Maes, 1994b, p71) There are many interface agent prototype applications: for example, the NEWT system is an USENET news filter, (along the lines mentioned in the second scenario that introduced this article) <ref> (Maes, 1994a, pp38-39) </ref>. A NEWT agent is trained by giving it a series of examples, illustrating articles that the user would and would not choose to read. The agent then begins to make suggestions to the user, and is given feedback on its suggestions.
Reference: <author> Maes, P. </author> <year> (1994b). </year> <title> Social interface agents: Acquiring competence by learning from users and other agents. </title> <editor> In Etzioni, O., editor, </editor> <booktitle> Software Agents Papers from the 1994 Spring Symposium (Technical Report SS-94-03), </booktitle> <pages> pages 71-78. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Interface Agents Maes defines interface agents as: `[C]omputer programs that employ artificial intelligence techniques in order to provide assistance to a user dealing with a particular application. The metaphor is that of a personal assistant who is collaborating with the user in the same work environment.' <ref> (Maes, 1994b, p71) </ref> There are many interface agent prototype applications: for example, the NEWT system is an USENET news filter, (along the lines mentioned in the second scenario that introduced this article) (Maes, 1994a, pp38-39).
Reference: <author> M c Cabe, F. G. and Clark, K. L. </author> <year> (1995). </year> <title> April agent process interaction language. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 324-340. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Ger-many. </address>
Reference-contexts: The need for a development methodology seems to be one of the most pressing requirements for reactive systems. Anecdotal descriptions of current reactive systems implementations indicate that each such system must be individually hand-crafted through a potentially lengthy period of experimentation <ref> (Wavish and Graham, 1995) </ref>. This kind of ap 33 proach seems unlikely to be usable for large systems. <p> But if agents are ever to be really autonomous, and act pro-actively, then they must be able to generate their own goals when either the situation demands, or the opportunity arises. Some preliminary work in this area is <ref> (Norman and Long, 1995) </ref>. Similarly, little work has yet been done into the management and scheduling of multiple, possibly conflicting goals; some preliminary work is reported in (Dongha, 1995). Finally, we turn to the relationship between agent theories and agent architectures. <p> This means that, amongst other things, the specification and verification 38 of Concurrent METATEM systems is a realistic proposition (Fisher and Wooldridge, 1993). At the time of writing, only prototype implementations of the language are available; full implementations are expected soon. The IMAGINE Project APRIL and MAIL APRIL <ref> (M c Cabe and Clark, 1995) </ref> and MAIL (Haugeneder et al., 1994) are two languages for developing multi-agent applications that were developed as part of the ESPRIT project IMAGINE (Haugeneder, 1994). The two languages are intended to fulfill quite different roles. <p> The result of the compilation process is a very fast implementation, which has been used to control a Compact Disk-Interactive (CD-I) application. ABLE has recently been extended to a version called Real-Time ABLE (RTA) <ref> (Wavish and Graham, 1995) </ref>. 4.a Discussion The emergence of various language-based software tools for building agent applications is clearly an important development for the wider acceptance and use of agent technology.
Reference: <author> McCarthy, J. </author> <year> (1978). </year> <title> Ascribing mental qualities to machines. </title> <type> Technical report, </type> <institution> Stanford University AI Lab., Stanford, </institution> <address> CA 94305. </address>
Reference-contexts: Ascription of mental qualities is most straightforward for machines of known structure such as thermostats and computer operating systems, but is most useful when applied to entities whose structure is incompletely known'. <ref> (McCarthy, 1978) </ref>, (quoted in (Shoham, 1990)) What objects can be described by the intentional stance? As it turns out, more or less anything can.
Reference: <author> McGregor, S. L. </author> <year> (1992). </year> <title> Prescient agents. </title> <editor> In Coleman, D., editor, </editor> <booktitle> Proceedings of Groupware-92, </booktitle> <pages> pages 228-230. </pages>
Reference-contexts: Similar ideas have been proposed by McGregor, who imagines prescient agents intelligent administrative assistants, that predict our actions, and carry out routine or repetetive administrative procedures on our behalf <ref> (McGregor, 1992) </ref>. There is much related work being done by the computer supported cooperative work (CSCW) community. CSCW is informally defined by Baecker to be `computer assisted coordinated activity such as problem solving and communication carried out by a group of collaborating individuals' (Baecker, 1993, p1).
Reference: <author> Montague, R. </author> <year> (1963). </year> <title> Syntactical treatments of modality, with corollaries on reflexion principles and finite axiomatizations. </title> <journal> Acta Philosophica Fennica, </journal> <volume> 16 </volume> <pages> 153-167. </pages>
Reference: <author> Moore, R. C. </author> <year> (1990). </year> <title> A formal theory of knowledge and action. </title> <editor> In Allen, J. F., Hendler, J., and Tate, A., editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 480-519. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In the following subsections, we briefly review some of this work. 17 Moore knowledge and action Moore was in many ways a pioneer of the use of logics for capturing aspects of agency <ref> (Moore, 1990) </ref>. His main concern was the study of knowledge pre-conditions for actions the question of what an agent needs to know in order to be able to perform some action.
Reference: <author> Morgenstern, L. </author> <year> (1987). </year> <title> Knowledge preconditions for actions and plans. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <pages> pages 867-874, </pages> <address> Milan, Italy. </address>
Reference-contexts: Unfortunately, meta-language formalisms have their own package of problems, not the least of which is that they tend to fall prey to inconsistency (Montague, 1963; Thomason, 1980). However, there have been some fairly successful meta-language formalisms, including those by Konolige (Konolige, 1982), Haas (Haas, 1986), Morgenstern <ref> (Morgenstern, 1987) </ref>, and Davies (Davies, 1993).
Reference: <author> Mori, K., Torikoshi, H., Nakai, K., and Masuda, T. </author> <year> (1988). </year> <title> Computer control system for iron and steel plants. </title> <journal> Hitachi Review, </journal> <volume> 37(4) </volume> <pages> 251-258. </pages> <note> 55 Morley, </note> <author> R. E. and Schelberg, C. </author> <year> (1993). </year> <title> An analysis of a plant-specific dynamic scheduler. </title> <booktitle> In Proceedings of the NSF Workshop on Dynamic Scheduling, </booktitle> <address> Cocoa Beach, Florida. </address>
Reference-contexts: 1986), patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control <ref> (Mori et al., 1988) </ref>. The classic reference to DAI is (Bond and Gasser, 1988), which includes both a comprehensive review article and a collection of significant papers from the field; a more recent review article is (Chaib-draa et al., 1992).
Reference: <author> Mukhopadhyay, U., Stephens, L., and Huhns, M. </author> <year> (1986). </year> <title> An intelligent system for document retrieval in distributed office environments. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 37 </volume> <pages> 123-135. </pages>
Reference-contexts: DAI researchers have applied agent technology in a variety of areas. Example applications include power systems management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval <ref> (Mukhopadhyay et al., 1986) </ref>, patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil
Reference: <author> Muller, J. P. </author> <year> (1994). </year> <title> A conceptual model for agent interaction. </title> <editor> In Deen, S. M., editor, </editor> <booktitle> Proceedings of the Second International Working Conference on Cooperating Knowledge Based Systems (CKBS-94), </booktitle> <pages> pages 213-234, </pages> <institution> DAKE Centre, University of Keele, UK. </institution>
Reference-contexts: Often, the reactive component is given some kind of precedence over the deliberative one, so that it can provide a rapid response to important environmental events. This kind of structuring leads naturally to the idea of a layered architecture, of which TOURINGMACHINES (Ferguson, 1992a) and INTERRAP <ref> (Muller and Pischel, 1994) </ref> are good examples. (These architectures are described below.) In such an architecture, an agent's control subsystems are arranged into a hierarchy, with higher layers dealing with information at increasing levels of abstraction.
Reference: <author> Muller, J. P. and Pischel, M. </author> <year> (1994). </year> <title> Modelling interacting agents in dynamic environments. </title> <booktitle> In Proceedings of the Eleventh European Conference on Artificial Intelligence (ECAI-94), </booktitle> <pages> pages 709-713, </pages> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: Often, the reactive component is given some kind of precedence over the deliberative one, so that it can provide a rapid response to important environmental events. This kind of structuring leads naturally to the idea of a layered architecture, of which TOURINGMACHINES (Ferguson, 1992a) and INTERRAP <ref> (Muller and Pischel, 1994) </ref> are good examples. (These architectures are described below.) In such an architecture, an agent's control subsystems are arranged into a hierarchy, with higher layers dealing with information at increasing levels of abstraction.
Reference: <author> Muller, J. P., Pischel, M., and Thiel, M. </author> <year> (1995). </year> <title> Modelling reactive behaviour in vertically layered agent architectures. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 261-276. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference: <author> Newell, A. and Simon, H. A. </author> <year> (1976). </year> <title> Computer science as empirical enquiry. </title> <journal> Communications of the ACM, </journal> <volume> 19 </volume> <pages> 113-126. </pages>
Reference-contexts: This paradigm is known as symbolic AI: we begin our review of architectures with a look at this paradigm, and the assumptions that underpin it. 3.a Classical Approaches: Deliberative Architectures The foundation upon which the symbolic AI paradigm rests is the physical-symbol system hypothesis, formulated by Newell and Simon <ref> (Newell and Simon, 1976) </ref>. A physical symbol system is defined to be a physically realizable set of physical entities (symbols) that can be combined to form structures, and which is capable of running processes that operate on those symbols according to symbolically coded sets of instructions.
Reference: <author> Nilsson, N. J. </author> <year> (1992). </year> <title> Towards agent programs with circuit semantics. </title> <type> Technical Report STAN-CS-92-1412, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> CA 94305. </address>
Reference-contexts: Kaelbling (Kaelbling, 1986) presents a clear discussion of the issues associated with developing resource-bounded rational agents, and proposes an agent architecture somewhat similar to that developed by Brooks. A proposal by Nilsson for teleo reactive programs goal directed programs that nevertheless respond to their environment is described in <ref> (Nilsson, 1992) </ref>. The proposal draws heavily on the situated automata paradigm; other work based on this paradigm is described in (Shoham, 1990; Kiss and Reich-gelt, 1992).
Reference: <author> Norman, T. J. and Long, D. </author> <year> (1995). </year> <title> Goal creation in motivated agents. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 277-290. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: But if agents are ever to be really autonomous, and act pro-actively, then they must be able to generate their own goals when either the situation demands, or the opportunity arises. Some preliminary work in this area is <ref> (Norman and Long, 1995) </ref>. Similarly, little work has yet been done into the management and scheduling of multiple, possibly conflicting goals; some preliminary work is reported in (Dongha, 1995). Finally, we turn to the relationship between agent theories and agent architectures.
Reference: <author> Papazoglou, M. P., Laufman, S. C., and Sellis, T. K. </author> <year> (1992). </year> <title> An organizational framework for cooperating intelligent information systems. </title> <journal> Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 1(1) </volume> <pages> 169-202. </pages>
Reference-contexts: to at least one, and potentially many information sources, and is able to collate and manipulate information obtained from these sources 42 in order to answer queries posed by users and other information agents (the network of inter--operating information sources are often referred to as intelligent and cooperative information systems <ref> (Papazoglou et al., 1992) </ref>). The information sources may be of many types, including, for example, traditional databases as well as other information agents. Finding a solution to a query might involve an agent accessing information sources over a network.
Reference: <author> Parunak, H. V. D. </author> <year> (1995). </year> <booktitle> Applications of distributed artificial intelligence in industry. </booktitle> <editor> In O'Hare, G. M. P. and Jennings, N. R., editors, </editor> <booktitle> Foundations of Distributed AI. </booktitle> <publisher> John Wiley & Sons: </publisher> <address> Chichester, England. </address> <note> (To appear). </note>
Reference-contexts: management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval (Mukhopadhyay et al., 1986), patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing <ref> (Parunak, 1995) </ref>, concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control (Mori et al., 1988).
Reference: <author> Patil, R. S., Fikes, R. E., Patel-Schneider, P. F., McKay, D., Finin, T., Gruber, T., and Neches, R. </author> <year> (1992). </year> <title> The DARPA knowledge sharing effort: Progress report. </title> <editor> In Rich, C., Swartout, W., and Nebel, B., editors, </editor> <booktitle> Proceedings of Knowledge Representation and Reasoning (KR&R-92), </booktitle> <pages> pages 777-788. </pages> <address> 56 Perlis, D. </address> <year> (1985). </year> <title> Languages with self reference I: </title> <booktitle> Foundations. Artificial Intelligence, </booktitle> <address> 25:301--322. </address>
Reference-contexts: Although not directly based on work in speech acts, (and arguably more to do with architectures than theories), we shall here mention work on agent communication languages (Genesereth and Ketchpel, 1994). The best known work on agent communication languages is that by the ARPA knowledge sharing effort <ref> (Patil et al., 1992) </ref>. This work has been largely devoted to developing two related languages: the knowledge query and manipulation language (KQML) and the knowledge interchange format (KIF).
Reference: <author> Perlis, D. </author> <year> (1988). </year> <title> Languages with self reference II: Knowledge, belief, and modality. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 179-212. </pages>
Reference: <author> Perloff, M. </author> <year> (1991). </year> <title> STIT and the language of agency. </title> <journal> Synthese, </journal> <volume> 86 </volume> <pages> 379-408. </pages>
Reference: <author> Poggi, A. </author> <year> (1995). </year> <title> DAISY: An object-oriented system for distributed artificial intelligence. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 341-254. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Two examples are AGENTSPEAK and DAISY. AGENTSPEAK is loosely based on the PRS agent architecture, and incorporates aspects of concurrent-object technology (Weerasooriya et al., 1995). In contrast, DAISY is based on the concurrent-object language CUBL (Adorni and Poggi, 1993), and incorporates aspects of the agent-oriented proposal <ref> (Poggi, 1995) </ref>. Other languages of interest include OZ (Henz et al., 1993) and IC PROLOG II (Chu, 1993).
Reference: <author> Pollack, M. E. and Ringuette, M. </author> <year> (1990). </year> <title> Introducing the Tileworld: Experimentally evaluating agent architectures. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 183-189, </pages> <address> Boston, MA. </address>
Reference-contexts: The choice between competing options is made by the deliberation process. The IRMA architecture has been evaluated in an experimental scenario known as the Tileworld <ref> (Pollack and Ringuette, 1990) </ref>. Vere and Bickmore HOMER An interesting experiment in the design of intelligent agents was conducted by Vere and Bick-more (Vere and Bickmore, 1990). <p> There is a pressing need for research into the capabilities of reactive systems, and perhaps in particular to the types of application for which these types of system are best suited; some preliminary work has been done in this area, using a problem domain known as the TILEWORLD <ref> (Pollack and Ringuette, 1990) </ref>. With respect to reactive systems, Ferguson suggests that: `[T]he strength of purely non-deliberative architectures lies in their ability to exploit local patterns of activity in their current surroundings in order to generate more or less hardwired action responses for a given set of stimuli.
Reference: <author> Rao, A. S. and Georgeff, M. P. </author> <year> (1991a). </year> <title> Asymmetry thesis and side-effect problems in linear time and branching time intention logics. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pages 498-504, </pages> <address> Sydney, Australia. </address>
Reference: <author> Rao, A. S. and Georgeff, M. P. </author> <year> (1991b). </year> <title> Modeling rational agents within a BDI-architecture. </title> <editor> In Fikes, R. and Sandewall, E., editors, </editor> <booktitle> Proceedings of Knowledge Representation and Reasoning (KR&R-91), </booktitle> <pages> pages 473-484. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The question of exactly which combination of attitudes is required to characterise an agent is also the subject of some debate. As we observed above, a currently popular approach is to use a combination of beliefs, desires, and intentions (hence BDI architectures <ref> (Rao and Georgeff, 1991b) </ref>). However, there are alternatives: Shoham, for example, suggests that the notion of choice is more fundamental (Shoham, 1990). Comparatively little work has yet been done on formally comparing the suitability of these various combinations. <p> Bratman, Israel and Pollack IRMA In section 2, we saw that some researchers have considered frameworks for agent theory based on beliefs, desires, and intentions <ref> (Rao and Georgeff, 1991b) </ref>. Some researchers have also developed agent architectures based on these attitudes. One example is the Intelligent Resource-bounded Machine Architecture (IRMA) (Bratman et al., 1988). This architecture has four key symbolic data structures: a plan library, and explicit representations of beliefs, desires, and intentions.
Reference: <author> Rao, A. S. and Georgeff, M. P. </author> <year> (1992a). </year> <title> An abstract architecture for rational agents. </title> <editor> In Rich, C., Swartout, W., and Nebel, B., editors, </editor> <booktitle> Proceedings of Knowledge Representation and Reasoning (KR&R-92), </booktitle> <pages> pages 439-449. </pages>
Reference-contexts: The close relationship between symbolic processing systems and mathematical logic means that the semantics of such architectures can often be represented as a logical system of some kind. There is a wealth of work establishing such relationships in AI, of which a particularly relevant example is <ref> (Rao and Georgeff, 1992a) </ref>. This article discusses the relationship between the abstract BDI logics de 34 veloped by Rao et al. for reasoning about agents, and an abstract `agent interpreter', based on the PRS.
Reference: <author> Rao, A. S. and Georgeff, M. P. </author> <year> (1992b). </year> <title> Social plans: Preliminary report. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 57-76. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Rao, A. S. and Georgeff, M. P. </author> <year> (1993). </year> <title> A model-theoretic approach to the verification of situated reasoning systems. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 318-324, </pages> <address> Chambery, France. </address>
Reference: <author> Reichgelt, H. </author> <year> (1989a). </year> <title> A comparison of first-order and modal logics of time. </title> <editor> In Jackson, P., Reichgelt, H., and van Harmelen, F., editors, </editor> <booktitle> Logic Based Knowledge Representation, </booktitle> <pages> pages 143-176. </pages> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Reichgelt, H. </author> <year> (1989b). </year> <title> Logics for reasoning about knowledge and belief. </title> <journal> Knowledge Engineering Review, </journal> <volume> 4(2) </volume> <pages> 119-139. </pages> <note> 57 Rosenschein, </note> <author> J. S. and Genesereth, M. R. </author> <year> (1985). </year> <title> Deals among rational agents. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence (IJCAI-85), </booktitle> <pages> pages 91-99, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: The semantics of the implicit belief operator were given in terms of a standard possible worlds approach. A number of objections have been raised to Levesque's model <ref> (Reichgelt, 1989b, p135) </ref>: first, it does not allow quantification this drawback has been rectified by Lakemeyer (Lakemeyer, 1991); second, it does not seem to allow for nested beliefs; third, the notion of a situation, which underlies Levesque's logic is, if anything, more mysterious than the notion of a world in possible
Reference: <author> Rosenschein, S. </author> <year> (1985). </year> <title> Formal theories of knowledge in AI and robotics. </title> <journal> New Generation Computing, </journal> <pages> pages 345-357. </pages>
Reference-contexts: move around an electronic network (White, 1994); veracity is the assumption that an agent will not knowingly communicate false inform ation (Galliers, 1988b, pp159-164); benevolence is the assumption that agents do not have conflicting goals, and that every agent will therefore always try to do what is asked of it <ref> (Rosenschein and Genesereth, 1985, p91) </ref>; and rationality is (crudely) the assumption that an agent will act in order to achieve its goals, and will not act in such a way as to prevent its goals being achieved at least insofar as its beliefs permit (Galliers, 1988b, pp49-54). (A discussion of some
Reference: <author> Rosenschein, S. and Kaelbling, L. P. </author> <year> (1986). </year> <title> The synthesis of digital machines with provable epistemic properties. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 83-98. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In his doctoral thesis, Seel showed that even very simple, automata-like objects can be consistently ascribed intentional descriptions (Seel, 1989); similar work by Rosenschein and Kaelbling, (albeit with a different motivation), arrived at a similar conclusion <ref> (Rosenschein and Kaelbling, 1986) </ref>. <p> the time of writing, Shoham has only published results on the first two components. (In (Shoham, 1990, p12) he wrote that `the third is still somewhat mysterious to me', though later in the paper he indicated that he was thinking along the lines of Rosenschein and Kaelbling's situated automata paradigm <ref> (Rosenschein and Kaelbling, 1986) </ref>.) Shoham's first attempt at an AOP language was the AGENT0 system. The logical component of this system is a quantified multi-modal logic, allowing direct reference to time. No semantics are given, but the logic appears to be based on (Thomas et al., 1991).
Reference: <author> Russell, S. J. and Wefald, E. </author> <year> (1991). </year> <title> Do the Right Thing Studies in Limited Rationality. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Sacerdoti, E. </author> <year> (1974). </year> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135. </pages>
Reference: <author> Sacerdoti, E. </author> <year> (1975). </year> <title> The non-linear nature of plans. </title> <booktitle> In Proceedings of the Fourth International Joint Conference on Artificial Intelligence (IJCAI-75), </booktitle> <pages> pages 206-214, </pages> <address> Stanford, CA. </address>
Reference: <author> Sadek, M. D. </author> <year> (1992). </year> <title> A study in the logic of intention. </title> <editor> In Rich, C., Swartout, W., and Nebel, B., editors, </editor> <booktitle> Proceedings of Knowledge Representation and Reasoning (KR&R-92), </booktitle> <pages> pages 462-473. </pages>
Reference: <author> Sargent, P. </author> <year> (1992). </year> <title> Back to school for a brand new ABC. </title> <booktitle> In The Guardian, </booktitle> <month> 12 March </month> <year> 1992, </year> <pages> page 28. </pages>
Reference-contexts: A British national daily paper recently predicted that: 3 `Agent-based computing (ABC) is likely to be the next significant breakthrough in software development.' <ref> (Sargent, 1992) </ref> Moreover, the UK-based consultancy firm Ovum has predicted that the agent technology industry would be worth some US$3.5 billion worldwide by the year 2000 (Houlder, 1994).
Reference: <author> Schoppers, M. J. </author> <year> (1987). </year> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <pages> pages 1039-1046, </pages> <address> Milan, Italy. </address>
Reference-contexts: Schoppers has proposed compiling plans in advance, using traditional planning techniques, in order to develop universal plans, which are essentially decision trees that can be used to efficiently determine an appropriate action in any situation <ref> (Schoppers, 1987) </ref>. Another proposal for building `reactive planners' involves the use of reactive action packages (Firby, 1987).
Reference: <author> Schwuttke, U. M. and Quan, A. G. </author> <year> (1993). </year> <title> Enhancing performance of cooperating agents in real-time diagnostic systems. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 332-337, </pages> <address> Chambery, France. </address>
Reference-contexts: Example applications include power systems management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval (Mukhopadhyay et al., 1986), patient care (Huang et al., 1995), telecommunications network management (Weihmayer and Velthuijsen, 1994), spacecraft control <ref> (Schwuttke 41 and Quan, 1993) </ref>, computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control (Mori et al., 1988).
Reference: <author> Searle, J. R. </author> <year> (1969). </year> <title> Speech Acts: An Essay in the Philosophy of Language. </title> <publisher> Cambridge University Press: </publisher> <address> Cambridge, England. </address>
Reference-contexts: He then gave examples of how these logics could be used in the specification and verification of protocols for cooperative action. 2.g Communication Formalisms for representing communication in agent theory have tended to be based on speech act theory, as originated by Austin (Austin, 1962), and further developed by Searle <ref> (Searle, 1969) </ref> and others (Cohen and Perrault, 1979; Cohen and Levesque, 1990a). Briefly, the key axiom of speech act theory is that communicative utterances are actions, in just the sense that physical actions are.
Reference: <author> Seel, N. </author> <year> (1989). </year> <title> Agent Theories and Architectures. </title> <type> PhD thesis, </type> <institution> Surrey University, Guildford, UK. </institution>
Reference-contexts: For convenience, we identify three key issues, and structure our survey around these (cf. <ref> (Seel, 1989, p1) </ref>): Agent theories are essentially specifications. Agent theorists address such questions as: How are we to conceptualise agents? What properties should agents have, and how are we to formally represent and reason about these properties? Agent architectures represent the move from specification to implementation. <p> Our starting point is the notion of an agent as an entity `which appears to be the subject of beliefs, desires, etc.' <ref> (Seel, 1989, p1) </ref>. The philosopher Dennett has coined the term intentional system to denote such systems. 2.a Agents as Intentional Systems When explaining human activity, it is often useful to make statements such as the following: Janine took her umbrella because she believed it was going to rain. <p> In his doctoral thesis, Seel showed that even very simple, automata-like objects can be consistently ascribed intentional descriptions <ref> (Seel, 1989) </ref>; similar work by Rosenschein and Kaelbling, (albeit with a different motivation), arrived at a similar conclusion (Rosenschein and Kaelbling, 1986).
Reference: <author> Segerberg, K. </author> <year> (1989). </year> <title> Bringing it about. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 18 </volume> <pages> 327-347. </pages> <address> 58 Shardlow, N. </address> <year> (1990). </year> <title> Action and agency in cognitive science. </title> <type> Master's thesis, </type> <institution> Department of Psychlogy, University of Manchester, </institution> <address> Oxford Rd., Manchester M13 9PL, UK. </address>
Reference: <author> Shoham, Y. </author> <year> (1988). </year> <title> Reasoning About Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address>
Reference: <author> Shoham, Y. </author> <year> (1989). </year> <title> Time for action: on the relation between time, knowledge and action. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 954-959, </pages> <address> Detroit, MI. </address>
Reference: <author> Shoham, Y. </author> <year> (1990). </year> <title> Agent-oriented programming. </title> <type> Technical Report STAN-CS-1335-90, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> CA 94305. </address>
Reference-contexts: Ascription of mental qualities is most straightforward for machines of known structure such as thermostats and computer operating systems, but is most useful when applied to entities whose structure is incompletely known'. (McCarthy, 1978), (quoted in <ref> (Shoham, 1990) </ref>) What objects can be described by the intentional stance? As it turns out, more or less anything can. <p> switch: 8 `It is perfectly coherent to treat a light switch as a (very cooperative) agent with the capability of transmitting current at will, who invariably transmits current when it believes that we want it transmitted and not otherwise; flicking the switch is simply our way of communicating our desires'. <ref> (Shoham, 1990, p6) </ref> And yet most adults would find such a description absurd perhaps even infantile. <p> this? The answer seems to be that while the intentional stance description is perfectly consistent with the observed behaviour of a light switch, and is internally consistent, ` it does not buy us anything, since we essentially understand the mechanism sufficiently to have a simpler, mechanistic description of its behaviour'. <ref> (Shoham, 1990, p6) </ref> Put crudely, the more we know about a system, the less we need to rely on animistic, intentional explanations of its behaviour. <p> As we observed above, a currently popular approach is to use a combination of beliefs, desires, and intentions (hence BDI architectures (Rao and Georgeff, 1991b)). However, there are alternatives: Shoham, for example, suggests that the notion of choice is more fundamental <ref> (Shoham, 1990) </ref>. Comparatively little work has yet been done on formally comparing the suitability of these various combinations. <p> For a discussion on the relationship between agents and concurrent object programming, see (Gasser and Briot, 1992). Shoham agent-oriented programming Yoav Shoham has proposed a `new programming paradigm, based on a societal view of computation' <ref> (Shoham, 1990, p4) </ref>,(Shoham, 1993). The key idea that informs this agent-oriented programming (AOP) paradigm is that of directly programming agents in terms of the mentalistic, intentional notions that agent theorists have developed to represent the properties of agents. <p> At the time of writing, Shoham has only published results on the first two components. (In <ref> (Shoham, 1990, p12) </ref> he wrote that `the third is still somewhat mysterious to me', though later in the paper he indicated that he was thinking along the lines of Rosenschein and Kaelbling's situated automata paradigm (Rosenschein and Kaelbling, 1986).) Shoham's first attempt at an AOP language was the AGENT0 system.
Reference: <author> Shoham, Y. </author> <year> (1993). </year> <title> Agent-oriented programming. </title> <journal> Artificial Intelligence, </journal> <volume> 60(1) </volume> <pages> 51-92. </pages>
Reference-contexts: For example, it is quite common in AI to characterise an agent using mentalistic notions, such as knowledge, belief, intention, and obligation <ref> (Shoham, 1993) </ref>.
Reference: <author> Singh, M. P. </author> <year> (1990a). </year> <title> Group intentions. </title> <booktitle> In Proceedings of the Tenth International Workshop on Distributed Artificial Intelligence (IWDAI-90). </booktitle>
Reference: <author> Singh, M. P. </author> <year> (1990b). </year> <title> Towards a theory of situated know-how. </title> <booktitle> In Proceedings of the Ninth European Conference on Artificial Intelligence (ECAI-90), </booktitle> <pages> pages 604-609, </pages> <address> Stockholm, Sweden. </address>
Reference: <author> Singh, M. P. </author> <year> (1991a). </year> <title> Group ability and structure. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized AI 2 Proceedings of the Second European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-90), </booktitle> <pages> pages 127-146. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Singh, M. P. </author> <year> (1991b). </year> <title> Towards a formal theory of communication for multi-agent systems. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pages 69-74, </pages> <address> Sydney, Australia. </address>
Reference: <author> Singh, M. P. </author> <year> (1992). </year> <title> A critical examination of the Cohen-Levesque theory of intention. </title> <booktitle> In Proceedings of the Tenth European Conference on Artificial Intelligence (ECAI-92), </booktitle> <pages> pages 364-368, </pages> <address> Vienna, Austria. </address>
Reference-contexts: Cohen and Levesque go on to show how such a definition meets many of Bratman's criteria for a theory of intention (outlined above). A critique of Cohen and Levesque's theory of intention may be found in <ref> (Singh, 1992) </ref>. Rao and Georgeff belief, desire, intention architectures As we observed earlier, there is no clear consensus in either the AI or philosophy communities about precisely which combination of information and pro-attitudes are best suited to charac-terising rational agents.
Reference: <author> Singh, M. P. </author> <year> (1994). </year> <title> Multiagent Systems: A Theoretical Framework for Intentions, </title> <booktitle> Know-How, and Communications (LNAI Volume 799). </booktitle> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Singh A quite different approach to modelling agents was taken by Singh, who has developed an interesting family of logics for representing intentions, beliefs, knowledge, know-how, and communication in a branching-time framework (Singh, 1990b; Singh, 1991a; Singh and Asher, 1991; Singh, 1991b); these articles are collected and expanded in <ref> (Singh, 1994) </ref>. Singh's formalism is extremely rich, and considerable effort has been devoted to establishing its properties.
Reference: <author> Singh, M. P. and Asher, N. M. </author> <year> (1991). </year> <title> Towards a formal theory of intentions. </title> <booktitle> In Logics in AI Proceedings of the European Workshop JELIA-90 (LNAI Volume 478), </booktitle> <pages> pages 472-486. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference: <author> Smith, R. G. </author> <year> (1980). </year> <title> A Framework for Distributed Problem Solving. </title> <note> UMI Research Press. 59 Steeb, </note> <author> R., Cammarata, S., Hayes-Roth, F. A., Thorndyke, P. W., and Wesson, R. B. </author> <year> (1988). </year> <title> Distributed intelligence for air fleet control. </title> <editor> In Bond, A. H. and Gasser, L., editors, </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <pages> pages 90-101. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: A script is very much like a script in Schank's original sense: it is a stereotypical recipe or plan for achieving a goal. Protocols are stereotypical dialogues representing cooperation frameworks such as the contract net <ref> (Smith, 1980) </ref>. The reasoning, deciding and reacting component is perhaps the key component in COSY. It is made up of a number of other subsystems, and is structured rather like the PRS and IRMA (see above). An agenda is maintained, that contains a number of active scripts.
Reference: <author> Steels, L. </author> <year> (1990). </year> <title> Cooperation between distributed agents through self organization. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized AI Proceedings of the First European Workshop on Modelling Autonomous Agents in Multi-Agent Worlds (MAAMAW-89), </booktitle> <pages> pages 175-196. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: Similar work has been reported by Steels, who described simulations of `Mars explorer' systems, containing a large number of subsumption-architecture agents, that can achieve near-optimal performance in certain tasks <ref> (Steels, 1990) </ref>.
Reference: <author> Thomas, S. R. </author> <year> (1993). </year> <title> PLACA, an Agent Oriented Programming Language. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> CA 94305. </address> <note> (Available as technical report STAN-CS-93-1487). </note>
Reference-contexts: Thomas PLACA AGENT0 was only ever intended as a prototype, to illustrate the principles of AOP. A more refined implementation was developed by Thomas, for her 1993 doctoral thesis <ref> (Thomas, 1993) </ref>. Her Planning Communicating Agents (PLACA) language was intended to address one severe drawback to AGENT0: the inability of agents to plan, and communicate requests for action via high-level goals. Agents in PLACA are programmed in much the same way as in AGENT0, in terms of mental change rules.
Reference: <author> Thomas, S. R., Shoham, Y., Schwartz, A., and Kraus, S. </author> <year> (1991). </year> <title> Preliminary thoughts on an agent description language. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6 </volume> <pages> 497-508. </pages>
Reference-contexts: The logical component of this system is a quantified multi-modal logic, allowing direct reference to time. No semantics are given, but the logic appears to be based on <ref> (Thomas et al., 1991) </ref>. The logic contains three modalities: belief, commitment and ability. The following is an acceptable formula of the logic, illustrating it's key properties: CAN 5 a open (door) 8 fi B 5 b CAN 5 a open (door) 8 .
Reference: <author> Thomason, R. </author> <year> (1980). </year> <title> A note on syntactical treatments of modality. </title> <journal> Synthese, </journal> <volume> 44 </volume> <pages> 391-395. </pages>
Reference: <author> Turner, R. </author> <year> (1990). </year> <title> Truth and Modality for Knowledge Representation. </title> <publisher> Pitman Publishing: London. </publisher>
Reference: <author> Varga, L. Z., Jennings, N. R., and Cockburn, D. </author> <year> (1994). </year> <title> Integrating intelligent systems into a cooperating community for electricity distribution management. </title> <journal> International Journal of Expert Systems with Applications, </journal> <volume> 7(4) </volume> <pages> 563-579. </pages>
Reference: <author> Vere, S. and Bickmore, T. </author> <year> (1990). </year> <title> A basic agent. </title> <journal> Computational Intelligence, </journal> <volume> 6 </volume> <pages> 41-60. </pages>
Reference-contexts: The choice between competing options is made by the deliberation process. The IRMA architecture has been evaluated in an experimental scenario known as the Tileworld (Pollack and Ringuette, 1990). Vere and Bickmore HOMER An interesting experiment in the design of intelligent agents was conducted by Vere and Bick-more <ref> (Vere and Bickmore, 1990) </ref>. They argued that the enabling technologies for intelligent agents are sufficiently developed to be able to construct a prototype autonomous agent, with linguistic ability, planning and acting capabilities, and so on. They developed such an agent, and christened it HOMER.
Reference: <author> Voorhees, E. M. </author> <year> (1994). </year> <title> Software agents for information retrieval. </title> <editor> In Etzioni, O., editor, </editor> <booktitle> Software Agents Papers from the 1994 Spring Symposium (Technical Report SS-94-03), </booktitle> <pages> pages 126-129. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: made of information agents, including a theoretical study of how agents are able to incorporate information from different sources (Levy et al., 1994; Gruber, 1991), as well a prototype system called IRA (information retrieval agent) that is able to search for loosely specificed articles from a range of document repositories <ref> (Voorhees, 1994) </ref>. Another important system in this area is called Carnot (Huhns et al., 1992), which allows pre-existing and heterogeneous database systems to work together to answer queries that are outside the scope of any of the individual databases.
Reference: <author> Wainer, J. </author> <year> (1994). </year> <title> Yet another semantics of goals and goal priorities. </title> <booktitle> In Proceedings of the Eleventh European Conference on Artificial Intelligence (ECAI-94), </booktitle> <pages> pages 269-273, </pages> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: The problem is discussed, (in the context of intentions), in (Bratman, 1990). The basic possible worlds model has been adapted by some researchers in an attempt to overcome this problem <ref> (Wainer, 1994) </ref>. Other, related semantics for goals have been proposed (Doyle et al., 1991; Kiss and Reichgelt, 1992; Rao and Georgeff, 1991b). 2.f Theories of Agency All of the formalisms considered so far have focussed on just one aspect of agency.
Reference: <author> Wavish, P. </author> <year> (1992). </year> <title> Exploiting emergent behaviour in multi-agent systems. </title> <editor> In Werner, E. and Demazeau, Y., editors, </editor> <booktitle> Decentralized AI 3 Proceedings of the Third European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-91), </booktitle> <pages> pages 297-310. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> Wavish, P. and Graham, M. </author> <year> (1995). </year> <title> Roles, skills, and behaviour: a situated action approach to organising systems of interacting agents. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 371-385. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address> <note> 60 Weerasooriya, </note> <author> D., Rao, A., and Ramamohanarao, K. </author> <year> (1995). </year> <title> Design of a concurrent agent--oriented language. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 386-402. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: The need for a development methodology seems to be one of the most pressing requirements for reactive systems. Anecdotal descriptions of current reactive systems implementations indicate that each such system must be individually hand-crafted through a potentially lengthy period of experimentation <ref> (Wavish and Graham, 1995) </ref>. This kind of ap 33 proach seems unlikely to be usable for large systems. <p> The result of the compilation process is a very fast implementation, which has been used to control a Compact Disk-Interactive (CD-I) application. ABLE has recently been extended to a version called Real-Time ABLE (RTA) <ref> (Wavish and Graham, 1995) </ref>. 4.a Discussion The emergence of various language-based software tools for building agent applications is clearly an important development for the wider acceptance and use of agent technology.
Reference: <author> Weihmayer, R. and Velthuijsen, H. </author> <year> (1994). </year> <title> Application of distributed AI and cooperative problem solving to telecommunications. </title> <editor> In Liebowitz, J. and Prereau, D., editors, </editor> <title> AI Approaches to Telecommunications and Network Management. </title> <publisher> IOS Press. </publisher>
Reference-contexts: Example applications include power systems management (Wittig, 1992; Varga et al., 1994), air-traffic control (Steeb et al., 1988), particle accelerator control (Jennings et al., 1993), intelligent document retrieval (Mukhopadhyay et al., 1986), patient care (Huang et al., 1995), telecommunications network management <ref> (Weihmayer and Velthuijsen, 1994) </ref>, spacecraft control (Schwuttke 41 and Quan, 1993), computer integrated manufacturing (Parunak, 1995), concurrent engineering (Cutkosky et al., 1993), transportation management (Fischer et al., 1993), job shop scheduling (Morley and Schelberg, 1993), and steel coil processing control (Mori et al., 1988).
Reference: <author> Werner, E. </author> <year> (1988). </year> <title> Toward a theory of communication and cooperation for multiagent planning. </title> <editor> In Vardi, M. Y., editor, </editor> <booktitle> Proceedings of the Second Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 129-144. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference: <author> Werner, E. </author> <year> (1989). </year> <title> Cooperating agents: A unified theory of communication and social structure. </title> <editor> In Gasser, L. and Huhns, M., editors, </editor> <booktitle> Distributed Artificial Intelligence Volume II, </booktitle> <pages> pages 3-36. </pages> <publisher> Pitman Publishing: London and Morgan Kaufmann: </publisher> <address> San Mateo, CA. </address>
Reference: <author> Werner, E. </author> <year> (1990). </year> <title> What can agents do together: A semantics of co-operative ability. </title> <booktitle> In Proceedings of the Ninth European Conference on Artificial Intelligence (ECAI-90), </booktitle> <pages> pages 694-701, </pages> <address> Stockholm, Sweden. </address>
Reference: <author> Werner, E. </author> <year> (1991). </year> <title> A unified view of information, intention and ability. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized AI 2 Proceedings of the Second European Workshop on Modelling Autonomous Agents and Multi-Agent Worlds (MAAMAW-90), </booktitle> <pages> pages 109-126. </pages> <publisher> Elsevier Science Publishers B.V.: </publisher> <address> Amsterdam, The Netherlands. </address>
Reference: <author> White, J. E. </author> <year> (1994). </year> <title> Telescript technology: The foundation for the electronic marketplace. White paper, General Magic, </title> <publisher> Inc., </publisher> <address> 2465 Latham Street, Mountain View, CA 94040. </address>
Reference-contexts: For example: mobility is the ability of an agent to move around an electronic network <ref> (White, 1994) </ref>; veracity is the assumption that an agent will not knowingly communicate false inform ation (Galliers, 1988b, pp159-164); benevolence is the assumption that agents do not have conflicting goals, and that every agent will therefore always try to do what is asked of it (Rosenschein and Genesereth, 1985, p91); and <p> Four components have been developed by General Magic to support TELESCRIPT technology. The first is the TELESCRIPT language. This language `is designed for carrying out complex communication tasks: navigation, transportation, authentication, access control, and so on' <ref> (White, 1994, p17) </ref>. The second component is the TELESCRIPT engine. An engine acts as an interpreter for the TELESCRIPT language, maintains places, schedules agents for execu 39 tion, manages communication and agent transport, and finally, provides an interface with other applications. The third component is the TELESCRIPT protocol set.
Reference: <author> Wilkins, D. </author> <year> (1988). </year> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Mor-gan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: See (Georgeff, 1987) for an overview of the state of the art in planning (as it was in 1987), (Allen et al., 1990) for a thorough collection of papers on planning, (many of the papers cited above are included), and <ref> (Wilkins, 1988) </ref> for a detailed description of SIPE, a sophisticated planning system used in a real-world 35 application (the control of a brewery!) Another important collection of planning papers is (Georgeff and Lansky, 1986).
Reference: <author> Wittig, T., </author> <title> editor (1992). ARCHON: An Architecture for Multi-Agent Systems. </title> <publisher> Ellis Horwood: </publisher> <address> Chichester, England. </address>
Reference: <author> Wood, S. </author> <year> (1993). </year> <title> Planning and Decision Making in Dynamic Domains. </title> <publisher> Ellis Horwood: </publisher> <address> Chichester, England. </address>
Reference-contexts: For example: the Integrated Planning, Execution and Monitoring (IPEM) system is based on a sophisticated non-linear planner (Ambros-Ingerson and Steel, 1988); Wood's AUTODRIVE system has planning agents operating in a highly dynamic environment (a traffic simulation) <ref> (Wood, 1993) </ref>; Etzioni has built `softbots' that can plan and act in a UNIX environment (Etzioni et al., 1994); and finally, Cohen's PHEONIX system includes planner-based agents that operate in the domain of simulated forest fire management (Cohen et al., 1989).
Reference: <author> Wooldridge, M. </author> <year> (1992). </year> <title> The Logical Modelling of Computational Multi-Agent Systems. </title> <type> PhD thesis, </type> <institution> Department of Computation, UMIST, Manchester, UK. </institution> <note> (Also available as Technical Report MMU-DOC-94-01, </note> <institution> Department of Computing, Manchester Metropolitan University, Chester St., Manchester, UK). </institution> <note> 61 Wooldridge, </note> <author> M. </author> <year> (1994). </year> <title> Coherent social action. </title> <booktitle> In Proceedings of the Eleventh European Conference on Artificial Intelligence (ECAI-94), </booktitle> <pages> pages 279-283, </pages> <address> Amsterdam, The Neth-erlands. </address>
Reference-contexts: Acknowledgements Much of this paper was adapted from the first author's 1992 PhD thesis <ref> (Wooldridge, 1992) </ref>, and as such this work was supported by the UK Science and Engineering Research Council (now the EPSRC).
Reference: <author> Wooldridge, M. </author> <year> (1995). </year> <title> This is MYWORLD: The logic of an agent-oriented testbed for DAI. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 160-178. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: The problem seems to be that having an intention to act makes it more likely that an agent will act, but does not generally guarantee it. While it seems straightforward to build systems that appear to have intentions, <ref> (Wooldridge, 1995) </ref>, it seems much harder to capture this relationship formally. Other problems that have not yet really been addressed in the literature include the management of multiple, possibly conflicting intentions, and the formation, scheduling, and reconsideration of intentions. <p> A serious attempt to define the semantics of a (somewhat simple) agent architecture is presented in <ref> (Wooldridge, 1995) </ref>, where a formal model of the system MYWORLD, in which agents are directly programmed in terms of beliefs and intentions, is used as the basis upon which to develop a logic for reasoning about MYWORLD systems.
Reference: <author> Wooldridge, M. and Fisher, M. </author> <year> (1992). </year> <title> A first-order branching time logic of multi-agent systems. </title> <booktitle> In Proceedings of the Tenth European Conference on Artificial Intelligence (ECAI-92), </booktitle> <pages> pages 234-238, </pages> <address> Vienna, Austria. </address>
Reference-contexts: Acknowledgements Much of this paper was adapted from the first author's 1992 PhD thesis <ref> (Wooldridge, 1992) </ref>, and as such this work was supported by the UK Science and Engineering Research Council (now the EPSRC).
Reference: <author> Wooldridge, M. and Fisher, M. </author> <year> (1994). </year> <title> A decision procedure for a temporal belief logic. </title> <editor> In Gabbay, D. M. and Ohlbach, H. J., editors, </editor> <booktitle> Temporal Logic Proceedings of the First International Conference (LNAI Volume 827), </booktitle> <pages> pages 317-331. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference: <author> Wooldridge, M. and Jennings, N. R. </author> <year> (1994). </year> <title> Formalizing the cooperative problem solving process. </title> <booktitle> In Proceedings of the Thirteenth International Workshop on Distributed Artificial Intelligence (IWDAI-94), </booktitle> <pages> pages 403-417, </pages> <address> Lake Quinalt, WA. </address>
Reference: <author> Yonezawa, A., </author> <title> editor (1990). ABCL An Object-Oriented Concurrent System. </title> <publisher> The MIT Press: </publisher> <address> Cambridge, MA. </address> <month> 62 </month>
Reference-contexts: The earliest concurrent object framework was Hewitt's Actor model (Hewitt, 1977; Agha, 1986); another well-known example is the ABCL system <ref> (Yonezawa, 1990) </ref>. For a discussion on the relationship between agents and concurrent object programming, see (Gasser and Briot, 1992). Shoham agent-oriented programming Yoav Shoham has proposed a `new programming paradigm, based on a societal view of computation' (Shoham, 1990, p4),(Shoham, 1993).
References-found: 205

