URL: ftp://ftp.cs.wisc.edu/computer-vision/cvgip93-allmen.ps.gz
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Phone: 969 ORG 8351  Phone: (510) 294-1248 FAX: (510) 294-1004  
Title: Dynamic Perceptual Organization Computing Spatiotemporal Relations for Dynamic Perceptual Organization  
Author: Mark Allmen Charles R. Dyer 
Note: The support of the National Science Foundation under Grant Number IRI-9022608 is gratefully ac knowledged.  
Address: P.O. Box  Livermore, CA 94511 Madison, Wisconsin 53706  
Affiliation: Sandia National Laboratories Computer Sciences Department  University of Wisconsin  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. P. Witkin and J. M. Tenenbaum, </author> <title> "On the role of structure in vision," in Human and Machine Vision (J. </title> <editor> Beck, B. Hope, and A. Rosenfeld, eds.), </editor> <address> 481-543, </address> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Rather than focus on recovering quantitative "maps" of intrinsic 3D structure, an alternative approach is to emphasize the goal of perceptual organization, i.e., discovering primitive image relations that group sets of image features into relevant structures <ref> [1, 2, 3] </ref>. The key organizing principle is to find relations that are unlikely to have occurred by accident. For example, proximity, collinearity and parallelism have been used for organizing spatial data [3].
Reference: [2] <author> D. G. Lowe and T. O. Binford, </author> <title> "Perceptual organization as a basis for visual recognition," </title> <booktitle> in Proc. American Assoc. Artificial Intelligence, </booktitle> <pages> pp. 255-260, </pages> <year> 1983. </year>
Reference-contexts: Rather than focus on recovering quantitative "maps" of intrinsic 3D structure, an alternative approach is to emphasize the goal of perceptual organization, i.e., discovering primitive image relations that group sets of image features into relevant structures <ref> [1, 2, 3] </ref>. The key organizing principle is to find relations that are unlikely to have occurred by accident. For example, proximity, collinearity and parallelism have been used for organizing spatial data [3].
Reference: [3] <author> D. G. Lowe, </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1985. </year>
Reference-contexts: Rather than focus on recovering quantitative "maps" of intrinsic 3D structure, an alternative approach is to emphasize the goal of perceptual organization, i.e., discovering primitive image relations that group sets of image features into relevant structures <ref> [1, 2, 3] </ref>. The key organizing principle is to find relations that are unlikely to have occurred by accident. For example, proximity, collinearity and parallelism have been used for organizing spatial data [3]. <p> The key organizing principle is to find relations that are unlikely to have occurred by accident. For example, proximity, collinearity and parallelism have been used for organizing spatial data <ref> [3] </ref>. While Witkin and Tenenbaum suggested using the manner in which objects move as an organizing criterion [4], motion properties have not been used to their full potential in this respect.
Reference: [4] <author> A. P. Witkin, </author> <title> "Scale-space filtering," </title> <booktitle> in Proceedings Int. Joint Conf. Artificial Intelligence, </booktitle> <pages> pp. 1019-1021, </pages> <year> 1983. </year>
Reference-contexts: The key organizing principle is to find relations that are unlikely to have occurred by accident. For example, proximity, collinearity and parallelism have been used for organizing spatial data [3]. While Witkin and Tenenbaum suggested using the manner in which objects move as an organizing criterion <ref> [4] </ref>, motion properties have not been used to their full potential in this respect. As objects and contours move in the scene (i.e., undergo scene motion), their projections into the image also move, generating image or spatiotemporal motion. Over time, these projections sweep out spatiotemporal volumes, surfaces and curves.
Reference: [5] <author> G. Johansson, </author> <title> "Visual perception of biological motion and a model for its analysis," </title> <journal> Perception and Psychophysics, </journal> <volume> 14, </volume> <year> 1973, </year> <pages> 201-211. </pages>
Reference-contexts: The motion of a few points attached to a walking human will usually require a relatively long temporal sequence ("one or two steps" as observed by Johansson <ref> [5] </ref>). Because the necessary interval of time to organize the data is scene dependent, it is important to analyze long image sequences (i.e., on the order of hundreds of frames) in order to handle all situations. <p> This is consistent with psychophysical evidence using moving light displays <ref> [5] </ref>. Historically, image motion has been used in two main ways: (1) to recover structure in the 3D scene, and (2) to recover instantaneous motion in the scene. Scene structure is often represented as the 2 1 2 -D sketch or intrinsic images. <p> In some cases, the dynamic perceptual organization paradigm alone is sufficient for recognition as shown by the human visual system's ability to recognize certain objects and their motion <ref> [5] </ref>. Also, in cases where depth information is unavailable and perceptual organization of static image features is ambiguous, grouping dynamic features based on their spatiotemporal characteristics can be used for recognizing generic high-level motions such as rolling and swinging. <p> Johansson's moving light displays (MLDs) are image sequences containing the motion of a few points of light, produced, for example, by attaching lights to the joints of a person walking in the dark <ref> [5] </ref>. Because each image consists of a few random points of light containing no structure, the perceptual organization of these points and the recognition of the objects is strictly due to the relations between the spatiotemporal curves swept out by the lights. Johansson [5] used MLDs consisting of ten lights to <p> of a person walking in the dark <ref> [5] </ref>. Because each image consists of a few random points of light containing no structure, the perceptual organization of these points and the recognition of the objects is strictly due to the relations between the spatiotemporal curves swept out by the lights. Johansson [5] used MLDs consisting of ten lights to examine human performance at interpreting articulated objects. MLDs were used so that only point motion information 7 Dynamic Perceptual Organization at the joints was available. <p> Therefore, how the HVS perceives these motions can be used to derive additional constraints to solve Eq. (2). Psychologists have long recognized this perceptual phenomenon [27, 28, 29], but have failed to develop a complete model of how the HVS computes relative and common motion <ref> [5, 23] </ref>. One commonality in those models is to minimize the total complexity of the relative and/or common motions [30, 31, 23]. Minimizing the motions can be viewed as making it as simple as possible. Unfortunately, how and what is being minimized has been poorly defined.
Reference: [6] <author> D. Marr and L. Vaina, </author> <title> "Representation and recognition of the movements of shapes," </title> <publisher> MIT AI Memo 597, </publisher> <month> October, </month> <year> 1980. </year>
Reference-contexts: Scene motion computes the motion of points in world coordinates. Only after the objects are recognized are the scene dynamics analyzed by using the scene motion to compute what, if any, high-level motion the objects are undergoing (e.g., walking by a human) <ref> [6, 7, 8] </ref>. This paradigm, which is the Marr approach with motion aspects emphasized, is shown in Figure 1. Note that the recognition of object motion is 4 Dynamic Perceptual Organization up through object recognition, and Motion Models are computed last, after the objects have already been recognized. <p> The four categories are: low-level structure, high-level structure, low-level motion and high-level motion. Low-level structure consists primarily of work that recovers 3D scene structure of rigid parts from image sequences (e.g., structure from motion). High-level structure has dealt with recovering and representing articulated objects <ref> [6, 7, 8] </ref>. However, given some object in an image sequence, all these articulated object representations are better suited to match the scene 8 Dynamic Perceptual Organization structure with a model rather than match the image motion or scene motion with a model. <p> Most of the work that might be considered to address this issue is actually recovering high-level structure and not modelling how objects move in order to recognize their motion <ref> [6, 7, 8] </ref>.
Reference: [7] <author> D. Hogg, </author> <title> "Model-based vision: A program to see a walking person," </title> <journal> Image and Vision Computing, </journal> <volume> 1, </volume> <year> 1983, </year> <pages> 5-20. </pages>
Reference-contexts: Scene motion computes the motion of points in world coordinates. Only after the objects are recognized are the scene dynamics analyzed by using the scene motion to compute what, if any, high-level motion the objects are undergoing (e.g., walking by a human) <ref> [6, 7, 8] </ref>. This paradigm, which is the Marr approach with motion aspects emphasized, is shown in Figure 1. Note that the recognition of object motion is 4 Dynamic Perceptual Organization up through object recognition, and Motion Models are computed last, after the objects have already been recognized. <p> The four categories are: low-level structure, high-level structure, low-level motion and high-level motion. Low-level structure consists primarily of work that recovers 3D scene structure of rigid parts from image sequences (e.g., structure from motion). High-level structure has dealt with recovering and representing articulated objects <ref> [6, 7, 8] </ref>. However, given some object in an image sequence, all these articulated object representations are better suited to match the scene 8 Dynamic Perceptual Organization structure with a model rather than match the image motion or scene motion with a model. <p> Most of the work that might be considered to address this issue is actually recovering high-level structure and not modelling how objects move in order to recognize their motion <ref> [6, 7, 8] </ref>.
Reference: [8] <author> K. Akita, </author> <title> "Image sequence analysis of real world human motion," </title> <journal> Pattern Recognition, </journal> <volume> 17, </volume> <year> 1984, </year> <pages> 73-83. </pages>
Reference-contexts: Scene motion computes the motion of points in world coordinates. Only after the objects are recognized are the scene dynamics analyzed by using the scene motion to compute what, if any, high-level motion the objects are undergoing (e.g., walking by a human) <ref> [6, 7, 8] </ref>. This paradigm, which is the Marr approach with motion aspects emphasized, is shown in Figure 1. Note that the recognition of object motion is 4 Dynamic Perceptual Organization up through object recognition, and Motion Models are computed last, after the objects have already been recognized. <p> The four categories are: low-level structure, high-level structure, low-level motion and high-level motion. Low-level structure consists primarily of work that recovers 3D scene structure of rigid parts from image sequences (e.g., structure from motion). High-level structure has dealt with recovering and representing articulated objects <ref> [6, 7, 8] </ref>. However, given some object in an image sequence, all these articulated object representations are better suited to match the scene 8 Dynamic Perceptual Organization structure with a model rather than match the image motion or scene motion with a model. <p> Most of the work that might be considered to address this issue is actually recovering high-level structure and not modelling how objects move in order to recognize their motion <ref> [6, 7, 8] </ref>.
Reference: [9] <author> J. Aloimonos, </author> <title> "Purposive and qualitative active vision," </title> <booktitle> in Int. Conf. Pattern Recognition, </booktitle> <pages> pp. 346-360, </pages> <year> 1990. </year>
Reference-contexts: The novel aspect of this work is that motion recognition is performed prior to object recognition and prior to recovery of scene structure, and does not require recovery of scene motion. Aloimonos <ref> [9] </ref> made a similar point, that scene structure is not necessarily needed in order to perform certain visual tasks.
Reference: [10] <author> S. Runeson and G. Frykholm, </author> <title> "Visual perception of lifted weight," </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 7, No. 4, </volume> <year> 1981, </year> <month> 733-740. </month> <title> 30 Dynamic Perceptual Organization </title>
Reference-contexts: The results with this display were similar to the results in the first demonstration. Johansson also tested displays for running, cycling, climbing, dancing in couples, various types of gymnastic motion, and others. In all cases adults correctly identified the motion. Runeson <ref> [10] </ref> made MLDs that had points of light not only on the joints of a person but also at the corners of a box that the person was lifting. Observers of this MLD were able to recognize and judge the weight of the box.
Reference: [11] <author> J. Cutting and D. Proffitt, </author> <title> "Gait perception as an example of how we may perceive events," in Intersensory perception and sensory integration (R. </title> <editor> Walk and H. L. Pick, eds.), </editor> <address> 249-273, New York: </address> <publisher> Plenum, </publisher> <year> 1981. </year>
Reference-contexts: The structure could not have been used since the person's structure remained unchanged between displays; it was the motion of the person that varied with the weight of the box. Other studies <ref> [11, 12] </ref> found evidence that adults are capable of recognizing friends and the gender of a person from only the joint motions in MLDs.
Reference: [12] <author> L. MacArther and R. Baron, </author> <title> "Toward an ecological theory of social perception," </title> <journal> Psychological Review, </journal> <volume> 90, </volume> <year> 1983, </year> <pages> 215-238. </pages>
Reference-contexts: The structure could not have been used since the person's structure remained unchanged between displays; it was the motion of the person that varied with the weight of the box. Other studies <ref> [11, 12] </ref> found evidence that adults are capable of recognizing friends and the gender of a person from only the joint motions in MLDs.
Reference: [13] <author> E. S. Spelke, </author> <title> "Origins of visual knowledge," in Visual Cognition and Action, </title> <booktitle> Vol. </booktitle> <address> 2 (D. </address> <publisher> Osherson, </publisher> <editor> S. Kosslyn, and J. Hollerbach, eds.), </editor> <address> 99-127, </address> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: Spelke also showed the importance of motion on object recognition, observing that young infants fail to recognize objects based on static configurational properties, but do apprehend objects by analyzing the motion of cohesive, bounded and spatiotemporally-continuous surfaces <ref> [13] </ref>. Related work on computational visual motion can be classified into four categories according to the type of information recovered from an image sequence. The four categories are: low-level structure, high-level structure, low-level motion and high-level motion.
Reference: [14] <author> K. Gould and M. Shah, </author> <title> "The trajectory primal sketch: A multi-scale scheme for representing motion characteristics," </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 79-85, </pages> <year> 1989. </year>
Reference-contexts: Low-level motion has been primarily concerned with combining image sequences so that viewer-centered changes between frames due to motion in the scene is made explicit (e.g., optical flow). Work on high-level motion is concerned with organizing lower-level motion descriptions. The trajectory primal sketch of Gould and Shah <ref> [14] </ref> does this by organizing the image motion of points into translation, rotation and cycloidal primitive types. Goddard [15] organized a sequence of angular velocity changes of joints into a sequence that represented high-level motions such as walking. <p> Most of the work that might be considered to address this issue is actually recovering high-level structure and not modelling how objects move in order to recognize their motion [6, 7, 8]. Only the work of Gould and Shah <ref> [14] </ref> and Goddard [15] has addressed the issue of robustly interpreting the high-level motion through an image sequence. 3 The Dynamic Perceptual Organization Paradigm The hypothesis of this paper is that it is possible to perceptually organize the image-sequence motion independently of the recovery of scene structure and scene motion. <p> A small number of researchers have argued that it is possible to recognize an object and its high-level motion without first recovering its high-level geometric structure <ref> [17, 16, 18, 14, 15] </ref>. The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object [14]. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence. <p> The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object <ref> [14] </ref>. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence. Similarly shaped flow curves are then grouped together. Specific perceptually-salient features are then detected from groups of flow curves.
Reference: [15] <author> N. H. Goddard, </author> <title> "Recognizing animal motion," </title> <booktitle> in Proc. of Image Understanding Workshop, </booktitle> <pages> pp. 938-944, </pages> <year> 1988. </year>
Reference-contexts: Work on high-level motion is concerned with organizing lower-level motion descriptions. The trajectory primal sketch of Gould and Shah [14] does this by organizing the image motion of points into translation, rotation and cycloidal primitive types. Goddard <ref> [15] </ref> organized a sequence of angular velocity changes of joints into a sequence that represented high-level motions such as walking. <p> Most of the work that might be considered to address this issue is actually recovering high-level structure and not modelling how objects move in order to recognize their motion [6, 7, 8]. Only the work of Gould and Shah [14] and Goddard <ref> [15] </ref> has addressed the issue of robustly interpreting the high-level motion through an image sequence. 3 The Dynamic Perceptual Organization Paradigm The hypothesis of this paper is that it is possible to perceptually organize the image-sequence motion independently of the recovery of scene structure and scene motion. <p> A small number of researchers have argued that it is possible to recognize an object and its high-level motion without first recovering its high-level geometric structure <ref> [17, 16, 18, 14, 15] </ref>. The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object [14]. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence. <p> Specific perceptually-salient features are then detected from groups of flow curves. These perceptual features include, but are not limited to: interactive motion between groups (e.g, occlusion and disocclusion), cyclic motion, and common and relative motion. approaches require high-level models that are rich in temporal information <ref> [15] </ref>. For example, the fundamental event in one of Goddard's scenarios is a change in angular velocity. A scenario becomes active when the correct sequence of these changes occur.
Reference: [16] <author> J. Yamato, J. Ohya, and K. Ishii, </author> <title> "Recognizing human action in time-sequential images using hidden Markov model," </title> <booktitle> in Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 379-385, </pages> <year> 1992. </year>
Reference-contexts: Goddard [15] organized a sequence of angular velocity changes of joints into a sequence that represented high-level motions such as walking. Yamato, Ohya and Ishii <ref> [16] </ref> were able to distinguish a small collection of motions under very controlled conditions by examining the variation of a measure based on the number of black pixels in a thresholded image sequence. <p> A small number of researchers have argued that it is possible to recognize an object and its high-level motion without first recovering its high-level geometric structure <ref> [17, 16, 18, 14, 15] </ref>. The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object [14]. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence.
Reference: [17] <author> R. Polana and R. C. Nelson, </author> <title> "Recognition of motion from temporal texture," </title> <booktitle> in Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 129-134, </pages> <year> 1992. </year>
Reference-contexts: A small number of researchers have argued that it is possible to recognize an object and its high-level motion without first recovering its high-level geometric structure <ref> [17, 16, 18, 14, 15] </ref>. The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object [14]. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence.
Reference: [18] <author> M. Allmen, </author> <title> Image sequence description using spatiotemporal flow curves: Toward motion-based recognition. </title> <type> PhD thesis, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1991. </year> <note> (Available as Computer Sciences Department Technical Report #1040). </note>
Reference-contexts: A small number of researchers have argued that it is possible to recognize an object and its high-level motion without first recovering its high-level geometric structure <ref> [17, 16, 18, 14, 15] </ref>. The image-sequence motion of a few representative points rather than the low-level structure, e.g., rigidity, can be used to recognize an object [14]. Most of these 9 Dynamic Perceptual Organization spatiotemporal surface flow vectors into the paths of points through an image sequence.
Reference: [19] <author> D. Marr, </author> <title> Vision. </title> <address> San Francisco: </address> <publisher> Freeman, </publisher> <year> 1982. </year>
Reference-contexts: We propose that motion should be perceptually organized in a hierarchical representation. We will construct this hierarchy non-purposively, i.e., without depending on high-level models, analogous to the way Marr developed the primal sketch and 2 1 2 sketch <ref> [19] </ref>. image sequence data is given as a three-dimensional spatiotemporal (ST) volume, i.e., an image plane fi time cube of pixels, and the fixed temporal depth of the cube provides a moving temporal window into the infinite "stream" of images.
Reference: [20] <author> M. Allmen and C. R. Dyer, </author> <title> "Computing spatiotemporal surface flow," </title> <booktitle> in Proc. 3rd Int. Conf. Computer Vision, </booktitle> <pages> pp. 47-50, </pages> <year> 1990. </year> <title> 31 Dynamic Perceptual Organization </title>
Reference-contexts: A first step in understanding 10 Dynamic Perceptual Organization the motion in an ST cube is to determine the instantaneous motion of each point in the cube, which we call the spatiotemporal surface flow <ref> [20] </ref>. This is the lowest level in our hierarchy. The next step is to organize the instantaneous motion of points into the long-range motion of each point through the ST cube up to the most recent frame. <p> The temporal component of a vector indicates the speed, as the speed approaches 0, t approaches 1, and as the speed approaches infinity, t approaches 0. ST surface flow can be computed as shown in <ref> [20] </ref> or traditional optical flow fields can be converted into ST surface flow fields. Vectors in an optical flow fields are typically two-dimensional, V = (x; y), with x and y indicating the direction of motion and the length, kVk, indicating the speed. <p> In particular, the computation of the instantaneous motion of points in an ST cube is presented, followed by the recovery and grouping of ST flow curves. Results such as these can then be used for further computations such as the computation of relative and common motion. See <ref> [20] </ref> for more examples of the computation of ST surface flow and see [21] for more results of computing ST flow curves. about a vertical line through the middle of the page at 0.01 radians/frame and a phone book page rotating about its center at 0.01 radians/frames.
Reference: [21] <author> M. Allmen and C. R. Dyer, </author> <title> "Long-range spatiotemporal motion understanding using spatiotemporal flow curves," </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 303-309, </pages> <year> 1991. </year>
Reference-contexts: As additional images become available, the paths of points are extended into the new frames. An ST curve through an ST cube such that the tangent vector at a point on the curve equals the ST surface flow at that point is called a spatiotemporal flow curve <ref> [21] </ref>. This is the next level in our hierarchy. Similarly shaped ST flow curves are then organized into groups so that each group represents a single coherent motion such as translation or rotation. From these groups even higher-level spatiotemporal structures can be organized. <p> From these groups even higher-level spatiotemporal structures can be organized. For example, spatiotemporal interaction between two groups of ST flow curves implies occlusion and disocclusion is occurring <ref> [21] </ref>. Periodic flow curves indicate cyclic motion (common among ambulatory objects) [22]. In addition, the ST flow curves in a group can be decomposed into the relative motion and common motion of the points. <p> Further, similarly shaped ST flow curves, i.e., curves with similar curvature and slope, can be organized into groups using standard clustering techniques and interactions between flow curves (Interactive Motion in Figure 3) can be detected and interpreted. (It was argued by Allmen and Dyer <ref> [21] </ref> that torsion is not necessary to distinguish between different types of motion.) Specifically, a hierarchical clustering algorithm is used to initially cluster the flow curves. Each resulting group then represents a single coherent motion. <p> From these groups of ST flow curves, separate moving objects can be hypothesized, and occlusion and disocclusion between them can be identified by examining how groups merge and split <ref> [21] </ref>. Results of this process are shown in Section 5. Using the groups of ST flow curves, we can now organize the motion into higher-level representations such as the common and relative motion within and between these groups of ST flow curves. <p> Results such as these can then be used for further computations such as the computation of relative and common motion. See [20] for more examples of the computation of ST surface flow and see <ref> [21] </ref> for more results of computing ST flow curves. about a vertical line through the middle of the page at 0.01 radians/frame and a phone book page rotating about its center at 0.01 radians/frames.
Reference: [22] <author> M. Allmen and C. R. Dyer, </author> <title> "Cyclic motion detection using spatiotemporal surfaces and curves," </title> <booktitle> in Proc. 10th Int. Conf. Pattern. Recognition, </booktitle> <pages> pp. 365-370, </pages> <year> 1990. </year>
Reference-contexts: From these groups even higher-level spatiotemporal structures can be organized. For example, spatiotemporal interaction between two groups of ST flow curves implies occlusion and disocclusion is occurring [21]. Periodic flow curves indicate cyclic motion (common among ambulatory objects) <ref> [22] </ref>. In addition, the ST flow curves in a group can be decomposed into the relative motion and common motion of the points. These two motions are equivalent to the relative and common motions that are observable by the human visual system [23]. <p> Sections 3.3 and 3.4 discuss the importance of relative and common motion, and why they are necessary. The importance of cyclic motion will not be discussed further in this paper since it has been described elsewhere <ref> [22] </ref>. Briefly, it is a significant generic spatiotemporal feature because it is characteristic of many natural objects and their 11 Dynamic Perceptual Organization motions. <p> We showed promising results for the early levels of our approach, indicating that the computation of spatiotemporal features and their relations is an important and well-defined step. These results and other work on cyclic motion detection <ref> [22] </ref> show that it is possible to organize the motion through an image sequence independently of scene structure and scene motion. Future work will continue to explore the full potential of this dynamic perceptual organization paradigm. 29 Dynamic Perceptual Organization
Reference: [23] <author> J. E. Cutting and D. R. Proffitt, </author> <title> "The minimum principle and the perception of absolute, common, and relative motions," </title> <journal> Cognitive Psychology, </journal> <volume> 14, </volume> <year> 1982, </year> <pages> 211-246. </pages>
Reference-contexts: In addition, the ST flow curves in a group can be decomposed into the relative motion and common motion of the points. These two motions are equivalent to the relative and common motions that are observable by the human visual system <ref> [23] </ref>. As stated above, this hierarchy includes only bottom-up, i.e., non model-based, aspects. <p> The cycloidal absolute motion is generally not perceived. Even though the absolute cycloidal motion is not perceived, the following equation holds <ref> [23] </ref>: common motion + relative motion = absolute motion (2) For example, we can show how this equation holds for a rolling wheel. <p> Therefore, how the HVS perceives these motions can be used to derive additional constraints to solve Eq. (2). Psychologists have long recognized this perceptual phenomenon [27, 28, 29], but have failed to develop a complete model of how the HVS computes relative and common motion <ref> [5, 23] </ref>. One commonality in those models is to minimize the total complexity of the relative and/or common motions [30, 31, 23]. Minimizing the motions can be viewed as making it as simple as possible. Unfortunately, how and what is being minimized has been poorly defined. <p> Psychologists have long recognized this perceptual phenomenon [27, 28, 29], but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions <ref> [30, 31, 23] </ref>. Minimizing the motions can be viewed as making it as simple as possible. Unfortunately, how and what is being minimized has been poorly defined. The importance of common and relative motions in higher-level representations of motion becomes apparent when examining situations where the absolute motion is distorted.
Reference: [24] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling, </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: However, since F is only defined at coordinate points and must be interpolated at intermediate pixels, the relatively simple Runge-Kutta method <ref> [24, 25] </ref> is appropriate.
Reference: [25] <author> C. W. Gear, </author> <title> Numerical Initial Value Problems in Ordinary Differential Equations. </title> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference-contexts: However, since F is only defined at coordinate points and must be interpolated at intermediate pixels, the relatively simple Runge-Kutta method <ref> [24, 25] </ref> is appropriate.
Reference: [26] <author> P. J. Besl and R. C. Jain, </author> <title> "Invariant surface characteristics for 3D object recognition in range images," </title> <journal> Comp. Vision, Graphics, and Image Proc., </journal> <volume> 33, </volume> <year> 1986, </year> <pages> 33-80. </pages>
Reference-contexts: A separate curve segment, centered at each point, is fit for every point making up a flow curve. This is done using a 1D version of the quadratic surface fitting procedure described by Besl and Jain <ref> [26] </ref>.
Reference: [27] <author> G. Johansson, </author> <title> Configurations in event perception. </title> <publisher> Almqvist & Wiksell, </publisher> <year> 1950. </year>
Reference-contexts: There are no "correct" solutions to Eq. (2), only solutions that are similar to the HVS's perception. Therefore, how the HVS perceives these motions can be used to derive additional constraints to solve Eq. (2). Psychologists have long recognized this perceptual phenomenon <ref> [27, 28, 29] </ref>, but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions [30, 31, 23].
Reference: [28] <author> J. Hochberg, </author> <title> "Effects of the gestalt revolution: The Cornell symposium on perception," </title> <journal> Psychological Review, </journal> <volume> 64, </volume> <year> 1957, </year> <pages> 73-84. </pages>
Reference-contexts: There are no "correct" solutions to Eq. (2), only solutions that are similar to the HVS's perception. Therefore, how the HVS perceives these motions can be used to derive additional constraints to solve Eq. (2). Psychologists have long recognized this perceptual phenomenon <ref> [27, 28, 29] </ref>, but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions [30, 31, 23].
Reference: [29] <author> H. Wallach, </author> <title> "Visual perception of motion," in The nature and art of motion (G. </title> <editor> Kepes, ed.), Braziller, </editor> <year> 1965. </year> <title> (Revised in H. Wallach, </title> <journal> On perception. </journal> <volume> Quadrangle, </volume> <year> 1976). </year>
Reference-contexts: There are no "correct" solutions to Eq. (2), only solutions that are similar to the HVS's perception. Therefore, how the HVS perceives these motions can be used to derive additional constraints to solve Eq. (2). Psychologists have long recognized this perceptual phenomenon <ref> [27, 28, 29] </ref>, but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions [30, 31, 23].
Reference: [30] <author> J. Hochberg and E. McAlister, </author> <title> "A quantitative approach to figural goodness," </title> <journal> Journal of Experimental Psychology, </journal> <volume> 46, </volume> <year> 1953, </year> <pages> 361-364. </pages>
Reference-contexts: Psychologists have long recognized this perceptual phenomenon [27, 28, 29], but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions <ref> [30, 31, 23] </ref>. Minimizing the motions can be viewed as making it as simple as possible. Unfortunately, how and what is being minimized has been poorly defined. The importance of common and relative motions in higher-level representations of motion becomes apparent when examining situations where the absolute motion is distorted.
Reference: [31] <author> J. Hochberg and V. Brooks, </author> <title> "The psychophysics of form: Reversible perspective drawing of spatial objects," </title> <journal> American Journal of Psychology, </journal> <volume> 73, </volume> <year> 1960, </year> <month> 337-354. </month> <title> 32 Dynamic Perceptual Organization </title>
Reference-contexts: Psychologists have long recognized this perceptual phenomenon [27, 28, 29], but have failed to develop a complete model of how the HVS computes relative and common motion [5, 23]. One commonality in those models is to minimize the total complexity of the relative and/or common motions <ref> [30, 31, 23] </ref>. Minimizing the motions can be viewed as making it as simple as possible. Unfortunately, how and what is being minimized has been poorly defined. The importance of common and relative motions in higher-level representations of motion becomes apparent when examining situations where the absolute motion is distorted.
Reference: [32] <author> J. </author> <title> Cutting, "Coding theory adapted to gate perception," </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 7, </volume> <year> 1981, </year> <pages> 71-87. </pages>
Reference-contexts: In order to prevent the two types of throwing from being equivalent, relative spatial information must be incorporated. Cutting showed that relative spatial information is a necessary component of MLDs in order for the HVS to perceive walking <ref> [32] </ref>. He presented subjects with a spatially anomalous "walking" MLD, where the initial positions of the lights were altered while keeping their individual absolute motions correct. None of the subjects detected the walking motion.
Reference: [33] <author> S. Ullman, </author> <title> The Interpretation of Visual Motion. </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press, </publisher> <year> 1979. </year>
Reference-contexts: The most novel aspect of the dynamic perceptual organization paradigm is that scene structure and scene motion are not recovered. In this section we briefly review the work of Ullman <ref> [33] </ref>, Hoffman and Flinchbaugh [34], and Bennett and Hoffman [35] to show the assumptions necessary to recover structure from motion. Given these assumptions about the scene, the image-sequence motion uniquely represents the scene motion. <p> The rigidity assumption states that any set of elements undergoing a spatiotemporal transformation and that has a unique interpretation as a rigid body moving in the scene, should be interpreted as such a body in motion. Ullman <ref> [33] </ref> used this assumption to show: Given three distinct orthographic views of four non-coplanar points in a rigid con figuration, the structure and motion compatible with the three views is uniquely determined up to a reflection about the image plane.
Reference: [34] <author> D. D. Hoffman and B. E. Flinchbaugh, </author> <title> "The interpretation of biological motion," </title> <journal> Biological Cybernetics, </journal> <volume> 42, </volume> <year> 1982, </year> <pages> 195-204. </pages>
Reference-contexts: The most novel aspect of the dynamic perceptual organization paradigm is that scene structure and scene motion are not recovered. In this section we briefly review the work of Ullman [33], Hoffman and Flinchbaugh <ref> [34] </ref>, and Bennett and Hoffman [35] to show the assumptions necessary to recover structure from motion. Given these assumptions about the scene, the image-sequence motion uniquely represents the scene motion. <p> But by making additional assumptions, one can make similar statements about the motion of complex objects and provide a computational model for the HVS's performance at recognizing MLDs. Since the rigidity assumption alone is not sufficient to explain the HVS's performance, Hoffman and Flinchbaugh <ref> [34] </ref> used the planarity assumption in order to reduce the number of points needed to recover scene structure.
Reference: [35] <author> B. M. Bennett and D. D. Hoffman, </author> <title> "The computation of structure from fixed-axis motion: Nonrigid structures," </title> <journal> Biological Cybernetics, </journal> <volume> 51, </volume> <year> 1985, </year> <pages> 293-300. </pages>
Reference-contexts: The most novel aspect of the dynamic perceptual organization paradigm is that scene structure and scene motion are not recovered. In this section we briefly review the work of Ullman [33], Hoffman and Flinchbaugh [34], and Bennett and Hoffman <ref> [35] </ref> to show the assumptions necessary to recover structure from motion. Given these assumptions about the scene, the image-sequence motion uniquely represents the scene motion. <p> Thus it is possible to explain the HVS's performance with MLDs if we believe that the HVS exploits the planarity assumption. Bennett and Hoffman <ref> [35] </ref> made even stronger statements about recovering scene structure.
Reference: [36] <author> J. Aloimonos, </author> <title> "Visual shape computation," </title> <journal> Proc. IEEE, </journal> <volume> 76, </volume> <year> 1988, </year> <pages> 899-916. 33 </pages>
Reference-contexts: This is guaranteed to be the case because p 1 (i) specifies only one scene configuration. Perhaps even more important than being unnecessary, the recovery of scene structure and scene motion is also undesirable. This is because the process, even when well-posed, is unstable because of non-linear constraints <ref> [36] </ref>. In practice, since ST flow curves are noisy, using them or any recovered image motion representation will result in very noisy computed scene structure and scene motion. Therefore, rather than use this unstable process, we believe it should be avoided altogether. <p> Therefore, rather than use this unstable process, we believe it should be avoided altogether. It is possible to avoid it because the image-sequence motion uniquely represents the scene. Alternatively, one could use an "active observer" approach and make the problem stable <ref> [36] </ref>, but, again, this is unnecessary for the reasons stated above. 5 Results In this section we show computational results for the first steps of our dynamic perceptual organization approach.
References-found: 36

