URL: http://www.isi.edu/teamcore/tambe/papers/95/AT/final3.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Title: EVENT TRACKING IN A DYNAMIC MULTI-AGENT ENVIRONMENT  
Author: Milind Tambe and Paul S. Rosenbloom 
Keyword: Key words: Event tracking, plan recognition, multi-agent systems, real-time performance, real-world applications  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292, USA  
Affiliation: Information Sciences Institute, University of Southern California,  
Date: 1995  
Note: Computational Intelligence, Volume Number (To appear),  
Abstract: In a dynamic, multi-agent environment, an automated intelligent agent is often faced with the possibility that other agents may instigate events that hinder or help the achievement of its own goals. To act intelligently in such an environment, an automated agent needs an event tracking capability to continually monitor the occurrence of such events and the temporal relationships among them. This capability enables an agent to infer the occurrence of important unobserved events as well as to obtain a better understanding of the interaction among events. This paper focuses on event tracking in one complex and dynamic multi-agent environment: the air-combat simulation environment. It analyzes the challenges that an automated pilot agent must face when tracking events in this environment. This analysis reveals three new issues that have not been addressed in previous work in this area: (i) tracking events generated by agents' flexible and reactive behaviors, (ii) tracking events in the context of continuous agent interactions, and (iii) tracking events in real-time. The paper proposes one solution to address these issues. One key idea in this solution is that the (architectural) mechanisms that an agent employs in generating its own flexible and reactive behaviors can be used to track other agents' flexible and reactive behaviors in real-time. A second key idea is the use of a world-centered representation for modeling agent interactions. The solution is demonstrated using an implementation of an automated pilot agent. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. </author> <year> 1983. </year> <title> Maintaining knowledge about temporal intervals. </title> <journal> Communications of the ACM 26(11). </journal>
Reference: <author> Anderson, J. R., C. F. Boyle, A. T. Corbett and M. W. </author> <booktitle> Lewis 1990. Cognitive modeling and intelligent tutoring. Artificial Intelligence 42 </booktitle> <pages> 7-49. </pages>
Reference: <author> Azarewicz, J., G. Fala, R. Fink and C. </author> <month> Heithecker </month> <year> 1986. </year> <title> Plan recognition for airborne tactical decision making. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 805-811. </pages> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference-contexts: In particular, in previous investigations in the related areas of plan/situation recognition (Kautz & Allen 1986; Song & Cohen 1991; Dousson, Gaborit, & Ghallab 1993; Van Beek & Cohen 1991; Carberry 1990a) | including one investigation focused on plan recognition in airborne tactical decision making <ref> (Azarewicz et al. 1986) </ref> | these issues have not been addressed. With regard to the first two issues, plan recognition models have not been applied in such dynamic, interactive multi-agent situations, and hence do not address strong interactions among agents or the resulting flexibility and reactivity in agent behaviors.
Reference: <author> Ballard, D. </author> <year> 1989. </year> <title> Reference frames for animate vision. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: In employing an active resolution strategy, AP's event tracking resembles an active vision system <ref> (Ballard 1989) </ref>, that can take actions, such as moving cameras to get closer to objects or changing focus, to simplify the computation required in early vision.
Reference: <author> Bates, J., A. B. Loyall and W. S. </author> <title> Reilly 1992. Integrating reactivity, goals and emotions in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: While this approach was introduced in the context of air-combat simulation, we expect it to generalize to other competitive or collaborative real-time, dynamic multi-agent environments, including music synthesis (for intelligent accompaniment), game playing, entertainment <ref> (Bates, Loyall, & Reilly 1992) </ref>, and education (Ward 1991). The article also outlined several unresolved issues. One important issue is robustness in the face of unknown events. As mentioned earlier, the system needs to improve its tracking capability in such situations.
Reference: <author> Calder, R. B., J. E. Smith, A. J. Courtemanche, J. M. F. Mar and A. Z. </author> <month> Cer-anowicz </month> <year> 1993. </year> <title> Modsaf behavior simulation and control. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle>
Reference-contexts: Consider the following example from the domain of simulated tactical air-combat (Tambe et al. 1995). This domain is based on a real-world simulator that has been commercially developed for the military <ref> (Calder et al. 1993) </ref>. The automated agents are to act as automated pilots for the simulated aircraft in this domain. These automated pilots will take part in exercises with human fighter pilots, where they will aid in tactics development and training.
Reference: <author> Carberry, S. </author> <year> 1990a. </year> <title> Incorporating default inferences into plan recognition. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> 471-478. </pages>
Reference: <author> Carberry, S. </author> <year> 1990b. </year> <title> Plan Recognition in Natural Language Dialogue. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Decker, K. and V. </author> <title> Lesser 1993. Quantitative modeling of complex computational task environments. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligenence. </booktitle>
Reference-contexts: The shift from self-centered and opponent-centered problem-spaces to a WCPS is related to the objective framework used in simulation and analysis of DAI systems <ref> (Decker & Lesser 1993) </ref>, which describes the essential, "real" situation in the world. However, the focus of our work is on an individual agent using its own world-centered model for event-tracking.
Reference: <author> Dousson, C., P. Gaborit and M. </author> <month> Ghallab </month> <year> 1993. </year> <title> Situation recognition: Representation and algorithms. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> 166-172. </pages>
Reference-contexts: The approach presented in this article avoids such an enumeration. With regard to the issue of tracking events in real-time, this has not been the focus of previous work in plan/situation recognition. There is some work that is beginning to address this issue <ref> (Dousson, Gaborit, & Ghallab 1993) </ref>, although it does not as yet deal with complex agent behaviors. Thus, researchers working on plan-recognition have not dealt with such interactive, real-time, multi-agent situations. There are, however, two other sub-areas of AI that have dealt with such situations.
Reference: <author> Durfee, E. H. and V. R. </author> <title> Lesser 1988. Using Partial Global Plans to Coordinate Distributed Problem Solvers. </title> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Thus, researchers working on plan-recognition have not dealt with such interactive, real-time, multi-agent situations. There are, however, two other sub-areas of AI that have dealt with such situations. The first such sub-area is Distributed AI (DAI). There is some work in DAI on understanding other agents' plans (e.g., see <ref> (Durfee & Lesser 1988) </ref>). However, it focuses on agents exchanging their plan data structures for active cooperation, rather than on plan recognition. The second sub-area is game playing. Game trees clearly deal with interactive situations, and they also model an opponent's actions in such situations.
Reference: <author> Gmytrasiewicz, P. J., E. H. Durfee and D. K. </author> <title> Wehe 1991. A decision theoretic approach to co-ordinating multi-agent interactions. </title> <booktitle> In Proceedings of International Joint Conference on Event Tracking in a Dynamic Multi-agent Environment 25 Artificial Intelligence. </booktitle>
Reference: <author> Hanks, S., M. E. Pollack and P. R. </author> <title> Cohen 1993. Benchmarks, test beds, controlled experimentation, and the design of agent architectures. </title> <journal> AI Magazine 14(4) </journal> <pages> 17-42. </pages>
Reference-contexts: Dealing with such novel maneuvers is a topic for future work. The second question above was related to understanding the effect of the current approach in improving AP's overall performance. It is difficult to evaluate the overall performance of a complex intelligent agent like AP <ref> (Hanks, Pollack, & Cohen 1993) </ref>. Obtaining quantitative estimates of the contribution of one of AP's component capabilities (such as event tracking) can prove to be even more difficult. Nonetheless, we can at least understand some of the types of benefits that AP accrues from its event tracking capability.
Reference: <author> Hill, R. and W. L. </author> <title> Johnson 1993. Impasse-driven tutoring for reactive skill acquisition. </title> <booktitle> In Proceedings of the Conference on Intelligent Computer-aided Training and Virtual Environment Technology. </booktitle>
Reference-contexts: The approach proposed here for event tracking is thus based on this model tracing work. However, there are some significant differences. For example, previous work has primarily focused on static, single-agent environments, where the agent being modeled is the only one causing changes in the environment <ref> (Hill & Johnson 1993) </ref>. However, before exploring these differences further, it is first useful to understand AP's event tracking in more detail. This is explained below, using the illustration of the multiple problem space hierarchies in Figure 4. <p> The first is dealing with ambiguity, which we have discussed in detail in the previous Event Tracking in a Dynamic Multi-agent Environment 15 section. The second is tracking an agent's detailed actions. As Hill and Johnson <ref> (Hill & Johnson 1993) </ref> have recently argued, detailed actions may overwhelm an agent with tracking overheads. This can be particularly problematical for AP, since this may disallow it from acting in real-time. AP faces this problem due to the dynamic and realistic nature of its environment.
Reference: <author> Johnson, W. L. </author> <year> 1994. </year> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Seattle, WA: Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference-contexts: Without an understanding of this situation, this type of switching of AP's attack may not be possible. Event Tracking in a Dynamic Multi-agent Environment 23 3. Event tracking helps in providing a better explanation: An explanation capability, for explaining AP's decisions to human experts, is currently under development <ref> (Johnson 1994) </ref>. This capability is to be used by the domain experts to understand AP's decision making process. If AP is seen to perform its task without tracking events appropriately, domain experts will not have sufficient confidence in its capabilities to actually use it for training or tactics development. 6.
Reference: <author> Jones, R., J. E. Laird, M. Tambe and P. S. </author> <title> Rosenbloom 1994. Generating behavior in response to interacting goals. </title> <booktitle> In Proceedings of the Fourth Conference on Computer Generated Forces and Behavioral Representation. </booktitle> <address> Orlando, Florida: </address> <institution> Institute for Simulation and Training, University of Central Florida. </institution>
Reference-contexts: generated a copy of these operators 2 Since the submission of this article, we have addressed this issue in (Tambe & Rosenbloom 1995). 3 There is on-going research on determining whether/how the Soar architecture can support a WCPS and this may impact the final implementation of event tracking in TacAir-Soar <ref> (Jones et al. 1994) </ref>. 20 Computational Intelligence 1. Create an initial state opponent using WCPS. 2. Create an operator opponent hierarchy based on the existing state opponent , while using ambiguity resolution strategies and approximation filters. 3.
Reference: <author> Katz, A. </author> <year> 1993. </year> <title> Intelligent player first principle foundations. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle> <address> Orlando, Florida: </address> <institution> Institute for Simulation and Training, University of Central Florida. </institution>
Reference-contexts: To avoid similar problems with modeling complex missile aero-dynamics, only a simple gun is modeled. This simple gun considerably simplifies the evaluation function. (A detailed list of idealizations appears in <ref> (Katz 1993) </ref>.) Given these idealizations, game-tree techniques appear impractical, at least at present, for event tracking in air-combat simulations. 3. A SOLUTION FOR EVENT TRACKING The proposed solution for event tracking is based on a core idea that addresses the issue of tracking flexible and reactive behaviors.
Reference: <author> Kautz, A. and J. F. </author> <title> Allen 1986. Generalized plan recognition. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 32-37. </pages> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference-contexts: This is similar 18 Computational Intelligence to the assumption in the plan recognition literature: the agent that is recognizing a plan is assumed to have full knowledge of all of the plans that the planning agent can execute <ref> (Kautz & Allen 1986) </ref>. We return to this assumption in Section 5. The third assumption was that AP can generate an accurate state opponent . While at first this seems like a highly problematical assumption, there are several ways in which this problem is simplified.
Reference: <author> Laird, J. E. and P. S. </author> <title> Rosenbloom 1990. Integrating execution, planning, and learning in soar for external environments. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Later, the STOP-TURN operator is applied to stop the aircraft's turn when it reaches its required heading. This operator organization supports AP's flexible and reactive behaviors, given Soar's architectural mechanisms for operator selection and termination <ref> (Laird & Rosen-bloom 1990) </ref>. For instance, there is a global state shared by all of the problem spaces. If this state changes so that the termination conditions of any of the operators in the operator hierarchy are achieved, then that operator can be terminated. <p> Thus, if the opponent simply begins to run away as AP is attempting to apply the EMPLOY-MISSILE operator, then this operator may be terminated, and its subgoals will be automatically deleted. The CHASE-OPPONENT operator may be selected instead. There are other mechanisms adding to AP's reactivity as well <ref> (Laird & Rosenbloom 1990) </ref>. Since all of the above operators are used in the generation of AP's own actions, they will be henceforth denoted using the subscript own. For instance, EMPLOY-MISSILE own will denote the operator AP uses in employing a missile.
Reference: <author> McDermott, D., and E. </author> <title> Davis 1984. Planning routes through uncertain territory. </title> <booktitle> Artificial Intelligence 22 </booktitle> <pages> 107-156. </pages>
Reference-contexts: One simple filter is to ignore any changes in the opponent's heading of less than three degrees, to compensate for the small errors in AP's perception of the opponent's heading. A second simple filter is the use of the fuzz-box approximation <ref> (McDermott & Davis 1984) </ref>. A fuzz-box indicates AP's tolerance for deviations in a given quantity, such as heading, altitude, speed, etc. For instance, for the opponent's pointing maneuver, where the opponent points at AP to fire a missile, the fuzz-box accepts five degrees of deviation.
Reference: <author> Rosenbloom, P. S., J. E. Laird, A. Newell and R. </author> <month> McCarl </month> <year> 1991. </year> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence 47(1-3):289-325. </journal>
Reference: <author> Schaper, G. A., S. Pandari and M. </author> <title> Singh 1994. Lookahead limits for intelligent player. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle> <address> Orlando, Florida: </address> <institution> Institute for Simulation and Training, University of Central Florida. </institution>
Reference: <author> Shapiro, S. C. and W. J. </author> <title> Rapaport 1991. Models and minds: knowledge representation for natural language competence. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The specific idea of avoiding duplicate representation of an object in state own and state opponent , is similar to a key feature of the SNePS belief modeling framework <ref> (Shapiro & Rapaport 1991) </ref>. In SNePS, the models of different agents' belief spaces may share the representation of an object and thus avoid duplication. WCPS extends this sharing to dynamic environments, so as to avoid the cost of updates, and harnesses the sharing in service of event tracking. 4.4.
Reference: <author> Song, F. and R. </author> <title> Cohen 1991. Temporal reasoning during plan recognition. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference-contexts: However, neither the recognizing agent, nor any other agents in the environment are assumed to have any influence on these plans. Consequently, these plan recognition models can rely on pre-compiled plan libraries, where each plan lists the sequence of events and the temporal relationships among the events <ref> (Song & Cohen 1991) </ref>. The representation of a plan in such a library is similar to the explicit representation of an event in terms of an enumeration of its subevents and their temporal relationships. A plan library represents the entire class of events of interest in this fashion.
Reference: <author> Tambe, M. and P. S. </author> <title> Rosenbloom 1995. Resc: An approach to agent tracking in a real-time, dynamic environment. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). </booktitle>
Reference-contexts: This information is essential for reacting intelligently to the on-going events, particularly since it enables an agent to infer the occurrence of important unobserved events. Consider the following example from the domain of simulated tactical air-combat <ref> (Tambe et al. 1995) </ref>. This domain is based on a real-world simulator that has been commercially developed for the military (Calder et al. 1993). The automated agents are to act as automated pilots for the simulated aircraft in this domain. <p> Section 4 presents important refinements to this basic idea that address agent interactions, and enable real-time event tracking. The resulting approach is demonstrated using an implementation of an automated pilot agent for air-combat simulation. This automated pilot is based on a system called TacAir-Soar <ref> (Tambe et al. 1995) </ref>, which has been developed within Soar, an integrated problem-solving and learning architecture (Laird & Rosenbloom 1990; Rosenbloom et al. 1991). This implementation and its results are discussed in Section 5. Finally, Section 6 presents a summary and issues for future work. 2. <p> To create this variant, we started with the operators that are used by the original TacAir-Soar system. Based on our current assumption regarding similarity of pilots' behaviors, we then generated a copy of these operators 2 Since the submission of this article, we have addressed this issue in <ref> (Tambe & Rosenbloom 1995) </ref>. 3 There is on-going research on determining whether/how the Soar architecture can support a WCPS and this may impact the final implementation of event tracking in TacAir-Soar (Jones et al. 1994). 20 Computational Intelligence 1. Create an initial state opponent using WCPS. 2.
Reference: <author> Tambe, M., W. L. Johnson, R. Jones, F. Koss, J. E. Laird, P. S. Rosenbloom and K. </author> <month> Schwamb </month> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16(1). </journal>
Reference-contexts: This information is essential for reacting intelligently to the on-going events, particularly since it enables an agent to infer the occurrence of important unobserved events. Consider the following example from the domain of simulated tactical air-combat <ref> (Tambe et al. 1995) </ref>. This domain is based on a real-world simulator that has been commercially developed for the military (Calder et al. 1993). The automated agents are to act as automated pilots for the simulated aircraft in this domain. <p> Section 4 presents important refinements to this basic idea that address agent interactions, and enable real-time event tracking. The resulting approach is demonstrated using an implementation of an automated pilot agent for air-combat simulation. This automated pilot is based on a system called TacAir-Soar <ref> (Tambe et al. 1995) </ref>, which has been developed within Soar, an integrated problem-solving and learning architecture (Laird & Rosenbloom 1990; Rosenbloom et al. 1991). This implementation and its results are discussed in Section 5. Finally, Section 6 presents a summary and issues for future work. 2. <p> To create this variant, we started with the operators that are used by the original TacAir-Soar system. Based on our current assumption regarding similarity of pilots' behaviors, we then generated a copy of these operators 2 Since the submission of this article, we have addressed this issue in <ref> (Tambe & Rosenbloom 1995) </ref>. 3 There is on-going research on determining whether/how the Soar architecture can support a WCPS and this may impact the final implementation of event tracking in TacAir-Soar (Jones et al. 1994). 20 Computational Intelligence 1. Create an initial state opponent using WCPS. 2.
Reference: <author> Tambe, M. </author> <year> 1995. </year> <title> Recursive agent and agent-group tracking in a real-time dynamic environment. </title> <booktitle> In Proceedings of the International Conference on Multi-agent systems (ICMAS). </booktitle>
Reference-contexts: This information is essential for reacting intelligently to the on-going events, particularly since it enables an agent to infer the occurrence of important unobserved events. Consider the following example from the domain of simulated tactical air-combat <ref> (Tambe et al. 1995) </ref>. This domain is based on a real-world simulator that has been commercially developed for the military (Calder et al. 1993). The automated agents are to act as automated pilots for the simulated aircraft in this domain. <p> Section 4 presents important refinements to this basic idea that address agent interactions, and enable real-time event tracking. The resulting approach is demonstrated using an implementation of an automated pilot agent for air-combat simulation. This automated pilot is based on a system called TacAir-Soar <ref> (Tambe et al. 1995) </ref>, which has been developed within Soar, an integrated problem-solving and learning architecture (Laird & Rosenbloom 1990; Rosenbloom et al. 1991). This implementation and its results are discussed in Section 5. Finally, Section 6 presents a summary and issues for future work. 2. <p> To create this variant, we started with the operators that are used by the original TacAir-Soar system. Based on our current assumption regarding similarity of pilots' behaviors, we then generated a copy of these operators 2 Since the submission of this article, we have addressed this issue in <ref> (Tambe & Rosenbloom 1995) </ref>. 3 There is on-going research on determining whether/how the Soar architecture can support a WCPS and this may impact the final implementation of event tracking in TacAir-Soar (Jones et al. 1994). 20 Computational Intelligence 1. Create an initial state opponent using WCPS. 2.
Reference: <author> Van Beek, P. and R. </author> <title> Cohen 1991. Resolving plan ambiguity for cooperative response generation. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <pages> 938-944. </pages>
Reference: <author> Ward, B. </author> <year> 1991. </year> <title> ET-Soar: Toward an ITS for Theory-Based Representations. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Science, Carnegie Mellon Univ. </institution>
Reference-contexts: Suggested solutions for addressing ambiguity typically address the representational aspect of this issue, but not the other two. In particular, one method of addressing the ambiguity is to maintain multiple operator hierarchies, so as to track each possibility independently <ref> (Ward 1991) </ref>. Thus, if there is some ambiguity about whether the opponent is actually executing RUN-AWAY opponent or EMPLOY-MISSILE opponent , then there are two separate operator hierarchies maintained for the two possibilities. <p> While this approach was introduced in the context of air-combat simulation, we expect it to generalize to other competitive or collaborative real-time, dynamic multi-agent environments, including music synthesis (for intelligent accompaniment), game playing, entertainment (Bates, Loyall, & Reilly 1992), and education <ref> (Ward 1991) </ref>. The article also outlined several unresolved issues. One important issue is robustness in the face of unknown events. As mentioned earlier, the system needs to improve its tracking capability in such situations.
Reference: <author> Wilks, Y. and A. </author> <title> Ballim 1987. Multiple agents and hueristic ascription of belief. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence. </booktitle>
References-found: 30

