URL: http://www.icsi.berkeley.edu/~fosler/papers/fingers.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/~fosler/papers/
Root-URL: http://www.icsi.berkeley.edu
Title: Using Orientation Histograms for Hand Gesture Recognition  CS280 Class Project  
Author: Eric Fosler Peter Neuhaus 
Degree: Professor Malik  
Date: May 11, 1995  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Bourlard and N. Morgan. </author> <title> Connectionist Speech Recognition: A Hybrid Approach. </title> <publisher> Kluwer Press, </publisher> <year> 1993. </year>
Reference: [2] <author> Sid S. Fels and Geoffrey E. Hinton. Glove-talk: </author> <title> A neural network interface between a data-glove and a speech synthesizer. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(1), </volume> <year> 1995. </year>
Reference-contexts: 1 Introduction Hand gestures can provide a rich command language for directing a computer to perform tasks, play games, create music, synthesize speech <ref> [2] </ref>, or perform other tasks. Many of the systems which currently perform these tasks have the unfortunate disadvantage of requiring specialized hardware. Given the rise of multimedia and teleconferencing applications, a vision-based approach to recognizing hand gestures will be very important in the near future.
Reference: [3] <author> William T. Freeman and Edward H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9), </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Our gesture recognition systems do not currently run in real-time. While the classification part of the algorithm is very fast 2 , our MATLAB filter implementation takes about 2-5 minutes to calculate the features. In future implementations, we would like to use steerable filters <ref> [3] </ref>, which will save considerably on computation. Freeman and Roth [4] use steerable filters and smooth the histogram output, the orientations are divided into 36 bins for pattern classification. Using this representation, they are able to get real-time performance using a clustered minimum-distance classifier.
Reference: [4] <author> William T. Freeman and Michal Roth. </author> <title> Orientation histograms for hand gesture recognition. </title> <booktitle> In International Workshop On Automatic Face And Gesture Recognition, </booktitle> <address> June 1995. Zurich, Switzerland. </address> <note> To appear. </note>
Reference-contexts: Given the rise of multimedia and teleconferencing applications, a vision-based approach to recognizing hand gestures will be very important in the near future. In this work, we attempt to replicate the work of Freeman and Roth <ref> [4] </ref> and to create a recognition system for pointing directions using several pattern recognition techniques. We also extend their work to several letters of the Signed English alphabet, and show that orientation histogram features are discriminable for at least five letters of the alphabet. <p> We decided to use a simplified version of orientation histograms, proposed by Freeman and Roth <ref> [4] </ref>. In our scheme, we filter the images with a bank of n filters oriented at n ; 2 degrees 1 . A sample image and the results of a bank of n = 8 oriented edge-detecting filters can be seen in Figure 1. <p> While the classification part of the algorithm is very fast 2 , our MATLAB filter implementation takes about 2-5 minutes to calculate the features. In future implementations, we would like to use steerable filters [3], which will save considerably on computation. Freeman and Roth <ref> [4] </ref> use steerable filters and smooth the histogram output, the orientations are divided into 36 bins for pattern classification. Using this representation, they are able to get real-time performance using a clustered minimum-distance classifier.
Reference: [5] <author> Thad Starner and Alex Pentland. </author> <title> Visual recognition of american sign language using hidden markov models. </title> <type> Technical report, </type> <institution> Media Lab, Massachusetts Institute of Technology, 1995. MIT Media Lab TR#306. </institution> <month> 5 </month>
Reference-contexts: We also extend their work to several letters of the Signed English alphabet, and show that orientation histogram features are discriminable for at least five letters of the alphabet. This work is similar to the American Sign Language recognition work of Starner and Pentland <ref> [5] </ref>, although the scope is more limited; however, we do not require that the signers wear specially marked gloves. 2 Orientation Histograms In order to use pattern classification techniques, we must first determine a feature vector for each image.
References-found: 5

