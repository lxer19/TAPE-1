URL: http://www.isi.edu/soar/galk/Publications/99/isisaij.ps.gz
Refering-URL: http://www.isi.edu/soar/galk/Publications/
Root-URL: http://www.isi.edu
Email: robocup-sim@isi.edu  
Phone: Tel: 310-822-1511  
Title: Building Agent Teams Using an Explicit Teamwork Model and Learning  
Author: Milind Tambe, Jafar Adibi, Yaser Al-Onaizan, Ali Erdem Gal A. Kaminka, Stacy C. Marsella, Ion Muslea 
Date: December 9, 1998  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292, USA  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: Multi-agent collaboration or teamwork and learning are two critical research challenges in a large number of multi-agent applications. These research challenges are highlighted in RoboCup, an international project focused on robotic and synthetic soccer as a common testbed for research in multi-agent systems. This article describes our approach to address these challenges, based on a team of soccer-playing agents built for the simulation league of RoboCup | the most popular of the RoboCup leagues so far. To address the challenge of teamwork, we investigate a novel approach based on the (re)use of a domain-independent, explicit model of teamwork, an explicitly represented hierarchy of team plans and goals, and a team organization hierarchy based on roles and role-relationships. This general approach to teamwork, shown to be applicable in other domains beyond RoboCup, both reduces development time and improves teamwork flexibility. We also demonstrate the application of off-line and on-line learning to improve and specialize agents' individual skills in RoboCup. These capabilities enabled our soccer-playing team, ISIS, to successfully participate in the first international RoboCup soccer tournament (RoboCup'97) held in Nagoya, Japan, in August 1997. ISIS won the third-place prize in over 30 teams that participated in the simulation league. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. F. Bersano-Begey, P. G. Kenny, and E. H. Durfee. </author> <title> Agent teamwork, adaptive learning, and adversarial planning in robocup using a prs architecture. In RoboCup-97: The first robot world cup soccer games and conferences. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1998. </year>
Reference-contexts: Their agents synchronize their individual beliefs periodically in a fixed manner, in contrast with ISIS's STEAM in which communications are issued dynamically and can be parameterized based on the domain of deployment. Another RoboCup effort focusing on explicit team plans and roles is <ref> [1] </ref>. They define levels of teamwork, starting at basic roles (which are static throughout the game), and building on top of those with formations and team plans for carrying out more complex tactics. These teamwork levels determine the agent's coordination responsibilities and prioritize its actions.
Reference: [2] <author> S. Ch'ng and L. Padgham. </author> <title> Team description: Royal merlbourne knights. In RoboCup-97: The first robot world cup soccer games and conferences. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1998. </year>
Reference-contexts: Some researchers investigating teamwork in RoboCup have used explicit team plans and roles, but they have relied on domain-dependent communication and coordination. A typical example includes work by Ch'ng and Padgham <ref> [2] </ref>. They present an elaborate analysis of roles in motivating teamwork and team plans. In this scheme, agents dynamically adopt and abandon roles in pre-defined tactics. The responsibilities and actions of each agent are determined by its current role in the current plan.
Reference: [3] <author> P. R. Cohen and H. J. Levesque. </author> <title> Teamwork. </title> <journal> Nous, </journal> <volume> 35, </volume> <year> 1991. </year>
Reference-contexts: Second, STEAM provides an explicit teamwork model, attempting to enhance teamwork flexibility, by providing agents abilities to autonomously reason about coordination and communication in teamwork. In STEAM, the teamwork model is based both on the joint intentions theory <ref> [3, 16] </ref> and the SharedPlans theory [7, 6, 8], but with key enhancements to reflect the constraints of real-world domains. The article discusses in detail STEAM's contribution in building RoboCup teams. <p> In essence, it attempts to provide agents with commonsense knowledge of teamwork, that would enable them to autonomously reason about coordination and communication in teamwork. Thus, it aims to substantially reduce the encoding effort, and improve teamwork flexibility. STEAM uses the joint intentions theory <ref> [16, 3] </ref> as the basic building block of teamwork, but it is also strongly influenced by the SharedPlans theory [7, 8], and constraints realized in practical applications.
Reference: [4] <author> T. Dean, K. Basye, and J. Skewchuk. </author> <title> Reinforcement learning for planning and control. </title> <booktitle> In Machine Learning Methods for Planning, </booktitle> <pages> pages 67-92. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Francisco, </address> <year> 1993. </year>
Reference-contexts: We have taken a different approach, driven by the question as to what would happen if players could learn their intercept plans themselves and what would that learning tell us. To that end, we are exploring a reinforcement learning <ref> [28, 4] </ref> approach whereby players can adapt their intercept online, under actual playing conditions using just the perceptual input provided by the RoboCup'97 server to the player: the ball's current direction, change in direction, distance.
Reference: [5] <author> J. Firby. </author> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <year> 1987. </year>
Reference-contexts: Once operators are selected for execution, they are executed by the application rules. If the agent's current beliefs match an operator's termination rules, then the operator terminates. Agents built in other architectures such as PRS [10], BB1 [9], RAP <ref> [5] </ref> for dynamic domains may be similarly characterized in this fashion. The key here is that in a dynamic domain such as Robocup, the operator selection, execution and termination may be heavily dependent on the current state of the environment as perceived by the individual agent.
Reference: [6] <author> B. Grosz. </author> <title> Collaborating systems. </title> <journal> AI magazine, </journal> <volume> 17(2), </volume> <year> 1996. </year>
Reference-contexts: Second, STEAM provides an explicit teamwork model, attempting to enhance teamwork flexibility, by providing agents abilities to autonomously reason about coordination and communication in teamwork. In STEAM, the teamwork model is based both on the joint intentions theory [3, 16] and the SharedPlans theory <ref> [7, 6, 8] </ref>, but with key enhancements to reflect the constraints of real-world domains. The article discusses in detail STEAM's contribution in building RoboCup teams. It also discusses the difficulties we have faced in applying STEAM in RoboCup, and thus points to areas of future work.
Reference: [7] <author> B. Grosz and S. Kraus. </author> <title> Collaborative plans for complex group actions. </title> <journal> Artificial Intelligence, </journal> <volume> 86 </volume> <pages> 269-358, </pages> <year> 1996. </year>
Reference-contexts: Second, STEAM provides an explicit teamwork model, attempting to enhance teamwork flexibility, by providing agents abilities to autonomously reason about coordination and communication in teamwork. In STEAM, the teamwork model is based both on the joint intentions theory [3, 16] and the SharedPlans theory <ref> [7, 6, 8] </ref>, but with key enhancements to reflect the constraints of real-world domains. The article discusses in detail STEAM's contribution in building RoboCup teams. It also discusses the difficulties we have faced in applying STEAM in RoboCup, and thus points to areas of future work. <p> Thus, it aims to substantially reduce the encoding effort, and improve teamwork flexibility. STEAM uses the joint intentions theory [16, 3] as the basic building block of teamwork, but it is also strongly influenced by the SharedPlans theory <ref> [7, 8] </ref>, and constraints realized in practical applications. The tie between the teamwork model and the previously discussed team operators is as follows: when executing (sub)team operators, agents bring to bear all of the teamwork reasoning of a general teamwork model, which facilitates their communication and coordination.
Reference: [8] <author> B. J. Grosz and C. L. Sidner. </author> <title> Plans for discourse. </title> <editor> In P. R. Cohen, J. Morgan, and M. Pollack, editors, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 417-445. </pages> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference-contexts: Second, STEAM provides an explicit teamwork model, attempting to enhance teamwork flexibility, by providing agents abilities to autonomously reason about coordination and communication in teamwork. In STEAM, the teamwork model is based both on the joint intentions theory [3, 16] and the SharedPlans theory <ref> [7, 6, 8] </ref>, but with key enhancements to reflect the constraints of real-world domains. The article discusses in detail STEAM's contribution in building RoboCup teams. It also discusses the difficulties we have faced in applying STEAM in RoboCup, and thus points to areas of future work. <p> Thus, it aims to substantially reduce the encoding effort, and improve teamwork flexibility. STEAM uses the joint intentions theory [16, 3] as the basic building block of teamwork, but it is also strongly influenced by the SharedPlans theory <ref> [7, 8] </ref>, and constraints realized in practical applications. The tie between the teamwork model and the previously discussed team operators is as follows: when executing (sub)team operators, agents bring to bear all of the teamwork reasoning of a general teamwork model, which facilitates their communication and coordination.
Reference: [9] <author> B. Hayes-Roth, L. Brownston, and R. V. Gen. </author> <title> Multiagent collaobration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <year> 1995. </year>
Reference-contexts: These two research challenges are of critical concern in a wide variety of multi-agent domains, ranging from virtual environments for training [33, 22], to multi-agent entertainment <ref> [9] </ref>, to information-integration on the Internet [34], to multi-robotic space missions. With respect to teamwork, one key challenge is to enable an agent team to perform coherently in highly uncertain, dynamic environments. <p> Once operators are selected for execution, they are executed by the application rules. If the agent's current beliefs match an operator's termination rules, then the operator terminates. Agents built in other architectures such as PRS [10], BB1 <ref> [9] </ref>, RAP [5] for dynamic domains may be similarly characterized in this fashion. The key here is that in a dynamic domain such as Robocup, the operator selection, execution and termination may be heavily dependent on the current state of the environment as perceived by the individual agent.
Reference: [10] <author> F. F. Ingrand, M. P. Georgeff, , and A. S. Rao. </author> <title> An architecture for real-time reasoning and system control. </title> <journal> IEEE EXPERT, </journal> <volume> 7(6), </volume> <year> 1992. </year>
Reference-contexts: Once operators are selected for execution, they are executed by the application rules. If the agent's current beliefs match an operator's termination rules, then the operator terminates. Agents built in other architectures such as PRS <ref> [10] </ref>, BB1 [9], RAP [5] for dynamic domains may be similarly characterized in this fashion. The key here is that in a dynamic domain such as Robocup, the operator selection, execution and termination may be heavily dependent on the current state of the environment as perceived by the individual agent.
Reference: [11] <author> N. Jennings. </author> <title> Controlling cooperative problem solving in industrial multi-agent systems using joint intentions. </title> <journal> Artificial Intelligence, </journal> <volume> 75, </volume> <year> 1995. </year>
Reference-contexts: For teamwork, we investigate the use of a novel approach, where agent-teams are developed based on an explicitly represented hierarchy of team goals and plans, an explicitly represented team organization hierarchy, and more importantly, a general-purpose, explicit model of 2 teamwork <ref> [11, 32] </ref>. The teamwork model is an attempt to provide agents with commonsense knowledge of teamwork, particularly in terms of individuals' commitments and responsibilities in teamwork. There are two key implications of this approach to team development. <p> Indeed, teamwork models have only recently begun to emerge as a promising and useful approach to multi-agent collaboration. Thus, the STEAM teamwork model used in ISIS, is among just a very few implemented general models of teamwork. Other models include Jennings' joint responsibility framework in the GRATE* system <ref> [11] </ref> (based on Joint Intentions theory), and Rich and Sidner's COLLAGEN [23] (based on the SharedPlans theory), that both operate in complex domains. <p> Teamwork models have recently been proposed as a promising approach to enhance teamwork flexibility and to enable reuse of teamwork capabilities <ref> [11, 32] </ref>. This article has empirically illustrated the usefulness of this teamwork-model-based approach in a novel domain. The teamwork model was shown to improve team performance, and reduce development and coding time. This teamwork-model-based approach is a general approach to teamwork, widely applicable in other domains beyond RoboCup.
Reference: [12] <author> D. Kinny, M. Ljungberg, A. Rao, E. Sonenberg, G. Tidhard, and E. Werner. </author> <title> Planned team activity. </title> <editor> In C. Castelfranchi and E. Werner, editors, </editor> <booktitle> Artificial Social Systems, Lecture notes in AI 830. </booktitle> <publisher> Springer, </publisher> <address> NY, </address> <year> 1992. </year>
Reference-contexts: Furthermore, roles may have specific coordination relationships among them. For instance, the execution of operators for one role may be dependent on operators for another role. The concept of roles has been discussed before in the multi-agent literature <ref> [12] </ref>. The key in STEAM is the instantiation of this concept as part of the team organization hierarcy, with its use as a constraint on the selection of the sub-operators of a team operator, and its use in expressing coordination relationships.
Reference: [13] <author> H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, and E. Osawa. </author> <title> Robocup: The robot world cup initiative. </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995. </year>
Reference-contexts: To pursue such research challenges, the RoboCup research initiative has proposed simulation and robotic soccer as a common, unified testbed for AI research in general, and multi-agent research in particular <ref> [14, 13] </ref> (www.robocup.org). By focusing on a common, standard testbed, and highlighting several research issues of critical concern in multi-agents, the RoboCup effort aims to accelerate the advance of the state-of-the-art in multi-agent systems.
Reference: [14] <author> H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, and E. Osawa. </author> <title> Robocup: The robot world cup initiative. </title> <booktitle> In Proceedings of the first international conference on autonomous agents, </booktitle> <year> 1997. </year>
Reference-contexts: To pursue such research challenges, the RoboCup research initiative has proposed simulation and robotic soccer as a common, unified testbed for AI research in general, and multi-agent research in particular <ref> [14, 13] </ref> (www.robocup.org). By focusing on a common, standard testbed, and highlighting several research issues of critical concern in multi-agents, the RoboCup effort aims to accelerate the advance of the state-of-the-art in multi-agent systems. <p> Soccer is a dynamic, real time game with incomplete sensory information and distributed control. Robocup is an attempt to stimulate AI and robotics research based on robotics and synthetic (simulated) soccer as a common testbed <ref> [15, 14] </ref>. For readers unfamiliar with Soccer, here is our attempt to briefly describe the game. Soccer is a continuous game between two teams competing in a rectangular field, each attacking a goal at the end of the opposite side of the field.
Reference: [15] <author> H. Kitano, M. Tambe, P. Stone, S. Coradesci, H. Matsubara, M. Veloso, I. Noda, E. Osawa, and M. Asada. </author> <title> The robocup synthetic agents' challenge. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Soccer is a dynamic, real time game with incomplete sensory information and distributed control. Robocup is an attempt to stimulate AI and robotics research based on robotics and synthetic (simulated) soccer as a common testbed <ref> [15, 14] </ref>. For readers unfamiliar with Soccer, here is our attempt to briefly describe the game. Soccer is a continuous game between two teams competing in a rectangular field, each attacking a goal at the end of the opposite side of the field.
Reference: [16] <author> H. J. Levesque, P. R. Cohen, and J. Nunes. </author> <title> On acting together. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, Calif.: </address> <publisher> AAAI press, </publisher> <year> 1990. </year>
Reference-contexts: Second, STEAM provides an explicit teamwork model, attempting to enhance teamwork flexibility, by providing agents abilities to autonomously reason about coordination and communication in teamwork. In STEAM, the teamwork model is based both on the joint intentions theory <ref> [3, 16] </ref> and the SharedPlans theory [7, 6, 8], but with key enhancements to reflect the constraints of real-world domains. The article discusses in detail STEAM's contribution in building RoboCup teams. <p> In essence, it attempts to provide agents with commonsense knowledge of teamwork, that would enable them to autonomously reason about coordination and communication in teamwork. Thus, it aims to substantially reduce the encoding effort, and improve teamwork flexibility. STEAM uses the joint intentions theory <ref> [16, 3] </ref> as the basic building block of teamwork, but it is also strongly influenced by the SharedPlans theory [7, 8], and constraints realized in practical applications.
Reference: [17] <author> S. Luke, Hohn C., J. Farris, G. Jackson, and J. Hendler. </author> <title> Co-evolving soccer softbot team coordination with genetic programming. In RoboCup-97: The first robot world cup soccer games and conferences. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1998. </year>
Reference: [18] <author> S. Mahadevan and J. Connel. </author> <title> Automatic programming of behavior-based robots using reinforcement learning. </title> <booktitle> In Proceedings of the National Conference of the American Association for Artificial Intelligence (AAAI), </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: In particular, the turn increment specific to that input condition is adjusted either up or down upon repeated failure. Currently, this clustering is designed by hand and is fixed, but automated, dynamic approaches may be applicable here (e.g., <ref> [18] </ref>). Finally, to provide for a more accurate assessment of success or failure, evaluation itself is driven by an "oracle", ISIS's higher-level, decision-making tier, which tends to have more complete information on why an intercept plan is failing.
Reference: [19] <author> H. Matsubara, I. Noda, and K. Hiraki. </author> <title> Learning of cooperative actions in multi-agent systems: a case study of pass play in soccer. </title> <editor> In S. Sen, editor, </editor> <booktitle> AAAI Spring Symposium on Adaptation, Coevolution and Learning in multi-agent systems, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: server, it is unclear at this stage if a particular communication cost setting is always the best, or if it should be varied over time, depending on the network load. 5 Agent Learning Our work on agent learning in ISIS was inspired by previous work on machine learning in RoboCup <ref> [25, 19] </ref>. We focused on a divide-and-conquer learning approach in designing agents. With this approach, different modules (skills) within individual agents were learned separately, using different learning techniques.
Reference: [20] <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: For example, it does not decide which one of its three suggested kicking directions should actually be used by a player-agent. Instead, all such decision-making rests with the higher layer implemented in the Soar integrated AI architecture <ref> [20, 24] </ref>. Once the Soar-based higher layer reaches a decision, it communicates with the lower layers, which then send the relevant commands to the soccer server.
Reference: [21] <author> J. R. Quinlan. C4.5: </author> <title> Programs for machine learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: With this approach, skills for different modules within individual agents were learned separately, using different learning techniques. In particular, one of the skills, to pick a direction to shoot into the opponents' goal while avoiding opponents, was learned off-line using C4.5 <ref> [21] </ref>. Another skill, to intercept the ball, used a mix of off-line and on-line reinforcement learning. One of the key surprises here was the degree to which individual agents specialized in their individual tasks in a given team. <p> The choice of the learning system was a crucial decision, and we selected C4.5 <ref> [21] </ref> for several reasons. First, C4.5 offers the appropriate expressive power because each game situation can be easily described in propositional logic.
Reference: [22] <author> A. S. Rao, A. Lucas, D. Morley, M. Selvestrel, and G. Murray. </author> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report Technical Note 42, </type> <institution> The Australian Artificial Intelligence Institute, </institution> <year> 1993. </year>
Reference-contexts: These two research challenges are of critical concern in a wide variety of multi-agent domains, ranging from virtual environments for training <ref> [33, 22] </ref>, to multi-agent entertainment [9], to information-integration on the Internet [34], to multi-robotic space missions. With respect to teamwork, one key challenge is to enable an agent team to perform coherently in highly uncertain, dynamic environments.
Reference: [23] <author> C. Rich and C. Sidner. COLLAGEN: </author> <title> When agents collaborate with people. </title> <booktitle> In Proceedings of the International Conference on Autonomous Agents (Agents'97), </booktitle> <year> 1997. </year>
Reference-contexts: Thus, the STEAM teamwork model used in ISIS, is among just a very few implemented general models of teamwork. Other models include Jennings' joint responsibility framework in the GRATE* system [11] (based on Joint Intentions theory), and Rich and Sidner's COLLAGEN <ref> [23] </ref> (based on the SharedPlans theory), that both operate in complex domains.
Reference: [24] <author> P. S. Rosenbloom, J. E. Laird, A. Newell, , and R. McCarl. </author> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):289-325, </volume> <year> 1991. </year>
Reference-contexts: For example, it does not decide which one of its three suggested kicking directions should actually be used by a player-agent. Instead, all such decision-making rests with the higher layer implemented in the Soar integrated AI architecture <ref> [20, 24] </ref>. Once the Soar-based higher layer reaches a decision, it communicates with the lower layers, which then send the relevant commands to the soccer server.
Reference: [25] <author> P. Stone and M. Veloso. </author> <title> Towards collaborative and adversarial learning: a case study in robotic soccer. </title> <editor> In S. Sen, editor, </editor> <booktitle> AAAI Spring Symposium on Adaptation, Coevolution and Learning in multi-agent systems, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: No centralized control is allowed. Furthermore, agent processes cannot directly communicate with one another; instead all such communication is mediated by the soccer server as discussed below. Figure 1 shows a snapshot of the soccer server with two competing teams: CMUnited <ref> [25] </ref> versus our ISIS team. The soccer server provides each individual player agent input in the form of two types of sensory information: visual information (i.e. see messages) and audio information (i.e. hear messages). <p> server, it is unclear at this stage if a particular communication cost setting is always the best, or if it should be varied over time, depending on the network load. 5 Agent Learning Our work on agent learning in ISIS was inspired by previous work on machine learning in RoboCup <ref> [25, 19] </ref>. We focused on a divide-and-conquer learning approach in designing agents. With this approach, different modules (skills) within individual agents were learned separately, using different learning techniques.
Reference: [26] <author> P. Stone and M. Veloso. </author> <title> Task decomposition and dynamic role assignment for real-time strategic teamwork. </title> <booktitle> In Proceedings of the international workshop on Agent theories, Architectures and Languages, </booktitle> <year> 1998. </year> <month> 26 </month>
Reference-contexts: A similar scheme is used by Stone and Veloso <ref> [26] </ref>. They offer an approach to managing flexible formations and roles within those formations, allowing agents to switch roles and formations dynamically in a domain-dependent manner.
Reference: [27] <author> P. Stone and M. Veloso. </author> <title> Using decision tree confidence factors for multiagent control. In RoboCup-97: The first robot world cup soccer games and conferences. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1998. </year>
Reference-contexts: Yet, the lessons learned by researchers participating in RoboCup, particularly the simulation league, have largely not been reported in a form that would be accessible to the research community at large. There are just a few notable exceptions (e.g., <ref> [27] </ref>). However, extracting such general lessons in areas of teamwork, agent modeling and multi-agent learning, so as to be applicable in other domains beyond RoboCup, is an important task for RoboCup researchers. <p> Our application of learning in ISIS agents is similar to some of the other investigations of learning in RoboCup agents. For instance, Luke et al.[17] use genetic programming to build agents that learn to use their basic individual skills in coordination. Stone and Veloso <ref> [27] </ref> present a related approach, in which the agents learn a decision tree which enables them to select a recipient for a pass.
Reference: [28] <author> R. S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44, </pages> <year> 1988. </year>
Reference-contexts: We have taken a different approach, driven by the question as to what would happen if players could learn their intercept plans themselves and what would that learning tell us. To that end, we are exploring a reinforcement learning <ref> [28, 4] </ref> approach whereby players can adapt their intercept online, under actual playing conditions using just the perceptual input provided by the RoboCup'97 server to the player: the ball's current direction, change in direction, distance.
Reference: [29] <author> M. Tambe. </author> <title> Teamwork in real-world, dynamic environments. </title> <booktitle> In Proceedings of the International Conference on Multi-agent Systems (ICMAS), </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: Thus, one of the goals of this article is to understand the benefits and costs of pursuing the above teamwork-model-based approach, an issue highly relevant for developing agent-teams for a variety of multi-agent domains. To this end, we investigate the (re)use of STEAM <ref> [29, 31, 32] </ref> (a Shell for TEAMwork), in building agent-teams in RoboCup. STEAM is a state-of-the-art system, and it contributes in two ways in building RoboCup agent-teams.
Reference: [30] <author> M. Tambe. </author> <title> Tracking dynamic team activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: However, currently, in the 23 absence of the required agent modeling capability STEAM cannot engage in such reasoning. Techniques for team modeling such as <ref> [30] </ref> would be applicable in this case. Indeed, this is partly the reason that many STEAM rules have currently not applied in RoboCup (so that STEAM reuse is limited to 45% of rules). A second key issue is improved agent and team learning, particularly to learn new team tactics.
Reference: [31] <author> M. Tambe. </author> <title> Agent architectures for flexible, practical teamwork. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Thus, one of the goals of this article is to understand the benefits and costs of pursuing the above teamwork-model-based approach, an issue highly relevant for developing agent-teams for a variety of multi-agent domains. To this end, we investigate the (re)use of STEAM <ref> [29, 31, 32] </ref> (a Shell for TEAMwork), in building agent-teams in RoboCup. STEAM is a state-of-the-art system, and it contributes in two ways in building RoboCup agent-teams.
Reference: [32] <author> M. Tambe. </author> <title> Towards flexible teamwork. </title> <journal> Journal of Artificial Intelligence Research (JAIR), </journal> <volume> 7 </volume> <pages> 83-124, </pages> <year> 1997. </year>
Reference-contexts: For teamwork, we investigate the use of a novel approach, where agent-teams are developed based on an explicitly represented hierarchy of team goals and plans, an explicitly represented team organization hierarchy, and more importantly, a general-purpose, explicit model of 2 teamwork <ref> [11, 32] </ref>. The teamwork model is an attempt to provide agents with commonsense knowledge of teamwork, particularly in terms of individuals' commitments and responsibilities in teamwork. There are two key implications of this approach to team development. <p> Thus, one of the goals of this article is to understand the benefits and costs of pursuing the above teamwork-model-based approach, an issue highly relevant for developing agent-teams for a variety of multi-agent domains. To this end, we investigate the (re)use of STEAM <ref> [29, 31, 32] </ref> (a Shell for TEAMwork), in building agent-teams in RoboCup. STEAM is a state-of-the-art system, and it contributes in two ways in building RoboCup agent-teams. <p> STEAM was originally developed in the context of building teams of attack-helicopter pilot-agents for real-world military simulations <ref> [32, 33] </ref>. STEAM was later reused in the same simulation environment, for building teams of transport helicopter pilot agents. RoboCup is a third domain for STEAM's reuse. <p> Indeed, some of the generalizations in STEAM were inspired by its application in RoboCup. This section provides only a brief overview of STEAM. For a more extensive discussion of STEAM please see <ref> [32] </ref>. There are two key aspects of STEAM that are relevant in building agent-teams. <p> The third set of selectivity-in-communication or SC axioms in STEAM arise because communication to attain perfect coherence in teamwork can sometimes be excessive, and indeed it may have highly detrimental side-effects <ref> [32] </ref>. Hence, STEAM also includes decision-theoretic communication selectivity. The key idea is to explicitly reason about the costs and benefits of different techniques for attaining mutual beliefs. <p> Such costs may indeed change over time. The next section discusses some experiments, trying to determine if the communication costs were reasonably accurately set in ISIS during the RoboCup'97 competitions. STEAM's teamwork model has also been currently encoded in the Soar integrated architecture, in the form of 283 rules <ref> [32] </ref>. These rules, with documentation, traces and pointers to their usage are available at (www.isi.edu/teamcore/tambe/steam/steam.html). 4 Applying STEAM in ISIS The application of STEAM in ISIS tests a novel approach to building agent-teams. This section discusses STEAM's application in ISIS in further detail. <p> STEAM significantly 22 differs from both these frameworks, via its focus on a different (and arguably wider) set of teamwork capabilities that arise in domains with teams of more than two-three agents, with more complex team organizational hierarchies, and with practical emphasis on communication costs (see <ref> [32] </ref> for a more detailed discussion). The other implementations of teamwork model emphasize different capabilities, e.g., COLLAGEN focuses on human-agent collaboration, and brings to bear capabilities more useful in such a collaboration. 8 Summary This article focused on two important research issues in multi-agent systems: (i) teamwork and (ii) learning. <p> Teamwork models have recently been proposed as a promising approach to enhance teamwork flexibility and to enable reuse of teamwork capabilities <ref> [11, 32] </ref>. This article has empirically illustrated the usefulness of this teamwork-model-based approach in a novel domain. The teamwork model was shown to improve team performance, and reduce development and coding time. This teamwork-model-based approach is a general approach to teamwork, widely applicable in other domains beyond RoboCup. <p> This teamwork-model-based approach is a general approach to teamwork, widely applicable in other domains beyond RoboCup. Indeed, the teamwork model applied in our work, STEAM, has also been applied for building teams of helicopter pilot agents for real-world combat simulations for training <ref> [32] </ref>. The article has also investigated the learning of low-level skills within a dynamic multi-agent setting. Both the off-line learning of goal kicking direction and on-line learning of intercept have been critical in improving ISIS agents. In some ways, our results also point out the importance of learning in "context".
Reference: [33] <author> M. Tambe, W. L. Johnson, R. Jones, F. Koss, J. E. Laird, P. S. Rosenbloom, and K. Schwamb. </author> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <month> Spring </month> <year> 1995. </year>
Reference-contexts: These two research challenges are of critical concern in a wide variety of multi-agent domains, ranging from virtual environments for training <ref> [33, 22] </ref>, to multi-agent entertainment [9], to information-integration on the Internet [34], to multi-robotic space missions. With respect to teamwork, one key challenge is to enable an agent team to perform coherently in highly uncertain, dynamic environments. <p> STEAM was originally developed in the context of building teams of attack-helicopter pilot-agents for real-world military simulations <ref> [32, 33] </ref>. STEAM was later reused in the same simulation environment, for building teams of transport helicopter pilot agents. RoboCup is a third domain for STEAM's reuse.
Reference: [34] <author> M. Williamson, K. Sycara, and K. Decker. </author> <title> Executing decision-theoretic plans in multi-agent environments. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Plan Execution: Problems and Issues, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: These two research challenges are of critical concern in a wide variety of multi-agent domains, ranging from virtual environments for training [33, 22], to multi-agent entertainment [9], to information-integration on the Internet <ref> [34] </ref>, to multi-robotic space missions. With respect to teamwork, one key challenge is to enable an agent team to perform coherently in highly uncertain, dynamic environments. In particular, in such complex environments, individual team members often encounter differing, incomplete, and even inconsistent views of their environment.
Reference: [35] <author> K. Yokota, K. Ozako, Matsumoto A., T. Fujii, Asama H., and I. Endo. </author> <title> Cooperation towards team play. In RoboCup-97: The first robot world cup soccer games and conferences. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, Germany, </address> <year> 1998. </year> <month> 27 </month>
References-found: 35

