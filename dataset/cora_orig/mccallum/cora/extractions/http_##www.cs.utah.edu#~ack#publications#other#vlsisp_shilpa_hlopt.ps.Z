URL: http://www.cs.utah.edu/~ack/publications/other/vlsisp_shilpa_hlopt.ps.Z
Refering-URL: http://www.cs.utah.edu/~ack/publications/other.html
Root-URL: 
Email: (ganesh@cs.utah.edu)  VENKATESH AKELLA (akella@ece.ucdavis.edu)  
Title: HIGH LEVEL OPTIMIZATIONS IN COMPILING PROCESS DESCRIPTIONS TO ASYNCHRONOUS CIRCUITS  
Author: GANESH GOPALAKRISHNAN 
Keyword: Asynchronous/Self-timed Systems, High Level Synthesis, High level optimizations  
Address: Salt Lake City, Utah 84112  Davis, CA 95616  
Affiliation: University of Utah Dept. of Computer Science  Department of Electrical and Computer Engineering, University of California,  
Abstract: Asynchronous/Self-Timed designs are beginning to attract attention as promising means of dealing with the complexity of modern VLSI technology. In this paper, we present our views on why asynchronous systems matter. We then present details of our high level synthesis tool SHILPA that can automatically synthesize asynchronous circuits from descriptions in our concurrent programming language, hopCP. We outline many of the novel features of hopCP and also sketch how these constructs are compiled into asynchronous circuits, and then focus on the high level optimizations employed by SHILPA, including concurrent guard evaluation and concurrent process decomposition. y The work reported here was part of this author's PhD dissertation work, and was supported by a University of Utah Graduate Fellowship fl Supported in part by NSF Award MIP 8902558
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ivan Sutherland. </author> <title> Micropipelines. </title> <journal> Communications of the ACM, </journal> <month> June </month> <year> 1989. </year> <note> The 1988 ACM Turing Award Lecture. </note>
Reference-contexts: 1 Introduction It has been pointed out by many researchers recently that asynchronous circuits|circuits that do not employ global clocks|have a number of advantages over synchronous circuits when it comes to building large and complex sequential systems <ref> [1, 2, 3, 4] </ref>. In this paper, we summarize recent developments in asynchronous circuit design and then present our high-level synthesis system, SHILPA 1 . We will focus on the high-level optimizations used by SHILPA. <p> Synchronous circuits also have many shortcomings. Large synchronous circuits employ high frequency and low skew global clocks, driving which can consume considerable amounts of power [7]. The design of synchronous/asynchronous interfaces|for example, peripheral interfaces|must be done with great care, for fear of inviting failure due to metastability <ref> [1] </ref>. <p> It generates circuits ready for implementation in Actel FPGAs, supported by Viewlogic tools. 3 Overview of SHILPA SHILPA generates transition style circuits using bundled data, as presented in <ref> [1] </ref>. We illustrate SHILPA through the design of a two-stage pipeline: (P [x] = a?y -&gt; b!(x+y) -&gt; P [y]) (Q [z] = b?z -&gt; c!z -&gt; Q [z]) The top-level command in SHILPA for compiling this specification is function compile. <p> There are two invocations of the synchronous input action on channel a? (and likewise on b?). The usual semantics of channels requires that these invocations share the same resources (c-elements, and handshake wires, in our case). Usually this is achieved by using a call module <ref> [1] </ref>. 18 Coming back to our example, assuming that the guards are mutually exclusive, SHILPA generates the circuit shown in Figure 5. The circuit works as follows. After CLR, when START is applied, both the call elements make a "procedure call" onto the c-elements through the respective R2 inputs. <p> However, an exact comparison is not possible between our approach and Martin's approach, because we synthesize two-phase transition style circuits (which have a large number of desirable characteristics <ref> [1] </ref>) while Martin synthesizes four-phase (level based) circuits. 5 Concurrent Process Decomposition It is easy to come up with iterative specifications for many computations. We have identified a useful heuristic for implementing iterative computations through concurrent process decomposition. Concurrent process decomposition is a very convenient way to achieve software pipelining.
Reference: 2. <author> C. A. Mead and L. Conway. </author> <title> An Introduction to VLSI Systems. </title> <publisher> Addison Wesley, </publisher> <year> 1980. </year> <note> Chapter 7, entitled "System Timing". </note>
Reference-contexts: 1 Introduction It has been pointed out by many researchers recently that asynchronous circuits|circuits that do not employ global clocks|have a number of advantages over synchronous circuits when it comes to building large and complex sequential systems <ref> [1, 2, 3, 4] </ref>. In this paper, we summarize recent developments in asynchronous circuit design and then present our high-level synthesis system, SHILPA 1 . We will focus on the high-level optimizations used by SHILPA. <p> In general, arbiters occupy more area to realize than predicate action blocks. They also use circuits such as the interlock <ref> [2] </ref> that cannot be realized in many technologies, such as most of today's FPGAs. (Note: The FPGA realization in [30] is only an approximation, to permit rapid prototyping.) The different categories of variables, channel names, and their scoping rules, are as follows.
Reference: 3. <author> John Brzozowski and Carl-Johan Seger. </author> <title> Advances in Asynchronous Circuit Theory: Part I: Gate and Unbounded Intertial Delay Models; and Part II: Bounded Intertial Delay Models, MOS Circuits, Design Techniques. </title> <type> Technical report, </type> <institution> University of Waterloo, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction It has been pointed out by many researchers recently that asynchronous circuits|circuits that do not employ global clocks|have a number of advantages over synchronous circuits when it comes to building large and complex sequential systems <ref> [1, 2, 3, 4] </ref>. In this paper, we summarize recent developments in asynchronous circuit design and then present our high-level synthesis system, SHILPA 1 . We will focus on the high-level optimizations used by SHILPA.
Reference: 4. <author> Ganesh Gopalakrishnan and Prabhat Jain. </author> <title> Some recent asynchronous system design methodologies. </title> <type> Technical Report UUCS-TR-90-016, </type> <institution> Dept. of Computer Science, University of Utah, </institution> <address> Salt Lake City, UT 84112, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction It has been pointed out by many researchers recently that asynchronous circuits|circuits that do not employ global clocks|have a number of advantages over synchronous circuits when it comes to building large and complex sequential systems <ref> [1, 2, 3, 4] </ref>. In this paper, we summarize recent developments in asynchronous circuit design and then present our high-level synthesis system, SHILPA 1 . We will focus on the high-level optimizations used by SHILPA.
Reference: 5. <author> Alfred Aho, Ravi Sethi, and Jeffrey Ullman. </author> <booktitle> Compilers, Principles Techniques and Tools. </booktitle> <publisher> 24 Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: In this paper, we summarize recent developments in asynchronous circuit design and then present our high-level synthesis system, SHILPA 1 . We will focus on the high-level optimizations used by SHILPA. High-level optimizations are similar to "flow-graph level optimizations" in programming language compilers <ref> [5] </ref>; they should not be confused with circuit level optimizations which are similar to machine code optimizations. Synchronous vs. Asynchronous Circuits Synchronous circuits are employed virtually everywhere. They have a number of desirable characteristics, some of which are the following.
Reference: 6. <author> Steven Nowick and David Dill. </author> <title> Exact two-level minimization of hazard-free logic with multiple-input changes. </title> <booktitle> In Proceedings of the International Conference on Computer Aided Design (ICCAD), </booktitle> <pages> pages 626-630, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: In asynchronous circuits, hazards can be mistaken for genuine signal transitions. Hence, it is of paramount importance to eliminate hazards, for instance by employing special purpose Boolean minimization procedures <ref> [6] </ref>. Synchronous circuits do not have the overhead of handshaking. Very many simulation and testing techniques, as well as Computer-Aided Design (CAD) tools, are available for them. Synchronous circuits also have many shortcomings.
Reference: 7. <author> D. W. Dobberpuhl. </author> <title> A 200-MHz 64-b Dual-Issue CMOS Microprocessor. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 27(11) </volume> <pages> 1555-1567, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Very many simulation and testing techniques, as well as Computer-Aided Design (CAD) tools, are available for them. Synchronous circuits also have many shortcomings. Large synchronous circuits employ high frequency and low skew global clocks, driving which can consume considerable amounts of power <ref> [7] </ref>. The design of synchronous/asynchronous interfaces|for example, peripheral interfaces|must be done with great care, for fear of inviting failure due to metastability [1].
Reference: 8. <author> Ted E.Williams and Mark Horowitz. </author> <title> A zero-overhead self-timed 160ns 54bit cmos divider. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> 26(11) </volume> <pages> 1651-1661, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: For example, there is no need to perform clock scheduling. Operations whose durations are data dependent as well as I/O dependent can be more cleanly and efficiently handled in the asynchronous high level synthesis framework. Asynchronous circuits can also exhibit better average case performance, unencumbered by clocking rules <ref> [8] </ref>. Despite these promises, many designers have have shunned away from asynchronous circuits. It is feared that asynchronous circuits are excessively larger than synchronous circuits. Asynchronous circuits offer the designer with even more freedom to explore the design space.
Reference: 9. <author> Jo C. Ebergen. </author> <title> Translating Programs into Delay Insensitive Circuits. </title> <institution> Centre for Mathematics and Computer Science, </institution> <address> Amsterdam, </address> <year> 1989. </year> <note> CWI Tract 56. </note>
Reference-contexts: It is hoped that many of these limitations of asynchronous circuits can be overcome very soon through additional research. Many of the early failures involving asynchronous circuits can now be avoided through careful design <ref> [9] </ref> or verification [10]. Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. <p> In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of [23, 24], as well as more recent works of <ref> [25, 10, 9, 26] </ref>, which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category. <p> There are also many efforts in which macromodules are used directly for realizing state machines (i.e. for low level synthesis). Some examples are <ref> [25, 9] </ref>. Some of these distinctions are also rapidly blurring, with the use of complex gates that directly realize multi-input multi-output Boolean functions as macromodules. In SHILPA, macromodules are the target of compilation, at present. <p> This c-element is therefore reset. Following this (the delay ensures this), control is returned back to the top XOR. The circuit comprising the lower two XORs, the two Cs and the two delays actually forms a 2 fi 1 cal component <ref> [9] </ref> (first introduced by Molnar). An M fi 1 cal component can be considered to be a generalized c-element. It has inputs a 1 ; : : : ; a M and b, and outputs c 1 ; : : : ; c M .
Reference: 10. <author> David L. Dill. </author> <title> Trace Theory for Automatic Hierarchical Verification of Speed-independent Circuits. </title> <publisher> MIT Press, </publisher> <year> 1989. </year> <note> An ACM Distinguished Dissertation. </note>
Reference-contexts: It is hoped that many of these limitations of asynchronous circuits can be overcome very soon through additional research. Many of the early failures involving asynchronous circuits can now be avoided through careful design [9] or verification <ref> [10] </ref>. Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. <p> In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of [23, 24], as well as more recent works of <ref> [25, 10, 9, 26] </ref>, which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category.
Reference: 11. <author> Alain J. Martin. </author> <title> Programming in VLSI: From communicating processes to delay-insensitive circuits. In C.A.R. Hoare, editor, </title> <booktitle> UT Year of Programming Institute on Concurrent Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs <ref> [11, 12] </ref>. Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. <p> Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level <ref> [11, 13, 14, 15] </ref> and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. <p> Our system, SHILPA, belongs to the former category. To the best of our knowledge, systems similar to ours that have been fully implemented and tried out in practice are those by Brunvand [14], van Berkel [27, 13], and by Martin and Burns <ref> [11, 28] </ref>. Improvements in SHILPA over these works are primarily the following. hopCP, the source language for SHILPA, is more expressive than Martin's input language `CHP', Brunvand's version of `Occam', or van Berkel's language `Tangram'. <p> Summary of Features To sum up, our work makes a number of advances over comparable works. hopCP has been designed for supporting the specification of large hardware systems at a high level. It is more expressive than the HDLs used in comparable works. Although Martin <ref> [11] </ref> also makes the distinction between mutually exclusive and non-exclusive "guards", his approach is slightly different. In Martin's approach, an input guard is turned into a input probe which is then made part of the Boolean guard. We do not use probes in hopCP for several reasons.
Reference: 12. <author> Erik L. Brunvand. </author> <title> The NSR Processor. In T.N. </title> <editor> Mudge, V. Milutinovic, and L. Hunter, editors, </editor> <booktitle> Proceedings of the 26th Annual Hawaiian International Conference on System Sciences, </booktitle> <volume> Volume 1, </volume> <pages> pages 428-436, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs <ref> [11, 12] </ref>. Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur.
Reference: 13. <author> Kees van Berkel. </author> <title> Handshake Circuits: An Asynchronous Architecture for VLSI Programming. </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year> <booktitle> International Series on Parallel Computation. </booktitle>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level <ref> [11, 13, 14, 15] </ref> and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. <p> Our system, SHILPA, belongs to the former category. To the best of our knowledge, systems similar to ours that have been fully implemented and tried out in practice are those by Brunvand [14], van Berkel <ref> [27, 13] </ref>, and by Martin and Burns [11, 28]. Improvements in SHILPA over these works are primarily the following. hopCP, the source language for SHILPA, is more expressive than Martin's input language `CHP', Brunvand's version of `Occam', or van Berkel's language `Tangram'.
Reference: 14. <author> Erik Brunvand. </author> <title> Translating Concurrent Communicating Programs into Asynchronous Circuits. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level <ref> [11, 13, 14, 15] </ref> and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. <p> Our system, SHILPA, belongs to the former category. To the best of our knowledge, systems similar to ours that have been fully implemented and tried out in practice are those by Brunvand <ref> [14] </ref>, van Berkel [27, 13], and by Martin and Burns [11, 28]. Improvements in SHILPA over these works are primarily the following. hopCP, the source language for SHILPA, is more expressive than Martin's input language `CHP', Brunvand's version of `Occam', or van Berkel's language `Tangram'. <p> Coming back to process P, consider a situation in which the communication actions a?z and b?x can arrive potentially concurrently. In this situation, an arbiter would be used to pick one of these communications (for example, as in <ref> [14] </ref>). However, if it can be determined (using Concur) that these actions are mutually exclusive, SHILPA compiles a circuit using 11 the concurrent guard evaluation technique. This technique also uses a circuit that is smaller and easier to realize than an arbiter.
Reference: 15. <author> Venkatesh Akella and Ganesh Gopalakrishnan. SHILPA: </author> <title> A High-Level Synthesis System for Self-Timed Circuits. </title> <booktitle> In International Conference on Computer-aided Design, </booktitle> <volume> ICCAD 92, </volume> <pages> pages 587-591, </pages> <month> November </month> <year> 1992. </year> <month> 25 </month>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level <ref> [11, 13, 14, 15] </ref> and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur.
Reference: 16. <author> Al Davis, Bill Coates, and Ken Stevens. </author> <title> The Post Office Experience: Designing a Large Asyn--chronous Chip. In T.N. </title> <editor> Mudge, V. Milutinovic, and L. Hunter, editors, </editor> <booktitle> Proceedings of the 26th Annual Hawaiian International Conference on System Sciences, </booktitle> <volume> Volume 1, </volume> <pages> pages 409-418, </pages> <month> Jan-uary </month> <year> 1993. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level [11, 13, 14, 15] and low-level synthesis tools <ref> [16, 17, 18] </ref> have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend.
Reference: 17. <author> Tam-Anh Chu. </author> <title> Synthesis of hazard-free control circuits from asynchronous finite state machine specifications. TAU '92: </title> <booktitle> 1992 Workshop on Timing Issues in the Specification and Synthesis of Digital Systems, </booktitle> <address> Princeton, NJ, March 18-20, </address> <year> 1992. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level [11, 13, 14, 15] and low-level synthesis tools <ref> [16, 17, 18] </ref> have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend.
Reference: 18. <author> Steven M. Nowick, Kenneth Y. Yun, and David L. Dill. </author> <title> Practical Asynchronous Controller Design. </title> <booktitle> In Proceedings of the International Conference on Computer Design, </booktitle> <pages> pages 341-345, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Area overheads are be 3 coming less severe, especially if a slight increase in area can actually buy reduced design time. Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level [11, 13, 14, 15] and low-level synthesis tools <ref> [16, 17, 18] </ref> have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend. <p> Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules [21], locally clocked asynchronous systems <ref> [18] </ref>, and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend. Whichever course the hardware design community may ultimately follow, it seems inevitable that asynchronous design will play an increasing role as time goes by.
Reference: 19. <author> Daniel M. Chapiro. </author> <title> Globally-Asynchronous Locally-Synchronous Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <month> October </month> <year> 1984. </year>
Reference-contexts: Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits <ref> [19, 20] </ref>, Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend. Whichever course the hardware design community may ultimately follow, it seems inevitable that asynchronous design will play an increasing role as time goes by.
Reference: 20. <author> M.J.Stucki and J.R.Cox, Jr. </author> <title> Synchronization strategies. </title> <booktitle> In Proceedings of the Caltech Conference on VLSI, </booktitle> <pages> pages 375-393, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: Recently, there have been many convincing demonstrations of the practicality of large asynchronous designs [11, 12]. Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits <ref> [19, 20] </ref>, Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend. Whichever course the hardware design community may ultimately follow, it seems inevitable that asynchronous design will play an increasing role as time goes by.
Reference: 21. <author> Fred U. Rosenberger, Charles E. Molnar, Thomas J. Chaney, and Ting-Pein Fang. Q-modules: </author> <title> Internally clocked delay-insensitive modules. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(9) </volume> <pages> 1005-1018, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Many high-level [11, 13, 14, 15] and low-level synthesis tools [16, 17, 18] have been developed. The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules <ref> [21] </ref>, locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus [22] are indicative of this trend. Whichever course the hardware design community may ultimately follow, it seems inevitable that asynchronous design will play an increasing role as time goes by.
Reference: 22. <author> David Ku. </author> <title> Constrained Synthesis and Optimization of Digital Integrated Circuits from Behavioral Specifications. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: The clean separation between "synchronous", and "asynchronous" systems has already begun to blur. Mixed synchronous/asynchronous circuits [19, 20], Q-modules [21], locally clocked asynchronous systems [18], and the "asynchronous style" synchronous control networks used in Olympus <ref> [22] </ref> are indicative of this trend. Whichever course the hardware design community may ultimately follow, it seems inevitable that asynchronous design will play an increasing role as time goes by. Based on this assumption, we are justified in taking the approach of studying asynchronous designs in isolation, in this paper.
Reference: 23. <author> Stephen H. Unger. </author> <title> Asynchronous Sequential Switching Circuits. </title> <publisher> John-Wiley, </publisher> <year> 1969. </year>
Reference-contexts: In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of <ref> [23, 24] </ref>, as well as more recent works of [25, 10, 9, 26], which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category.
Reference: 24. <author> Arthur D. Friedman. </author> <title> Fundamentals of Logic Design and Switching Theory. </title> <publisher> Computer Science Press, </publisher> <year> 1986. </year>
Reference-contexts: In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of <ref> [23, 24] </ref>, as well as more recent works of [25, 10, 9, 26], which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category.
Reference: 25. <author> Jan Tijmen Udding. </author> <title> A formal model for defining and classifying delay-insensitive circuits and systems. </title> <journal> Distributed Computing, </journal> (1):197-204, 1986. <volume> 26 </volume>
Reference-contexts: In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of [23, 24], as well as more recent works of <ref> [25, 10, 9, 26] </ref>, which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category. <p> There are also many efforts in which macromodules are used directly for realizing state machines (i.e. for low level synthesis). Some examples are <ref> [25, 9] </ref>. Some of these distinctions are also rapidly blurring, with the use of complex gates that directly realize multi-input multi-output Boolean functions as macromodules. In SHILPA, macromodules are the target of compilation, at present.
Reference: 26. <author> Mark B. Josephs. </author> <title> Receptive process theory. </title> <journal> Acta Informatica, </journal> <volume> 29 </volume> <pages> 17-31, </pages> <year> 1992. </year>
Reference-contexts: In these efforts, asynchronous design is viewed as concurrent programming, where the computation to be implemented is expressed in a high-level concurrent HDL. This approach is more suitable for system level synthesis. This is in contrast to the works of [23, 24], as well as more recent works of <ref> [25, 10, 9, 26] </ref>, which are more suited for low level synthesis and verification of asynchronous state machines. Our system, SHILPA, belongs to the former category.
Reference: 27. <author> C. van Berkel, C. Niessen, M.Rem, and R.Saeijs. </author> <title> Vlsi programming and silicon compilation: a novel approach from phillips research. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Design (ICCD), </booktitle> <year> 1988. </year>
Reference-contexts: Our system, SHILPA, belongs to the former category. To the best of our knowledge, systems similar to ours that have been fully implemented and tried out in practice are those by Brunvand [14], van Berkel <ref> [27, 13] </ref>, and by Martin and Burns [11, 28]. Improvements in SHILPA over these works are primarily the following. hopCP, the source language for SHILPA, is more expressive than Martin's input language `CHP', Brunvand's version of `Occam', or van Berkel's language `Tangram'.
Reference: 28. <author> Steven M. Burns and Alain J. Martin. </author> <title> Synthesis of self-timed circuits by program transformation. </title> <booktitle> In Proc. 1988 IFIP WG 10.2 International Working Conference on "The Fusion of Hardware Design and Verification", </booktitle> <institution> Univ. of Strathclyde, </institution> <address> Glasgow, Scotland, </address> <pages> pages 97-114, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Our system, SHILPA, belongs to the former category. To the best of our knowledge, systems similar to ours that have been fully implemented and tried out in practice are those by Brunvand [14], van Berkel [27, 13], and by Martin and Burns <ref> [11, 28] </ref>. Improvements in SHILPA over these works are primarily the following. hopCP, the source language for SHILPA, is more expressive than Martin's input language `CHP', Brunvand's version of `Occam', or van Berkel's language `Tangram'.
Reference: 29. <author> Venkatesh Akella and Ganesh Gopalakrishnan. </author> <title> Static analysis techniques for the synthesis of efficient asynchronous circuits. </title> <type> Technical Report UUCS-91-018, </type> <institution> Dept. of Computer Science, University of Utah, </institution> <address> Salt Lake City, UT 84112, </address> <year> 1991. </year> <title> TAU '92: </title> <booktitle> 1992 Workshop on Timing Issues in the Specification and Synthesis of Digital Systems, </booktitle> <address> Princeton, NJ, March 18-20, </address> <year> 1992. </year>
Reference-contexts: This intermediate 4 form is very amenable to flow-analysis. Optimizations for resource sharing can be easily carried out on HFGs. Life-time analysis for variable reuse is also easy to carry out on HFGs. A tool called Concur <ref> [29] </ref>, that can determine if two actions are serially ordered or not, could be developed fairly easily, thanks to the HFG based notation. Concur is central to many of the optimizations performed by SHILPA.
Reference: 30. <author> Erik Brunvand. </author> <title> A cell set for self-timed design using Actel FPGAs. </title> <type> Technical Report 91-013, </type> <institution> Dept. of Computer Science, University of Utah, </institution> <address> Salt Lake City, UT 84112, </address> <year> 1991. </year>
Reference-contexts: Some examples are [25, 9]. Some of these distinctions are also rapidly blurring, with the use of complex gates that directly realize multi-input multi-output Boolean functions as macromodules. In SHILPA, macromodules are the target of compilation, at present. Our set of macromodules were originally developed by Brunvand <ref> [30] </ref> using the Actel field programmable gate arrays (FPGAs); we have made numerous extensions to this cell set. 5 Organization In Section 2, we briefly sketch the syntax and semantics of hopCP. In Section 3, we illustrate SHILPA on a two-stage pipeline. <p> If SHILPA does not find the pattern "formula" and "~formula," it assumes that the Boolean guards are not mutually exclusive, and uses an arbiter to select one of the true Boolean guards (Figure 2). We use the ring-style arbiter from <ref> [30] </ref> which functions (roughly) as follows: after a request is applied, a token is circulated within the arbiter; more than one reqi input may be asserted at any 8 time; one of these requests is acknowledged. In general, arbiters occupy more area to realize than predicate action blocks. <p> In general, arbiters occupy more area to realize than predicate action blocks. They also use circuits such as the interlock [2] that cannot be realized in many technologies, such as most of today's FPGAs. (Note: The FPGA realization in <ref> [30] </ref> is only an approximation, to permit rapid prototyping.) The different categories of variables, channel names, and their scoping rules, are as follows. <p> Suppose A IN happens first; then C2 fires. It generates A OUT and also returns the "call" through AS and A2 of CALL2. This transition first triggers XOR1 through its lower input. This causes another R2 on CALL1. We have selected the CALL implementation of <ref> [30] </ref> in which the sequence R1; R1 causes a sequence RS; RS (and likewise R2; R2 also causes RS; RS), and in addition, the CALL element is reset at the end of this sequence. Therefore, CALL1 is reset by the two R2 transitions it sees.
Reference: 31. <author> Venkatesh Akella. </author> <title> An Integrated Framework for High-Level Synthesis of Self-timed Circuits. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Utah, </institution> <year> 1992. </year>
Reference-contexts: The textual syntax for this abbreviated definition would be (after simplifications): T [x] = a?x -&gt; b!x+2 -&gt; T [x] Informal Execution Semantics The informal execution semantics of the example in Figure 1 are as follows (the formal semantics of hopCP are given in <ref> [31] </ref>). Suppose the execution is begun at P and R. These processes begin their execution concurrently. Process P first makes a choice between the guards a?z and b?x. This alternative ("choice") command has the same meaning as in CSP-like languages.
Reference: 32. <author> Venkatesh Akella and Ganesh Gopalakrishnan. </author> <title> Specification and validation of control intensive ics in hopcp. </title> <type> Technical Report UUCS-92-001, </type> <institution> Dept. of Computer Science, University of Utah, </institution> <address> Salt Lake City, UT 84112, </address> <year> 1991. </year> <note> Accept subject to revisions by the IEEE Transactions on Software Engineering. </note>
Reference-contexts: The availability of barrier synchronization as well as multicast offers considerable flexibility in specifying system level behavior, as we have shown through numerous large examples, notably the specification of the high level protocols obeyed by Intel 8251 USART <ref> [32] </ref>. These constructs are also useful for specifying concurrent algorithms [33]. These features of hopCP are absent from comparable languages that are used for asynchronous high level synthesis. Coming back to process P, consider a situation in which the communication actions a?z and b?x can arrive potentially concurrently.
Reference: 33. <author> Arthur Charlesworth. </author> <title> The Multiway Rendezvous. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 350-366, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The availability of barrier synchronization as well as multicast offers considerable flexibility in specifying system level behavior, as we have shown through numerous large examples, notably the specification of the high level protocols obeyed by Intel 8251 USART [32]. These constructs are also useful for specifying concurrent algorithms <ref> [33] </ref>. These features of hopCP are absent from comparable languages that are used for asynchronous high level synthesis. Coming back to process P, consider a situation in which the communication actions a?z and b?x can arrive potentially concurrently.
Reference: 34. <author> Ganesh Gopalakrishnan and Venkatesh Akella. </author> <title> A Transformational Approach to Asynchronous High-level Synthesis. </title> <booktitle> In VLSI-93. IFIP, </booktitle> <month> September </month> <year> 1993. </year> <note> To Appear. 27 </note>
Reference-contexts: When the addition finishes, the results of addition are first loaded into the result register (top-left reg8), and then transferred into register z (top-right reg8) before restarting process PZ. We are currently studying the process of semi-automating concurrent process decomposition in SHILPA <ref> [34] </ref>.
References-found: 34

