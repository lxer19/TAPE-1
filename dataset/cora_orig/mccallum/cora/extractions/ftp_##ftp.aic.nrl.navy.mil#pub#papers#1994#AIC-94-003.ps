URL: ftp://ftp.aic.nrl.navy.mil/pub/papers/1994/AIC-94-003.ps
Refering-URL: http://www.aic.nrl.navy.mil/~schultz/papers.html
Root-URL: 
Email: schultz@aic.nrl.navy.mil  
Title: LEARNING ROBOT BEHAVIORS USING GENETIC ALGORITHMS  
Author: ALAN C. SCHULTZ 
Keyword: THE LEARNING PARADIGM  
Note: Appeared in Procs. of the International Symposium on Robotics and Manufacturing, August 14-18, 1994.  
Address: Washington, DC 20375-5337  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory  
Abstract: Genetic Algorithms are used to learn navigation and collision avoidance behaviors for robots. The learning is performed under simulation, and the resulting behaviors are then used to control the The approach to learning behaviors for robots described here reflects a particular methodology for learning via a simulation model. The motivation is that making mistakes on real systems may be costly or dangerous. In addition, time constraints might limit the number of experiences during learning in the real world, while in many cases, the simulation model can be made to run faster than real time. Since learning may require experimenting with behaviors that might occasionally produce unacceptable results if applied to the real world, or might require too much time in the real environment, we assume that hypothetical behaviors will be evaluated in a simulation model (the off-line system). As illustrated in Figure 1, the current best behavior can be placed in the real, on-line system, while learning continues in the off-line system [1]. The learning algorithm was designed to learn useful behaviors from simulations of limited fidelity. The expectation is that behaviors learned in these simulations will be useful in real-world environments. Previous studies have illustrated that knowledge learned under simulation is robust and might be applicable to the real world if the simulation is more general (i.e. has more noise, more varied conditions, etc.) than the real world environment [2]. Where this is not possible, it is important to identify the differences between the simulation and the world and note the effect upon the learning process. The research reported here continues to examine this hypothesis. The next section very briefly explains the learning algorithm (and gives pointers to where more extensive documentation can be found). After that, the actual robot is described. Then we describe the simulation of the robot. The task _______________ actual robot.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Grefenstette, J. J. and C. L. Ramsey, </author> <title> An approach to anytime learning, </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <year> 1992, </year> <pages> (pp 189-195), </pages> <editor> D. Sleeman and P. Edwards (eds.), </editor> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: 2. <author> Ramsey, C. L., A. C. Schultz and J. J. Grefenstette, </author> <title> Simulation-assisted learning by competition: Effects of noise differences between training model and target environment. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <year> 1990, </year> <pages> (pp 211-215). </pages> <address> Austin, TX: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: 3. <author> Schultz, A. C. and J. J. Grefenstette, </author> <title> Improving tactical plans with genetic algorithms. </title> <booktitle> Proceedings of IEEE Conference on Tools for AI, </booktitle> <year> 1990, </year> <pages> (pp 328-334). </pages> <address> Washington, DC: </address> <publisher> IEEE. </publisher>
Reference: 4. <author> Gordon, D. F., </author> <title> An enhancer for reactive plans. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <year> 1991, </year> <pages> (pp 505-508). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: 5. <author> Schultz, A. C., </author> <title> Using a genetic algorithm to learn strategies for collision avoidance and local navigation. </title> <booktitle> Seventh International Symposium on Unmanned, Untethered, Submersible Technology, </booktitle> <year> 1991, </year> <pages> (pp 213-225). </pages> <address> Dur-ham, NH. </address>
Reference: 6. <author> Grefenstette, J. J., C. L. Ramsey and A. C. Schultz, </author> <title> Learning sequential decision rules using simulation models and competition. </title> <booktitle> Machine Learning 5(4), </booktitle> <year> 1990, </year> <pages> 355-381. </pages>
Reference: 7. <editor> Grefenstette, J. J., </editor> <booktitle> Lamarckian learning in multi-agent environments. Proceedings of the Fourth International Conference of Genetic Algorithms, </booktitle> <year> 1991, </year> <pages> (pp 303-310). </pages> <address> San Diego, CA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> 6 </pages>
References-found: 7

