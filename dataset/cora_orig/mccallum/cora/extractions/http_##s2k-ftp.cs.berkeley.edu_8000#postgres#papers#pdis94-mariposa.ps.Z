URL: http://s2k-ftp.cs.berkeley.edu:8000/postgres/papers/pdis94-mariposa.ps.Z
Refering-URL: http://s2k-ftp.cs.berkeley.edu:8000/mariposa/papers.html
Root-URL: 
Title: AN ECONOMIC PARADIGM FOR QUERY PROCESSING AND DATA MIGRATION IN MARIPOSA  
Author: Michael Stonebraker, Robert Devine, Marcel Kornacker, Witold Litwin, Avi Pfeffer, Adam Sah, and Carl Staelin 
Address: Berkeley, California 94720  
Affiliation: Computer Science Div., Dept. of EECS University of California  
Abstract: Many new database applications require very large volumes of data. Mariposa is a data base system under construction at Berkeley responding to this need. Mariposa objects can be stored over thousands of autonomous sites and on memory hierarchies with very large capacity. This scale of the system leads to complex query execution and storage management issues, unsolvable in practice with traditional techniques. We propose an economic paradigm as the solution. A query receives a budget which it spends to obtain the answers. Each site attempts to maximize income by buying and selling storage objects, and processing queries for locally stored objects. We present the protocols which underlie the Mariposa economy. 
Abstract-found: 1
Intro-found: 1
Reference: [BERN81] <author> Bernstein, P. A., Goodman, N., Wong, E., Reeve, C. L. and Rothnie, J. </author> <title> Query Processing in a System for Distributed Databases (SDD-1), </title> <journal> ACM Tr ans. on Database Sys. </journal> <volume> 6, 4, </volume> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: Author's current address: Enterprise Computing Group, Microsoft Corp., 1 Microsoft Way, Redmond, WA 98052. Author's current address: Hewlett-Packard Laboratories, P.O. Box 10490, Palo Alto, CA 94303. (2) Support data mobility. Previous distributed database systems (e.g., <ref> [WILL81, BERN81, LITW82, STON86] </ref>) and distributed storage managers (e.g., [HOWA88]) have all assumed that each storage object had a fixed home to which it is returned upon system quiescence.
Reference: [BERN83] <author> Bernstein, P. and Goodman, N., </author> <title> The Failure and Recovery Problem for Replicated Databases, </title> <booktitle> Proc. 1983 ACM Symp. on Principles of Distributed Computing, </booktitle> <address> Montreal, Quebec, Canada, </address> <month> Aug. </month> <year> 1983. </year>
Reference-contexts: Alternately, traditional distributed database systems implemented (or at least specified) support for permanent copies of database relations <ref> [WILL81, BERN83, ELAB85] </ref>. Our goal is to support both transient and permanent copies of storage fragments within a single framework. (7) Autonomous site decisions. In a very large network, it is unreasonable to assume that any central entity has control over policy decisions at the local sites.
Reference: [CHER89] <author> Cheriton, D. </author> <title> and Mann T.P., Decentralizing a Global Naming Service for Improved Performance and Fault Tolerance, </title> <journal> ACM Trans. on Comp. Sys. </journal> <volume> 7, 2, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: Like other objects, a name context can also be named. In addition, like data fragments, it can be migrated between name servers and there can be multiple copies residing on different servers for better load balancing and availability. This scheme differs from another proposed decentralized name service <ref> [CHER89] </ref> that avoided a centralized name authority by relying upon each type of server to manage their own names without relying on a dedicated name service. 4.2. Name Resolution A name must be resolved to discover which object is bound to the name.
Reference: [COPE88] <author> Copeland, G., Alexander, W., Boughter, E. and Keller, T., </author> <title> Data Placement in Bubba, </title> <booktitle> Proc. 1988 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Chicago, IL, </address> <month> Jun. </month> <year> 1988. </year>
Reference-contexts: Clearly, if there are too few fragments in a class, then parallel execution of Mariposa queries will be hindered. On the other hand, if there are too many fragments, then the overhead of dealing with all the fragments will increase and response time will suffer, as noted in <ref> [COPE88] </ref>. The algorithms for splitting and coalescing fragments must strike the correct balance between these two effects. One strategy is to simply let market pressure correct for inappropriate fragment sizes.
Reference: [DOZI92] <author> Dozier, J., </author> <title> How Sequoia 2000 Addresses Issues in Data and Information Systems for Global Change, </title> <type> Sequoia 2000 Technical Report 92/14, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> Aug. </month> <year> 1992. </year>
Reference: [ELAB85] <author> El Abbadi, A., Skeen, D. and Cristian, F., </author> <title> An Efficient, Fault-Tolerant Protocol for Replicated Data Management, </title> <booktitle> Proc. 4th ACM SIGMOD-SIGACT Symp. on Principles of Database Systems, </booktitle> <address> Portland, OR, </address> <month> Mar. </month> <year> 1985. </year>
Reference-contexts: Alternately, traditional distributed database systems implemented (or at least specified) support for permanent copies of database relations <ref> [WILL81, BERN83, ELAB85] </ref>. Our goal is to support both transient and permanent copies of storage fragments within a single framework. (7) Autonomous site decisions. In a very large network, it is unreasonable to assume that any central entity has control over policy decisions at the local sites.
Reference: [EPST78] <author> Epstein, R. S., Stonebraker, M. and Wong, E., </author> <title> Distributed Query Processing in Relational Database Systems, </title> <booktitle> Proc. 1978 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Austin, TX, </address> <month> May </month> <year> 1978. </year>
Reference-contexts: Traditional distributed database systems operate by moving the query from a client site to the site where the object resides, and then moving the result of the query back to the client <ref> [EPST78, LOHM86] </ref>. This implements a move the query to the data processing scenario. Alternately, distributed file systems and object-oriented database systems move the data a storage block at a time from a server to a client. As such, they implement a move the data to the query processing scenario.
Reference: [FERG93] <author> Ferguson, D., Nikolaou, C. and Yemini, Y., </author> <title> An Economy for Managing Replicated Data in Autonomous Decentralized Systems, </title> <booktitle> Proc. Int. Symp. on Autonomous Decentralized Sys. </booktitle> <address> (ISADS 93), Kaw asaki, Japan, </address> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: Lastly, each processing site makes storage decisions to buy and sell fragments and copies of fragments, based on optimizing the revenue it collects. Our model is similar to <ref> [FERG93, WALD92, MALO88] </ref> which take similar economic approaches to other computer resource allocation problems. In the next section, we describe the three kinds of entities in our economic system. <p> Here, CPU time on remote machines is auctioned off by the processing sites and applications hand in bids for time slices. This is is contrast to our system, where processing sites make bids for servicing requests. A model similar to ours is proposed in <ref> [FERG93] </ref>, where fragments can be moved and replicated between the nodes of a network of computers, although they are not allowed to be split or coalesced. Transactions are given a budget when entering the system. Accesses to fragments are purchased from the sites offering them at the desired price/quality ratio.
Reference: [HONG91] <author> Hong, W. and Stonebraker, M., </author> <title> Optimization of Parallel Query Execution Plans in XPRS, </title> <booktitle> Proc. 1st Int. Conf. on Parallel and Distributed Info. Sys., </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Locally defined rules may affect how the subqueries are assigned to sites. Decomposing query plans in the manner just described greatly reduces optimizer complexity. Signs that the resulting plans may not be significantly suboptimal appear in <ref> [HONG91] </ref>, where a similar decomposition is studied. Decomposing the plan before distributing it also makes it easier to assign portions of the budget to sub-queries. Servers. Server sites provide a processor with varying amounts of persistent storage.
Reference: [HOWA88] <author> Howard, J. H., Kazar, M. L. Menees, S. G., Nichols, D. A., Satyanarayanan, M., Sidebotham, R. N. and West, M. J., </author> <title> Scale and Performance in a Distributed File System, </title> <journal> ACM Trans. on Comp. Sys. </journal> <volume> 6, 1, </volume> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Author's current address: Enterprise Computing Group, Microsoft Corp., 1 Microsoft Way, Redmond, WA 98052. Author's current address: Hewlett-Packard Laboratories, P.O. Box 10490, Palo Alto, CA 94303. (2) Support data mobility. Previous distributed database systems (e.g., [WILL81, BERN81, LITW82, STON86]) and distributed storage managers (e.g., <ref> [HOWA88] </ref>) have all assumed that each storage object had a fixed home to which it is returned upon system quiescence. Changing the home of an an object is a heavyweight operation that entails, for example, destroying and recreating all the indexes for that object.
Reference: [HUBE88] <author> Huberman, B. A. (ed.), </author> <title> The Ecology of Computation, </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: The quality of service is then a measurement of the metadata's rate of update as well as the name server's rate of update. 5. RELATED WORK So far there are only a few systems documented in the literature which incorporate microeconomic approaches to deal with resource sharing problems. <ref> [HUBE88] </ref> contains a collection of articles that cover the underlying principles and explore the behavior of those systems. [KURO89] present a solution to the file allocation problem that makes use of microeconomic principles, but is based on a cooperative, not competitive environment. [MALO88] describes the implementation of a process migration facility
Reference: [KURO89] <author> Kurose, J. and Simha, R., </author> <title> A Microeconomic Approach to Optimal Resource Allocation in Distributed Computer Systems, </title> <journal> IEEE Trans. on Computers 38, </journal> <volume> 5, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: RELATED WORK So far there are only a few systems documented in the literature which incorporate microeconomic approaches to deal with resource sharing problems. [HUBE88] contains a collection of articles that cover the underlying principles and explore the behavior of those systems. <ref> [KURO89] </ref> present a solution to the file allocation problem that makes use of microeconomic principles, but is based on a cooperative, not competitive environment. [MALO88] describes the implementation of a process migration facility for a pool of workstations connected through a LAN.
Reference: [LAMP86] <author> Lampson, B., </author> <title> Designing a Global Name Service, </title> <booktitle> Proc. ACM Symp. on Principles of Distributed Computing, </booktitle> <address> Calgary, Alberta, Canada, </address> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: All full names are globally unique within the name space however the policy for selecting names is locally defined. So as not to constrain the later growth of the name space from the amalgamation of other name spaces, a non-fixed-root name space as suggested in <ref> [LAMP86] </ref> can be used to support upwards growth beyond the current root. Finally, a name context is a set of names that are affiliated.
Reference: [LITW82] <author> Litwin, W. et al., </author> <title> SIRIUS System for Distributed Data Management, in Distributed Data Bases, </title> <editor> H. J. Schneider (ed.), </editor> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1982. </year>
Reference-contexts: Author's current address: Enterprise Computing Group, Microsoft Corp., 1 Microsoft Way, Redmond, WA 98052. Author's current address: Hewlett-Packard Laboratories, P.O. Box 10490, Palo Alto, CA 94303. (2) Support data mobility. Previous distributed database systems (e.g., <ref> [WILL81, BERN81, LITW82, STON86] </ref>) and distributed storage managers (e.g., [HOWA88]) have all assumed that each storage object had a fixed home to which it is returned upon system quiescence.
Reference: [LOHM86] <author> Mackert, L. F. and Lohman, G. M., </author> <title> R* Optimizer Validation and Performance Evaluation for Local Queries, </title> <booktitle> Proc. 1986 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Washington, DC, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: Traditional distributed database systems operate by moving the query from a client site to the site where the object resides, and then moving the result of the query back to the client <ref> [EPST78, LOHM86] </ref>. This implements a move the query to the data processing scenario. Alternately, distributed file systems and object-oriented database systems move the data a storage block at a time from a server to a client. As such, they implement a move the data to the query processing scenario. <p> Moreover, it must convert site-independent resource usage numbers into ones specific to its site through a weighting function, as in <ref> [LOHM86] </ref>. In addition, it must assume that it would have successfully bid on the same set of queries as appeared in the revenue history. Since it will be faster or slower than the site from which the revenue history was collected, it must adjust the revenue collected for each query.
Reference: [MALO88] <author> Malone, T. W., Fikes, R. E., Grant, K. R. and Howard, M. T., </author> <title> Enterprise: A Market-like Task Scheduler for Distributed Computing Environments, </title> <booktitle> in [HUBE88]. </booktitle>
Reference-contexts: Lastly, each processing site makes storage decisions to buy and sell fragments and copies of fragments, based on optimizing the revenue it collects. Our model is similar to <ref> [FERG93, WALD92, MALO88] </ref> which take similar economic approaches to other computer resource allocation problems. In the next section, we describe the three kinds of entities in our economic system. <p> microeconomic approaches to deal with resource sharing problems. [HUBE88] contains a collection of articles that cover the underlying principles and explore the behavior of those systems. [KURO89] present a solution to the file allocation problem that makes use of microeconomic principles, but is based on a cooperative, not competitive environment. <ref> [MALO88] </ref> describes the implementation of a process migration facility for a pool of workstations connected through a LAN. In this system, a client broadcasts a request for bids that includes a task description.
Reference: [MILL88] <author> Miller, M. S. and Drexler, K. E., </author> <title> Markets and Computation: Agoric Open Systems, </title> <booktitle> in [HUBE88]. </booktitle>
Reference: [SELI79] <author> Selinger, P. G., Astrahan, M. M., Chamberlin, D. D., Lorie, R. A. and Price, T. G., </author> <title> Access Path Selection in a Relational Database Management System, </title> <booktitle> Proc. 1979 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Boston, MA, </address> <month> Jun. </month> <year> 1979. </year>
Reference-contexts: After successful parsing, the broker prepares a query execution plan. This is a two-step process. First, a conventional query optimizer along the lines of <ref> [SELI79] </ref> generates a single site query execution plan by assuming that all the fragments are merged together and reside at a single server site.
Reference: [STON86] <author> Stonebraker, M., </author> <title> The Design and Implementation of Distributed INGRES, in The INGRES Papers, </title> <editor> M. Stonebraker (ed.), </editor> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Author's current address: Enterprise Computing Group, Microsoft Corp., 1 Microsoft Way, Redmond, WA 98052. Author's current address: Hewlett-Packard Laboratories, P.O. Box 10490, Palo Alto, CA 94303. (2) Support data mobility. Previous distributed database systems (e.g., <ref> [WILL81, BERN81, LITW82, STON86] </ref>) and distributed storage managers (e.g., [HOWA88]) have all assumed that each storage object had a fixed home to which it is returned upon system quiescence.
Reference: [STON91a] <author> Stonebraker, M. and Kemnitz, G., </author> <title> The POST-GRES Next-Generation Database Management System, </title> <journal> Comm. of the ACM 34, </journal> <volume> 10, </volume> <month> Oct. </month> <year> 1991. </year>
Reference: [STON91b] <author> Stonebraker, M., </author> <title> An Overview of the Sequoia 2000 Project, </title> <type> Sequoia 2000 Technical Report 91/5, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> Dec. </month> <year> 1991. </year>
Reference: [STON94a] <author> Stonebraker, M., Aoki, P. M., Devine, R., Litwin, W. and Olson, M., Mariposa: </author> <title> A New Architecture for Distributed Data, </title> <booktitle> Proc. 10th Int. Conf. on Data Engineering, </booktitle> <address> Houston, TX, </address> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION <ref> [STON94a] </ref> presents the design of a new distributed database and storage system, called Mariposa. This system combines the best features of traditional distributed database systems, object-oriented DBMSs, tertiary memory file systems and distributed file systems. The goals of Mariposa are manifold: (1) Support a very large number of sites. <p> This paral-lelizes the single site plan produced from the first step. The details of this fragmentation process are described in <ref> [STON94a] </ref>.
Reference: [STON94b] <author> Stonebraker, M., Devine, R., Kornacker, M., Litwin, W., Pfeffer, A., Sah, A. and Staelin, C. </author> <title> An Economic Paradigm for Query Processing and Data Migration in Mariposa, </title> <type> Sequoia 2000 Technical Report 94/49, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The second algorithm takes the budget of the entire query and the structure of the query plan to produce a subbudget for each subquery. This algorithm is presented in more detail in <ref> [STON94b] </ref>. 3.2. Finding Contractors Using either the expensive or the cheap protocol from the previous section, a broker must be able to effectively identify one (or more) sites who may process a subquery. <p> We expect that global updates of metadata will suffer from a scalability problem, sacrificing the advantages of the decentralized nature of microeconomic decisions. More detailed comparisons of Mariposa with other systems can be found in <ref> [STON94b] </ref>. 6. CONCLUSIONS We present a distributed microeconomic approach to deal with query execution and storage management. The difficulty in scheduling distributed actions in a large system stems from the combinatorially large number of possible choices for each action, expense of global synchronization, and requirement for supporting heterogeneous systems.
Reference: [WALD92] <author> Waldspurger, C. A., Hogg, T., Huberman, B., Kephart, J. and Stornetta, S., Spawn: </author> <title> A Distributed Computational Ecology, </title> <journal> IEEE Trans. on Software Engineering 18, </journal> <volume> 2, </volume> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Lastly, each processing site makes storage decisions to buy and sell fragments and copies of fragments, based on optimizing the revenue it collects. Our model is similar to <ref> [FERG93, WALD92, MALO88] </ref> which take similar economic approaches to other computer resource allocation problems. In the next section, we describe the three kinds of entities in our economic system. <p> The client then sends that task to the server with the lowest completion time. Another distributed process scheduling system is presented in <ref> [WALD92] </ref>. Here, CPU time on remote machines is auctioned off by the processing sites and applications hand in bids for time slices. This is is contrast to our system, where processing sites make bids for servicing requests.
Reference: [WELL93] <author> Wellman, M. P. </author> <title> A Market-Oriented Programming Environment and Its Applications to Distributed Multicommodity Flow Problems, </title> <journal> Journal of AI Research 1, </journal> <volume> 1, </volume> <month> Aug. </month> <year> 1993. </year>
References-found: 25

