URL: ftp://cs.mtu.edu/pub/carr/modulo.ps.gz
Refering-URL: http://www.cs.rice.edu:80/~cding/publications.html
Root-URL: 
Title: Modulo Scheduling with Cache Reuse Information  
Author: Chen Ding Steve Carr Phil Sweany 
Abstract: Instruction scheduling in general, and software pipe-lining in particular face the difficult task of scheduling operations in the presence of uncertain latencies. The largest contributor to these uncertain latencies is the use of cache memories required to provide adequate memory access speed in modern processors. Scheduling for instruction-level parallel architectures with non-blocking caches usually assigns memory access latency by assuming either that all accesses are cache hits or that all are cache misses. We contend that allowing memory latencies to be set by cache reuse analysis leads to better software pipelining than using either the all-hit or all-miss assumption. Using a simple cache reuse model in our modulo scheduling software pipelining optimization, we achieved a benefit of 10% improved execution performance over assuming all-cache-hits and we used 18% fewer registers than were required by an all-cache-miss assumption. In addition, we outline refinements to our simple reuse model that should allow modulo scheduling with reuse to achieve improved execution performance over the all-cache-miss assumption as well. Therefore, we conclude that software pipelining algorithms for target architectures with non-blocking cache, but without rotating register files, should use a memory-reuse latency model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aiken, A., and Nicolau, A. </author> <title> Optimal loop par-allelization. </title> <booktitle> In Conference on Programming Language Design and Implementation (Atlanta Geor-gia, </booktitle> <month> June </month> <year> 1988), </year> <booktitle> SIGPLAN '88, </booktitle> <pages> pp. 308-317. </pages>
Reference-contexts: After scheduling the N copies of the loop, some pattern recognition technique is used to identify a repeating kernel within the schedule. Examples of kernel recognition methods are Aiken and Nicolau's perfect pipelining method <ref> [1, 2] </ref> and Allan's petri-net pipelining technique [4]. In contrast to kernel recognition methods, modulo scheduling does not schedule multiple iterations of a loop and then look for a pattern.
Reference: [2] <author> Aiken, A., and Nicolau, A. </author> <title> Perfect Pipelining: </title>
Reference-contexts: After scheduling the N copies of the loop, some pattern recognition technique is used to identify a repeating kernel within the schedule. Examples of kernel recognition methods are Aiken and Nicolau's perfect pipelining method <ref> [1, 2] </ref> and Allan's petri-net pipelining technique [4]. In contrast to kernel recognition methods, modulo scheduling does not schedule multiple iterations of a loop and then look for a pattern.
References-found: 2

