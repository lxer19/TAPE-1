URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/fp/public/papers/lics89.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/fp/public/papers/
Root-URL: http://www.cs.cmu.edu
Email: Internet: fp@cs.cmu.edu  
Title: Elf: A Language for Logic Definition and Verified Metaprogramming  
Author: Frank Pfenning 
Date: June 5-8, 1989.  
Note: This research was supported in part by the Office of Naval Research under contract N00014-84-K-0415 and in part by the Defense Advanced Research Projects Agency (DOD), ARPA Order No. 5404, monitored by the Office of Naval Research under the same contract. To appear at the Fourth Annual Symposium on Logic in Computer Science, Asilomar, California,  
Address: Pittsburgh, Pennsylvania 15213-3890  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: We describe Elf, a metalanguage for proof manipulation environments that are independent of any particular logical system. Elf is intended for meta-programs such as theorem provers, proof transformers, or type inference programs for programming languages with complex type systems. Elf unifies logic definition (in the style of LF, the Edinburgh Logical Framework) with logic programming (in the style of Prolog). It achieves this unification by giving types an operational interpretation, much the same way that Prolog gives certain formulas (Horn-clauses) an operational interpretation. Novel features of Elf include: (1) the Elf search process automatically constructs terms that can represent object-logic proofs, and thus a program need not construct them explicitly, (2) the partial correctness of meta-programs with respect to a given logic can be expressed and proved in Elf itself, and (3) Elf exploits Elliott's unification algorithm for a -calculus with dependent types. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [1] <author> Arnon Avron, Furio A. Honsell, and Ian A. Mason. </author> <title> Using Typed Lambda Calculus to Implement Formal Systems on a Machine. </title> <type> Technical Report ECS-LFCS-87-31, </type> <institution> Laboratory for Foundations of Computer Science, University of Edin-burgh, Edinburgh, </institution> <address> Scotland, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs. In <ref> [1] </ref>, Avron, Honsell, and Mason give a variety of examples for encoding logics in LF. Griffin's EFS (Environment for Formal Systems, see [14]) is an implementation that allows definition of logics and interactive theorem proving in LF. <p> Secondly, products combined with polymorphism significantly strengthen Elf as a representation and metapro-gramming language to handle the common case of a object languages with binding constructs of variable arity (see [27]). For example, a natural encoding of Hoare logic in LF as given in Section 4.10 of <ref> [1] </ref> must be restricted to a fixed number of registers|a restriction that can be dropped in with polymorphism. Thirdly, -types can introduce "constants" that are local to a module as -quantified variables, something not possible in Prolog.
Reference: [2] <author> M. Beeson. </author> <title> Some applications of Gentzen's proof theory in automated deduction. </title> <note> 1988. Submitted. </note>
Reference-contexts: Often the search space for such relations is linear and a decision procedure can be given immediately, that is, the signature itself may be used dynamically. Natural deduction theorem provers such as Gentzen (see Beeson <ref> [2] </ref>) or those proposed by Felty and Miller [11] can also be expressed very naturally in Elf. The extraction of programs from proofs is another example of the kind of algorithm that can easily be implemented in Elf.
Reference: [3] <author> Robert L. Constable et al. </author> <title> Implementing Mathematics with the Nuprl Proof Development System. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1986. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF [12], HOL [13], Calculus of Constructions [5], Isabelle [25], NuPrl <ref> [3] </ref>). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs.
Reference: [4] <author> Robert L. Constable, Todd Knoblock, and Joseph L. Bates. </author> <title> Writing programs that construct proofs. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 1(3) </volume> <pages> 285-326, </pages> <year> 1984. </year>
Reference-contexts: Finally, the partial correctness of meta-programs with respect to a given logic can be expressed and proved by Elf itself (see the example in Section 5.2). This creates the possibility of deriving verified meta-programs through theorem proving in Elf (see Constable, Knoblock & Bates <ref> [4] </ref>, Knoblock & Constable [19] or Howe [17] for other approaches). The base language for Elf is the LF type theory (a simply typed -calculus extended to allow dependent function types), enriched with strong sums (which we prefer to call dependent products).
Reference: [5] <author> Thierry Coquand and Gerard Huet. </author> <title> The calculus of constructions. </title> <journal> Information and Computation, </journal> 76(2/3):95-120, February/March 1988. 
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF [12], HOL [13], Calculus of Constructions <ref> [5] </ref>, Isabelle [25], NuPrl [3]). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs.
Reference: [6] <author> N. G. de Bruijn. </author> <title> A survey of the project Au-tomath. </title> <editor> In J. P. Seldin and J. R. Hindley, editors, To H. B. </editor> <booktitle> Curry: Essays on Combina-tory Logic, Lambda Calculus and Formalism, </booktitle> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath <ref> [6] </ref>, LCF [12], HOL [13], Calculus of Constructions [5], Isabelle [25], NuPrl [3]). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs.
Reference: [7] <author> Conal Elliott. </author> <title> Higher-order unification with dependent types. In Rewriting Techniques and Applications, </title> <publisher> Springer-Verlag LNCS, </publisher> <month> April </month> <year> 1989. </year> <note> To appear. Elf 10 </note>
Reference-contexts: Transitions correspond either to unification steps or steps in a goal-directed search for a term of the given type. The unification steps are based on an extensions of Elliott's unification algorithm on terms in the LF type theory (see <ref> [7] </ref> and [8]). The non-deterministic interpreter is made practical by a commitment to depth-first search, a distinction between open and closed judgments and dynamic and static constants, and the addition of the cut search directive familiar from Prolog (see Section 4). <p> Note that A i may contain N j for j &lt; i, and A may contain all terms N i . Unification transitions U . Unfortunately, space does not permit to include a presentation of the unification transitions, which are discussed in <ref> [7] </ref>. <p> Under the assumption of the weak 1 Pairs in solved form are guaranteed to have solutions. El-liott's unification algorithm uses the criterion that both M and N are "flexible" (see <ref> [7] </ref>). Elf 6 : G : M 2 x:A : B =) 8x:A 9y:B : M x = y 2 B ^ y 2 B Atom : M 2 C =) x 2 A M 2 C where M 2 C is in the scope of 8x:A. <p> The basic mechanism for term inference in is described in <ref> [7] </ref>. It is extremely important to note that term inference, as defined by Elliott, does not require general theorem proving, since it leaves free variables of closed type uninstantiated, even though there may not be any terms without free variables of such a type.
Reference: [8] <author> Conal Elliott. </author> <title> Some Extensions and Applications of Higher-order Unification: A Thesis Proposal. </title> <type> Ergo Report 88-061, </type> <institution> Carnegie Mellon University, Pittsburgh, </institution> <month> June </month> <year> 1988. </year> <note> Thesis to appear June 1989. </note>
Reference-contexts: Transitions correspond either to unification steps or steps in a goal-directed search for a term of the given type. The unification steps are based on an extensions of Elliott's unification algorithm on terms in the LF type theory (see [7] and <ref> [8] </ref>). The non-deterministic interpreter is made practical by a commitment to depth-first search, a distinction between open and closed judgments and dynamic and static constants, and the addition of the cut search directive familiar from Prolog (see Section 4). <p> required here, both of which have been described for the simply typed -calculus and carry over to in a straightforward way: (1) the dependency of universal and existen tial quantifiers must be taken into account without Skolemization (see Miller [23]), and (2) the algorithm must deal with products (see Elliott <ref> [8] </ref>). We write =) fl for the reflexive and transitive closure of the transition relation =). At this point we are ready to formulate a first preliminary soundness and completeness theorems for the abstract interpreter with respect to the state logic.
Reference: [9] <author> Amy Felty. </author> <title> Implementing Theorem Provers in Logic Programming. </title> <type> Technical Report MS-CIS-87-109, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: Felty showed in <ref> [9] </ref> how to implement the reductions in Prolog, but at a very heavy price. Each of her clauses contains a proof-checking subgoal that may be very expensive to execute.
Reference: [10] <author> Amy Felty and Dale Miller. </author> <title> A metalanguage for type checking and inference. November 1988. </title> <type> Manuscript. </type>
Reference-contexts: We are also considering a sublanguage of Elf along the lines of Felty and Miller's L <ref> [10] </ref> for which unification would be decidable. Acknowledgments I would like to thank Ken Cline, Conal Elliott, Amy Felty, and Dale Miller for helpful discussions concerning the subject of this paper.
Reference: [11] <author> Amy Felty and Dale A. Miller. </author> <title> Specifying theorem provers in a higher-order logic programming language. </title> <editor> In Ewing Lusk and Ross Overbeek, editors, </editor> <booktitle> 9th International Conference on Automated Deduction, </booktitle> <address> Argonne, </address> <publisher> Illinois, </publisher> <pages> pages 61-80, </pages> <publisher> Springer-Verlag LNCS 310, </publisher> <address> Berlin, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Secondly, Elf avoids the undesirable operational behavior of meta-programs that sometimes arises from encoding a logic in higher-order logic as done in Isabelle [25] and by Felty and Miller in <ref> [11] </ref> (see the example in Section 5.3). Finally, the partial correctness of meta-programs with respect to a given logic can be expressed and proved by Elf itself (see the example in Section 5.2). <p> Often the search space for such relations is linear and a decision procedure can be given immediately, that is, the signature itself may be used dynamically. Natural deduction theorem provers such as Gentzen (see Beeson [2]) or those proposed by Felty and Miller <ref> [11] </ref> can also be expressed very naturally in Elf. The extraction of programs from proofs is another example of the kind of algorithm that can easily be implemented in Elf. In many of these examples, the implementations are related to Prolog implementations of a similar flavor. <p> partial correctness of many programs can be guaranteed by Elf, and (3) the operational behavior of Elf is much better when explicit type-checking or proof-checking would be required in Prolog (as is frequently necessary in the programs obtained by translating LF signatures into Prolog programs as outlined by Felty in <ref> [11] </ref>). 6 Implementation and further work An implementation of Elf in Common Lisp is in progress in the framework of the Ergo project at Carnegie Mellon University.
Reference: [12] <author> Michael J. Gordon, Arthur J. Milner, and Christopher P. </author> <title> Wadsworth. </title> <publisher> Edinburgh LCF. Springer-Verlag LNCS 78, </publisher> <year> 1979. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF <ref> [12] </ref>, HOL [13], Calculus of Constructions [5], Isabelle [25], NuPrl [3]). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs.
Reference: [13] <author> Mike Gordon. </author> <title> HOL: A Machine Oriented Formulation of Higher-order Logic. </title> <type> Technical Report 68, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF [12], HOL <ref> [13] </ref>, Calculus of Constructions [5], Isabelle [25], NuPrl [3]). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs.
Reference: [14] <author> Timothy G. Griffin. </author> <title> An Environment for Formal Systems. </title> <type> Technical Report 87-846, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: LF provides a uniform way of encoding a logical language, its inference rules and its proofs. In [1], Avron, Honsell, and Mason give a variety of examples for encoding logics in LF. Griffin's EFS (Environment for Formal Systems, see <ref> [14] </ref>) is an implementation that allows definition of logics and interactive theorem proving in LF. EFS provides a nice syntactic environment, but lacks meta-programming support, this is, it lacks a metalan-guage for programming theorem proving, type inference, proof transformation, and similar tasks.
Reference: [15] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <note> Jan-uary 1989. Submitted to JACM. A preliminary version appeared in Symposium on Logic in Computer Science, pages 194-204, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF [12], HOL [13], Calculus of Constructions [5], Isabelle [25], NuPrl [3]). In <ref> [15] </ref>, Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs. <p> In Section 5 we give excerpts from some example Elf programs. An implementation of Elf in Common Lisp is currently in progress in the framework of the Ergo project at Carnegie Mellon University. 2 The base language The base language for Elf, , is the type theory of LF <ref> [15] </ref>, , enriched by a type constructor. The motivation for extending the LF type theory by are discussed in Section 4.4. We are excluding the type family constructor as a matter of convenience|in the formulation of LF in [15], at the level of types does not appear in normal forms of <p> The base language for Elf, , is the type theory of LF <ref> [15] </ref>, , enriched by a type constructor. The motivation for extending the LF type theory by are discussed in Section 4.4. We are excluding the type family constructor as a matter of convenience|in the formulation of LF in [15], at the level of types does not appear in normal forms of types and thus seems essential only for the formulation of type inference algorithms. <p> To simplify the presentation we consider ff-convertible terms to be identical and also assume that all constants in a signature and variables in a context are distinct. 2.1 Syntax There are five syntactic categories, just as in . In order to be consistent with the notation in <ref> [15] </ref> we overloaded the symbol to stand for signatures and also be used as a type constructor. It should always be obvious which one is meant. We will use M and N to stand for terms, A and B to stand for types, and K to stand for kinds. <p> Atomic types C are types that begin with neither a nor a . 2.2 Typing rules We adopt the presentation from <ref> [15] </ref> and add the following rules for dependent products (strong sums): Elf 3 ` A 2 Type ; x:A ` B 2 Type ` x:A : B 2 Type ` M 2 A ` N 2 [M=x]B ` M 2 x:A : B ` M 2 x:A : B 2.3 Conversion <p> One can weaken the notion of conversion and obtain the Church-Rosser property by omitting and , but a complete abstract interpreter for Elf using this weaker notion would have to be unduly complex. For (without pairing) these tradeoffs already exist and are discussed at some length in <ref> [15] </ref>. <p> Theorem 1 (Basic properties of under weak con version.) 1. All terms are Church-Rosser. 2. All well-typed terms are strongly normalizing. 3. Type-checking and kind-checking is decidable. Proof sketch: The proof is an extension of the one in <ref> [15] </ref>. Church-Rosser for this weak notion of conversion can be proved as in [15], since it holds for all, and not only for well-typed terms. To prove strong normalization, we translate both types and terms from into terms in a simply typed -calculus with products and explicit types. <p> All terms are Church-Rosser. 2. All well-typed terms are strongly normalizing. 3. Type-checking and kind-checking is decidable. Proof sketch: The proof is an extension of the one in <ref> [15] </ref>. Church-Rosser for this weak notion of conversion can be proved as in [15], since it holds for all, and not only for well-typed terms. To prove strong normalization, we translate both types and terms from into terms in a simply typed -calculus with products and explicit types. <p> Intuitively, we are willing to tolerate free variables of open type in proofs, but no free variables of closed type. In an encoding of first-order logic as in <ref> [15] </ref>, true would be a closed judgment, while i (representing the domain of individuals) would be an open judgment. It is the programmer's respon sibility to annotate constants in the signature as open or closed, but a convenient defaulting mechanism is provided. <p> It is very close to the LF encoding in <ref> [15] </ref>, with the exception of some annotations.
Reference: [16] <author> Robert Harper, Donald Sannella, and Andrzej Tarlecki. </author> <title> Structure and representation in the Ed-inburgh logical framework. This volume. </title>
Reference-contexts: The additional complexity of types over terms is small and term-inference 3 similar to the ones in Prolog, see [20]. Another related approach to structuring of theories may be found in <ref> [16] </ref>. can be extended easily to type inference. A more serious practical problem is that of ambiguity: omitted types and terms can often be restored in a number of incompatible ways. Currently, we require more information from the user in such a case.
Reference: [17] <author> Douglas J. Howe. </author> <title> Computational metatheory in Nuprl. </title> <editor> In Ewing Lusk and Ross Overbeek, editors, </editor> <booktitle> 9th International Conference on Automated Deduction, </booktitle> <address> Argonne, </address> <publisher> Illinois, </publisher> <pages> pages 238-257, </pages> <publisher> Springer-Verlag LNCS 310, </publisher> <address> Berlin, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: This creates the possibility of deriving verified meta-programs through theorem proving in Elf (see Constable, Knoblock & Bates [4], Knoblock & Constable [19] or Howe <ref> [17] </ref> for other approaches). The base language for Elf is the LF type theory (a simply typed -calculus extended to allow dependent function types), enriched with strong sums (which we prefer to call dependent products).
Reference: [18] <author> Joxan Jaffar and Jean-Louis Lassez. </author> <title> Constraint logic programming. </title> <booktitle> In Proceedings of the Fourteenth Annual ACM Symposium on Principles of Programming Languages, Munich, </booktitle> <pages> pages 111-119, </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1987. </year>
Reference-contexts: It is interesting to note that this condition is independent of any notion Elf 4 of unification and thus encompasses constraint logic programming (see Jaffar & Lassez <ref> [18] </ref>). Here we are in a similar situation, turning a type theory into a programming language. The basic idea is to give types an operational interpretation much in the same way that formulas are given an operational interpretation in a logic programming language. Informally, this operational interpretation is as follows. <p> Oth erwise we backtrack over previous choices. 4. If F is T , an equality in solved form, or M 2 C for open C, we pass over it, looking for the next atomic formula. Thus, equalities in solved form are constraints in the sense of Jaffar & Lassez <ref> [18] </ref>. 5. If F is an equality not in solved form, we call the unification algorithm on the whole state. Unification may fail (upon which we backtrack), not terminate, or replace the given equality by a conjunction of solved equalities, with T representing the empty conjunction.
Reference: [19] <author> Todd B. Knoblock and Robert L. Constable. </author> <title> Formalized metareasoning in type theory. </title> <booktitle> In First Annual Symposium on Logic in Computer Science, </booktitle> <address> Cambridge, Massachusetts, </address> <pages> pages 237-248, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: Finally, the partial correctness of meta-programs with respect to a given logic can be expressed and proved by Elf itself (see the example in Section 5.2). This creates the possibility of deriving verified meta-programs through theorem proving in Elf (see Constable, Knoblock & Bates [4], Knoblock & Constable <ref> [19] </ref> or Howe [17] for other approaches). The base language for Elf is the LF type theory (a simply typed -calculus extended to allow dependent function types), enriched with strong sums (which we prefer to call dependent products).
Reference: [20] <author> Dale Miller. </author> <title> A logical analysis of modules for logic programming. </title> <journal> Journal of Logic Programming, </journal> <note> 1988. To appear. </note>
Reference-contexts: Experience with higher-order unification suggests that -unification should be able to handle most practical examples of term inference rather easily, so a small resource bound should suffice. The additional complexity of types over terms is small and term-inference 3 similar to the ones in Prolog, see <ref> [20] </ref>. Another related approach to structuring of theories may be found in [16]. can be extended easily to type inference. A more serious practical problem is that of ambiguity: omitted types and terms can often be restored in a number of incompatible ways.
Reference: [21] <author> Dale Miller, Gopalan Nadathur, Frank Pfenning, and Andre Scedrov. </author> <title> Uniform proofs as a foundation for logic programming. </title> <journal> Journal of Pure and Applied Logic, </journal> <note> 1988. To appear. </note>
Reference-contexts: Its range of applications therefore include the range of applications of such environments (as indicated above). The basic idea behind Elf is to unify logic definition (in the style of LF) with logic pro Elf 2 gramming (in the style of Prolog, see <ref> [22, 21, 24] </ref>). It achieves this unification by giving types an operational interpretation, much the same way that Prolog gives certain formulas (Horn-clauses) an operational interpretation. Here are some of the salient characteristics of this unified approach to logic definition and metaprogram-ming. <p> Unlike in Prolog, no restriction on goals or programs needs to be made: the completeness theorem for our abstract interpreter guarantees that goal-directed search is complete. Thus, Elf is a language in the spirit of Miller, Nadathur, Pfenning and Scedrov's <ref> [21] </ref> definition of an abstract logic programming language, though it is not based on logic but on the type theory. The abstract interpreter, formulated as a transition system, is described in Section 3. <p> The basic idea behind turning a logic into a logic programming language is to identify two sets of formulas: legal goals and legal programs. Many factors may influence the choice of these sets, but we would like to single out particularly important criterion (as argued in <ref> [21] </ref>): a (non-deterministic) abstract interpreter should be able to perform goal-directed search in such a way that every legal goal that is a theorem in the underlying logic, will succeed.
Reference: [22] <author> Dale Miller, Gopalan Nadathur, and Andre Sce-drov. </author> <title> Hereditary Harrop formulas and uniform proof systems. </title> <booktitle> In Second Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 98-105, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Its range of applications therefore include the range of applications of such environments (as indicated above). The basic idea behind Elf is to unify logic definition (in the style of LF) with logic pro Elf 2 gramming (in the style of Prolog, see <ref> [22, 21, 24] </ref>). It achieves this unification by giving types an operational interpretation, much the same way that Prolog gives certain formulas (Horn-clauses) an operational interpretation. Here are some of the salient characteristics of this unified approach to logic definition and metaprogram-ming.
Reference: [23] <author> Dale A. Miller. </author> <title> Unification under mixed prefixes. 1987. </title> <type> Unpublished manuscript. </type>
Reference-contexts: There are two extensions to Elliott's algorithm required here, both of which have been described for the simply typed -calculus and carry over to in a straightforward way: (1) the dependency of universal and existen tial quantifiers must be taken into account without Skolemization (see Miller <ref> [23] </ref>), and (2) the algorithm must deal with products (see Elliott [8]). We write =) fl for the reflexive and transitive closure of the transition relation =).
Reference: [24] <author> Gopalan Nadathur and Dale Miller. </author> <title> An overview of Prolog. </title> <editor> In Robert A. Kowalski and Ken-neth A. Bowen, editors, </editor> <booktitle> Logic Programming: Proceedings of the Fifth International Conference and Symposium, </booktitle> <volume> Volume 1, </volume> <pages> pages 810-827, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Its range of applications therefore include the range of applications of such environments (as indicated above). The basic idea behind Elf is to unify logic definition (in the style of LF) with logic pro Elf 2 gramming (in the style of Prolog, see <ref> [22, 21, 24] </ref>). It achieves this unification by giving types an operational interpretation, much the same way that Prolog gives certain formulas (Horn-clauses) an operational interpretation. Here are some of the salient characteristics of this unified approach to logic definition and metaprogram-ming. <p> This does not correspond to any construct in a Horn-clause logic, but the type construction serves the role of the 8 and connectives in a hereditary Harrop logic (see <ref> [24] </ref>). The natural criterion for the choice of legal goal and program types is slightly stronger here, since we would also like to ensure that all terms of the given type can be found using goal-directed search, interpreting and as outlined above.
Reference: [25] <author> Lawrence C. Paulson. </author> <title> The Representation of Logics in Higher-Order Logic. </title> <type> Technical Report 113, </type> <institution> University of Cambridge, </institution> <address> Cambridge, England, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: Mechanized support for deduction in a variety of logics and type theories has been the subject of much research (see, for example, Automath [6], LCF [12], HOL [13], Calculus of Constructions [5], Isabelle <ref> [25] </ref>, NuPrl [3]). In [15], Harper, Honsell, and Plotkin present LF (the Edinburgh Logical Framework) as a general metathe-ory for the definition of logics. LF provides a uniform way of encoding a logical language, its inference rules and its proofs. <p> Secondly, Elf avoids the undesirable operational behavior of meta-programs that sometimes arises from encoding a logic in higher-order logic as done in Isabelle <ref> [25] </ref> and by Felty and Miller in [11] (see the example in Section 5.3). Finally, the partial correctness of meta-programs with respect to a given logic can be expressed and proved by Elf itself (see the example in Section 5.2). <p> This example illustrates how a "clause" (a declaration dynamic c : A) in Elf can be proved correct by giving a closed term of type A. In practice, one would obtain the proof of 8push^ by theorem proving in a programming environment (for example, in the style of Isabelle <ref> [25] </ref>), an issue beyond the scope of this paper.
Reference: [26] <author> Frank Pfenning. </author> <title> Partial polymorphic type inference and higher-order unification. </title> <booktitle> In Proceedings of the 1988 ACM Conference on Lisp and Functional Programming, </booktitle> <publisher> ACM Press, </publisher> <month> July </month> <year> 1988. </year>
Reference-contexts: M n . : j T j F 1 ^ F 2 j 8x:A : F j 9x:A : F The first line contains the formulas that are considered atomic. Except for atomic : = and formulas, this is very close to the unification logic introduced in <ref> [26] </ref>, and it is used in a very similar fashion. The restricted form of implication is used to describe the backchaining in the abstract interpreter. The inference system in Figure 1 defines the judgment `` .
Reference: [27] <author> Frank Pfenning and Conal Elliott. </author> <title> Higher-order abstract syntax. </title> <booktitle> In Proceedings of the SIGPLAN '88 Symposium on Language Design and Implementation, </booktitle> <pages> pages 199-208, </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1988. </year> <note> Available as Ergo Report 88-036. </note>
Reference-contexts: Secondly, products combined with polymorphism significantly strengthen Elf as a representation and metapro-gramming language to handle the common case of a object languages with binding constructs of variable arity (see <ref> [27] </ref>). For example, a natural encoding of Hoare logic in LF as given in Section 4.10 of [1] must be restricted to a fixed number of registers|a restriction that can be dropped in with polymorphism.
Reference: [28] <author> Anne S. Troelstra. </author> <title> Strong normalization for typed terms with surjective pairing. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 27(4) </volume> <pages> 547-550, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: To prove strong normalization, we translate both types and terms from into terms in a simply typed -calculus with products and explicit types. It follows from a the strong normalization theorem by Troelstra <ref> [28] </ref> for a simply typed -calculus (even including and surjective pairing) that such terms are strongly normalizing which in turn implies this for the original terms with dependent types.
References-found: 29

