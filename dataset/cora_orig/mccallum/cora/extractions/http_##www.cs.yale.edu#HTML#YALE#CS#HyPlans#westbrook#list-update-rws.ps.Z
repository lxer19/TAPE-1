URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/westbrook/list-update-rws.ps.Z
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/westbrook/
Root-URL: http://www.cs.yale.edu
Title: Randomized Competitive Algorithms for the List Update Problem 1  
Author: Nick Reingold Jeffery Westbrook Daniel D. Sleator 
Date: May 29, 1992  
Abstract: We prove upper and lower bounds on the competitiveness of randomized algorithms for the list update problem of Sleator and Tarjan. We give a simple and elegant randomized algorithm that is more competitive than the best previous randomized algorithm due to Irani. Our algorithm uses randomness only during an initialization phase, and from then on runs completely deterministically. It is the first randomized competitive algorithm with this property to beat the deterministic lower bound. We generalize our approach to a model in which access costs are fixed but update costs are scaled by an arbitrary constant d. We prove lower bounds for deterministic list update algorithms and for randomized algorithms against oblivious and adaptive on-line adversaries. In particular, we show that for this problem adaptive on-line and adaptive off-line adversaries are equally powerful.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, R. M. Karp, D. Peleg, and D. West. </author> <title> A graph-theoretic game and its application to the k-server problem. </title> <booktitle> In Proceedings DIMACS Workshop on On-line Algorithms, </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: To our knowledge, BIT is the first barely random algorithm for any on-line problem that provably has a better competitive ratio than any deterministic algorithm for that problem. Recently Alon et. al have given a barely random algorithm for k-servers on a circle that is 2k-competitive <ref> [1] </ref>. However, it is known for k = 2, and conjectured for all k, that there exists a k-competitive deterministic k-server algorithm, matching the known lower bound of k [9, 20]. We generalize the BIT algorithm to a family of COUNTER algorithms.
Reference: [2] <author> S. Ben-David, A. Borodin, R. M. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in on-line algorithms. </title> <booktitle> In Proc. 20th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 379-386, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: A great deal of recent work has focused on the use of randomization to improve | sometimes exponentially | the competitiveness of on-line algorithms <ref> [2, 12, 13, 19] </ref>. Karp and Raghavan [private communication, 1990] inaugurated the study of randomized list update algorithms by showing a lower bound of 1.18 on the competitiveness of any randomized algorithm. <p> Two factors differentiate adversaries: how the request sequences are generated, and how the adversary is charged for servicing the sequence. Following <ref> [2, 22] </ref> we consider three kinds of adversary: oblivious (weak), adaptive on-line (medium), and adaptive off-line (strong). The oblivious adversary chooses a complete request sequence before the on-line algorithm begins to process it. <p> An unpublished result of Karp and Raghavan shows that if A is a deterministic, c-competitive list update algorithm in the standard model, then c 2. By a theorem of Ben-David, et al. <ref> [2] </ref>, a lower bound for deterministic algorithms implies the same lower bound for randomized algorithms against adaptive off-line (strong) adversaries. Note that the move-to-front algorithm is 2-competitive. Now we show that even against an adaptive on-line (medium) adversary, no randomized algorithm is better than 2-competitive.
Reference: [3] <author> J. L. Bentley, K. L. Clarkson, and D. B. Levine. </author> <title> Fast linear expected-time algorithms for computing maxima and convex hulls. </title> <booktitle> In Proc. 1st ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 179-187, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, self-adjusting rules are effective because they take advantage of the locality of reference found in real systems. List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls <ref> [3, 14] </ref>. For all these reasons, the list update problem has been extensively studied [4, 8, 15, 21, 24]. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [4] <author> J. L. Bentley and C. C. McGeoch. </author> <title> Amortized analyses of self-organizing sequential search heuristics. </title> <journal> Commun. ACM, </journal> <volume> 28(4) </volume> <pages> 404-411, </pages> <month> Apr. </month> <year> 1985. </year>
Reference-contexts: List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied <ref> [4, 8, 15, 21, 24] </ref>. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive. <p> If an algorithm is c-competitive on each of these two-element lists, then it is c-competitive on the list as a whole. This pairwise independence property of move-to-front-type heuristics was first observed by Bentley and C. McGeoch <ref> [4] </ref>, who made use of it to prove that the deterministic move-to-front algorithm is within a factor of 2 of any static list. The upper bound for BIT is tight in the i 1 cost model. Consider a list of size two, initially ordered 1; 2.
Reference: [5] <author> J. L. Bentley, D. D. Sleator, R. E. Tarjan, and V. Wei. </author> <title> A locally adaptive data compression scheme. </title> <journal> Commun. ACM, </journal> <volume> 29(4), </volume> <month> April </month> <year> 1986. </year>
Reference-contexts: Maintaining a dictionary as a linear list is frequently used in practice because of its great simplicity. Furthermore, self-adjusting rules are effective because they take advantage of the locality of reference found in real systems. List update techniques have also been used to develop data compression algorithms <ref> [5] </ref>, as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied [4, 8, 15, 21, 24].
Reference: [6] <author> D. L. Black and D. D. Sleator. </author> <title> Competitive algorithms for replication and migration problems. </title> <type> Technical Report CMU-CS-89-201, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <year> 1989. </year> <month> 18 </month>
Reference-contexts: This gives evidence that the scaling conjecture of Manasse et. al. [20] may apply to randomized algorithms. This version of the list update problem is similar to the replication/migration problems studied by Black and Sleator <ref> [6] </ref>. We also show a lower bound of 3 on the competitiveness of any deterministic algorithm in this model, so again our randomized algorithms beat the deterministic lower bound. An important question in the competitive analysis of randomized algorithms is the relationship between oblivious, on-line adaptive and off-line adaptive adversaries.
Reference: [7] <author> A. Borodin, N. Linial, and M. Saks. </author> <title> An optimal online algorithm for metrical task systems. </title> <booktitle> In Proc. 19th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 373-382, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction Recently much attention has been given to competitive analysis of on-line algorithms <ref> [7, 20, 22, 25] </ref>. Roughly speaking, an on-line algorithm is c-competitive if, for any request sequence, its cost is no more than c times the cost of the optimum off-line algorithm for that sequence. <p> An on-line list update algorithm must service each request without any knowledge of future requests. An off-line algorithm is shown the entire sequence in advance; the optimum cost can always be achieved by an off-line algorithm. Following <ref> [7, 20] </ref> we say a deterministic list update algorithm, A, is c-competitive if there is a constant b such that for all size lists and all request sequences , For randomized list update algorithms, competitiveness is defined with respect to the model of an adversary.
Reference: [8] <author> P. J. Burville and J. F. C. Kingman. </author> <title> On a model for storage and search. </title> <journal> Journal of Applied Probability, </journal> <volume> 10 </volume> <pages> 697-701, </pages> <year> 1973. </year>
Reference-contexts: List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied <ref> [4, 8, 15, 21, 24] </ref>. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [9] <author> M. Chrobak and L. Larmore. </author> <title> On fast algorithms for two servers. </title> <journal> Journal of Algorithms, </journal> <note> 1991. To appear. </note>
Reference-contexts: Recently Alon et. al have given a barely random algorithm for k-servers on a circle that is 2k-competitive [1]. However, it is known for k = 2, and conjectured for all k, that there exists a k-competitive deterministic k-server algorithm, matching the known lower bound of k <ref> [9, 20] </ref>. We generalize the BIT algorithm to a family of COUNTER algorithms. Using a COUNTER algorithm, we are able to achieve our best result, a p 3-competitive 2 algorithm.
Reference: [10] <author> M. Chrobak, L. L. Larmore, N. Reingold, and J. Westbrook. </author> <title> Optimal multiprocessor migration algorithms using work functions. </title> <type> Manuscript, </type> <year> 1991. </year>
Reference-contexts: Recently barely random algorithms have also been found for the migration problem <ref> [10, 26] </ref>. Open Question #3: For which other on-line problems do such algorithms exist? Our results in Section 4 give evidence for the conjecture that for a large class of applications, adaptive on-line and adaptive off-line adversaries are equally powerful. <p> Similar results have been obtained for page caching [22] and metrical task systems [12]. On the other hand, the results of <ref> [10, 26] </ref> show that this does not hold in general. Open Question #4: For what other classes of on-line problems are these two adversaries equivalent? 7 Acknowledgements We thank Richard Beigel, Sandy Irani, Prabhakar Raghavan, and Neal Young for useful discussions.
Reference: [11] <author> S. D. Conte and C. de Boor. </author> <title> Elementary Numerical Analysis, An Algorithmic Approach. </title> <publisher> McGraw-Hill, </publisher> <address> third edition, </address> <year> 1980. </year>
Reference-contexts: We compute this eigenvector from the matrix using the power method <ref> [11] </ref>. Table 2 shows the best results we have obtained for n = 3; 4; 5 and 6. In all cases, the number of iterations in the power method necessary to get the distance between successive iterates less than 10 7 was no more than 30.
Reference: [12] <author> D. Coppersmith, P. Doyle, P. Raghavan, and M. Snir. </author> <title> Random walks on weighted graphs, and applications to on-line algorithms. </title> <booktitle> In Proc. 20th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 369-377, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: A great deal of recent work has focused on the use of randomization to improve | sometimes exponentially | the competitiveness of on-line algorithms <ref> [2, 12, 13, 19] </ref>. Karp and Raghavan [private communication, 1990] inaugurated the study of randomized list update algorithms by showing a lower bound of 1.18 on the competitiveness of any randomized algorithm. <p> We show that in the standard model of the list update problem no randomized algorithm can be better than 2-competitive against either an adaptive on-line adversary or an adaptive off-line adversary. These results complement those found in page caching [22] and metrical task systems <ref> [12] </ref>. In all these applications, randomization helps against oblivious adversaries, and is no use against either kind of adaptive adversaries. Both kinds of adaptive adversaries are equivalent in power. <p> Similar results have been obtained for page caching [22] and metrical task systems <ref> [12] </ref>. On the other hand, the results of [10, 26] show that this does not hold in general. Open Question #4: For what other classes of on-line problems are these two adversaries equivalent? 7 Acknowledgements We thank Richard Beigel, Sandy Irani, Prabhakar Raghavan, and Neal Young for useful discussions.
Reference: [13] <author> A. Fiat, R. Karp, M. Luby, L. McGeoch, D. D. Sleator, and N. Young. </author> <title> On competitive algorithms for paging problems. </title> <note> To appear in Journal of Algorithms, </note> <year> 1988. </year>
Reference-contexts: A great deal of recent work has focused on the use of randomization to improve | sometimes exponentially | the competitiveness of on-line algorithms <ref> [2, 12, 13, 19] </ref>. Karp and Raghavan [private communication, 1990] inaugurated the study of randomized list update algorithms by showing a lower bound of 1.18 on the competitiveness of any randomized algorithm.
Reference: [14] <author> M. J. </author> <title> Golin. </title> <type> PhD Thesis. PhD thesis, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <year> 1990. </year> <note> Tech. Report CS-TR-266-90. </note>
Reference-contexts: Furthermore, self-adjusting rules are effective because they take advantage of the locality of reference found in real systems. List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls <ref> [3, 14] </ref>. For all these reasons, the list update problem has been extensively studied [4, 8, 15, 21, 24]. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [15] <author> W. J. Hendricks. </author> <title> An account of self-organizing systems. </title> <journal> SIAM J. Comput., </journal> <volume> 5(4) </volume> <pages> 715-723, </pages> <month> Dec. </month> <year> 1976. </year>
Reference-contexts: List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied <ref> [4, 8, 15, 21, 24] </ref>. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [16] <author> S. Irani. </author> <title> Two results on the list update problem. </title> <journal> Inf. Process. Lett., </journal> <volume> 38 </volume> <pages> 301-306, </pages> <year> 1991. </year>
Reference-contexts: Karp and Raghavan [private communication, 1990] inaugurated the study of randomized list update algorithms by showing a lower bound of 1.18 on the competitiveness of any randomized algorithm. Irani discovered a 1:875-competitive randomized algorithm <ref> [16] </ref>, thus exhibiting the first randomized algorithm to beat the deterministic lower bound. In this paper we examine the effect of randomization in greater depth. We present a very simple randomized algorithm, BIT, that is 1:75-competitive. <p> For thoroughness, however, we consider free exchanges performed by OPT, since some researchers have studied a variant of the standard model in which only free exchanges are allowed <ref> [16] </ref>. The extension of BIT to handle insertions and deletions is straightforward. On an insertion, BIT inserts the item at the back of the list, randomly initializes the bit of the new item, then moves the item to the front if its bit is 1.
Reference: [17] <author> S. Irani, N. Reingold, J. Westbrook, and D. D. Sleator. </author> <title> Randomized algorithms for the list update problem. </title> <booktitle> In Proc. 2nd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 251-260, </pages> <year> 1991. </year>
Reference-contexts: In their seminal work on competitive analysis [25], Sleator and Tarjan studied heuristics commonly used in system software to maintain 1 A preliminary version of these results appeared in a joint paper with S. Irani in the proceedings of the 2nd Symposium on Discrete Algorithms, 1991 <ref> [17] </ref>. 2 Department of Computer Science, Yale University, New Haven, CT 06520-2158. Research par tially supported by NSF grants CCR-8808949 and CCR-8958528. 3 Department of Computer Science, Yale University, New Haven, CT 06520-2158. Research partially supported by NSF grant CCR-9009753. 4 Carnegie-Mellon University, Pittsburgh, PA.
Reference: [18] <author> A. Karlin, M. Manasse, L. Rudolph, and D. Sleator. </author> <title> Competitive snoopy caching. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 79-119, </pages> <year> 1988. </year>
Reference-contexts: We now show that 3 is a lower bound on the competitive factor for problems in the P d models. This result generalizes that of Karlin et al. <ref> [18] </ref>, whose Theorem 3.3 can be interpreted as showing a lower bound of 3 on the competitive factor for lists of length 2 in the i 1 cost model. Theorem 4.2 Let A be an on-line algorithm for list update in a P d model.
Reference: [19] <author> A. R. Karlin, M. S. Manasse, L. A. McGeoch, and S. Owicki. </author> <title> Competitive randomized algorithms for non-uniform problems. </title> <booktitle> In Proc. 1st ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1990. </year>
Reference-contexts: A great deal of recent work has focused on the use of randomization to improve | sometimes exponentially | the competitiveness of on-line algorithms <ref> [2, 12, 13, 19] </ref>. Karp and Raghavan [private communication, 1990] inaugurated the study of randomized list update algorithms by showing a lower bound of 1.18 on the competitiveness of any randomized algorithm.
Reference: [20] <author> M. Manasse, L. A. McGeoch, and D. Sleator. </author> <title> Competitive algorithms for online problems. </title> <booktitle> In Proc. 20th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 322-333, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Recently much attention has been given to competitive analysis of on-line algorithms <ref> [7, 20, 22, 25] </ref>. Roughly speaking, an on-line algorithm is c-competitive if, for any request sequence, its cost is no more than c times the cost of the optimum off-line algorithm for that sequence. <p> Recently Alon et. al have given a barely random algorithm for k-servers on a circle that is 2k-competitive [1]. However, it is known for k = 2, and conjectured for all k, that there exists a k-competitive deterministic k-server algorithm, matching the known lower bound of k <ref> [9, 20] </ref>. We generalize the BIT algorithm to a family of COUNTER algorithms. Using a COUNTER algorithm, we are able to achieve our best result, a p 3-competitive 2 algorithm. <p> We give a family of COUNTER algorithms that are always better than 2:75-competitive and that in fact become more competitive as d increases. This gives evidence that the scaling conjecture of Manasse et. al. <ref> [20] </ref> may apply to randomized algorithms. This version of the list update problem is similar to the replication/migration problems studied by Black and Sleator [6]. <p> An on-line list update algorithm must service each request without any knowledge of future requests. An off-line algorithm is shown the entire sequence in advance; the optimum cost can always be achieved by an off-line algorithm. Following <ref> [7, 20] </ref> we say a deterministic list update algorithm, A, is c-competitive if there is a constant b such that for all size lists and all request sequences , For randomized list update algorithms, competitiveness is defined with respect to the model of an adversary. <p> It is interesting that as d tends to infinity, the best competitive ratio decreases and tends to (5 + 17)=4 2:28. This gives strong evidence that the scaling conjecture of Manasse et. al. <ref> [20] </ref> is true for the list update problem. It is possible to find RANDOM RESET algorithms which do slightly better than the COUNTER competitive ratios given in Table 1. These results are also shown in Table 1.
Reference: [21] <author> J. McCabe. </author> <title> On serial files with relocatable records. </title> <journal> Operations Research, </journal> <volume> 13:609--618, </volume> <year> 1965. </year>
Reference-contexts: List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied <ref> [4, 8, 15, 21, 24] </ref>. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [22] <author> P. Raghavan and M. Snir. </author> <title> Memory versus randomization in on-line algorithms. Research Report RC 15622 (No. </title> <type> 69444), </type> <institution> IBM T. J. Watson Reseach Center, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction Recently much attention has been given to competitive analysis of on-line algorithms <ref> [7, 20, 22, 25] </ref>. Roughly speaking, an on-line algorithm is c-competitive if, for any request sequence, its cost is no more than c times the cost of the optimum off-line algorithm for that sequence. <p> Our upper bounds hold against oblivious adversaries. We show that in the standard model of the list update problem no randomized algorithm can be better than 2-competitive against either an adaptive on-line adversary or an adaptive off-line adversary. These results complement those found in page caching <ref> [22] </ref> and metrical task systems [12]. In all these applications, randomization helps against oblivious adversaries, and is no use against either kind of adaptive adversaries. Both kinds of adaptive adversaries are equivalent in power. <p> Two factors differentiate adversaries: how the request sequences are generated, and how the adversary is charged for servicing the sequence. Following <ref> [2, 22] </ref> we consider three kinds of adversary: oblivious (weak), adaptive on-line (medium), and adaptive off-line (strong). The oblivious adversary chooses a complete request sequence before the on-line algorithm begins to process it. <p> Open Question #3: For which other on-line problems do such algorithms exist? Our results in Section 4 give evidence for the conjecture that for a large class of applications, adaptive on-line and adaptive off-line adversaries are equally powerful. Similar results have been obtained for page caching <ref> [22] </ref> and metrical task systems [12]. On the other hand, the results of [10, 26] show that this does not hold in general.
Reference: [23] <author> N. Reingold and J. Westbrook. </author> <title> Optimum off-line algorithms for the list update problem. </title> <type> Technical Report YALEU/DCS/TR-805, </type> <institution> Yale University, </institution> <year> 1990. </year>
Reference-contexts: Hence E [a i ] 1:5 opt i . Summing over all events, noting that m of the events are accesses, completes the proof of Theorem 3.1. The analysis of case 1 can be simplified by using a theorem of Reingold and Westbrook <ref> [23] </ref> which states that for any request sequence there is an optimum algorithm that does only paid exchanges. For thoroughness, however, we consider free exchanges performed by OPT, since some researchers have studied a variant of the standard model in which only free exchanges are allowed [16]. <p> Suppose the chain has stationary distribution ~. Then the expected cost per access is ~c ~, if the chain is in steady state. For n 3 there is no obvious strategy for a k-lookahead algorithm, since no bounded lookahead algorithm can be optimum <ref> [23] </ref>. Furthermore, the size of the transition matrix is n k , so for values of n and k even a little bigger than three it is infeasible to try different strategies by hand and compute the steady state vector symbolically. <p> Among optimum algorithms that have the above three properties, our algorithm services the first request with the lowest cost. This tends to make MARKOV (n; k)'s cost per access smaller, so we get a better lower bound. It is shown in <ref> [23] </ref> that there is an optimum algorithm with the first three properties. There is no known way to compute the optimum algorithm for a given request sequence that is polynomial in both n and k, however, so the time and space to generate MARKOV (n; k) grow exponentially.
Reference: [24] <author> R. Rivest. </author> <title> On self-organizing sequential search heuristics. </title> <journal> Commun. ACM, </journal> <volume> 19(2) </volume> <pages> 63-67, </pages> <month> February </month> <year> 1976. </year>
Reference-contexts: List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied <ref> [4, 8, 15, 21, 24] </ref>. Sleator and Tarjan [25] demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive.
Reference: [25] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Commun. ACM, </journal> <volume> 28(2) </volume> <pages> 202-208, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Recently much attention has been given to competitive analysis of on-line algorithms <ref> [7, 20, 22, 25] </ref>. Roughly speaking, an on-line algorithm is c-competitive if, for any request sequence, its cost is no more than c times the cost of the optimum off-line algorithm for that sequence. <p> Roughly speaking, an on-line algorithm is c-competitive if, for any request sequence, its cost is no more than c times the cost of the optimum off-line algorithm for that sequence. In their seminal work on competitive analysis <ref> [25] </ref>, Sleator and Tarjan studied heuristics commonly used in system software to maintain 1 A preliminary version of these results appeared in a joint paper with S. <p> List update techniques have also been used to develop data compression algorithms [5], as well as fast and simple algorithms for computing point maxima and convex hulls [3, 14]. For all these reasons, the list update problem has been extensively studied [4, 8, 15, 21, 24]. Sleator and Tarjan <ref> [25] </ref> demonstrated that the move-to-front algorithm, which uses the simple rule of moving an item to the front of the list each time it is accessed, is 2-competitive. <p> A deletion is done by searching for the item and then removing it. At any time, the algorithm may exchange the position of any two adjacent items in the list. In the standard model <ref> [25] </ref> an access or deletion of the i th item in the list costs i and an insertion costs n + 1, where n is the length of the list prior to the insertion. <p> Thus the analysis applied above to accesses can be applied here to show that an insertion has the same expected cost as an access. (This observation is due to Sleator and Tarjan <ref> [25] </ref>.) Similarly, a deletion is like an access, except that all inversions involving the deleted item disappear, so the potential function decreases even more than during an access.
Reference: [26] <author> J. Westbrook. </author> <title> Randomized algorithms for multiprocessor page migration. </title> <booktitle> In Proceedings of the DIMACS Workshop on On-Line Algorithms, </booktitle> <publisher> American Mathematical Society, </publisher> <month> February </month> <year> 1991. </year> <note> To appear. 20 </note>
Reference-contexts: Recently barely random algorithms have also been found for the migration problem <ref> [10, 26] </ref>. Open Question #3: For which other on-line problems do such algorithms exist? Our results in Section 4 give evidence for the conjecture that for a large class of applications, adaptive on-line and adaptive off-line adversaries are equally powerful. <p> Similar results have been obtained for page caching [22] and metrical task systems [12]. On the other hand, the results of <ref> [10, 26] </ref> show that this does not hold in general. Open Question #4: For what other classes of on-line problems are these two adversaries equivalent? 7 Acknowledgements We thank Richard Beigel, Sandy Irani, Prabhakar Raghavan, and Neal Young for useful discussions.
References-found: 26

