URL: ftp://ife.ethz.ch/pub/music/paper/nf94-2.ps
Refering-URL: http://www.ife.ee.ethz.ch/music/music.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Programming Environment for a High Performance Parallel Supercomputer with Intelligent Communication  
Author: Anton Gunzinger 
Abstract: At the Electronics Lab of the Swiss Federal Institute of Techology (ETH) in Zurich, the high performance Parallel Supercomputer MUSIC (MUlti processor System with Intelligent Communication) has beed developed. As applications in neural network simulation and molecular dynamics show, the Electronics Lab Supercomputer is absolutely on a par with those of conventional supercomputers, but electric power requirements are reduced by a factor of 1000, wight is reduced by a factor of 400 and price is reduced by a factor of 100. Software development is a key using such a parallel system. This report focus on the programming environment of the MUSIC system and on it's applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Annaratone, E. Arnould, T. Gross, H. T. Kung, M. Lam, O. Menzilicioglu, J. A. Webb. </author> <title> The WARP Computer: Architecture, Implementation and Performence. </title> <journal> IEEE Trans. on Computer, </journal> <volume> Vol. C-36, No. 12, </volume> <month> De-cember </month> <year> 1987, </year> <month> pp.1523-1538 </month>
Reference-contexts: 1. INTRODUCTION Scientific computing often demands high computing power. Because many tasks in these applications have a great potential for parallel processing, developers have proffered a number of parallel computer architectures <ref> [1, 3, 12, 4] </ref>. Using an array of high performance,inexpensive processors (mass production), a system can reach several GFlops at a significantly lower cost, power consumption, and space requirements than traditional supercomputers of equal performance.
Reference: [2] <author> Nelson Morgan, James Beck, Phil Kohn, Jeff Bilmes, Eric Allman, and Joachim Beer. </author> <title> The ring array processor: A multiprocessing peripheral for connectionist applications. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14(3) </volume> <pages> 248-259, </pages> <month> March </month> <year> 1992. </year>
Reference: [3] <author> R. R. Shively and L. J. Wu. </author> <title> Application and Packaging of the AT&T DSP3 Parallel Signal Processor. </title> <editor> In V. Cappellini and A. G. Con-stantinides, editors, </editor> <booktitle> Digital Signal Processing-91. </booktitle> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: 1. INTRODUCTION Scientific computing often demands high computing power. Because many tasks in these applications have a great potential for parallel processing, developers have proffered a number of parallel computer architectures <ref> [1, 3, 12, 4] </ref>. Using an array of high performance,inexpensive processors (mass production), a system can reach several GFlops at a significantly lower cost, power consumption, and space requirements than traditional supercomputers of equal performance.
Reference: [4] <author> Michael Witbrock and Marco Zagha. </author> <title> An implementation of backpropagation learning on GF11, a large SIMD parallel computer. </title> <journal> Parallel Computing, </journal> <volume> 14(3) </volume> <pages> 329-346, </pages> <year> 1990. </year>
Reference-contexts: 1. INTRODUCTION Scientific computing often demands high computing power. Because many tasks in these applications have a great potential for parallel processing, developers have proffered a number of parallel computer architectures <ref> [1, 3, 12, 4] </ref>. Using an array of high performance,inexpensive processors (mass production), a system can reach several GFlops at a significantly lower cost, power consumption, and space requirements than traditional supercomputers of equal performance.
Reference: [5] <author> Anton Gunzinger, Urs Muller, and Hansruedi Vonder Muhll. </author> <title> Architecture and Realization of a Multi Signalprocessor System. </title> <editor> In Am-non Aliphas, editor, </editor> <address> Berlin '91, </address> <pages> pages 242-249. </pages> <publisher> DSP Associates, </publisher> <year> 1991. </year>
Reference: [6] <author> Urs A. Muller, Bernhard Baumle, Peter Kohler, Anton Gunzinger, and Walter Guggenbuhl. </author> <title> Achieving supercomputer performance for neural net simulation with an array of digital signal processors. </title> <journal> IEEE Micro, </journal> <volume> 12(5) </volume> <pages> 55-65, </pages> <month> October </month> <year> 1992. </year>
Reference: [7] <author> Anton Gunzinger, Urs A. Muller, Walter Scott, Bernhard Baumle, Peter Kohler, Hans-ruedi Vonder Muhll, Florian Muller-Plathe, Wilfried F. van Gunsteren, and Walter Guggenbuhl. </author> <title> Achieving super computer performance with a DSP array processor. </title> <editor> In Robert Werner, editor, </editor> <title> Supercomputing '92, Programming Environment for a High Performance Parallel Supercomputer with Intelligent Communication pages 543-550, </title> <publisher> Loas Alamitos, </publisher> <address> California, </address> <month> November 16-20, </month> <year> 1992, </year> <title> Minneapolis, Min-nesota 1992. IEEE/ACM, </title> <publisher> IEEE Computer Society Press. </publisher>
Reference: [8] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representation by error propagation. </title> <editor> In David E. Rumel-hart and James L. McClelland, editors, </editor> <booktitle> Parallel Distributet Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> Bradford Books, </publisher> <address> Cambridge MA, </address> <year> 1986. </year>
Reference: [9] <author> Wei-Ming Lin, Viktor K. Prasanna, and K. Wojtek Przytula. </author> <title> Algorithmic mapping of neural network models onto parallel simd machines. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(12) </volume> <pages> 1390-1401, </pages> <month> December </month> <year> 1991. </year>
Reference: [10] <author> Heinz Muhlbein and Klaus Wolf. </author> <title> Neural network simulation on parallel computers. </title> <editor> In David J. Evans, Gerhard R. Joubert, and Frans J. Peters, editors, </editor> <booktitle> Parallel Computing-89, </booktitle> <pages> pages 365-374, </pages> <address> Amsterdam, 1990. </address> <publisher> North Holland. </publisher>
Reference: [11] <author> Dean A. Pomerleau, George L. Gusciora, David S. Touretzky, and H. T. Kung. </author> <title> Neural network simulation at warp speed: How we got 17 million connections per second. </title> <booktitle> In IEEE International Conference on Neural Networks, pages II.143-150, </booktitle> <address> July 24-27, San Diego, </address> <month> Cal-ifornia </month> <year> 1988. </year>
Reference: [12] <author> Xiru Zhang, Michael Mckenna, Jill P. Mesirov, and David L. Waltz. </author> <title> An efficient implementation of the back-propagation algorithm on the connection machine cm-2. </title> <editor> In David S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems (NIPS-89), </booktitle> <pages> pages 801-809, </pages> <address> 2929 Campus Drive, Suite 260, San Mateo, CA 94403, 1990. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: 1. INTRODUCTION Scientific computing often demands high computing power. Because many tasks in these applications have a great potential for parallel processing, developers have proffered a number of parallel computer architectures <ref> [1, 3, 12, 4] </ref>. Using an array of high performance,inexpensive processors (mass production), a system can reach several GFlops at a significantly lower cost, power consumption, and space requirements than traditional supercomputers of equal performance.
Reference: [13] <author> W. F. van Gunsteren and H. J. C. Berend-sen. </author> <title> Molecular Dynamics Computer Simulations: Methodology, </title> <booktitle> Applications and Perspectives in Chemistry.Angewandte Chemie Int. </booktitle> <editor> Ed. Engl. </editor> <volume> 29(1990), </volume> <pages> pages 992-1023. </pages>
Reference: [14] <author> M. P. Allen and D. J. Tildesley. </author> <title> Computer Simulations of Liquids, </title> <publisher> Oxford University Press 1987 </publisher>
Reference: [15] <author> W. F. van Gunsteren, H. J. C. Berendsen, F. Colonna, D. Perahia, J.P. Hollenberg and D. </author> <title> Lellouch On Searching Neighbours in Computer Simulations of Macromolecular Systems J. </title> <journal> Comp. Chem. </journal> <volume> Vol. 5 No. </volume> <month> 3 272 -279 </month> <year> (1984) </year>
Reference: [16] <institution> Florian Muller-Plathe Parallelising a Molecular Dynamics Algorithm on a Multi-Processor Workstation Computer Physics Communications 61 285-293 (1990) </institution>
References-found: 16

