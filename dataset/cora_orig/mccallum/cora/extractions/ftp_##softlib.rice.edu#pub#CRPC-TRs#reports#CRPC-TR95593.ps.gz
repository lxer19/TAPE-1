URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR95593.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Inner and outer iterations for the Chebyshev algorithm  
Author: Eldar Giladi Gene H. Golub Joseph B. Keller 
Date: January 17, 1996  
Address: Caltech, Pasadena CA 91125.  Stanford CA 94305.  Stanford CA 94305.  
Affiliation: Applied Mathematics 217-50  Department of Computer Science Stanford University,  Departments of Mathematics and Mechanical Engineering Stanford University,  
Abstract: We analyze the Chebyshev iteration in which the linear system involving the splitting matrix is solved inexactly by an inner iteration. We assume that the tolerance for the inner iteration may change from one outer iteration to the other. When the tolerance converges to zero, the asymptotic convergence rate is unaffected. Motivated by this result, we seek the sequence of tolerance values that yields the lowest cost. We find that among all sequences of slowly varying tolerances, a constant one is optimal. Numerical calculations that verify our results are shown. Our analysis is based on asymptotic methods, such as the W.K.B method, for linear recurrence equations and an estimate of the accuracy of the resulting asymptotic result. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G.H.Golub and R.S.Varga. </author> <title> Chebyshev semi-iterative methods, successive over-relaxation iterative methods, and second-order richardson iterative methods, parts i and ii. </title> <journal> Numer. Math., </journal> <volume> 3 </volume> <pages> 147-168, </pages> <year> 1961. </year>
Reference-contexts: 1 Introduction The Chebyshev iterative algorithm <ref> [1] </ref> for solving linear systems of equations requires at each step the solution of a subproblem i.e. the solution of another linear system. We fl Phone (o): (818)-395-4550, FAX: (818)-578-0124, e-mail: giladi@ama.caltech.edu 1 assume that the subproblem is also solved iteratively by an "inner iteration". <p> Moreover, we expect some fluctuations around the predicted behavior when t 1. We covered both cases in our experiments. We solve the symmetric system Ax = b; (128) arising from the central difference discretization of the operator dx 2 + (:8 sin (10x) + 1)C; (129) in the interval <ref> [0; 1] </ref> with homogeneous Dirichlet boundary conditions. The right side b in (128) is chosen at random. The splitting matrix M is obtained from the discretization of the operator dx 2 + C; (130) with homogeneous Dirichlet boundary conditions. The mesh parameter in this discretiza tion is h = 1=100.
Reference: [2] <author> E. Giladi. </author> <title> Hybrid Numerical Asymptotic Methods. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: First, we evaluate the asymptotic convergence rate when the tolerance values converge to 0. Then, we seek the "optimal strategy", that is, the sequence of tolerance values that yields the lowest possible cost for a given *. The present results, extend those in Giladi <ref> [2] </ref>, [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], [7], [8], [9], [10]).
Reference: [3] <author> E.Giladi. </author> <title> On the interplay between inner and outer iterations for a class of iterative methods. </title> <booktitle> In Proceedings of the Colorado conference on iterative methods, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: First, we evaluate the asymptotic convergence rate when the tolerance values converge to 0. Then, we seek the "optimal strategy", that is, the sequence of tolerance values that yields the lowest possible cost for a given *. The present results, extend those in Giladi [2], <ref> [3] </ref>. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], [7], [8], [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm.
Reference: [4] <author> G.H. Golub and M.L. Overton. </author> <title> The convergence of inexact chebyshev and richardson iterative methods for solving linear systems. </title> <journal> Numer. Math., </journal> <volume> 53 </volume> <pages> 571-593, </pages> <year> 1988. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton <ref> [4] </ref> (see also [5], [6], [7], [8], [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm. <p> We denote the error at step k by e k = x x k : (9) We also define K, V , and j by K = I ffM 1 A; K = V V 1 ; = Diag ( j ): (10) We use the same derivation as in <ref> [4] </ref> to show that when j 6= 1 k V 1 e k k j cosh (k cosh 1 )j ; (11) where ffi represents a sequence of tolerance values fffi k g 1 k=1 . <p> This is in contrast to the case of constant tolerance for which the asymptotic convergence rate of the inexact algorithm is lower than that of the exact algorithm <ref> [4] </ref>. We base our analysis on the bound (11). Therefore, we wish to compute lim k!1 k t (k; ffi) j cosh (k cosh 1 ())j ! 1=k In order to do so, we need to estimate the asymptotic behavior for large k of t (k; ffi).
Reference: [5] <author> R.A.Nicolaides. </author> <title> On the local convergence of certain two step iterative procedures. </title> <journal> Numer. Math., </journal> <volume> 24 </volume> <pages> 95-101, </pages> <year> 1975. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also <ref> [5] </ref>, [6], [7], [8], [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [6] <author> V.Pereyra. </author> <title> Accelerating the convergence of discretization algorithms. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 4 </volume> <pages> 508-533, </pages> <year> 1967. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], <ref> [6] </ref>, [7], [8], [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [7] <author> N.K.Nichols. </author> <title> On the convergence of two-stage iterative process for solving linear equations. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 10 </volume> <pages> 460-469, </pages> <year> 1973. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], <ref> [7] </ref>, [8], [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [8] <author> S.C.Eisenstat R.S.Dembo and T.Steihaug. </author> <title> Inexact newton methods. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 </volume> <pages> 400-408, </pages> <year> 1982. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], [7], <ref> [8] </ref>, [9], [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [9] <author> A.Frommer and D.B.Szyld. </author> <title> H-splittings and two-stage iterative methods. </title> <journal> Numerische Mathematik, </journal> <volume> 63 </volume> <pages> 345-356, </pages> <year> 1992. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], [7], [8], <ref> [9] </ref>, [10]). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [10] <author> H. C. Elman and G. H. Golub. </author> <title> Inexact and preconditioned uzawa algorithms for saddle point problems. </title> <journal> SIAM Numer. Anal., </journal> <volume> 31 </volume> <pages> 1645-1661, </pages> <year> 1994. </year>
Reference-contexts: The present results, extend those in Giladi [2], [3]. The asymptotic convergence rate of the inexact Chebyshev iteration, with a fixed tolerance for the inner iteration, was derived in Golub and Overton [4] (see also [5], [6], [7], [8], [9], <ref> [10] </ref>). Previous work has mainly concentrated on the convergence rate, whereas we emphasize the cost of the algorithm. In section 2, we review the Chebyshev method and present the basic error bound for the inexact algorithm.
Reference: [11] <author> T. A. Manteuffel. </author> <title> The tchebyshev iteration for nonsymmetric linear systems. </title> <journal> Numer. Math., </journal> <volume> 28 </volume> <pages> 307-327, </pages> <year> 1977. </year>
Reference-contexts: We also estimate the optimal constant. Then, in section 8 we present a few numerical calculations that demonstrate the accuracy of the analysis of section 7. In Section 9, we generalize this result to other iterative schemes. 2 Chebyshev iteration Chebyshev iteration (see Manteuffel <ref> [11] </ref>) to solve the real n fi n system of linear equations Ax = b (1) uses the splitting A = M (M A): (2) It requires that the spectrum of M 1 A be contained in an ellipse, symmetric about the real axis, in the open right half of the
Reference: [12] <author> E. Giladi and J. B. Keller. </author> <title> Eulerian number asymptotics. </title> <journal> Proceedings of the London Royal Society, Series A, </journal> <volume> 445 </volume> <pages> 291-303, </pages> <year> 1994. </year>
Reference-contexts: We shall now obtain the asymptotic behavior of (k; ffi) for large k from (13) with ffi k = C k . We use the method of <ref> [12] </ref>. We first replace t (k; ffi) by (k; ^ ffi) in (13) and set ^ ffi k = C=k. <p> The method we use is similar to the W.K.B method [13] for linear ordinary differential equations with a small parameter, and the ray method Keller [14] for linear partial differential equations with a small parameter. These methods have recently been adapted to linear difference equations with small parameters <ref> [12] </ref>, [15]. We now obtain an approximate solution to equation (13) when ffi k = ffi (fik) belongs to S.
Reference: [13] <author> C. M. Bender and S.Orszag. </author> <title> Advanced Mathematical Methods for Scientists and Engineers. Mc. </title> <address> Graw Hill, </address> <year> 1978. </year>
Reference-contexts: Moreover, since ffi k is slowly varying the impact of this change on the cost is negligible. The method we use is similar to the W.K.B method <ref> [13] </ref> for linear ordinary differential equations with a small parameter, and the ray method Keller [14] for linear partial differential equations with a small parameter. These methods have recently been adapted to linear difference equations with small parameters [12], [15]. <p> We use the method of reduction of order <ref> [13] </ref>. Specifically, we seek a solution of the form e (k; ffi) = x k t (k; ffi); (70) where t (k; ffi) is the solution to equation (13), (14) and x k is to be determined.
Reference: [14] <author> J.B.Keller. </author> <title> Rays, waves and asymptotics. </title> <journal> Bull. Am. Math. Soc., </journal> <volume> 84 </volume> <pages> 727-750, </pages> <year> 1978. </year>
Reference-contexts: Moreover, since ffi k is slowly varying the impact of this change on the cost is negligible. The method we use is similar to the W.K.B method [13] for linear ordinary differential equations with a small parameter, and the ray method Keller <ref> [14] </ref> for linear partial differential equations with a small parameter. These methods have recently been adapted to linear difference equations with small parameters [12], [15]. We now obtain an approximate solution to equation (13) when ffi k = ffi (fik) belongs to S.
Reference: [15] <author> C. Knessl. </author> <title> The wkb approximation to the g/m/m queue. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 51 </volume> <pages> 1119-1133, </pages> <year> 1991. </year>
Reference-contexts: The method we use is similar to the W.K.B method [13] for linear ordinary differential equations with a small parameter, and the ray method Keller [14] for linear partial differential equations with a small parameter. These methods have recently been adapted to linear difference equations with small parameters [12], <ref> [15] </ref>. We now obtain an approximate solution to equation (13) when ffi k = ffi (fik) belongs to S.
Reference: [16] <author> G.F.Carrier and C.E.Pearson. </author> <title> Ordinary Differential Equations. </title> <publisher> SIAM, </publisher> <year> 1991. </year> <month> 30 </month>
Reference-contexts: This is done by solving the non-linear recurrence equation (99) for fl k;j , subject to the initial condition (98). We solve this equation with a method analogous to the one described in section 16.7 of <ref> [16] </ref> and obtain fl 2S Sffi (fik) S+ffi (fik) (1+ffi (fik)+S) 2j + 1 where S = (1 + ffi (fik)) 2 1: (105) From equation (105) S &gt; ffi (fik) so that 0 &lt; S + ffi (fik) Furthermore, it follows from (105) and the definition of in (46) that
Reference: [17] <author> T. A. Manteuffel. </author> <title> Adaptive procedure for estimation of parameters for the nonsym-metric tchebychev iteration. </title> <journal> Numer. Math., </journal> <volume> 31 </volume> <pages> 187-208, </pages> <year> 1978. </year>
Reference-contexts: Since B (N; ^ ffi) approximates a bound for the error, the tolerance obtained by this method will be a lower bound for the optimal tolerance. The estimation of the optimal constant depends on the parameters and in expression (126). These are often determined adaptively while solving the system <ref> [17] </ref>. 8 Numerical calculations We now present a few numerical calculations that verify the analysis of section 7. In each experiment, we solve a linear system with Chebyshev iteration to accuracy *, using a variable strategy ffi.
Reference: [18] <author> R.S.Varga. </author> <title> Matrix iterative analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1962. </year> <month> 31 </month>
Reference-contexts: We use two methods for the inner iteration. The symmetric Gauss Seidel, with the convergence factor 0:993, close to 1, and the symmetric successive over relaxation method <ref> [18] </ref> (S.S.O.R) with the smaller convergence factor 0:925. In the S.S.O.R iteration, the relaxation parameter ! is the optimal parameter ! fl of S.O.R. In each experiment, we record the number of outer iterations and the total number of inner iterations for the variable and constant strategy cases.
References-found: 18

