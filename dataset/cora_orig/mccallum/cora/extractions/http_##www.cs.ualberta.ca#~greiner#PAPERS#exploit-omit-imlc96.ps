URL: http://www.cs.ualberta.ca/~greiner/PAPERS/exploit-omit-imlc96.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  grove@research.nj.nec.com  kogan@rutcor.rutgers.edu  
Title: Exploiting the Omission of Irrelevant Data  
Author: Russell Greiner Adam J. Grove Alexander Kogan 
Address: 755 College Road East Princeton, NJ 08540-6632  4 Independence Way Princeton, NJ 08540  NJ 07102  New Brunswick, NJ 08903  
Affiliation: Siemens Corporate Research  NEC Research Institute  Rutgers University Faculty of Management; Newark,  RUTCOR;  
Abstract: Most learning algorithms work most effectively when their training data contain completely specified labeled samples. In many diagnostic tasks, however, the data will include the values of only some of the attributes; we model this as a blocking process that hides the values of those attributes from the learner. While blockers that remove the values of critical attributes can handicap a learner, this paper instead focuses on blockers that remove only irrelevant attribute values, i.e., values that are not needed to classify an instance, given the values of the other unblocked attributes. We first motivate and formalize this model of "superfluous-value blocking", and then demonstrate that these omissions can be useful, by proving that certain classes that seem hard to learn in the general PAC model | viz., decision trees and DNF formulae | are trivial to learn in this setting. We also show that this model can be extended to deal with (1) theory revision (i.e., modifying an existing formula); (2) blockers that occasionally include superfluous values or exclude required values; and (3) other cor ruptions of the training data. 
Abstract-found: 1
Intro-found: 1
Reference: [Ang92] <author> D. Angluin. </author> <title> Computational learning theory: survey and selected bibliography. </title> <booktitle> In STOC-92, </booktitle> <pages> pages 351-369. </pages> <address> NY, </address> <year> 1992. </year>
Reference-contexts: Moreover, Learn-DNF requires s ffi blocked, labeled, samples, and will return a DNF formula with at most j'j terms. Notice Learn-DNF uses only positive samples. By contrast, learning arbitrary DNF formulae in the standard model is one of the major open challenges of PAC-learning in general <ref> [Ang92] </ref>. Many learnability results are expressed in terms of the size of the smallest DNF formula for a concept.
Reference: [AS91] <author> D. Angluin and D. </author> <title> Slonim. Learning monotone DNF with an incomplete membership oracle. </title> <booktitle> In COLT-91, p. </booktitle> <pages> 139-146, </pages> <year> 1991. </year>
Reference-contexts: The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label <ref> [AS91, FGMP94] </ref>, or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n i; let X n = f0; 1g n be the set of all
Reference: [BFOS84] <author> L. Breiman, J. Friedman, J. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, </address> <year> 1984. </year>
Reference-contexts: His model allows the system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different model [SG96, SG94]. In this model, after the world produces a completely-specified sample at random, a second "blocking" process (which also could be "nature") hides the values of certain attributes at random. <p> However, as we see later, the interesting cases arise where most or all of the superfluous attributes are in fact blocked. To motivate our model, consider the behavior of a classifier d t using a standard decision tree, a la cart <ref> [BFOS84] </ref> or c4.5 [Qui92]. Here, given any instance, d t will perform (and record) only the tests on a sin 2 This is a slight abuse of notation, as fi may be stochastic. This caveat also applies to Definition 1. gle path through the tree.
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In AAAI-88, p. </booktitle> <pages> 49-54, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Finally, notice that Theorem 2 assumes that each instance is blocked by the blocker fi ' cor . [GGK96] motivates and discusses other meaningful blocking models, and also connects this theory revision idea with the notions of "on-line algorithms" and "anytime al gorithms" <ref> [DB88] </ref>. Finally, it also presents algorithms for modifying decision trees. 3.3 TRAINING-DATA DEGRADATION So far our B (DNF ) model has assumed that the blocker removes all-and-only the superfluous attribute values. There may, however, be cases where the environment/teacher reports an irrelevant value, or fails to report a relevant one.
Reference: [FGMP94] <author> M. Frazier, S. Goldman, N. Mishra, and L. Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <editor> In COLT-94, p. </editor> <address> 328-339. </address> <publisher> ACM, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label <ref> [AS91, FGMP94] </ref>, or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n i; let X n = f0; 1g n be the set of all
Reference: [GGK96] <author> Russell Greiner, Adam Grove, and Alex Kogan. </author> <title> Knowing what doesn't matter. </title> <type> Tech. report, </type> <institution> Siemens Corp. Res., </institution> <year> 1996. </year> <note> ftp://scr.siemens.com/pub/learning/Papers/ greiner/superfluous-journal.ps </note>
Reference-contexts: The extended paper <ref> [GGK96] </ref> presents the proofs of all theorems, and other related results including a more comprehensive treatment of decision trees. We close this section by further motivating our framework and describing how it differs from related work on learning from incomplete data. <p> In fact, we can learn a lot by knowing that an attribute is irrelevant. Note that this notion of relevance is not absolute: an attribute may be irrelevant in the context of certain other attribute values, and relevant in other cases. The extended paper <ref> [GGK96] </ref> connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector <p> in the same PAC sense used in Theorem 1, whenever it is given at least jSj 1 * s ln (8n) + ln 1 samples. (Here, s bounds the number of leaves in the decision tree.) Thus, this algorithm can be significantly more efficient than Learn-DNF if s n; see <ref> [GGK96] </ref> for more discussion. 3.2 THEORY REVISION In many situations, we may already have an initial DNF ' init that is considered quite accurate, but not perfect. <p> Finally, notice that Theorem 2 assumes that each instance is blocked by the blocker fi ' cor . <ref> [GGK96] </ref> motivates and discusses other meaningful blocking models, and also connects this theory revision idea with the notions of "on-line algorithms" and "anytime al gorithms" [DB88]. <p> Below, we consider and less than minfk ln n n ; 0:5g for some constant k. (The actual algorithms appear in <ref> [GGK96] </ref>.) Theorem 4 It is possible to PAC-learn DN F n;s with (0; k ln n n ) attribute degradation (resp., (k ln n n ; 0) attribute degradation), using O ( sn 2k * ln s ffi ) examples (resp., O ( s 2 n 2k * ln s ffi <p> It is possible to PAC-learn DN F n;s with fl (A; samp) for any constant &lt; 1. This holds even in the presence of (0; O (ln n=n); 1; 1) attribute degradation. The extended paper <ref> [GGK96] </ref> also proves it is possible to learn DN F n;s with: * classification noise of ff &lt; 0:5 (i.e., stochastically changing the label of an instance with probability bounded by ff), * attribute noise of &lt; n 1 k =16 (i.e., stochastically changing the value of an attribute with some
Reference: [GM93] <author> S. Goldman and D. Mathias. </author> <title> Teaching a smarter learner. </title> <editor> In COLT-93, p. </editor> <address> 67-76. </address> <publisher> ACM, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Note that this notion of relevance is not absolute: an attribute may be irrelevant in the context of certain other attribute values, and relevant in other cases. The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" <ref> [GM93] </ref>, and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n
Reference: [GS95] <author> S. Goldman and R. Sloan. </author> <title> Can PAC learning algorithms tolerate random attribute noise? Algo-rithmica, </title> <type> 14(1), </type> <year> 1995. </year>
Reference-contexts: The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values <ref> [SV88, Lit91, GS95] </ref>. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n i; let X n = f0; 1g n be the set of all possible domain instances.
Reference: [HKLW91] <author> D. Haussler, M. Kearns, N. Littlestone, and M. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Inform. Comput., </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Unfortunately, this formula could be exponentially larger than the smallest equivalent DNF formula. Also, while Learn-DNF (and Theorem 1) require a bound s on the size of the target formula, we can avoid this by using the standard technique of successively doubling estimates of s <ref> [HKLW91] </ref>. 3 Relation to Decision Trees: The correctness of Learn-DNF immediately implies that decision trees are also trivial to learn in our model.
Reference: [JKP94] <author> G. John, R. Kohavi, and K. Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In IMCL-94, p. </booktitle> <pages> 121-129, </pages> <year> 1994. </year>
Reference-contexts: Note that this notion of relevance is not absolute: an attribute may be irrelevant in the context of certain other attribute values, and relevant in other cases. The extended paper [GGK96] connects our model with other notions of "(ir)relevance" <ref> [JKP94, Lit88] </ref> and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; :
Reference: [KL93] <author> M. Kearns and M. Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 807-837, </pages> <year> 1993. </year>
Reference-contexts: It is possible to learn DN F n;s under fl (A; inst) k degradation, for any constant k. This holds even in the presence of (0; O (ln n=n); 1; 1) attribute degradation. A quite different type of degradation occurs if an adversary can arbitrarily change instances <ref> [KL93] </ref>. However, we assume that the adversary has to pass a certain fraction of instances unchanged; i.e., on each instance the adversary will, with probability 1 , show the learner exactly the appropriate blocked instance.
Reference: [KLPV87] <author> M. Kearns, M. Li, L. Pitt, and L. Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In STOC-87, p. </booktitle> <pages> 285-295, </pages> <year> 1987. </year>
Reference-contexts: Section 3 extends this idea to general DNF formulae. Performance Criterion: We use the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired perfor mance of our learners. For any hypothesis h, let Err (h) = P (~x : '(~x) 6= h (~x)) be the probability that h will misclassify an instance ~x drawn from P .
Reference: [KMR + 94] <author> M. Kearns, Y. Mansour, D. Ron, R. Ru-binfeld, R. Schapire, and L. Sellie. </author> <title> On the learnabil-ity of discrete distributions. </title> <booktitle> In STOC, p. </booktitle> <pages> 273-282, </pages> <year> 1994. </year>
Reference-contexts: This degradation is sufficiently large that we may not ever see an entirely correct (i.e., completely un-degraded) term, within polynomially many samples. However, we can recover terms by collecting all m subsets of size 2k positive samples, and "voting" (see <ref> [KMR + 94] </ref>). That is, we construct a term from each size-2k subsample by considering each variable x i in turn, and setting it to 0, 1, or fl according to which value is given most often to x i in the subsample.
Reference: [KR93] <author> E. Kushilevitz and D. Roth. </author> <title> On learning visual concepts and DNF formulae. </title> <editor> In COLT-93, p. </editor> <address> 317-326. New York, </address> <year> 1993. </year>
Reference: [LDRG94] <author> P. Langley, G. Drastal, B. Rao, and R. Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Workshop on Principles of Diagnosis, </booktitle> <address> New Paltz, </address> <year> 1994. </year>
Reference-contexts: We let B (DNF ) fer to this model where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [WP93, MB88, OM90, LDRG94] </ref>. There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: Note that this notion of relevance is not absolute: an attribute may be irrelevant in the context of certain other attribute values, and relevant in other cases. The extended paper [GGK96] connects our model with other notions of "(ir)relevance" <ref> [JKP94, Lit88] </ref> and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values [SV88, Lit91, GS95]. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; :
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In COLT-91, p. </booktitle> <pages> 147-156, </pages> <year> 1991. </year>
Reference-contexts: The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values <ref> [SV88, Lit91, GS95] </ref>. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n i; let X n = f0; 1g n be the set of all possible domain instances.
Reference: [LR87] <author> J. Little and D. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: His model allows the system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different model [SG96, SG94]. In this model, after the world produces a completely-specified sample at random, a second "blocking" process (which also could be "nature") hides the values of certain attributes at random.
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <editor> In ICML-88, p. </editor> <address> 339-51. </address> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We let B (DNF ) fer to this model where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [WP93, MB88, OM90, LDRG94] </ref>. There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [OM90] <author> D. Ourston and R. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In AAAI-90, p. </booktitle> <pages> 815-820, </pages> <year> 1990. </year>
Reference-contexts: We let B (DNF ) fer to this model where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [WP93, MB88, OM90, LDRG94] </ref>. There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [PBH90] <author> B. Porter, R. Bareiss, and R. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45(1-2):229-63, </volume> <year> 1990. </year>
Reference-contexts: Motivation and Related Work: Most implemented learning systems tend to work effectively when very few features are missing, and when these missing features are randomly distributed across the samples. However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that many real-world datasets are missing more than half of the feature values! Moreover, these values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" [PBH90], which <p> studies [PBH90, RCJ88] have shown that many real-world datasets are missing more than half of the feature values! Moreover, these values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" <ref> [PBH90] </ref>, which is precisely the situation considered in this paper (see Definition 1).
Reference: [Qui92] <author> J.R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: His model allows the system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different model [SG96, SG94]. In this model, after the world produces a completely-specified sample at random, a second "blocking" process (which also could be "nature") hides the values of certain attributes at random. <p> However, as we see later, the interesting cases arise where most or all of the superfluous attributes are in fact blocked. To motivate our model, consider the behavior of a classifier d t using a standard decision tree, a la cart [BFOS84] or c4.5 <ref> [Qui92] </ref>. Here, given any instance, d t will perform (and record) only the tests on a sin 2 This is a slight abuse of notation, as fi may be stochastic. This caveat also applies to Definition 1. gle path through the tree.
Reference: [RCJ88] <author> K. Ruberg, S. Cornick, and K.A. James. </author> <title> House calls: Building and maintaining a diagnostic rule-base. </title> <booktitle> In 3rd Knowledge Acquisition for Knowledge-Based Systems Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: Motivation and Related Work: Most implemented learning systems tend to work effectively when very few features are missing, and when these missing features are randomly distributed across the samples. However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that many real-world datasets are missing more than half of the feature values! Moreover, these values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" [PBH90], which
Reference: [SG96] <author> D. Schuurmans and R. Greiner. </author> <title> Learning to classify incomplete examples. </title> <booktitle> In Computational Learning Theory and `Natural' Learning Systems, IV, </booktitle> <publisher> MIT, </publisher> <year> 1996. </year>
Reference-contexts: By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different model <ref> [SG96, SG94] </ref>. In this model, after the world produces a completely-specified sample at random, a second "blocking" process (which also could be "nature") hides the values of certain attributes at random. Note that no useful information is conveyed by the fact that an attribute is hidden in a particular example.
Reference: [SG94] <author> D. Schuurmans and R. Greiner. </author> <title> Learning default concepts. </title> <booktitle> In CSCSI-94, p. </booktitle> <pages> 519-523, </pages> <year> 1994. </year>
Reference-contexts: By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different model <ref> [SG96, SG94] </ref>. In this model, after the world produces a completely-specified sample at random, a second "blocking" process (which also could be "nature") hides the values of certain attributes at random. Note that no useful information is conveyed by the fact that an attribute is hidden in a particular example.
Reference: [SV88] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In COLT-88, p. </booktitle> <pages> 97-103, </pages> <year> 1988. </year>
Reference-contexts: The extended paper [GGK96] connects our model with other notions of "(ir)relevance" [JKP94, Lit88] and "teachers" [GM93], and differentiates it from learnability models which either omit the class label [AS91, FGMP94], or which change some attribute values <ref> [SV88, Lit91, GS95] </ref>. 2 FRAMEWORK Following standard practice, we identify each domain instance with a finite vector of boolean attributes ~x = hx 1 ; : : :; x n i; let X n = f0; 1g n be the set of all possible domain instances.
Reference: [Tur95] <author> P. Turney. </author> <title> Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. </title> <journal> Journal of AI Research, </journal> <volume> 2 </volume> <pages> 369-409, </pages> <year> 1995. </year>
Reference-contexts: Our model of learning can, therefore, be applicable to many diagnostic tasks, and will be especially useful where the experts are unavailable or are unable to articulate the classification process they are using. Turney <ref> [Tur95] </ref> discusses a model that also assumes that experts intentionally perform only a subset of the possible tests. His model allows the system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present.
Reference: [Val84] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: Section 3 extends this idea to general DNF formulae. Performance Criterion: We use the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired perfor mance of our learners. For any hypothesis h, let Err (h) = P (~x : '(~x) 6= h (~x)) be the probability that h will misclassify an instance ~x drawn from P .
Reference: [WP93] <author> J. Wogulis and M. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In IJCAI-93, p. </booktitle> <pages> 1128-1134, </pages> <year> 1993. </year> <month> 9 </month>
Reference-contexts: We let B (DNF ) fer to this model where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [WP93, MB88, OM90, LDRG94] </ref>. There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
References-found: 29

