URL: http://www.cse.ucsc.edu/~manfred/pubs/differential.ps
Refering-URL: http://www.cse.ucsc.edu/~manfred/pubs.html
Root-URL: http://www.cse.ucsc.edu
Email: fmanfred,jagotag@cs.ucsc.edu  
Title: Continuous And Discrete-Time Nonlinear Gradient Descent: Relative Loss Bounds and Convergence  
Author: M. K. Warmuth and A. K. Jagota 
Date: September 30, 1997  
Address: Santa Cruz  
Affiliation: Department of Computer Science University of California at  
Abstract: We introduce a general algorithm for continuous- and discrete-time nonlinear gradient-descent. The nonlinearity is captured by the choice of a link function. The discrete-time algorithm yields, for various choices of link function, the conventional gradient-descent algorithm as well as several exponentiated gradient ones. We obtain relative loss bounds for the general algorithm in an on-line setting for both the continuous- and discrete-time versions. These bounds reveal the dependence on the link function and show that an additional term is present in the discrete-time case which disappears in the continuous-time case. This additional term is responsible for the pair of dual norms that appear in the relative loss bounds for linear and logistic regression. The continuous-time version is also shown to have a simple proof of convergence in the batch setting. Convergence of Hopfield recurrent neural networks is seen as a special case.
Abstract-found: 1
Intro-found: 1
Reference: [AHW95] <author> P. Auer, M. Herbster, and M. K. Warmuth. </author> <title> Exponentially many local minima for single neurons. </title> <booktitle> In Proc. 1995 Neural Information Processing Conference, </booktitle> <pages> pages 316-317. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The key tool for analyzing an update is a distance function associated with an update [Lit89, KW97b]. Here we use a general form that is based on an arbitrary link function. This form was introduced in [JK97] and was inspired by the definition of matching loss function given in <ref> [HKW95, AHW95, JK97] </ref>. f (! fl ; !) = i ![i] This distance function is usually asymmetric. In [KW97b] discretized updates are derived from the distance functions. In Section 3 we extend this method to derive the continuous-time updates also from the distance 3 functions.
Reference: [Ama85] <author> S. Amari. </author> <title> Differential Geometrical Methods in Statistics. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: They used an alternate form of the above distance function as their starting point. Statistical interpretations of these distance functions and their relation to Information Geometry <ref> [Ama85] </ref> will be discussed in [KW97a]. We now generalize the methodology of worst-case relative loss bounds to our discrete-time and continuous-time cases. Imagine that a DT algorithm only sees the examples at the times 0; h; 2h; : : : ; T .
Reference: [Byl97] <author> T. Bylander. </author> <title> The binary exponentiated gradient algorithm for learning linear functions. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 184-192. </pages> <note> ACM, 1997. To appear. </note>
Reference-contexts: alternate parameters as follows: = f (!) and ! = f 1 () : The differential equations (1) of our main update are now * d t [i] = @! t [i] 2 Table 1: Several discrete-time gradient-based algorithms: EGU|Unnormalized Exponentiated Gradient [KW97b], EG|Exponentiated Gradient [KW97b], and BEG|Bounded Exponentiated Gradient <ref> [Byl97] </ref>. <p> Similarly, if the interval is (0; 1), then the inverse of the sigmoid function f (z) = ln z 1z is a suitable choice, giving the BEG algorithm <ref> [Byl97] </ref>. Note that if we don't have any information about 5 ! L (! t ) and the learning rate , then f (! t ) h 5 ! L (! t ) might not lie in the range of f. <p> The methods in <ref> [KW97b, HKW95, JK97, Byl97] </ref> for linear and logistic regression can be interpreted as upper bounding this additional sum by hc f X 2 P T t=0;h;::: hL t (! t ), where X is an upper bound on the norm of the instances and c f is a constant. <p> So we choose y = f (x), where f (z) = ln z 1z is the inverse of the logistic function. Now our main update (3) for CT becomes * 2 (W + W T )x, which corresponds to the BEG algorithm of Tom Bylander <ref> [Byl97] </ref>, and is also a convergent update for Hopfield nets with arbitrary W . When W is symmetric, we have * known update for the Hopfield net. The dual of this update is * x= x fi (1 x) fi W x, where fi denotes component-wise multiplication.
Reference: [FT91] <author> L. Fahrmeir and G. Tutz. </author> <title> Multivariate Statistical Modelling Based on Generalized linear Models. </title> <publisher> Springer-Verlag, </publisher> <address> New-York, </address> <year> 1991. </year>
Reference-contexts: A typical example is f (z) = ln (z). We call f a link function because of its connection to the canonical link function for the exponential family of densities used in statistics <ref> [MN89, FT91] </ref>. (The statistical interpretation of (1) and the related discretized updates given below are the focus of another paper [KW97a].) Note that if f is increasing on its domain, then so is its inverse f 1 .
Reference: [GLS97] <author> A. J. Grove, N. Littlestone, and D. Schuurmans. </author> <title> General convergence results for linear discriminant updates. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 171-183. </pages> <note> ACM, 1997. To appear. </note>
Reference-contexts: In [KW97b] discretized updates are derived from the distance functions. In Section 3 we extend this method to derive the continuous-time updates also from the distance 3 functions. The general form of the link function based main update (3) was developed independently by <ref> [GLS97] </ref> for the case of classification with a linear threshold function. They used an alternate form of the above distance function as their starting point. Statistical interpretations of these distance functions and their relation to Information Geometry [Ama85] will be discussed in [KW97a]. <p> However for the case of linear threshold functions the updates for more general pairs of dual norms have been developed and analyzed <ref> [GLS97] </ref>.
Reference: [HKP91] <author> J. Hertz, A. Krogh, and R.G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Recall that L is bounded from below. Thus to establish monotone convergence for the main CT update (1), it suffices to show that * L (!) &lt; 0 if at least one component of * ! [i] is non-zero. (See <ref> [HKP91, p. 56] </ref> for a similar derivation in the context of Hopfield nets.) If at least one component of * ! [i] is non-zero then * n X @L (!) * n X * * n X f 0 * The function L is also time-invariant in fixed-weights recurrent networks such <p> similar derivation in the context of Hopfield nets.) If at least one component of * ! [i] is non-zero then * n X @L (!) * n X * * n X f 0 * The function L is also time-invariant in fixed-weights recurrent networks such as the Hopfield network <ref> [HKP91] </ref>. In this case the loss function L W (x) is usually a scalar Liapunov function and x is the activity-vector of the n neuron states. Note that here we use the more customary parameter vector x in place of ! used in the rest of the paper. <p> The subscript W is the fixed interconnection weight matrix between the pairs of neurons. Thus the function L W here tracks the evolution of the neuronal states and not the weights. The above argument yields convergence of continuous-time Hopfield networks <ref> [HKP91] </ref> as a special case. 8 For example a simple Liapunov function for Hopfield nets is L W (x) = 1 2 x T W x. Since the activity of each state must lie in (0; 1) we would naturally choose a link function f with domain (0; 1).
Reference: [HKW95] <author> D. P. Helmbold, J. Kivinen, and M. K. Warmuth. </author> <title> Worst-case loss bounds for sigmoided linear neurons. </title> <booktitle> In Proc. 1995 Neural Information Processing Conference, </booktitle> <pages> pages 309-315. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The key tool for analyzing an update is a distance function associated with an update [Lit89, KW97b]. Here we use a general form that is based on an arbitrary link function. This form was introduced in [JK97] and was inspired by the definition of matching loss function given in <ref> [HKW95, AHW95, JK97] </ref>. f (! fl ; !) = i ![i] This distance function is usually asymmetric. In [KW97b] discretized updates are derived from the distance functions. In Section 3 we extend this method to derive the continuous-time updates also from the distance 3 functions. <p> One of the norms measures the instances x t and the corresponding dual norm measures the off-line parameter vector ! fl . So far this has only been done for two pairs of dual norms <ref> [KW97b, HKW95] </ref>, one pair characterizing the GD algorithm and another one for the EG algorithm. However for the case of linear threshold functions the updates for more general pairs of dual norms have been developed and analyzed [GLS97]. <p> The methods in <ref> [KW97b, HKW95, JK97, Byl97] </ref> for linear and logistic regression can be interpreted as upper bounding this additional sum by hc f X 2 P T t=0;h;::: hL t (! t ), where X is an upper bound on the norm of the instances and c f is a constant. <p> Convergence of Hopfield recurrent neural networks was shown as a special case. We introduced a large number of different updates in this paper. However, the relative loss bounds also provide a yard stick for discerning between the updates <ref> [KW97b, HKW95] </ref>. The larger research goal is a systematic study of learning algorithms in simple settings using the link function as way of characterizing the update. The CT case is a simplified extreme case that can aide the understanding of the DT case.
Reference: [HSSW97] <author> D. Helmbold, R. E. Schapire, Y. Singer, and M. K. Warmuth. </author> <title> A comparison of new and old algorithms for a mixture estimation problem. </title> <booktitle> Machine Learning, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: We call this the reparameterized GD update. * For example if f (z) = ln (z) then the components of ! are kept nonnegative. In a simple mixture estimation problem it was experimentally found that this reparameterization method did not work as well as the main update <ref> [HSSW97] </ref>. Another indication is that we are not aware of any relative loss bounds proven for the reparameterized GD update (except when f is the identity). However there is a large body of relative loss bounds for the main update with various choices for the link function. <p> the step size h was always one: f (!; ! t ) + h L t (!) U h def Note that, since f (!; ! t ) is convex in !, the Taylor approximation of L t (!) assures that U h t (!) is convex in !. (See <ref> [HSSW97] </ref> for further motivations of the approximation step.) We may then minimize U t (!) by setting all its partial derivatives with respect to ![i] to zero, giving the main update: ! t+1 := f 1 (f (! t ) 5 ! L t (! t+1 )) or h This clearly
Reference: [JK97] <author> M. K. Warmuth J. Kivinen. </author> <title> Relative loss bounds for multidimensional regression problems. </title> <booktitle> In Advances in Neural Information Processing Systems, 11, </booktitle> <address> Cambridge, MA, </address> <year> 1997. </year> <note> MIT Press. To appear. </note>
Reference-contexts: The key tool for analyzing an update is a distance function associated with an update [Lit89, KW97b]. Here we use a general form that is based on an arbitrary link function. This form was introduced in <ref> [JK97] </ref> and was inspired by the definition of matching loss function given in [HKW95, AHW95, JK97]. f (! fl ; !) = i ![i] This distance function is usually asymmetric. In [KW97b] discretized updates are derived from the distance functions. <p> The key tool for analyzing an update is a distance function associated with an update [Lit89, KW97b]. Here we use a general form that is based on an arbitrary link function. This form was introduced in [JK97] and was inspired by the definition of matching loss function given in <ref> [HKW95, AHW95, JK97] </ref>. f (! fl ; !) = i ![i] This distance function is usually asymmetric. In [KW97b] discretized updates are derived from the distance functions. In Section 3 we extend this method to derive the continuous-time updates also from the distance 3 functions. <p> The methods in <ref> [KW97b, HKW95, JK97, Byl97] </ref> for linear and logistic regression can be interpreted as upper bounding this additional sum by hc f X 2 P T t=0;h;::: hL t (! t ), where X is an upper bound on the norm of the instances and c f is a constant.
Reference: [KW97a] <author> K. Kazoury and M. K. Warmuth. </author> <title> Relative loss bounds and the exponential family of distributions. </title> <type> Unpublished manuscript., </type> <year> 1997. </year>
Reference-contexts: We call f a link function because of its connection to the canonical link function for the exponential family of densities used in statistics [MN89, FT91]. (The statistical interpretation of (1) and the related discretized updates given below are the focus of another paper <ref> [KW97a] </ref>.) Note that if f is increasing on its domain, then so is its inverse f 1 . Thus if f is a link function, then f 1 is so as well. <p> They used an alternate form of the above distance function as their starting point. Statistical interpretations of these distance functions and their relation to Information Geometry [Ama85] will be discussed in <ref> [KW97a] </ref>. We now generalize the methodology of worst-case relative loss bounds to our discrete-time and continuous-time cases. Imagine that a DT algorithm only sees the examples at the times 0; h; 2h; : : : ; T .
Reference: [KW97b] <author> Jyrki Kivinen and Manfred K. Warmuth. </author> <title> Additive versus exponentiated gradient updates for linear prediction. </title> <journal> Information and Computation, </journal> <volume> 132(1) </volume> <pages> 1-64, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: The case h = 1 is the main model of on-line learning for which relative (worst-case) loss bounds have been proven <ref> [Lit88, LW94, Vov90, KW97b] </ref>. <p> parameters ! we introduce a vector of n alternate parameters as follows: = f (!) and ! = f 1 () : The differential equations (1) of our main update are now * d t [i] = @! t [i] 2 Table 1: Several discrete-time gradient-based algorithms: EGU|Unnormalized Exponentiated Gradient <ref> [KW97b] </ref>, EG|Exponentiated Gradient [KW97b], and BEG|Bounded Exponentiated Gradient [Byl97]. <p> introduce a vector of n alternate parameters as follows: = f (!) and ! = f 1 () : The differential equations (1) of our main update are now * d t [i] = @! t [i] 2 Table 1: Several discrete-time gradient-based algorithms: EGU|Unnormalized Exponentiated Gradient <ref> [KW97b] </ref>, EG|Exponentiated Gradient [KW97b], and BEG|Bounded Exponentiated Gradient [Byl97]. <p> However if f (x) = ln (x) then the discretized version (3) of the main update with h = 1 gives the Unnormalized Exponentiated Gradient Update (EGU) of <ref> [KW97b] </ref> (See the Table 1 for more examples). In the next section we discuss the purpose and desired properties of link functions. The key tool for analyzing an update is a distance function associated with an update [Lit89, KW97b]. <p> In the next section we discuss the purpose and desired properties of link functions. The key tool for analyzing an update is a distance function associated with an update <ref> [Lit89, KW97b] </ref>. Here we use a general form that is based on an arbitrary link function. <p> This form was introduced in [JK97] and was inspired by the definition of matching loss function given in [HKW95, AHW95, JK97]. f (! fl ; !) = i ![i] This distance function is usually asymmetric. In <ref> [KW97b] </ref> discretized updates are derived from the distance functions. In Section 3 we extend this method to derive the continuous-time updates also from the distance 3 functions. <p> Optimizing this DT bound (for any fixed h) will hence involve a careful tuning of . Finally, this term is also responsible for the appearance of a pair of dual norms in the relative loss bounds for the DT linear and logistic regression <ref> [KW97b] </ref> for the GD and EG algorithms. The pair of dual norms characterizes the radically different behavior of the two algorithms that shows up experimentally [KW97b]. One of the norms measures the instances x t and the corresponding dual norm measures the off-line parameter vector ! fl . <p> term is also responsible for the appearance of a pair of dual norms in the relative loss bounds for the DT linear and logistic regression <ref> [KW97b] </ref> for the GD and EG algorithms. The pair of dual norms characterizes the radically different behavior of the two algorithms that shows up experimentally [KW97b]. One of the norms measures the instances x t and the corresponding dual norm measures the off-line parameter vector ! fl . <p> One of the norms measures the instances x t and the corresponding dual norm measures the off-line parameter vector ! fl . So far this has only been done for two pairs of dual norms <ref> [KW97b, HKW95] </ref>, one pair characterizing the GD algorithm and another one for the EG algorithm. However for the case of linear threshold functions the updates for more general pairs of dual norms have been developed and analyzed [GLS97]. <p> implies ! fl = !, (ii) f (! fl ; !) = f 1 (; fl ), and (iii) f (! fl ; !) is convex in ! fl for every !. 3 Derivation of updates from the distance function Next we generalize a principled method that Kivinen and Warmuth <ref> [KW97b] </ref> used for deriving their algo rithms. The aim is to minimize the cumulative loss P t h L t (! t ). The parameter vector ! t represents all the prior learning experience. <p> The methods in <ref> [KW97b, HKW95, JK97, Byl97] </ref> for linear and logistic regression can be interpreted as upper bounding this additional sum by hc f X 2 P T t=0;h;::: hL t (! t ), where X is an upper bound on the norm of the instances and c f is a constant. <p> The relative loss bounds in the on-line learning case can be used to show bounds on the speed of convergence on the training data. More interestingly, using a simple averaging argument these bounds can also be converted into bounds on the generalization error <ref> [KW97b] </ref>. Whether or not relative loss bounds are obtainable the above way, it is easy to establish in the CT case monotone convergence of the loss. We only need the assumption that the time-invariant L function is bounded from below. <p> Convergence of Hopfield recurrent neural networks was shown as a special case. We introduced a large number of different updates in this paper. However, the relative loss bounds also provide a yard stick for discerning between the updates <ref> [KW97b, HKW95] </ref>. The larger research goal is a systematic study of learning algorithms in simple settings using the link function as way of characterizing the update. The CT case is a simplified extreme case that can aide the understanding of the DT case.
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: The case h = 1 is the main model of on-line learning for which relative (worst-case) loss bounds have been proven <ref> [Lit88, LW94, Vov90, KW97b] </ref>.
Reference: [Lit89] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, Technical Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: In the next section we discuss the purpose and desired properties of link functions. The key tool for analyzing an update is a distance function associated with an update <ref> [Lit89, KW97b] </ref>. Here we use a general form that is based on an arbitrary link function.
Reference: [LW94] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: The case h = 1 is the main model of on-line learning for which relative (worst-case) loss bounds have been proven <ref> [Lit88, LW94, Vov90, KW97b] </ref>.
Reference: [MN89] <author> P. McCullagh and J. A. Nelder. </author> <title> Generalized Linear Models. </title> <publisher> Chapman & Hall, </publisher> <year> 1989. </year>
Reference-contexts: A typical example is f (z) = ln (z). We call f a link function because of its connection to the canonical link function for the exponential family of densities used in statistics <ref> [MN89, FT91] </ref>. (The statistical interpretation of (1) and the related discretized updates given below are the focus of another paper [KW97a].) Note that if f is increasing on its domain, then so is its inverse f 1 .
Reference: [Vov90] <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year> <month> 10 </month>
Reference-contexts: The case h = 1 is the main model of on-line learning for which relative (worst-case) loss bounds have been proven <ref> [Lit88, LW94, Vov90, KW97b] </ref>.
References-found: 16

