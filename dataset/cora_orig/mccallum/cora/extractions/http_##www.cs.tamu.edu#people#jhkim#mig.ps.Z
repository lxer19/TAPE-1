URL: http://www.cs.tamu.edu/people/jhkim/mig.ps.Z
Refering-URL: http://www.cs.tamu.edu/people/jhkim/publications.html
Root-URL: http://www.cs.tamu.edu
Email: E-mail: fjhkim,vaidyag@cs.tamu.edu  
Title: Adaptive Migratory Scheme for Distributed Shared Memory  
Author: Jai-Hoon Kim Nitin H. Vaidya 
Keyword: distributed shared memory, release memory consistency, adaptive protocol, migratory protocol, competitive update protocol, performance evaluation, cost analysis model.  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: Technical Report 96-023 November 1996 Abstract This paper presents an adaptive migratory scheme for software Distributed Shared Memory (DSM). On a migratory sharing, a message for sending a copy of a page to a remote node, on which a page fault occurs, is directly followed by an invalidation request from the remote node. Our adaptive migratory scheme eliminates an overhead for invalidation by self-invalidation on sending a copy of a page. Each node can independently detect migratory memory access pattern and self-invalidate local copy of a page by using the local information only. Experimental results show that the performance is improved by dynamically selecting the migratory protocol. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Carter, D. Khandekar, and L. Kamb, </author> <title> "Distributed shared memory: Where we are and where we should be headed," </title> <booktitle> in Proc. of the Fifth Workshop on Hot Topics in Operating Systems, </booktitle> <pages> pp. 119-122, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: We implemented the adaptive protocol by modifying another DSM, named Quarks (Beta release 0.8) <ref> [1, 8] </ref>. This section presents the experimental results.
Reference: [2] <author> J. B. Carter, </author> <title> Efficient Distributed Shared Memory Based On Multi-Protocol Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: In these architectures, global 2 state (number of cached copies, last invalidator of a block) can be known by some or all nodes. However, these schemes can not be used directly in the DSM where no actual owner exists like in Munin <ref> [2] </ref> or Quarks [8]. No node has global information about copies of a page. Our scheme is implemented incorporated into a software DSM in which memory coherency is maintained in totally distributed manner. Our adaptive migratory scheme does not need global information. <p> In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes. However, these schemes can not be used directly in the DSM where no actual owner exists such as in Munin <ref> [2] </ref> or Quarks [8]. No node has global information about copies of a page. New adaptive scheme for migratory sharing needs to be designed for the software DSM (or similar architecture) in which memory coherency is maintained in totally distributed manner.
Reference: [3] <author> A. Cox and R. Fower, </author> <title> "The implementation of a coherent memory abstraction on a numa multiprocessor: Experience with platinum," </title> <booktitle> in Proc. of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 32-44, </pages> <year> 1989. </year>
Reference-contexts: Dynamic page placement schemes <ref> [3, 10] </ref> including page migratory have been implemented in OS-level NUMA memory management. Their schemes can dynamically select either migration or replication for page placement according to application and architecture. <p> Our scheme is implemented incorporated into a software DSM in which memory coherency is maintained in totally distributed manner. Our adaptive migratory scheme does not need global information. Each node tries to detect the migratory memory access patterns only with local information. <ref> [3, 10] </ref> are proposed for dynamic page placement in NUMA architecture. Their dynamic page placement policy can not be applied to DSM due to architectural difference. On page fault, in NUMA architecture, a local node can access remote memory without page allocation in local memory. <p> this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. <ref> [3, 10] </ref> are based on page placement scheme for NUMA multiprocessors. <p> This hybrid feature can be implemented by slightly modifying the proposed scheme. Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features [4] Dir or Bus Inv + Mig [12] Dir Comp + Mig [11] Dir Inv + Self-Inv <ref> [3, 10] </ref> MM-NUMA Remote + Replicate + Mig CC [9] SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir = directory-based cache coherence multiprocessor * MM-NUMA = memory management system for MUMA multiprocessor * SDSM =
Reference: [4] <author> A. Cox and R. Fowler, </author> <title> "Adaptive cache coherency for detecting migratory shared data," </title> <booktitle> in Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 98-108, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The proposed scheme allows each node to independently choose (at run-time) a different protocol (migratory, invalidate, or competitive update protocol) for each page by using the local information only. Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. <p> Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. Dynamic page placement schemes [3, 10] including page migratory have been implemented in OS-level NUMA memory management. <p> Their schemes can dynamically select either migration or replication for page placement according to application and architecture. Our adaptive migratory scheme is implemented for a software DSM and different from others as follows: * design domain: <ref> [4] </ref> is designed on bus-based multiprocessor and directory-based cache coherence multiprocessor. [12, 14, 11] are based on directory-based cache coherence multiprocessor. <p> If another protocol is optimal on a migratory sharing in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. <ref> [4, 14, 12] </ref> select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on <p> in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: <ref> [4, 14, 11] </ref> are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on page placement scheme for NUMA multiprocessors. <p> Our scheme is based on adaptive DSM in which each node can inde pendently choose (at run-time) a different protocol for each copy of a page. * hybrid protocol: In <ref> [4, 12, 14] </ref>, all copies of a block enter migratory mode or exit from migratory mode. In our scheme, each node decides independently to use migratory protocol. Therefore, some nodes can use a migratory protocol while the other nodes use other protocol (invalidate or competitive update protocol). <p> Therefore, some nodes can use a migratory protocol while the other nodes use other protocol (invalidate or competitive update protocol). This hybrid feature can be implemented by slightly modifying the proposed scheme. Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features <ref> [4] </ref> Dir or Bus Inv + Mig [12] Dir Comp + Mig [11] Dir Inv + Self-Inv [3, 10] MM-NUMA Remote + Replicate + Mig CC [9] SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir <p> To detect migratory sharing, following conditions can be checked <ref> [4, 14, 12] </ref>: 1. i 6= j, writing node is not the same as the previous writer 2. <p> To detect migratory sharing, following conditions can be checked [4, 14, 12]: 1. i 6= j, writing node is not the same as the previous writer 2. The number of cached copies is two (for <ref> [4, 14] </ref>) or node i and j are the only one that read a block since node i write (for [12]). 3.2 Motivation Previous works [4, 12, 14] for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. <p> The number of cached copies is two (for [4, 14]) or node i and j are the only one that read a block since node i write (for [12]). 3.2 Motivation Previous works <ref> [4, 12, 14] </ref> for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes.
Reference: [5] <author> F. Dahlgren and P. Stenstrom, </author> <title> "Using write caches to improve performance of cache coherence protocols in shared-memory multiprocessors," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 26, </volume> <pages> pp. 193-210, </pages> <month> Apr. </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: This prediction should be accurate, provided that the memory access patterns change relatively infrequently. In [9], we present an adaptive scheme that chooses between the invalidate protocol and the competitive update protocol <ref> [7, 5, 6] </ref>. The competitive update protocol is defined by a "threshold" parameter; we will rename the threshold as the "limit".
Reference: [6] <author> H. Grahn, P. Stenstrom, and M. Dubois, </author> <title> "Implementation and evaluation of update--based cache protocols under relaxed memory consistency models," </title> <journal> Future Generation Computer Systems, </journal> <volume> vol. 11, </volume> <pages> pp. 247-271, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: This prediction should be accurate, provided that the memory access patterns change relatively infrequently. In [9], we present an adaptive scheme that chooses between the invalidate protocol and the competitive update protocol <ref> [7, 5, 6] </ref>. The competitive update protocol is defined by a "threshold" parameter; we will rename the threshold as the "limit".
Reference: [7] <author> A. Karlin, M. Manasse, L. Rudolph, and D. Sleator, </author> <title> "Competitive snoopy caching," </title> <booktitle> in Proc. of the 27'th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 244-254, </pages> <year> 1986. </year>
Reference-contexts: This prediction should be accurate, provided that the memory access patterns change relatively infrequently. In [9], we present an adaptive scheme that chooses between the invalidate protocol and the competitive update protocol <ref> [7, 5, 6] </ref>. The competitive update protocol is defined by a "threshold" parameter; we will rename the threshold as the "limit".
Reference: [8] <author> D. Khandekar, </author> <title> "Quarks: Portable dsm on unix," </title> <type> tech. rep., </type> <institution> University of Utah. </institution>
Reference-contexts: In these architectures, global 2 state (number of cached copies, last invalidator of a block) can be known by some or all nodes. However, these schemes can not be used directly in the DSM where no actual owner exists like in Munin [2] or Quarks <ref> [8] </ref>. No node has global information about copies of a page. Our scheme is implemented incorporated into a software DSM in which memory coherency is maintained in totally distributed manner. Our adaptive migratory scheme does not need global information. <p> In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes. However, these schemes can not be used directly in the DSM where no actual owner exists such as in Munin [2] or Quarks <ref> [8] </ref>. No node has global information about copies of a page. New adaptive scheme for migratory sharing needs to be designed for the software DSM (or similar architecture) in which memory coherency is maintained in totally distributed manner. <p> We implemented the adaptive protocol by modifying another DSM, named Quarks (Beta release 0.8) <ref> [1, 8] </ref>. This section presents the experimental results. <p> This section presents the experimental results. We evaluated the adaptive scheme using synthetic applications (qtest, ProdCons, and Reader/Writer) as well as other applications (Floyd-Warshall, SOR, QSORT, IS, Matmult, and Gauss-Jacobi). qtest is a simple shared memory application based on a program available with the Quarks release <ref> [8] </ref>: all nodes access the shared data concurrently. A process acquires mutual exclusion before each access and releases it after that. We measured the cost (i.e., number of messages and size of data transferred) by executing different instances of the synthetic application, as described below. <p> We measured the cost (i.e., number of messages and size of data transferred) by executing different instances of the synthetic application, as described below. Floyd-Warshall, QSORT, IS, and Gauss-Jacobi were developed at Texas A&M University. SOR and Matmult are available with the Quarks release <ref> [8] </ref>. ProdCons and Reader/Writer are based on qtest. Sampling period (N s ) is chosen to be 2 for all applications. <p> The paper presents experimental evalua 20 21 tion of the adaptive migratory scheme using an implementation based on Quarks DSM <ref> [8] </ref>. Experimental results from the implementation suggest that the proposed adaptive approach can indeed reduce the cost. Further work is needed to fully examine the effectiveness of the proposed approach: * The cost metrics considered in the paper are number and size of messages.
Reference: [9] <author> J.-H. Kim and N. H. Vaidya, </author> <title> "A cost-comparison approach for adaptive distributed shared memory," </title> <booktitle> in ACM International Conference on Supercomputing (ICS), </booktitle> <pages> pp. 44-51, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: 1 Introduction This report presents an adaptive migratory DSM algorithm which can dynamically self-invalidate local copy of a page on a migratory memory access pattern. The adaptive migratory algorithm is implemented based on our previous work <ref> [9] </ref> which can adapt to memory access patterns to reduce coherency overhead by adjusting "update limit". Adaptive DSM [9] outperforms a competitive update protocol as well as an invalidate protocol and an update protocol in many types of applications. However, [9] can not adapt to a migratory memory access pattern. <p> The adaptive migratory algorithm is implemented based on our previous work <ref> [9] </ref> which can adapt to memory access patterns to reduce coherency overhead by adjusting "update limit". Adaptive DSM [9] outperforms a competitive update protocol as well as an invalidate protocol and an update protocol in many types of applications. However, [9] can not adapt to a migratory memory access pattern. <p> adaptive migratory algorithm is implemented based on our previous work <ref> [9] </ref> which can adapt to memory access patterns to reduce coherency overhead by adjusting "update limit". Adaptive DSM [9] outperforms a competitive update protocol as well as an invalidate protocol and an update protocol in many types of applications. However, [9] can not adapt to a migratory memory access pattern. On a migratory sharing, a message for sending a copy of a page to a remote node, on which a page fault occurs, is directly followed by an invalidation request from the remote node. <p> Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features [4] Dir or Bus Inv + Mig [12] Dir Comp + Mig [11] Dir Inv + Self-Inv [3, 10] MM-NUMA Remote + Replicate + Mig CC <ref> [9] </ref> SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir = directory-based cache coherence multiprocessor * MM-NUMA = memory management system for MUMA multiprocessor * SDSM = software Distributed Shared Memory * Inv = invalidate protocol <p> Adaptive Protocols. 2 Basic Adaptive Protocol Adaptive migratory scheme is based on <ref> [9] </ref> in which each node can independently choose an invalidate protocol or a competitive update protocol for each copy of a page. The basic adaptive protocol [9] is summarized in this section: 1. <p> Adaptive Protocols. 2 Basic Adaptive Protocol Adaptive migratory scheme is based on <ref> [9] </ref> in which each node can independently choose an invalidate protocol or a competitive update protocol for each copy of a page. The basic adaptive protocol [9] is summarized in this section: 1. Collect statistics over a "sampling period". (Accesses to each memory page are divided into sampling periods.) 4 2. Using the statistics, determine the protocol that minimizes the "cost" for each page P . 3. <p> Repeat above steps. Essentially, the proposed implementation would use statistics collected during current execution to predict the optimal consistency protocol for the near-future. This prediction should be accurate, provided that the memory access patterns change relatively infrequently. In <ref> [9] </ref>, we present an adaptive scheme that chooses between the invalidate protocol and the competitive update protocol [7, 5, 6]. The competitive update protocol is defined by a "threshold" parameter; we will rename the threshold as the "limit". <p> The protocol is completely distributed in that each node independently determines the limit to be used for each page it has in its local memory. (Thus, different nodes may choose different limits for the same page.) The objective of the protocol <ref> [9] </ref> is to minimize the "cost" metric of interest. Two cost metrics considered are: (i) number of messages, and (ii) amount of data transferred. Let us focus on the accesses to a particular page P as observed at a node A. These accesses can be partitioned into "segments". <p> New adaptive scheme for migratory sharing needs to be designed for the software DSM (or similar architecture) in which memory coherency is maintained in totally distributed manner. Each node needs to detect the migratory memory access patterns with local information only. Our scheme is implemented based on <ref> [9] </ref> in which each node can independently choose an invalidate protocol or a competitive update protocol for each copy of a page. However, [9] can not adapt to a migratory memory access pattern. <p> Each node needs to detect the migratory memory access patterns with local information only. Our scheme is implemented based on <ref> [9] </ref> in which each node can independently choose an invalidate protocol or a competitive update protocol for each copy of a page. However, [9] can not adapt to a migratory memory access pattern. Proposed adaptive protocol includes migratory protocol as one of the choices in addition to invalidate and competitive update protocols. In a migratory memory access pattern, our previous adaptive scheme [9] will usually choose invalidate protocol if the number of nodes (N <p> However, <ref> [9] </ref> can not adapt to a migratory memory access pattern. Proposed adaptive protocol includes migratory protocol as one of the choices in addition to invalidate and competitive update protocols. In a migratory memory access pattern, our previous adaptive scheme [9] will usually choose invalidate protocol if the number of nodes (N ) is not quite small ((U N 1) U critical ). Consider the following scenario in a migratory memory access pattern: 1. Only node A has a copy of page P . 2. <p> At the beginning of each segment, a page fault occurs which requires F messages for forwarding page request, and two additional messages for receiving the page and sending acknowledgement. The number of messages required for an invalidate protocol (M invalidate ) is F + 4 <ref> [9] </ref>. (Invalidate protocol requires two more messages than migratory protocol for receiving an invalidation message and sending a negative acknowledgement.) in migratory memory access patterns (we assume that F = 4, and L = 3 for competitive update protocol). <p> The amount of data transferred for an invalidate protocol (D invalidate ) is p update + (F + 2) p control + p page , where p update is the average size of an update message <ref> [9] </ref>. (At the beginning of each segment, page fault occurs which requires data transfer of size F p control for forwarding page request, p page for receiving page, and p control for sending acknowledgement. <p> to be migratory in all segment choose migratory protocol; else choose invalidate protocol; - else choose competitive update protocol; segment = 0; updateInSampling = 0; mig = -1; - else // performs local access between page sending // and receiving update message mig = -1; pageSent = 0; Refer to <ref> [9] </ref> for the detailed implementation to count updateCnt and segment, etc. On page reply, counter mig resets at the new sampling period (segment = 0). <p> In Figure 3, the curve named "protocol" denotes the number of messages required by the specified protocol, and "#update" denotes the average number of updates per segment (U ) calculated over the entire application. "adaptive" denotes the scheme in <ref> [9] </ref>. "adaptive+" denotes adaptive migratory protocol. As number of nodes N increases, the average number of updates per segment (U ) increases proportionally. Adaptive migratory protocol performs best because qtest1 shows the migratory memory access pattern.
Reference: [10] <author> R. LaRowe, C. Ellis, and L. Kaplan, </author> <title> "The robustness of numa memory management," </title> <booktitle> in Proc. of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 137-151, </pages> <year> 1991. </year>
Reference-contexts: Dynamic page placement schemes <ref> [3, 10] </ref> including page migratory have been implemented in OS-level NUMA memory management. Their schemes can dynamically select either migration or replication for page placement according to application and architecture. <p> Our scheme is implemented incorporated into a software DSM in which memory coherency is maintained in totally distributed manner. Our adaptive migratory scheme does not need global information. Each node tries to detect the migratory memory access patterns only with local information. <ref> [3, 10] </ref> are proposed for dynamic page placement in NUMA architecture. Their dynamic page placement policy can not be applied to DSM due to architectural difference. On page fault, in NUMA architecture, a local node can access remote memory without page allocation in local memory. <p> If another protocol is optimal on a migratory sharing in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. <ref> [10] </ref> needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on page placement scheme for NUMA multiprocessors. <p> this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. <ref> [3, 10] </ref> are based on page placement scheme for NUMA multiprocessors. <p> This hybrid feature can be implemented by slightly modifying the proposed scheme. Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features [4] Dir or Bus Inv + Mig [12] Dir Comp + Mig [11] Dir Inv + Self-Inv <ref> [3, 10] </ref> MM-NUMA Remote + Replicate + Mig CC [9] SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir = directory-based cache coherence multiprocessor * MM-NUMA = memory management system for MUMA multiprocessor * SDSM =
Reference: [11] <author> A. Lebeck and D. Wood, </author> <title> "Dynamic self-invalidation: Reducing coherence overhead in shared-memory multiprocessors," </title> <booktitle> in Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: On a migratory sharing, a message for sending a copy of a page to a remote node, on which a page fault occurs, is directly followed by an invalidation request from the remote node. Our adaptive migratory algorithm eliminates an overhead for invalidation by self-invalidation <ref> [11] </ref> on sending a copy of a page to the remote node. The proposed scheme allows each node to independently choose (at run-time) a different protocol (migratory, invalidate, or competitive update protocol) for each page by using the local information only. <p> Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing [4, 12, 14], and self-invalidation <ref> [11] </ref> have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. <p> Adaptive protocols for migratory sharing [4, 12, 14], and self-invalidation <ref> [11] </ref> have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. Dynamic page placement schemes [3, 10] including page migratory have been implemented in OS-level NUMA memory management. Their schemes can dynamically select either migration or replication for page placement according to application and architecture. <p> Their schemes can dynamically select either migration or replication for page placement according to application and architecture. Our adaptive migratory scheme is implemented for a software DSM and different from others as follows: * design domain: [4] is designed on bus-based multiprocessor and directory-based cache coherence multiprocessor. <ref> [12, 14, 11] </ref> are based on directory-based cache coherence multiprocessor. In a bus-based multiprocessor, requests (for read/write miss and invalidate) by other nodes can be detected via bus, and in a directory-based cache coherence multiprocessor, home node maintains directory entries. <p> in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: <ref> [4, 14, 11] </ref> are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on page placement scheme for NUMA multiprocessors. <p> This hybrid feature can be implemented by slightly modifying the proposed scheme. Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features [4] Dir or Bus Inv + Mig [12] Dir Comp + Mig <ref> [11] </ref> Dir Inv + Self-Inv [3, 10] MM-NUMA Remote + Replicate + Mig CC [9] SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir = directory-based cache coherence multiprocessor * MM-NUMA = memory management system for
Reference: [12] <author> H. Nilson and P. Stenstrom, </author> <title> "An adaptive update-based cache coherence protocol for reduction of miss rate and traffic," </title> <type> tech. rep., </type> <institution> Lund University. </institution> <note> To appear in Parallel Architectures and Languages Europe, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: The proposed scheme allows each node to independently choose (at run-time) a different protocol (migratory, invalidate, or competitive update protocol) for each page by using the local information only. Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. <p> Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. Dynamic page placement schemes [3, 10] including page migratory have been implemented in OS-level NUMA memory management. <p> Their schemes can dynamically select either migration or replication for page placement according to application and architecture. Our adaptive migratory scheme is implemented for a software DSM and different from others as follows: * design domain: [4] is designed on bus-based multiprocessor and directory-based cache coherence multiprocessor. <ref> [12, 14, 11] </ref> are based on directory-based cache coherence multiprocessor. In a bus-based multiprocessor, requests (for read/write miss and invalidate) by other nodes can be detected via bus, and in a directory-based cache coherence multiprocessor, home node maintains directory entries. <p> If another protocol is optimal on a migratory sharing in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. <ref> [4, 14, 12] </ref> select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on <p> alternatively), other protocol (competitive update protocol, in this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and <ref> [12] </ref> is based on competitive update protocol. [3, 10] are based on page placement scheme for NUMA multiprocessors. <p> Our scheme is based on adaptive DSM in which each node can inde pendently choose (at run-time) a different protocol for each copy of a page. * hybrid protocol: In <ref> [4, 12, 14] </ref>, all copies of a block enter migratory mode or exit from migratory mode. In our scheme, each node decides independently to use migratory protocol. Therefore, some nodes can use a migratory protocol while the other nodes use other protocol (invalidate or competitive update protocol). <p> This hybrid feature can be implemented by slightly modifying the proposed scheme. Table. 1 shows summary of each scheme. 3 Scheme Design domain Protocols (Schemes) Features [4] Dir or Bus Inv + Mig <ref> [12] </ref> Dir Comp + Mig [11] Dir Inv + Self-Inv [3, 10] MM-NUMA Remote + Replicate + Mig CC [9] SDSM Inv + Comp CC Proposed SDSM Inv + Comp + Mig CC + TD * Bus = bus-based cache coherence multiprocessor * Dir = directory-based cache coherence multiprocessor * MM-NUMA <p> To detect migratory sharing, following conditions can be checked <ref> [4, 14, 12] </ref>: 1. i 6= j, writing node is not the same as the previous writer 2. <p> The number of cached copies is two (for [4, 14]) or node i and j are the only one that read a block since node i write (for <ref> [12] </ref>). 3.2 Motivation Previous works [4, 12, 14] for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes. <p> The number of cached copies is two (for [4, 14]) or node i and j are the only one that read a block since node i write (for [12]). 3.2 Motivation Previous works <ref> [4, 12, 14] </ref> for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes.
Reference: [13] <author> U. Ramachandran, G. Shah, A. Sivasubramaniam, A. Singla, and I. Yanasak, </author> <title> "Architectural mechanisms for explicit communication in shared memory multiproccessors," </title> <booktitle> in Supercomputing `95, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Other cost metrics need to be considered. In particular, impact of our heuristics on application execution time needs to be evaluated. * The adaptive approach (based on cost-comparison) presented here can be combined with ideas developed by other researchers (e.g., <ref> [13] </ref>) to obtain further improvement in DSM performance. As yet, we have not explored this possibility. Acknowledgements We thank John Carter and D. Khandekar at the University of Utah for making Quarks source code available in public domain, and Akhilesh Kumar for the Floyd-Warshall source code.
Reference: [14] <author> P. Stenstrom, M. Brorsson, and L. Sandberg, </author> <title> "An adaptive cache coherence protocol optimized for migratory sharing," </title> <booktitle> in Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 109-118, </pages> <month> May </month> <year> 1993. </year> <month> 23 </month>
Reference-contexts: The proposed scheme allows each node to independently choose (at run-time) a different protocol (migratory, invalidate, or competitive update protocol) for each page by using the local information only. Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. <p> Experimental results show that the performance is improved by dynamically selecting the migratory protocol. Adaptive protocols for migratory sharing <ref> [4, 12, 14] </ref>, and self-invalidation [11] have been proposed previously for hardware cache-coherent scheme. [4, 12, 14] dynamically identify migratory shared data and switch to migratory protocol in order to reduce the overhead. [11] can predict blocks to be invalidated and perform self-invalidation. Dynamic page placement schemes [3, 10] including page migratory have been implemented in OS-level NUMA memory management. <p> Their schemes can dynamically select either migration or replication for page placement according to application and architecture. Our adaptive migratory scheme is implemented for a software DSM and different from others as follows: * design domain: [4] is designed on bus-based multiprocessor and directory-based cache coherence multiprocessor. <ref> [12, 14, 11] </ref> are based on directory-based cache coherence multiprocessor. In a bus-based multiprocessor, requests (for read/write miss and invalidate) by other nodes can be detected via bus, and in a directory-based cache coherence multiprocessor, home node maintains directory entries. <p> If another protocol is optimal on a migratory sharing in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. <ref> [4, 14, 12] </ref> select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: [4, 14, 11] are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on <p> in special cases (e.g., two nodes update shared memory alternatively), other protocol (competitive update protocol, in this case) is chosen. [4, 14, 12] select a migratory protocol when memory access pattern is migratory sharing. [10] needs to tune the policy parameters on an application and architecture basis. * basic protocol: <ref> [4, 14, 11] </ref> are based on invalidate protocol, and [12] is based on competitive update protocol. [3, 10] are based on page placement scheme for NUMA multiprocessors. <p> Our scheme is based on adaptive DSM in which each node can inde pendently choose (at run-time) a different protocol for each copy of a page. * hybrid protocol: In <ref> [4, 12, 14] </ref>, all copies of a block enter migratory mode or exit from migratory mode. In our scheme, each node decides independently to use migratory protocol. Therefore, some nodes can use a migratory protocol while the other nodes use other protocol (invalidate or competitive update protocol). <p> A page is modified within a critical section to maintain mutual exclusion. Every access for a page is ordered by a sequence of acquire, shared memory access, and release. Migratory sharing is formally defined in <ref> [14] </ref> by using a regular expression: (R i )(R i ) fl (W i )(R i + W i ) fl (R j )(R j ) fl (W j )(R j + W j ) fl ::: In the above regular expression, R i and W i denotes a read and <p> To detect migratory sharing, following conditions can be checked <ref> [4, 14, 12] </ref>: 1. i 6= j, writing node is not the same as the previous writer 2. <p> To detect migratory sharing, following conditions can be checked [4, 14, 12]: 1. i 6= j, writing node is not the same as the previous writer 2. The number of cached copies is two (for <ref> [4, 14] </ref>) or node i and j are the only one that read a block since node i write (for [12]). 3.2 Motivation Previous works [4, 12, 14] for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. <p> The number of cached copies is two (for [4, 14]) or node i and j are the only one that read a block since node i write (for [12]). 3.2 Motivation Previous works <ref> [4, 12, 14] </ref> for migratory sharing are designed for bus-based multiprocessor and/or directory-based cache coherence multiprocessor. In these architectures, global state 6 (number of cached copies, last invalidator of a block) can be known by some or all nodes.
References-found: 14

