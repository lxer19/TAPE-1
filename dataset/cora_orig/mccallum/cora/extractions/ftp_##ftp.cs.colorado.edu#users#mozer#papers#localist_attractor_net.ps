URL: ftp://ftp.cs.colorado.edu/users/mozer/papers/localist_attractor_net.ps
Refering-URL: http://www.cs.colorado.edu/~mozer/papers/localist_attractor_net.html
Root-URL: http://www.cs.colorado.edu
Email: zemel@u.arizona.edu mozer@colorado.edu  
Title: Localist Attractor Networks  
Author: Richard S. Zemel Michael C. Mozer 
Address: Tucson, AZ 85721 Boulder, CO 80309-0430  
Affiliation: Department of Psychology Department of Computer Science University of Arizona University of Colorado  
Abstract: Attractor networks, which map a continuous input space to a discrete output space, are useful for pattern completion, cleaning up noisy or missing features in an input. However, designing a net to have a given set of attractors is notoriously tricky; training procedures are CPU intensive and often produce spurious attractors and ill-conditioned attractor basins. These difficulties occur because each connection in the network participates in the encoding of multiple attractors. We describe an alternative formulation of attractor networks in which the encoding of knowledge is local, not distributed. Although localist attractor nets have similar dynamics to their distributed counterparts, they are much easier to work with and interpret. We propose a statistical formulation of localist attractor net dynamics, which yields a convergence proof and a mathematical interpretation of model parameters. We present simulation experiments that explore the behavior of lo-calist attractor nets, showing that they produce a gang effectthe presence of an attractor enhances the attractor basins of neighboring attractorsand that spurious attractors occur only at points of symmetry in state space.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Golden, R. </author> <year> (1988). </year> <title> Probabilistic characterization of neural model computations. </title> <editor> In D. Z. Anderson (Ed.), </editor> <booktitle> Neural Information Processing Systems (pp. </booktitle> <pages> 310-316). </pages> <institution> American Institute of Physics. </institution>
Reference: [2] <author> Hopfield, J. J. </author> <year> (1982). </year> <title> Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 79, </volume> <pages> 2554-2558. </pages>
Reference: [3] <author> Mathis, D. </author> <year> (1997). </year> <title> A computational theory of consciousness in cognition. </title> <type> Unpublished Doctoral Dissertation. </type> <institution> Boulder, CO: Department of Computer Science, University of Colorado. </institution>
Reference: [4] <author> Mathis, D., & Mozer, M. C. </author> <year> (1996). </year> <title> Conscious and unconscious perception: A computational theory. </title> <editor> In G. Cot-trell (Ed.), </editor> <booktitle> Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 324-328). </pages> <publisher> Erlbaum. </publisher>
Reference: [5] <author> McClelland, J. L. & Rumelhart, D. E. </author> <year> (1981). </year> <title> An interactive activation model of context effects in letter perception: Part I. An account of basic findings. </title> <journal> Psychological Review, </journal> <volume> 88, </volume> <pages> 375-407. </pages>
Reference: [6] <author> Mozer, M. C., Sitton, M., & Farah, M. </author> <year> (1998). </year> <title> A superadditive-impairment theory of optic aphasia. </title> <editor> In M. I. Jordan, M. Kearns, & S. Solla (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 10. </booktitle> <publisher> MIT Press. </publisher>
Reference: [7] <author> Neal, R. M. & Hinton, G. E. </author> <year> (1998). </year> <title> A view of the EM algorithm that justifies incremental, sparse, and other variants. </title> <note> To appear in M. </note> <editor> I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Kluwer Academic Press. </publisher>
Reference: [8] <author> Rodrigues, N. C., & Fontanari, J. F. </author> <year> (1997). </year> <title> Multivalley structure of attractor neural networks. </title> <journal> Journal of Physics A (Mathematical and General), </journal> <volume> 30, </volume> <pages> 7945-7951. </pages>
Reference: [9] <author> Saul, L.K., Jaakkola, T., & Jordan, M.I. </author> <year> (1996). </year> <title> Mean field theory for sigmoid belief networks. </title> <journal> Journal of AI Research, </journal> <volume> 4, </volume> <pages> 6176. </pages>
References-found: 9

