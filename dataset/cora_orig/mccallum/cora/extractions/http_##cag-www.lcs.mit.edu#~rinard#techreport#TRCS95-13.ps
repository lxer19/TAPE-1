URL: http://cag-www.lcs.mit.edu/~rinard/techreport/TRCS95-13.ps
Refering-URL: http://cag-www.lcs.mit.edu/~rinard/techreport/index.html
Root-URL: 
Email: (martin@cs.ucsb.edu)  (pedro@cs.ucsb.edu)  
Title: Automatically Parallelizing Serial Programs Using Commutativity Analysis  
Author: Martin C. Rinard Pedro Diniz 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: This paper introduces a new analysis technique, commutativity analysis, for automatically parallelizing programs written in a sequential, imperative programming language. Existing parallelizing compilers preserve the data dependences of the original serial program. They analyze the program at the level of individual reads and writes to single words of memory to generate parallel code that preserves the relative order of reads and writes to the same word. Commutativity analysis, on the other hand, aggregates both data and computation into larger grain units. It then analyzes the computation at this granularity to discover when pieces of the computation commute (i.e. generate the same result regardless of the order in which they execute). If all of the operations required to perform a given computation commute, the compiler can automatically generate parallel code. While the resulting parallel program may violate the data dependences of the original serial program, it is still guaranteed to generate the same result. This paper presents commutativity analysis and shows how to exploit the extracted information to automatically generate parallel code.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. Banerjee, R. Eigenmann, A. Nicolau, and D. Padua. </author> <title> Automatic program parallelization. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 211-243, </pages> <month> February </month> <year> 1993. </year> <month> 24 </month>
Reference-contexts: 1 Introduction Current parallelizing compilers preserve the semantics of the original serial program by preserving the data dependences <ref> [1, 12] </ref>. They analyze the program to identify independent pieces of computation (two pieces of computation are independent if neither writes a piece of memory that the other accesses), then generate code that executes independent pieces concurrently.
Reference: [2] <author> J. Barnes and P. Hut. </author> <title> A hierarchical o(nlogn) force-calculation algorithm. </title> <booktitle> Nature, </booktitle> <pages> pages 446-449, </pages> <month> December </month> <year> 1976. </year>
Reference-contexts: and parameters then simulate the methods under the two execution orders to check if they do not commute with that initial assignment. 2 8 Experimental Results To evaluate the locking and concurrency management overhead in a real-world application, we applied com-mutativity analysis by hand to the Barnes-Hut hierarchical N-body solver <ref> [2] </ref> and measured the performance of the resulting parallel code. The Barnes-Hut is a challenging application because it manipulates a recursive, pointer-based data structure (a space subdivision tree). We are aware of no existing parallelizing compiler capable of automatically parallelizing this application.
Reference: [3] <author> P. Barth, R. Nikhil, and Arvind. M-structures: </author> <title> Extending a parallel, non-strict, functional language with state. </title> <booktitle> In Proceedings of the Fifth ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 538-568. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: Finally, preserving the data dependences for programs that periodically update shared data structures can artificially limit the amount of exposed concurrency, since tasks must delay updates until they are sure that each update will not change the relative order of reads and writes to the shared data structure <ref> [3, 17] </ref>. This paper presents a new analysis technique called commutativity analysis. Instead of preserving the relative order of individual reads and writes to single words of memory, commutativity analysis aggregates both 1 data and computation into larger grain units. <p> This is a very encouraging result considering the amount of effort and sophistication of the optimizations in the barnes code. 23 9 Related Work Other researchers have recognized the value of including support for commuting operations in parallel computing systems <ref> [21, 3, 20] </ref>. These systems, however, focus on exploiting commuting operations and rely on some external mechanism, typically the programmer, to specify when the operations actually commute. The techniques presented in this paper, on the other hand, automatically detect commuting operations.
Reference: [4] <author> W. Blume and R. Eigenmann. </author> <title> Symbolic range propagation. </title> <booktitle> In Proceedings of the 9th International Parallel Processing Symposium, </booktitle> <pages> pages 357-363, </pages> <address> Santa Barbara, CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Other researchers have successfully applied similar expression manipulation techniques in other analysis contexts <ref> [4] </ref>. Even with exponential running time, there are some expressions that always denote the same value but do not have the same simplified form.
Reference: [5] <author> D. Callahan. </author> <title> Recognizing and parallelizing bounded recurrences. </title> <booktitle> In Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: The techniques presented in this paper, on the other hand, automatically detect commuting operations. Several existing compilers can recognize when a loop performs a reduction of many values into a single value <ref> [7, 16, 5] </ref>. These compilers recognize when the reduction primitive (typically addition) is associative. They then exploit this algebraic property to eliminate the data dependence associated with the serial accumulation of values into the result. The generated program computes the reduction in parallel.
Reference: [6] <author> P. Diniz and M. Rinard. </author> <title> Exploiting commuting operations in parallelizing serial programs. </title> <type> Technical Report TRCS95-11, </type> <institution> Dept. of Computer Science, University of California at Santa Barbara, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: The commutativity analysis algorithm is capable of exploiting the concurrency in the force calculation and position/velocity update phases. Starting with an object-based version of the code, we generated parallel code for force calculation and position/velocity phases and implemented a library that provided the basic concurrency management functionality <ref> [6] </ref>. We expect the compiler to generate the same code and use the same library. We ran this version on the Stanford DASH machine [13]. We compare its performance with that of the barnes code, a highly tuned hand-parallelized code from the SPLASH2 benchmark set [23].
Reference: [7] <author> A. Fisher and A. Ghuloum. </author> <title> Parallelizing complex scans and reductions. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Program Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The algorithm builds the table by recursively traversing the outer conditional expressions to identify the minimal conjunctions of basic terms that select each maximal conditional-free subexpression as the value of the original expression. It is possible to further simplify the table using logic minimization techniques as proposed in <ref> [7] </ref>. To compare two expressions for equality the algorithm performs a simple recursive isomorphism test. The algorithm checks that the condition tables have the same indexes and that corresponding subexpressions in the table are isomorphic. The array expression simplification rules in Figure 12 also compare expressions for inequality. <p> The techniques presented in this paper, on the other hand, automatically detect commuting operations. Several existing compilers can recognize when a loop performs a reduction of many values into a single value <ref> [7, 16, 5] </ref>. These compilers recognize when the reduction primitive (typically addition) is associative. They then exploit this algebraic property to eliminate the data dependence associated with the serial accumulation of values into the result. The generated program computes the reduction in parallel.
Reference: [8] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability A Guide to the Theory of NP-Completness. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: Proof: The proof is a simple reduction of the non-tautology decision problem (NTDP) <ref> [8] </ref>: Given a boolean expression E (v 1 , ,v n ), is E (v 1 , ,v n ) true for all boolean assignments to v 1 , ,v n ? We transform NTDP to NCDP by generating two methods op 1 and op 2 that operate on objects with
Reference: [9] <author> W.L. Harrison. </author> <title> The interprocedural analysis and automatic parallelization of Scheme programs. </title> <journal> Lisp and Symbolic Computation, </journal> 2(3/4):179-396, October 1989. 
Reference-contexts: While researchers have been able to develop reasonably effective algorithms for loop nests that manipulate dense matrices using affine access functions [14], there has been little progress towards the successful automatic analysis of programs that manipulate pointer-based data structures. Researchers have attempted to build totally automatic systems <ref> [9] </ref>, but the most promising approaches require the programmer to provide annotations that specify information about the global topology of the manipulated data structures [10]. A second, more fundamental limitation of data-dependence based approaches is an inability to parallelize computations that manipulate graph-like data structures.
Reference: [10] <author> L. Hendren, J. Hummel, and A. Nicolau. </author> <title> Abstractions for recursive pointer data structures: improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Researchers have attempted to build totally automatic systems [9], but the most promising approaches require the programmer to provide annotations that specify information about the global topology of the manipulated data structures <ref> [10] </ref>. A second, more fundamental limitation of data-dependence based approaches is an inability to parallelize computations that manipulate graph-like data structures. The aliases inherently present in these data structures preclude the static discovery of independent pieces of code, forcing the compiler to generate serial code.
Reference: [11] <author> G. Huet. </author> <title> Confluent reductions: Abstract properties and applications to term rewriting systems. </title> <journal> Journal of the ACM, </journal> <volume> 27(4) </volume> <pages> 797-821, </pages> <year> 1980. </year>
Reference-contexts: M; p 2 mst (A) : hm 1 ; p 1 i ) ) hm 0 ; pi and hm 2 ; p 2 i ) ) hm 0 ; pi Proof Sketch: If all of the invoked operations commute then the transition system is confluent, which guarantees deterministic execution <ref> [11] </ref>. An immediate corollary of these two lemmas is that if the serial computation terminates, then all parallel computations terminate with identical memories.
Reference: [12] <author> D. Kuck, Y. Muraoka, and S. Chen. </author> <title> On the number of operations simultaneously executable in Fortran-like programs and their resulting speedup. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-21(12):1293-1310, </volume> <month> December </month> <year> 1972. </year>
Reference-contexts: 1 Introduction Current parallelizing compilers preserve the semantics of the original serial program by preserving the data dependences <ref> [1, 12] </ref>. They analyze the program to identify independent pieces of computation (two pieces of computation are independent if neither writes a piece of memory that the other accesses), then generate code that executes independent pieces concurrently.
Reference: [13] <author> D. Lenoski. </author> <title> The Design and Analysis of DASH: A Scalable Directory-Based Multiprocessor. </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <address> CA, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: We expect the compiler to generate the same code and use the same library. We ran this version on the Stanford DASH machine <ref> [13] </ref>. We compare its performance with that of the barnes code, a highly tuned hand-parallelized code from the SPLASH2 benchmark set [23]. Tables 5 and 6 present the timing results.
Reference: [14] <author> D. Maydan, J. Hennessy, and M. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Program Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: A significant limitation of this approach is the difficulty of performing dependence analysis that is precise enough to expose substantial amounts of concurrency. While researchers have been able to develop reasonably effective algorithms for loop nests that manipulate dense matrices using affine access functions <ref> [14] </ref>, there has been little progress towards the successful automatic analysis of programs that manipulate pointer-based data structures.
Reference: [15] <author> E. Mohr, D. Kranz, and R. Halstead. </author> <title> Lazy task creation: a technique for increasing the granularity of parallel programs. </title> <booktitle> In Proceedings of the 1990 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 185-197, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This lock ensures that each invocation of parallel visit executes atomically with respect to all other invocations with the same receiver. The parallel visit method acquires the lock before accessing the receiver and releases the lock before invoking any methods. A straightforward application of lazy task creation techniques <ref> [15] </ref> can increase the granularity of the resulting parallel computation. class graph - lock mutex; boolean mrk; int val, sum; graph *left; graph *right; - graph::visit (int s) - this-&gt;parallel_visit (s); wait (); - graph::parallel_visit (int p) - acquire (mutex); graph *l = left; graph *r = right; int v =
Reference: [16] <author> S. Pinter and R. Pinter. </author> <title> Program optimization and parallelization using idioms. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Orlando, FL, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The techniques presented in this paper, on the other hand, automatically detect commuting operations. Several existing compilers can recognize when a loop performs a reduction of many values into a single value <ref> [7, 16, 5] </ref>. These compilers recognize when the reduction primitive (typically addition) is associative. They then exploit this algebraic property to eliminate the data dependence associated with the serial accumulation of values into the result. The generated program computes the reduction in parallel.
Reference: [17] <author> M. Rinard. </author> <title> The Design, Implementation and Evaluation of Jade, a Portable, Implicitly Parallel Programming Language. </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <address> CA, </address> <year> 1994. </year> <month> 25 </month>
Reference-contexts: Finally, preserving the data dependences for programs that periodically update shared data structures can artificially limit the amount of exposed concurrency, since tasks must delay updates until they are sure that each update will not change the relative order of reads and writes to the shared data structure <ref> [3, 17] </ref>. This paper presents a new analysis technique called commutativity analysis. Instead of preserving the relative order of individual reads and writes to single words of memory, commutativity analysis aggregates both 1 data and computation into larger grain units.
Reference: [18] <author> D. Scales and M. S. Lam. </author> <title> An efficient shared memory system for distributed memory machines. </title> <type> Technical Report CSL-TR-94-627, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Programmers who parallelize computations by hand have always used commuting operations. For example, four (Water, MP3D, LocusRoute and Cholesky) of the six parallel applications in the SPLASH benchmark suite [19] and three of the four parallel applications described in <ref> [18] </ref> violate the data dependences of the original serial program and rely on commuting operations for their correct execution.
Reference: [19] <author> J. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Programmers who parallelize computations by hand have always used commuting operations. For example, four (Water, MP3D, LocusRoute and Cholesky) of the six parallel applications in the SPLASH benchmark suite <ref> [19] </ref> and three of the four parallel applications described in [18] violate the data dependences of the original serial program and rely on commuting operations for their correct execution.
Reference: [20] <author> J. Solworth and B. Reagan. </author> <title> Arbitrary order operations on trees. </title> <booktitle> In Languages and Compilers for Parallel Computing, Fourth International Workshop, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: This is a very encouraging result considering the amount of effort and sophistication of the optimizations in the barnes code. 23 9 Related Work Other researchers have recognized the value of including support for commuting operations in parallel computing systems <ref> [21, 3, 20] </ref>. These systems, however, focus on exploiting commuting operations and rely on some external mechanism, typically the programmer, to specify when the operations actually commute. The techniques presented in this paper, on the other hand, automatically detect commuting operations.
Reference: [21] <author> G. Steele. </author> <title> Making asynchronous parallelism safe for the world. </title> <booktitle> In Proceedings of the Seventeenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 218-231, </pages> <address> San Francisco, CA, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: This is a very encouraging result considering the amount of effort and sophistication of the optimizations in the barnes code. 23 9 Related Work Other researchers have recognized the value of including support for commuting operations in parallel computing systems <ref> [21, 3, 20] </ref>. These systems, however, focus on exploiting commuting operations and rely on some external mechanism, typically the programmer, to specify when the operations actually commute. The techniques presented in this paper, on the other hand, automatically detect commuting operations.
Reference: [22] <author> W. Weihl. </author> <title> Commutativity-based concurrency control for abstract data types. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1488-1505, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Knowledge of the algebraic properties therefore enhances the effectiveness of, rather than enables, the presented techniques. Research performed in the context of database concurrency control has shown that it is possible to take advantage of commuting operations to increase the amount of concurrency available in transaction processing systems <ref> [22] </ref>. The presented approach is based on using abstract specifications of the behavior of the operations to expose the commutativity. It is the responsibility of the programmer to ensure that the actual implementation preserves the semantics of the specification.
Reference: [23] <author> S. Woo, M. Ohara, E. Torrie, J.P. Singh, and A. Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22th International Symposium on Computer Architecture, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1995. </year> <month> 26 </month>
Reference-contexts: We expect the compiler to generate the same code and use the same library. We ran this version on the Stanford DASH machine [13]. We compare its performance with that of the barnes code, a highly tuned hand-parallelized code from the SPLASH2 benchmark set <ref> [23] </ref>. Tables 5 and 6 present the timing results. Processors Nbody 1 2 4 8 16 1024 7.94 4.05 2.19 1.38 0.92 4096 51.23 26.82 14.20 8.09 5.16 16384 301.4 146.9 77.56 45.60 26.13 Table 5: Execution times for commutativity analysis version (seconds).
References-found: 23

