URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mmoll/www/moll.MScThesis.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mmoll/www/publications.html
Root-URL: 
Title: Head-Corner Parsing using Typed Feature Structures  
Author: Mark Moll Dr.ir. H.J.A. op den Akker Prof.dr.ir. A. Nijholt Ir. H.W.L. ter Doest 
Degree: Graduation Committee  
Affiliation: Prof.dr. C. Hoede (Dept. of Appl. Math.) Subdepartment Software Engineering and Theoretical Computer Science Computer Science Department Universitity of Twente  
Date: August 1995  
Abstract-found: 0
Intro-found: 1
Reference: <author> Aho, A. V., Hopcroft, J. E., and Ullman, J. D. </author> <year> (1983). </year> <title> Data structures and algorithms. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Note that the Parser does not have to concern itself with ambiguous words; these are handled by the Scanner and the Lexicon. Items for ambiguous and consecutive words are handled in the same way by the Parser. The Lexicon is implemented as a binary search tree of Words <ref> (Aho et al. 1983) </ref>. Every node in the tree contains a Word. In the tree attached to the left branch of a word, only words occur with a smaller lexicographical value. Likewise, in the tree at the right branch only words occur with a larger lexicographical value. <p> The most important one is the SymbolTable class. It contains many methods to facilitate the specification of semantic actions for the TFS grammar 3 . During the parsing of a specification all information about types, words, grammar rules and variables is stored in a so-called hash table <ref> (Aho et al. 1983) </ref>. A hash table is an array of entry lists. An entry is an object that contains the feature structure of a certain type, word, rule of variable and the name that is associated with it.
Reference: <author> Aho, A. V., Sethi, R., and Ullman, J. D. </author> <year> (1986). </year> <title> Compilers: </title> <booktitle> Principles, Techniques and Tools. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: More about symbol tables, hash functions and other compiler construction topics can be found in <ref> (Aho et al. 1986) </ref>. 2 Type identifiers are actually just integers. 3 The grammar for TFS itself, that is, not a grammar specified with TFS. Chapter 6 Discussion 6.1 Unification Revisited There has been a lot of research on unification.
Reference: <author> At-Kaci, H. </author> <year> (1984). </year> <title> A Lattice-Theoretic Approach to Computation Based on a Calculus of Partially Ordered Types. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania. </institution>
Reference: <author> Alshawi, H., </author> <title> editor (1992). The Core Language Engine. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: But apart from expressiveness of the specification language, the ease with which the intended information about a language can be encoded is also important. An example of a language that combines expressiveness with ease of use is the Core Language Engine <ref> (Alshawi 1992) </ref>. Unfortunately the Core Language Engine (CLE) does not support typing. Within my thesis' subject a type specification language has been developed that can be positioned somewhere between ALE and CLE.
Reference: <author> Bergin, J. </author> <year> (1994). </year> <title> Data Abstraction: the Object-Oriented Approach using C++. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: Programming in C++ could be done in an imperative style, but then there would be no advantage in using C++ over using Modula-2 (which was used for the predecessors of the TFS parser). I thought that the object-oriented design methodology <ref> (Bergin 1994) </ref> might be very useful to keep a system as large as TFS manageable and maintainable.
Reference: <author> Bouma, G. </author> <year> (1993). </year> <title> Nonmonotonicity and Categorial Unification Grammar. </title> <type> PhD thesis, </type> <institution> Rijksuniversiteit Groningen. </institution>
Reference: <author> Carpenter, B. </author> <year> (1992). </year> <title> The Logic of Typed Feature Sructures. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: To keep track of the least upper bound relation a lower triangle matrix with the least upper bound of every two types is updated after each addition of a type to the symbol table. The type lattice is restricted to be a finite bounded complete partial order <ref> (Carpenter 1992) </ref>.
Reference: <author> Carpenter, B., and Penn, G. </author> <year> (1994). </year> <title> Ale 2.0 user's guide. </title> <type> Technical report, </type> <institution> Carnegie Mellon University Laboratory for Computational Linguistics, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: Almost always the usage of a specification language is limited to only one grammar formalism. This is not necessarily a drawback, as such a specification language can be better tailored towards the peculiarities of the formalism. For example, ALE <ref> (Carpenter and Penn 1994) </ref> is a very powerful (type) specification language for the domain of unification-based grammar formalisms. But apart from expressiveness of the specification language, the ease with which the intended information about a language can be encoded is also important.
Reference: <author> Carroll, L. </author> <title> (1871). Through the Looking-Glass, and What Alice Found There. </title> <publisher> Macmillan. </publisher>
Reference: <author> Carroll, L. </author> <year> (1960). </year> <title> The Annotated Alice. Clarkson N. Potter. Alice's Adventures in Wonderland & Through the Looking-Glass, Edited by Martin Gardner. </title>
Reference: <author> Eisele, A., and Dorre, J. </author> <year> (1988). </year> <title> Unification of disjunctive feature descriptions. </title> <booktitle> In Proceedings of the 26th Annual Meeting of the ACL. </booktitle> <address> Buffalo. </address>
Reference: <author> Groenink, A. </author> <year> (1992). </year> <title> Een semantische interpretator voor een prototype natuurlijke-taalinterface. </title> <type> Technical Report TI-SV-92-1845, </type> <institution> PTT Research, Leidschendam, The Netherlands. </institution> <note> In Dutch. 41 42 References Grosz, </note> <editor> B., Jones, K. S., and Webber, B., editors (1982). </editor> <booktitle> Readings in Natural Language Processing. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Harrison, M. A. </author> <year> (1978). </year> <title> Introduction to Formal Language Theory. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Hegner, S. J. </author> <year> (1991). </year> <title> Horn extended feature structures: Fast unification with negation and limited disjunction. </title> <booktitle> In Fifth European Chapter of the Association for Computational Linguistics (EACL'91), </booktitle> <pages> 33-38. </pages> <address> Berlin. </address>
Reference: <author> Hoeven, G. v. d., Andernach, J., Van de Burgt, S., Kruijff, G.-J., Nijholt, A., Schaake, J., and De Jong, F. </author> <year> (1995). </year> <title> Schisma: A natural language accessible theatre information and booking system. </title> <booktitle> In Proceedings of the First International Workshop on Applications of Natural Language to Data Bases. </booktitle> <address> Versailles, France. </address>
Reference-contexts: It outputs one (ideally) or several (in case of semantic ambiguities) analyses of the input from the Maf module. The dialogue manager then selects the most likely analysis given the status of the current dialogue. More about the dialogue manager can be found in <ref> (Hoeven et al. 1995) </ref>. With my thesis project I focus on the Pars module. To allow the Pars module to work independently from the maf module, the parser is equipped with a (very simple) scanner to read words and look them up in a lexicon.
Reference: <author> Johnson, M. </author> <year> (1988). </year> <title> Attribute-Value Logic and the Theory of Grammar. </title> <booktitle> CSLI Lecture Notes Series. </booktitle> <publisher> University of Chicago Press. </publisher>
Reference-contexts: One way to make extensions is to take the logical approach. In the past feature structures have been formalized with an attribute-value logic <ref> (Johnson 1988) </ref> or with so-called -terms (At-Kaci 1984). Based on such a logical backbone, feature structures can be extended with, for instance, disjunction and negation (Hegner 1991; Eisele and Dorre 1988; Kasper 1987).
Reference: <author> Kasper, R. T. </author> <year> (1987). </year> <title> A unification method for disjunctive feature descriptions. </title> <booktitle> In Proceedings of the 25th Annual Meeting of the ACL. </booktitle>
Reference: <author> Kay, M. </author> <year> (1980). </year> <title> Algorithm schemata and data structures in syntactic processing. </title> <type> Report CSL-80-12, </type> <institution> Xerox Parc, </institution> <address> Palo Alto, CA. </address> <note> Reprinted in (Grosz et al. </note> <year> 1982). </year>
Reference: <author> Kogure, K. </author> <year> (1994). </year> <title> Structure sharing problem and its solution in graph unification. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics, </booktitle> <pages> 886-892. </pages>
Reference: <author> Nijholt, A. </author> <year> (1990). </year> <title> The CYK-approach to serial and parallel parsing. </title> <type> Memorandum Infor-matica 90-13, </type> <institution> University of Twente, Department of Computer Science. </institution>
Reference: <author> Rounds, W., and Kasper, R. </author> <year> (1986). </year> <title> A complete logical calculus for record structures representing linguistic information. </title> <booktitle> In Proceedings of the 15th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> 39-43. </pages> <address> Cambridge, MA. </address>
Reference: <author> Shieber, S. M. </author> <year> (1986). </year> <title> An Introduction to Unification-Based Approaches to Grammar. Stan-ford, CA: Center for the Study of Language and Information, </title> <publisher> Stanford University. </publisher>
Reference-contexts: During parsing constraints can be checked with feature structures, and after parsing the meaning of the language utterance can (hopefully) be extracted from them. The structure of our feature structures is similar to the more traditional form of feature structures as used in the patr-ii system <ref> (Shieber 1986) </ref> and those defined by Rounds and Kasper (1986). Typed feature structures are defined as rooted DAGs (directed acyclic graphs), with labeled edges and nodes.
Reference: <author> Sikkel, K. </author> <year> (1993). </year> <title> Parsing Schemata. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Twente, Enschede, The Netherlands. </institution>
Reference-contexts: Expressing Semantics Chapter 5 The Parser I n this chapter the head-corner parsing algorithm will be discussed that is used to parse sentences. The first two sections are based on the chapters 10 and 11 of <ref> (Sikkel 1993) </ref>. Parts of these chapters can also be found in (Sikkel and Op den Akker 1993). In section 5.3 an extension of the formalism with typed feature structures is introduced. <p> Expressing Semantics Chapter 5 The Parser I n this chapter the head-corner parsing algorithm will be discussed that is used to parse sentences. The first two sections are based on the chapters 10 and 11 of (Sikkel 1993). Parts of these chapters can also be found in <ref> (Sikkel and Op den Akker 1993) </ref>. In section 5.3 an extension of the formalism with typed feature structures is introduced. <p> This process continues as long as the agenda is not empty. Figure 5.1 shows a general schema for a chart parser. The head-corner parser that is described here corresponds to the sHC parsing schema as described in chapter 11 of <ref> (Sikkel 1993) </ref>. This schema can parse sentences from arbitrary context-free head grammars in cubic time. A head-corner chart parser uses different kinds of items. <p> Note that, unlike the parsing system P pHC (UG) for untyped unification grammars as defined on pages 266-267 of <ref> (Sikkel 1993) </ref>, no extra constraints on features are required for the feature structures associated with the items. In our case these constraints are unnecessary, since the typing already restricts the feature structures to valid values. 5.4 Implementation The implementation of the head-corner parser is at this moment heavily under construction. <p> Also, by the use of inheritance specifications tend to get shorter, an advantage that will become more apparent for larger grammars. 39 40 7. Conclusions * The head-corner parsing system P sHC <ref> (Sikkel 1993) </ref> can also be applied to typed feature structures. This results in a similar system, where feature structures are associated with items and constraints are put on them. * The object-oriented design methodology has proven to be very useful for a programming-in-the-large project.
Reference: <author> Sikkel, K., and Op den Akker, R. </author> <year> (1993). </year> <title> Predictive head-corner chart parsing. </title> <booktitle> In Proceedings of the Third International Workshop on Parsing Technologies, </booktitle> <pages> 267-275. </pages> <address> Tilburg (The Netherlands), Durbuy (Belgium). </address>
Reference-contexts: Expressing Semantics Chapter 5 The Parser I n this chapter the head-corner parsing algorithm will be discussed that is used to parse sentences. The first two sections are based on the chapters 10 and 11 of <ref> (Sikkel 1993) </ref>. Parts of these chapters can also be found in (Sikkel and Op den Akker 1993). In section 5.3 an extension of the formalism with typed feature structures is introduced. <p> Expressing Semantics Chapter 5 The Parser I n this chapter the head-corner parsing algorithm will be discussed that is used to parse sentences. The first two sections are based on the chapters 10 and 11 of (Sikkel 1993). Parts of these chapters can also be found in <ref> (Sikkel and Op den Akker 1993) </ref>. In section 5.3 an extension of the formalism with typed feature structures is introduced. <p> This process continues as long as the agenda is not empty. Figure 5.1 shows a general schema for a chart parser. The head-corner parser that is described here corresponds to the sHC parsing schema as described in chapter 11 of <ref> (Sikkel 1993) </ref>. This schema can parse sentences from arbitrary context-free head grammars in cubic time. A head-corner chart parser uses different kinds of items. <p> Note that, unlike the parsing system P pHC (UG) for untyped unification grammars as defined on pages 266-267 of <ref> (Sikkel 1993) </ref>, no extra constraints on features are required for the feature structures associated with the items. In our case these constraints are unnecessary, since the typing already restricts the feature structures to valid values. 5.4 Implementation The implementation of the head-corner parser is at this moment heavily under construction. <p> Also, by the use of inheritance specifications tend to get shorter, an advantage that will become more apparent for larger grammars. 39 40 7. Conclusions * The head-corner parsing system P sHC <ref> (Sikkel 1993) </ref> can also be applied to typed feature structures. This results in a similar system, where feature structures are associated with items and constraints are put on them. * The object-oriented design methodology has proven to be very useful for a programming-in-the-large project.
Reference: <author> Sowa, J. F. </author> <year> (1984). </year> <title> Conceptual Structures. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: That is, words have a more or less fixed meaning, which is what Alice is trying to say. But the same word can have different connotations for different people, based on the mental models that have been formed for each word <ref> (Sowa 1984) </ref>. 1.1 Assignment Description In computational linguistics formal systems are defined and used to describe natural language utterances. Of course, these systems cannot fully capture the (intended) meaning of natural language, but for most practical situations this is not a problem.
Reference: <author> Stroustrup, B. </author> <year> (1991). </year> <title> The C++ Programming Language. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. second edition. </publisher>
Reference: <author> Sudkamp, T. A. </author> <year> (1988). </year> <title> Languages and Machines. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: When the Maf and Pars module are integrated, the scanner can be removed. 1.3 Context-Free Grammars 3 1.3 Context-Free Grammars In the field of computational linguistics (natural) languages are formalized by means of a grammar and a lexicon 1 . There are many classes of grammars <ref> (Sudkamp 1988) </ref>. An important class of grammars are the context-free grammars. A context-free grammar G is a 4-tuple hN; ; P; Si. N is a set of nonterminals (`names of parts of sentences'). The set is a collection of terminals.
Reference: <author> Tomabechi, H. </author> <year> (1991). </year> <title> Quasi-destructive graph unification. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the ACL. </booktitle> <address> Berkeley, CA. </address> <note> References 43 Tomabechi, </note> <author> H. </author> <year> (1992). </year> <title> Quasi-destructive graph unification with structure-sharing. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics, </booktitle> <pages> 440-446. </pages>
Reference: <author> Veldhuijzen van Zanten, G., and Op den Akker, R. </author> <year> (1994). </year> <title> Developing natural language interfaces: a test case. </title> <editor> In Boves, L., and Nijholt, A., editors, </editor> <booktitle> Twente Workshop on Language Technology 8: Speech and Language Engineering, </booktitle> <pages> 121-135. </pages> <address> Enschede, The Netherlands. </address>
Reference-contexts: With this algorithm the copying of (partial) feature structures is delayed until it has been established that unification can succeed. But Tomabechi already suggests in a footnote that the algorithm can be improved by sharing substructures. This idea has been worked out into an algorithm <ref> (Veldhuijzen van Zanten and Op den Akker 1994) </ref>. The copy algorithm has been implemented in a predecessor of the current parser and has proven to be very effective in experiments. Table 2.1 shows the results of one of these experiments.
Reference: <author> Verlinden, M. </author> <year> (1993). </year> <title> Ontwerp en implementatie van een head-corner ontleder voor grammat-ica's met feature structures. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of Twente, Enschede, The Netherlands. </institution> <note> In Dutch. </note>
Reference: <author> Wroblewski, D. </author> <year> (1987). </year> <title> Nondestructive graph unification. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Yellin, D. </author> <year> (1988). </year> <title> A dynamic transitive closure algorithm. </title> <type> Research Report RC 13535, </type> <institution> IBM Research Division, T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY. 44 References </address>
Reference-contexts: If no error has occured while reading the specification, the contents of the symbol table is mapped to C++ code. During the first step also the type lattice and the transitive and reflexive closure of the head-corner relation 1 are determined <ref> (Yellin 1988) </ref>. In the second compilation step the C++ code is compiled and then linked with grammar-independent code: code that implements the parsing algorithm and code used for the user interface and the `linguistic workbench' (see figure 3.1).
References-found: 32

