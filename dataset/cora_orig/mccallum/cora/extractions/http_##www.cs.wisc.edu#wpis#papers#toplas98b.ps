URL: http://www.cs.wisc.edu/wpis/papers/toplas98b.ps
Refering-URL: http://www.cs.wisc.edu/~reps/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Maximal-Munch Tokenization in Linear Time  
Author: THOMAS REPS 
Keyword: CR Categories and Subject Descriptors: D.3.4 [Programming Languages]: Processors compilers; F.1.1 [Computation by Abstract Devices]: Models of Computation automata; F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems pattern matching; I.5.4 [Pattern Recognition]: Applications text processing General Terms: Algorithms, Theory Additional Key Words and Phrases: backtracking, dynamic programming, memoization, tabulation, tokenization  
Affiliation: University of Wisconsin  
Abstract: The lexical-analysis (or scanning) phase of a compiler attempts to partition an input string into a sequence of tokens. The convention in most languages is that the input is scanned left to right, and each token identified is a maximal munch of the remaining inputthe longest prefix of the remaining input that is a token of the language. Although most of the standard compiler textbooks present a way to perform maximal-munch tokenization, the algorithm they describe is one that, for certain sets of token definitions, can cause the scanner to exhibit quadratic behavior in the worst case. In this paper, we show that maximal-munch tokenization can always be performed in time linear in the size of the input. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aho, A.V., Hopcroft, J.E., and Ullman, J.D., </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1974). </address>
Reference-contexts: gathered at the time pairs are popped off the stack (line [21]), and used during the scan-hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 However, there is no impact from the standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input <p> Backtrack to the most recent final state */ [20] while q / F do [21] [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) <p> In particular, if k is | Q | , the space used is n +1 bitsi.e., a quantity independent of the number of statesand the running time is hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 4 By using a technique described by Aho, Hopcroft, and Ullman (see <ref> [1, Problem 2.12] </ref>), we can sidestep the need to initialize failed_previously; however, this increases the space used from | Q | (n +1) bits to W ( | Q | (n +1)) pointers. 5 The DO statement in Fortran requires unbounded lookahead, but Fortran does not use the maximal-munch convention. - <p> In Figure 3 (b), four lines are changed from Figure 1 (a) (which is repeated as Figure 3 (a) for the reader's convenience). As before, changes in the code that appears on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, <p> / F do [21] failed_previously [q,i ] := true [22] q, i := pop () [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom,
Reference: 2. <author> Aho, A.V. and Ullman, J.D., </author> <title> Principles of Compiler Design, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1977). </address>
Reference-contexts: Most of the standard compiler textbooks, including [2,12,3,7,13], discuss this issue briefly. For example, Aho and Ullman's 1977 book discusses the issue in the context of a lexical analyzer based on deterministic finite-state automata (DFAs) <ref> [2, pp. 109-110] </ref>: There are several nuances in this procedure of which the reader should be aware. First, there are in the combined NFA several different accepting states. That is, the accepting state of each N i indicates that its own token, P i , has been found. <p> On first consideration, the backtracking loop that searches for the most recent final state in Figure 1 (a) (lines [20]-[26]) seems like extra work. A maximal-munch tokenization algorithm need not use a stack to review the states of the DFA which we have entered while processing the input <ref> [2] </ref>: As the input is scanned, it merely has to maintain a pair of variables, say last_final_state_position and last_final_state, to record the position and state, respectively, for the maximum index position at which M was in a final state. <p> stack (line [21]), and used during the scan-hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 However, there is no impact from the standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q <p> while q / F do [21] [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length <p> As before, changes in the code that appears on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i <p> [22] q, i := pop () [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i <p> However, lexical-analysis tools such as Lex are often used for tasks outside the domain of compilation. For example, Aho and Ullman mention the use of Lex to recognize imperfections in printed circuits <ref> [2] </ref>. Some of these nonstandard applications may represent situations in which the algorithms presented in this paper could be of importance. ACKNOWLEDGEMENTS M. Sagiv introduced me to the problem, and showed me the example that a student of his, R.
Reference: 3. <author> Aho, A.V., Sethi, R., and Ullman, J.D., </author> <booktitle> Compilers: Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1986). </address>
Reference-contexts: The discussion of the problem in the 1986 book by Aho, Sethi, and Ullman is similar, except that they assume that lexical analysis is performed by simulating an NFA, rather than first converting an NFA to a DFA <ref> [3, pp. 104] </ref>. Other similar discussions are given by Waite and Goos [12], Fischer and LeBlanc [7], and Wilhelm and Maurer [13]. <p> For instance, Aho, Sethi, and Ullman say The separation of lexical analysis from [parsing] often allows us to simplify one or the other of these phases . . . Compiler efficiency is improved . . . [and] compiler portability is enhanced <ref> [3, pp. 84-85] </ref>. Because a program's syntax is typically defined with an LL, LALR, or LR grammar, the parsing phase can always be carried out in linear time. <p> no impact from the standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) <p> [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do <p> As before, changes in the code that appears on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] <p> [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13]
Reference: 4. <author> Aho, </author> <title> A.V., Algorithms for finding patterns in strings, </title> <note> pp. 255-300 in Handbook of Theor. Comp. Sci., Vol. A: Algorithms and Complexity, </note> <editor> ed. J. </editor> <publisher> van Leeuwen,The M.I.T. Press, </publisher> <address> Cambridge, MA (1990). </address>
Reference-contexts: from the standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q <p> Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if <p> As before, changes in the code that appears on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] <p> Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14]
Reference: 5. <author> Cook, S.A., </author> <title> Linear time simulation of deterministic two-way pushdown automata, pp. </title> <booktitle> 172-179 in Information Processing 71: Proc. of the IFIP Congress 71, </booktitle> <publisher> ed. C.V. </publisher> <address> Freiman,North-Holland, Amsterdam (1972). </address>
Reference-contexts: 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do <ref> [5] </ref> failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then <p> changes in the code that appears on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do <ref> [5] </ref> failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q <p> 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do <ref> [5] </ref> failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi
Reference: 6. <author> DeRemer, F.L., </author> <title> Lexical analysis, pp. 109-120 in Compiler Construction: An Advanced Course, </title> <editor> ed. F.L. Bauer and J. Eickel,Springer-Verlag, </editor> <address> New York, NY (1974). </address>
Reference-contexts: the standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] <ref> [6] </ref> [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := <p> length (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false <ref> [6] </ref> od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty <p> on the right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false <ref> [6] </ref> od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to <p> (input) then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false <ref> [6] </ref> od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset
Reference: 7. <author> Fischer, C.N. and LeBlanc, </author> <title> R.J., Crafting a Compiler, </title> <publisher> Benjamin/Cummings Publishing Company, Inc., </publisher> <address> Menlo Park, CA (1988). </address>
Reference-contexts: Other similar discussions are given by Waite and Goos [12], Fischer and LeBlanc <ref> [7] </ref>, and Wilhelm and Maurer [13].
Reference: 8. <author> Hopcroft, J.E. and Ullman, J.D., </author> <title> Introduction to Automata Theory, Languages, and Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1979). </address>
Reference-contexts: We assume that we are given a deterministic finite-state automaton (DFA) M such that L (M) = L (R 1 + R 2 + . . . + R k ). g Standard notation for DFAs is used (e.g., see <ref> [8] </ref>). That is, a DFA M is a five-tuple Q, S, d, q 0 , F, where - Q is a finite nonempty set of states. <p> standpoint of asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d <p> then [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] <p> right-hand side are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi <p> [29] return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack
Reference: 9. <author> Knuth, D.E., Morris, J.H., and Pratt, </author> <title> V.R., Fast pattern matching in strings, </title> <note> SIAM J. Computing 6(2) pp. </note> <month> 323-350 </month> <year> (1977). </year>
Reference-contexts: asymptotic worst-case complexity: The worst-case running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input <p> return Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] push (q, <p> are indicated in a contrasting typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] push <p> Success [30] fi [31] pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty
Reference: 10. <author> Mogensen, T., WORM-2DPDAs: </author> <title> An extension to 2DPDAs that can be simulated in linear time, Inf. </title> <booktitle> Proc. Let. </booktitle> <pages> 52 pp. </pages> <month> 15-22 </month> <year> (1994). </year>
Reference-contexts: running time is quadratic no matter which of these two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := <p> pool [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d <p> typeface. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := <p> [32] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] if q Tab <p> These are initialized in the loop on lines [4]-[6]. (ii) failed_previously is only accessed for states that are members of Tab (see lines [14] and [21]). (iii) The stack only ever contains entries for Bottom (line <ref> [10] </ref>), final states (line [16]), and states that are members of Tab (line [16]). Note that if Tab = , only a single pair ever appears on the stacki.e., one that is either of the form Bottom, position or final-state, position. <p> Note that q is either Bottom, if q, i came from line <ref> [10] </ref>, or a final state if q, i came from line [16] (see also line [15]). By properties (i) and (ii) above, Tokenize can only consume a bounded amount of input once it reaches one of the non-final states in Bounded. <p> The author was motivated to develop the algorithms presented in the paper after observing that a certain result in automata theory, due to Mogensen <ref> [10] </ref> (which extends an earlier result by Cook [5,1]) implied that maximal-munch tokenization could be performed in linear time.
Reference: 11. <author> Reps, T., </author> <title> `Maximal-munch' tokenization in linear time, </title> <institution> TR-1347, Comp. Sci. Dept., Univ. of Wisconsin, Madison, </institution> <note> WI (May 1997; revised August 1997). </note>
Reference-contexts: two backtracking methods is used. - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the most recent <p> input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + <p> : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i <p> : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] if q Tab F then push (q, i) fi [17] q := <p> Given a DFA M that recognizes the tokens of a language, it is easy to construct a WORM-2DPDA M that identifies maximal-munch tokens (see <ref> [11] </ref>). <p> The well-known algorithm of Knuth, Morris, and Pratt for linear-time pattern matching in strings is another example of an algorithm that was developed in a similar fashion [9,1,4]. (A lengthier discussion of these ideas can be found in <ref> [11] </ref>.) Although most programming languages do have the property that there is a token class for which some of the tokens are prefixes of tokens in another token class (e.g., integer and floating-point constants), the potential quadratic behavior of lexical analyzers is almost certainly not a problem in practice.
Reference: 12. <author> Waite, W.M. and Goos, G., </author> <title> Compiler Construction, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY (1983). </address>
Reference-contexts: Other similar discussions are given by Waite and Goos <ref> [12] </ref>, Fischer and LeBlanc [7], and Wilhelm and Maurer [13]. <p> - 5 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the most recent final state */ [20] while <p> Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the <p> S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to <p> S, d, q 0 , F = M in [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] if q Tab F then push (q, i) fi [17] q := d (q, input [i ]) <p> If this assumption is relaxed, permitting the state to be retained from the last invocation, then it is sometimes possible to avoid even the limited backtracking discussed above . . . Whether this technique solves all prob lems is still an open question <ref> [12, pp. 138-139] </ref>. The solutions given in the present paper are based on a different principle; rather than permitting the state - 12 - to be retained from the last invocation, they rely on tabulation to avoid repeating work.
Reference: 13. <author> Wilhelm, R. and Maurer, D., </author> <title> Compiler Design (English Edition), </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1995). </address>
Reference-contexts: Other similar discussions are given by Waite and Goos [12], Fischer and LeBlanc [7], and Wilhelm and Maurer <ref> [13] </ref>. <p> DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> do [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the most recent final state */ [20] while q / F do [21] [23] if q = <p> in [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> do [14] if failed_previously [q,i] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the most recent final state */ [20] while q / <p> [3] begin [4] for each q Q and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> do [14] if failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] push (q, i) [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to the most recent final state */ [20] while q <p> [3] begin [4] for each q Tab and i [1..length (input)+1] do [5] failed_previously [q,i ] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom, i) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> do [14] if q Tab cand failed_previously [q,i ] then break fi [15] if q F then reset the stack to empty fi [16] if q Tab F then push (q, i) fi [17] q := d (q, input [i ]) [18] i := i + 1 /* Backtrack to
References-found: 13

