URL: ftp://theory.lcs.mit.edu/pub/people/acr/bglr.ps
Refering-URL: http://theory.lcs.mit.edu:80/~acr/
Root-URL: 
Email: e-mail: mihir@watson.ibm.com.  e-mail: shafi@theory.  email: lund@research.att.com.  e-mail: acr@theory.lcs.  
Title: Efficient Probabilistically Checkable Proofs and Applications to Approximation  
Author: M. Bellare S. Goldwasser C. Lund A. Russell 
Keyword: High Performance Computing and Communications, IBM  
Note: lcs.mit.edu. Partially supported by NSF FAW grant No. 9023312-CCR, DARPA grant No. N00014-92-J-1799, and grant No. 89-00312 from the United States Israel Binational Science Foundation (BSF), Jerusalem, Israel.  mit.edu. Supported by a NSF Graduate Fellowship and by NSF grant 92-12184, AFOSR 89-0271, and DARPA N00014-92-J-1799.  
Address: PO Box 704, Yorktown Heights, NY 10598, USA.  Square, Cambridge, MA 02139, USA.  Room 2C324, 600 Mountain Avenue, P. O. Box 636, Murray Hill, NJ 07974-0636, USA.  Square, Cambridge, MA 02139, USA.  
Affiliation: T.J. Watson Research Center,  MIT Laboratory for Computer Science, 545 Technology  AT&T Bell Laboratories,  MIT Laboratory for Computer Science, 545 Technology  
Abstract: We construct multi-prover proof systems for NP which use only a constant number of provers to simultaneously achieve low error, low randomness and low answer size. As a consequence, we obtain asymptotic improvements to approximation hardness results for a wide range of optimization problems including minimum set cover, dominating set, maximum clique, chromatic number, and quartic programming; and constant factor improvements on the hardness results for MAXSNP problems and quadratic programming. In particular, we show that approximating minimum set cover within any constant is NP-complete; approximating minimum set cover within c log n, for c &lt; 1=8, implies NP DTIME(n log log n ); approximating the maximum of a quartic program within any constant is NP-hard; approximating maximum clique or chromatic number within n 1=29 implies NP BPP; approximating MAX-3SAT within 113=112 is NP-complete; and 1=143-approximating the max of a quadratic program is NP-hard. 
Abstract-found: 1
Intro-found: 1
Reference: [AS] <author> S. Arora and S. Safra. </author> <title> Approximating clique is NP-complete. </title> <type> FOCS 92. </type>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> important problems P , with values of Q and T which differ from problem to problem; for example, it was shown by [LY1] that approximating the size of the minimum set cover to within fi (log N ) implies NP DTIME (n polylog n ), and it was shown by <ref> [FGLSS, AS, ALMSS] </ref> that for some constant c &gt; 0 approximating the size of a maximum clique in a graph within factor n c implies that P = NP. <p> We focus on two of them. The first is the (single round version of the) multi-prover model of Ben-Or, Gold-wasser, Kilian and Wigderson [BGKW]. The second is the "oracle" model of Fortnow, Rompel and Sipser [FRS], renamed "probabilistically checkable proofs" by Arora and Safra <ref> [AS] </ref>. In each case, we may distinguish five parameters which we denote by r; p; a; q and * (all are in general functions of the input length n). <p> We let MIP 1 = MIP 1 [poly (n); poly (n); poly (n); poly (n); 1=2]. It is known that MIP 1 = NEXP [BFL]. Probabilistically checkable proofs, as defined in <ref> [AS, ALMSS] </ref> are the same as what [FRS] had earlier called the oracle model. In this model, a verifier V has ac 4 cess to an input x 2 f0; 1g n and an oracle which is regarded as a function from f0; 1g q to f0; 1g a . <p> We also let PCP [r; p] = PCP [r; p; 1; O (r); 1=2] as defined in <ref> [AS] </ref>. It is known that PCP = MIP 1 [FRS]. Furthermore, it is easy to see that MIP 1 [r; p; a; q; *] PCP [r; p; a; q; *]. But whether or not the converse containment is true remains an open question. <p> So the total error is at most 2* = 2 k . We omit the details. 3.2 Reducing Answer Sizes Answer sizes will be reduced by recursion (cf. <ref> [AS] </ref>). First need to define carefully how we look at MIP 1 verifiers. Let V be a MIP 1 [r; p; a; q; 2 k (n) ] verifier for some language L. <p> The proof will use Theorem 1.1 and ideas in <ref> [AS, ALMSS] </ref>. The main improvement over the construction of [ALMSS] is our improved recursion step (Lemma 3.2 and Lemmas 3.5 and 3.10) which allows us to combine proof systems with almost no increase in the error probability.
Reference: [ALMSS] <author> S. Arora, C. Lund, R. Motwani, M. Su-dan and M. Szegedy. </author> <title> Proof verification and intractability of approximation problems. </title> <type> FOCS 92. </type>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> important problems P , with values of Q and T which differ from problem to problem; for example, it was shown by [LY1] that approximating the size of the minimum set cover to within fi (log N ) implies NP DTIME (n polylog n ), and it was shown by <ref> [FGLSS, AS, ALMSS] </ref> that for some constant c &gt; 0 approximating the size of a maximum clique in a graph within factor n c implies that P = NP. <p> We omit the question size q from the table because it is in all cases O (r) and doesn't matter in reductions anyway. The main result of <ref> [ALMSS] </ref>, which states that there is a constant t such that NP = PCP [O (log n); t; 1; O (log n); 1=2], is incorporated as the special case k (n) = 1 of the result shown in (2). <p> The constant in the fi (1) error in the result shown in (1) is a value very close to 1; specifically, it equals 1 1=(2t) where t is the constant in the <ref> [ALMSS] </ref> result. Comparing these results with ours, we note the following features, all of which are important to our applications. First, by setting k (n) to an appropriate constant, complexity is ignored the models are of course the same [FRS, BFL]. <p> On the other hand, the number of provers we use is four rather than the two achieved in the results (1) and (3), but this will suffice for our applications to approximation. The (constant) number of bits t that one needs to check in the <ref> [ALMSS] </ref> result NP PCP [O (log n); t; 1; O (log n); 1=2] is of the order of 10 4 . Some reductions in this value were obtained by [PS]. <p> Some reductions in this value were obtained by [PS]. Our improved complexity of four prover proofs for NP in terms of randomness and answer size for a given error, together with a careful analysis of the <ref> [ALMSS] </ref> construction and proofs enable us to obtain substantially smaller values than previously known. Specifically, focusing on the expected value, we show the following. Theorem 1.2 NP = PCP 0 [O (log n); 29; 1; O (logn); 1=2]. <p> Then NP DTIME (n log log n ). Similar improvements follow for all of the following problems: dominating set, hitting set, hypergraph transversal, minimum exact cover (cf. [KT, LY1]). Max Clique, Chromatic number. Known results for Max-Clique are based on the result of <ref> [ALMSS] </ref> which states that there are constants t; d such that NP = PCP [d log n; t; 1; O (log n); 1=2]. <p> The factors in both cases can be increased to n 1=24 if the conclusion is weakened to NEXP BPEXP. Max-3SAT. Using the same characterization of NP as for Max-Clique, it was also shown by <ref> [ALMSS] </ref> that there exists a constant c &gt; 1 such that approximating the maximum number of simultaneously satisfiable clauses in a 3SAT instance to within factor c is NP-complete. We can prove the same with a higher value of c than previously achieved. <p> We let MIP 1 = MIP 1 [poly (n); poly (n); poly (n); poly (n); 1=2]. It is known that MIP 1 = NEXP [BFL]. Probabilistically checkable proofs, as defined in <ref> [AS, ALMSS] </ref> are the same as what [FRS] had earlier called the oracle model. In this model, a verifier V has ac 4 cess to an input x 2 f0; 1g n and an oracle which is regarded as a function from f0; 1g q to f0; 1g a . <p> It is obtained by applying standard transformations (cf. [BGKW, FRS]) to the NP PCP [O (log n); O (1); 1; O (log n); 1=2] result of <ref> [ALMSS] </ref>. Lemma 2.1 Suppose k (n) O (log n). Then NP MIP 1 [O (k (n) log n); O (k (n)); O (1); O (log n); 2 k (n) ]. <p> The proof will use Theorem 1.1 and ideas in <ref> [AS, ALMSS] </ref>. The main improvement over the construction of [ALMSS] is our improved recursion step (Lemma 3.2 and Lemmas 3.5 and 3.10) which allows us to combine proof systems with almost no increase in the error probability. <p> The proof will use Theorem 1.1 and ideas in [AS, ALMSS]. The main improvement over the construction of <ref> [ALMSS] </ref> is our improved recursion step (Lemma 3.2 and Lemmas 3.5 and 3.10) which allows us to combine proof systems with almost no increase in the error probability. <p> Furthermore we have an improved analysis of the linearity test in [BLR] and of the matrix multiplication test for the special case needed in <ref> [ALMSS] </ref>. We will now sketch our construction. Some knowledge of the proof in [ALMSS] is assumed of the reader. First we need some different encoding schemes. Let X be an n-bit string. <p> Furthermore we have an improved analysis of the linearity test in [BLR] and of the matrix multiplication test for the special case needed in <ref> [ALMSS] </ref>. We will now sketch our construction. Some knowledge of the proof in [ALMSS] is assumed of the reader. First we need some different encoding schemes. Let X be an n-bit string. <p> Let W 0 = (W j W k ) j&lt;k . If the proof is valid then Z R the assignments to z R equals E R (A 1 ; : : : ; B 4 ; W; W 0 ). In <ref> [ALMSS] </ref> it was shown how to probabilistically verify such proofs. Assume that (Y 0 1 ; : : : ; Y 0 such a proof and that l = jA 1 j + jA 2 j + + jW 0 j. <p> : Thus the test is the following: Pick v; u; w 2 R f0; 1g l and s; t 2 R f0; 1g jW j and test that ( su + u )( tv + v ) = ( s@tw + w ): Consistency Test (T R 3 ): In <ref> [ALMSS] </ref> they showed that from D and s 2 f0; 1g jW j it is possible to compute an index v s of E R (A 1 ; : : : ; B 4 ; W; W 0 ) and a bit b s such that for all W if D <p> The first case follows from a Lemma in <ref> [BLR, ALMSS] </ref>. Hence assume that we are in case two. Let S be the set of u 2 f0; 1g l such that u 6= E R (Y ) u . Let q be the probability that u + v 6= u+v and let s = jSj=2 l . <p> Their proofs are omitted in this abstract. Lemma 3.8 If P R 1 and :P R 2 then the probability that T R 2 rejects is at least 3ffi 02 8 (1 2ffi 0 ). Lemma 3.9 <ref> [ALMSS] </ref> If P R 1 ; P R 3 then the probability that T R 3 rejects is at least (1=2)(1 2ffi 0 ).
Reference: [ADP] <author> G. Ausiello, A. D'Atri and M. Protasi. </author> <title> Structure preserving reductions among convex optimization problems. </title> <journal> Journal of Computer and System Sciences 21, </journal> <month> 136-153 </month> <year> (1980). </year>
Reference-contexts: S = fx 2 [0; 1] n : Ax bg). Note that we are maximizing over a subset of R n ; solutions are not restricted to integers. We denote by f fl the maximum of f over the feasible region, and by f fl the minimum. Following <ref> [ADP, Va] </ref> we say that ~ f is a -approximation, where 2 [0; 1], if jf fl ~ f j jf fl f fl j.
Reference: [BFL] <author> L. Babai, L. Fortnow and C. Lund. </author> <title> NonDeterministic Exponential Time has Two-Prover Interactive Protocols. </title> <type> FOCS 90. </type>
Reference-contexts: Comparing these results with ours, we note the following features, all of which are important to our applications. First, by setting k (n) to an appropriate constant, complexity is ignored the models are of course the same <ref> [FRS, BFL] </ref>. For explanations and more information we refer the reader to x2. we can achieve any constant error using only logarith-mic randomness and answer sizes, which improves the result shown in (1), where logarithmic randomness and answer size are only achievable for a particular constant error. <p> MIP 1 [r; p; a; q; *] denotes the class of languages possessing MIP 1 [r; p; a; q; *] verifiers. We let MIP 1 = MIP 1 [poly (n); poly (n); poly (n); poly (n); 1=2]. It is known that MIP 1 = NEXP <ref> [BFL] </ref>. Probabilistically checkable proofs, as defined in [AS, ALMSS] are the same as what [FRS] had earlier called the oracle model.
Reference: [BFLS] <author> L. Babai, L. Fortnow, L. Levin, and M. Szegedy. </author> <title> Checking Computations in Polyloga-rithmic Time. </title> <note> STOC 91. </note>
Reference-contexts: Let us now proceed to our first step. 3.1 Reducing Randomness As discussed above, the transformation of [FL, LS] reduces the error without increasing the number of provers, but costs in randomness. We combine this transformation with the idea of <ref> [BFLS] </ref> of using as "base field" not f0; 1g but some larger subset H of the underlying finite field F . <p> = 1 there exists an 1 i p such that (X 0 i ; E P (X i )) 1 2 k 0 (n) , then Pr R 0 [C 0 R 0 (X 0 p ; Z 1 ; Z 2 ) = Proof: The proof combines ideas in <ref> [BFLS, BLR, FRS, LS, FL] </ref>. Step 1: First we obtain a circuit family fC 00 1 ]; [x 0 p ]; z)g; where the circuit size and number of additional random bits are poly (log jCj; k 0 (n)). <p> We use the con struction of <ref> [BFLS] </ref> to construct these proofs. From [BFLS] it follows that we verify with probability 1/2 that W 0 has the correct properties by using poly (log jCj) random bits, reading poly (log jCj) bits and performing a computation that corresponds to circuits of size poly (log jCj). <p> We use the con struction of <ref> [BFLS] </ref> to construct these proofs. From [BFLS] it follows that we verify with probability 1/2 that W 0 has the correct properties by using poly (log jCj) random bits, reading poly (log jCj) bits and performing a computation that corresponds to circuits of size poly (log jCj).
Reference: [Be] <author> M. Bellare. </author> <title> Interactive Proofs and Approximation. </title> <note> IBM Research Report RC 17969 (May 1992). </note>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> However, the reduction, like those of <ref> [BR, FL, Be] </ref>, additionally requires that the number of provers be p = 2, although (in this case) it can be extended easily to any constant.
Reference: [BGG] <author> M. Bellare, O. Goldreich and S. Gold-wasser. </author> <title> Randomness in Interactive Proofs. </title> <type> FOCS 90. </type>
Reference-contexts: Using the reduction of [FGLSS], it follows that there exists a constant c &gt; 0 such that approximating the size of the maximum clique in a graph to within n c is NP-complete; this result uses randomness efficient error reduction techniques such as <ref> [CW, IZ, BGG] </ref>, and c depends on t; d as well as other constants arising from the error-reduction. Zuck-erman [Zu] uses a random construction which achieves c = 1=t at the cost of weakening the conclusion to NP BPP.
Reference: [BR] <author> M. Bellare and P. Rogaway. </author> <title> The Complexity of Approximating a Nonlinear program. IBM Research Report RC 17831 (March 1992). </title>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> However, the reduction, like those of <ref> [BR, FL, Be] </ref>, additionally requires that the number of provers be p = 2, although (in this case) it can be extended easily to any constant. <p> Quadratic and Quartic Programming. Quadratic programming is the problem of maximizing a polynomial of (total) degree two over a (compact) subset of R n specified by linear constraints. NP MIP 1 [O (log n); 2; O (log n); O (log n); fi (1)], it was shown by <ref> [BR, FL] </ref> that there exists a constant c 2 (0; 1) such that the following is true: the existence of a polynomial time algorithm for c-approximating 3 the maximum of a quadratic program implies P = NP. <p> Quadratic programming has applications in economics, planning and genetics. Given NP MIP 1 [O (log n); 2; O (log n); O (log n); *], it is shown by <ref> [BR, FL] </ref> that the existence of a polynomial time, -approximation for quadratic programming implies P = NP, where = (1 *)=(1 +*). Theorem 1.7 follows from Corollary 3.11. The reduction of two prover proofs to quadratic programming in [BR, FL] is easily extended to a reduction of four prover proofs to <p> 2; O (log n); O (log n); *], it is shown by <ref> [BR, FL] </ref> that the existence of a polynomial time, -approximation for quadratic programming implies P = NP, where = (1 *)=(1 +*). Theorem 1.7 follows from Corollary 3.11. The reduction of two prover proofs to quadratic programming in [BR, FL] is easily extended to a reduction of four prover proofs to quartic programming. Theorem 1.1 guarantees for us four prover proof sys tems for NP with logarithmic randomness and answer sizes, and error an arbitrary constant. Put together these facts enable us to prove Theorem 1.8.
Reference: [BGKW] <author> M. Ben-Or, S. Goldwasser, J. Kilian and A. Wigderson. </author> <title> Multi-Prover Interactive Proofs: How to Remove Intractability Assumptions. </title> <note> STOC 88. </note>
Reference-contexts: We focus on two of them. The first is the (single round version of the) multi-prover model of Ben-Or, Gold-wasser, Kilian and Wigderson <ref> [BGKW] </ref>. The second is the "oracle" model of Fortnow, Rompel and Sipser [FRS], renamed "probabilistically checkable proofs" by Arora and Safra [AS]. In each case, we may distinguish five parameters which we denote by r; p; a; q and * (all are in general functions of the input length n). <p> It is obtained by applying standard transformations (cf. <ref> [BGKW, FRS] </ref>) to the NP PCP [O (log n); O (1); 1; O (log n); 1=2] result of [ALMSS]. Lemma 2.1 Suppose k (n) O (log n). Then NP MIP 1 [O (k (n) log n); O (k (n)); O (1); O (log n); 2 k (n) ].
Reference: [BLR] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-testing and self-correcting programs, with applications to numerical programs. </title> <note> STOC 90. </note>
Reference-contexts: = 1 there exists an 1 i p such that (X 0 i ; E P (X i )) 1 2 k 0 (n) , then Pr R 0 [C 0 R 0 (X 0 p ; Z 1 ; Z 2 ) = Proof: The proof combines ideas in <ref> [BFLS, BLR, FRS, LS, FL] </ref>. Step 1: First we obtain a circuit family fC 00 1 ]; [x 0 p ]; z)g; where the circuit size and number of additional random bits are poly (log jCj; k 0 (n)). <p> Lastly, assuming that there exists some W such that (W 0 ; E P (W )) &lt; 1=3, we use the idea of self-correction <ref> [BLR, GS] </ref>, which allows us to probabilistically access the segments of X 00 i . <p> The main improvement over the construction of [ALMSS] is our improved recursion step (Lemma 3.2 and Lemmas 3.5 and 3.10) which allows us to combine proof systems with almost no increase in the error probability. Furthermore we have an improved analysis of the linearity test in <ref> [BLR] </ref> and of the matrix multiplication test for the special case needed in [ALMSS]. We will now sketch our construction. Some knowledge of the proof in [ALMSS] is assumed of the reader. First we need some different encoding schemes. Let X be an n-bit string. <p> Since the values of W and W 0 is not directly accessible in the technique of self-correction is used <ref> [BLR] </ref>. This technique give us a probabilistic method to access the bits encoded in . <p> The first case follows from a Lemma in <ref> [BLR, ALMSS] </ref>. Hence assume that we are in case two. Let S be the set of u 2 f0; 1g l such that u 6= E R (Y ) u . Let q be the probability that u + v 6= u+v and let s = jSj=2 l .
Reference: [CW] <author> A. Cohen and A. Wigderson. Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources. </title> <type> FOCS 89. </type>
Reference-contexts: parameters we need to consider. 1 r = r (n) p = p (n) a = a (n) * = *(n) How (in a word) (1) O (log n) 2 O (1) fi (1) [ALMSS]+[FRS] (2) O (log n) O (k (n)) O (1) 2 k (n) O (k (n)) <ref> [CW, IZ] </ref>-style repetitions of (1). (3) O (k (n) log 2 n) 2 O (k (n) log 2 n) 2 k (n) [FL] (4) O (k (n) log n) + poly (k (n); log log n) 4 poly (k (n); log log n) 2 k (n) This paper. of the form <p> Using the reduction of [FGLSS], it follows that there exists a constant c &gt; 0 such that approximating the size of the maximum clique in a graph to within n c is NP-complete; this result uses randomness efficient error reduction techniques such as <ref> [CW, IZ, BGG] </ref>, and c depends on t; d as well as other constants arising from the error-reduction. Zuck-erman [Zu] uses a random construction which achieves c = 1=t at the cost of weakening the conclusion to NP BPP. <p> Lemma 2.1 Suppose k (n) O (log n). Then NP MIP 1 [O (k (n) log n); O (k (n)); O (1); O (log n); 2 k (n) ]. Note we could further reduce the randomness to O (log n) by using the techniques of <ref> [CW, IZ] </ref>; this is the result we stated in Figure 1 (2). But the advantage will be lost in the transformations we will apply later, so we don't bother. 3 Efficient Proof Systems We prove our main theorem in two steps.
Reference: [Co] <author> A. Condon. </author> <title> The complexity of the max word problem, or the power of one-way interactive proof systems. </title> <note> STACS 91. </note>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>.
Reference: [FRS] <author> L. Fortnow, J. Rompel and M. Sipser. </author> <title> On the power of multiprover interactive protocols. </title> <booktitle> Proceedings of the 3rd Structures, IEEE (1988). </booktitle>
Reference-contexts: We focus on two of them. The first is the (single round version of the) multi-prover model of Ben-Or, Gold-wasser, Kilian and Wigderson [BGKW]. The second is the "oracle" model of Fortnow, Rompel and Sipser <ref> [FRS] </ref>, renamed "probabilistically checkable proofs" by Arora and Safra [AS]. In each case, we may distinguish five parameters which we denote by r; p; a; q and * (all are in general functions of the input length n). <p> Comparing these results with ours, we note the following features, all of which are important to our applications. First, by setting k (n) to an appropriate constant, complexity is ignored the models are of course the same <ref> [FRS, BFL] </ref>. For explanations and more information we refer the reader to x2. we can achieve any constant error using only logarith-mic randomness and answer sizes, which improves the result shown in (1), where logarithmic randomness and answer size are only achievable for a particular constant error. <p> We let MIP 1 = MIP 1 [poly (n); poly (n); poly (n); poly (n); 1=2]. It is known that MIP 1 = NEXP [BFL]. Probabilistically checkable proofs, as defined in [AS, ALMSS] are the same as what <ref> [FRS] </ref> had earlier called the oracle model. In this model, a verifier V has ac 4 cess to an input x 2 f0; 1g n and an oracle which is regarded as a function from f0; 1g q to f0; 1g a . <p> We also let PCP [r; p] = PCP [r; p; 1; O (r); 1=2] as defined in [AS]. It is known that PCP = MIP 1 <ref> [FRS] </ref>. Furthermore, it is easy to see that MIP 1 [r; p; a; q; *] PCP [r; p; a; q; *]. But whether or not the converse containment is true remains an open question. In particular, known simulations of probabilistically checkable proofs by multi-prover ones (such as those used by [FRS] <p> <ref> [FRS] </ref>. Furthermore, it is easy to see that MIP 1 [r; p; a; q; *] PCP [r; p; a; q; *]. But whether or not the converse containment is true remains an open question. In particular, known simulations of probabilistically checkable proofs by multi-prover ones (such as those used by [FRS] to show PCP = MIP 1 ) don't preserve complexity. 4 Let us now state the (well known) lemma which will be our starting point. <p> It is obtained by applying standard transformations (cf. <ref> [BGKW, FRS] </ref>) to the NP PCP [O (log n); O (1); 1; O (log n); 1=2] result of [ALMSS]. Lemma 2.1 Suppose k (n) O (log n). Then NP MIP 1 [O (k (n) log n); O (k (n)); O (1); O (log n); 2 k (n) ]. <p> Figure 1 (3)). We tackle this problem by concentrating first on keeping the randomness down. In a first step we show how to reduce the number of provers to two while not increasing the 4 The basic result of <ref> [FRS] </ref> is PCP [r; p; a; q; *] MIP 1 [r + lg p; 2; a; q; 1 (1 *)=p]. randomness, but at the cost of an exponential blowup in answer sizes. <p> = 1 there exists an 1 i p such that (X 0 i ; E P (X i )) 1 2 k 0 (n) , then Pr R 0 [C 0 R 0 (X 0 p ; Z 1 ; Z 2 ) = Proof: The proof combines ideas in <ref> [BFLS, BLR, FRS, LS, FL] </ref>. Step 1: First we obtain a circuit family fC 00 1 ]; [x 0 p ]; z)g; where the circuit size and number of additional random bits are poly (log jCj; k 0 (n)). <p> Step 2: Next we transform the C 00 circuits into circuits fC 000 R 00 ;R 000 ([x 0 p ]; [z (1) ]; : : : ; [z (p 0 ) ])g (i.e., a one-round p + p 0 -prover proof system) as follows using the standard method in <ref> [FRS] </ref>. (For every j = 1; 2; : : : ; p 0 , Z (j) should equal Z.) Assume that C 00 R 00 depends on the variables z i 1 ; : : : ; z i q . Note that q jC 00 R 00 j. <p> Proof: The maximum number of bits checked in the above proof is t = 36, so that NP PCP [O (log n); t; 1; O (log n); 1=2]. By the transformation of <ref> [FRS] </ref> we get NP MIP 1 [O (log n); 2; O (1); O (log n); 1 1=(2t)]. 4 Applications Fix a combinatorial optimization problem and let g (x) be the optimal value at input x.
Reference: [FGLSS] <author> U. Feige, S. Goldwasser, L. Lov asz, S. Safra, and M. Szegedy. </author> <title> Approximating clique is almost NP-complete. </title> <type> FOCS 91. </type>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> important problems P , with values of Q and T which differ from problem to problem; for example, it was shown by [LY1] that approximating the size of the minimum set cover to within fi (log N ) implies NP DTIME (n polylog n ), and it was shown by <ref> [FGLSS, AS, ALMSS] </ref> that for some constant c &gt; 0 approximating the size of a maximum clique in a graph within factor n c implies that P = NP. <p> Max Clique, Chromatic number. Known results for Max-Clique are based on the result of [ALMSS] which states that there are constants t; d such that NP = PCP [d log n; t; 1; O (log n); 1=2]. Using the reduction of <ref> [FGLSS] </ref>, it follows that there exists a constant c &gt; 0 such that approximating the size of the maximum clique in a graph to within n c is NP-complete; this result uses randomness efficient error reduction techniques such as [CW, IZ, BGG], and c depends on t; d as well as
Reference: [FL] <author> U. Feige and L. Lov asz. </author> <title> Two-Prover One Round Proof Systems: Their Power and their Problems. </title> <note> STOC 92. </note>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> (in a word) (1) O (log n) 2 O (1) fi (1) [ALMSS]+[FRS] (2) O (log n) O (k (n)) O (1) 2 k (n) O (k (n)) [CW, IZ]-style repetitions of (1). (3) O (k (n) log 2 n) 2 O (k (n) log 2 n) 2 k (n) <ref> [FL] </ref> (4) O (k (n) log n) + poly (k (n); log log n) 4 poly (k (n); log log n) 2 k (n) This paper. of the form NP MIP 1 [r; p; a; q; *]. <p> Second, the number of provers we use is a constant independent of the error, which is not true of the result shown in (2). Finally, for small k (n) and given error 2 k (n) our randomness and answer sizes are smaller than those of the result of <ref> [FL] </ref> shown in (3); in particular, for k (n) = log o (1) n we have O (k (n) log n) randomness and answer sizes, and for k (n) = O (log log n) we have polyloglog (n) answer sizes. <p> However, the reduction, like those of <ref> [BR, FL, Be] </ref>, additionally requires that the number of provers be p = 2, although (in this case) it can be extended easily to any constant. <p> Quadratic and Quartic Programming. Quadratic programming is the problem of maximizing a polynomial of (total) degree two over a (compact) subset of R n specified by linear constraints. NP MIP 1 [O (log n); 2; O (log n); O (log n); fi (1)], it was shown by <ref> [BR, FL] </ref> that there exists a constant c 2 (0; 1) such that the following is true: the existence of a polynomial time algorithm for c-approximating 3 the maximum of a quadratic program implies P = NP. <p> The starting point is the proof system of Lemma 2.1. This proof system has O (k (n)) provers, and we need to reduce this to a constant. Applying the transformation of <ref> [LS, FL] </ref> will not suffice, because in reducing the number of provers this transformation increases the amount of randomness as well as the answer sizes (cf. Figure 1 (3)). We tackle this problem by concentrating first on keeping the randomness down. <p> However, in a second step we apply recursion to reduce the answer sizes while keeping the other quantities under control. Let us now proceed to our first step. 3.1 Reducing Randomness As discussed above, the transformation of <ref> [FL, LS] </ref> reduces the error without increasing the number of provers, but costs in randomness. We combine this transformation with the idea of [BFLS] of using as "base field" not f0; 1g but some larger subset H of the underlying finite field F . <p> = 1 there exists an 1 i p such that (X 0 i ; E P (X i )) 1 2 k 0 (n) , then Pr R 0 [C 0 R 0 (X 0 p ; Z 1 ; Z 2 ) = Proof: The proof combines ideas in <ref> [BFLS, BLR, FRS, LS, FL] </ref>. Step 1: First we obtain a circuit family fC 00 1 ]; [x 0 p ]; z)g; where the circuit size and number of additional random bits are poly (log jCj; k 0 (n)). <p> Step 3: Lastly we transform the C 000 circuits into the C 0 circuits using the same construction as in Theorem 3.1. I.e., we use the transformation from p 0 provers into 2 provers in <ref> [LS, FL] </ref> on the inputs z (j) to get segmented circuits with p + 2 inputs. This will use an additional O (p 0 log (jzj)k 0 (n)) random bits. <p> Quadratic programming has applications in economics, planning and genetics. Given NP MIP 1 [O (log n); 2; O (log n); O (log n); *], it is shown by <ref> [BR, FL] </ref> that the existence of a polynomial time, -approximation for quadratic programming implies P = NP, where = (1 *)=(1 +*). Theorem 1.7 follows from Corollary 3.11. The reduction of two prover proofs to quadratic programming in [BR, FL] is easily extended to a reduction of four prover proofs to <p> 2; O (log n); O (log n); *], it is shown by <ref> [BR, FL] </ref> that the existence of a polynomial time, -approximation for quadratic programming implies P = NP, where = (1 *)=(1 +*). Theorem 1.7 follows from Corollary 3.11. The reduction of two prover proofs to quadratic programming in [BR, FL] is easily extended to a reduction of four prover proofs to quartic programming. Theorem 1.1 guarantees for us four prover proof sys tems for NP with logarithmic randomness and answer sizes, and error an arbitrary constant. Put together these facts enable us to prove Theorem 1.8.
Reference: [GS] <author> P. Gemmell and M. Sudan. </author> <title> Highly Resilient Correctors For Polynomials. </title> <journal> IPL, </journal> <year> 1992. </year>
Reference-contexts: Lastly, assuming that there exists some W such that (W 0 ; E P (W )) &lt; 1=3, we use the idea of self-correction <ref> [BLR, GS] </ref>, which allows us to probabilistically access the segments of X 00 i .
Reference: [IZ] <author> R. Impagliazzo and D. Zuckerman. </author> <title> How to Recycle Random Bits. </title> <type> FOCS 89. </type>
Reference-contexts: parameters we need to consider. 1 r = r (n) p = p (n) a = a (n) * = *(n) How (in a word) (1) O (log n) 2 O (1) fi (1) [ALMSS]+[FRS] (2) O (log n) O (k (n)) O (1) 2 k (n) O (k (n)) <ref> [CW, IZ] </ref>-style repetitions of (1). (3) O (k (n) log 2 n) 2 O (k (n) log 2 n) 2 k (n) [FL] (4) O (k (n) log n) + poly (k (n); log log n) 4 poly (k (n); log log n) 2 k (n) This paper. of the form <p> Using the reduction of [FGLSS], it follows that there exists a constant c &gt; 0 such that approximating the size of the maximum clique in a graph to within n c is NP-complete; this result uses randomness efficient error reduction techniques such as <ref> [CW, IZ, BGG] </ref>, and c depends on t; d as well as other constants arising from the error-reduction. Zuck-erman [Zu] uses a random construction which achieves c = 1=t at the cost of weakening the conclusion to NP BPP. <p> Lemma 2.1 Suppose k (n) O (log n). Then NP MIP 1 [O (k (n) log n); O (k (n)); O (1); O (log n); 2 k (n) ]. Note we could further reduce the randomness to O (log n) by using the techniques of <ref> [CW, IZ] </ref>; this is the result we stated in Figure 1 (2). But the advantage will be lost in the transformations we will apply later, so we don't bother. 3 Efficient Proof Systems We prove our main theorem in two steps.
Reference: [Jo] <author> D. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> J. of Computer and System Sciences 9, </journal> <month> 256-278 </month> <year> (1974). </year> <month> 11 </month>
Reference-contexts: For a definition of the problem we refer the reader to x4.1. Recall that there exists a polynomial time algorithm for approximating the size of the minimum set cover to within a factor of fi (log N ), where N is the number of elements in the base set <ref> [Jo, Lo] </ref>. Hardness of approximation was recently shown by Lund and Yannakakis [LY1].
Reference: [KT] <author> P. Kolaitis and M. Thakur. </author> <title> Approximation properties of NP minimization classes. Structure in Complexity Theory, </title> <year> 1991. </year>
Reference-contexts: Suppose there is a polynomial time algorithm which approximates the size of the minimum set cover to within c log N . Then NP DTIME (n log log n ). Similar improvements follow for all of the following problems: dominating set, hitting set, hypergraph transversal, minimum exact cover (cf. <ref> [KT, LY1] </ref>). Max Clique, Chromatic number. Known results for Max-Clique are based on the result of [ALMSS] which states that there are constants t; d such that NP = PCP [d log n; t; 1; O (log n); 1=2].
Reference: [LS] <author> D. Lapidot and A. Shamir. </author> <title> Fully Parallelized Multi-Prover Protocols for NEXP-time. </title> <type> FOCS 91. </type>
Reference-contexts: The starting point is the proof system of Lemma 2.1. This proof system has O (k (n)) provers, and we need to reduce this to a constant. Applying the transformation of <ref> [LS, FL] </ref> will not suffice, because in reducing the number of provers this transformation increases the amount of randomness as well as the answer sizes (cf. Figure 1 (3)). We tackle this problem by concentrating first on keeping the randomness down. <p> However, in a second step we apply recursion to reduce the answer sizes while keeping the other quantities under control. Let us now proceed to our first step. 3.1 Reducing Randomness As discussed above, the transformation of <ref> [FL, LS] </ref> reduces the error without increasing the number of provers, but costs in randomness. We combine this transformation with the idea of [BFLS] of using as "base field" not f0; 1g but some larger subset H of the underlying finite field F . <p> Regard each Q i as divided into s pieces, each of size h (that is, Q i = Q 1 i : : : Q s i with each Q j that Q i is an element of H s F s . We now apply the technique of <ref> [LS] </ref>. V 0 chooses, randomly and uniformly, y 1 ; : : : ; y p from F s . For each i we let l i : F ! F s be (a canonical representation of) the unique line through Q i and y i . <p> Since h (n) log log n and q = O (log n) this is O (k (n) log n 2 h (n) ) as desired. To prove the soundness, we need to trace through the proof of <ref> [LS] </ref>, making the appropriate modifications. The error stemming from the construction of [LS] (i.e. the probability that the provers' replies are not "functional") can be bounded by p sd which is at most 2 h1 2 k1 = * for large enough n. <p> Since h (n) log log n and q = O (log n) this is O (k (n) log n 2 h (n) ) as desired. To prove the soundness, we need to trace through the proof of <ref> [LS] </ref>, making the appropriate modifications. The error stemming from the construction of [LS] (i.e. the probability that the provers' replies are not "functional") can be bounded by p sd which is at most 2 h1 2 k1 = * for large enough n. So the total error is at most 2* = 2 k . <p> = 1 there exists an 1 i p such that (X 0 i ; E P (X i )) 1 2 k 0 (n) , then Pr R 0 [C 0 R 0 (X 0 p ; Z 1 ; Z 2 ) = Proof: The proof combines ideas in <ref> [BFLS, BLR, FRS, LS, FL] </ref>. Step 1: First we obtain a circuit family fC 00 1 ]; [x 0 p ]; z)g; where the circuit size and number of additional random bits are poly (log jCj; k 0 (n)). <p> Step 3: Lastly we transform the C 000 circuits into the C 0 circuits using the same construction as in Theorem 3.1. I.e., we use the transformation from p 0 provers into 2 provers in <ref> [LS, FL] </ref> on the inputs z (j) to get segmented circuits with p + 2 inputs. This will use an additional O (p 0 log (jzj)k 0 (n)) random bits. <p> Put together these facts enable us to prove Theorem 1.8. We omit the details. Acknowledgments We are grateful to Dror Lapidot, for explaining to us the construction and proof of <ref> [LS] </ref>: these were crucial to the proof of Theorem 3.1. We thank Rajeev Motwani, Nick Reingold, Muli Safra, Madhu Sudan, Mario Szegedy, Steve Vavasis and Mihalis Yannakakis for their helpful insights.
Reference: [Lo] <author> L. Lov asz. </author> <title> On the ratio of optimal integral and fractional covers. </title> <booktitle> Discrete Mathematics 13, </booktitle> <month> 383-390 </month> <year> (1975). </year>
Reference-contexts: For a definition of the problem we refer the reader to x4.1. Recall that there exists a polynomial time algorithm for approximating the size of the minimum set cover to within a factor of fi (log N ), where N is the number of elements in the base set <ref> [Jo, Lo] </ref>. Hardness of approximation was recently shown by Lund and Yannakakis [LY1].
Reference: [LY1] <author> C. Lund and M. Yannakakis. </author> <title> On the Hardness of Approximating Minimization Problems. </title> <note> STOC 93. </note>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> Today such results are known for many important problems P , with values of Q and T which differ from problem to problem; for example, it was shown by <ref> [LY1] </ref> that approximating the size of the minimum set cover to within fi (log N ) implies NP DTIME (n polylog n ), and it was shown by [FGLSS, AS, ALMSS] that for some constant c &gt; 0 approximating the size of a maximum clique in a graph within factor n <p> Recall that there exists a polynomial time algorithm for approximating the size of the minimum set cover to within a factor of fi (log N ), where N is the number of elements in the base set [Jo, Lo]. Hardness of approximation was recently shown by Lund and Yannakakis <ref> [LY1] </ref>. <p> Suppose there is a polynomial time algorithm which approximates the size of the minimum set cover to within c log N . Then NP DTIME (n log log n ). Similar improvements follow for all of the following problems: dominating set, hitting set, hypergraph transversal, minimum exact cover (cf. <ref> [KT, LY1] </ref>). Max Clique, Chromatic number. Known results for Max-Clique are based on the result of [ALMSS] which states that there are constants t; d such that NP = PCP [d log n; t; 1; O (log n); 1=2]. <p> Then NP BPP. All this is also true for the problem of approximating the chromatic number of a graph <ref> [LY1] </ref>, so that the same statement holds for this problem as well. The factors in both cases can be increased to n 1=24 if the conclusion is weakened to NEXP BPEXP. Max-3SAT. <p> In this lemma, l is a parameter to be chosen at will, and Q i refers to the question spaces of the uniformity condition. The statement and proof of this lemma that appear in <ref> [LY1] </ref> are only for the case p = 2, but the authors say later that it extends to any constant, and this extension is indeed easy. 5 For completeness we provide the construction for this extension. <p> Let m def P p be a "set system" as per <ref> [LY1, Lemma 3.3] </ref>. The base set S of the set cover instance S ' associated to ' is defined by S = f0; 1g r fi B. The sets in S ' are the following. <p> we have the set S (i; Q; A) defined as f hR; bi 2 S : Q = Q V (R; i) and b 2 B A g : The proof that this construction works is a simple ex tension of the proof for the case p = 2 in <ref> [LY1] </ref>. We claim (proof omitted) that the verifier of Theorem 1.1 satisfies functionality and uniformity. Equality of question space sizes can then be achieved by a simple transformation as shown in [LY1], and dis-jointness of answer spaces by a simple padding; the cost is only a constant factor in randomness, question <p> that this construction works is a simple ex tension of the proof for the case p = 2 in <ref> [LY1] </ref>. We claim (proof omitted) that the verifier of Theorem 1.1 satisfies functionality and uniformity. Equality of question space sizes can then be achieved by a simple transformation as shown in [LY1], and dis-jointness of answer spaces by a simple padding; the cost is only a constant factor in randomness, question sizes, and answer sizes. Thus we have canonical MIP 1 [r; 4; a; q; 2 k (n) ] verifiers for SAT with r; q; a being as in Theorem 1.1.
Reference: [LY2] <author> C. Lund and M. Yannakakis. </author> <title> The Approximation of Maximum Subgraph Problems. </title> <booktitle> ICALP 93. </booktitle>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>.
Reference: [MS] <author> F. MacWilliams and N. Sloane. </author> <title> The Theory of Error-Correcting Codes. </title> <publisher> North-Holland, </publisher> <year> 1981. </year>
Reference-contexts: Lemma 3.5 If Pr R [P R 1 ; P R 3 and P R p then x 2 L. Proof: The following lemma implies that each segment of Y 0 i can only be decoded to a constant number of different segments of Y i . Lemma 3.6 <ref> [MS] </ref> Let A = A (n; d; w) be the maximum number of binary vectors of length n, each with weight (i.e., number of non-zeroes) at most w, and any two of which are distance at least d apart.
Reference: [PY] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Optimization, approximation, and complexity classes. </title> <note> STOC 88. </note>
Reference: [PS] <author> S. Phillips and S. Safra. </author> <title> PCP and tighter bounds for approximating MAXSNP. </title> <type> Manuscript, </type> <year> 1992. </year>
Reference-contexts: The (constant) number of bits t that one needs to check in the [ALMSS] result NP PCP [O (log n); t; 1; O (log n); 1=2] is of the order of 10 4 . Some reductions in this value were obtained by <ref> [PS] </ref>. Our improved complexity of four prover proofs for NP in terms of randomness and answer size for a given error, together with a careful analysis of the [ALMSS] construction and proofs enable us to obtain substantially smaller values than previously known.
Reference: [Va] <author> S. Vavasis. </author> <title> On approximation algorithms for concave programming. Recent Advances in Global Optimization, </title> <editor> C. A. Floudas and P.M. </editor> <booktitle> Pardalos, </booktitle> <pages> pp. 3-18, </pages> <publisher> Princeton University Press, </publisher> <year> 1992. </year>
Reference-contexts: S = fx 2 [0; 1] n : Ax bg). Note that we are maximizing over a subset of R n ; solutions are not restricted to integers. We denote by f fl the maximum of f over the feasible region, and by f fl the minimum. Following <ref> [ADP, Va] </ref> we say that ~ f is a -approximation, where 2 [0; 1], if jf fl ~ f j jf fl f fl j. <p> Following [ADP, Va] we say that ~ f is a -approximation, where 2 [0; 1], if jf fl ~ f j jf fl f fl j. We refer the reader to <ref> [Va] </ref> for discussion of the appropriateness of this definition, and the inappropriateness of the one we have been using above, in the context of continuous optimization problems. Quadratic programming has applications in economics, planning and genetics.
Reference: [Zu] <author> D. Zuckerman. </author> <title> NP-Complete Problems have a version that is hard to Approximate. Structure in Complexity Theory, </title> <booktitle> 1993. </booktitle> <pages> 12 </pages>
Reference-contexts: 1 Introduction The last two years have witnessed major advances in classifying the complexity of approximating classical optimization problems <ref> [Co, FGLSS, AS, ALMSS, BR, FL, Be, Zu, LY1, LY2] </ref>. <p> Zuck-erman <ref> [Zu] </ref> uses a random construction which achieves c = 1=t at the cost of weakening the conclusion to NP BPP.
References-found: 28

