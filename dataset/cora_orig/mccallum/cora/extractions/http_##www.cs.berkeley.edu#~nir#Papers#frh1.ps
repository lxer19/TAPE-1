URL: http://www.cs.berkeley.edu/~nir/Papers/frh1.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.berkeley.edu,  halpern@cs.cornell.edu,  
Title: Modeling Belief in Dynamic Systems. Part I: Foundations  
Author: Nir Friedman Joseph Y. Halpern 
Date: 23 July 1997  
Note: Preprint submitted to Elsevier Science  
Web: http://www.cs.berkeley.edu/ nir  http://www.cs.cornell.edu/home/halpern  
Address: 387 Soda Hall, University of California, Berkeley, CA 94720,  Ithaca, NY 14853,  
Affiliation: Computer Science Division,  Computer Science Department, Cornell University,  
Abstract: Belief change is a fundamental problem in AI: Agents constantly have to update their beliefs to accommodate new observations. In recent years, there has been much work on axiomatic characterizations of belief change. We claim that a better understanding of belief change can be gained from examining appropriate semantic models. In this paper we propose a general framework in which to model belief change. We begin by defining belief in terms of knowledge and plausibility: an agent believes if he knows that is more plausible than :. We then consider some properties defining the interaction between knowledge and plausibility, and show how these properties affect the properties of belief. In particular, we show that by assuming two of the most natural properties, belief becomes a KD45 operator. Finally, we add time to the picture. This gives us a framework in which we can talk about knowledge, plausibility (and hence belief), and time, which extends the framework of Halpern and Fagin for modeling knowledge in multi-agent systems. We then examine the problem of "minimal change". This notion can be captured by using prior plausibilities, an analogue to prior probabilities, which can be updated by "conditioning". We show by example that conditioning on a plausibility measure can capture many scenarios of interest. In a companion paper, we show how the two best-studied scenarios of belief change, belief revision and belief update, fit into our framework. ? Some of this work was done while both authors were at the IBM Almaden Research Center. The first author was also at Stanford while much of the work was done. IBM and Stanford's support are gratefully acknowledged. The work was also supported in part by the Air Force Office of Scientific Research (AFSC), under Contract F49620-91-C-0080 and grant F94620-96-1-0323 and by NSF under grants IRI-95-03109 and IRI-96-25901. A preliminary version of this paper appears in Proceedings of the 5th Conference on Theoretical Aspects of Reasoning About Knowledge, 1994, pp. 44-64, under the title "A knowledge-based framework for belief change, Part I: Foundations". 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. E. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: partial meet functions for contraction and revision. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: the K i 's are equivalence relations. 6 an algebra of measurable subsets of W (that is, a set of subsets closed under union and complementation to which we assign probability), and Pr is a probability measure, that is, a function mapping each set in F to a number in <ref> [0; 1] </ref> satisfying the well-known probability axioms (Pr (;) = 0, Pr (W ) = 1, and Pr (A [ B) = Pr (A) + Pr (B), if A and B are disjoint). A plausibility space is a direct generalization of a probability space. <p> A plausibility space is a direct generalization of a probability space. We simply replace the probability measure Pr by a plausibility measure Pl, which, rather than mapping sets in F to numbers in <ref> [0; 1] </ref>, maps them to elements in some arbitrary partially ordered set. We read Pl (A) as "the plausibility of set A". If Pl (A) Pl (B), then B is at least as plausible as A. <p> Clearly plausibility spaces generalize probability spaces. We now briefly discuss a few other notions of uncertainty that they generalize: A belief function B on W is a function B : 2 W ! <ref> [0; 1] </ref> satisfying certain axioms [55]. These axioms certainly imply property A1, so a belief function is a plausibility measure. A fuzzy measure (or a Sugeno measure) f on W [59] is a function f : 2 W 7! [0; 1], that satisfies A1 and some continuity constraints. <p> B on W is a function B : 2 W ! <ref> [0; 1] </ref> satisfying certain axioms [55]. These axioms certainly imply property A1, so a belief function is a plausibility measure. A fuzzy measure (or a Sugeno measure) f on W [59] is a function f : 2 W 7! [0; 1], that satisfies A1 and some continuity constraints. A possibility measure [12] Poss is a fuzzy measure such that Poss (W ) = 1, Poss (;) = 0, and Poss (A) = sup w2A (Poss (fwg). <p> Thus, we see that Battigalli and Bonanno essentially require systems with minimal change to satisfy conditioning with a prior that is a ranking. As we shall see in the next section, similar requirements are made by the AGM formulation of belief revision <ref> [1] </ref>. 4.2 Properties of Prior Plausibilities If we take the plausibilities in a system to be generated by a prior, then many of the conditions we are interested in, such as QUAL and REF, can be viewed as being as being induced by the analogous property on the prior.
Reference: [2] <author> P. Battigalli and G. Bonanno. </author> <title> The logic of belief persistency. </title> <journal> Economics and philosophy, </journal> <note> 1997. To appear. </note>
Reference-contexts: For example, all of the approaches we mentioned above would not apply when we consider a changing environment, since they cannot reason about how the environment changes between one time point and the next. Finally, we examine the work of Battigalli and Bonanno <ref> [2] </ref>. They consider a logic of knowledge, belief, and time, and attempt to capture properties of "minimal change" of beliefs. Their language is slightly different from ours.
Reference: [3] <author> C. Boutilier. Normative, </author> <title> subjective and autoepistemic defaults: adopting the Ramsey test. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proc. Third International Conference on Principles of Knowledge Representation and Reasoning (KR '92), </booktitle> <pages> pages 685-696. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1992. </year>
Reference-contexts: As we show by example, having knowledge, plausibility, and time represented explicitly gives us a powerful and expressive framework for capturing belief change. This framework is particularly suited to studying how plausibility changes over time. One 1 In fact, this issue is discussed by Boutilier <ref> [3] </ref>, although his framework does not allow him to represent such a situation. 3 important intuition we would like to capture is that of minimal change. Suppose an agent gets new information at time t. <p> Moreover, if I also satisfies SDP, then (I; r; m + 1) j= B i if and only if (I; r; m) j= fl ! i fl . We now use this result to relate our approach to other approaches for modeling conditionals in the literature. Boutilier <ref> [3] </ref>, Goldszmidt and Pearl [31], and Lamarre and Shoham [43] give conditional statements similar semantics (using a preference ordering), but ! is read "after learning , is believed". Two crucial assumptions are made in these papers. <p> We have chosen to use plausibility measures for several reasons. First, plausibility measures generalize all approaches to representing uncertainty that we are aware of. The use of plausibility makes it easier to compare our approach, not only to preference-based approaches (e.g., <ref> [3] </ref>), but also to approaches based on -rankings (e.g., [31]), probably measures (e.g., [35]), or any other measure of uncertainty. More importantly, it makes it easier for us to incorporate intuitions from other approaches.
Reference: [4] <author> C. Boutilier. </author> <title> Conditional logics of normality: a modal approach. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 87-154, </pages> <year> 1994. </year>
Reference: [5] <author> C. Boutilier. </author> <title> Unifying default reasoning and belief revision in a modal framework. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 33-85, </pages> <year> 1994. </year>
Reference: [6] <author> R. Brafman, J.-C. Latombe, Y. Moses, and Y. Shoham. </author> <title> Applications of a logic of knowledge to motion planning under uncertainty. </title> <journal> Journal of the ACM, </journal> <note> 1997. To appear. </note>
Reference-contexts: This is done, for example, in <ref> [6] </ref>. 27 - (I; r; m) j= fl if (I; r; m + 1) j= . 9 This framework is clearly a temporal extension of the logic of knowledge and plausibility described in the previous section. 3.2 Example: Circuit Diagnosis Revisited We now show how the framework can be used to
Reference: [7] <author> J. Burgess. </author> <title> Quick completeness proofs for some logics of conditionals. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 22 </volume> <pages> 76-84, </pages> <year> 1981. </year>
Reference-contexts: In the general case, there are no axioms connecting knowledge and plausibility. For each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK, and UNIF are taken from [45] and <ref> [7] </ref> (see also [17,24]), while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in [14] for their probabilistic counterparts.
Reference: [8] <author> R. Davis and W. Hamscher. </author> <title> Model-based reasoning: troubleshooting. </title> <editor> In H. </editor> <booktitle> Shrobe and The American Association for Artificial Intelligence, </booktitle> <editor> editors, </editor> <booktitle> Exploring AI, </booktitle> <pages> pages 297-346. </pages> <publisher> Morgan Kaufmann, </publisher> <address> SF, </address> <year> 1988. </year>
Reference-contexts: Although it only involves one agent and only one plausibility measure in any given structure, it can easily be extended to allow for many agents with different plausibility measures. The circuit diagnosis problem has been well studied in the literature (see <ref> [8] </ref> for an overview). Consider a circuit that contains n logical components c 1 ; : : : ; c n and k lines l 1 ; : : : ; l k .
Reference: [9] <author> B. De Finetti. </author> <title> Probability, Induction and Statistics. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1972. </year>
Reference: [10] <author> J. de Kleer. </author> <title> Using crude probability estimates to guide diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 381-392, </pages> <year> 1990. </year>
Reference-contexts: This proposition shows that M diag;1 and M diag;2 capture standard assumptions made in model-based diagnosis; M diag;1 captures the assumptions made in <ref> [10] </ref>, while M diag;2 captures the assumptions made in [54].
Reference: [11] <author> P. Diaconis and S. L. Zabell. </author> <title> Updating subjective probability. </title> <journal> Journal of the American Statistical Society, </journal> <volume> 77(380) </volume> <pages> 822-830, </pages> <year> 1982. </year>
Reference-contexts: Indeed, this holds true for other distance measures as well <ref> [11] </ref>. 31 Time b b b b b b b b b b b b b b b b b b b b b b r b b b Fig. 2. Schematic description of how the agent's knowledge evolves in time in synchronous systems with perfect recall. <p> A well-known result of Diaconis and Zabell <ref> [11] </ref> that shows that, in a precise sense, any form of coherent probabilistic belief change can be described by conditioning.
Reference: [12] <author> D. Dubois and H. Prade. </author> <title> An introduction to possibilistic and fuzzy logics. </title> <editor> In G. Shafer and J. Pearl, editors, </editor> <booktitle> Readings in Uncertain Reasoning, </booktitle> <pages> pages 742-761. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1990. </year>
Reference-contexts: These axioms certainly imply property A1, so a belief function is a plausibility measure. A fuzzy measure (or a Sugeno measure) f on W [59] is a function f : 2 W 7! [0; 1], that satisfies A1 and some continuity constraints. A possibility measure <ref> [12] </ref> Poss is a fuzzy measure such that Poss (W ) = 1, Poss (;) = 0, and Poss (A) = sup w2A (Poss (fwg).
Reference: [13] <author> D. Dubois and H. Prade. </author> <title> Possibilistic logic, preferential models, </title> <booktitle> non-monotonicity and related issues. In Proc. Twelfth International Joint Conference on Artificial Intelligence (IJCAI '91), </booktitle> <pages> pages 419-424. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1991. </year> <month> 60 </month>
Reference-contexts: A possibility structure is a tuple (W; Poss; ), where Poss is a possibility measure on W . It satisfies a conditional ! if either Poss ([[]]) = 0 or Poss ([[ ^ ]]) &gt; Poss ([[ ^ : ]]) <ref> [13] </ref>. That is, either is impossible, in which case the conditional holds vacuously, or ^ is more possible than ^ : . A-structure is a tuple (W; ; ), where is an ordinal ranking on W .
Reference: [14] <author> R. Fagin and J. Y. Halpern. </author> <title> Reasoning about knowledge and probability. </title> <journal> Journal of the ACM, </journal> <volume> 41(2) </volume> <pages> 340-367, </pages> <year> 1994. </year>
Reference-contexts: The properties of belief depend on how the plausibility measure interacts with the accessibility relation that defines knowledge. We study these interactions, keeping in mind that plausibility generalizes probability. In view of this, it is perhaps not surprising that many of the issues studied by Fagin and Halpern <ref> [14] </ref> when considering the interaction of knowledge and probability also arise in our framework. There are, however, a number of new issues that arise in our framework due to the interaction between knowledge and belief. <p> In the next section, we review the syntax and semantics of the standard approach to modeling knowledge using Kripke structures and show how plausibility can be added to the framework. Much of our technical discussion of axiomatizations and decision procedures is closely related to that of <ref> [14] </ref>. In Section 3.1, we present our full framework which adds plausibility to the framework of [33] for modeling knowledge (and time) in multi-agent systems. In Section 4 we introduce prior plausibilities and show how they can be used. <p> of the three minimal diagnoses occurred: fX 1 g, fX 2 ; O 1 g or fX 2 ; A 2 g. 2.6 Properties of Knowledge and Plausibility Kripke structures for knowledge and plausibility are quite similar to the Kripke structures for knowledge and probability introduced by Fagin and Halpern <ref> [14] </ref>. <p> We would not expect the agent to place a positive probability on worlds that he considers impossible. Similarly, he would not want to consider as plausible (even remotely) a world he knows to be impossible. This intuition leads us to the following condition, called CONS for consistency (following <ref> [14] </ref>): CONS W (w;i) K i (w) for all worlds w and all agents i. 5 A consequence of assuming CONS is a stronger connection between knowledge and belief. <p> This amounts to assuming that the plausibility measure is a function of the agent's epistemic state. This is captured by an assumption called SDP (following <ref> [14] </ref>) for state determined plausibilities: SDP For all worlds w and w 0 and all agents i, if (w; w 0 ) 2 K i then P i (w) = P i (w 0 ). It is easy to see that SDP implies that an agent knows his plausibility measure. <p> We now present sound and complete axiomatizations for the full language L KC . The technical details are much in the spirit of the axiomatizations presented in <ref> [14] </ref> for knowledge and probability. Our complete axiomatization for M consists of two "modules": a complete axiomatization for knowledge (i.e., S5) and a complete axiomatization for conditionals. In the general case, there are no axioms connecting knowledge and plausibility. <p> For each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK, and UNIF are taken from [45] and [7] (see also [17,24]), while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in <ref> [14] </ref> for their probabilistic counterparts. We also provide complete characterizations of the complexity of the validity problem for all the logics considered, based on complexity results for knowledge [34] and for conditionals [21]. <p> C7. N ! CONS and SDP correspond to the following axioms, respectively; C9. K i ) N i It is interesting to note that the axioms for CONS and UNIF are derived from the axioms defined in <ref> [14] </ref> by replacing w () = 1 (the probability of is 1) by N i , which has a similar reading. We show that adding the appropriate axioms to AX gives a sound and complete axiomatization of the logic with respect to the class of structures satisfying the corresponding conditions. <p> Proof. See Appendix A.2. 2 We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics [34] and conditional logics [21]. Again, the technical details are much in the spirit of those in <ref> [14] </ref>. We start with few results that will be useful in our discussion of complexity. As is often the case in modal logics, we can prove a "small model property" for our logic: if a formula is satisfiable at all, it is satisfiable in a small model. <p> We briefly sketch the main ideas here, referring the reader to the other papers for details. The polynomial space lower bound follows from the polynomial space lower bound for logics of knowledge alone [34]. For the exponential lower bound we use exactly the lower bound described Fagin and Halpern <ref> [14] </ref> for the combination of knowledge and probability (which is in turn based on the lower bound for PDL [16]). This lower bound construction uses only formulas involving K i and probabilistic statements of the form w i () = 1 (i.e., the probability of is 1).
Reference: [15] <author> R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1995. </year>
Reference-contexts: Theorem 1 [34] The axiom system K (resp. K45, KD45, S5) is a sound and complete axiomatization of L K with respect to M K (resp. M et K , M est K ). In this paper, we use the multi-agent systems formalism of <ref> [15] </ref> to model knowledge; this means that knowledge satisfies the axioms of S5. (We provide some motivation for this choice below; see [15] for further discussion.) This implies that if an agent knows , then is true (K3) and that the agent is introspective| he knows what he knows and does <p> M et K , M est K ). In this paper, we use the multi-agent systems formalism of <ref> [15] </ref> to model knowledge; this means that knowledge satisfies the axioms of S5. (We provide some motivation for this choice below; see [15] for further discussion.) This implies that if an agent knows , then is true (K3) and that the agent is introspective| he knows what he knows and does not know (K4 and K5). Belief, on the other hand, is typically viewed as defeasible. <p> Taking ~ i to define the K i relation, we get a Kripke structure over points. 8 This definition of knowledge has proved useful in many applications in distributed systems and AI (see <ref> [15] </ref> and the references therein). As argued above, we want to add the notion of plausibility so that we can model the agent's beliefs. It is straightforward to do so by adding a plausibility assessment for each agent at each point. <p> Proposition 31 If I is a synchronous system satisfying perfect recall and PRIOR, then I is coherent. 14 We remark that COH is analogous to the axiom K i fl ) flK i that characterizes perfect recall in synchronous systems <ref> [15] </ref>. Roughly speaking, this is because coherence ensures that the agent does not forget what she ruled out as implausible. 39 Proof. Straightforward; left to the reader. 2 Thus, PRIOR forces systems to be coherent, and hence to satisfy COH. It also forces systems to satisfy CONS, and hence C5.
Reference: [16] <author> M. J. Fischer and R. E. Ladner. </author> <title> Propositional dynamic logic of regular programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18(2) </volume> <pages> 194-211, </pages> <year> 1979. </year>
Reference-contexts: For the exponential lower bound we use exactly the lower bound described Fagin and Halpern [14] for the combination of knowledge and probability (which is in turn based on the lower bound for PDL <ref> [16] </ref>). This lower bound construction uses only formulas involving K i and probabilistic statements of the form w i () = 1 (i.e., the probability of is 1). Since N i has exactly the same properties as w i () = 1, the same construction applies to our logic.
Reference: [17] <author> N. Friedman. </author> <title> Modeling Beliefs in Dynamic Systems. </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <year> 1997. </year>
Reference: [18] <author> N. Friedman and J. Y. Halpern. </author> <title> Conditional logics of belief change. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '94), </booktitle> <pages> pages 915-921. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, Calif., </address> <year> 1994. </year>
Reference-contexts: Nevertheless, it is clear that this assumption is being made. 36 regardless of whether B i is believed at (r; m+1). In <ref> [18] </ref>, we examine conditionals of the form &gt; intended to capture the second interpretation " is believed after learning ". The semantics for these conditionals involves examining future time points, just as our intuitive reading dictates.
Reference: [19] <author> N. Friedman and J. Y. Halpern. </author> <title> A knowledge-based framework for belief change. Part I: foundations. </title> <editor> In R. Fagin, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fifth Conference, </booktitle> <pages> pages 44-64. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1994. </year>
Reference-contexts: The second is that we include knowledge and time, as well as belief, explicitly in the framework. We could have easily modified the framework to use other ways of modeling uncertainty. Indeed, in a preliminary version of this paper <ref> [19] </ref>, we used preference orderings. We have chosen to use plausibility measures for several reasons. First, plausibility measures generalize all approaches to representing uncertainty that we are aware of. <p> We have focused here on the foundations of the framework. In the future, we hope to apply the framework to examine more realistic problems. We have already begun to do this. For example, in <ref> [19] </ref> we provide a detailed analysis of iterated prisoner dilemma games between two agents. It is well-known that the players cannot cooperate when they have common knowledge of rationality. However, we show that they can cooperate when they have common belief of rationality.
Reference: [20] <author> N. Friedman and J. Y. Halpern. </author> <title> Plausibility measures: a user's manual. </title> <editor> In P. Besnard and S. Hanks, editors, </editor> <booktitle> Proc. Eleventh Conference on Uncertainty in Artificial Intelligence (UAI '95), </booktitle> <pages> pages 175-184. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: This rule determines the order induced by posterior plausibilities. Since we are interested only in this aspect of plausibility, any method of conditioning that satisfies COND will do for our present purposes. (See <ref> [20] </ref> for an examination of other properties we might require of conditioning.) Notice that any two methods for conditioning are isomorphic in the following sense: Let S 1 = (W 1 ; Pl 1 ) and S 2 = (W 2 ; Pl 2 ) be two plausibility spaces. <p> Any two definitions of conditioning that satisfy COND result in order-isomorphic plausibility spaces (see <ref> [20] </ref>). This discussion suggests that we define Pl (r;m+1;i) to be the result of conditioning Pl (r;m;i) 10 There is another sense in which Pr E represents the minimal change from Pr.
Reference: [21] <author> N. Friedman and J. Y. Halpern. </author> <title> On the axiomatization and complexity of conditional logics. </title> <note> In preperation. A preliminary version appeared in J. </note> <editor> Doyle, E. Sandewall, and P. Torasso, editors. </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference (KR '94), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1994., 1996. </year>
Reference-contexts: We also provide complete characterizations of the complexity of the validity problem for all the logics considered, based on complexity results for knowledge [34] and for conditionals <ref> [21] </ref>. The axiom system can be modularized into three components: propositional reasoning, reasoning about knowledge, and reasoning about conditionals. <p> Proof. See Appendix A.2. 2 We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics [34] and conditional logics <ref> [21] </ref>. Again, the technical details are much in the spirit of those in [14]. We start with few results that will be useful in our discussion of complexity. <p> So the representation of such structures is polynomial in jW j. Is it possible to find a small preferential Kripke structure satisfying ? Indeed we can. Using results of <ref> [21] </ref>, we immediately get the following lemma: Lemma 14 Let A be a subset of fCONS; NORM; REF; SDP; UNIF; RANKg. If a formula is satisfiable in a Kripke structure satisfying A with N worlds, then is satisfiable in a preferential Kripke structure with at most jSub ()jN worlds. <p> The formula is satisfiable in a Kripke structure satisfying A if and only if it is satisfiable in a Kripke structure with at most 2 j Sub () j worlds. Proof. The proof of this theorem relies on techniques from <ref> [21] </ref>. We sketch only the main steps here. The proof is based on a standard filtration argument. Suppose there is a structure M and a world w in M such that (M; w) j= . Let Sub + () = Sub () [ f: : 2 Sub ()g. <p> Arguments essentially identical to those of <ref> [21] </ref> show that (M 0 ; [w]) j= if and only if (M; w) j= for all 2 Sub (); we omit details here. We now have to describe how to modify this argument to ensure that M 0 satisfies A. <p> We now have to describe how to modify this argument to ensure that M 0 satisfies A. The modifications for NORM; REF; UNIF and RANK are described in <ref> [21] </ref>. Suppose that M satisfies CONS. Let [w 0 ] 2 W 0 ([w];i) . By definition, w 0 2 W (w [w] ;i) . But since M satisfies CONS, we have that w 0 2 K i (w [w] ). <p> Since CONS and SDP imply UNIF, and since A contains CONS and either SDP or UNIF, we conclude that M satisfies UNIF. Using techniques from <ref> [21] </ref> we can assume, without loss of generality, that for each world w, the plausibility space P 1 (w) is preferential (i.e., induced by some preference ordering) and that W (w;1) has at most jSub ()j 2 worlds.
Reference: [22] <author> N. Friedman and J. Y. Halpern. </author> <title> A qualitative Markov assumption and its implications for belief change. </title> <editor> In E. Horvitz and F. Jensen editors. </editor> <booktitle> Proc. Twelfth Conference on Uncertainty in Artificial Intelligence (UAI '96), </booktitle> <pages> pages 263-273, </pages> <year> 1996. </year>
Reference: [23] <author> N. Friedman and J. Y. Halpern. </author> <title> Modeling belief in dynamic systems. Part II: revision and update. </title> <note> Submitted for publication. A preliminary version appears in J. </note> <editor> Doyle, E. Sandewall, and P. Torasso, editors. </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference (KR '94), </booktitle> <year> 1994, </year> <pages> pp. </pages> <month> 190-201, </month> <title> under the title "A knowledge-based framework for belief change. Part II: revision and update.", </title> <year> 1997. </year>
Reference-contexts: Belief revision and belief update describe only two of the many ways in which beliefs can change. Our goal is to construct a framework to reason about belief change in general. This paper describes the details of that framework. In a companion paper <ref> [23] </ref> we consider the special cases of belief revision and update in more detail. Perhaps the most straightforward approach to belief change is to simply represent an agent's beliefs as a closed set of formulas in some language and then put constraints on how these beliefs can change. <p> This is essentially the approach taken in [1,27,38]; as their results show, much can be done with this framework. The main problem with this approach is that it does not provide a good semantics for belief. As we hope to show in this paper and in <ref> [23] </ref>, such a semantics can give us a much deeper understanding of how and why beliefs change. Moreover, this semantics provides the tools to deal with complicating factors such actions, external events, and multiple agents. <p> As we show, many situations previously studied in the literature, such as diagnostic reasoning [54], can be easily captured by using such prior plausibilities. Moreover, as we show in a companion paper <ref> [23] </ref>, belief revision and belief update|which both attempt to capture intuitions involving minimal change in beliefs|can be captured in our framework by conditioning on an appropriate prior plausibility measure. Thinking in terms of priors also gives us insight into other representations of belief change, such as those of of [5,31,43]. <p> More importantly, it makes it easier for us to incorporate intuitions from other approaches. We have already seen one example of this phenomenon in the present paper: we defined a plausibilistic analogue of conditioning, and used it to model minimal change. As we show in <ref> [23] </ref>, we can represent the standard approaches to minimal change|belief revision and belief update|in terms of conditioning.
Reference: [24] <author> N. Friedman and J. Y. Halpern. </author> <title> Plausibility measures and default reasoning. </title> <journal> Journal of the ACM, </journal> <note> 1997. To appear. A preliminary version of this work appeared in Proc. National Conference on Artificial Intelligence (AAAI '96), </note> <year> 1996, </year> <pages> pages 1297-1304. </pages>
Reference-contexts: A preference ordering on W is a partial order over W [41,56]. Intuitively, w w 0 holds if w is preferred to w 0 . Preference orders have been used to provide semantics for default (i.e., conditional) statements. In <ref> [24] </ref> we show how to map preference orders on W to plausibility measures on W in a way that preserves the ordering of events of the form fwg 7 as well as the truth values of defaults. We review these results below. <p> We review these results below. A parametrized probability distribution (PPD) on W is a sequence fPr i : i 0g of probability measures over W . Such structures provide semantics for defaults in *-semantics [50,30]. In <ref> [24] </ref> we show how to map PPDs into plausibility structures in a way that preserves the truth-values of conditionals (again, see discussion below). 2.3 The Logic of Conditionals Our goal is to describe the agent's beliefs in terms of plausibility. <p> Formally, ! is satisfied if lim i!1 Pr i ([[ ]]j [[ ]]) = 1 [30] (where Pr i ([[ ]]j [[]]) is taken to be 1 if Pr i ([[]]) = 0). In <ref> [24] </ref> we use plausibility to provide semantics for conditionals and show that our definition generalizes the definition in the various approaches we just described. We briefly review the definitions and results here. <p> It is easy to see that this semantics for conditionals generalizes the semantics of conditionals in possibility structures and -structures. The following result shows that it also generalizes the semantics of conditionals in preferential structures and PPD structures. Proposition 2 <ref> [24] </ref> (a) If is a preference ordering on W , then there is a plausibility measure Pl on W such that (W; ; ) j= ! if and only if (W; Pl ; ) j= ! . (b) If P P = fPr i g is a PPD on W , <p> For a subset A of W , we can then define Pl (A) to be the least upper bound of fd w : w 2 Ag. Since D is closed under least upper bounds, Pl (A) is well defined. As shown in <ref> [24] </ref>, this choice of Pl satisfies Proposition 2. The construction in the case of PPD's is even more straightforward. <p> Since the AND rule is a fundamental feature of qualitative reasoning, we would like to restrict to plausibility structures where it holds. In <ref> [24] </ref> we show that the following condition is necessary and sufficient to guarantee that the And rule holds: A2 If A, B, and C are pairwise disjoint sets, Pl (A [ B) &gt; Pl (C), and Pl (A [ C) &gt; Pl (B), then Pl (A) &gt; Pl (B [ C). <p> It holds exactly if (N ^ N ) ) N ( ^ ). A plausibility space (W; Pl) is qualitative if it satisfies A2 and A3. A plausibility structure (W; Pl; ) is qualitative if (W; Pl) is a qualitative plausibility space. In <ref> [24] </ref> we show that, in a very general sense, qualitative plausibility structures capture default reasoning. More precisely, we show that the KLM properties are sound with respect to a class of plausibility structures if and only if the class consists of qualitative plausibility structures.
Reference: [25] <author> N. Friedman, J. Y. Halpern, and D. Koller. </author> <title> Conditional first-order logic revisited. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '96), </booktitle> <pages> pages 1305-1312. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, Calif., </address> <year> 1996. </year>
Reference-contexts: We note, however, that this finite model property is no longer true when we consider the interaction of beliefs with other modalities, such as time, or when we examine the first-order case. In these situations, the two models of beliefs are not equivalent. Plausibility is strictly more expressive; see <ref> [25] </ref>. We now examine the formal properties of belief and knowledge in structures of knowledge and plausibility. We start by restricting our attention to L B . As we show below, the modal 20 system K precisely characterizes the valid formulas of L B in the class M. <p> See Appendix A.4. 2 Are these conditions necessary to characterize BT1 and BT2? The answer is no. First, the proof of Lemma 28 applies to systems with infinite branching, if the agents' prior satisfies an infinitary version of A2. As shown in <ref> [25] </ref>, this infinitary version is satisfied by -rankings and preference orderings that are well founded (that is, they have no infinite descending sequences w 3 w 2 w 1 ). Thus, any system with static propositions whose prior is induced by a well-founded preference order satisfies BT1 and BT2. <p> For example, work on defaults has mainly focused on properties of structures with a finite number of worlds. In our framework, however, even a simple system with two global states might have an uncountable number of runs. As shown in <ref> [25] </ref>, once we examine structures with infinitely many worlds, qualitative plausibility measures can capture natural ordering of events that cannot be captured by preference orderings, possibility measures, or -rankings.
Reference: [26] <author> D. Gabbay, A. Pnueli, S. Shelah, and J. Stavi. </author> <title> On the temporal analysis of fairness. </title> <booktitle> In Proc. 7th ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 163-173, </pages> <year> 1980. </year>
Reference-contexts: In order to reason about the temporal aspects of the system, we add to the language temporal modalities in the standard fashion (see <ref> [26] </ref>). These include fl for " is true at the next time step" We call this language L KCT .
Reference: [27] <author> P. Gardenfors. </author> <title> Knowledge in Flux. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1988. </year>
Reference: [28] <author> P. Gardenfors and D. Makinson. </author> <title> Revisions of knowledge systems using epistemic entrenchment. </title> <editor> In M. Vardi, editor, </editor> <booktitle> Proc. Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-95. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1988. </year> <month> 61 </month>
Reference-contexts: For example, the agent might have a preference ordering over possible worlds [5,32,39] or an entrenchment ordering over formulas <ref> [28] </ref>. This ordering dictates how the agent's beliefs change. For example, in [32], the new beliefs are characterized by the most preferred worlds that are consistent with the new observation, while in [28] beliefs are discarded according to their degree of entrenchment until it is consistent to add the new observation <p> example, the agent might have a preference ordering over possible worlds [5,32,39] or an entrenchment ordering over formulas <ref> [28] </ref>. This ordering dictates how the agent's beliefs change. For example, in [32], the new beliefs are characterized by the most preferred worlds that are consistent with the new observation, while in [28] beliefs are discarded according to their degree of entrenchment until it is consistent to add the new observation to the resulting set of beliefs. Keeping this insight in mind, we now describe plausibility measures [20,24].
Reference: [29] <author> M. L. Ginsberg. </author> <title> Counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 35-79, </pages> <year> 1986. </year>
Reference-contexts: Additionally, rational preference orderings of [41] are essentially rankings in the sense that for each rational preference ordering we can construct a ranking that satisfies exactly the same conditional statements [17,24]. While rankings are quite natural, they have often been rejected as being too inexpressive <ref> [29] </ref>. In a ranking there is a total order on events.
Reference: [30] <author> M. Goldszmidt, P. Morris, and J. Pearl. </author> <title> A maximum entropy approach to nonmonotonic reasoning. </title> <journal> IEEE Transactions of Pattern Analysis and Machine Intelligence, </journal> <volume> 15(3) </volume> <pages> 220-232, </pages> <year> 1993. </year>
Reference-contexts: Intuitively, it satisfies a conditional ! if the conditional probability given goes to 1 in the limit. Formally, ! is satisfied if lim i!1 Pr i ([[ ]]j [[ ]]) = 1 <ref> [30] </ref> (where Pr i ([[ ]]j [[]]) is taken to be 1 if Pr i ([[]]) = 0). In [24] we use plausibility to provide semantics for conditionals and show that our definition generalizes the definition in the various approaches we just described.
Reference: [31] <author> M. Goldszmidt and J. Pearl. </author> <title> Rank-based systems: A simple approach to belief revision, belief update and reasoning about evidence and actions. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proc. Third International Conference on Principles of Knowledge Representation and Reasoning (KR '92), </booktitle> <pages> pages 661-672. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1992. </year>
Reference-contexts: A possibility measure [12] Poss is a fuzzy measure such that Poss (W ) = 1, Poss (;) = 0, and Poss (A) = sup w2A (Poss (fwg). An ordinal ranking (or -ranking) on W (as defined by <ref> [31] </ref>, based on ideas that go back to [57]) is a function : 2 W ! IN fl , where IN fl = IN [ f1g, such that (W ) = 0, (;) = 1, and (A) = min w2A ((fwg)). <p> A-structure is a tuple (W; ; ), where is an ordinal ranking on W . It satisfies a conditional ! if either ([[]]) = 1 or ([[ ^ ]]) &lt; ([[ ^ : ]]) <ref> [31] </ref>. A preferential structure is a tuple (W; ; ), where is a partial order on W . The intuition [56] is that a preferential structure satisfies a conditional ! if all the most preferred worlds (i.e., the minimal worlds according to ) in [[]] satisfy . <p> We now use this result to relate our approach to other approaches for modeling conditionals in the literature. Boutilier [3], Goldszmidt and Pearl <ref> [31] </ref>, and Lamarre and Shoham [43] give conditional statements similar semantics (using a preference ordering), but ! is read "after learning , is believed". Two crucial assumptions are made in these papers. The first is that the agent considers only one plausibility assessment, which in our terminology amounts to SDP. <p> First, plausibility measures generalize all approaches to representing uncertainty that we are aware of. The use of plausibility makes it easier to compare our approach, not only to preference-based approaches (e.g., [3]), but also to approaches based on -rankings (e.g., <ref> [31] </ref>), probably measures (e.g., [35]), or any other measure of uncertainty. More importantly, it makes it easier for us to incorporate intuitions from other approaches.
Reference: [32] <author> A. Grove. </author> <title> Two modelings for theory change. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 17 </volume> <pages> 157-170, </pages> <year> 1988. </year>
Reference-contexts: For example, the agent might have a preference ordering over possible worlds [5,32,39] or an entrenchment ordering over formulas [28]. This ordering dictates how the agent's beliefs change. For example, in <ref> [32] </ref>, the new beliefs are characterized by the most preferred worlds that are consistent with the new observation, while in [28] beliefs are discarded according to their degree of entrenchment until it is consistent to add the new observation to the resulting set of beliefs.
Reference: [33] <author> J. Y. Halpern and R. Fagin. </author> <title> Modelling knowledge and action in distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 159-179, </pages> <year> 1989. </year> <note> A preliminary version appeared in Proc. 4th ACM Symposium on Principles of Distributed Computing, </note> <year> 1985, </year> <title> with the title "A formal model of knowledge, action, and communication in distributed systems: </title> <note> preliminary report". </note>
Reference-contexts: We want a framework that captures the beliefs of the agent before and after the change. This is achieved by introducing time explicitly into the framework. The resulting framework is an extension of the framework of Halpern and Fagin <ref> [33] </ref> for modeling knowledge in multi-agent systems, and allows to talk about knowledge, plausibility (and hence belief), and time. This framework is analogous to combination of knowledge, probability and time studied in [35]. <p> Much of our technical discussion of axiomatizations and decision procedures is closely related to that of [14]. In Section 3.1, we present our full framework which adds plausibility to the framework of <ref> [33] </ref> for modeling knowledge (and time) in multi-agent systems. In Section 4 we introduce prior plausibilities and show how they can be used. We conclude in Section 5 with some discussion of the general approach. <p> We introduce more structure into the description by adopting the framework of Halpern and Fagin <ref> [33] </ref> for modeling multi-agent systems. This structure gives a natural definition of knowledge and an intuitive way to describe agents' interactions with their environment. We start by describing the framework of Halpern and Fagin, and then add plausibility.
Reference: [34] <author> J. Y. Halpern and Y. Moses. </author> <title> A guide to completeness and complexity for modal logics of knowledge and belief. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 319-379, </pages> <year> 1992. </year>
Reference-contexts: We conclude in Section 5 with some discussion of the general approach. Proofs of theorems are given in Appendix A. 2 Knowledge and Plausibility In this section, we briefly review the standard models for knowledge and beliefs (see <ref> [34] </ref> for further motivation and details), describe a notion of plausibility, and then show how to combine the two notions. Finally, we compare the derived notion of belief with previous work on the subject. 2.1 The Logic of Knowledge We start by examining the standard models for knowledge and belief. <p> Theorem 1 <ref> [34] </ref> The axiom system K (resp. K45, KD45, S5) is a sound and complete axiomatization of L K with respect to M K (resp. M et K , M est K ). <p> We also provide complete characterizations of the complexity of the validity problem for all the logics considered, based on complexity results for knowledge <ref> [34] </ref> and for conditionals [21]. The axiom system can be modularized into three components: propositional reasoning, reasoning about knowledge, and reasoning about conditionals. <p> Then AX [ A is a sound and complete axiomatization with respect to the structures in M satisfying A. Proof. See Appendix A.2. 2 We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics <ref> [34] </ref> and conditional logics [21]. Again, the technical details are much in the spirit of those in [14]. We start with few results that will be useful in our discussion of complexity. <p> Proof. Again soundness is straightforward, so we focus on completeness. We sketch a completeness proof following the usual Makinson [46] style of proof. We describe only the parts that are different from the standard proofs. See, for example, Halpern and Moses <ref> [34] </ref> for details. <p> Using standard arguments, it is easy to show that the K i 's are equivalence relations (see <ref> [34] </ref>). Using a standard induction argument, we can verify that (M KB ; w V ) j= if and only if 2 V . This construction proves completeness for AX KB . <p> The proof combines ideas from [14,21,34]. We briefly sketch the main ideas here, referring the reader to the other papers for details. The polynomial space lower bound follows from the polynomial space lower bound for logics of knowledge alone <ref> [34] </ref>. For the exponential lower bound we use exactly the lower bound described Fagin and Halpern [14] for the combination of knowledge and probability (which is in turn based on the lower bound for PDL [16]). <p> bound follows by showing that if a formulas is satisfiable at all, it is satisfiable in an exponential size structure that can be constructed in deterministic exponential time; the technique is similar to that used to show that logics of knowledge with common knowledge are decidable in deterministic exponential time <ref> [34] </ref> or that PDL is decidable in deterministic exponential time [52]. 2 Theorem 17: Let A be a subset of fCONS; NORM; REF; SDP; UNIF; RANKg containing CONS and either UNIF or SDP. For the case of one agent, the validity problem in structures satisfying A is co-NP-complete. Proof.
Reference: [35] <author> J. Y. Halpern and M. R. Tuttle. </author> <title> Knowledge, probability, </title> <journal> and adversaries. Journal of the ACM, </journal> <volume> 40(4) </volume> <pages> 917-962, </pages> <year> 1993. </year>
Reference-contexts: The resulting framework is an extension of the framework of Halpern and Fagin [33] for modeling knowledge in multi-agent systems, and allows to talk about knowledge, plausibility (and hence belief), and time. This framework is analogous to combination of knowledge, probability and time studied in <ref> [35] </ref>. As we show by example, having knowledge, plausibility, and time represented explicitly gives us a powerful and expressive framework for capturing belief change. This framework is particularly suited to studying how plausibility changes over time. <p> We would then expect the agent to modify his prior by conditioning on whatever information he has learned. This is essentially the approach taken in <ref> [35] </ref> to defining how the agents' probability distribution changes in a multi-agent system. We can do the analogous thing with plausibility. We start by making the simplifying assumption that we are dealing with synchronous systems where agents have perfect recall [36]. <p> First, plausibility measures generalize all approaches to representing uncertainty that we are aware of. The use of plausibility makes it easier to compare our approach, not only to preference-based approaches (e.g., [3]), but also to approaches based on -rankings (e.g., [31]), probably measures (e.g., <ref> [35] </ref>), or any other measure of uncertainty. More importantly, it makes it easier for us to incorporate intuitions from other approaches. We have already seen one example of this phenomenon in the present paper: we defined a plausibilistic analogue of conditioning, and used it to model minimal change.
Reference: [36] <author> J. Y. Halpern and M. Y. Vardi. </author> <title> The complexity of reasoning about knowledge and time, I: lower bounds. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(1) </volume> <pages> 195-237, </pages> <year> 1989. </year>
Reference-contexts: This is essentially the approach taken in [35] to defining how the agents' probability distribution changes in a multi-agent system. We can do the analogous thing with plausibility. We start by making the simplifying assumption that we are dealing with synchronous systems where agents have perfect recall <ref> [36] </ref>. Intuitively, this means that the agents know what the time is and do not forget the observations they have made. Formally, a system is synchronous if for any i, (r; m) ~ i (r 0 ; m 0 ) only if m = m 0 .
Reference: [37] <author> J. Hintikka. </author> <title> Knowledge and Belief. </title> <publisher> Cornell University Press, </publisher> <address> Ithaca, N.Y., </address> <year> 1962. </year>
Reference: [38] <author> H. Katsuno and A. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <editor> In J. A. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Proc. Second International Conference on Principles of Knowledge Representation and Reasoning (KR '91), </booktitle> <pages> pages 387-394. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1991. </year>
Reference-contexts: In the literature, two instances of this general phenomenon have been studied in detail: Belief revision [1,27] attempts to describe how an agent should accommodate a new belief (possibly inconsistent with his other beliefs) about a static world. Belief update <ref> [38] </ref>, on the other hand, attempts to describe how an agent should change his beliefs as a result of learning about a change in the world. Belief revision and belief update describe only two of the many ways in which beliefs can change.
Reference: [39] <author> H. Katsuno and A. Mendelzon. </author> <title> Propositional knowledge base revision and minimal change. </title> <journal> Artificial Intelligence, </journal> <volume> 52(3) </volume> <pages> 263-294, </pages> <year> 1991. </year>
Reference: [40] <author> S. Kraus and D. Lehmann. </author> <title> Knowledge, belief, and time. </title> <journal> Theoretical Computer Science, </journal> <volume> 58 </volume> <pages> 155-174, </pages> <year> 1988. </year>
Reference-contexts: Moreover, the interaction between knowledge and belief satisfies the standard properties considered by Kraus and Lehmann <ref> [40] </ref>. Although our major goal is not an abstract study of the properties of knowledge and belief, we view the fact that we have a concrete interpretation under which these properties can be studied to be an important side-benefit of our approach. <p> Proof. See Appendix A.1. 2 We now consider knowledge and belief together. This combination has been investigated in the literature [40,58]. In particular, Kraus and Lehmann <ref> [40] </ref> define Kripke structures for knowledge and belief that have two accessibility relations, one characterizing the worlds that are knowledge-accessible and one characterizing worlds that are belief-accessible. K i and B i are defined, as usual, in terms of these relations. <p> Proof. See Appendix A.1. 2 21 As an immediate corollary, we get that there is a close relationship between our framework and that of <ref> [40] </ref>. Let KL be the logic of Kraus and Lehmann: Corollary 9 For any 2 L KB , KL j= if and only if M CONS;NORM j= . <p> conditioning that captures the intuition that plausibility changes in the minimal way that is required by changes to the agent's knowledge. 3.1 Knowledge and Plausibility in Multi-Agent Systems A straightforward approach to adding time is by introducing another accessibility relation on worlds, which characterizes their temporal relationship (see, for example, <ref> [40] </ref>). We introduce more structure into the description by adopting the framework of Halpern and Fagin [33] for modeling multi-agent systems. This structure gives a natural definition of knowledge and an intuitive way to describe agents' interactions with their environment.
Reference: [41] <author> S. Kraus, D. Lehmann, and M. Magidor. </author> <title> Nonmonotonic reasoning, preferential models and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207, </pages> <year> 1990. </year>
Reference-contexts: What do we do in these structures? There are a number of options: the first is to assume that, for each formula , there are minimal worlds in [[]]; this is the assumption actually made in <ref> [41] </ref>, where it is called the smoothness assumption. A yet more general definition|one that works even if is not smooth|is given in [45,4]. Roughly speaking, ! is true if, from a certain point on, whenever is true, so is . <p> While there has been little consensus on what the "right" properties for defaults should be, there has been some consensus on a reasonable "core" of inference rules for default reasoning. This core, known as the KLM properties <ref> [41] </ref>, consists of the following axiom and rules of inference: LLE. From , 0 and ! infer 0 ! (left logical equivalence) RW. From ) 0 and ! infer ! 0 (right weakening) REF. ! (reflexivity) AND. From ! 1 and ! 2 infer ! 1 ^ 2 OR. <p> We also show that a very weak condition is necessary and sufficient in order for the KLM properties to be complete axiomatization of the language of default entailment considered in <ref> [41] </ref>. These results help explain why so many different approaches to giving semantics to conditionals are characterized by the KLM properties. <p> Note that -rankings and possibility measures are two examples of rankings. Additionally, rational preference orderings of <ref> [41] </ref> are essentially rankings in the sense that for each rational preference ordering we can construct a ranking that satisfies exactly the same conditional statements [17,24]. While rankings are quite natural, they have often been rejected as being too inexpressive [29].
Reference: [42] <author> S. Kullback and R. A. Leibler. </author> <title> On information and sufficiency. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 22 </volume> <pages> 76-86, </pages> <year> 1951. </year>
Reference-contexts: "distance" of a probability distribution Pr 0 from Pr in terms of the cross-entropy of Pr 0 relative to Pr, then it is well known that Pr E is the distribution that minimizes the relative cross-entropy from Pr among all distributions Pr 0 such that Pr 0 (E) = 1 <ref> [42] </ref>. Indeed, this holds true for other distance measures as well [11]. 31 Time b b b b b b b b b b b b b b b b b b b b b b r b b b Fig. 2.
Reference: [43] <author> P. Lamarre and Y. Shoham. </author> <title> Knowledge, certainty, belief, </title> <editor> and conditionalisation. In J. Doyle, E. Sandewall, and P. Torasso, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference (KR '94), </booktitle> <pages> pages 415-424. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1994. </year>
Reference-contexts: We now relate to three other notions of beliefs in the literature|those of Moses and Shoham [49], Voorbraak [58], and Lamarre and Shoham <ref> [43] </ref>. Moses and Shoham [49] also view belief as being derived from knowledge. The intuition that they try to capture is that once the agent makes a defeasible assumption, the rest of his beliefs should follow from his knowledge. <p> Our notion of belief is weaker, in that we allow agents to be aware of the defeasibility of their beliefs. Lamarre and Shoham <ref> [43] </ref> investigate the notion of knowledge as justified true belief using a framework that is very similar to ours. They start with an explicit preference ordering over possible worlds, and then define B ff to read "given evidence ff, holds in the most plausible ff-worlds". <p> We now use this result to relate our approach to other approaches for modeling conditionals in the literature. Boutilier [3], Goldszmidt and Pearl [31], and Lamarre and Shoham <ref> [43] </ref> give conditional statements similar semantics (using a preference ordering), but ! is read "after learning , is believed". Two crucial assumptions are made in these papers. The first is that the agent considers only one plausibility assessment, which in our terminology amounts to SDP.
Reference: [44] <author> H. J. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '84), </booktitle> <pages> pages 198-202, </pages> <year> 1984. </year> <month> 62 </month>
Reference: [45] <author> D. K. Lewis. </author> <title> Counterfactuals. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Mass., </address> <year> 1973. </year>
Reference-contexts: To satisfy OR in general we need another condition: 10 A3 If Pl (A) = Pl (B) =?, then Pl (A [ B) =?. A3 also has a nice axiomatic characterization. Let N be an abbreviation for : ! false. (This operator is called the "outer modality" in <ref> [45] </ref>.) Expanding the definition of !, we get that N holds at w if and only if Pl ([[:]]) =?. Thus, N holds if : is considered completely implausible. We can think of the N modality as the plausibilistic version of necessity. <p> plausible worlds are in K i (w), it follows that if the agent knows he also believes . (Indeed, as we shall see, this condition characterizes CONS.) 5 We remark that CONS is inappropriate if we use ! to model, not plausibility, but counterfactual conditions, as is done by Lewis <ref> [45] </ref>. If CONS holds, then it is easy to see that K i ) K i (: ! i ) is valid, for all . <p> Since 1 &gt; 0, this means the agent assigns non-zero probability to some sets of worlds. It is possible to have &gt; = ? in plausibility spaces. If this happens, the agent considers all sets to be completely implausible. The following condition, called NORM for normality (following <ref> [45] </ref>), says this does not happen: NORM P (w; i) is normal, that is, &gt; (w;i) &gt;? (w;i) , for all worlds w and all agents i. We can strengthen this condition somewhat to one that says that the agent never considers the real world implausible. <p> Stating this condition, however, leads to a technical problem. Recall that Pl (w;i) is defined over the set of measurable subsets of W (w;i) . In general, however, singletons may not be measurable. Thus, we examine a slightly weaker condition which we call REF for reflexive (following <ref> [45] </ref>): REF For all worlds w and all agents i, - w 2 W (w;i) , and - Pl (w;i) (A) &gt;? for all A 2 F (w;i) such that w 2 A. <p> In a ranking there is a total order on events. The standard argument for partial orders is as follows: In general, an agent may not be able to determine the relative plausibility of a and b. 6 This condition is not the same as uniformity as defined in <ref> [45] </ref>; rather, it corresponds in the Lewis terminology to absoluteness. 18 If the plausibility measure is a ranking, the agent is forced to make this determination; with a partial order, he is not. This argument loses much of its force in our framework, once we combine knowledge and plausibility. <p> In the general case, there are no axioms connecting knowledge and plausibility. For each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK, and UNIF are taken from <ref> [45] </ref> and [7] (see also [17,24]), while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in [14] for their probabilistic counterparts.
Reference: [46] <author> D. Makinson. </author> <title> On some completeness theorems in modal logic. </title> <journal> Zeitschrift fur Mathematische Logik und Grundlagen der Mathematik, </journal> <volume> 12 </volume> <pages> 379-384, </pages> <year> 1966. </year>
Reference-contexts: Proof. Again soundness is straightforward, so we focus on completeness. We sketch a completeness proof following the usual Makinson <ref> [46] </ref> style of proof. We describe only the parts that are different from the standard proofs. See, for example, Halpern and Moses [34] for details.
Reference: [47] <author> R. van der Meyden. </author> <title> Mutual belief revision (preliminary report). </title> <editor> In J. Doyle, E. Sandewall, and P. Torasso, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference (KR '94), </booktitle> <pages> pages 595-606. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1994. </year>
Reference-contexts: It is well-known that the players cannot cooperate when they have common knowledge of rationality. However, we show that they can cooperate when they have common belief of rationality. A recent proposal by van der Meyden <ref> [47] </ref> for multi-agent belief change can easily be embedded in our framework [48]. We hope to use our framework to study some of the problems considered by van der Meyden, such as speech-act semantics. Another natural application area is reasoning about actions and planning in the presence of uncertainty.
Reference: [48] <author> R. van der Meyden. </author> <type> Personal communication. </type> <year> 1994. </year>
Reference-contexts: It is well-known that the players cannot cooperate when they have common knowledge of rationality. However, we show that they can cooperate when they have common belief of rationality. A recent proposal by van der Meyden [47] for multi-agent belief change can easily be embedded in our framework <ref> [48] </ref>. We hope to use our framework to study some of the problems considered by van der Meyden, such as speech-act semantics. Another natural application area is reasoning about actions and planning in the presence of uncertainty.
Reference: [49] <author> Y. Moses and Y. Shoham. </author> <title> Belief as defeasible knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 64(2) </volume> <pages> 299-322, </pages> <year> 1993. </year>
Reference-contexts: Let KL be the logic of Kraus and Lehmann: Corollary 9 For any 2 L KB , KL j= if and only if M CONS;NORM j= . We now relate to three other notions of beliefs in the literature|those of Moses and Shoham <ref> [49] </ref>, Voorbraak [58], and Lamarre and Shoham [43]. Moses and Shoham [49] also view belief as being derived from knowledge. The intuition that they try to capture is that once the agent makes a defeasible assumption, the rest of his beliefs should follow from his knowledge. <p> We now relate to three other notions of beliefs in the literature|those of Moses and Shoham <ref> [49] </ref>, Voorbraak [58], and Lamarre and Shoham [43]. Moses and Shoham [49] also view belief as being derived from knowledge. The intuition that they try to capture is that once the agent makes a defeasible assumption, the rest of his beliefs should follow from his knowledge.
Reference: [50] <author> J. Pearl. </author> <title> Probabilistic semantics for nonmonotonic reasoning: a survey. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR '89), </booktitle> <pages> pages 505-516, </pages> <year> 1989. </year> <note> Reprinted in Readings in Uncertain Reasoning, </note> <editor> G. Shafer and J. Pearl (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1990, </year> <pages> pp. 699-710. </pages>
Reference-contexts: An alternative approach is to put a probability measure over the set of possible worlds. Then we can interpret "the agent believes " as "the probability of is close to 1" <ref> [50] </ref>. We examine a new approach to modeling uncertainty based on plausibility measures, introduced in [20,24], where a plausibility measure just associates with an event (i.e., a set of possible worlds) its plausibility, an element in some partially ordered set.
Reference: [51] <author> M. Piccione and A. Rubinstein. </author> <title> On the interpretation of decision problems with imperfect recall. Games and Economic Behavior, </title> <note> 1997. To appear. </note>
Reference-contexts: In an asynchronous setting, an agent might consider several points on the same run possible. The question then arises as to how (or whether) we should distribute the plausibility of a run over these points. Two approaches are considered in a probabilistic setting in <ref> [51] </ref>, in 16 We could, of course, redefine PRIOR so as to guarantee that Proposition 22 holds, but this leads to other complications. 41 the context of analyzing games with imperfect recall.
Reference: [52] <author> V. R. Pratt. </author> <title> Models of program logics. </title> <booktitle> In Proc. 20th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 115-122, </pages> <year> 1979. </year>
Reference-contexts: at all, it is satisfiable in an exponential size structure that can be constructed in deterministic exponential time; the technique is similar to that used to show that logics of knowledge with common knowledge are decidable in deterministic exponential time [34] or that PDL is decidable in deterministic exponential time <ref> [52] </ref>. 2 Theorem 17: Let A be a subset of fCONS; NORM; REF; SDP; UNIF; RANKg containing CONS and either UNIF or SDP. For the case of one agent, the validity problem in structures satisfying A is co-NP-complete. Proof. We show that the satisfiability problem is NP-complete.
Reference: [53] <author> F. P. Ramsey. </author> <title> Truth and probability. </title> <editor> In R. B. Braithwaite, editor, </editor> <booktitle> The Foundations of Probability and other Logical Essays. </booktitle> <publisher> Harcourt Brace, </publisher> <address> New York, </address> <year> 1931. </year>
Reference: [54] <author> R. Reiter. </author> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 57-95, </pages> <year> 1987. </year> <note> Reprinted in in Readings in Nonmonotonic Reasoning, </note> <editor> M. L. Ginsberg (ed.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Francisco, CA. </address> <year> 1987, </year> <pages> pp. 352-371. </pages>
Reference-contexts: We can then proceed much in the spirit of the Bayesian approach, but starting with a prior plausibility and conditioning. As we show, many situations previously studied in the literature, such as diagnostic reasoning <ref> [54] </ref>, can be easily captured by using such prior plausibilities. Moreover, as we show in a companion paper [23], belief revision and belief update|which both attempt to capture intuitions involving minimal change in beliefs|can be captured in our framework by conditioning on an appropriate prior plausibility measure. <p> In general, there is more than one explanation for the observed faulty behavior. Thus, the agent can not know exactly which components are faulty, but he may have beliefs on that loosely follow the examples of Reiter <ref> [54] </ref>. 13 score. Plausibility To model the agent's beliefs, we need to decide on the plausibility measure the agent has at any world. We assume that only failure sets are relevant for determining a world's plausibility. Thus, we start by constructing a plausibility measure over possible failures of the circuit. <p> This proposition shows that M diag;1 and M diag;2 capture standard assumptions made in model-based diagnosis; M diag;1 captures the assumptions made in [10], while M diag;2 captures the assumptions made in <ref> [54] </ref>. <p> Thus, in I diag;1 the agent does not consider new failure sets as long as the observation is not surprising. On the other hand, in I diag;2 the agent has to examine new candidates after each test. The latter behavior is essentially that described by Reiter <ref> [54, Section 5] </ref>. 29 3.3 Axiomatizing the Language of Knowledge, Plausibility and Time We now present sound and complete axiomatization for the language L KCT . The technical details are much in the spirit of the results of Section 2.8, with two exceptions.
Reference: [55] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J., </address> <year> 1976. </year>
Reference-contexts: Clearly plausibility spaces generalize probability spaces. We now briefly discuss a few other notions of uncertainty that they generalize: A belief function B on W is a function B : 2 W ! [0; 1] satisfying certain axioms <ref> [55] </ref>. These axioms certainly imply property A1, so a belief function is a plausibility measure. A fuzzy measure (or a Sugeno measure) f on W [59] is a function f : 2 W 7! [0; 1], that satisfies A1 and some continuity constraints.
Reference: [56] <author> Y. Shoham. </author> <title> A semantical approach to nonmonotonic logics. </title> <booktitle> In Proc. 2nd IEEE Symp. on Logic in Computer Science, </booktitle> <pages> pages 275-279, </pages> <year> 1987. </year> <note> Reprinted in M. </note> <editor> L. Ginsberg (Ed.), </editor> <booktitle> Readings in Nonmonotonic Reasoning, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Francisco, Calif., </address> <year> 1987, </year> <pages> pp. 227-250. </pages>
Reference-contexts: It satisfies a conditional ! if either ([[]]) = 1 or ([[ ^ ]]) &lt; ([[ ^ : ]]) [31]. A preferential structure is a tuple (W; ; ), where is a partial order on W . The intuition <ref> [56] </ref> is that a preferential structure satisfies a conditional ! if all the most preferred worlds (i.e., the minimal worlds according to ) in [[]] satisfy . However, there may be no minimal worlds in [[]].
Reference: [57] <author> W. Spohn. </author> <title> Ordinal conditional functions: a dynamic theory of epistemic states. </title> <editor> In W. Harper and B. Skyrms, editors, </editor> <title> Causation in Decision, </title> <journal> Belief Change and Statistics, </journal> <volume> volume 2, </volume> <pages> pages 105-134. </pages> <publisher> Reidel, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1988. </year>
Reference-contexts: A possibility measure [12] Poss is a fuzzy measure such that Poss (W ) = 1, Poss (;) = 0, and Poss (A) = sup w2A (Poss (fwg). An ordinal ranking (or -ranking) on W (as defined by [31], based on ideas that go back to <ref> [57] </ref>) is a function : 2 W ! IN fl , where IN fl = IN [ f1g, such that (W ) = 0, (;) = 1, and (A) = min w2A ((fwg)).
Reference: [58] <author> F. Voorbraak. </author> <title> Generalized Kripke models for epistemic logic. </title> <editor> In Y. Moses, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fourth Conference, </booktitle> <pages> pages 214-228. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1992. </year>
Reference-contexts: Let KL be the logic of Kraus and Lehmann: Corollary 9 For any 2 L KB , KL j= if and only if M CONS;NORM j= . We now relate to three other notions of beliefs in the literature|those of Moses and Shoham [49], Voorbraak <ref> [58] </ref>, and Lamarre and Shoham [43]. Moses and Shoham [49] also view belief as being derived from knowledge. The intuition that they try to capture is that once the agent makes a defeasible assumption, the rest of his beliefs should follow from his knowledge. <p> Proof. See Appendix A.1. 2 Voorbraak <ref> [58] </ref> distinguishes two notions of knowledge: objective knowledge and true justified belief . He then studies the interaction of both notions of knowledge with beliefs. The intuition we assign to knowledge is similar to Voorbraak's intuition for objective knowledge.
Reference: [59] <author> Z. Wang and G. J. Klir. </author> <title> Fuzzy Measure Theory. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1992. </year> <month> 63 </month>
Reference-contexts: These axioms certainly imply property A1, so a belief function is a plausibility measure. A fuzzy measure (or a Sugeno measure) f on W <ref> [59] </ref> is a function f : 2 W 7! [0; 1], that satisfies A1 and some continuity constraints. A possibility measure [12] Poss is a fuzzy measure such that Poss (W ) = 1, Poss (;) = 0, and Poss (A) = sup w2A (Poss (fwg).
References-found: 59

