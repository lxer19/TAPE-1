URL: http://www.cs.princeton.edu/~huffmire/paper.ps.gz
Refering-URL: http://www.cs.princeton.edu/~huffmire/
Root-URL: http://www.cs.princeton.edu
Title: Wavelet-Based Video Indexing and Querying for a Smart VCR  
Author: Xiaodong Wen, Theodore D. Huffmire, Helen H. Hu, and Adam Finkelstein 
Affiliation: Princeton University  
Abstract: We present several algorithms suitable for analysis of broadcast video. First, we show how wavelet analysis of frames of video can be used to detect transitions between shots in a video stream, thereby dividing the stream into segments. Next we describe how each segment can be inserted into a video database using an indexing scheme that involves a wavelet-based "signature." Finally, we show that during a subsequent broadcast of a similar video segment, the clip can be found in the database by quickly searching for the relevant signature. The method is robust against noise and typical variations in the video stream, even global changes in brightness that can fool histogram-based techniques. In the paper, we compare experimentally our shot transition mechanism to a color histogram implementation, and also evaluate the effectiveness of our database searching scheme. Our algorithms are very efficient and run in real-time on a desktop computer. This technology could be employed to construct a "smart VCR" that was capable of alerting the viewer to the beginning of a specific program or identifying commercials and then muting the volume on the TV. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Ahanger and T.D.C. Little. </author> <title> A survery of technologies for parsing and indexing digital video. Journal of Visual Communication and Image Representation, </title> <booktitle> Integrating Artificial Intelligence and Database Technologies, </booktitle> <volume> 7 </volume> <pages> 28-43, </pages> <year> 1996. </year>
Reference-contexts: A survey of parsing and indexing technologies by Ahanger and Little <ref> [1] </ref> discusses methods mainly in the pixel domain. Most of previous approaches to video indexing in the pixel domain have focused on color histograms. 2 Color-histogram-based methods detect cuts by comparing the similarity between distributions of colors in the frames. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position.
Reference: [2] <author> E. Ardizzone, M. La Casis, V. Di Gesu, and C. Valenti. </author> <title> Content-based indexing of image and video databases by global and shape features. </title> <booktitle> In Proc. of the International Conference on Pattern Recognition, </booktitle> <pages> pages 140-144, </pages> <year> 1996. </year>
Reference-contexts: Gargi [10] presents an overview of how well histogram methods work in different color spaces using a variety of metrics. Color-histogram features have been combined with motion, texture, shape, and edge features to detect cuts as well as represent the content of a shot <ref> [2, 23] </ref>. Niblack et al.describe the QBIC system, which performs content-based retrieval based on color, shape, texture, and sketches in large image and video databases [7, 20]. Much less work has been done in the compressed domain.
Reference: [3] <author> Yawgeng A. Chau and Jar-Chi Shee. </author> <title> Multiresolution sequential image change detection with wavelets. </title> <booktitle> In Proceedings of Visual communications and Image processing, </booktitle> <pages> pages 497-506, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: An object-based approach for temporal video partitioning and content-based indexing was presented in [11]. While nobody (to our knowledge) has previously used wavelets for video segmentation and querying, Chau presented a wavelets-based method for detecting spatial regions in a video sequence that are changing in time <ref> [3] </ref>. Also related to wavelets, this paper expands on our previous method for searching in an image database using wavelet decompositions of the images [14]. There are several benefits to using wavelets for video analysis. The video signal may arrive at any resolution, and may be noisy.
Reference: [4] <author> C. K. Chui. </author> <title> An Introduction to Wavelets, volume 1 of Wavelet Analysis and its Applications. </title> <publisher> Academic Press, Inc., </publisher> <year> 1992. </year>
Reference-contexts: In this section, we develop only the details relating to wavelets that are necessary to implement the system we have developed. For a more general presentation of wavelet analysis see one of the several excellent monographs on the subject <ref> [4, 5] </ref>; to learn about the use of wavelets in computer graphics see Stollnitz [22]. In previous work [14], we developed a distance metric for images (a measure of how different one image is from another) based on wavelets.
Reference: [5] <author> Ingrid Daubechies. </author> <title> Ten Lectures on Wavelets, </title> <booktitle> volume 61 of CBMS-NSF Regional Conference Series in Applied Mathematics. Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: In this section, we develop only the details relating to wavelets that are necessary to implement the system we have developed. For a more general presentation of wavelet analysis see one of the several excellent monographs on the subject <ref> [4, 5] </ref>; to learn about the use of wavelets in computer graphics see Stollnitz [22]. In previous work [14], we developed a distance metric for images (a measure of how different one image is from another) based on wavelets. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position.
Reference: [6] <author> R. Devore, B. Jawerth, and B. Lucier. </author> <title> Image compression through wavelet transform coding. </title> <journal> In IEEE Transactions on Information Theory, </journal> <volume> volume 38(2), </volume> <pages> pages 719-746, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: We believe that the effectiveness of this method derived from several desirable properties of wavelets: * Wavelet decompositions allow for very good image approximation with just a few coefficients. This property has been successfully exploited for lossy image compression <ref> [6] </ref>. * Wavelet decompositions can be used to extract and encode edge information [18]. Edges provide important visual cues in differentiating images. * The coefficients of a wavelet decomposition provide information that is independent of the original image resolution.
Reference: [7] <author> Flicker, Myron, Harpreet Sawhnery, and etal. </author> <title> Query by image and video content: The QBIC system. </title> <journal> Computer, </journal> <volume> 28(9), </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: Color-histogram features have been combined with motion, texture, shape, and edge features to detect cuts as well as represent the content of a shot [2, 23]. Niblack et al.describe the QBIC system, which performs content-based retrieval based on color, shape, texture, and sketches in large image and video databases <ref> [7, 20] </ref>. Much less work has been done in the compressed domain. Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann [15, 16, 17]. They extract features from available DCT, macroblock, and motion vector information.
Reference: [8] <author> James D. Foley, Andries van Dam, Steven K. Feiner, and John F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: Color space In our application, we perform all comparisons using only the luminance channel Y from the television standard color space, YIQ <ref> [8] </ref>. In an early implementation, we used all three color channels, but later found that using only the Y channel is sufficient and even improves the performance of our application. 2.
Reference: [9] <author> D. Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> CACM, </journal> <volume> 34(4) </volume> <pages> 46-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: If the corresponding segment in the database is tagged as the beginning of a commercial, then the VCR could, for example, mute the volume. This technology has other applications as well, such as the automatic identification of keyframes for MPEG <ref> [9] </ref> and Quicktime [21] video compression, or as a back-end process for the automatic storyboarding and searching aspects of a video library [12]. 1.1 Related Work A number of researchers have addressed video segmentation and querying. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position. <p> For example, if the query signature has a positive coefficient left in position ~ Q <ref> [1; 5; 9] </ref>, we would look at the list at Y + [1; 5; 9] to see which shots in the database also have a positive coefficient left in that position.
Reference: [10] <author> U. Gargi, R. Kasturi, and S. Antani. </author> <title> An evaluation of color histogram based methods in video indexing. </title> <type> Technical Report CSE-96-053, </type> <institution> Penn State University, Department of Computer Science and Engineering, </institution> <year> 1996. </year>
Reference-contexts: Most of previous approaches to video indexing in the pixel domain have focused on color histograms. 2 Color-histogram-based methods detect cuts by comparing the similarity between distributions of colors in the frames. Gargi <ref> [10] </ref> presents an overview of how well histogram methods work in different color spaces using a variety of metrics. Color-histogram features have been combined with motion, texture, shape, and edge features to detect cuts as well as represent the content of a shot [2, 23]. <p> This corresponds to indexes for approximately 20 hours of typical broadcast video per megabyte. 18 6 Results In this section, we evaluate the effectiveness of our techniques for scene cut detection and video searching. First we describe some experiments performed by Gargi and Kasturi <ref> [10] </ref> with a variety of color-histogram-based scene cut detection algorithms and compare them with our wavelets-based scene cut detection algorithm. Next we describe experiments measuring the effectiveness of wavelets-based video querying. <p> Next we describe experiments measuring the effectiveness of wavelets-based video querying. Finally, we evaluate the running times of these algorithms. 6.1 Comparing Wavelets Algorithms to Color Histogram Methods Gargi and Kasturi provide an overall evaluation of color-histogram methods in video indexing <ref> [10] </ref>. Their objective was to compare several color-histogram-based methods in the literature to learn which is most effective. For their tests, they manually marked 200 ground-truth cuts in a 21,000-frame sequence containing trailers, sitcoms, dramas, commercials, news clips, outdoor wildlife scenes, news shows, and news clips.
Reference: [11] <author> Bilge Gunsel, A. Murat Tekalp, and Peter J.L. van Beek. </author> <title> Object-based video indexing for virtual studio productions. </title> <booktitle> In IEEE CVPR'97, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: Several object-based video indexing methods have been described in the literature. Nagasaka presented full-video searching technology for specified objects using features derived locally [19]. An object-based approach for temporal video partitioning and content-based indexing was presented in <ref> [11] </ref>. While nobody (to our knowledge) has previously used wavelets for video segmentation and querying, Chau presented a wavelets-based method for detecting spatial regions in a video sequence that are changing in time [3].
Reference: [12] <author> Hong heather Yu and Wayne Wolf. </author> <title> A visual search system for video and image databases. </title> <booktitle> In IEEE Multimedia, </booktitle> <year> 1997. </year>
Reference-contexts: This technology has other applications as well, such as the automatic identification of keyframes for MPEG [9] and Quicktime [21] video compression, or as a back-end process for the automatic storyboarding and searching aspects of a video library <ref> [12] </ref>. 1.1 Related Work A number of researchers have addressed video segmentation and querying. A survey of parsing and indexing technologies by Ahanger and Little [1] discusses methods mainly in the pixel domain.
Reference: [13] <author> F. Idris and S. Panchanathan. </author> <title> Indexing of compressed video sequences. </title> <booktitle> In Proc. of the SPIE Conference on Multimedia Storage and Archiving Systems, </booktitle> <volume> volume 2670, </volume> <pages> pages 247-253, </pages> <year> 1996. </year>
Reference-contexts: Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann [15, 16, 17]. They extract features from available DCT, macroblock, and motion vector information. An algorithm based on vector quantization has been proposed for indexing compressed video by Idris <ref> [13] </ref>. Several object-based video indexing methods have been described in the literature. Nagasaka presented full-video searching technology for specified objects using features derived locally [19]. An object-based approach for temporal video partitioning and content-based indexing was presented in [11].
Reference: [14] <author> Charles E. Jacobs, Adam Finkelstein, and David H. Salesin. </author> <title> Fast multiresolution image querying. </title> <booktitle> In Proceedings of SIGGRAPH '95, </booktitle> <pages> pages 277-286, </pages> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Also related to wavelets, this paper expands on our previous method for searching in an image database using wavelet decompositions of the images <ref> [14] </ref>. There are several benefits to using wavelets for video analysis. The video signal may arrive at any resolution, and may be noisy. The wavelet-based signatures we use for indexing are considerably smaller than the original video, and therefore admit a very large database in a small amount of memory. <p> For a more general presentation of wavelet analysis see one of the several excellent monographs on the subject [4, 5]; to learn about the use of wavelets in computer graphics see Stollnitz [22]. In previous work <ref> [14] </ref>, we developed a distance metric for images (a measure of how different one image is from another) based on wavelets. For that project, we focused on retrieval of images from an image database using query-by-example ("find all images that look like this image"). <p> Typically, to generalize to three-channel (color) images, one would perform the transform separately in each color channel; indeed, the image-querying technique <ref> [14] </ref> employed three color channels. In contrast, we have found that for video querying, the luminance channel is sufficient for both indexing and searching, and therefore we work only with grayscale images. <p> However, the weight given to the difference in average intensities, w a , cannot be too large, or the metric will rely too much on differences in brightness. As in our image querying metric <ref> [14] </ref>, we group the weights according to the size of the wavelet functions to which they correspond, using a simple function bin (i; j). <p> Following the same procedure as <ref> [14] </ref>, we can greatly accelerate our video querying metric. We will only consider terms in which the query signature 11 has a non-zero wavelet coefficient ~ Q [i; j; k].
Reference: [15] <author> V. Kobla, D.S. Doermann, and K-I. Lin. </author> <title> Archiving, indexing, and retrieval of video in the compressed domain. </title> <booktitle> In Proc. of the SPIE Conference on Multimedia Storage and Archiving Systems, </booktitle> <volume> volume 2916, </volume> <year> 1996. </year>
Reference-contexts: Much less work has been done in the compressed domain. Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann <ref> [15, 16, 17] </ref>. They extract features from available DCT, macroblock, and motion vector information. An algorithm based on vector quantization has been proposed for indexing compressed video by Idris [13]. Several object-based video indexing methods have been described in the literature.
Reference: [16] <author> V. Kobla, D.S. Doermann, K-I. Lin, and C. Falutsos. </author> <title> Compressed domain video indexing techniques using dct and motion vector information in mpeg video. </title> <booktitle> In Proc. of SPIE conference on Storage and Retrieval for Image and Video Database V, </booktitle> <volume> volume 3022, </volume> <pages> pages 200-211, </pages> <year> 1997. </year>
Reference-contexts: Much less work has been done in the compressed domain. Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann <ref> [15, 16, 17] </ref>. They extract features from available DCT, macroblock, and motion vector information. An algorithm based on vector quantization has been proposed for indexing compressed video by Idris [13]. Several object-based video indexing methods have been described in the literature.
Reference: [17] <author> V. Kobla, D.S. Doermann, and A. Rosenfeld. </author> <title> Compressed domain video segmentation. </title> <type> Cf AR Technical Report CAR-TR-839, </type> <year> 1996. </year>
Reference-contexts: Much less work has been done in the compressed domain. Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann <ref> [15, 16, 17] </ref>. They extract features from available DCT, macroblock, and motion vector information. An algorithm based on vector quantization has been proposed for indexing compressed video by Idris [13]. Several object-based video indexing methods have been described in the literature.
Reference: [18] <author> Stephane Mallat and Sifen Zhong. </author> <title> Wavelet transform maxima and mul-tiscale edges. </title> <editor> In Ruskai, et al, editor, </editor> <booktitle> Wavelets and Their Applications, </booktitle> <pages> pages 67-104. </pages> <publisher> Jones and Bartlett Publishers, Inc., </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: This property has been successfully exploited for lossy image compression [6]. * Wavelet decompositions can be used to extract and encode edge information <ref> [18] </ref>. Edges provide important visual cues in differentiating images. * The coefficients of a wavelet decomposition provide information that is independent of the original image resolution.
Reference: [19] <author> A. Nagasaka and Y. Tanaka. </author> <title> Automatic video indexing and full-video search for object appearances. </title> <booktitle> In Proc. of the working Conference on visual Database Systems, </booktitle> <pages> pages 119-133, </pages> <year> 1991. </year>
Reference-contexts: An algorithm based on vector quantization has been proposed for indexing compressed video by Idris [13]. Several object-based video indexing methods have been described in the literature. Nagasaka presented full-video searching technology for specified objects using features derived locally <ref> [19] </ref>. An object-based approach for temporal video partitioning and content-based indexing was presented in [11]. While nobody (to our knowledge) has previously used wavelets for video segmentation and querying, Chau presented a wavelets-based method for detecting spatial regions in a video sequence that are changing in time [3].
Reference: [20] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, P. Yanker, C. Faloutsos, and G. Taubin. </author> <title> The QBIC project: Querying images by content using color, texture, and shape. </title> <booktitle> In Storage and Retrieval for Image and Video Databases, </booktitle> <pages> pages 173-187. SPIE, </pages> <year> 1993. </year> <month> 24 </month>
Reference-contexts: Color-histogram features have been combined with motion, texture, shape, and edge features to detect cuts as well as represent the content of a shot [2, 23]. Niblack et al.describe the QBIC system, which performs content-based retrieval based on color, shape, texture, and sketches in large image and video databases <ref> [7, 20] </ref>. Much less work has been done in the compressed domain. Compressed domain parsing and indexing and retrieval of video are presented by Kobla and Doermann [15, 16, 17]. They extract features from available DCT, macroblock, and motion vector information.
Reference: [21] <author> Steven Radecki. </author> <title> Multimedia With Quicktime. </title> <publisher> Academic Press, </publisher> <year> 1993. </year> <note> ISBN 0-12-574750-0. </note>
Reference-contexts: If the corresponding segment in the database is tagged as the beginning of a commercial, then the VCR could, for example, mute the volume. This technology has other applications as well, such as the automatic identification of keyframes for MPEG [9] and Quicktime <ref> [21] </ref> video compression, or as a back-end process for the automatic storyboarding and searching aspects of a video library [12]. 1.1 Related Work A number of researchers have addressed video segmentation and querying.
Reference: [22] <author> Eric J. Stollnitz, Tony D. DeRose, and David H. Salesin. </author> <title> Wavelets for Computer Graphics: Theory and Applications. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: algorithms, and conclude in Section 7 with some areas for future research. 3 2 Wavelet Basics Wavelet analysis is a tool that has emerged relatively recently from the mathematical community and has found a variety of applications in areas such as signal processing, numerical analysis, music synthesis, and computer graphics <ref> [22] </ref>. Like Fourier analysis, a wavelet representation provides access to a set of data at various levels of detail; however, wavelets differ from Fourier analysis in that the different frequencies described by individual wavelet basis functions are localized rather than global. <p> For a more general presentation of wavelet analysis see one of the several excellent monographs on the subject [4, 5]; to learn about the use of wavelets in computer graphics see Stollnitz <ref> [22] </ref>. In previous work [14], we developed a distance metric for images (a measure of how different one image is from another) based on wavelets. For that project, we focused on retrieval of images from an image database using query-by-example ("find all images that look like this image"). <p> First, shot-change detection is similar to image searching, as it involves comparing frames of video. Second, searching for a video 4 sequence in a video database is analogous to searching for an image in an image database. There are a host of wavelet transforms in the literature <ref> [22] </ref>, each bearing different properties such as smoothness, symmetry, number of vanishing moments, and compactness of support. In this work we employ the simplest wavelets|the Haar transform|because it is the fastest transform to compute and is effective for our purposes.
Reference: [23] <author> H.J. Zhang, C.Y. Low, S.W. Smoliar, and J.H. Wu. </author> <title> Video parsing, retrieval and browsing: An integrated and content-based solution. </title> <booktitle> In Proc. of the ACM multimedia Conference, </booktitle> <pages> pages 15-24, </pages> <year> 1995. </year> <month> 25 </month>
Reference-contexts: Gargi [10] presents an overview of how well histogram methods work in different color spaces using a variety of metrics. Color-histogram features have been combined with motion, texture, shape, and edge features to detect cuts as well as represent the content of a shot <ref> [2, 23] </ref>. Niblack et al.describe the QBIC system, which performs content-based retrieval based on color, shape, texture, and sketches in large image and video databases [7, 20]. Much less work has been done in the compressed domain.
References-found: 23

