URL: http://www.cs.columbia.edu/~lerner/thesis/ebs.ps
Refering-URL: http://www.cs.columbia.edu/~lerner/thesis/
Root-URL: http://www.cs.columbia.edu
Title: Energy-Based Smooth Surface Segmentation  
Author: Michah Lerner 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences  
Date: 1993  
Affiliation: COLUMBIA UNIVERSITY  
Abstract-found: 0
Intro-found: 1
Reference: [ Allen, 1985 ] <author> P. K. Allen. </author> <title> Object Recognition Using Vision and Touch. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, Department of Computer Science., </institution> <year> 1985. </year>
Reference-contexts: A representation that is more flexible than planar or quadratic surfaces is the spline patches [ Naik and Jain, 1988 ] <ref> [ Allen, 1985 ] </ref> [ Allen, 1987 ] . These can represent any slope up to the (m 1) th degree of the spline. Thus, a smaller number of patches may be used.
Reference: [ Allen, 1987 ] <author> P. K. Allen. </author> <title> Robotic Object Recognition Using Vision and Touch. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1987. </year>
Reference-contexts: A representation that is more flexible than planar or quadratic surfaces is the spline patches [ Naik and Jain, 1988 ] [ Allen, 1985 ] <ref> [ Allen, 1987 ] </ref> . These can represent any slope up to the (m 1) th degree of the spline. Thus, a smaller number of patches may be used. Both non-planar surfaces, 31 as well as planar patches, can be represented, since splines can twist and bend.
Reference: [ Anandan and Weiss, 1985 ] <author> P. Anandan and R. Weiss. </author> <title> Introducing a smoothness constraint in a matching approach for the computation of displacement fields. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pages 186-195. DARPA, </pages> <year> 1985. </year>
Reference-contexts: in surface reconstruction, disparity field recovery and certain classes of motion detection problems have been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see [ Terzopoulos, 1984 ] , [ Blake and Zisserman, 1986a ] , [ Hoff and Ahuja, 1985 ] , <ref> [ Anandan and Weiss, 1985 ] </ref> , [ Boult and Chen, 1988a ] , [ Chou and Brown, 1990 ] .
Reference: [ Bajcsy and Solina, 1987 ] <editor> R. Bajcsy and F. Solina. </editor> <title> Three dimensional object representation revisted. </title> <booktitle> In Proceedings of the IEEE Computer Society International Conference on Computer Vision, </booktitle> <pages> pages 231-240. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Step 3 Adjust the reconstruction mechanism to deal with the newly-marked dis continuities and return to Step 1. Other segmentation approaches for surface reconstruction have incorporated smooth measures implied by volumetric models (see [ Rao et al., 1987 ] , [ Pentland, 1986 ] , <ref> [ Bajcsy and Solina, 1987 ] </ref> ), or local smoothness properties such as planarity or curvature consistency (see [ Besel and Jain, 1986 ] ). The smoothness-based approach recovers individual surfaces by use of minimal surface bending-energy.
Reference: [ Bates and Wahba, 1982 ] <author> D. Bates and G. Wahba. </author> <title> Computational methods for generalized cross-validation with large data sets. </title> <editor> In C.T.H. Baker and G.F. Miller, editors, </editor> <title> Treatment of Integral Equations by Numerical Methods, </title> <address> pages 283-296. </address> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: A desirable modification of CV is known as Generalized Cross Validation (GCV) and possess appealing properties. GCV is a technique for computation of both the kernel splines and in a single coordinate process, provided that only one surface is being reconstructed <ref> [ Bates and Wahba, 1982 ] </ref> . While GCV can find also discontinuities, this is very expensive. In segmentation algorithms, however, the points on a surface are not known until segmentation has been completed. These points may even be removed by culprit deletion.
Reference: [ Besel and Jain, 1986 ] <author> P. J. Besel and R. C. Jain. </author> <title> Segmentation through symbolic surface description. </title> <booktitle> In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 77-85. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference-contexts: Other segmentation approaches for surface reconstruction have incorporated smooth measures implied by volumetric models (see [ Rao et al., 1987 ] , [ Pentland, 1986 ] , [ Bajcsy and Solina, 1987 ] ), or local smoothness properties such as planarity or curvature consistency (see <ref> [ Besel and Jain, 1986 ] </ref> ). The smoothness-based approach recovers individual surfaces by use of minimal surface bending-energy. This contrasts with segmentation into structural descriptions, for example, a tree of fixed-curvature patches.
Reference: [ Besl and Jain, 1986 ] <author> P. J. Besl and R. C. Jain. </author> <title> Invariant surface characteristics for 3d object recognition in range images. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 33 </volume> <pages> 33-80, </pages> <year> 1986. </year>
Reference-contexts: The primary workers in this fields are Besl and Jain. 2.2.1 Besl and R.C. Jain Besl and Jain approach the problem of partitioning image arrays into low-level entities, namely regions of arbitrary shape as approximated by bivariate functions 26 <ref> [ Besl and Jain, 1986 ] </ref> [ Besl and Jain, March 1988 ] . Other researchers make unnecessarily restrictive assumptions about object shape, curvature, similarity of regions, and edge shape. The single less restrictive assumption in this work is surface coherence. <p> Many random walks (with associated surface and energy computations) are formed from the same initial point. One of these surfaces will be selected as the seed surface (see Alg II-d). It is insightful to note the similarity of this technique to the region-growing methods (such as <ref> [ Besl and Jain, 1986 ] </ref> ) in use with the domain of regularly spaced and dense data. In the latter case the near neighbors are simply those points which are grid-neighbors in the dense sample. <p> The experimental discussion of merging is found in section 10.3. 7.1.3 Merging: Discussion and Conclusion Merging either of regions or of surfaces is prevalent in segmentation research. The HK-map algorithm of <ref> [ Besl and Jain, 1986 ] </ref> [ Besl and Jain, March 1988 ] depends heavily upon region merging to join compatibly-signed regions in merge steps. Topologically adjacent regions which share a uniformity predicate can be joined into one region.
Reference: [ Besl and Jain, March 1988 ] <author> P. J. Besl and R. C. Jain. </author> <title> Segmentation through variable-order surface fitting. </title> <journal> IEEE PAMI, </journal> <volume> 10(2) </volume> <pages> 167-192, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: The primary workers in this fields are Besl and Jain. 2.2.1 Besl and R.C. Jain Besl and Jain approach the problem of partitioning image arrays into low-level entities, namely regions of arbitrary shape as approximated by bivariate functions 26 [ Besl and Jain, 1986 ] <ref> [ Besl and Jain, March 1988 ] </ref> . Other researchers make unnecessarily restrictive assumptions about object shape, curvature, similarity of regions, and edge shape. The single less restrictive assumption in this work is surface coherence. Image data is interpreted as noisy samples of piecewise smooth surfaces. <p> The authors can continuously evaluate the reconstruction, as they note: In this surface-based segmentation algorithm every pixel in every region is constantly checked to see how close the sensed value at a given pixel is to the approximating surface function for the given region <ref> [ Besl and Jain, March 1988 ] </ref> , (pg 173). This is easy to do, since the fit can be assessed by subtracting the surface from its representation. <p> In the edge approach, they identify jump edges (discontinuous depth), crease edges (discontinuous surface normals), and smooth edges (continuous normal with discontinuous curvature). However, since there are no reliable crease edge detectors, they find it necessary to consider the alternative of region-based approaches. We will note that Besl <ref> [ Besl and Jain, March 1988 ] </ref> criticizes the edge-based approach for a different 30 reason, namely that it introduced unnecessary constraints. Hoffman and Jain use the region approach by merging object faces according to scene-dependent parameters. <p> The surface patches can be established from information about depth, orientation of surface normals. Higher order quadratic patches allow greater variation within each patch. For example, quadratic surface patches allow variation in each surface patch, and variable-order surfaces <ref> [ Besl and Jain, March 1988 ] </ref> combines several orders of surfaces in a coarse-to-fine approach. A representation that is more flexible than planar or quadratic surfaces is the spline patches [ Naik and Jain, 1988 ] [ Allen, 1985 ] [ Allen, 1987 ] . <p> The experimental discussion of merging is found in section 10.3. 7.1.3 Merging: Discussion and Conclusion Merging either of regions or of surfaces is prevalent in segmentation research. The HK-map algorithm of [ Besl and Jain, 1986 ] <ref> [ Besl and Jain, March 1988 ] </ref> depends heavily upon region merging to join compatibly-signed regions in merge steps. Topologically adjacent regions which share a uniformity predicate can be joined into one region.
Reference: [ Bhanu and Nuttall, 1989 ] <author> B. Bhanu and L. A. Nuttall. </author> <title> Recognition of 3-d objects in range images using a butterfly multiprocessor. </title> <journal> Pattern Recognition, </journal> <volume> 22(1) </volume> <pages> 49-64, </pages> <year> 1989. </year> <month> 293 </month>
Reference-contexts: There are other notable representation techniques. Fractal-based methods [ Pentland, November 1984 ] can approximate the roughness of a surface. Volumetric segmentation are studied in [ Solina, 1987 ] . Model-based primitives bear a resemblance to template matching, and are developed <ref> [ Bhanu and Nuttall, 1989 ] </ref> for specific scenes using range finder data. The expected scene items are measured in a laboratory and described by simplified feature sets obtained, for example, from histograms.
Reference: [ Blake and Zisserman, 1986a ] <author> A. Blake and A. Zisserman. </author> <title> Invariant surface reconstruction using weak continuity constraints. </title> <booktitle> In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 62-68. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference-contexts: Of these, the segmentation tasks in surface reconstruction, disparity field recovery and certain classes of motion detection problems have been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see [ Terzopoulos, 1984 ] , <ref> [ Blake and Zisserman, 1986a ] </ref> , [ Hoff and Ahuja, 1985 ] , [ Anandan and Weiss, 1985 ] , [ Boult and Chen, 1988a ] , [ Chou and Brown, 1990 ] . <p> In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , <ref> [ Blake and Zisserman, 1986a ] </ref> , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. <p> The results are compared with the Gauss-Seidel method under a number of metrics, including convergence rate and exact machine instruction counts. The significance of this work is the capacity to accelerate the solution of minimization problems, including those defined by Grimson and Terzopoulos. 2.1.5 Blake and Zisserman In <ref> [ Blake and Zisserman, 1986a ] </ref> [ Blake and Zisserman, 1986b ] Blake and Zisserman incorporate discontinuities into optimization problems by use of "weak constraints." These constraints model an elastic string which can be broken at finite cost. <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , <ref> [ Blake and Zisserman, 1986a ] </ref> , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface.
Reference: [ Blake and Zisserman, 1986b ] <author> A. Blake and A. Zisserman. </author> <title> Weak continuity constraints in computer vision. </title> <type> Technical report, </type> <institution> University of Edingurgh, 1986. Department of Computer Science, </institution> <note> TR# CSR-197-86. </note>
Reference-contexts: The significance of this work is the capacity to accelerate the solution of minimization problems, including those defined by Grimson and Terzopoulos. 2.1.5 Blake and Zisserman In [ Blake and Zisserman, 1986a ] <ref> [ Blake and Zisserman, 1986b ] </ref> Blake and Zisserman incorporate discontinuities into optimization problems by use of "weak constraints." These constraints model an elastic string which can be broken at finite cost. <p> This model is implemented as a reconstruction of minimum bending-energy surfaces. Augmentation are to merge surfaces when they are sufficiently close, and also to add points in the sequence of increasing energy con 36 tribution. A somewhat different approach is taken by <ref> [ Blake and Zisserman, 1986b ] </ref> (see below), who impose a cost on the number of surfaces or bins. <p> It is therefore at least as hard as Minimum Sum of Squares. Method of Breakpoint Location A similar multi-surface segmentation problem has been discussed by <ref> [ Blake and Zisserman, 1986b ] </ref> , who describes segmentation of 1D and 2D samples into "bins" of data. <p> This describes the segmentation as a minimization problem which imposes an energy penalty for starting a new surface, and then trades between the cost of making additional surfaces and the energy on the surface itself <ref> [ Blake and Zisserman, 1986b ] </ref> Though the formulation is extremely attractive, the computational methods necessary to find a minimizing solution are very expensive. They also raise a calibration issue, namely to determine the cost of a new free-form surface.
Reference: [ Boult and Chen, 1988a ] <author> T. E. Boult and L. H. Chen. </author> <title> Synergistic smooth surface stereo. </title> <booktitle> In Proceedings of the IEEE Computer Society International Conference on Computer Vision, </booktitle> <year> 1988. </year>
Reference-contexts: certain classes of motion detection problems have been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see [ Terzopoulos, 1984 ] , [ Blake and Zisserman, 1986a ] , [ Hoff and Ahuja, 1985 ] , [ Anandan and Weiss, 1985 ] , <ref> [ Boult and Chen, 1988a ] </ref> , [ Chou and Brown, 1990 ] . In each of these cases, the attempt at segmentation can be roughly described as follows: Step 1 Perform an initial smoothness-based reconstruction (this is generally a min imal energy surface or configuration).
Reference: [ Boult and Chen, 1988b ] <author> T. E. Boult and L. H. Chen. </author> <title> Synergistic smooth surface stereo. </title> <booktitle> In CVPR-88, </booktitle> <pages> pages 118-122. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: They conclude that reproducing kernel splines are a good method for interpolating sparse depth data; we pursue this in the current research. In subsequent work [ Chen and Boult, 1988 ] <ref> [ Boult and Chen, 1988b ] </ref> , a prototype surface segmentation method was built to demonstrate this minimum energy 23 principle. This uses the local energy minimization method, sets the maximum allowable surface energy statically, and groups points according to their ambiguity.
Reference: [ Boult and Kender, 1986 ] <author> T. E. Boult and J. R. Kender. </author> <title> Visual surface reconstruction using sparse depth data. </title> <booktitle> In CVPR-86, </booktitle> <pages> pages 68-76. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference-contexts: Sadly, the hybrid approach captures the worst of both representations. It has the representational disadvantage of a gradient limit on the membranes, and it also has the computational disadvantage of an expensive computation for the plate parameters. 2.1.6 Boult In <ref> [ Boult and Kender, 1986 ] </ref> Boult and Kender describe methods that find a surface which minimizes a given unreasonableness function. They formulate the problem for approximation or interpolation, and they restrict the unreasonableness with a norm (or semi-norm). <p> Although there is no non-trivial bound on the run time for segmentation, the cost for surface reconstruction is O (m 3 ) + O (mn) (for m data points and n reconstruction points) <ref> [ Boult and Kender, 1986 ] </ref> . This contrasts to O (n 2 ) for finite-element methods [ Terzopoulos, 1983 ] . We accelerate computation by use of a closed-form expression of the norm, and we further accelerate the computation with a parallel computer.
Reference: [ Boult, 1986 ] <author> T. E. Boult. </author> <title> Information Based Complexity in Non-Linear Equations and Computer Vision. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1986. </year>
Reference-contexts: surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , <ref> [ Boult, 1986 ] </ref> , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. <p> The visual interpolation approach finds f fl 2 F 1 such that kf fl k F 1 is minimum over all functions in F 1 <ref> [ Boult, 1986 ] </ref> . This process does not smooth the data. <p> The degree of interpolation and approximation are controlled by , with a pure interpolation approach as ! 0 <ref> [ Boult, 1986 ] </ref> . <p> The important properties of these splines include their well-defined degree of smoothness, and the fact they recover the unique function which minimizes a given norm (i.e., energy) for the data. This assumed model of world surfaces is intimately related to techniques for regularized surface reconstruction, see <ref> [ Boult, 1986 ] </ref> , as will be discussed. 1 These are defined except on sets of measure zero, i.e. points. 44 One can control both the smoothness of the class, as well as the zero-energy surfaces which belong to the model (i.e. the nullspace), by adjusting the values of m <p> bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , <ref> [ Boult, 1986 ] </ref> , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. A significant special 47 case consider of the representation, m = 2; = 0. <p> There are several other means to obtain the smoothest (most reasonable) function. These include discrete minimization, finite-element / multi-resolution methods, and quotient reproducing splines <ref> [ Boult, 1986 ] </ref> (pg 114), although these methods are beyond the 50 scope of this dissertation. An essential ingredient of the current algorithm, at least from the point of view of efficient serial implementation, is the use of the reproducing kernel-based spline reconstruction as described in [ Boult, 1986 ] <p> quotient reproducing splines <ref> [ Boult, 1986 ] </ref> (pg 114), although these methods are beyond the 50 scope of this dissertation. An essential ingredient of the current algorithm, at least from the point of view of efficient serial implementation, is the use of the reproducing kernel-based spline reconstruction as described in [ Boult, 1986 ] . <p> property of the reproducing kernel spline is that "the solution to the problem of finding an interpolating function of minimal norm in the semi-Hilbert setting could be written down in terms of K F 1 ((x; y); (x i ; y j )), the reproducing kernel of F 1 " <ref> [ Boult, 1986 ] </ref> (page 109). The key problem is to obtain the kernel and norm; despite existence the kernel's derivation can be difficult. The problem has been studied extensively by [ Duchon, 1976 ] and more recently by [ Shiau, 1985 ] .
Reference: [ Brady et al., 1985 ] <author> M. J. Brady, A. Ponce, and Y. H. Asada. </author> <title> Describing surfaces. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 1-28, </pages> <year> 1985. </year>
Reference-contexts: The resulting surfaces are merged at the boundaries of adjacent patches. 2.3 Summary In summary of the survey section, we note the main representations that have been exploited by vision researchers for the surface segmentation and reconstruction problems. For a survey of representations, see <ref> [ Brady et al., 1985 ] </ref> . Planar surface patches [ Taylor et al., 1989 ] partition the image into many small windows which can each be approximated by a planar surface patch. The surface patches can be established from information about depth, orientation of surface normals.
Reference: [ Chen and Boult, 1988 ] <author> L. H. Chen and T. E. Boult. </author> <title> An integrated approach to stereo matching, surface reconstruction and depth segmentation using consistent smoothness assumptions. </title> <booktitle> In Image Understanding Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: They conclude that reproducing kernel splines are a good method for interpolating sparse depth data; we pursue this in the current research. In subsequent work <ref> [ Chen and Boult, 1988 ] </ref> [ Boult and Chen, 1988b ] , a prototype surface segmentation method was built to demonstrate this minimum energy 23 principle. This uses the local energy minimization method, sets the maximum allowable surface energy statically, and groups points according to their ambiguity.
Reference: [ Choi and Kender, 1985 ] <author> D. J. Choi and J. R. Kender. </author> <title> Solving the depth interpolation problem with adaptive chebyshev acceleration method on a parallel computer. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pages 219-223. DARPA, </pages> <year> 1985. </year>
Reference-contexts: to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , <ref> [ Choi and Kender, 1985 ] </ref> . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. <p> to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , <ref> [ Choi and Kender, 1985 ] </ref> . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. A significant special 47 case consider of the representation, m = 2; = 0.
Reference: [ Choi, 1988 ] <author> D. G. Choi. </author> <title> Solving the Depth Interpolation Problem on a Parallel Architecture with Efficient Numerical Methods. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1988. </year>
Reference-contexts: Neither of these is particularly fast for parallel computation, and Choi's thesis <ref> [ Choi, 1988 ] </ref> presents a detailed analysis of improved methods. Grimson's work obtains its data from a standard stereo method that measures the angular difference (disparity) between several imaging devices of known separation (e.g. two cameras with a fixed baseline) and a number of unique points in the scene. <p> Terzopoulos therefore uses the regularization method to reformulate the problem as a well-posed problem of variational calculus. We make the critical note that Terzopoulos does not minimize the number of surfaces. Terzopoulos' work is reviewed in detail by <ref> [ Choi, 1988 ] </ref> . 18 Terzopoulos combines 2 kinds of functions. The energy functional is: E (v) = S (v) + P (v) where S is a stabilizer function and P is a penalty function.
Reference: [ Chou and Brown, 1990 ] <author> P. Chou and C. Brown. </author> <title> 294 The theory and practice of bayesian image labeling. </title> <journal> International Journal of Computer Vision, </journal> <pages> page 49, </pages> <year> 1990. </year>
Reference-contexts: been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see [ Terzopoulos, 1984 ] , [ Blake and Zisserman, 1986a ] , [ Hoff and Ahuja, 1985 ] , [ Anandan and Weiss, 1985 ] , [ Boult and Chen, 1988a ] , <ref> [ Chou and Brown, 1990 ] </ref> . In each of these cases, the attempt at segmentation can be roughly described as follows: Step 1 Perform an initial smoothness-based reconstruction (this is generally a min imal energy surface or configuration).
Reference: [ Cohen and Cohen, 1990 ] <author> L. D. Cohen and I. Cohen. </author> <title> A finite element method applied to new active contour models and 3d reconstruction from cross sections. </title> <type> Technical Report Technical report no. 1245, </type> <institution> Intitut National de Recherche en Informatique et en Automatique, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: The use of an attribute graph, combined with the multilevel resolution (low-medium-fine) and an energy model, is a combination of powerful cooperating methods. 2.1.8 Cohen, Cohen and Ayach This research uses deformable surfaces to segment 3D images by use of a finite element method, as described in detail in <ref> [ Cohen and Cohen, 1990 ] </ref> [ Cohen et al., 1991 ] [ Cohen et al., 1992 ] . Active contours are a deformable model, with mechanical properties such as elasticity and rigidity. The energy of these is modelled by the finite element method.
Reference: [ Cohen et al., 1991 ] <author> I. Cohen, L. D. Cohen, and N. Ayache. </author> <title> Introducing deformable surfaces to segment 3d images and infer differential structures. </title> <type> Technical Report Technical report no. 1403, </type> <institution> Intitut National de Recherche en Informatique et en Automatique, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: graph, combined with the multilevel resolution (low-medium-fine) and an energy model, is a combination of powerful cooperating methods. 2.1.8 Cohen, Cohen and Ayach This research uses deformable surfaces to segment 3D images by use of a finite element method, as described in detail in [ Cohen and Cohen, 1990 ] <ref> [ Cohen et al., 1991 ] </ref> [ Cohen et al., 1992 ] . Active contours are a deformable model, with mechanical properties such as elasticity and rigidity. The energy of these is modelled by the finite element method.
Reference: [ Cohen et al., 1992 ] <author> I. Cohen, L. D. Cohen, and N. Ayache. </author> <title> Using deformable surfaecs to segment 3d images and infer differential structures. </title> <booktitle> In Second ECCV 92, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: (low-medium-fine) and an energy model, is a combination of powerful cooperating methods. 2.1.8 Cohen, Cohen and Ayach This research uses deformable surfaces to segment 3D images by use of a finite element method, as described in detail in [ Cohen and Cohen, 1990 ] [ Cohen et al., 1991 ] <ref> [ Cohen et al., 1992 ] </ref> . Active contours are a deformable model, with mechanical properties such as elasticity and rigidity. The energy of these is modelled by the finite element method.
Reference: [ Daniel et al., 1976 ] <author> J.W. Daniel, W.B. Gragg, L. Kaufman, and G. W. Stewart. </author> <title> Reorthogonalization and stable algorithms for updating the gram-schmidt qr factorization. </title> <journal> Math. Comp., </journal> <volume> 30 </volume> <pages> 722-795, </pages> <year> 1976. </year>
Reference-contexts: The surface is defined by the solution to a linear system which depends only on the location of the data. If the solution to this system can be updated quickly, the surface can also be updated quickly. Updates are performed with the Bragg-Stewart updatable QR method <ref> [ Daniel et al., 1976 ] </ref> , which permits the addition and deletion of arbitrary rows and columns. This permits deletion of arbitrary points with their constraints. This is important when the segmenter makes an error that must be corrected. <p> The Bragg-Stewart updateable QR method <ref> [ Daniel et al., 1976 ] </ref> is an important component in the implementation because it permits the incremental updating of the linear system which describes the splines and recovers their parameters.
Reference: [ Duchon, 1976 ] <author> J. Duchon. </author> <title> Interpolation de fonctions de deux variables suivant le principe de la flexion des plaques minces. </title> <journal> Revue Francaise d'Automatique, Informatique et Recherche Operationnelle, </journal> <pages> pages 5-12, </pages> <month> December </month> <year> 1976. </year>
Reference-contexts: Surface reconstruction is viewed as a function recovery problem. The surfaces can be described as functions, and for a suitable representation of functions the behavior may be described by the smoothness. The reproducing kernel spline (RKS) <ref> [ Duchon, 1976 ] </ref> is one formalism which can represent functions of specific smoothing classes. A smoothness-based surface recovery method constructs the smoothing splines from a data sample to obtain the surface which minimizes a given norm. <p> In other words H s = F (1 + jt j 2 ) s=2 L 2 . It is a Hilbert space <ref> [ Duchon, 1976 ] </ref> . A refinement of H s (R n ) is the space D m H s , also referred to as D m H . This is the space of all functions with the m th derivative in H s . <p> This space has associated splines which are defined via convolution with appropriate smoothing kernels. At this point it should be noted that a key property of this space is the existence of splines that uniquely recover functions which minimize the semi-norm on the space. Theorem 4bis of <ref> [ Duchon, 1976 ] </ref> states: Then there exists exactly one function (in D m H ) of the form (t) = a2A a K 2m+2sn (t a) + p (t) ... taking prescribed values on A. <p> The key problem is to obtain the kernel and norm; despite existence the kernel's derivation can be difficult. The problem has been studied extensively by <ref> [ Duchon, 1976 ] </ref> and more recently by [ Shiau, 1985 ] . They give many reproducing kernels and show that these solve the regularized problem. <p> They give many reproducing kernels and show that these solve the regularized problem. For a more gentle discussion of kernel splines see [ Eubank, 1988 ] , which shows various ways to develop multivariate smoothing splines such as those of <ref> [ Duchon, 1976 ] </ref> , [ Meinguet, 1983 ] and [ Wahba, 1984 ] . <p> Multiplication has a dampening or smoothing effect, which is exactly what one should expect since convolution is simply multiplication in Fourier space <ref> [ Duchon, 1976 ] </ref> .
Reference: [ Eubank, 1988 ] <author> R. L. Eubank. </author> <title> Spline Smoothing and Nonparametric Regression. </title> <publisher> Dekker, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: The problem has been studied extensively by [ Duchon, 1976 ] and more recently by [ Shiau, 1985 ] . They give many reproducing kernels and show that these solve the regularized problem. For a more gentle discussion of kernel splines see <ref> [ Eubank, 1988 ] </ref> , which shows various ways to develop multivariate smoothing splines such as those of [ Duchon, 1976 ] , [ Meinguet, 1983 ] and [ Wahba, 1984 ] . <p> Fourier coefficients from the data, dampening of the Fourier coefficients ^ fi j by multiplication with kernel K j, and estimators that "use all the Fourier coefficients, but for larger , relies primarily on the information from low frequencies by down weighting the contributions of higher frequencies to the estimators" <ref> [ Eubank, 1988 ] </ref> (pg 124). Note that the dampening of Fourier coefficients by multiplication is the vector product operation of the filtering-by-convolution.
Reference: [ Fan et al., 1986 ] <author> T. J. Fan, G. Medioni, and R. Nevatia. </author> <title> Description of surfaces from range data using curvature properties. </title> <booktitle> In CVPR-86, </booktitle> <pages> pages 86-91. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference-contexts: The algorithm then extracts and localizes significant features by "scale-space filtering," and interprets the curvature in terms of physical properties. The filtering is essentially a coarse-to-fine set of Gaussian filters. The implementation issues include Gaussian smoothing, curvature computation, and zero-crossing finding, as well as merging and linking regions <ref> [ Fan et al., 1986 ] </ref> [ Fan et al., 1988 ] . The authors give examples to show that several sizes of filters and multiple curvature detectors are important.
Reference: [ Fan et al., 1988 ] <author> T. J. Fan, G. Medioni, and R. Nevatia. </author> <title> Desciption of surfaces and range data using curvature properties. In CVPR-88, page 86. </title> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: The filtering is essentially a coarse-to-fine set of Gaussian filters. The implementation issues include Gaussian smoothing, curvature computation, and zero-crossing finding, as well as merging and linking regions [ Fan et al., 1986 ] <ref> [ Fan et al., 1988 ] </ref> . The authors give examples to show that several sizes of filters and multiple curvature detectors are important. In particular, a saddle point presents confusing information about the major and minor curvature axes k 1 ; k 2 and the system sometimes interchanges these.
Reference: [ Franke, 1982 ] <author> R. Franke. </author> <title> Smooth interpolation of scattered data by local thin plate splines. </title> <journal> Comp. & Math. with Applications, </journal> <volume> 8(4) </volume> <pages> 273-281, </pages> <year> 1982. </year>
Reference-contexts: a tree is very energetic when viewed from closeup. 1.2.1 Energy Measure In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , <ref> [ Franke, 1982 ] </ref> , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , <ref> [ Franke, 1982 ] </ref> , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] .
Reference: [ Garey and Johnson, 1979 ] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A guide to the theory of NP-completeness. W.H. </title> <publisher> Freeman, </publisher> <address> San Fransisco, </address> <year> 1979. </year> <month> 295 </month>
Reference-contexts: The details of the point-adding are described in chapter 5. Note that ambiguous data samples are permitted to appear on multiple surfaces ( T n1 37 3.1.4 NP-hardness of MSVR/A The problem is NP-hard by reduction to the Minimum Sum of Squares (MSS) <ref> [ Garey and Johnson, 1979 ] </ref> (problem SP19). An instance of MSS is a finite set A, a size s (a) 2 Z + ja 2 A, positive integers K jAj, and J .
Reference: [ Grimson, 1981 ] <author> W. E. L. </author> <title> Grimson. From Images to Surfaces: A Computational Study of the Human Visual System. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1981. </year>
Reference-contexts: As an example, the bark of a tree is very energetic when viewed from closeup. 1.2.1 Energy Measure In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see <ref> [ Grimson, 1981 ] </ref> , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> An interpolating surface description can be computed from the sketch to provide depth values at any point. Such a description should describe the discontinuities of the scene, and should permit easy identification of the distinct surfaces. However, these goals cannot be achieved by Grimson's model <ref> [ Grimson, 1981 ] </ref> because it does not include segmentation. Methods that add segmentation to the 2 1 2 D sketch would often require a secondary process (such as boundary detection) to distinguish between the multiple surfaces 1 . <p> This visual surface interpolation problem is to find the unique surface minimizing a smoothness functional. He chose the quadratic variation: ( Z 1 Z 1 @x 2 + 2 @ 2 f 2 @y 2 ! ) 1 though he discusses several other possible functionals <ref> [ Grimson, 1981 ] </ref> . Grimson then presents several computational methods to solve the abstract problem. <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see <ref> [ Grimson, 1981 ] </ref> , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] .
Reference: [ Hoff and Ahuja, 1985 ] <author> W. Hoff and N. Ahuja. </author> <title> Surfaces from stereo. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pages 98-106. DARPA, </pages> <year> 1985. </year>
Reference-contexts: Of these, the segmentation tasks in surface reconstruction, disparity field recovery and certain classes of motion detection problems have been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see [ Terzopoulos, 1984 ] , [ Blake and Zisserman, 1986a ] , <ref> [ Hoff and Ahuja, 1985 ] </ref> , [ Anandan and Weiss, 1985 ] , [ Boult and Chen, 1988a ] , [ Chou and Brown, 1990 ] . <p> when viewed from closeup. 1.2.1 Energy Measure In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , <ref> [ Hoff and Ahuja, 1985 ] </ref> , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , <ref> [ Hoff and Ahuja, 1985 ] </ref> , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] .
Reference: [ Hoff and Ahuja, 1987 ] <author> W. Hoff and N. Ahuja. </author> <title> Extracting surfaces from stereo images: an integrated approach. </title> <booktitle> In Proceedings of the IEEE Computer Society International Conference on Computer Vision, </booktitle> <pages> pages 284-294. </pages> <publisher> IEEE, </publisher> <year> 1987. </year>
Reference-contexts: This results in a difficult chicken-and-egg problem. To make matters worse, the quality of the reconstruction in the neighborhood of an unmarked (i.e., as yet undetected) discontinuity is generally poor. Thus, the localization of the discontinuity by use of iterative reconstruction/segmentation approaches, see [ Terzopoulos, 1984 ] or <ref> [ Hoff and Ahuja, 1987 ] </ref> , will be questionable.
Reference: [ Hoff and Ahuja, February 1989 ] <author> W. Hoff and N. Ahuja. </author> <title> Surfaces from stereo: Integrating feature matching, disparity estimation, and contour detection. </title> <journal> IEEE PAMI, </journal> <volume> 11(2) </volume> <pages> 121-136, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: In particular, a saddle point presents confusing information about the major and minor curvature axes k 1 ; k 2 and the system sometimes interchanges these. This particular question can be resolved by Gaussian smoothing and the scale-space filtering. 2.2.3 Hoff and Ahuja In <ref> [ Hoff and Ahuja, February 1989 ] </ref> Hoff considers the problem of constructing 3D surfaces from stereo data, following the approach of detecting and combining surface patches. He combined two constraints: constant-local-disparity and figural 29 continuity.
Reference: [ Hoffman and Jain, September 1987 ] <author> R. Hoffman and A. K. Jain. </author> <title> Segmentation and classification of range images. </title> <journal> IEEE PAMI, </journal> <volume> 9(5) </volume> <pages> 608-620, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: This is due to the source of depth data (depth-from-stereo). The disparity of horizontal edges cannot be measured with horizontal cameras; similarly, textureless images (or sparsely featured images) need to be processed by some other method. 2.2.4 Hoffman and A.K. Jain The approach of Hoffman <ref> [ Hoffman and Jain, September 1987 ] </ref> taxonomized all approaches as either edge detecting or region-growing/clustering. In the edge approach, they identify jump edges (discontinuous depth), crease edges (discontinuous surface normals), and smooth edges (continuous normal with discontinuous curvature).
Reference: [ Jou and Bovik, 1988 ] <author> J. Y. Jou and A. C. Bovik. </author> <title> Improving visible-surface reconstruction. </title> <booktitle> In CVPR88, </booktitle> <pages> pages 138-143. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: We do not "activate" transparent surface interpretation. 19 2.1.3 Jou and Bovik These researchers make significant use of discontinuity information to accelerate the process of minimizing the surface energy with a finite-element approximation (FEM) <ref> [ Jou and Bovik, 1988 ] </ref> . Depth data is obtained from triangulation. Possible depth discontinuities are obtained from irradiance discontinuities (edges). These edges indicate (1) depth discontinuities, (2) surface orientation discontinu-ities, (3) rate variation in reflectance, or (4) incident illumination discontinuities.
Reference: [ Julesz, 1971 ] <author> B. Julesz. </author> <title> Foundations of Cyclopean Perception. </title> <publisher> University of Chiage Press, </publisher> <address> Chiago, IL, </address> <year> 1971. </year>
Reference-contexts: A final remark about traditional segmentation is related to the definition of "boundaries." It is well known that the perceived "boundaries" of surfaces in depth share many characteristics with subjective contours, see <ref> [ Julesz, 1971 ] </ref> , [ Marr, 1981 ] . This suggests that a definition of "boundaries" in depth might be accomplished by some secondary processing which is shared with "boundary" detection from other visual modalities.
Reference: [ Lee, 1985 ] <author> D. Lee. </author> <title> Contributions to Information-based Complexity, Image Understanding, and Logic Circuit Design. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1985. </year>
Reference-contexts: domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , <ref> [ Lee, 1985 ] </ref> , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface. <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , <ref> [ Lee, 1985 ] </ref> , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . Bending energy thus seems a natural choice for the "measure" to determine if a group of points belong to the same surface.
Reference: [ Li, 1990 ] <author> S. Z. Li. </author> <title> Invariant surface segmentation through energy minimization with discontinuties. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 161-194, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: We accelerate computation by use of a closed-form expression of the norm, and we further accelerate the computation with a parallel computer. This method has computational advantages compared to Terzopoulos' method. 24 In recent work of <ref> [ Li, 1990 ] </ref> the segmentation of range images is performed by estimation of curvature images and optimization of a two-term energy function. This work utilizes the viewpoint-independent surface representation of mean curvature and Gaussian curvature, and builds an attribute relation graph. <p> This is consistent with the current trend in vision systems to develop multi-level processes. The lowest level forms hypotheses, which are considered and modified at higher levels. Energy can provide an effective means to formulate these hypotheses. Indeed the recent work of <ref> [ Li, 1990 ] </ref> utilizes energy-based methods at the low, medium, and high-ends of a hierarchical algorithm. 292
Reference: [ Marr, 1981 ] <author> D. Marr. </author> <title> VISION. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1981. </year>
Reference-contexts: A final remark about traditional segmentation is related to the definition of "boundaries." It is well known that the perceived "boundaries" of surfaces in depth share many characteristics with subjective contours, see [ Julesz, 1971 ] , <ref> [ Marr, 1981 ] </ref> . This suggests that a definition of "boundaries" in depth might be accomplished by some secondary processing which is shared with "boundary" detection from other visual modalities.
Reference: [ Meinguet, 1983 ] <author> J. Meinguet. </author> <title> Surface spline interpolation: Basic theory and computational aspects. </title> <institution> Institut de Mathematique Pure dt Appliquee, Universite Catholique de Louvain, </institution> <month> 35, </month> <year> 1983. </year> <month> 296 </month>
Reference-contexts: They give many reproducing kernels and show that these solve the regularized problem. For a more gentle discussion of kernel splines see [ Eubank, 1988 ] , which shows various ways to develop multivariate smoothing splines such as those of [ Duchon, 1976 ] , <ref> [ Meinguet, 1983 ] </ref> and [ Wahba, 1984 ] .
Reference: [ Naik and Jain, 1988 ] <author> S. M. Naik and R. C. Jain. </author> <title> Spline-based surface fitting on range images for cad applications. </title> <booktitle> In CVPR-88, </booktitle> <pages> pages 249-253. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: For example, quadratic surface patches allow variation in each surface patch, and variable-order surfaces [ Besl and Jain, March 1988 ] combines several orders of surfaces in a coarse-to-fine approach. A representation that is more flexible than planar or quadratic surfaces is the spline patches <ref> [ Naik and Jain, 1988 ] </ref> [ Allen, 1985 ] [ Allen, 1987 ] . These can represent any slope up to the (m 1) th degree of the spline. Thus, a smaller number of patches may be used.
Reference: [ Oden and Reddy, 1976 ] <author> J. T. Oden and J. N. Reddy. </author> <title> Introduction to the Mathematical Theory of Finite Elements. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: This definition is formed with respect to the Fourier transform on distributions, due to the possibility of discontinuities in the functions <ref> [ Oden and Reddy, 1976 ] </ref> . <p> The Fourier transform is extended to distributions by consideration of the space of functions with rapid decay: S = S (R n ) = f : x fi D ff 2 L 2 (R n ); 8ff and fi 2 Z n 45 It is known <ref> [ Oden and Reddy, 1976 ] </ref> that for every 2 S there is a Fourier transform ^ 2 S, and that Fourier transforms of distributions can be defined according to the rule: h^q; i = hq; ^ i: Thus u 2 L 2 (R n ) has a tempered distribution q <p> This is the space of all functions with the m th derivative in H s . This generalization of H s (R n ) is equivalent in the special case D m H = H m+ (R 2 ), a fractional Sobolev space <ref> [ Oden and Reddy, 1976 ] </ref> . It can be proved that a reproducing kernel of D m H exists and is a semi-Hilbert subspace. This space has associated splines which are defined via convolution with appropriate smoothing kernels. <p> Moreover, if f is another function taking the small values on A, one has kf k m;s kk m;s . 2 These "fractional order Sobolev spaces" <ref> [ Oden and Reddy, 1976 ] </ref> can also be defined without the Fourier transform, as a Sloboditskii space. 46 As will be detailed in section 3.2 this uniqueness ensures the solution is well-posed, or regularized.
Reference: [ Pentland, 1986 ] <author> A. Pentland. </author> <title> Recognition by parts. </title> <type> Technical Report 406, </type> <institution> SRI International, </institution> <month> December </month> <year> 1986. </year>
Reference-contexts: Step 3 Adjust the reconstruction mechanism to deal with the newly-marked dis continuities and return to Step 1. Other segmentation approaches for surface reconstruction have incorporated smooth measures implied by volumetric models (see [ Rao et al., 1987 ] , <ref> [ Pentland, 1986 ] </ref> , [ Bajcsy and Solina, 1987 ] ), or local smoothness properties such as planarity or curvature consistency (see [ Besel and Jain, 1986 ] ). The smoothness-based approach recovers individual surfaces by use of minimal surface bending-energy.
Reference: [ Pentland, November 1984 ] <author> A. Pentland. </author> <title> Fractal-based description of natural scenes. </title> <journal> IEEE PAMI, </journal> <volume> 6(6) </volume> <pages> 661-675, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: Note that the special reproducing-kernel splines to be used in this thesis have very special properties different from the fi-splines. We will use these reproducing kernel splines in the experimental thesis to be described. There are other notable representation techniques. Fractal-based methods <ref> [ Pentland, November 1984 ] </ref> can approximate the roughness of a surface. Volumetric segmentation are studied in [ Solina, 1987 ] . Model-based primitives bear a resemblance to template matching, and are developed [ Bhanu and Nuttall, 1989 ] for specific scenes using range finder data.
Reference: [ Press, 1988 ] <author> W. H. </author> <title> Press. Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <address> Cambridge, New York, </address> <year> 1988. </year>
Reference-contexts: To compute the minimum function value we use the conjugate gradient method of function minimization from <ref> [ Press, 1988 ] </ref> . The compute code for this minimization is shown below: #define TOL .1 meritmin=brent (lamba,lambb,lambc,compute_merit,TOL,&lambdamin); fprintf (stderr,"sderror=%e MeritMin=%e LambdaMin=%e"n", sderror, meritmin, lambdamin); where the computemerit routine is below, and the brent routine for function minimization is from [ Press, 1988 ] (page 297). double compute_merit (lambda) double <p> use the conjugate gradient method of function minimization from <ref> [ Press, 1988 ] </ref> . The compute code for this minimization is shown below: #define TOL .1 meritmin=brent (lamba,lambb,lambc,compute_merit,TOL,&lambdamin); fprintf (stderr,"sderror=%e MeritMin=%e LambdaMin=%e"n", sderror, meritmin, lambdamin); where the computemerit routine is below, and the brent routine for function minimization is from [ Press, 1988 ] (page 297). double compute_merit (lambda) double lambda; double total_squared_error; double total_error, tdist; int i, delstatus; reinitalize_surface (&spline [0]); reinitalize_surface (&spline [1]); spline [0].smoothparm=lambda; spline [1].smoothparm=lambda; 117 noise 0.0001 10.94 0.01 987.68 0.25 27162.05 Table 8.1: Values for (i=0;i&lt;data_size;i++) /* Build initial surface. */ - add_update (&spline [0],xdat <p> If pointwise noise values or a sensor noise model is provided, then the noise values of the individual points can be used in the spline construction. Noise is generated with the gasdev routine of <ref> [ Press, 1988 ] </ref> . The generated noise values are saved to permit comparison of pointwise segmentation behavior with surface noise values.
Reference: [ Rao et al., 1987 ] <author> K. Rao, R. Nevatia, and G. Medioni. </author> <title> Issues in shape description and an approach for working with sparse data. </title> <booktitle> In Proceegings of the AAAI Workshop on Spatial Reasoning and Multi-sensor Fusion, </booktitle> <pages> pages 168-177, </pages> <address> St. Charles. IL, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: Step 3 Adjust the reconstruction mechanism to deal with the newly-marked dis continuities and return to Step 1. Other segmentation approaches for surface reconstruction have incorporated smooth measures implied by volumetric models (see <ref> [ Rao et al., 1987 ] </ref> , [ Pentland, 1986 ] , [ Bajcsy and Solina, 1987 ] ), or local smoothness properties such as planarity or curvature consistency (see [ Besel and Jain, 1986 ] ). The smoothness-based approach recovers individual surfaces by use of minimal surface bending-energy.
Reference: [ Schumaker and Arenin, 1981 ] <author> L. L. Schumaker and V. Ya. Arenin. </author> <title> Spline Functions: Basic Theory. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: This is because more derivatives allow greater flexibility in the function. Special smooth classes of H m (), H s (R n ), and H m D will be defined in some detail later, see section 3.4. Many classes of smooth functions are described in <ref> [ Schumaker and Arenin, 1981 ] </ref> , including (for r a positive integer): C r [I] = ff : the r th derivative D r f belongs to C [I]g; namely the space of r-times continuously differentiable functions. <p> The reproducing kernel spline (RKS) is precisely such a formalization. Extensions to this theory have been defined <ref> [ Schumaker and Arenin, 1981 ] </ref> , and are summarized briefly for completeness. The modulus of smoothness (or continuity) is a precise measure of function smoothness. It is defined as the supremium norm of the r th forward difference on a Lebesque space. <p> definitions of test functions C 1 0 () (a function in C 1 () with support on a compact subset), distributions D 0 (), sets of bounded linear functionals which include all functions and can be defined to have a derivative, and the multidimensional Sobolev space L A p () <ref> [ Schumaker and Arenin, 1981 ] </ref> . This demonstrates that smoothness classes can be defined by giving the number of function derivatives. Smooth functions can be ranked through hierarchies of smooth functions.
Reference: [ Shahraray and Anderson, 1989 ] <author> B. Shahraray and D. J. Anderson. </author> <title> Optimal estimation of contour properties by cross-validated regularization. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-11(6):600-610, </volume> <month> June </month> <year> 1989. </year>
Reference-contexts: Indeed, the formulation allows pointwise setting of the point-wise i value according to the significance of the individual points. The literature in reproducing kernel based splines identifies as an important problem the setting of the parameter, see for example <ref> [ Shahraray and Anderson, 1989 ] </ref> [ Shiau, 1985 ] [ Thomson et al., 1991 ] . The Generalized Cross Validation (GCV) 115 method is one method to simultaneously recover surface shape and the value of which minimizes the average squared error. <p> We can instead compute a "sample reuse" or cross-validation value by selecting the value of which minimizes the average discrepancy between the observed values of the data samples, and the predicted values <ref> [ Shahraray and Anderson, 1989 ] </ref> . This cross-validation (CV) value can be computed as described below in section 8.1. A desirable modification of CV is known as Generalized Cross Validation (GCV) and possess appealing properties. <p> error between each of the n points p i and the surface that excludes p i : n1 X (Eval (Spline without point i ; x i ; y i ) z i ) Minimization of this quantity is the same as computation of the V 0 () described in <ref> [ Shahraray and Anderson, 1989 ] </ref> [ Shiau, 1985 ] . To compute the minimum function value we use the conjugate gradient method of function minimization from [ Press, 1988 ] .
Reference: [ Shiau, 1985 ] <author> J. H. Shiau. </author> <title> Smoothing spline estimation of functions with discontinuities. </title> <type> Technical Report Technical report no. 768, </type> <institution> Department of Statistics, University of Wisconsin, </institution> <month> August </month> <year> 1985. </year>
Reference-contexts: Grimson then presents several computational methods to solve the abstract problem. He discusses 1 Discontinuity detection can be done in conjunction with fitting as in <ref> [ Shiau, 1985 ] </ref> , though it is expensive. 17 many minimization techniques, including the calculus of variations, and uses the conjugate gradient method for approximation and the gradient projection method for interpolation. <p> The key problem is to obtain the kernel and norm; despite existence the kernel's derivation can be difficult. The problem has been studied extensively by [ Duchon, 1976 ] and more recently by <ref> [ Shiau, 1985 ] </ref> . They give many reproducing kernels and show that these solve the regularized problem. <p> These moment conditions are: 1. 1 K (u)du = 1, R 1 51 R 1 4. 1 K (u) 2 du &lt; 1. The reproducing kernel spline is a "extension of the ordinary smoothing spline estimation method" <ref> [ Shiau, 1985 ] </ref> defined on a reproducing kernel Hilbert space, that is, it has the moment properties described above. Multiplication has a dampening or smoothing effect, which is exactly what one should expect since convolution is simply multiplication in Fourier space [ Duchon, 1976 ] . <p> Indeed, the formulation allows pointwise setting of the point-wise i value according to the significance of the individual points. The literature in reproducing kernel based splines identifies as an important problem the setting of the parameter, see for example [ Shahraray and Anderson, 1989 ] <ref> [ Shiau, 1985 ] </ref> [ Thomson et al., 1991 ] . The Generalized Cross Validation (GCV) 115 method is one method to simultaneously recover surface shape and the value of which minimizes the average squared error. <p> points p i and the surface that excludes p i : n1 X (Eval (Spline without point i ; x i ; y i ) z i ) Minimization of this quantity is the same as computation of the V 0 () described in [ Shahraray and Anderson, 1989 ] <ref> [ Shiau, 1985 ] </ref> . To compute the minimum function value we use the conjugate gradient method of function minimization from [ Press, 1988 ] .
Reference: [ Solina, 1987 ] <author> F. Solina. </author> <title> Shape Recovery and Segmentation with Deformable Part Models. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1987. </year>
Reference-contexts: We will use these reproducing kernel splines in the experimental thesis to be described. There are other notable representation techniques. Fractal-based methods [ Pentland, November 1984 ] can approximate the roughness of a surface. Volumetric segmentation are studied in <ref> [ Solina, 1987 ] </ref> . Model-based primitives bear a resemblance to template matching, and are developed [ Bhanu and Nuttall, 1989 ] for specific scenes using range finder data. The expected scene items are measured in a laboratory and described by simplified feature sets obtained, for example, from histograms.
Reference: [ Taylor et al., 1989 ] <author> R. W. Taylor, M. Savini, and A. P. Reeves. </author> <title> Fast segmentation of range imagery into planar regions. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 45, </volume> <year> 1989. </year>
Reference-contexts: For a survey of representations, see [ Brady et al., 1985 ] . Planar surface patches <ref> [ Taylor et al., 1989 ] </ref> partition the image into many small windows which can each be approximated by a planar surface patch. The surface patches can be established from information about depth, orientation of surface normals. Higher order quadratic patches allow greater variation within each patch.
Reference: [ Terzopoulos, 1983 ] <author> D. Terzopoulos. </author> <title> Multilevel computational processes for visual surface reconstruction. </title> <booktitle> 297 Computer Vision, Graphics, and Image Processing, </booktitle> <volume> 24 </volume> <pages> 52-96, </pages> <year> 1983. </year>
Reference-contexts: subtle differences in the information between the two views (due, for example, to occluding boundaries on cylinders) as well as features that have several indistinguishable matches in each view. 2.1.2 Terzopoulos An extension of the above research effort combines the thin-plate with another model, namely membranes, in a hybrid representation <ref> [ Terzopoulos, 1983 ] </ref> [ Terzopoulos, 1984 ] [ Terzopoulos, 1986 ] . This research develops a theory for the recovery of the discontinuities and surface reconstruction. The world model is a thin flexible plate with springs that constrain the plate to depth measurements. <p> This contrasts to O (n 2 ) for finite-element methods <ref> [ Terzopoulos, 1983 ] </ref> . We accelerate computation by use of a closed-form expression of the norm, and we further accelerate the computation with a parallel computer.
Reference: [ Terzopoulos, 1984 ] <author> D. Terzopoulos. </author> <title> Multiresolution Computation of Visible-Surface Representations. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1984. </year>
Reference-contexts: Of these, the segmentation tasks in surface reconstruction, disparity field recovery and certain classes of motion detection problems have been approached by application of segmentation coupled with recovery using an energy-based smoothness assumption; for example, see <ref> [ Terzopoulos, 1984 ] </ref> , [ Blake and Zisserman, 1986a ] , [ Hoff and Ahuja, 1985 ] , [ Anandan and Weiss, 1985 ] , [ Boult and Chen, 1988a ] , [ Chou and Brown, 1990 ] . <p> As an example, the bark of a tree is very energetic when viewed from closeup. 1.2.1 Energy Measure In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , <ref> [ Terzopoulos, 1984 ] </ref> , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> This results in a difficult chicken-and-egg problem. To make matters worse, the quality of the reconstruction in the neighborhood of an unmarked (i.e., as yet undetected) discontinuity is generally poor. Thus, the localization of the discontinuity by use of iterative reconstruction/segmentation approaches, see <ref> [ Terzopoulos, 1984 ] </ref> or [ Hoff and Ahuja, 1987 ] , will be questionable. <p> information between the two views (due, for example, to occluding boundaries on cylinders) as well as features that have several indistinguishable matches in each view. 2.1.2 Terzopoulos An extension of the above research effort combines the thin-plate with another model, namely membranes, in a hybrid representation [ Terzopoulos, 1983 ] <ref> [ Terzopoulos, 1984 ] </ref> [ Terzopoulos, 1986 ] . This research develops a theory for the recovery of the discontinuities and surface reconstruction. The world model is a thin flexible plate with springs that constrain the plate to depth measurements. <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , <ref> [ Terzopoulos, 1984 ] </ref> , [ Wahba, 1984 ] , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] .
Reference: [ Terzopoulos, 1986 ] <author> D. Terzopoulos. </author> <title> Regularization of inverse visual problems involving discontinuities. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8(4):413-424, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: views (due, for example, to occluding boundaries on cylinders) as well as features that have several indistinguishable matches in each view. 2.1.2 Terzopoulos An extension of the above research effort combines the thin-plate with another model, namely membranes, in a hybrid representation [ Terzopoulos, 1983 ] [ Terzopoulos, 1984 ] <ref> [ Terzopoulos, 1986 ] </ref> . This research develops a theory for the recovery of the discontinuities and surface reconstruction. The world model is a thin flexible plate with springs that constrain the plate to depth measurements.
Reference: [ Thomson et al., 1991 ] <author> A. M. Thomson, J. C. Brown, J. M. Kay, and D. M. Titter-ington. </author> <title> A study of methods of choosing the smoothing parameter in image restoration by regularization. </title> <journal> PAMI, </journal> <volume> 13(4) </volume> <pages> 326-339, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Indeed, the formulation allows pointwise setting of the point-wise i value according to the significance of the individual points. The literature in reproducing kernel based splines identifies as an important problem the setting of the parameter, see for example [ Shahraray and Anderson, 1989 ] [ Shiau, 1985 ] <ref> [ Thomson et al., 1991 ] </ref> . The Generalized Cross Validation (GCV) 115 method is one method to simultaneously recover surface shape and the value of which minimizes the average squared error.
Reference: [ Tikhonov, 1977 ] <author> A. N. </author> <title> Tikhonov. Solution of Ill-pose Problems (Translated from Russion 'Netody resheniia Nekor rektnydl zadah'). </title> <address> Halsted, </address> <year> 1977. </year>
Reference-contexts: The reconstruction and approximation problems are formally ill-posed. Such problems need to be modified to obtain a well defined answer. One method to form such modifications is regularization theory <ref> [ Tikhonov, 1977 ] </ref> . To see the problem is ill-posed consider a finite set of data points. This set does not define the function away from the data points. <p> It is therefore virtually impossible to compare different data samples by comparing the functions which fit these samples. Stated formally <ref> [ Tikhonov, 1977 ] </ref> : The problem of determining the solution z in the space F from the `initial data' u in the space U is said to be well-posed on the pair of metric spaces (F; U ) if the following three conditions are satisfied: 1. for every element u <p> Tikhonov defines <ref> [ Tikhonov, 1977 ] </ref> (pg. 46) the requirements for a technique called regularization to form a well-posed problem. This allows the construction of unique solutions that are stable under small changes in the initial data. <p> It is crucial that the modified problem be shown to solve 40 the initial problem as well. While it is not in the confines of this thesis to explore this difficult theory, the interested reader is referred to <ref> [ Tikhonov, 1977 ] </ref> . The recovered surfaces are constructed by approximation methods that employ this "regularization" approach by inclusion of a term that distinguishes between otherwise indistinguishable solutions. A norm kk is used in this work as detailed in section 3.4.
Reference: [ Wahba, 1984 ] <author> G. Wahba. </author> <title> Surface fitting with scattered noisy data on euclidean d-space and on the sphere. </title> <journal> Rocky Mountain Journal of Mathematics, </journal> <volume> 14(1) </volume> <pages> 281-299, </pages> <year> 1984. </year> <month> 298 </month>
Reference-contexts: an example, the bark of a tree is very energetic when viewed from closeup. 1.2.1 Energy Measure In computer vision, as well as other domains, researchers have used minimal surface bending-energy as an assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , <ref> [ Wahba, 1984 ] </ref> , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> The degree of interpolation and approximation are controlled by , with a pure interpolation approach as ! 0 [ Boult, 1986 ] . Selection of the optimal smoothing parameter is addressed by <ref> [ Wahba, 1984 ] </ref> for a single surface, and in this multiple-surface work we approximate it by executing many runs on calibration data at various values for different noise values to obtain the minimum energy. 3.1.3 Multiple Surface VR and VA (MSVR/A) The overall problem of multiple-surface segmentation is to form <p> Ideally the value should be computed based on the overall error in the initial data, and the GCV method <ref> [ Wahba, 1984 ] </ref> could be used to automatically compute while recovering the parameters for a single surface. However, the problem is recovering values for multiple surfaces has not been addressed in the literature. This thesis employs a simple scheme to compute an approximate value. <p> Minimal surface bending-energy is a key assumption to aid in surface recovery, see [ Grimson, 1981 ] , [ Terzopoulos, 1984 ] , <ref> [ Wahba, 1984 ] </ref> , [ Franke, 1982 ] , [ Hoff and Ahuja, 1985 ] , [ Blake and Zisserman, 1986a ] , [ Lee, 1985 ] , [ Boult, 1986 ] , [ Choi and Kender, 1985 ] . <p> For a more gentle discussion of kernel splines see [ Eubank, 1988 ] , which shows various ways to develop multivariate smoothing splines such as those of [ Duchon, 1976 ] , [ Meinguet, 1983 ] and <ref> [ Wahba, 1984 ] </ref> .
References-found: 58

