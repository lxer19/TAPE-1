URL: ftp://wol.ra.phy.cam.ac.uk/pub/mackay/tcc-al.ps.gz
Refering-URL: http://131.111.48.24/mackay/README.html
Root-URL: 
Email: bfrey@turbo.beckman.uiuc.edu  mackay@mrao.cam.ac.uk  
Title: Trellis-Constrained Codes  
Author: Brendan J. Frey David J. C. MacKay B. J. Frey and D. J. C. MacKay 
Note: (1998) In Proceedings of the 35 th Allerton Conference on Communication, Control and Computing 1997, Champaign-Urbana,  
Address: Cambridge University  
Affiliation: Beckman Institute for Advanced Science and Technology University of Illinois at Urbana-Champaign  Department of Physics, Cavendish Laboratories  Illinois.  
Abstract: We introduce a class of iteratively decodable trellis-constrained codes as a generalization of turbocodes, low-density parity-check codes, serially-concatenated convolutional codes, and product codes. In a trellis-constrained code, multiple trellises interact to define the allowed set of codewords. As a result of these interactions, the minimum-complexity single trellis for the code can have a state space that grows exponentially with block length. However, as with turbocodes and low-density parity-check codes, a decoder can approximate bit-wise maximum a posteriori decoding by using the sum-product algorithm on the factor graph that describes the code. We present two new families of codes, homogenous trellis-constrained codes and ring-connected trellis-constrained codes, and give results that show these codes perform in the same regime as do turbo-codes and low-density parity-check codes.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. M. Tanner, </author> <title> "A recursive approach to low complexity codes," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 27, </volume> <pages> pp. 533-547, </pages> <year> 1981. </year>
Reference-contexts: A single trellis for the same turbocode would have an unwieldly large number of states. More important than representation, a factor graph provides a framework for iterative decoding via message passing on the graph. The probability propagation algorithm [8, 9], a.k.a. the sum-product algorithm <ref> [1, 2] </ref>, can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding [6, 7].) Two different factor graphs for the same code may give decoders with different performances.
Reference: [2] <author> N. Wiberg, H.-A. Loeliger, and R. Kotter, </author> <title> "Codes and iterative decoding on general graphs," </title> <journal> European Transactions on Telecommunications, </journal> <volume> vol. 6, </volume> <pages> pp. 513-525, </pages> <month> September/October </month> <year> 1995. </year>
Reference-contexts: A single trellis for the same turbocode would have an unwieldly large number of states. More important than representation, a factor graph provides a framework for iterative decoding via message passing on the graph. The probability propagation algorithm [8, 9], a.k.a. the sum-product algorithm <ref> [1, 2] </ref>, can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding [6, 7].) Two different factor graphs for the same code may give decoders with different performances.
Reference: [3] <author> N. Wiberg, </author> <title> Codes and Decoding on General Graphs. </title> <institution> Linkoping Sweden: Department of Electrical Engineering, Linkoping University, </institution> <year> 1996. </year> <note> Doctoral dissertation. </note>
Reference-contexts: However, as evidenced by the excellent error-correcting capabilities of the iterative decoders for turbocodes [10] and low-density parity-check codes [4], the algorithm works impressively well in the graphs that describe these codes, even though they contain many cycles. See <ref> [3] </ref> and [5] for extensive dissertations on this subject. 1 (a) n 1 = 3=4 n 2 = 3=4 R t = 3=4, n t = 1=3, t = 1; : : : ; 6 R 2 = 3=4, n 2 = 1 of all the constituent trellises, with the codeword
Reference: [4] <author> D. J. C. MacKay and R. M. Neal, </author> <title> "Near Shannon limit performance of low density parity check codes," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <pages> pp. 1645-1646, </pages> <month> August </month> <year> 1996. </year> <title> Due to editing errors, </title> <journal> reprinted in Electronics Letters, </journal> <volume> vol. 33, </volume> <month> March </month> <year> 1997, </year> <pages> 457-458. </pages>
Reference-contexts: This probability propagation algorithm [8,9] is exact only in cycle-free graphs. However, as evidenced by the excellent error-correcting capabilities of the iterative decoders for turbocodes [10] and low-density parity-check codes <ref> [4] </ref>, the algorithm works impressively well in the graphs that describe these codes, even though they contain many cycles. <p> for this code are given in [13] and are (32; 4; 22; 15; 17) octal .) Fig. 2 shows the performance of this homogenous TCC, relative to the turbocode introduced by Berrou et. al. [14] and the best rate 1/2, N = 65; 389 low-density parity-check code published to date <ref> [4] </ref>. Although it does not perform as well as the turbocode, it performs significantly better than the low-density parity-check code. <p> E b =N 0 (dB) Shannon's limit Unco ded BER to the best rate 1/2 turbocode and low-density parity-check code performances published to date <ref> [4, 10] </ref>. 3 Ring-Connected Trellis-Constrained Codes Fig. 1e shows the factor graph for a simple ring-connected TCC with T = 3.
Reference: [5] <author> B. J. Frey, </author> <title> Bayesian Networks for Pattern Classification, Data Compression and Channel Coding. </title> <institution> Toronto Canada: Department of Electrical and Computer Engineering, University of Toronto, </institution> <year> 1997. </year> <note> Doctoral dissertation available at http://www.cs.utoronto.ca/~frey. </note>
Reference-contexts: However, as evidenced by the excellent error-correcting capabilities of the iterative decoders for turbocodes [10] and low-density parity-check codes [4], the algorithm works impressively well in the graphs that describe these codes, even though they contain many cycles. See [3] and <ref> [5] </ref> for extensive dissertations on this subject. 1 (a) n 1 = 3=4 n 2 = 3=4 R t = 3=4, n t = 1=3, t = 1; : : : ; 6 R 2 = 3=4, n 2 = 1 of all the constituent trellises, with the codeword bits reordered.
Reference: [6] <author> F. R. Kschischang and B. J. Frey, </author> <title> "Iterative decoding of compound codes by probability propagation in graphical models." </title> <note> To appear in IEEE Journal on Selected Areas in Communications, available at http://www.cs.utoronto.ca/~frey, 1998. </note>
Reference-contexts: The probability propagation algorithm [8, 9], a.k.a. the sum-product algorithm [1, 2], can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding <ref> [6, 7] </ref>.) Two different factor graphs for the same code may give decoders with different performances. As another example, Fig. 1c shows the factor graph for a simple low-density parity- check code.
Reference: [7] <author> R. J. McEliece, D. J. C. MacKay, and J. F. Cheng, </author> <title> "Turbo-decoding as an instance of Pearl's `belief propagation' algorithm." </title> <journal> To appear in IEEE Journal on Selected Areas in Communications, </journal> <year> 1998. </year>
Reference-contexts: The probability propagation algorithm [8, 9], a.k.a. the sum-product algorithm [1, 2], can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding <ref> [6, 7] </ref>.) Two different factor graphs for the same code may give decoders with different performances. As another example, Fig. 1c shows the factor graph for a simple low-density parity- check code.
Reference: [8] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <address> San Mateo CA.: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Fig. 1b shows the factor graph for a simple turbocode. A single trellis for the same turbocode would have an unwieldly large number of states. More important than representation, a factor graph provides a framework for iterative decoding via message passing on the graph. The probability propagation algorithm <ref> [8, 9] </ref>, a.k.a. the sum-product algorithm [1, 2], can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding [6, 7].) Two different factor graphs for the same code may give decoders with
Reference: [9] <author> S. L. Lauritzen and D. J. Spiegelhalter, </author> <title> "Local computations with probabilities on graphical struc-tures and their application to expert systems," </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 50, </volume> <pages> pp. 157-224, </pages> <year> 1988. </year>
Reference-contexts: Fig. 1b shows the factor graph for a simple turbocode. A single trellis for the same turbocode would have an unwieldly large number of states. More important than representation, a factor graph provides a framework for iterative decoding via message passing on the graph. The probability propagation algorithm <ref> [8, 9] </ref>, a.k.a. the sum-product algorithm [1, 2], can be applied to a factor graph to approximate bit-wise maximum a posteriori (MAP) decoding. (In the 2 special case of a turbocode, this general algorithm reduces to turbodecoding [6, 7].) Two different factor graphs for the same code may give decoders with
Reference: [10] <author> C. Berrou and A. Glavieux, </author> <title> "Near optimum error correcting coding and decoding: </title> <journal> Turbo-codes," IEEE Transactions on Communications, </journal> <volume> vol. 44, </volume> <pages> pp. 1261-1271, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: This probability propagation algorithm [8,9] is exact only in cycle-free graphs. However, as evidenced by the excellent error-correcting capabilities of the iterative decoders for turbocodes <ref> [10] </ref> and low-density parity-check codes [4], the algorithm works impressively well in the graphs that describe these codes, even though they contain many cycles. <p> E b =N 0 (dB) Shannon's limit Unco ded BER to the best rate 1/2 turbocode and low-density parity-check code performances published to date <ref> [4, 10] </ref>. 3 Ring-Connected Trellis-Constrained Codes Fig. 1e shows the factor graph for a simple ring-connected TCC with T = 3. <p> Fig. 2 shows the performance of this ring-connected TCC. It performs signficantly better than the homogenous TCC and the low-density parity-check code and only 0.2 dB worse than the turbocde. 4 Discussion There is some literature on the properties of the constituent trellises that make good tur- bocodes <ref> [10, 17, 18] </ref> and serially-concatenated convolutional codes [19]. We are currently exploring similar arguments for choosing the properties of the constituent trellises that 6 will make good homogenous TCC's and ring-connected TCC's. <p> For example, in order to avoid low-weight codewords in a turbocode, we try to avoid permuters that keep a pair of bits the same distance apart in the two constituent trellises <ref> [10] </ref>. This degenerate effect is "broken" by the ring of a ring-connected TCC, which requires not only that two neighboring trellises have an equal set of shared "input" bits, but also that their "output" bits must satisfy the constraints given by the ramainder of the ring.
Reference: [11] <author> B. J. Frey, F. R. Kschischang, H. A. Loeliger, and N. Wiberg, </author> <title> "Factor graphs and algorithms," </title> <booktitle> in Proceedings of the 35 th Allerton Conference, </booktitle> <year> 1998. </year>
Reference-contexts: The small unfilled discs represent codeword bits. Fig. 1a shows the factor graph (see <ref> [11] </ref> in these proceedings) for a trellis. Unlike in a trellis, in a factor graph the values that each state variable (large white discs) can take on are not explicitly shown.
Reference: [12] <author> D. J. C. MacKay, </author> <title> "Good codes based on very sparse matrices." </title> <note> Submitted to IEEE Transactions on Information Theory, </note> <year> 1997. </year>
Reference-contexts: As another example, Fig. 1c shows the factor graph for a simple low-density parity- check code. Each of the six trellises is a simple parity-check trellis that enforces even parity on its six codeword bits <ref> [12] </ref>. In a sense, whereas the trellis assisted in the design of low-complexity codes and exact linear-time probabilistic decoders (the Viterbi algorithm and the forward-backward algorithm), the factor graph assists in the design of high-complexity codes and approximate linear-time probabilistic decoders.
Reference: [13] <author> D. G. Daut, J. W. Modestino, and L. D. Wismer, </author> <title> "New short constraint length convolutional code constructions for selected rational rates," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 28, </volume> <pages> pp. 794-800, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: A for a description of how the BER confidence intervals were computed.) Each rate 3/4 trellis was obtained by shortening every fifth bit of a rate 4/5 nonsystematic convolutional code with maximum d min . (The generator polynomials for this code are given in <ref> [13] </ref> and are (32; 4; 22; 15; 17) octal .) Fig. 2 shows the performance of this homogenous TCC, relative to the turbocode introduced by Berrou et. al. [14] and the best rate 1/2, N = 65; 389 low-density parity-check code published to date [4].
Reference: [14] <author> C. Berrou, A. Glavieux, and P. Thitimajshima, </author> <title> "Near Shannon limit error-correcting coding and decoding: Turbo codes," </title> <booktitle> in Proceedings of the IEEE International Conference on Communications, </booktitle> <year> 1993. </year>
Reference-contexts: bit of a rate 4/5 nonsystematic convolutional code with maximum d min . (The generator polynomials for this code are given in [13] and are (32; 4; 22; 15; 17) octal .) Fig. 2 shows the performance of this homogenous TCC, relative to the turbocode introduced by Berrou et. al. <ref> [14] </ref> and the best rate 1/2, N = 65; 389 low-density parity-check code published to date [4]. Although it does not perform as well as the turbocode, it performs significantly better than the low-density parity-check code.
Reference: [15] <author> S. Benedetto and G. Montorsi, </author> <title> "Serial concatenation of block and convolutional codes," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <pages> pp. 887-888, </pages> <year> 1996. </year>
Reference-contexts: This code can be viewed as a serially-concatenated convolutional code <ref> [15, 16] </ref> in which some of the 5 output bits are constrained to be equal to some of the input bits. The factor graph thus forms a ring of connected trellises. In the ring-connected TCC shown, each constituent trellis checks exactly 2=T of the codeword bits.
Reference: [16] <author> S. Benedetto and G. Montorsi, </author> <title> "Iterative decoding of serially concatenated convolutional codes," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <pages> pp. 1186-1188, </pages> <year> 1996. </year>
Reference-contexts: This code can be viewed as a serially-concatenated convolutional code <ref> [15, 16] </ref> in which some of the 5 output bits are constrained to be equal to some of the input bits. The factor graph thus forms a ring of connected trellises. In the ring-connected TCC shown, each constituent trellis checks exactly 2=T of the codeword bits.
Reference: [17] <author> S. Benedetto and G. Montorsi, "Unveiling turbo-codes: </author> <title> Some results on parallel concatenated coding schemes," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 42, </volume> <pages> pp. 409-428, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Fig. 2 shows the performance of this ring-connected TCC. It performs signficantly better than the homogenous TCC and the low-density parity-check code and only 0.2 dB worse than the turbocde. 4 Discussion There is some literature on the properties of the constituent trellises that make good tur- bocodes <ref> [10, 17, 18] </ref> and serially-concatenated convolutional codes [19]. We are currently exploring similar arguments for choosing the properties of the constituent trellises that 6 will make good homogenous TCC's and ring-connected TCC's.
Reference: [18] <author> D. Divsalar and R. J. </author> <title> McEliece, "Effective free distance of turbocodes," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <pages> pp. 445-446, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Fig. 2 shows the performance of this ring-connected TCC. It performs signficantly better than the homogenous TCC and the low-density parity-check code and only 0.2 dB worse than the turbocde. 4 Discussion There is some literature on the properties of the constituent trellises that make good tur- bocodes <ref> [10, 17, 18] </ref> and serially-concatenated convolutional codes [19]. We are currently exploring similar arguments for choosing the properties of the constituent trellises that 6 will make good homogenous TCC's and ring-connected TCC's.
Reference: [19] <author> S. Benedetto, G. Montorsi, D. Divsalar, and F. Pollara, </author> <title> "Serial concatenation of interleaved codes: Performance analysis, design, and iterative decoding." </title> <note> To appear in IEEE Transactions on Information Theory, 1997. 10 </note>
Reference-contexts: It performs signficantly better than the homogenous TCC and the low-density parity-check code and only 0.2 dB worse than the turbocde. 4 Discussion There is some literature on the properties of the constituent trellises that make good tur- bocodes [10, 17, 18] and serially-concatenated convolutional codes <ref> [19] </ref>. We are currently exploring similar arguments for choosing the properties of the constituent trellises that 6 will make good homogenous TCC's and ring-connected TCC's. The behavior of these two new families of TCC's is quite different from that of turbocodes, so we expect different properties to be relevant.
References-found: 19

