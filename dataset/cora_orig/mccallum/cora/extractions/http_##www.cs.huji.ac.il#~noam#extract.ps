URL: http://www.cs.huji.ac.il/~noam/extract.ps
Refering-URL: http://www.cs.huji.ac.il/~noam/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Randomness is Linear in Space  
Author: Noam Nisan David Zuckerman 
Abstract: We show that any randomized algorithm that runs in space S and time T and uses poly(S) random bits can be simulated using only O(S) random bits in space S and time T + poly(S). A deterministic simulation in space S follows. Of independent interest is our main technical tool: a procedure which extracts randomness from a defective random source using a small additional number of truly random bits. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi, </author> <title> Deterministic Simulation of Logspace, </title> <booktitle> Proceedings of the 19th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1987, </year> <pages> pp. 132-140. </pages>
Reference-contexts: There is only one result that improves this bound for some R. Namely, Ajtai, Komlos, and Szemeredi showed that any randomized-space (S) algorithm using only O (S 2 = log S) random bits can be simulated deterministically in space (S) <ref> [1] </ref>. In this paper we improve upon this result and give a deterministic simulation of algorithms using poly (S) random bits. What we obtain is a pseudo-random generator. Our generator converts O (S) truly random bits to poly (S) bits that look random to all space (S) machines. <p> Proof: The fact that G runs on-line in space O (S) follows immediately from the fact that E can be computed in space O (n). To prove that G is a pseudorandom generator we will show that it fools any space (S) machine M . As in <ref> [1] </ref>, we model M as a layered multi-graph L with a layer for each 0 i l, where each layer has 2 S vertices.
Reference: [2] <author> L. Babai, N. Nisan, and M. Szegedy, </author> <title> Multiparty Protocols, Pseudorandom Generators for Logspace, and Time-Space Tradeoffs, </title> <journal> J. Comp. Syst. and Sci. </journal> <volume> 45(2) (1992), </volume> <pages> pp. 204-232. </pages>
Reference-contexts: Despite much effort very little is known. In this paper we consider this question when the complexity measured is space. Is randomized-space (S) stronger than deterministic-space (S)? While several nontrivial deterministic simulations of randomized-space are known <ref> [2, 15, 16] </ref>, this question is still completely open. No simulation of randomized-space (S) is known which uses less than O (S 2 ) deterministic space, a simulation which can be achieved by Savitch's theorem [17].
Reference: [3] <author> M. Bellare, O. Goldreich, and S. Goldwasser, </author> <title> Randomness in Interactive Proofs, </title> <booktitle> Computational Complexity 5 (1993): </booktitle> <pages> 319-354. </pages>
Reference-contexts: For the value of t we obtain, however, the running time of this simulation will not be polynomial but only quasi-polynomial. On the other hand, our simulation satisfies a stronger requirement: it truly approximates the acceptance probability of a BPP machine. The result of <ref> [3] </ref> is similar in this regard, but does not yield an extractor. 2 Definitions and Notation Throughout this paper, we use the convention that capital letters denote random variables, sets, distributions, and probability spaces; other variables will be in small letters. <p> ; : : : ; X l in f1; 2; : : :; ng such that P r [ ffi 2 l=16 of the X i 's lie in T ] 1 2 k : Proof: We combine 10-wise independence and random walks on expanders in a manner similar to <ref> [3] </ref>. We divide f1; 2; : : :; ng into m disjoint sets A 1 ; : : : ; A m of size p = n=m, where m = 14k=ffi.
Reference: [4] <author> B. Berger and J. Rompel, </author> <title> Simulating (log c n)-Wise Independence in N C, </title> <journal> JACM 38(4) </journal> <pages> 1026-1046, </pages> <year> 1991. </year>
Reference-contexts: The property we wish to have from the random choice is that, with high probability, it intersects every given subset of size ffin in at least ffil=2 places. The simplest way to do this is using k-wise independent distributions (see e.g. <ref> [7, 13, 4, 14] </ref>). In order to ensure that no duplicate elements are chosen, we do the following. Choosing l out of n elements: We divide the n elements into l disjoint sets A 1 ; : : :; A l of size m = n=l, i.e.
Reference: [5] <author> L. Carter and M. Wegman, </author> <title> Universal Hash Functions, </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 18(2) (1979): </volume> <pages> 143-154. 13 </pages>
Reference-contexts: the random walk; and second, by redefining i as important if ffi i 2 I j = (2 (1+j) ; 2 j ], where j is chosen so that the sum of the ffi i in this interval is maximum. 2 5.1.2 Universal Hashing We will use universal hash functions <ref> [5] </ref>. Formally, let H be a set of functions h : f0; 1g n ! f0; 1g m .
Reference: [6] <author> B. Chor and O. Goldreich, </author> <title> Unbiased Bits from Sources of Weak Randomness and Probabilistic Communica--tion Complexity, </title> <journal> SIAM J. Comput., </journal> <volume> 17(2) </volume> (1988):230-261. 
Reference-contexts: A block-wise ffi-source is the same as the PRB-source of <ref> [6] </ref> except that here the block length is allowed to vary. 3 Fooling Randomized Space-Bounded Machines Our goal in this section is to use an extractor to construct a pseudo-random generator for space bounded computation. 3 Definition 3 A generator G : f0; 1g n ! f0; 1g m is called
Reference: [7] <author> B. Chor and O. Goldreich, </author> <title> On the Power of Two-Point Based Sampling, </title> <journal> Journal of Complexity 5 </journal> (1989):96-106. 
Reference-contexts: The property we wish to have from the random choice is that, with high probability, it intersects every given subset of size ffin in at least ffil=2 places. The simplest way to do this is using k-wise independent distributions (see e.g. <ref> [7, 13, 4, 14] </ref>). In order to ensure that no duplicate elements are chosen, we do the following. Choosing l out of n elements: We divide the n elements into l disjoint sets A 1 ; : : :; A l of size m = n=l, i.e.
Reference: [8] <author> A. Cohen and A. Wigderson, Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources, </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference-contexts: It is not difficult to see that this can be used to simulate BPP using a ffi-source [20, 21], or to do "deterministic amplification" <ref> [11, 8] </ref>. For the value of t we obtain, however, the running time of this simulation will not be polynomial but only quasi-polynomial. On the other hand, our simulation satisfies a stronger requirement: it truly approximates the acceptance probability of a BPP machine. <p> The vertex visited at the ith step defines a set S i A i as above. We set S = [ m i=1 S i . To analyze this, we need the following modification of a lemma from [11] (see also <ref> [8] </ref>): Lemma 8 Suppose that for 1 i 7k, W i f1; 2; : : : ; N g, jW i j :99N , and G i is a regular expander multi-graph on N nodes with corresponding transition matrix having second largest eigenvalue in absolute value at most 1=10.
Reference: [9] <author> O. Gabber and Z. Galil, </author> <title> Explicit Construction of Linear-Sized Superconcentrators, </title> <journal> J. Comp. and Sys. Sci 22 (1981), </journal> <pages> pp. 407-420. </pages>
Reference-contexts: Call such a set S i good. We now use an explicitly constructible constant-degree expander graph G on p 10 nodes, with second largest eigenvalue in absolute value at most 1=10. For example, we can use a power of the one in <ref> [9] </ref> with sufficiently many self loops to eliminate the negative eigenvalues. We then take a random walk for m steps from a uniformly random start vertex. The vertex visited at the ith step defines a set S i A i as above.
Reference: [10] <author> R. Impagliazzo, L. Levin, and M. Luby, </author> <title> Pseudo-Random Generation from One-Way Functions, </title> <booktitle> Proceedings of the 21st Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1989, </year> <pages> pp. 12-24. </pages>
Reference-contexts: if for every ffi-source D, the distribution of E (x; y) ffi y induced by choosing x from D and y uniformly in f0; 1g t is within statistical distance of * from the uniform distribution (on f0; 1g m fi f0; 1g t .) The Leftover Hash Lemma of <ref> [10] </ref> 1 gives an extractor with t &gt; n. Our main construction is an extractor with t &lt;< n. <p> In this context we obtain very small families of hash functions which still have good properties; specifically, they satisfy a lemma similar to the Leftover Hash Lemma <ref> [10] </ref>. 1 The term "Leftover Hash Lemma" was coined in [11], which gives a proof due to Rackoff with improved constants. 2 Expansion: An extractor E defines in a natural way a bipartite graph on f0; 1g n fi f0; 1g m , where x 2 f0; 1g n is connected <p> x 2 2 f0; 1g n and y 1 ; y 2 2 f0; 1g m we have that P r h2H [h (x 1 ) = y 1 and h (x 2 ) = y 2 ] = 2 2m : We will require the Leftover Hash Lemma of <ref> [10] </ref>. Lemma 9 (Leftover Hash Lemma [10]) Let X f0; 1g n ; jXj 2 r . Let k &gt; 0, and let H be a universal family of hash functions mapping n bits to r 2k bits. <p> and y 1 ; y 2 2 f0; 1g m we have that P r h2H [h (x 1 ) = y 1 and h (x 2 ) = y 2 ] = 2 2m : We will require the Leftover Hash Lemma of <ref> [10] </ref>. Lemma 9 (Leftover Hash Lemma [10]) Let X f0; 1g n ; jXj 2 r . Let k &gt; 0, and let H be a universal family of hash functions mapping n bits to r 2k bits.
Reference: [11] <author> R. Impagliazzo and D. Zuckerman, </author> <title> How to Recycle Random Bits, </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 248-253. </pages>
Reference-contexts: In this context we obtain very small families of hash functions which still have good properties; specifically, they satisfy a lemma similar to the Leftover Hash Lemma [10]. 1 The term "Leftover Hash Lemma" was coined in <ref> [11] </ref>, which gives a proof due to Rackoff with improved constants. 2 Expansion: An extractor E defines in a natural way a bipartite graph on f0; 1g n fi f0; 1g m , where x 2 f0; 1g n is connected to z 2 f0; 1g m if there exists y <p> It is not difficult to see that this can be used to simulate BPP using a ffi-source [20, 21], or to do "deterministic amplification" <ref> [11, 8] </ref>. For the value of t we obtain, however, the running time of this simulation will not be polynomial but only quasi-polynomial. On the other hand, our simulation satisfies a stronger requirement: it truly approximates the acceptance probability of a BPP machine. <p> The vertex visited at the ith step defines a set S i A i as above. We set S = [ m i=1 S i . To analyze this, we need the following modification of a lemma from <ref> [11] </ref> (see also [8]): Lemma 8 Suppose that for 1 i 7k, W i f1; 2; : : : ; N g, jW i j :99N , and G i is a regular expander multi-graph on N nodes with corresponding transition matrix having second largest eigenvalue in absolute value at most
Reference: [12] <author> M. Jerrum and A. Sinclair, </author> <title> Approximating the Permanent, </title> <journal> SIAM J. Comput. </journal> <volume> 18 </volume> (1989):1149-1178. 
Reference-contexts: Several classes of randomized algorithms run naturally in linear space and thus can be simulated using only a linear number of random bits. Examples include walks on "rapidly mixing Markov chains" (as in <ref> [12] </ref>) and random generation using the "rejection method." A particularly interesting example is uniform generation of prime numbers which, using this corollary, can be approximated (within small statistical distance) using a linear number of random bits (see [15] for more details).
Reference: [13] <author> M. Luby, </author> <title> Removing Randomness in Parallel Computation Without a Processor Penalty, </title> <booktitle> Proceedings of the 29th Symposium on Foundations of Computer Science, </booktitle> <year> 1988, </year> <pages> pp. 162-173. </pages>
Reference-contexts: The property we wish to have from the random choice is that, with high probability, it intersects every given subset of size ffin in at least ffil=2 places. The simplest way to do this is using k-wise independent distributions (see e.g. <ref> [7, 13, 4, 14] </ref>). In order to ensure that no duplicate elements are chosen, we do the following. Choosing l out of n elements: We divide the n elements into l disjoint sets A 1 ; : : :; A l of size m = n=l, i.e.
Reference: [14] <author> R. Motwani, J. Naor, and M. Naor, </author> <title> The Probabilistic Method Yields Deterministic Parallel Algorithms, </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 8-13. </pages>
Reference-contexts: The property we wish to have from the random choice is that, with high probability, it intersects every given subset of size ffin in at least ffil=2 places. The simplest way to do this is using k-wise independent distributions (see e.g. <ref> [7, 13, 4, 14] </ref>). In order to ensure that no duplicate elements are chosen, we do the following. Choosing l out of n elements: We divide the n elements into l disjoint sets A 1 ; : : :; A l of size m = n=l, i.e.
Reference: [15] <author> N. Nisan, </author> <title> Pseudorandom generators for space-bounded computation, </title> <booktitle> Combinatorica 12(4) (1992), </booktitle> <pages> pp. 449-461. </pages>
Reference-contexts: Despite much effort very little is known. In this paper we consider this question when the complexity measured is space. Is randomized-space (S) stronger than deterministic-space (S)? While several nontrivial deterministic simulations of randomized-space are known <ref> [2, 15, 16] </ref>, this question is still completely open. No simulation of randomized-space (S) is known which uses less than O (S 2 ) deterministic space, a simulation which can be achieved by Savitch's theorem [17]. <p> Examples include walks on "rapidly mixing Markov chains" (as in [12]) and random generation using the "rejection method." A particularly interesting example is uniform generation of prime numbers which, using this corollary, can be approximated (within small statistical distance) using a linear number of random bits (see <ref> [15] </ref> for more details). We remark that the results of [15] imply that randomized space S polynomial-time algorithms may be simulated using O (S log n) random bits, so Corollary 2 is only interesting when S = n (1) . <p> chains" (as in [12]) and random generation using the "rejection method." A particularly interesting example is uniform generation of prime numbers which, using this corollary, can be approximated (within small statistical distance) using a linear number of random bits (see <ref> [15] </ref> for more details). We remark that the results of [15] imply that randomized space S polynomial-time algorithms may be simulated using O (S log n) random bits, so Corollary 2 is only interesting when S = n (1) . Our main technical tool is a construction of the following kind of function which we call an extractor. <p> We remark that we can improve the dependence on ffi in two ways: first, by using the generator of <ref> [15] </ref> for the bits of the random walk; and second, by redefining i as important if ffi i 2 I j = (2 (1+j) ; 2 j ], where j is chosen so that the sum of the ffi i in this interval is maximum. 2 5.1.2 Universal Hashing We will
Reference: [16] <author> N. Nisan, </author> <title> RL SC, </title> <booktitle> Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1992, </year> <pages> pp. 619-623. </pages>
Reference-contexts: Despite much effort very little is known. In this paper we consider this question when the complexity measured is space. Is randomized-space (S) stronger than deterministic-space (S)? While several nontrivial deterministic simulations of randomized-space are known <ref> [2, 15, 16] </ref>, this question is still completely open. No simulation of randomized-space (S) is known which uses less than O (S 2 ) deterministic space, a simulation which can be achieved by Savitch's theorem [17].
Reference: [17] <author> W.J. Savitch, </author> <title> Relationships between nondeterministic and deterministic space complexities, </title> <journal> J. Comp. and Syst. Sci. </journal> <volume> 4(2) </volume> (1970):177-192. 
Reference-contexts: No simulation of randomized-space (S) is known which uses less than O (S 2 ) deterministic space, a simulation which can be achieved by Savitch's theorem <ref> [17] </ref>. Indeed, from Savitch's proof it follows that a language accepted by a randomized-space (S) machine using R random bits is also accepted by a deterministic-space (S log (R=S)) machine. There is only one result that improves this bound for some R.
Reference: [18] <author> J.P. Schmidt, A. Siegel, A. Srinivasan, </author> <title> Chernoff-Hoeffding Bounds for Applications with Limited Independence, </title> <booktitle> Proceedings of the 4th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 331-340. </pages>
Reference-contexts: Suppose k ffil=6. If S is chosen at random as described above, then P r [jS " T j ffil=2] 1 e bk=2c : 6 We use the following lemma, which is a special case of Theorem 2.5 from <ref> [18] </ref>: Lemma 6 Let Y 1 ; : : : ; Y l be k-wise independent 0-1 random variables, Y = P l p ke 1=3 =, and suppose ff 1.
Reference: [19] <author> A. Wigderson and D. Zuckerman, </author> <title> Expanders that Beat the Eigenvalue Bound: Explicit Construction and Applications, </title> <booktitle> Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 245-251. </pages>
Reference-contexts: As in the constructions of [20, 21], this graph has good expansion properties, which are better than what can be obtained using eigenvalue methods. These ideas are further used in <ref> [19] </ref>. Weak random sources and deterministic amplification: Given an extractor and the first parameter x to it, an algorithm may go over all the possible values of y.
Reference: [20] <author> D. Zuckerman, </author> <title> General Weak Random Sources, </title> <booktitle> Proceedings of the 31st Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 534-543. </pages>
Reference-contexts: As in the constructions of <ref> [20, 21] </ref>, this graph has good expansion properties, which are better than what can be obtained using eigenvalue methods. These ideas are further used in [19]. <p> Weak random sources and deterministic amplification: Given an extractor and the first parameter x to it, an algorithm may go over all the possible values of y. It is not difficult to see that this can be used to simulate BPP using a ffi-source <ref> [20, 21] </ref>, or to do "deterministic amplification" [11, 8]. For the value of t we obtain, however, the running time of this simulation will not be polynomial but only quasi-polynomial. On the other hand, our simulation satisfies a stronger requirement: it truly approximates the acceptance probability of a BPP machine.
Reference: [21] <author> D. Zuckerman, </author> <title> Simulating BPP Using a General Weak Random Source, </title> <booktitle> Proceedings of the 32nd Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 79-89. 14 </pages>
Reference-contexts: In fact, one virtue of our construction is that it is elementary: the only tools we use are the Leftover Hash Lemma and k-wise independence. Our use of these tools is based on the methods of <ref> [21] </ref>. Indeed, the extractor can be viewed as a simplification and extension of the algorithms in [21], although in one sense the extractor is weaker (see below). One may think of extractors in various ways and contexts. We briefly sketch some of these below. <p> Our use of these tools is based on the methods of <ref> [21] </ref>. Indeed, the extractor can be viewed as a simplification and extension of the algorithms in [21], although in one sense the extractor is weaker (see below). One may think of extractors in various ways and contexts. We briefly sketch some of these below. <p> As in the constructions of <ref> [20, 21] </ref>, this graph has good expansion properties, which are better than what can be obtained using eigenvalue methods. These ideas are further used in [19]. <p> Weak random sources and deterministic amplification: Given an extractor and the first parameter x to it, an algorithm may go over all the possible values of y. It is not difficult to see that this can be used to simulate BPP using a ffi-source <ref> [20, 21] </ref>, or to do "deterministic amplification" [11, 8]. For the value of t we obtain, however, the running time of this simulation will not be polynomial but only quasi-polynomial. On the other hand, our simulation satisfies a stronger requirement: it truly approximates the acceptance probability of a BPP machine.
References-found: 21

