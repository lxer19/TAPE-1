URL: ftp://carrie.lcs.mit.edu/pub/sweeney/ifip.ps
Refering-URL: http://carrie.lcs.mit.edu/people/sweeney/bioprivacy.html
Root-URL: 
Email: Email: sweeney@ai.mit.edu  
Title: Datafly: a System for Providing Anonymity in Medical Data  
Author: Latanya Sweeney 
Keyword: Confidentiality, privacy, computational disclosure control, electronic medical records  
Address: Cambridge,MA 02139 USA  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: We present a computer program named Datafly that maintains anonymity in medical data by automatically generalizing, substituting, inserting and removing information as appropriate without losing many of the details found within the data. Decisions are made at the field and record level at the time of database access, so the approach can be used on the fly in role-based security within an institution, and in batch mode for exporting data from an institution. Often organizations release and receive medical data with all explicit identifiers, such as name, address, phone number, and Social Security number, removed in the incorrect belief that patient confidentiality is maintained because the resulting data look anonymous; however, we show that in most of these cases, the remaining data can be used to re-identify individuals by linking or matching the data to other databases or by looking at unique characteristics found in the fields and records of the database itself. When these less apparent aspects are taken into account, each released record can be made to ambiguously map to many possible people, providing a level of anonymity which the user determines. 
Abstract-found: 1
Intro-found: 1
Reference: [Ale78] <author> Alexander, L. and Jabine, T. </author> <title> (1978) Access to social security microdata files for research and statistical purposes. </title> <journal> Social Security Bulletin. </journal> <volume> 41 8. </volume>
Reference-contexts: The Social Security Administration (SSA) releases public-use files based on national samples with small sampling fractions (usually less than 1 in 1,000); the files contain no geographic codes, or at most regional or size-of-place designators <ref> [Ale78] </ref>. The SSA recognizes that data containing individuals with unique combinations of characteristics can be linked or matched with other data sources, so the SSA's general rule is that any subset of the data that can be defined in terms of combinations of characteristics must contain at least 5 individuals.
Reference: [Cla97] <author> Clayton, P., et al. </author> <title> (1997) Protecting electronic health information. </title> <institution> National Research Council. </institution> <address> Washington, DC: </address> <publisher> National Academy Press. </publisher>
Reference-contexts: The recent report from the National Research Council warns that as more HMOs and hospitals merge, the number of people with access increases by an order of magnitude since most of these systems allow full access to all records by any authorized person <ref> [Cla97] </ref>. As one would expect, there have been many abuses. For example, in 1995, Wood-ward [Woo95] cited an alarming case of a Maryland banker who cross-referenced a list of patients with cancer against a list of people who had outstanding loans at his bank and then called in the loans. <p> The New York Times reported cases of snooping by insiders in large hospital computer networks [Gra97], even though the use of a simple audit trail, a list of each person who looked up a patient's record, could curtail such behavior <ref> [Cla97] </ref>. Why are identified data so available? Lincoln and Essin present major concerns over the numerous uses to which medical records are put and discuss related problems when so many demands are made for its disclosure [Lin92]. We found an evolutionary problem as well.
Reference: [Coo97] <author> Cooper, G. et al. </author> <title> (1997) An evaluation of machine- learning methods for predicting pneumonia mortality. </title> <booktitle> Artificial Intelligence in Medicine 9, </booktitle> <volume> no. 2: </volume> <pages> 107-138. </pages>
Reference-contexts: Analysis of the detailed information contained within electronic medical records promises many advantages to society, including improvements in medical care, reduced institution costs, the development of predictive and diagnostic support systems <ref> [Coo97] </ref>, and the integration of applicable data from multiple sources into a unified display for clinicians [Koh96]; but these benefits require sharing the contents of medical records with secondary viewers, such as researchers, economists, statisticians, administrators, consultants, and computer scientists, to name a few.
Reference: [Dun87] <author> Duncan, G. and Lambert, D. </author> <title> (1987) The risk of disclosure for microdata. </title> <booktitle> Proceedings of the Bureaus of the Census Third Annual Research Conference. </booktitle> <address> Washington: </address> <institution> Bureau of the Census. </institution>
Reference-contexts: What is customary is to measure risk against a specific compromising technique, such as linking to known databases, that we assume the recipient is using. Several researchers have proposed mathematical measures of the risk. Most of these calculations consist of computing the conditional probability of the intruder's success <ref> [Dun87] </ref>. Certainly, producing anonymous data requires criteria against which to check resulting data and to lo-cate sensitive values. If this is based only on the database itself, the minimum bin sizes and sampling fractions may be far from optimal and may not reflect the general population.
Reference: [Dun91] <author> Duncan, G. and Mukherjee, S. </author> <title> (1991) Microdata disclosure limitation in statistical databases: query size and random sample query control. </title> <booktitle> IEEE Symposium on Research in Security and Privacy. </booktitle> <address> Oakland: IEEE2986 :278-287. </address>
Reference-contexts: Possible replacement strategies not used in Datafly include changing singletons to median values, swapping values and inserting complementary records to boost overall bin measurements. These are ways to add noise to the data <ref> [Dun91] </ref>, but were not elected in this implementation of Datafly, so that each value in the data is accurate though not necessarily as specific as the original. 3.6 Combinations of fields Table 4 provides an example wherein there is only one occurrence of a female Caucasian even though there are many
Reference: [Gra97] <author> Grady, D. </author> <title> (1997) Hospital files as open book. </title> <address> The New York Times; New York, March 12, 1997:C8. </address>
Reference-contexts: Linowes and Spencer [Lin90] surveyed 87 Fortune 500 companies with a total of 3.2 million employees and found that 35% said they used medical records to make decisions about employees. The New York Times reported cases of snooping by insiders in large hospital computer networks <ref> [Gra97] </ref>, even though the use of a simple audit trail, a list of each person who looked up a patient's record, could curtail such behavior [Cla97].
Reference: [Hun96] <author> Hundepool, A. and Willenborg, L. </author> <title> (1996) and Tau-argus: software for statistical disclosure control. </title> <booktitle> Third International Seminar on Statistical Confidentiality. </booktitle> <address> Bled. </address>
Reference-contexts: Statistics Netherlands has already produced, though has not yet released, a first version of a program named -Argus that seeks to accomplish this goal <ref> [Hun96] </ref>. The -Argus program is already considered the official confidentiality software of the European community even though Statistics Netherlands admittedly considers this first version a rough draft. A presentation of the concepts on which -Argus is based can be found in Willenborg and De Waal [Wil96].
Reference: [Isr94] <editor> Israel, R. et al. </editor> <booktitle> (1994) The international classification of diseases. Deaprtment of Health and Human Services Publication. </booktitle> <address> (PHS) 94-1260. </address>
Reference: [Lin92] <author> Lincoln, T. and Essin, D. </author> <title> (1992) The computer-based patient record: issues of organization, security and confidentiality. Database Security. </title> <publisher> Elsevier Science Publishers (IFIP) 1-19. </publisher>
Reference-contexts: Why are identified data so available? Lincoln and Essin present major concerns over the numerous uses to which medical records are put and discuss related problems when so many demands are made for its disclosure <ref> [Lin92] </ref>. We found an evolutionary problem as well. Most electronic medical records are really two medical records in one bundle. This duality came about primarily for historical reasons.
Reference: [Kir94] <author> Kirkendall, N. et al. </author> <title> (1994) Report on statistical disclosure limitation methodology. Statistical Policy Working Paper. </title> <institution> Washington: Office of Management and Budget, </institution> <month> 22. </month>
Reference-contexts: Rather than removing entire records when one or more fields contain outlier information, as is done in the Datafly System, the - Argus System simply suppresses or blanks out the outlier values at the cell-level; this process is called cell suppression <ref> [Kir94] </ref>. The resulting data typically contain all the rows and columns of the original data though there may be missing values in some cell locations. Recall Table 4 presented earlier in which there were many Caucasians and many females, but only one female Caucasian in the database. <p> In concluding our comparison of these systems, one drawback of both systems is the determination of the proper bin size. With large governmental databases, some agencies require a bin size of 5 and others 3 with virtually no geographic information <ref> [Kir94] </ref>. Geographic identification, as we discussed much earlier, is another problem when releasing medical data since the medical institution typically services patients in its geographical area. Therefore, these bin sizes are inappropriate for most medical data. <p> For example, the existence of rather extensive registers of business establishments in the hands of government agencies, trade associations and firms like Dunn and Bradstreet has virtually ruled out the possibility of releasing database information about businesses <ref> [Kir94] </ref>. What is needed is a contractual arrangement between the recipient and the producer to make the trust explicit and share the risk. Below are some guidelines that make it clear which fields need to be protected against linking since the recipient is required to provide such a list.
Reference: [Koh94] <author> Kohane, I. </author> <title> (1994) Getting the data in: three-year experience with a pediatric electronic medical record system. </title> <editor> In: Ozbolt J., ed. </editor> <booktitle> Proceedings, Symposium on Computer Applications in Medical Care. </booktitle> <address> Washington, DC: Hanley & Belfus, </address> <publisher> Inc. </publisher> <pages> 457-461. </pages>
Reference-contexts: an operational description of how Datafly works, in the next section, we will use Datafly to produce anonymous data from the pediatric medical database. 3.8 Multiple Records Per Patient In addition to the Cambridge voter data described earlier, we also used a de-identified subset of a pediatric medical record system <ref> [Koh94] </ref>. It consisted of 300 patient records with 7617 visits and 285 fields stored in over 12 relational database tables. We were only concerned with fields that are commonly exported to government agencies, researchers and consultants. Table 7 lists some of the data fields used.
Reference: [Koh96] <author> Kohane, I., et al. </author> <title> (1996) Sharing electronic medical records across heterogeneous and competing institutions. </title> <editor> In: Cimino, J., ed. </editor> <booktitle> Proceedings, American Medical Infor-matics Association. </booktitle> <address> Washington, DC: Hanley & Belfus, </address> <publisher> Inc, </publisher> <pages> 608-612. </pages>
Reference-contexts: Analysis of the detailed information contained within electronic medical records promises many advantages to society, including improvements in medical care, reduced institution costs, the development of predictive and diagnostic support systems [Coo97], and the integration of applicable data from multiple sources into a unified display for clinicians <ref> [Koh96] </ref>; but these benefits require sharing the contents of medical records with secondary viewers, such as researchers, economists, statisticians, administrators, consultants, and computer scientists, to name a few.
Reference: [Lin90] <author> Linowes, D. and Spencer, R. </author> <title> (1990) Privacy: the workplace issue of the '90s. The John Marshall Law Review , 23, </title> <type> 591-620. </type>
Reference-contexts: For example, in 1995, Wood-ward [Woo95] cited an alarming case of a Maryland banker who cross-referenced a list of patients with cancer against a list of people who had outstanding loans at his bank and then called in the loans. Linowes and Spencer <ref> [Lin90] </ref> surveyed 87 Fortune 500 companies with a total of 3.2 million employees and found that 35% said they used medical records to make decisions about employees.
Reference: [Ski92] <author> Skinner, C. and Holmes, D. </author> <title> (1992) Modeling population uniqueness. </title> <booktitle> Proceedings of the International Seminar on Statistical Confidentiality. International Statistical Institute, </booktitle> <pages> 175-199. </pages>
Reference-contexts: However, researchers have developed and tested several methods for estimating the percentage of unique values in the general population based on a smaller database <ref> [Ski92] </ref>. These methods are based on subsampling techniques and equivalence class structure.
Reference: [Swe96] <author> Sweeney, L. </author> <title> (1996) Replacing personally-identifying information in medical records, the Scrub system. </title> <editor> In: Cimino, J., ed. </editor> <booktitle> Proceedings, American Medical Infor-matics Association. </booktitle> <address> Washington, DC: Hanley & Belfus, </address> <publisher> Inc, </publisher> 1996 333-337. 
Reference-contexts: In all the results reported herein, b and b f are calculated with r 1 = 0 and r 2 determined by the sawtooth function described previously. 3.5 Replacement algorithms As in the Scrub System <ref> [Swe96] </ref>, each entity, or in this case each field, has an algorithm that is responsible for producing replacement values. These replacement algorithms are quite diverse and offer a range of options.
Reference: [Swe97] <author> Sweeney, L. </author> <title> (1997) Weaving technology and policy together to maintain confidentiality. </title> <journal> Journal of Law, Medicine and Ethics. Boston: American Association of Law, Medicine and Ethics, </journal> <volume> 25 :98-110. </volume>
Reference-contexts: However, the Scrub System merely de-identifies information and cannot guarantee anonymity. There are three major difficulties in providing anonymous data. One of the problems is that anonymity is in the eye of the beholder <ref> [Swe97] </ref>. Consider an HIV testing center located in a heavily populated community within a large metropolitan area. <p> Clearly, the risks of re-identifying data depend both on the content of the released data and on related information available to the recipient. A second problem with producing anonymous data concerns unique and unusual information appearing within the data themselves <ref> [Swe97] </ref>. Consider the database shown in Table 3. It is not surprising that the Social Security number is uniquely identifying, or given the size of the database, that the birth date is also unique.
Reference: [Tur90] <author> Turn, R. </author> <booktitle> (1990) Information privacy issues for the 1990s. IEEE Symposium on Research in Security and Privacy. </booktitle> <address> Oakland: IEEE2884 :394-400. </address>
Reference-contexts: 1 INTRODUCTION Sharing and disseminating electronic medical records while maintaining a commitment to patient confidentiality is one of the biggest challenges facing medical informatics and society at large <ref> [Tur90] </ref>. A few years ago, in 1994, we surveyed some college students at Harvard and in Taiwan.
Reference: [Wil96] <author> Willenborg, L. and De Waal, T. </author> <title> (1996) Statistical disclosure control in practice. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The -Argus program is already considered the official confidentiality software of the European community even though Statistics Netherlands admittedly considers this first version a rough draft. A presentation of the concepts on which -Argus is based can be found in Willenborg and De Waal <ref> [Wil96] </ref>. The program -Argus, like the Datafly System, makes decisions based on bin sizes, generalizes values within fields as needed, and removes extreme outlier information from the released data. The -Argus program is written in C++ and runs under Windows on a PC.
Reference: [Woo95] <author> Woodward, B. </author> <title> (1995) The computer-based patient record and confidentiality. </title> <journal> The New England Journal of Medicine; Boston: Massachusetts Medical Society, </journal> <pages> 333 1419-1422. </pages>
Reference-contexts: As one would expect, there have been many abuses. For example, in 1995, Wood-ward <ref> [Woo95] </ref> cited an alarming case of a Maryland banker who cross-referenced a list of patients with cancer against a list of people who had outstanding loans at his bank and then called in the loans.
Reference: [Woo96] <author> Woodward, B. </author> <title> (1996) Patient privacy in a computerized world. </title> <booktitle> 1997 Medical and Health Annual 1997. </booktitle> <address> Chicago: </address> <publisher> Encyclopedia Britannica, Inc. </publisher> <pages> 256-259. </pages>
Reference-contexts: In the case of electronic medical records, the public's expectations may not be consistent with actual practice and the public may not be aware that their perceived social contract is tenuous. In 1996, TIME/CNN conducted a telephone poll of 406 adults in the United States <ref> [Woo96] </ref> in which 88% replied that to the best of their knowledge, no personal medical information about themselves had ever been disclosed without their permission. <p> Woodward makes a compelling argument that to the public, patient confidentiality implies that only people directly involved in their care will have access to their medical records and that these people will be bound by strict ethical and legal standards that prohibit further disclosure <ref> [Woo96] </ref>. The public are not likely to accept that their records are kept "confidential" if large numbers of people have access to their contents.
References-found: 20

