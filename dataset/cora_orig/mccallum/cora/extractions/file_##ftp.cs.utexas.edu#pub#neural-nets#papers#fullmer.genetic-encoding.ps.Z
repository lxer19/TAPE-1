URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/fullmer.genetic-encoding.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: email fullmer,risto@cs.utexas.edu  
Title: USING MARKER-BASED GENETIC ENCODING OF NEURAL NETWORKS TO EVOLVE FINITE-STATE BEHAVIOUR  
Author: Brad Fullmer and Risto Miikkulainen 
Address: Austin, Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences The University of Texas at  
Abstract: A new mechanism for genetic encoding of neural networks is proposed, which is loosely based on the marker structure of biological DNA. The mechanism allows all aspects of the network structure, including the number of nodes and their connectivity, to be evolved through genetic algorithms. The effectiveness of the encoding scheme is demonstrated in an object recognition task that requires artificial creatures (whose behaviour is driven by a neural network) to develop high-level finite-state exploration and discrimination strategies. The task requires solving the sensory-motor grounding problem, i.e. developing a functional understanding of the effects that a creature's movement has on its sensory input. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barto, A. G., Sutton, R. S., and Anderson, C. W. </author> <year> 1983. </year> <title> Neuronlike adaptive elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 13 </volume> <pages> 834-846. </pages>
Reference-contexts: Many algorithms, such as backpropagation (Rumel-hart et al., 1986), require that the correct output is known at each input situation. This requirement is relaxed in reinforcement learning, where only an estimate of the goodness of the action (or sequence of actions) is needed for learning <ref> (Barto et al., 1983) </ref>. In fl This research was supported in part by a grant from the University of Texas Research Institute to the second author.
Reference: <author> Collins, R. J. and Jefferson, D. R. </author> <year> 1991. </year> <title> AntFarm: Towards simulated evolution. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Genetic algorithms have been used previously to evolve various types of behaviour in artificial creatures such as following a broken trail (Jefferson et al., 1991), foraging for food <ref> (Collins and Jefferson, 1991) </ref> and communicating instructions (Werner and Dyer, 1991). A central question in the neuro-evolution approach is how the network structure can be represented in terms of genetic information so that genetic algorithms are maximally effective. <p> A creature takes an action based on its current visual input and its internal state, and updates its internal state. Similar behaviour also evolves in other neuro-evolution systems such as Genesys (Jef-ferson et al., 1991) and AntFarm <ref> (Collins and Jeffer-son, 1991) </ref>. An interesting direction for future work is to determine how far this approach can be carried on. ANNs even with finite number of nodes are Turing-equivalent (Siegelman and Sontag, 1991).
Reference: <author> Dress, W. B. </author> <year> 1987. </year> <title> Darwinian optimization of synthetic neural systems. </title> <booktitle> In Proceedings of the IEEE First International Conference on Neural Networks. </booktitle> <address> Piscataway, NJ: </address> <publisher> IEEE. </publisher>
Reference: <author> Goldberg, D. E. </author> <year> 1988. </year> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In other words, the constant nodes act as bias nodes, which are commonly used in place of threshold parameters in e.g. backpropagation learning (Rumelhart et al., 1986). 4 The Genetic Algorithm 4.1 Overall Strategy The genetic algorithm used in our experiments is based on standard techniques <ref> (Goldberg, 1988) </ref>. After all One Iteration of GA for a Population of 50 1. Combine the best 15 chromosomes to form 30 new chromosomes (pairing each with another chromosome whose score is at least as good). 2. Replace the worst 30 chromosomes with the new offspring. 3. <p> Finally, every creature except the top-scorer undergoes mutation. A population of 50 creatures was used in the experiments. The genetic algorithm is summarized in table 1. It is common in genetic algorithm experiments to allow the genetic operators to manipulate the chromosome at the bit level <ref> (Goldberg, 1988) </ref>. Our scheme, however, treats the integer as the basic genetic unit. This approach was adopted mainly to reduce processing overhead, thereby allowing larger chromosomes. 4.2 Crossover The standard two-point crossover approach is used to generate offspring (Goldberg, 1988). <p> allow the genetic operators to manipulate the chromosome at the bit level <ref> (Goldberg, 1988) </ref>. Our scheme, however, treats the integer as the basic genetic unit. This approach was adopted mainly to reduce processing overhead, thereby allowing larger chromosomes. 4.2 Crossover The standard two-point crossover approach is used to generate offspring (Goldberg, 1988). The parent chromosomes are partitioned at two randomly chosen points (figure 4). Since the chromosome is treated as a circular entity, this effectively breaks the chromosome into two continuous chunks. An offspring chromosome is constructed by taking one chunk from each parent. <p> This would introduce new variability in the gene pool. However, much of the same variability can also be achieved through mutation. 4.3 Mutation The standard mutation operation works by flipping a bit in a chromosome <ref> (Goldberg, 1988) </ref>. To simulate the natural variability of this scheme at the integer level, the following approach is used: individual integer elements are mutated by randomly selecting a delta value within the legal range and adding the delta to the existing integer value.
Reference: <author> Hancock, P. J. B. </author> <year> 1990. </year> <title> GANNET: Design of a neural net for face recognition by genetic algorithm. </title> <note> Unpublished Research Report. </note>
Reference: <author> Holland, J. H. </author> <year> 1975. </year> <title> Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press. </publisher>
Reference: <author> Jefferson, D., Collins, R., Cooper, C., Dyer, M., Flowers, M., Korf, R., Taylor, C., and Wang, A. </author> <year> 1991. </year> <title> Evolution as a theme in artificial life: The genesys/tracker system. </title> <editor> In Farmer, J. D., Lang-ton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: As in biological evolution, the population adjusts to evolutionary pressures by developing advantageous attributes including high-level behavioural strategies and low-level sensory processing capabilities. Genetic algorithms have been used previously to evolve various types of behaviour in artificial creatures such as following a broken trail <ref> (Jefferson et al., 1991) </ref>, foraging for food (Collins and Jefferson, 1991) and communicating instructions (Werner and Dyer, 1991). A central question in the neuro-evolution approach is how the network structure can be represented in terms of genetic information so that genetic algorithms are maximally effective. <p> Genetic algorithms have been used previously to evolve various types of behaviour in artificial creatures such as following a broken trail (Jefferson et al., 1991), foraging for food <ref> (Collins and Jefferson, 1991) </ref> and communicating instructions (Werner and Dyer, 1991). A central question in the neuro-evolution approach is how the network structure can be represented in terms of genetic information so that genetic algorithms are maximally effective. <p> The creature can perform the following actions: 1. Turn left 2. Turn right 3. Move forward 4. Do nothing The fourth option is included so that the creature can change the internal state of its neural net without changing its position <ref> (Jefferson et al., 1991) </ref>. The creature is initially placed on a random square (one not occupied by the object) and faces a random direction. The creature is given a lifespan of 35 cycles, where each cycle consists of: 1.
Reference: <author> McClelland, J. L., Rumelhart, D. E., and Hinton, G. E. </author> <year> 1986. </year> <title> The appeal of parallel distributed processing. </title> <editor> In Rumelhart, D. E. and McClel-land, J. L., editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Mjolsness, E., Sharp, D. H., and Alpert, B. K. </author> <year> 1988. </year> <title> Scaling, machine learning and genetic neural nets. </title> <type> Technical Report YALEU/DCS/TR-613: </type> <institution> Department of Computer Science, Yale University. </institution>
Reference: <author> Rothwell, N. V. </author> <year> 1988. </year> <title> Understanding Genetics. </title> <address> New York: </address> <publisher> Oxford University Press, Inc. Fourth edition. </publisher>
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, R. J. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McClel-land, J. L., editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Other nodes can reference these nodes as inputs, effectively establishing a non-zero threshold for that node. In other words, the constant nodes act as bias nodes, which are commonly used in place of threshold parameters in e.g. backpropagation learning <ref> (Rumelhart et al., 1986) </ref>. 4 The Genetic Algorithm 4.1 Overall Strategy The genetic algorithm used in our experiments is based on standard techniques (Goldberg, 1988). After all One Iteration of GA for a Population of 50 1.
Reference: <author> Siegelman, H. and Sontag, E. D. </author> <year> 1991. </year> <title> Neural nets are universal computing devices. </title> <type> Technical Report SYCON-91-08: </type> <institution> Rutgers Center for Systems and Control, Rutgers University. </institution>
Reference-contexts: Similar behaviour also evolves in other neuro-evolution systems such as Genesys (Jef-ferson et al., 1991) and AntFarm (Collins and Jeffer-son, 1991). An interesting direction for future work is to determine how far this approach can be carried on. ANNs even with finite number of nodes are Turing-equivalent <ref> (Siegelman and Sontag, 1991) </ref>.
Reference: <author> Werner, G. M. and Dyer, M. G. </author> <year> 1991. </year> <title> Evolution of communication in artificial organisms. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Genetic algorithms have been used previously to evolve various types of behaviour in artificial creatures such as following a broken trail (Jefferson et al., 1991), foraging for food (Collins and Jefferson, 1991) and communicating instructions <ref> (Werner and Dyer, 1991) </ref>. A central question in the neuro-evolution approach is how the network structure can be represented in terms of genetic information so that genetic algorithms are maximally effective. In this paper, a new representation mechanism that is loosely based on the marker structure of DNA is proposed.
References-found: 13

