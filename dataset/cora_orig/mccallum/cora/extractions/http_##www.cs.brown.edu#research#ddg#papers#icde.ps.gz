URL: http://www.cs.brown.edu/research/ddg/papers/icde.ps.gz
Refering-URL: http://www.cs.brown.edu/research/ddg/publications.html
Root-URL: http://www.cs.brown.edu
Email: sa@cs.brown.edu  franklin@cs.umd.edu  sbz@cs.brown.edu  
Title: Prefetching from a Broadcast Disk  
Author: Swarup Acharya Michael Franklin Stanley Zdonik 
Affiliation: Brown University  University of Maryland  Brown University  
Date: Feb 1996  
Note: Appears in Proceedings of the International Conference on Data Engineering, New Orleans, LA,  
Abstract: Broadcast Disks have been proposed as a means to efficiently deliver data to clients in asymmetric environments where the available bandwidth from the server to the clients greatly exceeds the bandwidth in the opposite direction. A previous study investigated the use of cost-based caching to improve performance when clients access the broadcast in a demand-driven manner [AAF95]. Such demand-driven access however, does not fully exploit the dissemination-based nature of the broadcast, which is particularly conducive to client prefetching. With a Broadcast Disk, pages continually flow past the clients so that, in contrast to traditional environments, prefetching can be performed without placing additional load on shared resources. We argue for the use of a simple prefetch heuristic called PT and show that PT balances the cache residency time of a data item with its bandwidth allocation. Because of this tradeoff, PT is very tolerant of variations in the broadcast program. We describe an implementable approximation for PT and examine its sensitivity to access probability estimation errors. The results show that the technique is effective even when the probability estimation is substantially different from the actual values. 
Abstract-found: 1
Intro-found: 1
Reference: [AAF95] <author> S. Acharya, R. Alonso, M. Franklin, and S. Zdonik, </author> <title> Broadcast Disks: Data Management for Asymmetric Communication Environments," </title> <booktitle> Proc. of ACM SIGMOD, </booktitle> <address> Santa Cruz, CA (May 1995). </address>
Reference-contexts: Thus, a designer can create an arbitrarily fine-grained memory hierarchy that is tailored to meet the needs of any particular client population. In <ref> [AAF95] </ref>, we demonstrate how the multi-disk scheme can produce performance improvements over a flat (one-disk) broadcast when the client access pattern is skewed. <p> Broadcast Environment Our model of the broadcast environment has been described previously (<ref> [AAF95] </ref>). The results presented in this paper are based on the same underlying model, extended to include prefetching. In this section we briefly describe the model, focusing on the modifications that were required to introduce prefetching. As in [AAF95], we model a broadcast environment that is restricted in several ways: * The client population and their access patterns do not change. <p> Multiple disks can be superimposed on a single broadcast channel by broadcasting some pages more frequently than others. Each disk corresponds to those pages which have the same broadcast frequency. The desirable characteristics of a broadcast program have been outlined in <ref> [AAF95] </ref>. <p> In this paper we explain the broadcast generation process using a simple example. For a detailed description of the algorithm, the reader is referred to <ref> [AAF95] </ref>. similar access probabilities. Each of these ranges will be a separate disk in the broadcast. In the example, pages of the first disk are to be broadcast twice as often as those in the second and four times as often as those of the slowest disk. <p> In general, the two figures exhibit similar behavior. Due to the uniform client access pattern, increasing disk skew (D) harms performance here, as the best broadcast for a uniform access distribution is a flat broadcast <ref> [AAF95] </ref>. In both graphs, PT outperforms PIX and is less sensitive to D in the range of 0 (flat disk) to 4 (at which the pages on the fastest disk are broadcast nine times more frequently than pages on the slowest disk). <p> A page is considered to be a prefetch candidate only if it is in the twoQ. 5.1 Expt. 5: LIX vs. AP T In this section, we compare the performance of AP T with LIX . LIX was introduced in <ref> [AAF95] </ref> as an efficient constant time approximation of PI X . LIX maintains an LRU-style chain ordered by probability of access for each disk of a multi-disk broadcast. LIX also keeps a running probability estimate for each broadcast page based on its past history of access. <p> Stashing and Hoarding used in the mobile computing environment ([KiS92], [TLA95]) are very similar to prefetching. However, their focus is to improve availability in the file system as opposed to performance. 7 Summary and Conclusions In a previous work <ref> [AAF95] </ref>, we described our notion of a multilevel broadcast disk and examined techniques for managing the client cache in this style of broadcast environment.
Reference: [AFZ95] <author> S. Acharya, M. Franklin, and S. Zdonik, </author> <title> Dissemination-based Data Delivery Using Broadcast Disks"," </title> <journal> IEEE Personal Communications 2(6) , (Dec. </journal> <year> 1995). </year>
Reference-contexts: In some extreme cases, such as disconnection in mobile computing environments, there may be no upstream (from clients to servers) communication capacity at all. Broadcast Disks ([AAF95], <ref> [AFZ95] </ref>) was introduced as a technique for delivering data to clients in asymmetric environments. It is a push-based technique data transfer from the server to clients is initiated by the server, rather than by explicit client requests (as in a traditional pull-based system).
Reference: [Amm87] <author> M. H. Ammar, </author> <title> Response Time in a Teletext System: An Individual User's Perspective," </title> <journal> IEEE Trans. on Communications 35(11) </journal> <pages> 1159-1170, </pages> <year> (1987). </year>
Reference-contexts: Our simple counting-based probability estimator can, thus, be replaced by any of the other more sophisticated models to produce even better results. There has also been some work on prefetching in Teletext systems (<ref> [Amm87] </ref>, [Won88]). In [Amm87], a caching strategy called the Linked Page scheme is described which uses embedded links in each page to decide what to prefetch next. Stashing and Hoarding used in the mobile computing environment ([KiS92], [TLA95]) are very similar to prefetching.
Reference: [BGH92] <author> T. G. Bowen, G. Gopal, G. Herman, T. Hickey, K. Lee, W. Mans-field, J. Raitz, and A. Weinrib, </author> <title> The Datacycle Architecture," </title> <note> CACM 35(12) (December 1992). </note>
Reference: [CKV93] <author> K. Curewitz, P. Krishnan, and J. S. Vitter, </author> <title> Practical Prefetching via Data Compression," </title> <booktitle> Proc. of ACM SIGMOD, </booktitle> <address> Washington, DC (May 1993). </address>
Reference: [DDY90] <author> Asit Dan, D. M. Dias, and P. S. Yu, </author> <title> The Effect of Skewed Access on Buffer Hits and Data Contention in a Data Sharing Environment," </title> <booktitle> VLDB (1990). </booktitle>
Reference-contexts: It produces access patterns that become increasingly skewed as increases the probability of accessing any page numbered i is proportional to (1=i) . Similar to earlier models of skewed access <ref> [DDY90] </ref>, we partitioned the pages into regions of Re-gionSize pages each, such that the probability of accessing any page within a region is uniform; the Zipf distribution is applied to these regions. Regions do not overlap and thus, there are AccessRange/RegionSize regions.
Reference: [Gif90] <author> D. Gifford, </author> <title> Polychannel Systems for Mass Digital Communications," </title> <booktitle> Communication of the ACM 33(2) (February 1990). </booktitle>
Reference-contexts: As described earlier, increasing the number of regions also linearly increases the cost of the algorithm. For the simulation space studied, four regions performed best. 6 Related Work The basic idea of broadcasting information has been discussed before ([BGH92], <ref> [Gif90] </ref>, [IVB94]). Our studies deviate from these in that we consider multi-level disks and their relationship to cache management. Prefetching has been studied extensively as a technique to improve user performance in various areas including databases, operating systems and processor architectures.
Reference: [GrA94] <author> J. Griffieon and R. Appleton, </author> <title> Reducing File System Latency using a Predictive Approach," </title> <booktitle> Proc. of USENIX Summer Tech. Conf , (June 1994). </booktitle>
Reference-contexts: Pre-paging based on hints was suggested in [Tri79]. The other class of prefetching algorithms is based on inferring access patterns from a stream user requests ([CKV93], [KoE91], [PaZ91], <ref> [GrA94] </ref> to name a few). Each of these techniques uses the access stream to develop a model of the user behavior. Our work leans towards the second category in the sense that we develop a model of client behavior based on past accesses.
Reference: [IVB94] <author> T. Imielinski, S. Viswanathan, and B. R. Badrinath, </author> <title> Energy Efficient Indexing on Air," </title> <booktitle> ACM SIGMOD (1994). </booktitle>
Reference-contexts: As described earlier, increasing the number of regions also linearly increases the cost of the algorithm. For the simulation space studied, four regions performed best. 6 Related Work The basic idea of broadcasting information has been discussed before ([BGH92], [Gif90], <ref> [IVB94] </ref>). Our studies deviate from these in that we consider multi-level disks and their relationship to cache management. Prefetching has been studied extensively as a technique to improve user performance in various areas including databases, operating systems and processor architectures.
Reference: [JoS94] <author> T. Johnson and D. Shasha, </author> <title> 2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm," </title> <booktitle> Proc. 20th VLDB Conf., </booktitle> <address> Santiago, Chile (1994). </address>
Reference-contexts: This simple approach gave us acceptable performance. Unlike demand-driven caching, prefetching also requires the access probabilities of pages not in the cache to determine if they are worth prefetching. We use a technique similar to the 2Q approach proposed in <ref> [JoS94] </ref> of maintaining a second queue (twoQ). When a page is evicted from the cache, its page number and its probability of access is entered into the twoQ in a FIFO fashion.
Reference: [KiS92] <author> J. Kistler and M. Satyanarayanan, </author> <title> Disconnected Operation in Coda File System," </title> <journal> ACM Trans. of Computer Systems 10(1) </journal> <pages> 3-25, </pages> <month> (Feb </month> <year> 1992). </year>
Reference: [Knu81] <author> Don Knuth, </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol II, </volume> <publisher> Addison Wesley, </publisher> <year> 1981. </year>
Reference: [KoE91] <author> D. Kotz and C. S. Ellis, </author> <title> Practical Prefeteching Techniques for Parallel File Systems," </title> <booktitle> Proc. of First PDIS, </booktitle> <address> Miami beach, FL (Dec 1991). </address>
Reference-contexts: Pre-paging based on hints was suggested in [Tri79]. The other class of prefetching algorithms is based on inferring access patterns from a stream user requests ([CKV93], <ref> [KoE91] </ref>, [PaZ91], [GrA94] to name a few). Each of these techniques uses the access stream to develop a model of the user behavior. Our work leans towards the second category in the sense that we develop a model of client behavior based on past accesses.
Reference: [PaZ91] <author> M. Palmer and S. Zdonik, </author> <title> Fido: A Cache That Learns to Fetch," </title> <booktitle> VLDB, </booktitle> <address> Barcelona (1991). </address>
Reference-contexts: Pre-paging based on hints was suggested in [Tri79]. The other class of prefetching algorithms is based on inferring access patterns from a stream user requests ([CKV93], [KoE91], <ref> [PaZ91] </ref>, [GrA94] to name a few). Each of these techniques uses the access stream to develop a model of the user behavior. Our work leans towards the second category in the sense that we develop a model of client behavior based on past accesses.
Reference: [PaG94] <author> R. H. Patterson and G. A. Gibson, </author> <title> Exposing I/O Concurrency with Informed Prefetching," </title> <booktitle> Proc. of Third PDIS, </booktitle> <address> Austin, TX (Sept. </address> <year> 1994). </year>
Reference-contexts: Prefetching has been studied extensively as a technique to improve user performance in various areas including databases, operating systems and processor architectures. Prefetching techniques usually fall into two categories prefetching based on user hints and prefetching based past access history. <ref> [PaG94] </ref> proposes Transparent-Informed Prefetching which exploits I/O concurrency in disk arrays using hints from applications. Pre-paging based on hints was suggested in [Tri79]. The other class of prefetching algorithms is based on inferring access patterns from a stream user requests ([CKV93], [KoE91], [PaZ91], [GrA94] to name a few).
Reference: [RoD90] <author> J. T. Robinson and M. V. Devarakonda, </author> <title> Data Cache Management Using Frequency-Based Replacement," </title> <booktitle> Proc. of ACM SIGMETRICS, </booktitle> <address> Boulder, CO (1990). </address>
Reference-contexts: As long as the access pattern is not changing, a longer sampling period should produce more accurate results. Such counting-based schemes have been proposed before for estimating probabilities for page replacement. The CLOCK [SPG90] and the frequency-based cache management algorithm introduced in <ref> [RoD90] </ref> are two examples. In general, such a probability model will likely not be completely accurate. This section describes experiments which analyze APT 's sensitivity to inaccuracies in the probability estimation. Different levels of accuracy are generated by varying the sample length in the learning run.
Reference: [ShL94] <author> S. Shekhar and D. Liu, </author> <title> Genesis and Advanced Traveler Information Systems(ATIS): </title> <booktitle> Killer Applications for Mobile Computing?," Proc. of the Mobidata Workshop, </booktitle> <institution> Rutgers Univ., </institution> <address> New Brunswick, NJ (Nov 1994). </address>
Reference: [SPG90] <author> A. Silberschatz, J. Peterson, and P. Galvin, </author> <title> Operating System Concepts, 3rd Edition, </title> <publisher> Addison Wesley, </publisher> <year> 1990. </year>
Reference-contexts: As long as the access pattern is not changing, a longer sampling period should produce more accurate results. Such counting-based schemes have been proposed before for estimating probabilities for page replacement. The CLOCK <ref> [SPG90] </ref> and the frequency-based cache management algorithm introduced in [RoD90] are two examples. In general, such a probability model will likely not be completely accurate. This section describes experiments which analyze APT 's sensitivity to inaccuracies in the probability estimation.
Reference: [TLA95] <author> C. Tait, H. Lei, S. Acharya, and H. Chang, </author> <title> Intelligent File Hoarding for Mobile Computers," </title> <booktitle> Proc. ACM Conf. on Mobile Computing and Networking, </booktitle> <address> Berkeley, CA (Nov. </address> <year> 1995). </year>
Reference-contexts: There has also been some work on prefetching in Teletext systems ([Amm87], [Won88]). In [Amm87], a caching strategy called the Linked Page scheme is described which uses embedded links in each page to decide what to prefetch next. Stashing and Hoarding used in the mobile computing environment ([KiS92], <ref> [TLA95] </ref>) are very similar to prefetching.
Reference: [Tri79] <author> K. Trivedi, </author> <title> An Analysis of Prepaging," </title> <booktitle> Computing 22(3), </booktitle> <year> (1979). </year>
Reference-contexts: Prefetching techniques usually fall into two categories prefetching based on user hints and prefetching based past access history. [PaG94] proposes Transparent-Informed Prefetching which exploits I/O concurrency in disk arrays using hints from applications. Pre-paging based on hints was suggested in <ref> [Tri79] </ref>. The other class of prefetching algorithms is based on inferring access patterns from a stream user requests ([CKV93], [KoE91], [PaZ91], [GrA94] to name a few). Each of these techniques uses the access stream to develop a model of the user behavior.
Reference: [Won88] <author> J. Wong, </author> <title> Broadcast Delivery," </title> <booktitle> Proceedings of the IEEE </booktitle> 76(12) 1566-1577(Dec. 1988). 10 
Reference-contexts: Our simple counting-based probability estimator can, thus, be replaced by any of the other more sophisticated models to produce even better results. There has also been some work on prefetching in Teletext systems ([Amm87], <ref> [Won88] </ref>). In [Amm87], a caching strategy called the Linked Page scheme is described which uses embedded links in each page to decide what to prefetch next. Stashing and Hoarding used in the mobile computing environment ([KiS92], [TLA95]) are very similar to prefetching.
References-found: 21

