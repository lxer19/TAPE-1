URL: http://american.cs.ucdavis.edu/publications/cse-92-24.ps
Refering-URL: http://www.cs.ucdavis.edu/research/tech-reports/1992.html
Root-URL: http://www.cs.ucdavis.edu
Email: (tyson@cs.ucdavis.edu) (arp@tosca.colorado.edu)  
Title: d d A Study of Single-Chip Processor/Cache Organizations for Large Numbers of Transistors  
Author: Matthew Farrens Andrew R. Pleszkun Gary Tyson 
Keyword: Cache, Multiple Processor, VLSI  
Note: 1  
Address: Davis, CA 95616  (farrens@cs.ucdavis.edu) Boulder, CO 80309-0425  
Affiliation: Computer Science Department Department of Electrical and University of California, Davis Computer Engineering  University of Colorado-Boulder  
Abstract: This paper presents an examination of different cache and processor configurations assuming transistor densities will continue to increase as they have in the past. While in the short term any additional transistors should clearly be put into increasing the size of on-chip first-level caches, as transistor counts increase above a certain level this is no longer holds true. As cache sizes increase, so does the difficulty of accessing the cache in a single-cycle. Context switches also present a potential problem. A trace-driven simulation-based study of a wide range of cache configurations and processor counts was performed, and the results are presented here. In order to compare different configurations, the concept of an Equivalent Cache Transistor is presented. We found that the access time of the first-level data cache proved critical; configurations with a small single-cycle access data cache consistently outperformed much larger 2-cycle access caches. In addition, it appears that once approximately 15 million transistors become available, a two processor configuration is preferable to a single processor with correspondingly larger caches. 
Abstract-found: 1
Intro-found: 1
Reference: [DWAA92] <author> D. W. Dobberpuhl, R. T. Witek, R. Allmon, R. Anglin, D. Bertucci, S. Britton, L. Chao, R. A. Conrad, D. E. Dever, B. Gieseke, S. M. N. Hassoun, G. W. Hoeppner, K. Kuchler, M. Ladd, B. M. Leary, L. Madden, E. J. McLellan, D. R. Meyer, J. Montanaro, D. A. Priore, V. Rajagopalan, S. Samudrala and S. Santhanam, </author> <title> ``A 200-MHz 64-b Dual-Issue CMOS Microprocessor'', </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 27, no. </volume> <month> 11 (November </month> <year> 1992). </year>
Reference-contexts: This processor has 16K bytes of on-chip cache and uses a 6 transistor standard cache cell design <ref> [DWAA92, Site93] </ref>. Then, using this transistor count in conjunction with an observation of the amount of on-chip space that is occupied by the caches, we can compute the number of transistors (in ECTs) needed to implement the processor.
Reference: [Hill87] <author> M. D. Hill, </author> <title> Aspects of Cache Memory and Instruction Buffer Performance, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Sciences,, Berkeley, California, </institution> <month> (November </month> <year> 1987). </year>
Reference-contexts: However, the afore-mentioned resource constraints forced us to chose a single associativity organization. While we realize that a large direct-mapped second-level cache should perform well <ref> [Hill87] </ref> we chose a 4-way set associative cache since in some of the system configurations, the second-level cache is not much larger than the first-level caches it supports. This is especially true when we look at multiple on-chip processor configurations where the second-level cache is supporting several first-level caches.
Reference: [John91] <author> M. Johnson, </author> <title> Superscalar Microprocessor Design, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> (1991). </year>
Reference-contexts: The Traces Sixteen traces were selected as representative of a typical workload. Nine traces were chosen from the SPEC89 benchmark suite, and augmented by seven additional traces used by Johnson in his book <ref> [John91] </ref>. The benchmark programs were compiled with the native RISC C compiler (/usr/bin/cc) on a DECstation 5000/240 with optimization level 2. The traces were then gathered using the pixie trace generating facility.
Reference: [LaPI88] <author> S. Laha, J. Patel and R. K. Iyer, </author> <title> ``Accurate Low-Cost Methods for Performance Evaluation of Cache Memory Systems'', </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 37, no. </volume> <month> 11 (November, </month> <year> 1988), </year> <pages> pp. 1325-1336. </pages>
Reference-contexts: So, for example, in our study we use sampled traces that consist of 100 contiguous blocks of instructions each 75,000 references long. This approach to using shorter traces to represent much longer reference streams is very similar to the approach used in <ref> [LaPI88] </ref>. In order to get some feel for how representative the sampled traces were, we also calculated the number of unique addresses in each sampled and unsampled trace. These numbers appear in Table 1. There are a number of interesting things to point out in the table.
Reference: [Site93] <author> R. L. </author> <title> Sites, ``Alpha AXP Architecture'', </title> <journal> Communications of the ACM, </journal> <volume> vol. 36, no. </volume> <month> 2 (February, </month> <year> 1993), </year> <pages> pp. 33-44. </pages>
Reference-contexts: This processor has 16K bytes of on-chip cache and uses a 6 transistor standard cache cell design <ref> [DWAA92, Site93] </ref>. Then, using this transistor count in conjunction with an observation of the amount of on-chip space that is occupied by the caches, we can compute the number of transistors (in ECTs) needed to implement the processor.
Reference: [Smit82] <author> J. E. Smith, </author> <title> ``Decoupled Access/Execute Computer Architectures'', </title> <booktitle> Proceedings of the Ninth Annual International Symposium on Computer Architecture, </booktitle> <address> Austin, Texas (April 26-29, </address> <year> 1982), </year> <pages> pp. 112-119. </pages>
Reference-contexts: Numerous cache studies have also validated this as a reasonable size <ref> [Smit82, SmGo85] </ref>. The processors are single-issue processors with a CPI of 1 (excluding memory references). These can be thought of as non-pipelined processors, since no internal hazards are simulated.
Reference: [SmGo85] <author> J. E. Smith and J. R. Goodman, </author> <title> ``Instruction Cache Replacement Policies and Organizations'', </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-34, no. </volume> <month> 3 (March </month> <year> 1985), </year> <pages> pp. 234-241. </pages>
Reference-contexts: Numerous cache studies have also validated this as a reasonable size <ref> [Smit82, SmGo85] </ref>. The processors are single-issue processors with a CPI of 1 (excluding memory references). These can be thought of as non-pipelined processors, since no internal hazards are simulated.
Reference: [YeP91] <author> T. Yeh and Y. Patt, </author> <title> ``Two-Level Adaptive Training Branch Prediction'', </title> <booktitle> Proceedings of the 24th Annual International Symposium on Microarchitecture, </booktitle> <address> Albuquerque, New Mexico (November 18-20, </address> <year> 1991), </year> <pages> pp. 51-61. - 22 </pages> - 
Reference-contexts: For example, it may make sense to invest some transistors in branch prediction hardware, such as that proposed by Yeh and Patt <ref> [YeP91] </ref>. Another use of extra transistors could be for register renaming schemes, or more hardware support for multiple or out-of-order issue of instructions. Also, at some point, when most of the chip area is used as memory, it becomes reasonable to consider placing more processors on the chip.
References-found: 8

