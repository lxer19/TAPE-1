URL: ftp://cse.ogi.edu/pub/tech-reports/1997/97-005.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Email: revel,dylan,dcs,walpole-@cse.ogi.edu  
Title: Adaptive Prefetching for Device-Independent File I/O sensitive to I/O latency and jitter, such as multimedia
Author: Dan Revel, Dylan McNamee, David Steere, and Jonathan Walpole 
Address: 20000 NW Walker Road, PO Box 91000 Portland, OR 97291-1000  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science and Technology  
Note: This research is partially supported by DARPA grant N00014-94-1-0845, DARPA contract F19628-95-C-0193, NSF grant CCR-9224375, and grants from Hewlett-Packard, Intel and Tektronix.  1) Introduction Applications that are  
Abstract: Device independent I/O has been a holy grail to OS designers since the early days of UNIX. Unfortunately, existing OS's fall short of this goal for applications that rely on very predictable I/O latency, such as multimedia players. Although techniques such as caching and sequential read-ahead can help by eliminating I/O latency in some cases, these same mechanisms can increase latency or add substantial jitter in others. In this paper we propose a new mechanism for achieving device-independent I/O - adaptive prefetching using applicationsupplied hints of access patterns. Adaptive prefetching actively monitors device performance and dynamically adjusts the amount of prefetching. Our experiments show device independence can be achieved: a Berkeley MPEG player sees the same latency when reading data from local disk or NFS. Moreover, our approach reduces jitter by a factor of 40 over standard techniques. Providing a device independent interface to resources has been a central feature of operating systems. For example, since the early days of Unix, application developers have enjoyed a simple and consistent, I/O independent, programming model provided by the file system abstraction. Programs handle data in files using a standard set of operations, such as open, read, write, seek, and close. In turn, the operating system translates these operations into device specific actions. The file system abstraction has proven to be a powerful tool, making it easy to write programs that store and access data on a wide variety of storage devices. However, current operating systems do not shield applications from variations in storage access latency due either to differences in hardware or variations in system load. In this paper we describe how device timing independent I/O can be provided to multimedia applications by combining application information, runtime monitoring and adaptation. We have implemented a user-level library which accepts application hints about future file accesses and actively manages the buffer cache. Application directed adaptive prefetching succeeds in hiding I/O latency in cases where prefetching based on a sequential readahead heuristic fails. Further, we maintain a prefetching window 
Abstract-found: 1
Intro-found: 0
Reference: [Aref97] <author> W.G. Aref, I. Kamel, T.N. Niranjan and S. Ghandeharizadeh. </author> <title> Disk Sceduling for Displaying and Recording Video in NonLinear News Editing Systems. </title> <booktitle> Proceedings of Multimedia Computing and Networking 1997. SPIE Proceedings Vol. 3020, </booktitle> <address> San Jose, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: First, application management eliminates the device independence provided by operating system abstractions of resources. Instead applications must manually control the timing of prefetch requests. As a result, developers tune current high performance multimedia applications for specific storage devices <ref> [Aref97] </ref>. Second, application management can produce poor resource allocation and scheduling decisions in a shared environment. Shared resource management can be done better by a single subsystem rather than a collection of applications working independently.
Reference: [Cao95] <author> Pei Cao, Edward W. Felton, Anna Karlin, and Kai Li. </author> <title> A Study of Integrated Prefetching and Caching Strategies. </title> <booktitle> Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1995. </year>
Reference: [Cen95] <author> Shanwei Cen, Calton Pu, Richard Staehli, and Jonathan Walpole. </author> <title> A Distributed Real-Time MPEG Video Audio Player. </title> <booktitle> Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <publisher> LNCS, v. 1018, Springer-Verlag, </publisher> <pages> pages 142-153, </pages> <year> 1995. </year>
Reference: [Chou85] <author> Hong-Tai Chou and David J. DeWitt. </author> <title> An Evaluation of Buffer Management Strategies. </title> <booktitle> Proceedings of the 11th VLDB Conference, </booktitle> <address> Stockholm, Sweden, </address> <pages> pages 127-141, </pages> <month> August </month> <year> 1985. </year>
Reference: [Freitag71] <author> R. J. Freitag and E. I. Organisk. </author> <title> The Multics Input/Output System. </title> <booktitle> Proceedings of the 3rd Symposium on Operating System Principles, </booktitle> <pages> pages 35-41, </pages> <year> 1971. </year>
Reference: [Gemmell95] <author> D. J. Gemmell, H. M. Vin, D. D. Kandlur, P. Venkat Rangan, and L. Rowe. </author> <title> Multimedia Storage Servers: A Tutorial and Survey. </title> <journal> IEEE Computer, </journal> <volume> Vol. 28, No. 5, </volume> <pages> pages 40-49, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: For example, the MPEG-1 standard compresses video sequences into bitstreams that require a transfer rate of about 1.5 Mbps. Multimedia storage servers are designed to provide consistent rate access to continuous media data. Gemmell presents a survey of architectures and algorithms used to design multimedia storage servers <ref> [Gemmell95] </ref>. In general these servers are dedicated systems and use admission control to provide rate guarantees to their clients.
Reference: [Jauhari90] <author> Rajiv Jauhari, Michael J. Carey, and Miron Livny. Priority-Hints: </author> <title> An Algorithm for Priority-Based Buffer Management. </title> <booktitle> Proceedings of the 16th VLDB Conference, </booktitle> <address> Brisbane, Australia, </address> <pages> pages 708-721, </pages> <month> August </month> <year> 1990. </year>
Reference: [Kimbrel96] <author> Tracy Kimbrel, Andrew Tomkins, R. Hugo Patterson, Brian Bershad, Pei Cao, Edward W. Felton, Garth A. Gibson, Anna R. Karlin, and Kai Li. </author> <title> A TraceDriven Comparison of Algorithms for Parallel Prefetching and Caching. </title> <booktitle> Proceedings of the 2nd Symposium on Operating Systems Design and Implementation, </booktitle> <address> Seattle, Washington, </address> <pages> pages 19-34, </pages> <month> October </month> <year> 1996. </year>
Reference: [Koster96] <author> Rainer Koster. </author> <title> Design of a Mulitmedia Player with Advanced QoS Control. </title> <type> Master's thesis, </type> <institution> Oregon Graduate Institute of Science and Technology, Portland, Oregon, </institution> <year> 1996. </year>
Reference: [Maier93] <author> D. Maier, J. Walpole and R. Staehli, </author> <title> Storage System Architectures for Continuous Media Data. </title> <booktitle> In FODO '93 Proceedings, </booktitle> <publisher> LNCS, v. 730, Springer-Verlag, </publisher> <pages> pp. 1-18, </pages> <year> 1993. </year>
Reference: [Martin] <author> Martin, C., P. S. Narayan, B. Ozden, R. Rastogi, and A. Silberschatz. </author> <title> The Fellini Multimedia Storage Server. Multimedia Information Storage and Management, </title> <editor> Editor - S. M. Chung, </editor> <publisher> Kluwer Academic Publishers, to appear. </publisher>
Reference-contexts: Gemmell presents a survey of architectures and algorithms used to design multimedia storage servers [Gemmell95]. In general these servers are dedicated systems and use admission control to provide rate guarantees to their clients. The Fellini multimedia storage server pro-poses to support both continuous media and conventional data accesses <ref> [Martin] </ref> The responsiveness of VCR-like functions, such as fast-forward and rewind, is particularly sensitive to I/O latency. Ozden's design for a Video-on-Demand server presents a scheme for a window of cached data around a playback point in order to support these functions [Ozden96].
Reference: [McCanne95] <author> McCanne, S., and Jacobson, V., </author> <title> vic: A Flexible Framework for Packet Video. </title> <booktitle> ACM Multimedia, November 1995, </booktitle> <address> San Francisco, CA, </address> <pages> pp. 511-522. </pages>
Reference-contexts: Adaptive applications Because multimedia applications must run over the Internet where resource availability can vary greatly adaptivity is rapidly becoming a standard feature of networked multimedia applications. For example, McCanne's video conferencing tool, vic <ref> [McCanne95] </ref>, uses the RTP multimedia transport protocol to monitor and adjust its bandwidth utilization. The Quasar networked video player uses feedback both to adjust bandwidth utilization and to maintain clientserver synchronization [Cen95,Koster96]. However, feedback based dynamic adaptation is not a simple task.
Reference: [McKusick84] <author> Marshall K. McKusick, William N. Joy, Samuel J. Leffler, and Robert S. Fabry. </author> <title> A Fast File System for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 181-197, </pages> <month> August </month> <year> 1984. </year>
Reference: [McNamee96] <author> Dylan James McNamee. </author> <title> Virtual Memory Alternatives for Transaction Buffer Management in a Single-Level Store. </title> <type> Phd. thesis, </type> <institution> Department of Computer Science, University of Washington, </institution> <year> 1996. </year>
Reference-contexts: Third, applications do not have the system level control needed enforce their decisions. For example, an application may try to buffer prefetched data in virtual memory expecting them to remain available for low-latency access only to have the data paged out by the virtual memory system <ref> [McNamee96] </ref>. One alternative is to allow applications to pin virtual memory pages so they could not be paged out. In this case, however, resource sharing is defeated.
Reference: [Mowry96] <author> Todd C. Mowry, Angela K. Demke, and Orran Krieger. </author> <title> Automatic Compiler-Inserted I/O Prefetching for Out-of-Core Applications. </title> <booktitle> Proceedings of the 2nd Symposium on Operating Systems Design and Implementation, </booktitle> <address> Seattle, Washington, </address> <pages> pages 3-17, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: In contrast, Mowry reduces the I/O latency for out-of-core scientific applications by using compile-time analysis to insert prefetch and release calls into an application to perform explicit cache management <ref> [Mowry96] </ref>. In contrast to previous work in prefetching, our work combines application hints with run time performance monitoring and feedback. This mechanism allows our cache management decisions to adapt dynamically to storage devices with differing performance characteristics and also to varying workloads on a shared system.
Reference: [Ozden96] <author> Ozden, B., R. Rastogi, and A. Silberschatz. </author> <title> On the Design of a Low-Cost Video-on-Demand Storage System. </title> <journal> Multimedia Systems Journal, </journal> <month> February </month> <year> 1996. </year>
Reference-contexts: Ozden's design for a Video-on-Demand server presents a scheme for a window of cached data around a playback point in order to support these functions <ref> [Ozden96] </ref>. Staehli and Maier [Staehli93,Maier93] have observed that storage systems may exploit multimedia content specifications to provide constrained latency storage access. In order to meet application requirements it is important not only to know what data is wanted, but also when that data is needed.
Reference: [Patterson95] <author> R. H. Patterson, G. A. Gibson, E. Ginting, D. Stodolsky, and J. Zelenka. </author> <title> Informed Prefetching and Caching. </title> <booktitle> Proceedings of the Fifteeth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 79-95, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: The operating systems research community has also explored using application knowledge to make informed prefetching and caching decisions [Cao95,Patterson95,Kimbrel96,Mowry96]. Notably, Patterson's Transparent Informed Prefetching (TIP) <ref> [Patterson95] </ref> uses application hints supplied at run time to make prefetching and caching decisions with the goal of increasing I/O throughput by exploiting the hardware parallelism of disk arrays.
Reference: [Rowe93] <author> L.A. Rowe, K. Patel and B.C. Smith, </author> <title> "Performance of a Software MPEG Video Decoder," </title> <booktitle> Proc. ACM Multimedia 93, </booktitle> <address> Anaheim, CA, </address> <month> August </month> <year> 1993 </year>
Reference-contexts: Next we describe the hardware and software used in our experiments. Then we describe our experiments and the metrics that were used. Finally, we present and discuss our results. Equipment We used the Berkeley MPEG video software decoder <ref> [Rowe93] </ref> (mpeg_play) version 2.2 to decode and display MPEG-1 video bitstreams in all of our experiments. We instrumented the mpeg_play application to measure CPU times using getrusage and an idle cycle counter read immediately before and after decoding and displaying the sequence of Iframes.
Reference: [Staehli93] <author> Richard Staehli and Jonathan Walpole. </author> <title> Constrained-Latency Storage Access. </title> <journal> IEEE Computer, </journal> <volume> Vol. 26, No. 3, </volume> <pages> pages 44-53, </pages> <month> March </month> <year> 1993. </year>
Reference: [Stonebraker81] <author> Michael Stonebraker. </author> <title> Operating System Support for Database Management. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 24, No. 7, </volume> <pages> pages 412-418, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: These policies are easy to implement and have been shown to provide good performance for many applications. Unfortunately, for some applications sequential readahead and LRU cache replacement provide poor performance. Database researchers pointed out the shortcomings of operating system buffer cache management policies more than fifteen years ago <ref> [Stonebraker81] </ref>. There is a body of research on how to improve database buffer cache management by using database and query specific information to select and tune buffer cache management policies for better performance [Chou85,Jauhari90].
References-found: 20

