URL: http://www.isle.org/~langley/papers/viz.iu96.ps
Refering-URL: http://www.isle.org/publications.html
Root-URL: 
Email: (provan@camis.stanford.edu)  (langley@cs.stanford.edu)  (binford@cs.stanford.edu)  
Title: Probabilistic Learning of Three-Dimensional Object Models  
Author: Gregory Provan Pat Langley Thomas O. Binford 
Address: 2164 Staunton Court, Palo Alto, CA 94306 USA  Stanford, CA 94305 USA  
Affiliation: Institute for the Study of Learning and Expertise  Robotics Laboratory, Computer Science Department Stanford University,  
Abstract: In this paper we report on an approach to learning object models for use in recognition and reconstruction. Our framework represents objects in an image using generalized cylinders and organizes knowledge about classes of objects in a Bayesian network. The recognition process involves propagating evidence through this inference network, whereas learning relies on updating of the network's conditional probabilities based on training cases. We report preliminary experimental results with synthetic data that suggest our method improves its recognition accuracy with experience. We also consider our framework's relation to other research on learning object knowledge for image understanding. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. R., & Matessa, M. </author> <year> (1992). </year> <title> Explorations of an incremental, Bayesian algorithm for categorization. </title> <booktitle> Machine Learning, </booktitle> <pages> 9 , 275-308. </pages>
Reference: <author> Beis, J. S., & Lowe, D. G. </author> <year> (1993). </year> <title> Learning indexing functions for 3D model-based object recognition. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 50-54). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Binford, T. O., Levitt, T. S., & Mann, W. B. </author> <year> (1989). </year> <title> Bayesian inference in model-based machine vision. </title> <editor> In L. N. Kanal, T. S. Levitt, & J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in artificial intelligence (Vol. </booktitle> <volume> 3). </volume> <publisher> North Holland. </publisher>
Reference: <author> Charniak, E. </author> <year> (1989). </year> <title> Bayesian networks without tears. AI Magazine, </title> <booktitle> Winter, </booktitle> <pages> 50-63. </pages>
Reference-contexts: However, we favor a probabilistic framework that lets one take uncertainty into account during the inference process. One common organization for probabilistic knowledge is known as a Bayesian network <ref> (Charniak, 1989) </ref>. This framework assumes a set of nodes, representing attributes or variables, connected by a set of directed links, indicating causal relations among the attributes.
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 261-284. </pages>
Reference: <author> Conklin, D. </author> <year> (1993). </year> <title> Transformation-invariant indexing and machine discovery for computer vision. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 10-14). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Cook, D., Hall, L., Stark, L., & Bowyer, K. </author> <year> (1993). </year> <title> Learning combination of evidence functions in object recognition. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 139-143). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Dickinson, S., Pentland, A., & Rosenfeld, A. </author> <year> (1992). </year> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> Pattern Analysis and Machine Intelligence, </journal> <pages> 14 , 174-198. </pages>
Reference-contexts: The literature on computer vision contains many responses to this basic issue. Some researchers describe objects in terms of low-level features (e.g., Murase & Nayar, 1993; Pope & Lowe, 1993). Others represent objects using a set of characteristic views that describe the objects' appearance from alternative perspectives <ref> (e.g., Dickinson, Pent-land, & Rosenfeld, 1992) </ref>. We prefer three-dimensional over two-dimensional representations because the latter are subject to much more variation across different perspectives.
Reference: <author> Gros, P. </author> <year> (1993). </year> <title> Matching and clustering: Two steps towards automatic object model generation in computer vision. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 40-44). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Gennari, J. H., Langley, P., & Fisher, D. H. </author> <year> (1989). </year> <title> Models of incremental concept formation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 40 , 11-61. </pages>
Reference-contexts: This sorting process leads to updates in the probabilistic summaries through which the description passes, and creates a new subclass upon finding children with class summaries that are sufficiently different from the new description. This incremental, unsupervised scheme is very similar to our earlier work on unsupervised concept formation <ref> (Gennari, Langley, & Fisher, 1989) </ref>, differing primarily in its evaluation metric and its reliance on beam search for sorting rather than a greedy method. Sengupta and Boyer have tested their approach using descriptions taken from a CAD library of 3D objects.
Reference: <author> Kibler, D., & Langley, P. </author> <year> (1988). </year> <title> Machine learning as an experimental science. </title> <booktitle> Proceedings of the Third Euro-pean Working Session on Learning (pp. </booktitle> <pages> 81-92). </pages> <note> Glas-gow: Pittman. Reprinted in J. </note> <editor> W. Shavlik & T. G. Di-etterich (Eds.) </editor> <booktitle> (1990), Readings in machine learning . San Francisco, </booktitle> <address> CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In this section we present two studies designed for this purpose. Experiments in visual learning, as in other areas, involve some dependent variable that measures behavior along a dimension of interest and one or more independent variables that, when varied, might affect that behavior <ref> (Kibler & Langley, 1988) </ref>. In this case, our dependent measure is the recognition or classification accuracy of the visual system; that is, the percentage of objects correctly assigned to their proper class.
Reference: <author> Langley, P. </author> <year> (1995). </year> <title> Order effects in incremental learning. </title> <editor> In P. Reimann & H. Spada (Eds.). </editor> <booktitle> Learning in humans and machines: Towards and interdisciplinary learning science. </booktitle> <publisher> Oxford: Elsevier. </publisher>
Reference-contexts: Down-turning Decreasing Left-tail-wing Elliptical Down-turning Decreasing Tail Elliptical Down-turning Decreasing Tank Tank-Base Elliptical Straight Constant Turret Circular Straight Up-level-down Cannon Circular Straight Constant Building Building-base Rectangular Straight Constant Building-roof Rectangular Straight Constant Both the competitive and proportional methods lack one desirable feature of naive Bayes its independence of training order <ref> (Langley, 1995) </ref>. Because early revisions can influence the probabilities generated for later training cases, the order of presentation can affect the probability estimates stored with each node.
Reference: <author> Langley, P., Iba, W., & Thompson, K. </author> <year> (1992). </year> <title> An analysis of Bayesian classifiers. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 223-228). </pages> <address> San Jose, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: As we will see in the sections that follow, this assumption considerably simplifies both learning and performance. In fact, each set of nodes and their common parent have the form of a naive Bayesian classifier <ref> (Langley, Iba, & Thompson, 1992) </ref>, a simple probabilistic representation that assumes a set of predictor variables that are conditionally independent given the class attribute.
Reference: <author> Levitt, T. S., Binford, T. O., & Ettinger, G. J. </author> <year> (1990). </year> <title> Utility-based control for computer vision. </title> <editor> In R. </editor> <address> D. </address>
Reference: <editor> Schacter, T. S. Levitt, L. N. Kanal, & J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in artificial intelligence (Vol. </booktitle> <volume> 4). </volume> <publisher> North Holland. </publisher>
Reference: <author> Liang, J., Christensen, H., & Jensen, F. </author> <year> (1994). </year> <title> Qualitative recognition using Bayesian reasoning. </title> <note> In E. </note>
Reference: <editor> Gelsema & L. Kanal (Eds.), </editor> <booktitle> Pattern recognition in practice (Vol. </booktitle> <pages> 4). </pages>
Reference: <author> Murase, H., & Nayar, S. K. </author> <year> (1993). </year> <title> Learning and recognition of 3D objects from brightness images. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 25-29). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Pope, A. R., & Lowe, D. G. </author> <year> (1993). </year> <title> Learning 3D object recognition models from 2D images. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 35-39). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Rimey, R., & Brown, C. </author> <year> (1994). </year> <title> Control of selection perception using Bayes nets and decision theory. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12 </volume> . 
Reference: <author> Segen, J. </author> <year> (1993). </year> <title> Learning shape models for a vision-based human-computer interface. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 120-124). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Sengupta, K., & Boyer, K. L. </author> <year> (1993). </year> <title> Incremental model base updating: Learning new model sites. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 1-5). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Suppes, P., & Liang, L. </author> <year> (1995). </year> <title> Concept learning rates and transfer performance of several multivariate neural network models. </title> <editor> In C. Dowling, F. Roberts, & P. Theuns (Eds.), </editor> <booktitle> Progress in mathematical psychology . Mahwah, </booktitle> <address> NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: method retains and revises two quantities, the sum and the sum of squares, which let it compute the mean and variance for a normal curve that it uses to find p (v j jC k ); a similar calculation lets it update the quantities needed to compute the covariance matrix <ref> (Suppes & Liang, 1995) </ref> if deemed necessary. Because some instances may have missing attributes, the system must include a fourth count for each class-attribute pair. The hierarchical structure of the cascaded Bayesian classifier requires some extensions to this learning method.
Reference: <author> Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. </author> <year> (1983). </year> <title> Learning physical descriptions from functional descriptions. </title> <booktitle> Proceedings of the Third National Conference on Artificial Intelligence (pp. </booktitle> <pages> 433-439). </pages> <address> Wash-ington, DC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Zerroug, M., & Nevatia, R. </author> <year> (1994). </year> <title> Three-dimensional part-based descriptions from a real intensity image. </title> <booktitle> Proceedings of the Image Understanding Workshop (pp. </booktitle> <pages> 1367-1374). </pages> <address> Monterrey, CA: </address> <publisher> Morgan Kaufmann. </publisher>
References-found: 25

