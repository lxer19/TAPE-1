URL: ftp://condor.cs.jhu.edu/pub/salzberg/starcr.ps.gz
Refering-URL: http://www.cs.jhu.edu/~salzberg/
Root-URL: http://www.cs.jhu.edu
Email: salzberg@cs.jhu.edu  E-mail:rupali@jhufos.pha.jhu.edu  E-mail:ford@stsci.edu  E-mail:murthy@cs.jhu.edu  E-mail:rlw@stsci.edu  
Title: Decision Trees for Automated Identification of Cosmic Ray Hits in Hubble Space Telescope Images  
Author: Steven Salzberg Rupali Chandar Holland Ford Sreerama K. Murthy and Richard L. White 
Note: 1 Direct correspondence to Salzberg.  
Address: Baltimore, MD 21218  Baltimore, MD 21218  Baltimore, MD 21218  Baltimore, MD 21218  3700 San Martin Drive, Baltimore, MD 21218  
Affiliation: Department of Computer Science, Johns Hopkins University,  Department of Physics and Astronomy, Johns Hopkins University,  Department of Physics and Astronomy, Johns Hopkins University,  Department of Computer Science, Johns Hopkins University,  Space Telescope Science Institute,  
Abstract-found: 0
Intro-found: 1
Reference: <author> Breiman, L., Friedman, J., Olshen, R., and Stone, C. </author> <year> 1984, </year> <title> Classification and Regression Trees, Wadsworth International Group Dasarathy, B.V. 1991, Nearest neighbor (NN) norms - NN pattern classification techniques, </title> <publisher> Los Alamitos, </publisher> <address> CA: </address> <publisher> IEEE Computer Society Press Freedman, </publisher> <address> W.L., </address> <institution> Hughes, S.M., </institution> <note> Madore, B.F., </note> <author> Mould, J.R., Lee, M.G., Stetson, P., Kennicutt, R.C., Turner, A., Ferrarese, L., Ford, H.C., Graham, J.A., Hill, R., Hoessel, J.G., Huchra, J., and Illingworth, G.D. </author> <year> 1994, </year> <title> ApJ, </title> <type> 427 Garey, M.R., </type> <institution> and Johnson, D.S. </institution> <year> 1979, </year> <title> Computers and Intractability a Guide to the theory of NP-Completeness, </title> <address> San Francisco, CA: </address> <publisher> Freeman and Co. </publisher>
Reference-contexts: This process continues until the example reaches a leaf node. The leaf nodes of the tree contain category labels, in this case either "star" or "cosmic ray." Many decision tree methods have been used for classification (Moret 1982), most notably C4.5 (Quinlan 1993) and CART <ref> (Breiman et al. 1984) </ref>. These classifiers were included in our experiments as well, since our goal was to find the best overall method for the star/cosmic ray problem. <p> The weakest subtree is the one whose removal has the smallest effect on this measure (for details, including a formal definition of "weakest" and of how accuracy is estimated for the training set, see Breiman et al. <ref> (Breiman et al. 1984) </ref>). This process results in a set of successively smaller trees, and OC1 chooses the tree from this set that gives maximum accuracy on the separate pruning set. The user can adjust the size of this pruning set, or even turn off pruning entirely. 3.1. <p> Many such measures have been defined in the literature, and one that has worked well for both OC1 and CART is the "twoing" criterion <ref> (Breiman et al. 1984) </ref>. This criterion assigns higher goodness values to hyperplanes that come close to splitting the data in half, and to those that do not split up examples from the same class. <p> OC1 then considers adjusting the coefficients of H one at a time. By treating a single coefficient a m as a variable, and all other coefficients as constants, we can compute the optimal value for a m , using an idea from Breiman et al. <ref> (Breiman et al. 1984) </ref>. OC1 cycles through the d coefficients until it can no longer improve any of them; i.e., it has reached a locally optimal hyperplane. <p> If that label is incorrect, the algorithm has no way of knowing.) Cross-validation studies are well-known to provide good estimates of accuracy, with relatively little "optimistic" bias. We ran four different decision tree algorithms on this data: CART <ref> (Breiman et al. 1984) </ref>, C4.5 (Quinlan 1993), and two versions of OC1. In addition to the version of OC1 described above, we also used a version that only considers axis-parallel (univariate) tests at each node of the tree. <p> Consequently, the goodness measures and pruning techniques used are different for each of the methods. Detailed descriptions of the default settings and what they mean for each system can be found found in the following references: C4.5 (Quinlan 1993), CART <ref> (Breiman et al. 1984) </ref>, and OC1 (Murthy et al. 1994). The accuracies on WF1 are given in Table 1. Each of the lines for OC1 is an average of ten 5-fold cross-validation (CV) experiments; the other systems were run using a single 5-fold CV design.

References-found: 1

