URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/assert-proposal-93.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: baffes@cs.utexas.edu  
Phone: (512) 471-9589  
Title: Learning to Model Students: Using Theory Refinement to Detect Misconceptions  
Author: Paul T. Baffes 
Note: Presented:  
Date: June 15, 1993  June 17, 1993  
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas  
Abstract: A new student modeling system called Assert is described. Assert is a general purpose algorithm which uses domain independent techniques to perform student modeling and to automatically construct libraries of common bugs. For its modeling component, Assert uses a machine learning technique which is an extension of the Either theory refinement algorithm. A common library of bugs is constructed by extracting commonalities across multiple student models. Initial experimental data suggests that Assert is a more effective modeling system than other techniques previously explored, and that the automatic bug library construction significantly enhances subsequent modeling efforts.
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. R., Boyle, C. F., and Reiser, B. J. </author> <year> (1985). </year> <title> The geometry tutor. </title> <booktitle> In Proceedings of the Ninth International Joint conference on Artificial intelligence, </booktitle> <pages> pages 1-7. </pages> <address> Los 31 Angeles, CA. </address>
Reference-contexts: It should also be noted that neither theory refinement nor student modeling is limited to a particular type of problem domain. Most student modeling tasks have focused on procedural problem solving domains such as geometry <ref> (Anderson et al., 1985) </ref>, subtraction (Brown and Burton, 1978; Burton, 1982; Sleeman and Smith, 1981; Langley et al., 1984), or writing computer programs (Johnson, 1986; Reiser et al., 1985).
Reference: <author> Baffes, P. and Mooney, R. </author> <year> (1993). </year> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial intelligence. </booktitle> <address> Chambery, France. </address>
Reference-contexts: The theory provided with the data set has an initial classification accuracy of 50%. The main point of the test was to illustrate whether Neither could maintain the predictive accuracy of Either while reducing execution time. Other tests of the Neither algorithm are described in <ref> (Baffes and Mooney, 1993) </ref>. The experiments proceeded as follows. Each data set was divided into training and test sets. Training sets were further divided into subsets, so that the algorithms could be evaluated with varying amounts of training data. After training, each system's accuracy was recorded on the test set.
Reference: <author> Baffes, P. and Mooney, R. J. </author> <year> (1992). </year> <title> Using theory revision to model students and acquire stereotypical errors. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 617-622. </pages> <address> Bloomington, </address> <note> IN. </note>
Reference-contexts: To simulate individual student differences, each student theory was further subjected to random antecedent modifications and rule additions and deletions, each with a probability of 0:10. 5.1.1 Experimental Method Assert was tested against both normal theory refinement and induction using a two-phased approach as first described in <ref> (Baffes and Mooney, 1992) </ref>. The first phase was used to build a stereotypical theory for use in the second phase as follows: 1. First, 20 artificial students were created using the methods described above. 2. For each student, all 180 examples were relabeled using the student's theory. 3.
Reference: <author> Brown, J. S. and Burton, R. R. </author> <year> (1978). </year> <title> Diagnostic models for procedural bugs in basic mathematical skills. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 155-192. </pages>
Reference: <author> Brown, J. S. and VanLehn, K. </author> <year> (1980). </year> <title> Repair theory: a generative theory of bugs in procedural skills. </title> <journal> Cognitive Science, </journal> <volume> 4 </volume> <pages> 379-426. </pages>
Reference: <author> Burton, R. R. </author> <year> (1982). </year> <title> Diagnosing bugs in a simple procedural skill. </title> <editor> In Sleeman, D. H. and Brown, J. S., editors, </editor> <booktitle> Intelligent Tutoring Systems, chapter 8. </booktitle> <address> London: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Again this is because induction from scratch is simply a harder task. 6 Related Work There are three other systems which utilize machine learning techniques for student modeling. The first of these is VanLehn's SIERRA system (VanLehn, 1983) which builds on ideas developed in the DEBUGGY system <ref> (Burton, 1982) </ref>. In DEBUGGY, student models are formed by introducing incorrect subskills into a lattice of skills called a procedural network. When a subskill is missing or incorrect, the result is faulty behavior.
Reference: <author> Carbonell, J. R. </author> <year> (1970). </year> <title> Mixed-initiative man-computer instructional dialogues. </title> <type> Technical Report BBN Report No. </type> <address> 1971, Cambridge, MA: </address> <institution> Bolt Beranek and Newman, Inc. </institution>
Reference-contexts: In the 1970s criticisms of the CAI approach began to emerge. Several researchers, most notably Carbonell <ref> (Carbonell, 1970) </ref> pointed out that CAI could not be truly responsive to individual student needs until a knowledge of the domain equivalent to that possessed by the educator was encoded in the system.
Reference: <author> Carr, B. and Goldstein, I. </author> <year> (1977). </year> <title> Overlays: a theory of modeling for computer-aided instruction. </title> <type> Technical Report A. I. Memo 406, </type> <address> Cambridge, MA: </address> <publisher> MIT. </publisher>
Reference-contexts: In all of these, the method used to represent the knowledge of the student has played a major role. Such representations are generally referred to as student models. Student modeling research has taken a variety of forms from overlay models <ref> (Carr and Goldstein, 1977) </ref> to rule-based representations (Young and O'Shea, 1981; Sleeman and Smith, 1981) to frame-based methods (Rich, 1990). The disadvantage of most of these techniques is their inability to deal with novel student errors. Additionally, they can require a great deal of effort to construct. <p> Without the flexibility to model novel student errors, ICAI systems will not progress much beyond electronic page turners with canned responses tuned to the average student. Over the last two decades, several techniques for student modeling have been developed. One method, called overlay modeling <ref> (Carr and Goldstein, 1977) </ref>, assumes a student's knowledge is always a subset of the correct domain knowledge. As the student performs actions which illustrate that he or she understands particular elements of the domain knowledge, these are marked in the overlay model.
Reference: <author> Clancey, W. J. </author> <year> (1979). </year> <title> Transfer of Rule-Based Expertise through a Tutorial Dialogue. </title> <type> PhD thesis, </type> <institution> Palo Alto, CA: Stanford University. </institution>
Reference-contexts: One exception to this rule is the GUIDON system <ref> (Clancey, 1979) </ref> which tutors students in a classification task involving the diagnosis of bacterial infections. For the purposes of this research, we have elected to use a propositional Horn-clause theory refinement system and focus on categorization tasks for the following reasons. <p> It is also important to reinforce a point first raised by Clancey's work on the GUIDON system <ref> (Clancey, 1979) </ref>. Like GUIDON, the models build by Assert will only be as good as the underlying rule base from which they are drawn.
Reference: <author> Craw, S. and Sleeman, D. </author> <year> (1990). </year> <title> The flexibility of speculative refinement. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 28-32. </pages> <address> Evanston, IL. </address>
Reference: <author> Dick, W. and Carey, L. </author> <year> (1990). </year> <title> The systematic design of instruction. Glenview, IL: Scott, Foresman/Little, Brown Higher Education. </title> <booktitle> Third edition. </booktitle>
Reference-contexts: Propositional theory refinement is well understood and complete systems have already been constructed which will revise Horn-clause theories. And while categorization problems have not been a major focus of ICAI modeling efforts, concept lessons have a well understood pedagogy <ref> (Dick and Carey, 1990) </ref> and are common CAI applications.
Reference: <author> Gilmore, D. and Self, J. </author> <year> (1988). </year> <title> The application of machine learning to intelligent tutoring systems. In Self, </title> <editor> J., editor, </editor> <booktitle> Artificial Intelligence and Human Learning, chapter 11. </booktitle> <address> New York, NY: </address> <publisher> Chapman and Hall. </publisher>
Reference-contexts: And while categorization problems have not been a major focus of ICAI modeling efforts, concept lessons have a well understood pedagogy (Dick and Carey, 1990) and are common CAI applications. Furthermore, as Gilmore and Self <ref> (Gilmore and Self, 1988) </ref> have pointed out, machine learning has been successfully applied in categorization domains making it natural to explore its potential in concept tutorials. 5 2.4 Learning from Multiple Student Models As has been stated in the previous section, theory refinement can be used to build student models and
Reference: <author> Ginsberg, A. </author> <year> (1990). </year> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 777-782. </pages> <address> Detroit, MI. </address>
Reference: <author> Johnson, W. L. </author> <year> (1986). </year> <title> Intention-Based Diagnosis of Novice Programming Errors. </title> <publisher> London: Pitman Publishing. </publisher>
Reference: <author> Langley, P., Ohlsson, S., and Sage, S. </author> <year> (1984). </year> <title> A machine learning approach to student modeling. </title> <type> Technical Report CMU-RI-TR-84-7, </type> <institution> Pittsburgh, PA.: Carnegie-Mellon University. </institution>
Reference: <author> Laubsch, J. H. </author> <year> (1975). </year> <title> Some thoughts about representing knowledge in instructional systems. </title> <booktitle> In Proceedings of the Fourth International Joint conference on Artificial intelligence, </booktitle> <pages> pages 122-125. </pages> <note> 32 Legree, </note> <author> P. J. and Gillis, P. D. </author> <year> (1991). </year> <title> Product effectiveness evaluation criteria for intelligent tutoring systems. </title> <journal> Journal of Computer-Based Instruction, </journal> <volume> 18(2) </volume> <pages> 57-62. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R. S., Carbonell, J. G., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83-134. </pages> <publisher> Tioga. </publisher>
Reference: <author> Mitchell, T. M. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18(2) </volume> <pages> 203-226. </pages>
Reference: <author> Murphy, M. A. and Davidson, G. V. </author> <year> (1991). </year> <title> Computer-based adaptive instruction: Effects of learner control on concept learning. </title> <journal> Journal of Computer-Based Instruction, </journal> <volume> 18(2) </volume> <pages> 51-56. </pages>
Reference-contexts: The data for this experiment is borrowed from a separate research project that tested the ability of nursing students to retain concepts for determining if a patient was suffering from shock <ref> (Murphy and Davidson, 1991) </ref>. Data from 26 of the students is used here. Each student interacted with a CAI system which presented patient case histories and asked the student to diagnose which of three kinds of shock, if any, the patient was experiencing.
Reference: <author> Nicolson, R. I. </author> <year> (1992). </year> <title> Diagnosis can help in intelligent tutoring. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 635-640. </pages> <address> Bloomington, </address> <note> IN. </note>
Reference-contexts: Additionally, they can require a great deal of effort to construct. There has also been some debate over the utility of student models, with early studies indicating ITS and CAI systems to be educationally equivalent, though the most recent results show ITS methods to be superior <ref> (Nicolson, 1992) </ref>. If student modeling techniques are to be useful, then, they must be flexible enough to handle novel errors, simpler to construct, and easily tested so that we may gauge the utility of the models produced.
Reference: <author> Ohlsson, S. and Langley, P. </author> <year> (1985). </year> <title> Identifying solution paths in cognitive diagnosis. </title> <type> Technical Report CMU-RI-TR-85-2, </type> <institution> Pittsburgh, PA.: Carnegie-Mellon University. </institution>
Reference: <author> Ourston, D. </author> <year> (1991). </year> <title> Using Explanation-Based and Empirical Methods in Theory Revision. </title> <type> PhD thesis, </type> <institution> Austin, TX: University of Texas. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 91-164. </note>
Reference-contexts: Either retracts and generalizes existing antecedents and learns new rules to fix these problems. Unlike other theory refinement systems that perform hill-climbing (and are therefore subject to local maxima), Either is guaranteed to fix any arbitrarily incorrect propositional Horn-clause theory <ref> (Ourston, 1991) </ref>. As an example of how Either repairs a theory, refer to Figure 1.
Reference: <author> Ourston, D. and Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 815-820. </pages> <address> Detroit, MI. </address>
Reference-contexts: The idea is one of refinement; the learner starts with an initial theory that is incorrect or incomplete, and modifies it to fit a set of data. For example, the Either system <ref> (Ourston and Mooney, 1990) </ref> alters an initially incomplete or incorrect rule base by modifying or deleting existing rules or by adding new rules until the rule base is consistent with the input examples.
Reference: <author> Ourston, D. and Mooney, R. J. </author> <title> (in press). Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence. </journal>
Reference: <author> Plotkin, G. D. </author> <year> (1970). </year> <title> A note on inductive generalization. </title> <editor> In Meltzer, B. and Michie, D., editors, </editor> <booktitle> Machine Intelligence (Vol. 5). </booktitle> <address> New York: </address> <publisher> Elsevier North-Holland. </publisher>
Reference-contexts: Fortunately, a straightforward technique exists for forming generalizations among refinements. Since any refinement to a propositional theory can be expressed as a logic clause, one can use the the least general generalization (LGG) operator <ref> (Plotkin, 1970) </ref>. When two propositional logic clauses are not identical, one can form a generalization of the two by dropping literals from the clauses.
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266. </pages>
Reference-contexts: A series of experiments were run starting Assert with (1) the correct animal rules, (2) the stereotypical theory from phase 1 above, or (3) no initial theory. With no initial theory, Assert defaults to inductive learning alone using a propositional version of the FOIL <ref> (Quinlan, 1990) </ref> algorithm. This phase ran as follows: 19 Initial Rules Accuracy stereotypical 93% correct 86% stereotypical, no refinement 81% correct, no refinement 71% none (induction) 52% Table 1: Accuracy of student models for animal domain tests. 1.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference-contexts: Lastly, the repairs in the cover are applied to the theory. If the application of a repair over-compensates by creating new failing examples, Either passes the covered examples and the new failing examples to an induction component based upon a version of Id3 <ref> (Quinlan, 1986) </ref>. The results of the induction are added as a new rule when generalizing or as additional antecedents when specializing. 3.2 Building Neither from Either The main loop of Neither, shown in Figure 3, is quite different from Either (see Figure 2).
Reference: <author> Reiser, B. J., Anderson, J. R., and Farrell, R. G. </author> <year> (1985). </year> <title> Dynamic student modeling in an intellignet tutor for LISP programming. </title> <booktitle> In Proceedings of the Ninth International Joint conference on Artificial intelligence, </booktitle> <pages> pages 8-14. </pages> <address> Los Angeles, CA. </address>
Reference: <author> Rich, E. </author> <year> (1990). </year> <title> Stereotypes and user modeling. </title> <editor> In Frederiksen, N., Glaser, R., Lesgold, A., and Shafto, M., editors, </editor> <title> Diagnostic Monitoring of Skill and Knowledge Acquisition, chapter 2. </title> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Such representations are generally referred to as student models. Student modeling research has taken a variety of forms from overlay models (Carr and Goldstein, 1977) to rule-based representations (Young and O'Shea, 1981; Sleeman and Smith, 1981) to frame-based methods <ref> (Rich, 1990) </ref>. The disadvantage of most of these techniques is their inability to deal with novel student errors. Additionally, they can require a great deal of effort to construct.
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, J. R. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McClelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> pages 318-362. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <address> 33 Sleeman, D., </address> <note> Hirsh, </note> <author> H., Ellery, I., and Kim, I. </author> <year> (1990). </year> <title> Extending domain theories: two case studies in student modeling. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 11-37. </pages>
Reference: <author> Sleeman, D., Kelly, A. E., Martinak, R., Ward, R. D., and Moore, J. </author> <year> (1987). </year> <title> Studies in the diagnosis and remediation of high school algebra students. </title> <journal> Cognitive Science, </journal> <volume> 13 </volume> <pages> 551-568. </pages>
Reference-contexts: We will follow the three-part testing method exemplified by the series of experiments on the PIXIE system <ref> (Sleeman et al., 1987) </ref> with a slight modification. Students will be divided into three groups, with each receiving different feedback. All three groups will receive instruction from a standard lecture format (not a ICAI system), and then each will be given a set of test questions.
Reference: <author> Sleeman, D. H. and Smith, M. J. </author> <year> (1981). </year> <title> Modelling students' problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 171-187. </pages>
Reference: <author> Towell, G. and Shavlik, J. </author> <year> (1991). </year> <title> Refining symbolic knowledge using neural networks. </title> <booktitle> In Proceedings of the International Workshop on Multistrategy Learning, </booktitle> <pages> pages 257-272. </pages> <address> Harper's Ferry, W.Va. </address>
Reference: <author> Towell, G. G., Shavlik, J. W., and Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866. </pages> <address> Boston, MA. </address>
Reference-contexts: Specifically, the student would be modeled as missing the first four conditions of the first rule of the theory. 3.4 Comparison of Neither and Either The DNA promoter sequences data set <ref> (Towell et al., 1990) </ref> was used as an initial test to measure the benefits of the Neither approach. This data set involves 57 features, 106 examples, and 2 categories. The theory provided with the data set has an initial classification accuracy of 50%.
Reference: <author> VanLehn, K. </author> <year> (1983). </year> <title> Felicity conditions for human skill acquisition: validating an AI-based theory. </title> <type> PhD thesis, </type> <institution> Cambridge, MA: Massachusetts Institute of Technology. </institution>
Reference-contexts: Again this is because induction from scratch is simply a harder task. 6 Related Work There are three other systems which utilize machine learning techniques for student modeling. The first of these is VanLehn's SIERRA system <ref> (VanLehn, 1983) </ref> which builds on ideas developed in the DEBUGGY system (Burton, 1982). In DEBUGGY, student models are formed by introducing incorrect subskills into a lattice of skills called a procedural network. When a subskill is missing or incorrect, the result is faulty behavior.
Reference: <author> Wenger, E. </author> <year> (1987). </year> <booktitle> Artificial Intelligence and Tutoring Systems. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Finally, the last two sections compare Assert to other adaptive modeling efforts and propose specific extensions to enhance Assert's capabilities. 2 Background 2.1 Student Modeling in ICAI Research One of the most important components of an ICAI system is the student model <ref> (Wenger, 1987) </ref>. Some researchers have argued (Carbonell, 1970; Laubsch, 1975) that the effectiveness of an ICAI system depends heavily upon its student modeling component. Without the flexibility to model novel student errors, ICAI systems will not progress much beyond electronic page turners with canned responses tuned to the average student.
Reference: <author> Winston, P. H. and Horn, B. K. P. </author> <year> (1989). </year> <title> Lisp. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: We chose a propositional theory which classifies descriptions of animals into one of twelve categories using a set of 14 features. The full animal theory shown in appendix A is an extension of a set of rules given in <ref> (Winston and Horn, 1989) </ref>. It contains four disjunctive subconcepts (bird, mammal, ungulate and carnivore) and many of the examples require a chain of multiple subconcepts to be correctly classified. The animal 18 domain thus represents a nice theory for testing Assert's ability to catch misconceptions.
Reference: <author> Young, R. M. and O'Shea, T. </author> <year> (1981). </year> <title> Errors in children's subtraction. </title> <journal> Cognitive Science, </journal> <volume> 5 </volume> <pages> 153-177. </pages>
References-found: 38

