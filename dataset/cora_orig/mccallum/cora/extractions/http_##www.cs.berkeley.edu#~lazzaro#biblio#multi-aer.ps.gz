URL: http://www.cs.berkeley.edu/~lazzaro/biblio/multi-aer.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~lazzaro/biblio/bib.html
Root-URL: 
Email: flazzaro,johnwg@cs.berkeley.edu  
Title: A Multi-Sender Asynchronous Extension to the AER Protocol  
Author: John Lazzaro and John Wawrzynek 
Address: Berkeley CA 94720-1776  
Affiliation: Computer Science Division UC Berkeley  
Abstract: The address-event representation (AER) is an asynchronous point-to-point communications protocol for silicon neural systems. This paper describes an extension of the AER protocol that allows multiple AER senders to share a common bus. A fully-functional silicon implementation of the extended protocol is described, as well as a functional board-level system of several of these chips sharing a common bus. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lazzaro, J. P., Wawrzynek, J., and Kramer, </author> <title> A (1994). Systems technologies for silicon auditory models. </title> <journal> IEEE Micro, </journal> <volume> 14:3. </volume> <pages> 7-15. </pages>
Reference-contexts: This latch is released when the bus acknowledge signal, A c , occurs. the depth of the arbitration tree and adding additional data lines, chips with linear arrays of 120 output units have been implemented <ref> [1] </ref>; in addition, a straightforward extension to this architecture supports chips with two-dimensional arrays of output units [2]. r a r a R c D o D 1 A c trol Logic A A a i A c i data (D o ; D 1 ) and request (R c ) <p> The practical use of this system in auditory applications is limited; the purpose of the chip was to test the modified AER sender design in an economical fashion. A version of the 120-channel auditory model presented in <ref> [1] </ref>, retrofitted with this modified AER sender design, has also been fabricated. A three-sender system built with this chip functions correctly, and exhibits bus transaction speeds consistent with the data above. R c 450ns 450ns to an SBus interface board with a 1s cycle time. <p> A variety of interesting auditory representations coding spectral shape, pitch, auditory localization, and other properties can be implemented on a single die, along with non-volatile electrically programmable parameter storage and an AER sender port <ref> [1] </ref>. Routing input to an auditory model chip is simple: a shielded audio cable suffices. This technique scales very well to hundreds of auditory model chips. If these auditory model chips use energy-efficient coding and the multi-sender AER protocol, combining the output of many auditory models is also straightforward.
Reference: [2] <author> Lazzaro, J. P., Wawrzynek, J., Mahowald., M., Sivilotti, M., Gillespie, D. </author> <year> (1993). </year> <title> Silicon auditory processors as computer peripherals. </title> <journal> IEEE Journal of Neural Networks 4:3 523-528. </journal>
Reference-contexts: Multiple copies of single chip, with different control parameters, can compute these representations independently <ref> [2] </ref>. However, while connecting a single AER port to a receiver is a simple exercise, connecting several ports to a single receiver is more difficult. As each AER port has its own dedicated data bus, the fan-in of the receiver grows linearly with the number of input ports. <p> The chip has been fabricated and tested, and the board implementation is fully functional. 2 An AER implementation Our multiple-sender AER implementation is an extension of the AER architecture shown in <ref> [2] </ref>. We begin the description of our multiple-sender extension with a review of the original architecture. 2.1 The output unit abstraction An output unit converts an analog signal into a stream of fixed-width, fixed-height pulses. <p> We use a tree of 2-input arbiters to implement this N input arbiter. Figure 2 shows an implementation of 4 output units serviced by an arbitration tree; the boxes marked A are two-input arbiters as implemented in <ref> [2] </ref>. The traces in Figure 2 show typical behavior for staggered and simultaneous pulse patterns. 2.3 Generating an asynchronous output bus The arbitration tree in Figure 2 acts to order the asynchronous activity of the output units into a sequence of individual events. <p> is released when the bus acknowledge signal, A c , occurs. the depth of the arbitration tree and adding additional data lines, chips with linear arrays of 120 output units have been implemented [1]; in addition, a straightforward extension to this architecture supports chips with two-dimensional arrays of output units <ref> [2] </ref>. r a r a R c D o D 1 A c trol Logic A A a i A c i data (D o ; D 1 ) and request (R c ) outputs of the off-chip bus.
Reference: [3] <author> Lazzaro, J. and Mead, C. </author> <year> (1989). </year> <title> Circuit models of sensory transduction in the cochlea. </title> <editor> In Mead, C. and Ismail, M. (eds), </editor> <title> Analog VLSI Implementations of Neural Networks. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers, </publisher> <pages> pp. 85-101. </pages>
Reference-contexts: The output units were driven by an auditory nerve model, as described in <ref> [3] </ref>. The chip was fabricated on the Orbit 2 low-noise analog n-well process, in a TinyChip 40-pin package. Pin positions of tri-state pads were placed at adjacent positions at the ends of the package, to induce worse-case noise coupling.
Reference: [4] <author> Mahowald, M.A. and Mead, C. </author> <year> (1991). </year> <title> The silicon retina. </title> <publisher> Scientific American, V264 N5:76-82. </publisher>
Reference-contexts: Early work in analog VLSI modeling of neural systems focused on mapping the computational methods of neural computation on to analog circuits. To send the results of the computation off chip, these systems use traditional data acquisition techniques. An example of this approach is the original silicon retina design <ref> [4] </ref>. On this chip, weak-inversion analog circuits model sensing and computation in the mammalian retina, while a uniform-rate sampling system multiplexes the output array into a signal suitable for driving a video monitor.
Reference: [5] <author> Mahowald, M. A. </author> <year> (1992). </year> <title> "Computation and Neural Systems," </title> <type> Ph.D. dissertation, </type> <institution> California Institute of Technology. </institution>
Reference-contexts: One general communications architecture for vision chips is broadcast: every vision chip sends all event information to every other chip in the system <ref> [5] </ref>. The multi-sender AER technology presented in this paper can be extended to support broadcast in a straightforward way.
Reference: [6] <author> Mortara, A. and Vittoz, E. A. </author> <year> (1994). </year> <title> "A communications architecture tailored for analog VLSI artificial neural networks intrinsic performance and limitations", </title> <journal> IEEE Journal of Neural Networks, </journal> <year> 1994 </year> <month> May, </month> <note> V5 N3:459-466. </note>
Reference: [7] <author> M. </author> <title> Sivilotti (1991) "Wiring concerns in analog VLSI systems, with applications to field-programmable networks," </title> <note> Computer Science Technical Report, </note> <author> Ph. D. </author> <type> dissertation, </type> <institution> California Institute of Technology. </institution>
Reference: [8] <author> M. Cooke, S. Beet, and M. </author> <title> Crawford (1993). "Visual Representations of Speech Signals." </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference-contexts: Would such a system be useful? Recent research in audio signal processing has cen-tered on building auditory scene analysis systems: sound processing systems that break up a sound signal into many different representations before making decisions on the data <ref> [8] </ref>. These systems are analogous to machine vision systems that compute motion, color, and edge representations on a raw input image before performing a task. A collection of silicon auditory model chips communicating with a host computer would function as a real-time, low-power hardware accelerator for auditory scene analysis.
References-found: 8

