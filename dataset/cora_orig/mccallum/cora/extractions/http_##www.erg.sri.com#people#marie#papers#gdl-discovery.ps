URL: http://www.erg.sri.com/people/marie/papers/gdl-discovery.ps
Refering-URL: http://www.erg.sri.com/people/marie/papers/gdl-discovery-abs.html
Root-URL: 
Email: marie@erg.sri.com  
Title: Goal-Directed Learning: A Decision-Theoretic Model for Deciding What to Learn Next  
Author: Marie desJardins 
Address: 333 Ravenswood Ave. Menlo Park CA 94025  
Affiliation: SRI International  
Abstract: This paper describes a theory called Goal-Directed Learning (gdl) that uses the principle of decision theory to choose learning tasks. The expected utility of being able to predict various features of the environment is computed and those with highest expected utility can be used as learning goals, which an agent's inductive mechanism should form theories to predict. We present a general decision-theoretic formula for the utility of learning goals, formalizing the concept that the best learning goals are those which, if learned, would maximize the agent's expected utility. The performance element of pagoda (Probabilistic Autonomous GOal-Directed Agent), an autonomous agent design presented in [4], is described, and a formula is given for computing the utility of learning goals in pagoda.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Matthew Brand. </author> <title> Decision-theoretic learning in an action system. </title> <booktitle> In Machine Learning Workshop, </booktitle> <pages> pages 283-287, </pages> <year> 1991. </year>
Reference-contexts: Although significant research has been done on the problems of generating individual training instances for learning a single concept [5, 8] and attention focusing to decide what sensory actions to perform <ref> [2, 1] </ref>, we do not know of any other research that specifically addresses the problem of selecting concepts to learn. 10 7 Conclusions Some important factors were not included in the analysis.
Reference: [2] <author> Lonnie Chrisman and Reid Simmons. </author> <title> Sensible planning: Focusing perceptual attention. </title> <booktitle> In AAAI, </booktitle> <pages> pages 756-761, </pages> <year> 1991. </year>
Reference-contexts: Although significant research has been done on the problems of generating individual training instances for learning a single concept [5, 8] and attention focusing to decide what sensory actions to perform <ref> [2, 1] </ref>, we do not know of any other research that specifically addresses the problem of selecting concepts to learn. 10 7 Conclusions Some important factors were not included in the analysis.
Reference: [3] <author> Thomas Dean, Kenneth Basye, Robert Chekaluk, et al. </author> <title> Coping with uncertainty in a control system for navigation and exploration. </title> <booktitle> In AAAI, </booktitle> <pages> pages 1010-1015, </pages> <year> 1990. </year>
Reference-contexts: Dean et al. <ref> [3] </ref> describe a decision-theoretic approach to planning under uncertainty that includes an expected value of exploration; this is related in spirit to our expected value of learning.
Reference: [4] <author> Marie desJardins. PAGODA: </author> <title> A Model for Autonomous Learning in Probabilistic Domains. </title> <type> PhD thesis, </type> <institution> UC Berkeley, </institution> <year> 1992. </year>
Reference-contexts: (i.e., it is assumed to have already formed a plan to achieve these values). 3 Performance Element pagoda is an autonomous agent design which incorporates gdl as well as techniques for finding an appropriate bias for learning goals, inductive learning of probabilistic domain theories, and planning with the learned theories <ref> [4] </ref>. pagoda has been implemented in the ralph (Rational Agent with Limited Performance Hardware) world, a testbed for designing intelligent agents [6]. In this section, we briefly describe pagoda's performance element, consisting of a representation for probabilistic theories and a planning mechanism using these theories.
Reference: [5] <author> Yolanda Gil. </author> <title> A domain-independent framework for effective experimentation in planning. </title> <booktitle> In Machine Learning Workshop, </booktitle> <pages> pages 13-17, </pages> <year> 1991. </year>
Reference-contexts: Dean et al. [3] describe a decision-theoretic approach to planning under uncertainty that includes an expected value of exploration; this is related in spirit to our expected value of learning. Although significant research has been done on the problems of generating individual training instances for learning a single concept <ref> [5, 8] </ref> and attention focusing to decide what sensory actions to perform [2, 1], we do not know of any other research that specifically addresses the problem of selecting concepts to learn. 10 7 Conclusions Some important factors were not included in the analysis.
Reference: [6] <author> Ronald Parr, Stuart Russell, and Mike Malone. </author> <title> The RALPH system. </title> <type> Technical report, </type> <institution> UC Berkeley, </institution> <year> 1992. </year> <month> (Forthcoming). </month>
Reference-contexts: agent design which incorporates gdl as well as techniques for finding an appropriate bias for learning goals, inductive learning of probabilistic domain theories, and planning with the learned theories [4]. pagoda has been implemented in the ralph (Rational Agent with Limited Performance Hardware) world, a testbed for designing intelligent agents <ref> [6] </ref>. In this section, we briefly describe pagoda's performance element, consisting of a representation for probabilistic theories and a planning mechanism using these theories. <p> In a simple ralph world, containing only ralph and one piece of food (which is regenerated at a random location whenever ralph eats it), pagoda learns the following theory to predict the change in its utility: R 1 [60] 2 ! 1:0 u (t + 1; 10) R 2 <ref> [6] </ref> action (t; :move-forward) ^vision (t; wall; 1) ! 1:0 u (t + 1; 11) R 3 [9] food-smell (t; 20) ^action (t; :munch) ! 1:0 u (t + 1; 90) Conditional probabilities are represented as subscripted implications for convenience only.
Reference: [7] <author> L. J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover, </publisher> <year> 1977. </year> <note> 2nd rev. ed. </note>
Reference-contexts: Therefore, it will need to focus its attention on aspects of the environment that are most relevant to its ability to succeed at whatever task it was built for: that is, it must decide what concepts to learn. Decision theory <ref> [9, 7] </ref> states that a rational agent's primary task is to maximize expected utility. pagoda does this by using a model of the world to make predictions about the effects of its actions on individual features the world.
Reference: [8] <author> Paul D. Scott and Shaul Markovitch. </author> <title> Uncertainty based selection of learning experiences. </title> <booktitle> In Machine Learning Workshop, </booktitle> <pages> pages 358-361, </pages> <year> 1989. </year>
Reference-contexts: Dean et al. [3] describe a decision-theoretic approach to planning under uncertainty that includes an expected value of exploration; this is related in spirit to our expected value of learning. Although significant research has been done on the problems of generating individual training instances for learning a single concept <ref> [5, 8] </ref> and attention focusing to decide what sensory actions to perform [2, 1], we do not know of any other research that specifically addresses the problem of selecting concepts to learn. 10 7 Conclusions Some important factors were not included in the analysis.
Reference: [9] <author> John von Neumann and Oskar Morgenstern. </author> <title> Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <year> 1947. </year>
Reference-contexts: Therefore, it will need to focus its attention on aspects of the environment that are most relevant to its ability to succeed at whatever task it was built for: that is, it must decide what concepts to learn. Decision theory <ref> [9, 7] </ref> states that a rational agent's primary task is to maximize expected utility. pagoda does this by using a model of the world to make predictions about the effects of its actions on individual features the world. <p> at a random location whenever ralph eats it), pagoda learns the following theory to predict the change in its utility: R 1 [60] 2 ! 1:0 u (t + 1; 10) R 2 [6] action (t; :move-forward) ^vision (t; wall; 1) ! 1:0 u (t + 1; 11) R 3 <ref> [9] </ref> food-smell (t; 20) ^action (t; :munch) ! 1:0 u (t + 1; 90) Conditional probabilities are represented as subscripted implications for convenience only. They are to be interpreted as conditional probabilities, not as the probability that the logical implication is true. Each rule (conditional distribution) is numbered for convenience.
Reference: [10] <author> Michael P. Wellman. </author> <title> The STRIPS assumption for planning under uncertainty. </title> <booktitle> In AAAI, </booktitle> <pages> pages 198-203, </pages> <year> 1990. </year> <month> 12 </month>
Reference-contexts: it allows the agent to plan to be at food, where it can eat the food and raise its utility. 6 Related Work Our approach to probabilistic planning is a fairly straightforward one, based on the principle of maximizing utility. pagoda uses a strips assumption similar to that discussed in <ref> [10] </ref>. Dean et al. [3] describe a decision-theoretic approach to planning under uncertainty that includes an expected value of exploration; this is related in spirit to our expected value of learning.
References-found: 10

