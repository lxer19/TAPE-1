URL: http://www.cs.cornell.edu/home/kleinber/focs97-ind.ps
Refering-URL: http://www.cs.cornell.edu/home/kleinber/kleinber.html
Root-URL: 
Title: Storage Management for Evolving Databases  
Author: J. Kleinberg R. Motwani P. Raghavan S. Venkatasubramanian 
Abstract: The problem of maintaining data that arrives continuously over time is increasingly prevalent in databases and digital libraries. Building on a model for sliding-window indices developed in [24], we devise efficient algorithms for some of the central problems that arise. We also show connections between the problems in this model and some fundamental problems in optimization and graph theory. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, F.R.K. Chung. </author> <title> Explicit construction of linear-size tolerant networks. </title> <journal> Discrete Math, </journal> <volume> 72(1988). </volume>
Reference-contexts: Using properties of strong expander graphs | in particular, a construction due to Alon and Chung <ref> [1] </ref> | we can show that the answer to this question is negative. Theorem 4.1 There is an absolute constant " such that the following holds.
Reference: [2] <author> J. Aspnes, Y. Azar, A. Fiat, S. Plotkin, and O. Waarts. </author> <title> On-line machine scheduling with applications to load balancing and virtual circuit routing. </title> <booktitle> In Proceedings of 25th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 623-631. </pages>
Reference: [3] <author> B. Awerbuch, Y. Azar, E.F. Grove, M-Y. Kao, P. Krishnan, and J.S. Vitter. </author> <title> Load Balancing in the L p Norm. </title> <booktitle> In Proceedings of 36th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1995, </year> <pages> pp. 383-391. </pages>
Reference: [4] <author> Y. Azar, A.Z. Broder, and A.R. Karlin. </author> <title> On-line load balancing. </title> <journal> Theoretical Computer Science, </journal> <volume> 130(1994) </volume> <pages> 73-84. </pages>
Reference: [5] <author> Y. Azar, B. Kalayanasundaram, S. Plotkin, K. R. Pruhs, and O. Waarts. </author> <title> On-line Load Balancing of Temporary Tasks. </title> <booktitle> Proceedings of the 1993 Workshop on Algorithms and Data Structures, </booktitle> <year> 1993, </year> <pages> pp. 119-130. </pages>
Reference: [6] <author> Y. Bartal, A. Fiat, H. Karloff, and R. Vohra. </author> <title> New Algorithms for an Ancient Scheduling Problem. </title> <booktitle> In Proceedings of 24th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1992, </year> <pages> pp. 51-58. </pages>
Reference: [7] <author> Y. Bartal, H. Karloff, and Y. Rabani. </author> <title> A better lower bound for on-line scheduling. </title> <journal> Information Processing Letters, </journal> <volume> 50(1994) </volume> <pages> 113-116. </pages>
Reference: [8] <author> E.W. Brown, J.P. Callan, and W.B. Croft. </author> <title> Fast incremental indexing for full-text information retrieval. </title> <booktitle> In Proceedings of the 20th International Conference on Very Large Databases, </booktitle> <year> 1994, </year> <pages> pp. 192-202. </pages>
Reference: [9] <author> M. Charikar and P. Indyk. Personal communica-tion, </author> <year> 1995. </year>
Reference: [10] <author> Bo Chen, A. van Vliet, and G.J. Woeginger. </author> <title> New lower and upper bounds for on-line scheduling. </title> <journal> Operations Research Letters, </journal> <volume> 16(1994) </volume> <pages> 221-230. </pages>
Reference: [11] <author> Bo Chen, A. van Vliet, and G.J. Woeginger. </author> <title> A lower bound for randomized on-line scheduling algorithms. </title> <journal> Information Research Letters, </journal> <volume> 51(1994) </volume> <pages> 219-222. </pages>
Reference: [12] <author> L. Cowen, W. Goddard, and E. Jesurum. </author> <title> Coloring with defect. </title> <booktitle> In Proceedings of the 8th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1997. </year>
Reference-contexts: We have not been able to find any previous reference to the fragmented coloring problem in the literature (survey books such as [19] do not contain it). In its statement, it is similar to the defective coloring problem studied recently by Cowen, Goddard, and Jesurum <ref> [12] </ref>. In particular, a (k; 1)-defective coloring in the sense of [12] is the same as a (k; 2)-fragmented coloring in the present context; but for larger values of c the two notions become very different. <p> In its statement, it is similar to the defective coloring problem studied recently by Cowen, Goddard, and Jesurum <ref> [12] </ref>. In particular, a (k; 1)-defective coloring in the sense of [12] is the same as a (k; 2)-fragmented coloring in the present context; but for larger values of c the two notions become very different. <p> We feel that (k; c)-fragmented coloring is an inter-esting combinatorial notion in its own right, and we discuss some basic results and questions here. First of all, let us compare this notion with that of defective coloring, as studied in Cowen, Goddard, and Jesurum <ref> [12] </ref>. There, a graph is said to have a (k; d)-defective coloring if it can be k-colored so that each vertex is adjacent to at most d other vertices of the same color. <p> Thus, a graph has a (k; 2)-fragmented coloring if and only if it has a (k; 1)-defective coloring. Hence, by a result of <ref> [12] </ref>, it is NP-hard to decide whether an arbitrary graph has a (k; 2)-fragmented coloring.
Reference: [13] <author> D. Cutting and J. Pedersen. </author> <title> Optimizations for dynamic inverted index maintenance. </title> <booktitle> In Proceedings of the International Conference on Information Retrieval. </booktitle> <year> 1990, </year> <pages> pp. 405-411. </pages>
Reference: [14] <institution> DEC Corporation. </institution> <note> AltaVista search engine. http://altavista.digital.com. </note>
Reference-contexts: Continuously arriving data: There are many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing [26, 28]; web search engines and indices of Netnews articles (e.g. <ref> [14, 18, 15] </ref>); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) [22, 23]. Sliding-window indices: Minimizing the storage required is a major objective in such settings; this is due both to storage costs and the requirements of fast query performance.
Reference: [15] <institution> Deja News Research Service. Dejanews news research service. </institution> <note> http://www.dejanews.com. </note>
Reference-contexts: Continuously arriving data: There are many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing [26, 28]; web search engines and indices of Netnews articles (e.g. <ref> [14, 18, 15] </ref>); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) [22, 23]. Sliding-window indices: Minimizing the storage required is a major objective in such settings; this is due both to storage costs and the requirements of fast query performance.
Reference: [16] <author> U. Faigle, W. Kern, and G. Turan. </author> <title> On the Performance of On-Line Algorithms for Partition Problems. </title> <journal> Acta Cybernetica, </journal> <volume> 9(1989) </volume> <pages> 107-119. </pages>
Reference: [17] <author> R.L. Graham. </author> <title> Bounds for Certain Multiprocessor Anomalies. </title> <journal> Bell System Technical Journal, </journal> <volume> 45(1966) </volume> <pages> 1563-1581. </pages>
Reference: [18] <author> Infoseek Corporation. </author> <title> Infoseek search engine. </title> <address> http://www.infoseek.com. </address>
Reference-contexts: Continuously arriving data: There are many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing [26, 28]; web search engines and indices of Netnews articles (e.g. <ref> [14, 18, 15] </ref>); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) [22, 23]. Sliding-window indices: Minimizing the storage required is a major objective in such settings; this is due both to storage costs and the requirements of fast query performance.
Reference: [19] <author> T. Jensen and B. Toft. </author> <title> Graph Coloring Problems. </title> <publisher> Wiley Interscience, </publisher> <year> 1995. </year>
Reference-contexts: We have not been able to find any previous reference to the fragmented coloring problem in the literature (survey books such as <ref> [19] </ref> do not contain it). In its statement, it is similar to the defective coloring problem studied recently by Cowen, Goddard, and Jesurum [12].
Reference: [20] <author> D. Karger, S.J. Phillips, and E. Torng. </author> <title> A better algorithm for an ancient scheduling problem. </title> <booktitle> In Proceedings of ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference: [21] <author> F.T. Leighton and E.J. Schwabe. </author> <title> Efficient algorithm for dynamic allocation of distributed memory. </title> <booktitle> In Proceedings of 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 470-479. </pages>
Reference: [22] <author> P.E. Ross. </author> <title> Cops versus robbers in cyberspace. </title> <journal> Forbes Magazine, </journal> <month> September 9, </month> <year> 1996, </year> <pages> pp. 134-139. </pages>
Reference-contexts: many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing [26, 28]; web search engines and indices of Netnews articles (e.g. [14, 18, 15]); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) <ref> [22, 23] </ref>. Sliding-window indices: Minimizing the storage required is a major objective in such settings; this is due both to storage costs and the requirements of fast query performance.
Reference: [23] <author> N. Shivakumar and H. Garcia-Molina. </author> <title> Building a scalable and accurate copy detection mechanism. </title> <booktitle> In Proceedings of the 1st ACM Conference on Digital Libraries, </booktitle> <year> 1996. </year>
Reference-contexts: many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing [26, 28]; web search engines and indices of Netnews articles (e.g. [14, 18, 15]); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) <ref> [22, 23] </ref>. Sliding-window indices: Minimizing the storage required is a major objective in such settings; this is due both to storage costs and the requirements of fast query performance.
Reference: [24] <author> N. Shivakumar and H. Garcia-Molina. </author> <title> Wave Indices: Indexing Evolving Databases. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction Large volumes of data arriving continuously over time add new complexity to problems of storage management in databases and digital libraries. Recent work in these communities has resulted in a framework for studying these issues (see e.g. <ref> [24] </ref> and the references therein). <p> In this way, a sliding-window index can be used as a fast cache of the most recent data; users interested in older data must tolerate a slower search process. 1.1 The problem statement In a sliding-window index <ref> [24] </ref>, we have k compartments P 1 ; : : : ; P k , and a window size w. Time progresses continuously, and a sequence of items X 1 ; X 2 ; : : : arrive at arbitrary times; unless otherwise specified, each item has an arbitrary size. <p> Thus for many of the applications of sliding-window indices (including those exemplified by the TPC-D benchmark from the Transaction Pro--cessing Council [26]), Shivakumar and Garcia-Molina report that the following approach achieves the best performance <ref> [24] </ref>: Wait and Throw Away (WATA): Only delete items from a given compartment when all the items in that compartment have expired. The use of this indexing scheme amortizes the cost of reclaiming space by allowing expired items to be cleared out only in increments of whole compartments. <p> In our model, the total weight is the sum of the sizes of the live items and of the expired items that have not yet been flushed out. Thus, minimizing total load becomes a non-trivial optimization problem, as it is in practice. In <ref> [24] </ref>, Shivakumar and Garcia-Molina propose a simple "round-robin" heuristic for minimizing total load which is always within a factor of 2 of optimal. * Maximum Load. Here, we wish to find an assignment that minimizes the maximum load of any compartment, over all time. <p> In reality, trace information generally allows one to design algorithms that exploit known cyclical (e.g., weekly) patterns in data arrival. Moreover, such algorithms are also evaluated and tuned on this type of trace information <ref> [24] </ref>. Thus, the most reasonable input model is the following periodic model: we take a finite sequence of item arrivals and repeat it indefinitely, shifted periodically by a fixed increment of time. <p> This improves on the 2-approximation heuristic proposed in <ref> [24] </ref>. We do this by first developing a polynomial-time algorithm for the finite off-line model (i.e. a finite set of items is presented to the algorithm), and then extending the techniques to apply to the periodic model as well. <p> Theorem 5.1 Any deterministic on-line algorithm has competitive ratio at least 1 + 1=k. If we assume that at most one item arrives per day, then a simple on-line algorithm is provided by the EQUIPARTITION heuristic of Shivakumar and Garcia-Molina <ref> [24] </ref> which places (w 1)=(k 1) files in each compartment before moving on to the next one. Theorem 5.2 EQUIPARTITION is 2-competitive but not c-competitive for any c &lt; 2. We now give an on-line algorithm that nearly matches the on-line lower bound contained in Theorem 5.1.
Reference: [25] <author> A. Tomasic, H. Garcia-Molina, and K. Shoens. </author> <title> Incremental updates of inverted lists for text document retrieval. </title> <booktitle> In Proceedings of the ACM SIG-MOD International Conference on Management of Data, </booktitle> <year> 1994. </year>
Reference: [26] <institution> TPC Committee. Transaction Processing Council. </institution> <note> http://www.tpc.org. </note>
Reference-contexts: The trend is to automate and simplify (human-intensive) administrative functions through the use of sophisticated algorithms. Continuously arriving data: There are many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing <ref> [26, 28] </ref>; web search engines and indices of Netnews articles (e.g. [14, 18, 15]); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) [22, 23]. <p> Thus for many of the applications of sliding-window indices (including those exemplified by the TPC-D benchmark from the Transaction Pro--cessing Council <ref> [26] </ref>), Shivakumar and Garcia-Molina report that the following approach achieves the best performance [24]: Wait and Throw Away (WATA): Only delete items from a given compartment when all the items in that compartment have expired.
Reference: [27] <author> J. Westbrook. </author> <title> Load Balancing for Response Time. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference: [28] <author> J. Widom. </author> <title> Research problems in data warehousing. </title> <booktitle> In Proceedings of the 4th Conference on Information and Knowledge Management, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: The trend is to automate and simplify (human-intensive) administrative functions through the use of sophisticated algorithms. Continuously arriving data: There are many settings in which large databases must be maintained subject to the frequent insertion of large quantities of new information: these include data warehousing <ref> [26, 28] </ref>; web search engines and indices of Netnews articles (e.g. [14, 18, 15]); and automated fraud detection mechanisms such as SCAM (Stanford Copy Analysis Mechanism) [22, 23].
Reference: [29] <author> T. Yan and H. Garcia-Molina. </author> <title> Sift a tool for wide-area information dissemination. </title> <booktitle> In Proceedings of USENIX, </booktitle> <year> 1995. </year>
References-found: 29

