URL: http://www.cs.tamu.edu/faculty/rwerger/Courses/605/omega.ps
Refering-URL: http://www.cs.tamu.edu/faculty/rwerger/Courses/605/
Root-URL: http://www.cs.tamu.edu
Email: pugh@cs.umd.edu, (301)-405-2705  
Title: The Omega Test: a fast and practical integer programming algorithm for dependence analysis integer programming
Author: William Pugh 
Address: College Park, MD 20742  
Affiliation: Dept. of Computer Science and Institute for Advanced Computer Studies Univ. of Maryland,  
Date: August 1992  July 12, 1993  
Note: Originally appeared at Supercomputing '91 This expanded version appeared in Comm. of the ACM,  The Omega test can be used to project  
Abstract: The Omega test is an integer programming algorithm that can determine whether a dependence exists between two array references, and if so, under what conditions. Conventional wisdom holds that integer programming techniques are far too expensive to be used for dependence analysis, except as a method of last resort for situations that cannot be decided by simpler methods. We present evidence that suggests this wisdom is wrong, and that the Omega test is competitive with approximate algorithms used in practice and suitable for use in production compilers. Experiments suggest that, for almost all programs, the average time required by the Omega test to determine the direction vectors for an array pair is less than 500 secs on a 12 MIPS workstation. The Omega test is based on an extension of Fourier-Motzkin variable elimination (a linear programming method) to integer programming, and has worst-case exponential time complexity. However, we show that for many situations in which other (polynomial) methods are accurate, the Omega test has low order polynomial time complexity. 
Abstract-found: 1
Intro-found: 1
Reference: [AI91] <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Scanning polyhedra with do loops. </title> <booktitle> In Proc. of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This use of integer programming and projection to perform this is described by <ref> [AI91] </ref>. 6 Performance We have implemented the Omega test in Wolfe's tiny tool [Wol91]. We handle min and max expressions in loop bounds and symbolic constants, and compute exact sets of direction vectors (as opposed to the compressed direction vectors normally generated by tiny). <p> Both Wolfe and Tseng [WT92] and May-dan, Hennessy and Lam [MHL91] suggest that due to the expense of Fourier-Motzkin variable elimination, simpler tests should be used instead in situations where they are known to be accurate. Ancourt and Irigoin <ref> [AI91] </ref> describe the use of Fourier-Motzkin variable elimination so as to determine loop bounds for iterating over an iteration space described by a set of linear inequalities (using projection as described in Section 4). Their work has significant overlaps with ours. <p> If the projection is not exact, then they add pseudo-linear constraints to the real shadow to obtain the integer shadow. These pseudo-linear constraints appear useful and appropriate for determining loop bounds. However, they are difficult to use for determining the existence of integer solutions. Ancourt and Irigoin <ref> [AI91] </ref> do not give any performance data for their algorithm. A recent report [IJT91] on the PIPS project mentions that Fourier-Motzkin variable elimination is used to analyze dependences (based on the work described in [AI91]). <p> Ancourt and Irigoin <ref> [AI91] </ref> do not give any performance data for their algorithm. A recent report [IJT91] on the PIPS project mentions that Fourier-Motzkin variable elimination is used to analyze dependences (based on the work described in [AI91]). The methods used are not fully described, but the basic framework appears similar to that described in Section 5.1. It is not clear how the pseudo-linear constraints of [AI91] are handled. They point out that in many simple cases, Fourier-Motzkin variable 15 elimination is fast and efficient. <p> [IJT91] on the PIPS project mentions that Fourier-Motzkin variable elimination is used to analyze dependences (based on the work described in <ref> [AI91] </ref>). The methods used are not fully described, but the basic framework appears similar to that described in Section 5.1. It is not clear how the pseudo-linear constraints of [AI91] are handled. They point out that in many simple cases, Fourier-Motzkin variable 15 elimination is fast and efficient. They state that using integer programming techniques for dependence analysis incurs a very high cost (that is acceptable since PIPS is not a production system). <p> It can make it much easier to describe and build program analysis and transformation tools. For example, it can be used for determining loop bounds after loop interchange <ref> [AI91] </ref>, and we have made extensive use of it in work that considers loop transformations in a uniform manner [Pug91]. 11 Acknowledgements Thanks to everyone who gave me feedback on this work, especially Michael Wolfe and the anonymous referee who provided detailed comments, as well as to my research group (Dave
Reference: [AK87] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [All83] <author> J. R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and Its Application to Program Transformations. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1983. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [Ban88] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [BC86] <author> M. Burke and R. Cytron. </author> <title> Interprocedural dependence analysis and parallelization. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> July </month> <year> 1986. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases. <p> Determining dependence direction vectors may require an exponential number calls to a dependence testing algorithm that only returns yes/no. To be competitive, a dependence analysis method must be able to short-cut this enumeration process (e.g., see <ref> [BC86, GKT91] </ref>). In Section 4, we show how the Omega test can be modified to project integer programming problems onto a subset of the variables, rather than just deciding them. <p> One way to determine dependence direction vectors is to make 3 L calls to a decision procedure (where L is the number of loops surrounding both references). In order to be competitive, a dependence analysis method must be able to short-cut this enumeration (for example, see <ref> [BC86, GKT91] </ref>). In our method, we take the integer programming problem for determining if any dependence exists between two references, and introduce a new variable for the dependence distance in each shared loop (along with the appropriate equality constraints to define the value of the variable).
Reference: [BK89] <author> V. Balasundaram and K. Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <volume> '89, </volume> <month> June </month> <year> 1989. </year>
Reference-contexts: Alternatively, at compile time we could ask the user if the predicate is true. 5.3 Summarizing Array References In interprocedural analysis, we need to characterize the portions of an array that may be affected by a procedure call <ref> [Tri85, BK89, HK90, IJT91] </ref>. We can use the Omega test to obtain an accurate summary of the locations of an array that might be affected by a single assignment statement. <p> It is unclear how to use the Omega test to merge affected regions; however, the Omega test could be used to convert exact affected regions into approximate affect regions (such as described by <ref> [BK89, HK90] </ref>) and then those regions could be merged. 5.4 Determining Loop Bounds The Omega test can be used to determine appropriate loop bounds when interchanging non-rectangular loops.
Reference: [DE73] <author> G.B. Dantzig and B.C. Eaves. </author> <title> Fourier-Motzkin elimination and its dual. </title> <journal> Journal of Combinatorial Theory (A), </journal> <volume> 14 </volume> <pages> 288-297, </pages> <year> 1973. </year>
Reference-contexts: Otherwise, we reduce the problem to one or more integer programming problems in fewer dimensions and repeat the above process, eventually getting to problems in one dimension. 4 2.3.1 Detecting real solutions using Fourier-Motzkin variable elimination Fourier-Motzkin variable elimination <ref> [DE73] </ref> eliminates a variable from a linear programming problem. Intuitively, Fourier-Motzkin variable elimination finds the n 1 dimensional shadow cast by an n dimensional object. Consider the dodecahedron in Figure 2a.
Reference: [GKT91] <author> G. Goff, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Practical dependence testing. </title> <booktitle> In ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <year> 1991. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases. <p> Determining dependence direction vectors may require an exponential number calls to a dependence testing algorithm that only returns yes/no. To be competitive, a dependence analysis method must be able to short-cut this enumeration process (e.g., see <ref> [BC86, GKT91] </ref>). In Section 4, we show how the Omega test can be modified to project integer programming problems onto a subset of the variables, rather than just deciding them. <p> One way to determine dependence direction vectors is to make 3 L calls to a decision procedure (where L is the number of loops surrounding both references). In order to be competitive, a dependence analysis method must be able to short-cut this enumeration (for example, see <ref> [BC86, GKT91] </ref>). In our method, we take the integer programming problem for determining if any dependence exists between two references, and introduce a new variable for the dependence distance in each shared loop (along with the appropriate equality constraints to define the value of the variable). <p> Of the remaining 9% of the cases, they found that their SVPC, Acyclic or Loop Residue tests could be applied in 86% of the unique cases. The Delta test <ref> [GKT91] </ref> works by searching for dependence distances that can be easily determined, and then propagating that information with the intent of making it possible to easily determine other dependence distances precisely.
Reference: [HK90] <author> Paul Havlak and Ken Kennedy. </author> <title> Experience with interprocedural analysis of array side effects. </title> <booktitle> In Supercomputing '90, </booktitle> <year> 1990. </year>
Reference-contexts: Alternatively, at compile time we could ask the user if the predicate is true. 5.3 Summarizing Array References In interprocedural analysis, we need to characterize the portions of an array that may be affected by a procedure call <ref> [Tri85, BK89, HK90, IJT91] </ref>. We can use the Omega test to obtain an accurate summary of the locations of an array that might be affected by a single assignment statement. <p> It is unclear how to use the Omega test to merge affected regions; however, the Omega test could be used to convert exact affected regions into approximate affect regions (such as described by <ref> [BK89, HK90] </ref>) and then those regions could be merged. 5.4 Determining Loop Bounds The Omega test can be used to determine appropriate loop bounds when interchanging non-rectangular loops.
Reference: [HP90] <author> M. Haghighat and C. Polychronopoulos. </author> <title> Symbolic dependence analysis for high performance parallelizing compilers. </title> <booktitle> In Proceedings of the Third Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: Since the constraints generated for the real and dark shadow differ only in their constant terms, we can share much of the work in adding these constraints. 7 3 Nonlinear subscripts Integer programming dependence analysis methods allow us to properly handle symbolic constants <ref> [LT88, HP90] </ref> and some types of min and max functions in loop bounds [WT92] and conditional assignments [LC90].
Reference: [IJT91] <author> Fran~cois Irigoin, Pierre Jouvelot, and Remi Triolet. </author> <title> Semantical interprocedural parallelization: An overview of the pips project. </title> <booktitle> In Proc. of the 1991 International Conference on Supercomputing, </booktitle> <pages> pages 244-253, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Alternatively, at compile time we could ask the user if the predicate is true. 5.3 Summarizing Array References In interprocedural analysis, we need to characterize the portions of an array that may be affected by a procedure call <ref> [Tri85, BK89, HK90, IJT91] </ref>. We can use the Omega test to obtain an accurate summary of the locations of an array that might be affected by a single assignment statement. <p> These pseudo-linear constraints appear useful and appropriate for determining loop bounds. However, they are difficult to use for determining the existence of integer solutions. Ancourt and Irigoin [AI91] do not give any performance data for their algorithm. A recent report <ref> [IJT91] </ref> on the PIPS project mentions that Fourier-Motzkin variable elimination is used to analyze dependences (based on the work described in [AI91]). The methods used are not fully described, but the basic framework appears similar to that described in Section 5.1.
Reference: [KK91] <author> D. Klappholz and X. Kong. </author> <title> Extending the Banerjee-Wolfe test to handle execution conditions. </title> <type> Technical Report 9101, </type> <institution> Dept. of EE/CS, Stevens Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: to analyze. 10 5.2 Run-time checks and Compile-time assertions By projecting a problem onto the variables corresponding to symbolic constants that cannot be determined at compile-time, we can produce a predicate that will allow us to determine at run-time if a particular dependence or dependence direction exists (as described by <ref> [KK91] </ref>). Alternatively, at compile time we could ask the user if the predicate is true. 5.3 Summarizing Array References In interprocedural analysis, we need to characterize the portions of an array that may be affected by a procedure call [Tri85, BK89, HK90, IJT91].
Reference: [KMC72] <author> D. Kuck, Y. Muraoka, and S. Chen. </author> <title> On the number of operations simultaneously executable in FORTRAN-like programs and their resulting speedup. </title> <journal> IEEE Transactions on Computers, </journal> <year> 1972. </year>
Reference-contexts: Dependence analysis is often structured as a decision problem: tests simply answer yes or no. Compilers and other program restructuring tools need to know the data dependence direction vector [Wol82] and data dependence distance vector <ref> [KMC72, Mur71] </ref> that describes the relation between the iterations in which the conflicting reads/writes occur. The data dependence distance vector describes the differences between the values of the common loop variables between the first and second access to the same array element. <p> In compilers and other program structuring tools, we need to know the data dependence direction vector [Wol82] and data dependence distance vector <ref> [KMC72, Mur71] </ref> describing the relation between the iterations in which the conflicting reads/writes occur. One way to determine dependence direction vectors is to make 3 L calls to a decision procedure (where L is the number of loops surrounding both references).
Reference: [LC90] <author> L. Lu and M. Chen. </author> <title> Subdomain dependence test for massive parallelism. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: differ only in their constant terms, we can share much of the work in adding these constraints. 7 3 Nonlinear subscripts Integer programming dependence analysis methods allow us to properly handle symbolic constants [LT88, HP90] and some types of min and max functions in loop bounds [WT92] and conditional assignments <ref> [LC90] </ref>. <p> The Constraint-Matrix test can fail to terminate and it is not clear how efficiently it works in practice. Lu and Chen describe <ref> [LC90] </ref> an integer programming algorithm for dependence analysis. However, their method appears prohibitively expensive for use in a production compiler. Triolet [Tri85] used Fourier-Motzkin techniques for representing affected array regions in interprocedural analysis.
Reference: [LT88] <author> A. Lichnewsky and F. Thomasset. </author> <title> Introducing symbolic problem solving techniques in the dependence testing phases of a vectorizer. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Since the constraints generated for the real and dark shadow differ only in their constant terms, we can share much of the work in adding these constraints. 7 3 Nonlinear subscripts Integer programming dependence analysis methods allow us to properly handle symbolic constants <ref> [LT88, HP90] </ref> and some types of min and max functions in loop bounds [WT92] and conditional assignments [LC90].
Reference: [LY90] <author> Z. Li and P. Yew. </author> <title> Some results on exact data dependence analysis. </title> <editor> In D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing. </booktitle> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [LYZ89] <author> Z. Li, P. Yew, and C. Zhu. </author> <title> Data dependence analysis on multi-dimensional array references. </title> <booktitle> In Proceedings of the 1989 ACM International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [MHL91] <author> D. E. Maydan, J. L. Hennessy, and M. S. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-14, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases. <p> Maydan, Hennessy and Lam <ref> [MHL91] </ref> use memoization to obtain better performance. Memoization could be added to the Omega test. <p> If not (and checking for contradictory constraint pairs has not produced a contradiction), we know the problem has solutions and do not need to perform any additional computation. This applies iff the "Single Variable Per Constraint" (SVPC) test <ref> [MHL91] </ref> can be applied, which was found [MHL91] to be applicable in 1/3 of the unique cases found in the Perfect Club Benchmark (a higher percentage if duplicate cases were considered separately). The "Acyclic Test" [MHL91] can be applied in exactly those cases that the Omega test can resolve just by <p> If not (and checking for contradictory constraint pairs has not produced a contradiction), we know the problem has solutions and do not need to perform any additional computation. This applies iff the "Single Variable Per Constraint" (SVPC) test <ref> [MHL91] </ref> can be applied, which was found [MHL91] to be applicable in 1/3 of the unique cases found in the Perfect Club Benchmark (a higher percentage if duplicate cases were considered separately). The "Acyclic Test" [MHL91] can be applied in exactly those cases that the Omega test can resolve just by eliminating unbound variables and performing exact projections <p> This applies iff the "Single Variable Per Constraint" (SVPC) test <ref> [MHL91] </ref> can be applied, which was found [MHL91] to be applicable in 1/3 of the unique cases found in the Perfect Club Benchmark (a higher percentage if duplicate cases were considered separately). The "Acyclic Test" [MHL91] can be applied in exactly those cases that the Omega test can resolve just by eliminating unbound variables and performing exact projections that do not increase the number of constraints, a process that takes O (mn 2 ) worst-case time. They found [MHL91] that this test could be applied in <p> The "Acyclic Test" <ref> [MHL91] </ref> can be applied in exactly those cases that the Omega test can resolve just by eliminating unbound variables and performing exact projections that do not increase the number of constraints, a process that takes O (mn 2 ) worst-case time. They found [MHL91] that this test could be applied in over 1/4 of the unique cases encountered. The "Loop Residue" algorithm [Sho81] can be applied in just those cases where each constraint is of the form x i x j + c, x i c, or c x i . <p> Thus, the Omega test will take O (n 3 ) time to resolve a set of constraints that can be solved by the Loop Residue algorithm. Maydan, Hennessy and Lam <ref> [MHL91] </ref> found that the Loop Residue algorithm could be applied in 1/4 of the unique cases encountered in their study of the Perfect Club benchmark. Maydan, Hennessy and Lam found that 91% of the cases they encountered could be determined by constant tests and Banerjee's Generalized GCD tests. <p> The Power test described by Wolfe and Tseng [WT92] combines the Banerjee's Generalized GCD test, constraint tightening, and Fourier-Motzkin variable elimination. They take no special action when performing an inexact projection except to flag the result as possibly being conservative. Fourier-Motzkin elimination is used by Maydan, Hennessy and Lam <ref> [MHL91] </ref> if none of the other methods they use give an exact answer. They use back substitution to determine a sample solution. <p> If the sample solution is not integral, they suggest the use of branch and bound methods to verify or disprove the existence of integer solutions (they have not found the need to implement this thus far). Both Wolfe and Tseng [WT92] and May-dan, Hennessy and Lam <ref> [MHL91] </ref> suggest that due to the expense of Fourier-Motzkin variable elimination, simpler tests should be used instead in situations where they are known to be accurate.
Reference: [Mur71] <author> Y. Muraoka. </author> <title> Parallelism Exposure and Exploitation in Programs. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> February </month> <year> 1971. </year>
Reference-contexts: Dependence analysis is often structured as a decision problem: tests simply answer yes or no. Compilers and other program restructuring tools need to know the data dependence direction vector [Wol82] and data dependence distance vector <ref> [KMC72, Mur71] </ref> that describes the relation between the iterations in which the conflicting reads/writes occur. The data dependence distance vector describes the differences between the values of the common loop variables between the first and second access to the same array element. <p> In compilers and other program structuring tools, we need to know the data dependence direction vector [Wol82] and data dependence distance vector <ref> [KMC72, Mur71] </ref> describing the relation between the iterations in which the conflicting reads/writes occur. One way to determine dependence direction vectors is to make 3 L calls to a decision procedure (where L is the number of loops surrounding both references).
Reference: [Pug91] <author> William Pugh. </author> <title> Uniform techniques for loop optimization. </title> <booktitle> In 1991 International Conference on Supercomputing, </booktitle> <pages> pages 341-352, </pages> <address> Cologne, Germany, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: It can make it much easier to describe and build program analysis and transformation tools. For example, it can be used for determining loop bounds after loop interchange [AI91], and we have made extensive use of it in work that considers loop transformations in a uniform manner <ref> [Pug91] </ref>. 11 Acknowledgements Thanks to everyone who gave me feedback on this work, especially Michael Wolfe and the anonymous referee who provided detailed comments, as well as to my research group (Dave Wonnacott, Udayan Borkar and Wayne Kelly).
Reference: [Sho81] <author> R. Shostak. </author> <title> Deciding linear inequalities by computing loop residues. </title> <journal> Journal of the ACM, </journal> <volume> 28(4) </volume> <pages> 769-779, </pages> <month> October </month> <year> 1981. </year>
Reference-contexts: They found [MHL91] that this test could be applied in over 1/4 of the unique cases encountered. The "Loop Residue" algorithm <ref> [Sho81] </ref> can be applied in just those cases where each constraint is of the form x i x j + c, x i c, or c x i . In a set of constraints with this property, Fourier-Motzkin variable elimination is exact and preserves this property.
Reference: [Tri85] <author> R. Triolet. </author> <title> Interprocedural analysis for program restructuring with Parafrase. CSRD Rpt. </title> <type> 538, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> December </month> <year> 1985. </year> <month> 17 </month>
Reference-contexts: Alternatively, at compile time we could ask the user if the predicate is true. 5.3 Summarizing Array References In interprocedural analysis, we need to characterize the portions of an array that may be affected by a procedure call <ref> [Tri85, BK89, HK90, IJT91] </ref>. We can use the Omega test to obtain an accurate summary of the locations of an array that might be affected by a single assignment statement. <p> The Constraint-Matrix test can fail to terminate and it is not clear how efficiently it works in practice. Lu and Chen describe [LC90] an integer programming algorithm for dependence analysis. However, their method appears prohibitively expensive for use in a production compiler. Triolet <ref> [Tri85] </ref> used Fourier-Motzkin techniques for representing affected array regions in interprocedural analysis. Triolet found Fourier-Motzkin techniques to be expensive (22 to 28 times longer than using simpler methods for representing affected array regions). Several implementations of Fourier-Motzkin variable elimination have been described for use in dependence analysis.
Reference: [Wal88] <author> D. Wallace. </author> <title> Dependence of multi-dimensional array references. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: any combination of the Single Variable Per Constraint test, the Acyclic test, the Loop Residue test and the Delta test, we expect that it should be able to solve more problems exactly and efficiently than any one of them alone. 8 Related work on Exact Dependence Analysis The Constraint-Matrix test <ref> [Wal88] </ref> makes use of the simplex algorithm modified for integer programming. The Constraint-Matrix test can fail to terminate and it is not clear how efficiently it works in practice. Lu and Chen describe [LC90] an integer programming algorithm for dependence analysis.
Reference: [Wol82] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: Dependence analysis is often structured as a decision problem: tests simply answer yes or no. Compilers and other program restructuring tools need to know the data dependence direction vector <ref> [Wol82] </ref> and data dependence distance vector [KMC72, Mur71] that describes the relation between the iterations in which the conflicting reads/writes occur. The data dependence distance vector describes the differences between the values of the common loop variables between the first and second access to the same array element. <p> We describe some that have occurred to us. 5.1 Dependence direction and distance vectors One problem with some dependence analysis methods is that they are only "yes/no" decision methods. In compilers and other program structuring tools, we need to know the data dependence direction vector <ref> [Wol82] </ref> and data dependence distance vector [KMC72, Mur71] describing the relation between the iterations in which the conflicting reads/writes occur. One way to determine dependence direction vectors is to make 3 L calls to a decision procedure (where L is the number of loops surrounding both references).
Reference: [Wol89] <author> Michael Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: Once we also verify that no location is written more than once, we know that the writes can be done in any order. for i = 1 to 100 do A [i, j+1] = A [100,j] There has been extensive study of methods for deciding array data dependences <ref> [All83, BC86, AK87, Ban88, Wol89, LYZ89, LY90, GKT91, MHL91] </ref>. Much of this work has focused on approximate methods 1 that are guaranteed to be fast but only compute exact results in certain (commonly occurring) special cases.
Reference: [Wol91] <author> Michael Wolfe. </author> <title> The tiny loop restructuring research tool. </title> <booktitle> In Proc of 1991 International Conference on Parallel Processing, </booktitle> <address> pages II-46 II-53, </address> <year> 1991. </year>
Reference-contexts: This use of integer programming and projection to perform this is described by [AI91]. 6 Performance We have implemented the Omega test in Wolfe's tiny tool <ref> [Wol91] </ref>. We handle min and max expressions in loop bounds and symbolic constants, and compute exact sets of direction vectors (as opposed to the compressed direction vectors normally generated by tiny). <p> Files available include a stand-alone version of the Omega test and a version of Wolfe's tiny tool <ref> [Wol91] </ref> extended to use the Omega test. 10 Conclusions Conservative dependence analysis methods may be efficacious for the demands of vectorizing compilers. Transforming programs so as to make efficient use of massively parallel SIMD computers is a much more demanding task.
Reference: [WT92] <author> M. J. Wolfe and C. Tseng. </author> <title> The Power test for data dependence. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(5) </volume> <pages> 591-601, </pages> <month> September </month> <year> 1992. </year> <month> 18 </month>
Reference-contexts: real and dark shadow differ only in their constant terms, we can share much of the work in adding these constraints. 7 3 Nonlinear subscripts Integer programming dependence analysis methods allow us to properly handle symbolic constants [LT88, HP90] and some types of min and max functions in loop bounds <ref> [WT92] </ref> and conditional assignments [LC90]. <p> Triolet found Fourier-Motzkin techniques to be expensive (22 to 28 times longer than using simpler methods for representing affected array regions). Several implementations of Fourier-Motzkin variable elimination have been described for use in dependence analysis. The Power test described by Wolfe and Tseng <ref> [WT92] </ref> combines the Banerjee's Generalized GCD test, constraint tightening, and Fourier-Motzkin variable elimination. They take no special action when performing an inexact projection except to flag the result as possibly being conservative. <p> They use back substitution to determine a sample solution. If the sample solution is not integral, they suggest the use of branch and bound methods to verify or disprove the existence of integer solutions (they have not found the need to implement this thus far). Both Wolfe and Tseng <ref> [WT92] </ref> and May-dan, Hennessy and Lam [MHL91] suggest that due to the expense of Fourier-Motzkin variable elimination, simpler tests should be used instead in situations where they are known to be accurate.
References-found: 27

