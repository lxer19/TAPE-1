URL: http://www.cs.brown.edu/research/graphics/research/pub/papers/IntSymp.ps
Refering-URL: http://www.cs.brown.edu/research/graphics/research/pub/
Root-URL: http://www.cs.brown.edu
Title: Resolving Occlusion in Augmented Reality  
Author: Matthias M. Wloka and Brian G. Anderson 
Keyword: real-time, stereo matching, occlusion, augmented reality, interaction, approximation, dynamic environments  
Affiliation: Science and Technology Center for Computer Graphics and Scientific Visualization, Brown University Site  
Abstract: We present a video see-through augmented reality system capable of resolving occlusion between real and computer-generated objects. The heart of our system is a new algorithm that assigns depth values to each pixel in a pair of stereo video images in near-real-time. The algorithm belongs to the class of stereo matching algorithms and thus works in fully dynamic environments. We describe our system in general and the stereo matching algorithm in particular. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arthur, Kevin. </author> <note> Private Communications (August 1994). </note>
Reference-contexts: Preliminary results in [10] indicate process times of several minutes per depth map on an high-end workstation <ref> [1] </ref>. In contrast, we claim sub-second performance for depth maps of similar resolution, although our depth maps are not as accurate.
Reference: [2] <author> Azuma, Ronald and Gary Bishop. </author> <title> Improving Static and Dynamic Registration in an Optical See-Through HMD. </title> <booktitle> Proceedings of SIGGRAPH '94 (Orlando, </booktitle> <address> Florida, </address> <month> July 24-29, </month> <year> 1994). </year> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, 1994, ACM SIGGRAPH, </booktitle> <address> New York, </address> <year> 1994, </year> <pages> pp. 197-204. </pages>
Reference-contexts: 1 Introduction Augmented reality systems enhance the user's vision with computer-generated imagery. To make such systems and their applications effective, the synthetic or virtual imagery needs to blend convincingly with the real images. Towards this goal, researchers study such areas as minimizing object registration errors <ref> [2] </ref> and overall system lag [2] [17] so as to increase the realness of virtual objects. Since occlusion provides a significant visual cue to the human perceptual system when displaying data in three dimensions, proper occlusion resolution between real and virtual objects is highly desirable in augmented reality systems. <p> 1 Introduction Augmented reality systems enhance the user's vision with computer-generated imagery. To make such systems and their applications effective, the synthetic or virtual imagery needs to blend convincingly with the real images. Towards this goal, researchers study such areas as minimizing object registration errors <ref> [2] </ref> and overall system lag [2] [17] so as to increase the realness of virtual objects. Since occlusion provides a significant visual cue to the human perceptual system when displaying data in three dimensions, proper occlusion resolution between real and virtual objects is highly desirable in augmented reality systems.
Reference: [3] <author> Bajura, Michael, Henry Fuchs, and Ryutarou Ohbuchi. </author> <title> Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery within the Patient. </title> <booktitle> Proceedings of SIGGRAPH '92 (Chicago, </booktitle> <address> Illinois, </address> <month> July 26-31, </month> <year> 1992). </year> <booktitle> In Computer Graphics 26, </booktitle> <month> 2 (July </month> <year> 1992), </year> <pages> 203-210. </pages>
Reference-contexts: Several extensions, described in Section 5, make the basic algorithm faster and more robust. Finally, in Section 6 we discuss drawbacks of the algorithm and propose possible future work. 2 Related Work While several other augmented reality systems are described in the literature <ref> [3] </ref> [7] [9], none of these systems addresses the occlusion problem. We know of only one augmented reality system other than our own that attempts to correct this deficiency [10].
Reference: [4] <author> Bajura, Mike and Ulrich Neumann. </author> <title> An Improved Model for Augmented Reality Systems. </title> <type> Technical Report TR-94-022, </type> <institution> University of North Carolina at Chapel Hill, Department of Computer Science, Chapel Hill, NC, </institution> <year> 1994. </year>
Reference-contexts: While we achieved alignment of 3 pixels manually by trial and error, less time-consuming options are available; for example, the images could be aligned in software <ref> [4] </ref> or by using calibrated off-the-shelf hardware [16]. The cameras continuously transmit gen-locked left/right video image pairs, such as shown in Figures 2 and 4, to the red and green inputs of a Sirius video card.
Reference: [5] <author> Barnard, Stephen T. and Martin A. Fischler. </author> <title> Computational Stereo. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(4) </volume> <pages> 553-572, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: Like Koch, we use a computer vision technique known as stereo matching to infer depth from stereo image pairs. Stereo matching is a well-established research area in the computer vision literature [8] <ref> [5] </ref>. Nonetheless, real-time algorithms for stereo matching are only a recent development. We believe that our near-real-time stereo matching algorithm is new. It is faster than other published near-real-time algorithms [13] [15], and is excelled only by algorithms running on custom-built hardware [15] [14] [11] (see Table 1).
Reference: [6] <author> Carlbom, Ingrid, William Freeman, Gudrun Klinker, Wil-iam E. Lorensen, Richard Szeliski, Demetri Terzopoulos, and Keith Waters. </author> <title> Computer Vision for Computer Graphics. </title> <booktitle> Course Notes of Course 03 of SIGGRAPH '94 (Orlando, </booktitle> <address> Florida, </address> <month> July 24-29, </month> <year> 1994). </year>
Reference-contexts: image and writes the resulting depth values into the left and right depth map. environments, it seems unnecessary to compute depth maps with the same resolution that objects are rendered. 6.2 Implications Our work is evidence for the continuing interaction between the research areas of computer vision and computer graphics <ref> [6] </ref>.
Reference: [7] <author> Caudell, Thomas P. and David W. Mizell. </author> <title> Augmented Reality: An Application of Heads-Up Display Technology to Manual Manufacturing Processes. </title> <booktitle> HICSS, </booktitle> <pages> pages 659-669, </pages> <year> 1992. </year>
Reference-contexts: Several extensions, described in Section 5, make the basic algorithm faster and more robust. Finally, in Section 6 we discuss drawbacks of the algorithm and propose possible future work. 2 Related Work While several other augmented reality systems are described in the literature [3] <ref> [7] </ref> [9], none of these systems addresses the occlusion problem. We know of only one augmented reality system other than our own that attempts to correct this deficiency [10].
Reference: [8] <author> Dhond, Umesh R. and J. K. Aggarwal. </author> <title> Structure from Stereo </title>
Reference-contexts: Like Koch, we use a computer vision technique known as stereo matching to infer depth from stereo image pairs. Stereo matching is a well-established research area in the computer vision literature <ref> [8] </ref> [5]. Nonetheless, real-time algorithms for stereo matching are only a recent development. We believe that our near-real-time stereo matching algorithm is new. It is faster than other published near-real-time algorithms [13] [15], and is excelled only by algorithms running on custom-built hardware [15] [14] [11] (see Table 1). <p> Once the relative image positions of a pair of matched points are established, triangulation is used to infer the distance of the matched points to the cameras <ref> [8] </ref>. Our algorithm is area-based, i.e., it attempts to match image areas to one another. It works in five phases. 4.1 Phase One In the first phase, we subsample the original video image. Currently, we operate at half the resolution of the video images.
References-found: 8

