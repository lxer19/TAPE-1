URL: http://www.mli.gmu.edu/papers/mli94-4.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Title: INFERENTIAL THEORY OF LEARNING: Developing Foundations for Multistrategy Learning  
Author: Ryszard S. Michalski 
Keyword: Key w o r d s learning theory, inference theory, multistrategy learning, deduction, induction, abduction, generalization, abstraction, prediction, analogy, knowledge transmutation.  
Address: ca 330 BC.  
Note: For every belief comes either through syllogism or from induction. Aristotle, Prior Analytics, Book II, Chapter 23  
Affiliation: George Mason University  (p.90)  
Abstract: The development of multistrategy learning systems should be based on a clear understanding of the roles and the applicability conditions of different learning strategies. To this end, this chapter introduces the Inferential Theory of Learning that provides a conceptual framework for explaining logical capabilities of learning strategies, i.e., their competence. Viewing learning as a process of modifying the learners knowledge by exploring the learners experience, the theory postulates that any such process can be described as a search in a knowledge space, triggered by the learners experience and guided by learning goals. The search operators are instantiations of knowledge transmutations, which are generic patterns of knowledge change. Transmutations may employ any basic type of inferencededuction, induction or analogy. Several fundamental knowledge transmutations are described in a novel and general way, such as generalization, abstraction, explanation and similization, and their counterparts, specialization, concretion, prediction and dissimilization, respectively. Generalization enlarges the reference set of a description (the set of entities that are being described). Abstraction reduces the amount of the detail about the reference set. Explanation generates premises that explain (or imply) the given properties of the reference set. Similization transfers knowledge from one reference set to a similar reference set. Using concepts of the theory, a multistrategy task-adaptive learning (MTL) methodology is outlined, and illustrated b y an example. MTL dynamically adapts strategies to the learning task, defined by the input information, learners background knowledge, and the learning goal. It aims at synergistically integrating a whole range of inferential learning strategies, such as empirical generalization, constructive induction, deductive generalization, explanation, prediction, abstraction, and similization. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Adler, M. J. and Gorman, W. (Eds.) </author> <title> The Great Ideas: A Synopicon of Great Books of the Western World, </title> <journal> Vol. </journal> <volume> 1, Ch. 39 (Induction), </volume> <pages> pp. 565-571, </pages> <publisher> Encyclopedia Britannica, Inc., </publisher> <year> 1987. </year>
Reference: <author> Aristotle, </author> <title> Posterior Analytics, </title> <booktitle> in The Works of Aristotle, </booktitle> <volume> Volume 1, </volume> <editor> R. M. Hutchins (Ed.), Encyclopedia Britannica, </editor> <publisher> Inc., </publisher> <year> 1987. </year>
Reference: <author> Bacon, F., Novum Organum, </author> <title> 1620 (in Great Books of the Western World, </title> <editor> R. M. Hutchins, Ed., </editor> <volume> vol. 30, </volume> <publisher> Encyclopedia Britannica, Inc., </publisher> <year> 1987). </year>
Reference: <author> Baroglio, C., Botta, M. and Saitta, L., </author> <title> WHY: A System that Learns Using Causal Models and Examples, in Machine Learning: A Multistrategy Approach, Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference: <author> Bergadano, F., Matwin, S., Michalski, R.S. and Zhang, J., </author> <title> Learning Two-tiered Descriptions of Flexible Concepts: The POSEIDON System, </title> <journal> Machine Learning, </journal> <volume> Vol. 8, </volume> <pages> pp. 5-43, </pages> <note> 1992 (originally published in Machine Learning and Inference Reports, No. </note> <institution> MLI-3, Center for Artificial Intelligence, George Mason University, </institution> <month> September </month> <year> 1990). </year>
Reference-contexts: Experiments have shown, however, that in situations where the input contains errors or noise, an inconsistent and/or incomplete hypothesis (with regard to the input) will often lead to a better overall predictive performance than a complete and consistent one <ref> (e.g., Bergadano et al., 1992) </ref>. In general, the plausibility of a hypothesis depends on the background knowledge of the learner.
Reference: <author> Birnbaum, L. and Collins, G., </author> <booktitle> Proceedings of the 8th International Conference on Machine Learning, </booktitle> <address> Chicago, </address> <month> June </month> <year> 1991. </year>
Reference: <author> Bloedorn, E. and Michalski, </author> <title> R.S., Data-Driven Constructive Induction, </title> <booktitle> Proceedings of the Tools for Artificial Intelligence Conference, </booktitle> <address> San Jose, CA, </address> <year> 1991. </year>
Reference: <author> Carbonell, J.G., Michalski R.S. and Mitchell, </author> <title> T.M., An Overview of Machine Learning, in Machine Learning: An Artificial Intelligence Approach, </title> <editor> Michalski, R.S., Carbonell, J.G. and Mitchell, T. M. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1983. </year>
Reference: <author> Cohen, L.J., </author> <title> The Implications of Induction, </title> <address> London, </address> <year> 1970. </year>
Reference: <author> Collins, A. and Michalski, </author> <title> R.S., The Logic of Plausible Reasoning: A Core Theory, </title> <journal> Cognitive Science, </journal> <volume> Vol. 13, </volume> <pages> pp. 1-49, </pages> <year> 1989. </year>
Reference-contexts: They also suggest some new types of transmutations, e.g., inductive specialization, analogical generalization, similization, and others. A number of ideas in the theory stem from the research on the core theory of human plausible reasoning <ref> (Collins and Michalski, 1989) </ref>. To provide an easy introduction and a general perspective on the subject, many results are presented in an informal fashion, using conceptual explanations and examples, rather formal definitions and proofs. Various details and a formalization of many ideas await further research. <p> The concept of mutual implication has been originally postulated in the theory of plausible reasoning <ref> (Collins and Michalski, 1989) </ref>, which was developed by analyzing protocols recording examples of human reasoning. Based on the above definition, one can say that abduction produces a plausible conclusion, if it traces backward a mutual implication in which b is sufficiently high. <p> In general, the plausibility of a hypothesis depends on the background knowledge of the learner. The core theory of plausible inference <ref> (Collins and Michalski, 1989) </ref> postulates that the plausibility depends on the structural aspects of the organization of human knowledge (Hieb and Michalski, 1992), and on various merit parameters. The utility criterion requires a hypothesis to be simple to express and easy to apply to the expected set of problems. <p> Therefore, to talk meaningfully about a similarity between entities, one needs to indicate, explicitly or implicitly, the relevant descriptors. To express this, we use the concept of the similarity in the context of a given set of descriptors <ref> (introduced by Collins and Michalski, 1989) </ref>. <p> For example, knowing that two plants are very different from the viewpoint of the climate in which they grow, and that one lives in a particular area, one may hypothesize that the second plant may not be growing in that area. More details on dissimilization transmutation are in <ref> (Collins and Michalski, 1989) </ref>. Summarizing, a similization transmutation, given some piece of knowledge, hypothesizes another piece of knowledge based on the assumption that if two entities are similar in terms of some properties (or transformations characterizing their relationship), then they may be similar in terms of other properties (or transformations). <p> This form of knowledge representation, called DIH (Dynamically Interlaced Hierarchies), allows the system to conduct different types of inference by modifying the location of the nodes connected by traces. This representation stems from the theory of human plausible reasoning proposed in <ref> (Collins and Michalski, 1989) </ref>. Details are described in (Hieb and Michalski, 1993). To give a very simple illustration of the underlying idea, consider a statement Roses grow in the 33 Summer.
Reference: <author> Console, L., Theseider, D. and Torasso, P., </author> <title> On the Relationship Between Abduction and Deduction, </title> <journal> Journal of Logic and Computation, </journal> <volume> Vol. 1, No. 5, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: One may point out that Peirce, who originally introduced the concept of abduction, did not have any measure of goodness of explanation and did restrict abduction to a reasoning that produces only causal or best explanations (Peirce, 1965). For a discussion on the relationship between abduction and deduction see <ref> (Console, Theseider and Torasso, 1991) </ref>. Some theoretical views on abduction are in (Zadrozny, 1991). For an analysis and development of casual reasoning in humans see (Schultz and Kestenbaum,1985). The proposed view of abduction extends usual characterizations of it.
Reference: <author> Danyluk, </author> <title> A.P., The Use of Explanations for Similarity-Based Learning, </title> <booktitle> Proceedings of IJCAI-87, </booktitle> <pages> pp. 274-276, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference: <author> Danyluk. </author> <title> A.P., Recent Results in the Use of Context for Learning New Rules, </title> <type> Technical Report No. </type> <institution> TR-98-066, Philips Laboratories, </institution> <year> 1989. </year>
Reference: <author> Danyluk, </author> <title> A.P., Gemini: An Integration of Analytical and Empirical Learning, in Machine Learning: A Multistrategy Approach, Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference: <author> De Raedt, L. and Bruynooghe, M., </author> <title> Interactive Theory Revision, in Machine Learning: A Multistrategy Approach, Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference: <author> Dietterich, T.G. and Flann, N.S., </author> <title> An Inductive Approach to Solving the Imperfect Theory Problem, </title> <booktitle> Proceedings of the 1988 Symposium on Explanation-Based Learning, </booktitle> <pages> pp. 42-46, </pages> <institution> Stanford University, </institution> <year> 1988. </year> <title> 39 Dietterich, T.G., Limitations on Inductive Learning, </title> <booktitle> Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <address> Ithaca, NY, </address> <pages> pp. 124-128, </pages> <year> 1989. </year>
Reference-contexts: Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM (Lebowitz, 1986), Odysseus (Wilkins, Clancey, and Buchanan, 1986), Prodigy (Minton et al., 1987), DISCIPLE (Kodratoff and Tecuci, 1987), Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM (Pazzani, 1988), IOE <ref> (Dietterich and Flann, 1988) </ref>, and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6). Most of these systems are concerned with integrating symbolic empirical induction with explanation-based learning. Some, like DISCIPLE, also include a simple method for analogical learning.
Reference: <author> Dietterich, T.G., </author> <title> Learning at the Knowledge Level," </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 3, </volume> <pages> pp. 287-316, </pages> <note> 1986 (Reprinted in J.W. </note> <editor> Shavlik and T.G. Dietterich (Eds.) </editor> <booktitle> Readings in Machine Learning, </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1990). </year>
Reference: <author> Fulk, M. </author> <title> and Case, </title> <editor> J. </editor> <booktitle> Proceedings of the 3rd Annual Workshop on Computational Learning Theory, </booktitle> <institution> University of Rochester, </institution> <address> N.Y., </address> <month> August 6-8, </month> <year> 1990. </year>
Reference: <author> Giordana, A., Saitta, L. and Roverso, D. </author> <title> Abstracting Concepts with Inverse Resolution, </title> <booktitle> Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. 142-146, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference: <author> Goldberg, D.E., </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: <author> Goodman, L.A. and Kruskal, </author> <title> W.H., Measures of Association for Cross Classifications, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference: <author> Grosof, B.N. and Russell, </author> <title> Declarative Bias for Structural Domains, </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <institution> Cornell Univeristy, </institution> <address> Ithaca, New York, </address> <publisher> Morgan Kaufmann Puboishers, Inc. </publisher> <year> 1989. </year>
Reference: <author> Hieb, M. and Michalski, </author> <title> R.S. A Knowledge Representation System Based on Dynamically Interlaced Hierarchies: Basic Ideas and Examples, Reports of Machine Learning and Inference Laboratory, </title> <institution> Center for Artificial Intelligence, George Mason University, </institution> <year> 1993. </year>
Reference-contexts: This form of knowledge representation, called DIH (Dynamically Interlaced Hierarchies), allows the system to conduct different types of inference by modifying the location of the nodes connected by traces. This representation stems from the theory of human plausible reasoning proposed in (Collins and Michalski, 1989). Details are described in <ref> (Hieb and Michalski, 1993) </ref>. To give a very simple illustration of the underlying idea, consider a statement Roses grow in the 33 Summer. <p> The strategies are presented as independent processes only in a conceptual sense. In the actual implementation of MTL, all strategies are to be performed within one integrated inference system. The system specializes to any specific strategy using the same general computational mechanism, based on Dynamic Interlaced Hierarchies <ref> (Hieb and Michalski, 1993) </ref>. In the Figure 6, the name obj (in small letters) denotes a variable; the name CUP1 (in capital letters) denotes a specific object.
Reference: <author> Hunter, L., </author> <title> Planning to Learn, </title> <booktitle> Proceedings of the Twelveth Annual Conference of the Cognitive Science Society , pp.26-34, </booktitle> <address> Hillsdale, NJ, </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1990. </year>
Reference-contexts: If a learning goal is complex, a learner needs to develop a plan specifying knowledge components to learn, and the order in which they should be learned <ref> (e.g., Hunter, 1990) </ref>. A domain-dependent goal calls for acquiring a specific piece of knowledge about the domain. A learner may pursue several goals simultaneously, and the goals may be conflicting. When they are conflicting, their relative importance controls the amount of effort that is extended to pursue any of them.
Reference: <editor> Kodratoff, Y.and Michalski, R.S. (Eds.) </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach vol. III, </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Transmutations that employ only conclusive deduction increase the amount of derived knowledge in the system. Such knowledge is a logical consequence of what the learner already knows. Learning that changes only the amount of derived knowledge in the systems is called analytic. <ref> (Michalski and Kodratoff, 1990) </ref>. Transmutations are not independent processes. An implementation of one complex transmutation may involve performing other transmutations. Thus, the theory views transmutations as types of knowledge change, and inferences as different ways in which these changes can be accomplished.
Reference: <editor> Kodratoff, Y., and Tecuci, G., DISCIPLE-1: </editor> <title> Interactive Apprentice System in Weak Theory Fields, </title> <booktitle> Proceedings of IJCAI-87, </booktitle> <pages> pp. 271-273, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM (Lebowitz, 1986), Odysseus (Wilkins, Clancey, and Buchanan, 1986), Prodigy (Minton et al., 1987), DISCIPLE <ref> (Kodratoff and Tecuci, 1987) </ref>, Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM (Pazzani, 1988), IOE (Dietterich and Flann, 1988), and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6). Most of these systems are concerned with integrating symbolic empirical induction with explanation-based learning.
Reference: <author> Laird, </author> <title> J.E., </title> <editor> (Ed.), </editor> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <institution> University of Michigan, </institution> <address> Ann Arbor, </address> <month> June 12-14, </month> <year> 1988. </year>
Reference: <author> Laird, J.E., Rosenbloom, P.S., and Newell A., </author> <title> Chunking in SOAR: the Anatomy of a General Learning Mechanism, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 11-46, </pages> <year> 1986. </year>
Reference-contexts: If such a rule is sufficiently general so that it is evoked sufficiently often, then storing it is cost-effective. Such a mechanism is related to chunking used in SOAR <ref> (Laird, Rosenbloom, and Newell, 1986) </ref>. If the input information (e.g., a rule supplied by a teacher) implies some part of BK, then an importance criterion is applied to it.
Reference: <author> Lebowitz, M., </author> <title> Integrated Learning: Controlling Explanation, </title> <journal> Cognitive Science, </journal> <volume> Vol. 10, No. </volume> <pages> 2 , pp. 219-240, </pages> <year> 1986. </year>
Reference-contexts: Human learning is intrinsically multistrategy, and research on multistrategy systems is of significant relevance to its understanding, and thus is important regardless of their practical applications. Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM <ref> (Lebowitz, 1986) </ref>, Odysseus (Wilkins, Clancey, and Buchanan, 1986), Prodigy (Minton et al., 1987), DISCIPLE (Kodratoff and Tecuci, 1987), Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM (Pazzani, 1988), IOE (Dietterich and Flann, 1988), and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6).
Reference: <author> Michalski, </author> <title> R.S., Theory and Methodology of Inductive Learning, Machine Learning: An Artificial Intelligence Approach, </title> <editor> R. S. Michalski, J. G. Carbonell, T. M. Mitchell (Eds.), </editor> <publisher> Tioga Publishing Co.(now Morgan Kaufmann), </publisher> <year> 1983. </year>
Reference-contexts: Also, to help the reader keep track with a large number of symbols and abbreviations, they were compiled into a list included in the Appendix. The chapter is a modified version of the paper (Michalski, 1993), and represents a significant extension or refinement of ideas described in earlier publications <ref> (Michalski, 1983, 1990a,b & 1991) </ref>. 2. BASIC TENETS OF THE THEORY Learning has been traditionally characterized as an improvement of the learners behavior due to experience. While this view is appealing due to its simplicity, it does not provide many clues about how to actually implement a learning system. <p> In the context of empirical inductive learning, the knowledge space is usually called a description space. Let us consider a few examples of transmutations. An inductive generalization takes descriptions of a subset of objects (e.g., concept examples), and hypothesizes a description of a superset. As shown in <ref> (Michalski, 1983) </ref>, such a process can be characterized as an application of inductive 7 generalization rules. A deductive generalization derives a description of a superset of a given fact by employing background domain knowledge and deductive inference rules. <p> In symbolic learning systems, knowledge transmutations are usually (but not always) implemented in a more or less explicit way, and executed in steps that are conceptually comprehensible. For example, the INDUCE learning system performs inductive generalization according to well-defined generalization rules, which represent conceptually understandable units of knowledge transformation <ref> (e.g., Michalski, 1983) </ref>. In subsymbolic systems (e.g., neural networks) transmutations are performed implicitly, in steps dictated by the underlying computational mechanism. These steps may not correspond to any conceptually simple operations. <p> The plausibility expresses a desire to find a true hypothesis. Because the problem is logically underconstrained, the truth of a hypothesis cannot be guaranteed in principle. To satisfy equation (4), a hypothesis has to be complete and consistent with regard to the input facts <ref> (Michalski, 1983) </ref>. Experiments have shown, however, that in situations where the input contains errors or noise, an inconsistent and/or incomplete hypothesis (with regard to the input) will often lead to a better overall predictive performance than a complete and consistent one (e.g., Bergadano et al., 1992). <p> A simple form of such a description is a list (or a conjunction) of all properties shared by the entities of the given set. The opposite transmutation is discrimination that determines a description that discriminates the given set of entities from another set of entities <ref> (Michalski, 1983) </ref>. 8. Derivations: Reformulation/intermediate transmutations/randomization Derivations are transmutations that derive one piece of knowledge from another piece of knowledge (based on some dependency between them), but do not fall into the special categories described above.
Reference: <author> Michalski, </author> <title> R.S., Learning Flexible Concepts: Fundamental Ideas and a Method Based on Two-tiered Representation, </title> <booktitle> in Machine Learning: An Artificial Intelligence Approach Volume III, Y. </booktitle>
Reference: <editor> Kodratoff and R.S. Michalski (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Transmutations that employ only conclusive deduction increase the amount of derived knowledge in the system. Such knowledge is a logical consequence of what the learner already knows. Learning that changes only the amount of derived knowledge in the systems is called analytic. <ref> (Michalski and Kodratoff, 1990) </ref>. Transmutations are not independent processes. An implementation of one complex transmutation may involve performing other transmutations. Thus, the theory views transmutations as types of knowledge change, and inferences as different ways in which these changes can be accomplished.
Reference: <author> Michalski, </author> <title> R.S., Toward a Unified Theory of Learning: Multistrategy Task-adaptive Learning, Reports of Machine Learning and Inference Laboratory MLI-90-1, </title> <month> January </month> <year> 1990a. </year> <title> 40 Michalski, R.S., A Methodological Framework for Multistrategy Task-adaptive Learning, </title> <booktitle> Proceedings of the Fifth International Symposium on Methodologies for Intelligent Systems, </booktitle> <address> Knoxville, </address> <publisher> (Elsevier Pub.), </publisher> <month> October </month> <year> 1990b. </year>
Reference: <author> Michalski, </author> <title> R.S., Toward a Unified Theory of Learning: An Outline of Basic Ideas, </title> <booktitle> Proceedings of the First World Conference on the Fundamentals of Artificial Intelligence, M. </booktitle> <address> De Glas and D. </address>
Reference: <editor> Gabbay (Eds.), </editor> <address> Paris, France, </address> <month> July 1-5, </month> <year> 1991. </year>
Reference: <author> Michalski, </author> <title> R.S., Inferential Theory of Learning as a Conceptual Framework for Multistrategy Learning, </title> <journal> Machine Learning Journal (Special Issue on Multistrategy Learning), </journal> <year> 1993. </year>
Reference-contexts: Also, to help the reader keep track with a large number of symbols and abbreviations, they were compiled into a list included in the Appendix. The chapter is a modified version of the paper <ref> (Michalski, 1993) </ref>, and represents a significant extension or refinement of ideas described in earlier publications (Michalski, 1983, 1990a,b & 1991). 2. BASIC TENETS OF THE THEORY Learning has been traditionally characterized as an improvement of the learners behavior due to experience. <p> This form of knowledge representation, called DIH (Dynamically Interlaced Hierarchies), allows the system to conduct different types of inference by modifying the location of the nodes connected by traces. This representation stems from the theory of human plausible reasoning proposed in (Collins and Michalski, 1989). Details are described in <ref> (Hieb and Michalski, 1993) </ref>. To give a very simple illustration of the underlying idea, consider a statement Roses grow in the 33 Summer. <p> The strategies are presented as independent processes only in a conceptual sense. In the actual implementation of MTL, all strategies are to be performed within one integrated inference system. The system specializes to any specific strategy using the same general computational mechanism, based on Dynamic Interlaced Hierarchies <ref> (Hieb and Michalski, 1993) </ref>. In the Figure 6, the name obj (in small letters) denotes a variable; the name CUP1 (in capital letters) denotes a specific object.
Reference: <author> Michalski, R.S. and Kodratoff, Y., </author> <title> Research in Machine Learning: Recent Progress, Classification of Methods and Future Directions, </title> <booktitle> in Machine Learning: An Artificial Intelligence Approach Vol. III, </booktitle> <editor> Y. Kodratoff and R.S. Michalski (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: This requirement does not, however, necessarily produce the most desirable concept descriptions. Because concept descriptions have to be expressed as a single decision tree, some unnecessary conditions may be introduced in the concept representation <ref> (Michalski, 1990) </ref>. There are three generally desirable characteristics of a hypothesis: plausibility, utility, and generality. The plausibility expresses a desire to find a true hypothesis. Because the problem is logically underconstrained, the truth of a hypothesis cannot be guaranteed in principle. <p> Transmutations that employ only conclusive deduction increase the amount of derived knowledge in the system. Such knowledge is a logical consequence of what the learner already knows. Learning that changes only the amount of derived knowledge in the systems is called analytic. <ref> (Michalski and Kodratoff, 1990) </ref>. Transmutations are not independent processes. An implementation of one complex transmutation may involve performing other transmutations. Thus, the theory views transmutations as types of knowledge change, and inferences as different ways in which these changes can be accomplished.
Reference: <author> Minton, S., </author> <title> Quantitative Results Concerning the Utility of Explanation-Based Learning, </title> <booktitle> Proceedings of AAAI-88, </booktitle> <pages> pp. 564-569, </pages> <address> Saint Paul, MN, </address> <year> 1988. </year>
Reference-contexts: If the new knowledge passes an importance criterion, it is stored for future use. This mechanism is related to the ideas on the utility of explanation based-learning <ref> (Minton, 1988) </ref>. If the input represents a useful result of a problem solving activity, e.g., given state x, it was found that a useful action is y. If such a rule is sufficiently general so that it is evoked sufficiently often, then storing it is cost-effective.
Reference: <author> Minton, S., Carbonell, J.G., Etzioni, O., Knoblock, </author> <title> C.A. and Kuokka, D.R., Acquiring Effective Search Control Rules: Explanation-Based Learning in the PRODIGY System, </title> <booktitle> Proceedings of the 4th International Machine Learning Workshop, </booktitle> <pages> pp. 122-133, </pages> <institution> University of California, Irvine, </institution> <year> 1987. </year>
Reference-contexts: Human learning is intrinsically multistrategy, and research on multistrategy systems is of significant relevance to its understanding, and thus is important regardless of their practical applications. Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM (Lebowitz, 1986), Odysseus (Wilkins, Clancey, and Buchanan, 1986), Prodigy <ref> (Minton et al., 1987) </ref>, DISCIPLE (Kodratoff and Tecuci, 1987), Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM (Pazzani, 1988), IOE (Dietterich and Flann, 1988), and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6). Most of these systems are concerned with integrating symbolic empirical induction with explanation-based learning.
Reference: <author> Mitchell, T.M., Keller,T. and Kedar-Cabelli, S., </author> <title> Explanation-Based Generalization: A Unifying View, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 1, </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: As shown in (Michalski, 1983), such a process can be characterized as an application of inductive 7 generalization rules. A deductive generalization derives a description of a superset of a given fact by employing background domain knowledge and deductive inference rules. A form of deductive generalization is explanation-based generalization <ref> (Mitchell, Keller and Kedar-Cabelli, 1986) </ref> that takes a concept example from an operational description space, a concept description from an abstract description space, and deduces a generalized concept description by employing domain knowledge linking the abstract and operational description spaces. <p> AN ILLUSTRATION OF MTL To illustrate the above-sketched ideas in terms of the inferential theory of learning, let us use a well-known example of learning the concept of a cup <ref> (Mitchell, Keller and Kedar-Cabelli, 1986) </ref>. The example is deliberately oversimplified, so that major ideas can be presented in a very simple way. (defined by a combination of the input, BK and the desired output).
Reference: <author> Mooney, R.J. and Ourston, D., </author> <title> A Multistrategy Approach to Theory Refinement, in Machine Learning: A Multistrategy Approach Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference: <author> Muggleton, S., </author> <title> A Strategy for Constructing New Predicates in First-Order Logic, </title> <booktitle> Proceedings of EWSL-88, Glasgow, Scotland, </booktitle> <pages> pp. 123-130, </pages> <year> 1988. </year> <title> Newell, The Knowledge Level, </title> <journal> AI Magazine, No.2, </journal> <pages> 1-20, </pages> <year> 1981. </year>
Reference: <author> Pazzani, M.J., </author> <title> Integrating Explanation-Based and Empirical Learning Methods in OCCAM, </title> <booktitle> Proceedings of EWSL-88, </booktitle> <pages> pp. 147-166, </pages> <address> Glasgow, Scotland, </address> <year> 1988. </year>
Reference-contexts: Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM (Lebowitz, 1986), Odysseus (Wilkins, Clancey, and Buchanan, 1986), Prodigy (Minton et al., 1987), DISCIPLE (Kodratoff and Tecuci, 1987), Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM <ref> (Pazzani, 1988) </ref>, IOE (Dietterich and Flann, 1988), and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6). Most of these systems are concerned with integrating symbolic empirical induction with explanation-based learning. Some, like DISCIPLE, also include a simple method for analogical learning.
Reference: <author> Peirce, C.S., </author> <title> Elements of Logic , in Collected papers of Charles Sanders Peirce (1839-1914), </title> <editor> Ch. Hartshorne and P. Weiss (Eds. </editor> ), <publisher> The Belknap Press Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1965. </year>
Reference: <author> Pearl J., </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: <author> Piatetsky-Shapiro, G., </author> <title> Probabilistic Data Dependencies, </title> <booktitle> Proceedings of the ML92 Workshop on Machine Discovery, </booktitle> <editor> J.M. Zytkow (Ed.), Aberdeen, </editor> <address> Scotland, </address> <month> July 4, </month> <year> 1992. </year>
Reference: <author> Plaisted, D., </author> <title> Theorem Proving with Abstraction, </title> <journal> Artificial Intelligence , Vol. </journal> <volume> 16, </volume> <pages> 47-108, </pages> <year> 1981. </year>
Reference: <author> Polya, G., </author> <title> Mathematics and Plausible Reasoning, Vol. I and II, </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1968. </year> <note> 41 Poole, </note> <author> D., </author> <title> Explanation and Prediction: An Architecture for Default and Abductive Reasoning, </title> <journal> Computational Intelligence, </journal> <volume> No. 5, </volume> <pages> pp. 97-110, </pages> <year> 1989. </year>
Reference: <author> Popper, K.R., </author> <title> Objective Knowledge: An Evolutionary Approach, </title> <publisher> Oxford at the Clarendon Press, </publisher> <year> 1972. </year>
Reference: <editor> Porter, B.W. and Mooney, R.J. (Eds. </editor> ), <booktitle> Proceedings of the 7th International Machine Learning Conference, </booktitle> <address> Austin, TX, </address> <year> 1990. </year>
Reference: <author> Ram, A., </author> <title> A Theory of Questions and Question Asking, </title> <journal> The Journal of the Learning Sciences, Vol.1, </journal> <volume> No. 3 and 4, pp.273-318, </volume> <year> 1991. </year>
Reference: <author> Ram, A. and Hunter, L., </author> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning, </title> <journal> Applied Intelligence , No. </journal> <volume> 2, </volume> <pages> pp. 47-73, </pages> <year> 1992. </year>
Reference: <author> Rivest, R., Haussler D. and Warmuth, M., </author> <booktitle> Proceedings of the Second Annual Workshop on Computational Learning Theory, </booktitle> <institution> University of Santa Cruz, </institution> <month> July 31-August 2, </month> <year> 1989. </year>
Reference: <author> Russell, S., </author> <title> The Use of Knowledge in Analogy and Induction, </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: <editor> Schafer, D., (Ed.), </editor> <booktitle> Proceedings. of the 3rd Intern. Conference on Genetic Algorithms, </booktitle> <institution> George Mason University, </institution> <month> June 4-7, </month> <year> 1989. </year>
Reference: <author> Schultz T.R. and Kestenbaum N. R., </author> <title> Causal Reasoning in Children, Annals of Child Development, </title> <editor> G.J. Whitehurst (Ed.), </editor> <volume> vol. 2, </volume> <pages> pp. 195-249, </pages> <publisher> JAI Press Inc., </publisher> <year> 1985. </year>
Reference-contexts: For a discussion on the relationship between abduction and deduction see (Console, Theseider and Torasso, 1991). Some theoretical views on abduction are in (Zadrozny, 1991). For an analysis and development of casual reasoning in humans see <ref> (Schultz and Kestenbaum,1985) </ref>. The proposed view of abduction extends usual characterizations of it. Abduction is viewed here as a form of knowledge-intensive induction that hypothesizes explanatory knowledge about a given reference set. This process involves tracing backward domain-dependent implications.
Reference: <editor> Segre, A. M. (Ed.), </editor> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <institution> Cornell University, </institution> <address> Ithaca, New York, June 26-27, </address> <publisher> Morgan Kaufman Publishers, </publisher> <year> 1989. </year>
Reference: <author> Sleeman, D. and Edwards, P., </author> <booktitle> Proceedings of the Ninth International Workshop, Univeristy of Aberdeen, </booktitle> <address> G.B., July 1-3, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year>
Reference: <author> Stepp, R.S. and Michalski, </author> <title> R.S., How to Structure Structured Objects, </title> <booktitle> Proceedings of the International Machine Learning Workshop, </booktitle> <institution> University of Illinois Allerton House, </institution> <address> Urbana, </address> <pages> pp. 156-160, </pages> <month> June 22-24, l983. </month>
Reference: <author> Tecuci, G. and Michalski, </author> <title> R.S., A Method for Multistrategy Task-adaptive Learning Based on Plausible Justifications, </title> <editor> in Birnbaum, L., and Collins, G. (Eds. </editor> ) <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <address> San Mateo, CA, </address> <publisher> Morgan Kaufmann, </publisher> <year> 1991a. </year>
Reference: <editor> Tecuci G. and Michalski R.S., </editor> <title> Input Understanding as a Basis for Multistrategy Task-adaptive Learning, </title> <booktitle> Proceedings of the 6th International Symposium on Methodologies for Intelligent Systems, </booktitle> <editor> Z. Ras and M. Zemankova (Eds. </editor> ), <booktitle> Lecture Notes on Artificial Intelligence, </booktitle> <publisher> Springer Verlag, </publisher> <year> 1991b. </year>
Reference: <editor> Tecuci, G. </editor> <title> Plausible Justification Trees: A Framework for Deep and Dynamic Integration of Learning Strategies, </title> <journal> Machine Learning Journal (Special Issue on Multistrategy Learning), </journal> <year> 1993. </year>
Reference: <editor> Touretzky, D., Hinton, G. and Sejnowski, T. (Eds.), </editor> <booktitle> Proceedings of the 1988 Connectionist Models Summer School, </booktitle> <institution> Carnegie Mellon University, </institution> <month> June 17-26, </month> <year> 1988. </year>
Reference: <author> Utgoff, P., </author> <title> Shift of Bias for Inductive Concept Learning, in Machine Learning: An Artificial Intelligence Approach Vol. II, </title> <editor> Michalski, R.S., Carbonell, J.G., and Mitchell, T. M. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1986. </year> <note> 42 Warmuth, </note> <editor> M. and Valiant, L. (Eds.) </editor> <booktitle> Proceedings of the 4rd Annual Workshop on Computational Learning Theory, </booktitle> <address> Santa Cruz, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference: <author> Whewell, W., </author> <title> History of the Inductive Sciences, 3 vols., </title> <booktitle> 3rd edition, </booktitle> <address> London, </address> <month> 1857. </month>
Reference: <author> Whitehall, B. L., </author> <title> Knowledge-based learning: Integration of Deductive and Inductive Learning for Knowledge Base Completion, </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, University of Illinois, </institution> <year> 1990. </year>
Reference: <author> Whitehall, B.L. and Lu, S. C-Y., </author> <title> Theory Completion using Knowledge-Based Learning, in Machine Learning: A Multistrategy Approach, Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference: <author> Wilkins, D.C., Clancey, W.J. and Buchanan, B.G., </author> <title> An Overview of the Odysseus Learning Apprentice, </title> <publisher> Kluwer Academic Press, </publisher> <address> New York, NY, </address> <year> 1986. </year>
Reference-contexts: Human learning is intrinsically multistrategy, and research on multistrategy systems is of significant relevance to its understanding, and thus is important regardless of their practical applications. Among early well-known multistrategy systems (often called integrated learning systems) are UNIMEM (Lebowitz, 1986), Odysseus <ref> (Wilkins, Clancey, and Buchanan, 1986) </ref>, Prodigy (Minton et al., 1987), DISCIPLE (Kodratoff and Tecuci, 1987), Gemini (Danyluk, 1987, 1989; also 1993chapter 7 in this book), OCCAM (Pazzani, 1988), IOE (Dietterich and Flann, 1988), and KBL (Whitehall, 1990; Whitehall and Lu, 1993chapter 6).
Reference: <author> Wnek, J. and Michalski, </author> <title> R.S., Hypothesis-Driven Constructive Induction in AQl7: A Method and Experiments, </title> <booktitle> Proc. of the IJCAI-9l Workshop on Evaluating and Changing Representation in Machine Learning, </booktitle> <editor> K. Morik, F. Bergadano, W. </editor> <booktitle> Buntine (Eds. </booktitle> ), <pages> pp. 13-22, </pages> <address> Sydney, Australia, </address> <month> August 24-30, </month> <year> 1991a. </year>
Reference: <author> Wnek, J. and Michalski, </author> <title> R.S.,An Experimental Comparison of Symbolic and Subsymbolic Learning Paradigms: Phase I - Learning Logicstyle Concepts, </title> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning, </booktitle> <editor> R.S. Michalski and G. Tecuci (Eds. </editor> ), <booktitle> GMU Center for Artificial Intelligence, </booktitle> <address> Harpers Ferry, </address> <month> Nov. </month> <pages> 7-9, </pages> <year> 1991b. </year>
Reference-contexts: Operations on concepts are visualized by changes in the configurations of the corresponding sets of cells. Examples of a diagrammatic visualization of inductive generalizations performed by a neural network, genetic algorithm, and two different symbolic learning systems are presented by Wnek and Michalski <ref> (1991b, Wnek and Michalski, 1993-chapter 18) </ref>. As indicated above, a learning process depends on the input information (input), background knowledge (BK), and the learning goal. These three components constitute a learning task.
Reference: <author> Wnek, J. and Michalski, </author> <title> R.S., COMPARING SYMBOLIC AND SUBSYMBOLIC LEARNING: Three Studies, in Machine Learning: A Multistrategy Approach, Volume IV, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1992. </year>
Reference: <author> Zadrozny, W. </author> <title> The Logic of Abduction (Preliminary Report), </title> <booktitle> First International Workshop on Principles of Diagnosis, </booktitle> <address> Stanford, CA., </address> <year> 1990. </year> <note> 43 APPENDIX </note>
References-found: 72

