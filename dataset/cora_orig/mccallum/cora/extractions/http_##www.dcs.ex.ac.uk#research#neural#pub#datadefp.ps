URL: http://www.dcs.ex.ac.uk/research/neural/pub/datadefp.ps
Refering-URL: http://www.dcs.ex.ac.uk/research/neural/pub/pub.htm
Root-URL: http://www.dcs.ex.ac.uk
Email: derek@dcs.exeter.ac.uk  
Title: Data-defined Problems and Multiversion Neural-net Systems  
Author: Derek Partridge William B Yates 
Date: April 30, 1996  
Address: Exeter EX4 4PT, UK  
Affiliation: Department of Computer Science University of Exeter  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> Frey, P. W. and Slate, D. J. </author> <year> 1991. </year> <title> Letter recognition using Holland-style adaptive classifiers, </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 161-182. </pages>
Reference-contexts: In order to provide a source of concrete illustrations for the theoretical framework to be developed, a specific example problem will be introduced. 4 Letter recognition: an example application A difficult data-defined problem is that of letter recognition as presented by Frey and Slate <ref> (1991) </ref>. The data that defines this problem consists of 20,000 unique letter images composed of the letters A to Z from 20 different fonts (publically available aha@ics.uci.edu).
Reference: 2. <author> Holland, J. H., Holyoak, K. J., Nisbett, R. E. and Thagard, P. R. </author> <year> 1986. </year> <title> Induction: Processes of inference and discovery, </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: 3. <author> Krzanowski, W. J. and Partridge, D. </author> <year> 1995. </year> <title> Software diversity: practical statistics for its measurement and exploitation, Res. </title> <type> Rep. 324, </type> <institution> Dept. of Computer Science, </institution> <note> University of Exeter (submitted to Information & Software Technology). </note>
Reference: 4. <author> Littlewood, B. and Miller, D. R. </author> <year> 1986. </year> <title> A conceptual model of coincident failure in multiversion software engineering, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 15, </volume> <pages> 1596-1614. </pages>
Reference: 5. <author> Partridge, D. </author> <year> 1994. </year> <title> Engineering AI Software, </title> <publisher> Intellect Books: Oxford, UK or Ablex Pub. Corp.: </publisher> <address> NJ, USA. </address>
Reference: 6. <author> Partridge, D. </author> <year> 1995. </year> <title> On the difficulty of really considering a radical novelty, </title> <journal> Minds and Machines, </journal> <volume> 5, </volume> <pages> 391-410. 11 </pages>
Reference: 7. <author> Partridge, D. </author> <year> 1996. </year> <title> Network generalization differences quantified, </title> <booktitle> Neural Networks, </booktitle> <volume> 9, </volume> <pages> 263-271. </pages>
Reference: 8. <author> Partridge, D. and Yates, W. B. </author> <year> 1995. </year> <title> Letter recognition using neural networks: a comparative study, Res. </title> <type> Rep. 334, </type> <institution> Dept. of Computer Science, University of Exeter. </institution>
Reference: 9. <author> Partridge, D. and Yates, W. B. </author> <year> 1996. </year> <title> Engineering multiversion neural-net systems, </title> <journal> Neural Computation, </journal> <volume> 8, </volume> <pages> 869-893. </pages>
Reference-contexts: This latter feature means that we have the opportunity to systematically engineer high diversity levels into a multiversion neural-net system. We have developed diversity measures (Krzanowski and Partridge, 1995), explored the sensitivity of important features of the initial conditions to version-set diversity <ref> (Partridge, 1996) </ref>, and developed systematic strategies for generating highly diverse version sets (Partridge and Yates, in press). <p> We employ a technique of `over produce and choose' (Yates and Partridge, in press) in which we generate a `space' of trained versions and then choose a maximally diverse subset as the final multiversion system. As a result of training networks, both MLPs and Radial Basis Function <ref> (RBF, see Partridge and Yates, 1996, for details) </ref> nets, under a variety of initial conditions, we obtained a `space' of 132 (68 MLPs and 65 RBFs) alternative trained versions for the OCR problem | a version space. <p> Using a procedure designed to select a subset of versions from this space under the constraint that some version-set measure should be maximized, three version sets, each containing nine networks, were selected. This selection procedure, known as the pick heuristic <ref> (Partridge and Yates, 1996) </ref>, has been extended to favour selection of diverse versions that also succeed on `difficult' inputs. "The difficulty in processing input x" (the (x) term in Littlewood and Miller's (1986) model, p. 1597) is derived from the number of versions, in the complete version space, that fail to <p> The three systems had 6 nets in common. OD CF D DF D aver max min maj. vote pick CF D 0.890 (0.875) 0.836 (0.814) 0.948 (0.942) 79.81% 88.62% 33.77% 85.87% pick DF D 0.842 (0.829) 0.730 (0.709) 0.972 <ref> (0.969) </ref> 69.92% 88.62% 33.77% 81.57% pick OD 0.887 (0.874) 0.815 (0.794) 0.966 (0.961) 66.95% 88.62% 36.68% 84.47% Table 1: test results on the 9-version systems selected Each diversity measure has two values recorded: diversity with respect to the `picking' set of 16,000 items, and in parentheses diversity with respect to the <p> OD CF D DF D aver max min maj. vote pick CF D 0.890 (0.875) 0.836 (0.814) 0.948 (0.942) 79.81% 88.62% 33.77% 85.87% pick DF D 0.842 (0.829) 0.730 (0.709) 0.972 (0.969) 69.92% 88.62% 33.77% 81.57% pick OD 0.887 (0.874) 0.815 (0.794) 0.966 <ref> (0.961) </ref> 66.95% 88.62% 36.68% 84.47% Table 1: test results on the 9-version systems selected Each diversity measure has two values recorded: diversity with respect to the `picking' set of 16,000 items, and in parentheses diversity with respect to the test set of 4,000 items.
Reference: 10. <author> Yates, W. B. and Partridge, D. </author> <title> (in press). Use of methodological diversity to improve neural network generalisation, </title> <booktitle> Neural Computing & Applications. </booktitle>
Reference: 11. <author> Rumelhart, D. E. and McClelland, J. L. </author> <year> 1986. </year> <title> Parallel Distributed Processing, </title> <publisher> MIT Press: </publisher> <address> Cambridge, MA. </address> <note> 12 DN pick CF D 94.62% DN pick DF D 94.07% DN pick OD 94.55% Table 3: test results from learned priorities 13 </note>
References-found: 11

