URL: http://www.cs.indiana.edu/l/www/ftp/hanson/Vis98/vis98.ibr.ps.gz
Refering-URL: http://www.cs.indiana.edu/l/www/ftp/hanson/Vis98/
Root-URL: http://www.cs.indiana.edu
Title: Image-Based Rendering with Occlusions via Cubist Images  
Author: Andrew J. Hanson Eric A. Wernert 
Keyword: CR Categories: I.3.6 [Computer Graphics]: Methodology and TechniquesInteraction Techniques. I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. I.3.8 [Computer Graphics]: Applications. Keywords: Image Based Rendering; Occlusions  
Note: Figure 1: (a) Head of Woman Reading and (b) Sleeping Nude by Pablo Picasso. c fl1998 Estate of Pablo Picasso/Artists Rights Society, N.Y.)  Email: fhanson, ewernertg@cs.indiana.edu  
Address: Bloomington, IN 47405 USA  
Affiliation: Computer Science Department Indiana University  
Abstract: We attack the problem of image-based rendering with occlusions and general camera motions by using distorted multiperspective images; such images provide multiple-viewpoint photometry similar to the paintings of cubist artists. We take scene geometry, in contrast, to be embodied in mappings of viewing rays from their original 3D intercepts into the warped multiperspective image space. This approach allows us to render approximations of scenes with occlusions using time-dense and spatially sparse sequences of camera rays, which is a significant improvement over the storage requirements of an equivalent animation sequence. Additional data compression can be achieved using sparse time keyframes as well. Interpolating the paths of sparse time key-rays correctly in image space requires singular interpolation functions with spatial discon-tinuities. While there are many technical questions yet to be resolved, the employment of these singular interpolation functions in the multiperspective image space appears to be of potential interest for generating general-viewpoint scene renderings with minimal data storage. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shenchang Eric Chen. </author> <title> Quicktime VR an image-based approach to virtual environment navigation. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 2938. </pages> <publisher> ACM SIGGRAPH, Addison Wes-ley, </publisher> <month> August </month> <year> 1995. </year> <institution> Held in Los Angeles, California, </institution> <month> 611 August </month> <year> 1995. </year>
Reference-contexts: Thus, IBR avoids the expense of storing a full time-step array of images by enforcing camera constraints (e.g., restricting the camera motion to pivot about a fixed focal center) that enable the use of prerendered texture maps embodying very complex image models (including real-life photographs) <ref> [1, 11, 15] </ref>.
Reference: [2] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View interpolation for image synthesis. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 279288, </pages> <month> August </month> <year> 1993. </year> <title> (a) (b) (c) (d) (e) constrained camera paths, the linear source-image interpolations (b),(c),(d) between the keyframe views (a) and (e) are relatively stable. (a) (b) (c) (d) (e) (b),(c),(d) between the keyframe views (a) and (e) are unacceptably distorted. </title>
Reference-contexts: Major obstacles to straightforward image warping include the tearing and folding of the image when general camera motions are attempted in the presence of occlusions. One approach to handling these difficulties is to obtain images from neighboring viewpoints to fill in the holes <ref> [2, 13] </ref>. The distortion maps of vanishing points in the image of a moving camera also need further image-plane geometry in the form of specially structured meshes, as investigated in [8, 7, 17]; foreground geometry can be extracted into a separate layer and the images recomposited using masks. <p> The warping of images to account for changes in the camera model has been studied in [10]. Other methods require the addition of depth or range data <ref> [2, 11] </ref> for each source image used for rendering, or adapt simplified polygon models to the task [3]. The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path.
Reference: [3] <author> L. Darsa, B.C. Silva, and A. Varshney. </author> <title> Navigating static environments using image space simplification and morphing. </title> <booktitle> In Proceedings of 1997 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 2534, </pages> <year> 1997. </year>
Reference-contexts: The warping of images to account for changes in the camera model has been studied in [10]. Other methods require the addition of depth or range data [2, 11] for each source image used for rendering, or adapt simplified polygon models to the task <ref> [3] </ref>. The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path.
Reference: [4] <author> Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and Michael F. Cohen. </author> <title> The lumigraph. </title> <editor> In Holly Rushmeier, editor, </editor> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 4354. </pages> <publisher> ACM SIGGRAPH, Addison Wes-ley, </publisher> <month> August </month> <year> 1996. </year> <title> Held in New Orleans, </title> <address> Louisiana, </address> <month> 49 August </month> <year> 1996. </year>
Reference-contexts: The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path. Alternative approaches based on light fields can require vast amounts of data storage <ref> [4, 9, 14] </ref>. 2 Concepts In this paper, we study the idea of IBR based on a flattened, possibly torn, wrap-around texture image (the source image) and the paths in time of camera rays mapped from their 3D scene intersection points to this single warped image.
Reference: [5] <author> M. Halle. </author> <title> Multiple viewpoint rendering. </title> <booktitle> In SIGGRAPH 98 Conference Proceedings, Annual Conference Series. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <year> 1998. </year>
Reference-contexts: Note added: since this paper was written, two papers have appeared that utilize related but not identical concepts that may also be of interest to the reader: the multiple-center-of-projection approach [12], and multiple viewpoint rendering <ref> [5] </ref>.
Reference: [6] <author> A. J. Hanson and E. Wernert. </author> <title> Constrained 3D navigation with 2D controllers. </title> <booktitle> In Proceedings of Visualization '97, </booktitle> <pages> pages 175182. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: The result is to provide a natural context for the exploitation of constraint manifolds that reduce the scope and complexity of the rendering task as well as enabling simplified navigation through the scene (see, e.g., <ref> [6] </ref>). The procedure we propose is then summarized as follows: Instead of assigning texture to each facet of the geometric structures, source image. In the first row, the 32fi32 array of dots represents the paths of rays from the camera focal point through sampled image pixel centers.
Reference: [7] <author> M. Hirose, S. Watanabe, and T. Endo. </author> <title> Generation of wide-range virtual spaces using photographic images. </title> <booktitle> In Proceedings of VRAIS '98, </booktitle> <volume> volume 5, </volume> <pages> pages 234241, </pages> <year> 1998. </year>
Reference-contexts: One approach to handling these difficulties is to obtain images from neighboring viewpoints to fill in the holes [2, 13]. The distortion maps of vanishing points in the image of a moving camera also need further image-plane geometry in the form of specially structured meshes, as investigated in <ref> [8, 7, 17] </ref>; foreground geometry can be extracted into a separate layer and the images recomposited using masks. The warping of images to account for changes in the camera model has been studied in [10].
Reference: [8] <author> Youichi Horry, Ken ichi Anjyo, and Kiyoshi Arai. </author> <title> Tour into the picture: Using a spidery mesh interface to make animation from a single image. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 225232. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: One approach to handling these difficulties is to obtain images from neighboring viewpoints to fill in the holes [2, 13]. The distortion maps of vanishing points in the image of a moving camera also need further image-plane geometry in the form of specially structured meshes, as investigated in <ref> [8, 7, 17] </ref>; foreground geometry can be extracted into a separate layer and the images recomposited using masks. The warping of images to account for changes in the camera model has been studied in [10].
Reference: [9] <author> Marc Levoy and Pat Hanrahan. </author> <title> Light field rendering. </title> <editor> In Holly Rushmeier, editor, </editor> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 3142. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year> <title> Held in New Orleans, </title> <address> Louisiana, </address> <month> 49 August </month> <year> 1996. </year>
Reference-contexts: The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path. Alternative approaches based on light fields can require vast amounts of data storage <ref> [4, 9, 14] </ref>. 2 Concepts In this paper, we study the idea of IBR based on a flattened, possibly torn, wrap-around texture image (the source image) and the paths in time of camera rays mapped from their 3D scene intersection points to this single warped image.
Reference: [10] <author> W. R. Mark, L. MacMillan, and G. Bishop. </author> <title> Post-rendering 3d warping. </title> <booktitle> In Proceedings of 1997 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 716, </pages> <year> 1997. </year>
Reference-contexts: The warping of images to account for changes in the camera model has been studied in <ref> [10] </ref>. Other methods require the addition of depth or range data [2, 11] for each source image used for rendering, or adapt simplified polygon models to the task [3].
Reference: [11] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIG-GRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 3946. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year> <institution> Held in Los Angeles, California, </institution> <month> 611 August </month> <year> 1995. </year>
Reference-contexts: Thus, IBR avoids the expense of storing a full time-step array of images by enforcing camera constraints (e.g., restricting the camera motion to pivot about a fixed focal center) that enable the use of prerendered texture maps embodying very complex image models (including real-life photographs) <ref> [1, 11, 15] </ref>. <p> The warping of images to account for changes in the camera model has been studied in [10]. Other methods require the addition of depth or range data <ref> [2, 11] </ref> for each source image used for rendering, or adapt simplified polygon models to the task [3]. The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path.
Reference: [12] <author> P. Rademacher and G. Bishop. </author> <title> Multiple-center-of-projection images. </title> <booktitle> In SIGGRAPH 98 Conference Proceedings, Annual Conference Series. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <year> 1998. </year>
Reference-contexts: Note added: since this paper was written, two papers have appeared that utilize related but not identical concepts that may also be of interest to the reader: the multiple-center-of-projection approach <ref> [12] </ref>, and multiple viewpoint rendering [5].
Reference: [13] <author> Steven M. Seitz and Charles R. Dyer. </author> <title> View morphing: Synthesizing 3D metamorphoses using image transforms. </title> <editor> In Holly Rushmeier, editor, </editor> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 2130. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year> <title> Held in New Orleans, </title> <address> Louisiana, </address> <month> 49 August </month> <year> 1996. </year>
Reference-contexts: Major obstacles to straightforward image warping include the tearing and folding of the image when general camera motions are attempted in the presence of occlusions. One approach to handling these difficulties is to obtain images from neighboring viewpoints to fill in the holes <ref> [2, 13] </ref>. The distortion maps of vanishing points in the image of a moving camera also need further image-plane geometry in the form of specially structured meshes, as investigated in [8, 7, 17]; foreground geometry can be extracted into a separate layer and the images recomposited using masks.
Reference: [14] <author> P. P. Sloan, M.F. Cohen, and S.J. Gortler. </author> <title> Time critical lu-migraph rendering. </title> <booktitle> In Proceedings of 1997 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 1723, </pages> <year> 1997. </year>
Reference-contexts: The multiperspective panorama approach [16] achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path. Alternative approaches based on light fields can require vast amounts of data storage <ref> [4, 9, 14] </ref>. 2 Concepts In this paper, we study the idea of IBR based on a flattened, possibly torn, wrap-around texture image (the source image) and the paths in time of camera rays mapped from their 3D scene intersection points to this single warped image.
Reference: [15] <author> Richard Szeliski and Heung-Yeung Shum. </author> <title> Creating full view panoramic mosaics and environment maps. </title> <editor> In Turner Whit-ted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 251258. </pages> <publisher> ACM SIGGRAPH, Addi-son Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: Thus, IBR avoids the expense of storing a full time-step array of images by enforcing camera constraints (e.g., restricting the camera motion to pivot about a fixed focal center) that enable the use of prerendered texture maps embodying very complex image models (including real-life photographs) <ref> [1, 11, 15] </ref>.
Reference: [16] <author> Daniel N. Wood, Adam Finkelstein, John F. Hughes, Craig E. Thayer, and David H. Salesin. </author> <title> Multiperspective panoramas for cel animation. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 243250. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: This distinguishes our construction from those whose source images are obtained from a sequence of physically plausible cameras, and which may contain multiple copies of the same scene element (see, e.g., the multiperspective panorama approach <ref> [16] </ref>). The most natural domains for our approach are thus terrain and terrain-like scenes that can be shrink-wrapped with a single continuous sheet, though other topologies can also be treated. <p> The warping of images to account for changes in the camera model has been studied in [10]. Other methods require the addition of depth or range data [2, 11] for each source image used for rendering, or adapt simplified polygon models to the task [3]. The multiperspective panorama approach <ref> [16] </ref> achieves some extra flexibility by using a single image as a repository for composited information relevant to many viewpoints on a single constrained camera animation path. <p> revert to forbidding certain camera parameter ranges, thus restricting the user's freedom to sets of views that have reduced rendering complexity criteria; this is a good example of an adaptation of the constrained navigation paradigm to the IBR arena, and is in some sense complementary to the multiperspective panorama concept <ref> [16] </ref>. The result is to provide a natural context for the exploitation of constraint manifolds that reduce the scope and complexity of the rendering task as well as enabling simplified navigation through the scene (see, e.g., [6]).
Reference: [17] <author> Z. Zhu, G. Xu, and X. Lin. </author> <title> Constructing 3D natural scene from video sequences with vibrated motions. </title> <booktitle> In Proceedings of VRAIS '98, </booktitle> <pages> pages 105112, </pages> <year> 1998. </year> <title> (a) (b) (c) 640fi640 flattened source image. (Owen Hall model courtesy of Indiana University Architect's Office.) (a) (b) (c) texture coordinates in the source image. (c) Tailored visualization achieved by altering color and lighting characteristics of source image. (a) (b) (c) keyframe pixels in the source image. (c) Trace of veridical pixel paths (blue) and approximate cubic interpolation (red) between keyframes. </title>
Reference-contexts: One approach to handling these difficulties is to obtain images from neighboring viewpoints to fill in the holes [2, 13]. The distortion maps of vanishing points in the image of a moving camera also need further image-plane geometry in the form of specially structured meshes, as investigated in <ref> [8, 7, 17] </ref>; foreground geometry can be extracted into a separate layer and the images recomposited using masks. The warping of images to account for changes in the camera model has been studied in [10].
References-found: 17

