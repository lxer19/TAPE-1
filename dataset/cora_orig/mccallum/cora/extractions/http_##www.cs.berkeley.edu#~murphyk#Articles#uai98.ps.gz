URL: http://www.cs.berkeley.edu/~murphyk/Articles/uai98.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~murphyk/publ.html
Root-URL: 
Email: fnir,murphyk,russellg@cs.berkeley.edu  
Title: Learning the Structure of Dynamic Probabilistic Networks  
Author: Nir Friedman Kevin Murphy Stuart Russell 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division, U. of California,  
Abstract: Dynamic probabilistic networks are a compact representation of complex stochastic processes. In this paper we examine how to learn the structure of a DPN from data. We extend structure scoring rules for standard probabilistic networks to the dynamic case, and show how to search for structure when some of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Binder, D. Koller, S. Russell, and K. </author> <title> Kanazawa. Adaptive probabilistic networks with hidden variables. </title> <journal> Mach. Learning, </journal> <volume> 29 </volume> <pages> 213-244, </pages> <year> 1997. </year>
Reference-contexts: For example, [31] show that DPNs can outperform HMMs on standard speech recognition tasks. PNs and DPNs are defined by a graphical structure and a set of parameters, which together specify a joint distribution over the random variables. Algorithms for learning the parameters of PNs <ref> [1, 21] </ref> and DPNs [1, 14] are becoming widely used. These algorithms typically use either gradient methods or EM, and can handle hidden variables and missing values. <p> For example, [31] show that DPNs can outperform HMMs on standard speech recognition tasks. PNs and DPNs are defined by a graphical structure and a set of parameters, which together specify a joint distribution over the random variables. Algorithms for learning the parameters of PNs [1, 21] and DPNs <ref> [1, 14] </ref> are becoming widely used. These algorithms typically use either gradient methods or EM, and can handle hidden variables and missing values. <p> To represent beliefs about the possible trajectories of the process, we need a probability distribution over the random variables X [0] [ X <ref> [1] </ref> [ X [2] [ : : :. Of course, such a distribution can be extremely complex. <p> these assumptions, a DPN that represents the joint distribution over all possible trajectories of a process con sists of two parts: * a prior network B 0 that specifies a distribution over initial states X [0]; and * a transition network B ! over the variables X [0] [ X <ref> [1] </ref> that is taken to specify the transition probability P (X [t + 1] j X [t]) for all t. network (but not the prior network), the variables in X [0] have no parents. The transition probability implied by such a network is: P B ! (x [1] j x [0]) <p> [0] [ X <ref> [1] </ref> that is taken to specify the transition probability P (X [t + 1] j X [t]) for all t. network (but not the prior network), the variables in X [0] have no parents. The transition probability implied by such a network is: P B ! (x [1] j x [0]) = i=1 P B ! (x i [1]jpa (X i [1])): A DPN defined by a pair (B 0 ; B ! ) corresponds to a semi-infinite network over the variables X [0]; : : : ; X [1]. <p> The transition probability implied by such a network is: P B ! (x <ref> [1] </ref> j x [0]) = i=1 P B ! (x i [1]jpa (X i [1])): A DPN defined by a pair (B 0 ; B ! ) corresponds to a semi-infinite network over the variables X [0]; : : : ; X [1]. In practice, we reason only about a finite interval 0; : : : ; T . <p> such a network is: P B ! (x <ref> [1] </ref> j x [0]) = i=1 P B ! (x i [1]jpa (X i [1])): A DPN defined by a pair (B 0 ; B ! ) corresponds to a semi-infinite network over the variables X [0]; : : : ; X [1]. In practice, we reason only about a finite interval 0; : : : ; T . To do this, we can notionally unroll the DPN structure into a PN over X [0]; : : : ; X [T ]. <p> In slice 0, the parents of X i [0] are those specified in the prior network B 0 ; in slice t + 1, the parents of X i [t + 1] are those nodes in slices t and t + 1 corresponding to the parents of X i <ref> [1] </ref> in B ! . We copy the conditional distributions for these variables in a similar manner. Figure 1 (b) shows the result of unrolling the network in Figure 1 (a) for 3 time slices. <p> assign the Dirichlet weights for G = (G 0 ; G ! ) as follows: N 0 (0) i ;k 0 = N (0) fi P B 0 (X i [0] = k 0 i ) i;j i ;k i = N ! fi P B 0 ! (X i <ref> [1] </ref> = k i j Pa (X i [1]) = j i ) (Note that the choice of parents here is based on G, and might differ from the structure of B 0 .) Intuitively, we can consider the belief in B 0 as equivalent to having previously experienced N (0) <p> 0 ; G ! ) as follows: N 0 (0) i ;k 0 = N (0) fi P B 0 (X i [0] = k 0 i ) i;j i ;k i = N ! fi P B 0 ! (X i <ref> [1] </ref> = k i j Pa (X i [1]) = j i ) (Note that the choice of parents here is based on G, and might differ from the structure of B 0 .) Intuitively, we can consider the belief in B 0 as equivalent to having previously experienced N (0) sequences with N ! transitions. <p> To learn such noisy-OR distributions, we follow the technique suggested in [27]; this entails introducing a new hidden node for each arc in the network, which is a noisy version of its parent, and replacing each noisy-OR gate with a deterministic-OR gate. We also tried using gradient descent, following <ref> [1] </ref>, but encountered difficulties with convergence in cases where the optimal parameter values were close to the boundaries (0 and relative log-loss (right) compared with the generating model on independent sample of 100 sequences.
Reference: [2] <author> X. Boyen and D. Koller. </author> <title> Tractable Inference for Complex Stochastic Processes. </title> <booktitle> In UAI, </booktitle> <year> 1998. </year>
Reference-contexts: To represent beliefs about the possible trajectories of the process, we need a probability distribution over the random variables X [0] [ X [1] [ X <ref> [2] </ref> [ : : :. Of course, such a distribution can be extremely complex. <p> There are various approximations that we could use to speed up inference: (1) The method proposed by Boyen and Koller <ref> [2] </ref>, which approximates posterior probabilities in the DPN in a factored form; this should be particularly appropriate for the biological models we are investigating. (2) Stochastic simulationfor example, the ER/SOF algorithm of Kanazawa et al. [18]. (3) Variational approximations, e.g., Jaakkola and Jorden [17] and Ghahramani and Jordan [14]. (4) Methods
Reference: [3] <author> W. Buntine. </author> <title> Theory refinement on Bayesian networks. </title> <booktitle> In UAI-91, </booktitle> <pages> pp. 52-60. </pages> <year> 1991. </year>
Reference-contexts: The BIC score uses Equation (3) to rank candidate network structures. Notice that it obviates the need for parameter priors, and the prior on structures is reduced to counting parameters. 2 An alternative approach is to evaluate (2) in closed form given a restricted family of priors <ref> [3, 4, 15] </ref>. Roughly speaking, the prior on the parameters for a given structure G is assumed to factor into independent priors over the parameters for each conditional distribution P (X i j pa (X i )). <p> Thus, by caching these counts we can efficiently evaluate many families. These two properties can be exploited by hill-climbing search procedures <ref> [3, 15] </ref> that gradually improve a candidate structure by applying the best arc addition, deletion, or reversal. In the case of DPNs, as opposed to static PNs, we have the additional constraint that the network structure must repeat over time.
Reference: [4] <author> G. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Mach. Learning, </journal> <volume> 9 </volume> <pages> 309-347, </pages> <year> 1992. </year>
Reference-contexts: Algorithms for learning the graphical structure, on the other hand, have until recently been restricted to networks with complete data, i.e., where the values of all variables are specified in each training case <ref> [4, 15] </ref>. Friedman [10, 11] has developed the Structural EM (SEM) algorithm for learning PN structure from data with hidden variables and missing values. <p> The BIC score uses Equation (3) to rank candidate network structures. Notice that it obviates the need for parameter priors, and the prior on structures is reduced to counting parameters. 2 An alternative approach is to evaluate (2) in closed form given a restricted family of priors <ref> [3, 4, 15] </ref>. Roughly speaking, the prior on the parameters for a given structure G is assumed to factor into independent priors over the parameters for each conditional distribution P (X i j pa (X i )).
Reference: [5] <author> T. Dean and K. </author> <title> Kanazawa. Probabilistic temporal reasoning. </title> <booktitle> In AAAI-88, </booktitle> <pages> pp. 524-528, </pages> <year> 1988. </year>
Reference-contexts: Somewhat less well-established, but perhaps of equal importance, are dynamic probabilistic networks (DPNs), which model the stochastic evolution of a set of random variables over time <ref> [5] </ref>. DPNs have significant advantages over competing representations such as Kalman filters, which handle only unimodal posterior distributions and linear models, and hidden Markov models (HMMs), whose parameterization grows exponentially with the number of state variables. For example, [31] show that DPNs can outperform HMMs on standard speech recognition tasks.
Reference: [6] <author> M. </author> <title> DeGroot. Optimal Statistical Decisions. </title> <year> 1970. </year>
Reference-contexts: In order to obtain a closed-form solution, we assume Dirichlet priors <ref> [6] </ref>.
Reference: [7] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Stat. Soc., </journal> <volume> B 39 </volume> <pages> 1-39, </pages> <year> 1977. </year>
Reference-contexts: For most events of interest, the counts are not defined, since we do not know the exact value of the variables in questions. The most commonly used method to alleviate this problem is the Expectation-Maximization (EM) algorithm <ref> [7, 21] </ref>. The E-step of EM uses the currently estimated parameters to complete the data by computing the expected counts. The M-step then re-estimates the maximum-likelihood parameter values as if the expected counts were true observed counts.
Reference: [8] <author> J. Forbes, T. Huang, K. Kanazawa, and S. Russell. </author> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: From this data, we want to learn models of typical classes of driving behavior. Such models can be useful for several tasks. A prime example arises in the BATmobile autonomous car project <ref> [8] </ref>. The BATmobile's autonomous controller attempts to predict the behavior of neighboring car. For example, it would be useful to know that someone who has just driven across two lanes might be attempting to leave the freeway, and consequently is likely to cut in front of you.
Reference: [9] <author> J. Forbes, N. Oza, R. Parr, and S. Russell. </author> <title> Feasibility study of fully automated traffic using decision-theoretic control. Cal. </title> <note> PATH Research Report UCB-ITS-PRR-97-18, </note> <institution> Inst. of Transportation Studies, </institution> <address> U. C. Berkeley, </address> <year> 1997. </year>
Reference-contexts: The learned model may also provide insight into how the behavior is generated. In this section, we describe some experiments we carried out using a simulated driving domain <ref> [9] </ref>. The data is an idealization of what cameras mounted on the side of the road can collect. In particular, at each time step of the simulation, we get a report on cars that are within the camera's range.
Reference: [10] <author> N. Friedman. </author> <title> Learning belief networks in the presence of missing values and hidden variables. </title> <booktitle> In ICML-97, </booktitle> <year> 1997. </year>
Reference-contexts: Algorithms for learning the graphical structure, on the other hand, have until recently been restricted to networks with complete data, i.e., where the values of all variables are specified in each training case [4, 15]. Friedman <ref> [10, 11] </ref> has developed the Structural EM (SEM) algorithm for learning PN structure from data with hidden variables and missing values. <p> EM has been traditionally viewed as a method for adjusting the parameters of a fixed model structure. However, the underlying theorem can be generalized to apply to structural as well as parametric modifications. Friedman's Structural EM (SEM) algorithm <ref> [10] </ref> has the same E-step as EM, completing the data by computing expected counts based on the current structure and parameters. <p> The expectation is taken with respect to Pr (D + j D; (B (0) ; B ! )), i.e., the probability assigned to this completion based on the old DPN. Using Theorem 3.1 of <ref> [10] </ref>, we can prove the following: Theorem 4.1: BIC ((B 0 ! ) : D) BIC ((B 0 ; B ! ) : D) &gt; 0 ; B 0 E [BIC ((B 0 ; B ! ) : D + ) : D; (B 0 ; B ! )] That is,
Reference: [11] <author> N. Friedman. </author> <title> The Bayesian Structural EM Algorithm. </title> <booktitle> In UAI-98, </booktitle> <year> 1998. </year>
Reference-contexts: Algorithms for learning the graphical structure, on the other hand, have until recently been restricted to networks with complete data, i.e., where the values of all variables are specified in each training case [4, 15]. Friedman <ref> [10, 11] </ref> has developed the Structural EM (SEM) algorithm for learning PN structure from data with hidden variables and missing values. <p> Friedman shows that for a large family of scorings rules, including the BIC score and BDe score <ref> [11] </ref>, the resulting network must have a higher score than the original. This is true even though the expected counts used in evaluating the new structure are computed using the old structure. We can extend Friedman's results to the DPN case in the following way. <p> In <ref> [11] </ref>, Friedman shows how to extend the SEM procedure to learn with the BDe score. The details are more involved, since the BDe score is not linear.
Reference: [12] <author> N. Friedman and M. Goldszmidt. </author> <title> Learning Bayesian networks with local structure. </title> <editor> In M. I. Jordan, ed., </editor> <title> Learning in Graphical Models, </title> <note> 1998. A preliminary version appeared in UAI '96.. </note>
Reference-contexts: Each conditional probability distribution can be represented as a table, called a CPT (conditional probability table). Representations which require fewer parameters, such as noisy-ORs [27] or trees <ref> [12] </ref>, are also possible indeed, we use them in the experimental results section but, for simplicity of notation, we shall stick to the CPT case. <p> Each vertex represents a site in the genome, and each arc is a possible triggering pathway. (b) A DPN model that is equivalent to the pathway model shown in (a). We learned networks with 0, 1, and 2 hidden variables using decision tree CPTs <ref> [12] </ref> with the BIC and BDe score.
Reference: [13] <author> D. Geiger and D. Heckerman. </author> <title> Learning Gaussian Networks. </title> <booktitle> In UAI, </booktitle> <year> 1994. </year>
Reference: [14] <author> Z. Ghahramani and M. I. Jordan. </author> <title> Factorial hidden Markov models. </title> <journal> Mach. Learning, </journal> <volume> 29 </volume> <pages> 245-274, </pages> <year> 1997. </year>
Reference-contexts: For example, [31] show that DPNs can outperform HMMs on standard speech recognition tasks. PNs and DPNs are defined by a graphical structure and a set of parameters, which together specify a joint distribution over the random variables. Algorithms for learning the parameters of PNs [1, 21] and DPNs <ref> [1, 14] </ref> are becoming widely used. These algorithms typically use either gradient methods or EM, and can handle hidden variables and missing values. <p> and Koller [2], which approximates posterior probabilities in the DPN in a factored form; this should be particularly appropriate for the biological models we are investigating. (2) Stochastic simulationfor example, the ER/SOF algorithm of Kanazawa et al. [18]. (3) Variational approximations, e.g., Jaakkola and Jorden [17] and Ghahramani and Jordan <ref> [14] </ref>. (4) Methods based on multilevel abstraction hierarchy to detect which variables are related to each other. We are currently extending SEM to learn the structure of linear Gaussian DPNs; we hope this will prove competitive with traditional techniques of system identification [23].
Reference: [15] <author> D. Heckerman, D. Geiger, and D. M. Chickering. </author> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <journal> Mach. Learning, </journal> <volume> 20 </volume> <pages> 197-243, </pages> <year> 1995. </year>
Reference-contexts: Algorithms for learning the graphical structure, on the other hand, have until recently been restricted to networks with complete data, i.e., where the values of all variables are specified in each training case <ref> [4, 15] </ref>. Friedman [10, 11] has developed the Structural EM (SEM) algorithm for learning PN structure from data with hidden variables and missing values. <p> This property holds for both the Bayesian Information Criterion (BIC) score [28], a variant of Minimum Description Length (MDL) scoring, and the BDe score <ref> [15] </ref>, a Bayesian metric that uses an explicit prior over networks. In this paper, we extend the BIC and BDe scores to handle the problem of learning DPN structure from complete data. More importantly, we extend the SEM algorithm to learn DPNs from incomplete data with both scores. <p> The notion of best match is defined using a scoring function. Sev eral different scoring functions have been proposed in the literature. The most frequently used are the Bayesian Information Criterion [28] and the BDe score <ref> [15] </ref>. Both of these 1 Some authors define DPNs using just the transition network, assuming that all slices, including slice 0, have the same structure. <p> The BIC score uses Equation (3) to rank candidate network structures. Notice that it obviates the need for parameter priors, and the prior on structures is reduced to counting parameters. 2 An alternative approach is to evaluate (2) in closed form given a restricted family of priors <ref> [3, 4, 15] </ref>. Roughly speaking, the prior on the parameters for a given structure G is assumed to factor into independent priors over the parameters for each conditional distribution P (X i j pa (X i )). <p> The details appear below. Since we might examine a large number of possible network structures, we would like to avoid having to assign a prior distribution over parameters for each possible structure. <ref> [15] </ref> provide a set of assumptions that allow the parameter prior for all structures to be specified using a single network with Dirichlet priors, together with a single virtual data count that describes the confidence in that prior. 2 A similar formula arises from the Minimum Description Length (MDL) principle [20]. <p> This still requires us to supply the Dirichlet hyperparame-ters for each candidate DPN structure. Since the number of possible DPN structures is large, these prior estimates might be hard to asses in practice. Following <ref> [15] </ref>, we can assign all of these given a prior DPN B 0 = (B 0 (0) ; B 0 equivalent sample sizes N (0) and N ! . <p> Thus, by caching these counts we can efficiently evaluate many families. These two properties can be exploited by hill-climbing search procedures <ref> [3, 15] </ref> that gradually improve a candidate structure by applying the best arc addition, deletion, or reversal. In the case of DPNs, as opposed to static PNs, we have the additional constraint that the network structure must repeat over time.
Reference: [16] <author> Z. Ghahramani and G. Hinton. </author> <title> Switching State-Space Models. </title> <note> Submitted for publication, </note> <year> 1998. </year>
Reference-contexts: One advantage of the Gaussian case over the discrete case is that marginalizing the posterior over two slices is an efficient operation. Ultimately we wish to tackle the case of hybrid DPNs, with both discrete and continuous variables. The advantage of hybrid DPNs over switching state space models <ref> [16] </ref> is that the state variables can be represented in factored form. For example, in the driving domain, we can have separate variables for the continuous observations (such as speed and position) and for the discrete hidden states (such as want to change lane or want to overtake).
Reference: [17] <author> T.S. Jaakkola and M.I. Jordan. </author> <title> Recursive algorithms for approximating probabilities in graphical models. </title> <booktitle> In NIPS 9, </booktitle> <pages> pp. 487-93, </pages> <year> 1997. </year>
Reference-contexts: The method proposed by Boyen and Koller [2], which approximates posterior probabilities in the DPN in a factored form; this should be particularly appropriate for the biological models we are investigating. (2) Stochastic simulationfor example, the ER/SOF algorithm of Kanazawa et al. [18]. (3) Variational approximations, e.g., Jaakkola and Jorden <ref> [17] </ref> and Ghahramani and Jordan [14]. (4) Methods based on multilevel abstraction hierarchy to detect which variables are related to each other. We are currently extending SEM to learn the structure of linear Gaussian DPNs; we hope this will prove competitive with traditional techniques of system identification [23].
Reference: [18] <author> K. Kanazawa, D. Koller, and S. Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> In UAI-95, </booktitle> <pages> pp. 346-351, </pages> <year> 1995. </year>
Reference-contexts: we could use to speed up inference: (1) The method proposed by Boyen and Koller [2], which approximates posterior probabilities in the DPN in a factored form; this should be particularly appropriate for the biological models we are investigating. (2) Stochastic simulationfor example, the ER/SOF algorithm of Kanazawa et al. <ref> [18] </ref>. (3) Variational approximations, e.g., Jaakkola and Jorden [17] and Ghahramani and Jordan [14]. (4) Methods based on multilevel abstraction hierarchy to detect which variables are related to each other.
Reference: [19] <author> U. Kjaerulff. </author> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In UAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: To efficiently compute the probabilities of the families, we can convert the DPN to a join tree and use a two-pass dynamic programming algorithm <ref> [19] </ref>, similar to the forwards-backwards algorithm used in HMMs [29]. To efficiently compute the probability of a set of nodes that is not contained in any of the join tree nodes, we need to use more sophisticated techniques [30].
Reference: [20] <author> W. Lam and F. Bacchus. </author> <title> Learning Bayesian belief networks: An approach based on the MDL principle. </title> <journal> Comp. Intel., </journal> <volume> 10 </volume> <pages> 269-293, </pages> <year> 1994. </year>
Reference-contexts: [15] provide a set of assumptions that allow the parameter prior for all structures to be specified using a single network with Dirichlet priors, together with a single virtual data count that describes the confidence in that prior. 2 A similar formula arises from the Minimum Description Length (MDL) principle <ref> [20] </ref>. This approach has the desirable property that the scores of two networks that are equivalent (i.e., describe the same set of independence assumptions) are the same.
Reference: [21] <author> S. L. Lauritzen. </author> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Comp. Stat. and Data Anal., </journal> <volume> 19 </volume> <pages> 191-201, </pages> <year> 1995. </year>
Reference-contexts: For example, [31] show that DPNs can outperform HMMs on standard speech recognition tasks. PNs and DPNs are defined by a graphical structure and a set of parameters, which together specify a joint distribution over the random variables. Algorithms for learning the parameters of PNs <ref> [1, 21] </ref> and DPNs [1, 14] are becoming widely used. These algorithms typically use either gradient methods or EM, and can handle hidden variables and missing values. <p> For most events of interest, the counts are not defined, since we do not know the exact value of the variables in questions. The most commonly used method to alleviate this problem is the Expectation-Maximization (EM) algorithm <ref> [7, 21] </ref>. The E-step of EM uses the currently estimated parameters to complete the data by computing the expected counts. The M-step then re-estimates the maximum-likelihood parameter values as if the expected counts were true observed counts.
Reference: [22] <author> S. Liang, S. Fuhrman, and R. Somogyi. </author> <title> Reveal, a general reverse engineering algorithm for inference of genetic network architectures. </title> <booktitle> In Pacific Symp. on Biocomputing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 18-29, </pages> <year> 1998. </year>
Reference-contexts: McAdams and Shapiro [26] model part of the genetic circuit of the lambda bacteriophage in terms of a sequential logic circuit; and attempts have even be made to automatically infer the form of such Boolean circuits from data <ref> [22] </ref>.
Reference: [23] <author> L. Ljung. </author> <title> System Identification: Theory for the User. </title> <publisher> Pren-tice Hall, </publisher> <year> 1987. </year>
Reference-contexts: We are currently extending SEM to learn the structure of linear Gaussian DPNs; we hope this will prove competitive with traditional techniques of system identification <ref> [23] </ref>. One advantage of the Gaussian case over the discrete case is that marginalizing the posterior over two slices is an efficient operation. Ultimately we wish to tackle the case of hybrid DPNs, with both discrete and continuous variables.
Reference: [24] <author> J. Malik and S. Russell. </author> <title> Traffic surveillance and detection technology development: New sensor technology final report. Research Report UCB-ITS-PRR-97-6, Cal. PATH Program, </title> <year> 1997. </year>
Reference-contexts: For example, it would be useful to know that someone who has just driven across two lanes might be attempting to leave the freeway, and consequently is likely to cut in front of you. Since tracking information from real cameras is readily available <ref> [24] </ref>, it is reasonable to hope that realistic models of human drivers can be obtained. In addition to their use in autonomous vehicles, such models are of paramount importance in so-called microscopic traffic models used in freeway design and construction planning and also in safety studies.
Reference: [25] <author> H. H. McAdams and A. Arkin. </author> <title> Stochastic mechanisms in gene expression. </title> <journal> Proc. of the Nat. Acad. of Sci., </journal> <volume> 94 </volume> <pages> 814-819, </pages> <year> 1997. </year>
Reference-contexts: is well known that the abstraction of binary-valued signals together with deterministic switches often breaks down, and one must model 3 For comparison, the gzip utility compresses the observations to approximately 5.6 bits per time slice. the continuous nature and inherent noise in the underlying system to get accurate predictions <ref> [25] </ref>. Also, one must be able to deal with noisy and incomplete observations of the system. We believe that DPNs provide a good tool for modeling such noisy, causal systems, and furthermore that SEM provides a good way to learn these models automatically from noisy, incomplete data.
Reference: [26] <author> H. H. McAdams and L. Shapiro. </author> <title> Circuit simulation of genetic networks. </title> <journal> Science, </journal> <volume> 269 </volume> <pages> 650-656, </pages> <year> 1995. </year>
Reference-contexts: Such models are useful in many areas of science, including molecular biology, where one is often interested in inferring the structure of regulatory pathways. McAdams and Shapiro <ref> [26] </ref> model part of the genetic circuit of the lambda bacteriophage in terms of a sequential logic circuit; and attempts have even be made to automatically infer the form of such Boolean circuits from data [22].
Reference: [27] <author> C. Meek and D. Heckerman. </author> <title> Structure and parameter learning for causal independence and causal interaction models. </title> <booktitle> In UAI-97, </booktitle> <pages> pp. 366-375, </pages> <year> 1997. </year>
Reference-contexts: Each conditional probability distribution can be represented as a table, called a CPT (conditional probability table). Representations which require fewer parameters, such as noisy-ORs <ref> [27] </ref> or trees [12], are also possible indeed, we use them in the experimental results section but, for simplicity of notation, we shall stick to the CPT case. <p> For a strict persistence model (vertices stay on once triggered), q parameters for persistence arcs are fixed at 0. To learn such noisy-OR distributions, we follow the technique suggested in <ref> [27] </ref>; this entails introducing a new hidden node for each arc in the network, which is a noisy version of its parent, and replacing each noisy-OR gate with a deterministic-OR gate.
Reference: [28] <author> G. Schwarz. </author> <title> Estimating the dimension of a model. </title> <journal> Ann. Stat., </journal> <volume> 6 </volume> <pages> 461-464, </pages> <year> 1978. </year>
Reference-contexts: SEM can be shown to find local optima defined by a scoring function that combines the likelihood of the data with a structural penalty that discourages overly complex networks. This property holds for both the Bayesian Information Criterion (BIC) score <ref> [28] </ref>, a variant of Minimum Description Length (MDL) scoring, and the BDe score [15], a Bayesian metric that uses an explicit prior over networks. In this paper, we extend the BIC and BDe scores to handle the problem of learning DPN structure from complete data. <p> The notion of best match is defined using a scoring function. Sev eral different scoring functions have been proposed in the literature. The most frequently used are the Bayesian Information Criterion <ref> [28] </ref> and the BDe score [15]. Both of these 1 Some authors define DPNs using just the transition network, assuming that all slices, including slice 0, have the same structure. <p> Given a large number of data points, the posterior probability is insensitive to the choice of prior (assuming that the prior does not give probability zero to any event). Schwarz <ref> [28] </ref> derives the following asymptotic estimate for well-behaved priors: log Pr (D j G) = log Pr (D j G; Q G ) 2 #G + O (1); where Q G are the parameter settings for G that maximize the likelihood of the data, N is the number of training instances,
Reference: [29] <author> P. Smyth, D. Heckerman, and M. Jordan. </author> <title> Probabilistic independence networks for hidden Markov probability models. </title> <journal> Neural Computation, </journal> <volume> 9(2) </volume> <pages> 227-269, </pages> <year> 1997. </year>
Reference-contexts: To efficiently compute the probabilities of the families, we can convert the DPN to a join tree and use a two-pass dynamic programming algorithm [19], similar to the forwards-backwards algorithm used in HMMs <ref> [29] </ref>. To efficiently compute the probability of a set of nodes that is not contained in any of the join tree nodes, we need to use more sophisticated techniques [30].
Reference: [30] <author> H. Xu. </author> <title> Computing marginals for arbitrary subsets from marginal representations in Markov trees. </title> <booktitle> Art. Intel., </booktitle> <volume> 74 </volume> <pages> 177-189, </pages> <year> 1995. </year>
Reference-contexts: To efficiently compute the probability of a set of nodes that is not contained in any of the join tree nodes, we need to use more sophisticated techniques <ref> [30] </ref>.
Reference: [31] <author> G. Zweig and S. Russell. </author> <title> Speech recognition with dynamic Bayesian networks. </title> <booktitle> In AAAI-98, </booktitle> <year> 1998. </year>
Reference-contexts: DPNs have significant advantages over competing representations such as Kalman filters, which handle only unimodal posterior distributions and linear models, and hidden Markov models (HMMs), whose parameterization grows exponentially with the number of state variables. For example, <ref> [31] </ref> show that DPNs can outperform HMMs on standard speech recognition tasks. PNs and DPNs are defined by a graphical structure and a set of parameters, which together specify a joint distribution over the random variables.
References-found: 31

