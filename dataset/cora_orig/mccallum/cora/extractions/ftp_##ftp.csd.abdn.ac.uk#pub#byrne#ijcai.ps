URL: ftp://ftp.csd.abdn.ac.uk/pub/byrne/ijcai.ps
Refering-URL: http://www.csd.abdn.ac.uk/~byrne/publications.html
Root-URL: 
Title: Refinement in Agent Groups  
Author: Ciara Byrne and Peter Edwards 
Address: King's College,  Aberdeen, Scotland AB9 2UE  
Affiliation: Department of Computing Science,  University of Aberdeen,  
Abstract: A group of intelligent agents may work together in order to solve a problem or achieve a common goal. If the group fails to achieve a goal, it may be able to adapt its behaviour so that such a goal can be achieved in the future. One of the ways in which the behaviour of the agent group can be changed is by refining the knowledge of individual agents.
Abstract-found: 1
Intro-found: 1
Reference: [ Craw and Sleeman, 1991 ] <author> S. Craw and D. Sleeman. </author> <title> The Flexibility of Speculative Refinement. </title> <editor> In L. A. Birnbaum and G. C. Collins, editors, </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <pages> pages 28-32, </pages> <year> 1991. </year>
Reference-contexts: Our research is concerned with how they can do this effectively. Extensive investigation of techniques for refining the knowledge held in a single knowledge base have already been carried out [ Ourston and Mooney, 1991 ] [ Richards and Mooney, 1992 ] <ref> [ Craw and Sleeman, 1991 ] </ref> . The process of refining multiple related knowledge bases, such as those of a group of agents, presents new challenges. The refinement of one agent's knowledge may affect other agents in the system.
Reference: [ Davies and Edwards, 1994 ] <author> Winton Davies and Peter Edwards. Agent-K: </author> <title> An Integration of AOP and KQML. </title> <editor> In Y. Labrou and T. Finin, editors, </editor> <booktitle> CIKM Workshop on Intelligent Information Agents. </booktitle> <institution> National Institute of Standards and Technology, Gaithersburg, Maryland, </institution> <year> 1994. </year>
Reference-contexts: Therefore, agents must volunteer information about their internal processing and cooperate with other agents in order to effectively refine their knowledge. In order to address these issues, we have extended an existing Agent-Oriented Programming language <ref> [ Davies and Edwards, 1994 ] </ref> in order to provide the information required for learning, and have proposed a mechanism for coordinating refinement in a group of agents. 2 An Agent Language We have specified our agents in an extended version of the agent-oriented programming language Agent-K [ Davies and Edwards, <p> Agent-Oriented Programming language <ref> [ Davies and Edwards, 1994 ] </ref> in order to provide the information required for learning, and have proposed a mechanism for coordinating refinement in a group of agents. 2 An Agent Language We have specified our agents in an extended version of the agent-oriented programming language Agent-K [ Davies and Edwards, 1994 ] . Agent-K is based on Agent-0 [ Shoham, 1990 ] . An Agent-K agent has a number of beliefs, capabilities and commitments. A belief is a logical statement which the agent "believes" to be true at a particular point in time.
Reference: [ Finin et al., 1992 ] <author> T. Finin, R. Fritzson, and D. McKay et al. </author> <title> An Overview of KQML: A Knowledge Query and Manipulation Language. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Mary-land, </institution> <year> 1992. </year>
Reference-contexts: A commitment rule's conditions are matched against incoming messages and the agent's current mental state. If the rule fires, then a commitment is formed to perform the action requested by the message sender. Agents use the KQML <ref> [ Finin et al., 1992 ] </ref> language for inter-agent communication. The basic Agent-K language has been extended to allow the specification, in the form of a simple goal tree, of an agent's individual goals. We will refer to this extended version of Agent-K as Agent-K*. <p> A facilitator coordinates interaction between agents. For example, KQML <ref> [ Finin et al., 1992 ] </ref> communication facilitators are used to manage message traffic among other agents by routing messages to appropriate agents, providing buffering and translation facilities, etc.
Reference: [ Lebowitz, 1987 ] <author> M. Lebowitz. </author> <title> Experiments with Incremental Concept Formation: </title> <journal> UNIMEM. Machine Learning, </journal> <volume> Vol. 2, No. 2, </volume> <pages> pages 103-108, </pages> <note> 1987. </note> [ <author> Ourston and Mooney, 1991 ] D. Ourston and R.J. Mooney. </author> <title> Changing the Rules: A Comprehensive Approach to Theory Refinement. </title> <booktitle> In Proceedings of the Eight International Conference on Machine Learning, </booktitle> <pages> pages 485-489, </pages> <year> 1991. </year>
Reference-contexts: The previous instantiations of the action serve as a set of examples for a conceptual clustering algorithm <ref> [ Lebowitz, 1987 ] </ref> which, based on the current domain knowledge, places them in a single category. The defining features of this category are that the prey is always small, Hunter1 is not cooperating and the action is initiated by Hunter1 itself.
Reference: [ Richards and Mooney, 1992 ] <author> B.L. Richards and R.J. Mooney. </author> <title> Learning Relations by Pathfinding. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 723-738, </pages> <year> 1992. </year>
Reference-contexts: Our research is concerned with how they can do this effectively. Extensive investigation of techniques for refining the knowledge held in a single knowledge base have already been carried out [ Ourston and Mooney, 1991 ] <ref> [ Richards and Mooney, 1992 ] </ref> [ Craw and Sleeman, 1991 ] . The process of refining multiple related knowledge bases, such as those of a group of agents, presents new challenges. The refinement of one agent's knowledge may affect other agents in the system.
Reference: [ Shoham, 1990 ] <author> Y. Shoham. </author> <title> Agent-Oriented Programming. </title> <type> Technical Report STAN-CS-1335-90, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1990. </year>
Reference-contexts: Agent-K is based on Agent-0 <ref> [ Shoham, 1990 ] </ref> . An Agent-K agent has a number of beliefs, capabilities and commitments. A belief is a logical statement which the agent "believes" to be true at a particular point in time. Beliefs may change over time. An agent's capabilities are the actions which it can perform.
References-found: 6

