URL: http://www.cs.ucla.edu/~goldman/tools_ai94.ps
Refering-URL: http://www.cs.ucla.edu/~goldman/papers.html
Root-URL: http://www.cs.ucla.edu
Title: Pattern Theoretic Knowledge Discovery  
Author: Jeffrey A. Goldman 
Address: WL/AART-2 Bldg 22 2690 C Street STE 1  45433-7408  
Affiliation: Wright-Laboratory  Wright-Patterson AFB, Ohio  
Abstract: Future research directions in Knowledge Discovery in Databases (KDD) include the ability to extract an overlying concept relating useful data. Current limitations involve the search complexity to find that concept and what it means to be "useful." The Pattern Theory research crosses over in a natural way to the aforementioned domain. The goal of this paper is threefold. First, we present a new approach to the problem of learning by Discovery and robust pattern finding. Second, we explore the current limitations of a Pattern Theoretic approach as applied to the general KDD problem. Third, we exhibit its performance with experimental results on binary functions, and we compare those results with C4.5. This new approach to learning demonstrates a powerful method for finding patterns in a robust manner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hussein Almuallim and Thomas G. Dietterich. </author> <title> Learning with many irrelevant features. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 547-552, </pages> <address> Anaheim, CA, 1990. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: If a larger function decomposed into more smaller sub-functions like F instead of less subfunctions like G, we can have a minimal decomposition be less useful than a decomposition which is not minimal. 2.2 FLASH's Strengths Irrelevant <ref> [1] </ref> fields (vacuous variables) are found easily in the decomposition process [6]. If the field is not present in the learned decomposition, then it has nothing to do with the pattern. For example, suppose a field is "pregnancy" but we are looking for patterns among men only.
Reference: [2] <author> Robert L. Ashenhurst. </author> <title> The decompositionof switching functions. </title> <booktitle> In Proceedings of the International Symposium on the Theory of Switching, </booktitle> <month> April </month> <year> 1957. </year>
Reference-contexts: It is noted that a given minimal decomposition is not unique. For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to <ref> [2] </ref> and [6]. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [6]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC.
Reference: [3] <author> David Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 177-221, </pages> <year> 1988. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning <ref> [3] </ref> [7] and switching theory [6]. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC).
Reference: [4] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, California, </address> <year> 1993. </year>
Reference-contexts: Specifically, we wish to demonstrate a correlation between DFC and the complexity of the pattern. Also, we compare learning ability in number of errors and in the concepts formed with the standard decision tree approach of C4.5 <ref> [4] </ref>. 3.1 Experimental Setup All of the learning curves were generated with the same decomposition strategy. The strategy was to search through all possible partitions from the top level, down to the evaluation of the cardinality of each function's subfunction, and in turn to its sub-function.
Reference: [5] <author> Timothy D. Ross, Jeffrey A. Goldman, David A. Gadd, Michael J. Noviskey, and Mark L. Axtell. </author> <title> On the decomposition of real-valued functions. </title> <booktitle> In Third International Workshop on Post-Binary ULSI Systems in affiliation with the Twenty-Fourth International Symposium on Multiple-Valued Logic, </booktitle> <year> 1994. </year>
Reference-contexts: However, since this approach has been proven to be valid for k valued fields, we will continue with this model without loss of generality [6]. In fact, our method has potential to generalize to continuous variables as well <ref> [5] </ref>. 3 Experimental Results The objective of this section is to present some functions indicative of concepts in a database and to show how the Pattern Theory approach is relevant to this domain. Specifically, we wish to demonstrate a correlation between DFC and the complexity of the pattern.
Reference: [6] <author> Timothy D. Ross, Michael J. Noviskey, Timothy N. Tay-lor, and David A. Gadd. </author> <title> Pattern theory: An engineering paradigm for algorithm design. </title> <type> Final Technical Report WL-TR-91-1060, </type> <institution> Wright Laboratory, USAF, </institution> <address> WL/AART, WPAFB, OH 45433-6543, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning [3] [7] and switching theory <ref> [6] </ref>. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC). <p> It is noted that a given minimal decomposition is not unique. For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to [2] and <ref> [6] </ref>. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [6]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC. <p> For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to [2] and <ref> [6] </ref>. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [6]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC. Moreover, "useful" concepts in databases correspond to functions that have a low DFC. The Function Learning And Synthesis Hot-Bed (FLASH) was developed to explore function decomposition, and pattern finding. <p> If a larger function decomposed into more smaller sub-functions like F instead of less subfunctions like G, we can have a minimal decomposition be less useful than a decomposition which is not minimal. 2.2 FLASH's Strengths Irrelevant [1] fields (vacuous variables) are found easily in the decomposition process <ref> [6] </ref>. If the field is not present in the learned decomposition, then it has nothing to do with the pattern. For example, suppose a field is "pregnancy" but we are looking for patterns among men only. <p> In our tests, we are simplifying the problem by only allowing binary valued fields. However, since this approach has been proven to be valid for k valued fields, we will continue with this model without loss of generality <ref> [6] </ref>. In fact, our method has potential to generalize to continuous variables as well [5]. 3 Experimental Results The objective of this section is to present some functions indicative of concepts in a database and to show how the Pattern Theory approach is relevant to this domain. <p> It is noted to the reader that many other kinds of "patterned" functions have been tested with FLASH besides Boolean Expressions. Some of them include symmetric functions, numerical functions, image functions, and string functions. For results with those types of functions, the reader is referred to Ross et al. <ref> [6] </ref>. The tests on the individual functions were as follows. First, each method was given a random set of data to train on ranging from 25 to 250 out of a total of 256 possible cases.
Reference: [7] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning [3] <ref> [7] </ref> and switching theory [6]. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC).
References-found: 7

