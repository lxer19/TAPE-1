URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/91-14.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Title: DIGITAL ANALOG SIMULATION OF UNIFORM MOTION IN REPRESENTATIONS OF PHYSICAL N-SPACE BY LATTICE-WORK MIMD COMPUTER ARCHITECTURES  
Author: Anil M. Shende 
Degree: a dissertation submitted to the faculty of the graduate school of  in partial fulfillment of the requirements for the degree of doctor of philosophy By  
Date: April 1991  
Address: new york  
Affiliation: state university of  
Abstract-found: 0
Intro-found: 1
Reference: [AC + 86] <author> Judy Anderson, William S. Coates, et al. FAIM-1: </author> <title> The General Architecture. </title> <type> Technical report, </type> <institution> Schlumberger Palo Alto Research, </institution> <month> April </month> <year> 1986. </year> <note> AI Technical Report No. 61. </note>
Reference-contexts: Since the evolution of parallel computing, a large number of parallel architectures have been proposed (e.g., [Ung58, Uhr72, Pea77, Tof77a, BWW81, Dye, Dye81, SS + 81, AS84, Hil84, Fun85, PF + 85, Sei85]). Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., <ref> [Hil84, Tof84, PF + 85, AC + 86] </ref>; also see [DL81, PU82, PD84, Lev85, Man] for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks).
Reference: [AG89] <author> George S. Almasi and Allan Gottlieb. </author> <title> Highly Parallel Computing. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1989. </year>
Reference-contexts: We first review, in Section 1.1, some of the current approaches, other than ours, for solving problems in scientific computing using parallelism. There we point out some of the disadvantages we see with these approaches. Then, in Section 1.2, we give an overview of this dissertation. 1.1 Previous Approaches <ref> [AG89, Qui87] </ref> indicate that parallel processing is of relevance to at least these scientific computing problems: fluid flow, computing a terrain map based on reflected signals from radar, weather prediction, molecular dynamics, tracing planetary motion, and the N -body problem. <p> Existing applications use analytical models of such phenomena and compute the unfolding. These models involve sets of equations. (See 1 The current group working on this project consists of Dr. John Case, Dr. Dayanand S. Rajan, and Anil M. Shende. CHAPTER 1. INTRODUCTION 3 <ref> [AG89] </ref>.) The attributes of the objects involved (location in space, mass, velocity, acceleration, etc.) are the parameter values for the set of equations in an analytic model for the phenomenon and the methods for solving this set of equations are the procedures. <p> As a consequence, the representation lacks some spatial attributes of these objects. For example, the distance, in the architecture being used, between two processors representing two different objects may be completely unrelated to the euclidean distance between the two represented objects in euclidean space (e.g., <ref> [AG89, N -body problem on the Cosmic Cube, page 367] </ref>). The representation of an object, within a processor, includes, as data, the co-ordinates of the object with respect to some fixed frame of reference attached to the region of euclidean space being represented. <p> For example, in the N -body problem, the force exerted by one body on another is a function of the euclidean distance between the two bodies. In the implementation of the solution on the Cosmic Cube <ref> [AG89] </ref>, these euclidean distances have to be computed based on the co-ordinates stored as a part of the representation of each body. <p> Thus, for example, inferring whether there is a collision during the unfolding may require an exhaustive search on the data structure (e.g., <ref> [AG89, N - body problem] </ref>). This needn't be required in our approach. Problems that have been considered for solutions using current approaches are from a wide variety of domains (graph-theoretic, numerical analysis, computational geometry, scientific computing, etc. [Qui87, AG89, Akl89]). <p> This needn't be required in our approach. Problems that have been considered for solutions using current approaches are from a wide variety of domains (graph-theoretic, numerical analysis, computational geometry, scientific computing, etc. <ref> [Qui87, AG89, Akl89] </ref>).
Reference: [Akl89] <author> Selim G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1989. </year>
Reference-contexts: This needn't be required in our approach. Problems that have been considered for solutions using current approaches are from a wide variety of domains (graph-theoretic, numerical analysis, computational geometry, scientific computing, etc. <ref> [Qui87, AG89, Akl89] </ref>).
Reference: [AS84] <author> N. Ahuja and S. Swamy. </author> <title> Multiprocessor pyramid architecture for bottom-up image analysis. </title> <journal> IEEE Trans. on PAMI, </journal> <volume> PAMI-6:463-474, </volume> <year> 1984. </year>
Reference-contexts: One of the key motivation for all parallel architectures is to reduce the computing time to solve problems. Some of these architectures were proposed with specific problems in mind (e.g., the pyramid for image processing <ref> [Uhr72, Dye, AS84] </ref>), but most of them were proposed for general-purpose problem solving. Parallel algorithm design is currently based on the architectural model being used [Qui87]. Data for a problem needs to be distributed appropriately so that algorithms may run efficiently on the corresponding target architecture. <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., <ref> [Uhr72, Dye, AS84, PF + 85] </ref>; also see [DL81, PU82, PD84, Lev85] for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [Aur90] <author> Franz Aurenhammer. </author> <title> Voronoi diagrams|a survey of a fundamental geometric data structure. </title> <type> Technical Report B-90-9, </type> <institution> Institute for Computer Science, Dept. of Mathematics, Freie Universitat Berlin, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: Similarly, some line and curve drawing algorithms in graphics turn out to light up a picture element (pixel) on a two dimensional square grid of pixels iff the line or curve passes through the Voronoi cell around the center of the pixel. <ref> [Aur90] </ref> is an excellent survey of all these applications of Voronoi cells. Almost all these applications are in two dimensions, and not specific to Voronoi cells around points in a lattice.
Reference: [Bro81] <author> R. Brooks. </author> <title> Symbolic reasoning among 3-d models and 2-d images. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 285-348, </pages> <year> 1981. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [Bur70] <editor> A. W. Burks, editor. </editor> <booktitle> Essays on Cellular Automata. </booktitle> <publisher> Univ. of Illinois Press, </publisher> <year> 1970. </year>
Reference-contexts: Furthermore, real space may be discrete, but admit of infinite regress, i.e., have no minimal distance between points. Herein, we model CHAPTER 2. OUR METHODOLOGY 20 space simply by computer meshes based on (certain) lattices (Section 1.2). The theory of Cellular Automata <ref> [Neu66, Bur70, Cod68] </ref> is a clean, theoretical model for representing discrete space, especially from the point of view of massively parallel processing. Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11].
Reference: [BWW81] <author> Adrian Bowyer, Philip J. Willis, and John R. Woodwark. </author> <title> A multiprocessor architecture for solving spatial problems. </title> <journal> The Computer Journal, </journal> <volume> 24(4) </volume> <pages> 353-357, </pages> <year> 1981. </year>
Reference: [Cod68] <author> E. F. Codd. </author> <title> Cellular Automata. </title> <publisher> Academic Press, </publisher> <year> 1968. </year> <note> 155 BIBLIOGRAPHY 156 </note>
Reference-contexts: Furthermore, real space may be discrete, but admit of infinite regress, i.e., have no minimal distance between points. Herein, we model CHAPTER 2. OUR METHODOLOGY 20 space simply by computer meshes based on (certain) lattices (Section 1.2). The theory of Cellular Automata <ref> [Neu66, Bur70, Cod68] </ref> is a clean, theoretical model for representing discrete space, especially from the point of view of massively parallel processing. Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11].
Reference: [Cox73] <author> H. S. M. Coxeter. </author> <title> Regular Polytopes. </title> <publisher> Dover Publications, </publisher> <year> 1973. </year>
Reference-contexts: We note here that the above definition of "tessellate" is not the same as the usual definition <ref> [Cox73] </ref>, although the basic concept is identical. Our definition is convenient for our purposes. 3.2 Representing Euclidean Space by Meshes In Section 3.2.1 we motivate (as in [CRS90a]) and formally define the class of regular lattices. <p> 2 Rel (D), the face, corresponding to R, of Voronoi ( ~ 0; D), denoted Face R ( ~ 0; D), is given by Face R ( ~ 0; D) = fx 2 Voronoi ( ~ 0; D) j (x; R) = (R; R)=2g: Note 3.4.1 It can be shown <ref> [CS88, Cox73] </ref> that Face R ( ~ 0; D), for any R 2 Rel (D), is a bounded, (n 1)-dimensional planar surface perpendicular to R. We now prove a few facts about relevant vectors in an n-dimensional lattice. Theorem 3.4.1 Rel (D) is finite. CHAPTER 3. PRELIMINARIES 40 Proof.
Reference: [CRS90a] <author> J. Case, D. S. Rajan, and A. M. Shende. </author> <title> Optimally representing euclidean space discretely for analogically simulating physical phenomena. </title> <booktitle> In Foundations of Software Technology & Theoretical Computer Science, volume 472 of Lecture Notes in Computer Science, </booktitle> <pages> pages 190-203. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: of the point in the representation D. (These informal properties are expressed somewhat more formally as Properties 3.2.1, 3.2.2, and 3.2.3 below.) The connection between these three properties and lattices is that D satisfies the three properties iff D is an n-dimensional lattice. (See Theorem 3.2.2.) We discuss this in <ref> [CRS90a] </ref> and in Chapter 3 below. In [CRS90a] we also discuss, in detail, a class of meshes associated with lattices having some additional especially nice properties. One of these additional properties, motivated, as was the lattice property, by both representing euclidean space well and computational cleanness, is a regularity property. <p> (These informal properties are expressed somewhat more formally as Properties 3.2.1, 3.2.2, and 3.2.3 below.) The connection between these three properties and lattices is that D satisfies the three properties iff D is an n-dimensional lattice. (See Theorem 3.2.2.) We discuss this in <ref> [CRS90a] </ref> and in Chapter 3 below. In [CRS90a] we also discuss, in detail, a class of meshes associated with lattices having some additional especially nice properties. One of these additional properties, motivated, as was the lattice property, by both representing euclidean space well and computational cleanness, is a regularity property. <p> In <ref> [CRS90a] </ref> it is essentially shown that A n is the unique (up to isomorphism) 14 n-dimensional regular lattice for which the number of immediate neighbors of any processor in the corresponding idealized mesh is greater than or equal to the number of nearest neighbors of any processor in the idealized mesh <p> A n also satisfies the following pleasing Property 1.2.3 which fails for some families of regular lattices. 13 By definition Z n is the set of n-tuples of integers, and A n is the set of (n + 1)-tuples of integers that add up to 0. 14 In <ref> [CRS90a] </ref> we do not make a distinction between A n and A n |we treat all lattices in A n equivalently. CHAPTER 1. <p> Chapter 3 Preliminaries In this chapter we define concepts and present useful facts about these concepts that we will use in this document. In Section 3.1 we set up notation, and define standard terms. Section 3.2.1 is essentially a summary of <ref> [CRS90a] </ref>. In that section, we discuss regular lattices and in Section 3.2.2 we discuss idealized meshes based on lattices. In Section 3.3 we present some technical observations regarding the presence of irrational euclidean distances in lattices. These observations are, necessarily, taken into account in Section 5.1. <p> We note here that the above definition of "tessellate" is not the same as the usual definition [Cox73], although the basic concept is identical. Our definition is convenient for our purposes. 3.2 Representing Euclidean Space by Meshes In Section 3.2.1 we motivate (as in <ref> [CRS90a] </ref>) and formally define the class of regular lattices. In that section we note that amongst n-dimensional regular lattices, lattices in A n have the largest number of basic directions. CHAPTER 3. PRELIMINARIES 29 In Section 3.2.2 we discuss idealized meshes based on lattices. <p> Definition 3.2.2 1. MinLgth (D) denotes the minimal distance of D. 2. For D, a lattice generated by its minimal length vectors, a vector in D of length MinLgth (D), is called a basic direction of D; the set of basic directions in D is denoted Dirs (D). In <ref> [CRS90a] </ref>, we impose the additional constraint that D be regular in the sense of the following property. <p> PRELIMINARIES 32 its calculation simplified is guaranteed by the existence of a regular basis. Furthermore, this makes computations more efficient, since the inner product of any pair of distinct basis vectors is a constant. We also proved, in <ref> [CRS90a] </ref>, essentially the following theorem whose direct consequence is that the n-dimensional lattice A n (see Example 3.2.1 above) is the unique (up to isomorphism) lattice that, among regular lattices, has the maximum number of basic directions. Our special interest in A n derives, in large part, from this result.
Reference: [CRS90b] <author> John Case, Dayanand S. Rajan, and Anil M. Shende. </author> <title> Parallel processor computer, </title> <month> December </month> <year> 1990. </year> <title> U.S. Patent Application submitted by SUNY, Research Foundation. </title>
Reference-contexts: Sometimes we will refer to a mesh-connected computer as a mesh computer or, simply, as a mesh. 5 The algorithms representing such particles would mostly be concerned with getting themselves moved, with appropriate timing, to adjacent processors so as to simulate motion of the particles they represent. 6 See also <ref> [CRS90b] </ref>. CHAPTER 1. INTRODUCTION 8 consider these algorithms to be basic to our approach, and expect to use these (or similar) algorithms for simulating the motion of physical objects. <p> 2 in the informal definition above of well-represented. 19 The algorithm template CURVE (Chapter 8), the basis for the algorithms in Chapter 9, requires more assumptions on the lattices associated with the idealized meshes, namely full well-representedness. 20 These assumptions are satisfied by our hardware design for individual processors in <ref> [CRS90b] </ref>. 21 By uniform we mean virtually constant speed. Deviations from constant speed are small, bounded, and occur only at the processors associated with those lattice points at irrational (relative to the minimal distance) euclidean distance from the source of the wave. <p> This does not cause any problem since the mesh still functions with bent connections as if it were part of a lattice. Having immediate connections be constant length can help ensure processor synchrony. We show in <ref> [CRS90b] </ref> that an embedding of M (A n ) into physical 3-space can be achieved with constant length direct communication links. We note an important fact about idealized meshes based on lattices, which we will use later in Section 4.3. <p> This discretizes time, for the mesh as a whole, into intervals of equal length. 1 For many hardware designs, for example, that of <ref> [CRS90b] </ref>, it suffices to implement (22) with a suitably chosen number, IT, of instruction cycles per pass. Such implementations are not, in general, particularly straightforward, so for simplicity here, we have assumed a hardware for which IT is 1. CHAPTER 4. <p> OPEN PROBLEMS 154 * Significantly speed up simulations by various sharpenings (including sharpen ings of our individual processor design in <ref> [CRS90b] </ref>). * Simplify simulations presented herein or produce new ones by examining "re gions of influence" other than Voronoi cells. * Examine the applicability, if any, to our methodology, of superimposing the dual of a lattice on a lattice. * Clarify more exactly the mathematical bounding relationships between MaxLinSpeed (K), for
Reference: [CS88] <author> J. H. Conway and N. J. A. Sloane. </author> <title> Sphere Packings, Lattices and Groups. </title> <publisher> Springer Verlag, </publisher> <year> 1988. </year>
Reference-contexts: If the interconnection scheme of a mesh computer is suitably patterned, we can define the idealized version of that mesh computer as its infinite continuation in every direction. In Section 3.2 we consider such idealized mesh computers based on lattices <ref> [GL87, CS88] </ref> and discuss the ill-defined problem of finding "n-dimensional" mesh computer interconnection schemes which provide "optimal" representations of corresponding regions of euclidean n-space. In Section 3.2.1 lattices are defined, and we discuss the problem of optimally representing euclidean spaces by lattices. <p> We choose certain discrete sets of points, D, from some perfect representation of euclidean n-space as those to be explicitly represented as processors in idealized meshes: we choose such D to be n-dimensional lattices <ref> [GL87, CS88] </ref>. 10 One of the important properties of any lattice (Property 3.2.2) is that there is a minimal distance between any two (distinct) points in that lattice. <p> INTRODUCTION 11 We will call n-dimensional lattices with Property 1.2.1 (or, equivalently, Property 3.2.4) regular. Z n and A n (see <ref> [CS88] </ref> 13 ) are examples of n-dimensional regular lattices. Idealized extensions of the meshes from the literature (square meshes [Mil89]) are usually associated with the lattice Z 2 . <p> It is perhaps surprising that there are n-dimensional lattices generated by their minimal length vectors which fail Property 1.2.2; the 4-dimensional lattice D 4 from <ref> [CS88] </ref> is an example. <p> Section 4.1 describes the lattices associated with the idealized versions of the interconnection schemes for the classes of mesh computers sufficient for (most of) our algorithms. These lattices are called well-represented. At the beginning of the 15 The formal definition is Definition 3.4.2. See also <ref> [CS88] </ref>. 16 See Proposition 3.4.2. CHAPTER 1. INTRODUCTION 13 next paragraph we sketch informally the definition of well-represented; the formal definition is Definition 4.1.4. As will be seen in Note 4.1.1, A n , the lattice we are especially interested in, turns out to be well-represented. <p> In Section 3.4 we formally define, and prove some useful properties of, Voronoi cells (introduced in Section 1.2) in a lattice. Except where noted otherwise, for proofs of theorems, lemmas, etc. stated in Sections 3.1, 3.2 and 3.4, see [Sim63], [GL87] and <ref> [CS88] </ref>, respectively; these books are general references for concepts defined and discussed in these sections. 3.1 Background Definitions and Notation We will use the following standard notation throughout the rest of this document. N denotes the set f0; 1; 2; . . .g. <p> In <ref> [CS88, GL87] </ref>, what is meant by "the Voronoi cell around a point P " is what we mean by "the closure of the Voronoi cell around P ". We define Voronoi cells as above only for our convenience. <p> 2 Rel (D), the face, corresponding to R, of Voronoi ( ~ 0; D), denoted Face R ( ~ 0; D), is given by Face R ( ~ 0; D) = fx 2 Voronoi ( ~ 0; D) j (x; R) = (R; R)=2g: Note 3.4.1 It can be shown <ref> [CS88, Cox73] </ref> that Face R ( ~ 0; D), for any R 2 Rel (D), is a bounded, (n 1)-dimensional planar surface perpendicular to R. We now prove a few facts about relevant vectors in an n-dimensional lattice. Theorem 3.4.1 Rel (D) is finite. CHAPTER 3. PRELIMINARIES 40 Proof. <p> It may be difficult to calculate the value of MPL s (L), for arbitrary well-represented lattices L. It is likely possible, though not easy, to calculate MPL s (L) for L in certain families of lattices (e.g., root lattices <ref> [CS88] </ref>) since, in these cases, there exist (often tedious) algorithms to generate the set, V (L), of vertices of Voronoi cells around the origin in L. Nonetheless, we can calculate MPL s (Z n ) and MPL s (A n ) rather easily. <p> Nonetheless, we can calculate MPL s (Z n ) and MPL s (A n ) rather easily. Clearly, V (Z n ) = f (z 1 ; . . . ; z n ) j 8i; 1 i n; z i = 1=2g: From <ref> [CS88] </ref> the set V (A n ) is given by V (A n ) = f (s 0 ; . . . ; s n ) j 9B f0; . . . ; ng; & (8i 2 (f0; . . . ; ng n B); s i = jBj=(n + 1))g: <p> set V (A n ) is given by V (A n ) = f (s 0 ; . . . ; s n ) j 9B f0; . . . ; ng; & (8i 2 (f0; . . . ; ng n B); s i = jBj=(n + 1))g: (See <ref> [CS88] </ref> for additional details about Voronoi cells around points in Z n and A n .) In Propositions 8.1.1 and 8.1.2 below, we give the values for MPL (Z n ) and MPL (A n ), respectively. <p> to one another, particles possibly doing different things from one another. * Extend algorithm CURVE to not necessarily constant speed cases and find algorithms which are instances of the extended version for curves more general than straight lines and circles. * Is there an interesting relation between the root lattices <ref> [CS88] </ref> and our well represented lattices? * Show how to compute MPL s (L) more generally. * Do simple physics problems with our methodology in meshes, e.g., motion of particles subjected to constant or other forces, three dimensional fluid flow prob lems, . . . . * Get analogs of WAVE
Reference: [DL81] <author> M. J. B. Duff and S. Levialdi, </author> <title> editors. Languages and Architectures for Image Processing. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see <ref> [DL81, PU82, PD84, Lev85, Man] </ref> for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., [Uhr72, Dye, AS84, PF + 85]; also see <ref> [DL81, PU82, PD84, Lev85] </ref> for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [Dye] <author> C. R. Dyer. </author> <title> A quadtree machine for parallel image processing. </title> <type> Technical Report KSL 51, </type> <institution> Univ. of Illinois at Chicago Circle. </institution>
Reference-contexts: One of the key motivation for all parallel architectures is to reduce the computing time to solve problems. Some of these architectures were proposed with specific problems in mind (e.g., the pyramid for image processing <ref> [Uhr72, Dye, AS84] </ref>), but most of them were proposed for general-purpose problem solving. Parallel algorithm design is currently based on the architectural model being used [Qui87]. Data for a problem needs to be distributed appropriately so that algorithms may run efficiently on the corresponding target architecture. <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., <ref> [Uhr72, Dye, AS84, PF + 85] </ref>; also see [DL81, PU82, PD84, Lev85] for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [Dye81] <author> C. R. Dyer. </author> <title> A VLSI pyramid machine for hierarchical parallel image processing. </title> <booktitle> PRIP, </booktitle> <pages> pages 381-386, </pages> <year> 1981. </year>
Reference: [Fey82] <author> Richard P. </author> <title> Feynman. Simulating physics with computers. </title> <journal> International Journal of Theoretical Physics, </journal> <volume> 21(6/7), </volume> <year> 1982. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
Reference: [FHP86] <author> U. Frisch, B. Hasslacher, and Y. Pomeau. </author> <title> Lattice-gas automata for the navier stokes equation. </title> <journal> Physical Review Letters, </journal> <volume> 56(14) </volume> <pages> 1505-1508, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: Lattice Gas models [Has87] are often studied using cellular automata to simulate complex physical phenomena. In a cellular automaton implementation of a Lattice Gas model, emphasis is placed on the simplicity of the local transition rule for the cellular automaton <ref> [FHP86] </ref>. Results are essentially computed by the statistical averaging of the states over cells in pre-determined "neighborhoods" in the cellular automaton [Has87]. Our methodology differs from Lattice Gas models in both these regards. We do not restrict ourselves to overly simple cellular automaton-like rules.
Reference: [For81] <author> K. Forbus. </author> <title> A study of qualitative and geometric knowledge in reasoning about motion. </title> <type> Technical Report AI.TR.615, </type> <institution> MIT, AI-Lab, </institution> <month> February </month> <year> 1981. </year> <note> BIBLIOGRAPHY 157 </note>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [For83] <author> K. Forbus. </author> <title> Qualitative reasoning about space and motion. </title> <editor> In D. Gentner and A. Stevens, editors, </editor> <title> Mental Models. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, N.J., </address> <year> 1983. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [FT82] <author> Edward Fredkin and Tommaso Toffoli. </author> <title> Conservative logic. </title> <journal> International Journal of Theoretical Physics, </journal> <volume> 21(3/4), </volume> <year> 1982. </year>
Reference: [Fun85] <author> Brian V. Funt. </author> <title> Problem-solving with diagrammatic representations. </title> <editor> In Ronald Brachman and Hector J. Levesque, editors, </editor> <booktitle> Readings in Knowledge Representation. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1985. </year>
Reference-contexts: Since the evolution of parallel computing, a large number of parallel architectures have been proposed (e.g., [Ung58, Uhr72, Pea77, Tof77a, BWW81, Dye, Dye81, SS + 81, AS84, Hil84, Fun85, PF + 85, Sei85]). Of these, some have been simulated in software (e.g., <ref> [Fun85] </ref>), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see [DL81, PU82, PD84, Lev85, Man] for extensive lists of existing machines).
Reference: [GL87] <author> Peter M. Gruber and Gerrit Lekkerkerker. </author> <title> Geometry of Numbers. </title> <publisher> North-Holland Mathematical Library, </publisher> <year> 1987. </year>
Reference-contexts: If the interconnection scheme of a mesh computer is suitably patterned, we can define the idealized version of that mesh computer as its infinite continuation in every direction. In Section 3.2 we consider such idealized mesh computers based on lattices <ref> [GL87, CS88] </ref> and discuss the ill-defined problem of finding "n-dimensional" mesh computer interconnection schemes which provide "optimal" representations of corresponding regions of euclidean n-space. In Section 3.2.1 lattices are defined, and we discuss the problem of optimally representing euclidean spaces by lattices. <p> We choose certain discrete sets of points, D, from some perfect representation of euclidean n-space as those to be explicitly represented as processors in idealized meshes: we choose such D to be n-dimensional lattices <ref> [GL87, CS88] </ref>. 10 One of the important properties of any lattice (Property 3.2.2) is that there is a minimal distance between any two (distinct) points in that lattice. <p> In Section 3.4 we formally define, and prove some useful properties of, Voronoi cells (introduced in Section 1.2) in a lattice. Except where noted otherwise, for proofs of theorems, lemmas, etc. stated in Sections 3.1, 3.2 and 3.4, see [Sim63], <ref> [GL87] </ref> and [CS88], respectively; these books are general references for concepts defined and discussed in these sections. 3.1 Background Definitions and Notation We will use the following standard notation throughout the rest of this document. N denotes the set f0; 1; 2; . . .g. <p> Property 3.2.3 Informally, an observer moved, without change of orientation, from any point in D to any other point in D will see the same picture. D is invariant under translations. Theorem 3.2.2 is essentially a combination of Theorems 1 and 2 proved in <ref> [GL87, Pages 18-19] </ref>, and characterizes the sets D that satisfy these three properties. Towards this, we first give the usual definition of lattices, and state some theorems about them. <p> In <ref> [CS88, GL87] </ref>, what is meant by "the Voronoi cell around a point P " is what we mean by "the closure of the Voronoi cell around P ". We define Voronoi cells as above only for our convenience.
Reference: [Gre72] <author> Donald Greenspan. </author> <title> A discrete numerical approach to fluid dynamics. </title> <journal> Information Processing, </journal> <volume> 71 </volume> <pages> 1297-1304, </pages> <year> 1972. </year>
Reference-contexts: Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11]. Most of these architectures are 2-dimensional square meshes. Greenspan and LaBudde <ref> [Gre72, Gre82, LG74] </ref> have positive results in discretiz-ing newtonian physics analytically. They formulate discrete mechanics as a system of difference equations corresponding to the differential equations of newtonian mechanics. This method of discrete mechanics could likely be adapted to be used in our approach.
Reference: [Gre82] <author> Donald Greenspan. </author> <title> Deterministic computer physics. </title> <journal> International Journal of Theoretical Physics, </journal> 21(6/7):505-523, 1982. 
Reference-contexts: On the other hand, there are phenomena, where the only apparent method for predicting the attribute values of the participating objects at any instant in time, is to simulate the unfolding of the phenomenon up through that instant in time <ref> [Gre82] </ref>. We are interested in using parallel computing for the prediction of physical phenomena to solve problems in scientific computing. <p> Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11]. Most of these architectures are 2-dimensional square meshes. Greenspan and LaBudde <ref> [Gre72, Gre82, LG74] </ref> have positive results in discretiz-ing newtonian physics analytically. They formulate discrete mechanics as a system of difference equations corresponding to the differential equations of newtonian mechanics. This method of discrete mechanics could likely be adapted to be used in our approach.
Reference: [Has87] <author> Brosl Hasslacher. </author> <title> Discrete fluids. </title> <journal> Los Alamos Science, </journal> (15):175-217, 1987. Special Issue. 
Reference-contexts: Our general approach is related to, but not the same as, the computational models of physics based on cellular automata [Sny47, Hil55, Ung58, Zus69, Tof77a, Tof77b, Fey82, FT82, Min82, Wol83, Mar84, Tof84, Vic84, Mac86, Svo86, SW86, TM87]. Lattice Gas models <ref> [Has87] </ref> are often studied using cellular automata to simulate complex physical phenomena. In a cellular automaton implementation of a Lattice Gas model, emphasis is placed on the simplicity of the local transition rule for the cellular automaton [FHP86]. <p> In a cellular automaton implementation of a Lattice Gas model, emphasis is placed on the simplicity of the local transition rule for the cellular automaton [FHP86]. Results are essentially computed by the statistical averaging of the states over cells in pre-determined "neighborhoods" in the cellular automaton <ref> [Has87] </ref>. Our methodology differs from Lattice Gas models in both these regards. We do not restrict ourselves to overly simple cellular automaton-like rules.
Reference: [Hei58] <author> Werner Heisenberg. </author> <title> Physics and Philosophy. </title> <publisher> Harper & Brothers Publishers, </publisher> <address> New York, </address> <year> 1958. </year>
Reference-contexts: Regarding spatial (and other) problems [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations. Heisenberg <ref> [Hei58, pages 164-165] </ref> argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] take this idea seriously.
Reference: [Hil55] <author> E. L. Hill. </author> <title> Relativistic theory of discrete momentum space and discrete space-time. </title> <journal> Physical Review, </journal> <volume> 100(6), </volume> <month> December </month> <year> 1955. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
Reference: [Hil84] <author> W. Daniel Hillis. </author> <title> The connection machine: A computer architecture based on cellular automata. </title> <journal> Physica 10D, </journal> <pages> pages 213-228, </pages> <year> 1984. </year>
Reference-contexts: Since the evolution of parallel computing, a large number of parallel architectures have been proposed (e.g., [Ung58, Uhr72, Pea77, Tof77a, BWW81, Dye, Dye81, SS + 81, AS84, Hil84, Fun85, PF + 85, Sei85]). Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., <ref> [Hil84, Tof84, PF + 85, AC + 86] </ref>; also see [DL81, PU82, PD84, Lev85, Man] for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., <ref> [Hil84] </ref>; see [Sie85] for a discussion of interconnection networks). With respect to current technology, three categories are usually used to describe the size of these architectures [Mil89, Chapter 1]: coarse-grained, medium-grained and fine-grained.
Reference: [Hin79] <author> G. Hinton. </author> <title> Some demonstrations of the effects of structural descriptions in mental imagery. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 231-250, </pages> <year> 1979. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [Kos80] <author> Stephen M. Kosslyn. </author> <title> Image and Mind. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1980. </year> <note> BIBLIOGRAPHY 158 </note>
Reference-contexts: The human reaction times produced are invariably linear in the real-time to physically carry out actual real-world rotation of shapes for matching, the folding of boxes, etc. <ref> [SC82, Kos80, Kos83] </ref>. This suggests that if one were to model, at a high level , human, non-verbal, spatial cognition, simulations of such spatial operations, as mentioned above, should be linear in real-time.
Reference: [Kos83] <author> Stephen M. Kosslyn. </author> <title> Ghosts in the Mind's Machine: Creating and Using Images in the Brain. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: The human reaction times produced are invariably linear in the real-time to physically carry out actual real-world rotation of shapes for matching, the folding of boxes, etc. <ref> [SC82, Kos80, Kos83] </ref>. This suggests that if one were to model, at a high level , human, non-verbal, spatial cognition, simulations of such spatial operations, as mentioned above, should be linear in real-time.
Reference: [Lev85] <author> S. Levialdi, </author> <title> editor. Integrated Technology for Parallel Image Processing. </title> <publisher> Academic Press, Inc., </publisher> <year> 1985. </year>
Reference-contexts: Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see <ref> [DL81, PU82, PD84, Lev85, Man] </ref> for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., [Uhr72, Dye, AS84, PF + 85]; also see <ref> [DL81, PU82, PD84, Lev85] </ref> for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [LG74] <author> Robert A. LaBudde and Donald Greenspan. </author> <title> Discrete mechanics|a general treatment. </title> <journal> Journal of Computational Physics, </journal> <volume> 15 </volume> <pages> 134-167, </pages> <year> 1974. </year>
Reference-contexts: Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11]. Most of these architectures are 2-dimensional square meshes. Greenspan and LaBudde <ref> [Gre72, Gre82, LG74] </ref> have positive results in discretiz-ing newtonian physics analytically. They formulate discrete mechanics as a system of difference equations corresponding to the differential equations of newtonian mechanics. This method of discrete mechanics could likely be adapted to be used in our approach.
Reference: [LS87] <author> J. Larkin and H. Simon. </author> <title> Why a picture is (sometimes) worth ten thousand words. </title> <booktitle> Cognitive Science, </booktitle> <year> 1987. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [Mac86] <author> Thinking Machines. </author> <title> Introduction to data level parallelism. </title> <type> Technical Report 86.14, </type> <institution> Thinking Machines, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: The difference equations of this method could very likely be modified into algorithms for computing "next" position/attributes of particles at each, discretely represented, point in the representation of the actual, euclidean trajectory of motion. We note that the 2-dimensional, literal , fluid flow simulations on the Connection Machine <ref> [Mac86, SW86] </ref> were quite successful. This strengthens our belief in the use of literal representations in simulating physical phenomena. Chapter 3 Preliminaries In this chapter we define concepts and present useful facts about these concepts that we will use in this document.
Reference: [Man] <author> Tom Manuel. </author> <title> Supercomputers: The proliferation begins. </title> <publisher> Electronics, </publisher> <pages> pages 51-56. </pages> <month> March 3, </month> <year> 1988. </year>
Reference-contexts: Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see <ref> [DL81, PU82, PD84, Lev85, Man] </ref> for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks).
Reference: [Man76] <author> M. Morris Mano. </author> <title> Computer System Architecture. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> New Jersey, </address> <year> 1976. </year>
Reference-contexts: For P in D, we will use the notation M (P ) to denote M (fP g). The individual processors in M (D) could have usual Von-Neumann architectures <ref> [Man76] </ref>, but with certain special abilities. Below, we list the general assumptions about the idealized hardware of M (D). CHAPTER 4. WELL-REPRESENTED LATTICES AND MESHES 58 Assumption 4.3.2 All connections in M (D) are identical in their abilities to carry data between processors.
Reference: [Mar84] <author> Norman Margolus. </author> <title> Physics-like models of computation. </title> <journal> Physica 10D, </journal> <pages> pages 81-95, </pages> <year> 1984. </year>
Reference: [MD84] <author> D. McDermott and E. Davis. </author> <title> Planning routes through uncertain territory. </title> <journal> Artificial Intelligence, </journal> <volume> 22 </volume> <pages> 107-156, </pages> <year> 1984. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [Mil89] <author> Susan E. Miller. </author> <title> A survey of parallel computing 2 nd edition. </title> <type> Technical Report RADC-TR-89-68, </type> <institution> Rome Air Development Center, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). With respect to current technology, three categories are usually used to describe the size of these architectures <ref> [Mil89, Chapter 1] </ref>: coarse-grained, medium-grained and fine-grained. Further, they can be divided into three categories with respect to their mode of operation [Mil89, Chapter 1]: Single Instruction Single Data Stream (SISD), Single Instruction Multiple Data stream (SIMD) and Multiple Instruction Multiple Data stream (MIMD); usually, coarse-grained machines operate in MIMD mode <p> With respect to current technology, three categories are usually used to describe the size of these architectures <ref> [Mil89, Chapter 1] </ref>: coarse-grained, medium-grained and fine-grained. Further, they can be divided into three categories with respect to their mode of operation [Mil89, Chapter 1]: Single Instruction Single Data Stream (SISD), Single Instruction Multiple Data stream (SIMD) and Multiple Instruction Multiple Data stream (MIMD); usually, coarse-grained machines operate in MIMD mode and fine-grained machines operate in SIMD mode. <p> Applications running on coarse-grained machines, typically, have a small number of parallel processes (one per processor), where each process is responsible for a suitable portion of the data. A host machine communicates with all the processes, collecting the partial results and combining them into a final result. (See <ref> [Mil89, Chapter 1] </ref>.) Applications running on fine-grained machines first distribute data among the processors (typically a small portion of data per processor), and then a host machine broadcasts instructions, one at a time, to all the processors simultaneously. At any CHAPTER 1. <p> At any CHAPTER 1. INTRODUCTION 4 instant in time, all processors execute the same instruction on their respective data items. The final configuration of data/results among the processors is the final result. (See <ref> [Mil89, Chapter 1] </ref>.) In this dissertation, we are mainly concerned with architectures having a very large number of processors. So, we will not discuss approaches to scientific computing using coarse-grained architectures. <p> Because of the basic nature of these physical phenomena, we 4 For us a mesh-connected computer consists of a finite number of processors locally interconnected for communication. Our use of the term `mesh-connected computer' is more general than its usage in the literature (see <ref> [Mil89] </ref>). In particular we do not restrict ourselves to meshes where the interconnection scheme is a square grid with processors at grid points. <p> INTRODUCTION 11 We will call n-dimensional lattices with Property 1.2.1 (or, equivalently, Property 3.2.4) regular. Z n and A n (see [CS88] 13 ) are examples of n-dimensional regular lattices. Idealized extensions of the meshes from the literature (square meshes <ref> [Mil89] </ref>) are usually associated with the lattice Z 2 . As will be seen below, we are particularly interested in the n-dimensional lattices from the class, A n , of lattices isomorphic to A n .
Reference: [Min82] <author> Marvin Minsky. </author> <title> Cellular vacuum. </title> <journal> International Journal of Theoretical Physics, </journal> <volume> 21(6/7), </volume> <year> 1982. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously. <p> Of course, if the universe is really discrete, it is not clear whether the interconnection scheme of real space is nicely patterned, and if so with what pattern, whether it is unpatterned, whether it changes with time, . . . <ref> [Min82] </ref>. Furthermore, real space may be discrete, but admit of infinite regress, i.e., have no minimal distance between points. Herein, we model CHAPTER 2. OUR METHODOLOGY 20 space simply by computer meshes based on (certain) lattices (Section 1.2).
Reference: [MS88] <author> Russ Miller and Quentin F. Stout. </author> <title> Efficient parallel convex hull algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37(12):1605-1618, </volume> <month> December </month> <year> 1988. </year> <note> BIBLIOGRAPHY 159 </note>
Reference-contexts: general as well as for scientific applications, is that of sorting (e.g., sorting points in euclidean space by their x-coordinates is a step in computing the convex hull of a set of points in euclidean space [MS89]|convex hulls are used in topological feature extraction, normalizing patterns in image processing, etc. <ref> [MS88] </ref>). For sorting, the maximum of the path lengths between any two pieces of data in the architecture becomes of paramount importance because this length places a worst-case lower bound on the amount of time required to move a data item to its destination in the sorted sequence.
Reference: [MS89] <author> Russ Miller and Quentin F. Stout. </author> <title> Mesh computer algorithms for computational geometry. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-38(3):321-340, </volume> <month> March </month> <year> 1989. </year>
Reference: [Neu66] <author> J. Von Neumann. </author> <title> Theory of Self-Reproducing Automata. </title> <publisher> Univ. Illinois Press, </publisher> <year> 1966. </year> <title> edited and compiled by A. </title> <publisher> W. Burks. </publisher>
Reference-contexts: Furthermore, real space may be discrete, but admit of infinite regress, i.e., have no minimal distance between points. Herein, we model CHAPTER 2. OUR METHODOLOGY 20 space simply by computer meshes based on (certain) lattices (Section 1.2). The theory of Cellular Automata <ref> [Neu66, Bur70, Cod68] </ref> is a clean, theoretical model for representing discrete space, especially from the point of view of massively parallel processing. Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing [PD84, Chaps. 10 & 11].
Reference: [Niv56] <author> Ivan Niven. </author> <title> Irrational Numbers. </title> <booktitle> Number 11 in The Carus Matematical Monographs. The Mathematical Association of America, </booktitle> <year> 1956. </year>
Reference-contexts: By the following result, essentially from <ref> [Niv56, Page 41] </ref>, we cannot have arbitrarily small, positive, rational multiples of with rational sine or cosine.
Reference: [PD84] <author> Kendall Preston and M. J. B. Duff. </author> <title> Modern Cellular Automata: Theory and Applications. </title> <publisher> Plenum Publishers, </publisher> <year> 1984. </year>
Reference-contexts: Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see <ref> [DL81, PU82, PD84, Lev85, Man] </ref> for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., [Uhr72, Dye, AS84, PF + 85]; also see <ref> [DL81, PU82, PD84, Lev85] </ref> for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind. <p> The theory of Cellular Automata [Neu66, Bur70, Cod68] is a clean, theoretical model for representing discrete space, especially from the point of view of massively parallel processing. Several cellular automata based architectures have been proposed and built for problems in discrete physics [TM87] and medical image processing <ref> [PD84, Chaps. 10 & 11] </ref>. Most of these architectures are 2-dimensional square meshes. Greenspan and LaBudde [Gre72, Gre82, LG74] have positive results in discretiz-ing newtonian physics analytically. They formulate discrete mechanics as a system of difference equations corresponding to the differential equations of newtonian mechanics.
Reference: [Pea77] <author> Marshall C. Pease III. </author> <title> The indirect binary n-cube microprocessor array. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-26(5):458-473, </volume> <month> May </month> <year> 1977. </year>
Reference: [PF + 85] <author> John Poulton, Henry Fuchs, et al. PIXEL-PLANES: </author> <title> Building a VLSI-based graphic system. </title> <booktitle> In Chapel Hill Conference on VLSI, </booktitle> <year> 1985. </year>
Reference-contexts: Since the evolution of parallel computing, a large number of parallel architectures have been proposed (e.g., [Ung58, Uhr72, Pea77, Tof77a, BWW81, Dye, Dye81, SS + 81, AS84, Hil84, Fun85, PF + 85, Sei85]). Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., <ref> [Hil84, Tof84, PF + 85, AC + 86] </ref>; also see [DL81, PU82, PD84, Lev85, Man] for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., <ref> [Uhr72, Dye, AS84, PF + 85] </ref>; also see [DL81, PU82, PD84, Lev85] for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [PU82] <author> Kendall Preston and Leonard Uhr, </author> <title> editors. Multicomputers and Image Processing: Algorithms and Programs. </title> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., [Hil84, Tof84, PF + 85, AC + 86]; also see <ref> [DL81, PU82, PD84, Lev85, Man] </ref> for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks). <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., [Uhr72, Dye, AS84, PF + 85]; also see <ref> [DL81, PU82, PD84, Lev85] </ref> for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [Qui87] <author> Michael J. Quinn. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1987. </year>
Reference-contexts: We first review, in Section 1.1, some of the current approaches, other than ours, for solving problems in scientific computing using parallelism. There we point out some of the disadvantages we see with these approaches. Then, in Section 1.2, we give an overview of this dissertation. 1.1 Previous Approaches <ref> [AG89, Qui87] </ref> indicate that parallel processing is of relevance to at least these scientific computing problems: fluid flow, computing a terrain map based on reflected signals from radar, weather prediction, molecular dynamics, tracing planetary motion, and the N -body problem. <p> Some of these architectures were proposed with specific problems in mind (e.g., the pyramid for image processing [Uhr72, Dye, AS84]), but most of them were proposed for general-purpose problem solving. Parallel algorithm design is currently based on the architectural model being used <ref> [Qui87] </ref>. Data for a problem needs to be distributed appropriately so that algorithms may run efficiently on the corresponding target architecture. There is a "semantic gap" between the problem at hand and the architecture being used, and algorithms bridge this gap. <p> This needn't be required in our approach. Problems that have been considered for solutions using current approaches are from a wide variety of domains (graph-theoretic, numerical analysis, computational geometry, scientific computing, etc. <ref> [Qui87, AG89, Akl89] </ref>).
Reference: [SC82] <author> R. N. Shepard and L. A. Cooper. </author> <title> Mental Images and Their Transformations. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1982. </year>
Reference-contexts: The human reaction times produced are invariably linear in the real-time to physically carry out actual real-world rotation of shapes for matching, the folding of boxes, etc. <ref> [SC82, Kos80, Kos83] </ref>. This suggests that if one were to model, at a high level , human, non-verbal, spatial cognition, simulations of such spatial operations, as mentioned above, should be linear in real-time.
Reference: [SC + 83] <editor> R. S. Stepleman, M. Carver, et al., editors. </editor> <publisher> Scientific Computing. North-Holland Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: Introduction Stepleman <ref> [SC + 83, Introduction, page v] </ref> defines scientific computing as: The coordination of mathematics and computing for the modeling of phys ical reality. In this dissertation, we assume that physical reality can be modeled as taking place in euclidean n-space, for various n.
Reference: [Sei85] <author> C. Seitz. </author> <title> The cosmic cube. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 22-23, </pages> <year> 1985. </year>
Reference: [Sel88] <author> B. Selman. </author> <title> Analogues. </title> <type> Technical report, </type> <institution> University of Toronto, </institution> <year> 1988. </year> <note> Technical Note CSRI-47. BIBLIOGRAPHY 160 </note>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence <ref> [Sel88] </ref>, classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. <p> Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [SF72] <author> R. N. Shepard and C. Feng. </author> <title> A chronometric study of mental paperfolding. </title> <journal> Cognitive Psychology, </journal> <volume> 3 </volume> <pages> 228-243, </pages> <year> 1972. </year>
Reference-contexts: The experiments of interest involve human subjects performing tasks ostensibly requiring dynamic mental imagery (e.g., mentally checking congruence of pairs of complex 3-dimensional shapes [SM71], the mental solving of box folding puzzles <ref> [SF72] </ref>, etc.). The human reaction times produced are invariably linear in the real-time to physically carry out actual real-world rotation of shapes for matching, the folding of boxes, etc. [SC82, Kos80, Kos83].
Reference: [Sie85] <author> Howard Jay Siegel. </author> <title> Interconnection Networks for Large-Scale Parallel Processing. </title> <publisher> Lexington Books, </publisher> <year> 1985. </year>
Reference-contexts: Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see <ref> [Sie85] </ref> for a discussion of interconnection networks). With respect to current technology, three categories are usually used to describe the size of these architectures [Mil89, Chapter 1]: coarse-grained, medium-grained and fine-grained.
Reference: [Sim63] <author> G. F. Simmons. </author> <title> Introduction to Topology and Modern Analysis. </title> <publisher> McGraw-Hill, </publisher> <year> 1963. </year>
Reference-contexts: These observations are, necessarily, taken into account in Section 5.1. In Section 3.4 we formally define, and prove some useful properties of, Voronoi cells (introduced in Section 1.2) in a lattice. Except where noted otherwise, for proofs of theorems, lemmas, etc. stated in Sections 3.1, 3.2 and 3.4, see <ref> [Sim63] </ref>, [GL87] and [CS88], respectively; these books are general references for concepts defined and discussed in these sections. 3.1 Background Definitions and Notation We will use the following standard notation throughout the rest of this document. N denotes the set f0; 1; 2; . . .g.
Reference: [Slo71] <author> Aaron Sloman. </author> <title> Interactions between philosophy and A.I.|the role of intuition and non-logical reasoning in intelligence. </title> <booktitle> Proceedings 2 nd IJCAI, </booktitle> <year> 1971. </year>
Reference-contexts: Simulations of such tasks using our literal transformations would be (approximately) linear in real-time, matching the human case. B. Selman, in his survey on reasoning with analogs in Artificial Intelligence [Sel88], classifies spatial knowledge representation by analogs as vivid and pictorial . Regarding spatial (and other) problems <ref> [Slo71, For81, For83, Hin79, Bro81, MD84, LS87, Sel88] </ref> emphasize the computational complexity savings in certain examples resulting from vivid (and non-vivid) analog processing and/or point out the inefficiency of propositional or relational representations. Their arguments apply even more to our literal representations.
Reference: [SM71] <author> R. N. Shepard and J. Metzler. </author> <title> Mental rotation of three-dimensional objects. </title> <journal> Science, </journal> <volume> 171(4) </volume> <pages> 701-703, </pages> <year> 1971. </year>
Reference-contexts: CHAPTER 2. OUR METHODOLOGY 19 2.2 Motivations For Our Approach The initial motivation came from some results in Experimental Psychology. The experiments of interest involve human subjects performing tasks ostensibly requiring dynamic mental imagery (e.g., mentally checking congruence of pairs of complex 3-dimensional shapes <ref> [SM71] </ref>, the mental solving of box folding puzzles [SF72], etc.). The human reaction times produced are invariably linear in the real-time to physically carry out actual real-world rotation of shapes for matching, the folding of boxes, etc. [SC82, Kos80, Kos83].
Reference: [Sny47] <author> Hartland S. Snyder. </author> <title> Quantized space-time. </title> <journal> Physical Review, </journal> <volume> 71(1) </volume> <pages> 38-41, </pages> <year> 1947. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
Reference: [SS + 81] <editor> H. J. Siegel, L. J. Siegel, et al. PASM: </editor> <title> A partitionable SIMD/MIMD system for image processing and pattern recognition. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-30:934-947, </volume> <year> 1981. </year>
Reference-contexts: Medium-grained machines opt for one of the two modes and some allow the user a choice (for an example of the latter see <ref> [SS + 81] </ref>). All single processor systems typically operate in SISD mode. Applications running on coarse-grained machines, typically, have a small number of parallel processes (one per processor), where each process is responsible for a suitable portion of the data.
Reference: [Svo86] <author> Karl Svozil. </author> <title> Are quantum fields cellular automata? Physics Letters A, </title> <type> 119(4), </type> <month> December </month> <year> 1986. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
Reference: [SW86] <author> James B. Salem and S. Wolfram. </author> <title> Thermodynamics and hydrodynamics with cellular automata. </title> <editor> In S. Wolfram, editor, </editor> <title> Theory and Applications of Cellular Automata. </title> <publisher> World Scientific, </publisher> <year> 1986. </year>
Reference-contexts: The difference equations of this method could very likely be modified into algorithms for computing "next" position/attributes of particles at each, discretely represented, point in the representation of the actual, euclidean trajectory of motion. We note that the 2-dimensional, literal , fluid flow simulations on the Connection Machine <ref> [Mac86, SW86] </ref> were quite successful. This strengthens our belief in the use of literal representations in simulating physical phenomena. Chapter 3 Preliminaries In this chapter we define concepts and present useful facts about these concepts that we will use in this document.
Reference: [TM87] <author> Tommaso Toffoli and Norman Margolus. </author> <title> Cellular Automata Machines. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously. <p> The theory of Cellular Automata [Neu66, Bur70, Cod68] is a clean, theoretical model for representing discrete space, especially from the point of view of massively parallel processing. Several cellular automata based architectures have been proposed and built for problems in discrete physics <ref> [TM87] </ref> and medical image processing [PD84, Chaps. 10 & 11]. Most of these architectures are 2-dimensional square meshes. Greenspan and LaBudde [Gre72, Gre82, LG74] have positive results in discretiz-ing newtonian physics analytically. They formulate discrete mechanics as a system of difference equations corresponding to the differential equations of newtonian mechanics.
Reference: [Tof77a] <author> Tommaso Toffoli. </author> <title> Cellular automata machines. </title> <type> Technical Report 208, </type> <institution> Comp. Comm. Sci. Dept., University of Michigan, </institution> <year> 1977. </year> <note> BIBLIOGRAPHY 161 </note>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
Reference: [Tof77b] <author> Tommaso Toffoli. </author> <title> Computation and construction universality of reversible cellular automata. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 15 </volume> <pages> 213-231, </pages> <year> 1977. </year>
Reference: [Tof84] <author> Tommaso Toffoli. </author> <title> CAM: A high-performance cellular-automaton machine. </title> <journal> Physica 10D, </journal> <pages> pages 195-204, </pages> <year> 1984. </year>
Reference-contexts: Since the evolution of parallel computing, a large number of parallel architectures have been proposed (e.g., [Ung58, Uhr72, Pea77, Tof77a, BWW81, Dye, Dye81, SS + 81, AS84, Hil84, Fun85, PF + 85, Sei85]). Of these, some have been simulated in software (e.g., [Fun85]), and some have been built (e.g., <ref> [Hil84, Tof84, PF + 85, AC + 86] </ref>; also see [DL81, PU82, PD84, Lev85, Man] for extensive lists of existing machines). Some of these machines dynamically achieve their interconnection patterns with the aid of interconnection (switching) networks (e.g., [Hil84]; see [Sie85] for a discussion of interconnection networks).
Reference: [Uhr72] <author> L. Uhr. </author> <title> Layered `recognition cone' networks that preprocess, classify, and describe. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-21:758-768, </volume> <year> 1972. </year>
Reference-contexts: One of the key motivation for all parallel architectures is to reduce the computing time to solve problems. Some of these architectures were proposed with specific problems in mind (e.g., the pyramid for image processing <ref> [Uhr72, Dye, AS84] </ref>), but most of them were proposed for general-purpose problem solving. Parallel algorithm design is currently based on the architectural model being used [Qui87]. Data for a problem needs to be distributed appropriately so that algorithms may run efficiently on the corresponding target architecture. <p> Further, most architectures that have been developed are not domain-specific. 3 Hence, software implementations of algorithms to solve these problems use some general-purpose language 3 Image processing seems to be the only area for which there are domain-specific parallel architectures, e.g., <ref> [Uhr72, Dye, AS84, PF + 85] </ref>; also see [DL81, PU82, PD84, Lev85] for extensive lists of machines. CHAPTER 1. INTRODUCTION 7 available on the machine. Algorithms are not developed with any particular programming language in mind.
Reference: [Ung58] <author> S. H. Unger. </author> <title> A computer oriented towards spatial problems. </title> <booktitle> In Proceedings of the IRE, </booktitle> <volume> volume 46, </volume> <pages> pages 1744-1750, </pages> <year> 1958. </year>
Reference: [Vic84] <author> Gerard Y. Vichniac. </author> <title> Simulating physics with cellular automata. </title> <journal> Physica 10D, </journal> <pages> pages 96-116, </pages> <year> 1984. </year>
Reference: [Wol83] <author> Stephen Wolfram. </author> <title> Statistical mechanics of cellular automata. </title> <journal> Reviews of Modern Physics, </journal> <volume> 55(3) </volume> <pages> 601-644, </pages> <month> July </month> <year> 1983. </year>
Reference: [Zus69] <author> K. Zuse. Rechnender Raum. Vieweg, Braunshweig, </author> <year> 1969. </year> <title> Translated as Calculating Space, </title> <type> Tech. </type> <institution> Transl. AZT-70-164-GEMIT, MIT Project MAC, </institution> <year> 1970. </year>
Reference-contexts: Their arguments apply even more to our literal representations. Heisenberg [Hei58, pages 164-165] argues that there must exist a universal constant in nature|the smallest length. This might mean that the universe, including space, is discrete. Some of the workers in discrete physics <ref> [Sny47, Zus69, Tof77a, Fey82, Min82, Hil55, Svo86, TM87] </ref> take this idea seriously.
References-found: 73

