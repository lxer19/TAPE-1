URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/konig/qual_proposal.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/konig/
Root-URL: http://www.icsi.berkeley.edu
Title: Acoustic Modeling in Continuous Speech Recognition A Connectionist Approach  
Author: Yochai Konig 
Date: October 1994  
Abstract: We are currently studying acoustic models for continuous speech recognition. These models represent the stochastic generation of feature vectors for an utterance, where a feature vector represents a short interval of speech, typically around 20ms. Our current emphasis is on devising stochastic models that overcome some of the principal limitations of Hidden Markov Models (HMMs). Some of these limitations include an inability to model non-stationarities within a speech segment, assumed independence between acoustic vectors within a state, and lack of local discrimination between similar sounds. Our work is related to that of a number of researchers who are attempting to overcome these limitations. Like a number of these researchers, we are interested in non-stationary modeling within a segment corresponding to a general speech category (e.g., phoneme). Our work differs in that we are considering stochastic models that use a posteriori probabilities, which are generated by a Multi-Layer Perceptron (MLP). In one study, we have modeled the dynamics within a speech segment using temporal position as an explicit variable. This time index model explicitly conditions the emission probability of a state on the time index, where time index is defined as the number of frames since entering a state until the current frame. The lesson from the pilot experiments is that the approach can greatly reduce error if we have good information about the phoneme boundary location. Currently we are experimenting with other discriminant models. We report here on the limitations and theoretical solutions, and suggest a line of research to investigate their practicality. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and N. Morgan. </author> <title> Connectionist Speech Recognition A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Specifically we return to the original work on hybrid models that combine HMMs and MLPs <ref> [1] </ref> and reexamine the assumptions that have been made to make it work. The original formulation has the advantage of being globally discriminant between competing utterances and thus being closer to the ideal Bayes classifier. We report about our experiments in section 5. <p> One solution would be to assume a parametric form for the trajectory, as was done by Deng. In our case, we have chosen to use a multilayer perceptron (MLP) approach, which in our previous work at ICSI, has proved useful for such estimates <ref> [1] </ref>. 4 The Time Index Model Implementation and Experiments 4.1 An Implementation of the Time Index Model In our model we define the emission probability of a state as P (xjq j ; ti) . <p> With the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in <ref> [1] </ref>. For the preliminary tests, we assumed knowledge of the boundaries between the phones as produced by an automatic alignment (Viterbi) procedure on the known word string [15]. <p> When we change the parameters of one model we have to modify the parameters of all other models according to the MAP approach, unlike the MLE approach. In this work, we investigate the model (referred to as Discriminant HMM in <ref> [1] </ref>) that is trained according to the MAP criteria. In [1] work it is also shown that the global MAP probability P (M i jX) can actually be expressed in terms of local acoustic probabilities like p (q n ` n 1 ; q n2 ` 1 ) (10) in which <p> In this work, we investigate the model (referred to as Discriminant HMM in <ref> [1] </ref>) that is trained according to the MAP criteria. In [1] work it is also shown that the global MAP probability P (M i jX) can actually be expressed in terms of local acoustic probabilities like p (q n ` n 1 ; q n2 ` 1 ) (10) in which q n ` n represents the state at time n <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> [1] </ref>. Our reference HMM/MLP system [1] (with optimized phone transition penalty) had 36.3% phone error on this task. <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> [1] </ref>. Our reference HMM/MLP system [1] (with optimized phone transition penalty) had 36.3% phone error on this task. When using MLP conditional transition probabilities (Equation10) on this task, without division by prior probabilities (as done with the standard HMM/MLP approach) and without any phone transition penalty, the error rate was 41.0%.
Reference: [2] <author> Herve Bourlard, Nelson Morgan, Chuck Wooters, and Steve Renals. </author> <title> Cdnn: A context dependent neural network for continuous speech recognition. </title> <booktitle> In Proceedings IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, California, </address> <month> March </month> <year> 1992. </year> <note> IEEE. </note>
Reference: [3] <author> P. F. Brown. </author> <title> The Acoustic-Modelling Problem in Automatic Speech Recognition. </title> <type> PhD thesis, </type> <address> CMU, Pittsburgh, PA, </address> <month> May </month> <year> 1987. </year> <month> 16 </month>
Reference-contexts: Another limitation of the HMM is that its standard training criterion is non discriminant. For every training sentence we maximize the likelihood of the correct model, without reducing the likelihoods of all the wrong models. Brown <ref> [3] </ref> has suggested a discriminant 3 training criteria, to maximize the mutual information between the observation sequence to the correct model. 1.4 Preview In the next section we review related work in non-stationary modeling that attempt to overcome the i.i.d assumption of the HMMs.
Reference: [4] <author> L. Deng. </author> <title> A generalized hidden markov model with state-conditioned trend functions of time for the speech signal. </title> <booktitle> Signal Processing, </booktitle> <volume> 27 </volume> <pages> 65-78, </pages> <year> 1992. </year>
Reference-contexts: Deng has coined his model the trended HMM <ref> [4] </ref>.
Reference: [5] <author> V.V. Digialakis. </author> <title> Segment-Based Stochastic Models of Spectral Dynamics for Continuous Speech Recognition. </title> <type> PhD thesis, </type> <institution> Boston University, </institution> <year> 1992. </year>
Reference-contexts: In segment-based models the basic unit is a sequence of acoustic vectors emitted in a given speech unit (a segment), as opposed to a single acoustic vector as used for HMMs. The production of the acoustic vectors in a segment may be described as a three step procedure <ref> [5] </ref>: 1. Generate a fixed length M that is the trajectory of the sound in the feature vector space. This trajectory is internal to the model and only serves as baseform to create the sequence of observations.
Reference: [6] <author> O. Ghitza and M.M. Sondhi. </author> <title> Hidden markov models with templates as non-stationary states: an application to speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 101-119, </pages> <year> 1993. </year>
Reference-contexts: Their specific implementation had ten 14-dimensional vectors of cep-stral coefficients. They used a multivariate Gaussian to represent the entire segment, which can require a 140 by 140 full covariance matrix for each phone (assuming that feature dependence is accounted for). Ghitza and Sondhi developed a model <ref> [6] </ref> that can also be viewed as a stochastic segment model with the following distinctions: 5 * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub word units, as opposed to the
Reference: [7] <author> J.R. Glass. </author> <title> Finding Acoustic Regularities in Speech Applications to Phonetic Recognition. </title> <type> PhD thesis, </type> <institution> M.I.T, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: Another potential problem is missing transitions, i.e., implicitly the net is a transition detector because when it says that the current state is different from the previous it signals a transition. And transition detection between phonemes is a known hard problem, see <ref> [7] </ref>. Thus, we can completely get off from the correct path given our dependency on the previous state. 6 Discussion and Future Work Our goal is to construct an acoustic model that overcomes the basic limitations of HMMs.
Reference: [8] <author> H. Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> JASA, </journal> <volume> 87, </volume> <year> 1990. </year>
Reference-contexts: There were 235 inputs to the net, including 234 that consisted of 9 frames of 26 features each (PLP12 + log gain + delta features for 11 each of these 13) <ref> [8] </ref>, and a final time index input. With the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in [1]. <p> There were 295 inputs to the net, including 234 that consisted of 9 frames of 26 features each (PLP12 + log gain + delta features for each of these 13) <ref> [8] </ref>, and 61 binary inputs that represent the possible previous state. With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in [1]. Our reference HMM/MLP system [1] (with optimized phone transition penalty) had 36.3% phone error on this task.
Reference: [9] <author> B. H. Juang and L.R. Rabiner. </author> <title> Mixture autoregressive hidden markov models for speech signals. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 6(33) </volume> <pages> 1404-1413, </pages> <year> 1985. </year>
Reference-contexts: The models differ in their assumptions about the nature of the correlation between the acoustic vectors in the sequence and in their basic modeling unit. For instance, some assume that only consecutive frames are correlated, e.g., autoregressive HMM <ref> [9] </ref>, while others assume that all the frames in the sequence are dependent on each other, e.g., segment-based models. In general these models attemp to overcome the HMM assumption of independent and identically distributed observations. <p> Different models take different approaches about the relation between these events. In HMMs, for instance, the assumption is that these events are independent of each other. But in autoregressive HMM there is a dependency between the current acoustic vector and the previous acoustic vectors <ref> [9] </ref>. 6 In the hybrid HMM/MLP framework the MLP estimates a posteriori probability of the phone given the acoustic data, i.e., P (qjx), where q is speech sub-unit (e.g. phone) and x is the acoustic data.
Reference: [10] <author> Y. Konig and N. Morgan. </author> <title> Supervised and unsupervised clustering of the speaker space for connectionist speech recognition. </title> <booktitle> In ICASSP, </booktitle> <address> Minneapolis, Minnesota, </address> <month> April </month> <year> 1993. </year> <note> IEEE. </note>
Reference: [11] <author> Y. Konig, N. Morgan, C. Wooters, V. Abrash, M. Cohen, and H. Franco. </author> <title> Modeling consistency in a speaker independent continuous speech recognition system. </title> <editor> In J.S. Hanson and J.D. Cowan znd C.L. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, volume 5, </booktitle> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufman. </publisher>
Reference: [12] <author> K. F. Lee. </author> <title> Automatic Speech Recognition: The Development of the SPHINX System. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: For a more detailed description see <ref> [12, 16] </ref>.
Reference: [13] <author> M. Ostendorf and S. Roukos. </author> <title> A stochastic segment model for phoneme-based continuous speech recognition. </title> <journal> IEEE ASSP trans., </journal> <volume> 37(12) </volume> <pages> 1857-1869, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: To briefly illustrate the range of stochastic segment models, we review some specific examples and their implementations. These models differ in the form of the distribution (Y js k ) and in the time-warping transformation T L . Ostendorf and Roukos <ref> [13] </ref> have used (among a number of methods) linear time sampling in their study, i.e., sampling Y in equal intervals along the time axis as their time warping procedure. Their specific implementation had ten 14-dimensional vectors of cep-stral coefficients. <p> segment model with the following distinctions: 5 * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub word units, as opposed to the phones in Ostendorf and Roukos' stochastic segment model <ref> [13] </ref>. * They maintained the HMM framework and assumed a semi-hidden Markov chain, i.e., each state has an explicit duration distribution. Another segment-based model is the Segmental Neural Net (SNN). The Segmental Neural Network (SNN) models all the frames of a phonetic segment simultaneously.
Reference: [14] <author> P. Price, W. Fisher, J. Bernstein, and D. </author> <title> Pallet. The darpa 1000-word resource management database for continuous spee ch recognition. </title> <booktitle> In Proceedings IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 651-654, </pages> <address> New York, 1988. </address> <publisher> IEEE. </publisher>
Reference-contexts: However, practical use of the time-index model will require good estimates of the probabilities of boundary positions. Some possible solutions are discussed later in this report (section 6). 4.2 Experiments We used the Resource Management (RM) speaker independent task <ref> [14] </ref> and the TIMIT database for our initial experiments. In our RM experiments our training data consisted of 3990 read continuous sentences, and the 300 sentence Feb89 test set for development and cross-validation for the network training.
Reference: [15] <author> A. J. </author> <title> Viterbi. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> 13(2) </volume> <pages> 260-269, </pages> <year> 1967. </year>
Reference-contexts: With the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in [1]. For the preliminary tests, we assumed knowledge of the boundaries between the phones as produced by an automatic alignment (Viterbi) procedure on the known word string <ref> [15] </ref>. These initial time-index results serve as a lower bound on error, as we can expect little improvement over the boundary detection found by the Viterbi procedure with a known word sequence.
Reference: [16] <author> M.A. Jack X.D. Huang, Y. Ariki. </author> <title> Hidden Markov Models For Speech Recognition. </title> <publisher> Edinburgh University Press, </publisher> <year> 1990. </year>
Reference-contexts: For a more detailed description see <ref> [12, 16] </ref>.
Reference: [17] <author> G. Zavaliagkos, Y.Zhao, R. Schwartz, and J. Makhoul. </author> <title> A hybrid segmental neural net/hidden markov model system for continuous speech recognition. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 2(1) </volume> <pages> 151-160, </pages> <month> January </month> <year> 1994. </year> <month> 17 </month>
Reference-contexts: Thus, the net estimates the probability P (phone | warped-acoustic-segment). The utterance is segmented into phonetic segments by an HMM-based system. The overall architecture uses the N-best paradigm, and the SNN is used as a post-processor <ref> [17] </ref>. These stochastic segment models are not inherently subject to the constraints of the i.i.d. assumptions discussed earlier. However, there are some practical difficulties: 1. There are many free parameters that must be estimated reliably from the data, e.g., large covariance matrixes.
References-found: 17

