URL: http://www2.cs.cornell.edu/CS71X-s97/papers/danvy-popl96.ps
Refering-URL: http://www2.cs.cornell.edu/CS71X-s97/cs719bib.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (danvy@daimi.aau.dk)  
Title: Type-Directed Partial Evaluation  
Author: Olivier Danvy 
Address: Aarhus University  
Affiliation: Computer Science Department  
Abstract: We present a strikingly simple partial evaluator, that is type-directed and reifies a compiled program into the text of a residual, specialized program. Our partial evaluator is concise (a few lines) and it handles the flagship examples of offline monovariant partial evaluation. Its source programs are constrained in two ways: they must be closed and mono-morphically typable. Thus dynamic free variables need to be factored out in a "dynamic initial environment". Type-directed partial evaluation uses no symbolic evaluation for specialization, and naturally processes static computational effects. Our partial evaluator is the part of an o*ine partial evaluator that residualizes static values in dynamic contexts. Its restriction to the simply typed lambda-calculus coincides with Berger and Schwichtenberg's "inverse of the evaluation functional" (LICS'91), which is an instance of normalization in a logical setting. As such, type-directed partial evaluation essentially achieves lambda-calculus normalization. We extend it to produce specialized programs that are recursive and that use disjoint sums and computational effects. We also analyze its limitations: foremost, it does not handle inductive types. This paper therefore bridges partial evaluation and - calculus normalization through higher-order abstract syntax, and touches upon parametricity, proof theory, and type theory (including subtyping and coercions), compiler optimization, and run-time code generation (including decom-pilation). It also offers a simple solution to denotational semantics-based compilation and compiler generation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thorsten Altenkirch, Martin Hofmann, and Thomas Streicher. </author> <title> Categorical reconstruction of a reduction 7 Davies and Pfenning's logical formalization of binding-time analysis and o*ine partial evaluation opens a promising avenue [20]. free reduction proof. </title> <editor> In Peter Dybjer and Randy Pol-lack, editors, </editor> <booktitle> Informal Proceedings of the Joint CLICS-TYPES Workshop on Categories and Type Theory, Goteborg, </booktitle> <address> Sweden, </address> <month> May </month> <year> 1995. </year> <type> Report 85, </type> <institution> Programming Methodology Group, Chalmers University and the University of Goteborg. </institution>
Reference-contexts: This technique of normalization by translation appears to be spreading [39]. Follow-up work on Berger and Schwichtenberg's algorithm includes Alten-kirch, Hofmann, and Streicher's categorical reconstruction of this algorithm <ref> [1] </ref>. 6 This reconstruction formalizes the environment of fresh identifiers generated by the reifica-tion of -abstractions as a categorical fibration. Berger and Schwichtenberg also dedicate a significant part of their paper to formalizing the generation of fresh identifiers (they represent abstract-syntax trees as base types).
Reference: [2] <author> Henk Barendregt. </author> <title> The Lambda Calculus | Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <year> 1984. </year>
Reference-contexts: The combinators S and K are defined as above <ref> [2, Definition 5.1.8, Item (i)] </ref>. 1.8 Beyond the pure -calculus Moving beyond the pure -calculus, let us reiterate this last experiment: we residualize the result of applying a procedure to an argument, and a multiplication is computed at resid-ualization time. &gt; (define bar (lambda (x) (lambda (k) (k (* x 5)))))
Reference: [3] <author> Ulrich Berger and Helmut Schwichtenberg. </author> <title> An inverse of the evaluation functional for typed -calculus. </title> <booktitle> In Proceedings of the Sixth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 203-211, </pages> <address> Amsterdam, The Netherlands, July 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: We implement type-directed residualization in Scheme [10] and illustrate it (Section 1.6). The restriction of type-directed residualization to the simply typed -calculus actually coincides with Berger and Schwichtenberg's normalization algorithm as presented in the proceedings of LICS'91 <ref> [3] </ref>, and is closely related to Pfenning's normalization algorithm in Elf [46] (Section 1.7). Residualization also exhibits a normalization effect. Moving beyond the pure -calculus, we observe that this effect appears for constants and their operators as well (Section 1.8). <p> In their paper "An Inverse of the Evaluation Functional for Typed -Calculus" <ref> [3] </ref>, Berger and Schwichten-berg present a normalization algorithm for the simply typed -calculus. It is used for normalizing proofs as programs. Berger and Schwichtenberg's algorithm coincides with the restriction of type-directed residualization to the simply typed -calculus. <p> Disregarding the dynamic base types, reflect thus acts as an evaluation functional, and reify acts as its inverse | hence probably the title of Berger and Schwichtenberg's paper <ref> [3] </ref>. In the implementation of his Elf logic programming language [46], Pfenning uses a similar normalization algorithm to test extensional equality, though with no static/dynamic notion and also with the following difference. <p> Only its restriction to the simply typed -calculus has been proven correct, because it coincides with Berger and Schwichtenberg's algorithm <ref> [3] </ref>. (The two-level -calculus, though, provides a more convenient format for proving, e.g., that static reduction does not go wrong and yields a completely dynamic term.) This section addresses the practical limitations of type directed partial evaluation. 4.1 Static errors and non-termination may occur As soon as we move beyond the <p> We have presented an algorithm that residualizes a closed typed static value in a dynamic context, by eta-expanding the value with two-level eta-redexes and then reducing all static redexes. For the simply typed -calculus, the algorithm coincides with Berger and Schwichtenberg's "inverse of the evaluation functional" <ref> [3] </ref>. It is also interesting in its own right in that it can be used as a partial evaluator for closed compiled programs, given their type. This partial evaluator, in several respects, outperforms all previous partial evaluators, e.g., in simplicity and in efficiency.
Reference: [4] <author> Lars Birkedal and Morten Welinder. </author> <title> Partial evaluation of Standard ML. </title> <type> Master's thesis, </type> <institution> DIKU, Computer Science Department, University of Copenhagen, </institution> <month> August </month> <year> 1993. </year> <type> DIKU report 93/22. </type>
Reference-contexts: These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> Considering higher-order values introduces a new challenge for resid-ualization. Most partial evaluators dodge this challenge by disallowing static higher-order values to occur in dynamic contexts | i.e., in practice, by dynamizing both, and more generally by restricting residualized values to be of base type <ref> [4, 6, 9, 36, 37] </ref>. Only recently, some light has been shed on the residualization of values at higher types, given information about these types [18, 19].
Reference: [5] <author> Hans-J. Boehm, </author> <title> editor. </title> <booktitle> Proceedings of the Twenty-First Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year> <note> ACM Press. </note>
Reference: [6] <author> Anders Bondorf. </author> <title> Self-Applicable Partial Evaluation. </title> <type> PhD thesis, </type> <institution> DIKU, Computer Science Department, University of Copenhagen, Copenhagen, Denmark, </institution> <year> 1990. </year> <type> DIKU Report 90-17. </type>
Reference-contexts: These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input. <p> Considering higher-order values introduces a new challenge for resid-ualization. Most partial evaluators dodge this challenge by disallowing static higher-order values to occur in dynamic contexts | i.e., in practice, by dynamizing both, and more generally by restricting residualized values to be of base type <ref> [4, 6, 9, 36, 37] </ref>. Only recently, some light has been shed on the residualization of values at higher types, given information about these types [18, 19].
Reference: [7] <author> Anders Bondorf. </author> <title> Improving binding times without explicit cps-conversion. </title> <editor> In William Clinger, editor, </editor> <booktitle> Proceedings of the 1992 ACM Conference on Lisp and Functional Programming, LISP Pointers, </booktitle> <volume> Vol. V, No. 1, </volume> <pages> pages 1-10, </pages> <address> San Francisco, California, June 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: In practice, this decision created the need for source binding-time improvements in o*ine partial evaluation [36, Chapter 12]. In contrast, binding-time coercions "improve binding times without explicit eta-conversion", to paraphrase the title of Bondorf's LFP'92 paper <ref> [7] </ref> | a property which should prove crucial for multi-level binding-time analyses since it eliminates the need for (unfathomed) multilevel binding-time improvements [26].
Reference: [8] <author> Anders Bondorf and Olivier Danvy. </author> <title> Automatic auto-projection of recursive equations with global variables and abstract data types. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 16 </volume> <pages> 151-195, </pages> <year> 1991. </year>
Reference-contexts: evaluation does not escape the prob lem of computation duplication: a program such as (lambda (f g x) ((lambda (y) (f y y)) (g x))) is residualized as (lambda (f g x) (f (g x) (g x))) Fortunately, the Similix solution applies: a residual let ex pression should be inserted <ref> [8] </ref>. The residual term above then reads: (lambda (f g x) (let ([y (g x)]) (f y y))) 10 We have implemented type-directed partial evaluation in such a way. This makes it possible to specialize a direct-style version of the Tiny interpreter in Section 2.3. <p> At first, this can be seen as a shortcoming, until one considers the contemporary treatment of side effects in partial evaluators. Since Similix <ref> [8] </ref>, all I/O-like side effects are re-sidualized, which on the one hand is safe but on the other hand prevents, e.g., the non-trivial specialization of an interpreter which finds its source program in a file. <p> In the spring of 1989, higher-order partial evaluation was blooming at DIKU [34]. In parallel with Bondorf (then visiting Dortmund), the author developed a version of Similix <ref> [8] </ref> that did not dynamize higher-order values in dynamic contexts. In this unreleased version, instead, the specializer kept track of the arity of static closures and eta-expanded them when they occurred in dynamic contexts. Type-directed partial evaluation stems from this unpublished work. The idea, however, did not take.
Reference: [9] <author> Anders Bondorf and Jesper Jtrgensen. </author> <title> Efficient analyses for realistic off-line partial evaluation. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(3) </volume> <pages> 315-346, </pages> <year> 1993. </year>
Reference-contexts: which is central to partial evaluation but unsafe without let insertion (under call by value), "Similix [...] refuses to lift higher-order values into residual expressions: lifting higher-order values and data structures is in general unsafe since it may lead to residual code that exponentially duplicates data structure and closure allocations" <ref> [9, page 327] </ref>. All the later higher-order partial evaluators developed at DIKU have adopted the same conservative strategy | a choice that Henglein questions from a type-theoretical standpoint [29]. In practice, this decision created the need for source binding-time improvements in o*ine partial evaluation [36, Chapter 12]. <p> Considering higher-order values introduces a new challenge for resid-ualization. Most partial evaluators dodge this challenge by disallowing static higher-order values to occur in dynamic contexts | i.e., in practice, by dynamizing both, and more generally by restricting residualized values to be of base type <ref> [4, 6, 9, 36, 37] </ref>. Only recently, some light has been shed on the residualization of values at higher types, given information about these types [18, 19].
Reference: [10] <editor> William Clinger and Jonathan Rees (editors). </editor> <title> Revised 4 report on the algorithmic language Scheme. LISP Pointers, </title> <address> IV(3):1-55, </address> <month> July-September </month> <year> 1991. </year>
Reference-contexts: After a first assessment (Section 1.3), we formalize it (Section 1.4) and outline a first application: given a compiled normal form and its type, we can recover its text (Section 1.5). We implement type-directed residualization in Scheme <ref> [10] </ref> and illustrate it (Section 1.6). The restriction of type-directed residualization to the simply typed -calculus actually coincides with Berger and Schwichtenberg's normalization algorithm as presented in the proceedings of LICS'91 [3], and is closely related to Pfenning's normalization algorithm in Elf [46] (Section 1.7). <p> Therefore, in principle, we can map a compiled program back into its text | under the restrictions that (1) this program terminates, and (2) it has a type. The following section illustrates this application. 1.6 Type-directed residualization in Scheme declaring and using records <ref> [10] </ref>. Procedure parse-type maps the concrete syntactic representation of a type (an S-expression) into the corresponding abstract syntactic representation (a nested record structure). <p> Unless the source term is tail-recursive, we thus need to abstract and to relocate this context. Context abstraction is achieved with a control operator. This context, however, needs to be delimited, which rules out call/cc <ref> [10] </ref> but invites one to use shift and reset [16, 17] (though of course any other delimited control operator could do as well [21]). 5 The extended residualizer is displayed in The following Scheme session illustrates this extension. &gt; (residualize (lambda (x) x) '((A + B) -&gt; (A + B))) (lambda <p> problem.) For example, given the looping thunk loop, the expression (residualize (lambda (dummy) ((loop) (/ 1 0))) '(Dummy -&gt; Whatever)) may either diverge or yield a "division by zero" error, depending on the Scheme processor at hand, since the order in which sub-expressions are evaluated, in an application, is undetermined <ref> [10] </ref>. 4.2 Residual programs must have a type We must know the type of every residual program, since it is this type that directs residualization. (The static parts of a source program, however, need not be typed.) Residual programs can be polymorphically typed at base type (names of base types do
Reference: [11] <author> Charles Consel. </author> <title> Analyse de Programmes, Evaluation Partielle et Generation de Compilateurs. </title> <type> PhD thesis, </type> <institution> Universite Pierre et Marie Curie (Paris VI), Paris, France, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input.
Reference: [12] <author> Charles Consel. </author> <title> Polyvariant binding-time analysis for applicative languages. </title> <editor> In David A. Schmidt, editor, </editor> <booktitle> Proceedings of the Second ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 66-77, </pages> <address> Copenhagen, Denmark, June 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: So do all other binding-time analyses [36], with the exception of Con-sel's <ref> [12] </ref> and Heintze's [40]. These analyses are polyvariant and thus they spawn another variant instead of dynamizing. In practice, type-directed partial evaluation needs a simple form of binding-time analysis: a type inferencer where all base types are duplicated into a static version and a dynamic version.
Reference: [13] <author> Charles Consel and Olivier Danvy. </author> <title> From interpreting to compiling binding times. </title> <editor> In Neil D. Jones, editor, </editor> <booktitle> Proceedings of the Third European Symposium on Programming, number 432 in Lecture Notes in Computer Science, </booktitle> <pages> pages 88-105, </pages> <address> Copenhagen, Denmark, </address> <month> May </month> <year> 1990. </year> <month> 13 </month>
Reference-contexts: fi-normal form. 1.5 Application We can represent a completely static expression with a compiled representation of this expression, and a completely dynamic expression with a (compiled) program constructing the textual representation of this expression. 1 In Consel's partial evaluator Schism, for example, this representation is used to optimize program specialization <ref> [13] </ref>. Since (1) re-ification amounts to mapping this static expression into a two-level term and (2) static reduction amounts to running both the static and the dynamic components of this two-level term, type-directed residualization constructs the textual representation of the original static expression.
Reference: [14] <author> Charles Consel and Olivier Danvy. </author> <title> Static and dynamic semantics processing. </title> <editor> In Robert (Corky) Cartwright, editor, </editor> <booktitle> Proceedings of the Eighteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 14-24, </pages> <address> Orlando, Florida, </address> <month> January </month> <year> 1991. </year> <note> ACM Press. </note>
Reference-contexts: Essentially, type-directed partial evaluation of the Tiny interpreter acts as a front-end compiler that maps the abstract syntax of a source program into a -expression representing the dynamic semantics of this program <ref> [14] </ref>. This - expression is in continuation-passing style [49], i.e., in three-address code. We have extended the definitional -interpreter described in this section to richer languages, including typed higher-order procedures, block structure, and subtyping, a la Reyn-olds [47]. Thus this technique of "type-directed compilation" scales up in practice.
Reference: [15] <author> Charles Consel and Olivier Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <editor> In Susan L. Graham, editor, </editor> <booktitle> Proceedings of the Twentieth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year> <note> ACM Press. </note>
Reference-contexts: 1 Background and Introduction Given a source program and parts of its input, a partial evaluator reduces static expressions and reconstructs dynamic expressions, producing a residual, specialized program <ref> [15, 36] </ref>. To this end, a partial evaluator needs some method for inserting (lifting) arbitrary statically-calculated fl Supported by BRICS (Basic Research in Computer Science, Centre of the Danish National Research Foundation). y Ny Munkegade, Building 540, DK-8000 Aarhus C, Denmark. <p> These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> In the following section, we apply it to various examples that have been presented as typical or even significant achievements of partial evaluation, in the literature <ref> [15, 33, 36] </ref>. These examples include the power and the format source programs, and interpreters for Paulson's imperative language Tiny and for the -calculus. <p> Its source code can be found in Figure 1 of Consel and Danvy's tutorial notes on partial evaluation at POPL'93 <ref> [15] </ref>. Type-directed partial evaluation yields the same residual code as the one presented in the tutorial notes (modulo of course the factorization of the residual operators write-string, write-number, write-newline, and list-ref). 2.3 Definitional interpreter for Paulson's Tiny language Recursive procedures can be defined with fixed-point operators. <p> Polyvariance makes it possible, e.g., to derive linear string matchers out of a quadratic one and to compile pattern matching and regular expressions efficiently <ref> [15, 36] </ref>. We are currently working on making type-directed partial evaluation polyvariant. 4.7 Residual programs are hard to decipher A pretty-printer proves very useful to read residual programs. We are currently experimenting with the ability to attach residual-name stubs to type declarations, as in Elf. <p> The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input. <p> source program p is a definitional interpreter, or where the source program is the partial evaluator PE itself and the static input is a definitional interpreter or PE itself, the partial-evaluation equations run p hs; di = run p hs; i h ; di are known as the "Futamura Projections" <ref> [15, 25, 36] </ref>.
Reference: [16] <author> Olivier Danvy and Andrzej Filinski. </author> <title> Abstracting control. </title> <editor> In Mitchell Wand, editor, </editor> <booktitle> Proceedings of the 1990 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 151-160, </pages> <address> Nice, France, June 1990. </address> <publisher> ACM Press. </publisher>
Reference-contexts: A bit of practice with two-level eta-expansion <ref> [16, 17, 18] </ref> makes it clear that, for example: # It is therefore natural to define a function " that is sym metric to #, i.e., that coerces its argument from dynamic to static, and to define the residualization of functions as follows. # t 2 (v @ (" t 1 <p> Unless the source term is tail-recursive, we thus need to abstract and to relocate this context. Context abstraction is achieved with a control operator. This context, however, needs to be delimited, which rules out call/cc [10] but invites one to use shift and reset <ref> [16, 17] </ref> (though of course any other delimited control operator could do as well [21]). 5 The extended residualizer is displayed in The following Scheme session illustrates this extension. &gt; (residualize (lambda (x) x) '((A + B) -&gt; (A + B))) (lambda (x0) (case-record x0 [(Left x1) (make-Left x1)] [(Right x2)
Reference: [17] <author> Olivier Danvy and Andrzej Filinski. </author> <title> Representing control, a study of the CPS transformation. </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <volume> 2(4) </volume> <pages> 361-391, </pages> <month> Decem-ber </month> <year> 1992. </year>
Reference-contexts: A bit of practice with two-level eta-expansion <ref> [16, 17, 18] </ref> makes it clear that, for example: # It is therefore natural to define a function " that is sym metric to #, i.e., that coerces its argument from dynamic to static, and to define the residualization of functions as follows. # t 2 (v @ (" t 1 <p> Unless the source term is tail-recursive, we thus need to abstract and to relocate this context. Context abstraction is achieved with a control operator. This context, however, needs to be delimited, which rules out call/cc [10] but invites one to use shift and reset <ref> [16, 17] </ref> (though of course any other delimited control operator could do as well [21]). 5 The extended residualizer is displayed in The following Scheme session illustrates this extension. &gt; (residualize (lambda (x) x) '((A + B) -&gt; (A + B))) (lambda (x0) (case-record x0 [(Left x1) (make-Left x1)] [(Right x2)
Reference: [18] <author> Olivier Danvy, Karoline Malmkjr, and Jens Palsberg. </author> <title> The essence of eta-expansion in partial evaluation. </title> <journal> LISP and Symbolic Computation, </journal> <volume> 8(3) </volume> <pages> 209-227, </pages> <year> 1995. </year> <booktitle> An earlier version appeared in the proceedings of the 1994 ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation. </booktitle>
Reference-contexts: It required, however, a binding-time improvement, i.e., human intervention on the source term. Recent work by Malmkjr, Palsberg, and the author <ref> [18, 19] </ref> shows that binding-time improvements compensate for the lack of binding-time coercions in existing binding-time analyses. Source eta-expansion, for example, provides a syntactic representation for a binding-time coercion between a higher-order static value and a dynamic context, or conversely between a dynamic value and a static higher-order context. <p> 1 ! b 1 is written # b 1 !b 1 f : g : b 1 ! (b 1 ! b 1 ) ! b 2 : One possibility is to represent the coercion directly with a two-level eta-redex, to make the type structure of the term syntactically apparent <ref> [18, 19] </ref>. The result of binding-time analysis is then the same as for Solution 2. Another possibility is to produce the binding-time coercion as such, without committing to its representation, and to leave it to the static reducer to treat this coercion appropriately. <p> A bit of practice with two-level eta-expansion <ref> [16, 17, 18] </ref> makes it clear that, for example: # It is therefore natural to define a function " that is sym metric to #, i.e., that coerces its argument from dynamic to static, and to define the residualization of functions as follows. # t 2 (v @ (" t 1 <p> that is sym metric to #, i.e., that coerces its argument from dynamic to static, and to define the residualization of functions as follows. # t 2 (v @ (" t 1 x 1 )) The functions # and " essentially match the insertion of two-level eta-redexes for binding-time improvements <ref> [18, 19] </ref>. Type-directed residualization maps a completely static two-level -term into a completely dynamic one. First, reify (#) and reflect (") fully eta-expand a static two-level -term with two-level eta-redexes. <p> Only recently, some light has been shed on the residualization of values at higher types, given information about these types <ref> [18, 19] </ref>. We have presented an algorithm that residualizes a closed typed static value in a dynamic context, by eta-expanding the value with two-level eta-redexes and then reducing all static redexes. For the simply typed -calculus, the algorithm coincides with Berger and Schwichtenberg's "inverse of the evaluation functional" [3].
Reference: [19] <author> Olivier Danvy, Karoline Malmkjr, and Jens Palsberg. </author> <title> Eta-expansion does The Trick. </title> <type> Technical report BRICS RS-95-41, DAIMI, </type> <institution> Computer Science Department, Aar-hus University, Aarhus, Denmark, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: It required, however, a binding-time improvement, i.e., human intervention on the source term. Recent work by Malmkjr, Palsberg, and the author <ref> [18, 19] </ref> shows that binding-time improvements compensate for the lack of binding-time coercions in existing binding-time analyses. Source eta-expansion, for example, provides a syntactic representation for a binding-time coercion between a higher-order static value and a dynamic context, or conversely between a dynamic value and a static higher-order context. <p> 1 ! b 1 is written # b 1 !b 1 f : g : b 1 ! (b 1 ! b 1 ) ! b 2 : One possibility is to represent the coercion directly with a two-level eta-redex, to make the type structure of the term syntactically apparent <ref> [18, 19] </ref>. The result of binding-time analysis is then the same as for Solution 2. Another possibility is to produce the binding-time coercion as such, without committing to its representation, and to leave it to the static reducer to treat this coercion appropriately. <p> that is sym metric to #, i.e., that coerces its argument from dynamic to static, and to define the residualization of functions as follows. # t 2 (v @ (" t 1 x 1 )) The functions # and " essentially match the insertion of two-level eta-redexes for binding-time improvements <ref> [18, 19] </ref>. Type-directed residualization maps a completely static two-level -term into a completely dynamic one. First, reify (#) and reflect (") fully eta-expand a static two-level -term with two-level eta-redexes. <p> Only recently, some light has been shed on the residualization of values at higher types, given information about these types <ref> [18, 19] </ref>. We have presented an algorithm that residualizes a closed typed static value in a dynamic context, by eta-expanding the value with two-level eta-redexes and then reducing all static redexes. For the simply typed -calculus, the algorithm coincides with Berger and Schwichtenberg's "inverse of the evaluation functional" [3].
Reference: [20] <author> Rowan Davies and Frank Pfenning. </author> <title> A modal analysis of staged computation. </title> <editor> In Guy L. Steele Jr., editor, </editor> <booktitle> Proceedings of the Twenty-Third Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> St. Peters-burg Beach, Florida, </address> <month> January </month> <year> 1996. </year> <note> ACM Press. </note>
Reference: [21] <author> Matthias Felleisen. </author> <title> The theory and practice of first-class prompts. </title> <editor> In Jeanne Ferrante and Peter Mager, editors, </editor> <booktitle> Proceedings of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 180-190, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: Context abstraction is achieved with a control operator. This context, however, needs to be delimited, which rules out call/cc [10] but invites one to use shift and reset [16, 17] (though of course any other delimited control operator could do as well <ref> [21] </ref>). 5 The extended residualizer is displayed in The following Scheme session illustrates this extension. &gt; (residualize (lambda (x) x) '((A + B) -&gt; (A + B))) (lambda (x0) (case-record x0 [(Left x1) (make-Left x1)] [(Right x2) (make-Right x2)])) &gt; (residualize (lambda (x) 42) '(Bool -&gt; Int)) (lambda (x0) (if x0
Reference: [22] <author> Andrzej Filinski. </author> <title> Representing monads. </title> <booktitle> In Boehm [5], </booktitle> <pages> pages 446-457. </pages>
Reference: [23] <author> Andrzej Filinski. </author> <title> Controlling Effects. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <year> 1995. </year>
Reference-contexts: An implementation of Berger and Schwichtenberg's algorithm in Standard ML can be found in Filinski's PhD 6 In that work, reify is "quote" and reflect is "unquote". 11 thesis <ref> [23] </ref>. This implementation handles most of the ex-amples displayed in the present paper, in ML. It is ingenious because as expressed in Figures 1 and 2, type-directed partial evaluation requires dependent types.
Reference: [24] <author> Daniel P. Friedman, Mitchell Wand, and Christopher T. Haynes. </author> <title> Essentials of Programming Languages. </title> <publisher> The MIT Press and McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: These examples include the power and the format source programs, and interpreters for Paulson's imperative language Tiny and for the -calculus. The presentation of each example is structured as follows: * we consider interpreter-like programs, i.e., programs where one argument determines a part of the control flow (Abelson, <ref> [24, Foreword] </ref>); 5 &gt; (define power (lambda (x n) (letrec ([loop (lambda (n) (cond [(zero? n) 1] [(odd? n) (* x (loop (1- n)))] [else (sqr (loop (/ n 2)))]))]) (loop n)))) &gt; (define sqr (lambda (x) (* x x))) &gt; (power 2 10) 1024 &gt; (define power-abstracted ;;; Int -&gt;
Reference: [25] <author> Yoshihito Futamura. </author> <title> Partial evaluation of computation process an approach to a compiler-compiler. </title> <journal> Systems, Computers, </journal> <volume> Controls 2, 5, </volume> <pages> pages 45-50, </pages> <year> 1971. </year>
Reference-contexts: Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input. <p> source program p is a definitional interpreter, or where the source program is the partial evaluator PE itself and the static input is a definitional interpreter or PE itself, the partial-evaluation equations run p hs; di = run p hs; i h ; di are known as the "Futamura Projections" <ref> [15, 25, 36] </ref>.
Reference: [26] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Efficient multilevel generating extensions for program specialization. </title> <editor> In S. D. Swierstra and M. Hermenegildo, editors, </editor> <booktitle> Seventh International Symposium on Programming Language Implementation and Logic Programming, number 982 in Lecture Notes in Computer Science, </booktitle> <pages> pages 259-278, </pages> <address> Utrecht, The Netherlands, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: In contrast, binding-time coercions "improve binding times without explicit eta-conversion", to paraphrase the title of Bondorf's LFP'92 paper [7] | a property which should prove crucial for multi-level binding-time analyses since it eliminates the need for (unfathomed) multilevel binding-time improvements <ref> [26] </ref>. Thus Mix-like partial evaluation [36] and type-directed partial evaluation fundamentally contrast when it comes to dynamic computations: Mix-like partial evaluators do not associate any structure to the binding time "dynamic", whereas we rely on the type structure of dynamic computations in an essential way.
Reference: [27] <author> Mayer Goldberg. </author> <title> Recursive Application Survival in the -Calculus. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Indiana University, Bloomington, Indiana, </institution> <year> 1996. </year> <month> Forthcoming. </month>
Reference-contexts: This program contains an application and this application is performed at residualization time. 2 &gt; (define foo (lambda (f) (lambda (x) (f x)))) &gt; (residualize (foo (lambda (z) z)) '(A -&gt; A)) (lambda (x0) x0) &gt; 2 Or, viewing residualization as a form of decompilation (an analogy due to Goldberg <ref> [27] </ref>): "at decompile time". <p> (b + c)) -&gt; a -&gt; Int)) (lambda (x0) (lambda (x1) 42)) &gt; (residualize (lambda (f) (lambda (x) ((lambda (y) 42) (f x)))) '((a -&gt; (b + c)) -&gt; a -&gt; Int)) (lambda (x0) (lambda (x1) (case-record (x0 x1) [(Left x2) 42] [(Right x3) 42]))) &gt; In his PhD thesis <ref> [27] </ref>, Goldberg investigates Godel-ization, i.e., the encoding of a value from one language into another. He identifies Berger and Schwichtenberg's algorithm as one instance of Godelization, and presents a Godelizer for proper combinators in the untyped -calculus.
Reference: [28] <author> John Hatcliff and Olivier Danvy. </author> <title> A generic account of continuation-passing styles. </title> <booktitle> In Boehm [5], </booktitle> <pages> pages 458-471. </pages>
Reference-contexts: Continuation-passing style: For a continuation-style interpreter, the type is the CPS counterpart of the type of the interpreted -term and the residual term is the CPS counterpart of the interpreted -term | for each possible continuation-passing style <ref> [28] </ref>. Figure 7 illustrates the point for left-to-right call-by-value.
Reference: [29] <author> Fritz Henglein. </author> <title> Dynamic typing: Syntax and proof theory. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 22(3) </volume> <pages> 197-230, </pages> <year> 1993. </year> <title> Special Issue on ESOP'92, </title> <booktitle> the Fourth European Symposium on Programming, Rennes, </booktitle> <month> February </month> <year> 1992. </year>
Reference-contexts: All the later higher-order partial evaluators developed at DIKU have adopted the same conservative strategy | a choice that Henglein questions from a type-theoretical standpoint <ref> [29] </ref>. In practice, this decision created the need for source binding-time improvements in o*ine partial evaluation [36, Chapter 12].
Reference: [30] <author> Gerard Huet. </author> <title> Resolution d'equations dans les langages d'ordre 1, </title> <type> 2, </type> ..., !. <institution> These d' Etat, Universite de Paris VII, Paris, France, </institution> <year> 1976. </year>
Reference-contexts: Corollary 2 The type of a source term and the type of a residual term have the same shape (i.e., erasing their annotations yields the same simple type). This last property extends to terms that are in long fi normal form <ref> [30] </ref>, i.e., to normal forms that are completely eta-expanded. By Proposition 1, we already know that static reduction of a completely static term in long fi-normal form yields a completely dynamic term in long fi-normal form.
Reference: [31] <author> C. Barry Jay and Neil Ghani. </author> <title> The virtues of eta-expansion. </title> <journal> Journal of Functional Programming, </journal> <volume> 5(3) </volume> <pages> 135-154, </pages> <year> 1995. </year>
Reference-contexts: In that context, (one-level) type-directed eta-expansion is a necessary step towards long fi-normal forms <ref> [31] </ref>. A recent trend, embodied by partial evaluation, amounts to staging normalization in two steps: a translation into an annotated language, followed by a symbolic evaluation. This technique of normalization by translation appears to be spreading [39].
Reference: [32] <editor> Neil D. Jones, editor. </editor> <booktitle> Semantics-Directed Compiler Generation, number 94 in Lecture Notes in Computer Science, </booktitle> <address> Aarhus, Denmark, </address> <year> 1980. </year>
Reference-contexts: Thus this technique of "type-directed compilation" scales up in practice. In that sense, type-directed partial evaluation provides a simple and effective solution to (de-notational) semantics-directed compilation in the -calculus <ref> [32, 43] </ref>. 2.4 Residualizing the residualizer To visualize the effect of residualization, one can residualize the residualizer with respect to a type.
Reference: [33] <author> Neil D. Jones. </author> <title> Challenging problems in partial evaluation and mixed computation. </title> <booktitle> In Partial Evaluation and Mixed Computation, </booktitle> <pages> pages 1-14. </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: In the following section, we apply it to various examples that have been presented as typical or even significant achievements of partial evaluation, in the literature <ref> [15, 33, 36] </ref>. These examples include the power and the format source programs, and interpreters for Paulson's imperative language Tiny and for the -calculus.
Reference: [34] <author> Neil D. Jones. </author> <title> Mix ten years after. </title> <editor> In William L. Scherlis, editor, </editor> <booktitle> Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 24-38, </pages> <address> La Jolla, Califor-nia, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Because it relies on one piece of static information | the type of the residual program | type-directed partial evaluation appears as an extreme form of o*ine partial evaluation. In the spring of 1989, higher-order partial evaluation was blooming at DIKU <ref> [34] </ref>. In parallel with Bondorf (then visiting Dortmund), the author developed a version of Similix [8] that did not dynamize higher-order values in dynamic contexts. In this unreleased version, instead, the specializer kept track of the arity of static closures and eta-expanded them when they occurred in dynamic contexts.
Reference: [35] <author> Neil D. Jones, Carsten K. Gomard, Anders Bondorf, Olivier Danvy, and Torben . Mogensen. </author> <title> A self-applicable partial evaluator for the lambda calculus. </title> <editor> In K. C. Tai and Alexander L. Wolf, editors, </editor> <booktitle> Proceedings of the 1990 IEEE International Conference on Computer Languages, </booktitle> <pages> pages 49-58, </pages> <address> New Orleans, Louisiana, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: The static parts of the source program, however, are less constrained than when using a partial evaluator: they can be untyped and impure. In that sense it is symmetric to a partial evaluator such as Gomard and Jones's -Mix <ref> [35, 36] </ref> that allows dynamic computations to be untyped but requires static computations to be typed. 3 In any case, residualization produces the same result as conventional partial evaluation (i.e., a specialized program) but is naturally more efficient since no program analysis other than type inference and no symbolic interpretation take
Reference: [36] <author> Neil D. Jones, Carsten K. Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall International Series in Computer Science. Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: 1 Background and Introduction Given a source program and parts of its input, a partial evaluator reduces static expressions and reconstructs dynamic expressions, producing a residual, specialized program <ref> [15, 36] </ref>. To this end, a partial evaluator needs some method for inserting (lifting) arbitrary statically-calculated fl Supported by BRICS (Basic Research in Computer Science, Centre of the Danish National Research Foundation). y Ny Munkegade, Building 540, DK-8000 Aarhus C, Denmark. <p> These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> it does not give a satisfactory result: static reduction unfolds the outer call, duplicates the denotation of f , and creates an inner fi-redex: g : b 1 ! (b 1 ! b 1 ) ! b 2 : To remedy this shortcoming, the source program needs a binding-time improvement <ref> [36, Chapter 12] </ref>, i.e., a modification of the source program to make the binding-time analysis yield better results. The particular binding-time improvement needed here is eta-expansion, as done in Solution 2. Solution 2: Eta-expanding the second occurrence of f makes it always occur in position of application. <p> In the following section, we apply it to various examples that have been presented as typical or even significant achievements of partial evaluation, in the literature <ref> [15, 33, 36] </ref>. These examples include the power and the format source programs, and interpreters for Paulson's imperative language Tiny and for the -calculus. <p> The static parts of the source program, however, are less constrained than when using a partial evaluator: they can be untyped and impure. In that sense it is symmetric to a partial evaluator such as Gomard and Jones's -Mix <ref> [35, 36] </ref> that allows dynamic computations to be untyped but requires static computations to be typed. 3 In any case, residualization produces the same result as conventional partial evaluation (i.e., a specialized program) but is naturally more efficient since no program analysis other than type inference and no symbolic interpretation take <p> The running question is as follows: which type should drive residualization? Direct style: For a direct-style interpreter, the type is the same as the type of the interpreted -term and the residual term is structurally equivalent to the interpreted -term <ref> [36, Section 7.4] </ref>. Continuation-passing style: For a continuation-style interpreter, the type is the CPS counterpart of the type of the interpreted -term and the residual term is the CPS counterpart of the interpreted -term | for each possible continuation-passing style [28]. Figure 7 illustrates the point for left-to-right call-by-value. <p> The outer occurrence must be declared in the initial run-time environment: (lambda (add) ((lambda (x) (lambda (y) (add (+ x 10) y))) 100)) This limitation may remind one of the need for binding-time separation in some partial evaluators <ref> [36, 41] </ref>. A simple solution, however, exists, that prevents segregation. <p> Polyvariance makes it possible, e.g., to derive linear string matchers out of a quadratic one and to compile pattern matching and regular expressions efficiently <ref> [15, 36] </ref>. We are currently working on making type-directed partial evaluation polyvariant. 4.7 Residual programs are hard to decipher A pretty-printer proves very useful to read residual programs. We are currently experimenting with the ability to attach residual-name stubs to type declarations, as in Elf. <p> It can be easily translated into Haskell (excluding disjoint sums, of course, for lack of computational effects). 5.2 Binding-time analysis All of Nielson and Nielson's binding-time analyses dynamize functions in dynamic contexts because of the difficulties of handling contravariance in program analysis [44]. So do all other binding-time analyses <ref> [36] </ref>, with the exception of Con-sel's [12] and Heintze's [40]. These analyses are polyvariant and thus they spawn another variant instead of dynamizing. <p> The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> All the later higher-order partial evaluators developed at DIKU have adopted the same conservative strategy | a choice that Henglein questions from a type-theoretical standpoint [29]. In practice, this decision created the need for source binding-time improvements in o*ine partial evaluation <ref> [36, Chapter 12] </ref>. In contrast, binding-time coercions "improve binding times without explicit eta-conversion", to paraphrase the title of Bondorf's LFP'92 paper [7] | a property which should prove crucial for multi-level binding-time analyses since it eliminates the need for (unfathomed) multilevel binding-time improvements [26]. <p> In contrast, binding-time coercions "improve binding times without explicit eta-conversion", to paraphrase the title of Bondorf's LFP'92 paper [7] | a property which should prove crucial for multi-level binding-time analyses since it eliminates the need for (unfathomed) multilevel binding-time improvements [26]. Thus Mix-like partial evaluation <ref> [36] </ref> and type-directed partial evaluation fundamentally contrast when it comes to dynamic computations: Mix-like partial evaluators do not associate any structure to the binding time "dynamic", whereas we rely on the type structure of dynamic computations in an essential way. <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input. <p> To be efficient, self-application requires a good binding-time analysis and a good binding-time division in the partial evaluator <ref> [36, Section 7.3] </ref>. <p> source program p is a definitional interpreter, or where the source program is the partial evaluator PE itself and the static input is a definitional interpreter or PE itself, the partial-evaluation equations run p hs; di = run p hs; i h ; di are known as the "Futamura Projections" <ref> [15, 25, 36] </ref>. <p> Considering higher-order values introduces a new challenge for resid-ualization. Most partial evaluators dodge this challenge by disallowing static higher-order values to occur in dynamic contexts | i.e., in practice, by dynamizing both, and more generally by restricting residualized values to be of base type <ref> [4, 6, 9, 36, 37] </ref>. Only recently, some light has been shed on the residualization of values at higher types, given information about these types [18, 19].
Reference: [37] <author> John Launchbury. </author> <title> Projection Factorisations in Partial Evaluation. </title> <booktitle> Distinguished Dissertations in Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input. <p> Considering higher-order values introduces a new challenge for resid-ualization. Most partial evaluators dodge this challenge by disallowing static higher-order values to occur in dynamic contexts | i.e., in practice, by dynamizing both, and more generally by restricting residualized values to be of base type <ref> [4, 6, 9, 36, 37] </ref>. Only recently, some light has been shed on the residualization of values at higher types, given information about these types [18, 19].
Reference: [38] <author> Julia L. Lawall and Olivier Danvy. </author> <title> Continuation-based partial evaluation. </title> <editor> In Carolyn L. Talcott, editor, </editor> <booktitle> Proceedings of the 1994 ACM Conference on Lisp and Functional Programming, LISP Pointers, </booktitle> <volume> Vol. VII, No. </volume> <pages> 3, </pages> <address> Orlando, Florida, June 1994. </address> <publisher> ACM Press. </publisher>
Reference: [39] <author> Ralph Loader. </author> <title> Normalisation by translation. </title> <type> Technical report, </type> <institution> Computing Laboratory, Oxford University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: A recent trend, embodied by partial evaluation, amounts to staging normalization in two steps: a translation into an annotated language, followed by a symbolic evaluation. This technique of normalization by translation appears to be spreading <ref> [39] </ref>. Follow-up work on Berger and Schwichtenberg's algorithm includes Alten-kirch, Hofmann, and Streicher's categorical reconstruction of this algorithm [1]. 6 This reconstruction formalizes the environment of fresh identifiers generated by the reifica-tion of -abstractions as a categorical fibration.
Reference: [40] <author> Karoline Malmkjr, Nevin Heintze, and Olivier Danvy. </author> <title> ML partial evaluation using set-based analysis. </title> <editor> In John Reppy, editor, </editor> <booktitle> Record of the 1994 ACM SIG-PLAN Workshop on ML and its Applications, Rapport 14 de recherche N o 2265, INRIA, </booktitle> <pages> pages 112-119, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year> <note> Also appears as Technical report CMU-CS-94-129. </note>
Reference-contexts: So do all other binding-time analyses [36], with the exception of Con-sel's [12] and Heintze's <ref> [40] </ref>. These analyses are polyvariant and thus they spawn another variant instead of dynamizing. In practice, type-directed partial evaluation needs a simple form of binding-time analysis: a type inferencer where all base types are duplicated into a static version and a dynamic version. <p> It is, however, monovariant. We are currently integrating the residualization algorithm in Pell-Mell, our partial evaluator for ML <ref> [40] </ref>. This algorithm fulfills our need for binding-time coercions at higher types. Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system.
Reference: [41] <author> Torben . Mogensen. </author> <title> Binding Time Aspects of Partial Evaluation. </title> <type> PhD thesis, </type> <institution> DIKU, Computer Science Department, University of Copenhagen, Copenhagen, Denmark, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> The outer occurrence must be declared in the initial run-time environment: (lambda (add) ((lambda (x) (lambda (y) (add (+ x 10) y))) 100)) This limitation may remind one of the need for binding-time separation in some partial evaluators <ref> [36, 41] </ref>. A simple solution, however, exists, that prevents segregation. <p> The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input.
Reference: [42] <author> Eugenio Moggi. </author> <title> Notions of computation and monads. </title> <journal> Information and Computation, </journal> <volume> 93 </volume> <pages> 55-92, </pages> <year> 1991. </year>
Reference-contexts: passing styles: The same technique applies for store-passing, etc. interpreters, be they direct or continuation-passing, and in particular for interpreters that simulate lazy evaluation with thunks. "Monadic" style: We cannot, however, specialize a "monadic" interpreter with respect to a source program because the residual program is parameterized with polymorphic functions <ref> [42, 50] </ref> and these polymorphic functions do not have a simple type.
Reference: [43] <author> Peter D. Mosses. </author> <title> SIS | semantics implementation system, reference manual and user guide. </title> <type> Technical Report MD-30, DAIMI, </type> <institution> Computer Science Department, Aarhus University, Aarhus, Denmark, </institution> <year> 1979. </year>
Reference-contexts: Thus this technique of "type-directed compilation" scales up in practice. In that sense, type-directed partial evaluation provides a simple and effective solution to (de-notational) semantics-directed compilation in the -calculus <ref> [32, 43] </ref>. 2.4 Residualizing the residualizer To visualize the effect of residualization, one can residualize the residualizer with respect to a type.
Reference: [44] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> Two-Level Functional Languages, </title> <booktitle> volume 34 of Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: We present such a method (Section 1.2); it is type directed and we express it using Nielson and Niel-son's two-level -calculus <ref> [44] </ref>. After a first assessment (Section 1.3), we formalize it (Section 1.4) and outline a first application: given a compiled normal form and its type, we can recover its text (Section 1.5). We implement type-directed residualization in Scheme [10] and illustrate it (Section 1.6). <p> These are the usual rules of binding-time analysis, which is otherwise abundantly described in the literature <ref> [4, 6, 11, 15, 36, 37, 41, 44] </ref>. In the rest of this paper, we use Nielson and Nielson's two-level -calculus, which is summarized in Appendix A. Before considering three solutions to analyzing the term above, let us mention a non-solution and why it is a nonsolution. <p> Proof: by structural induction on the types (see Appendix A for the notion of well-typing). Property 1 In the simply typed case, static reduction in the two-level -calculus enjoys both strong normalization and subject reduction <ref> [44] </ref>. <p> It can be easily translated into Haskell (excluding disjoint sums, of course, for lack of computational effects). 5.2 Binding-time analysis All of Nielson and Nielson's binding-time analyses dynamize functions in dynamic contexts because of the difficulties of handling contravariance in program analysis <ref> [44] </ref>. So do all other binding-time analyses [36], with the exception of Con-sel's [12] and Heintze's [40]. These analyses are polyvariant and thus they spawn another variant instead of dynamizing.
Reference: [45] <author> Larry Paulson. </author> <title> Compiler generation from denotational semantics. </title> <editor> In Bernard Lorho, editor, </editor> <booktitle> Methods and Tools for Compiler Construction, </booktitle> <pages> pages 219-250. </pages> <publisher> Cambridge University Press, </publisher> <year> 1984. </year>
Reference-contexts: This makes it simple to residualize recursive procedures | by abstracting their (typed) fixed-point operator. As an example, let us consider Paulson's Tiny language <ref> [45] </ref>, which is a classical example in partial evaluation [6, 8, 6 block res, val, aux in val := read ; aux := 1 ; while val &gt; 0 do aux := aux * val ; val := val - 1 res := aux (lambda (add sub mul eq gt read
Reference: [46] <author> Frank Pfenning. </author> <title> Logic programming in the LF logical framework. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 149-181. </pages> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: We implement type-directed residualization in Scheme [10] and illustrate it (Section 1.6). The restriction of type-directed residualization to the simply typed -calculus actually coincides with Berger and Schwichtenberg's normalization algorithm as presented in the proceedings of LICS'91 [3], and is closely related to Pfenning's normalization algorithm in Elf <ref> [46] </ref> (Section 1.7). Residualization also exhibits a normalization effect. Moving beyond the pure -calculus, we observe that this effect appears for constants and their operators as well (Section 1.8). We harness it to achieve partial evaluation of compiled programs (Section 2). <p> Disregarding the dynamic base types, reflect thus acts as an evaluation functional, and reify acts as its inverse | hence probably the title of Berger and Schwichtenberg's paper [3]. In the implementation of his Elf logic programming language <ref> [46] </ref>, Pfenning uses a similar normalization algorithm to test extensional equality, though with no static/dynamic notion and also with the following difference.
Reference: [47] <author> John C. Reynolds. </author> <title> The essence of Algol. </title> <editor> In van Vliet, editor, </editor> <booktitle> International Symposium on Algorithmic Languages, </booktitle> <pages> pages 345-372, </pages> <address> Amsterdam, 1982. </address> <publisher> North-Holland. </publisher>
Reference-contexts: This - expression is in continuation-passing style [49], i.e., in three-address code. We have extended the definitional -interpreter described in this section to richer languages, including typed higher-order procedures, block structure, and subtyping, a la Reyn-olds <ref> [47] </ref>. Thus this technique of "type-directed compilation" scales up in practice.
Reference: [48] <author> Erik Ruf. </author> <title> Topics in Online Partial Evaluation. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, California, </institution> <note> Feb-ruary 1993. Technical report CSL-TR-93-563. </note>
Reference-contexts: The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5). <p> Type-directed partial evaluation also formalizes and clarifies a number of earlier pragmatic decisions in the system. For example, our treatment of inductive data structures can be seen as lazy insertion of coercions (Section 4.2). 5.4 Self-application Self-application is the best-known way to optimize partial evaluation <ref> [6, 11, 15, 25, 36, 37, 41, 48] </ref>: rather than running the partial evaluator on a source program, with all the symbolic interpretive overhead this entails, one could instead 1. generate a specializer dedicated to this program (a.k.a. "a generating extension"), and 2. run this dedicated specializer on the available input.
Reference: [49] <author> Guy L. Steele Jr. Rabbit: </author> <title> A compiler for Scheme. </title> <type> Technical Report AI-TR-474, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: Essentially, type-directed partial evaluation of the Tiny interpreter acts as a front-end compiler that maps the abstract syntax of a source program into a -expression representing the dynamic semantics of this program [14]. This - expression is in continuation-passing style <ref> [49] </ref>, i.e., in three-address code. We have extended the definitional -interpreter described in this section to richer languages, including typed higher-order procedures, block structure, and subtyping, a la Reyn-olds [47]. Thus this technique of "type-directed compilation" scales up in practice.
Reference: [50] <author> Philip Wadler. </author> <title> The essence of functional programming (tutorial). </title> <editor> In Andrew W. Appel, editor, </editor> <booktitle> Proceedings of the Nineteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-14, </pages> <address> Albuquerque, New Mexico, </address> <month> January </month> <year> 1992. </year> <note> ACM Press. </note>
Reference-contexts: passing styles: The same technique applies for store-passing, etc. interpreters, be they direct or continuation-passing, and in particular for interpreters that simulate lazy evaluation with thunks. "Monadic" style: We cannot, however, specialize a "monadic" interpreter with respect to a source program because the residual program is parameterized with polymorphic functions <ref> [42, 50] </ref> and these polymorphic functions do not have a simple type.
Reference: [51] <author> Daniel Weise, Roland Conybeare, Erik Ruf, and Scott Seligman. </author> <title> Automatic online partial evaluation. </title> <editor> In John Hughes, editor, </editor> <booktitle> Proceedings of the Fifth ACM Conference on Functional Programming and Computer Architecture, number 523 in Lecture Notes in Computer Science, </booktitle> <pages> pages 165-191, </pages> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: The last ten years have seen two flavors of partial evaluation emerge: online and o*ine. O*ine partial evaluation is staged into two components: program analysis and program specialization. Online partial evaluation is more monolithic. Extensive work on both sides <ref> [6, 11, 15, 34, 36, 41, 48, 51] </ref> has led to the conclusions of both the usefulness of program analysis and the need for online partial evaluation in a program specializer (as illustrated in Section 4.5).
References-found: 51

