URL: ftp://theory.lcs.mit.edu/pub/people/oded/tiny.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/complexity.html
Root-URL: 
Title: Tiny Families of Functions with Random Properties: A Quality-Size Trade-off for Hashing  
Author: Oded Goldreich Avi Wigderson 
Keyword: Randomness and Computation, Randomness Extractors, Sampling Algorithms, Random-Looking Functions, Expander Graphs, Ramanujan Graphs, Universal Hashing, Small-Biased Probability Spaces, Lindsey's Lemma.  
Note: Research was supported in part by grant No. 92-00226 from the United States Israel Binational Science Foun dation (BSF), Jerusalem, Israel. Research was supported in part by the Wolfson Research Awards, administered by the Israel Academy of Sciences and Humanities.  
Date: March 21, 1997  
Address: Rehovot, Israel.  Givat Ram Jerusalem, Israel.  
Affiliation: Department of Computer Science and Applied Mathematics Weizmann Institute of Science  Institute for Computer Science Hebrew University  
Abstract: We present three explicit constructions of hash functions, which exhibit a trade-off between the size of the family (and hence the number of random bits needed to generate a member of the family), and the quality (or error parameter) of the pseudo-random property it achieves. Unlike previous constructions, most notably universal hashing, the size of our families is essentially independent of the size of the domain on which the functions operate. The first construction is for the mixing property mapping a proportional part of any subset of the domain to any other subset. The other two are for the extraction property mapping any subset of the domain almost uniformly into a range smaller than it. The second and third constructions handle (respectively) the extreme situations when the range is very large or very small. We provide lower bounds showing that our constructions are nearly optimal, and mention some applications of the new constructions. fl An extended abstract of this paper has appeared in the 26th ACM Symposium on Theory of Computing (STOC 94) held in Montreal, Quebec, Canada, May 23-25, 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, E. Szemeredi, </author> <title> "Deterministic Simulation in LogSpace", </title> <booktitle> Proc. 19th STOC, </booktitle> <year> 1987, </year> <pages> pp. 132-140. </pages>
Reference-contexts: The following lemma refers to the effect of a single random step. It follows easily by the standard techniques of dealing with random walks on expander graphs (cf., <ref> [1, 6] </ref>). Lemma 2.3 (Expander Smoothing Lemma): Let G = (V; E), d and be as in the previous lemma. <p> Namely, there is a value function defined over a huge space, say - : f0; 1g n 7! <ref> [0; 1] </ref>, and one wishes to approximate - def 2 n x2f0;1g n -(x). To this end, one may randomly select a small sample set S and compute 1 jSj x2S -(x). <p> Definition 6.1 (sampler): A sampler is a randomized algorithm that on input parameters n (length), * (accuracy) and ffi (error), and oracle access to any function - : f0; 1g n 7! <ref> [0; 1] </ref>, outputs, with probability at least 1 ffi, a value that is at most * away from - def 2 n x2f0;1g n -(x). Namely, Prob (jsampler -(n; *; ffi) -j &gt; *) &lt; ffi where the probability is taken over the internal coin tosses of the sampler. <p> The estimate of the sampler is merely the average (of -) over the values at these u j 's; namely, ~- = m j=1 Clearly, the complexities are as claimed in Theorem 6.2. It is left to show that for every - : f0; 1g n 7! <ref> [0; 1] </ref>, Prob (j~- -j &gt; *) &lt; ffi We first observe that it suffices to evaluate the behavior of the sampler on functions of the form - : f0; 1g n 7! f (i 1 2 : i = 1; ::; 2* 1 g. <p> Specifically, for every - : f0; 1g n 7! <ref> [0; 1] </ref>, there exists a : f0; 1g n 7! f (i 1 2 : i = 1; ::; 2* 1 g so that j-(x) (x)j * 4 , 8x 2 f0; 1g n .
Reference: [2] <author> N. Alon, </author> <title> "Eigenvalues, Geometric Expanders, Sorting in Rounds and Ramsey Theory", </title> <journal> Combinatorica, </journal> <volume> 6 (1986), </volume> <pages> pp. 231-243. </pages>
Reference-contexts: B S 0 so that jBj 4 * jSj (17) fl fl fl jBj (s 1 ;:::;s t )2B P t fl fl fl p 2 2* p p * p Contradiction follows by contrasting Eq. (18) with the following lemma, which generalizes Lindsey's Lemma (cf., [13, p. 88] and <ref> [2] </ref>). Lemma 5.2 (A Generalized Lindsey's Lemma): Let A be an N -by-M matrix of complex numbers, so that each row has inner-product 5 with itself equal to M and each pair of different rows have inner-product bounded (in magnitude) by * 0 M .
Reference: [3] <author> N. Alon, J. Bruck, J. Naor, M. Naor and R. Roth, </author> <title> "Construction of Asymptotically Good, Low-Rate Error-Correcting Codes through Pseudo-Random Graphs", </title> <journal> IEEE Transactions on Information Theory 38 (1992), </journal> <pages> pp. 509-516. </pages>
Reference-contexts: Here some minor technicalities arise as these graphs are given only for certain degrees and certain sizes. Specifically, they can be efficiently constructed for 1 2 q k (q 2k 1) vertices, where q d 1 1 mod 4 and d 1 being a quadratic residue modulo q (cf., <ref> [3, Sec. II] </ref>). Still, fixing d and *; N , we may find a q satisfying the above conditions with 1 2 q k (q 2k 1) 2 [(1 *) N; N ], in time polynomial in 1=*.
Reference: [4] <author> N. Alon, O. Goldreich, J. Hastad, R. Peralta, </author> <title> "Simple Constructions of Almost k-wise Independent Random Variables", </title> <journal> Journal of Random structures and Algorithms, </journal> <volume> Vol. 3, No. 3, </volume> <year> (1992), </year> <pages> pp. 289-304. </pages>
Reference-contexts: That is, fl fl Exp (s 1 ;:::;s t )2S ! i=1 a i s i fl The following theorem, due to G. Even [14], is obtained by generalizing a construction of Alon et. al. <ref> [4] </ref>. Specifically, Even generalizes the LFSR construction by considering sequences over GF (p) (rather than over GF (2)). <p> Typically, such random variables are defined by the uniform distribution over some sample space S GF (p) t . We will use such a sample space, S, for bias * 0 = poly (*=p) (to be specified later). Hence, using the sample space of <ref> [4, 14] </ref>, we have jSj = poly (n=* 0 ) = poly (n p=*) = poly (n2 m =*). 14 Our construction. The functions in our family, denoted F , correspond to the samples in the small-bias space. <p> Standard modifications can be applied to derive functions mapping f0; 1g n to f0; 1g m (recall p 2 m and p t 2 n ). 5.3 Analysis Our analysis uses the fact that the construction of small-bias spaces of <ref> [4, 14] </ref> satisfies a bound on an exponential sum related to the above intuitive motivation to small-bias spaces (see Definition 2.4). We then prove a Lindsey-like lemma on near-orthogonal vectors and combine it with the bound above to give the result.
Reference: [5] <author> N. Alon and V.D. Milman, </author> <title> 1 , Isoperimetric Inequalities for Graphs and Superconcentrators, </title> <journal> J. Combinatorial Theory, Ser. </journal> <volume> B 38 (1985), </volume> <pages> pp. 73-88. </pages>
Reference-contexts: The question is whether jE i (A;B)j jV j is approximately jAj jV j jBj jV j , for almost all 1 i d. One can easily verify that, in general, the answer is negative. Specifically, for Cayley Graph expanders (e.g., <ref> [25, 5, 16, 24] </ref>), there are sets A and B for which there exist no i such that jE i (A;B)j jV j approximates jAj jV j (e.g., consider the cosets obtained by omitting one generator).
Reference: [6] <author> N. Alon and J.H. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992. </year>
Reference-contexts: Then for every two subsets, A; B V , it holds fi fi j (A fi B) " Ej jV j jBj fi fi jAj jBj &lt; d The lemma (and a proof) appears as Corollary 2.5 in <ref> [6, Chap. 9] </ref>. 3 The are minor technicalities which can be easily fixed. Firstly, the Gaber-Galil expanders are defined (only) for graph sizes which are perfect squares [16]. This suffices for even n's. <p> The following lemma refers to the effect of a single random step. It follows easily by the standard techniques of dealing with random walks on expander graphs (cf., <ref> [1, 6] </ref>). Lemma 2.3 (Expander Smoothing Lemma): Let G = (V; E), d and be as in the previous lemma.
Reference: [7] <author> M. Bellare, O. Goldreich, and S. </author> <title> Goldwasser "Randomness in Interactive Proofs", </title> <journal> Computational Complexity, </journal> <volume> Vol. 4, No. 4 (1993), </volume> <pages> pp. 319-354. </pages>
Reference-contexts: The previous best algorithm (by <ref> [7] </ref>) had randomness complexity 2n + O (log (1=ffi)), provided * &gt; 2 n . consists of uniformly selecting a single vertex and outputting the average of the function values on all its neighbors. Both these constructions are analyzed below. <p> Both these constructions are analyzed below. The sampler guaranteed in Theorem 6.2 is not optimal in its query complexity (specifically, the dependency on ffi is bad). However, this can be easily redeemed using a generic method of Bellare et al <ref> [7] </ref>: Given a sampler of query complexity q (n; *; ffi) and randomness complexity r (n; *; ffi) they obtain a sampler having query complexity O (q (n; *; 0:1) log (1=ffi)) and randomness complexity r (n; *; 0:1) + O (log (1=ffi)). <p> Previously, efficient samplers with optimal sample-complexity were known only for twice the optimal randomness-complexity <ref> [7] </ref> (yet, [8] have proved non-constructively that "samplers" with sample and randomness complexities as in the corollary do exist 7 ). The known results are summarized in Figure 1. <p> This is done by using a Ramanujan Expander (rather than an arbitrary expander) in the method of Bellare et al <ref> [7] </ref>. <p> As in the general case, Theorem 6.5 will follow by employing the method of Bellare et. al. <ref> [7] </ref> to an even simpler sampler asserted in Lemma 6.6 (below). This latter sampling algorithm uses, in an essential way, an efficiently constructible Ramanujan (expander) Graph [24]; namely, d-regular expanders with second eigenvalue, , satisfying 2 p d (rather than merely &lt; d 1 1 O (1) ).
Reference: [8] <author> R. Canetti, G. Even and O. Goldreich, </author> <title> "Lower Bounds for Sampling Algorithms for Estimating the Average", </title> <journal> IPL, </journal> <volume> Vol. 53, </volume> <pages> pp. 17-25, </pages> <year> 1995. </year>
Reference-contexts: Furthermore, for the special case of Boolean functions, an optimal sampler utilizes a Ramanujan graph of degree O (1=* 2 ffi) and 18 lower bound <ref> [8] </ref> upper bound [8] algorithms (this paper) Boolean n + log 2 (1=ffi) n + 2 log 2 (2=ffi) n + O (log (1=ffi)) (Thm. 6.5) functions 2 log 2 (1=*) log 2 log 2 (1=ffi) O (1) general n + log 2 (1=ffi) n + 2 log 2 (2=ffi) n <p> Furthermore, for the special case of Boolean functions, an optimal sampler utilizes a Ramanujan graph of degree O (1=* 2 ffi) and 18 lower bound <ref> [8] </ref> upper bound [8] algorithms (this paper) Boolean n + log 2 (1=ffi) n + 2 log 2 (2=ffi) n + O (log (1=ffi)) (Thm. 6.5) functions 2 log 2 (1=*) log 2 log 2 (1=ffi) O (1) general n + log 2 (1=ffi) n + 2 log 2 (2=ffi) n + O (log <p> This sampler is optimal (up to a multiplicative factor) in its sample-complexity <ref> [8, Thm. 1] </ref>, and among the samplers with nearly optimal sample complexity it is optimal (up to the additive logarithmic factors) in its randomness-complexity [8, Thm. 2]. <p> This sampler is optimal (up to a multiplicative factor) in its sample-complexity [8, Thm. 1], and among the samplers with nearly optimal sample complexity it is optimal (up to the additive logarithmic factors) in its randomness-complexity <ref> [8, Thm. 2] </ref>. Previously, efficient samplers with optimal sample-complexity were known only for twice the optimal randomness-complexity [7] (yet, [8] have proved non-constructively that "samplers" with sample and randomness complexities as in the corollary do exist 7 ). The known results are summarized in Figure 1. <p> Previously, efficient samplers with optimal sample-complexity were known only for twice the optimal randomness-complexity [7] (yet, <ref> [8] </ref> have proved non-constructively that "samplers" with sample and randomness complexities as in the corollary do exist 7 ). The known results are summarized in Figure 1. <p> Furthermore, to get an algorithm which samples the universe only on O (1=ffi* 2 ) points, it is crucial to use a Ramanujan graph in role of the expander in the Karp-Pippinger-Sipser method. 7 Actually, the non-constructive upper bound of <ref> [8, Cor. 2] </ref> is slightly better than the result of Corollary 6.3. 19 Definition 6.4 (Boolean sampler): A Boolean sampler is a randomized algorithm, denoted A, which satisfies Prob (jA -(n; *; ffi) -j &gt; *) &lt; ffi for every Boolean function - : f0; 1g n 7! f0; 1g.
Reference: [9] <author> L. Carter and M. Wegman, </author> <title> "Universal Classes of Hash Functions", </title> <journal> J. Computer and System Sciences, </journal> <volume> Vol. 18, </volume> <pages> pp. </pages> <month> 143-154 </month> <year> (1979). </year>
Reference-contexts: 1 Introduction In 1979, Carter and Wegman introduced the notion of universal hashing functions <ref> [9] </ref>. Though these functions were introduced with data storage application in mind, they found many applications to complexity theory [30, 32, 34, 18, 17, 21, 22, 19, 20, 27, 28, 36]. <p> Several efficient families of universal hashing functions are known <ref> [9] </ref>. The functions in these families can be described using O (n + m) bits and posses an efficient (e.g., polynomial-time and even logspace) evaluating algorithms. For example, linear transformations with Toeplitz 2 matrices require only n + 2m 1 bits.
Reference: [10] <author> B. Chor and O. Goldreich, </author> <title> "Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity", </title> <journal> SIAM J. Comput., </journal> <volume> Vol. 17, No. 2, </volume> <month> April </month> <year> 1988, </year> <pages> pp. 230-261. </pages>
Reference-contexts: Actually, we consider a generalization of the extraction problem to random variables with an upper bound, of 1 K2 m , on the probability function. Such a bound is called min-entropy (cf., Chor and Goldreich <ref> [10] </ref>). Definition 4.1 (min-entropy): Let X be a random variable.
Reference: [11] <author> B. Chor and O. Goldreich, </author> <title> "On the Power of Two-Point Based Sampling," </title> <journal> Jour. of Complexity, </journal> <volume> Vol 5, </volume> <year> 1989, </year> <pages> pp. 96-106. </pages>
Reference-contexts: Whereas generating t totally independent random points in f0; 1g n requires t n unbiased coin flips, one can generate t pairwise-independent random points using only 2 n unbiased coin flips <ref> [11] </ref>. Using the new family of mixing functions, we were able to reduce the randomness complexity of the approximation problem to n + O (log (1=*)), while maintaining the number of sample points (up-to a multiplicative constant). <p> Here we also use a sample space for sequences of pairwise independent elements uniformly distributed in [d]. In particular, we use sequences of length m def * 2 ffi which can be efficiently generated using 2 log 2 d = O (log (1=*ffi)) random bits (cf., <ref> [11] </ref>). The sampler. We select uniformly a vertex v (in the expander graph) and a sequence of m pairwise-independent elements in [d], denoted, i 1 ; :::; i m .
Reference: [12] <author> A. Cohen and A. Wigderson, "Dispensers, </author> <title> Deterministic Amplification, and Weak Random Sources", </title> <booktitle> 30th FOCS, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference: [13] <author> P. Erdos and J. Spencer, </author> <title> Probabilistic Methods in Combinatorics, </title> <publisher> Academic Press, </publisher> <year> 1974. </year> <month> 23 </month>
Reference-contexts: This yields, B S 0 so that jBj 4 * jSj (17) fl fl fl jBj (s 1 ;:::;s t )2B P t fl fl fl p 2 2* p p * p Contradiction follows by contrasting Eq. (18) with the following lemma, which generalizes Lindsey's Lemma (cf., <ref> [13, p. 88] </ref> and [2]). Lemma 5.2 (A Generalized Lindsey's Lemma): Let A be an N -by-M matrix of complex numbers, so that each row has inner-product 5 with itself equal to M and each pair of different rows have inner-product bounded (in magnitude) by * 0 M .
Reference: [14] <author> G. </author> <title> Even, "Construction of Small Probability Spaces for Deterministic Simulation", M.Sc. </title> <type> thesis, </type> <institution> Computer Science Department, Technion, Haifa, Israel, </institution> <year> 1991. </year> <note> (In Hebrew, abstract in English) </note>
Reference-contexts: That is, fl fl Exp (s 1 ;:::;s t )2S ! i=1 a i s i fl The following theorem, due to G. Even <ref> [14] </ref>, is obtained by generalizing a construction of Alon et. al. [4]. Specifically, Even generalizes the LFSR construction by considering sequences over GF (p) (rather than over GF (2)). <p> Even [14], is obtained by generalizing a construction of Alon et. al. [4]. Specifically, Even generalizes the LFSR construction by considering sequences over GF (p) (rather than over GF (2)). Theorem 2.5 <ref> [14, 15] </ref>: For every integer t, prime p and * &gt; 0, there exists an efficiently con structible *-bias sample space for GF (p) t of size (2t=*) 2 . 3 Tiny Families of Functions with Mixing Properties Recall that a function f is mixing for subsets A and B of <p> Typically, such random variables are defined by the uniform distribution over some sample space S GF (p) t . We will use such a sample space, S, for bias * 0 = poly (*=p) (to be specified later). Hence, using the sample space of <ref> [4, 14] </ref>, we have jSj = poly (n=* 0 ) = poly (n p=*) = poly (n2 m =*). 14 Our construction. The functions in our family, denoted F , correspond to the samples in the small-bias space. <p> Standard modifications can be applied to derive functions mapping f0; 1g n to f0; 1g m (recall p 2 m and p t 2 n ). 5.3 Analysis Our analysis uses the fact that the construction of small-bias spaces of <ref> [4, 14] </ref> satisfies a bound on an exponential sum related to the above intuitive motivation to small-bias spaces (see Definition 2.4). We then prove a Lindsey-like lemma on near-orthogonal vectors and combine it with the bound above to give the result.
Reference: [15] <author> G. Even, O. Goldreich, M. Luby, N. Nisan, and B. Velickovic, </author> <title> "Approximations of General Independent Distributions", </title> <booktitle> 24th STOC, </booktitle> <pages> pp. 10-16, </pages> <year> 1992. </year>
Reference-contexts: Even [14], is obtained by generalizing a construction of Alon et. al. [4]. Specifically, Even generalizes the LFSR construction by considering sequences over GF (p) (rather than over GF (2)). Theorem 2.5 <ref> [14, 15] </ref>: For every integer t, prime p and * &gt; 0, there exists an efficiently con structible *-bias sample space for GF (p) t of size (2t=*) 2 . 3 Tiny Families of Functions with Mixing Properties Recall that a function f is mixing for subsets A and B of
Reference: [16] <author> O. Gaber and Z. Galil, </author> <title> "Explicit Constructions of Linear Size Superconcentrators", </title> <journal> JCSS, </journal> <volume> 22 (1981), </volume> <pages> pp. 407-420. </pages>
Reference-contexts: We first recall that for d = 16 and some &lt; 16, efficiently constructible (16; )-families do exist (cf., <ref> [16] </ref>) 3 . In our applications we use (parameterized) expanders satisfying d &lt; ff and d = poly (1=ff), where ff is an application-specific parameter. Such (parameterized) expanders are also efficiently constructible. <p> Firstly, the Gaber-Galil expanders are defined (only) for graph sizes which are perfect squares <ref> [16] </ref>. This suffices for even n's. For odd n's, we may use a trivial modification, such as taking two copies of the graph of size 2 n1 and connecting each pair of corresponding vertices. <p> The question is whether jE i (A;B)j jV j is approximately jAj jV j jBj jV j , for almost all 1 i d. One can easily verify that, in general, the answer is negative. Specifically, for Cayley Graph expanders (e.g., <ref> [25, 5, 16, 24] </ref>), there are sets A and B for which there exist no i such that jE i (A;B)j jV j approximates jAj jV j (e.g., consider the cosets obtained by omitting one generator).
Reference: [17] <author> O. Goldreich, H. Krawcyzk and M. Luby, </author> <title> "On the Existence of Pseudorandom Generators", </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. </volume> <month> 22-6 (Dec. </month> <year> 1993), </year> <pages> pp. 1163-1175. </pages>
Reference-contexts: The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources [36], pseudorandom generators <ref> [17, 21] </ref> and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice.
Reference: [18] <author> S. Goldwasser and M. Sipser, </author> <title> "Private Coins versus Public Coins in Interactive Proof Systems", </title> <booktitle> Advances in Computing Research: a research annual, Vol. 5 (Randomness and Computation, </booktitle> <editor> S. Micali, </editor> <publisher> ed.), </publisher> <pages> pp. 73-90, </pages> <year> 1989. </year>
Reference-contexts: The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources [36], pseudorandom generators [17, 21] and interactive proofs <ref> [18] </ref>. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice. Hence, we assume for simplicity that m = n.
Reference: [19] <author> R. Impagliazzo and M. Luby, </author> <title> "One-Way Functions are Essential for Complexity Based Cryptography", </title> <booktitle> 30th FOCS, </booktitle> <pages> pp. 230-235, </pages> <year> 1989. </year>
Reference: [20] <author> R. Impagliazzo and L.A. Levin, </author> <title> "No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random ", 31st FOCS, </title> <journal> pp. </journal> <pages> 812-821, </pages> <year> 1990. </year>
Reference: [21] <author> R. Impagliazzo, L.A. Levin, and M.G. Luby, </author> <title> "Pseudorandom Generators from any One-Way Functions", </title> <booktitle> 21st STOC, </booktitle> <pages> pp. 12-24, </pages> <year> 1989. </year>
Reference-contexts: The parameter K &gt; 1 determines the quality of the approximation to the uniform distribution and the fraction of bad functions in F (i.e. those that don't achieve this approximation). The extraction property is the heart of the Leftover Hash Lemma <ref> [21] </ref> and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources [36], pseudorandom generators [17, 21] and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in <p> The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources [36], pseudorandom generators <ref> [17, 21] </ref> and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice. <p> The set of random variables fh (x)jx 2 f0; 1g n g defined by a random h 2 H are pairwise independent and uniformly distributed in f0; 1g m . Leftover Hash Lemma. This fundamental lemma of <ref> [21] </ref> asserts that a random hash function from a universal family will smooth min-entropy k whenever the range parameter m is smaller than k. More precisely Lemma 2.1 (Leftover Hash Lemma [21]): Let X be any random variable on f0; 1g n with min-entropy k (i.e., Prob (X = x) 2 <p> Leftover Hash Lemma. This fundamental lemma of <ref> [21] </ref> asserts that a random hash function from a universal family will smooth min-entropy k whenever the range parameter m is smaller than k. More precisely Lemma 2.1 (Leftover Hash Lemma [21]): Let X be any random variable on f0; 1g n with min-entropy k (i.e., Prob (X = x) 2 k for all x's).
Reference: [22] <author> R. Impagliazzo and D. Zuckerman, </author> <title> "How to Recycle Random Bits", </title> <booktitle> 30th FOCS, </booktitle> <year> 1989, </year> <pages> pp. 248-253. </pages>
Reference-contexts: The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness <ref> [22] </ref>, weak random sources [36], pseudorandom generators [17, 21] and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice.
Reference: [23] <author> R.M. Karp, N. Pippinger and M. Sipser, </author> <title> "A Time-Randomness Tradeoff", </title> <booktitle> AMS Conference on Probabilistic Computational Complexity, </booktitle> <address> Durham, New Hampshire (1982). </address>
Reference-contexts: This simpler sampler has even lower randomness complexity (specifically n instead of n + O (log (1=*))). Our sampling procedure is exactly the one suggested by Karp, Pippinger and Sipser for hitting a witness set <ref> [23] </ref>, yet the analysis is somewhat more involved.
Reference: [24] <author> A. Lubotzky, R. Phillips, P. Sarnak, </author> <title> "Explicit Expanders and the Ramanujan Conjectures", </title> <booktitle> Proc. 18th STOC, </booktitle> <year> 1986, </year> <pages> pp. 240-246. </pages>
Reference-contexts: This yields a constructible (16 k ; k )-family, and both k 16 k &lt; ff and 16 k = poly (1=ff) indeed hold. To obtain the best constants in Sections 3, 4 and 6.2, one may use efficiently constructible Ramanujan Graphs <ref> [24] </ref>. Furthermore, using Ramanujan Graphs is essential for our proof of The orem 6.5. Ramanujan Graphs satisfy 2 p d and so, setting d = 4=ff, we obtain d &lt; ff, where ff is an application-specific parameter. <p> The question is whether jE i (A;B)j jV j is approximately jAj jV j jBj jV j , for almost all 1 i d. One can easily verify that, in general, the answer is negative. Specifically, for Cayley Graph expanders (e.g., <ref> [25, 5, 16, 24] </ref>), there are sets A and B for which there exist no i such that jE i (A;B)j jV j approximates jAj jV j (e.g., consider the cosets obtained by omitting one generator). <p> As in the general case, Theorem 6.5 will follow by employing the method of Bellare et. al. [7] to an even simpler sampler asserted in Lemma 6.6 (below). This latter sampling algorithm uses, in an essential way, an efficiently constructible Ramanujan (expander) Graph <ref> [24] </ref>; namely, d-regular expanders with second eigenvalue, , satisfying 2 p d (rather than merely &lt; d 1 1 O (1) ).
Reference: [25] <author> G.A. Margulis, </author> <title> "Explicit Construction of Concentrators", </title> <journal> Prob. Per. Infor. </journal> <volume> 9 (4) (1973), </volume> <month> 71-80. </month> <title> (In Russian, English translation in Problems of Infor. </title> <journal> Trans. </journal> <year> (1975), </year> <pages> 325-332.) </pages>
Reference-contexts: The question is whether jE i (A;B)j jV j is approximately jAj jV j jBj jV j , for almost all 1 i d. One can easily verify that, in general, the answer is negative. Specifically, for Cayley Graph expanders (e.g., <ref> [25, 5, 16, 24] </ref>), there are sets A and B for which there exist no i such that jE i (A;B)j jV j approximates jAj jV j (e.g., consider the cosets obtained by omitting one generator).
Reference: [26] <author> J. Naor and M. Naor, </author> <title> "Small-bias Probability Spaces: Efficient Constructions and Applications", </title> <journal> SIAM J. on Computing, </journal> <volume> Vol 22, </volume> <year> 1993, </year> <pages> pp. 838-856. </pages>
Reference: [27] <author> N. Nisan, </author> <title> "Pseudorandom Generators for Space Bounded Computation", </title> <type> Combinatorica 12 (4), </type> <year> 1992, </year> <pages> pp. 449-461. </pages>
Reference-contexts: The prime use of the mixing property is in the logspace pseudorandom generators of Nisan <ref> [27, 28] </ref>. In the definitions above, there is an error parameter * (e.g. the fraction of bad functions, the distance from the uniform distribution etc.), which determines the quality of the mixing or extraction achieved by the family F . <p> For sampling procedures, which use an asymptotically optimal number of sample points, the amount of randomness required to generate the sample points is reduced by a factor of 2, yielding an optimal result up-to a small additive term; and 2. The randomness complexity of Nisan's "generalized logspace" generator <ref> [27] </ref>, is reduced by a logarithmic factor. The second construction implies a randomness-efficient leftover hash lemma, which is particularly appealing in case n m t n. <p> We state the precise theorem, then describe the construction. We prove that our family has optimal size up to a polynomial, and present an application: saving randomness in the generalized logspace model of <ref> [27] </ref>. We conclude with a different perspective of this result, advocated by Linial. 3.1 Main result Theorem 3.1 (The Mixing Family): Let n be an integer and * &gt; 2 n=O (1) . <p> On the other hand, (A) (B) = (1=2t) 2 , and the theorem follows (even for the special case of hitting A fi B when (A) (B) *). 3.5 Application to Generalized Random Logspace In <ref> [27] </ref>, Nisan considered the problem of saving randomness in a context in which m randomized algorithms are executed and their output is fed to an s-space bounded machine which then produces a final Boolean output. (Actually, the problem is not affected if the s-space machine is allowed to have output of <p> The obvious way of running the entire procedure requires m n coin flips. In case we are willing to tolerate an * additive error/deviation in the final output, more randomness-efficient solutions are possible. In particular, Nisan showed <ref> [27] </ref> that the randomness complexity can be decreased to O (maxfn; s + log (m=*)g log m) Replacing the universal hash functions used in [27] by our family of mixing functions, we note that the above problem can be solved with randomness complexity n + O ((s + log (m=*)) log <p> In case we are willing to tolerate an * additive error/deviation in the final output, more randomness-efficient solutions are possible. In particular, Nisan showed <ref> [27] </ref> that the randomness complexity can be decreased to O (maxfn; s + log (m=*)g log m) Replacing the universal hash functions used in [27] by our family of mixing functions, we note that the above problem can be solved with randomness complexity n + O ((s + log (m=*)) log m) We remark that in many applications n s + log (m=*).
Reference: [28] <author> N. Nisan, </author> <title> "RL SC", </title> <journal> Journal of Computational Complexity 4, </journal> <year> 1994, </year> <pages> pp. 1-11. </pages>
Reference-contexts: The prime use of the mixing property is in the logspace pseudorandom generators of Nisan <ref> [27, 28] </ref>. In the definitions above, there is an error parameter * (e.g. the fraction of bad functions, the distance from the uniform distribution etc.), which determines the quality of the mixing or extraction achieved by the family F .
Reference: [29] <author> N. Nisan and D. Zuckerman, </author> <title> "Randomness is Linear in Space", </title> <note> to appear in JCSS. Preliminary version in 25th STOC, pp. 235-244, 1993. 24 </note>
Reference-contexts: The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources [36], pseudorandom generators [17, 21] and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in <ref> [29] </ref>, with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice. Hence, we assume for simplicity that m = n. <p> The only previous result achieving such a quality-size trade-off is by Nisan and Zuckerman <ref> [29] </ref>. They deal with the extraction problem in the difficult range m = fi (n) (which we cannot handle), via an ingenious construction, following earlier work of Zuckerman [36]. <p> In fact, in preliminary versions of this work we have used the extractors of <ref> [29] </ref> in order to derive alternative constructions with size k O (log (1=*) . However, these alternative constructions are subsumed by Zuckerman's recent work [37]. 4.3 Analysis Despite the apparent similarity to the construction for mixing, the analysis of the current construction is completely different. <p> = * 6 2 3+ck , and using n m k = 6 + ck + (8 + c) log (1=*), the first term in Eq. (14) is bounded by * 2 =4, and the lemma follows. 13 4.4 Lower Bound We conclude by observing that a lower bound of <ref> [29] </ref> (i.e., [29, Thm 3]) implies that, for * = 2 (k) , our construction is optimal. This holds even when trying to extract just one bit. <p> 6 2 3+ck , and using n m k = 6 + ck + (8 + c) log (1=*), the first term in Eq. (14) is bounded by * 2 =4, and the lemma follows. 13 4.4 Lower Bound We conclude by observing that a lower bound of [29] (i.e., <ref> [29, Thm 3] </ref>) implies that, for * = 2 (k) , our construction is optimal. This holds even when trying to extract just one bit. <p> Substituting *=2 for *, the theorem follows. 17 5.4 Lower Bound To illustrate that our construction is near optimal when k = O (log n) we recall a lower bound of <ref> [29] </ref> (already mentioned in Section 4.4). We stress that the bound holds even when trying to extract just one bit. <p> We stress that the bound holds even when trying to extract just one bit. Theorem 5.3 <ref> [29, Thm. 3] </ref>: A family of functions from f0; 1g n to f0; 1g, with extraction property of accuracy * &lt; 0:5 with respect to random variables of min-entropy k n 1, must have size at least maxfn k + 1; (1=*) 1g.
Reference: [30] <author> M. Sipser, </author> <title> "A Complexity Theoretic Approach to Randomness", </title> <booktitle> 15th STOC, </booktitle> <year> 1983, </year> <pages> pp. 330-335. </pages>
Reference: [31] <author> M. Sipser, "Expanders, </author> <title> Randomness or Time vs Space", </title> <booktitle> Structure in Complexity Theory (proceedings), </booktitle> <year> 1986. </year>
Reference: [32] <author> L. Stockmeyer, </author> <title> "The Complexity of Approximate Counting", </title> <booktitle> 15th STOC, </booktitle> <year> 1983, </year> <pages> pp. 118-126. </pages>
Reference: [33] <author> A. Srinivasan and D. Zuckerman, </author> <title> "Computing with Very Weak Random Sources", </title> <booktitle> 35th FOCS, </booktitle> <pages> pp. 264-275, </pages> <year> 1994. </year>
Reference-contexts: In addition, they applied their extractors to show that poly (S) many random bits add no power at all to space (S) Turing machines. (Actually, they showed how to simulate poly (S) many random bits, in space (S) computations by using O (S) many random coins.) Srinivasan and Zuckerman <ref> [33] </ref> have independently discovered a construction similar to our third construction. Their construction is different and its analysis is simpler than the analysis of our construction. <p> Their construction is different and its analysis is simpler than the analysis of our construction. Furthermore, they have used such a construction as the main technical tool in reducing the size of extractors, for the range m = fi (n). Subsequently, Zuckerman [37], using ideas from <ref> [35, 33] </ref>, obtained nearly optimal results for the extraction problem in the range m = fi (n). This construction has numerous applications which we shall not elaborate here. <p> We note that the BP P simulation of <ref> [33] </ref> mentioned in the introduction uses an extracting family for this value of the parameter k. 6 A New Sampling Procedure In many settings repeated sampling is used to estimate the average value of a huge set of values.
Reference: [34] <author> L. Valiant and V.V. Vazirani, </author> <title> "NP is as Easy as Detecting Unique Solutions", </title> <journal> Theoretical Computer Science, </journal> <volume> Vol. 47, </volume> <year> 1986, </year> <pages> pp. 85-93. </pages>
Reference: [35] <author> A. Wigderson, D. Zuckerman, </author> " <title> Expanders that Beat the Eigenvalue Bound, Explicit Construction and Applications", </title> <booktitle> Proc. of the 25th STOC, </booktitle> <pages> pp. 245-251, </pages> <year> 1993. </year> <note> To appear in Combinatorica. </note>
Reference-contexts: Their construction is different and its analysis is simpler than the analysis of our construction. Furthermore, they have used such a construction as the main technical tool in reducing the size of extractors, for the range m = fi (n). Subsequently, Zuckerman [37], using ideas from <ref> [35, 33] </ref>, obtained nearly optimal results for the extraction problem in the range m = fi (n). This construction has numerous applications which we shall not elaborate here.
Reference: [36] <author> D. Zuckerman, </author> <title> "Simulating BPP Using a General Weak Random Source," </title> <journal> Algorithmica, </journal> <volume> Vol. 16, </volume> <pages> pp. 367-391, </pages> <year> 1996. </year>
Reference-contexts: The extraction property is the heart of the Leftover Hash Lemma [21] and its precursors, which were key to numerous results, e.g. in saving randomness [22], weak random sources <ref> [36] </ref>, pseudorandom generators [17, 21] and interactive proofs [18]. (Alternative function families with extraction property were previously constructed in [29], with a variety of other applications.) The mixing property is meaningful also in case m = n, and in fact it is commonly used with this choice. <p> The only previous result achieving such a quality-size trade-off is by Nisan and Zuckerman [29]. They deal with the extraction problem in the difficult range m = fi (n) (which we cannot handle), via an ingenious construction, following earlier work of Zuckerman <ref> [36] </ref>.
Reference: [37] <author> D. Zuckerman, </author> <title> "Randomness-Optimal Sampling, Extractors, and Constructive Leader Election", </title> <booktitle> 28th STOC, </booktitle> <year> 1996, </year> <pages> pp. 286-295. 25 </pages>
Reference-contexts: Their construction is different and its analysis is simpler than the analysis of our construction. Furthermore, they have used such a construction as the main technical tool in reducing the size of extractors, for the range m = fi (n). Subsequently, Zuckerman <ref> [37] </ref>, using ideas from [35, 33], obtained nearly optimal results for the extraction problem in the range m = fi (n). This construction has numerous applications which we shall not elaborate here. <p> In fact, in preliminary versions of this work we have used the extractors of [29] in order to derive alternative constructions with size k O (log (1=*) . However, these alternative constructions are subsumed by Zuckerman's recent work <ref> [37] </ref>. 4.3 Analysis Despite the apparent similarity to the construction for mixing, the analysis of the current construction is completely different. In particular, it is based on "stronger" technical tools: the Expander Smoothing Lemma and the Leftover Hash Lemma. Clearly, the family F satisfies the succinctness and efficiency requirements.
References-found: 37

