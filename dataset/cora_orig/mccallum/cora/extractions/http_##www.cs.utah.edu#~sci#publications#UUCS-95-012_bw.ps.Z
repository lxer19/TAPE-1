URL: http://www.cs.utah.edu/~sci/publications/UUCS-95-012_bw.ps.Z
Refering-URL: http://www.cs.utah.edu/~sci/projects/hci.html
Root-URL: 
Email: Email: dweinste@cs.utah.edu and crj@cs.utah.edu  
Title: Hierarchical Data Structures for Interactive Volume Visualization  
Author: David M. Weinstein Christopher R. Johnson 
Date: August 17, 1995  
Address: Salt Lake City, UT 84112 USA  
Affiliation: Department of Computer Science University of Utah  
Pubnum: UUCS-95-012  
Abstract: In order to interactively investigate large-scale 3D data sets, we propose an improved hierarchical data structure for structured grids and an original hierarchical data structure for unstructured grids. These multi-tiered implementations allow the user to interactively control both the local and global density of the mesh. Therefore, the user can interactively refine areas of interest and decimate peripheral regions. By controlling the density of the mesh throughout the volume, the user controls where computational cycles are spent and gains a deeper insight into the geometric structure of the mesh. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ainsworth and J. T. Oden. </author> <title> A procedure for a posteriori error estimation for h-p finite element methods. </title> <journal> Comput. Methods Appl. Mech. Engrg., </journal> <volume> 101:73, </volume> <year> 1992. </year>
Reference-contexts: In order to reduce the total error in an FE solution, one can refine the mesh in the areas of high gradients, and the system can then be re-solved <ref> [1, 2, 3, 4] </ref>. As mesh element size decreases, the result is guaranteed to converge to the analytic solution [4]. Unfortunately, the mesh refinement techniques most frequently used by scientists often yield widely varying densities within the support mesh, thereby creating wide discrepancies in the accuracy of the visualization.
Reference: [2] <author> C. Johnson and P. Hansbo. </author> <title> Adaptive finite element methods in computational mechanics. </title> <journal> Comput. Methods Appl. Mech. Engrg., </journal> <volume> 101:143, </volume> <year> 1992. </year>
Reference-contexts: In order to reduce the total error in an FE solution, one can refine the mesh in the areas of high gradients, and the system can then be re-solved <ref> [1, 2, 3, 4] </ref>. As mesh element size decreases, the result is guaranteed to converge to the analytic solution [4]. Unfortunately, the mesh refinement techniques most frequently used by scientists often yield widely varying densities within the support mesh, thereby creating wide discrepancies in the accuracy of the visualization.
Reference: [3] <author> C.R. Johnson and R.S. Macleod. </author> <title> Nonuniform spacial mesh adaption using a poteriori error estimates: applications to forward and inverse problems. </title> <journal> Applied Numerical Mathematics, </journal> <volume> 14 </volume> <pages> 311-326, </pages> <year> 1994. </year>
Reference-contexts: In order to reduce the total error in an FE solution, one can refine the mesh in the areas of high gradients, and the system can then be re-solved <ref> [1, 2, 3, 4] </ref>. As mesh element size decreases, the result is guaranteed to converge to the analytic solution [4]. Unfortunately, the mesh refinement techniques most frequently used by scientists often yield widely varying densities within the support mesh, thereby creating wide discrepancies in the accuracy of the visualization.
Reference: [4] <author> O. C. Zienkiewicz and J. Z. Zhu. </author> <title> A simple error estimator and adaptive procedure for pratical engineering analysis. </title> <journal> Int. J. Numer. Method Engrg., </journal> <volume> 24:337, </volume> <year> 1987. </year>
Reference-contexts: In order to reduce the total error in an FE solution, one can refine the mesh in the areas of high gradients, and the system can then be re-solved <ref> [1, 2, 3, 4] </ref>. As mesh element size decreases, the result is guaranteed to converge to the analytic solution [4]. Unfortunately, the mesh refinement techniques most frequently used by scientists often yield widely varying densities within the support mesh, thereby creating wide discrepancies in the accuracy of the visualization. <p> In order to reduce the total error in an FE solution, one can refine the mesh in the areas of high gradients, and the system can then be re-solved [1, 2, 3, 4]. As mesh element size decreases, the result is guaranteed to converge to the analytic solution <ref> [4] </ref>. Unfortunately, the mesh refinement techniques most frequently used by scientists often yield widely varying densities within the support mesh, thereby creating wide discrepancies in the accuracy of the visualization.
Reference: [5] <author> C.S. Gitlin and C.R. Johnson. </author> <title> Techniques for visualizing 3d unstructured meshes. </title> <institution> University of Utah Technical Report, UUCS-94-018, </institution> <year> 1994. </year>
Reference-contexts: Second, it reduces the amount of "screen clutter" created when the results are rendered to the display. Examples of these types of domain reducing algorithms range from clipping plane and seeding algorithms <ref> [5] </ref>, to complete automatic refinement in regions containing information of interest [6]. Clipping planes and seeding algorithms localize the region of operation and allow tight user control over the spatial domain. <p> Current research in this area has focused on methods to limit the domain of the mesh, operating on only a subsection of the volume at a time. Examples of this type of method include clipping planes and seed/grow algorithms <ref> [5] </ref>. In the clipping planes algorithm, elements (or parts of elements) are 3 displayed only if they fall within the volume created by the planes.
Reference: [6] <author> J. Wilhelms and A. Van Gelder. </author> <title> Octrees for faster isosurface generation. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 11(3) </volume> <pages> 201-227, </pages> <year> 1992. </year>
Reference-contexts: Second, it reduces the amount of "screen clutter" created when the results are rendered to the display. Examples of these types of domain reducing algorithms range from clipping plane and seeding algorithms [5], to complete automatic refinement in regions containing information of interest <ref> [6] </ref>. Clipping planes and seeding algorithms localize the region of operation and allow tight user control over the spatial domain. <p> In contrast, completely automatic refinement limits the computational domain, but does not support a means for interactively constraining where work is done spatially. 2 2.1 Structured Grids The complete automatic refinement algorithm is an isosurfacing algorithm which was introduced by Wilhelm and Van Gelder in 1992 <ref> [6] </ref>. The strength of this algorithm comes from its efficient use of octrees to store the volume data. The hierarchical nature of octree space decomposition enables the algorithm to trivially reject large portions of the domain, without having to query any part of the subtree within the rejected region. <p> We then applied the isosurfacing algorithm for different levels of mesh refinement, and compared our results to those generated via a marching cubes style algorithm [11]. Marching cubes required 0.64 seconds to extract the isosurface. Wilhelm and Van Gelder's BONO algorithm <ref> [6] </ref> was somewhat faster, requiring only 0.43 seconds to execute. The execution time for our algorithm varied linearly, depending on how deeply the mesh was discretized. The isosurface in Fig. 2 was generated from the completely refined octree, and also required 0.43 seconds.
Reference: [7] <author> J. Foley, A. van Dam, S. Feiner, and J. Hughes. </author> <title> Computer Graphics Principles and Practice. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: The hierarchical nature of octree space decomposition enables the algorithm to trivially reject large portions of the domain, without having to query any part of the subtree within the rejected region. The original octree data structure was proposed independently at approximately the same time by Hunter et.al. <ref> [7] </ref>, and has found application areas in mesh generation [8], modeling [9] and rendering [10], to name just a few. In Wilhelm and Van Gelder's implementation, their Branch-On-Need Octree (BONO) algorithm stores the maximum and minimum scalar values of the region spanned by each subtree in the region's parent node.
Reference: [8] <editor> M.S. Shephard and M.K. Georges. </editor> <title> Automatic three-dimensional mesh generation by the fintite octree technique. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 32 </volume> <pages> 709-749, </pages> <year> 1991. </year>
Reference-contexts: The original octree data structure was proposed independently at approximately the same time by Hunter et.al. [7], and has found application areas in mesh generation <ref> [8] </ref>, modeling [9] and rendering [10], to name just a few. In Wilhelm and Van Gelder's implementation, their Branch-On-Need Octree (BONO) algorithm stores the maximum and minimum scalar values of the region spanned by each subtree in the region's parent node.
Reference: [9] <author> G.M. Hunter. </author> <title> Efficient Computation and Data Structures for Graphics. </title> <type> PhD thesis, </type> <institution> Princeton University, Princeton, NJ, </institution> <year> 1978. </year> <month> 13 </month>
Reference-contexts: The original octree data structure was proposed independently at approximately the same time by Hunter et.al. [7], and has found application areas in mesh generation [8], modeling <ref> [9] </ref> and rendering [10], to name just a few. In Wilhelm and Van Gelder's implementation, their Branch-On-Need Octree (BONO) algorithm stores the maximum and minimum scalar values of the region spanned by each subtree in the region's parent node.
Reference: [10] <author> L. Doctor and J. Torborg. </author> <title> Display techniques for octree-encoded objects. </title> <journal> IEEE Comp Graph & Applic, </journal> <volume> 1(1) </volume> <pages> 29-38, </pages> <year> 1981. </year>
Reference-contexts: The original octree data structure was proposed independently at approximately the same time by Hunter et.al. [7], and has found application areas in mesh generation [8], modeling [9] and rendering <ref> [10] </ref>, to name just a few. In Wilhelm and Van Gelder's implementation, their Branch-On-Need Octree (BONO) algorithm stores the maximum and minimum scalar values of the region spanned by each subtree in the region's parent node.
Reference: [11] <author> W.E. Lorensen and H.E. Cline. </author> <title> Marching cubes: A high resolution 3d surface construction algorithm. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 163-169, </pages> <year> 1987. </year>
Reference-contexts: The algorithm can then recursively traverse the tree, only isosurfacing those subtrees with ranges containing the value being sought. They report overall speed-ups between 132% and 321% when comparing their algorithm to the marching cubes isosurface extraction algorithm <ref> [11] </ref>. In this paper, we present a further extension to the octree data structure. Our extension allows the user to interactively control the traversal depth within different regions of the tree. <p> This set-up time is somewhat negligible though, since the octree only needs to be computed once. We then applied the isosurfacing algorithm for different levels of mesh refinement, and compared our results to those generated via a marching cubes style algorithm <ref> [11] </ref>. Marching cubes required 0.64 seconds to extract the isosurface. Wilhelm and Van Gelder's BONO algorithm [6] was somewhat faster, requiring only 0.43 seconds to execute. The execution time for our algorithm varied linearly, depending on how deeply the mesh was discretized.
Reference: [12] <author> J.T. Purciful. </author> <title> Three-dimensional widgets for scientific visualization and animation. </title> <type> Master's thesis, </type> <institution> University of Utah, </institution> <year> 1995. </year> <note> (to be submitted). </note>
Reference-contexts: All of these operators are implemented in such a way as to maintain the integrity of the structure (i.e. there is always exactly one LEAF bit set along any path in the tree). They are controlled via a simple user interface consisting of a cross-hair widget <ref> [12] </ref> and a set of Tcl/Tk push-buttons [13]. Fig. 1 shows the SCIRun [14] visual programming map constructed for this algorithm. The cross-hair widget can be interactively moved through the field to identify regions of the octree, and the buttons are linked to method callbacks which move the LEAF bits.
Reference: [13] <author> J.K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: They are controlled via a simple user interface consisting of a cross-hair widget [12] and a set of Tcl/Tk push-buttons <ref> [13] </ref>. Fig. 1 shows the SCIRun [14] visual programming map constructed for this algorithm. The cross-hair widget can be interactively moved through the field to identify regions of the octree, and the buttons are linked to method callbacks which move the LEAF bits.
Reference: [14] <author> C.R. Johnson and S.G. Parker. </author> <title> A computational steering model applied to problems in medicine. </title> <booktitle> In Supercomputing `94, </booktitle> <pages> pages 540-549. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: By employing a "computational steering" paradigm, the user is no longer required to wait for lengthy calculations to complete before seeing results. Instead, the user can guide the computation by feeding back parameter changes to the system based on initial, often partial results from a larger calculation <ref> [14] </ref>. Integrating the user into the computational visualization process means faster convergence time for the user to achieve the desired results, and, ultimately, increased productivity. <p> They are controlled via a simple user interface consisting of a cross-hair widget [12] and a set of Tcl/Tk push-buttons [13]. Fig. 1 shows the SCIRun <ref> [14] </ref> visual programming map constructed for this algorithm. The cross-hair widget can be interactively moved through the field to identify regions of the octree, and the buttons are linked to method callbacks which move the LEAF bits.
Reference: [15] <author> J. Clark. </author> <title> Hierarchical geometric models for visible surface algorithms. </title> <journal> Communications of the ACM, </journal> 19(10) 547-554, 1976. 
Reference-contexts: The seminal work on this topic was conducted by Clark <ref> [15] </ref> and continues to be used today in progressive refinement for architectural walk-throughs and other interactive applications [16]. For our multimesh data structure, the bottom level of the multimesh hierarchy contains the original mesh, with all of its nodes and connectivities.
Reference: [16] <author> T.A. Funkhouser and C.H. Sequin. </author> <title> Adaptive display algorithm for interactive frame rates during visualization of complex virtual environments. </title> <booktitle> In ACM SIG-GRAPH Computer Graphics, </booktitle> <pages> pages 247-254. </pages> <publisher> IEEE Press, </publisher> <year> 1993. </year>
Reference-contexts: The seminal work on this topic was conducted by Clark [15] and continues to be used today in progressive refinement for architectural walk-throughs and other interactive applications <ref> [16] </ref>. For our multimesh data structure, the bottom level of the multimesh hierarchy contains the original mesh, with all of its nodes and connectivities. Each level up contains a subset of the nodes on the level below and a new set of connections for those nodes.
Reference: [17] <author> F. Yu and C.R. Johnson. </author> <title> An automatic adaptive refinement and derefinement method. </title> <booktitle> In Proceedings of the 14th IMACS World Congress, </booktitle> <year> 1994. </year>
Reference-contexts: The difficulty raised is that of how to re-mesh areas of the mesh when nodes are removed. Yu implemented an algorithm for local mesh derefinement <ref> [17] </ref>, and his methods are very successful if boundary nodes are never removed, the domain is convex, and the original mesh is Delaunay. However, as this is not always the case (especially with regard to the removal of boundary nodes), we have implemented a top-down construction.
Reference: [18] <author> D.F. Watson. </author> <title> Computing the n-dimensional dealunay tesselation with applications to voronoi polytopes. </title> <journal> Computer Journal, </journal> <volume> 24(2) </volume> <pages> 167-172, </pages> <year> 1981. </year> <month> 14 </month>
Reference-contexts: For this construction, we ignore the original mesh connectivities, and, adding nodes in order of importance, construct the levels of the mesh from the top down. Each node is inserted via a Watson's style algorithm <ref> [18] </ref>, and as a result remains Delaunay at all 8 times. The top-down method is considerably faster than the bottom-up approach, requiring on the average O (n log n) time to build all levels of the multimesh.
References-found: 18

