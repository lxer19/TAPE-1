URL: http://www.cs.tamu.edu/research/robotics/Sean/Papers/sean_diss.ps.gz
Refering-URL: http://www.cs.tamu.edu/research/robotics/Sean/Papers/sean_bib.html
Root-URL: http://www.cs.tamu.edu
Title: A GENERALIZED TELEAUTONOMOUS ARCHITECTURE USING SITUATION-BASED ACTION SELECTION  
Author: BRENDAN SEAN GRAVES 
Degree: A Dissertation by  in partial fulfillment of the requirements for the degree of DOCTOR OF PHILOSOPHY  
Date: May 1995  
Affiliation: of Graduate Studies of Texas A&M University  
Note: Submitted to the Office  Major Subject: Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. E. Agre, </author> <title> "Routines," </title> <type> Technical Report MIT AIM828, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1985. </year>
Reference-contexts: A completely different approach to planning was developed by Agre and Chapman of MIT. Their system was based on routines, which are methods of representing objects in the world based on the interaction of the robot and those objects <ref> [1, 2, 3] </ref>. The idea behind routines is that a human's usual activities are not symbolic reasoning or planning, but simply carrying out pre-learned routines. In this view, plans allow some improvisation, much like 3.5. LIMITATIONS OF PREVIOUS WORK 24 a cook uses a recipe. <p> F r (20; 19; (100; 100; 25)) ! (100; 100; 25 + (20 19)) (6.30) As shown by Equation 6.19, the gripper command is supplied by fi g : c 4 = <ref> [*; *; *; 1] </ref> (6.32) The input matrix C may be given as C = 6 6 4 c 2 c s 7 7 5 2 6 4 22 20 100 * * * * 1 7 7 k h i Column j of C, labeled ~ c j , contains
Reference: [2] <author> P. E. Agre, </author> <title> "The dynamic structure of everyday life," </title> <type> Technical Report MIT AITR1085, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: A completely different approach to planning was developed by Agre and Chapman of MIT. Their system was based on routines, which are methods of representing objects in the world based on the interaction of the robot and those objects <ref> [1, 2, 3] </ref>. The idea behind routines is that a human's usual activities are not symbolic reasoning or planning, but simply carrying out pre-learned routines. In this view, plans allow some improvisation, much like 3.5. LIMITATIONS OF PREVIOUS WORK 24 a cook uses a recipe.
Reference: [3] <author> P. E. Agre and D. Chapman, </author> <title> "What are plans for?," In Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, </title> <editor> P. Maes, </editor> <booktitle> editor, </booktitle> <pages> pp. 17-34, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: A completely different approach to planning was developed by Agre and Chapman of MIT. Their system was based on routines, which are methods of representing objects in the world based on the interaction of the robot and those objects <ref> [1, 2, 3] </ref>. The idea behind routines is that a human's usual activities are not symbolic reasoning or planning, but simply carrying out pre-learned routines. In this view, plans allow some improvisation, much like 3.5. LIMITATIONS OF PREVIOUS WORK 24 a cook uses a recipe.
Reference: [4] <author> J. S. Albus, H. G. McCain, and R. Lumia, </author> <title> "NASA/NBS standard reference model for telerobot control system architecture (NASREM)," </title> <type> Technical Report NIST Technical Note 1235, </type> <note> 1989 Edition, </note> <institution> National Institute of Standards and Technology, Robot Systems Division, </institution> <address> Washington, DC, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: What is needed is a way to generalize these architectures so that they meet the flexibility constraint described above. Generalized architectures for teleautonomy have been proposed, most notably the NASREM (NASA/NBS Standard Reference Model for Telerobot Control System Architecture) specification <ref> [4] </ref>. <p> Chapter 9 summarizes, and gives directions for future work. Chapter 2 Preliminary Definitions 2.1 Definitions This chapter will provide a groundwork for further discussion of TaS's by defining the terminology to be used. action an elemental robot operation, similar to a NASREM Level 3 elementary move (E-move) <ref> [4] </ref>. Actions map to the degrees of freedom of the robot system. Actions are mutually exclusive, since they place differing demands on the robot hardware. <p> Task planning is performed manually a-priori by the system designer. Open questions include the scalability of the technology demonstrated, its capability for use in mission-critical applications, and its applicability to new tasks. A well-known generalized architecture is NASREM <ref> [4] </ref>. NASREM is a specification for the control system of space telerobots, particularly the now-defunct Flight Telerobotics Ser-vicer [6]. This architecture consists of three hierarchies: task decomposition, world model, and sensory processing. <p> Although their system supports five different control modes, a method of automatically selecting and sequencing mode changes is not supported. The need for multi-level operator interaction is also discussed by Albus <ref> [4] </ref> in the NASREM specification, but the manner in which this interaction should be performed or sequenced is not described. Another notable system called ALLY [24] is an intelligent advisory system. It is based on the idea that human-machine cooperation should be based on a metaphor of human-to-human cooperation.
Reference: [5] <author> American Robot Corporation, </author> <title> Merlin Universal Controller High Speed Host Interface User Manual, </title> <publisher> American Robot Corporation, </publisher> <address> Bridgeville, PA, </address> <year> 1993. </year>
Reference-contexts: The results reported in this chapter are based on a version of ASIAGO running on a 50 MHz Intel 486 ISA bus personal computer. The devices used for testing purposes included a American Robot Merlin 6 DOF anthropomorphic manipulator <ref> [5] </ref>, a wrist mounted JR3 6 DOF force/moment sensor [48], and a pneumatic gripper. These devices were interfaced to the PC using RCCL (Robot Control C Library) [44], which was specially ported for use under LynxOS for control of the Merlin manipulator.
Reference: [6] <author> J. Andary, D. Hewitt, and P. Spidaliere, </author> <title> "Characteristics and requirements of robotic manipulators for space operations," </title> <booktitle> In Cooperative Intelligent Robotics in Space II, </booktitle> <editor> W. E. Stoney, </editor> <booktitle> editor, </booktitle> <pages> pp. 13-23, </pages> <address> Boston, MA, </address> <year> 1991, </year> <booktitle> Proc. SPIE 1612. </booktitle>
Reference-contexts: Open questions include the scalability of the technology demonstrated, its capability for use in mission-critical applications, and its applicability to new tasks. A well-known generalized architecture is NASREM [4]. NASREM is a specification for the control system of space telerobots, particularly the now-defunct Flight Telerobotics Ser-vicer <ref> [6] </ref>. This architecture consists of three hierarchies: task decomposition, world model, and sensory processing. Goals at each level of the task decomposition hierarchy are divided both spatially and temporally into simpler commands for the next lower level.
Reference: [7] <author> R. J. Anderson, </author> <title> "SMART: A modular architecture for robotics and teleoperation," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 416 - 421, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Object-oriented architectures for telerobotics have been the subject of work at Sandia National Labs, particularly the Robot Independent Programming Environment (RIPE) [61] and the Sequential Modular Architecture for Robotics and Teleoperation (SMART) <ref> [7] </ref>. Both of these systems are good examples of the use of object-oriented techniques for construction of telerobotic systems. The application of SMART to the problem of teleoperation in underground storage tanks illustrated the fact that generalized architectures are capable of performing real-world tasks.
Reference: [8] <author> R. C. Arkin, </author> <title> "Motor schema based navigation for a mobile robot: An approach to programming by behavior," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 264-271, </pages> <address> Raleigh, NC, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: ALFA does not contain looping constructs and sequential assignment statements. The use of ALFA is restricted to situations where fairly simple relationships between inputs and outputs can be exploited to produce useful actions. ALFA is more useful as part of a larger system, as described below. Arkin's schema-based control <ref> [8] </ref> uses `motor schemas' as the basic unit of behavior specification. These motor schemas are concurrent processes which map perceptual information into actions. The actions are combined using a potential fields approach. Arkin's work is inspired by neurological and psychological models.
Reference: [9] <author> P. Backes, M. Long, and R. Steele, </author> <title> "The modular telerobot task execution system for space telerobotics," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 524 - 530, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year> <note> 137 BIBLIOGRAPHY 138 </note>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1. <p> For example, an inspection path may be automatically generated upon receipt of a command by the human operator. Alternately, task sequences may be generated manually, and typically in advance of the performance of the actual operation <ref> [9] </ref>. Unexpected circumstances during task operation could cause the operator to create new plans. The ability of the remote robotic system to perform planning on its own could be very useful. <p> In addition to these limitations, methods for selecting actions by fusing control decisions from a variety of command sources deserve further study. While this idea has been investigated in the past (in particular by Backes and colleagues <ref> [9] </ref>), a blending approach that allows non-motion commands to be integrated would be particularly useful. Chapter 4 Requirements Analysis 4.1 Introduction During the course of conducting the literature survey, a few points came to light. <p> In contrast, NASREM emphasizes the specification and decomposition of system functionality. As stated by Rumbaugh [73], such a design is fragile. As "...the requirements change, a system based on decomposing functionality may require massive restructuring." This fact is illustrated by NASREM-inspired system designs found in the literature <ref> [9, 68, 56] </ref> which borrow NASREM's task decomposition hierarchy (derived from the real-world problem domain) but do not use NASREM's intra-level design (which is a functional specification). In other words, the functional aspects of NASREM did not match the requirements of these derived systems.
Reference: [10] <author> P. G. Backes and M. K. </author> <title> Long, "Merging concurrent behaviors on a redundant manipulator," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 638 - 645, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: In cases where a buffer does not supply commands for all degrees of freedom, a null command is placed in the appropriate position in the command vector. c 1 is constructed according to ffi 1 as given in Equation 6.16. That is: c 1 = <ref> [10; 15; 20; *] </ref> (6.28) where * represents the null command for the gripper. c 2 is similar to c 1 , except that the data from fi q must be transformed according to the homogeneous transform of Equation 6.17 giving: c 2 = [22; 20; 100; *] (6.29) c 3 <p> Thus, commands for a wide range of purposes, such as camera control, buffer control, and device configuration, can be processed similarly. One interesting point is that MOTES's Fusion Module uses a control-theoretic technique <ref> [10] </ref> to perform fusion rather than the algorithmic technique used by ASIAGO's Integrator. The former technique has the advantage that different control modes (such as shared, force, or manual) may be generated simply by changing parameters in the control law.
Reference: [11] <author> P. G. Backes and K. S. Tso, </author> <title> "UMI: An interactive supervisory and shared control system for telerobotics," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1096 - 1101, </pages> <address> Cincinnati, OH, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1.
Reference: [12] <author> J. F. Bard, </author> <title> "Evaluating space station applications of automation and robotics," </title> <journal> IEEE Transactions on Engineering Management, </journal> <volume> vol. EM-33, no. 2, </volume> <pages> pp. 102-111, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The prospect of long-term space operation, such as that of the international space station, has fueled numerous studies <ref> [12, 33, 31] </ref> concerning maintenance of the space structures by humans and/or robots. These studies indicate that any long-term space presence, whether in low Earth orbit or on the moon or Mars, will require a large amount of extra-vehicular activity (EVA), such as inspection, maintenance, and repair.
Reference: [13] <author> A. K. Bejczy, W. S. Kim, and S. C. Venema, </author> <title> "The phantom robot: Predictive displays for teleoperation with time delay," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Cincinnati, OH, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: In some cases, predictive displays are superimposed over live or slow-scan video images. A typical problem with such systems is calibration between the live video image and the computer graphics overlay. This was resolved by Bejczy and colleagues <ref> [13] </ref> by interactive specification of distinguished points by the operator allowing automatic calculation of a camera calibration matrix. Other capabilities have been added to predictive displays | for example time and space desynchronization [27], which improves task performance speed and reduces operator workload.
Reference: [14] <author> B. Bon and J. Beahan, </author> <title> "A graphics-based operator control station for local/remote tele-robotics," </title> <booktitle> In Proceedings of the SPIE Applications of Artificial Intelligence X: Machine Vision and Robotics Conference, </booktitle> <address> Orlando, FL, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1. <p> Computer graphic displays have been used to extrapolate robot motion forward in time [67]. These predictive displays are useful when there is significant transmission delay and/or a slow video frame rate between the robot and operator [80]. Similar predictive displays are described which include operator-assisted simulation of sensing <ref> [14] </ref> and the addition of virtual obstacles in areas the operator cannot view via video [69]. In some cases, predictive displays are superimposed over live or slow-scan video images. A typical problem with such systems is calibration between the live video image and the computer graphics overlay. <p> The method of interaction with this system is very simple and did not lend itself to experiments in task sequencing or automatic mode selection. The use of reactive control in a telerobotic scenario is briefly described by Bon and Beahan in <ref> [14] </ref>. Their system allows the user to specify the parameters of a motion or sensing 3.4. PLANNING 23 command to be performed at the remote site, together with a set of reflexes and monitoring functions to be executed in real-time during the motion.
Reference: [15] <author> R. P. Bonasso, </author> <title> "Underwater experiments using a reactive system for autonomous vehicles," </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence, AAAI, </booktitle> <address> Ana-heim, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: She also developed a language called Gapps, which is intended to specify the action component of an agent. Goal reduction rules are used to specify a run-time function of input variables. Working robots have been built using Rex/Gapps <ref> [15, 16] </ref>. A problem with Rosenshein and Kaelbling's architecture is that all computation is advanced by a fixed amount at every cycle. While this system does allow constant-time response times, the constant may become large when a complicated planner is implemented. <p> In cases where a buffer does not supply commands for all degrees of freedom, a null command is placed in the appropriate position in the command vector. c 1 is constructed according to ffi 1 as given in Equation 6.16. That is: c 1 = <ref> [10; 15; 20; *] </ref> (6.28) where * represents the null command for the gripper. c 2 is similar to c 1 , except that the data from fi q must be transformed according to the homogeneous transform of Equation 6.17 giving: c 2 = [22; 20; 100; *] (6.29) c 3
Reference: [16] <author> R. P. Bonasso, H. J. Antonisse, and M. G. Slack, </author> <title> "A reactive robot system for find and fetch tasks in an outdoor environment," </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence, AAAI, </booktitle> <pages> pp. 801 - 808, </pages> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: She also developed a language called Gapps, which is intended to specify the action component of an agent. Goal reduction rules are used to specify a run-time function of input variables. Working robots have been built using Rex/Gapps <ref> [15, 16] </ref>. A problem with Rosenshein and Kaelbling's architecture is that all computation is advanced by a fixed amount at every cycle. While this system does allow constant-time response times, the constant may become large when a complicated planner is implemented. <p> NaT's force the control system to make commitments about how obstacles are to be avoided, thereby producing plans which are task directed and avoid local minima. This approach has been successfully applied to control real robots <ref> [16] </ref>. The main difficulty with this approach is in the construction of the NaT world model | how NaT's are selected and how the parameters which govern their behavior are selected. Action selection can be considered a subproblem of reactive control, however, it also has important links to teleautonomy.
Reference: [17] <author> R. A. Brooks, </author> <title> "A robust layered control system for a mobile robot," </title> <type> Technical Report MIT AIM864, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1985. </year>
Reference-contexts: His numerous publications on the subject argue that reactive control alone can produce intelligent robot systems [20, 18, 19]. Brooks' design 3.3. CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 21 methodology for implementing reactive control is the subsumption architecture <ref> [17] </ref>. This architecture is an incremental method for building robot control systems linking perception to action. An augmented finite-state machine is used to implement low-level behaviors. One advantage of this system is that simple behaviors can be developed quickly and then easily augmented to produce higher-level behaviors.
Reference: [18] <author> R. A. Brooks, </author> <title> "A robot that walks; emergent behaviors from a carefully evolved network," </title> <type> Technical Report MIT AIM1091, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cam-bridge, MA, </address> <month> February </month> <year> 1989. </year>
Reference-contexts: However, reactive controllers have been constructed which perform useful operations without any deliberative component. One well-known proponent of the use of reactive control is Rodney Brooks of the Mas-sachusetts Institute of Technology (MIT). His numerous publications on the subject argue that reactive control alone can produce intelligent robot systems <ref> [20, 18, 19] </ref>. Brooks' design 3.3. CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 21 methodology for implementing reactive control is the subsumption architecture [17]. This architecture is an incremental method for building robot control systems linking perception to action. An augmented finite-state machine is used to implement low-level behaviors.
Reference: [19] <author> R. A. Brooks, </author> <title> "Intelligence without reason," </title> <type> Technical Report AIM-1293, </type> <institution> MIT Artificial Intelligence Lab, </institution> <address> Cambridge, MA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The first technique, deliberative control, uses traditional artificial intelligence algorithms to model and reason about the world. As such, these systems have traditionally suffered from performance problems due to computational complexity and sensing uncertainty <ref> [19] </ref>. The advantage of deliberative control is that it can deal with fairly complex situations where multiple steps might be required to successfully complete a task. At the other end of the spectrum lies reactive control, which eschews artificial intelligence techniques in favor of clever use of simple behaviors. <p> Hybrid systems incorporating aspects of both deliberative control and reactive control have also been built. While there is some debate over the utility of combining deliberative and reactive control (Brooks states that hybrid systems combine the worst aspects of each <ref> [19] </ref>), working systems have been built which demonstrate robust behavior. There are three aspects of controlling autonomous robots in unstructured environments that are problematic for standard control theory [83]: * complex, sequential goals must be encoded, * missing information must be coped with, 3.3. <p> However, reactive controllers have been constructed which perform useful operations without any deliberative component. One well-known proponent of the use of reactive control is Rodney Brooks of the Mas-sachusetts Institute of Technology (MIT). His numerous publications on the subject argue that reactive control alone can produce intelligent robot systems <ref> [20, 18, 19] </ref>. Brooks' design 3.3. CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 21 methodology for implementing reactive control is the subsumption architecture [17]. This architecture is an incremental method for building robot control systems linking perception to action. An augmented finite-state machine is used to implement low-level behaviors. <p> How this arbitration is performed is a crucial problem. An action selection mechanism (ASM) is a computational mechanism which can produce a selected action as output when given different stimuli as inputs. Tyrell [86] compared a number of ASM's including those of Rosenblatt and Payton [71] and Brooks <ref> [19] </ref>. The comparison was done using an elaborate simulated environment, which uncovered flaws in each of the ASM's. Tyrell determined that a slightly modified version of Rosenblatt and Payton's technique would perform best. 3.3.3 Hybrid Control This section will consider systems which combine reactive control methods with SMPA methods.
Reference: [20] <author> R. A. Brooks and A. M. Flynn, </author> <title> "Fast, cheap and out of control," </title> <type> Technical Report MIT AIM1182, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: However, reactive controllers have been constructed which perform useful operations without any deliberative component. One well-known proponent of the use of reactive control is Rodney Brooks of the Mas-sachusetts Institute of Technology (MIT). His numerous publications on the subject argue that reactive control alone can produce intelligent robot systems <ref> [20, 18, 19] </ref>. Brooks' design 3.3. CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 21 methodology for implementing reactive control is the subsumption architecture [17]. This architecture is an incremental method for building robot control systems linking perception to action. An augmented finite-state machine is used to implement low-level behaviors. <p> In cases where a buffer does not supply commands for all degrees of freedom, a null command is placed in the appropriate position in the command vector. c 1 is constructed according to ffi 1 as given in Equation 6.16. That is: c 1 = <ref> [10; 15; 20; *] </ref> (6.28) where * represents the null command for the gripper. c 2 is similar to c 1 , except that the data from fi q must be transformed according to the homogeneous transform of Equation 6.17 giving: c 2 = [22; 20; 100; *] (6.29) c 3 <p> That is: c 1 = [10; 15; 20; *] (6.28) where * represents the null command for the gripper. c 2 is similar to c 1 , except that the data from fi q must be transformed according to the homogeneous transform of Equation 6.17 giving: c 2 = <ref> [22; 20; 100; *] </ref> (6.29) c 3 is derived from buffers fi m and fi s , as shown in Equation 6.18. The contents of these buffers, as well as the constant value of 20 are passed to transformation function F r which returns c 3 .
Reference: [21] <author> F. M. Brown and C. H. Spenny, </author> <booktitle> "Machine intelligence and robotics," In Critical Technologies for National Defense, chapter 11, </booktitle> <pages> pp. 165 - 183, </pages> <institution> American Institute of Aeronautics and Astronautics, Inc., </institution> <address> Washington, DC, </address> <year> 1991. </year> <note> BIBLIOGRAPHY 139 </note>
Reference-contexts: The study also concluded that teleautonomous capabilities such as the use of on-board collision avoidance and control from the ground would "greatly enhance" robot and crew performance. Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications <ref> [21] </ref>, undersea operations [92], lunar or planetary exploration [89], underground tank inspection [63], telediagnosis/telesurgery [79], nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems.
Reference: [22] <author> G. Bruno and M. K. Morgenthaler, </author> <title> "Real-time proximity cues for teleoperation using model-based force reflection," </title> <booktitle> In Cooperative Intelligent Robotics in Space II, </booktitle> <editor> W. E. Stoney, </editor> <booktitle> editor, </booktitle> <pages> pp. 346-355, </pages> <address> Boston, MA, </address> <year> 1991, </year> <booktitle> Proc. SPIE 1612. </booktitle>
Reference-contexts: However, in the absence of a visual predictor, predictive force feedback enabled the performance of certain tasks which could not have otherwise been completed. Similar force prediction systems are described by Bruno and Morgenthaler <ref> [22] </ref> and Kotoku [52]. In [34], Funda and Paul discuss some possible solutions to the time delay problem. They describe the concept of teleprogramming, whereby a graphical preview of the environment is coupled with real-time kinesthetic feedback computed on the basis of the operator's interaction with the simulated remote environment. <p> That is: c 1 = [10; 15; 20; *] (6.28) where * represents the null command for the gripper. c 2 is similar to c 1 , except that the data from fi q must be transformed according to the homogeneous transform of Equation 6.17 giving: c 2 = <ref> [22; 20; 100; *] </ref> (6.29) c 3 is derived from buffers fi m and fi s , as shown in Equation 6.18. The contents of these buffers, as well as the constant value of 20 are passed to transformation function F r which returns c 3 .
Reference: [23] <author> A. Burns and A. Wellings, </author> <title> Real-time Systems and Their Programming Languages, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: Before humans and robots work side-by-side, as in the Gamma scenario, the TaS must be proven safe. This means that mishaps do not occur whether or not the intended function is performed <ref> [23] </ref>. Numerous architectures for telerobotic systems (which are a subclass of TaS's) have been described in the literature. Such architectures will be discussed further in Chapter 3. <p> After the ER collects data from the relevant buffers, it may perform analysis on the data to determine a course of action. The use of guard variables is similar to that used in the operating systems context for controlling access to critical sections <ref> [23] </ref>. The typical concern with this approach is efficiency, since any change in the variables upon which the guard condition is defined requires reevaluation of the guard. In an operating systems context this approach is prohibitively inefficient, since the guard variables may be changing very rapidly.
Reference: [24] <author> J. B. Bushman, C. M. Mitchell, P. M. Jones, and K. S. Rubin, "ALLY: </author> <title> An operator's associate for cooperative supervisory control systems," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 23, no. 1, </volume> <pages> pp. 111 - 128, </pages> <year> 1993. </year>
Reference-contexts: The need for multi-level operator interaction is also discussed by Albus [4] in the NASREM specification, but the manner in which this interaction should be performed or sequenced is not described. Another notable system called ALLY <ref> [24] </ref> is an intelligent advisory system. It is based on the idea that human-machine cooperation should be based on a metaphor of human-to-human cooperation. ALLY assists the operator in carrying out the supervisory control functions for a simulated NASA ground control system.
Reference: [25] <author> F. T. Buzan and T. B. Sheridan, </author> <title> "A model-based predictive operator aid for telema-nipulators with time delay," </title> <booktitle> In Proc. IEEE Int. Conference on Systems, Man, and Cybernetics, </booktitle> <address> Anaheim, CA, </address> <year> 1989. </year>
Reference-contexts: Other capabilities have been added to predictive displays | for example time and space desynchronization [27], which improves task performance speed and reduces operator workload. Predictive displays have also been augmented with predictive force feedback. Such systems attempt to calculate and represent time-delayed force signals. Buzan and Sheridan <ref> [25] </ref> report that predictive force feedback has a negligible effect on task performance when a perfect visual predictive display is available and used. However, in the absence of a visual predictor, predictive force feedback enabled the performance of certain tasks which could not have otherwise been completed.
Reference: [26] <author> J. Connell and P. Viola, </author> <title> "Cooperative control of a semi-autonomous mobile robot," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1118 - 1121, </pages> <address> Cincinnati, OH, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Although the author states that ATLANTIS is an architecture, it is really a low-level language plus design guidelines. One example of interaction between a human and a reactive robotic system is described in <ref> [26] </ref>. The robot consists of a chair mounted on a mobile platform. The human operator sits in the chair and can inject commands into the control system. This allows the operator to guide the robot directly, or to switch between various autonomous behaviors.
Reference: [27] <author> L. Conway, R. A. Volz, and M. W. Walker, </author> <booktitle> "Teleautonomous systems: Methods and architectures for intermingling autonomous and telerobotics technology," In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Raleigh, NC, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: TaS's are designed to support the interaction of humans with remote, intelligent systems of many forms (including robots, vehicles, and humans). By providing the remote system the capability of decision making, operator performance can be improved <ref> [27] </ref>. <p> This was resolved by Bejczy and colleagues [13] by interactive specification of distinguished points by the operator allowing automatic calculation of a camera calibration matrix. Other capabilities have been added to predictive displays | for example time and space desynchronization <ref> [27] </ref>, which improves task performance speed and reduces operator workload. Predictive displays have also been augmented with predictive force feedback. Such systems attempt to calculate and represent time-delayed force signals.
Reference: [28] <author> L. Conway, R. A. Volz, and M. W. Walker, </author> <title> "Teleautonomous systems: Projecting and coordinating intelligent action at a distance," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 6, no. 2, </volume> <pages> pp. 146-158, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: First, however, some background information is in order. 1.2 Introduction to Teleautonomous Systems The system described in the above scenario is called a Teleautonomous System (TaS) <ref> [28] </ref>. TaS's combine the advantages of teleoperation 1 with those of autonomous systems by including the projection of cognitive processing. An integral part of teleautonomous system theory 1 Terminology will be formalized in Chapter 2. For now, the reader may assume that commonly accepted meanings are used. 1.3. <p> Symbolic models can also store the current state of parameters of the models. task apiece of work to be performed at the work site. teleautonomous system (TaS) a distributed system which supports the interaction of humans with remote, intelligent, partly autonomous systems (i.e. robots, vehicles, or other humans) <ref> [28] </ref>. teleoperative control a control mode in which the operator provides direct control using hand controllers. telerobot a robot controlled remotely by an operator, using a computer intermediary [79]. 2.2.
Reference: [29] <author> P. Daley, </author> <title> "Advanced processing architectures which accommodate autonomy," </title> <booktitle> In Cooperative Intelligent Robotics in Space II, </booktitle> <editor> W. E. Stoney, </editor> <booktitle> editor, </booktitle> <pages> pp. 49-54, </pages> <address> Boston, MA, </address> <year> 1991, </year> <booktitle> Proc. SPIE 1612. </booktitle>
Reference-contexts: This is the approach to be taken in this dissertation. 8 2.1. DEFINITIONS 9 A discussion of the architectural issues related to (tele-)autonomous systems is given by Daley <ref> [29] </ref>. Three different types of architectures are described: functional architectures, which describe the functional relationships of components; processing architectures, which describe the types and numbers of processors which will be used; and system configuration architectures, which describe the hardware suites, control algorithms, and communication details.
Reference: [30] <author> T. DeMarco, </author> <title> Structured Analysis and Systems Specification, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1979. </year>
Reference-contexts: Thus, an object-oriented model (OOM) is valid for a wide range of functions that may be required in a particular domain. If the system's functional requirements change, the object-oriented model will usually remain valid. The difference between OMT and the functional methods of Yourdon [93] and DeMarco <ref> [30] </ref> 33 5.1. INTRODUCTION 34 is that the functional approach emphasizes the specification and decomposition of system functionality. This means that any changes made in the functional requirements will require changes in the system model. Three kinds of models are used in OMT to describe a system.
Reference: [31] <author> J. Erickson, C. Price, and D. Cooke, </author> <title> "Future needs for space robots for SEI," </title> <booktitle> In Cooperative Intelligent Robotics in Space II, </booktitle> <editor> W. E. Stoney, </editor> <booktitle> editor, </booktitle> <pages> pp. 2-12, </pages> <address> Boston, MA, </address> <year> 1991, </year> <booktitle> Proc. SPIE 1612. </booktitle>
Reference-contexts: The prospect of long-term space operation, such as that of the international space station, has fueled numerous studies <ref> [12, 33, 31] </ref> concerning maintenance of the space structures by humans and/or robots. These studies indicate that any long-term space presence, whether in low Earth orbit or on the moon or Mars, will require a large amount of extra-vehicular activity (EVA), such as inspection, maintenance, and repair.
Reference: [32] <author> L. J. Everett and R. C. Redfield, </author> <title> "A robust, automated alignment concept for robotics," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 10, no. 4, </volume> <pages> pp. 530 - 534, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: USER-INSTALLED MODULES 111 The following example will illustrate how these operations were implemented in ASIAGO. The example makes use of the Targeting and Reflective Alignment Concept (TRAC) <ref> [32] </ref>, a vision-based alignment sensor capable of measuring all six components of relative alignment between two objects. The sensor includes a video camera on one object of the alignment pair (in this case the robot), a special reflective target on the second object of the alignment pair, and calibration software.
Reference: [33] <author> W. F. Fisher and C. R. Price, </author> <title> "Space station freedom external maintenance task team final report," </title> <type> Technical report, </type> <institution> NASA Johnson Space Center, Houston, TX, </institution> <month> July </month> <year> 1990. </year> <note> BIBLIOGRAPHY 140 </note>
Reference-contexts: The prospect of long-term space operation, such as that of the international space station, has fueled numerous studies <ref> [12, 33, 31] </ref> concerning maintenance of the space structures by humans and/or robots. These studies indicate that any long-term space presence, whether in low Earth orbit or on the moon or Mars, will require a large amount of extra-vehicular activity (EVA), such as inspection, maintenance, and repair. <p> Due to their routine and hazardous nature, these tasks could be performed by TaS's. For example, during analysis of Space Station Freedom, a total of 8,158 items which might require maintenance or replacement by EVA were identified <ref> [33] </ref>. These items, called orbital replacement units (ORU's), were classified into six categories: electronic, electrical, electromechanical, structural, structural-mechanical, and mechanical. Over the 35-year life of the station, an average of 3,276 hours of EVA per year was predicted to maintain these ORU's. <p> It was unrealistic to assume that this level of EVA activity could be performed and robots were cited as a solution. In fact, the authors of the study concluded that robots could "...provide a worthwhile resource capable of assuming most of the external maintenance workload..." <ref> [33] </ref>. The study also concluded that teleautonomous capabilities such as the use of on-board collision avoidance and control from the ground would "greatly enhance" robot and crew performance. Similarly, there are other domains which may utilize TaS's.
Reference: [34] <author> J. Funda and R. P. Paul, </author> <title> "Remote control of a robotic system by teleprogramming," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Sacramento, CA, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: However, in the absence of a visual predictor, predictive force feedback enabled the performance of certain tasks which could not have otherwise been completed. Similar force prediction systems are described by Bruno and Morgenthaler [22] and Kotoku [52]. In <ref> [34] </ref>, Funda and Paul discuss some possible solutions to the time delay problem. They describe the concept of teleprogramming, whereby a graphical preview of the environment is coupled with real-time kinesthetic feedback computed on the basis of the operator's interaction with the simulated remote environment.
Reference: [35] <author> E. Gat, </author> <title> "Reliable goal-directed reactive control of autonomous mobile robots,", </title> <type> Ph.D. dissertation, </type> <institution> Virginia Polytechnic Institute and State University, Blacksburg, VA, </institution> <year> 1991. </year>
Reference-contexts: A problem with Rosenshein and Kaelbling's architecture is that all computation is advanced by a fixed amount at every cycle. While this system does allow constant-time response times, the constant may become large when a complicated planner is implemented. A system named ALFA <ref> [35, 62] </ref> has been used by JPL for control of autonomous mobile robots. ALFA is a (mostly) stateless language for computing transfer functions from a large number of inputs to a large number of outputs. As such, it bears many similarities to Kaelbling's Rex language. <p> Tyrell determined that a slightly modified version of Rosenblatt and Payton's technique would perform best. 3.3.3 Hybrid Control This section will consider systems which combine reactive control methods with SMPA methods. Also, some systems couple reactive control with control-theoretic techniques. Gat's ATLANTIS <ref> [35] </ref> is a hybrid design which places a reactive module and a deliberative module under control of a sequencer. The sequencer initiates activities, which may consist of low level actions (implemented in ALFA) or high level planning or sensing (i.e. vision) operations. <p> An inference mechanism maintains these structures. PRS can be used to construct a complete robot control system; however, such a system would not be very robust because PRS lacks a low-level control layer to recognize execution failures <ref> [35] </ref>. PRS could be useful if incorporated into a larger TaS which used other means of providing low-level control. RoboSoar [53] is a planning system which incorporates learning algorithms. It attempts to incrementally learn the best actions for achieving tasks, based on experience with the environment.
Reference: [36] <author> M. P. Georgeff and F. F. Ingrand, </author> <title> "Decision-making in an embedded reasoning system," </title> <booktitle> In Proc. of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 972-978, </pages> <address> Tokyo, Japan, </address> <year> 1989. </year>
Reference-contexts: TIPS was the planning and reasoning component of a larger Remote Mission Specialist (RMS) system which was developed at JPL. RMS, like the other planning systems described in this section, lacks low-level robot control capabilities. The Procedural Reasoning System (PRS) <ref> [36] </ref> is an embedded planning system which supports both goal-directed reasoning and the ability to react to real-time events.
Reference: [37] <author> M. P. Georgeff and A. L. Lansky, </author> <title> editors, Reasoning about Actions and Plans, </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: A good introduction to some of the basic problems of telerobotics is provided by Sheridan [78]. This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems <ref> [37] </ref>. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications [41, 42, 11, 64, 14, 9]. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system.
Reference: [38] <author> M. L. Ginsberg, </author> <title> "Universal planning: An (almost) universally bad idea," </title> <journal> AI Magazine, </journal> <volume> vol. 10, no. 4, </volume> <pages> pp. 40-44, </pages> <year> 1989. </year>
Reference-contexts: Also, since Reflex Command Queues are tied to specific exception conditions, all possible conditions requiring reflex commands must be pre-determined. This concept, also known as universal planning [77], has been attacked on the grounds that for any useful problem, the number of situations increases exponentially <ref> [38] </ref>. The German ROTEX telerobotic experiment [45, 46] is another example of an architecture for shared human-autonomous control. This space robot technology experiment was carried in Spacelab mission D2 in 1993. A sophisticated 6-axis robot was placed inside a Spacelab rack where it performed assembly, connection/disconnection and grasping operations.
Reference: [39] <author> S. Graves, L. Ciscon, and J. D. Wise, </author> <title> "A modular software system for distributed telerobotics," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 2783 - 2785, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: A TaS designed to be distributed over a wide-area network (such as the Internet) has been constructed by the Universities Space Automation/Robotics Consortium (USARC) [51]. The system, named the Telerobotics Construction Set (TCS) <ref> [40, 39, 91] </ref>, utilizes an object 3.2. USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems [90]. Standardized hand controller, robot, video, and data interfaces are used to integrate heterogeneous processing resources into a complete system.
Reference: [40] <author> S. Graves, J. Mollenhauer, and B. Morgan, </author> <title> "Dynamic session management for telerobotic control and simulation," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1740 - 1745, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: OUTLINE OF THE DISSERTATION 7 The goal of the prototype implementation is to demonstrate how command sources, control techniques, robots, and sensors may be flexibly incorporated into architecture. This implementation component will become part of the Universities Space Automation and Robotics Consortium (USARC) Telerobotics Construction Set (TCS) <ref> [40] </ref>. The USARC TCS will be described in more detail in Chapter 3. Existing limitations of the USARC TCS, such as communication bandwidth and latency, will affect the completed implementation's performance. <p> A session management system appropriately named Telerobotics Session Manager (TSM) is described in <ref> [40] </ref>. simulation see predictive display. site a physical location at which are located processors and software dedicated to performing a particular aspect of the telerobotic task. A site may be defined as a control, work, or monitoring site. <p> A TaS designed to be distributed over a wide-area network (such as the Internet) has been constructed by the Universities Space Automation/Robotics Consortium (USARC) [51]. The system, named the Telerobotics Construction Set (TCS) <ref> [40, 39, 91] </ref>, utilizes an object 3.2. USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems [90]. Standardized hand controller, robot, video, and data interfaces are used to integrate heterogeneous processing resources into a complete system.
Reference: [41] <author> S. Hayati, T. Lee, K. Tso, P. Backes, and J. Lloyd, </author> <title> "A testbed for a unified teleoperated-autonomous dual-arm robotic system," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1090 - 1095, </pages> <address> Cincinnati, OH, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1.
Reference: [42] <author> S. Hayati, T. Lee, K. Tso, P. Backes, and J. Lloyd, </author> <title> "A unified teleoperated autonomous dual-arm robotic system," </title> <journal> IEEE Transactions on Control Systems, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 3 - 8, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1.
Reference: [43] <author> S. Hayati and S. T. Venkataraman, </author> <title> "Design and implementation of a robot control system with traded and shared control capability," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1310-1315, </pages> <address> Scottsdale, AZ, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: The method used to build C will be described in Section 6.4. Given an input matrix C, we may define a matrix M called the blending matrix. The blending matrix is similar in purpose to the mixing matrix described in <ref> [43] </ref>. A blending matrix M is a s fi d matrix of coefficients m ij which regulate the contribution of inputs towards generating a particular degree of freedom of the action vector.
Reference: [44] <author> V. Hayward and R. Paul, </author> <title> "Robot manipulator control under UNIX: RCCL, a robot control C library," </title> <journal> International Journal of Robotics Research, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 94-111, </pages> <year> 1986. </year>
Reference-contexts: The devices used for testing purposes included a American Robot Merlin 6 DOF anthropomorphic manipulator [5], a wrist mounted JR3 6 DOF force/moment sensor [48], and a pneumatic gripper. These devices were interfaced to the PC using RCCL (Robot Control C Library) <ref> [44] </ref>, which was specially ported for use under LynxOS for control of the Merlin manipulator. Silicon Graphics Onyx and Indigo workstations running IRIX 5.2 and Motif 1.2 were used to create and run the graphical user interface for ASIAGO.
Reference: [45] <author> G. Hirzinger, J. Heindl, K. Landzettel, and B. Brunner, </author> <title> "Multisensory shared autonomy a key issue in the space robot technology experiment ROTEX," </title> <booktitle> In Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, </booktitle> <pages> pp. 221-230, </pages> <address> Raleigh, NC, </address> <month> July </month> <year> 1992. </year> <note> BIBLIOGRAPHY 141 </note>
Reference-contexts: This concept, also known as universal planning [77], has been attacked on the grounds that for any useful problem, the number of situations increases exponentially [38]. The German ROTEX telerobotic experiment <ref> [45, 46] </ref> is another example of an architecture for shared human-autonomous control. This space robot technology experiment was carried in Spacelab mission D2 in 1993. A sophisticated 6-axis robot was placed inside a Spacelab rack where it performed assembly, connection/disconnection and grasping operations.
Reference: [46] <author> G. Hirzinger, B. Brunner, J. Dietrich, and J. Heindl, </author> <title> "Sensor-based space robotics | ROTEX and its telerobotic features," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 9, no. 5, </volume> <pages> pp. 649 - 663, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: This concept, also known as universal planning [77], has been attacked on the grounds that for any useful problem, the number of situations increases exponentially [38]. The German ROTEX telerobotic experiment <ref> [45, 46] </ref> is another example of an architecture for shared human-autonomous control. This space robot technology experiment was carried in Spacelab mission D2 in 1993. A sophisticated 6-axis robot was placed inside a Spacelab rack where it performed assembly, connection/disconnection and grasping operations.
Reference: [47] <institution> IEEE, IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, Institute of Electrical and Electronics Engineers, </institution> <address> Piscataway, NJ, </address> <year> 1990. </year>
Reference-contexts: most appropriate action with regard to all types of stimuli [86]. action selection mechanism (ASM) a computational mechanism which produces a se lected action as output when given a set of inputs [86]. architecture this dissertation uses the term `architecture' to mean the organizational structure of a system or component <ref> [47] </ref>, as defined in the IEEE Standard Glossary of Software Engineering Terminology. Unfortunately, the term is often used to indicate a particular instance or implementation of a system.
Reference: [48] <author> JR3, Inc., </author> <title> JR3 Universal Force-Moment Sensor System Operation Manual, </title> <publisher> JR3, Inc., </publisher> <address> Woodland, CA. </address>
Reference-contexts: The results reported in this chapter are based on a version of ASIAGO running on a 50 MHz Intel 486 ISA bus personal computer. The devices used for testing purposes included a American Robot Merlin 6 DOF anthropomorphic manipulator [5], a wrist mounted JR3 6 DOF force/moment sensor <ref> [48] </ref>, and a pneumatic gripper. These devices were interfaced to the PC using RCCL (Robot Control C Library) [44], which was specially ported for use under LynxOS for control of the Merlin manipulator.
Reference: [49] <author> L. P. Kaelbling and S. J. Rosenschein, </author> <title> "Action and planning in embedded agents," In Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, </title> <editor> P. Maes, </editor> <booktitle> editor, </booktitle> <pages> pp. 35-48, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Although the authors argue that Brooks' subsumption scheme can result in incorrect behaviors, it is not shown that the fine-grained scheme will guarantee correctness. Rosenshein and Kaelbling showed that it is possible to compile formal symbolic specifications of a robot's design, yielding efficient real-time programs <ref> [72, 49] </ref>. These specifications can be compiled to generate provably correct robot programs. Kaelbling developed a programming language called Rex [50], which allows the specification of machines by declaratively describing their behavior. She also developed a language called Gapps, which is intended to specify the action component of an agent.
Reference: [50] <author> L. P. Kaelbling and N. J. Wilson, </author> <title> "Rex programmer's manual," </title> <type> Technical Report 381R, </type> <institution> SRI International, </institution> <address> Menlo Park, CA, </address> <year> 1988. </year>
Reference-contexts: Rosenshein and Kaelbling showed that it is possible to compile formal symbolic specifications of a robot's design, yielding efficient real-time programs [72, 49]. These specifications can be compiled to generate provably correct robot programs. Kaelbling developed a programming language called Rex <ref> [50] </ref>, which allows the specification of machines by declaratively describing their behavior. She also developed a language called Gapps, which is intended to specify the action component of an agent. Goal reduction rules are used to specify a run-time function of input variables.
Reference: [51] <author> G. V. Kondraske, R. A. Volz, D. H. Johnson, D. Tesar, J. C. Trinkle, et al., </author> <title> "Network-based infrastructure for distributed remote operations and robotics research," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 9, no. 5, </volume> <pages> pp. 702 - 704, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: For example, NASREM functional specifications were modified with regard to work site device interfacing, world model access timing, and operator interface requirements. A TaS designed to be distributed over a wide-area network (such as the Internet) has been constructed by the Universities Space Automation/Robotics Consortium (USARC) <ref> [51] </ref>. The system, named the Telerobotics Construction Set (TCS) [40, 39, 91], utilizes an object 3.2. USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems [90].
Reference: [52] <author> T. Kotoku, </author> <title> "A predictive display with force feedback and its application to remote manipulation system with transmission time delay," </title> <booktitle> In Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, </booktitle> <pages> pp. 239-246, </pages> <address> Raleigh, NC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: However, in the absence of a visual predictor, predictive force feedback enabled the performance of certain tasks which could not have otherwise been completed. Similar force prediction systems are described by Bruno and Morgenthaler [22] and Kotoku <ref> [52] </ref>. In [34], Funda and Paul discuss some possible solutions to the time delay problem. They describe the concept of teleprogramming, whereby a graphical preview of the environment is coupled with real-time kinesthetic feedback computed on the basis of the operator's interaction with the simulated remote environment.
Reference: [53] <author> J. Laird, A. Newell, and P. Rosenbloom, </author> <title> "Soar: An architecture for general intelligence," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 33, no. 3, </volume> <pages> pp. 23 - 30, </pages> <year> 1987. </year>
Reference-contexts: PRS could be useful if incorporated into a larger TaS which used other means of providing low-level control. RoboSoar <ref> [53] </ref> is a planning system which incorporates learning algorithms. It attempts to incrementally learn the best actions for achieving tasks, based on experience with the environment. RoboSoar's limitation is the same as that of PRS the lack of a low-level control layer.
Reference: [54] <author> A. L. Lansky, </author> <title> "A representation of parallel activity based on events, structure, and causality," </title> <booktitle> In Reasoning about Actions and Plans: Proc. 1986 Workshop, </booktitle> <editor> M. Georgeff and A. Lansky, editors, pp. </editor> <address> 123 - 159, Timberline, OR, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: To do this, ER's monitor designated input buffers for specific data patterns or conditions which indicate situations for which new Modes or command sequences should be issued. The use of events as a technique for modeling domain knowledge is described by Lansky <ref> [54] </ref>. An event-based approach makes certain kinds of properties more natural to express and reason about, especially with respect to the complicated properties of multiagent worlds. In an event-based system, state is defined strictly in terms of past events and their relationships. 6.6. <p> Instead, a set of ER's are defined which may control individual or groups of system parameters based on the current situation. The structure of the ER's is more flexible since it can support the implementation of different domain modeling approaches, for example Lansky's GEM event-based concurrency model <ref> [54] </ref>. ASIAGO could also lend itself to the usage of planning systems such as GEMPLAN [54]. <p> The structure of the ER's is more flexible since it can support the implementation of different domain modeling approaches, for example Lansky's GEM event-based concurrency model <ref> [54] </ref>. ASIAGO could also lend itself to the usage of planning systems such as GEMPLAN [54]. ROTEX Control Modes ROTEX provides several operating modes including automatic, teleoperation on board, tele-operation from the ground, and "telesensor-programming." Automatic control is performed in a fairly traditional sense | o*ine programming a-priori or reprogramming from the ground.
Reference: [55] <author> J. C. Laprie, </author> <title> "Dependable computing and fault tolerance: Concepts and terminology," </title> <booktitle> In Digest of Papers, The Fifteenth Annual Int. Symposium on Fault-Tolerant Computing, </booktitle> <pages> pp. 2 - 11, </pages> <address> San Diego, CA, </address> <year> 1985. </year>
Reference-contexts: RESEARCH GOALS 6 dependability According to Laprie <ref> [55] </ref>, dependability allows reliance to be justifiably placed on a system. Dependability has three aspects: * reliability | continuity of service; * safety | non-occurrence of catastrophic failures; * security | protection against intentional faults.
Reference: [56] <author> S. Leake, T. Green, S. Cofer, and T. Sauerwein, </author> <title> "Hierarchical Ada robot programming system (HARPS): A complete and working telerobot control system based on the NAS-REM model," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1022 - 1028, </pages> <address> Scottsdale, AZ, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: In contrast, NASREM emphasizes the specification and decomposition of system functionality. As stated by Rumbaugh [73], such a design is fragile. As "...the requirements change, a system based on decomposing functionality may require massive restructuring." This fact is illustrated by NASREM-inspired system designs found in the literature <ref> [9, 68, 56] </ref> which borrow NASREM's task decomposition hierarchy (derived from the real-world problem domain) but do not use NASREM's intra-level design (which is a functional specification). In other words, the functional aspects of NASREM did not match the requirements of these derived systems.
Reference: [57] <author> D. R. Lefebvre and G. N. Saridis, </author> <title> "A computer architecture for intelligent machines," </title> <booktitle> In Proceedings of the Third Annual Conference on Intelligent Robotic Systems for Space Exploration, </booktitle> <pages> pp. 31-43, </pages> <address> Troy, NY, </address> <month> November </month> <year> 1991. </year> <note> BIBLIOGRAPHY 142 </note>
Reference-contexts: The advantages of these architectures is that they encourage the use of the most appropriate hardware to solve a particular problem, and that they readily support processing on a wide range of time scales. Lefebvre and Saridis have developed a Theory of Intelligent Machines <ref> [57, 58] </ref> which has been applied to the development of a robot architecture. This architecture uses Generalized Stochastic Petri Nets (GSPN) to organize and coordinate task primitives. The architecture uses an event-driven programming approach to control distributed heterogeneous computing, sensing, and actuation resources.
Reference: [58] <author> D. R. Lefebvre and G. N. Saridis, </author> <title> "Integrating robotic functions and operator supervision using Petri nets," </title> <booktitle> In Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, </booktitle> <pages> pp. 20-26, </pages> <address> Raleigh, NC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: A weakness of SMART and RIPE is that they are off-line construction tools which do not readily support changing modes or dynamic reconfiguration. Most teleautonomous applications make use of distributed and heterogeneous computing, sensing, and actuation resources <ref> [58] </ref>. While the architectures described thus far can each satisfy the need to distribute heterogeneous resources (to various extents), work has been done on architectures that specifically address this concern. <p> The advantages of these architectures is that they encourage the use of the most appropriate hardware to solve a particular problem, and that they readily support processing on a wide range of time scales. Lefebvre and Saridis have developed a Theory of Intelligent Machines <ref> [57, 58] </ref> which has been applied to the development of a robot architecture. This architecture uses Generalized Stochastic Petri Nets (GSPN) to organize and coordinate task primitives. The architecture uses an event-driven programming approach to control distributed heterogeneous computing, sensing, and actuation resources.
Reference: [59] <institution> Lynx Real-Time Systems, Inc., </institution> <note> LynxOS Version 2.1 Reference Manual, </note> <institution> Lynx Real-Time Systems, Inc., Los Gatos, </institution> <address> CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The implementation is actually written in C; however, Pascal notation is generally easier to read and conforms to the notation commonly used in algorithms and software engineering literature. 7.1 Overview ASIAGO consists of approximately 12,000 lines of ANSI C code, running under version 2.1 of the LynxOS operating system <ref> [59] </ref>. LynxOS is a proprietary UNIX-like real-time operating system, which conforms with POSIX 1003.1 and is designed for deterministic hard real-time response. The results reported in this chapter are based on a version of ASIAGO running on a 50 MHz Intel 486 ISA bus personal computer.
Reference: [60] <editor> P. Maes, editor, </editor> <title> Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Systems dedicated to planning using symbolic models are useful for complex operations such as assembly planning. A good introduction to some of the basic problems of telerobotics is provided by Sheridan [78]. This reference also discusses user interface issues. Good references are also available for autonomous robot control <ref> [60] </ref> and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications [41, 42, 11, 64, 14, 9].
Reference: [61] <author> D. Miller and C. Lennox, </author> <title> "An object-oriented environment for robot systems," </title> <journal> IEEE Transactions on Control Systems, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 14 - 23, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Also, concurrency, monitoring, and error handling are treated as features which are added after the system is capable of handling nominal situations. Object-oriented architectures for telerobotics have been the subject of work at Sandia National Labs, particularly the Robot Independent Programming Environment (RIPE) <ref> [61] </ref> and the Sequential Modular Architecture for Robotics and Teleoperation (SMART) [7]. Both of these systems are good examples of the use of object-oriented techniques for construction of telerobotic systems.
Reference: [62] <author> D. P. Miller, R. S. Desai, E. Gat, R. Ivlev, and J. Loch, </author> <title> "Reactive navigation through rough terrain: Experimental results," </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence, AAAI, </booktitle> <pages> pp. 823-828, </pages> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: A problem with Rosenshein and Kaelbling's architecture is that all computation is advanced by a fixed amount at every cycle. While this system does allow constant-time response times, the constant may become large when a complicated planner is implemented. A system named ALFA <ref> [35, 62] </ref> has been used by JPL for control of autonomous mobile robots. ALFA is a (mostly) stateless language for computing transfer functions from a large number of inputs to a large number of outputs. As such, it bears many similarities to Kaelbling's Rex language.
Reference: [63] <author> N. E. Miner and S. A. Stansfield, </author> <title> "An interactive virtual reality simulation system for robot control and operation training," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 1428 - 1435, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations [92], lunar or planetary exploration [89], underground tank inspection <ref> [63] </ref>, telediagnosis/telesurgery [79], nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode.
Reference: [64] <author> D. S. Mittman, B. Bon, J. Brogdon, C. E. Collins, G. Fleischer, et al., </author> <title> "The JPL/KSC telerobotic inspection demonstration," </title> <journal> Telematics and Informatics, </journal> <volume> vol. 7, no. </volume> <pages> 3-4, pp. 341-349, </pages> <year> 1990. </year>
Reference-contexts: This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications <ref> [41, 42, 11, 64, 14, 9] </ref>. Their work includes MOTES (Modular Telerobot Task Execution System), which is an architecture for sequencing commands for a telerobotic system. MOTES allows supervisory, teleoperated, and shared control. 15 3.1.
Reference: [65] <author> Modulus Technologies, Inc., </author> <title> InterAgent Toolkit Reference Manual, Modulus Technologies, </title> <publisher> Inc., </publisher> <address> Houston, TX, </address> <year> 1993. </year>
Reference-contexts: These machines were also used to interface with a 6 DOF isometric teachball, which was used during tests of analogical motion. 101 7.2. COMMUNICATION MANAGER 102 The network interface was provided by an Ethernet connection. The distributed application environment InterAgent <ref> [65] </ref> was used to provide ASIAGO with a object-oriented view of command sources consistent with the object-oriented model developed in Chapter 4. The infrastructure for testing ASIAGO was provided by the USARC, which was formed to promote research into robotics and telerobotics for space-based applications.
Reference: [66] <author> J. Mollenhauer, </author> <title> "Telerobotics session manager user/programmer's manual," </title> <type> Technical Report TR 93-040, </type> <institution> Texas A&M University Department of Computer Science, College Station, TX, </institution> <year> 1993. </year>
Reference-contexts: USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems [90]. Standardized hand controller, robot, video, and data interfaces are used to integrate heterogeneous processing resources into a complete system. A mechanism called Telerobotics Session Manager (TSM) <ref> [66] </ref> is provided to allow the operator to dynamically reconfigure the data flows and interconnections in the system.
Reference: [67] <author> M. Noyes and T. B. Sheridan, </author> <title> "A novel predictor for telemanipulation through a time delay," </title> <booktitle> In Proc. 1984 Annual Conf. on Manual Control, </booktitle> <address> Moffett Field, CA, </address> <year> 1984, </year> <institution> NASA Ames Research Center. </institution>
Reference-contexts: The input to a planner may be configuration commands, sensory data, or various kinds of input data from the operator. predictive display a computer graphic display used to extrapolate robot motion, and its effects, forward in time <ref> [67] </ref>. reactive controller a control source which performs direct mapping from sensor data to robot commands, compositing multiple simple behaviors to produce robust robot activity. robot amechanism guided by control inputs. The robot may generate status data to indicate its position, velocity, etc. <p> Computer graphic displays have been used to extrapolate robot motion forward in time <ref> [67] </ref>. These predictive displays are useful when there is significant transmission delay and/or a slow video frame rate between the robot and operator [80].
Reference: [68] <author> D. R. Olsen, S. Messiora, and S. Leake, </author> <title> "Software architecture for a distributed real-time system in Ada, with application to telerobotics," </title> <type> Technical Report 4367, </type> <institution> NASA Goddard Space Flight Center, </institution> <address> Greenbelt, MA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This problem is alleviated somewhat by the use of a multi-level representation. However, operator interaction with the system is limited to monitoring, authorization/confirmation, and error detection/recovery (manual configuration of the Petri net to match reality). A distributed control system based on NASREM is described in <ref> [68] </ref>. The control system, Engineering Testbed (ETB), was designed to be an operating prototype of the Developmental Test Flight One (DTF-1) for the Flight Telerobotic Servicer (FTS) program. This system was never completed, due to the cancellation of the FTS program. <p> In contrast, NASREM emphasizes the specification and decomposition of system functionality. As stated by Rumbaugh [73], such a design is fragile. As "...the requirements change, a system based on decomposing functionality may require massive restructuring." This fact is illustrated by NASREM-inspired system designs found in the literature <ref> [9, 68, 56] </ref> which borrow NASREM's task decomposition hierarchy (derived from the real-world problem domain) but do not use NASREM's intra-level design (which is a functional specification). In other words, the functional aspects of NASREM did not match the requirements of these derived systems.
Reference: [69] <author> J. H. Park and T. B. Sheridan, </author> <title> "Supervisory teleoperation control using computer graphics," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 493-498, </pages> <address> Cincinnati, OH, </address> <month> May </month> <year> 1990. </year> <note> BIBLIOGRAPHY 143 </note>
Reference-contexts: These predictive displays are useful when there is significant transmission delay and/or a slow video frame rate between the robot and operator [80]. Similar predictive displays are described which include operator-assisted simulation of sensing [14] and the addition of virtual obstacles in areas the operator cannot view via video <ref> [69] </ref>. In some cases, predictive displays are superimposed over live or slow-scan video images. A typical problem with such systems is calibration between the live video image and the computer graphics overlay.
Reference: [70] <author> M. Rokey and S. Grenander, </author> <title> "Planning for space telerobotics: The remote mission specialist," </title> <journal> IEEE Expert, </journal> <pages> pp. 8-15, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: For example, if communication with the control site is unexpectedly broken, a deliberative process could be invoked which would generate a task sequence to safely abort the operation. One example of a planning system specifically designed for use in telerobots was TIPS (Telerobot Interactive Planning System) <ref> [70] </ref>. TIPS was designed to add high-level control to a robotic system, either as an autonomous agent or as an interface between the robot and the human operator. TIPS was the planning and reasoning component of a larger Remote Mission Specialist (RMS) system which was developed at JPL.
Reference: [71] <author> J. K. Rosenblatt and D. W. Payton, </author> <title> "A fine-grained alternative to the subsumption architecture," </title> <booktitle> In Proc. AAAI Stanford Spring Symposium Series, </booktitle> <pages> pp. 70 - 74, </pages> <address> Stanford, CA, </address> <year> 1989. </year>
Reference-contexts: An augmented finite-state machine is used to implement low-level behaviors. One advantage of this system is that simple behaviors can be developed quickly and then easily augmented to produce higher-level behaviors. Rosenblatt and Payton developed an extension to Brook's work called fine-grained sub-sumption <ref> [71] </ref>. Motivating the fine-grained approach is the desire to use smaller decision making units. In Brook's version of subsumption, conflicts between behaviors are resolved by having the commands of a higher level behavior completely override the lower. <p> How this arbitration is performed is a crucial problem. An action selection mechanism (ASM) is a computational mechanism which can produce a selected action as output when given different stimuli as inputs. Tyrell [86] compared a number of ASM's including those of Rosenblatt and Payton <ref> [71] </ref> and Brooks [19]. The comparison was done using an elaborate simulated environment, which uncovered flaws in each of the ASM's.
Reference: [72] <author> S. J. Rosenschein and L. P. Kaelbling, </author> <title> "The synthesis of digital machines with provable epistemic properties," </title> <booktitle> In Proc. of the Conf. on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <editor> J. Y. Halpern, </editor> <booktitle> editor, </booktitle> <pages> pp. 83-98, </pages> <address> Monterey, CA, </address> <year> 1986. </year>
Reference-contexts: Although the authors argue that Brooks' subsumption scheme can result in incorrect behaviors, it is not shown that the fine-grained scheme will guarantee correctness. Rosenshein and Kaelbling showed that it is possible to compile formal symbolic specifications of a robot's design, yielding efficient real-time programs <ref> [72, 49] </ref>. These specifications can be compiled to generate provably correct robot programs. Kaelbling developed a programming language called Rex [50], which allows the specification of machines by declaratively describing their behavior. She also developed a language called Gapps, which is intended to specify the action component of an agent.
Reference: [73] <author> J. Rumbaugh, M. Blaha, W. Premerlani, F. Eddy, and W. Lorensen, </author> <title> Object-Oriented Modeling and Design, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: Because action selection may generate servo setpoints, action selection must be performable within the servo cycle of the manipulator being controlled. Chapter 5 Ob ject-Oriented Model of System Requirements 5.1 Introduction This chapter will describe the requirements of the teleautonomous system using the Object Modeling Technique (OMT) of Rumbaugh <ref> [73] </ref>. The software package OMT (Object Modeling Tool), developed at the General Electric Research and Development Center, was used to automatically generate the figures in this chapter [73]. First, some background on object-oriented modeling will be given. <p> of System Requirements 5.1 Introduction This chapter will describe the requirements of the teleautonomous system using the Object Modeling Technique (OMT) of Rumbaugh <ref> [73] </ref>. The software package OMT (Object Modeling Tool), developed at the General Electric Research and Development Center, was used to automatically generate the figures in this chapter [73]. First, some background on object-oriented modeling will be given. This will also describe the motivation for the use of this technique over other techniques, such as function-oriented methods. The TaS model will be developed in the following sections. <p> We will concentrate primarily on the object model. 5.1.3 Representation of Models in OMT The object model is composed of object diagrams, which are graphs whose nodes represent object classes, and whose edges define relationships between classes. A convention for diagraming these graphs is given by Rumbaugh <ref> [73] </ref>, and will be explained as the model is developed in the next section. The dynamic model is used to specify control flow in the system. <p> THE OBJECT MODEL 35 5.1.4 Object Modeling Tool Object Modeling Tool (OMTool) is a program developed at the General Electric Research and Development Center for designing object models <ref> [73] </ref>. It conforms to the OMT object model notation, and allows object models to be interactively designed. A typical session of OMTool is shown in Figure 5.1. The OMT notation uses a variety of symbols and annotations to indicate relationships such as inheritance, aggregation, association, ordering, and generalization. <p> Constraints on objects and associations may be indicated. Within each object class symbol, attributes and operations are listed. From the object model, OMTool can generate C++ declaration code for implementation purposes. 5.2 The Object Model According to Rumbaugh <ref> [73] </ref>, the following steps are performed in construction of an object model: * Identify objects and classes * Prepare a data dictionary * Identify associations (including aggregations) between objects * Identify attributes of objects and links * Organize and simplify object classes using inheritance * Verify that access paths exist for <p> Analysis ASIAGO is an object-oriented design, whereas NASREM is a functional design; ASIAGO embodies a representation of the real-world problem domain, derived from an analysis of the problem. In contrast, NASREM emphasizes the specification and decomposition of system functionality. As stated by Rumbaugh <ref> [73] </ref>, such a design is fragile.
Reference: [74] <author> T. Sato and S. Hirai, "MEISTER: </author> <title> A model enhanced intelligent and skillful teleoperation robot system," </title> <booktitle> In Robotics Research The Fourth International Symposium, </booktitle> <pages> pp. 155 - 162, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 19 The problem of providing an intuitive and powerful interface between the operator and autonomous functions is exacerbated by the use of many control modes and functionalities. Sato and Hirai <ref> [74] </ref> describe an architecture called MEISTER which supports operator interaction with the telerobot system at the servo level (master/slave control of robot motions) and the task level (task execution by programmed control).
Reference: [75] <author> C. P. Sayers and R. P. Paul, </author> <title> "An operator interface for teleprogramming employing synthetic fixtures," </title> <journal> Presence, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 309 - 320, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: Mode 2 Analogical control with obstacle avoidance and synthetic fixture This mode is used after the TRAC system has identified the exact position of the screw. The mode is defined as an extension of the previous mode by adding a synthetic fixture <ref> [75] </ref> which assists the operator in aligning the screwdriver with the screw. A synthetic fixture is a user interface tool which produces task-dependent operator cues. In the case of this task, the synthetic fixture is a virtual line extending through the screw's rotational axis into the workspace.
Reference: [76] <author> P. Schilling, M. Skubic, and G. Kondraske, </author> <title> "Shared human autonomous control: </title> <type> TATP1 demo 5 report," Technical Report TR 94-003R, </type> <institution> University of Texas at Arlington, Ar-lington, TX, </institution> <year> 1994. </year>
Reference-contexts: A mechanism called Telerobotics Session Manager (TSM) [66] is provided to allow the operator to dynamically reconfigure the data flows and interconnections in the system. Initial experiments using TCS to perform shared human/autonomous control have shown promising results <ref> [84, 76] </ref>; these experiments have also illustrated weaknesses with respect to the synchronization of distributed resources, the overhead in session startup, and the integration of commands from multiple sources. 3.2 User Interfaces for Teleautonomous Systems Work has been reported in numerous fields relevant to TaS user interfaces.
Reference: [77] <author> M. J. Schoppers, </author> <title> "In defense of reaction plans as caches," </title> <journal> AI Magazine, </journal> <volume> vol. 10, no. 4, </volume> <pages> pp. 51-60, </pages> <year> 1989. </year>
Reference-contexts: When a reflex action is executed, the Task Command Queue is cleared. Thus, reflex commands cannot be integrated with task commands. Also, since Reflex Command Queues are tied to specific exception conditions, all possible conditions requiring reflex commands must be pre-determined. This concept, also known as universal planning <ref> [77] </ref>, has been attacked on the grounds that for any useful problem, the number of situations increases exponentially [38]. The German ROTEX telerobotic experiment [45, 46] is another example of an architecture for shared human-autonomous control. This space robot technology experiment was carried in Spacelab mission D2 in 1993.
Reference: [78] <author> T. B. Sheridan, </author> <title> "Human supervisory control of robot systems," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 808-812, </pages> <address> San Francisco, CA, </address> <month> April </month> <year> 1986, </year> <note> IEEE. </note>
Reference-contexts: Systems dedicated to planning using symbolic models are useful for complex operations such as assembly planning. A good introduction to some of the basic problems of telerobotics is provided by Sheridan <ref> [78] </ref>. This reference also discusses user interface issues. Good references are also available for autonomous robot control [60] and planning systems [37]. 3.1 Survey of Telerobotic Architectures The telerobotics work conducted by the Jet Propulsion Lab (JPL) has been described in numerous publications [41, 42, 11, 64, 14, 9].
Reference: [79] <author> T. B. Sheridan, Telerobotics, </author> <title> Automation, and Human Supervisory Control, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations [92], lunar or planetary exploration [89], underground tank inspection [63], telediagnosis/telesurgery <ref> [79] </ref>, nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode. <p> Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations [92], lunar or planetary exploration [89], underground tank inspection [63], telediagnosis/telesurgery <ref> [79] </ref>, nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode. <p> (TaS) a distributed system which supports the interaction of humans with remote, intelligent, partly autonomous systems (i.e. robots, vehicles, or other humans) [28]. teleoperative control a control mode in which the operator provides direct control using hand controllers. telerobot a robot controlled remotely by an operator, using a computer intermediary <ref> [79] </ref>. 2.2. THE SCENARIO REVISITED 13 traded control a control mode in which supervisory control alternates with teleoperative control. user interface a generic name for any mechanism the system might use to communicate information to the operator.
Reference: [80] <author> T. B. Sheridan, </author> <title> "Space teleoperation through time delay: </title> <journal> Review and prognosis," IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 9, no. 5, </volume> <pages> pp. 592 - 606, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Computer graphic displays have been used to extrapolate robot motion forward in time [67]. These predictive displays are useful when there is significant transmission delay and/or a slow video frame rate between the robot and operator <ref> [80] </ref>. Similar predictive displays are described which include operator-assisted simulation of sensing [14] and the addition of virtual obstacles in areas the operator cannot view via video [69]. In some cases, predictive displays are superimposed over live or slow-scan video images.
Reference: [81] <author> A. Silberschatz, J. Peterson, and P. Galvin, </author> <title> Operating System Concepts Fourth Edition, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: The first case requires a timeout value so that data is not buffered indefinitely. 6.8. DEADLOCKS 99 According to standard operating systems principles, deadlock occurs when every process in a set is waiting for a resource which is currently held by another process in the set <ref> [81] </ref>. For a set of processes to be in a deadlocked state, the following four conditions must be simultaneously satisfied: Mutual Exclusion At least one of the resources must be nonsharable. This means that only one process may use this resource at a time.
Reference: [82] <author> R. Simmons and E. Krotkov, </author> <title> "An integrated walking system for the Ambler planetary rover," </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 2086-2091, </pages> <address> Sacra-mento, CA, </address> <month> May </month> <year> 1991. </year> <note> BIBLIOGRAPHY 144 </note>
Reference-contexts: Although NASREM is ostensibly a generalized architecture, its functional specification limits its generality. Specifically, NAS-REM is useful only when adequate processing and sensing resources exist and task dynamics allow for model building and symbolic reasoning. Another generalized architecture is the Task Control Architecture (TCA) <ref> [82] </ref>, developed by Carnegie Mellon University (CMU). It is based on a structured control approach, layering exception handling components on higher-level planning components. Temporal constraints 3.1. SURVEY OF TELEROBOTIC ARCHITECTURES 17 are used to ensure timely response to exceptions.
Reference: [83] <author> R. G. Simmons and R. J. Firby, </author> <title> "Robot architectures," </title> <booktitle> In Tutorial SA5 Notes, Tenth National Conference on Artificial Intelligence, </booktitle> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: There are three aspects of controlling autonomous robots in unstructured environments that are problematic for standard control theory <ref> [83] </ref>: * complex, sequential goals must be encoded, * missing information must be coped with, 3.3. CONTROL SYSTEMS FOR AUTONOMOUS ROBOTS 20 * imperfect understanding of the system must be dealt with.
Reference: [84] <author> M. Skubic, G. Kondraske, J. Wise, G. Khoury, R. Volz, and S. Askew, </author> <title> "A telerobo-tics construction set with integrated performance analysis," </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on International Conference on Intelligent Robots and Systems, </booktitle> <address> Pittsburgh, PA, </address> <month> August </month> <year> 1995. </year> <note> Accepted for publication. </note>
Reference-contexts: A mechanism called Telerobotics Session Manager (TSM) [66] is provided to allow the operator to dynamically reconfigure the data flows and interconnections in the system. Initial experiments using TCS to perform shared human/autonomous control have shown promising results <ref> [84, 76] </ref>; these experiments have also illustrated weaknesses with respect to the synchronization of distributed resources, the overhead in session startup, and the integration of commands from multiple sources. 3.2 User Interfaces for Teleautonomous Systems Work has been reported in numerous fields relevant to TaS user interfaces.
Reference: [85] <author> M. Slack, </author> <title> "Navigation templates: Mediating qualitative guidance and quantitative control in mobile robots," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 23, no. 2, </volume> <pages> pp. 452-466, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The actions are combined using a potential fields approach. Arkin's work is inspired by neurological and psychological models. Some shortcomings of this approach are the complications caused by local minima and the uncharacteristically large (for reactive systems) computational resources needed to process the schemas. Slack's Navigation Templates (NaT's) <ref> [85] </ref> are another form of potential field. They 3.3.
Reference: [86] <author> T. Tyrrell, </author> <title> "Computational mechanisms for action selection,", </title> <type> Ph.D. dissertation, </type> <institution> University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <year> 1993. </year>
Reference-contexts: For example, at any given moment, a robot's end effector may be in only one position. action selection the process of choosing, at each moment in time, the most appropriate action with regard to all types of stimuli <ref> [86] </ref>. action selection mechanism (ASM) a computational mechanism which produces a se lected action as output when given a set of inputs [86]. architecture this dissertation uses the term `architecture' to mean the organizational structure of a system or component [47], as defined in the IEEE Standard Glossary of Software Engineering <p> may be in only one position. action selection the process of choosing, at each moment in time, the most appropriate action with regard to all types of stimuli <ref> [86] </ref>. action selection mechanism (ASM) a computational mechanism which produces a se lected action as output when given a set of inputs [86]. architecture this dissertation uses the term `architecture' to mean the organizational structure of a system or component [47], as defined in the IEEE Standard Glossary of Software Engineering Terminology. Unfortunately, the term is often used to indicate a particular instance or implementation of a system. <p> Similarly, a TaS must integrate commands from the operator (s) with those from autonomous agents. How this arbitration is performed is a crucial problem. An action selection mechanism (ASM) is a computational mechanism which can produce a selected action as output when given different stimuli as inputs. Tyrell <ref> [86] </ref> compared a number of ASM's including those of Rosenblatt and Payton [71] and Brooks [19]. The comparison was done using an elaborate simulated environment, which uncovered flaws in each of the ASM's.
Reference: [87] <editor> United States Air Force Scientific Advisory Board, </editor> <title> "Report of the ad hoc committee on information architectures that enhance operational capability in peacetime and wartime," </title> <type> Technical report, </type> <institution> Department of the Air Force, </institution> <address> Washington, DC, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: One method of specifying an architecture is to define the components of the system, their connections (interrelationships between pairs of components), and the constraints (principles, guidelines, and shared assumptions) <ref> [87] </ref>. This is the approach to be taken in this dissertation. 8 2.1. DEFINITIONS 9 A discussion of the architectural issues related to (tele-)autonomous systems is given by Daley [29].
Reference: [88] <author> J. Vertut and P. Coiffet, </author> <title> Robot Technology, </title> <booktitle> Volume 3A: Teleoperation and Robotics: Evolution and Development, </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations [92], lunar or planetary exploration [89], underground tank inspection [63], telediagnosis/telesurgery [79], nuclear power plant applications <ref> [88] </ref>, and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode.
Reference: [89] <author> W. L. Whittaker and T. Kanade, </author> <title> "Japan robotics aim for unmanned space exploration," </title> <journal> IEEE Spectrum, pp. </journal> <volume> 64 - 67, </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations [92], lunar or planetary exploration <ref> [89] </ref>, underground tank inspection [63], telediagnosis/telesurgery [79], nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode.
Reference: [90] <author> J. D. Wise and L. Ciscon, </author> <title> "TelRIP distributed applications environment operating manual," </title> <type> Technical Report 9103, </type> <institution> Rice University, Houston, TX, </institution> <year> 1992. </year>
Reference-contexts: The system, named the Telerobotics Construction Set (TCS) [40, 39, 91], utilizes an object 3.2. USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems <ref> [90] </ref>. Standardized hand controller, robot, video, and data interfaces are used to integrate heterogeneous processing resources into a complete system. A mechanism called Telerobotics Session Manager (TSM) [66] is provided to allow the operator to dynamically reconfigure the data flows and interconnections in the system.
Reference: [91] <author> J. D. Wise, L. A. Ciscon, and S. Graves, </author> <title> "A distributed telerobotics system for space operations," </title> <booktitle> In Cooperative Intelligent Robotics in Space III, </booktitle> <editor> W. E. Stoney, </editor> <booktitle> editor, </booktitle> <pages> pp. 359-370, </pages> <address> Boston, MA, </address> <year> 1992, </year> <booktitle> Proc. SPIE 1829. </booktitle>
Reference-contexts: A TaS designed to be distributed over a wide-area network (such as the Internet) has been constructed by the Universities Space Automation/Robotics Consortium (USARC) [51]. The system, named the Telerobotics Construction Set (TCS) <ref> [40, 39, 91] </ref>, utilizes an object 3.2. USER INTERFACES FOR TELEAUTONOMOUS SYSTEMS 18 based data distribution system to support distributed telerobot systems [90]. Standardized hand controller, robot, video, and data interfaces are used to integrate heterogeneous processing resources into a complete system.
Reference: [92] <author> V. S. Yastrebov and G. A. Stepanov, </author> <title> "Underwater robot/manipulator development," </title> <journal> Marine Technology Society Journal, </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 23 - 30, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: The study also concluded that teleautonomous capabilities such as the use of on-board collision avoidance and control from the ground would "greatly enhance" robot and crew performance. Similarly, there are other domains which may utilize TaS's. Examples include tactical and strategic military applications [21], undersea operations <ref> [92] </ref>, lunar or planetary exploration [89], underground tank inspection [63], telediagnosis/telesurgery [79], nuclear power plant applications [88], and mining [79]. 1.4 Modes of Control in Teleautonomous Systems In a TaS, inputs from various sources are combined to control remote systems.
Reference: [93] <author> E. Yourdon, </author> <title> Modern Structured Analysis, </title> <publisher> Yourdon Press, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: Thus, an object-oriented model (OOM) is valid for a wide range of functions that may be required in a particular domain. If the system's functional requirements change, the object-oriented model will usually remain valid. The difference between OMT and the functional methods of Yourdon <ref> [93] </ref> and DeMarco [30] 33 5.1. INTRODUCTION 34 is that the functional approach emphasizes the specification and decomposition of system functionality. This means that any changes made in the functional requirements will require changes in the system model. Three kinds of models are used in OMT to describe a system. <p> Data flow diagrams are used to represent functional models. The functional modeling technique used in OMT is similar to that used in a number of traditional software development systems. Yourdan <ref> [93] </ref> gives a thorough background on data flow diagrams. 1 While the term dynamic model is often used in reference to a numerical model based on differential equations, OMT uses the term to refer to a state transition model. 5.2.
References-found: 93

