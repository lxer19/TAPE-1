URL: http://www.cs.umd.edu/~kalvis/PAPERS/team.ps
Refering-URL: http://www.cs.umd.edu/~kalvis/PAPERS/
Root-URL: 
Email: kalvis@cs.umd.edu  rusins@cclu.lv  smith@cs.umd.edu  
Title: Asymmetric Team Learning  
Author: Kalvis Apstis Rusi~ns Freivalds Carl H. Smith 
Address: College Park, MD 20742, USA  Rai~na bulvaris 29 Rga, LV-1459, Latvia  College Park, MD 20742, USA  
Affiliation: Department of Computer Science University of Maryland  Institute of Mathematics and Computer Science  Department of Computer Science University of Maryland  
Abstract: We generalize the traditional concept of team learning. The success of an asymmetric team in learning some function depends upon the successes of participant machines by an arbitrary nondecreasing Boolean function. Asymmetric team types are ordered accordingly to their learning power by basic reductions. The problem to determine this order for an arbitrary pair of asymmetric teams is shown to be NP-hard. Basic reductions are independent of the properties of any particular definition of learning. Many learning types (e.g. EX n | learning with no more than n mind-changes) have additional team order relations which vary from case to case. We define a learning type PINFIN which allows only the basic reductions between its teams. The relation between asymmetric team learning and probabilistic learning is described by a zero sum matrix game.
Abstract-found: 1
Intro-found: 1
Reference: [AAFS97] <author> A. Ambainis, K. Apstis, R. Freivalds, and C. Smith. </author> <title> Team learning and matrix games. </title> <note> Available from http://www.cs.umd.edu/ ~kalvis/, Submitted to ALT'97. </note>
Reference-contexts: For example, <ref> [AAFS97] </ref> presents a method which allows to compare learning abilities of two teams of FIN machines; teams may be both symmetric and asymmetric. 2 PRELIMINARIES IN denotes the set of natural numbers, and F the set of recursive functions. fhg denotes the partial recursive function with index h, see [Soa87].
Reference: [FW79] <author> R. V. Freivalds and R. Wiehagen. </author> <title> Inductive inference with additional information. </title> <journal> Elek-tronische Informationsverabeitung und Ky-bernetik, </journal> <volume> 15(4) </volume> <pages> 179-184, </pages> <year> 1979. </year>
Reference: [Gol67] <author> E. M. Gold. </author> <title> Language identification in the limit. </title> <journal> Information and Control, </journal> <volume> 10 </volume> <pages> 447-474, </pages> <year> 1967. </year>
Reference: [Pit89] <author> L. Pitt. </author> <title> Probabilistic inductive inference. </title> <journal> Journal of the ACM, </journal> <volume> 36(2) </volume> <pages> 383-433, </pages> <year> 1989. </year>
Reference-contexts: For an [m; n]L-learnable class there are n machines such that each function of the class is learned by at least m of these machines. Team learning has been extensively studied <ref> [Smi82, Sch86, Pit89, Smi94] </ref>. fl Supported by NSF Grant 9301339. y Supported by Latvia Council of Science Grant 96.0282. z Supported by NSF Grant 9301339.
Reference: [PS88] <author> L. Pitt and C. Smith. </author> <title> Probability and plurality for aggregations of learning machines. </title> <journal> Information and Computation, </journal> <volume> 77 </volume> <pages> 77-92, </pages> <year> 1988. </year>
Reference: [PZ96] <author> L.A. Petrosian and N.A. Zenkevich. </author> <title> Game theory. </title> <address> River Edge, Singapore, </address> <year> 1996. </year>
Reference: [Sch86] <author> G. Schafer. </author> <title> Some results in the theory of effective program synthesis: Learning by defective information. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 215. </volume> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: For an [m; n]L-learnable class there are n machines such that each function of the class is learned by at least m of these machines. Team learning has been extensively studied <ref> [Smi82, Sch86, Pit89, Smi94] </ref>. fl Supported by NSF Grant 9301339. y Supported by Latvia Council of Science Grant 96.0282. z Supported by NSF Grant 9301339.
Reference: [Smi82] <author> C. H. Smith. </author> <title> The power of pluralism for automatic program synthesis. </title> <journal> Journal of the ACM, </journal> <volume> 29(4) </volume> <pages> 1144-1165, </pages> <year> 1982. </year>
Reference-contexts: For an [m; n]L-learnable class there are n machines such that each function of the class is learned by at least m of these machines. Team learning has been extensively studied <ref> [Smi82, Sch86, Pit89, Smi94] </ref>. fl Supported by NSF Grant 9301339. y Supported by Latvia Council of Science Grant 96.0282. z Supported by NSF Grant 9301339.
Reference: [Smi94] <author> C. Smith. </author> <title> Three decades of team learning. </title> <booktitle> In Proceedings of AII/ALT'94, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1994. </year>
Reference-contexts: For an [m; n]L-learnable class there are n machines such that each function of the class is learned by at least m of these machines. Team learning has been extensively studied <ref> [Smi82, Sch86, Pit89, Smi94] </ref>. fl Supported by NSF Grant 9301339. y Supported by Latvia Council of Science Grant 96.0282. z Supported by NSF Grant 9301339.
Reference: [Soa87] <author> R. I. Soare. </author> <title> Recursively Enumerable Sets and Degrees. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: example, [AAFS97] presents a method which allows to compare learning abilities of two teams of FIN machines; teams may be both symmetric and asymmetric. 2 PRELIMINARIES IN denotes the set of natural numbers, and F the set of recursive functions. fhg denotes the partial recursive function with index h, see <ref> [Soa87] </ref>. Subsets of F are denoted by U; V; W with or without decorations.
References-found: 10

