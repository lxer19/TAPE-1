URL: ftp://ftp.cogsci.indiana.edu/pub/wang.resource.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Email: pwang@cogsci.indiana.edu  
Title: Problem-Solving under Insufficient Resources  
Author: Pei Wang 
Date: September 21, 1995  
Address: 510 North Fess, Bloomington, IN 47408  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: This paper discusses the problem of resources-limited information processing. After a review of relevant approaches in several fields, a new approach, controlled concur-rency, is described and analyzed. This method is proposed for adaptive systems working under insufficient knowledge and resources. According to this method, a problem-solving activity consists of a sequence of steps which behaves like an anytime algorithm | it is interruptible, and the quality of the result is improved incrementally. The system carries out many such activities in parallel, distributes its resources among the them in a time-sharing manner, and dynamically adjusts the distribution according to the feedback of each step. The step sequence for a given problem is formed at run time, according to the system's knowledge structure, which is also dynamically formed and adjusted. Finally, this approach is compared with other approaches, and several of its properties and implications are discussed. In a computer system, all problem-solving activities cost computational resources, mainly processor time and memory space. Because these two types of resource can often be substituted by each other, this paper focuses on the management of the time resource. The paper begins by a review of the different assumptions about time resource made in various fields for different purposes. Then, a new situation, problem-solving under insufficient resources, is defined and discussed. A resource-management mechanism, controlled concurrency, is proposed for this situation. After its basic components are introduced, the properties and implications of the mechanism are discussed and compared with those of other approaches. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. </author> <year> (1990). </year> <title> The Adaptive Character of Thought. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, New Jersey. </address>
Reference-contexts: This is in fact a "forgetting" function used by many psychological models of human memory <ref> (Anderson, 1990) </ref>. Taking the integration of the above urgency function, we get the expected relative time-cost of a task: T = 0 u (as a relative measurement, the constant is omitted).
Reference: <author> Boddy, M. and Dean, T. </author> <year> (1994). </year> <title> Deliberation scheduling for problem solving in time constrained environments. </title> <journal> Artificial Intelligence, </journal> <volume> 67 </volume> <pages> 245-285. </pages>
Reference-contexts: To do this, the system needs a meta-level algorithm, which explicitly allocate processing time to object-level procedures, according to the expected effect of those allocations on the system's performance. This idea is developed in research projects under the name of 4 "deliberation scheduling" <ref> (Boddy and Dean, 1994) </ref>, "metareasoning" (Russell and Wefald, 1991), and "flexible computation" (Horvitz, 1989). 1.7 Dynamical resource allocation The above approaches stress the advanced planning of resource allocation, therefore depends on the quality of the expectations, though run-time monitoring is also possible (Zilberstein, 1995).
Reference: <author> Bylander, T. </author> <year> (1991). </year> <journal> Tractability and artificial intelligence. Journal of Experimental & Theoretical Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 171-178. </pages>
Reference: <author> Dean, T. and Boddy, M. </author> <year> (1988). </year> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54. </pages>
Reference-contexts: A more general concept along this path is the concept of "anytime algorithm" <ref> (Dean and Boddy, 1988) </ref>.
Reference: <author> Englebretsen, G. </author> <year> (1981). </year> <title> Three Logicians. </title> <editor> Van Gorcum, Assen, </editor> <address> The Netherlands. </address>
Reference-contexts: Now we can describe the memory structure of NARS in terms of bags. NARS uses a term logic (Wang, 1994). This kind of logic is characterized by the use of subject-predicate sentences and syllogistic inference rules, as exemplified by the logics of Aristotle and Peirce <ref> (Englebretsen, 1981) </ref>. A property of term logic is that all inference rules require the two premises to share a term. This nice property of term logic naturally localizes the choosing range of knowledge.
Reference: <author> Fagin, R. and Halpern, J. </author> <year> (1988). </year> <title> Belief, awareness, and limited reasoning. </title> <journal> Artificial Intel ligence, </journal> <volume> 34 </volume> <pages> 39-76. </pages>
Reference-contexts: Many features of NARS directly follow from this assumption. For example, the results are usually only derived from part of the system's knowledge, and which part of the knowledge base is used depends on the context at the run time. Consequently, NARS is no longer "logical omniscience" <ref> (Fagin and Halpern, 1988) </ref> | it cannot recall every piece of knowledge in its knowledge base, not to mention being aware of all their implications. From the previous description of the memory organization, we can see that two types of "forgetting" happen in NARS.
Reference: <author> Frisch, A. and Haddawy, P. </author> <year> (1994). </year> <title> Anytime deduction for probabilistic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 93-122. </pages>
Reference-contexts: The above feature distinguishes NARS from other similar approaches that are based on the idea of anytime algorithm <ref> (Frisch and Haddawy, 1994) </ref> or asynchronous parallelism (Hofstadter and the Fluid Analogies Research Group, 1995). In NARS the processing of a task becomes unpredictable and un-repeatable (from the initial design of the system and the task itself), because the context plays a central role.
Reference: <author> Good, I. </author> <year> (1983). </year> <title> Good Thinking: The Foundations of Probability and Its Applications. </title> <publisher> Uni versity of Minnesota Press, </publisher> <address> Minneapolis. </address>
Reference-contexts: Usually, the quality of a solution depends on its resource cost, which includes its processor-time expense. To work under a time pressure means to give up best solutions, and to find a trade-off between solution quality and time cost <ref> (Good, 1983) </ref>. 1.4 Constant time pressure The above situation is the usual case, rather that exceptions, in the fields of real-time systems and artificial intelligence. In these domains, the above time pressure is treated in different ways.. <p> According to Good's "Type II rationality" <ref> (Good, 1983) </ref>, in this situation an optimum solution should be based on decision theory, by taking the cost of deliberation and the expected performance of the involved algorithms into account. <p> are discussed. 3.1 Rational results Like all other approaches that take the limitation of resources into consideration, NARS gives up the requirement for optimum results, and turns to look for the best results the system can get under the constraints of available resources | what Good calls "type II rationality" <ref> (Good, 1983) </ref>. What distinguish NARS from other approaches is the way the constraints are specified. By interpreting "insufficient knowledge and resources" as being finite and open, and working in real time, the constraints assumed by NARS are stronger than the assumptions accepted by other approaches.
Reference: <author> Hofstadter, D. </author> <year> (1979). </year> <title> Godel, Escher, Bach: an Eternal Golden Braid. </title> <publisher> Basic Books, </publisher> <address> New York. 19 Hofstadter, D. </address> <year> (1985). </year> <title> Waking up from the Boolean dream, or, subcognition as computation. In Metamagical Themas: Questing for the Essence of Mind and Pattern, chapter 26. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: In this way, the problems solved by the designer and the problems solved by the system itself are clearly distinguished. In light of this opinion, we can explain why Tesler's Theorem | "AI is whatever hasn't been done yet." <ref> (Hofstadter, 1979) </ref> | applies to many AI projects: in those projects, the designers usually use their intelligence to solve domain problems, then put the solutions into computer systems in the form of task-specific algorithms.
Reference: <author> Hofstadter, D. </author> <year> (1993). </year> <title> How could a copycat ever be creative? In Working Notes, </title> <booktitle> 1993 AAAI Spring Symposium Series, Symposium: AI and Creativity, </booktitle> <pages> pages 1-10. </pages>
Reference-contexts: It should be understood that the system is indeterministic in above sense, rather than because it takes out items from bags according to a probabilistic distribution | that is simply a way to allocate resources unevenly, and can be implemented deterministically <ref> (Hofstadter, 1993) </ref>. 3.4 Is this still computation? With the control mechanism described previously, it is easy to see that even for the same task, with the same priority and decay, the results provided by the system at different time may be different (though not necessarily so).
Reference: <author> Hofstadter, D. </author> <title> and the Fluid Analogies Research Group (1995). Fluid Concepts and Creative Analogies: Computer models of the Fundamental Mechanisms of Thought. </title> <address> BasicBooks, New Nork. </address>
Reference-contexts: This is particularly true for adaptive systems. The "parallel terraced scan" strategy developed by Hofstadter's research group provides an example of dynamical resource allocation <ref> (Hofstadter and the Fluid Analogies Research Group, 1995) </ref>. When exploring an unfamiliar territory to achieve a goal under a time pressure, it is usually impossible to try every path to its end. Without sufficient knowledge, it is also impossible to get a satisfactory plan before the adventure. <p> The above feature distinguishes NARS from other similar approaches that are based on the idea of anytime algorithm (Frisch and Haddawy, 1994) or asynchronous parallelism <ref> (Hofstadter and the Fluid Analogies Research Group, 1995) </ref>. In NARS the processing of a task becomes unpredictable and un-repeatable (from the initial design of the system and the task itself), because the context plays a central role.
Reference: <author> Hopcroft, J. and Ullman, J. </author> <year> (1979). </year> <title> Introduction to Automata Theory, Language, and Com putation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts. </address>
Reference-contexts: A problem is computable as long as the machine stops after finite steps, and the number of steps does not matter <ref> (Hopcroft and Ullman, 1979) </ref>. In this field, the attitude to resource can be summarized as: the time spent in the problem-solving activity can be ignored, given that it is finite. People can wait a period with an arbitrary-but-finite length for a solution. <p> We can identically say that M is a function that maps d i to d o , or that M is an algorithm with d i and d o as input and output, respectively <ref> (Hopcroft and Ullman, 1979) </ref>. A conventional computing system works in a sequential and deterministic way: wait for the user to input a new task, get a task, process that task, report the result, reset the working memory, wait for the user to input a new task, etc., etc.
Reference: <author> Horvitz, E. </author> <year> (1989). </year> <title> Reasoning about beliefs and actions under computational resource con straints. </title> <editor> In Kanal, L., Levitt, T., and Lemmer, J., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 301-324. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: This idea is developed in research projects under the name of 4 "deliberation scheduling" (Boddy and Dean, 1994), "metareasoning" (Russell and Wefald, 1991), and "flexible computation" <ref> (Horvitz, 1989) </ref>. 1.7 Dynamical resource allocation The above approaches stress the advanced planning of resource allocation, therefore depends on the quality of the expectations, though run-time monitoring is also possible (Zilberstein, 1995).
Reference: <author> Kugel, P. </author> <year> (1986). </year> <title> Thinking may be more than computing. </title> <journal> Cognition, </journal> <volume> 22 </volume> <pages> 137-198. </pages>
Reference-contexts: For this situation, we hope to take the time pressure into consideration in the run time. One instance of this approach is to use an interruptible algorithm. In the simplest case, a "trial and error" procedure can be used to "solve" a uncomputable problem <ref> (Kugel, 1986) </ref>. Suppose we want to check whether a Turing machine halts, we can use such a procedure. It reports "NO" at the very beginning, then simulate the given Turing machine. When the Turing machine halts, the trial-and-error procedure reports "YES" and halts. <p> As a result, the system may report more than one answers for a question | it can "change its mind" when new evidence is taken into account, like trial-and-error procedures <ref> (Kugel, 1986) </ref>. The system keeps a record of the best result it has found for each question, and when a new candidate is found, it is compared with the recorded one. <p> What happens here has been pointed out by Hofstadter as "something can be computational at one level, but not at another level" (Hofstadter, 1985), and by Kugel as "cognitive processes that, although they involve more 17 than computing, can still be modeled on the machines we call `computers' " <ref> (Kugel, 1986) </ref>. On the contrary, though conventional computer systems can also be described in these scales, they are computing in all of them. For practical purposes, what we are interested in is the relationship between questions and answers.
Reference: <author> Laffey, T., Cox, P., Schmidt, J., Kao, S., and Read, J. </author> <year> (1988). </year> <title> Real-time knowledge based system. </title> <journal> AI Magazine, </journal> <volume> 9 </volume> <pages> 27-45. </pages>
Reference: <author> Levesque, H. </author> <year> (1988). </year> <title> Logic and the complexity of reasoning. </title> <editor> In Thomason, R., editor, </editor> <booktitle> Philo sophical Logic and Artificial Intelligence, </booktitle> <pages> pages 73-107. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston. </address>
Reference: <author> Rawlins, G. </author> <year> (1992). </year> <title> Compared to What? Computer Science Press, </title> <address> New York. </address>
Reference-contexts: This is the territory of computational complexity theory <ref> (Rawlins, 1992) </ref>. According to the form of complexity functions, algorithms are put into a hierarchy of complexity classes | constant, logarithmical, polynomial, exponential, and so on. Algorithms with low complexity are preferred. <p> Consequently, we have to relax our request for the solution from "best" to "satisfactory", then look for an algorithm which can get such a solution as fast as possible. This approach leads to concepts like approximation algorithm and heuristic algorithm <ref> (Rawlins, 1992) </ref>. Similarly, we can first decide the time request, usually in the form of a deadline, then look for an algorithm which can meet the deadline, and can also provide a solution as good as possible.
Reference: <author> Russell, S. and Wefald, E. </author> <year> (1991). </year> <booktitle> Principles of metareasoning. Artificial Intelligence, </booktitle> <address> 49:361 395. </address>
Reference-contexts: To do this, the system needs a meta-level algorithm, which explicitly allocate processing time to object-level procedures, according to the expected effect of those allocations on the system's performance. This idea is developed in research projects under the name of 4 "deliberation scheduling" (Boddy and Dean, 1994), "metareasoning" <ref> (Russell and Wefald, 1991) </ref>, and "flexible computation" (Horvitz, 1989). 1.7 Dynamical resource allocation The above approaches stress the advanced planning of resource allocation, therefore depends on the quality of the expectations, though run-time monitoring is also possible (Zilberstein, 1995).
Reference: <author> Strosnider, J. and Paul, C. </author> <year> (1994). </year> <title> A structured view of real-time problem solving. </title> <journal> AI Magazine, </journal> <volume> 15(2) </volume> <pages> 45-66. </pages>
Reference-contexts: NARS is a real-time system, and the bag structure consistently implements some techniques used in real-time systems, such as pruning, ordering, approximation, and scoping <ref> (Strosnider and Paul, 1994) </ref>. In traditional real-time systems, time requests are indicated by deadlines (Laffey et al., 1988; Strosnider and Paul, 1994). This method is not suitable for NARS, because here new tasks may appear at any time, and thus no pre-designed mechanism can satisfy all possible combinations of deadlines.
Reference: <author> Valiant, L. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142. </pages>
Reference: <author> Wang, P. </author> <year> (1994). </year> <title> From inheritance relation to nonaxiomatic logic. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 11(4) </volume> <pages> 281-319. </pages>
Reference-contexts: As discussed above, when an answer is found, it does not necessarily mean that the system will stop processing the task. According to the logic used in NARS, it is always possible to find a better answer for a question, no matter what has been found <ref> (Wang, 1994) </ref>. As a result, the system may report more than one answers for a question | it can "change its mind" when new evidence is taken into account, like trial-and-error procedures (Kugel, 1986). <p> The system keeps a record of the best result it has found for each question, and when a new candidate is found, it is compared with the recorded one. If the new one is better (for how the quality of a answer is measured, see <ref> (Wang, 1994) </ref>), it is reported, and the record is updated. Of course, it is also possible for a question to be removed from the task pool before any answer is found for it. <p> Its effect is to take an item out of the bag. The probability for an item to be chosen is proportional to its priority. Now we can describe the memory structure of NARS in terms of bags. NARS uses a term logic <ref> (Wang, 1994) </ref>. This kind of logic is characterized by the use of subject-predicate sentences and syllogistic inference rules, as exemplified by the logics of Aristotle and Peirce (Englebretsen, 1981). A property of term logic is that all inference rules require the two premises to share a term. <p> The name of a chunk is a term, and the body of the 11 chunk contains the meaning of that term | according to the experience-grounded semantics accepted by NARS <ref> (Wang, 1994) </ref>, the meaning of a term is determined by its experienced relations with other terms. The memory of the system is simply a group of chunks. Now the operation of choosing a task takes two steps: choosing a chunk first, then choosing a task from it.
Reference: <author> Wang, P. </author> <year> (1995). </year> <title> Non-Axiomatic Reasoning System: Exploring the Essence of Intelligence. </title> <type> PhD thesis, </type> <institution> Indiana University. </institution>
Reference-contexts: To explain how the priority and decay values are calculated, it is inevitable to address many technical details of the NARS model, and thus is beyond the scope of this paper. Such an explanation can be found in <ref> (Wang, 1995) </ref>. It is possible to implement the above procedure in such a way that an inference step takes roughly constant time, no matter how large the involved bags are (Wang, 1995). Such a step is like an "atomic" instruction of problem-solving activities. <p> Such an explanation can be found in <ref> (Wang, 1995) </ref>. It is possible to implement the above procedure in such a way that an inference step takes roughly constant time, no matter how large the involved bags are (Wang, 1995). Such a step is like an "atomic" instruction of problem-solving activities. <p> Therefore, the new approach is not necessarily better than the other approaches in all situations. The "insufficient knowledge and resources" situation has special importance from the viewpoint of artificial intelligence and cognitive science <ref> (Wang, 1995) </ref>. Briefly speaking, many AI problems have this property, and many human behaviors can be explained from 18 this assumption. Since few traditional theory makes this assumption, new approaches become specially wanted.
Reference: <author> Zilberstein, S. </author> <year> (1995). </year> <title> Operational rationality through compliation of anytime algorithm. </title> <journal> AI Magazine, </journal> <volume> 16(2) </volume> <pages> 79-80. 20 </pages>
Reference-contexts: projects under the name of 4 "deliberation scheduling" (Boddy and Dean, 1994), "metareasoning" (Russell and Wefald, 1991), and "flexible computation" (Horvitz, 1989). 1.7 Dynamical resource allocation The above approaches stress the advanced planning of resource allocation, therefore depends on the quality of the expectations, though run-time monitoring is also possible <ref> (Zilberstein, 1995) </ref>. However, if the information about object-level procedures mainly comes at the run time, the meta-level planner may have little to do before the procedures actually run | its expectations will be very different from the reality revealed later.
References-found: 23

