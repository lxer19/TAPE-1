URL: ftp://ftp.eecs.umich.edu/people/wellman/aaai-rational-fs95.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/wellman/Publications.html
Root-URL: http://www.cs.umich.edu
Email: wellman@umich.edu  
Title: Rationality in Decision Machines  
Author: Michael P. Wellman 
Keyword: Machine Rationality  
Address: 1101 Beal Avenue Ann Arbor, MI 48109-2110  
Affiliation: University of Michigan, AI Laboratory  
Abstract: This brief position paper 1 sketches a view, in many respects conventional, of the role of rationality in artificial intelligence. In this view, rationality is primarily a way to describe coherence between actions and agent attitudes such as belief and preference. Decisions are the fundamental unit of calculation for a rational computer, and therefore we properly refer to them as decision machines . Collections of interacting decision machines, or decision factories , should not in general be expected to be rational, although we should exploit the rationality of their constituent machines in configuring decision factories. Computer scientists at least since Turing have understood that a program is an abstract specification of a machine , describable behaviorally in terms of the input/output relationship resulting from its computation. In adopting the common term, the fields pioneers probably meant to highlight the mechanical nature of computation, and perhaps also to emphasize the productive quality of running computer programs. The machines product is of course the value of a functionthe function represented by the programat the point represented by the machines input. But often we find it helpful to view this product at a higher level, say, as the solution to some well-posed problem. Indeed, every subfield of computer science defines its own abstractions above the level of computing functions. For example, database specialists might prefer to view the input of their machine as a query , the product as data , and the machines activity as retrieval. Of course we can always reduce this abstract database machine to the more concrete computing machine, but in doing so we may increase the description complexity and make it more difficult to analyze, predict, or design the behavior of database machines. In this case and most others, the 
Abstract-found: 1
Intro-found: 1
Reference: <author> Clearwater, S. H., ed. </author> <year> (1995). </year> <title> Market-Based Control: A Paradigm for Distributed Resource Allocation . World Scientific. </title>
Reference: <author> Doyle, J. </author> <year> (1992). </year> <title> Rationality and its roles in reasoning. </title> <booktitle> Computational Intelligence 8: </booktitle> <pages> 376-409. </pages>
Reference-contexts: In the remainder of this essay, the term agent is applied generically to denote the entity producing behavior. This formulation can be criticized on several grounds, foremost of which is that it embodies, logical rather than economic rationality <ref> (Doyle, 1992) </ref>. But let us put aside such concerns and consider the perspective that a rationality principle of this general form takes on computing machines. The relevant output identified by this principle is an action selection.
Reference: <author> Newell, A. </author> <year> (1982). </year> <title> The knowledge level. </title> <journal> Artificial Intelligence 18: </journal> <volume> 87127. </volume>
Reference: <author> Pollack, M. E. </author> <year> (1992). </year> <title> The uses of plans. </title> <booktitle> Artificial Intelligence 57: </booktitle> <pages> 43-68. </pages>
Reference-contexts: But decisions can also involve more complex patterns of activity, including conditional commitments, combinations of actions, or any expressible distinction in plan space, for that matter. Indeed, something of this nature is necessary to incorporate notions of intention <ref> (Pollack, 1992) </ref>, since intentions are rendered superfluous if either individual actions or entire grand-world plans are adopted as the unit of analysis. Since the most comprehensive rationality criteria are expressed in terms of grand-world plans, assessing the rationality of a decision is not entirely straightforward.
Reference: <author> Pollock, J. L. </author> <year> (1992). </year> <title> New foundations for practical reasoning. Minds and Machines 2: </title> <type> 113144. </type>
Reference: <author> Rosenschein, J. S., and G. </author> <title> Zlotkin (1994). Rules of Encounter: Designing Conventions for Automated Negotiation among Computers. </title> <publisher> MIT Press. </publisher>
Reference: <author> Rosenschein, S. J., and L. P. </author> <title> Kaelbling (1995). A situated view of representation and control. </title> <booktitle> Artificial Intelligence 73: </booktitle> <pages> 149-173. </pages>
Reference-contexts: The true output of a computer program is a stream of physical encodings, which are then transduced by some external effectors into activity affecting the environment. But neither this activity nor the information states inducing it are inherently divisible in some particular way into discretely selectable action units <ref> (Rosenschein and Kaelbling, 1995) </ref>. There are at least two standard technical meanings of the term action in AI and the decision sciences. In one, typical of foundational treatments of decision theory, an act or action denotes the entire behavior of the agent in question.
Reference: <author> Russell, S. J., and P. </author> <title> Norvig (1995). Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice-Hall. </publisher>
Reference: <author> Russell, S. J., and D. </author> <title> Subramanian (1995). Provably bounded-optimal agents. </title> <journal> Journal of Artificial Intelligence Research 2: </journal> <pages> 575-609. </pages>
Reference: <author> Savage, L. J. </author> <year> (1972). </year> <booktitle> The Foundations of Statistics. Second edition. </booktitle> <address> New York, </address> <publisher> Dover Publications. </publisher>
Reference: <author> Wellman, M. P. </author> <year> (1990). </year> <title> Formulation of Tradeoffs in Planning Under Uncertainty . London, </title> <publisher> Pitman. </publisher>
Reference-contexts: As a computation proceeds, uncertainty is progressively resolved, and its possible end results are narrowed. This is equivalent to saying that the agent makes decisions , committing to progressively smaller sets of possible plans. In previous work I have proposed a general dominance-based criterion for assessing grand-world distinctions <ref> (Wellman, 1990) </ref>, but more specialized approaches are appropriate for particular formulations of plan space. Of course, we can always revert to the special case of episodic decision making when that approximation is acceptable.
Reference: <author> Wellman, M. P. </author> <year> (1993). </year> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research 1: </journal> <pages> 1-23. </pages>
Reference: <author> Wellman, M. P. </author> <year> (1995). </year> <title> The economic approach to Artificial Intelligence. </title> <note> ACM Computing Surveys (to appear). </note>
Reference-contexts: If it is somehow crucial that rationality be achieved overall, then perhaps it should be sacrificed in the components. If one is seeking ideas about collections of rational agents, my summary suggestion is to look toward microeconomics <ref> (Wellman, 1995) </ref>. Indeed, its pervasive use of the rationality abstraction is one of the main features distinguishing economics from other social science disciplines.
References-found: 13

