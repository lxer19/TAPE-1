URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93424.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: E-mail: demmel@cs.berkeley.edu  E-mail: heath@ncsa.uiuc.edu  E-mail: vorst@math.ruu.nl  
Title: LAPACK Working Note 60, UT CS-93-192 Parallel numerical linear algebra  
Author: James W. Demmel Michael T. Heath Henk A. van der Vorst 
Date: August 18, 1993  
Address: Berkeley, CA 94720 USA  Urbana, IL 61801 USA  Utrecht, The Netherlands  
Affiliation: Computer Science Division and Mathematics Department University of California at Berkeley  Department of Computer Science and National Center for Supercomputing Applications University of Illinois  Mathematical Institute Utrecht University  
Abstract-found: 0
Intro-found: 1
Reference: <author> A. Aho, J. Hopcroft and J. </author> <title> Ullman (1974), </title> <booktitle> The Design and Analysis of Computer Algorithms, </booktitle> <address> Addison-Wesley (New York). </address> <note> 76 E. </note> <author> Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Green--baum, S. Hammarling, A. McKenney, S. Ostrouchov and D. </author> <note> Sorensen (1992), LAPACK Users' Guide, Release 1.0, SIAM (Philadelphia). </note>
Reference-contexts: Another possibility is Strassen's method <ref> (Aho, Hopcroft and Ullman, 1974) </ref>, which multiplies matrices recursively by dividing them into 2 fi2 block matrices, and multiplying the subblocks using 7 matrix multiplications (recursively) and 15 matrix additions of half the size; this leads to an asymptotic complexity of n log 2 7 n 2:81 instead of n 3
Reference: <author> E. Anderson and J. </author> <title> Dongarra (1990), `Evaluating block algorithm variants in LAPACK', </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-90-103, </type> <institution> University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 19). </note> <institution> ANSI/IEEE, </institution> <address> New York, </address> <year> (1985), </year> <title> IEEE Standard for Binary Floating Point Arithmetic, </title> <address> Std 754-1985 edition (New York). </address>
Reference: <author> W. E. </author> <title> Arnoldi (1951), `The principle of minimized iteration in the solution of the matrix eigenproblem', </title> <journal> Quart. Appl. Math. </journal> <volume> 9, </volume> <pages> 17-29. </pages>
Reference-contexts: When A is symmetric this leads to an algorithm with can efficiently compute many, if not all, eigenvalues and eigenvectors (Parlett, 1980). In fact, the CG method (and Bi-CG) can be viewed as a solution process on top of Lanczos. The long recursion process is known as Arnoldi's method <ref> (Arnoldi, 1951) </ref>, which we have seen already as the underlying orthogonalization procedure for GMRES.
Reference: <author> C. Ashcraft, S.C. Eisenstat and J.W.-H. </author> <title> Liu (1990), `A fan-in algorithm for distributed sparse numerical factorization', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 11, </volume> <pages> 593-599. </pages>
Reference-contexts: The shortcomings of the fan-out algorithm motivated the formulation of the following fan-in algorithm for sparse factorization, which is a parallel implementation of column-Cholesky <ref> (Ashcraft, Eisenstat and Liu, 1990) </ref>: Algorithm 23 Distributed fan-in sparse Cholesky factorization for j = 1; n if j 2 mycols or mycols " Struct (L jfl ) 6= ; u = 0 for k 2 mycols " Struct (L jfl ) u = u + ` jk fl L flk
Reference: <author> C. Ashcraft, S.C. Eisenstat, J.W.-H. Liu and A.H. </author> <title> Sherman (1990), `A comparison of three column-based distributed sparse factorization schemes', </title> <type> Technical Report YALEU/DCS/RR-810, </type> <institution> Dept of Computer Science, Yale University, </institution> <address> New Haven, CT. </address>
Reference-contexts: The shortcomings of the fan-out algorithm motivated the formulation of the following fan-in algorithm for sparse factorization, which is a parallel implementation of column-Cholesky <ref> (Ashcraft, Eisenstat and Liu, 1990) </ref>: Algorithm 23 Distributed fan-in sparse Cholesky factorization for j = 1; n if j 2 mycols or mycols " Struct (L jfl ) 6= ; u = 0 for k 2 mycols " Struct (L jfl ) u = u + ` jk fl L flk
Reference: <author> C. Ashcraft and R. </author> <title> Grimes (1988), `On vectorizing incomplete factorizations and SSOR preconditioners', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 122-151. </pages>
Reference: <author> C. Ashcraft, R. Grimes, J. Lewis, B. Peyton and H. </author> <title> Simon (1987), `Progress in sparse matrix methods for large linear systems on vector supercomputers', </title> <journal> Int. J. Supercomput. Appl. </journal> <volume> 1(4), </volume> <pages> 10-30. </pages>
Reference-contexts: For example, such techniques have been used to attain very high performance for sparse factorization on conventional vector supercomputers <ref> (Ashcraft, Grimes, Lewis, Peyton and Simon, 1987) </ref> and on RISC workstations (Rothberg and Gupta, 1989). 7.4 Parallelism in sparse factorization We now examine in greater detail the opportunities for parallellism in sparse Cholesky factorization and various algorithms for exploiting it.
Reference: <author> L. Auslander and A. </author> <title> Tsao (1992), `On parallelizable eigensolvers', </title> <journal> Adv. Appl. Math. </journal> <volume> 13, </volume> <pages> 253-261. </pages>
Reference: <author> I. </author> <title> Babuska (1972), `Numerical stability in problems of linear algebra', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 9, </volume> <pages> 53-77. </pages>
Reference: <author> Z. Bai and J. </author> <title> Demmel (1989), `On a block implementation of Hessenberg multi-shift QR iteration', </title> <journal> Int. J. High Speed Comput. </journal> <note> 1(1), 97-112 (also LAPACK Working Note 8). </note>
Reference-contexts: of the bottom right k fi k matrix, say), which permits us to work on k rows and 4 As noted in Section 6.2, we cannot even efficiently reduce to condensed form for the generalized eigenproblem A B. 43 columns of the matrix at a time using Level 2 BLAS <ref> (Bai and Demmel, 1989) </ref>. Asymptotic convergence remains quadratic (Watkins and Elsner, 1991). The drawbacks to this scheme are twofold. First, any attempt to use Level 3 BLAS introduces rather small (hence inefficient) matrix-matrix operations, and raises the operation count considerably.
Reference: <author> Z. Bai and J. </author> <title> Demmel (1992), `Design of a parallel nonsymmetric eigenrou-tine toolbox', </title> <institution> Computer Science Dept preprint, University of California, Berkeley, </institution> <address> CA. </address>
Reference: <author> Z. Bai, D. Hu and L. </author> <title> Reichel (1991), `A Newton basis GMRES implementation', </title> <type> Technical Report 91-03, </type> <institution> University of Kentucky. </institution>
Reference-contexts: This approach has led to speedups on relatively large matrices on some machines <ref> (Bailey, Lee and Simon, 1991) </ref>. A drawback is the need for significant workspace, and somewhat lower numerical stability, although it is adequate for many purposes (Demmel and Higham, 1992; Higham, 1990).
Reference: <author> D. H. Bailey, K. Lee and H. D. </author> <title> Simon (1991), `Using Strassen's algorithm to accelerate the solution of linear systems', </title> <journal> J. Supercomput. </journal> <volume> 4, </volume> <pages> 97-371. </pages> <note> 77 J. </note> <month> Barlow </month> <year> (1991), </year> <title> `Error analysis of update methods for the symmetric eigen-value problem', </title> <note> to appear in SIAM J. Math. Anal. Appl. (Tech Report CS-91-21, </note> <institution> Computer Science Department, Penn State University.) </institution> <note> C. </note> <author> Beattie and D. </author> <title> Fox (1989), `Localization criteria and containment for Rayleigh quotient iteration', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 10 (1), </volume> <pages> 80-93. </pages>
Reference-contexts: This approach has led to speedups on relatively large matrices on some machines <ref> (Bailey, Lee and Simon, 1991) </ref>. A drawback is the need for significant workspace, and somewhat lower numerical stability, although it is adequate for many purposes (Demmel and Higham, 1992; Higham, 1990).
Reference: <author> K. Bell, B. Hatlestad, O. Hansteen and P. </author> <month> Araldsen </month> <year> (1973), </year> <title> NORSAM|A programming system for the finite element method, User's Manual, Part I, General description. Institute for Structural Analysis, </title> <address> NTH, N-7034 Trondheim, Norway. </address>
Reference-contexts: Currently one must immerse oneself in the multitudinous and often ephemeral details of these systems in order to write reasonably efficient programs. Perhaps not surprisingly, a number of techniques for dealing with data transfer in blocked fashion in the 1960s are being rediscovered and reused <ref> (Bell, Hatlestad, Hansteen and Araldsen, 1973) </ref>. Our first goal is to enunciate two simple principles for identifying the important strengths and weaknesses of parallel programming systems (both hardware and software): locality and regularity of operation. We do this in Section 2.
Reference: <author> R. Benner, G. Montry and G. </author> <title> Weigand (1987), `Concurrent multifrontal methods: shared memory, cache, and frontwidth issues', </title> <journal> Int. J. Supercomput. Appl. </journal> <volume> 1 (3), </volume> <pages> 26-44. </pages>
Reference: <author> H. Berryman, J. Saltz, W. Gropp and R. </author> <title> Mirchandaney (1989), `Krylov methods preconditioned with incompletely factored matrices on the CM-2', </title> <type> Technical Report 89-54, </type> <institution> NASA Langley Research Center, ICASE, Hampton, VA. </institution>
Reference: <author> D. Bertsekas and J. </author> <title> Tsitsiklis (1989), Parallel and Distributed Comptutation: Numerical Methods, </title> <publisher> Prentice Hall (New York). </publisher>
Reference: <author> C. </author> <title> Bischof (1989), `Computing the singular value decomposition on a distributed system of vector processors', </title> <booktitle> Parallel Comput. </booktitle> <pages> 11 171-186. </pages>
Reference: <author> C. Bischof and X. </author> <title> Sun (1992), `A divide and conquer method for tridiagonalizing symmetric matrices with repeated eigenvalues', </title> <type> MCS Report P286-0192, </type> <institution> Argonne National Lab. </institution>
Reference: <author> C. Bischof and P. </author> <title> Tang (1991a), `Generalized incremental condition estimation', </title> <institution> Computer Science Dept, </institution> <type> Technical Report CS-91-132, </type> <institution> University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 32). </note>
Reference-contexts: This cannot be directly combined with blocking as we have just described it, and so instead pivoting algorithms which only look among locally stored columns if possible have been developed <ref> (Bischof and Tang, 1991a,b) </ref>. Other shared memory algorithms based on Givens rotations have also been developed (Chu, 1988a; Gentleman and Kung, 1981; Sameh, 1985), although these do not seem superior on shared memory machines.
Reference: <author> C. Bischof and P. </author> <title> Tang (1991b), `Robust incremental condition estimation', </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-91-133, </type> <institution> University of Ten-nessee, Knoxville, </institution> <note> TN (LAPACK Working Note 33). </note>
Reference: <author> R. P. </author> <title> Brent (1973), Algorithms for Minimization Without Derivatives, </title> <publisher> Prentice-Hall (New York). </publisher>
Reference: <author> R. Brent and F. </author> <title> Luk (1985), `The solution of singular value and symmetric eigenvalue problems on multiprocessor arrays', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 6, </volume> <pages> 69-84. </pages>
Reference-contexts: It has also been of renewed interest on parallel machines because of its inherent parallellism: Jacobi rotations can be applied in parallel to disjoint pairs of rows and/or columns of the matrix, so a matrix with n rows and/or columns can have bn=2c Jacobi rotations applied simultaneously <ref> (Brent and Luk, 1985) </ref>. The question remains of the order in which to apply the simultaneous rotations to achieve quick convergence.
Reference: <author> J. Brunet, A. Edelman and J. </author> <title> Mesirov (1990), `An optimal hypercube direct n-body solver on the connection machine', </title> <booktitle> in: Proceedings of Supercomputing '90, </booktitle> <publisher> IEEE Computer Society Press (New York), </publisher> <pages> 748-752. </pages> <address> 78 D. </address> <note> Calvetti, </note> <author> J. Petersen and L. </author> <title> Reichel (1991), `A parallel implementation of the GMRES method', </title> <type> Technical Report ICM-9110-6, </type> <institution> Institute for Computational Mathematics, Kent, OH. </institution>
Reference-contexts: x j ), i.e. an N -body interaction where f i is the force on body i, 8 F (x i ; x j ) is the force on body i due to body j, and x i and x j are the positions of bodies i and j respectively <ref> (Brunet, Edelman and Mesirov, 1990) </ref>. Consider implementing this on a d-dimensional hypercube, and suppose N = d2 d for simplicity.
Reference: <author> L. </author> <title> Cannon (1969), `A cellular computer to implement the Kalman filter algorithm', </title> <type> PhD thesis, </type> <institution> Montana State University, Bozeman, MN. </institution>
Reference: <author> S. C. Chen, D. J. Kuck and A. H. </author> <title> Sameh (1978), `Practical parallel band triangular system solvers', </title> <journal> ACM Trans. Math. </journal> <volume> Software 4, </volume> <pages> 270-277. </pages>
Reference: <author> A. T. </author> <title> Chronopoulos (1991), `Towards efficient parallel implementation of the CG method applied to a class of block tridiagonal linear systems', </title> <booktitle> in: Supercomputing '91, </booktitle> <publisher> IEEE Computer Society Press (Los Alamitos, CA), </publisher> <pages> 578-587. </pages>
Reference: <author> A. T. Chronopoulos and C. W. </author> <title> Gear (1989), `s-step iterative methods for symmetric linear systems', </title> <journal> J. Comput. Appl. Math. </journal> <volume> 25, </volume> <pages> 153-168. </pages>
Reference: <author> A. T. Chronopoulos and S. K. </author> <title> Kim (1990), `s-Step Orthomin and GMRES implemented on parallel computers', </title> <type> Technical Report 90/43R, </type> <institution> UMSI, Minneapolis. </institution>
Reference-contexts: The obvious way to extract more parallellism and data locality is to generate a basis v 1 , Av 1 , ..., A m v 1 for the Krylov subspace first, and to orthogonalize this set afterwards; this is called m-step GMRES (m) <ref> (Chronopoulos and Kim, 1990) </ref>. This approach does not increase the computational work and, in contrast to CG, the numerical instability due to generating a possibly near-dependent set is not necessarily a drawback.
Reference: <author> E. </author> <title> Chu (1988a), `Orthogonal decomposition of dense and sparse matrices on multiprocessors', </title> <type> PhD thesis, </type> <institution> University of Waterloo. </institution>
Reference: <author> M. </author> <title> Chu (1988b), `A note on the homotopy method for linear algebraic eigenvalue problems', </title> <journal> Lin. Alg. Appl. </journal> <volume> 105, </volume> <pages> 225-236. </pages>
Reference: <author> M. Chu, T.-Y. Li and T. </author> <title> Sauer (1988), `Homotopy method for general -matrix problems', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 9 (4), </volume> <pages> 528-536. </pages>
Reference: <author> L. </author> <month> Csanky </month> <year> (1977), </year> <title> `Fast parallel matrix inversion algorithms', </title> <journal> SIAM J. Comput. </journal> <pages> 5 618-623. </pages>
Reference-contexts: Also, to achieve the maximum speedup O (n 3 ) processors are required, which is 28 unrealistic for large n. We can use this algorithm to build an O (log 2 n) algorithm for the general problem Ax = b <ref> (Csanky, 1977) </ref>, but this algorithm is so unstable as to be entirely useless in floating point (in IEEE double precision floating point, it achieves no precision in inverting 3I, where I is an identity matrix of size 60 or larger). There are four steps: 1.
Reference: <author> J.J.M. </author> <title> Cuppen (1981), `A divide and conquer method for the symmetric tridi-agonal eigenproblem', </title> <journal> Numer. Math. </journal> <volume> 36, </volume> <pages> 177-195. </pages>
Reference-contexts: There have also been generalizations to the band definite generalized symmetric eigenvalue problem (Ma, Patrick and Szyld, 1989). 6.3.3 Cuppen's divide-and-conquer algorithm The third algorithm is a divide-and-conquer algorithm by Cuppen <ref> (Cuppen, 1981) </ref>, and later analysed and modified by many others (Barlow, 1991; Dongarra 39 and Sorensen, 1987; Gu and Eisenstat, 1992; Ipsen and Jessup, 1990; Jessup and Sorensen, 1989; Sorensen and Tang, 1991).
Reference: <author> G. Davis, R. Funderlic and G. </author> <title> Geist (1987), `A hypercube implementation of the implicit double shift QR algorithm', in: Hypercube Multiprocessors 1987, </title> <publisher> SIAM (Philadelphia), </publisher> <pages> 619-626. </pages>
Reference: <author> E. F. D'Azevedo and C. H. </author> <title> Romine (1992), `Reducing communication costs in the conjugate gradient algorithm on distributed memory multiprocessors', </title> <type> Technical Report ORNL/TM-12192, </type> <institution> Oak Ridge National Laboratory. </institution>
Reference: <author> P. P. N. </author> <title> de Groen (1991), `Base p-cyclic reduction for tridiagonal systems of equations', </title> <journal> Appl. Numer. Math. </journal> <pages> 8 117-126. </pages> <note> 79 E. de Sturler (1991), `A parallel restructured version of GMRES(m)', Technical Report 91-85, </note> <institution> Delft University of Technology, Delft. </institution>
Reference-contexts: Each row (column) of the grid thus occupies an m- (n-) dimensional subcube of the original hypercube, with nearest neighbours in the grid mapped to nearest neighbours in the hypercube <ref> (Ho, Johnsson and Edelman, 1991) </ref>. We illustrate for a 4 fi 4 grid in Figure 5. This approach easily extends to multi-dimensional arrays of size 2 m 1 fi fi 2 m r , where P r i=1 m i is at most the dimension of the hypercube. <p> Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992).
Reference: <author> A. </author> <month> Deichmoller </month> <year> (1991), </year> ` <title> Uber die Berechnung verallgemeinerter singularer Werte mittles Jacobi-ahnlicher Verfahren', </title> <type> PhD thesis, </type> <institution> Fernuniversitat|Hagen, Hagen, Germany. </institution>
Reference: <author> E. Dekel, D. Nassimi and S. </author> <title> Sahni (1981), `Parallel matrix and graph algorithms', </title> <journal> SIAM J. Comput. </journal> <volume> 10 (4), </volume> <pages> 657-675. </pages>
Reference-contexts: In the following algorithm, denotes the bitwise exclusive-or operator. We assume the 2 n fi 2 n grid of data is embedded in the hypercube so that A (i;j) is stored in processor i 2 n + j <ref> (Dekel, Nassimi and Sahni, 1981) </ref>: Algorithm 7 Dekel's matrix multiplication algorithm for k = 1 : n Let i k = (kth bit of i) 2 k forall i = 0 : 2 n 1, forall j = 0 : 2 n 1 Swap A (i;ji k ) and A (i;j)
Reference: <author> T. </author> <title> Dekker (1971), `A floating point technique for extending the available precision', </title> <journal> Numer. Math. </journal> <pages> 18 224-242. </pages>
Reference: <author> J. </author> <title> Demmel (1987), `Three methods for refining estimates of invariant subspaces', </title> <booktitle> Computing 38, </booktitle> <pages> 43-57. </pages>
Reference-contexts: On the other hand, if it is difficult to find a good place to split the spectrum, convergence can be slow, and the final approximate invariant subspace inaccurate. At this point, iterative refinement could be used to improve the factorization <ref> (Demmel, 1987) </ref>. These methods apply to the generalized nonsymmetric eigenproblem as well (Bai and Demmel, 1992; Malyshev, 1991). 7 Direct methods for sparse linear systems 7.1 Cholesky factorization In this section we discuss parallel algorithms for solving sparse systems of linear equations by direct methods.
Reference: <author> J. </author> <title> Demmel (1992a), `Specifications for robust parallel prefix operations', </title> <type> Technical report, </type> <institution> Thinking Machines Corp., </institution> <address> Cambridge, MA. </address>
Reference-contexts: This requires good support for parallel prefix operations, and is not as easy to parallellize as simply having each processor refine different sets of intervals containing different eigenvalues <ref> (Demmel, 1992a) </ref>. Within a single processor one can also run Algorithm 17 or 18 for many different by pipelining or vectorizing (Simon, 1989).
Reference: <author> J. </author> <title> Demmel (1992b), `Trading off parallelism and numerical stability', </title> <institution> Computer Science Division Technical Report UCB//CSD-92-702, University of California, Berkeley, </institution> <address> CA. </address>
Reference-contexts: This is true for various kinds of linear systems and eigenvalue problems, which we will point out as they arise. Some of these tradeoffs can be mitigated by better floating point 13 arithmetic <ref> (Demmel, 1992b) </ref>. Others can be dealt with by using the following simple paradigm: 1. Solve the problem using a fast method, provided it is rarely unstable. 2. Quickly and reliably confirm or deny the accuracy of the computed solution.
Reference: <author> J. Demmel and N. J. </author> <title> Higham (1992), `Stability of block algorithms with fast Level 3 BLAS', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 18 (3), </volume> <pages> 274-291. </pages>
Reference-contexts: It turns out it accelerates convergence to do the Cholesky decomposition with pivoting, and then apply Jacobi to the columns of L rather than the columns of L T <ref> (Demmel and Veselic, 1992) </ref>. It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way (Slapnicar, 1992). Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS.
Reference: <author> J. Demmel and W. </author> <title> Kahan (1990), `Accurate singular values of bidiagonal matrices', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 11 (5), </volume> <pages> 873-912. </pages>
Reference: <author> J. Demmel and K. </author> <title> Veselic (1992), `Jacobi's method is more accurate than QR', </title> <journal> SIAM J. Mat. Anal. Appl. </journal> <volume> 13 (4), </volume> <pages> 1204-1246. </pages>
Reference-contexts: It turns out it accelerates convergence to do the Cholesky decomposition with pivoting, and then apply Jacobi to the columns of L rather than the columns of L T <ref> (Demmel and Veselic, 1992) </ref>. It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way (Slapnicar, 1992). Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS.
Reference: <author> S. </author> <title> Doi (1991), `On parallelism and convergence of incomplete LU factorizations', </title> <journal> Appl. Numer. Math. </journal> <volume> 7, </volume> <pages> 417-436. </pages>
Reference-contexts: Some modest degree of parallellism can be obtained, however, with so-called incomplete twisted factorizations (Dongarra et al., 1991; van der Vorst, 1987b; van der Vorst, 1989a). Multi-colour schemes with a large number of colours (e.g., 20 to 100) may lead to little or no degradation in convergence behaviour <ref> (Doi, 1991) </ref>, but also to less parallellism. Moreover, the ratio of computation to communication may be more unfavourable. 3. Forced parallellism. Parallelism can also be forced by simply neglecting couplings to unknowns residing in other processors.
Reference: <author> J. Dongarra, J. Bunch, C. Moler and G. W. </author> <title> Stewart (1979), LINPACK User's Guide, </title> <publisher> SIAM (Philadelphia). </publisher>
Reference-contexts: All the rest of 3! permutations of i, j and k lead to valid algorithms, some of which access columns of A in the innermost loop. Algorithm 10 is one of these, and is used in the LINPACK routine sgefa <ref> (Dongarra et al., 1979) </ref>: Algorithm 10 Column oriented Gaussian elimination (kji-LU decomposition) for k = 1 : n 1 f choose l so jA lk j = max kin jA ik j, swap A lk and A kk g for i = k + 1 : n for j = k
Reference: <author> J. Dongarra, J. Du Croz, I. Duff and S. </author> <title> Hammarling (1990), `A set of Level 3 Basic Linear Algebra Subprograms', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 16 (1), </volume> <pages> 1-17. </pages>
Reference-contexts: Operations like matrix-matrix multiplication operate on pairs of matrices, and offer the best q values; these are called Level 3 BLAS <ref> (Dongarra, Du Croz, Duff and Hammarling, 1990) </ref>, and include solving triangular systems of equations with many right hand sides.
Reference: <author> J. Dongarra, J. Du Croz, S. Hammarling and Richard J. </author> <title> Hanson (1988), `An extended set of fortran basic linear algebra subroutines', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 14 (1), </volume> <pages> 1-17. </pages>
Reference-contexts: Operation Definition Floating Memory q point references operations saxpy y i = ffx i +y i , i = 1; :::; n 2n 3n+1 2=3 Matrix-vector mult y i = P n Matrix-matrix mult C ij = P n <ref> (Dongarra, Du Croz, Hammarling and Richard Hanson, 1988) </ref>, and include solving triangular systems of equations and rank-1 updates of matrices (A + xy T , x and y column vectors).
Reference: <author> J. Dongarra, I. Duff, D. Sorensen and H. van der Vorst (1991), </author> <title> Solving Linear Systems on Vector and Shared Memory Computers, </title> <note> SIAM (Philadelphia). 80 J. </note> <author> Dongarra, G. A. Geist, and C. </author> <title> Romine (1990b), `Computing the eigenvalues and eigenvectors of a general matrix by reduction to tridiagonal form', </title> <type> Technical Report ORNL/TM-11669, </type> <note> Oak Ridge National Laboratory (to appear in ACM TOMS). </note>
Reference-contexts: Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992). <p> Evaluating the determinant of a Hessenberg matrix costs only a triangular solve and an inner product, and therefore is efficient. It shares similar advantages and disadvantages as the previous homotopy algorithm. Alternatively, one can use Newton's method to compute the eigendecompo-sition of H from S <ref> (Dongarra and Sidani, 1991) </ref>. The function to which one applies Newton's method is f (z; ) = [(Hz z) T ; e T z 1] T , where e is a fixed unit vector.
Reference: <author> J. Dongarra and E. </author> <title> Grosse (1987), `Distribution of mathematical software via electronic mail', </title> <journal> Commun. ACM 30(5), </journal> <pages> 403-407. </pages>
Reference: <author> J. Dongarra, S. Hammarling and D. </author> <title> Sorensen (1989), `Block reduction of matrices to condensed forms for eigenvalue computations', </title> <journal> J. Comput. Appl. Math. </journal> <note> 27, 215-227 (LAPACK Working Note 2). </note>
Reference: <author> J. Dongarra and S. </author> <title> Ostrouchov (1990), `LAPACK block factorization algorithms on the Intel iPSC/860', </title> <institution> Computer Science Dept Technical Report CS-90-115, University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 24). </note>
Reference-contexts: Operations like matrix-matrix multiplication operate on pairs of matrices, and offer the best q values; these are called Level 3 BLAS <ref> (Dongarra, Du Croz, Duff and Hammarling, 1990) </ref>, and include solving triangular systems of equations with many right hand sides.
Reference: <author> J. Dongarra and M. </author> <title> Sidani (1991), `A parallel algorithm for the non-symmetric eigenvalue problem', </title> <institution> Computer Science Dept Technical Report CS-91-137, University of Tennessee, Knoxville, TN. </institution>
Reference-contexts: Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992). <p> Evaluating the determinant of a Hessenberg matrix costs only a triangular solve and an inner product, and therefore is efficient. It shares similar advantages and disadvantages as the previous homotopy algorithm. Alternatively, one can use Newton's method to compute the eigendecompo-sition of H from S <ref> (Dongarra and Sidani, 1991) </ref>. The function to which one applies Newton's method is f (z; ) = [(Hz z) T ; e T z 1] T , where e is a fixed unit vector.
Reference: <author> J. Dongarra and D. </author> <title> Sorensen (1987), `A fully parallel algorithm for the symmetric eigenproblem', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 8(2), </volume> <pages> 139-154. </pages>
Reference: <author> J. Dongarra and R. van de Geijn (1991), </author> <title> `Reduction to condensed form for the eigenvalue problem on distributed memory computers', </title> <institution> Computer Science Dept Technical Report CS-91-130, University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 30), to appear in Parallel Comput.. </note>
Reference-contexts: Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992). <p> Evaluating the determinant of a Hessenberg matrix costs only a triangular solve and an inner product, and therefore is efficient. It shares similar advantages and disadvantages as the previous homotopy algorithm. Alternatively, one can use Newton's method to compute the eigendecompo-sition of H from S <ref> (Dongarra and Sidani, 1991) </ref>. The function to which one applies Newton's method is f (z; ) = [(Hz z) T ; e T z 1] T , where e is a fixed unit vector.
Reference: <author> J. Dongarra and R. van de Geijn (1991), </author> <title> `Two dimensional basic linear algebra communication subprograms', </title> <institution> Computer Science Dept Technical Report CS-91-138, University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 37). </note>
Reference-contexts: Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992). <p> Evaluating the determinant of a Hessenberg matrix costs only a triangular solve and an inner product, and therefore is efficient. It shares similar advantages and disadvantages as the previous homotopy algorithm. Alternatively, one can use Newton's method to compute the eigendecompo-sition of H from S <ref> (Dongarra and Sidani, 1991) </ref>. The function to which one applies Newton's method is f (z; ) = [(Hz z) T ; e T z 1] T , where e is a fixed unit vector.
Reference: <author> J. Du Croz, P. J. D. Mayes and G. </author> <title> Radicati di Brozolo (1990), `Factorizations of band matrices using Level 3 BLAS', </title> <institution> Computer Science Dept Technical Report CS-90-109, University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 21). </note>
Reference-contexts: Operations like matrix-matrix multiplication operate on pairs of matrices, and offer the best q values; these are called Level 3 BLAS <ref> (Dongarra, Du Croz, Duff and Hammarling, 1990) </ref>, and include solving triangular systems of equations with many right hand sides.
Reference: <author> P. Dubois and G. </author> <title> Rodrigue (1977), `An analysis of the recursive doubling algorithm', High Speed Computer and Algorithm Organization, </title> <editor> (D. J. Kuck and A. H. Sameh, eds), </editor> <publisher> Academic Press (New York). </publisher>
Reference: <author> A. </author> <title> Dubrulle (1991), `The multishift QR algorithm: is it worth the trouble?', </title> <institution> Palo Alto Scientific Center Report G320-3558x, IBM Corp., 1530 Page Mill Road, </institution> <address> Palo Alto, CA 94304. </address>
Reference-contexts: Asymptotic convergence remains quadratic (Watkins and Elsner, 1991). The drawbacks to this scheme are twofold. First, any attempt to use Level 3 BLAS introduces rather small (hence inefficient) matrix-matrix operations, and raises the operation count considerably. Second, the convergence properties degrade significantly, resulting in more overall work as well <ref> (Dubrulle, 1991) </ref>. As a result, speedups have been extremely modest. This routine is available in LAPACK as shseqr (Anderson et al., 1992). Yet another way to introduce parallellism into Hessenberg QR is to pipeline several bulge chasing steps (van de Geijn, 1987; Watkins, 1992; Watkins and Elsner, 1991).
Reference: <author> I.S. </author> <title> Duff (1986), `Parallel implementation of multifrontal schemes', </title> <journal> Parallel Comput. </journal> <volume> 3, </volume> <pages> 193-204. </pages> <note> 81 I.S. </note> <author> Duff, A.M. Erisman and J.K. </author> <title> Reid (1986), Direct Methods for Sparse Ma--trices, </title> <publisher> Oxford University Press (Oxford, </publisher> <address> UK). </address>
Reference: <author> I.S. Duff and G.A. </author> <title> Meurant (1989), `The effect of ordering on preconditioned conjugate gradient', </title> <journal> BIT 29, </journal> <pages> 635-657. </pages>
Reference: <author> P. </author> <title> Eberlein (1962), `A Jacobi method for the automatic computation of eigen-values and eigenvectors of an arbitrary matrix', </title> <journal> J. </journal> <volume> SIAM 10, </volume> <pages> 74-88. </pages>
Reference: <author> P. </author> <title> Eberlein (1987), `On the Schur decomposition of a matrix for parallel computation', </title> <journal> IEEE Trans. Comput. </journal> <volume> 36, </volume> <pages> 167-174. </pages>
Reference: <author> V. </author> <title> Eijkhout (1992), `Qualitative properties of the conjugate gradient and Lanc-zos methods in a matrix framework', </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-92-170, </type> <institution> University of Tennessee, Knoxville, </institution> <note> TN (LAPACK Working Note 51). </note>
Reference: <author> S. Eisenstat, M. Heath, C. Henkel and C. </author> <title> Romine (1988), `Modified cyclic algorithms for solving triangular systems on distributed memory multiprocessors', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 589-600. </pages>
Reference: <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C.-W. Tseng and M.-Y. </author> <title> Wu (1990), `Fortran D language specification', </title> <institution> Computer Science Department Report CRPC-TR90079, Rice University, Houston, TX. </institution>
Reference: <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon and D. </author> <title> Walker (1988), Solving Problems on Concurrent Processors, vol. I, </title> <publisher> Prentice Hall (New York). </publisher>
Reference-contexts: Upward circular shift each column of B by 1, so B (i;j) is assigned B ((i+1)modN;j) . of this algorithm suitable for machines that are efficient at spreading subblocks across rows (or down columns) is to do this instead of the preshifting and rotation of A (or B) <ref> (Fox, Johnson, Lyzenga, Otto, Salmon and Walker, 1988) </ref>. This algorithm is easily adapted to a hypercube.
Reference: <author> R. W. Freund, G. H. Golub and N. M. </author> <title> Nachtigal (1992), `Iterative solution of linear systems', </title> <booktitle> Acta Numerica 1, </booktitle> <pages> 57-100. </pages>
Reference: <author> K. Gallivan, M. Heath, E. Ng, J. Ortega, B. Peyton, R. Plemmons, C. Romine, A. Sameh and R. </author> <title> Voigt (1990), Parallel Algorithms for Matrix Computations, </title> <publisher> SIAM (Philadelphia). </publisher>
Reference-contexts: Section 3.3); 16 2. if the fast memory consists of vector registers and has vector operations supporting saxpy but not inner products, a column blocked code may be superior; 3. a real code will have to deal with nonsquare matrices, for which the optimal block sizes may not be square <ref> (Gallivan et al., 1990) </ref>.
Reference: <author> K. Gallivan, W. Jalby, U. Meier and A. </author> <title> Sameh (1988), `Impact of hierarchical memory systems on linear algebra algorithm design', </title> <journal> Int. J. Supercomput. Appl. </journal> <volume> 2, </volume> <pages> 12-48. </pages>
Reference-contexts: Other shared memory algorithms based on Givens rotations have also been developed (Chu, 1988a; Gentleman and Kung, 1981; Sameh, 1985), although these do not seem superior on shared memory machines. It is also possible to use Level 2 and 3 BLAS in the modified Gram-Schmidt algorithm <ref> (Gallivan, Jalby, Meier and Sameh,1988) </ref>. 5.2 Distributed memory algorithms Just as we could map Algorithm 13 (Gaussian elimination with Level 3 BLAS) to a distributed memory machine with blocked and/or scattered layout by inserting appropriate communication, this can also be done for QR with Level 3 BLAS.
Reference: <author> K. A. Gallivan, M. T. Heath, E. Ng, et al. </author> <year> (1990), </year> <title> Parallel Algorithms for Matrix Computations, </title> <publisher> SIAM (Philadelphia). </publisher>
Reference-contexts: Section 3.3); 16 2. if the fast memory consists of vector registers and has vector operations supporting saxpy but not inner products, a column blocked code may be superior; 3. a real code will have to deal with nonsquare matrices, for which the optimal block sizes may not be square <ref> (Gallivan et al., 1990) </ref>.
Reference: <author> K. A. Gallivan, R. J. Plemmons and A. H. </author> <title> Sameh (1990), `Parallel algorithms for dense linear algebra computations', </title> <journal> SIAM Rev. </journal> <volume> 32, </volume> <pages> 54-135. </pages>
Reference-contexts: Section 3.3); 16 2. if the fast memory consists of vector registers and has vector operations supporting saxpy but not inner products, a column blocked code may be superior; 3. a real code will have to deal with nonsquare matrices, for which the optimal block sizes may not be square <ref> (Gallivan et al., 1990) </ref>.
Reference: <author> B. S. Garbow, J. M. Boyle, J. J. Dongarra and C. B. </author> <title> Moler (1977), Matrix eigen-system routines - EISPACK guide extension, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> vol. 51, </volume> <publisher> Springer-Verlag (Berlin). 82 G. </publisher> <editor> A. </editor> <title> Geist (1990), `Parallel tridiagonalization of a general matrix using dis-tributed memory multiprocessors', </title> <booktitle> in Proc. Fourth SIAM Conf. on Parallel Processing for Scientific Computing, SIAM (Philadelphia), </booktitle> <pages> 29-35. </pages>
Reference: <author> G. A. </author> <title> Geist (1991), `Reduction of a general matrix to tridiagonal form', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 12(2), </volume> <pages> 362-373. </pages>
Reference: <author> G. A. Geist and G. J. </author> <title> Davis (1990), `Finding eigenvalues and eigenvectors of unsymmetric matrices using a distributed memory multiprocessor', </title> <journal> Parallel Comput. </journal> <volume> 13(2), </volume> <pages> 199-209. </pages>
Reference: <author> G. A. Geist, A. Lu and E. </author> <title> Wachspress (1989), `Stabilized reduction of an arbitrary matrix to tridiagonal form', </title> <type> Technical Report ORNL/TM-11089, </type> <institution> Oak Ridge National Laboratory. </institution>
Reference: <author> M. Gentleman and H. T. </author> <title> Kung (1981), `Matrix triangularization by systolic arrays', </title> <booktitle> in Proc. SPIE 298, Real Time Signal Processing, </booktitle> <address> San Diego, CA, </address> <pages> 19-26. </pages>
Reference: <author> J.A. </author> <title> George (1973), `Nested dissection of a regular finite element mesh', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 10, </volume> <pages> 345-363. </pages>
Reference-contexts: Again, this is typical of minimum degree orderings. In view of this property, Liu (1989) has developed an interesting strategy for further reordering of an initial minimum degree ordering that preserves fill while reducing the height of the elimination tree. a divide-and-conquer strategy <ref> (George, 1973) </ref>. Let S be a set of nodes, called a separator, whose removal, along with all edges incident upon nodes in S, disconnects G (A) into two remaining subgraphs.
Reference: <author> J.A. George, M.T. Heath, J.W.-H. Liu and E. </author> <title> Ng (1986), `Solution of sparse positive definite systems on a shared memory multiprocessor', </title> <journal> Int. J. Parallel Progr. </journal> <volume> 15, </volume> <pages> 309-325. </pages>
Reference: <author> J.A. George, M.T. Heath, J.W.-H. Liu and E. </author> <title> Ng (1988), `Sparse Cholesky factorization on a local-memory multiprocessor', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 327-340. </pages>
Reference-contexts: One of the earliest and simplest parallel algorithms for sparse Cholesky factorization is the following version of submatrix-Cholesky <ref> (George, Heath, Liu and Ng, 1988) </ref>. Algorithm 22 runs on each processor, with each responsible for its own subset, mycols, of columns.
Reference: <author> J.A. George, M.T. Heath, J.W.-H. Liu and E. </author> <title> Ng (1989), `Solution of sparse positive definite systems on a hypercube', </title> <journal> J. Comput. Appl. Math. </journal> <volume> 27, </volume> <pages> 129-156. </pages>
Reference-contexts: The cmod operations involve only a couple of flops each, so that even the `medium-grain' tasks are actually rather small in this case.) by a minimum degree algorithm. Minimum degree is the most effective general purpose heuristic known for limiting fill in sparse factorization <ref> (George and Liu, 1989) </ref>. In its simplest form, this algorithm begins by selecting a node of minimum degree (i.e. one having fewest incident edges) in G (A) and numbering it first. <p> A better approach for sparse factorization is to preserve locality by assigning subtrees of the elimination tree to contiguous subsets of neighbouring processors. A good example of this technique is the `subtree-to-subcube' mapping often used with hypercube multicomputers <ref> (George, Heath, Liu and Ng, 1989) </ref>. Of course, the same idea applies to other network topologies, such as submeshes of a larger mesh. We will assume that some such mapping is used, and we will comment further on its implications later.
Reference: <author> J.A. George and J.W.-H. </author> <title> Liu (1981), Computer Solution of Large Sparse Positive Definite Systems, </title> <publisher> Prentice-Hall (Englewood Cliffs, </publisher> <address> NJ). </address>
Reference: <author> J.A. George and J.W.-H. </author> <title> Liu (1989), `The evolution of the minimum degree ordering algorithm', </title> <journal> SIAM Rev. </journal> <volume> 31, </volume> <pages> 1-19. </pages>
Reference-contexts: The cmod operations involve only a couple of flops each, so that even the `medium-grain' tasks are actually rather small in this case.) by a minimum degree algorithm. Minimum degree is the most effective general purpose heuristic known for limiting fill in sparse factorization <ref> (George and Liu, 1989) </ref>. In its simplest form, this algorithm begins by selecting a node of minimum degree (i.e. one having fewest incident edges) in G (A) and numbering it first. <p> A better approach for sparse factorization is to preserve locality by assigning subtrees of the elimination tree to contiguous subsets of neighbouring processors. A good example of this technique is the `subtree-to-subcube' mapping often used with hypercube multicomputers <ref> (George, Heath, Liu and Ng, 1989) </ref>. Of course, the same idea applies to other network topologies, such as submeshes of a larger mesh. We will assume that some such mapping is used, and we will comment further on its implications later.
Reference: <author> J.A. George, J.W.-H. Liu and E. </author> <title> Ng (1989), `Communication results for parallel sparse Cholesky factorization on a hypercube', </title> <journal> Parallel Comput. </journal> <volume> 10, </volume> <pages> 287-298. </pages>
Reference-contexts: The cmod operations involve only a couple of flops each, so that even the `medium-grain' tasks are actually rather small in this case.) by a minimum degree algorithm. Minimum degree is the most effective general purpose heuristic known for limiting fill in sparse factorization <ref> (George and Liu, 1989) </ref>. In its simplest form, this algorithm begins by selecting a node of minimum degree (i.e. one having fewest incident edges) in G (A) and numbering it first. <p> A better approach for sparse factorization is to preserve locality by assigning subtrees of the elimination tree to contiguous subsets of neighbouring processors. A good example of this technique is the `subtree-to-subcube' mapping often used with hypercube multicomputers <ref> (George, Heath, Liu and Ng, 1989) </ref>. Of course, the same idea applies to other network topologies, such as submeshes of a larger mesh. We will assume that some such mapping is used, and we will comment further on its implications later.
Reference: <author> J. Gilbert and R. </author> <title> Schreiber (1992), `Highly parallel sparse cholesky factorization', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 13, </volume> <pages> 1151-1172. </pages>
Reference: <author> G. Golub and C. Van Loan (1989), </author> <title> Matrix Computations, 2nd ed, </title> <publisher> Johns Hopkins University Press (Baltimore, </publisher> <address> MD). </address> <note> 83 A. </note> <author> Gottlieb and G. </author> <title> Almasi (1989), Highly Parallel Computing, </title> <address> Benjamin Cum--mings (Redwood City, CA). </address>
Reference-contexts: In this section we concentrate on factoring 24 P A = LU , which has the dominant number of floating point operations, 2n 3 =3+ O (n 2 ). Pivoting is required for numerical stability, and we use the standard partial pivoting scheme <ref> (Golub and Van Loan, 1989) </ref>; this means L has unit diagonal and other entries bounded in magnitude by one. <p> For simplicity we consider only QR without pivoting, and mention work incorporating pivoting at the end. The conventional approach is to premultiply A by a sequence of simple orthogonal matrices Q i chosen to introduce zeros below the diagonal of A <ref> (Golub and Van Loan, 1989) </ref>. Eventually A becomes upper triangular, and equal to R, and the product Q N Q 1 = Q. <p> changed rows of one column of A; a Household reflection may be written I 2uu T , where u is a unit vector with nonzeros only in the rows to be changed. 5.1 Shared memory algorithms The basic algorithm to compute a QR decomposition using Householder transformations is given in <ref> (Golub and Van Loan, 1989) </ref>: Algorithm 13 QR decomposition using Level 2 BLAS for k = 1 : n 1 Compute a unit vector u k so that (I 2u k u T k )A (k + 1 : m; k) = 0 Update A = A 2 fl u k <p> If T has diagonal entries a 1 ; :::; a n and offdiag-onals b 1 ; :::; b n1 , then we can count the number of eigenvalues of T less than <ref> (Golub and Van Loan, 1989) </ref>. <p> The current level of parallel software support on many machines can make this difficult to implement well. 6.4 Jacobi's method for the symmetric eigenproblem and SVD Jacobi's method has been used for the nonsymmetric eigenproblem, the symmetric eigenproblem, the SVD, and generalizations of these problems to pairs of matrices <ref> (Golub and Van Loan, 1989) </ref>. It works by applying a series of Ja-cobi rotations (a special kind of Givens rotation) to the left and/or right of the matrix in order to drive it to a desired canonical form, such as the diagonal form for the symmetric eigenproblem. <p> Since we do not require A to be symmetric, we need long recurrences: each new vector must be explicitly orthogonalized against all previously generated basis vectors. In its most common form GMRES orthogonalizes using Modified Gram-Schmidt <ref> (Golub and Van Loan, 1989) </ref>. In order to limit memory requirements (since all basis vectors must be stored), GMRES is restarted after each cycle of m iteration steps; this is called GMRES (m).
Reference: <author> M. Gu and S. </author> <title> Eisenstat (1992), `A stable and efficient algorithm for the rank-1 modification of the symmetric eigenproblem', </title> <institution> Computer Science Dept Report YALEU/DCS/RR-916, Yale University. </institution>
Reference: <author> V. Hari and K. </author> <title> Veselic (1987), `On Jacobi methods for singular value decompositions', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 8, </volume> <pages> 741-754. </pages>
Reference-contexts: Such a one-sided Jacobi is natural when computing the SVD <ref> (Hari and Veselic, 1987) </ref>, but requires some preprocessing for the symmetric eigenproblem (Demmel and Veselic, 1992; Slapnicar, 1992); for example, in the symmetric positive definite case one can perform Cholesky on A to obtain A = LL T , apply one-sided Jacobi on L or L T to get its (partial)
Reference: <author> M.T. Heath, E. Ng and B. </author> <title> Peyton (1991), `Parallel algorithms for sparse linear systems', </title> <journal> SIAM Rev. </journal> <volume> 33, </volume> <pages> 420-460. </pages>
Reference: <author> M.T. Heath and C. </author> <title> Romine (1988), `Parallel solution of triangular systems on distributed memory multiprocessors', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 558-588. </pages>
Reference-contexts: One of the earliest and simplest parallel algorithms for sparse Cholesky factorization is the following version of submatrix-Cholesky <ref> (George, Heath, Liu and Ng, 1988) </ref>. Algorithm 22 runs on each processor, with each responsible for its own subset, mycols, of columns.
Reference: <author> D. </author> <title> Heller (1978), `Some aspects of the cyclic reduction algorithm for block tridiagonal linear systems', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 13, </volume> <pages> 484-496. </pages>
Reference: <author> M. R. Hestenes and E. </author> <title> Stiefel (1954), `Methods of conjugate gradients for solving linear systems', </title> <institution> J. Res. Natl Bur. Stand. </institution> <note> 49, 409-436. High Peformance Fortran (1991), documentation available via anonymous ftp from titan.cs.rice.edu in directory public/HPFF. </note>
Reference: <author> N. J. </author> <title> Higham (1990), `Exploiting fast matrix multiplication within the Level 3 BLAS', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 16, </volume> <pages> 352-368. </pages>
Reference: <author> C. T. </author> <title> Ho (1990), Optimal communication primitives and graph embeddings on hypercubes, </title> <type> PhD thesis, </type> <institution> Yale University. </institution>
Reference: <author> C. T. Ho, S. L. Johnsson and A. </author> <title> Edelman (1991), `Matrix multiplication on hypercubes using full bandwidth and constant storage', </title> <booktitle> in The Sixth Distributed Memory Computing Conf. Proc., </booktitle> <publisher> IEEE Computer Society Press (New York), </publisher> <pages> 447-451. </pages>
Reference-contexts: Each row (column) of the grid thus occupies an m- (n-) dimensional subcube of the original hypercube, with nearest neighbours in the grid mapped to nearest neighbours in the hypercube <ref> (Ho, Johnsson and Edelman, 1991) </ref>. We illustrate for a 4 fi 4 grid in Figure 5. This approach easily extends to multi-dimensional arrays of size 2 m 1 fi fi 2 m r , where P r i=1 m i is at most the dimension of the hypercube.
Reference: <author> X. Hong and H. T. </author> <title> Kung (1981), `I/O complexity: the red blue pebble game', </title> <booktitle> in Proc. 13th Symposium on the Theory of Computing, </booktitle> <publisher> ACM (New York), </publisher> <pages> 326-334. </pages>
Reference: <author> J. </author> <title> Howland (1983), `The sign matrix and the separation of matrix eigenvalues', </title> <journal> Lin. Alg. Appl. </journal> <volume> 49, </volume> <pages> 221-232. </pages>
Reference: <author> I. Ipsen and E. </author> <title> Jessup (1990), `Solving the symmetric tridiagonal eigenvalue problem on the hypercube', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 11(2), </volume> <pages> 203-230. </pages>
Reference-contexts: If we simply do inverse iteration without communication, the speedup will be nearly perfect. However, we cannot guarantee orthogonality of eigenvectors of clustered eigenvalues <ref> (Ipsen and Jessup, 1990) </ref>, which currently seems to require reorthogonalization of eigenvectors within clusters (other methods are under investigation (Parlett, 1992)).
Reference: <author> B.M. </author> <month> Irons </month> <year> (1970), </year> <title> `A frontal solution program for finite element analysis', </title> <booktitle> Int. </booktitle>
Reference-contexts: Multifrontal methods have a number of attrac-tive advantages, most of which accrue from the localization of memory references in the front matrices, thereby facilitating the effective use of memory hierarchies, including cache, virtual memory with paging, or explicit out-of-core solutions (the latter was the original motivation for these methods <ref> (Irons, 1970) </ref>). In addition, since the front matrices are essentially dense, the operations on them can be done using optimized kernels, such as the BLAS, to take advantage of vectorization or any other available architectural features.
Reference: <author> J. </author> <title> Numer. </title> <journal> Math. </journal> <volume> Engrg 2, </volume> <pages> 5-32. </pages> <note> 84 J.A.G. </note> <author> Jess and H.G.M. </author> <title> Kees (1982), `A data structure for parallel L/U decom-position', </title> <journal> IEEE Trans. Comput. </journal> <volume> C-31, </volume> <pages> 231-239. </pages>
Reference: <author> E. </author> <title> Jessup (1991), `A case against a divide and conquer approach to the nonsymmetric eigenproblem', </title> <type> Technical Report ORNL/TM-11903, </type> <institution> Oak Ridge National Laboratory. </institution>
Reference: <author> E. Jessup and I. </author> <title> Ipsen (1992), `Improving the accuracy of inverse iteration', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 13(2), </volume> <pages> 550-572. </pages>
Reference: <author> E. Jessup and D. </author> <title> Sorensen (1989), `A divide and conquer algorithm for computing the singular value decomposition of a matrix', </title> <booktitle> in Proc. Third SIAM Conf. on Parallel Processing for Scientific Computing SIAM (Philadel-phia), </booktitle> <pages> 61-66. </pages> <publisher> SIAM. </publisher>
Reference: <author> S. L. </author> <title> Johnsson (1987), `Communication efficient basic linear algebra computations on hypercube architecture', </title> <journal> J. Parallel Distr. Comput. </journal> <volume> 4, </volume> <pages> 133-172. </pages>
Reference: <author> S. L. </author> <title> Johnsson (1990), </title> <type> private communication. </type>
Reference-contexts: We describe these layouts here. High Performance Fortran (HPF) (High Peformance Fortran, 1991) permits the user to define a virtual array of processors, align actual data structures 3 The matrix multiplication subroutine in the CM-2 Scientific Subroutine Library took approximately 10 person-years of effort <ref> (Johnsson, 1990) </ref>. 21 like matrices and arrays with this virtual array (and so with respect to each other), and then to layout the virtual processor array on an actual machine. We describe the layout functions f offered for this last step.
Reference: <author> S. L. Johnsson and C. T. </author> <title> Ho (1989), `Matrix multiplication on Boolean cubes using generic communication primitives', in Parallel Processing and Medium Scale Multiprocessors, </title> <editor> (A. Wouk, ed), </editor> <publisher> SIAM (Philadelphia), </publisher> <pages> 108-156. </pages>
Reference: <author> W. </author> <title> Kahan (1968), `Accurate eigenvalues of a symmetric tridiagonal matrix', </title> <institution> Computer Science Dept Technical Report CS41, Stanford University, </institution> <address> Stan-ford, CA, </address> <month> July </month> <year> 1966 </year> <month> (revised June </month> <year> 1968). </year>
Reference-contexts: 0, p 0 = 1, p 1 = 0, b 0 = 0 for i = 1 : n i1 p i2 if p i p i1 &lt; 0, count = count + 1 In practice, these algorithms need to protected against over/underflow; Algorithm 17 is much easier to protect <ref> (Kahan, 1968) </ref>. Using either of these algorithms, we can count the number of eigenvalues in an interval. The traditional approach is to bisect each interval, say [ 1 ; 2 ], by running Algorithm 17 or 18 at = ( 1 + 2 )=2. <p> The first kind of parallellism uses parallel prefix as described in (1) in Section 2.2, and so care needs to be taken to avoid over/underflow. The numerical stability of the serial implementations of Algorithms 17 <ref> (Kahan, 1968) </ref> and 18 (Wilkinson, 1965) is very good, but that of the parallel prefix algorithm is unknown, although numerical experiments are promising (Swarztrauber, 1992).
Reference: <author> R. Karp and V. </author> <title> Ramachandran (1990), `Parallel algorithms for shared memory machines', in Handbook of Theoretical Computer Science, vol. A: Algorithms and Complexity, </title> <editor> (J. van Leeuwen, ed), </editor> <publisher> Elsevier and MIT Press (New York), </publisher> <pages> 869-941. </pages>
Reference: <author> C. Kenney and A. </author> <title> Laub (1991), `Rational iteration methods for the matrix sign function', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 21, </volume> <pages> 487-494. </pages>
Reference: <author> A. S. </author> <title> Krishnakumar and Morf (1986), `Eigenvalues of a symmetric tridiagonal matrix: a divide and conquer approach', </title> <journal> Numer. Math. </journal> <volume> 48, </volume> <pages> 349-368. </pages>
Reference: <author> D. Kuck and A. </author> <title> Sameh (1977), `A parallel QR algorithm for symmetric tridi-agonal matrices', </title> <journal> IEEE Trans. Comput. C-26(2). </journal>
Reference-contexts: As it stands this recurrence is not parallellizable, but by squaring the matrix entries it can be changed into a recurrence of the form (1) in Section 2.2 <ref> (see Kuck and Sameh, 1977) </ref>. The numerical stability of this method is not known, but available analyses are pessimistic (Kuck and Sameh, 1977). Furthermore, QR iterations must be done sequentially, with usually just one eigenvalue converging at a time. <p> As it stands this recurrence is not parallellizable, but by squaring the matrix entries it can be changed into a recurrence of the form (1) in Section 2.2 (see Kuck and Sameh, 1977). The numerical stability of this method is not known, but available analyses are pessimistic <ref> (Kuck and Sameh, 1977) </ref>. Furthermore, QR iterations must be done sequentially, with usually just one eigenvalue converging at a time. If one only wants eigenvalues, this method does not appear to be competitive with the alternatives below.
Reference: <author> H. T. </author> <title> Kung (1974), `New algorithms and lower bounds for the parallel evaluation of certain rational expressions', </title> <type> Technical report, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> J. J. Lambiotte and R. G. </author> <title> Voigt (1974), `The solution of tridiagonal linear systems on the CDC-STAR-100 computer', </title> <type> Technical report, </type> <institution> ICASE-NASA Langley Research Center, </institution> <address> Hampton, VA. </address> <publisher> 85 B. </publisher> <month> Lang </month> <year> (1992), </year> <title> `Reducing symmetric band matrices to tridiagonal form - a comparison of a new parallel algorithm with two serial algorithms on the iPSC/860', </title> <institution> Institut fur angewandte mathematik report, Universitat Karlsruhe. </institution>
Reference: <author> C. Lawson, R. Hanson, D. Kincaid and F. </author> <title> Krogh (1979), `Basic linear algebra subprograms for fortran usage', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 5, </volume> <pages> 308-323. </pages>
Reference-contexts: We see that only matrix multiplication offers us an opportunity to make this ratio large. This table reflects a hierarchy of operations: Operations like saxpy operate on vectors and offer the worst q values; these are called Level 1 BLAS <ref> (Lawson, Hanson, Kincaid and Krogh, 1979) </ref> and include inner products and other simple operations. Operations like matrix-vector multiplication operate on matrices and vectors, and offer slightly better q values; these are called Level 2 BLAS 14 Table 1: Memory references and operation counts for the BLAS.
Reference: <author> S. Lederman, A. Tsao and T. </author> <title> Turnbull (1992), `A parallelizable eigensolver for real diagonalizable matrices with real eigenvalues', </title> <type> Report TR-01-042, </type> <institution> Supercomputing Research Center, Bowie, MD. </institution>
Reference: <author> J.G. Lewis, B.W. Peyton and A. </author> <title> Pothen (1989), `A fast algorithm for reordering sparse matrices for parallel factorization', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 10, </volume> <pages> 1156-1173. </pages>
Reference: <author> G. Li and T. </author> <title> Coleman (1988), `A parallel triangular solver on a distributed memory multiprocessor', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 485-502. </pages>
Reference-contexts: Operation Definition Floating Memory q point references operations saxpy y i = ffx i +y i , i = 1; :::; n 2n 3n+1 2=3 Matrix-vector mult y i = P n Matrix-matrix mult C ij = P n <ref> (Dongarra, Du Croz, Hammarling and Richard Hanson, 1988) </ref>, and include solving triangular systems of equations and rank-1 updates of matrices (A + xy T , x and y column vectors). <p> Other shared memory algorithms based on Givens rotations have also been developed (Chu, 1988a; Gentleman and Kung, 1981; Sameh, 1985), although these do not seem superior on shared memory machines. It is also possible to use Level 2 and 3 BLAS in the modified Gram-Schmidt algorithm <ref> (Gallivan, Jalby, Meier and Sameh,1988) </ref>. 5.2 Distributed memory algorithms Just as we could map Algorithm 13 (Gaussian elimination with Level 3 BLAS) to a distributed memory machine with blocked and/or scattered layout by inserting appropriate communication, this can also be done for QR with Level 3 BLAS. <p> One of the earliest and simplest parallel algorithms for sparse Cholesky factorization is the following version of submatrix-Cholesky <ref> (George, Heath, Liu and Ng, 1988) </ref>. Algorithm 22 runs on each processor, with each responsible for its own subset, mycols, of columns.
Reference: <author> R. </author> <month> Li </month> <year> (1992), </year> <title> `Solving the secular equation stably', </title> <institution> UC Berkeley Math. Dept Report, </institution> <note> in preparation. </note>
Reference-contexts: The second issue to consider when sending messages is the semantic power of the messages <ref> (Wen and Yelick, 1992) </ref>. The most restrictive possibility is that the processor executing `send' and the processor executing `receive' must synchronize, and so block until the transaction is completed. <p> This lets us solve quickly using a Newton-like method (although care must be taken to guarantee convergence <ref> (Li, 1992) </ref>). The corresponding eigenvector for a root j is then simply given by (D j I) 1 z. <p> It turns out it accelerates convergence to do the Cholesky decomposition with pivoting, and then apply Jacobi to the columns of L rather than the columns of L T <ref> (Demmel and Veselic, 1992) </ref>. It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way (Slapnicar, 1992). Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS. <p> The numerical method follows these curves by standard curve-following schemes, predicting the position of a nearby 45 point on the curve using the derivative of the eigenvalue with respect to t, and then correcting its predicted value using Newton's method. Two schemes have been investigated. The first <ref> (Li et al., 1992) </ref> follows eigenvalue/eigenvector pairs.
Reference: <author> T.-Y. Li and Z. </author> <title> Zeng (1992), `Homotopy-determinant algorithm for solving nonsymmetric eigenvalue problems', </title> <journal> Math. Comput. </journal> <note> to appear. </note>
Reference-contexts: The second issue to consider when sending messages is the semantic power of the messages <ref> (Wen and Yelick, 1992) </ref>. The most restrictive possibility is that the processor executing `send' and the processor executing `receive' must synchronize, and so block until the transaction is completed. <p> This lets us solve quickly using a Newton-like method (although care must be taken to guarantee convergence <ref> (Li, 1992) </ref>). The corresponding eigenvector for a root j is then simply given by (D j I) 1 z. <p> It turns out it accelerates convergence to do the Cholesky decomposition with pivoting, and then apply Jacobi to the columns of L rather than the columns of L T <ref> (Demmel and Veselic, 1992) </ref>. It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way (Slapnicar, 1992). Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS. <p> The numerical method follows these curves by standard curve-following schemes, predicting the position of a nearby 45 point on the curve using the derivative of the eigenvalue with respect to t, and then correcting its predicted value using Newton's method. Two schemes have been investigated. The first <ref> (Li et al., 1992) </ref> follows eigenvalue/eigenvector pairs.
Reference: <author> T.-Y. Li, Z. Zeng and L. </author> <title> Cong (1992), `Solving eigenvalue problems of nonsymmetric matrices with real homotopies', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 29(1), </volume> <pages> 229-248. </pages>
Reference-contexts: The second issue to consider when sending messages is the semantic power of the messages <ref> (Wen and Yelick, 1992) </ref>. The most restrictive possibility is that the processor executing `send' and the processor executing `receive' must synchronize, and so block until the transaction is completed. <p> This lets us solve quickly using a Newton-like method (although care must be taken to guarantee convergence <ref> (Li, 1992) </ref>). The corresponding eigenvector for a root j is then simply given by (D j I) 1 z. <p> It turns out it accelerates convergence to do the Cholesky decomposition with pivoting, and then apply Jacobi to the columns of L rather than the columns of L T <ref> (Demmel and Veselic, 1992) </ref>. It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way (Slapnicar, 1992). Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS. <p> The numerical method follows these curves by standard curve-following schemes, predicting the position of a nearby 45 point on the curve using the derivative of the eigenvalue with respect to t, and then correcting its predicted value using Newton's method. Two schemes have been investigated. The first <ref> (Li et al., 1992) </ref> follows eigenvalue/eigenvector pairs.
Reference: <author> T.-Y. Li, H. Zhang and X.-H. </author> <title> Sun (1991), `Parallel homotopy algorithm for symmetric tridiagonal eigenvalue problem', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 12(3), </volume> <pages> 469-487. </pages>
Reference-contexts: Convergence of the intervals can be accelerated by using a zero-finder such as zeroin (Brent, 1973; Lo et al., 1987), Newton's method, Rayleigh quotient iteration (Beattie and Fox, 1989), Laguerre's method, or other methods <ref> (Li, Zhang and Sun, 1991) </ref>. to choose as an approximate zero of d n or p n , i.e. an approximate eigenvalue of T . There is parallellism both within Algorithm 18 and by running Algorithm 17 or 18 simultaneously for many values of .
Reference: <author> C-C. Lin and E. </author> <title> Zmijewski (1991), `A parallel algorithm for computing the eigenvalues of an unsymmetric matrix on an SIMD mesh of processors', </title> <institution> Department of Computer Science TRCS 91-15, University of California, Santa Barbara, </institution> <address> CA. </address>
Reference: <author> J.W.-H. </author> <title> Liu (1986), `Computational models and task scheduling for parallel sparse Cholesky factorization', </title> <journal> Parallel Comput. </journal> <volume> 3, </volume> <pages> 327-342. </pages>
Reference: <author> J.W.-H. </author> <title> Liu (1989), `Reordering sparse matrices for parallel elimination', </title> <journal> Parallel Comput. </journal> <volume> 11, </volume> <pages> 73-91. </pages>
Reference-contexts: The cmod operations involve only a couple of flops each, so that even the `medium-grain' tasks are actually rather small in this case.) by a minimum degree algorithm. Minimum degree is the most effective general purpose heuristic known for limiting fill in sparse factorization <ref> (George and Liu, 1989) </ref>. In its simplest form, this algorithm begins by selecting a node of minimum degree (i.e. one having fewest incident edges) in G (A) and numbering it first. <p> A better approach for sparse factorization is to preserve locality by assigning subtrees of the elimination tree to contiguous subsets of neighbouring processors. A good example of this technique is the `subtree-to-subcube' mapping often used with hypercube multicomputers <ref> (George, Heath, Liu and Ng, 1989) </ref>. Of course, the same idea applies to other network topologies, such as submeshes of a larger mesh. We will assume that some such mapping is used, and we will comment further on its implications later.
Reference: <author> J.W.-H. </author> <title> Liu (1990), `The role of elimination trees in sparse factorization', </title> <journal> SIAM J. Matrix Anal. Appl. </journal> <volume> 11, </volume> <pages> 134-172. </pages>
Reference-contexts: The shortcomings of the fan-out algorithm motivated the formulation of the following fan-in algorithm for sparse factorization, which is a parallel implementation of column-Cholesky <ref> (Ashcraft, Eisenstat and Liu, 1990) </ref>: Algorithm 23 Distributed fan-in sparse Cholesky factorization for j = 1; n if j 2 mycols or mycols " Struct (L jfl ) 6= ; u = 0 for k 2 mycols " Struct (L jfl ) u = u + ` jk fl L flk
Reference: <author> S.-S. Lo, B. Phillipe and A. </author> <title> Sameh (1987), `A multiprocessor algorithm for the symmetric eigenproblem', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 8(2), </volume> <pages> 155-165. </pages> <note> 86 R. </note> <author> Lucas, W. Blank and J. </author> <month> Tieman </month> <year> (1987), </year> <title> `A parallel solution method for large sparse systems of equations', </title> <journal> IEEE Trans. Comput. Aided Des. </journal> <volume> CAD-6, </volume> <pages> 981-991. </pages>
Reference: <author> F. Luk and H. </author> <title> Park (1989), `On parallel Jacobi orderings', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 10(1), </volume> <pages> 18-26. </pages>
Reference: <author> S. C. Ma, M. Patrick and D. </author> <title> Szyld (1989), `A parallel, hybrid algorithm for the generalized eigenproblem', in Parallel Processing for Scientific Computing, (Garry Rodrigue, ed), </title> <journal> SIAM (Philadelphia), </journal> <volume> ch 16, </volume> <pages> 82-86. </pages>
Reference-contexts: Other recent surveys include Dongarra, Duff, Sorensen and van der Vorst (1991) and Gallivan, Heath, Ng, Ortega, Peyton, Plemmons, Romine, Sameh and Voigt (1990), the latter of which includes a bibliography of over 2000 entries. 2 Features of parallel systems 2.1 General principles A large number of different parallel computers <ref> (Gottlieb and Almasi, 1989) </ref>, languages (see Zima and Chapman (1991) and the references therein), and software tools have recently been built or proposed. <p> Examples include machines from Convex, Cray, Fujitsu, Hitachi, 11 NEC, and others <ref> (Gottlieb and Almasi, 1989) </ref>. The memories of these machines are organized into some number, say b, of memory banks, so that memory address m resides in memory bank m mod b. <p> Other ways to count the eigenvalues in intervals have been proposed as well (Krishnakumar and Morf, 1986; Swarztrauber, 1992), although these are more complicated than either Algorithm 17 or 18. There have also been generalizations to the band definite generalized symmetric eigenvalue problem <ref> (Ma, Patrick and Szyld, 1989) </ref>. 6.3.3 Cuppen's divide-and-conquer algorithm The third algorithm is a divide-and-conquer algorithm by Cuppen (Cuppen, 1981), and later analysed and modified by many others (Barlow, 1991; Dongarra 39 and Sorensen, 1987; Gu and Eisenstat, 1992; Ipsen and Jessup, 1990; Jessup and Sorensen, 1989; Sorensen and Tang, 1991).
Reference: <author> N. K. Madsen, G. H. Rodrigue and J. I. </author> <month> Karush </month> <year> (1976), </year> <title> `Matrix multiplication by diagonals on a vector/parallel processor', </title> <journal> Inform. Process. Lett. </journal> <volume> 5, </volume> <pages> 41-45. </pages>
Reference: <author> A. N. </author> <title> Malyshev (1991), `Parallel aspects of some spectral problems in linear algebra', </title> <institution> Dept of Numerical Mathematics Report NM-R9113, Centre for Mathematics and Computer Science, </institution> <address> Amsterdam. </address>
Reference: <author> V. </author> <title> Mehrmann (1991), `Divide and conquer methods for block tridiagonal systems', </title> <type> Technical Report Bericht Nr. 68, </type> <institution> Inst. fuer Geometrie und Prakt. Math., Aachen. </institution>
Reference: <author> U. </author> <title> Meier (1985), `A parallel partition method for solving banded systems of linear equations', </title> <journal> Parallel Comput. </journal> <volume> 2, </volume> <pages> 33-43. </pages>
Reference: <author> J. A. Meijerink and H. A. van der Vorst (1977), </author> <title> `An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix', </title> <journal> Math. Comput. </journal> <volume> 31, </volume> <pages> 148-162. </pages>
Reference: <author> J. A. Meijerink and H. A. van der Vorst (1981), </author> <title> `Guidelines for the usage of incomplete decompositions in solving sets of linear equations as they occur in practical problems', </title> <journal> J. Comput. Phys. </journal> <volume> 44, </volume> <pages> 134-155. </pages>
Reference: <author> G. </author> <title> Meurant (1984a), `The block preconditioned conjugate gradient method on vector computers', </title> <journal> BIT 24, </journal> <pages> 623-633. </pages>
Reference: <author> G. </author> <title> Meurant (1984b), `Numerical experiments for the preconditioned conjugate gradient method on the CRAY X-MP/2', </title> <type> Technical Report LBL-18023, </type> <institution> University of California, Berkeley, </institution> <address> CA. </address>
Reference: <author> P. H. Michielse and H. A. van der Vorst (1988), </author> <title> `Data transport in Wang's partition method', </title> <journal> Parallel Comput. </journal> <volume> 7, </volume> <pages> 87-95. </pages>
Reference-contexts: In Michielse and van der Vorst (1988) it has been shown that this limits the performance of the algorithm, the speedup being bounded by the ratio of computational speed and communication speed. This ratio is often very low <ref> (Michielse and van der Vorst, 1988) </ref>. The other approach is first to eliminate successively the last nonzero elements in the subdiagonal blocks ~ L j;j1 . This can be done with a short recurrence of length n=k 1, after which all fill-in can be eliminated in parallel.
Reference: <author> M. Mu and J.R. </author> <month> Rice </month> <year> (1992), </year> <title> `A grid based subtree-subcube assignment strategy for solving partial differential equations on hypercubes', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 13, </volume> <pages> 826-839. </pages> <month> 87 J.M. </month> <title> Ortega (1988), Introduction to Parallel and Vector Solution of Linear Systems, </title> <publisher> Plenum Press (New York and London). </publisher>
Reference: <author> M.H.C. </author> <title> Paardekooper (1989), `A quadratically convergent parallel Jacobi process for diagonally dominant matrices with distinct eigenvalues', </title> <journal> J. Com-put. Appl. Math. </journal> <volume> 27, </volume> <pages> 3-16. </pages>
Reference: <author> C. C. </author> <title> Paige (1976), `Error analysis of the Lanczos algorithm for tridiagonalizing a symmetric matrix', </title> <journal> J. Inst. Math. Appl. </journal> <volume> 18, </volume> <pages> 341-349. </pages>
Reference: <author> P. Pandey, C. Kenney and A. </author> <title> Laub (1990), `A parallel algorithm for the matrix sign function', </title> <journal> Int. J. High Speed Comput. </journal> <volume> 2(2), </volume> <pages> 181-191. </pages>
Reference: <author> B. N. </author> <title> Parlett (1980), The Symmetric Eigenvalue Problem, </title> <publisher> Prentice-Hall (En-glewood Cliffs, </publisher> <address> NJ). </address>
Reference-contexts: For larger linear systems, they observed speedups close to 2:5. 9 Iterative methods for eigenproblems The oldest iterative scheme for determining a few dominant eigenvalues and corresponding eigenvectors of a matrix A is the power method <ref> (Parlett, 1980) </ref>: Algorithm 28 Power method select x 0 with kx 0 k 2 = 1 k = 0 repeat k = k + 1 = ky k k 2 until x k converges 72 If the eigenvalue of A of maximum modulus is well separated from the oth-ers, then x <p> This can be done by either short recurrences or long recurrences. The short (three-term) recurrence is known as the Lanczos method. When A is symmetric this leads to an algorithm with can efficiently compute many, if not all, eigenvalues and eigenvectors <ref> (Parlett, 1980) </ref>. In fact, the CG method (and Bi-CG) can be viewed as a solution process on top of Lanczos. The long recursion process is known as Arnoldi's method (Arnoldi, 1951), which we have seen already as the underlying orthogonalization procedure for GMRES. <p> standard Lanc-zos method this loss of orthogonality goes hand in hand with the convergence of Ritz values and leads to multiple eigenvalues of T k (see Paige (1976) and Parlett (1980)), and so can be accounted for, for instance, by selective reorthogonaliza-tion, for which the converged Ritz vectors are required <ref> (Parlett, 1980) </ref>.
Reference: <author> B. </author> <title> Parlett (1992), </title> <type> private communication. </type>
Reference-contexts: Interesting linear algebra problems that can be cast in this way include tridiagonal Gaussian elimination, solving bidiag-onal linear systems of equations, Sturm sequence evaluation for the symmetric tridiagonal eigenproblem, and the bidiagonal dqds algorithm for singular values <ref> (Parlett and Fernando, 1992) </ref>; we discuss some of these later. The numerical stability of these procedures remains open, although it is often good in practice (Swarztrauber, 1992). We now turn to the principle of locality. <p> If we simply do inverse iteration without communication, the speedup will be nearly perfect. However, we cannot guarantee orthogonality of eigenvectors of clustered eigenvalues (Ipsen and Jessup, 1990), which currently seems to require reorthogonalization of eigenvectors within clusters (other methods are under investigation <ref> (Parlett, 1992) </ref>). We can certainly reorthogonalize against eigenvec-tors of nearby eigenvalues stored on the same processor without communication, or even against those of neighbouring processors with little communication; this leads to a tradeoff between orthogonality, on the one hand, and communication and load balance, on the other. <p> This method is attractive because finding eigenvalues of a tridiagonal matrix (even nonsymmetric) is much faster than for a Hessenberg matrix (Wilkinson, 1965). The drawback is that reduction to tridiagonal form may require very ill conditioned similarity transformations, and may even break down <ref> (Parlett, 1992) </ref>. Breakdown can be avoided by restarting the process with different initializing vectors, or by accepting a `bulge' in the tridiagonal form. This happens with relatively low probability, but keeps the algorithm from being fully reliable.
Reference: <author> B. </author> <title> Parlett (1992b), `Reduction to tridiagonal form and minimal realizations', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 13(2), </volume> <pages> 567-593. </pages>
Reference: <author> B. Parlett and V. </author> <title> Fernando (1992), `Accurate singular values and differential QD algorithms', </title> <institution> Math. Department PAM-554, University of California, Berkeley, </institution> <address> CA. </address>
Reference-contexts: Interesting linear algebra problems that can be cast in this way include tridiagonal Gaussian elimination, solving bidiag-onal linear systems of equations, Sturm sequence evaluation for the symmetric tridiagonal eigenproblem, and the bidiagonal dqds algorithm for singular values <ref> (Parlett and Fernando, 1992) </ref>; we discuss some of these later. The numerical stability of these procedures remains open, although it is often good in practice (Swarztrauber, 1992). We now turn to the principle of locality. <p> If we simply do inverse iteration without communication, the speedup will be nearly perfect. However, we cannot guarantee orthogonality of eigenvectors of clustered eigenvalues (Ipsen and Jessup, 1990), which currently seems to require reorthogonalization of eigenvectors within clusters (other methods are under investigation <ref> (Parlett, 1992) </ref>). We can certainly reorthogonalize against eigenvec-tors of nearby eigenvalues stored on the same processor without communication, or even against those of neighbouring processors with little communication; this leads to a tradeoff between orthogonality, on the one hand, and communication and load balance, on the other. <p> This method is attractive because finding eigenvalues of a tridiagonal matrix (even nonsymmetric) is much faster than for a Hessenberg matrix (Wilkinson, 1965). The drawback is that reduction to tridiagonal form may require very ill conditioned similarity transformations, and may even break down <ref> (Parlett, 1992) </ref>. Breakdown can be avoided by restarting the process with different initializing vectors, or by accepting a `bulge' in the tridiagonal form. This happens with relatively low probability, but keeps the algorithm from being fully reliable.
Reference: <author> B. N. Parlett and J. K. </author> <title> Reid (1981), `Tracking the progress of the Lanczos algorithm for large symmetric eigenproblems', </title> <journal> IMA J. Numer. Anal. </journal> <volume> 1, </volume> <pages> 135-155. </pages>
Reference: <author> S. G. </author> <title> Petiton (1992), `Parallel subspace method for non-Hermitian eigenprob-lems on the Connection Machine (CM2)', </title> <journal> Appl. Numer. Math. </journal> <volume> 10. </volume>
Reference: <author> C. </author> <title> Pommerell (1992), Solution of large unsymmetric systems of linear equations, </title> <type> PhD thesis, </type> <institution> Swiss Federal Institute of Technology, </institution> <address> Zurich. </address>
Reference: <author> A. Pothen, S. Jha and U. </author> <title> Vemulapati (1987), `Orthogonal factorization on a distributed memory multiprocessor', </title> <booktitle> in Hypercube Multiprocessors 1987, </booktitle> <address> Knoxville, TN, </address> <publisher> SIAM (Philadelphia), </publisher> <pages> 587-598. </pages>
Reference-contexts: So in log 2 p of these steps, the first column has been reduced to a single r fi r triangle, and the algorithm moves on to the next block column. 34 Other Givens based algorithms have been proposed, but seem to require more communication than this one <ref> (Pothen et al., 1987) </ref>. 6 Eigenproblems and the singular value decom position 6.1 General comments The standard serial algorithms for computing the eigendecomposition of a symmetric matrix A, a general matrix B, or the singular value decomposition (SVD) of a general matrix C have the same two-phase structure: apply orthogonal transformations
Reference: <author> D. </author> <title> Priest (1991), `Algorithms for arbitrary precision floating point arithmetic', </title> <booktitle> in Proc. 10th Symp. Computer Arithmetic, </booktitle> <address> Grenoble, </address> <publisher> France, </publisher> <editor> (P. Kornerup and D. Matula, eds), </editor> <publisher> IEEE Computer Society Press (New York), </publisher> <pages> 132-145. </pages>
Reference: <author> G. Radicati di Brozolo and Y. Robert (1989), </author> <title> `Parallel conjugate gradient-like algorithms for solving sparse nonsymmetric linear systems on a vector multiprocessor', </title> <journal> Parallel Comput. </journal> <volume> 11, </volume> <pages> 223-239. </pages>
Reference: <author> Y. Robert (1990), </author> <title> The Impact of Vector and Parallel Architectures on the Gaussian Elimination Algorithm, </title> <publisher> Wiley (New York). </publisher> <address> 88 J. </address> <month> Roberts </month> <year> (1980), </year> <title> `Linear model reduction and solution of the algebraic Riccati equation', </title> <journal> Int. J. Control 32, </journal> <pages> 677-687. </pages>
Reference: <author> C. Romine and J. </author> <title> Ortega (1988), `Parallel solution of triangular systems of equations', </title> <journal> Parallel Comput. </journal> <volume> 6, </volume> <pages> 109-114. </pages>
Reference: <author> E. Rothberg and A. </author> <month> Gupta </month> <year> (1989), </year> <title> `Fast sparse matrix factorization on modern workstations', </title> <type> Technical Report STAN-CS-89-1286, </type> <institution> Stanford University, Stanford, California. </institution>
Reference-contexts: For example, such techniques have been used to attain very high performance for sparse factorization on conventional vector supercomputers (Ashcraft, Grimes, Lewis, Peyton and Simon, 1987) and on RISC workstations <ref> (Rothberg and Gupta, 1989) </ref>. 7.4 Parallelism in sparse factorization We now examine in greater detail the opportunities for parallellism in sparse Cholesky factorization and various algorithms for exploiting it.
Reference: <author> Y. </author> <title> Saad (1980), `Variations on Arnoldi's method for computing eigenelements of large unsymmetric matrices', </title> <journal> Lin. Alg. Appl. </journal> <volume> 34, </volume> <pages> 269-295. </pages>
Reference: <author> Y. </author> <title> Saad (1985a), `Partial eigensolutions of large nonsymmetric matrices', </title> <type> Technical Report, </type> <institution> Dept. of Comp. Science, </institution> <address> New Haven, CN. </address>
Reference: <author> Y. </author> <title> Saad (1985b), `Practical use of polynomial preconditionings for the conjugate gradient method', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 6, </volume> <pages> 865-881. </pages>
Reference-contexts: Still another approach is to use polynomial preconditioning: w = p j (A)r, i.e. K 1 = p j (A), for some suitable jth degree polynomial. This preconditioner can be implemented by forming only matrix-vector products, which, depending on the structure of A, are easier to parallellize <ref> (Saad, 1985b) </ref>. For p j one often selects a Chebychev polynomial, which requires some information on the spectrum of A. Finally we point out the possibility of using the truncated Neumann series for the approximate inverse of A, or parts of L and U .
Reference: <author> Y. </author> <title> Saad (1988), `Krylov subspace methods on supercomputers', </title> <type> Technical report, </type> <institution> RIACS, Moffett Field, </institution> <address> CA. </address>
Reference-contexts: The authors claim success in using this approach without serious stability problems for small values of s. Nevertheless, it seems that s-step CG still has a bad reputation <ref> (Saad, 1988) </ref> because of these problems. However, a similar approach, suggested by Chronopoulos and Kim (1990) for other processes such as GMRES, seems to be more promising. <p> In Algorithm 27, this is done using Level 1 BLAS, which may be quite inefficient. To incorporate Level 2 BLAS we can do either Householder orthogonalization or classical Gram-Schmidt twice (which mitigates classical Gram-Schmidt's potential instability <ref> (Saad, 1988) </ref>). Both approaches significantly increase the computational work and do not remove the synchronization and data-locality problems completely.
Reference: <author> Y. Saad and M. H. </author> <title> Schultz (1985), `Conjugate Gradient-like algorithms for solving nonsymmetric linear systems', </title> <journal> Math. Comput. </journal> <volume> 44, </volume> <pages> 417-424. </pages>
Reference: <author> A. </author> <title> Sameh (1971), `1On Jacobi and Jacobi-like algorithms for a parallel computer', </title> <journal> Math. Comput. </journal> <volume> 25, </volume> <pages> 579-590. </pages>
Reference: <author> A. </author> <title> Sameh (1985), `On some parallel algorithms on a ring of processors', </title> <journal> Comput. Phys. Commun. </journal> <volume> 37, </volume> <pages> 159-166. </pages>
Reference: <author> A. Sameh and R. </author> <title> Brent (1977), `Solving triangular systems on a parallel computer', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 14, </volume> <pages> 1101-1113. </pages>
Reference-contexts: Each parallel step involves multiplying n fi n matrices (which are initially quite sparse, but fill up), and so takes about log 2 n parallel substeps, for a total of log 2 2 n. The error analysis of this algorithm <ref> (Sameh and Brent, 1977) </ref> yields an error bound proportional to (T ) 3 " where (T ) = kT k kT 1 k is the condition number and " is machine precision; this is in contrast to the error bound (T )" for the usual algorithm. <p> As it stands this recurrence is not parallellizable, but by squaring the matrix entries it can be changed into a recurrence of the form (1) in Section 2.2 <ref> (see Kuck and Sameh, 1977) </ref>. The numerical stability of this method is not known, but available analyses are pessimistic (Kuck and Sameh, 1977). Furthermore, QR iterations must be done sequentially, with usually just one eigenvalue converging at a time. <p> As it stands this recurrence is not parallellizable, but by squaring the matrix entries it can be changed into a recurrence of the form (1) in Section 2.2 (see Kuck and Sameh, 1977). The numerical stability of this method is not known, but available analyses are pessimistic <ref> (Kuck and Sameh, 1977) </ref>. Furthermore, QR iterations must be done sequentially, with usually just one eigenvalue converging at a time. If one only wants eigenvalues, this method does not appear to be competitive with the alternatives below.
Reference: <author> J. J. F. M. Schlichting and H. A. van der Vorst (1987), </author> <title> `Solving bidiagonal systems of linear equations on the CDC CYBER 205', </title> <type> Technical Report NM-R8725, </type> <institution> CWI, </institution> <address> Amsterdam, the Netherlands. </address>
Reference: <author> J. J. F. M. Schlichting and H. A. van der Vorst (1989), </author> <title> `Solving 3D block bidiagonal linear systems on vector computers', </title> <journal> J. Comput. Appl. Math. </journal> <volume> 27, </volume> <pages> 323-330. </pages>
Reference: <author> R. Schreiber and C. Van Loan (1989), </author> <title> `A storage efficient WY representation for products of Householder transformations', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 10, </volume> <pages> 53-57. </pages>
Reference-contexts: To convert to Level 3 BLAS requires the observation that one can write Q b Q b1 Q 1 = I U T U T where U = [u 1 ; :::; u b ] is m fi b, and T is b fi b and triangular <ref> (Schreiber and Van Loan, 1989) </ref>; for historical reasons this is called a compact WY transformation.
Reference: <author> M. K. </author> <title> Seager (1986), `Parallelizing conjugate gradient for the CRAY X-MP', </title> <journal> Parallel Comput. </journal> <volume> 3, </volume> <pages> 35-47. 89 G. </pages> <month> Shroff </month> <year> (1991), </year> <title> `A parallel algorithm for the eigenvalues and eigenvectors of a general complex matrix', </title> <journal> Numer. Math. </journal> <volume> 58, </volume> <pages> 779-805. </pages>
Reference-contexts: Moreover, the ratio of computation to communication may be more unfavourable. 3. Forced parallellism. Parallelism can also be forced by simply neglecting couplings to unknowns residing in other processors. This is like block Jacobi preconditioning, in which the blocks may be decomposed in incomplete form <ref> (Seager, 1986) </ref>. Again, this may not always reduce the overall solution time, since the effects of increased parallellism are more than undone by an increased number of iteration steps.
Reference: <author> G. Shroff and R. </author> <title> Schreiber (1989), `On the convergence of the cyclic Jacobi method for parallel block orderings', </title> <journal> SIAM J. Matt. Anal. Appl. </journal> <volume> 10, </volume> <pages> 326-346. </pages>
Reference: <author> H. </author> <title> Simon (1989), `Bisection is not optimal on vector processors', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 10(1), </volume> <pages> 205-209. </pages>
Reference-contexts: This requires good support for parallel prefix operations, and is not as easy to parallellize as simply having each processor refine different sets of intervals containing different eigenvalues (Demmel, 1992a). Within a single processor one can also run Algorithm 17 or 18 for many different by pipelining or vectorizing <ref> (Simon, 1989) </ref>. These many could come from disjoint intervals or from dividing a single interval into more than two small ones (multi-section); the latter approach appears to be efficient only when a few eigenvalues are desired, so that there are not many disjoint intervals over which to parallellize (Simon, 1989). <p> or vectorizing <ref> (Simon, 1989) </ref>. These many could come from disjoint intervals or from dividing a single interval into more than two small ones (multi-section); the latter approach appears to be efficient only when a few eigenvalues are desired, so that there are not many disjoint intervals over which to parallellize (Simon, 1989). Achieving good speedup requires load balancing, and this is not always possible to do by statically assigning work to processors.
Reference: <author> I. </author> <month> Slapnicar </month> <year> (1992), </year> <title> Accurate symmetric eigenreduction by a Jacobi method, </title> <type> PhD thesis, </type> <institution> Fernuniversitat - Hagen, Hagen, Germany. </institution>
Reference-contexts: It is possible to use the symmetric-indefinite decomposition of an indefinite symmetric matrix in the same way <ref> (Slapnicar, 1992) </ref>. Jacobi done in this style is a fine-grain algorithm, operating on pairs of columns, and so cannot exploit higher level BLAS.
Reference: <author> B. T. Smith, J. M. Boyle, J. J. Dongarra, B. S. Garbow, Y. Ikebe, V. C. Klema and C. B. </author> <title> Moler (1976), Matrix Eigensystem Routines - EISPACK Guide: </title> <booktitle> Springer Lecture Notes in Computer Science 6, </booktitle> <publisher> Springer-Verlag (Berlin). </publisher>
Reference: <author> D. </author> <title> Sorensen (1992), `Implicit application of polynomial filters in a k-step Arnoldi method', </title> <journal> SIAM J. Math. Anal. Appl. </journal> <volume> 13(1), </volume> <pages> 357-385. </pages>
Reference: <author> D. Sorensen and P. </author> <title> Tang (1991), `On the orthogonality of eigenvectors computed by divide-and-conquer techniques', </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 28(6), </volume> <pages> 1752-1775. </pages>
Reference: <author> G. W. </author> <title> Stewart (1985), `A Jacobi-like algorithm for computing the Schur decomposition of a non-Hermitian matrix', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 6, </volume> <pages> 853-864. </pages>
Reference: <author> G. W. </author> <title> Stewart (1987), `A parallel implementation of the QR algorithm', </title> <journal> Parallel Comput. </journal> <volume> 5, </volume> <pages> 187-196. </pages>
Reference: <author> E. </author> <title> Stickel (1991), `Separating eigenvalues using the matrix sign function', </title> <journal> Lin. Alg. Appl. </journal> <volume> 148, </volume> <pages> 75-88. </pages>
Reference: <author> H. S. </author> <title> Stone (1973), `An efficient parallel algorithm for the solution of a tridiag-onal linear system of equations', </title> <journal> J. Assoc. Comput. Mach. </journal> <volume> 20, </volume> <pages> 27-38. </pages>
Reference-contexts: Thus, the original system splits in two independent lower bidiagonal systems of half the size, one for the odd-numbered unknowns, and one for the even-numbered unknowns. This process can be repeated recursively for both new systems, leading to an algorithm known as recursive doubling <ref> (Stone, 1973) </ref>. In Algorithm 2 (Section 2.2) it was presented as a special case of parallel prefix. It has been analysed and generalized for banded systems in Dubois and Rodrigue (1977).
Reference: <author> P. </author> <title> Swarztrauber (1992), `A parallel algorithm for computing the eigenvalues of a symmetric tridiagonal matrix', Math. Comput. to appear. Thinking Machines Corporation (1987), Connection Machine Model CM-2 Technical Summary, IBM. </title>
Reference-contexts: The numerical stability of these procedures remains open, although it is often good in practice <ref> (Swarztrauber, 1992) </ref>. We now turn to the principle of locality. <p> The numerical stability of the serial implementations of Algorithms 17 (Kahan, 1968) and 18 (Wilkinson, 1965) is very good, but that of the parallel prefix algorithm is unknown, although numerical experiments are promising <ref> (Swarztrauber, 1992) </ref>. This requires good support for parallel prefix operations, and is not as easy to parallellize as simply having each processor refine different sets of intervals containing different eigenvalues (Demmel, 1992a).
Reference: <author> R. van de Geijn (1987), </author> <title> Implementing the QR algorithm on an array of processors, </title> <type> PhD thesis, </type> <institution> University of Maryland, College Park, Computer Science Department Report TR-1897. </institution> <note> 90 R. </note> <author> van de Geijn and D. </author> <title> Hudson (1989), `Efficient parallel implementation of the nonsymmetric QR algorithm', in Hypercube Concurrent Computers and Applications, </title> <editor> (J. Gustafson, ed), </editor> <publisher> ACM (New York). </publisher>
Reference-contexts: Therefore, we must use `out-of-date' shifts to have enough available to start multiple bulge chases. This destroys the usual local quadratic convergence, but it remains superlinear <ref> (van de Geijn, 1987) </ref>. It has been suggested that choosing the eigenvalues of the bottom right k fi k submatrix may have superior convergence to just choosing a sequence from the bottom 1fi1 or 2fi2 submatrices (Watkins, 1992).
Reference: <author> E. Van de Velde (1992), </author> <title> Introduction to Concurrent Scientific Computing, </title> <address> Cal-tech (Pasadena). </address>
Reference-contexts: A different approach is to write algorithms that work independently of the location of the data, and rely on the underlying language or run-time system to optimize the necessary communications. This makes code easier to write, but puts a large burden on compiler and run-time system writers <ref> (Van de Velde, 1992) </ref>. 4 Systems of linear equations We discuss both dense and band matrices, on shared and distributed memory machines.
Reference: <author> H. A. van der Vorst (1982), </author> <title> `A vectorizable variant of some ICCG methods', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 3, </volume> <pages> 86-92. </pages>
Reference: <author> H. A. van der Vorst (1986), </author> <title> `The performance of Fortran implementations for preconditioned conjugate gradients on vector computers', </title> <journal> Parallel Comput. </journal> <volume> 3, </volume> <pages> 49-58. </pages>
Reference: <author> H. A. van der Vorst (1987a), </author> <title> `Analysis of a parallel solution method for tridi-agonal linear systems', </title> <journal> Parallel Comput. </journal> <volume> 5, </volume> <pages> 303-311. </pages>
Reference: <author> H. A. van der Vorst (1987b), </author> <title> `Large tridiagonal and block tridiagonal linear systems on vector and parallel computers', </title> <journal> Parallel Comput. </journal> <volume> 5, </volume> <pages> 45-54. </pages>
Reference: <author> H. A. van der Vorst (1989a), </author> <title> `High performance preconditioning', </title> <journal> SIAM J. Sci. Statist. Comput. </journal> <volume> 10, </volume> <pages> 1174-1185. </pages>
Reference: <author> H. A. van der Vorst (1989b), </author> <title> `ICCG and related methods for 3D problems on vector computers', </title> <journal> Comput. Phys. Commun. </journal> <volume> 53, </volume> <pages> 223-235. </pages>
Reference: <author> H. A. van der Vorst (1989c), </author> <title> `Practical aspects of parallel scientific computing', Future Gener. </title> <journal> Comput. Sys. </journal> <volume> 4, </volume> <pages> 285-291. </pages>
Reference-contexts: For the recurrence we need some data communication between processors. However, for k large enough with respect to n=k, one can attain speedups close to 2k=5 for this algorithm on a k processor system <ref> (van der Vorst, 1989c) </ref>. For a generalization of the divide-and-conquer approach for banded systems, see Meier (1985); the data transport aspects for distributed memory machines have been discussed in Michielse and van der Vorst (1988).
Reference: <author> H. A. van der Vorst and K. </author> <title> Dekker (1989), `Vectorization of linear recurrence relations', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 10, </volume> <pages> 27-35. </pages>
Reference-contexts: In this section we concentrate on factoring 24 P A = LU , which has the dominant number of floating point operations, 2n 3 =3+ O (n 2 ). Pivoting is required for numerical stability, and we use the standard partial pivoting scheme <ref> (Golub and Van Loan, 1989) </ref>; this means L has unit diagonal and other entries bounded in magnitude by one. <p> For simplicity we consider only QR without pivoting, and mention work incorporating pivoting at the end. The conventional approach is to premultiply A by a sequence of simple orthogonal matrices Q i chosen to introduce zeros below the diagonal of A <ref> (Golub and Van Loan, 1989) </ref>. Eventually A becomes upper triangular, and equal to R, and the product Q N Q 1 = Q. <p> changed rows of one column of A; a Household reflection may be written I 2uu T , where u is a unit vector with nonzeros only in the rows to be changed. 5.1 Shared memory algorithms The basic algorithm to compute a QR decomposition using Householder transformations is given in <ref> (Golub and Van Loan, 1989) </ref>: Algorithm 13 QR decomposition using Level 2 BLAS for k = 1 : n 1 Compute a unit vector u k so that (I 2u k u T k )A (k + 1 : m; k) = 0 Update A = A 2 fl u k <p> To convert to Level 3 BLAS requires the observation that one can write Q b Q b1 Q 1 = I U T U T where U = [u 1 ; :::; u b ] is m fi b, and T is b fi b and triangular <ref> (Schreiber and Van Loan, 1989) </ref>; for historical reasons this is called a compact WY transformation. <p> If T has diagonal entries a 1 ; :::; a n and offdiag-onals b 1 ; :::; b n1 , then we can count the number of eigenvalues of T less than <ref> (Golub and Van Loan, 1989) </ref>. <p> The current level of parallel software support on many machines can make this difficult to implement well. 6.4 Jacobi's method for the symmetric eigenproblem and SVD Jacobi's method has been used for the nonsymmetric eigenproblem, the symmetric eigenproblem, the SVD, and generalizations of these problems to pairs of matrices <ref> (Golub and Van Loan, 1989) </ref>. It works by applying a series of Ja-cobi rotations (a special kind of Givens rotation) to the left and/or right of the matrix in order to drive it to a desired canonical form, such as the diagonal form for the symmetric eigenproblem. <p> Since we do not require A to be symmetric, we need long recurrences: each new vector must be explicitly orthogonalized against all previously generated basis vectors. In its most common form GMRES orthogonalizes using Modified Gram-Schmidt <ref> (Golub and Van Loan, 1989) </ref>. In order to limit memory requirements (since all basis vectors must be stored), GMRES is restarted after each cycle of m iteration steps; this is called GMRES (m).
Reference: <author> H. A. van der Vorst and C. </author> <title> Vuik (1991), `GMRESR: A family of nested GMRES methods', </title> <type> Technical Report 91-80, </type> <institution> Delft University of Technology, Faculty of Technical Mathematics. </institution>
Reference-contexts: Hessenberg reduction is sgehrd, and bidiagonal reduction is sgebrd. The mapping to a distributed memory machine follows as with previous algorithms like QR and Gaussian elimination <ref> (Dongarra and van de Geijn, 1991) </ref>. 36 For parallel reduction of a band symmetric matrix to tridiagonal form, see Bischof and Sun (1992) and Lang (1992).
Reference: <author> K. </author> <title> Veselic (1979), `A quadratically convergent Jacobi-like method for real matrices with complex conjugate eigenvalues', </title> <journal> Numer. Math. </journal> <volume> 33, </volume> <pages> 425-435. </pages>
Reference: <author> H. F. </author> <title> Walker (1988), `Implementation of the GMRES method using Householder transformations', </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9, </volume> <pages> 152-163. </pages>
Reference-contexts: Upward circular shift each column of B by 1, so B (i;j) is assigned B ((i+1)modN;j) . of this algorithm suitable for machines that are efficient at spreading subblocks across rows (or down columns) is to do this instead of the preshifting and rotation of A (or B) <ref> (Fox, Johnson, Lyzenga, Otto, Salmon and Walker, 1988) </ref>. This algorithm is easily adapted to a hypercube.
Reference: <author> H. H. </author> <title> Wang (1981), `A parallel method for tridiagonal equations', </title> <journal> ACM Trans. Math. Soft. </journal> <volume> 7, </volume> <pages> 170-183. </pages>
Reference-contexts: In the original approach <ref> (Wang, 1981) </ref>, the fill-in in the subdiagonal blocks is eliminated in parallel, or vector mode, for each subdiagonal block (note that each subdiagonal block has only one column with nonzero elements).
Reference: <author> D. </author> <title> Watkins (1992), `Shifting strategies for the parallel QR algorithm', </title> <institution> Dept of Pure and Applied Mathematics report, Washington State Univ., </institution> <address> Pullman, WA. </address>
Reference-contexts: This destroys the usual local quadratic convergence, but it remains superlinear (van de Geijn, 1987). It has been suggested that choosing the eigenvalues of the bottom right k fi k submatrix may have superior convergence to just choosing a sequence from the bottom 1fi1 or 2fi2 submatrices <ref> (Watkins, 1992) </ref>.
Reference: <author> D. Watkins and L. </author> <title> Elsner (1991), `Convergence of algorithms of decomposition type for the eigenvalue problem', </title> <journal> Lin. Alg. Appl. </journal> <volume> 143, </volume> <pages> 19-47. </pages>
Reference-contexts: Asymptotic convergence remains quadratic <ref> (Watkins and Elsner, 1991) </ref>. The drawbacks to this scheme are twofold. First, any attempt to use Level 3 BLAS introduces rather small (hence inefficient) matrix-matrix operations, and raises the operation count considerably. Second, the convergence properties degrade significantly, resulting in more overall work as well (Dubrulle, 1991).
Reference: <author> C.-P. Wen and K. </author> <title> Yelick (1992), `A survey of message passing systems', </title> <institution> Computer science division, University of California, Berkeley, </institution> <address> CA. </address>
Reference-contexts: The second issue to consider when sending messages is the semantic power of the messages <ref> (Wen and Yelick, 1992) </ref>. The most restrictive possibility is that the processor executing `send' and the processor executing `receive' must synchronize, and so block until the transaction is completed.
Reference: <author> J. H. </author> <title> Wilkinson (1965), The Algebraic Eigenvalue Problem, </title> <publisher> Oxford University Press (Oxford). </publisher>
Reference-contexts: The first kind of parallellism uses parallel prefix as described in (1) in Section 2.2, and so care needs to be taken to avoid over/underflow. The numerical stability of the serial implementations of Algorithms 17 (Kahan, 1968) and 18 <ref> (Wilkinson, 1965) </ref> is very good, but that of the parallel prefix algorithm is unknown, although numerical experiments are promising (Swarztrauber, 1992). <p> This method is attractive because finding eigenvalues of a tridiagonal matrix (even nonsymmetric) is much faster than for a Hessenberg matrix <ref> (Wilkinson, 1965) </ref>. The drawback is that reduction to tridiagonal form may require very ill conditioned similarity transformations, and may even break down (Parlett, 1992). Breakdown can be avoided by restarting the process with different initializing vectors, or by accepting a `bulge' in the tridiagonal form.
Reference: <author> Z. </author> <title> Zeng (1991), Homotopy-determinant algorithm for solving matrix eigenvalue problems and its parallelizations, </title> <type> PhD thesis, </type> <institution> Michigan State University. </institution>
Reference: <author> H. Zima and B. </author> <title> Chapman (1991), Supercompilers for Parallel and Vectors Computers, </title> <publisher> ACM (New York). </publisher>
Reference: <author> E. </author> <title> Zmijewski (1989), `Limiting communication in parallel sparse Cholesky factorization', </title> <type> Technical Report TRCS89-18, </type> <institution> Department of Computer Science, University of California, Santa Barbara, </institution> <address> CA. </address> <month> 92 </month>
References-found: 200

