URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/landay/pub/www/research/publications/proximate.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/landay/pub/www/research/publications/publications.html
Root-URL: 
Email: pier@parc.xerox.com  landay@cs.cmu.edu  
Phone: (415) 812-4861  (412) 268-3564  
Title: ISSUES FOR PROXIMATE USER INTERFACES  
Author: Ken Pier James A. Landay 
Keyword: User Interface, Interaction Techniques, Stylus, Pen, Toolkits.  
Address: 3333 Coyote Hill Rd. Palo Alto, CA 94304  5000 Forbes Avenue Pittsburgh, PA 15213, USA  
Affiliation: Information Sciences and Technology Laboratory Xerox PARC  School of Computer Science Carnegie Mellon University  
Abstract: In the future world of ubiquitous computing, interactive devices ranging in size from pocket to wall will be strewn about the users environment. Display and digitizer surfaces will be merged so that users appear to interact directly on display surfaces using an electronic pen or touchscreen. Within some size range of these devices, and for some tasks, traditional widget style interfaces may suffice. However, for devices at the extremes of the size range, such as the Xerox Liveboard, widget style interfaces break down. When interacting directly on a very large display surface, static interface widgets will be so situated as to be useless, out of reach on the opposite side of the board, near the ceiling, or near the floor. In this paper, we discuss issues and solutions to this problem and present a prototype example of a proximate user interface. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <institution> Adobe Systems Inc. </institution> <note> Adobe Illustrator (TM) User's Manual Version 1.0, </note> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [1, 15, 21] </ref> are highly dependent on buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface.
Reference: 2. <author> Borenstein, N. </author> <title> Multimedia electronic mail: </title> <booktitle> will the dream become a reality? In Communications of the ACM 34, </booktitle> <volume> 4. </volume> <month> (April, </month> <year> 1991), </year> <pages> pp. 117-119. </pages>
Reference-contexts: Such "multimedia" mail messages are becoming more common in the Internet community <ref> [2] </ref>. Shneiderman [26] has demonstrated that a competent typist can achieve up to 25 words per minute typing speed on a pop-up touchscreen keyboard. The pop-up keyboard consists of a picture of a conventional QWERTY keyboard upon which the user pecks out characters with the stylus.
Reference: 3. <author> Buxton, W. and Myers, B. </author> <title> A Study in Two-Handed Input. </title> <booktitle> In Proceedings of the CHI '86 Conference on Human Factors in Computing Systems. </booktitle> <address> (Boston, MA. </address> <month> Apr. </month> <pages> 13-17, </pages> <address> 1986). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1986, </year> <pages> pp. 321-326. </pages>
Reference-contexts: Buxton <ref> [3] </ref> has long advocated the use of two-handed interfaces. Mouse, keyboard, and trackball are an example of a multi-handed input suite that works on conventional workstations. In the case of the Liveboard, we can use ParcTab buttons (viz.
Reference: 4. <author> Callahan, J., Hopkins, D., Weiser, M., and Shneiderman, B. </author> <title> An Empirical Comparison of Pie vs. Linear Menus. </title> <booktitle> In Proceedings of the CHI '88 Conference on Human Factors in Computing Systems. </booktitle> <address> (Washington, DC. </address> <month> May. </month> <pages> 15-19, </pages> <address> 1988). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1988, </year> <pages> pp. 95-100. </pages>
Reference-contexts: Use of voice requires only that the input generated by the vocal tract be received by a microphone, recognized in real time, and that recognition results be quickly transmitted to the computing device at hand. Examples of proximate interface elements for the stylus include pie menus <ref> [4] </ref>, hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. <p> The user could then invoke an operation from that menu by releasing the mouse button over the desired function icon. The menu subsequently disappeared. 2.1.3 Pie Menus at the University of Maryland In 1986, Don Hopkins <ref> [4] </ref> produced a pie menu interface element for the X10 window system. Implementations for Sunview and NeWS window systems were produced in subsequent years. Figure 2 illustrates a pie menu.
Reference: 5. <author> Carr, R. and Shafer, D. </author> <title> The Power of PenPoint. </title> <publisher> Addison Wesley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than the interface elements in use today. Existing stylus-based interfaces <ref> [5, 16, 19] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length. <p> For example, if we display a Macintosh screen on an existing Liveboard, its pull-down menus will be above the reach of many, and above the reach of all on a 2X Liveboard. If we run the GO Corp. stylus-based Notebook User Interface <ref> [5] </ref> on a 2X Liveboard, the screen image will scale up, thanks to ImagePoint resolution-independent imaging, but the BookShelf, a fixed palette of icons at the bottom of the screen, will be below our knees, and the pull-down menu bar above our reach. <p> Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads <ref> [5] </ref>, and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. <p> Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces <ref> [5, 12, 23] </ref>. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard. <p> The systems produced by GO, Microsoft, and Momenta are discussed below. 2.2.1 GO The stylus-based Notebook User Interface by the GO Corp. <ref> [5] </ref> is nearly entirely gesture based. There are about a dozen basic gestures for navigating through and displaying documents (i.e., applications), and many more gestures available for documentspecific editing of such elements as graphics and text. <p> Proximate user interfaces must be flexible and able to respond to the variety of work surfaces available. The interface elements that we have identified as proximate are flexible enough to work well on a variety of work surfaces. 3.3 Ease of Discovery and Use Emphasis on paper-like interfaces <ref> [5, 22] </ref> for individual use and on "walk up and use" interfaces for collaboration (in the Xerox Liveboard community) raise fundamental questions concerning ease of discovery and use.
Reference: 6. <editor> Elrod, S., et. al. Liveboard. </editor> <booktitle> In Proceedings of the CHI '92 Conference on Human Factors in Computing Systems. </booktitle> <address> (Monterey, CA. </address> <month> May. </month> <pages> 3-7, </pages> <address> 1992). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> pp. 599-607. </pages>
Reference-contexts: Within some size range of these devices, and for some tasks, traditional "widget" style interfaces may suffice. However, for outsize devices, devices at the extremes of the size range, such as the Xerox ParcTab in Photo 1 and the Xerox Liveboard <ref> [6] </ref> in Photo 2, widget style interfaces break down. The elements of interfaces required for outsize devices are different than the interface elements in use today. <p> In fact, the Xerox Liveboard <ref> [6] </ref> stylus has three rather awkward buttons on the stylus itself, intended to emulate the three-button mouse attached to conventional workstations. Although providing this mouse mimicry allows existing software to run unchanged, it is a poor substitute for a true stylus-based interface and in fact hinders development of new interfaces. <p> incorporating from zero to two buttons on the stylus (in addition to a switch on the tip of the stylus): the prototype notebook from the GO Corp. (0), the Momenta Corp. stylus (1), the Xerox Liveboard stylus 2 (2) Stylus buttons have empirically been observed to be awkward to use <ref> [6] </ref>. In particular, a stylus has very little surface area near the fingertips not covered by the user's grip, so buttons tend to be placed close together on the "top" or "side" of the stylus case.
Reference: 7. <author> Goldberg, D. </author> <title> Touch Typing With a Stylus. </title> <note> To appear in Proeedings of INTERCHI '93. </note>
Reference-contexts: Other arrangements of characters on pop-up keyboards would be possible, and users could tailor such arrangements to their individual preferences. David Goldberg, at Xerox PARC, has devised a clever alphabet called Unistrokes for what he calls "touch typing with a stylus" <ref> [7] </ref>. He eliminates the need for hard or soft keyboards, substituting what he claims is an easy-to-learn shorthand alphabet using simple, single stroke characters.
Reference: 8. <author> Heller, D. </author> <title> XView Programming Manual. </title> <publisher> O'Reilly Associates, Inc. </publisher> <year> 1990. </year>
Reference-contexts: Unistrokes, like touch typing, can be very fast, once learned, and also allows eyes-free "heads up" writing, since all of the strokes can be written on top of each other; recognized characters appear immediately in text being created or edited. 3.5 Toolkits and User Interface Builders Existing toolkits <ref> [8, 14] </ref> and user interface builders [27] do not readily extend to the proximate user interface paradigm. They are targeted at arranging a set of interactors that are constantly visible in fixed places on a display.
Reference: 9. <author> Hopkins, Don. </author> <title> The design and implementation of pie menus. </title> <journal> Dr. Dobb's Journal. </journal> <volume> Vol. 16, No. 12, </volume> <month> (Dec </month> <year> 1991), </year> <pages> pp. 16-26. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus <ref> [9] </ref>, pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. <p> Another difficulty is the interpretation of the meaning of "held still." Is a motion of a single pixel really meant as a motion? What about two pixels? Three? A millimeter? Lack of a rock-steady hand should not bar the user from interacting. Hopkins <ref> [9] </ref> and Kurtenbach [12] report the use of temporal modes as accelerators for pie menus.
Reference: 10. <institution> HSD Microcomputer Inc. </institution> <note> SimonSays User's Manual, Version 1.1, </note> <institution> Mountain View, </institution> <address> CA. </address>
Reference-contexts: Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders <ref> [10] </ref>. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard. <p> Most efforts at speech recognition in real time have produced limited results until recently. It is now possible to do real time, speaker dependent, isolated word, small vocabulary recognition with sufficiently high hit rates, in software, to be useful in user interfaces. Systems such as SimonSays <ref> [10] </ref> provide an interactive user interface builder for voice commands to window applications. SimonSays builds a macro-like event sequence by capturing standard user input to an application, and allows the user to assign a word or short phrase to name the macro.
Reference: 11. <author> Johnson, Jeff, et. al. </author> <title> The Xerox Star: A Retrospective. </title> <journal> In IEEE Computer, </journal> <volume> Vol. 22, No. 9, </volume> <month> (Sep </month> <year> 1989), </year> <pages> pp. 11-29. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets <ref> [11] </ref>, pop-up handwriting recognition pads [5], and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10].
Reference: 12. <author> Kurtenbach, G., and Buxton, W. </author> <title> Issues in Combining Marking and Direct Manipulation Techniques. </title> <booktitle> In Proceedings of UIST'91, the Fourth Annual Symposium on User Interface Software and Technology (Hilton Head, </booktitle> <address> SC. </address> <month> Nov. </month> <pages> 11-13). </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1991, </year> <pages> pp. 137-144. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces <ref> [5, 12, 23] </ref>. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard. <p> It is therefore impossible to draw over a button or to have a button in the midst of the drawing surface. This is the manner in which conventional drawing programs are organized. Interference does not occur in programs such as GEdit <ref> [12] </ref>, which uses a combination of gestures and pie menus for interaction, because the stylus input is always aimed at the interface and does not interfere with the synthetic graphical objects that GEdit creates and modifies. <p> Another difficulty is the interpretation of the meaning of "held still." Is a motion of a single pixel really meant as a motion? What about two pixels? Three? A millimeter? Lack of a rock-steady hand should not bar the user from interacting. Hopkins [9] and Kurtenbach <ref> [12] </ref> report the use of temporal modes as accelerators for pie menus.
Reference: 13. <author> Landay, James A., and Myers, Brad A. </author> <title> Extending an Existing User Interface Toolkit to Support Gesture Recognition. </title> <booktitle> In Adjunct Proceedings of INTERCHI (Amsterdam, </booktitle> <address> Netherlands. April 24-29). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Our pie menus use much of the same interaction code as do other Garnet menus (e.g., pull-down menu bars). Most other toolkits we examined would have required us to write all of this interaction code ourselves. In addition, the existing gesture inter-actor <ref> [13] </ref> in Garnet made doing gesture recognition in our application quite easy. The application that we examined for scaling problems was GarnetDraw, a simple synthetic-graphics drawing program, shown in Figure 3. This application is typical of many conventional drawing applications found on X11, the Macintosh, and Microsoft Windows.
Reference: 14. <author> Linton, M.A., Vlissides, J.M., and Calder, P.R. </author> <title> Composing user interfaces with InterViews. </title> <journal> In I E E E Computer, </journal> <volume> Vol. 22, No. 2, </volume> <month> (Feb </month> <year> 1989), </year> <pages> pp. 8-22. </pages>
Reference-contexts: Unistrokes, like touch typing, can be very fast, once learned, and also allows eyes-free "heads up" writing, since all of the strokes can be written on top of each other; recognized characters appear immediately in text being created or edited. 3.5 Toolkits and User Interface Builders Existing toolkits <ref> [8, 14] </ref> and user interface builders [27] do not readily extend to the proximate user interface paradigm. They are targeted at arranging a set of interactors that are constantly visible in fixed places on a display.
Reference: 15. <author> Lubow, M. </author> <title> Working out with AutoCAD. </title> <publisher> New Riders Publishing, </publisher> <address> P.O. Box 4846, Thousand Oaks, CA 91360 U.S.A., </address> <year> 1987. </year>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [1, 15, 21] </ref> are highly dependent on buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface.
Reference: 16. <institution> Momenta Corp. </institution> <note> Momenta User's Manual Version 1.0, </note> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than the interface elements in use today. Existing stylus-based interfaces <ref> [5, 16, 19] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length. <p> Microsoft makes no claims for scalability of Windows to larger or smaller display surfaces. 2.2.3 Momenta (R.I.P. 1988-1992) In the stylus-based interface for the notebook computer by the Momenta Corp. <ref> [16] </ref>, a pie menu called the Command Compass is the main interactor for Momenta applications. There is partial proximation in this interface since selecting an object, like a graphic or text, causes an icon for the applicationspecific command compass to appear on or near the selected object.
Reference: 17. <author> Myers, Brad A., et al. Garnet: </author> <title> Comprehensive Support for Graphical, Highly-Interactive User Interfaces. </title> <journal> In IEEE Computer, </journal> <volume> Vol. 23, No. 11, </volume> <month> (Nov </month> <year> 1990), </year> <pages> pp. 71-85. </pages>
Reference-contexts: The Proximate toolkit is a collection of interface elements written in Common Lisp and added to the Garnet User Interface Development Environment within the X11 Window System <ref> [17, 24] </ref>. The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques.
Reference: 18. <author> Myers, Brad A. </author> <title> A New Model for Handling Input. </title> <journal> In ACM Transactions on Information Systems, </journal> <volume> Vol. 8, No. 3, </volume> <month> (Jul </month> <year> 1990), </year> <pages> pp. 289-320. </pages>
Reference-contexts: The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques. In addition, the Garnet in-teractor abstraction <ref> [18] </ref>, which separates interaction mechanisms from graphics presentation, is ideal for creating an implementation of pie menus. Our pie menus use much of the same interaction code as do other Garnet menus (e.g., pull-down menu bars).
Reference: 19. <institution> NCR Corp. Microsoft Windows For Pen Computing: </institution> <note> Guide to Pen Computing, </note> <year> 1992. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than the interface elements in use today. Existing stylus-based interfaces <ref> [5, 16, 19] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length.
Reference: 20. <author> Newman, W. </author> <title> Markup. In the Alto User's Handbook, </title> <institution> Xerox Palo Alto Research Center, </institution> <address> 3333 Coyote Hill Rd., Palo Alto, CA 94304, </address> <year> 1979. </year>
Reference-contexts: menus and pie menus described below. 2.1.1 Movable Menu Proximate user interfaces date back to 1969, when Wiseman [31] first proposed the idea of a "movable menu" displayed close to the cursor and appearing only when the user needs it. 2.1.2 Markup at Xerox PARC In 1976, in the Markup <ref> [20] </ref> graphical editing program on the Xerox Alto [28], a mouse button was reserved to pop up a single large icon-based menu, part of which is shown in Figure 1, centered around the display cursor.
Reference: 21. <author> Pier, K.A., Bier, E.A., and Stone, </author> <title> M.C. An Introduction to Gargoyle: an Interactive Illustration Tool. </title> <booktitle> In Proceedings of EP88, the International Conference on Electronic Publishing, Document Manipulation and Typography (Nice, </booktitle> <address> France. </address> <month> Apr. </month> <pages> 20-22). </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988, </year> <pages> pp. 223-238. </pages> <note> Also available in Xerox PARC Technical Report EDL-89-1, </note> <year> 1989. </year>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [1, 15, 21] </ref> are highly dependent on buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface. <p> The pie menu will pop up if a sufficiently long period elapses without stylus motion. A similar form of temporal accelerator appears in the Cedar system pop-up buttons <ref> [21] </ref>, in which a static button can be quickly clicked on using a combination of mouse buttons and keyboard modifiers to invoke an operation, instead of pressing down and waiting for the pop-up button to appear with menu choices and documentation.
Reference: 22. <author> Rhyne, J.R., and Wolf, </author> <title> C.G. Paperlike User Interfaces. </title> <institution> IBM T. J. Watson Research Center, </institution> <address> Yorktown Heights, New York, </address> <year> 1991. </year>
Reference-contexts: Proximate user interfaces must be flexible and able to respond to the variety of work surfaces available. The interface elements that we have identified as proximate are flexible enough to work well on a variety of work surfaces. 3.3 Ease of Discovery and Use Emphasis on paper-like interfaces <ref> [5, 22] </ref> for individual use and on "walk up and use" interfaces for collaboration (in the Xerox Liveboard community) raise fundamental questions concerning ease of discovery and use.
Reference: 23. <author> Rubine, D. </author> <title> Integrating Gesture Recognition and Direct Manipulation. </title> <booktitle> In Proceedings of the Summer '91 USENIX Technical Conference. </booktitle> <month> (June, </month> <year> 1991). </year> <institution> USENIX Association, </institution> <year> 1991, </year> <pages> pp. 95-100. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces <ref> [5, 12, 23] </ref>. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard.
Reference: 24. <author> Scheifler, R.W., and Gettys, J. </author> <title> The X window system. </title> <journal> ACM Transactions on Graphics Vol. </journal> <volume> 5, No. 2, </volume> <month> (Apr </month> <year> 1986), </year> <pages> pp. 79-109. </pages>
Reference-contexts: Is it possible to transmute these interfaces to proximate user interfaces without swamping the user in a deep hierarchy of proximate interactors? 3.2 Scalability Many existing user interface toolkits are layered on top of graphics standards, such as Microsoft Windows and X Windows <ref> [24] </ref>, which are inadequate for use on outsize devices. Microsoft Windows and X Windows do not have a resolution-independent imaging model; they deal in units of pixels rather than in some absolute, scalable unit. <p> The Proximate toolkit is a collection of interface elements written in Common Lisp and added to the Garnet User Interface Development Environment within the X11 Window System <ref> [17, 24] </ref>. The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques.
Reference: 25. <author> Schmandt, C., et al. </author> <title> Observations on Using Speech Input for Window Navigation. </title> <booktitle> In Proceedings of IFIP INTERACT '90: Human-Computer Interaction, </booktitle> <year> 1990, </year> <pages> pp. 787-793. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt <ref> [25] </ref>, Bush and Wilcox [30], and are available in commercial speech-based user interface builders [10]. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard.
Reference: 26. <author> Shneiderman, B., et al. </author> <title> A New Era for Touchscreen Applications. In User Interface Strategies '91, A Live, Interactive Satellite Broadcast. </title> <institution> (College Park, MD. Dec. 5). University of Maryland Instructional Television System, </institution> <year> 1990. </year>
Reference-contexts: Such "multimedia" mail messages are becoming more common in the Internet community [2]. Shneiderman <ref> [26] </ref> has demonstrated that a competent typist can achieve up to 25 words per minute typing speed on a pop-up touchscreen keyboard. The pop-up keyboard consists of a picture of a conventional QWERTY keyboard upon which the user pecks out characters with the stylus.
Reference: 27. <author> Sun Microsystems, Inc. </author> <title> Open Windows Developers Guide 1.1, User's Manual, </title> <year> 1990. </year>
Reference-contexts: can be very fast, once learned, and also allows eyes-free "heads up" writing, since all of the strokes can be written on top of each other; recognized characters appear immediately in text being created or edited. 3.5 Toolkits and User Interface Builders Existing toolkits [8, 14] and user interface builders <ref> [27] </ref> do not readily extend to the proximate user interface paradigm. They are targeted at arranging a set of interactors that are constantly visible in fixed places on a display.
Reference: 28. <editor> Thacker, C.P., et al. </editor> <title> Alto: a Personal Computer, in Computer Structures: Principles and Examples, </title> <editor> eds. D. P. Siewiorek, C.G. Bell and A. Newell. </editor> <publisher> Mcgraw-Hill, </publisher> <year> 1982. </year>
Reference-contexts: Menu Proximate user interfaces date back to 1969, when Wiseman [31] first proposed the idea of a "movable menu" displayed close to the cursor and appearing only when the user needs it. 2.1.2 Markup at Xerox PARC In 1976, in the Markup [20] graphical editing program on the Xerox Alto <ref> [28] </ref>, a mouse button was reserved to pop up a single large icon-based menu, part of which is shown in Figure 1, centered around the display cursor. The user could then invoke an operation from that menu by releasing the mouse button over the desired function icon.
Reference: 29. <author> Weiser, M. </author> <booktitle> The Computer for the 21st Century. In Scientific American 265, </booktitle> <month> 3 (Sep. </month> <year> 1991), </year> <pages> pp. 94-104. </pages>
Reference-contexts: 1 Introduction In the future world of ubiquitous computing <ref> [29] </ref>, interactive devices ranging in size from pocket to wall will be strewn about the user's environment, be it office or home. Display and digitizer surfaces will be merged so that users appear to interact directly on the display surface using an electronic stylus (pen) or touchscreen.
Reference: 30. <author> Wilcox, L.D., and Bush, M. A. </author> <title> HMM-based Wordspotting for Voice Editing and Indexing. </title> <booktitle> In Proceedings of Eurospeech '91 (Genova, </booktitle> <address> Italy, </address> <month> Sep. </month> <pages> 24-26). ESCA, </pages> <year> 1991, </year> <pages> pp. 25-28. </pages>
Reference-contexts: Examples of proximate interface elements for the stylus include pie menus [4], hierarchical pie menus [9], pop-up menus, pop-up property sheets [11], pop-up handwriting recognition pads [5], and gesture-based interfaces [5, 12, 23]. Vocal user interface elements have been demonstrated by Schmandt [25], Bush and Wilcox <ref> [30] </ref>, and are available in commercial speech-based user interface builders [10]. This paper addresses issues raised by proximate user interfaces on a large display surface as exemplified by the Xerox Liveboard.
Reference: 31. <author> Wiseman, N. E., et al. PIXIE: </author> <title> A New Approach to Graphical Man-Machine Communication. </title> <booktitle> In Proc. 1969 CAD Conf., IEE Conf. </booktitle> <publisher> Pub. </publisher> <address> 51, (Southampton, </address> <year> 1969), </year> <note> p. 463. </note>
Reference-contexts: These include the movable menus and pie menus described below. 2.1.1 Movable Menu Proximate user interfaces date back to 1969, when Wiseman <ref> [31] </ref> first proposed the idea of a "movable menu" displayed close to the cursor and appearing only when the user needs it. 2.1.2 Markup at Xerox PARC In 1976, in the Markup [20] graphical editing program on the Xerox Alto [28], a mouse button was reserved to pop up a single
References-found: 31

