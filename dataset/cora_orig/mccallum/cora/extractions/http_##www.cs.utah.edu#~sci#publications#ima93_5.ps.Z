URL: http://www.cs.utah.edu/~sci/publications/ima93_5.ps.Z
Refering-URL: http://www.cs.utah.edu/~sci/projects/comp_apps.html
Root-URL: 
Phone: 2  3  
Title: Applications of Automatic Mesh Generation and Adaptive Methods in Computational Medicine  
Author: J.A. Schmidt C.R. Johnson J.C. Eason R.S. MacLeod 
Address: Salt Lake City, UT 84112,  Durham, NC 27708,  Salt Lake City, UT 84112.  
Affiliation: 1 Department of Computer Science, University of Utah,  Department of Biomedical Engineering, Duke University,  Cardiovascular Research and Training Institute, University of Utah,  
Date: April 9, 1994  
Abstract: Important problems in Computational Medicine exist that can benefit from the implementation of adaptive mesh refinement techniques. Biological systems are so inherently complex that only efficient models running on state of the art hardware can begin to simulate reality. To tackle the complex geometries associated with medical applications we present a general purpose mesh generation scheme based upon the Delaunay tessellation algorithm and an iterative point generator. In addition, automatic, two- and three-dimensional adaptive mesh refinement methods are presented that are derived from local and global estimates of the finite element error. Mesh generation and adaptive refinement techniques are utilized to obtain accurate approximations of bioelectric fields within anatomically correct models of the heart and human thorax. Specifically, we explore the simulation of cardiac defibrillation and the general forward and inverse problems in electrocardiography (ECG). Comparisons between uniform and adaptive refinement techniques are made to highlight the computational efficiency and accuracy of adaptive methods in the solution of field problems in computational medicine. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. </author> <title> Board. Grand Challenges in Biomedical Computing, </title> <booktitle> chapter 18, </booktitle> <pages> pages 479-502. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: Flaherty and I. Babuska, Springer-Verlag, 1994. 1 in numerical analysis. Computational Medicine encompasses a broad range of top-ics including bioelectric field simulation (modeling of electrical and magnetic fields from the brain and heart, and modeling of excitable tissues), biomechanical modeling (biomechanics, ergonomics, and hemodynamics), molecular biology, and imaging technology <ref> [1, 2, 3, 4, 5] </ref>. It is not the purpose of this paper to discuss the entire field of computational medicine, but to investigate accuracy issues in bioelectric simulations issues that impact most other field problems in computational medicine.
Reference: [2] <author> P. Hunter, P. Nielsen, I. Smaill, B. LeGrice, and I. Hunter. </author> <title> An Anatomical Heart Model with Applications to Myocardial Activation and Ventricular Mechanics, </title> <booktitle> chapter 1, </booktitle> <pages> pages 3-26. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: Flaherty and I. Babuska, Springer-Verlag, 1994. 1 in numerical analysis. Computational Medicine encompasses a broad range of top-ics including bioelectric field simulation (modeling of electrical and magnetic fields from the brain and heart, and modeling of excitable tissues), biomechanical modeling (biomechanics, ergonomics, and hemodynamics), molecular biology, and imaging technology <ref> [1, 2, 3, 4, 5] </ref>. It is not the purpose of this paper to discuss the entire field of computational medicine, but to investigate accuracy issues in bioelectric simulations issues that impact most other field problems in computational medicine.
Reference: [3] <author> C. Peskin and D. McQueen. </author> <title> Cardiac Fluid Dynamics, </title> <booktitle> chapter 3, </booktitle> <pages> pages 51-62. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: Flaherty and I. Babuska, Springer-Verlag, 1994. 1 in numerical analysis. Computational Medicine encompasses a broad range of top-ics including bioelectric field simulation (modeling of electrical and magnetic fields from the brain and heart, and modeling of excitable tissues), biomechanical modeling (biomechanics, ergonomics, and hemodynamics), molecular biology, and imaging technology <ref> [1, 2, 3, 4, 5] </ref>. It is not the purpose of this paper to discuss the entire field of computational medicine, but to investigate accuracy issues in bioelectric simulations issues that impact most other field problems in computational medicine.
Reference: [4] <author> R. Spilker, E. de Almeida, and P. Donzelli. </author> <title> Finite Element Methods for the Biomechanics of Soft Hydrated Tissues: Nonlinear Analysis and Adaptive Control of Meshes, </title> <booktitle> chapter 9, </booktitle> <pages> pages 227-262. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: Flaherty and I. Babuska, Springer-Verlag, 1994. 1 in numerical analysis. Computational Medicine encompasses a broad range of top-ics including bioelectric field simulation (modeling of electrical and magnetic fields from the brain and heart, and modeling of excitable tissues), biomechanical modeling (biomechanics, ergonomics, and hemodynamics), molecular biology, and imaging technology <ref> [1, 2, 3, 4, 5] </ref>. It is not the purpose of this paper to discuss the entire field of computational medicine, but to investigate accuracy issues in bioelectric simulations issues that impact most other field problems in computational medicine.
Reference: [5] <author> J. Rosenman and T. Cullip. </author> <title> High-Performance Computing in Radiation Cancer Treatment, </title> <booktitle> chapter 17, </booktitle> <pages> pages 465-478. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: Flaherty and I. Babuska, Springer-Verlag, 1994. 1 in numerical analysis. Computational Medicine encompasses a broad range of top-ics including bioelectric field simulation (modeling of electrical and magnetic fields from the brain and heart, and modeling of excitable tissues), biomechanical modeling (biomechanics, ergonomics, and hemodynamics), molecular biology, and imaging technology <ref> [1, 2, 3, 4, 5] </ref>. It is not the purpose of this paper to discuss the entire field of computational medicine, but to investigate accuracy issues in bioelectric simulations issues that impact most other field problems in computational medicine.
Reference: [6] <author> R. Plonsey and D. Fleming. </author> <title> Bioelectric Phenomena. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: It has been shown that the electric signals in the body produced by the macroscopically viewed heart can be described as a solution to a quasi-static Poisson's equation <ref> [6] </ref>. While the theoretical solutions of such elliptic equations are not usually difficult (at least in the direct sense, when we know the nature of the sources | the complementary inverse problems are another story), computationally, there are many challenges to overcome in obtaining accurate approximations.
Reference: [7] <author> R.S. MacLeod. </author> <title> Percutaneous Transluminal Coronary Angioplasty as a Model of Cardiac Ischemia: Clinical and Modelling Studies. </title> <type> PhD thesis, </type> <institution> Dalhousie University, Halifax, N.S. Canada, </institution> <year> 1990. </year>
Reference-contexts: An accurate solution to the inverse problem in electrocardiography would provide a noninvasive procedure for the evaluation of many cardiac abnormalities including myocardial ischemia <ref> [7, 8] </ref> and the localization of ventricular arrhythmias.
Reference: [8] <author> R.S. MacLeod, C.R. Johnson, and B.M. Gardner, M.J. Horacek. </author> <title> Localization of ischemia during coronary angioplasty using body surface potential mapping and an electrocardiographic inverse solution. </title> <booktitle> In Computers in Cardiology, </booktitle> <pages> pages 251-254. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: An accurate solution to the inverse problem in electrocardiography would provide a noninvasive procedure for the evaluation of many cardiac abnormalities including myocardial ischemia <ref> [7, 8] </ref> and the localization of ventricular arrhythmias. <p> In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [9] <author> R.M. Gulrajani, P. Savard, and F.A. Roberge. </author> <title> The inverse problem in electrocardiography: Solutions in terms of equivalent sources. CRC Crit. </title> <journal> Rev. Biomed. Eng., </journal> <volume> 16 </volume> <pages> 171-214, </pages> <year> 1988. </year>
Reference-contexts: In order to solve the general problem, one usually represents the heart's electrical activity by a collection of discrete source terms such as dipoles or other higher-order current generators. One then tries to recover magnitude, location and orientation of the simplified model sources (see <ref> [9] </ref> for recent review). Alternatively, if instead of discrete sources within the heart, one formulates the problem in terms of electrostatic potentials on a surface bounding the heart, the resulting problem does possess a unique solution [10].
Reference: [10] <author> Y. Yamashita. </author> <title> Theoretical studies on the inverse problem in electrocardiography and the uniqueness of the solution. </title> <journal> IEEE Trans Biomed Eng, </journal> <volume> BME-29:719-725, </volume> <year> 1982. </year>
Reference-contexts: Alternatively, if instead of discrete sources within the heart, one formulates the problem in terms of electrostatic potentials on a surface bounding the heart, the resulting problem does possess a unique solution <ref> [10] </ref>. In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. [11, 12, 13, 14, 15, 8].
Reference: [11] <author> R.M. Gulrajani, F.A. Roberge, and G.E. Mailloux. </author> <title> The forward problem of electrocardiography. </title> <editor> In P.W. Macfarlane and T.D. Veitch Lawrie, editors, </editor> <booktitle> Comprehensive Electrocardiology, </booktitle> <pages> pages 197-236. </pages> <publisher> Pergamon Press, Oxford, </publisher> <address> England, </address> <booktitle> 1989. </booktitle> <volume> Volume 1. </volume>
Reference-contexts: In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [12] <author> R.M. Gulrajani, F.A. Roberge, and P. Savard. </author> <title> The inverse problem of electrocardiography. </title> <editor> In P.W. Macfarlane and T.D. Veitch Lawrie, editors, </editor> <booktitle> Comprehensive Electrocardiology, </booktitle> <pages> pages 237-288. </pages> <publisher> Pergamon Press, Oxford, </publisher> <address> England, </address> <booktitle> 1989. </booktitle> <volume> Volume 1. </volume> <pages> 20 </pages>
Reference-contexts: In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [13] <author> Y. Rudy and B.J. Messinger-Rapport. </author> <title> The inverse solution in electrocardiogra-phy: Solutions in terms of epicardial potentials. CRC Crit. </title> <journal> Rev. Biomed. Eng., </journal> <volume> 16 </volume> <pages> 215-268, </pages> <year> 1988. </year>
Reference-contexts: In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [14] <author> C.R. Johnson and A.E. Pollard. </author> <title> Electrical activation of the heart: Computational studies of the forward and inverse problems in electrocardiography. </title> <editor> In K.R. Billingsley, H.V. Brown III, and E.D. Durohanes, editors, </editor> <booktitle> Computer Assisted Modeling on the IBM 3090, </booktitle> <pages> pages 583-628. </pages> <publisher> Baldwin Press, </publisher> <address> University of Georgia, Athens, Georgia, </address> <year> 1992. </year>
Reference-contexts: In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [15] <author> C.R. Johnson. </author> <title> The generalized inverse problem in electrocardiography. </title> <booktitle> In IEEE Engineering in Medicine and Biology Society 12th Annual International Conference, </booktitle> <pages> pages 593-594. </pages> <publisher> IEEE Press, </publisher> <year> 1990. </year>
Reference-contexts: In fact, this has been the approach used in most recent research, since, unlike discrete source models, it also offers to opportunity for direct validation through measurements of potentials on the heart surface. <ref> [11, 12, 13, 14, 15, 8] </ref>. Mathematically, instead of solving Poisson's equation, we solve a generalized Laplace's equation with Cauchy boundary conditions 1 .
Reference: [16] <author> D.F. Watson. </author> <title> Computing the n-dimensional dealunay tesselation with applications to voronoi polytopes. </title> <journal> Computer Journal, </journal> <volume> 24(2) </volume> <pages> 167-172, </pages> <year> 1981. </year>
Reference-contexts: The meshes used for the research presented here ranged in size from thousands of elements for two-dimensional models to hundreds of thousands of elements for three-dimensional models. The method we used to create meshes is based upon the Delaunay tessellation algorithm originally proposed by Watson <ref> [16] </ref> and later extended by Weatherhill [17]. The Delaunay criteria states that the circumsphere of any tetrahedron (triangle) 3 contains no other mesh points.
Reference: [17] <author> N. Weatherill and O. Hassan. </author> <title> efficient three-dimensional grid generation using the Delaunay triangulation. </title> <booktitle> In Proceeings of the 1st European CFD Conference, </booktitle> <volume> volume 1, </volume> <year> 1992. </year>
Reference-contexts: The method we used to create meshes is based upon the Delaunay tessellation algorithm originally proposed by Watson [16] and later extended by Weatherhill <ref> [17] </ref>. The Delaunay criteria states that the circumsphere of any tetrahedron (triangle) 3 contains no other mesh points. The thrust of the Watson/Weatherhill algorithm is to efficiently insert a point into an existing grid (bounding simplex) in such a way that the Delaunay criterion is met.
Reference: [18] <author> A. Watt. </author> <title> Fundamentals of Three-Dimensional Computer Graphics. </title> <publisher> Addison-Wesley, </publisher> <address> Wokingham, England, </address> <year> 1989. </year>
Reference-contexts: To classify a tetrahedron we had to localize the position of its centroid relative to the surfaces separating regions of different conductivity. To localize the element, we utilized a ray tracing approach <ref> [18] </ref> which projects a ray from the centroid of an element to a point at infinity and counts the instances the ray intersects with a triangulated surface.
Reference: [19] <author> M. Mirowski, Mower M., P. Reid, L. Watkins, and A. Langer. </author> <title> The automatic implantable defibrillator. </title> <journal> Pace, </journal> <volume> 5 </volume> <pages> 384-399, </pages> <year> 1982. </year>
Reference-contexts: The most effective way to stop ventricular fibrillation once is has begun is to deliver a strong electrical shock to the heart, via the torso surface <ref> [19] </ref> (external) or the heart surface [20] (internal), i.e., to apply defibrillation [21]. Experimental studies using lab animals provide a controlled opportunity to study important parameters in defibrillation, e.g., electrode placement, shock strength, and shock duration, the results of which are often extrapolated to humans.
Reference: [20] <author> A. Langer, M. Heilman, M. Mower, and M. Mirowski. </author> <title> considerations in the development of the automatic implantable defibrillator. </title> <journal> Medical Instrumentation, </journal> <volume> 10 </volume> <pages> 163-167, </pages> <year> 1976. </year>
Reference-contexts: The most effective way to stop ventricular fibrillation once is has begun is to deliver a strong electrical shock to the heart, via the torso surface [19] (external) or the heart surface <ref> [20] </ref> (internal), i.e., to apply defibrillation [21]. Experimental studies using lab animals provide a controlled opportunity to study important parameters in defibrillation, e.g., electrode placement, shock strength, and shock duration, the results of which are often extrapolated to humans.
Reference: [21] <author> M. Mirowski. </author> <title> The automatic implantable cardioverter-defibrillation: an overview. </title> <journal> Journal of the American College of Cardiology, </journal> <volume> 6 </volume> <pages> 461-466, </pages> <year> 1985. </year>
Reference-contexts: The most effective way to stop ventricular fibrillation once is has begun is to deliver a strong electrical shock to the heart, via the torso surface [19] (external) or the heart surface [20] (internal), i.e., to apply defibrillation <ref> [21] </ref>. Experimental studies using lab animals provide a controlled opportunity to study important parameters in defibrillation, e.g., electrode placement, shock strength, and shock duration, the results of which are often extrapolated to humans.
Reference: [22] <author> O. Deale and B. Lerman. </author> <title> Intrathoracic current flow during transthoracic defib-rillation in dogs. </title> <journal> Circulation Research, </journal> <volume> 67 </volume> <pages> 1405-1419, </pages> <year> 1990. </year>
Reference-contexts: Animal experiments also provide investigators with a means of assessing the accuracy of computational models, and basic assumptions about the mechanism underlying defibrillation. Recently, Deale and Lerman <ref> [22, 23] </ref> performed fundamental experimental studies, which concluded [22] "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators [24, 25, 26] have predicted figures for the <p> Animal experiments also provide investigators with a means of assessing the accuracy of computational models, and basic assumptions about the mechanism underlying defibrillation. Recently, Deale and Lerman [22, 23] performed fundamental experimental studies, which concluded <ref> [22] </ref> "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators [24, 25, 26] have predicted figures for the defibrillation current traversing the heart that are closer <p> Difference factors of 3-4 between models and conclusions based on experimental data suggest deficient models or misinterpretation of experimental data. The computer simulations were performed using canine anatomy with shock electrodes located geometrically similar to the experiment of Deale and Lerman <ref> [22] </ref>. They used a simple resistor model based on experimental measurements to calculate the data shown in the above figures. The difference between the simulations and experiments arise from using a 3-D model as opposed to a 1-D model. <p> One of the purposes of this research work was to estimate the accuracy of the experimental results for canine defibrillation and to assess different modeling assumptions. To replicate the experimental setup of Deale and Lerman <ref> [22] </ref>, we constructed a computer model in which we paid special attention to the numerical accuracy of the simulations by implementing mesh refinement. Adaptive refinement was superior to uniform refinement in achieving reliable estimates of current densities on and near the electrodes. <p> In particular, the skeletal muscle is a major obstacle to the flow of current into the heart region, at least in part because of its anisotropic nature [42]. To simulate this situation, we placed round electrodes on both sides of the torso surface of the dog thorax model <ref> [22, 23] </ref>. We constructed a base mesh with uniform spacing, then modified it using both uniform and adaptive refinement.
Reference: [23] <author> B. Lerman and O. Deale. </author> <title> Relation betweend transcardiac and transthoracic current during defibrillation in humans. </title> <journal> Circulation Research, </journal> <volume> 67 </volume> <pages> 1420-1426, </pages> <year> 1990. </year>
Reference-contexts: Animal experiments also provide investigators with a means of assessing the accuracy of computational models, and basic assumptions about the mechanism underlying defibrillation. Recently, Deale and Lerman <ref> [22, 23] </ref> performed fundamental experimental studies, which concluded [22] "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators [24, 25, 26] have predicted figures for the <p> In particular, the skeletal muscle is a major obstacle to the flow of current into the heart region, at least in part because of its anisotropic nature [42]. To simulate this situation, we placed round electrodes on both sides of the torso surface of the dog thorax model <ref> [22, 23] </ref>. We constructed a base mesh with uniform spacing, then modified it using both uniform and adaptive refinement.
Reference: [24] <author> W. Karlon, S. Eisenberg, and J. Lehr. </author> <title> Defibrillation current density distributions: a three-dimensional finite element model of the canine thorax. </title> <booktitle> In Proceedings of the 13th Annual Conference of the IEEE Engineering in Medicine and Biology Society, </booktitle> <volume> volume 13, </volume> <pages> pages 770-771, </pages> <year> 1991. </year>
Reference-contexts: Recently, Deale and Lerman [22, 23] performed fundamental experimental studies, which concluded [22] "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators <ref> [24, 25, 26] </ref> have predicted figures for the defibrillation current traversing the heart that are closer to 15%. Difference factors of 3-4 between models and conclusions based on experimental data suggest deficient models or misinterpretation of experimental data.
Reference: [25] <author> W. Karlon. </author> <title> Defibrillation current density distributions: A three-dimensional finite element model of the canine thorax. M.s. </title> <type> thesis, </type> <institution> Boston University, </institution> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: Recently, Deale and Lerman [22, 23] performed fundamental experimental studies, which concluded [22] "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators <ref> [24, 25, 26] </ref> have predicted figures for the defibrillation current traversing the heart that are closer to 15%. Difference factors of 3-4 between models and conclusions based on experimental data suggest deficient models or misinterpretation of experimental data.
Reference: [26] <author> F. Claydon, T. Pilkington, A. Tang, M. Morrow, and R. Ideker. </author> <title> A volume conductor model of the thorax for thestudy of defibrillation fields. </title> <journal> IEEE Transactions on Biomedical Engineering, </journal> <volume> BME-35, </volume> <year> 1988. </year>
Reference-contexts: Recently, Deale and Lerman [22, 23] performed fundamental experimental studies, which concluded [22] "...that for canine transthoracic defibrillation, 82% of the total delivered current is shunted between the electrodes by the thoracic cage, 14% is shunted by the lungs, and only 4% traverses the heart." Previous investigators <ref> [24, 25, 26] </ref> have predicted figures for the defibrillation current traversing the heart that are closer to 15%. Difference factors of 3-4 between models and conclusions based on experimental data suggest deficient models or misinterpretation of experimental data.
Reference: [27] <author> H. Fuchs, Z. Kedem, and S. Uselton. </author> <title> Optimal surface reconstruction from planar contours. </title> <journal> Communications of the ACM, </journal> <volume> 20, </volume> <year> 1977. </year>
Reference-contexts: Adaptive refinement was superior to uniform refinement in achieving reliable estimates of current densities on and near the electrodes. We obtained boundary points from MRI images and digitized photos of a dog torso anatomy. Using the method described above, we created both surface triangulations <ref> [27] </ref> and a tetrahedral volume mesh. The point spacing function, which controls spacing between points in the interior of the mesh, was initially set to match the spacing of the surface points.
Reference: [28] <author> C.R. Johnson, R.S. MacLeod, and P.R. Ershler. </author> <title> A computer model for the study of electrical current flow in the human thorax. </title> <journal> Computers in Biology and Medicine, </journal> <volume> 22(3) </volume> <pages> 305-323, </pages> <year> 1992. </year>
Reference-contexts: To study the direct and inverse problems in electrocardiography, we developed a series of two- and three-dimensional boundary element and finite element models based upon magnetic resonance images from a human subject <ref> [28, 29, 30] </ref>. Each of 116 MRI scans were segmented into contours defining torso, fat, muscle, lung, and heart regions. Additional node points were added to digitize each layer and were subsequently tessellated into tetrahedra using the Delaunay triangulation algorithm [28]. <p> Each of 116 MRI scans were segmented into contours defining torso, fat, muscle, lung, and heart regions. Additional node points were added to digitize each layer and were subsequently tessellated into tetrahedra using the Delaunay triangulation algorithm <ref> [28] </ref>. The resulting model of the human thorax contained approximately 675,000 volume elements, each with a corresponding conductivity tensor. Figure 1 illustrates the model construction process by showing a collage of the original MRI scan, a triangulated lung, and a portion of the tetrahedralization of the volume.
Reference: [29] <author> C.R. Johnson, R.S. MacLeod, and M.A. Matheson. </author> <title> Computer simultions reveal complexity of electrical activity in the human thorax. </title> <journal> Comp. in Physics, </journal> <volume> 6(3) </volume> <pages> 230-237, </pages> <month> May/June </month> <year> 1992. </year>
Reference-contexts: To study the direct and inverse problems in electrocardiography, we developed a series of two- and three-dimensional boundary element and finite element models based upon magnetic resonance images from a human subject <ref> [28, 29, 30] </ref>. Each of 116 MRI scans were segmented into contours defining torso, fat, muscle, lung, and heart regions. Additional node points were added to digitize each layer and were subsequently tessellated into tetrahedra using the Delaunay triangulation algorithm [28].
Reference: [30] <author> C.R. Johnson, R.S. MacLeod, and M.A. Matheson. </author> <title> Computational medicine: Bioelectric field problems. </title> <booktitle> IEEE COMPUTER, </booktitle> <pages> pages 59-67, </pages> <month> Oct., </month> <year> 1993. </year>
Reference-contexts: To study the direct and inverse problems in electrocardiography, we developed a series of two- and three-dimensional boundary element and finite element models based upon magnetic resonance images from a human subject <ref> [28, 29, 30] </ref>. Each of 116 MRI scans were segmented into contours defining torso, fat, muscle, lung, and heart regions. Additional node points were added to digitize each layer and were subsequently tessellated into tetrahedra using the Delaunay triangulation algorithm [28].
Reference: [31] <author> P. Colli Franzone, L. Guerri, B. Taccardi, and C. Viganotti. </author> <title> Finite element approximation of regularized solutions of the inverse potential problem of electrocardiography and applications to experimental data. Calcolo, </title> <address> XXII(I):91-186, </address> <year> 1985. </year>
Reference-contexts: to the inverse problem involves enclosing the 8 heart with a bounding surface, and, instead of solving the Poisson equation in (1) for the primary cardiac currents, solving Laplace's equation for the potentials on the closed surface just outside the heart (according to the same boundary conditions as in (4)) <ref> [31] </ref>. The advantages of this formulation include that the solution to the resulting inverse problem is unique and that these solutions can be directly verified by measuring the potentials on the outer surface of the heart [32].
Reference: [32] <author> B.J. Messinger-Raport and Y. Rudy. </author> <title> Noninvasive recovery of epicardial potentials in a realistic heart-torso geometry. </title> <journal> Circ Res, </journal> <volume> 66, 4 </volume> <pages> 1023-1039, </pages> <year> 1990. </year>
Reference-contexts: The advantages of this formulation include that the solution to the resulting inverse problem is unique and that these solutions can be directly verified by measuring the potentials on the outer surface of the heart <ref> [32] </ref>. While the solution to this problem is unique, it is still ill-posed in the Hadamard sense that small errors in input data can cause large unbounded oscillatory errors in the solution data.
Reference: [33] <author> D. Burnett. </author> <title> Finite Element Analysis- From Concepts to Applications. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1987. </year>
Reference-contexts: If we reduce the size of the elements, h-refinement, or increase the order of the basis function, p-refinement, the approximation improves <ref> [33] </ref>. While either approach can be applied globally, computational limits make it more efficient to apply refinement locally, to regions where it is deemed most beneficial. One way to monitor the overall effect of refinement is to compute the total energy, which must converge monotonically if refinement is progressing effectively.
Reference: [34] <author> R. Lewis, H. Huang, A. Usmani, and J. </author> <title> Cross. Finite element analysis of heat transfer and flow problems using adaptive remeshing including application to solidification problems. </title> <journal> International Journal of Numerical Methods in Engineering, </journal> <volume> 32 </volume> <pages> 767-781, </pages> <year> 1991. </year>
Reference-contexts: We have implemented two different adaptive h-refinement techniques. One global method based on an estimate of the element energy error, derived from methods suggested by Lewis <ref> [34] </ref>, and another method which utilizes the weak form of the approximation to estimate errors which are valid globally, but which can be applied locally. We briefly outline both of the methods below. <p> Hence, (20) can be calculated using the energy due to the smoothed currents and the energy due to the constant currents. The smoothed current densities are now defined at the same nodal locations as the potentials and are continuous across element boundaries. The smoothing process used the Galerkin technique <ref> [34] </ref> and involved minimizing the difference between the two current densities, (r ~ r ^ ) (21) where r ~ is the smoothed gradient representing the exact gradient and r ^ is the constant gradient from the FEM solution. <p> Once the energy error has been computed, the mesh refinement can begin. The error must be related to some parameter which guides the mesh refinement. We utilized a spacing function, h e , which controls the size and number of elements <ref> [34] </ref>. This spacing function, h e is defined to be the linear interpolation of the spacing values at the four nodes of the tetrahedron.
Reference: [35] <author> O. Zienkiewicz and J. Zhu. </author> <title> A simple error estimator and adaptive procedure for practical engineering analysis. </title> <journal> International Journal of Numerical Methods in Engineering, </journal> <volume> 24 </volume> <pages> 337-357, </pages> <year> 1987. </year>
Reference-contexts: The error norm is defined as: ke q k = ( 1 Zienkiewicz <ref> [35, 36] </ref> has shown that Z (r) T (r ^ )d = Z (r ^ ) T (r ^ )d: (17) Using this result, (16) becomes ke q k 2 = Z (r ^ ) T (r ^ )d (18) or equivalently, ke q k 2 = kqk 2 k^qk 2 <p> Zienkiewicz showed that when the current densities arising from the gradients are globally smoothed, they provide a more accurate estimate of the energy than the energy using the constant current densities <ref> [35, 36] </ref>. Hence, (20) can be calculated using the energy due to the smoothed currents and the energy due to the constant currents. The smoothed current densities are now defined at the same nodal locations as the potentials and are continuous across element boundaries.
Reference: [36] <author> O. Zienkiewicz and J. Zhu. </author> <title> Adaptivity and mesh generation. </title> <journal> International Journal of Numerical Methods in Engineering, </journal> <volume> 32 </volume> <pages> 783-810, </pages> <year> 1991. </year>
Reference-contexts: The error norm is defined as: ke q k = ( 1 Zienkiewicz <ref> [35, 36] </ref> has shown that Z (r) T (r ^ )d = Z (r ^ ) T (r ^ )d: (17) Using this result, (16) becomes ke q k 2 = Z (r ^ ) T (r ^ )d (18) or equivalently, ke q k 2 = kqk 2 k^qk 2 <p> Zienkiewicz showed that when the current densities arising from the gradients are globally smoothed, they provide a more accurate estimate of the energy than the energy using the constant current densities <ref> [35, 36] </ref>. Hence, (20) can be calculated using the energy due to the smoothed currents and the energy due to the constant currents. The smoothed current densities are now defined at the same nodal locations as the potentials and are continuous across element boundaries.
Reference: [37] <author> P.G. Ciarlet and J.L Lions. </author> <title> Handbook of Numerical Analysis: Finite Element Methods, volume 1. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: Given these definitions, we can then obtain the error estimates analogous to those in (28) and (29) for the finite element approximation <ref> [37, 38] </ref>: X (h k jj H 2 (K) ) 2 ] 2 (33) or, in the L 2 () norm, k h k L 2 () k h k L 2 () Ch 2 jj H 2 () : (34) For the potential gradients we have [39] 5 : kr
Reference: [38] <author> C. Johnson. </author> <title> Numercial solution of Partial Differential Equations by the Finite Element Method. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Given these definitions, we can then obtain the error estimates analogous to those in (28) and (29) for the finite element approximation <ref> [37, 38] </ref>: X (h k jj H 2 (K) ) 2 ] 2 (33) or, in the L 2 () norm, k h k L 2 () k h k L 2 () Ch 2 jj H 2 () : (34) For the potential gradients we have [39] 5 : kr
Reference: [39] <author> R. Rannacher and R. Scott. </author> <title> Some optimal error estimates for piecewise linear finite element approximations. </title> <journal> Math. Comp., </journal> <volume> 38 </volume> <pages> 437-445, </pages> <year> 1982. </year> <month> 22 </month>
Reference-contexts: finite element approximation [37, 38]: X (h k jj H 2 (K) ) 2 ] 2 (33) or, in the L 2 () norm, k h k L 2 () k h k L 2 () Ch 2 jj H 2 () : (34) For the potential gradients we have <ref> [39] </ref> 5 : kr r h k L 1 () Ckr r h ~ k L 1 () C max [h K max kD ff k L 1 () ]: (35) Given these previous error estimates for the finite element approximation, we can now use the estimates to decide where in
Reference: [40] <author> C.R. Johnson and R.S. MacLeod. </author> <title> Nonuniform spatial mesh adaption using a posteriori error estimates: applications to forward and inverse problems. In J.E. Flaherty and M.S. Shephard, editors, Adaptive Methods for Partial Differential Equations. </title> <publisher> Elsevier, </publisher> <year> 1992. </year> <note> (in press). </note>
Reference-contexts: Thus we have used a minimax principle, minimizing the maximum error based upon initial (conservative) estimates of the potential field and potential gradients <ref> [40] </ref>. 5 We note that there a numerous possibilities for various norms and the ones given above should be seen as examples 14 Applications of Adaptive Methods in Electrocardiology Defibrillation We present two different model applications that use the adaptive techniques outlined earlier applied to defibrillation modeling.
Reference: [41] <author> P. Nielsen, I. Le Grice, B. Smaill, and P. Hunter. </author> <title> Mathematical model of geometry and fibrous structure of the heart. </title> <journal> American Journal of Physiology: Heart Circulation and Physiology, </journal> <volume> 29 </volume> <pages> 1365-1378, </pages> <year> 1991. </year>
Reference-contexts: The second simulation involves modeling external defibrillation on a dog thorax. In both cases, the energy norm described earlier was used to calculate the energy error which guided mesh refinement. The isolated dog heart geometry was obtained from a group in New Zealand <ref> [41] </ref>. Two rectangular electrodes were placed on the surface of the isolated heart and a voltage difference was applied to simulate a typical defibrillation protocol. The conductivity of the heart was assumed to be homogeneous and isotropic throughout both the heart tissue and blood cavities.
Reference: [42] <author> C.R. Johnson, R.S. MacLeod, and A. Dutson. </author> <title> Effects of anistropy and inhomogeneity on electrocardiographic fields: a finite element study. </title> <booktitle> In IEEE Engineering in Medicine and Biology Society 14th Annual International Conference, </booktitle> <pages> pages 2009-2010. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: In external defibrillation, much larger currents are injected into the torso to overcome the shunting effect of the inhomogeneities within the body. In particular, the skeletal muscle is a major obstacle to the flow of current into the heart region, at least in part because of its anisotropic nature <ref> [42] </ref>. To simulate this situation, we placed round electrodes on both sides of the torso surface of the dog thorax model [22, 23]. We constructed a base mesh with uniform spacing, then modified it using both uniform and adaptive refinement.
Reference: [43] <author> K.R. Foster and H.P. Schwan. </author> <title> Dielectric properties of tissues and biological materials: A critical review. Critical Reviews in Biomed. </title> <journal> Eng., </journal> <volume> 17 </volume> <pages> 25-104, </pages> <year> 1989. </year>
Reference-contexts: The following conductivities in units of S/cm were used, SK = :0067 ^ h theta +:00043 ^ h r +:0067^z, B = :00138, L = :0005, and H = :00232 with subscripts SK, B, L, and H denoting skeletal muscle, body, lungs, and heart respectively <ref> [43] </ref>. We created three different uniformly refined meshes and from the smallest of these carried out adaptive refinement based on the error estimators described earlier. Table 1 gives the mesh statistics for the three uniformly refined meshes. <p> The tissue conductivities were assigned as fat = .045 S/m, fatpad = .045 S/m, lungs = .096 S/m, skeletal muscle (along the fiber) = .3 S/m, skeletal muscle (across the fiber) = .1 S/m, and an average thorax value = .24 S/m <ref> [43] </ref>. From forward solutions calculated using the adapted mesh we computed inverse solutions on the same mesh. The L-curve algorithm [44] was utilized to estimate the optimal a priori regularization parameter for Tikhonov regularization technique, which we used to compute the inverse solution matrix.
Reference: [44] <author> P.C. Hansen. </author> <title> Analysis of discrete ill-posed problems by means of the L-curve. </title> <journal> SIAM Review, </journal> <volume> 34(4) </volume> <pages> 561-580, </pages> <year> 1992. </year>
Reference-contexts: From forward solutions calculated using the adapted mesh we computed inverse solutions on the same mesh. The L-curve algorithm <ref> [44] </ref> was utilized to estimate the optimal a priori regularization parameter for Tikhonov regularization technique, which we used to compute the inverse solution matrix.
Reference: [45] <author> F.P. Colli Franzone, G. Gassaniga, L. Guerri, B. Taccardi, and C. Viganotti. </author> <title> Accuracy evaluation in direct and inverse electrocardiology. </title> <editor> In P.W. Macfarlane, editor, </editor> <booktitle> Progress in Electrocardiography, </booktitle> <pages> pages 83-87. </pages> <publisher> Pitman Medical, </publisher> <year> 1979. </year>
Reference-contexts: The inverse solutions were within 12.6% of those recorded originally, which compares favorably to previously reported values, which lay in the range of 20-40%, <ref> [45, 46, 47, 48] </ref>, albeit for three-dimensional problems. An example of the current flow in the human thorax model is shown in Figure 5. Conclusions We have developed tools to automatically create and modify three-dimensional meshes for the complex geometries often associated with bioelectric field problems.
Reference: [46] <author> P. Colli Franzone, L. Guerri, S. Tentonia, C. Viganotti, S. Spaggiari, and B. Tac-cardi. </author> <title> A numerical procedure for solving the inverse problem of electrocardiography. Analysis of the time-space accuracy from in vitro experimental data. </title> <journal> Math Biosci, </journal> <volume> 77:353, </volume> <year> 1985. </year>
Reference-contexts: The inverse solutions were within 12.6% of those recorded originally, which compares favorably to previously reported values, which lay in the range of 20-40%, <ref> [45, 46, 47, 48] </ref>, albeit for three-dimensional problems. An example of the current flow in the human thorax model is shown in Figure 5. Conclusions We have developed tools to automatically create and modify three-dimensional meshes for the complex geometries often associated with bioelectric field problems.
Reference: [47] <author> B.J. Messinger-Rapport and Y. Rudy. </author> <title> Regularization of the inverse problem in electrocardiography: A model study. </title> <journal> Math Biosci, </journal> <volume> 89 </volume> <pages> 79-118, </pages> <year> 1988. </year>
Reference-contexts: The inverse solutions were within 12.6% of those recorded originally, which compares favorably to previously reported values, which lay in the range of 20-40%, <ref> [45, 46, 47, 48] </ref>, albeit for three-dimensional problems. An example of the current flow in the human thorax model is shown in Figure 5. Conclusions We have developed tools to automatically create and modify three-dimensional meshes for the complex geometries often associated with bioelectric field problems.

References-found: 47

