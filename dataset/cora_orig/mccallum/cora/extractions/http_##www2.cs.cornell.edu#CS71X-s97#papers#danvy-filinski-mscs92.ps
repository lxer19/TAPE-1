URL: http://www2.cs.cornell.edu/CS71X-s97/papers/danvy-filinski-mscs92.ps
Refering-URL: http://www2.cs.cornell.edu/CS71X-s97/cs719bib.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (danvy@cis.ksu.edu)  (Andrzej.Filinski@cs.cmu.edu)  
Title: Representing Control A Study of the CPS transformation  
Author: Olivier Danvy Andrzej Filinski 
Date: February 1991; Revised June 1992  
Affiliation: Kansas State University  Carnegie Mellon University  
Abstract: This paper investigates the transformation of v -terms into continuation-passing style (CPS). We show that by appropriate -expansion of Fischer and Plotkin's two-pass equational specification of the CPS transform, we can obtain a static and context-free separation of the result terms into "essential" and "administrative" constructs. Interpreting the former as syntax builders and the latter as directly executable code, we obtain a simple and efficient one-pass transformation algorithm, easily extended to conditional expressions, recursive definitions, and similar constructs. This new transformation algorithm leads to a simpler proof of Plotkin's simulation and indifference results. Further we show how CPS-based control operators similar to but more general than Scheme's call/cc can be naturally accommodated by the new transformation algorithm. To demonstrate the expressive power of these operators, we use them to present an equivalent but even more concise formulation of the efficient CPS transformation algorithm. Finally, we relate the fundamental ideas underlying this derivation to similar concepts from other work on program manipulation; we derive a one-pass CPS transformation of n -terms; and we outline some promising areas for future research. fl To appear in the journal Mathematical Structures in Computer Science. Technical Report CIS-91-2 (revised version), Department of Computing and Information Sciences, Kansas State University. y Department of Computing and Information Sciences, Kansas State University, Manhattan, Kansas 66506, USA. This work was partly supported by NSF under grant CCR-9102625. z School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, USA. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Alternatively (by omitting the equations for shift and reset), it translates terms of a Scheme-like language (i.e., -calculus + escape) into standard CPS. Such a transformation has a practical interest for compiling, e.g., Scheme or Standard ML programs <ref> [43, 1] </ref>, and thus constitutes a significant example of using shift/reset: even the pure CPS translation is expressed naturally using the new control operators. As with all meta-circular definitions, we need to bootstrap it. <p> This correspondence helps to ensure consistency between the two methods of language definition. 6 Related Work 6.1 CPS transformation Two other works have independently employed CPS translations similar to the one presented here. The first one is Appel's CPS transformer in the Standard ML of New Jersey compiler <ref> [1] </ref>. The second one is Wand's combinator-based compilation technique [45]. But neither motivate their transformer, e.g., as we do in Section 2, nor extend it to control operators or normal order, as we do in Sections 5 and A. <p> Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation [9, 11, 40]. 6.2 Primitive operators Most CPS-based compilers <ref> [43, 1, 45] </ref> and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear. In particular, the oft-quoted advantage of having explicit names for all subexpressions can be realized equally well with let-expressions.
Reference: [2] <author> Anders Bondorf. </author> <title> Automatic autoprojection of higher-order recursive equations. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 17 </volume> <pages> 3-34, </pages> <year> 1991. </year>
Reference-contexts: Recent work by Bondorf and the first author emphasize the issues of code duplication and termination properties [3], and use the technique of enumerating finitary constructs <ref> [2] </ref>, as we do in Sections 2 and 4.2. The latter is also central to Shivers's work on higher-order flow analysis [41]. All these concepts were pervasive in our derivation of a one-pass CPS transformer.
Reference: [3] <author> Anders Bondorf and Olivier Danvy. </author> <title> Automatic autoprojection of recursive equations with global variables and abstract data types. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 16 </volume> <pages> 151-195, </pages> <year> 1991. </year>
Reference-contexts: Recent work by Bondorf and the first author emphasize the issues of code duplication and termination properties <ref> [3] </ref>, and use the technique of enumerating finitary constructs [2], as we do in Sections 2 and 4.2. The latter is also central to Shivers's work on higher-order flow analysis [41]. All these concepts were pervasive in our derivation of a one-pass CPS transformer.
Reference: [4] <author> William Clinger. </author> <title> The Scheme 311 compiler, an exercise in Denotational Semantics. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 356-364, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Or equivalently we can duplicate the rules to account for tail-call contexts, as in Figure 3, and in a way reminiscent of Clinger's double induction proof in his Scheme compiler <ref> [4] </ref>. Rationale: The auxiliary translation [[:::]] 0 is used when the static continuation would have the form m:@k m; this avoids building an -redex in the transformation of appli cations (hence the term "properly tail-recursive" [43]).
Reference: [5] <editor> William Clinger and Jonathan Rees (editors). </editor> <title> Revised 4 report on the algorithmic language Scheme. LISP Pointers, </title> <address> IV(3):1-55, </address> <month> July-September </month> <year> 1991. </year>
Reference-contexts: Prerequisites In the following, we will assume a basic familiarity with CPS and the v -calculus, i.e., the applicative order -calculus that forms the core of languages such as Scheme <ref> [5] </ref> and Standard ML [29]. For convenience in referring to individual applications, we will generally express them with an explicit operator @, writing @M N instead of the traditional simple juxtaposition M N .
Reference: [6] <author> Charles Consel and Olivier Danvy. </author> <title> Static and dynamic semantics processing. </title> <booktitle> In POPL'91 [36], </booktitle> <pages> pages 14-24. </pages>
Reference-contexts: together as representing composition and identity on continuation functions respectively; proper CPS form is restored by iterating the CPS transformation [10]. 6.4 Partial evaluation Partial evaluation (or more accurately: program specialization [25]) makes heavy use of binding time information to process the static and the dynamic semantics of source programs <ref> [6] </ref>, as we do here. Recent work by Bondorf and the first author emphasize the issues of code duplication and termination properties [3], and use the technique of enumerating finitary constructs [2], as we do in Sections 2 and 4.2.
Reference: [7] <author> Charles Consel and Olivier Danvy. </author> <title> For a better support of static data flow. </title> <booktitle> In Proceedings of the Fifth ACM Conference on Functional Programming and Computer Architecture, number 523 in Lecture Notes in Computer Science, </booktitle> <pages> pages 496-519, </pages> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: The former is a two-level version of the latter. Moreover, our derivation illustrates a new trend in partial evaluation: using CPS to improve binding time properties of source programs, leading to better specialization <ref> [7] </ref>. Work is going on to further automate the process. 7 Conclusion and Issues As proven constructively in this paper, transforming -terms into CPS can be expressed in one pass by moving administrative redexes to translation time in a context-free way.
Reference: [8] <author> Olivier Danvy. </author> <title> Programming with tighter control. </title> <journal> Special issue of the BIGRE journal: Putting Scheme to Work, </journal> (65):10-29, July 1989. 
Reference-contexts: Earlier on, prompts were specified with an operational description in terms of textual reductions [14]. In general, these static vs. dynamic interpretations lead to different behaviors <ref> [8] </ref>. In our framework, reset naturally is the direct style counterpart of initializing the continuation of a CPS -term with the identity function.
Reference: [9] <author> Olivier Danvy. </author> <title> Back to direct style. </title> <editor> In Bernd Krieg-Bruckner, editor, </editor> <booktitle> Proceedings of the Fourth European Symposium on Programming, number 582 in Lecture Notes in Computer Science, </booktitle> <pages> pages 130-150, </pages> <publisher> Rennes, </publisher> <address> France, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation <ref> [9, 11, 40] </ref>. 6.2 Primitive operators Most CPS-based compilers [43, 1, 45] and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear.
Reference: [10] <author> Olivier Danvy and Andrzej Filinski. </author> <title> Abstracting control. </title> <booktitle> In LFP'90 [26], </booktitle> <pages> pages 151-160. </pages>
Reference-contexts: the natural direct-style program hlet b 1 = @flip () in : : : let b n = @flip () in 'i This approach to nondeterministic programming also easily handles irregular search structures, where further tests may depend on outcome of previous "guesses", e.g., for simulating a nondeterministic finite automaton <ref> [10] </ref>. 5.3 Control and prompt While shift and reset are very similar to Felleisen's operators control and prompt [14], there is a significant semantical difference between shift/reset and control/prompt: the context abstracted by shift is determined statically by the static program text, while control captures the context up to the nearest <p> But the second CPS transformation now gives a proper CPS term (with h as the continuation parameter): let f cc = x:k:h:k x (a:k a h) 23 Remark: Iterating this construction leads to "extended CPS" and a whole hierarchy of control operators <ref> [10] </ref>. <p> These could be unfolded by substituting the control abstractions for the identifiers in the translated terms, as we first specified it <ref> [10] </ref>: [[escape c in M ]] = :(@[[M [c c 0 ]]] )[c 0 a: 0 :@ a] [[shift c in M ]] = :(@[[M [c c 0 ]]] (m:m))[c 0 a: 0 :@ 0 (@ a)] However, these substitutions introduce residual fi-redexes when control abstractions are applied within the scope <p> On the other hand, we can get an interpretive semantics for the extended language by translating a trivial (i.e., defining shift in terms of shift, etc.) self-interpreter into extended CPS <ref> [10] </ref>. This correspondence helps to ensure consistency between the two methods of language definition. 6 Related Work 6.1 CPS transformation Two other works have independently employed CPS translations similar to the one presented here. The first one is Appel's CPS transformer in the Standard ML of New Jersey compiler [1]. <p> In particular, shift and reset are introduced together as representing composition and identity on continuation functions respectively; proper CPS form is restored by iterating the CPS transformation <ref> [10] </ref>. 6.4 Partial evaluation Partial evaluation (or more accurately: program specialization [25]) makes heavy use of binding time information to process the static and the dynamic semantics of source programs [6], as we do here. <p> And in fact, recent developments seem to support this conviction [32]. 28 Moreover, there is a close relationship between computational monads [30] and "generalized CPS", as suggested in "Abstracting Control" <ref> [10] </ref> and properly formalized by Wadler [44]. Effectively, this implies that CPS-based control operators like shift and reset can by themselves uniformly express a rich class of computational behaviors, including partiality, nondeterminism, and state.
Reference: [11] <author> Olivier Danvy and Julia L. Lawall. </author> <title> Back to direct style II: First-class continuations. </title> <booktitle> In LFP'92 [27]. </booktitle>
Reference-contexts: Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation <ref> [9, 11, 40] </ref>. 6.2 Primitive operators Most CPS-based compilers [43, 1, 45] and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear.
Reference: [12] <author> Olivier Danvy and Carolyn L. Talcott, </author> <title> editors. </title> <booktitle> Proceedings of the ACM SIGPLAN Workshop on Continuations, </booktitle> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year> <type> Technical report STAN-CS-92-1426, </type> <institution> Stanford University. </institution>
Reference: [13] <author> Bruce F. Duba, Robert Harper, and David MacQueen. </author> <title> Typing first-class continuations in ML. </title> <booktitle> In POPL'91 [36], </booktitle> <pages> pages 163-173. </pages>
Reference-contexts: Section 4.1). We adopt the same simple solution: at syntax-analysis time, occurrences of identifiers declared within a control abstraction are guaranteed to occur only in application position, which we single out by tagging this application with throw, as in Standard ML of New Jersey <ref> [13] </ref>. [[escape c in M ]] = :(@[[M [c c 0 ]]] )[c 0 a: 0 :@ a] [[shift c in M ]] = :(@[[M [c c 0 ]]] (m:m))[c 0 a: 0 :@ 0 (@ a)] [[throw c M ]] = :@[[M ]] (m:@(@c m) ) To avoid dealing with
Reference: [14] <author> Matthias Felleisen. </author> <title> The theory and practice of first-class prompts. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 180-190, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: @flip () in 'i This approach to nondeterministic programming also easily handles irregular search structures, where further tests may depend on outcome of previous "guesses", e.g., for simulating a nondeterministic finite automaton [10]. 5.3 Control and prompt While shift and reset are very similar to Felleisen's operators control and prompt <ref> [14] </ref>, there is a significant semantical difference between shift/reset and control/prompt: the context abstracted by shift is determined statically by the static program text, while control captures the context up to the nearest dynamically enclosing prompt. 22 The difference between shift and control is probably best displayed by the following two <p> Their two denotational descriptions introduce an algebra of control and lead to a representation of continuations as prompt-delimited sequences of activation frames, and their composition as the concatenation of these sequences [18]. Earlier on, prompts were specified with an operational description in terms of textual reductions <ref> [14] </ref>. In general, these static vs. dynamic interpretations lead to different behaviors [8]. In our framework, reset naturally is the direct style counterpart of initializing the continuation of a CPS -term with the identity function. <p> However, because CPS appears to constrain expressive power, Felleisen and others have successively proposed new control operators to compose continuations [15] and to limit their extent <ref> [14] </ref>. As later shown by Sitaram and Felleisen [42], inclusion of control delimiters is also necessary to obtain fully abstract models of control for CPS models with 27 escape.
Reference: [15] <author> Matthias Felleisen, Daniel P. Friedman, Bruce Duba, and John Merrill. </author> <title> Beyond continuations. </title> <type> Technical Report 216, </type> <institution> Computer Science Department, Indiana University, Bloomington, Indi-ana, </institution> <month> February </month> <year> 1987. </year>
Reference-contexts: However, because CPS appears to constrain expressive power, Felleisen and others have successively proposed new control operators to compose continuations <ref> [15] </ref> and to limit their extent [14]. As later shown by Sitaram and Felleisen [42], inclusion of control delimiters is also necessary to obtain fully abstract models of control for CPS models with 27 escape.
Reference: [16] <author> Matthias Felleisen, Daniel P. Friedman, Eugene Kohlbecker, and Bruce Duba. </author> <title> Reasoning with continuations. </title> <booktitle> In Proceedings of the First Symposium on Logic in Computer Science, </booktitle> <pages> pages 131-141, </pages> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1986. </year> <note> IEEE. </note>
Reference-contexts: (the process of computation, possibly error-raising) to be expressed in CPS and the pure (and hence freely rearrangable) function computed, in which case we actually get the best of both worlds. 6.3 Control operators From Reynolds's escape to call/cc in Scheme, control operators are nicely introduced within the CPS transformation <ref> [38, 16] </ref>. However, because CPS appears to constrain expressive power, Felleisen and others have successively proposed new control operators to compose continuations [15] and to limit their extent [14].
Reference: [17] <author> Matthias Felleisen, Daniel P. Friedman, Eugene Kohlbecker, and Bruce Duba. </author> <title> A syntactic theory of sequential control. </title> <journal> Theoretical Computer Science, </journal> <volume> 52(3) </volume> <pages> 205-237, </pages> <year> 1987. </year>
Reference-contexts: Shift also differs from escape by not implicitly duplicating the current continuation (Felleisen's C-operator introduced the behavior of not duplicating continuations <ref> [17] </ref>).
Reference: [18] <author> Matthias Felleisen, Mitchell Wand, Daniel P. Friedman, and Bruce F. Duba. </author> <title> Abstract continuations: A mathematical semantics for handling full functional jumps. </title> <booktitle> In Proceedings of the 1988 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 52-62, </pages> <address> Snowbird, Utah, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Their two denotational descriptions introduce an algebra of control and lead to a representation of continuations as prompt-delimited sequences of activation frames, and their composition as the concatenation of these sequences <ref> [18] </ref>. Earlier on, prompts were specified with an operational description in terms of textual reductions [14]. In general, these static vs. dynamic interpretations lead to different behaviors [8]. In our framework, reset naturally is the direct style counterpart of initializing the continuation of a CPS -term with the identity function.
Reference: [19] <author> Andrzej Filinski. </author> <title> Linear continuations. </title> <booktitle> In POPL'92 [37], </booktitle> <pages> pages 27-38. </pages>
Reference-contexts: The role of continuations in programming language design and implementation has long been dominated by pragmatic concerns. In the last few years, however, the subject has seen renewed theoretical interest, especially with the introduction of concepts and methods from mathematical logic and category theory, e.g., <ref> [22, 31, 19] </ref>. We believe that any investigation of advanced control structures based on the CPS transform will be able to pick up and integrate such developments more directly than a free-standing approach derived from more intuitively "desirable" operational behavior could.
Reference: [20] <author> Michael J. Fischer. </author> <title> Lambda calculus schemata. </title> <booktitle> In Proceedings of the ACM Conference on Proving Assertions about Programs, </booktitle> <pages> pages 104-109. </pages> <booktitle> SIGPLAN Notices, </booktitle> <volume> Vol. 7, No 1 and SIGACT News, No 14, </volume> <month> January </month> <year> 1972. </year>
Reference-contexts: Section 6 reviews related work on continuations and partial evaluation, and Section 7 concludes. Section A reproduces the development of Section 2 on Plotkin's CPS transformer for n -terms. 2 Classical CPS transformation Let us consider Fischer and Plotkin's equational specification for transforming a v -term into CPS <ref> [20, 35] </ref>, as displayed in Figure 1. Source terms are represented between double brackets and is a fresh variable.
Reference: [21] <author> Pascal Fradet and Daniel Le Metayer. </author> <title> Compilation of functional languages by program transformation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13 </volume> <pages> 21-51, </pages> <year> 1991. </year>
Reference-contexts: However, readability appears to suffer when the continuation argument, which is often large, must be followed by others in an application. Making continuations occur first is used sometimes to compile functional programs by program transformation <ref> [21] </ref>. It is simple to write a one-pass CPS transformer where continuations precede values | just swap values and continuations in any of the specifications displayed in the figures. 5 Abstracting Control So far we have been investigating how to perform the CPS transformation.
Reference: [22] <author> Timothy G. Griffin. </author> <title> A formulae-as-types notion of control. </title> <booktitle> In Proceedings of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 47-58, </pages> <address> San Fran-cisco, California, </address> <month> January </month> <year> 1990. </year> <note> ACM Press. </note>
Reference-contexts: In the new translation, on the other hand, we get a direct correspondence between reduction steps in the original and the translated term. Remark: It does seem possible to modify the colon-translation to perform more ad ministrative reductions at translation time <ref> [22] </ref>. Nevertheless, a practical translation (i.e., for a full language like Scheme) based on such an approach could be awkward because of the combinatorial explosion arising from translation-time distinctions between values and non-values in source terms. 12 Let us first observe a few elementary properties of the two-level translation. <p> The role of continuations in programming language design and implementation has long been dominated by pragmatic concerns. In the last few years, however, the subject has seen renewed theoretical interest, especially with the introduction of concepts and methods from mathematical logic and category theory, e.g., <ref> [22, 31, 19] </ref>. We believe that any investigation of advanced control structures based on the CPS transform will be able to pick up and integrate such developments more directly than a free-standing approach derived from more intuitively "desirable" operational behavior could.
Reference: [23] <author> Ralph E. Griswold and Madge T. Griswold. </author> <title> The Icon Programming Language. </title> <publisher> Prentice-Hall, </publisher> <year> 1983. </year>
Reference-contexts: For example, let us consider a functional representation of "applicative" nondeterministic (in the sense of backtracking) programming, as embodied, e.g., in the programming language Icon <ref> [23] </ref>. Let us define a basic "nondeterministic choice" procedure: flip = ():shift c in @c tt _ @c ff When invoked, flip will "return" twice: once with each possible truth value.
Reference: [24] <author> Bob Harper and Mark Lillibridge. </author> <title> Polymorphic type assignment and CPS conversion. In Danvy and Talcott [12]. </title> <type> Technical report, </type> <institution> Stanford University. </institution>
Reference-contexts: Thus, the translation seems compatible with a restricted variant of ML-style polymorphism in which generalization can only be applied to values <ref> [24] </ref>. 4.2 On duplicating contexts The CPS translation above duplicates contexts for each conditional expression: [[P ! M; N ]] = :@[[P ]] (p:p ! @[[M ]] ; @[[N ]] ) which increases the size of residual terms, as pointed out by Steele [43].
Reference: [25] <author> Neil D. Jones, Peter Sestoft, and Harald Stndergaard. </author> <title> MIX: A self-applicable partial evaluator for experiments in compiler generation. </title> <journal> LISP and Symbolic Computation, </journal> <volume> 2(1) </volume> <pages> 9-50, </pages> <year> 1989. </year>
Reference-contexts: In particular, shift and reset are introduced together as representing composition and identity on continuation functions respectively; proper CPS form is restored by iterating the CPS transformation [10]. 6.4 Partial evaluation Partial evaluation (or more accurately: program specialization <ref> [25] </ref>) makes heavy use of binding time information to process the static and the dynamic semantics of source programs [6], as we do here.
Reference: [26] <institution> Proceedings of the 1990 ACM Conference on Lisp and Functional Programming, Nice, France, </institution> <month> June </month> <year> 1990. </year>
Reference: [27] <institution> Proceedings of the 1992 ACM Conference on Lisp and Functional Programming, </institution> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year> <month> 30 </month>
Reference: [28] <author> Chris Mellish and Steve Hardy. </author> <title> Integrating Prolog in the POPLOG environment. </title> <editor> In John A. Campbell, editor, </editor> <booktitle> Implementations of PROLOG, </booktitle> <pages> pages 147-162. </pages> <publisher> Ellis Horwood, </publisher> <year> 1984. </year>
Reference-contexts: The CPS transformation permits a simple definition of generalized escape constructs like Scheme's call/cc. Such operators are often perceived to eliminate the need for explicit CPS programs. However, sometimes the greater generality of "genuine" CPS is actually needed to express an algorithm (e.g., to implement backtracking <ref> [28] </ref>.) Our investigation of the CPS transform leads naturally to the introduction of two new control operators, shift and reset, which allow the additional power of general CPS to be exploited in direct style programs.
Reference: [29] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Prerequisites In the following, we will assume a basic familiarity with CPS and the v -calculus, i.e., the applicative order -calculus that forms the core of languages such as Scheme [5] and Standard ML <ref> [29] </ref>. For convenience in referring to individual applications, we will generally express them with an explicit operator @, writing @M N instead of the traditional simple juxtaposition M N . This is a purely syntactical variation: no change or refinement of semantics is implied by the @-notation.
Reference: [30] <author> Eugenio Moggi. </author> <title> Computational lambda-calculus and monads. </title> <booktitle> In Proceedings of the Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 14-23, </pages> <address> Pacific Grove, California, </address> <month> June </month> <year> 1989. </year> <note> IEEE. </note>
Reference-contexts: And in fact, recent developments seem to support this conviction [32]. 28 Moreover, there is a close relationship between computational monads <ref> [30] </ref> and "generalized CPS", as suggested in "Abstracting Control" [10] and properly formalized by Wadler [44]. Effectively, this implies that CPS-based control operators like shift and reset can by themselves uniformly express a rich class of computational behaviors, including partiality, nondeterminism, and state.
Reference: [31] <author> Chetan R. Murthy. </author> <title> Extracting Constructive Content from Classical Proofs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1990. </year>
Reference-contexts: transformation [35] is concise and simple, but tends to yield unreasonably large residual terms containing a lot of "administrative redexes." While these redexes turn out to be relatively harmless from a theoretical perspective, they do require a special twist (the so-called "colon-translation") for proving certain important properties of the transformation <ref> [35, 39, 31] </ref>. In practice, eliminating the administrative redexes is absolutely essential to obtain transformed terms of a manageable size. However, such a "post-reduction" pass is often integrated with other, independent simplifications and optimization steps, and leads to relatively complex CPS transformers [43]. <p> The role of continuations in programming language design and implementation has long been dominated by pragmatic concerns. In the last few years, however, the subject has seen renewed theoretical interest, especially with the introduction of concepts and methods from mathematical logic and category theory, e.g., <ref> [22, 31, 19] </ref>. We believe that any investigation of advanced control structures based on the CPS transform will be able to pick up and integrate such developments more directly than a free-standing approach derived from more intuitively "desirable" operational behavior could.
Reference: [32] <author> Chethan R. Murthy. </author> <title> Control operators, hierarchies, and pseudo-classical type systems: A-translation at work. In Danvy and Talcott [12]. </title> <type> Technical report, </type> <institution> Stanford University. </institution>
Reference-contexts: We believe that any investigation of advanced control structures based on the CPS transform will be able to pick up and integrate such developments more directly than a free-standing approach derived from more intuitively "desirable" operational behavior could. And in fact, recent developments seem to support this conviction <ref> [32] </ref>. 28 Moreover, there is a close relationship between computational monads [30] and "generalized CPS", as suggested in "Abstracting Control" [10] and properly formalized by Wadler [44].
Reference: [33] <author> Flemming Nielson. </author> <title> Two-level semantics and abstract interpretation. </title> <journal> Theoretical Computer Science, </journal> <volume> 69(2) </volume> <pages> 117-242, </pages> <year> 1989. </year>
Reference-contexts: Proof: We started from Fischer & Plotkin's specification and altered it in a meaning-preserving way, by introducing three -redexes. We obtained a staged specification where static and dynamic constructs are not only distinct but context-independent. (Using Nielson and Nielson's terminology <ref> [34, 33] </ref>, our two-level specification is "well-typed.") We can now reduce away all the static fi-redexes. Moreover, since the specification is compositional, a simple typing argument suffices to show that it is well-defined for all source terms, i.e., that the static reductions do in fact terminate.
Reference: [34] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> Two-level semantics and code generation. </title> <journal> Theoretical Computer Science, </journal> <volume> 56(1) </volume> <pages> 59-133, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: With its static/dynamic annotations, it can be read as a two-level specification a la Nielson and Nielson <ref> [34] </ref>. Operationally, the overlined 's and @'s correspond to functional abstractions and applications in the translation program, while only the underlined occurrences represent abstract-syntax constructors. Transforming a -term into CPS amounts to representing contexts (i.e., -terms with a hole) as -abstractions. <p> Proof: We started from Fischer & Plotkin's specification and altered it in a meaning-preserving way, by introducing three -redexes. We obtained a staged specification where static and dynamic constructs are not only distinct but context-independent. (Using Nielson and Nielson's terminology <ref> [34, 33] </ref>, our two-level specification is "well-typed.") We can now reduce away all the static fi-redexes. Moreover, since the specification is compositional, a simple typing argument suffices to show that it is well-defined for all source terms, i.e., that the static reductions do in fact terminate. <p> The latter is also central to Shivers's work on higher-order flow analysis [41]. All these concepts were pervasive in our derivation of a one-pass CPS transformer. In particular, the notion of a two-level -calculus as advocated in Nielson and Nielson's TML <ref> [34] </ref> proves useful to develop and to express new CPS transformations that distinguish properly between translation-time and run-time constructs. With respect to partial evaluation, this development illustrates the connection between a CPS transformer and a -calculus interpreter expressed in CPS. The former is a two-level version of the latter.
Reference: [35] <author> Gordon D. Plotkin. </author> <title> Call-by-name, call-by-value and the -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year>
Reference-contexts: 1 Introduction and Motivation The usual presentation of the continuation-passing style (CPS) transformation <ref> [35] </ref> is concise and simple, but tends to yield unreasonably large residual terms containing a lot of "administrative redexes." While these redexes turn out to be relatively harmless from a theoretical perspective, they do require a special twist (the so-called "colon-translation") for proving certain important properties of the transformation [35, 39, <p> transformation [35] is concise and simple, but tends to yield unreasonably large residual terms containing a lot of "administrative redexes." While these redexes turn out to be relatively harmless from a theoretical perspective, they do require a special twist (the so-called "colon-translation") for proving certain important properties of the transformation <ref> [35, 39, 31] </ref>. In practice, eliminating the administrative redexes is absolutely essential to obtain transformed terms of a manageable size. However, such a "post-reduction" pass is often integrated with other, independent simplifications and optimization steps, and leads to relatively complex CPS transformers [43]. <p> Reducing a CPS term with the call-by-name (CBN) or with the call-by-value (CBV) strategies yields the same evaluation steps <ref> [38, 35] </ref>. Overview The rest of this paper is organized as follows. Section 2 describes the stepwise derivation of a one-pass CPS transformer from Plotkin's two-pass equational specification. Theorem 1 states that the one-pass transformer computes a result fi-equivalent to the original Fischer/Plotkin transformation. <p> Section 6 reviews related work on continuations and partial evaluation, and Section 7 concludes. Section A reproduces the development of Section 2 on Plotkin's CPS transformer for n -terms. 2 Classical CPS transformation Let us consider Fischer and Plotkin's equational specification for transforming a v -term into CPS <ref> [20, 35] </ref>, as displayed in Figure 1. Source terms are represented between double brackets and is a fresh variable. <p> Moreover, since we have eliminated all administrative redexes "once and for all", the proofs become considerably simpler than for the unoptimized translation. It may be worth quickly going over why administrative redexes raise problems in the original translation <ref> [35, 39] </ref>. Ideally, the following implication would hold: M ! v N ) @[[M ]] (x:x) ! fl Unfortunately, the administrative redexes get in the way of such a result. <p> One therefore has to prove instead that the implication above holds "modulo administrative reductions". This is formalized by the so-called "colon-translation" developed by Plotkin <ref> [35] </ref>. For any term M and value K, one defines syntactically a term M : K and proves it equal to @[[M ]] K with the first series of administrative reductions performed (i.e., corresponding to the term M 0 above). <p> (a:@ a))) @(@m n) (a:@ a)))[x 0 (V )]))[x 0 (V )] @(@m n) (a:@ a))))[x 0 (V )] = (@[[(@M N )[x x 0 ]]] )[x 0 (V )] The cases for the second equation are analogous. 2 Let us now recall the formal definition of the reduction strategies <ref> [35] </ref>: Definition 3 One-step by-value reduction is defined as follows: @(x:M ) V ! v M [x V ] @M N ! v @M 0 N @V N ! v @V N 0 (where V is a value), and similarly one-step by-name reduction: @(x:M ) N ! n M [x N
Reference: [36] <institution> Proceedings of the Eighteenth Annual ACM Symposium on Principles of Programming Languages, </institution> <address> Orlando, Florida, </address> <month> January </month> <year> 1991. </year> <note> ACM Press. </note>
Reference: [37] <institution> Proceedings of the Nineteenth Annual ACM Symposium on Principles of Programming Languages, </institution> <address> Albuquerque, New Mexico, </address> <month> January </month> <year> 1992. </year> <note> ACM Press. </note>
Reference: [38] <author> John C. Reynolds. </author> <title> Definitional interpreters for higher-order programming languages. </title> <booktitle> In Proceedings of 25th ACM National Conference, </booktitle> <pages> pages 717-740, </pages> <address> Boston, </address> <year> 1972. </year>
Reference-contexts: Note, however, that we adopt this convention only to simplify the presentation, not to advocate a general style of programming which depends implicitly on argument evaluation order. Occasionally, we will use Reynolds's notion of "serious" and "trivial" v -terms <ref> [38] </ref>. <p> Reducing a CPS term with the call-by-name (CBN) or with the call-by-value (CBV) strategies yields the same evaluation steps <ref> [38, 35] </ref>. Overview The rest of this paper is organized as follows. Section 2 describes the stepwise derivation of a one-pass CPS transformer from Plotkin's two-pass equational specification. Theorem 1 states that the one-pass transformer computes a result fi-equivalent to the original Fischer/Plotkin transformation. <p> (the process of computation, possibly error-raising) to be expressed in CPS and the pure (and hence freely rearrangable) function computed, in which case we actually get the best of both worlds. 6.3 Control operators From Reynolds's escape to call/cc in Scheme, control operators are nicely introduced within the CPS transformation <ref> [38, 16] </ref>. However, because CPS appears to constrain expressive power, Felleisen and others have successively proposed new control operators to compose continuations [15] and to limit their extent [14].
Reference: [39] <author> Jon G. Riecke. </author> <title> Should a function continue? Master's thesis, </title> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: transformation [35] is concise and simple, but tends to yield unreasonably large residual terms containing a lot of "administrative redexes." While these redexes turn out to be relatively harmless from a theoretical perspective, they do require a special twist (the so-called "colon-translation") for proving certain important properties of the transformation <ref> [35, 39, 31] </ref>. In practice, eliminating the administrative redexes is absolutely essential to obtain transformed terms of a manageable size. However, such a "post-reduction" pass is often integrated with other, independent simplifications and optimization steps, and leads to relatively complex CPS transformers [43]. <p> Moreover, since we have eliminated all administrative redexes "once and for all", the proofs become considerably simpler than for the unoptimized translation. It may be worth quickly going over why administrative redexes raise problems in the original translation <ref> [35, 39] </ref>. Ideally, the following implication would hold: M ! v N ) @[[M ]] (x:x) ! fl Unfortunately, the administrative redexes get in the way of such a result.
Reference: [40] <author> Amr Sabry and Matthias Felleisen. </author> <title> Reasoning about programs in continuation-passing style. </title> <booktitle> In LFP'92 [27]. </booktitle>
Reference-contexts: Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation <ref> [9, 11, 40] </ref>. 6.2 Primitive operators Most CPS-based compilers [43, 1, 45] and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear.
Reference: [41] <author> Olin Shivers. </author> <title> The semantics of Scheme control-flow analysis. </title> <editor> In Paul Hudak and Neil D. Jones, editors, </editor> <title> Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </title> <journal> SIGPLAN Notices, </journal> <volume> Vol. 26, No 9, </volume> <pages> pages 190-198, </pages> <address> New Haven, Connecticut, June 1991. </address> <publisher> ACM, ACM Press. </publisher>
Reference-contexts: Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation [9, 11, 40]. 6.2 Primitive operators Most CPS-based compilers [43, 1, 45] and program analyzers <ref> [41] </ref> also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear. In particular, the oft-quoted advantage of having explicit names for all subexpressions can be realized equally well with let-expressions. <p> Recent work by Bondorf and the first author emphasize the issues of code duplication and termination properties [3], and use the technique of enumerating finitary constructs [2], as we do in Sections 2 and 4.2. The latter is also central to Shivers's work on higher-order flow analysis <ref> [41] </ref>. All these concepts were pervasive in our derivation of a one-pass CPS transformer. In particular, the notion of a two-level -calculus as advocated in Nielson and Nielson's TML [34] proves useful to develop and to express new CPS transformations that distinguish properly between translation-time and run-time constructs.
Reference: [42] <author> Dorai Sitaram and Matthias Felleisen. </author> <title> Reasoning with continuations II: Full abstraction for models of control. </title> <booktitle> In LFP'90 [26], </booktitle> <pages> pages 161-175. </pages>
Reference-contexts: However, because CPS appears to constrain expressive power, Felleisen and others have successively proposed new control operators to compose continuations [15] and to limit their extent [14]. As later shown by Sitaram and Felleisen <ref> [42] </ref>, inclusion of control delimiters is also necessary to obtain fully abstract models of control for CPS models with 27 escape.
Reference: [43] <author> Guy L. Steele Jr. Rabbit: </author> <title> A compiler for Scheme. </title> <type> Technical Report AI-TR-474, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: In practice, eliminating the administrative redexes is absolutely essential to obtain transformed terms of a manageable size. However, such a "post-reduction" pass is often integrated with other, independent simplifications and optimization steps, and leads to relatively complex CPS transformers <ref> [43] </ref>. In the following, we will consider a systematization of the two-pass CPS transformation by focusing the attention on redexes that are introduced by the transformation itself, and by explicitly not reducing what would correspond to redexes in the source -term. <p> Source terms are represented between double brackets and is a fresh variable. Taken literally, this translation yields many artificial "administrative" redexes that must be post-reduced in a second pass; only then do we obtain a result in what is commonly recognized as "continuation-passing style" <ref> [43] </ref>. <p> Rationale: The auxiliary translation [[:::]] 0 is used when the static continuation would have the form m:@k m; this avoids building an -redex in the transformation of appli cations (hence the term "properly tail-recursive" <ref> [43] </ref>). <p> generalization can only be applied to values [24]. 4.2 On duplicating contexts The CPS translation above duplicates contexts for each conditional expression: [[P ! M; N ]] = :@[[P ]] (p:p ! @[[M ]] ; @[[N ]] ) which increases the size of residual terms, as pointed out by Steele <ref> [43] </ref>. For example, translating the direct style expression @f ((x ! y; z) ! 4; 5) yields the more voluminous :x ! (y ! @(@f 4)(v:@k v) ; @(@f 5)(v:@k v) ) ; and thus a bigger term to compile and correspondingly more object code to produce. <p> Alternatively (by omitting the equations for shift and reset), it translates terms of a Scheme-like language (i.e., -calculus + escape) into standard CPS. Such a transformation has a practical interest for compiling, e.g., Scheme or Standard ML programs <ref> [43, 1] </ref>, and thus constitutes a significant example of using shift/reset: even the pure CPS translation is expressed naturally using the new control operators. As with all meta-circular definitions, we need to bootstrap it. <p> Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation [9, 11, 40]. 6.2 Primitive operators Most CPS-based compilers <ref> [43, 1, 45] </ref> and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear. In particular, the oft-quoted advantage of having explicit names for all subexpressions can be realized equally well with let-expressions.
Reference: [44] <editor> Philip Wadler. </editor> <booktitle> The essence of functional programming. In POPL'92 [37], </booktitle> <pages> pages 1-14. 31 </pages>
Reference-contexts: And in fact, recent developments seem to support this conviction [32]. 28 Moreover, there is a close relationship between computational monads [30] and "generalized CPS", as suggested in "Abstracting Control" [10] and properly formalized by Wadler <ref> [44] </ref>. Effectively, this implies that CPS-based control operators like shift and reset can by themselves uniformly express a rich class of computational behaviors, including partiality, nondeterminism, and state.
Reference: [45] <author> Mitchell Wand. </author> <title> Correctness of procedure representations in higher-order assembly language. </title> <editor> In Steve Brookes, Michael Main, Austin Melton, Michael Mislove, and David Schmidt, editors, </editor> <booktitle> Mathematical Foundations of Programming Semantics, volume 598 of Lecture Notes in Computer Science, </booktitle> <address> Pittsburgh, Pennsylvania, </address> <month> March </month> <year> 1991. </year> <booktitle> 7th International Conference. </booktitle> <volume> 32 [[x]] = x </volume>
Reference-contexts: The first one is Appel's CPS transformer in the Standard ML of New Jersey compiler [1]. The second one is Wand's combinator-based compilation technique <ref> [45] </ref>. But neither motivate their transformer, e.g., as we do in Section 2, nor extend it to control operators or normal order, as we do in Sections 5 and A. <p> Today Sabry and Felleisen are also investigating the CPS transformation in one pass, and Lawall and the first author are investigating the inverse "Direct Style" transformation [9, 11, 40]. 6.2 Primitive operators Most CPS-based compilers <ref> [43, 1, 45] </ref> and program analyzers [41] also use continuation-passing forms of even the primitive operators. However, the practical justification of such a "radical CPS" transform is not completely clear. In particular, the oft-quoted advantage of having explicit names for all subexpressions can be realized equally well with let-expressions.
Reference: [[@M N ]] = <editor> :@[[M ]] (m:@(@m [[N ]]) ) [[:::]] : [syntax ! syntax] ! syntax [[x]] = :@x (a:@ </editor> <publisher> a) </publisher>
Reference: [[@M N ]] = <editor> :@[[M ]] (m:@(@m (k:@[[N ]] (n:@k n))) (a:@ </editor> <publisher> a)) </publisher>
References-found: 47

