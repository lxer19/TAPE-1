URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dbj/www/ftp/wwos92.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dbj/www/other.html
Root-URL: 
Title: Distributed Operating Systems Based on a Protected Global Virtual Address Space  
Author: John B. Carter, Alan L. Cox, David B. Johnson, and Willy Zwaenepoel 
Address: P.O. Box 1892 Houston, TX 77251  
Affiliation: Rice University Department of Computer Science  
Abstract: With the advent of the 64-bit microprocessor, the virtual address space supported by a workstation will be large enough to permit the use of a single shared address space spanning a network of workstations as the primary abstraction provided by a distributed operating system. In such a system, built upon a software distributed shared memory, the programmer has considerable flexibility when choosing a mechanism for interprocess communication. This flexibility permits the programmer to make a case-by-case choice between simplicity and performance when both goals are not simultaneously achievable. With the inclusion of mechanisms supporting protection and fault tolerance, we believe that such a system can provide the advantages of conventional message-based distributed operating systems (e.g., multiple protection domains, hidden data abstractions, simple client-server interface, and failure isolation), in addition to several other benefits (e.g., easy sharing of complex data structures between processes, transparent replication of server functions, and a uniform interface for all communication).
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Atkinson, A. Demers, C. Hauser, C. Jacobi, , P. Kessler, and M. Weiser. </author> <title> Experiences creating a portable Cedar. </title> <booktitle> In Proceedings of the SIGPLAN `89 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining high-performance DSM and RPC mechanisms to provide both data movement and function shipping. <p> the existence of the shared 3 global address space does not force the creation of a large, system-wide checkpoint, since the underlying implementation uses physically separate memories and communication paths that can be recorded. 3 Related Work A number of single address space systems have been built over the years <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
Reference: [2] <author> H.E. Bal and A.S. Tanenbaum. </author> <title> Distributed programming with shared data. </title> <booktitle> In Proceedings of the 1988 International Conference on Computer Languages, </booktitle> <pages> pages 82-91, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [3] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space. <p> Second, implementations of relaxed memory consistency models, such as release consistency [6], that are specifically designed for use by software DSM can significantly reduce the communication that occurs between machines sharing data [8]. Munin <ref> [3] </ref> has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent. Third, with the advent of 64-bit microprocessors, the address space is large enough to name all potential objects in a distributed system.
Reference: [4] <author> J.S. Chase, F.G. Amador, E.D. Lazowska, H.M. Levy, and R.J. Littlefield. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 147-158, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [5] <author> E.N. Elnozahy and W. Zwaenepoel. Manetho: </author> <title> Transparent rollback-recovery with low overhead, limited rollback, and fast output commit. </title> <journal> IEEE Transactions on Computers Special Issue On Fault-Tolerant Computing, </journal> <volume> 41(5), </volume> <month> May </month> <year> 1992. </year> <note> To appear. </note>
Reference-contexts: These messages may be caused either by RPCs or by the protocols used to maintain memory consistency of the global address space. By integrating the fault-tolerance support with the RPC and consistency protocol support, existing distributed system fault-tolerance approaches <ref> [7, 5] </ref> can be used with minor modification.
Reference: [6] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <address> Seattle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: However, the provision of function shipping is necessary when the shared data should not be moved or replicated. Second, implementations of relaxed memory consistency models, such as release consistency <ref> [6] </ref>, that are specifically designed for use by software DSM can significantly reduce the communication that occurs between machines sharing data [8]. Munin [3] has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent.
Reference: [7] <author> D.B. Johnson. </author> <title> Distributed System Fault Tolerance Using Message Logging and Checkpointing. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: These messages may be caused either by RPCs or by the protocols used to maintain memory consistency of the global address space. By integrating the fault-tolerance support with the RPC and consistency protocol support, existing distributed system fault-tolerance approaches <ref> [7, 5] </ref> can be used with minor modification.
Reference: [8] <author> P. Keleher, A. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> To appear at the 19th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Second, implementations of relaxed memory consistency models, such as release consistency [6], that are specifically designed for use by software DSM can significantly reduce the communication that occurs between machines sharing data <ref> [8] </ref>. Munin [3] has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent. Third, with the advent of 64-bit microprocessors, the address space is large enough to name all potential objects in a distributed system.
Reference: [9] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year> <month> 4 </month>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [10] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining high-performance DSM and RPC mechanisms to provide both data movement and function shipping. <p> the existence of the shared 3 global address space does not force the creation of a large, system-wide checkpoint, since the underlying implementation uses physically separate memories and communication paths that can be recorded. 3 Related Work A number of single address space systems have been built over the years <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
Reference: [11] <author> U. Ramachandran and M.Y.A. Khalidi. </author> <title> An implementation of distributed shared memory. </title> <booktitle> Distributed and Multiprocessor Systems Workshop, </booktitle> <pages> pages 21-38, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [12] <author> M.L. Scott, T.J. LeBlanc, and B.D. Marsh. </author> <title> Design rational for Psyche, a general-purpose multiprocessor operating system. </title> <booktitle> In 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 252-262, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining high-performance DSM and RPC mechanisms to provide both data movement and function shipping. <p> the existence of the shared 3 global address space does not force the creation of a large, system-wide checkpoint, since the underlying implementation uses physically separate memories and communication paths that can be recorded. 3 Related Work A number of single address space systems have been built over the years <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
References-found: 12

