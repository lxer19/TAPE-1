URL: http://www.speech.sri.com/people/heck/pubs/avbpa.ps.gz
Refering-URL: http://www.speech.sri.com/people/heck/pubs.html
Root-URL: 
Email: -julia,heck-@speech.sri.com  cheyer@ai.sri.com  
Phone: +1 415 859 42 69  
Title: A Speaker Identification Agent  
Author: Luc E. Julia Larry P. Heck Adam J. Cheyer 
Address: 333 Ravenswood Ave. MENLO PARK, CA 94025 USA  333 Ravenswood Ave. MENLO PARK, CA 94025 USA  
Affiliation: SRI International STAR Laboratory  SRI International Artificial Intelligence Center  
Abstract: This paper describes a prototype application which combines speaker identification technology and an agent architecture to provide user-definable monitors for incoming voicemail messages. Through a Web-distributable Java user interface, the user may enter requests by using spoken or typed natural language. Multiple distributed agents process the requests, periodically testing the user's voicemail system to identify the composer of the message from a set of selected speakers. When a message meets the conditions specified by the user, agents locate the requester's position and notify him or her of the arrival of the important message by using various communication media (email, fax, telephone, pager). The technology responsible for identifying a speaker from voice is a text-independent method developed at SRI International. Encapsulating this capability as an agent permits plug-and-play reusability in the growing number of applications being developed within the agent-based framework.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Automated Office Assistant System: </institution> <note> http://www.ai.sri.com/cgi-bin/oaa/office.pl </note>
Reference-contexts: 1 Introduction For several years, SRI International has been using agent architectures as a means of developing systems by bringing together technologies such as speech recognition, natural language understanding, planning and heterogeneous database access. In one such application, the Automated Office Assistant <ref> [1] </ref>, ten or more distributed agents provide remote access to conventional applications such as databases, calendars and email, through various input modalities, including handwriting, gesture and speech.
Reference: [2] <author> Cheyer A. and Julia L. </author> <year> (1995). </year> <title> Multimodal Maps: An Agent-based Approach. </title> <address> CMC'95 : Eindhoven, Netherlands, </address> <pages> pp. 103-113. </pages>
Reference-contexts: We are currently applying this within an existing multimodal (pen and voice) map-based application <ref> [2] </ref>. In this application, no matter what machine or location the user is running the application from, the system will set up the user's preferences according to the identification made during the first interactions.
Reference: [3] <institution> CIC Signature Sentinel TM : http://www.cic.com </institution>
Reference-contexts: In parallel, selected handwriting and gesture inputs are analyzed using SigCheck, CIC's dynamic handwriting verification technology <ref> [3] </ref>. Another application that we are ready to put together is an intelligent answering machine.
Reference: [4] <author> Heck L.P. and Weintraub M. </author> <year> (1997). </year> <title> Handset-Dependent Background Models for Robust Text-Independent Speaker Recognition. </title> <booktitle> Submitted to IEEE Proc. Intern. Conf. on Acoust., Speech, and Signal Proc.: </booktitle> <address> Munich, Germany. </address>
Reference-contexts: In addition, the architecture allows independence and cooperation between agents - as agents dynamically connect to the system, new capabilities become available to the user. Recently, SRI's speech laboratory developed an original set of methods to identify a speaker by his or her voice <ref> [4] </ref>. The Speaker Recognition System does not require knowledge or constraints on the spoken text, and is therefore suited for identifying persons from conversational-style voicemail messages. <p> The front-end processing of the speech occurs in several steps. First, the speech is segmented into frames by a sliding 25ms window progressing at a 10ms frame rate. Next, mel-scale cepstral feature vectors are extracted from the speech frames <ref> [4] </ref>. In this work, we use 17th-order mel-cepstra, with the 0th-order term removed. Finally, the feature vectors are channel equalized with a blind deconvolution. The deconvolution is implemented by subtracting the average cepstral vector from each input phone message. <p> & & ... is computed as ( ) ( ) T k t k T = 1 & For openset voicemail speaker detection, a likelihood ratio detector is used that normalizes the score of the claimant speaker by the score of a single composite model of all other impostor speakers <ref> [4] </ref>. In the log-domain, the ratio can be expressed as a difference of terms, ( ) ( ) ( ) k k where k denotes the composite impostor model. <p> Composite models are much simpler to implement than cohort models, and have been shown to outperform cohort models on the May 1995 and March 1996 NIST Evaluation Corpora from Switchboard <ref> [4] </ref>. For the voicemail system described in this paper, we empirically determined the best number of mixtures in the composite model to be 2048 Gaussians. 4 Training and Execution The speaker identification technology requires training to acquire a set of registered "known" users of the system. <p> Once the system has been run over the training data, the Speaker Identification Agent is capable of recognizing voices given as little as 5 s of text-independent speech. The performance of our system was evaluated in the March and July 1996 NIST speaker recognition benchmarks <ref> [4] </ref>. The evaluations utilized the Switchboard database, which is a collection of long-distance telephone conversations with unconstrained vocabulary. The test was similar to the voicemail task described in this paper, although somewhat more difficult because less data was used to train the system (2 min).
Reference: [5] <author> Higgins A., Bahler L. and Porter J. </author> <year> (1992). </year> <title> Speaker verification using randomized phrase prompting. </title> <booktitle> Digital Signal Processing, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 89-106. </pages>
Reference: [6] <institution> Open Agent Architecture TM : http://www.ai.sri.com/~oaa </institution>
Reference-contexts: In one such application, the Automated Office Assistant [1], ten or more distributed agents provide remote access to conventional applications such as databases, calendars and email, through various input modalities, including handwriting, gesture and speech. Agents implemented in SRI's Open Agent Architecture (OAA) <ref> [6] </ref> hide the complexities of finding, accessing and combining data to meet a user's requests; users need not know where their requests are being executed, nor how.
Reference: [7] <author> Reynolds D.A. </author> <year> (1995). </year> <title> Speaker identification and verification using Gaussian mixture speaker models. </title> <journal> Speech Communications, </journal> <volume> Vol. 17, </volume> <pages> pp. 91-108. </pages>
Reference-contexts: The GMMs are used to represent the acoustic parameter distribution of each claimant speaker, ( ) p x p b x k k i = 1 where p i i k are the mixture weight and the Gaussian density for the i th mixture out of M for speaker k <ref> [7] </ref>.
Reference: [8] <author> Rosenberg A.E., DeLong J., Lee C.H., Juang B.H. and Soong F.K. </author> <year> (1992). </year> <title> The use of cohort normalized scores for speaker verification. </title> <booktitle> IEEE Proc. Intern. Conf. Speech and Signal Proc., </booktitle> <pages> pp. 599-602. </pages>
References-found: 8

