URL: http://www.research.microsoft.com/apl/marmot.ps
Refering-URL: http://www.research.microsoft.com/apl/
Root-URL: http://www.research.microsoft.com
Title: Marmot: an Optimizing Compiler for Java  
Author: Robert Fitzgerald, Todd B. Knoblock, Erik Ruf, Bjarne Steensgaard, and David Tarditi 
Date: October 29, 1998.  
Note: Draft of  
Affiliation: Microsoft Research  
Abstract: Performance optimizations for high level languages are best developed and evaluated in the context of an optimizing compiler and an e-cient runtime system. To this end, we have constructed Marmot, a native compiler and runtime system for Java. Marmot is a complete system, using well-known scalar, object, and low-level optimizations, without reliance on external (flxed) compilers, back ends, runtime systems, or libraries. Initial performance results demonstrate that Marmot is competitive with existing Java systems, and suggests targets for future optimization research. 
Abstract-found: 1
Intro-found: 1
Reference: [App98] <author> Andrew W. Appel. </author> <title> Modern Compiler Implementa-ton in Java. </title> <publisher> Cambridge University Press, </publisher> <year> 1998. </year>
Reference-contexts: (v)[t 1 ; : : : ; t n ] Multiway transfer, t 1 ; : : : ; t n are the case tag constants. 2.2.1 Representing Exceptions and Handlers in JIR In order to represent exception handlers, the basic blocks of JIR difier from the classic deflnition (e.g., <ref> [ASU86, App98, Muc97] </ref>) in that they are single entry, but multiple exit. In addition, basic blocks are not terminated at function call boundaries. <p> Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound <ref> [App98] </ref>. Also, the common subexpres-sion elimination optimization removes fully redundant checks. The remaining bounds checks are optimized in two phases. First, the available inequality facts relating locals and constants in a method are collected using a dataow analysis.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jefirey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <address> Ad-dison-Wesley, Reading, MA, USA, </address> <year> 1986. </year>
Reference-contexts: (v)[t 1 ; : : : ; t n ] Multiway transfer, t 1 ; : : : ; t n are the case tag constants. 2.2.1 Representing Exceptions and Handlers in JIR In order to represent exception handlers, the basic blocks of JIR difier from the classic deflnition (e.g., <ref> [ASU86, App98, Muc97] </ref>) in that they are single entry, but multiple exit. In addition, basic blocks are not terminated at function call boundaries. <p> meta-class layout has been determined, MIR conversion is able to statically construct the required meta-data instances for all class and array types. 2.8.2 Converting Methods to MIR For each JIR basic block in the CFG and updates the JIR basic block Marmot converts methods to MIR procedures using syntax-directed translation <ref> [ASU86] </ref>. For each JIR block in the JIR CFG, it creates a corresponding MIR block, then translates each statement in the JIR block to one or more MIR statements in the MIR block.
Reference: [Asu91] <author> Jonathan M. Asuru. </author> <title> Optimization of array subscript range checks. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(2) </volume> <pages> 109-118, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [Bac97] <author> David F. Bacon. </author> <title> Fast and Efiective Optimization of Statically Typed ObjectOriented Languages. </title> <type> PhD thesis, </type> <institution> U.C. Berkeley, </institution> <month> October </month> <year> 1997. </year>
Reference-contexts: This is similar to the Rapid Type Analysis algorithm of Bacon <ref> [Bac97] </ref>, except that IIA does not rely on a precomputed call graph, eliminating the need for an explicit Class Hierarchy Analysis [DGC95] pass. We use an explicit annotation mech mutation. 5 anism to document the invocation and instantiation be-havior of native methods in our library code. <p> Marmot optimizes the singlethreaded case by using the IIA to detect that no thread objects are started, allowing it to remove all synchronization operations from the program before further optimizations are performed. Similar analyses appear in Bacon <ref> [Bac97] </ref> and Muller et al. [MMBC97]. 2.6.4 Phase Ordering briey describe the phases here. Because SSA conversion and type elaboration are relatively expensive, it is profltable to run the treeshake optimization to remove unused methods from the representation prior to conversion.
Reference: [BCHS88] <author> Preston Briggs, Keith D. Cooper, Timothy J. Har-vey, and L. Taylor Simpson. </author> <title> Practical improvements to the construction and destruction of static single assignment form. </title> <journal> Software: Practice and Experience, </journal> <volume> 1(1), </volume> <month> January </month> <year> 1988. </year>
Reference-contexts: Choi et al. [CSS96] describe phi maintenance for several loop transformations, but do not give a solution for general CFG maintenance is often the most di-cult implementation task (and largest compilation-time cost) in Marmot optimizations. Briggs et al. <ref> [BCHS88] </ref> noted that systems treating all phi operations in a basic block as parallel assignments may require a scheduling pass to properly serialize these assignments during the phi elimination phase.
Reference: [BCT94] <author> Preston Briggs, Keith D. Cooper, and Linda Torc-zon. </author> <title> Improvements to graph coloring register allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(3) </volume> <pages> 428-455, </pages> <month> May </month> <year> 1994. </year> <month> 14 </month>
Reference-contexts: Third, it eliminates dead and unreachable code. Finally, it does peephole optimizations. Marmot does not yet do instruction scheduling. 2.10 Register Allocation Marmot uses graph-coloring register allocation in the style of Chaitin [CAC + 81, Cha82], incorporating improvements to the coloring process suggested by Briggs et al. <ref> [BCT94] </ref>. The allocator has flve phases: 1. The flrst phase eliminates high-level procedure calls, returns, and throws. It does this by introducing appropriate low-level control transfer instructions and making parameter passing and value return explicit as moves between physical locations and pseudo-registers. 2. <p> The second phase eliminates unnecessary register moves by coalescing pseudo-registers. It coalesces registers aggressively and does not use the more conservative heuristics suggested by <ref> [BCT94, 8 GA96] </ref>. The phase rewrites the intermediate form after each pass of coalescing and iterates until no register coalesces occur. 3. The third phase, which is performed lazily, estimates the cost of spilling each pseudo-register. <p> It sums all occurrences of each pseudo-register, weighting each occurrence of a register by 10 n , where n is the loop-nesting depth of that occur rence. 4. The fourth phase attempts to flnd a coloring using optimistic coloring <ref> [BCT94] </ref>. If at some point coloring stops because no colors are available (and hence a register must be spilled), the phase removes the pseudo-register with the lowest spilling cost from the interference graph and continues coloring.
Reference: [BKMS98] <author> David F. Bacon, Ravi Konuru, Chet Murthy, and Mauricio Serrano. </author> <title> Thin locks: Featherweight synchronization for Java. </title> <booktitle> In Proceedings of the SIG-PLAN '98 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-268, </pages> <month> June </month> <year> 1998. </year>
Reference-contexts: The most prominent is synchronization state for synchronized statements and methods and for the wait () and notify () methods of java.lang.Object. It also incorporates a hash-code used by java.lang.Object.hashCode (). Bacon et al. <ref> [BKMS98] </ref> describes a similar scheme to reduce space overhead due to synchronization. 2.11.2 Interfaces Marmot implements interface dispatch via a per-class data structure called an interface table, or itable. A class's vtable contains one itable for each interface the class implements.
Reference: [Bri92] <author> Preston Briggs. </author> <title> Register Allocation via Graph Coloring. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Operations including cast, array store and instanceof checks, java.lang.System.arraycopy (), thread synchronization and interface call lookup are implemented in Java. 6 See <ref> [Bri92] </ref> for a detailed description of when this can be done. 2.11.1 Data Layout Every object has a vtable pointer and a monitor pointer as its flrst two flelds. The remaining flelds contain the object's instance variables, except for arrays, where they contain the length fleld and array contents.
Reference: [BS96] <author> David F. Bacon and Peter F. Sweeney. </author> <title> Fast static analysis of C++ virtual function calls. </title> <booktitle> In Proceedings OOPSLA '96, ACM SIGPLAN Notices, </booktitle> <pages> pages 324-341, </pages> <month> October </month> <year> 1996. </year> <title> Published as Proceedings OOPSLA '96, </title> <journal> ACM SIGPLAN Notices, </journal> <volume> volume 31, number 10. </volume>
Reference-contexts: To this end, we have built Marmot, a bytecode-to-native-code compiler, runtime system, and library for Java. Marmot is Current: Marmot implements both standard scalar optimizations (of the sort found in Fortran, C and C++ [Muc97]) and basic objectoriented optimizations such as call binding based on class hierarchy analysis <ref> [BS96, DGC95] </ref>. Modern representation techniques such as SSA and type-based compilation [CFR + 89, Tar96] are also used. These improve optimizations and support tracing garbage collection. Complete: Marmot implements all Java language features except dynamic class loading and reection 1 .
Reference: [CAC + 81] <author> Gregory J. Chaitin, Marc A. Auslander, Ashok K. Chandra, John Cocke, Martin E. Hopkins, and Peter W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6(1) </volume> <pages> 47-57, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: Second, Marmot replaces unconditional jumps to control instructions and conditional branches to unconditional jumps. Third, it eliminates dead and unreachable code. Finally, it does peephole optimizations. Marmot does not yet do instruction scheduling. 2.10 Register Allocation Marmot uses graph-coloring register allocation in the style of Chaitin <ref> [CAC + 81, Cha82] </ref>, incorporating improvements to the coloring process suggested by Briggs et al. [BCT94]. The allocator has flve phases: 1. The flrst phase eliminates high-level procedure calls, returns, and throws.
Reference: [CC77] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: A unifled lattice model for static analysis of programs by construction or approximation of flxpoints. </title> <booktitle> In Proceedings of the Fourth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <address> Los Angeles, </address> <month> January </month> <year> 1977. </year>
Reference-contexts: Initial conversion to a temporary-variable based in termediate representation. 2. Conversion to static single assignment form. 3. Type elaboration. The next three sections describe these steps. 2.3 Initial Conversion The initial conversion from bytecode to JIR uses an abstract interpretation algorithm <ref> [CC77] </ref>. An abstraction of the bytecode VM stack is built and the efiects of the bytecode execution stream are modeled. A temporary variable is associated with each stack depth, temp 0 for the bottom-of-stack value, temp 1 for depth 1, and so forth.
Reference: [CFR + 89] <author> Ron Cytron, Jeanne Ferrante, Berry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> An e-cient method of computing static single assignment form. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1989. </year>
Reference-contexts: Marmot is Current: Marmot implements both standard scalar optimizations (of the sort found in Fortran, C and C++ [Muc97]) and basic objectoriented optimizations such as call binding based on class hierarchy analysis [BS96, DGC95]. Modern representation techniques such as SSA and type-based compilation <ref> [CFR + 89, Tar96] </ref> are also used. These improve optimizations and support tracing garbage collection. Complete: Marmot implements all Java language features except dynamic class loading and reection 1 . <p> This lowering to explicitly represented operations is done to make the operations available for further analysis and optimization. 2.4 Static Single Assignment Conversion The second step of converting from bytecode to JIR is conversion to static single assignment (SSA) form <ref> [CFR + 89, CFRW91] </ref>. The conversion is based upon Lengauer and Tarjan's dominator tree algorithm [LT79] and Sreedhar and Gao's phi placement algorithm [SG95]. Conversion is complicated by the presence of exception-handling edges, which must be considered during the computation of iterated dominance frontiers.
Reference: [CFRW91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, and Mark N. Wegman. </author> <title> E-ciently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: This lowering to explicitly represented operations is done to make the operations available for further analysis and optimization. 2.4 Static Single Assignment Conversion The second step of converting from bytecode to JIR is conversion to static single assignment (SSA) form <ref> [CFR + 89, CFRW91] </ref>. The conversion is based upon Lengauer and Tarjan's dominator tree algorithm [LT79] and Sreedhar and Gao's phi placement algorithm [SG95]. Conversion is complicated by the presence of exception-handling edges, which must be considered during the computation of iterated dominance frontiers.
Reference: [CG95] <author> Wei-Ngan Chin and Eak-Khoon Goh. </author> <title> A reexamination of "optimization of array subscript range checks". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(2) </volume> <pages> 217-227, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [Cha82] <author> G.J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In Proceedings of the ACM SIG-PLAN '82 Symposium on Compiler Construction, </booktitle> <pages> pages 98-105, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Second, Marmot replaces unconditional jumps to control instructions and conditional branches to unconditional jumps. Third, it eliminates dead and unreachable code. Finally, it does peephole optimizations. Marmot does not yet do instruction scheduling. 2.10 Register Allocation Marmot uses graph-coloring register allocation in the style of Chaitin <ref> [CAC + 81, Cha82] </ref>, incorporating improvements to the coloring process suggested by Briggs et al. [BCT94]. The allocator has flve phases: 1. The flrst phase eliminates high-level procedure calls, returns, and throws.
Reference: [CL98a] <author> Patrick Chan and Rosanna Lee. </author> <title> The Java Class Libraries, volume 1. </title> <publisher> Addison-Wesley, </publisher> <address> second editon edition, </address> <year> 1998. </year>
Reference-contexts: It is not a general solution, but it has su-ced for our library development. 2.12 Libraries Marmot uses a set of libraries written from speciflca-tions of the Java 1.1 class libraries <ref> [CL98a, CL98b] </ref>. The java.lang, java.util, java.io, and java.awt packages are mostly complete. Individual classes in other packages have been implemented as required. Some methods have not yet been updated to provide full UNI-CODE support. The AWT library currently only supports the Java 1.1 event model.
Reference: [CL98b] <author> Patrick Chan and Rosanna Lee. </author> <title> The Java Class Libraries, volume 2. </title> <publisher> Addison-Wesley, </publisher> <address> second editon edition, </address> <year> 1998. </year>
Reference-contexts: It is not a general solution, but it has su-ced for our library development. 2.12 Libraries Marmot uses a set of libraries written from speciflca-tions of the Java 1.1 class libraries <ref> [CL98a, CL98b] </ref>. The java.lang, java.util, java.io, and java.awt packages are mostly complete. Individual classes in other packages have been implemented as required. Some methods have not yet been updated to provide full UNI-CODE support. The AWT library currently only supports the Java 1.1 event model.
Reference: [CMCH91] <author> Pohua P. Chang, Scott A. Mahlke, William Y. Chen, and Wen-mei W. Hwu. </author> <title> Proflle-guided automatic inline expansion for c programs. </title> <journal> Software: Practice and Experience, </journal> <volume> 22(5) </volume> <pages> 349-369, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In this sense, JIR basic blocks are similar to superblocks <ref> [CMCH91] </ref>. The conversion of bytecode to JIR proceeds in three steps: 1. Initial conversion to a temporary-variable based in termediate representation. 2. Conversion to static single assignment form. 3. Type elaboration.
Reference: [CSS96] <author> Jong-Deok Choi, Vivek Sarkar, and Edith Schon-berg. </author> <title> Incremental computation of static single assignment form. </title> <booktitle> In CC '96: Sixth International Conference on Compiler Construction, </booktitle> <volume> LNCS 1060, </volume> <pages> pages 223-237, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: After initial conversion, that base no longer exists. Since converting out of and back into SSA form on each CFG edit would be prohibitively expensive, we are forced to write custom phi-maintenance code for each CFG transformation. Choi et al. <ref> [CSS96] </ref> describe phi maintenance for several loop transformations, but do not give a solution for general CFG maintenance is often the most di-cult implementation task (and largest compilation-time cost) in Marmot optimizations.
Reference: [DDG + 96] <author> Jefirey Dean, Greg DeFouw, David Grove, Vassily Litvinov, and Craig Chambers. </author> <title> Vortex: An optimizing compiler for objectoriented languages. </title> <booktitle> In Proceedings OOPSLA '96, ACM SIGPLAN Notices, </booktitle> <pages> pages 83-100, </pages> <month> October </month> <year> 1996. </year> <title> Published as Proceedings OOPSLA '96, </title> <journal> ACM SIGPLAN Notices, </journal> <volume> volume 31, number 10. </volume>
Reference-contexts: The IMPACT NET compiler [HGH96, HCJ + 97] uses the IMPACT optimizing compiler back end. The Java compiler from the Ce-cil/Vortex project <ref> [DDG + 96] </ref> uses the Vortex compiler back end. The Vortex runtime system includes a nonconservative garbage collector tuned for Cecil programs; the other systems retroflt (conservative) garbage collectors into their runtime systems since the systems were not designed for tracing collection.
Reference: [DE73] <author> George B. Dantzig and B. Curtis Eaves. </author> <title> Fourier-Motzkin elimination and its dual. </title> <journal> Journal of Combinatorial Theory (A), </journal> <volume> 14 </volume> <pages> 288-297, </pages> <year> 1973. </year>
Reference-contexts: Sources of facts are control ow branching, array creation, and available array bounds checks. To these facts are added additional facts derived from bounds and monotonicity of induction variables. Second, an inequality decision procedure, Fourier elimination <ref> [DE73, Duf74, Wil76] </ref>, is used at each array bounds check to determine if the check is redundant relative to the available facts. If both the lower- and upper-bound checks are redundant, then the bounds check is removed.
Reference: [DGC95] <author> Jefirey Dean, David Grove, and Craig Chambers. </author> <title> Optimization of objectoriented programs using static class hierarchy analysis. </title> <editor> In W. Olthofi, editor, </editor> <booktitle> Proceedings ECOOP'95, </booktitle> <volume> LNCS 952, </volume> <pages> pages 77-101, </pages> <address> Aarhus, Denmark, </address> <month> August </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: To this end, we have built Marmot, a bytecode-to-native-code compiler, runtime system, and library for Java. Marmot is Current: Marmot implements both standard scalar optimizations (of the sort found in Fortran, C and C++ [Muc97]) and basic objectoriented optimizations such as call binding based on class hierarchy analysis <ref> [BS96, DGC95] </ref>. Modern representation techniques such as SSA and type-based compilation [CFR + 89, Tar96] are also used. These improve optimizations and support tracing garbage collection. Complete: Marmot implements all Java language features except dynamic class loading and reection 1 . <p> This is similar to the Rapid Type Analysis algorithm of Bacon [Bac97], except that IIA does not rely on a precomputed call graph, eliminating the need for an explicit Class Hierarchy Analysis <ref> [DGC95] </ref> pass. We use an explicit annotation mech mutation. 5 anism to document the invocation and instantiation be-havior of native methods in our library code. Marmot uses the results of this analysis in several ways.
Reference: [DMM98] <author> Amer Diwan, Kathryn S. McKinley, and J. Eliot B. Moss. </author> <title> Type-based alias analysis. </title> <booktitle> In Proceedings of the SIGPLAN '98 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 106-117, </pages> <month> June </month> <year> 1998. </year>
Reference-contexts: In isolation, the latter technique is not very efiective due to the imprecision of the IIA (e.g., java.lang.Object [] could conceivably denote any instantiated reference array type). Marmot addresses this limitation by adding a simple global analysis (similar to type-based alias analysis <ref> [DMM98] </ref>) which computes a ow-insensitive alias relation on instantiated array types. The resulting improvement in precision allows the removal of additional array store checks. Because Java programs may execute multiple threads simultaneously, many of the methods in the standard library guard potential critical sections with synchronization operations.
Reference: [Duf74] <author> R. J. </author> <title> Dun. On Fourier's analysis of linear inequality systems. </title> <booktitle> In Mathematical Programming Study 1, </booktitle> <pages> pages 71-95. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: Sources of facts are control ow branching, array creation, and available array bounds checks. To these facts are added additional facts derived from bounds and monotonicity of induction variables. Second, an inequality decision procedure, Fourier elimination <ref> [DE73, Duf74, Wil76] </ref>, is used at each array bounds check to determine if the check is redundant relative to the available facts. If both the lower- and upper-bound checks are redundant, then the bounds check is removed.
Reference: [GA96] <author> Lal George and Andrew W. Appel. </author> <title> Iterated register coalescing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(3) </volume> <pages> 300-324, </pages> <month> May </month> <year> 1996. </year>
Reference: [GP97] <author> William G. Griswold and Paul S. Phillips. </author> <title> Bill and paul's excellent ucsd benchmarks for java (version 1.1). </title> <note> http://www-cse.ucsd.edu/users/wgg/JavaProf/javaprof.html, October 1997. </note>
Reference-contexts: UCSD Benchmarks for Java <ref> [GP97] </ref>, modifled them to prevent the compilers from doing inlining, loop hoisting, etc., and added tests for other things we wanted to measure. Marmot generated code was generally comparable with code generated by the other systems.
Reference: [GS98] <author> David Gay and Bjarne Steensgaard. </author> <title> Stack allocating objects in Java. </title> <note> In preparation, </note> <year> 1998. </year>
Reference-contexts: The allocation is then moved up the call graph into the lifetime-dominating method, while a storage pointer is passed downward so that the object can be initialized at its original allocation site. See Gay and Steens-gaard <ref> [GS98] </ref> for details of this optimization. 2.6.3 Java-Speciflc Optimizations To date, work on Marmot has concentrated on efiorts to implement fairly standard scalar and objectoriented optimizations in the context of Java; thus, the present version of the optimizer contains relatively few transformations speciflc to the Java programming language.
Reference: [Gup90] <author> Rajiv Gupta. </author> <title> A fresh look at optimizing array bound checking. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 272-282, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [Gup93] <author> Rajiv Gupta. </author> <title> Optimizing array bound checks using ow analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 2(1-4):135-150, </volume> <month> March-December </month> <year> 1993. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [HBG + 97] <author> Urs Holzle, Lars Bak, Stefien Grarup, Robert Griesemer, and Srdjan Mitrovic. </author> <title> Java on steroids: Sun's high-performance Java implementation. Presentation at Hot Chips IX, </title> <publisher> Stanford, </publisher> <address> California, USA, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: Tower Technology's TowerJ [Tow98] generates native code for numerous platforms (machine architectures and operating systems) while SuperCede [Sup98] and Symantec's Visual Cafe [Sym98] generate native code for x86 systems. These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler <ref> [HBG + 97] </ref> uses technology similar to that of the Self compilers. Optimizations are based on measured runtime behavior, with recompilation and optimization being performed while the program is running. Instantiations' Jove compiler [Ins98] and Natural-Bridge's BulletTrain compiler [Nat98] both employ static whole-program analysis and optimization.
Reference: [HCJ + 97] <author> Cheng-Hsueh A. Hsieh, Marie T. Conte, Teresa L. Johnson, John C. Gyllenhaal, and Wen-mei W. Hwu. </author> <title> Optimizing NET compilers for improved Java performance. </title> <journal> Computer, </journal> <volume> 30(6) </volume> <pages> 67-75, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: The IMPACT/NET project <ref> [HGH96, HCJ + 97] </ref> has transliterated a variety of C/C++ benchmark programs to Java, making such comparisons possible. Figure 6 shows the performance of Java programs compiled by Marmot relative to corresponding C/C++ programs compiled by Microsoft Visual C++ version 6.0. <p> The IBM High Performance Compiler for Java uses the common back end from IBM's XL compilers. j2s from UCSB [KH97] and j2s from University of Colorado [MDG97] both use the SUIF system. The IMPACT NET compiler <ref> [HGH96, HCJ + 97] </ref> uses the IMPACT optimizing compiler back end. The Java compiler from the Ce-cil/Vortex project [DDG + 96] uses the Vortex compiler back end.
Reference: [HGH96] <author> Cheng-Hsueh A. Hsieh, John C. Gyllenhaal, and Wen-mei W. Hwu Hwu. </author> <title> Java bytecode to native code translation: The Cafieine prototype and preliminary results. </title> <booktitle> In IEEE Proceedings of the 29th Annual International Symposium on Microarchi-tecture, </booktitle> <year> 1996. </year>
Reference-contexts: The IMPACT/NET project <ref> [HGH96, HCJ + 97] </ref> has transliterated a variety of C/C++ benchmark programs to Java, making such comparisons possible. Figure 6 shows the performance of Java programs compiled by Marmot relative to corresponding C/C++ programs compiled by Microsoft Visual C++ version 6.0. <p> Eliminating all the checks provides an upper bound on how much performance can be gained by semantics-preserving optimizations to eliminate the checks. It is interesting to note that for the smaller micro-benchmarks, array bounds checks consume 8-10% of execution time, consistent with earlier observations <ref> [HGH96] </ref>. However, as program sizes increase and more diverse data structures are used, the relative signiflcance of bounds checks decreases. In many small SPEC-like benchmark programs, the cost of array store checks and dynamic casts was quite 11 J++ = 1). <p> The IBM High Performance Compiler for Java uses the common back end from IBM's XL compilers. j2s from UCSB [KH97] and j2s from University of Colorado [MDG97] both use the SUIF system. The IMPACT NET compiler <ref> [HGH96, HCJ + 97] </ref> uses the IMPACT optimizing compiler back end. The Java compiler from the Ce-cil/Vortex project [DDG + 96] uses the Vortex compiler back end.
Reference: [Ins98] <author> Instantiations, Inc. Jove: </author> <title> Super optimizing deployment environment for Java. </title> <note> http://www.instantiations.com/javaspeed/jovereport.htm, July 1998. </note>
Reference-contexts: These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler [HBG + 97] uses technology similar to that of the Self compilers. Optimizations are based on measured runtime behavior, with recompilation and optimization being performed while the program is running. Instantiations' Jove compiler <ref> [Ins98] </ref> and Natural-Bridge's BulletTrain compiler [Nat98] both employ static whole-program analysis and optimization. They include their own runtime systems.
Reference: [KH97] <author> Holger Kienle and Urs Holzle. j2s: </author> <title> A SUIF Java compiler. </title> <booktitle> In Proceedings of the Second SUIF Compiler Workshop, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Other Java compiler projects statically compile Java source or Java bytecodes via an existing back end which is already used to compile other languages. The IBM High Performance Compiler for Java uses the common back end from IBM's XL compilers. j2s from UCSB <ref> [KH97] </ref> and j2s from University of Colorado [MDG97] both use the SUIF system. The IMPACT NET compiler [HGH96, HCJ + 97] uses the IMPACT optimizing compiler back end. The Java compiler from the Ce-cil/Vortex project [DDG + 96] uses the Vortex compiler back end.
Reference: [Kno98] <author> Todd B. Knoblock. </author> <title> Array bounds check optimizations for Java. </title> <note> In preparation, </note> <year> 1998. </year>
Reference-contexts: Second, an inequality decision procedure, Fourier elimination [DE73, Duf74, Wil76], is used at each array bounds check to determine if the check is redundant relative to the available facts. If both the lower- and upper-bound checks are redundant, then the bounds check is removed. See Knoblock <ref> [Kno98] </ref> for additional information on array bounds check optimizations in Marmot. 2.6.2 ObjectOriented Optimizations Marmot's objectoriented optimizations are implemented using a combination of inter-module ow-insensitive and permethod ow-sensitive techniques. The instantiation and invocation analysis, IIA, simultaneously computes conservative approximations of the sets of instantiated classes and invoked methods.
Reference: [KW95] <author> Priyadarshan Kolte and Michael Wolfe. </author> <title> Elimination of redundant array subscript range checks. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 270-278, </pages> <year> 1995. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [LT79] <author> Thomas Lengauer and Robert Endre Tarjan. </author> <title> A fast algorithm for flnding dominators in a ow-graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 121-141, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: The conversion is based upon Lengauer and Tarjan's dominator tree algorithm <ref> [LT79] </ref> and Sreedhar and Gao's phi placement algorithm [SG95]. Conversion is complicated by the presence of exception-handling edges, which must be considered during the computation of iterated dominance frontiers.
Reference: [LY97] <author> Tim Lindholm and Frank Yellin. </author> <title> The Java Virtual Machine Speciflcation. The Java Series. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, USA, </address> <year> 1997. </year> <month> 15 </month>
Reference-contexts: The following sections describe the more important representations and optimizations following the order of their use. 2.1 Bytecode Marmot takes verifled Java bytecode <ref> [LY97] </ref> as input. Compiling a Java program begins with a class flle containing the main method. This class is converted and all statically referenced classes in it are queued for processing. The conversion continues from the work queue until the transitive closure of all reachable classes have been converted. <p> is declared in a superinterface can be given a slot of m from a su-perinterface. 7 All new methods declared in I can be placed after all the itables for the direct superinterfaces of I. 2.11.3 Exceptions Marmot uses the same kind of program-counter-based exception handling mechanism that Java bytecode <ref> [LY97] </ref> uses. Memory containing Marmot-generated machine code is divided into ranges, each of which is associated with a list of exception handlers.
Reference: [MCM82] <author> Victoria Markstein, John Cocke, and Peter Mark--stein. </author> <title> Optimization of range checking. </title> <booktitle> In Proceedings of the ACM SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <pages> pages 114-119, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran <ref> [MCM82, Gup90, Asu91, Gup93, CG95, KW95] </ref> and other contexts [SI77, XP98]. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks.
Reference: [MDG97] <author> Sumith Mathew, Eric Dahlman, and Sandeep Gupta. </author> <title> Compiling Java to SUIF: Incorporating support for objectoriented languages. </title> <booktitle> In Proceedings of the Second SUIF Compiler Workshop, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: The IBM High Performance Compiler for Java uses the common back end from IBM's XL compilers. j2s from UCSB [KH97] and j2s from University of Colorado <ref> [MDG97] </ref> both use the SUIF system. The IMPACT NET compiler [HGH96, HCJ + 97] uses the IMPACT optimizing compiler back end. The Java compiler from the Ce-cil/Vortex project [DDG + 96] uses the Vortex compiler back end.
Reference: [MMBC97] <author> Gilles Muller, Barbara Moura, Fabrice Bellard, and Charles Consel. Harissa: </author> <title> a exible and e-cient Java environment mixing bytecode and compiled code. </title> <booktitle> In Proceedings of the Third Conference on Object-Oriented Technologies and Sytems (COOTS '97), </booktitle> <year> 1997. </year>
Reference-contexts: Marmot optimizes the singlethreaded case by using the IIA to detect that no thread objects are started, allowing it to remove all synchronization operations from the program before further optimizations are performed. Similar analyses appear in Bacon [Bac97] and Muller et al. <ref> [MMBC97] </ref>. 2.6.4 Phase Ordering briey describe the phases here. Because SSA conversion and type elaboration are relatively expensive, it is profltable to run the treeshake optimization to remove unused methods from the representation prior to conversion. This pass also detects singlethreaded code and removes synchronization operations if possible. <p> This suggests that Java implementors should investigate the elimination of synchronization primitives in multithreaded programs. 4 Related Work Several Java compiler projects statically compile either Java source code or Java bytecodes to C, using C as a portable assembly language. The most complete implementations known to us are Harissa <ref> [MMBC97] </ref>, Toba [PTB + 97], and TurboJ [Ope98]. Harissa and Toba both have their own runtime systems using the Boehm-Demers-Weiser conservative garbage collector. TurboJ incorporates compiled code into the Sun Microsystems Java runtime system using JNI.
Reference: [Muc97] <author> Steven S. Muchnick. </author> <title> Advanced Compiler Design and Implementation. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Fran-cisco, </address> <year> 1997. </year>
Reference-contexts: We are particularly concerned with implementation choices afiecting the performance of large applications. To this end, we have built Marmot, a bytecode-to-native-code compiler, runtime system, and library for Java. Marmot is Current: Marmot implements both standard scalar optimizations (of the sort found in Fortran, C and C++ <ref> [Muc97] </ref>) and basic objectoriented optimizations such as call binding based on class hierarchy analysis [BS96, DGC95]. Modern representation techniques such as SSA and type-based compilation [CFR + 89, Tar96] are also used. These improve optimizations and support tracing garbage collection. <p> (v)[t 1 ; : : : ; t n ] Multiway transfer, t 1 ; : : : ; t n are the case tag constants. 2.2.1 Representing Exceptions and Handlers in JIR In order to represent exception handlers, the basic blocks of JIR difier from the classic deflnition (e.g., <ref> [ASU86, App98, Muc97] </ref>) in that they are single entry, but multiple exit. In addition, basic blocks are not terminated at function call boundaries.
Reference: [Nat98] <author> NaturalBridge, </author> <title> LLC. Bullettrain Java compiler technology. </title> <note> http://www.naturalbridge.com/, 1998. </note>
Reference-contexts: These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler [HBG + 97] uses technology similar to that of the Self compilers. Optimizations are based on measured runtime behavior, with recompilation and optimization being performed while the program is running. Instantiations' Jove compiler [Ins98] and Natural-Bridge's BulletTrain compiler <ref> [Nat98] </ref> both employ static whole-program analysis and optimization. They include their own runtime systems.
Reference: [Nef98] <author> John Nefienger. </author> <title> Which Java VM scales best? Java-World, </title> <type> 3(8), </type> <month> August </month> <year> 1998. </year>
Reference-contexts: Currently considered a state-of-the-art JIT compiler <ref> [Nef98] </ref>. Commercial static compilers: SuperCede for Java, Version 2.03, Upgrade Edition. Research static compilers: IBM Research High Performance Compiler for Java (HPJ).
Reference: [Ope98] <author> The Open Group. </author> <title> TurboJ high performance Java compiler. </title> <note> http://www.camb.opengroup.com/openitsol/turboj/, February 1998. </note>
Reference-contexts: The most complete implementations known to us are Harissa [MMBC97], Toba [PTB + 97], and TurboJ <ref> [Ope98] </ref>. Harissa and Toba both have their own runtime systems using the Boehm-Demers-Weiser conservative garbage collector. TurboJ incorporates compiled code into the Sun Microsystems Java runtime system using JNI.
Reference: [PTB + 97] <author> Todd A. Proebsting, Gregg Townsend, Patrick Bridges, John H. Harman, Tim Newsham, and Scott A. Watterson. Toba: </author> <title> Java for applications: A way ahead of time (WAT) compiler. </title> <booktitle> In Proceedings of the Third Conference on ObjectOriented Technologies and Sytems (COOTS '97), </booktitle> <year> 1997. </year>
Reference-contexts: The most complete implementations known to us are Harissa [MMBC97], Toba <ref> [PTB + 97] </ref>, and TurboJ [Ope98]. Harissa and Toba both have their own runtime systems using the Boehm-Demers-Weiser conservative garbage collector. TurboJ incorporates compiled code into the Sun Microsystems Java runtime system using JNI.
Reference: [SG95] <author> Vugranam C. Sreedhar and Guang R. Gao. </author> <title> A linear time algorithm for placing nodes. </title> <booktitle> In Proceedings 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 62-73, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: The conversion is based upon Lengauer and Tarjan's dominator tree algorithm [LT79] and Sreedhar and Gao's phi placement algorithm <ref> [SG95] </ref>. Conversion is complicated by the presence of exception-handling edges, which must be considered during the computation of iterated dominance frontiers. Such edges may also require that their source blocks be split to preserve the usual one-to-one correspondence between phi arguments and CFG edges.
Reference: [SI77] <author> Norishisa Suzuki and Kiyoshi Ishihata. </author> <title> Implementation of an array bound checker. </title> <booktitle> In Proceedings of the Fourth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 132-143, </pages> <month> Janury </month> <year> 1977. </year>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran [MCM82, Gup90, Asu91, Gup93, CG95, KW95] and other contexts <ref> [SI77, XP98] </ref>. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks. The remaining bounds checks are optimized in two phases.
Reference: [Sup98] <author> SuperCede, Inc. </author> <title> SuperCede for Java, </title> <note> Version 2.03, Upgrade Edition. http://www.supercede.com/, Septem-ber 1998. </note>
Reference-contexts: Most Java compilers compiling directly to native code are part of commercial development systems. Tower Technology's TowerJ [Tow98] generates native code for numerous platforms (machine architectures and operating systems) while SuperCede <ref> [Sup98] </ref> and Symantec's Visual Cafe [Sym98] generate native code for x86 systems. These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler [HBG + 97] uses technology similar to that of the Self compilers.
Reference: [Sym98] <author> Symantec Corporation. </author> <title> Visual Cafe Pro. </title> <note> http://www.symantec.com/, September 1998. </note>
Reference-contexts: Most Java compilers compiling directly to native code are part of commercial development systems. Tower Technology's TowerJ [Tow98] generates native code for numerous platforms (machine architectures and operating systems) while SuperCede [Sup98] and Symantec's Visual Cafe <ref> [Sym98] </ref> generate native code for x86 systems. These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler [HBG + 97] uses technology similar to that of the Self compilers. Optimizations are based on measured runtime behavior, with recompilation and optimization being performed while the program is running.
Reference: [Tar96] <author> David Tarditi. </author> <title> Design and Implementation of Code Optimizations for a TypeDirected Compiler for Standard ML. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: Marmot is Current: Marmot implements both standard scalar optimizations (of the sort found in Fortran, C and C++ [Muc97]) and basic objectoriented optimizations such as call binding based on class hierarchy analysis [BS96, DGC95]. Modern representation techniques such as SSA and type-based compilation <ref> [CFR + 89, Tar96] </ref> are also used. These improve optimizations and support tracing garbage collection. Complete: Marmot implements all Java language features except dynamic class loading and reection 1 .
Reference: [Tow98] <institution> Tower Technology. TowerJ, </institution> <note> release 2. http://www.twr.com/, September 1998. </note>
Reference-contexts: Most Java compilers compiling directly to native code are part of commercial development systems. Tower Technology's TowerJ <ref> [Tow98] </ref> generates native code for numerous platforms (machine architectures and operating systems) while SuperCede [Sup98] and Symantec's Visual Cafe [Sym98] generate native code for x86 systems. These systems all include customized runtime systems. Sun Microsystem's HotSpot compiler [HBG + 97] uses technology similar to that of the Self compilers.
Reference: [Wil76] <author> H. P. Williams. </author> <title> Fourier-Motzkin elimination extension to integer programming problems. </title> <journal> Journal of Conbinatorial Theory (A), </journal> <volume> 21 </volume> <pages> 118-123, </pages> <year> 1976. </year>
Reference-contexts: Sources of facts are control ow branching, array creation, and available array bounds checks. To these facts are added additional facts derived from bounds and monotonicity of induction variables. Second, an inequality decision procedure, Fourier elimination <ref> [DE73, Duf74, Wil76] </ref>, is used at each array bounds check to determine if the check is redundant relative to the available facts. If both the lower- and upper-bound checks are redundant, then the bounds check is removed.
Reference: [XP98] <author> Hongwei Xi and Frank Pfenning. </author> <title> Eliminating array bound checking through dependent types. </title> <booktitle> In Proceedings of the SIGPLAN '98 Conference on Programming Language Design and Implementation, </booktitle> <pages> page unknown pages, </pages> <year> 1998. </year> <month> 16 </month>
Reference-contexts: Unlike most of the optimizations shown in Figure 2, array bounds check optimization is not yet a standard technique, particularly in the face of Java's exception semantics. Several techniques for array bounds check optimization have been developed for Fortran [MCM82, Gup90, Asu91, Gup93, CG95, KW95] and other contexts <ref> [SI77, XP98] </ref>. Marmot employs the folklore optimization that the upper and lower bounds checks for a zero-origin array may be combined into a single unsigned check for the upper bound [App98]. Also, the common subexpres-sion elimination optimization removes fully redundant checks. The remaining bounds checks are optimized in two phases.
References-found: 54

