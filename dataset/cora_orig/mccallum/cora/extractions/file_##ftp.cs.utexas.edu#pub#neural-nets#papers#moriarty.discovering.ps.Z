URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/moriarty.discovering.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: moriarty,risto@cs.utexas.edu  
Title: Discovering Complex Othello Strategies Through Evolutionary Neural Networks  
Author: David E. Moriarty and Risto Miikkulainen 
Address: Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: An approach to develop new game playing strategies based on artificial evolution of neural networks is presented. Evolution was directed to discover strategies in Othello against a random-moving opponent and later against an ff-fi search program. The networks discovered first a standard positional strategy, and subsequently a mobility strategy, an advanced strategy rarely seen outside of tournaments. The latter discovery demonstrates how evolutionary neural networks can develop novel solutions by turning an initial disadvantage into an advantage in a changed environment. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Belew, R. K., McInerney, J., and Schraudolph, N. N. </author> <year> (1991). </year> <title> Evolving networks: Using genetic algorithm with connectionist learning. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Billman, D., and Shaman, D. </author> <year> (1990). </year> <title> Strategy knowledge and strategy change in skilled performance: A study of the game othello. </title> <journal> American Journal of Psychology, </journal> <volume> 103 </volume> <pages> 145-166. </pages>
Reference-contexts: Connection Science, 7 (3): 195-209, 1995. A more sophisticated mobility strategy is often employed by tournament players because it produces much stronger play. It is, however, considered to be very hard to learn <ref> (Billman and Shaman 1990) </ref>. After a positional strategy was encoded into an ff-fi search program and the networks were allowed to compete with the ff-fi program, they evolved to exploit their initial material disadvantage and discovered the mobility strategy. <p> Mobility strategies often involve short term goals such as keeping a low piece count and clustering pieces. Mobility is one of the core ideas that forms the basis of all modern tournament play. Mobility has been shown to be much harder to learn than a positional strategy <ref> (Billman and Shaman 1990) </ref>. Unlike many good ideas that are often discovered independently by several people, it is widely believed that mobility was discovered only once in Japan and has since been introduced to America and Europe through American players in contact with the Japanese (Billman and Shaman 1990). <p> learn than a positional strategy <ref> (Billman and Shaman 1990) </ref>. Unlike many good ideas that are often discovered independently by several people, it is widely believed that mobility was discovered only once in Japan and has since been introduced to America and Europe through American players in contact with the Japanese (Billman and Shaman 1990). Being able to independently discover a mobility strategy through evolutionary neural networks would therefore be a significant demonstration of the potential power of neuro-evolution. 3 Implementation 3.1 Game-playing Neural Networks Our approach was to evolve a population of neural networks in the game of Othello.
Reference: <author> Charness, N. </author> <year> (1976). </year> <title> Memory for chess positions; resistance to interference. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 2 </volume> <pages> 641-653. </pages>
Reference: <author> DeGroot, A. D. </author> <year> (1965). </year> <title> Thought and Choice in Chess. The Hague, </title> <address> The Netherlands: </address> <publisher> Mouton. </publisher>
Reference: <author> Frey, P. W., and Adesman, P. </author> <year> (1976). </year> <title> Recall memory for visually presented chess positions. </title> <journal> Memory and Cognition, </journal> <volume> 4 </volume> <pages> 541-547. </pages>
Reference: <author> Fullmer, B., and Miikkulainen, R. </author> <year> (1992). </year> <title> Evolving finite state behavior using marker-based genetic encoding of neural networks. </title> <booktitle> In Proceedings of the First European Conference on Artificial Life. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In the marker-based approach, however, the two neurons can be evolved in 5 sequential node definitions, which results in a much smaller schema defining length. Short, highly functional schemata of this kind are hypothesized to be essential for efficient operation of genetic algorithms <ref> (Goldberg 1989) </ref>. The marker-based scheme presented above is a successor of Fullmer and Miikkulainen (1992). Whereas they defined output nodes explicitly like all other nodes in the network, our version of marker-based encoding only requires the definition of hidden nodes.
Reference: <author> Griffiths, A. J. F., Miller, J. H., Suzuki, D. T., Lewontin, R. C., and Gelbart, W. M. </author> <year> (1993). </year> <title> An introduction to Genetic Analysis. </title> <editor> W. H. </editor> <publisher> Freeman. </publisher>
Reference-contexts: In DNA, strings of nucleotide triplets specify strings of amino acids that make up a protein. Since multiple proteins may be defined on the same DNA strand, certain nucleotide triplets have a special status as markers that indicate the start and the end of a protein definition <ref> (Griffiths et al. 1993) </ref>. Artificial genes can similarly use markers to define separate nodes in a neural network. Each node definition contains a start integer and an end integer. The integers in-between specify the node. Figure 2 outlines the node definition in the marker-based scheme.
Reference: <author> Holland, J. H. </author> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press. </publisher>
Reference: <author> Jefferson, D., Collins, R., Cooper, C., Dyer, M., Flowers, M., Korf, R., Taylor, C., and Wang, A. </author> <year> (1991). </year> <title> Evolution as a theme in artificial life: The genesys/tracker system. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The chromosome was simply the concatenation of the weights in the network. Similar fixed architecture encoding techniques have been shown to be effective in domains such as evolving communication (Werner and Dyer 1991), processing sonar signals (Montana and Davis 1989), and trail-following <ref> (Jefferson et al. 1991) </ref>. However, fixed encoding turned out inadequate for this task. The fixed-architecture networks achieved similar performance (97% winning percentage) against a random mover, although it took 1000 generations.
Reference: <author> Lee, K.-F., and Mahajan, S. </author> <year> (1990). </year> <title> The development of a world class Othello program. </title> <journal> Artificial Intelligence, </journal> <volume> 43 </volume> <pages> 21-36. </pages>
Reference-contexts: Discovering a known counterintuitive strategy demonstrates the power of neuro-evolution. In principle it should be possible to develop truly new strategies as well. In preliminary experiments, we have replaced the positional opponent described in this paper with the Bill program <ref> (Lee and Mahajan 1990) </ref>, which contains sophisticated positional and mobility strategies optimized through Bayesian learning. To date, the networks have been unable to discover a strategy that can defeat Bill.
Reference: <author> Montana, D. J., and Davis, L. </author> <year> (1989). </year> <title> Training feedforward neural networks using genetic algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Aritificial Intelligence, </booktitle> <pages> 762-767. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The chromosome was simply the concatenation of the weights in the network. Similar fixed architecture encoding techniques have been shown to be effective in domains such as evolving communication (Werner and Dyer 1991), processing sonar signals <ref> (Montana and Davis 1989) </ref>, and trail-following (Jefferson et al. 1991). However, fixed encoding turned out inadequate for this task. The fixed-architecture networks achieved similar performance (97% winning percentage) against a random mover, although it took 1000 generations.
Reference: <author> Rosenbloom, P. </author> <year> (1982). </year> <title> A world championship-level Othello program. </title> <journal> Artificial Intelligence, </journal> <volume> 19 </volume> <pages> 279-320. </pages>
Reference-contexts: Each network's fitness was determined by the number of games won out of ten played against the ff-fi search program searching three levels down. The ff-fi program used a positional strategy similar to Iago's <ref> (Rosenbloom 1982) </ref>. Iago's evaluation function also contained a complex mobility strategy, which was purposely left out to provide a weakness that the networks could exploit.
Reference: <author> Werner, G. M., and Dyer, M. G. </author> <year> (1991). </year> <title> Evolution of communication in artificial organisms. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., and Taylor, C., editors, </editor> <booktitle> Artificial Life II. </booktitle> <address> Reading, MA: </address> <note> Addison-Wesley. 13 Whitley, </note> <author> D., Starkweather, T., and Bogart, C. </author> <year> (1990). </year> <title> Genetic algorithms and neural networks: Optimizing connections and connectivity. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 347-361. 14 </pages>
Reference-contexts: Each hidden unit had a recursive connection to itself to allow short-term memory to develop. The chromosome was simply the concatenation of the weights in the network. Similar fixed architecture encoding techniques have been shown to be effective in domains such as evolving communication <ref> (Werner and Dyer 1991) </ref>, processing sonar signals (Montana and Davis 1989), and trail-following (Jefferson et al. 1991). However, fixed encoding turned out inadequate for this task. The fixed-architecture networks achieved similar performance (97% winning percentage) against a random mover, although it took 1000 generations.
References-found: 14

