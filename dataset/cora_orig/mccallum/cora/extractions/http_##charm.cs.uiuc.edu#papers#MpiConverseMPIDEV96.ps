URL: http://charm.cs.uiuc.edu/papers/MpiConverseMPIDEV96.ps
Refering-URL: http://charm.cs.uiuc.edu/papers/MpiConverseMPIDEV96.html
Root-URL: http://www.cs.uiuc.edu
Email: fmilind,kaleg@cs.uiuc.edu  
Title: MICE: A Prototype MPI Implementation in Converse Environment  
Author: Milind A. Bhandarkar and Laxmikant V. Kal e 
Address: Urbana, IL 61801  
Affiliation: Parallel Programming Laboratory Department of Computer Science University of Illinois at Urbana-Champaign  
Abstract: This paper describes MICE, a prototype implementation of MPI on the Converse interoperable parallel programming environment. It is based on MPICH, a public-domain implementation of MPI and uses the Abstract Device Interface (ADI) which has been retargeted on top of Converse. MICE makes use of message-managers and allows use of thread-objects to let MPI modules co-exist with other types of computations and communication (such as a library computation in Charm++ or asynchronous computations in mul-tipol) within a single application. It also makes it possible to interoperate PVM (in a restricted form) and MPI modules. Thread-objects make it possible to build multi-threaded MPI programs. This MPI implementation demonstrates that it is possible to provide interoperability without any significant performance degradation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Gropp, E. Lusk, and A. Skjellum. </author> <title> Using MPI: Portable Parallel Programming with the Message-Passing Interface. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: In particular, we are interested in ways to use modules developed using message-driven objects alongwith MPI modules in a single application. This paper describes MICE, a prototype implementation of MPI on the Converse [3] interoperable parallel programming environment. It is based on MPICH <ref> [1] </ref> implementation and uses the Abstract Device Interface (ADI)[7] which has been implemented on top of Converse. Converse makes it feasible to employ modules written using different parallel programming languages and run-time systems in a single application. <p> Converse has many built-in load balancing strategies which could be selected by the user at link-time. (Or the language implementor could provide the user with more choices of load balancing strategies.) 3. MPICH Device Interface MPICH <ref> [1] </ref> is a public-domain implementation developed at Argonne National Laboratory and Mississippi State Uni versity. This is a two level implementation of which the top layer provides device-independent functionality of MPI and the bottom layer implements the device-specific part. There are hooks from the device-independent part into the device-specific part.
Reference: [2] <author> L. Kale. </author> <title> The Chare Kernel parallel programming language and system. </title> <booktitle> In Proceedings of the International Conference on Parallel Proces sing, </booktitle> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Converse makes it feasible to employ modules written using different parallel programming languages and run-time systems in a single application. Currently, in addition to MPI, a number of parallel programming environments such as threaded-PVM [6] (without process management facilities), Charm <ref> [2] </ref> (an object-based message-driven language), Charm++[4] (an object-oriented message-driven language), IMPORT (a parallel simulation language) and threaded SM (a simple messaging layer) have been ported to Converse.
Reference: [3] <author> L. Kale, M. Bhandarkar, N. Jagathesan, S. Krishnan, and J. Yelon. </author> <title> Converse: An Interoperable Framework for Parallel Programming. </title> <note> In International Parallel Processing Symposium 1996 (to appear), </note> <year> 1996. </year>
Reference-contexts: In particular, we are interested in ways to use modules developed using message-driven objects alongwith MPI modules in a single application. This paper describes MICE, a prototype implementation of MPI on the Converse <ref> [3] </ref> interoperable parallel programming environment. It is based on MPICH [1] implementation and uses the Abstract Device Interface (ADI)[7] which has been implemented on top of Converse. Converse makes it feasible to employ modules written using different parallel programming languages and run-time systems in a single application. <p> In section 4, we present our implementation of MICE. Section 5 describes how MPI could be used with modules written in other languages. We compare the performance of our MPI implementation with MPICH in section 6 and conclude in section 7. 2. Converse Converse <ref> [3] </ref> is an interoperable parallel programming framework for implementing parallel languages. Converse has a dual objective to first, support co-existence of modules written in different parallel languages/paradigms in a single application program; and second, to support quick development of runtime systems for new languages and parallel libraries. <p> If at any time only one module is active across all processors, and control is transferred from one module to another explicitly by the application, it is called an explicit control-regime. Figure 1 from <ref> [3] </ref> illustrates control transfers in explicit and implicit control-regimes in a multilingual program. grams MICE supports both explicit and implicit control-regimes and also allows MPI modules to co-exist with other languages with different levels of concurrency.
Reference: [4] <author> L. Kale and S. Krishnan. CHARM++: </author> <title> A Portable Concurrent Object Oriented System Based on C++. </title> <editor> In A. Paepcke, editor, </editor> <booktitle> Proceedings of OOPSLA'93, </booktitle> <pages> pages 91-108. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference: [5] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> May </month> <year> 1994. </year>
Reference-contexts: 1. Introduction Message-Passing parallel programming has become the method of choice for many parallel programmers. There have been tremendous advances in this field in the past few years. One such advance is the emergence of Message Passing Interface Standard, MPI <ref> [5] </ref>. Since the detailed specification of MPI 1.0, many public-domain and vendor-specific implementations of MPI became available and many existing applications were ported using MPI. Many new applications are also being developed in the MPI environment.
Reference: [6] <author> V. Sunderam. </author> <title> PVM: A Framework for Parallel Distributed Computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Converse makes it feasible to employ modules written using different parallel programming languages and run-time systems in a single application. Currently, in addition to MPI, a number of parallel programming environments such as threaded-PVM <ref> [6] </ref> (without process management facilities), Charm [2] (an object-based message-driven language), Charm++[4] (an object-oriented message-driven language), IMPORT (a parallel simulation language) and threaded SM (a simple messaging layer) have been ported to Converse.
Reference: [7] <author> W. Gropp and E. Lusk. </author> <title> MPICH ADI Implementation Reference Manual, </title> <month> August </month> <year> 1995. </year>

References-found: 7

