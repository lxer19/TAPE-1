URL: http://www.cs.toronto.edu/~greiner/PAPERS/phc-applic.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@learning.siemens.com  
Phone: (609) 734-3627  
Title: Probabilistic Hill-Climbing: Theory and Applications  
Author: Russell Greiner 
Note: [Awarded "Best Paper Prize"]  
Address: Princeton, NJ 08540  
Affiliation: Siemens Corporate Research,  
Abstract: Many learning systems search through a space of possible performance elements, seeking an element with high expected utility. As the task of finding the globally optimal element is usually intractable, many practical learning systems use hill-climbing to find a local optimum. Unfortunately, even this is difficult, as it depends on the distribution of problems, which is typically unknown. This paper addresses the task of approximating this hill-climbing search when the utility function can only be estimated by sampling. We present an algorithm that returns an element that is, with provably high probability, essentially a local optimum. We then demonstrate the generality of this algorithm by sketching three meaningful applications, that respectively find an element whose efficiency, accuracy or completeness is nearly optimal. These results suggest approaches to solving the utility problem from explanation-based learning, the multiple extension problem from nonmonotonic reasoning and the tractability/completeness tradeoff problem from knowledge representation. Appears in the Proceedings of the Ninth Canadian Conference on Artificial Intelligence (CSCSI-92), Vancouver, May 1992. 
Abstract-found: 1
Intro-found: 1
Reference: [BD88] <author> M. Boddy and T. Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1988. </year>
Reference-contexts: Thus, for sufficiently small values of *, palo will always produce a bona fide local optimum. N-PALO5. We can view palo as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, palo provides a usable result (here, the performance element produced at the j th iteration, PE j ), with the property that later systems are (probably) better than earlier ones; i.e., i &gt; j means C [ PE i ] &gt; C [ PE j
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: N-PALO2. All three c ff (PE; q) functions discussed in this paper are "bounded"; i.e., satisfy 8 PE 2 PE; q 2 Q: c ` c ff (PE; q) c ` + 4 See <ref> [Bol85, p. 12] </ref>. N.b., these inequalities holds for essentially arbitrary distributions, not just normal distributions, subject only to the minor constraint that the random vari ables fd i g is bounded. for some constants c ` 2 &lt; and 2 &lt; + .
Reference: [Bre89] <author> G. Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <address> Detroit, </address> <year> 1989. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements [PGA86] <ref> [Prz87, Bre89, vA90] </ref>, where each element PE = hF ; H; fii corresponds to a set of factual information F, a set of allowed hypotheses H (each a simple type of default [Rei87]) and a specific ordering of the hypotheses.
Reference: [Che52] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference-contexts: This average tends to the true population mean as n ! 1; i.e., = lim n;1 Y n . Chernoff bounds <ref> [Che52] </ref> describe the probable rate of convergence: the probability that "Y n is more than + fl" goes to 0 exponentially fast as n increases; and, for a fixed n, exponentially as fl increases.
Reference: [CM81] <author> W. Clocksin and C. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: N-Eff1. This class of performance elements corresponds to many standard problem solvers, including Prolog <ref> [CM81] </ref>; see also [GN87]. We can also use these inference graphs to describe operators working in state spaces; here each internal arc of the inference graph corresponds to an operator invocation and each leaf arc to a general "probabilistic experiment".
Reference: [DB88] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: Thus, for sufficiently small values of *, palo will always produce a bona fide local optimum. N-PALO5. We can view palo as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, palo provides a usable result (here, the performance element produced at the j th iteration, PE j ), with the property that later systems are (probably) better than earlier ones; i.e., i &gt; j means C [ PE i ] &gt; C [ PE j
Reference: [DeJ88] <author> G. DeJong. </author> <booktitle> AAAI workshop on Explanation-Based Learning. Sponsored by AAAI, </booktitle> <year> 1988. </year>
Reference-contexts: As examples, many inductive systems seek a function whose classification is optimal, i.e., which labels correctly as many examples as possible; and many explanation-based learning <ref> [DeJ88, MCK + 89] </ref> and chunking [LNR87] systems seek a problem solving system that is optimally efficient [Min88, Gre91].
Reference: [DG84] <author> W. Dowling and J. Gallier. </author> <title> Linear time algorithms for testing the satisfiability of propositional horn formula. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 267-84, </pages> <year> 1984. </year>
Reference-contexts: Moreover, these tests are linear in the sizes of and S (respectively, and W ) <ref> [DG84] </ref>.) Otherwise, if W 6j= and S j= , PE returns IDK. Notice this compiled system is usually tractable, 10 yet can deal with an arbitrary propositional theory. It may, however, no longer be completely categoric; hence, we have (potentially) sacrificed complete accuracy for tractability [SK91].
Reference: [GD91] <author> J. Gratch and G. Dejong. </author> <title> A hybrid approach to guaranteed effective control strategies. </title> <booktitle> In Proceedings of IWML-91, </booktitle> <year> 1991. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [Hin89] and id3 [Qui86], use this approach, as do many speedup learning methods; see especially <ref> [GD91] </ref>. Unfortunately, few existing systems guarantee that each hill-climbing step is even an improvement, meaning the final element is not always even superior to the initial one, much less an optimum in the space of elements.
Reference: [GE91] <author> R. Greiner and C. Elkan. </author> <title> Measuring and improving the effectiveness of representations. </title> <booktitle> In Proceedings of IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: with high probability. (Unfortunately, the size of the optimal weakening can be exponential in the size of the initial theory, meaning the linear bounds mentioned above are not meaningful. [Gre92] considers ways of finding weak-enings that are good with respect to a utility metric that combines both categoricity and efficiency <ref> [GE91] </ref>, to produce a polynomially-sized weakening.) 5 Conclusion This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility is optimal [Hau90, Vap82]: viz., that the distribution information (which is required to determine which element is optimal) is usually unknown,
Reference: [GJ92] <author> R. Greiner and I. Jurisica. </author> <title> a statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Here, we can guarantee that fl [PE ff ; PE fi ] . For certain transformations t k , we can find yet smaller values for fl [t k (PE); PE]; see <ref> [GJ92] </ref>. N-PALO3. Although Theorem 1 bounds the number of samples per iteration, it is impossible to bound the number of iterations of the overall palo algorithm without making additional assumptions about the search space defined by the T transformations. <p> Using G A , for example, a 3 could encode the "take some blood" operator, and a 5 , the experiment that succeeds if the patient tests positive on bt#1, etc. N-Eff2. The companion paper <ref> [GJ92] </ref> provides more formal descriptions of inference graphs and strategies.
Reference: [GN87] <author> M. Genesereth and N. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1987. </year>
Reference-contexts: N-Eff1. This class of performance elements corresponds to many standard problem solvers, including Prolog [CM81]; see also <ref> [GN87] </ref>. We can also use these inference graphs to describe operators working in state spaces; here each internal arc of the inference graph corresponds to an operator invocation and each leaf arc to a general "probabilistic experiment".
Reference: [GO91] <author> R. Greiner and P. Orponen. </author> <title> Probably approximately optimal derivation strategies. </title> <booktitle> In Proceedings of KR-91, </booktitle> <year> 1991. </year>
Reference-contexts: many helpful comments from William Cohen, Dale Schuurmans and the anonymous referees. the utility function used to compare the different elements is defined as the expected value of a particular scoring function, averaged over the distribution of samples (or goals, queries, problems, : : : ) that will be seen <ref> [Hau88, OG90, GO91] </ref>. There are two problems with implementing such a learning system: First, we need to know the distribution of samples to determine which element is optimal; unfortunately, this information is usually unknown.
Reference: [Gol79] <author> A. Goldberg. </author> <title> An average case complexity analysis of the satisfiability problem. </title> <booktitle> In Proceedings of CADE-79, </booktitle> <year> 1979. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for example, we do not assume that this distribution of problems will be uniform <ref> [Gol79] </ref>, nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" [Kel87]. N-PALO2.
Reference: [Gre91] <author> R. Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: As examples, many inductive systems seek a function whose classification is optimal, i.e., which labels correctly as many examples as possible; and many explanation-based learning [DeJ88, MCK + 89] and chunking [LNR87] systems seek a problem solving system that is optimally efficient <ref> [Min88, Gre91] </ref>. In each of these cases, fl Most of this work was performed at the University of Toronto, where it was supported by the Institute for Robotics and Intelligent Systems and by an operating grant from the National Science and Engineering Research Council of Canada. <p> For example, many "PAC-learning" systems [Val84] use these estimates to identify an element that is approximately a global optimum. This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements <ref> [Gre91, Hau88] </ref>. A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [Hin89] and id3 [Qui86], use this approach, as do many speedup learning methods; see especially [GD91]. <p> Moreover, the task of finding the globally optimal strategy is NP-hard <ref> [Gre91] </ref>. 5 Here, hep () means has hepatitis, jaun () means is jaundiced, and badB () means has "bad blood", bt#i () means tests positive for blood test #i.
Reference: [Gre92] <author> R. Greiner. </author> <title> Probabilistic hill-climbing: Theory and applications. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1992. </year>
Reference-contexts: To deter mine this, define d i = [PE ff ; PE fi ; q i ] = c (PE ff ; q i ) c (PE fi ; q i ) 3 This proof, and others, appear in the expanded version of this paper <ref> [Gre92] </ref>. to be the difference in cost between using PE ff to deal with the problem q i , and using PE fi . <p> Our goal is identifying the ordering that is accurate most often. Unfortunately, the task of identifying this optimal ordering of the hypotheses is NP-complete even for the simplistic situation we have been considering (where every derivation involves exactly one hypothesis, etc.); see <ref> [Gre92] </ref>. Once again, palo is designed to deal with this situation. <p> Using Equation 1, we can then define C c [ hS; Wi ] to be the expected value of c c (hS; Wi; ). Our goal is to determine the approximation hS; Wi with the largest C c [ ] value. As before, this task is NP-hard (see <ref> [Gre92] </ref>) and depends on the distribution, suggesting yet again that we use the palo system. <p> We can therefore decouple the task of finding a good strengthening from that of finding a good weakening, and handle each separately. This paper discusses only how to finding a good strengthening; <ref> [Gre92] </ref> merges this with the algorithm that computes a good weakening. <p> N-Cat1. The PE (S i ; W j ) systems discussed here each return IDK if W 6j= and S j= . <ref> [Gre92] </ref> proposes several other options for this situation | e.g., perhaps the PE should "guess" at an answer here, or perhaps spend as long as necessary to compute whether ? etc. | and discusses their relative advantages. N-Cat2. [Gre92] also presents an algorithm that finds a good weakening. <p> discussed here each return IDK if W 6j= and S j= . <ref> [Gre92] </ref> proposes several other options for this situation | e.g., perhaps the PE should "guess" at an answer here, or perhaps spend as long as necessary to compute whether ? etc. | and discusses their relative advantages. N-Cat2. [Gre92] also presents an algorithm that finds a good weakening. <p> subtle reasons, that process is slightly different from palo, and computes a W g that is close to the global optimal, with high probability. (Unfortunately, the size of the optimal weakening can be exponential in the size of the initial theory, meaning the linear bounds mentioned above are not meaningful. <ref> [Gre92] </ref> considers ways of finding weak-enings that are good with respect to a utility metric that combines both categoricity and efficiency [GE91], to produce a polynomially-sized weakening.) 5 Conclusion This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility
Reference: [Gro91] <author> B. Grosof. </author> <title> Generalizing prioritization. </title> <booktitle> In Proceeding of KR-91, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: N-Acc2. Our descriptions have assumed that every ordering of hypotheses is meaningful. In some contexts, there may already be a meaningful partial ordering of the hypotheses, perhaps based on specificity or some other criteria <ref> [Gro91] </ref>. Here, we can still use palo to complete the partial ordering, by determining the relative priorities of the initially incomparable elements. N-Acc3. The motivation underlying this work is similar to the research of [Sha89] and others, who also use probabilistic information to order the various default rules.
Reference: [Hau88] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <year> 1988. </year>
Reference-contexts: many helpful comments from William Cohen, Dale Schuurmans and the anonymous referees. the utility function used to compare the different elements is defined as the expected value of a particular scoring function, averaged over the distribution of samples (or goals, queries, problems, : : : ) that will be seen <ref> [Hau88, OG90, GO91] </ref>. There are two problems with implementing such a learning system: First, we need to know the distribution of samples to determine which element is optimal; unfortunately, this information is usually unknown. <p> For example, many "PAC-learning" systems [Val84] use these estimates to identify an element that is approximately a global optimum. This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements <ref> [Gre91, Hau88] </ref>. A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [Hin89] and id3 [Qui86], use this approach, as do many speedup learning methods; see especially [GD91]. <p> Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation [Rei87, HM86, Mor87], and corresponds to the "bias problem" in machine learning <ref> [Mit80, Utg84, RG87, Hau88] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [Hau90] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <type> Technical Report UCSC-CRL-91-02, </type> <institution> UC Santa Cruz, </institution> <year> 1990. </year>
Reference-contexts: of finding weak-enings that are good with respect to a utility metric that combines both categoricity and efficiency [GE91], to produce a polynomially-sized weakening.) 5 Conclusion This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility is optimal <ref> [Hau90, Vap82] </ref>: viz., that the distribution information (which is required to determine which element is optimal) is usually unknown, and that finding a globally optimal performance element can be intractable.
Reference: [Hin89] <author> G. Hinton. </author> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):185-234, </volume> <year> 1989. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop <ref> [Hin89] </ref> and id3 [Qui86], use this approach, as do many speedup learning methods; see especially [GD91].
Reference: [HM86] <author> S. Hanks and D. McDermott. </author> <title> Default reasoning, nonmonotonic logics, and the frame problem. </title> <booktitle> In Proceedings of AAAI-86, </booktitle> <year> 1986. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation <ref> [Rei87, HM86, Mor87] </ref>, and corresponds to the "bias problem" in machine learning [Mit80, Utg84, RG87, Hau88]. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [Kel87] <author> R. Keller. </author> <title> Defining operationality for explanation-based learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for example, we do not assume that this distribution of problems will be uniform [Gol79], nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" <ref> [Kel87] </ref>. N-PALO2. All three c ff (PE; q) functions discussed in this paper are "bounded"; i.e., satisfy 8 PE 2 PE; q 2 Q: c ` c ff (PE; q) c ` + 4 See [Bol85, p. 12].
Reference: [LNR87] <author> J. Laird, A. Newell, and P. Rosenbloom. </author> <title> SOAR: An architecture of general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(3), </volume> <year> 1987. </year>
Reference-contexts: As examples, many inductive systems seek a function whose classification is optimal, i.e., which labels correctly as many examples as possible; and many explanation-based learning [DeJ88, MCK + 89] and chunking <ref> [LNR87] </ref> systems seek a problem solving system that is optimally efficient [Min88, Gre91].
Reference: [MCK + 89] <author> S. Minton, J. Carbonell, C. Knoblock, D. Kuokka, O. Etzioni, and Y. Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):63-119, </volume> <year> 1989. </year>
Reference-contexts: As examples, many inductive systems seek a function whose classification is optimal, i.e., which labels correctly as many examples as possible; and many explanation-based learning <ref> [DeJ88, MCK + 89] </ref> and chunking [LNR87] systems seek a problem solving system that is optimally efficient [Min88, Gre91].
Reference: [Min88] <author> S. Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: As examples, many inductive systems seek a function whose classification is optimal, i.e., which labels correctly as many examples as possible; and many explanation-based learning [DeJ88, MCK + 89] and chunking [LNR87] systems seek a problem solving system that is optimally efficient <ref> [Min88, Gre91] </ref>. In each of these cases, fl Most of this work was performed at the University of Toronto, where it was supported by the Institute for Robotics and Intelligent Systems and by an operating grant from the National Science and Engineering Research Council of Canada.
Reference: [Mit80] <author> T. Mitchell. </author> <title> The need for bias in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Laboratory for Computer Science Research, </institution> <month> May </month> <year> 1980. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation [Rei87, HM86, Mor87], and corresponds to the "bias problem" in machine learning <ref> [Mit80, Utg84, RG87, Hau88] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [MMS85] <author> T. Mitchell, S. Mahadevan, and L. Steinberg. </author> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> In Proceedings of IJCAI-85, </booktitle> <year> 1985. </year>
Reference-contexts: Given any parameters *; ffi &gt; 0, palo efficiently produces an element whose expected utility is, with probability greater than 1 ffi, an *-local optimal. 1 Moreover, palo can work unobtrusively <ref> [MMS85] </ref>, passively gathering the statistics it needs by simply watching a performance element solve problems relevant to a user's applications. <p> N-PALO1. The samples that palo uses may be produced by a user of the performance system, who is simply asking questions relevant to his current applications; here, palo is unobtrusively gathering statistics as the user is solving his own problems <ref> [MMS85] </ref>. This means that the total cost of the overall system, that both solves performance problems and "learns" by hill-climbing to successive performance elements, can be only marginally more than the cost of only running the performance element to simply solve the performance problems.
Reference: [Mor87] <author> P. Morris. </author> <title> Curing anomalous extensions. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation <ref> [Rei87, HM86, Mor87] </ref>, and corresponds to the "bias problem" in machine learning [Mit80, Utg84, RG87, Hau88]. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [OG90] <author> P. Orponen and R. Greiner. </author> <title> On the sample complexity of finding good search strategies. </title> <booktitle> In Proceedings of COLT-90, </booktitle> <year> 1990. </year>
Reference-contexts: many helpful comments from William Cohen, Dale Schuurmans and the anonymous referees. the utility function used to compare the different elements is defined as the expected value of a particular scoring function, averaged over the distribution of samples (or goals, queries, problems, : : : ) that will be seen <ref> [Hau88, OG90, GO91] </ref>. There are two problems with implementing such a learning system: First, we need to know the distribution of samples to determine which element is optimal; unfortunately, this information is usually unknown.
Reference: [PGA86] <author> D. Poole, R. Goebel, and R. Aleliunas. </author> <title> Theorist: A logical reasoning system for default and diagnosis. </title> <type> Technical Report CS-86-06, </type> <institution> University of Waterloo, </institution> <year> 1986. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements <ref> [PGA86] </ref> [Prz87, Bre89, vA90], where each element PE = hF ; H; fii corresponds to a set of factual information F, a set of allowed hypotheses H (each a simple type of default [Rei87]) and a specific ordering of the hypotheses.
Reference: [Prz87] <author> T. Przymusinski. </author> <title> On the declarative semantics of stratified deductive databases and logic programs. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 193-216, </pages> <year> 1987. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements [PGA86] <ref> [Prz87, Bre89, vA90] </ref>, where each element PE = hF ; H; fii corresponds to a set of factual information F, a set of allowed hypotheses H (each a simple type of default [Rei87]) and a specific ordering of the hypotheses.
Reference: [Qui86] <author> J. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [Hin89] and id3 <ref> [Qui86] </ref>, use this approach, as do many speedup learning methods; see especially [GD91]. Unfortunately, few existing systems guarantee that each hill-climbing step is even an improvement, meaning the final element is not always even superior to the initial one, much less an optimum in the space of elements.
Reference: [Rei87] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2, </volume> <publisher> Annual Reviews Incorporated, </publisher> <year> 1987. </year>
Reference-contexts: Note also that we are viewing each strategy as a performance element. 4.2 Improving Accuracy A nonmonotonic system can be ambiguous, in that it can produce many individually plausible but collectively incompatible solutions to certain queries <ref> [Rei87] </ref>. Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation [Rei87, HM86, Mor87], and corresponds to the "bias problem" in machine learning [Mit80, Utg84, RG87, Hau88]. <p> Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation <ref> [Rei87, HM86, Mor87] </ref>, and corresponds to the "bias problem" in machine learning [Mit80, Utg84, RG87, Hau88]. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often. <p> We focus on stratified Theorist-style performance elements [PGA86] [Prz87, Bre89, vA90], where each element PE = hF ; H; fii corresponds to a set of factual information F, a set of allowed hypotheses H (each a simple type of default <ref> [Rei87] </ref>) and a specific ordering of the hypotheses.
Reference: [RG87] <author> S. Russell and B. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation [Rei87, HM86, Mor87], and corresponds to the "bias problem" in machine learning <ref> [Mit80, Utg84, RG87, Hau88] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [Sha89] <author> L. Shastri. </author> <title> Default reasoning in semantic networks: A formalization of recognition and inheritance. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 283-355, </pages> <year> 1989. </year>
Reference-contexts: Here, we can still use palo to complete the partial ordering, by determining the relative priorities of the initially incomparable elements. N-Acc3. The motivation underlying this work is similar to the research of <ref> [Sha89] </ref> and others, who also use probabilistic information to order the various default rules.
Reference: [SK75] <author> H. Simon and J. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference-contexts: instantia-tions of these parameters are also summarized in Table 1.) For pedagogical reasons, each subsection begins with a quick simplistic description of the application, and then provides notes that describe how to build a more comprehensive system. 4.1 Improving Efficiency Many derivation processes can be viewed as a satisfic-ing search <ref> [SK75] </ref> through a given graph structure. As an example, notice that using the information shown in ground individual , corresponds naturally to a search Rule Set R 1 : hep (X) :- jaun (X). R 2 : hep (X) :- badB (X). R 3 : badB (X) :- bt#1 (X). <p> Each strategy will find an answer, if one exists. As this is a satisficing search, all answers are equally acceptable <ref> [SK75] </ref>, which means that all strategies are equally accurate. We can therefore consider the costs of the strategies, preferring the one whose expected cost is minimal.
Reference: [SK91] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: It can, however, be performed efficiently if the theory contains only Horn clauses. Sel-man and Kautz <ref> [SK91] </ref> use this observation to define a particular "knowledge compilation" method: Given a general propositional theory , their compiler computes a pair of "bracketing" Horn theories S and W , with the property S j= j= W . 9 The resulting "compiled system" PE = PE (S; W ) uses these <p> Notice this compiled system is usually tractable, 10 yet can deal with an arbitrary propositional theory. It may, however, no longer be completely categoric; hence, we have (potentially) sacrificed complete accuracy for tractability <ref> [SK91] </ref>. We of course would like to find an approximation hS; W i that minimizes the probability that the associ ated PE (S; W ) system will return IDK. <p> T reorder arcs reorder priority change 1 clause Range fl [t (PE); PE] c (G) 2 1 Table 1: Summary of Applications Now write = H [ N , where H is the subset of that are Horn and N = ffl i g m i=1 is its non-Horn subset. <ref> [SK91] </ref> proves that each optimal strengthening is of the form S o = H [ 0 N , where each fl 0 2 0 N is a horn-strengthening of some fl 2 N .
Reference: [Utg84] <author> P. Utgoff. </author> <title> Shift of Bias for Inductive Concept Learning. </title> <type> PhD thesis, </type> <institution> Rutgers, Laboratory for Computer Science Research, </institution> <month> Octo-ber </month> <year> 1984. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; the challenge then is to determine which one. This is the essence of the "multiple extension problem" in knowledge representation [Rei87, HM86, Mor87], and corresponds to the "bias problem" in machine learning <ref> [Mit80, Utg84, RG87, Hau88] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial nonmonotonic system, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [vA90] <author> P. van Arragon. </author> <title> Nested default reasoning with priority levels. </title> <booktitle> In Proceedings of CSCSI-90, </booktitle> <year> 1990. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements [PGA86] <ref> [Prz87, Bre89, vA90] </ref>, where each element PE = hF ; H; fii corresponds to a set of factual information F, a set of allowed hypotheses H (each a simple type of default [Rei87]) and a specific ordering of the hypotheses.
Reference: [Val84] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: There are, of course, standard statistical techniques that use a set of observed samples to estimate the needed information; and several classes of learning systems have incorporated these techniques. For example, many "PAC-learning" systems <ref> [Val84] </ref> use these estimates to identify an element that is approximately a global optimum. This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements [Gre91, Hau88].
Reference: [Vap82] <author> V. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: of finding weak-enings that are good with respect to a utility metric that combines both categoricity and efficiency [GE91], to produce a polynomially-sized weakening.) 5 Conclusion This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility is optimal <ref> [Hau90, Vap82] </ref>: viz., that the distribution information (which is required to determine which element is optimal) is usually unknown, and that finding a globally optimal performance element can be intractable.
References-found: 41

