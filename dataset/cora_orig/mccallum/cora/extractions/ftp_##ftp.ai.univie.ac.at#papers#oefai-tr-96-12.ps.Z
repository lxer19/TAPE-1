URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-96-12.ps.Z
Refering-URL: http://www.ai.univie.ac.at/cgi-bin/biblio_ora?sort_by_author=yes&tailor=1&loc=0&format=ml/ml&keyword=Publications&keyword=WWW_ML&relop=/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Efficient Search for Strong Partial Determinations restricted search indeed retrieves a subset of strong partial
Author: Stefan Kramer and Bernhard Pfahringer 
Note: Applications to real-world data suggest that the  
Abstract: Our work offers both a solution to the problem of finding functional dependencies that are distorted by noise and to the open problem of efficiently finding strong (i.e., highly compressive) partial determinations per se. Briefly, we introduce a restricted form of search for partial determinations which is based on functional dependencies. Focusing attention on solely partial determinations derivable from overfitting functional dependencies enables efficient search for strong partial determinations. Furthermore, we generalize the compression-based measure for evaluating partial determinations to n-valued attributes. feasibility and usefulness of our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [Agrawal & Srikant, 1994] <author> Agrawal R. and Srikant R.: </author> <title> Fast Algorithms for Mining Association Rules. </title> <booktitle> Proceedings of the 20 th VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: We discovered strong partial determinations that indeed reflect the implicit and hidden structure of the dataset. 6 7 Related Work Functional dependencies [Mannila & Raiha, 1994] are essentially relational and do not allow for the possibility of exceptions. On the contrary, association rules <ref> [Agrawal & Srikant, 1994] </ref> not only allow for the possibility of exceptions, but are essentially probabilistic. Partial determinations ([Russell, 1989], [Pfahringer & Kramer, 1995]) can be viewed as generalizations of both functional dependencies and association rules, in that they are relational in nature and may have exceptions.
Reference: [Bell & Brockhausen, 1995] <author> Bell S., Brockhausen P.: </author> <title> Discovery of Data Dependencies in Relational Databases, </title> <institution> FB Informatik, Universitaet Dortmund, </institution> <note> LS-8 Report 14, 1995. 8 </note>
Reference-contexts: The reliability measure is supposed to measure the "functional degree" of the map given subsequent data. As we have argued in [Pfahringer & Kramer, 1995], this measure does not avoid overfitting the data, since it does not have a penalty for overly complex dependencies. <ref> [Bell & Brockhausen, 1995] </ref> hint at a simple modification of their functional dependency search algorithm to cope with noise.
Reference: [Flach, 1993] <author> Flach P.A.: </author> <title> Predicate Invention in Inductive Data Engineering, in Brazdil P.B.(ed.), Machine Learning: </title> <publisher> ECML-93, Springer, </publisher> <address> Berlin, pp.83-94, </address> <year> 1993. </year>
Reference-contexts: So the pruning approach would not find partial determinations in these situations. We plan to extend our work along the following lines: our method could be applied to inductive data engineering in the context of deductive databases, similar to INDEX <ref> [Flach, 1993] </ref>. The returned partial determinations could be used to restructure the database in order to minimize the required memory. Another application of the measure would be to evaluate and compare functional dependencies.
Reference: [Kivinen & Mannila, 1993] <author> Kivinen J., Mannila H.: </author> <title> The power of sampling in knowledge discovery, </title> <institution> University of Helsinki Department of Computer Science, Series C, </institution> <note> No. C-1993- 66, </note> <year> 1993. </year>
Reference-contexts: Another challenge would be a tight integration of the search for functional dependencies and the search for partial determinations. Finally, it would be interesting to compare and combine our approach with sampling techniques as proposed in <ref> [Kivinen & Mannila, 1993] </ref> and [Kivinen & Mannila, 1995]. Acknowledgements This research is partly sponsored by the Austrian Fonds zur Forderung der Wissenschaftlichen Forschung (FWF) under grant number P10489-MAT.
Reference: [Kivinen & Mannila, 1995] <author> Kivinen J., Mannila H.: </author> <title> Approximate dependency inference from relations, </title> <journal> Theoretical Computer Science, </journal> <volume> 149(1) </volume> <pages> 129-149, </pages> <year> 1995. </year>
Reference-contexts: But their modification can only take into account the number of "errors" in the projection, whereas a reliable estimate would need to assess the global number of "errors". <ref> [Kivinen & Mannila, 1995] </ref> contains a thorough theoretical analysis of approximate inference of data dependencies. The paper discusses three different measures of approximate functional dependencies which can be used in a sampling framework. <p> Another challenge would be a tight integration of the search for functional dependencies and the search for partial determinations. Finally, it would be interesting to compare and combine our approach with sampling techniques as proposed in [Kivinen & Mannila, 1993] and <ref> [Kivinen & Mannila, 1995] </ref>. Acknowledgements This research is partly sponsored by the Austrian Fonds zur Forderung der Wissenschaftlichen Forschung (FWF) under grant number P10489-MAT. Financial support for the Austrian Research Institute for Artificial Intelligence is provided by the Austrian Federal Ministry of Science, Research, and Arts.
Reference: [Mannila & Raiha, 1994] <author> Mannila H. and Raiha K.-J.: </author> <title> Algorithms for Inferring Functional Dependencies From Relations. </title> <booktitle> Data & Knowledge Engineering 12 (1994) 83-99, </booktitle> <year> 1994. </year>
Reference-contexts: 1 Introduction Functional dependencies <ref> [Mannila & Raiha, 1994] </ref> are a fundamental form of knowledge to be discovered in databases. In real-world databases, however, we have to face the effects of noise on functional dependencies: dependencies among attributes that would have been functional without noise are likely to have exceptions. <p> Other findings included, amongst others, implicit database design conventions, and redundancies due to the flat table representation of what was actually structured knowledge. We discovered strong partial determinations that indeed reflect the implicit and hidden structure of the dataset. 6 7 Related Work Functional dependencies <ref> [Mannila & Raiha, 1994] </ref> are essentially relational and do not allow for the possibility of exceptions. On the contrary, association rules [Agrawal & Srikant, 1994] not only allow for the possibility of exceptions, but are essentially probabilistic.
Reference: [Pfahringer & Kramer, 1995] <author> Pfahringer B., Kramer S.: </author> <title> Compression-Based Evaluation of Partial Determinations, </title> <booktitle> Proceedings of the First International Conference on Knowledge Discovery and Data Mining, </booktitle> <publisher> AAAI Press, </publisher> <year> 1995. </year>
Reference-contexts: More precisely and in machine learning terms, they would overfit the data, meaning that these algorithms would find too specific functional dependencies instead of the ones we would like to find. In contrast to functional dependencies, partial determinations ([Russell, 1989], <ref> [Pfahringer & Kramer, 1995] </ref>) or approximate functional dependencies allow for exceptions. Partial determinations may reflect probabilistic dependencies among attributes, but they may also be "impure" functional dependencies, i.e. functional dependencies which are distorted by noise and have only a few exceptions. In this paper, as in [Pfahringer & Kramer, 1995], we <p> partial determinations ([Russell, 1989], <ref> [Pfahringer & Kramer, 1995] </ref>) or approximate functional dependencies allow for exceptions. Partial determinations may reflect probabilistic dependencies among attributes, but they may also be "impure" functional dependencies, i.e. functional dependencies which are distorted by noise and have only a few exceptions. In this paper, as in [Pfahringer & Kramer, 1995], we deal with those partial determinations which help to compress a given database as much as possible. These highly compressive partial determinations will be called strong partial determinations. In the next section we define and compare functional dependencies and partial determinations. <p> These highly compressive partial determinations will be called strong partial determinations. In the next section we define and compare functional dependencies and partial determinations. In the third section we summarize the ideas from <ref> [Pfahringer & Kramer, 1995] </ref>. Subsequently, we define and explain a new compression-based measure for partial determinations ranging over n-valued attributes. Then we describe an efficient method to search for strong partial determinations. <p> To avoid this, we also have to take into account how 2 complex partial determinations are. Therefore, <ref> [Pfahringer & Kramer, 1995] </ref> proposes a compression-based measure based on the so-called Minimum Description Length (MDL) principle [Rissanen, 1978]. <p> The theory with the minimal total message length (the most compressive partial determination) is also the most probable theory explaining the data [Rissanen, 1978]. To illustrate the key idea of the measure for partial determinations proposed in <ref> [Pfahringer & Kramer, 1995] </ref>, we consider the hypothetical task of transmitting a given database as efficiently as possible (see fig. 1). <p> The values of Y need not be transmitted anymore. Thus we achieve some compression of the data, the degree of which is estimated by our measure based on the MDL principle. The work reported in <ref> [Pfahringer & Kramer, 1995] </ref> has several limitations and problems: the paper only deals with partial determinations ranging over boolean attributes. Secondly, the problem of efficiently finding compressive partial determinations has not been solved. The paper compared three search methods: hill-climbing, exhaustive search up to a certain depth, and stochastic search. <p> On the contrary, association rules [Agrawal & Srikant, 1994] not only allow for the possibility of exceptions, but are essentially probabilistic. Partial determinations ([Russell, 1989], <ref> [Pfahringer & Kramer, 1995] </ref>) can be viewed as generalizations of both functional dependencies and association rules, in that they are relational in nature and may have exceptions. As we have shown in [Pfahringer & Kramer, 1995], extending the measures used for evaluating association rules, namely support and confidence, to partial determinations <p> Partial determinations ([Russell, 1989], <ref> [Pfahringer & Kramer, 1995] </ref>) can be viewed as generalizations of both functional dependencies and association rules, in that they are relational in nature and may have exceptions. As we have shown in [Pfahringer & Kramer, 1995], extending the measures used for evaluating association rules, namely support and confidence, to partial determinations leads to several problems. The term "partial determination" has been introduced by Russell ([Russell, 1989]). He also described a method for evaluating partial determinations with respect to given facts. <p> The reliability measure is supposed to measure the "functional degree" of the map given subsequent data. As we have argued in <ref> [Pfahringer & Kramer, 1995] </ref>, this measure does not avoid overfitting the data, since it does not have a penalty for overly complex dependencies. [Bell & Brockhausen, 1995] hint at a simple modification of their functional dependency search algorithm to cope with noise. <p> Secondly, we tackled the problem of efficiently finding strong (i.e., highly compressive) partial determinations, which has not been solved 7 in <ref> [Pfahringer & Kramer, 1995] </ref>. Focusing attention on a highly interesting subset of partial determinations (those which could be functional dependencies distorted by noise) enables efficient search for strong partial determinations. Note that basically any algorithm for inferring functional dependencies could be used in the first step of our method. <p> It is also important to note that this approach is based on assumptions about real-world data, namely that there are strict functional dependencies which are distorted by noise. In this paper we also generalize the compression-based measure proposed in <ref> [Pfahringer & Kramer, 1995] </ref> to partial determinations ranging over n-valued attributes. Applications to real-world data suggest the usefulness of our approach. Our approach to searching for partial determinations has several limitations: clearly, we cannot find all partial determinations, but only a subset.
Reference: [Rissanen, 1978] <author> J. Rissanen: </author> <title> Modeling by Shortest Data Description. In: </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: To avoid this, we also have to take into account how 2 complex partial determinations are. Therefore, [Pfahringer & Kramer, 1995] proposes a compression-based measure based on the so-called Minimum Description Length (MDL) principle <ref> [Rissanen, 1978] </ref>. The MDL principle tries to measure both the simplicity and the accuracy of a particular theory (in our setting: a partial determination) in a common currency, namely in terms of the number of bits needed for encoding both a theory and the data given that theory. <p> The theory with the minimal total message length (the most compressive partial determination) is also the most probable theory explaining the data <ref> [Rissanen, 1978] </ref>. To illustrate the key idea of the measure for partial determinations proposed in [Pfahringer & Kramer, 1995], we consider the hypothetical task of transmitting a given database as efficiently as possible (see fig. 1).
Reference: [Russell, 1989] <author> Russell S.J.: </author> <title> The Use of Knowledge in Analogy and Induction. </title> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: In the following, we will restrict ourselves to RHSs consisting of single attributes. Semantically, X ! d Y holds in r, denoted r j= X ! d Y , if d is the determination factor d (X; Y ) as defined by <ref> [Russell, 1989] </ref>. The determination factor is the probability that two randomly chosen tuples have the same values of Y , provided they have the same values of X. Note that d (X; Y ) is defined without regard to a particular mapping from Dom (X) to Dom (Y ).
Reference: [Schlimmer, 1993] <author> Schlimmer J.C.: </author> <title> Efficiently Inducing Determinations: A Complete and Systematic Search Algorithm that Uses Optimal Pruning. </title> <booktitle> Proceedings of the 10 th International Conference on Machine Learning, </booktitle> <year> 1993. </year>
Reference-contexts: Furthermore, the determinations of interest are like association rules in that they have binary attributes. The algorithm generates such simple determinations and returns them if the support is bigger than the counter-support and if a statistical test suggests their significance. <ref> [Schlimmer, 1993] </ref> proposes an algorithm that returns every "reliable" partial determination with a complexity lower than a user-defined threshold. The reliability measure is supposed to measure the "functional degree" of the map given subsequent data.
Reference: [Shannon & Weaver, 1949] <author> Shannon C.E. and Weaver W.: </author> <title> The Mathematical Theory of Communication, </title> <publisher> University of Illinois Press, </publisher> <year> 1949. </year>
Reference-contexts: For estimating the cost c choose of encoding the selection of E elements out of N possible elements (4) we just use the theoretical entropy-based bound provided by 4 <ref> [Shannon & Weaver, 1949] </ref>. Encoding a string over a multi-valued alphabet (5) is a straightforward generalization of (4). It can be thought of as a repeated binary selection encoding of what is the value occurring most frequently and which positions in the string are exceptions, i.e. have a different value.
Reference: [Shen, 1991] <author> Shen W.-M.: </author> <title> Discovering Regularities from Large Knowledge Bases. </title> <booktitle> Proceedings of the 8 th International Workshop on Machine Learning, </booktitle> <year> 1991. </year> <month> 9 </month>
Reference-contexts: He also described a method for evaluating partial determinations with respect to given facts. Briefly, Russell uses sampling to estimate the proportion of tuples in the database for which the determination holds. In other words, he estimates nothing else but the accuracy, and thus the overfitting argument applies. <ref> [Shen, 1991] </ref> describes an algorithm that searches for three kinds of regularities in a large knowledge base. One of those regularities are determinations, but they are restricted to those having only a single attribute in the left-hand side.
References-found: 12

