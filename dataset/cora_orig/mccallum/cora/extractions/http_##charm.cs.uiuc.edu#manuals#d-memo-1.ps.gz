URL: http://charm.cs.uiuc.edu/manuals/d-memo-1.ps.gz
Refering-URL: http://charm.cs.uiuc.edu/manuals/
Root-URL: http://www.cs.uiuc.edu
Title: Abstract  
Keyword: Index Terms Heterogeneous computing. Parallel and distributed processing. Directories of unordered queues. Dynamic Data Migration. Portability. Extensibility.  
Abstract: Heterogeneously distributed and parallel computing environments are highly dependent on hardware, data migration, and protocols. The result is significant difficulty in software reuse, portability across platforms, and an increased overall development effort. The appearance of a shared directory of unordered queues can be provided by integrating heterogeneous computers transparently. This integration provides a conducive environment for parallel and distributed application development, by abstracting the issues of hardware and communication. Object oriented technology is exploited to provide this seamless environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Khokhar, et al., </author> <title> Challenges and Opportunities, </title> <journal> IEEE Computer, June 1993, </journal> <volume> vol. 26, no. 6, </volume> <pages> pp. 18-27 </pages>
Reference-contexts: 1 Introduction Heterogeneous computing (HC) allows parallel and distributed applications to achieve a higher level of performance at a lower cost/performance ratio. HC provides the ability to coordinate a wide range of diverse high-performance machines, each being used for computationally demanding tasks <ref> [1] </ref>. This provides the ability to differentiate between code, algorithms, and data to optimize the matching of computational tasks to the appropriate machine [2]. However, this leads to difficulty in writing parallel and distributed programs in an easy, efficient, and portable manner. <p> Instead of pointers to objects, we use folder names. 6.2.2 Arrays Arrays of shared objects may be created similarly. The element a [i,j] can be stored in a folder whose name is constructed as: FOLDER_NAME key; SYMBOL a; ... a = memo.create_symbol (); key.S = a; key.X <ref> [1] </ref> = j; The above example illustrates using the key name to build a 2-dimensional array abstraction. 6.2.3 Unordered Queues A folder is an unordered queue, so if order is not vitally important, process can communicate simply by passing memos through a folder. 6.2.4 Job Jar An important use of an
Reference: [2] <author> R.F. Freund, H.J. Siegel, </author> <title> Heterogeneous Processing, </title> <journal> IEEE Computer, June 1993, </journal> <volume> vol. 26, no. 6, </volume> <pages> pp. 13-17. </pages>
Reference-contexts: HC provides the ability to coordinate a wide range of diverse high-performance machines, each being used for computationally demanding tasks [1]. This provides the ability to differentiate between code, algorithms, and data to optimize the matching of computational tasks to the appropriate machine <ref> [2] </ref>. However, this leads to difficulty in writing parallel and distributed programs in an easy, efficient, and portable manner. The complexity arises from the differences in specialized hardware, incompatible data domain mappings, communication protocols, operating system interfaces, and other distinguishing characteristics (e.g. number of processors, shared versus distributed memory).
Reference: [3] <author> A. Deogirikar, </author> <title> Keynote Speaker, </title> <booktitle> TOOLS USA 93 Conf. on OO Tech. </booktitle> <address> Santa Barbara, CA. </address> <month> Summer 93. </month>
Reference-contexts: In addition to the basic HC problems, emerging technology is changing the shape of computing. One trend indicates that many parallel and distributed applications may potentially be a workstation phenomenon rather than a specialized parallel hardware phenomenon. As shown by Eq. (1), processor performance is doubling annually since 1984 <ref> [3] </ref>. Workstations are typically the first to exploit new processor technology. Additionally, networking speeds are jumping by an order of magnitude on average, every three years [3]. <p> As shown by Eq. (1), processor performance is doubling annually since 1984 <ref> [3] </ref>. Workstations are typically the first to exploit new processor technology. Additionally, networking speeds are jumping by an order of magnitude on average, every three years [3]. Recent research in networking protocols, such as Distributed Queueing Random Access Protocol (DQRAP), has shown that M/D/1 performance numbers can be achieved over a broadcast channel [13]. This results in a near ideal hardware environment for HC. The fact is that workstations are economical.
Reference: [4] <author> T.W. Christopher, </author> <title> Message Driven Computing and its Relationship to Actors, </title> <booktitle> Proc. ACM Sigplan Wkshop on Object-Based Conc. Prog., </booktitle> <address> San Diego, CA. </address> <year> 1988. </year>
Reference-contexts: Languages we have implemented on top of the API include: Message Driven Computing language, a pattern driven language based on Actors <ref> [4] </ref>. Lucid, a dataow programming language [5]. We have found that these languages are excellent for writing parallel programs (as well as using D-Memos API itself).
Reference: [5] <author> G.K. Thiruvathukal, et al., </author> <title> A Simulation of Demand Driven Dataow: Translation of Lucid into Message Driven Computing Language., </title> <booktitle> 5th Intl Symp. on Parallel Proc., </booktitle> <address> Anaheim, Ca. </address> <year> 1991. </year>
Reference-contexts: Languages we have implemented on top of the API include: Message Driven Computing language, a pattern driven language based on Actors [4]. Lucid, a dataow programming language <ref> [5] </ref>. We have found that these languages are excellent for writing parallel programs (as well as using D-Memos API itself).
Reference: [6] <author> D. Gelernter, </author> <title> Generative Communication in Linda, </title> <journal> ACM Transactions on Parallel Languages and Systems, </journal> <volume> Vol. 7, No 1, </volume> <month> Jan. </month> <year> 1985, </year> <pages> Pages 80-112. </pages>
Reference-contexts: The API provides a rich set of primitives for supporting many synchronization mechanisms and programming paradigms. Examples include named objects, arrays of objects, locks, semaphores, unordered and ordered queues, job jars, futures, incremental structures, and barriers (see Memo Language (API) on page 6). The API is inuenced by Linda <ref> [6] </ref>, but it has been scaled down in features of dubious value and augmented with features of proven value. 3 Abstracting the HC Environment Object oriented design (OOD) was chosen for implementation, because it offers several advantages over the commonly used (or abused) structured methodologies. <p> By defining unique application names, applications will share data between only their own processes. This sharing of data is fully distributed in time and in space, as is Linda <ref> [6] </ref>. By using common application names, different programs will be able to communicate. This provides the idea of being fully distributed in time and space over multiple applications. Note that eventhough the memo servers are shared over applications, each memo server is loaded with unique routing tables for each application. <p> The Linda research was used to create the illusion of a virtual machine, wherein an arbitrary number of processes communicated via a virtual shared memory known as a tuple space <ref> [6] </ref>. We believe that this tuple space is just a at directory of unordered queues. Using this approach, we are able to provide better programming abstractions then Linda (e.g. job jars, dataow). Parallel Virtual Machine (PVM) is a low-level approach taken to support the virtual machine concept [11].
Reference: [7] <author> W. OConnell, et al. </author> <title> A Generic Modelling Framework for Building Heterogenous Distributed and Parallel Environments, </title> <booktitle> Proc. 10th Intl Conf. on Adv. </booktitle> <institution> Sci. & Tech., Naperville, Il, </institution> <month> March, </month> <year> 1994. </year>
Reference-contexts: Other systems do not. The abstract class must be able to cope with both cases 3.1 HC Foundations (Abstractions) Our approach has been to define and implement four general HC abstractions. The core set is: communication, shared-memory, transferable, and locking. These abstractions are based on the Generic Modelling Framework <ref> [7] </ref>. To support a new platform in a HC network one must consider each of these four abstractions. Often it is merely a matter of extending one or two of them to support the new platform. The OO terminology for this idea is class derivation.
Reference: [8] <author> Blossom, </author> <title> Decoding ASN.1 Transfer Syntax, The C Users journal, </title> <booktitle> Sept. </booktitle> <volume> 91, vol. 9, num. 9, </volume> <pages> pp 57-63. </pages>
Reference-contexts: Transferables encode/decode themselves recursively, so that messages may be created from either previously user defined or base transferables. The inspiration for the transferable classes is found in the Abstract Syntax Notation/1 (ASN.1) <ref> [8] </ref> and the XDR library supported by Sun RPC. There are two major differences, however, between the mechanisms supported by the transferable classes and these other methods of encoding data. The major difference is that arbitrary data structures, even self-referential structures, can be moved with ease via the transferable classes.
Reference: [9] <author> Arvind. I-structures: </author> <title> An Efficient Data Type for Functional Languages, TR LCS/TM-178, </title> <publisher> MIT, </publisher> <pages> 80 </pages>
Reference-contexts: Both the producer and the consumer may run in parallel, with the consumer only being delayed if it attempts to fetch from a variable before it has been assigned. An I-structure (an incremental structure) is a collection (e.g. an array) of futures. I-structures were invented for dataow <ref> [9] </ref>. In D-Memo, any folder that will have only one memo ever placed into it may correspond to a future. The consumer executing a get, get_copy, or get_alt fetching from the folder will be delayed until the value has been produced. The folder will vanish once the memo is removed.
Reference: [10] <author> A.H. </author> <title> Veen Data Flow Architecture, </title> <journal> ACM Computing Surveys, </journal> <volume> 18, 4, </volume> <month> Dec. </month> <year> 1986. </year> <pages> pp. 365-396. </pages>
Reference: [11] <author> Beguelin, A. et al. </author> <title> A Users Guide to PVM: Parallel Virtual Machine, </title> <journal> TR ORNL/TM-11826, Sept.91. </journal>
Reference-contexts: We believe that this tuple space is just a at directory of unordered queues. Using this approach, we are able to provide better programming abstractions then Linda (e.g. job jars, dataow). Parallel Virtual Machine (PVM) is a low-level approach taken to support the virtual machine concept <ref> [11] </ref>. A system service is provided for each machine on a heterogeneous network. The interface between two processes on the network is possible via a subroutine library. The routines in the subroutine library allow processes to communicate with one another without knowing the details of communicating with the system service.
Reference: [12] <author> A. </author> <title> Grimshaw Easy-to-Use object oriented Parallel Processing with Mentat, </title> <booktitle> IEEE Computer, </booktitle> <month> May 93 </month>
Reference-contexts: Mentat is a system that offers many of the advantages of the Linda and PVM systems with some enhancements <ref> [12] </ref>. At the application level it offers a balance between explicit and implicit parallelism by providing an extended C++ development language. Through C++ extensions and a run time system, Mentat is able to provide applications with an environment to support fine-grain and coarse-grain parallelism.
Reference: [13] <author> W. Xu, G. Campbell, </author> <title> A Distributed Queueing Random Access Protocol for a Broadcast Channel. </title> <journal> Comp. Comm. Review, ACM SIGCOMM, </journal> <month> Oct. 93. </month>
Reference-contexts: Additionally, networking speeds are jumping by an order of magnitude on average, every three years [3]. Recent research in networking protocols, such as Distributed Queueing Random Access Protocol (DQRAP), has shown that M/D/1 performance numbers can be achieved over a broadcast channel <ref> [13] </ref>. This results in a near ideal hardware environment for HC. The fact is that workstations are economical. Most organizations can not afford specialized machines. If they can, the number is limited.
References-found: 13

