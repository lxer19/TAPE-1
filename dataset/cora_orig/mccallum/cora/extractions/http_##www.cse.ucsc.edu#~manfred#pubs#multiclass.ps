URL: http://www.cse.ucsc.edu/~manfred/pubs/multiclass.ps
Refering-URL: http://www.cse.ucsc.edu/~manfred/pubs.html
Root-URL: http://www.cse.ucsc.edu
Email: Jyrki.Kivinen@cs.Helsinki.FI  manfred@cse.ucsc.edu  
Title: Relative Loss Bounds for Multidimensional Regression Problems  
Author: Jyrki Kivinen Manfred K. Warmuth 
Date: June 24, 1997  
Address: P.O. Box 26 (Teollisuuskatu 23)  Finland  Santa Cruz, CA 95064 USA  
Affiliation: Department of Computer Science  University of Helsinki  Department of Computer Science University of California, Santa Cruz  
Pubnum: FIN-00014  
Abstract: We study on-line generalized linear regression with multidimensional outputs, i.e., neural networks with multiple output nodes but no hidden nodes. We allow at the final layer transfer functions such as the softmax function that need to consider the linear activations to all the output neurons. We also use a parameterization function which transforms parameter vectors maintained by the algorithm into the actual weights. The on-line algorithm we consider updates the parameters in an additive manner, analogous to the delta rule, but because the actual weights are obtained via the possibly nonlinear parameterization function they may behave in a very different manner. Our approach is based on applying the notion of a matching loss function in two different contexts. First, we measure the loss of the algorithm in terms of the loss that matches the transfer function used to produce the outputs. Second, the loss function that matches the parameterization function can be used both as a measure of distance between models in motivating the update rule of the algorithm and as a potential function in analyzing its relative performance compared to an arbitrary fixed model. As a result, we have a unified treatment that generalizes earlier results for the gradient descent and exponentiated gradient algorithms to multidimensional outputs, including multiclass logistic regression.
Abstract-found: 1
Intro-found: 1
Reference: [AHW95] <author> P. Auer, M. Herbster, and M. K. Warmuth. </author> <title> Exponentially many local minima for single neurons. </title> <booktitle> In Proc. 1995 Neural Information Processing Conference, </booktitle> <pages> pages 316-317. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: In particular, when we apply the logistic transfer function and try to find a weight vector ! that minimizes the total square loss over ` examples (x t ; y t ), we may have up to ` n local minima <ref> [AHW95, Bud93] </ref>. Hence, some other choice of loss function might be more convenient. <p> In the one-dimensional case, for a strictly increasing continuous it is possible to define a matching loss function L which has the property that the total loss is a convex function of the weight vector ! and thus, in particular, has no spurious local minima <ref> [AHW95, HKW95] </ref>. For example, the matching loss function for the logistic transfer function is the relative entropy (a generalization of the logarithmic loss for continuous-valued outcomes). The main theme of this paper is the generalization of the notion of the matching loss function for multidimensional outputs. <p> For discussion of our line of research in the context of statistics see Azoury and Warmuth [AW97]. Consider first the one-dimensional case, with a differentiable transfer function : R ! R such that 0 (a) &gt; 0 for all a. For this case, the matching loss <ref> [AHW95] </ref> is defined by L (y; ^y) = 1 (y) where we have used the fact that must be invertible. Figure 1 gives a graphical representation.
Reference: [Ama85] <author> S. Amari. </author> <title> Differential Geometrical Methods in Statistics. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: the multidimensional case and has as its matching loss function the relative entropy for multiclass output L (y; b y) = j=1 y j : (3) The loss L ((a); ( b a)) can be interpreted as the relative entropy between two densities with parameters a and b a, respectively <ref> [Ama85] </ref>. The parameterized densities are from the exponential family of densities characterized by . Similar loss functions have been also used in other work on generalized linear models [MN89, FT91]. <p> The general nature of relative on-line loss bounds, and the particular results we have for the general additive algorithm, are explained in Section 4. 2 Matching loss functions Our notion of matching loss is the same that is used by Amari <ref> [Ama85] </ref> and others [MN89, FT91]. As we are here not directly interested in probabilistic interpretations, this literature is not a convenient source and we prefer to derive directly the few basic properties we need.
Reference: [AW97] <author> K. Azoury and M. K. Warmuth. </author> <title> Relative loss bounds and the exponential family of distributions. </title> <type> Unpublished manuscript, </type> <year> 1997. </year>
Reference-contexts: The parameterized densities are from the exponential family of densities characterized by . Similar loss functions have been also used in other work on generalized linear models [MN89, FT91]. These statistical interpretations of the loss function and relative loss bounds are discussed in a future paper <ref> [AW97] </ref>; here we need only some very basic properties of the matching loss. The most obvious new result we obtain comes from observing that the results of Helmbold et al. [HKW95] for matching loss functions in the one-dimensional case generalize almost directly into 2 the multidimensional case. <p> As we are here not directly interested in probabilistic interpretations, this literature is not a convenient source and we prefer to derive directly the few basic properties we need. For discussion of our line of research in the context of statistics see Azoury and Warmuth <ref> [AW97] </ref>. Consider first the one-dimensional case, with a differentiable transfer function : R ! R such that 0 (a) &gt; 0 for all a. For this case, the matching loss [AHW95] is defined by L (y; ^y) = 1 (y) where we have used the fact that must be invertible.
Reference: [Bud93] <author> M. Budinich. </author> <title> Some notes on perceptron learning. </title> <journal> J. Phys. A.: Math. Gen., </journal> <volume> 26 </volume> <pages> 4237-4247, </pages> <year> 1993. </year>
Reference-contexts: In particular, when we apply the logistic transfer function and try to find a weight vector ! that minimizes the total square loss over ` examples (x t ; y t ), we may have up to ` n local minima <ref> [AHW95, Bud93] </ref>. Hence, some other choice of loss function might be more convenient.
Reference: [CB97] <author> N. Cesa-Bianchi. </author> <title> Analysis of two gradient-based algorithms for on-line regression. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory. ACM, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: In work parallel to this, the general additive update (5) in the context of linear classification, i.e., with a thresholded transfer function, has recently been developed and analyzed by Grove et al. [GLS97] with methods and results very similar to ours. Cesa-Bianchi <ref> [CB97] </ref> has used somewhat different methods to obtain bounds also in cases in which the loss function does not match the transfer function. <p> Here we consider only the case k = 1 with one-dimensional outputs; some of these ideas also generalize to the multi-dimensional case. First we see how the methods used by Cesa-Bianchi <ref> [CB97] </ref> to deal with nonmatching loss functions relate to our present framework. Fix now a strictly increasing differentiable tranfer function : R ! R, and let L be a twice differentiable function on V fi V such that L (y; (! x)) is convex in !. <p> In the case of linear regression, with the identity function as the transfer function , this property holds for any convex loss function, and Cesa-Bianchi <ref> [CB97] </ref> has shown that it also is holds for the Hellinger loss with the logistic function as the transfer function. <p> By checking the proof of Lemma 8 we can easily see that Lemma 8 remains true if we replace GA by GA L and Loss by Loss L; where L satisfier the convexity condition given above. To see how bounds such as those given by Cesa-Bianchi <ref> [CB97] </ref> can be obtained from Lemma 8, we derive for the terms ( t+1 ; t ) bounds somewhat different from those of the proof of Lemma 9. <p> ) + 2 13 Choosing = q 2 ( 1 ; fl )=`b X ; =Z gives Loss L; (GA L ( ; ; fi 1 ; ); S) Loss L; ( ( fl ); S) + Z q from which we get essentially the basic bound given by Cesa-Bianchi <ref> [CB97, Theorem 4] </ref> for the gradient descent and exponentiated gradient algorithms by bounding b X ; as shown in Example 5 for the identity and softmax functions.
Reference: [FT91] <author> L. Fahrmeir and G. Tutz. </author> <title> Multivariate Statistical Modelling Based on Generalized Linear Models. </title> <publisher> Springer-Verlag, </publisher> <address> New-York, </address> <year> 1991. </year>
Reference-contexts: The parameterized densities are from the exponential family of densities characterized by . Similar loss functions have been also used in other work on generalized linear models <ref> [MN89, FT91] </ref>. These statistical interpretations of the loss function and relative loss bounds are discussed in a future paper [AW97]; here we need only some very basic properties of the matching loss. <p> The general nature of relative on-line loss bounds, and the particular results we have for the general additive algorithm, are explained in Section 4. 2 Matching loss functions Our notion of matching loss is the same that is used by Amari [Ama85] and others <ref> [MN89, FT91] </ref>. As we are here not directly interested in probabilistic interpretations, this literature is not a convenient source and we prefer to derive directly the few basic properties we need. For discussion of our line of research in the context of statistics see Azoury and Warmuth [AW97].
Reference: [Fos91] <author> D. P. Foster. </author> <title> Prediction in the worst case. </title> <journal> The Annals of Statistics, </journal> <volume> 19(2) </volume> <pages> 1084-1090, </pages> <year> 1991. </year>
Reference-contexts: In the basic case of linear regression, this results in the on-line linear least squares method. Relative loss bounds for such updates have been obtained by Foster <ref> [Fos91] </ref> and Vovk [Vov97]. 4 Relative loss bounds Our goal is to provide for the algorithm's loss upper bounds that hold for arbitrary trial sequences S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )).
Reference: [GLS97] <author> A. J. Grove, N. Littlestone, and D. Schuurmans. </author> <title> General convergence results for linear discriminant updates. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory. ACM, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: In work parallel to this, the general additive update (5) in the context of linear classification, i.e., with a thresholded transfer function, has recently been developed and analyzed by Grove et al. <ref> [GLS97] </ref> with methods and results very similar to ours. Cesa-Bianchi [CB97] has used somewhat different methods to obtain bounds also in cases in which the loss function does not match the transfer function. <p> The same notion of distance is also used by Grove et al. <ref> [GLS97] </ref>. To obtain a formula more obviously analogous with the one-dimensional case (6) we can write ( b a; a) = a where the integral is a path integral the value of which must be independent of the actual path chosen between a and b a. <p> [HKW95] in the case of one-dimensional output with an arbitrary strictly increasing differentiable transfer function and a matching loss function. (In these articles the algorithm is called the gradient descent algorithm when is the identity function and the exponentiated gradient algorithm when is the softmax function.) Recently Grove et al. <ref> [GLS97] </ref> have shown how in the thresholded case it is possible to obtain bounds in terms of a general class of pairs of dual norms by choosing the appropriate parameterization function . We now turn to proving Theorem 7.
Reference: [HKW95] <author> D. P. Helmbold, J. Kivinen, and M. K. Warmuth. </author> <title> Worst-case loss bounds for sigmoided linear neurons. </title> <booktitle> In Proc. 1995 Neural Information Processing Conference, </booktitle> <pages> pages 309-315. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: In the one-dimensional case, for a strictly increasing continuous it is possible to define a matching loss function L which has the property that the total loss is a convex function of the weight vector ! and thus, in particular, has no spurious local minima <ref> [AHW95, HKW95] </ref>. For example, the matching loss function for the logistic transfer function is the relative entropy (a generalization of the logarithmic loss for continuous-valued outcomes). The main theme of this paper is the generalization of the notion of the matching loss function for multidimensional outputs. <p> These statistical interpretations of the loss function and relative loss bounds are discussed in a future paper [AW97]; here we need only some very basic properties of the matching loss. The most obvious new result we obtain comes from observing that the results of Helmbold et al. <ref> [HKW95] </ref> for matching loss functions in the one-dimensional case generalize almost directly into 2 the multidimensional case. In particular, we generalize the result for the logistic transfer function to obtain a similar result for multiclass classification through the softmax function. <p> Thus, gradient descent (GD) is the special case in which the parameterization function is the identity function. On the other hand, if we take to be the softmax function (2), then (5) gives the exponentiated gradient (EG) update <ref> [KW97, HKW95] </ref>. The update (5) may appear unmotivated if the parameterization function is completely arbitrary, but if has a matching loss function L for which (1) holds then (5) turns out to be natural and effective. <p> In these bounds we again use the matching loss, now to measure the progress of the weight vector in each update. The techniques used in the motivation and loss bound proofs are generalizations of the techniques used earlier <ref> [KW97, HKW95] </ref> in the special cases of gradient descent algorithm (with the square Euclidean distance as the distance function) and the exponentiated gradient algorithm (with relative entropy as the distance function). <p> A more detailed discussion of the bounds for these special case is given by Kivinen and Warmuth [KW97] for the linear regression case and by Helmbold et al. <ref> [HKW95] </ref> in the case of one-dimensional output with an arbitrary strictly increasing differentiable transfer function and a matching loss function. (In these articles the algorithm is called the gradient descent algorithm when is the identity function and the exponentiated gradient algorithm when is the softmax function.) Recently Grove et al. [GLS97]
Reference: [KW97] <author> J. Kivinen and M. K. Warmuth. </author> <title> Additive versus exponentiated gradient updates for linear prediction. </title> <journal> Information and Computation, </journal> <volume> 132(1) </volume> <pages> 1-64, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: In particular, we generalize the result for the logistic transfer function to obtain a similar result for multiclass classification through the softmax function. The more interesting part of this work is that we refine previous techniques <ref> [KW97] </ref> for applying a matching loss function as a distance function in deriving and analyzing on-line algorithms for updating the weights used in prediction. Recall that these weights compose a matrix 2 R kfiR . <p> Thus, gradient descent (GD) is the special case in which the parameterization function is the identity function. On the other hand, if we take to be the softmax function (2), then (5) gives the exponentiated gradient (EG) update <ref> [KW97, HKW95] </ref>. The update (5) may appear unmotivated if the parameterization function is completely arbitrary, but if has a matching loss function L for which (1) holds then (5) turns out to be natural and effective. <p> In these bounds we again use the matching loss, now to measure the progress of the weight vector in each update. The techniques used in the motivation and loss bound proofs are generalizations of the techniques used earlier <ref> [KW97, HKW95] </ref> in the special cases of gradient descent algorithm (with the square Euclidean distance as the distance function) and the exponentiated gradient algorithm (with relative entropy as the distance function). <p> The case of the softmax function is a little more complicated. As the range of the softmax function is limited to the probability simplex, we cannot directly represent weight vectors with arbitrarily large norms through this parameterization function. However, simple standard reductions (see e.g. <ref> [KW97] </ref> for details) allow us to represent vectors with arbitrarily large norms and both positive and negative components. <p> A more detailed discussion of the bounds for these special case is given by Kivinen and Warmuth <ref> [KW97] </ref> for the linear regression case and by Helmbold et al. [HKW95] in the case of one-dimensional output with an arbitrary strictly increasing differentiable transfer function and a matching loss function. (In these articles the algorithm is called the gradient descent algorithm when is the identity function and the exponentiated gradient
Reference: [MN89] <author> P. McCullagh and J. A. Nelder. </author> <title> Generalized Linear Models. </title> <publisher> Chapman & Hall, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: The square loss given by P t;j (y t;j ^y t;j ) 2 =2 is a popular choice and and in many situation suitable in particular for linear regression. In generalized linear regression <ref> [MN89] </ref> we fix a transfer function and apply it on top of a linear model. Thus, in the one-dimensional case we would have ^y t = (! x t ). <p> The parameterized densities are from the exponential family of densities characterized by . Similar loss functions have been also used in other work on generalized linear models <ref> [MN89, FT91] </ref>. These statistical interpretations of the loss function and relative loss bounds are discussed in a future paper [AW97]; here we need only some very basic properties of the matching loss. <p> The general nature of relative on-line loss bounds, and the particular results we have for the general additive algorithm, are explained in Section 4. 2 Matching loss functions Our notion of matching loss is the same that is used by Amari [Ama85] and others <ref> [MN89, FT91] </ref>. As we are here not directly interested in probabilistic interpretations, this literature is not a convenient source and we prefer to derive directly the few basic properties we need. For discussion of our line of research in the context of statistics see Azoury and Warmuth [AW97].
Reference: [Vov97] <author> V. Vovk. </author> <title> Competitive on-line linear regression. </title> <type> Unpublished manuscript., </type> <year> 1997. </year>
Reference-contexts: In the basic case of linear regression, this results in the on-line linear least squares method. Relative loss bounds for such updates have been obtained by Foster [Fos91] and Vovk <ref> [Vov97] </ref>. 4 Relative loss bounds Our goal is to provide for the algorithm's loss upper bounds that hold for arbitrary trial sequences S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )).
Reference: [WJ97] <author> M. K. Warmuth and A. K. Jagota. </author> <title> Continuous versus discrete-time nonlinear gradient descent: Relative loss bounds and convergence. </title> <note> Submitted to NIPS fl 97. 15 </note>
Reference-contexts: Cesa-Bianchi [CB97] has used somewhat different methods to obtain bounds also in cases in which the loss function does not match the transfer function. Warmuth and Jagota <ref> [WJ97] </ref> view (5) as an Euler discretization of a system of partial differential equations and investigate the behavior of the relative loss bounds as the discretization parameter approaches zero. In Section 2 we review some basic properties of matching loss functions and give some examples. <p> This is to maintain consistency with the notation of <ref> [WJ97] </ref>.) To see the simplest way of generalizing (6) into multiple dimensions we write it as L ((a); (^a)) = P (^a) P (a) (a)(^a a) where P is an integral function of . As 0 (a) &gt; 0 for all a, the integral function P is convex. <p> We now turn to proving Theorem 7. The following key lemma is a straightforward generalization of a result of Warmuth and Jagota <ref> [WJ97] </ref>. Lemma 8 Let fi t+1 denote the parameter matrix of GA ( ; ; fi 1 ; ) after trial t on a trial sequence S.
References-found: 13

