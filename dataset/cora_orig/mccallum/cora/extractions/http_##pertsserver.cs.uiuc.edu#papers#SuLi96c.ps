URL: http://pertsserver.cs.uiuc.edu/papers/SuLi96c.ps
Refering-URL: http://pertsserver.cs.uiuc.edu/papers/
Root-URL: http://www.cs.uiuc.edu
Email: fjsun, janeliug@cs.uiuc.edu  
Title: Synchronization Protocols in Distributed Real-Time Systems  
Author: Jun Sun Jane Liu 
Address: Urbana, IL 61801  
Affiliation: Department of Computer Science, University of Illinois, Urbana-Champaign  
Abstract: In many distributed real-time systems, the workload can be modeled as a set of periodic tasks, each of which consists of a chain of subtasks executing on different processors. Synchronization protocols are used to govern the release of subtasks so that the precedence constraints among subtasks are satisfied and the schedulability of the resultant system is analyzable. When different protocols are used , tasks can have different worst-case and average end-to-end response times. This paper focuses on distributed real-time systems that contain independent, periodic tasks scheduled by fixed-priority scheduling algorithms. It describes three synchronization protocols together with algorithms to analyze the schedulability of the system when these protocols are used. Simulation was conducted to compare the performance of these protocols with respect to the worst-case and average case end-to-end response times. The simulation experiment and the performance of the protocols are described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard-real-time environment. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: 1 Introduction In many real-time systems, the workload can be modeled as a set of periodic tasks <ref> [1] </ref>. Each periodic task is an infinite stream of execution requests that are released (i.e., made) at a fixed maximum rate. We call each request an instance of the task. When the context is clear, we may simply say a task to mean an instance of that task. <p> It is well known that fixed priority scheduling is an effective means to schedule periodic tasks on a single processor and 1 to ensure that the time constraints of the tasks are satisfied <ref> [1, 2, 3, 4] </ref>. According to this approach, each task is assigned a fixed priority (i.e., all instances of the task have the same priority). <p> At any time, the scheduler simply chooses to run the task with the highest priority among all the tasks whose instances are released but not yet completed. A great deal of work has been done on how to assign the priorities <ref> [1, 5, 6] </ref> and how to bound the response times of tasks [1, 7, 2] for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order. <p> A great deal of work has been done on how to assign the priorities [1, 5, 6] and how to bound the response times of tasks <ref> [1, 7, 2] </ref> for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order. An example is a monitor task that collects remote sensor data and displays the data on the local screen.
Reference: [2] <author> J. Lehoczky. </author> <title> Fixed priority scheduling of periodic task sets with arbitrary deadlines. </title> <booktitle> In 11th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 201-209, </pages> <month> December </month> <year> 1990. </year> <month> 26 </month>
Reference-contexts: It is well known that fixed priority scheduling is an effective means to schedule periodic tasks on a single processor and 1 to ensure that the time constraints of the tasks are satisfied <ref> [1, 2, 3, 4] </ref>. According to this approach, each task is assigned a fixed priority (i.e., all instances of the task have the same priority). <p> A great deal of work has been done on how to assign the priorities [1, 5, 6] and how to bound the response times of tasks <ref> [1, 7, 2] </ref> for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order. An example is a monitor task that collects remote sensor data and displays the data on the local screen. <p> All instances of the three subtasks are released periodically according to the period p 1 and their own phases. Since all subtasks on each processor are strictly periodic, the Busy Period Analysis method proposed by Lehoczky <ref> [2] </ref> can be applied to obtain an upper bound on the response time of each subtask. The estimated worst-case EER time of a task is simply the sum of the bounds on the response times of all its subtasks. <p> In the case of the MPM and RG protocols, two interrupts are associated with each subtask instance. The costs of the interrupt (s) and context switches can be easily taken into account in the schedulability analysis <ref> [2] </ref>. 12 4 Schedulability Analysis Synchronization protocols not only preserve the precedence constraints among subtasks, but also ensure that the schedulab-ility of the resultant system is analyzable. In the previous section, we demonstrated that the precedence constraints among subtasks are satisfied. <p> The Busy Period Analysis technique, which was first proposed by Lehoczky <ref> [16, 2] </ref> and later extended by Audsley [3], Tindell [17, 18], and Burns [19], can be applied to obtain upper bounds on the response times of subtasks. <p> We follow first four of the following five steps to obtain an upper bound on the response time of a subtask T i;j when subtasks are synchronized according to the PM and MPM protocols. The correctness of the bound was proven by Lehoczky in <ref> [2] </ref>. The fifth step gives an upper bound on the EER time of T i . Its correctness is obvious. Step 1.
Reference: [3] <author> N. Audsley, A. Burns, K. Tindell, M. Richardson, and A. Wellings. </author> <title> Applying new scheduling theory to static priority pre-emptive scheduling. </title> <journal> Software Engineering Journal, </journal> <volume> 8(5) </volume> <pages> 284-292, </pages> <year> 1993. </year>
Reference-contexts: It is well known that fixed priority scheduling is an effective means to schedule periodic tasks on a single processor and 1 to ensure that the time constraints of the tasks are satisfied <ref> [1, 2, 3, 4] </ref>. According to this approach, each task is assigned a fixed priority (i.e., all instances of the task have the same priority). <p> The Busy Period Analysis technique, which was first proposed by Lehoczky [16, 2] and later extended by Audsley <ref> [3] </ref>, Tindell [17, 18], and Burns [19], can be applied to obtain upper bounds on the response times of subtasks. For each task, the sum of the upper bounds on the response times of all its subtasks is naturally an upper bound on its EER time.
Reference: [4] <author> K. W. Tindell. </author> <title> Fixed Priority Scheduling of Hard Real-Time Systems. </title> <type> PhD thesis, </type> <institution> University of York, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: It is well known that fixed priority scheduling is an effective means to schedule periodic tasks on a single processor and 1 to ensure that the time constraints of the tasks are satisfied <ref> [1, 2, 3, 4] </ref>. According to this approach, each task is assigned a fixed priority (i.e., all instances of the task have the same priority).
Reference: [5] <author> J. Leung and J. Whitehead. </author> <title> On the complexity of fixed-priority scheduling of periodic, real-time tasks. Performance Evaluation, </title> <booktitle> 2 </booktitle> <pages> 237-250, </pages> <year> 1982. </year>
Reference-contexts: At any time, the scheduler simply chooses to run the task with the highest priority among all the tasks whose instances are released but not yet completed. A great deal of work has been done on how to assign the priorities <ref> [1, 5, 6] </ref> and how to bound the response times of tasks [1, 7, 2] for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order.
Reference: [6] <author> N. C. Audsley. </author> <title> Optimal priority assignment and feasibility of static priority tasks with arbitrary start times. </title> <type> Technical Report YCS 164, </type> <institution> Dept. of Computer Science, University of York, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: At any time, the scheduler simply chooses to run the task with the highest priority among all the tasks whose instances are released but not yet completed. A great deal of work has been done on how to assign the priorities <ref> [1, 5, 6] </ref> and how to bound the response times of tasks [1, 7, 2] for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order.
Reference: [7] <author> M. Joseph and P. Pandya. </author> <title> Finding response times in a real-time system. </title> <journal> The Computer Journal of the British Computer Society, </journal> <volume> 29(5) </volume> <pages> 390-395, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: A great deal of work has been done on how to assign the priorities [1, 5, 6] and how to bound the response times of tasks <ref> [1, 7, 2] </ref> for single processor systems. In a distributed real-time system, each instance of a task may need to execute on different processors in order. An example is a monitor task that collects remote sensor data and displays the data on the local screen.
Reference: [8] <author> K. Tindell, A. Burns, and A. Wellings. </author> <title> Allocating real-time tasks. An NP-hard problem made easy. </title> <journal> Real-Time Systems Journal, </journal> <volume> 4(2), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: We are not concerned with the problem of how to assign priorities to subtasks. Rather, we assume that the priorities of subtasks on each processor have been assigned according to some priority assignment algorithm (e.g., one of the known algorithms in <ref> [8, 9, 10] </ref>). In this paper, we focus on various ways to synchronize the execution of sibling subtasks on different processors. Specifically, we describe three synchronization protocols.
Reference: [9] <author> B. Kao and H. Garcia-Molina. </author> <title> Deadline assignment in a distributed soft real-time system. </title> <booktitle> In The 13th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 428-437, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: We are not concerned with the problem of how to assign priorities to subtasks. Rather, we assume that the priorities of subtasks on each processor have been assigned according to some priority assignment algorithm (e.g., one of the known algorithms in <ref> [8, 9, 10] </ref>). In this paper, we focus on various ways to synchronize the execution of sibling subtasks on different processors. Specifically, we describe three synchronization protocols. <p> The last parameter of a synthetic system is the priority assigned to each subtask. We choose the Proportional-Deadline-Monotonic priority assignment method to assign priorities to subtasks. (This method is similar to the Equal Flexibility assignment in <ref> [9] </ref>.) According to this method, each subtask has a proportional deadline (P D i;j ) defined as follows. P D i;j = P n i D i where D i is the relative deadline of T i , which is equal to its period for this simulation.
Reference: [10] <author> J. Garcia and M. Harbour. </author> <title> Optimized priority assignment for tasks and messages in distributed hard real-time systems. </title> <booktitle> In The Third Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 124-132, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: We are not concerned with the problem of how to assign priorities to subtasks. Rather, we assume that the priorities of subtasks on each processor have been assigned according to some priority assignment algorithm (e.g., one of the known algorithms in <ref> [8, 9, 10] </ref>). In this paper, we focus on various ways to synchronize the execution of sibling subtasks on different processors. Specifically, we describe three synchronization protocols.
Reference: [11] <author> R. Bettati. </author> <title> End-to-End Scheduling to Meet Deadlines in Distributed Systems. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: The second protocol is an extension to the one proposed by Bettati, which was designed for flow-shop systems <ref> [11] </ref>. This protocol has certain limitations. The third protocol combines the strengths of the previous two protocols while avoiding their shortcomings. <p> subtask are not released too soon, they attempt to improve the schedulability of the tasks at the expense of their average EER times. 3.1 The Phase Modification (PM) Protocol The Phase Modification protocol, abbreviated as the PM protocol, was initially proposed by Bettati and used to schedule periodic flow-shop tasks <ref> [11] </ref>. Unlike the DS protocol, the PM protocol insists that instances of all subtasks of each task are released periodically according to the period of the task. To ensure that the precedence constraints among subtasks are satisfied, each subtask is given its own phase.
Reference: [12] <author> H. Zhang and D. Ferrari. </author> <title> Rate-controlled service disciplines. </title> <journal> Journal of High Speed Networking, </journal> ?(?):?, ? <year> 1994. </year>
Reference-contexts: The synchronization problem studied in this paper resembles the problem of jitter and rate control of real-time traffic in ATM networks. (An overview of the latter can be found in <ref> [12] </ref>.) Indeed, one of the protocols described here is similar to the method used in the jitter-EDD algorithm [13] for shaping inter-arrival patterns of packets. Packet transmissions at each switch (in our terminology, subtasks on the switch processor) are scheduled on the earliest-deadline-first (i.e., dynamic priority) basis.
Reference: [13] <author> D. Verma, H. Zhang, and D. Ferrari. </author> <title> Guaranteeing delay jitter bounds in packet switching networks. </title> <booktitle> In Proceedings of Tricomm'91, </booktitle> <pages> pages 35-46, </pages> <address> Chapel Hill, North Carolina, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The synchronization problem studied in this paper resembles the problem of jitter and rate control of real-time traffic in ATM networks. (An overview of the latter can be found in [12].) Indeed, one of the protocols described here is similar to the method used in the jitter-EDD algorithm <ref> [13] </ref> for shaping inter-arrival patterns of packets. Packet transmissions at each switch (in our terminology, subtasks on the switch processor) are scheduled on the earliest-deadline-first (i.e., dynamic priority) basis. By contrast, our focus is on fixed priority systems. Furthermore, we provide schedulability analysis algorithms to bound the worst-case EER times.
Reference: [14] <author> M. G. Harbour, M. H. Klein, and J. P. Lehoczky. </author> <title> Timing analysis for fixed-priority scheduling of hard real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(1) </volume> <pages> 13-28, </pages> <month> January </month> <year> 1994. </year> <month> 27 </month>
Reference-contexts: By contrast, our focus is on fixed priority systems. Furthermore, we provide schedulability analysis algorithms to bound the worst-case EER times. Harbour et al. studied a similar problem in <ref> [14] </ref>. In their model, each task is periodic and consists of a chain of subtasks. Subtasks are assigned fixed priorities and scheduled on the fixed-priority basis. The only difference from our model is that all tasks execute on a single processor.
Reference: [15] <author> B. </author> <title> Hunting. The solution's in the CAN Part 1. </title> <booktitle> Circuit Cellar, </booktitle> <pages> pages 14-20, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: In this paper, we do not explicitly model inter-processor communication, and assume that the cost of inter-processor communication required to synchronize subtasks on different processors is zero. This assumption is not as restrictive as it seems. In some cases, such as in CAN <ref> [15] </ref>, where message transmissions are prioritized, communication links can be modeled as processors, and message transmissions can be modeled as communication subtasks on link processors.
Reference: [16] <author> J. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotonic scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 166-171, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The Busy Period Analysis technique, which was first proposed by Lehoczky <ref> [16, 2] </ref> and later extended by Audsley [3], Tindell [17, 18], and Burns [19], can be applied to obtain upper bounds on the response times of subtasks.
Reference: [17] <author> K. W. Tindell, A. Burns, and A. J. Wellings. </author> <title> An extendible approach for analyzing fixed priority hard real-time tasks. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 6(2) </volume> <pages> 133-152, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: The Busy Period Analysis technique, which was first proposed by Lehoczky [16, 2] and later extended by Audsley [3], Tindell <ref> [17, 18] </ref>, and Burns [19], can be applied to obtain upper bounds on the response times of subtasks. For each task, the sum of the upper bounds on the response times of all its subtasks is naturally an upper bound on its EER time.
Reference: [18] <author> K. Tindell and J. Clark. </author> <title> Holistic schedulability analysis for distributed hard real-time systems. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 50(2) </volume> <pages> 117-134, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The Busy Period Analysis technique, which was first proposed by Lehoczky [16, 2] and later extended by Audsley [3], Tindell <ref> [17, 18] </ref>, and Burns [19], can be applied to obtain upper bounds on the response times of subtasks. For each task, the sum of the upper bounds on the response times of all its subtasks is naturally an upper bound on its EER time.
Reference: [19] <author> A. Burns, K. Tindell, and A. J. Wellings. </author> <title> Fixed priority scheduling with deadlines prior to completion. </title> <booktitle> In Sixth Euromicro Workshop on Real-Time Systems, </booktitle> <pages> pages 138-142, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The Busy Period Analysis technique, which was first proposed by Lehoczky [16, 2] and later extended by Audsley [3], Tindell [17, 18], and Burns <ref> [19] </ref>, can be applied to obtain upper bounds on the response times of subtasks. For each task, the sum of the upper bounds on the response times of all its subtasks is naturally an upper bound on its EER time.
Reference: [20] <author> J. Sun and J. Liu. </author> <title> Bounding the end-to-end response times of tasks in a distributed real-time system using the direct synchronization protocol. </title> <type> Technical Report UIUCDCS-R-96-1949, </type> <institution> University of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: In general, when the DS protocol is used, we may see several instances of a subtask released rather close together in time or even back-to-back consecutively. This phenomenon, clumping effect, is demonstrated in detail in <ref> [20] </ref>. The upper bounds on the subtask response times, even if we can find them, can be quite pessimistic due to the clumping effect, and the final bound on the EER time of a task based on these bounds can be quite pessimistic as well. <p> Algorithm IEERT makes use the given response time bounds and calculate the number of instances whose time demands must be taken into account, while Algorithm SA/PM relies on the periodicity of interfering subtasks to calculate this number. The proof of correctness of Algorithm IEERT can be found in <ref> [20] </ref>. In the description of Algorithm SA/DS, we let R = fR i;j g and IEERT (T; R) denote the set R 0 of new upper bounds obtained by Algorithm IEERT (R 0 = IEERT (T; R)). Figure 11 lists the pseudo-code of Algorithm SA/DS. <p> Compute the new bound R 0 i;j by i;j = maxfR i;j (m)g; f or 1 m M 19 proof of the theorem can be found in <ref> [20] </ref>. Theorem 2 If for each subtask T i;j there exists some X i;j &gt; 0 such that X = IEERT (T; X) where X = fX i;j g, then X i;j is a correct upper bound on the IEER time of T i;j .
Reference: [21] <author> S. Chatterjee and J. Strosnider. </author> <title> Distributed pipeline scheduling: End-to-end analysis of heterogeneous, </title> <booktitle> multi-resource real-time systems. In The 15th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 204-211, </pages> <month> May </month> <year> 1995. </year> <month> 28 </month>
Reference-contexts: The PM or MPM protocol should be favored when small output jitters are desirable. In previous studies on scheduling distributed real-time applications, such as in <ref> [21] </ref>, subtasks are typically assigned local deadlines and scheduled locally. Loose synchronization among subtasks is assumed. In this paper, we have attempted to provide insight to the synchronization problem in distributed real-time systems and to give an initial answer towards an unified end-to-end scheduling framework.
References-found: 21

