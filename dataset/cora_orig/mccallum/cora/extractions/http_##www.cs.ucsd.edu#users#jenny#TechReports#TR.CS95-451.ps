URL: http://www.cs.ucsd.edu/users/jenny/TechReports/TR.CS95-451.ps
Refering-URL: http://www.cs.ucsd.edu/users/jenny/cv.html
Root-URL: http://www.cs.ucsd.edu
Title: A Hierarchical Representation for Heterogeneous Applications  
Author: Cosimo Anglano Jennifer Schopf, Rich Wolski, and Francine Berman 
Date: January 5,1995  
Address: San Diego  
Affiliation: Dipartimento di Informatica Dept. of Computer Science and Engineering Universita di Torino University of California,  
Note: Zoom:  
Abstract: UCSD CS Technical Report #CS95-451 Abstract Heterogeneous network computing is defined as the implementation of a large, complex application on a network of possibly diverse computers. With the increase in network communication speeds and the availability of fast workstations and multiprocessors, heterogeneous network computing is emerging as a viable option for the development of performance-efficient applications. In this paper, we describe Zoom, a hierarchical representation in which heterogeneous applications can be described. The goal of Zoom is to provide an abstraction that computer and computational scientists can use to describe heterogeneous applications, and to provide a foundation from which program development tools for heterogeneous network computing can be built. Three levels (structure, implementation and data) of the Zoom hierarchy are described and are used to illustrate two heterogeneous applications. Extensions to Zoom to include addi tional resource parameters required by program development tools are also discussed.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alvisi, L., Amoroso, A., Baronio, A., Babaoglu, O., et al. </author> <title> Parallel scientific computing in distributed systems: the paralex approach. </title> <booktitle> In Computer and Information Sciences VI. Proceedings of the 1991 International Symposium (October 1991), </booktitle> <editor> M. Baray and B. Ozguc, Eds., </editor> <volume> vol. 2, </volume> <pages> pp. 1093-103. </pages>
Reference-contexts: Because of distinct features in each representation, not all programs can be translated this way, but the process gives insight into how both Zoom and HeNCE might be expanded to be compatible. Paralex <ref> [1] </ref> is a system similar to HeNCE, but with further restrictions. Its ability to represent pipelining is constrained to a single program graph, and each procedure is allowed only a single output.
Reference: [2] <author> Anglano, C., Wolski, R., Schopf, J., and Berman, F. </author> <title> Developing heterogeneous applications using zoom and hence. </title> <booktitle> to appear in the Proceedings of the Heterogeneous Computing Workshop (1995). </booktitle>
Reference-contexts: Zoom provides a way to describe the structure of applications but there is no notion of state and state transitions of the represented application. We have explored a Zoom-to-HeNCE translation which would enable programmers to use the Zoom hierarchical representation and the HeNCE execution model <ref> [2] </ref>. Because of distinct features in each representation, not all programs can be translated this way, but the process gives insight into how both Zoom and HeNCE might be expanded to be compatible. Paralex [1] is a system similar to HeNCE, but with further restrictions.
Reference: [3] <author> Arakawa, A., and Lamb, V. R. </author> <title> Computational design of the basic dynamical processes of the ucla general circulation model. </title> <booktitle> Methods in Computational Physics 17 (1977), </booktitle> <pages> 173-265. </pages>
Reference-contexts: The Zoom representation for both approaches serves as an analysis tool exposing their similarities and differences. 3.2.2 Coupled GCM Description The atmospheric GCM (AGCM) has been developed by Professor A. Arakawa and his collaborators over several years at UCLA <ref> [3] </ref>. It predicts horizontal velocity components, potential temperature, water vapor and ozone mixing ratios, surface pressure, and ground temperature. The UCLA AGCM also predicts the depth of the planetary boundary layer (PBL) which it treats as well-mixed.
Reference: [4] <author> Beguelin, A., Dongarra, J., Geist, G., Manchek, R., Plank, J., and Sunderam, V. </author> <title> Hence: A user's guide version 1.2. </title> <type> Tech. Rep. </type> <institution> CS-92-157, University of Tennessee, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Sections 4 and 5 discuss extensions to the current representational framework and present conclusions. 2 1.1 Related Work As heterogeneous network computing is a new and evolving field, there are few antecedents to Zoom. The closest comparison can be drawn with the HeNCE representation <ref> [4] </ref> used to specify heterogeneous applications as part of a graphical tool for PVM [20]. Both HeNCE and Zoom allow the programmer to describe the components of an application and the type of communication between those components. There are some differences, however.
Reference: [5] <author> Bergman, L., Braun, H.-W., Chinoy, B., Kolawa, A., Kuppermann, A., Lyster, P., Mechoso, C. R., Messina, P., Morrison, J., Stanfill, D., St.John, W., and Tenbrick, S. </author> <title> Casa gigabit testbed : 1993 annual report; a testbed for distributed computing. </title> <type> Tech. Rep. </type> <institution> CCSF-33, Caltech Concurrent Supercomputing Facilities, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: For example, the Calcrust application, which provides a 3-dimensional image of the earth's surface and its crust, combines USGS data, sounding data taken by various oil companies, and NASA satellite data <ref> [5] </ref>. In each case, the data was collected for some other purpose and each "owner" has a specialized system for accessing it. At the junction of these trends is the emergence of heterogeneous network computing. <p> Further, it is targeted to, and relies upon, the Isis [7] parallel programming toolkit, whereas Zoom is independent of a particular programming environment. 1.2 A Prototype Heterogeneous Application To motivate key aspects of heterogeneous applications, we describe an application based loosely on the Calcrust application. Calcrust <ref> [5] </ref>, developed at JPL, provides a 3-dimensional rendered image of the earth's surface and its crust. The input data comes from several different sources (oil company archives, USGS surveys, daily satellite sweeps, etc.) The data is first filtered and refined via an FFT based set of routines. <p> At the California Institute of Technology, physical chemists M. Wu and A. Kuppermann, as a part of the Casa Project <ref> [5] </ref> have been working on a 3D-REACT application that simulates a hydrogen-deuterium reaction of H + D 2 =) HD + D: The hydrogen-deuterium reaction is studied because it is one of the simplest reactions that can be calculated from first principles. <p> The current generation of microprocessor-based distributed-memory multiprocessors offer larger memory systems and greater theoretical performance limits than vector or shared-memory vector systems. Much of the current GCM development activity, then, centers on parallelization for multiprocessor computers [11, 13]. Gigabit networks linking various high-performance computing platforms <ref> [5] </ref> renders it possible to use several different machines in the execution of a single GCM, or a coupled collection of GCMs. By dividing the codes into communicating components, each of which is well-suited to a different computational paradigm, heterogeneous computing on a fast network promises improved performance.
Reference: [6] <author> Berry, M. </author> <title> Anticipations of the geometric phase. </title> <booktitle> Physics Today 43, </booktitle> <month> 12 (December </month> <year> 1990), </year> <pages> 34-40. </pages>
Reference-contexts: Wu and Kuppermann have refined this calculation by including a property known as the geometric phase [24]. Michael Berry (University of Bristol) first called attention to this phase, which now bears his name, in a variety of physical systems <ref> [6] </ref>. The inclusion of this phase alters the calculation so that an attribute of symmetry is used to to achieve a more precise result with respect to the basic laws of quantum dynamics.
Reference: [7] <author> Birman, K., and Marzullo, K. </author> <title> Isis and the meta project. Sun Technology 2, </title> <booktitle> 3 (Summer 1989), </booktitle> <pages> 90-104. </pages>
Reference-contexts: Paralex [1] is a system similar to HeNCE, but with further restrictions. Its ability to represent pipelining is constrained to a single program graph, and each procedure is allowed only a single output. Further, it is targeted to, and relies upon, the Isis <ref> [7] </ref> parallel programming toolkit, whereas Zoom is independent of a particular programming environment. 1.2 A Prototype Heterogeneous Application To motivate key aspects of heterogeneous applications, we describe an application based loosely on the Calcrust application.
Reference: [8] <author> Bisiani, R., and Forin, A. </author> <title> Multilanguage parallel programming of heterogeneous machines. </title> <journal> IEEE Transactions on Computers 37, </journal> <month> 8 (August </month> <year> 1988), </year> <pages> 930-45. 21 </pages>
Reference-contexts: The three different possible Paragon implementations for 3 A general form of data conversion was discussed for heterogeneous applications in [14] as well as <ref> [8] </ref>. 8 the renderer are marked P1, P2 and P3.
Reference: [9] <author> Bryan, K. </author> <title> A numerical method for the study of the circulation of the world ocean. </title> <journal> Journal of Computational Physics 4, </journal> <month> 3 (October </month> <year> 1969), </year> <pages> 347-76. </pages>
Reference-contexts: The entire computation is then repeated to simulate a time period of hours, days, or longer. The OGCM (O) component of the model is based on work done by K. Bryan and M. Cox at the NOAA Geophysical Fluid Dynamics Laboratory, Princeton University <ref> [9, 12] </ref>. It predicts horizontal velocity components, temperature, salinity, and optionally other tracers. Density is determined from temperature and salinity using either Knudsen's equation [10] or the UNESCO formula [21]. The model's top is assumed to be a rigid lid.
Reference: [10] <author> Bryan, K., and Cox, M. D. </author> <title> An approximate equation of state for numerical models of ocean circulation. </title> <journal> Journal of Physical Oceanography 2, </journal> <month> 4 (October </month> <year> 1972), </year> <pages> 510-14. </pages>
Reference-contexts: Bryan and M. Cox at the NOAA Geophysical Fluid Dynamics Laboratory, Princeton University [9, 12]. It predicts horizontal velocity components, temperature, salinity, and optionally other tracers. Density is determined from temperature and salinity using either Knudsen's equation <ref> [10] </ref> or the UNESCO formula [21]. The model's top is assumed to be a rigid lid. Velocities are split into components corresponding to vertically averaged flow and the deviation from the vertical average. Calculation of the vertical average requires only adjacent grid-point values in both the horizontal and vertical directions.
Reference: [11] <author> Chervin, R. M., and A. J. Semeter, J. </author> <title> An ocean modeling system for supercomputer architectures of the 1990's. </title> <booktitle> In Proceedings of the NATA Advanced Research Workshop on Climate-Ocean Interaction (1988), </booktitle> <editor> M. Schlesinger, </editor> <publisher> Ed., </publisher> <pages> pp. 87-97. </pages>
Reference-contexts: The current generation of microprocessor-based distributed-memory multiprocessors offer larger memory systems and greater theoretical performance limits than vector or shared-memory vector systems. Much of the current GCM development activity, then, centers on parallelization for multiprocessor computers <ref> [11, 13] </ref>. Gigabit networks linking various high-performance computing platforms [5] renders it possible to use several different machines in the execution of a single GCM, or a coupled collection of GCMs.
Reference: [12] <author> Cox, M. D. </author> <title> A primitive equation, 3-dimensional model of the ocean. </title> <type> Tech. Rep. Tech. Rep. No. 1, </type> <institution> GFDL Ocean Group, </institution> <year> 1984. </year>
Reference-contexts: The entire computation is then repeated to simulate a time period of hours, days, or longer. The OGCM (O) component of the model is based on work done by K. Bryan and M. Cox at the NOAA Geophysical Fluid Dynamics Laboratory, Princeton University <ref> [9, 12] </ref>. It predicts horizontal velocity components, temperature, salinity, and optionally other tracers. Density is determined from temperature and salinity using either Knudsen's equation [10] or the UNESCO formula [21]. The model's top is assumed to be a rigid lid.
Reference: [13] <author> Hoffman, G. R., and Maretis, D. K. </author> <title> The Dawn of Massively Parallel Processing in Meterology. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: The current generation of microprocessor-based distributed-memory multiprocessors offer larger memory systems and greater theoretical performance limits than vector or shared-memory vector systems. Much of the current GCM development activity, then, centers on parallelization for multiprocessor computers <ref> [11, 13] </ref>. Gigabit networks linking various high-performance computing platforms [5] renders it possible to use several different machines in the execution of a single GCM, or a coupled collection of GCMs.
Reference: [14] <author> Khokhar, A., Prasanna, V. K., Shaaban, M., and Wang, C.-L. </author> <title> Heterogeneous Supercomputing: Problems and Issues. </title> <booktitle> In Proceedings of the 1992 Heterogeneous Workshop (1992), </booktitle> <publisher> IEEE CS Press. </publisher>
Reference-contexts: The three different possible Paragon implementations for 3 A general form of data conversion was discussed for heterogeneous applications in <ref> [14] </ref> as well as [8]. 8 the renderer are marked P1, P2 and P3.
Reference: [15] <author> Levi, B. G. </author> <title> The geometric phase shows up in chemical reactions. </title> <booktitle> Physics Today 46, </booktitle> <month> 3 (March </month> <year> 1993), </year> <pages> 17-19. </pages>
Reference-contexts: The inclusion of this phase alters the calculation so that an attribute of symmetry is used to to achieve a more precise result with respect to the basic laws of quantum dynamics. For more details on the reaction itself, see <ref> [15] </ref>. 3.1.1 General Structure of the Application Wu and Kuppermann believe that the computing power offered by a heterogeneous configuration of machines can be used effectively to reduce the wall clock time needed by this computationally intensive application [22, 23].
Reference: [16] <author> Mechoso, C. R., Farrara, J. D., and Spahr, J. A. </author> <title> Running a climate model in a heterogeneous, distributed computer environment. </title> <booktitle> In Proceedings of the Third IEEE International Symposium on High Performance and Distributed Computing (August 1994), </booktitle> <pages> pp. 79-84. </pages>
Reference-contexts: By dividing the codes into communicating components, each of which is well-suited to a different computational paradigm, heterogeneous computing on a fast network promises improved performance. The atmospheric GCM developed at UCLA, for example, is composed of highly vectorizable dynamics routines, and easily parallelizable physics routines <ref> [16] </ref>. By mapping the vector routines to a vector computer, and the parallel routines to a parallel computer, connected by a high-speed network, good overall execution performance should be possible. 3.2.1 Comparative Study Potentially, several GCM simulations can be coupled to yield a comprehensive climate model. <p> The UCLA group has been focusing on minimum execution time performance (and in particular, achieving superlinear speedup) using a heterogeneous suite of machines <ref> [16, 17] </ref>. By decomposing the problem into a repeated phase whose execution can be pipelined, the communication latencies can be effectively masked.
Reference: [17] <author> Mechoso, C. R., Ma, C.-C., Farrara, J. D., Spahr, J. A., and Moore, R. W. </author> <title> Distribution of a climate model across high-speed networks. </title> <booktitle> In Proceedings of Supercomputing 1991 (1991), </booktitle> <pages> pp. 253-60. </pages>
Reference-contexts: The UCLA group has been focusing on minimum execution time performance (and in particular, achieving superlinear speedup) using a heterogeneous suite of machines <ref> [16, 17] </ref>. By decomposing the problem into a repeated phase whose execution can be pipelined, the communication latencies can be effectively masked.
Reference: [18] <author> Mechoso, C. R., Ma, C.-C., Farrara, J. D., Spahr, J. A., and Moore, R. W. </author> <title> Paral-lelization and distribution of a coupled atmosphere-ocean general circulation model. </title> <journal> Monthly Weather Review 121, </journal> <month> 7 (July </month> <year> 1993), </year> <pages> 2062-76. </pages>
Reference-contexts: Through this parameterization, an individual GCM modeling the atmosphere can be coupled with one modeling the ocean to study how the interaction between the atmosphere and the ocean affects global climate <ref> [18] </ref>. Until recently, most GCM codes have been heavily optimized for vector computing environments. They tend to be computationally intensive grid-oriented calculations that are well-suited to data parallel algorithms. <p> The UCLA AGCM also predicts the depth of the planetary boundary layer (PBL) which it treats as well-mixed. The code can be parameterized with cumulus convection and its interactions with the PBL, solar and radiative heating, and orographic gravity wave drag <ref> [18] </ref>. The AGCM is organized into two relatively well-defined components: * AGCM/Physics, which diagnostically computes the effects of motion processes resolved by the model. <p> The UCLA model employs overlap within a timestep between Ap and Ad, and also between Ap and O. The cycle within the Ad coupling unit indicates that multiple (8) Ad calculations are executed during each simulated interval. In <ref> [18] </ref>, the authors discuss the concept of I/O decomposition in which Ad and O can begin computing their values for a given timestep before Ap has completely computed all of its values for the same timestep. In this way, Ap, Ad, and O can all execute concurrently.
Reference: [19] <author> Snyder, L. </author> <title> Phase Abstractions for Portable and Scalable Parallel Programming. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The first phase of an application may have a single arc leading to the opening phase boundary 2 The decomposition of heterogeneous applications into phases represents the structure of typical heterogeneous programs and follows <ref> [19] </ref>. 5 emanating from a key word INITIAL. The last phase of an application may have a single arc emanating from the closing phase boundary to a key word RESULT. Any machine implementation, data, or resource management issues for the coupling units are unspecified at Level 1.
Reference: [20] <author> Sunderam, V. S., Geist, G. A., Dongarra, J., and Manchek, R. </author> <title> The pvm concurrent computing system: evolution, experiences, </title> <booktitle> and trends. Parallel Computing 20, </booktitle> <month> 4 (April </month> <year> 1994), </year> <pages> 531-45. </pages>
Reference-contexts: The closest comparison can be drawn with the HeNCE representation [4] used to specify heterogeneous applications as part of a graphical tool for PVM <ref> [20] </ref>. Both HeNCE and Zoom allow the programmer to describe the components of an application and the type of communication between those components. There are some differences, however. First, HeNCE is a "flat" representation, i.e. all application components are specified with the same level of detail. <p> To ensure the longevity of a code such as a coupled GCM, rapid portability to new architectures is necessary. Further, cluster computing using networked sets of workstations promises cost-effective compute cycles. The LLNL approach has been to use FORTRAN and PVM <ref> [20] </ref> as a portable language environment. Since PVM is supported for both workstation networks and multiprocessors, the Livermore GCM implementation will run on both a cluster or workstations and more tightly coupled computing platforms.
Reference: [21] <editor> UNESCO. </editor> <booktitle> UNESCO Technical papers in Marine Science number 36. UNESCO, </booktitle> <address> Paris, </address> <year> 1981, </year> <title> ch. Tenth report of the joint panel on oceanographic tables and standards. </title>
Reference-contexts: Bryan and M. Cox at the NOAA Geophysical Fluid Dynamics Laboratory, Princeton University [9, 12]. It predicts horizontal velocity components, temperature, salinity, and optionally other tracers. Density is determined from temperature and salinity using either Knudsen's equation [10] or the UNESCO formula <ref> [21] </ref>. The model's top is assumed to be a rigid lid. Velocities are split into components corresponding to vertically averaged flow and the deviation from the vertical average. Calculation of the vertical average requires only adjacent grid-point values in both the horizontal and vertical directions.
Reference: [22] <author> Wu, M., and Kuppermann, A. </author> <title> Casa quantum chemical reaction dynamics. In 1994 CASA Gigabit Network Testbed Annual Report (1994). </title>
Reference-contexts: For more details on the reaction itself, see [15]. 3.1.1 General Structure of the Application Wu and Kuppermann believe that the computing power offered by a heterogeneous configuration of machines can be used effectively to reduce the wall clock time needed by this computationally intensive application <ref> [22, 23] </ref>. As part of the CASA project, they have investigated using a Cray C-90 and an Intel Delta in tandem to implement this application.
Reference: [23] <author> Wu, Y.-S. M. </author> <type> Personal communication, </type> <year> 1994. </year>
Reference-contexts: For more details on the reaction itself, see [15]. 3.1.1 General Structure of the Application Wu and Kuppermann believe that the computing power offered by a heterogeneous configuration of machines can be used effectively to reduce the wall clock time needed by this computationally intensive application <ref> [22, 23] </ref>. As part of the CASA project, they have investigated using a Cray C-90 and an Intel Delta in tandem to implement this application.
Reference: [24] <author> Wu, Y.-S. M., and Kuppermann, A. </author> <title> Prediction of the effect of the geometric phase on product rotational state distributions and integral cross sections. </title> <journal> Chemical Physics Letters 201 (January 1993), </journal> <pages> 178-86. 22 </pages>
Reference-contexts: Wu and Kuppermann have refined this calculation by including a property known as the geometric phase <ref> [24] </ref>. Michael Berry (University of Bristol) first called attention to this phase, which now bears his name, in a variety of physical systems [6].
References-found: 24

