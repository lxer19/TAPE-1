URL: http://www.medg.lcs.mit.edu/ftp/doyle/arpi-final94.ps
Refering-URL: http://www.medg.lcs.mit.edu/ftp/doyle/
Root-URL: 
Author: Jon Doyle, Principal Investigator 
Keyword: Planning and Replanning of Large-Scale Activities  
Address: 545 Technology Square Cambridge, Massachusetts 02139  
Affiliation: Massachusetts Institute of Technology Laboratory for Computer Science  
Note: USAF Rome Laboratories Contract F30602-91-C-0018  
Email: doyle@lcs.mit.edu  
Phone: Tel: (617) 253-3512, Fax: (617) 258-8682  
Date: January 31, 1991|March 31, 1994  
Abstract: This reproduces a report submitted to Rome Laboratory on October 27, 1994. c flCopyright 1994 by Jon Doyle. All rights reserved. Freely available via http://www.medg.lcs.mit.edu/doyle. Final Report on Rational Distributed Reason Maintenance for Abstract Efficiency dictates that plans for large-scale distributed activities be revised incrementally, with parts of plans being revised only if the expected utility of identifying and revising the sub-plans improve on the expected utility of using the original plan. The problems of identifying and reconsidering the subplans affected by changed circumstances or goals are closely related to the problems of revising beliefs as new or changed information is gained. But traditional techniques of reason maintenance|the standard method for belief revision|choose revisions arbitrarily and enforce global notions of consistency and groundedness which may mean reconsidering all beliefs or plan elements at each step. We develop revision methods aiming to revise only those beliefs and plans worth revising, and to tolerate incoherence and ungroundedness when these are judged less detrimental than a costly revision effort. We use an artificial market economy in planning and revision tasks to arrive at overall judgments of worth, and present a representation for qualitative preferences that permits capture of common forms of dominance information. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. R. Bogan. </author> <title> Economic allocation of computation time with computation markets. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <year> 1993. </year> <type> Thesis Proposal. </type>
Reference-contexts: Base level actions have associated procedures. We have explored two approaches to allocating computational resources. Our initial approach was based on an auction of computation opportunities, while a later approach developed by our student Nathaniel Bogan <ref> [1] </ref> conducts auctions to rent computational resources to the highest bidders. The initial RECON implementation scheduled tasks on a single processor by auctioning off opportunities to compute. <p> Nathaniel Bogan developed an improved version of RECON by incorporating several standard approaches from economic theory and practice <ref> [1] </ref>. In his scheme, consumers and producers bid rental prices for computational resources (e.g., processors), and RECON allocates time to those producers offering the highest rental rates (in the non-equilibrium approximation). The winner is then charged at this rate according to how much time it actually uses.
Reference: [2] <author> J. G. Carbonell. </author> <title> Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> volume 2, </volume> <pages> pages 371-392. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: That is, we view reasons as information about past computations or conditions which may be used to reconstruct results in changed circumstances, either exactly or in modified form (as in derivational analogy <ref> [2] </ref> or case-based reasoning). Treating reasons as aids to recomputation is in marked contrast with the traditional use of reasons as rigid requirements that belief states must satisfy instead of as information which may be used or ignored as suits the reasoner's purposes.
Reference: [3] <author> J. de Kleer. </author> <title> An assumption-based tms. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 127-162, </pages> <year> 1986. </year>
Reference-contexts: For example, the system will ordinarily use reasons to construct a single global set of beliefs, as in the original conception. But for some specific sets of reasons, say those corresponding to a circumscribed problem, the RMS may determine all consistent sets of beliefs as in the ATMS <ref> [3] </ref>. Alternatively, only some consistent interpretations may be constructed, such as those maximal in some order (as in preferential nonmonotonic logics [27]). In general, the aim is to use the recorded reasons to draw as many conclusions as the reasoner needs.
Reference: [4] <author> J. de Kleer, J. Doyle, G. L. Steele Jr., and G. J. Sussman. Amord: </author> <title> Explicit control of reasoning. </title> <booktitle> In Proceedings of the ACM Symposium on Artificial Intelligence and Programming Languages, </booktitle> <pages> pages 116-125, </pages> <year> 1977. </year>
Reference-contexts: This possibility was, in fact, one of the original motivations for reason maintenance systems (see <ref> [4, 5] </ref>).
Reference: [5] <author> J. Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: This possibility was, in fact, one of the original motivations for reason maintenance systems (see <ref> [4, 5] </ref>). <p> For concreteness, we describe the structure of the particular reason maintenance system RMS developed by the author <ref> [5] </ref>. We may formalize its essential features as follows, simplifying its complex actual structure in ways that do not matter for the present discussion. (See [6, 7, 11] for more detailed discussions.) States of RMS contain two types of elements: nodes and reasons.
Reference: [6] <author> J. Doyle. </author> <title> The ins and outs of reason maintenance. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 349-351, </pages> <year> 1983. </year>
Reference-contexts: For concreteness, we describe the structure of the particular reason maintenance system RMS developed by the author [5]. We may formalize its essential features as follows, simplifying its complex actual structure in ways that do not matter for the present discussion. (See <ref> [6, 7, 11] </ref> for more detailed discussions.) States of RMS contain two types of elements: nodes and reasons. We write N to denote the set of possible nodes, and R to denote the set of possible reasons.
Reference: [7] <author> J. Doyle. </author> <title> Some theories of reasoned assumptions: An essay in rational psychology. </title> <type> Technical Report 83-125, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1983. </year>
Reference-contexts: For concreteness, we describe the structure of the particular reason maintenance system RMS developed by the author [5]. We may formalize its essential features as follows, simplifying its complex actual structure in ways that do not matter for the present discussion. (See <ref> [6, 7, 11] </ref> for more detailed discussions.) States of RMS contain two types of elements: nodes and reasons. We write N to denote the set of possible nodes, and R to denote the set of possible reasons. <p> In such theories, one may express all reasons as defeasible reasons and express all changes of belief through addition of reasons. See <ref> [7] </ref> for details. 6 (a) n j = (I; O; n i ), (b) for each x 2 I, x = n k for some k &lt; j, and (c) x =2 N for each x 2 O. Each set of reasons supports 0 or more legal states. <p> Similarly, the annotations may indicate to persist in believing the proposition without reevaluating the supporting reason, to check that the reason is not invalidated by beliefs within the containing locale, or to check validity with respect to external beliefs. We have developed in <ref> [7] </ref> and [11] a formalization of this more general framework of reason maintenance that permits local variability of consequential import, groundedness, and other properties of RMS states.
Reference: [8] <author> J. Doyle. </author> <title> Reasoned assumptions and Pareto optimality. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 87-90, </pages> <year> 1985. </year>
Reference-contexts: Though algorithms for determining sets of conclusions from default rules do not involve any explicit rationality calculations, the conclusions drawn can be shown to be Pareto optimal sets, that is, rational choices of conclusions when the default rules are interpreted as preferences over states of belief <ref> [8, 11] </ref>. Viewed this way, default rules encode compiled preferences, and mechanisms for deriving sets of conclusions from default rules constitute an example of an implicitly rational choice mechanism. Process rationality enters the task of planning in numerous ways.
Reference: [9] <author> J. Doyle. </author> <title> Artificial intelligence and rational self-government. </title> <type> Technical Report CS-88-124, </type> <institution> Carnegie-Mellon University Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: But if we are to achieve the efficiency required for revising large plans, reason maintenance must be redesigned to make these choices rationally whenever possible. Accordingly, we developed formal foundations for the theory of rational belief revision <ref> [9, 10] </ref>. But to really achieve efficiency, the RMS must do more than choose rationally among assumptions in backtracking.
Reference: [10] <author> J. Doyle. </author> <title> Rational belief revision (preliminary report). </title> <editor> In R. E. Fikes and E. Sandewall, editors, </editor> <booktitle> Proceedings of the Second Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 163-174, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: But if we are to achieve the efficiency required for revising large plans, reason maintenance must be redesigned to make these choices rationally whenever possible. Accordingly, we developed formal foundations for the theory of rational belief revision <ref> [9, 10] </ref>. But to really achieve efficiency, the RMS must do more than choose rationally among assumptions in backtracking.
Reference: [11] <author> J. Doyle. </author> <title> Reasoned assumptions and rational psychology. </title> <note> Fundamenta Informaticae, 20(1-3):35-73, </note> <year> 1994. </year>
Reference-contexts: Though algorithms for determining sets of conclusions from default rules do not involve any explicit rationality calculations, the conclusions drawn can be shown to be Pareto optimal sets, that is, rational choices of conclusions when the default rules are interpreted as preferences over states of belief <ref> [8, 11] </ref>. Viewed this way, default rules encode compiled preferences, and mechanisms for deriving sets of conclusions from default rules constitute an example of an implicitly rational choice mechanism. Process rationality enters the task of planning in numerous ways. <p> For concreteness, we describe the structure of the particular reason maintenance system RMS developed by the author [5]. We may formalize its essential features as follows, simplifying its complex actual structure in ways that do not matter for the present discussion. (See <ref> [6, 7, 11] </ref> for more detailed discussions.) States of RMS contain two types of elements: nodes and reasons. We write N to denote the set of possible nodes, and R to denote the set of possible reasons. <p> Similarly, the annotations may indicate to persist in believing the proposition without reevaluating the supporting reason, to check that the reason is not invalidated by beliefs within the containing locale, or to check validity with respect to external beliefs. We have developed in [7] and <ref> [11] </ref> a formalization of this more general framework of reason maintenance that permits local variability of consequential import, groundedness, and other properties of RMS states.
Reference: [12] <author> J. Doyle, Y. Shoham, and M. P. Wellman. </author> <title> A logic of relative desire (preliminary report). </title> <editor> In Z. W. Ras and M. Zemankova, editors, </editor> <booktitle> Methodologies for Intelligent Systems, 6, volume 542 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 16-31, </pages> <address> Berlin, Oct. 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Therefore, in designing preference languages, we seek constructs for describing general patterns of preference that hold over classes of outcomes and situations. Toward this end, we have developed a qualitative logic of preference ceteris paribus or preference "other things equal" <ref> [12, 13, 31] </ref> in collaboration with Michael Wellman. This logic affords flexible specification of objectives, underpinned by a decision-theoretic semantics. The most common representation used or assumed for preference information is that of numerical utility functions.
Reference: [13] <author> J. Doyle and M. P. Wellman. </author> <title> Representing preferences as ceteris paribus comparatives. </title> <editor> In S. Hanks, S. Russell, and M. P. Wellman, editors, </editor> <booktitle> Proceedings of the AAAI Spring Symposium on Decision-Theoretic Planning, </booktitle> <year> 1994. </year>
Reference-contexts: Therefore, in designing preference languages, we seek constructs for describing general patterns of preference that hold over classes of outcomes and situations. Toward this end, we have developed a qualitative logic of preference ceteris paribus or preference "other things equal" <ref> [12, 13, 31] </ref> in collaboration with Michael Wellman. This logic affords flexible specification of objectives, underpinned by a decision-theoretic semantics. The most common representation used or assumed for preference information is that of numerical utility functions.
Reference: [14] <author> P. Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Reasons ordinarily supply only partial information in that the reasoner need not register all inferences with the RMS. In the extreme case, the external reasoners may command the RMS to simply believe some proposition, independent of reasons. This corresponds to the "revision" operation in philosophical treatments of belief revision <ref> [14] </ref>. Because of this partiality, the RMS will sometimes be unable to track all the consequences of all beliefs. Although knowledge is usually preferable to ignorance, this incompleteness of the beliefs of the RMS need not be detrimental since the underlying knowledge and inferences of the reasoner are incomplete anyway.
Reference: [15] <author> P. Haddawy and S. Hanks. </author> <title> Issues in decision-theoretic planning: Symbolic goals and numeric utilities. </title> <booktitle> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <pages> pages 48-58, </pages> <year> 1990. </year> <month> 24 </month>
Reference-contexts: that spans the spectrum from completely qualitative representations like our language of comparative preference to ordinary numeric utility functions, including intermediate representations of multiattribute utility functions such as subutility composition trees [32], the standard forms of multiattribute utility functions [17], and their application to expressing different types of planning goals <ref> [15, 16] </ref>. 7 Conclusion Reason maintenance offers important abilities for use in planning and replanning, but to prove useful for large-scale activities, the techniques must be capable of incremental application that does not incur the costs of global reconsideration.
Reference: [16] <author> P. Haddawy and S. Hanks. </author> <title> Representations for decision-theoretic planning: Utility functions for deadline goals. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 71-82, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: that spans the spectrum from completely qualitative representations like our language of comparative preference to ordinary numeric utility functions, including intermediate representations of multiattribute utility functions such as subutility composition trees [32], the standard forms of multiattribute utility functions [17], and their application to expressing different types of planning goals <ref> [15, 16] </ref>. 7 Conclusion Reason maintenance offers important abilities for use in planning and replanning, but to prove useful for large-scale activities, the techniques must be capable of incremental application that does not incur the costs of global reconsideration.
Reference: [17] <author> R. L. Keeney and H. Raiffa. </author> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: representations as well, and we are working toward a preference language that spans the spectrum from completely qualitative representations like our language of comparative preference to ordinary numeric utility functions, including intermediate representations of multiattribute utility functions such as subutility composition trees [32], the standard forms of multiattribute utility functions <ref> [17] </ref>, and their application to expressing different types of planning goals [15, 16]. 7 Conclusion Reason maintenance offers important abilities for use in planning and replanning, but to prove useful for large-scale activities, the techniques must be capable of incremental application that does not incur the costs of global reconsideration.
Reference: [18] <author> A. L. Lansky. </author> <title> Localized event-based reasoning for multiagent domains. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 319-340, </pages> <year> 1988. </year>
Reference-contexts: Decomposition of knowledge in this way is a familiar element of many representational schemes (e.g., those based on Minsky's [21] original frame-systems idea). The use of locality in planning is illustrated most explicitly by the encapsulation mechanisms of Lansky's <ref> [18] </ref> gemplan system. Along with the general desire for incrementality, there are several additional reasons for distributing reason maintenance across different processors. In the first place, the information and effort required may be too great to store or perform on a single machine.
Reference: [19] <author> D. McAllester. </author> <title> Truth maintenance. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pages 1109-1116, </pages> <address> Menlo Park, CA, 1990. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Due to the difficulty of quickly computing this form of conservative updates, however, RMS only approximated conservative updates. Reason maintenance systems developed later use simpler notions of conservatism which may be computed more rapidly (see, for example, <ref> [19, 23] </ref>. The RMS also supports the operation of the dependency-directed backtracking (DDB) system, which attempts to defeat assumptions underlying those nodes identified as contradictions.
Reference: [20] <author> D. McDermott and J. Doyle. </author> <title> Non-monotonic logic|I. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 41-72, </pages> <year> 1980. </year>
Reference-contexts: This misrepresentation may stem from the somewhat misleading role of logical consistency in nonmonotonic logic <ref> [20] </ref>.) Since RMS has no knowledge of the meanings of nodes, the reasoner must tell it which nodes represent contradictions.
Reference: [21] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <editor> In P. H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, chapter 6, </booktitle> <pages> pages 211-277. </pages> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: Decomposition of knowledge in this way is a familiar element of many representational schemes (e.g., those based on Minsky's <ref> [21] </ref> original frame-systems idea). The use of locality in planning is illustrated most explicitly by the encapsulation mechanisms of Lansky's [18] gemplan system. Along with the general desire for incrementality, there are several additional reasons for distributing reason maintenance across different processors.
Reference: [22] <author> R. C. Moore. </author> <title> Semantical considerations on nonmonotonic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 75-94, </pages> <year> 1985. </year>
Reference-contexts: Naturally, in this setting the RMS is not expected to determine completely and accurately what the system believes. Instead, it only offers a theory of what the overall system believes|an "autoepistemic" theory, in the sense 9 of Moore <ref> [22] </ref>, but not necessarily a complete or correct one. Given this purpose, the basic operation of the RMS is to record reasons and other information, and, when so instructed, to revise beliefs in accordance with the expectations and preferences supplied by the reasoner.
Reference: [23] <author> B. Nebel. </author> <title> Representation and Reasoning in Hybrid Representation Systems. </title> <booktitle> Number 422 in Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: Due to the difficulty of quickly computing this form of conservative updates, however, RMS only approximated conservative updates. Reason maintenance systems developed later use simpler notions of conservatism which may be computed more rapidly (see, for example, <ref> [19, 23] </ref>. The RMS also supports the operation of the dependency-directed backtracking (DDB) system, which attempts to defeat assumptions underlying those nodes identified as contradictions.
Reference: [24] <author> M. E. Pollack, T. Znati, E. Ephrati, D. Joslin, S. Lauzac, A. Nunes, N. Onder, Y. Ronen, and S. </author> <title> Ur. The DIPART project: A status report. </title> <booktitle> In Technical Papers of the ARPA Planning Initiative Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: More general versions should reinstate the organization used in our original implementation, in which these queues are nontrivial agendas. With such an organization, the locales and RMS processing sites bear some resemblance to the LMC architecture developed to good effect by Pollack et al. <ref> [24] </ref>. 4.3 Nodes Nodes consist of both information about the relations between the node and external objects, locales, and other nodes, and information about this relational information itself. The first purpose of a node is to denote some object, in most cases external to the the locale and the RMS.
Reference: [25] <author> C. Rich. </author> <title> The layered architecture of a system for reasoning about programs. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: The original RMS architectures make reason maintenance the base-level stratum upon which all other reasoning procedures are erected. To enable belief revision, one must encode every bit of information that might change in reasons and tell these reasons to the RMS (cf. <ref> [25, 28] </ref>). This can present an excessive burden, as manifest by the observation that the RMSs supplied in expert system shells all too often go unused.
Reference: [26] <author> L. J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1972. </year>
Reference-contexts: In the first place, numeric utility functions are too specific: the foundations of decision theory and economics start with qualitative preference orders, and many 21 different utility functions can represent the same preference order <ref> [26] </ref>. Thus a utility function may convey more information than is really there. In the second place, while utility functions make some optimization procedures convenient, they tend to make specification and elucidation of preferences difficult.
Reference: [27] <author> Y. Shoham. </author> <title> Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: But for some specific sets of reasons, say those corresponding to a circumscribed problem, the RMS may determine all consistent sets of beliefs as in the ATMS [3]. Alternatively, only some consistent interpretations may be constructed, such as those maximal in some order (as in preferential nonmonotonic logics <ref> [27] </ref>). In general, the aim is to use the recorded reasons to draw as many conclusions as the reasoner needs. One consequence of the incompleteness and incorrectness of reasons is that beliefs of the system may be inconsistent in routine operation.
Reference: [28] <author> M. B. Vilain. </author> <title> The restricted language architecture of a hybrid representation system. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 547-551, </pages> <year> 1985. </year>
Reference-contexts: The original RMS architectures make reason maintenance the base-level stratum upon which all other reasoning procedures are erected. To enable belief revision, one must encode every bit of information that might change in reasons and tell these reasons to the RMS (cf. <ref> [25, 28] </ref>). This can present an excessive burden, as manifest by the observation that the RMSs supplied in expert system shells all too often go unused.
Reference: [29] <author> M. P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman and Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Each of these ways of implementing rationality is best in some circumstances, since compilation is not always possible or worthwhile. Examples of implicitly rational procedures abound in AI under the name of heuristics. For instance, the "status quo optimality" heuristic <ref> [29, Section 6.4.1] </ref> constrains the set of possible revisions under the assumption that the current plan is optimal. In particular, the replanner need only respond to the specific changes. <p> It appears that many important decisions can be made simply on the basis of dominance arguments expressed completely qualitatively in this form, so this approach should permit important decision-making and planning to proceed even without numeric utilities. Wellman <ref> [29] </ref> has developed the probabilistic version of this idea into a dominance-guided planning procedure that plans "up to tradeoffs" in his terminology, meaning it constructs plans that are optimal as far as the qualitative probabilistic information is concerned, and we expect an even more robust planning procedure could be constructed in
Reference: [30] <author> M. P. Wellman. </author> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: But the true flowering of computational markets has occurred only recently, mainly with the WALRAS computational economy developed by Wellman <ref> [30] </ref>. Designed to make use of the main ideas of theoretical economics about markets, WALRAS provides a general mechanism for implementing markets in arbitrary sets of goods, traded by arbitrary consuming and producing agents.
Reference: [31] <author> M. P. Wellman and J. Doyle. </author> <title> Preferential semantics for goals. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 698-703, </pages> <year> 1991. </year>
Reference-contexts: Therefore, in designing preference languages, we seek constructs for describing general patterns of preference that hold over classes of outcomes and situations. Toward this end, we have developed a qualitative logic of preference ceteris paribus or preference "other things equal" <ref> [12, 13, 31] </ref> in collaboration with Michael Wellman. This logic affords flexible specification of objectives, underpinned by a decision-theoretic semantics. The most common representation used or assumed for preference information is that of numerical utility functions.
Reference: [32] <author> M. P. Wellman and J. Doyle. </author> <title> Modular utility representation for decision-theoretic planning. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <year> 1992. </year> <month> 25 </month>
Reference-contexts: language for encoding preference information would include quantitative representations as well, and we are working toward a preference language that spans the spectrum from completely qualitative representations like our language of comparative preference to ordinary numeric utility functions, including intermediate representations of multiattribute utility functions such as subutility composition trees <ref> [32] </ref>, the standard forms of multiattribute utility functions [17], and their application to expressing different types of planning goals [15, 16]. 7 Conclusion Reason maintenance offers important abilities for use in planning and replanning, but to prove useful for large-scale activities, the techniques must be capable of incremental application that does
References-found: 32

