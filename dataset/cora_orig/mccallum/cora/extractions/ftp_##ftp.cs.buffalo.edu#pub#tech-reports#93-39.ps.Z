URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/93-39.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Email: fsher,wafford,milung@cs.buffalo.edu  
Title: Relating Gibbs Distributions to Empirically Derived Marginal Distributions for Image Analysis  
Author: D. B. Sher C. E. Wafford and D. Milun 
Address: Garden City NY 11530 Buffalo NY 14260  
Affiliation: Mathematics Dept Computer Science Dept. Nassau Community College SUNY Buffalo  
Abstract: The log marginal probability ratios of a Gibbs distribution over an 8 connected neighborhood system is a linear function of its 66 clique weights. We empirically determine log marginal probability ratios of artificial noiseless images and use the pseudoinverse method to compute the closest Gibbs distribution. We compare these Gibbs distributions to ad hoc distributions suggested in the literature and to the empirical marginals from which they are derived.
Abstract-found: 1
Intro-found: 1
Reference: [Bes74] <author> J.E. Besag. </author> <title> Spatial interaction and the statistical analysis of lattice systems (with discussion). </title> <journal> Journal Royal Statistical Society, Series B, </journal> <volume> 36 </volume> <pages> 192-236, </pages> <year> 1974. </year>
Reference-contexts: In this paper we shall refer to this particular HK level as "optimum" HK. 3 Background This approach of using local neighborhood characteristics is essentially that of Markov random fields (MRF), originally developed and applied to image domains by J. Besag and D. and S. Geman <ref> [Bes74, Bes86, GG84] </ref>. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90].
Reference: [Bes86] <author> J.E. Besag. </author> <title> On the statistical analysis of dirty pictures. </title> <journal> Journal Royal Statistical Society, Series B, </journal> <volume> 48 </volume> <pages> 259-302, </pages> <year> 1986. </year>
Reference-contexts: Gibbs distributions have convenient theoretical properties: they are compact | of lower dimensionality than marginal distributions | and important optimization methods such as the iterated conditional modes (ICM) algorithm and simulated annealing are guaranteed to converge <ref> [Bes86, GG84] </ref>. This paper examines how closely Gibbs distributions model the local structures that commonly occur in a typical class of artificial imagery. Our experiments use empirical distributions over 3 fi 3 neighborhoods from images of occluding ellipses and rotated rectangles as in figure 1. <p> In this paper we shall refer to this particular HK level as "optimum" HK. 3 Background This approach of using local neighborhood characteristics is essentially that of Markov random fields (MRF), originally developed and applied to image domains by J. Besag and D. and S. Geman <ref> [Bes74, Bes86, GG84] </ref>. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90].
Reference: [Bla89] <author> Andrew Blake. </author> <title> Comparison of the efficiency of deterministic and stochastic algorithms for visual reconstruction. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(1) </volume> <pages> 2-12, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [BT92] <author> Luigi Bedini and Anna Tonazzini. </author> <title> Image restoration preserving discontinuities: the Bayesian approach and neural networks. </title> <journal> Image and Vision Computing, </journal> <volume> 10(2) </volume> <pages> 108-118, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [DE87] <author> Haluk Derin and Howard Elliott. </author> <title> Modeling and segmentation of noisy and textured images using Gibbs random fields. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1) </volume> <pages> 39-55, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs. Gray, Kay and Titterington [GKT92] follows up on work by Derin and Elliott <ref> [DE87] </ref> on the estimation of MRF parameters using a method called the "logit" method, and a "histogram count", which is very similar to the sampling ideas of this paper.
Reference: [GG84] <author> Stuart Geman and Donald Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(6) </volume> <pages> 721-741, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: Gibbs distributions have convenient theoretical properties: they are compact | of lower dimensionality than marginal distributions | and important optimization methods such as the iterated conditional modes (ICM) algorithm and simulated annealing are guaranteed to converge <ref> [Bes86, GG84] </ref>. This paper examines how closely Gibbs distributions model the local structures that commonly occur in a typical class of artificial imagery. Our experiments use empirical distributions over 3 fi 3 neighborhoods from images of occluding ellipses and rotated rectangles as in figure 1. <p> We model these marginal distributions with Gibbs distributions, experimentally determine how well the Gibbs distributions models the empirical data, and test the Gibbs model against the empirical distribution using the ICM and simulated annealing algorithms. In D. and S. Geman's 1984 paper <ref> [GG84] </ref> the Gibbs distribution is defined as follows: 1 A Gibbs distribution relative to fS; Gg is a probability measure on with the following representation: (!) = Z where Z and T are constants and U , called the energy function, is of the form U (!) = c2C Recall that <p> In this paper we shall refer to this particular HK level as "optimum" HK. 3 Background This approach of using local neighborhood characteristics is essentially that of Markov random fields (MRF), originally developed and applied to image domains by J. Besag and D. and S. Geman <ref> [Bes74, Bes86, GG84] </ref>. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90].
Reference: [GG91] <author> D. Geiger and F. Girosi. </author> <title> Parallel and deterministic algorithms from MRF's: Surface reconstructions. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-13(5):401-413, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [GGGD90] <author> D. Geman, S. Geman, C. Graffigne, and P. Dong. </author> <title> Boundary detection by constrained optimization. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(7) </volume> <pages> 609-628, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [GKT92] <author> A.J Gray, J.W. Kay, </author> <title> and D.M. Titterington. On the estimation of noisy binary Markov random fields. </title> <journal> Pattern Recognition, </journal> <volume> 25(7) </volume> <pages> 749-768, </pages> <year> 1992. </year>
Reference-contexts: However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs. Gray, Kay and Titterington <ref> [GKT92] </ref> follows up on work by Derin and Elliott [DE87] on the estimation of MRF parameters using a method called the "logit" method, and a "histogram count", which is very similar to the sampling ideas of this paper.
Reference: [HK90] <author> E.R. Hancock and J. Kittler. </author> <title> A label error process for discrete relaxation. </title> <booktitle> In Proceedings of the 10th international conference on pattern recognition, </booktitle> <pages> pages 523-527. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: This causes many of the empirical marginals to be zero in the sampled distribution. However the probability ratios of such local neighborhoods may be necessary for image analysis using these distributions. Hancock and Kittler <ref> [HK90] </ref> studied this problem for fields directly estimated by people (where this problem is even more acute) and suggested a solution to this problem. They add "noise" to an estimate distribution, by smoothing it.
Reference: [JW90] <author> F.C. Jeng and J.W. Woods. </author> <title> Simulated annealing in compound Gaussian random fields. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 36(1) </volume> <pages> 94-107, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [KY91] <author> Il Young Kim and Hyun Seung Yang. </author> <title> Markov random field based image labeling with parameter estimation by error backpropagation. </title> <journal> IEICE Transactions on Information and Systems, </journal> <volume> E74(10):3513-3521, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: Lakshmanan and Derin [LD89] and Manjunath and Chellappa [MC91] also try to estimate the MRF parameters from a single image, but they use either a simulated annealing or nearest neighbor approach to do so. Kim and Yang <ref> [KY91] </ref> use the error backpropagation technique from neural networks to estimate the MRF parameters. 4 Derived Distributions The Gibbs distributions suggested by various authors in the literature tend to have a very simply structure over the 66 clique potentials.
Reference: [LD89] <author> S. Lakshmanan and H. Derin. </author> <title> Simultaneous parameter estimation and segmentation of Gibbs random fields using simulated annealing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(8) </volume> <pages> 799-813, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs. <p> Gray, Kay and Titterington [GKT92] follows up on work by Derin and Elliott [DE87] on the estimation of MRF parameters using a method called the "logit" method, and a "histogram count", which is very similar to the sampling ideas of this paper. Lakshmanan and Derin <ref> [LD89] </ref> and Manjunath and Chellappa [MC91] also try to estimate the MRF parameters from a single image, but they use either a simulated annealing or nearest neighbor approach to do so.
Reference: [Mar85] <author> Jose Luis Marroquin. </author> <title> Probabilistic solution of inverse problems. </title> <type> Technical Report TR 860, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> September </month> <year> 1985. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [MC91] <author> B. S. Manjunath and R. Chellappa. </author> <title> Unsupervised texture segmentation using Markov random field models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-13(5):478-482, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Lakshmanan and Derin [LD89] and Manjunath and Chellappa <ref> [MC91] </ref> also try to estimate the MRF parameters from a single image, but they use either a simulated annealing or nearest neighbor approach to do so.
Reference: [MMP85] <author> J. Marroquin, S. Mitter, and T. Poggio. </author> <title> Probabilistic solution of ill-posed problems in computational vision. </title> <editor> In Lee S. Bauman, editor, </editor> <booktitle> Proceedings: Image Understanding Workshop, </booktitle> <pages> pages 293-309. </pages> <institution> Science Applications International Corporation, </institution> <month> December </month> <year> 1985. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [MS91] <author> Davin Milun and David Sher. </author> <title> Improving Markov random field reconstructions by using noisy probabilities. </title> <editor> In V. Cantoni, M. Ferretti, S. Levialdi, R. Negrini, and R. Stefanelli, editors, </editor> <booktitle> 6th International Conference on Image Analysis and Processing : Progress in Image Analysis and Processing II, </booktitle> <pages> pages 147-154. </pages> <publisher> World Scientific, </publisher> <month> September </month> <year> 1991. </year>
Reference-contexts: They add "noise" to an estimate distribution, by smoothing it. The marginal probability of a neighborhood labeling depends on how close it is, by the L 1 norm, to the high probability neighborhood labelings. 2 In previous work <ref> [MS91, MS93] </ref> we used a modification of this method of Hancock and Kittler, and smoothed empirical probability densities, and used these probability density functions as prior information at a simulated annealer, and in ICM algorithm. We found that using this Hancock-Kittler smoothing yielded reconstructions which were visually and statistically superior.
Reference: [MS93] <author> Davin Milun and David Sher. </author> <title> Improving sampled probability distributions for Markov random fields. </title> <journal> Pattern Recognition Letters, </journal> <volume> 14(10) </volume> <pages> 781-788, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: They add "noise" to an estimate distribution, by smoothing it. The marginal probability of a neighborhood labeling depends on how close it is, by the L 1 norm, to the high probability neighborhood labelings. 2 In previous work <ref> [MS91, MS93] </ref> we used a modification of this method of Hancock and Kittler, and smoothed empirical probability densities, and used these probability density functions as prior information at a simulated annealer, and in ICM algorithm. We found that using this Hancock-Kittler smoothing yielded reconstructions which were visually and statistically superior.
Reference: [Pra78] <author> W. K. Pratt. </author> <title> Digital Image Processing. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: One is the metric of the number of bits that differ between the reconstructed image and the original noise-free image. The results from this metric are included in tables 2 and 3. The second measure we used is Pratt's Figure of Merit <ref> [Pra78] </ref>. This is a number in range 0 to 1, which represents how good an edge detector is, with 1 being perfect. It takes into account both edge position and accuracy.
Reference: [She91] <author> David Sher. </author> <title> Minimizing the cost of errors with a Markov random field. </title> <journal> Pattern Recognition Letters, </journal> <volume> 12(2), </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [Swa90] <author> Michael J. Swain. </author> <title> Parameter learning for Markov random fields with highest confidence first estimation. </title> <type> Technical Report TR350, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [TGD92] <author> H. L. Tan, S. B. Gelfand, and E. J. Delp. </author> <title> A cost minimization approach to edge detection using simulated annealing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-14(1):3-19, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: Besag and D. and S. Geman [Bes74, Bes86, GG84]. Many researchers have followed up on this research, and have developed various techniques for "solving" images when the local neighborhood characteristics are specified as an MRF, for example <ref> [JW90, GGGD90, TGD92, BT92, Mar85, MMP85, She91, GG91, Bla89, LD89, Swa90] </ref>. However, not much attention has been paid to the methods of deriving the probability density functions of the MRFs.
Reference: [ZZAA92] <author> Yunxin Zhau, Xinhau Zhuang, Les Atlas, and Lars Anderson. </author> <title> Parameter estimation and restoration of noisy images using Gibbs distributions in hidden Markov models. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 54(3) </booktitle> <pages> 187-197, </pages> <month> May </month> <year> 1992. </year> <month> 7 </month>
Reference-contexts: Those that use the 8-connected neighborhood ([DE87, LD89] among others), usually use some relatively simple rule such as assigning one value fi to a clique if all pixels within it are equal, and fi otherwise. Even many people who use 4-connected neighborhoods, use a similar scheme, such as <ref> [ZZAA92] </ref>. The distributions found by the method of pseudoinverses, as described in Section 1, have only a small number of cliques with non-zero potentials. This makes our derived cliques a very compact method of storing local information.
References-found: 23

