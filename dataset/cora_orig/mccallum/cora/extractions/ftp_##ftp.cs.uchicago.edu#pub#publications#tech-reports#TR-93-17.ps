URL: ftp://ftp.cs.uchicago.edu/pub/publications/tech-reports/TR-93-17.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Email: panni@cs.uchicago.edu  ms@research.att.com  
Title: Fault tolerant circuits and probabilistically checkable proofs  
Author: Anna Gal Mario Szegedy 
Address: 1100 E. 58th Street Chicago, IL 60637  600 Mountain Avenue Murray Hill NJ 07974  
Affiliation: The University of Chicago Department of Computer Science  AT&T Bell Laboratories  
Abstract: We introduce a new model of fault tolerant Boolean circuits. We allow an adversary to choose some gates to be faulty, unlike the model considered by von Neumann and Pippenger where the errors are randomly distributed. Our model also differs from previous models that considered non-random faults. Our main result is that every symmetric function has a small (size O(n), depth O(log n)) fault tolerant circuit that will compute the function adequately, even if a small constant fraction of the gates is modified by an adversary. We also show a perhaps unexpected relation between our model and probabilistically checkable proofs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora and S. Safra, </author> <title> "Probabilistic checking of proofs," </title> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 2-13. </pages>
Reference-contexts: Thus, for practical purposes it can be justified similarily to the previous approaches to handle non-random faults. There is a connection between our model and recently discovered constructions for proof encodings <ref> [1] </ref>, [8], [5]. In Section 5 we show that if small depth circuits for certain Boolean functions can be turned into fault tolerant circuits with constant redundancy, then N P = P CP (log n; log n) [1] follows. <p> is a connection between our model and recently discovered constructions for proof encodings <ref> [1] </ref>, [8], [5]. In Section 5 we show that if small depth circuits for certain Boolean functions can be turned into fault tolerant circuits with constant redundancy, then N P = P CP (log n; log n) [1] follows. Another result of the same section verifies the existence of such circuits. Combining the two theorems however we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log <p> tolerant circuits with constant redundancy, then N P = P CP (log n; log n) <ref> [1] </ref> follows. Another result of the same section verifies the existence of such circuits. Combining the two theorems however we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log n; 1) [5]. <p> The second parameter is the number of bits that P reads from y (for the 8 worst y). If the former function is O (ff (jxj)) and the later is O (fi (jxj)) then it is said that L belongs to P CP (ff; fi). Arora and Safra <ref> [1] </ref> characterized the language class N P as P CP (log n; log n). Later this result was improved by Arora et al. [5] to show that N P = P CP (log n; 1).
Reference: [2] <author> M. Ajtai, M. Ben-Or, </author> <title> "A theorem on probabilistic constant depth computations," </title> <booktitle> In Proc. of "16-th ACM Symposium on Theory of Computing", </booktitle> <year> 1984, </year> <pages> pp. 471-474. </pages>
Reference-contexts: For the first sight it may appear that computational devices that loosely compute a function f can be far weaker than those that are able to get the value of f everywhere. For instance it is well known <ref> [2] </ref> that there is an AC 0 circuit that loosely computes the majority function, whereas majority itself cannot be computed in AC 0 . One may speculate similarly that every function in N P might be loosely computed in P .
Reference: [3] <author> M. Ajtai, J. Komlos, E. Szemeredi, </author> <title> "An O(n log n) sorting network," </title> <booktitle> In Proc. of "15-th ACM Symposium on Theory of Computing", </booktitle> <year> 1983, </year> <pages> pp. 1-9. </pages>
Reference-contexts: Thus building C 0 as above would allow us to differenciate between satisfiable and non satisfiable instances. 3 Halvers Our construction for symmetric functions is based on the *-halvers of Ajtai, Komlos and Szemeredi <ref> [3] </ref>. The *-halvers are bounded depth comparator networks computing *-halved permutations of the input. If the halving were perfect then every element in the upper half would be greater than or equal to any element in the lower half. <p> Their new construction is based on units called k-comparators. A k-comparator has to sort its k input elements. All of our constructions work using the new efficient *-halvers as well as using the original *-halvers. Note however that the *-halvers of <ref> [3] </ref> are explicit, based on explicit constructions of expander graphs, but we only know the existence of the more efficient *-halvers. For simplicity and for providing a uniform way to talk about *-halvers we assume that each k-comparator is realized by depth k 2-comparator networks.
Reference: [4] <author> M. Ajtai, J. Komlos, E. Szemeredi, "Halvers and expanders," </author> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 686-692. </pages>
Reference-contexts: The *-halving property allowes that an * fraction of the elements may get into the wrong half. For a set of the l smallest (largest) elements, where l n=2, at most *l of them may end up in the upper (lower) half of the output. In a recent paper <ref> [4] </ref> Ajtai, Komlos and Szemeredi introduced more efficient *-halvers. Their new construction is based on units called k-comparators. A k-comparator has to sort its k input elements. All of our constructions work using the new efficient *-halvers as well as using the original *-halvers. <p> For simplicity and for providing a uniform way to talk about *-halvers we assume that each k-comparator is realized by depth k 2-comparator networks. Since the *-halvers of <ref> [4] </ref> are depth 2 k-comparator networks, the depth of our realization of such *-halvers by 2-comparator networks will be 2k. In what follows by the depth of an *-halver we always mean the depth of the realization by 2-comparator networks.
Reference: [5] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, M. Szegedy, </author> <title> "Proof verification and hardness of approximation problems," </title> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 14-23. </pages>
Reference-contexts: Thus, for practical purposes it can be justified similarily to the previous approaches to handle non-random faults. There is a connection between our model and recently discovered constructions for proof encodings [1], [8], <ref> [5] </ref>. In Section 5 we show that if small depth circuits for certain Boolean functions can be turned into fault tolerant circuits with constant redundancy, then N P = P CP (log n; log n) [1] follows. Another result of the same section verifies the existence of such circuits. <p> Combining the two theorems however we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log n; 1) <ref> [5] </ref>. <p> Arora and Safra [1] characterized the language class N P as P CP (log n; log n). Later this result was improved by Arora et al. <ref> [5] </ref> to show that N P = P CP (log n; 1). We are now ready to describe the relation between fault tolerant circuits and probabilistically checkable proofs. <p> Sketch of the proof: The proof connects recent results of Arora et al. <ref> [5] </ref> with the theorem of Section 4 in a simple manner. In [5] the true prover follows a certain algorithm in order to create a string that the verifier can check. First the true prover takes an assignment x with C (x) = 1. <p> Sketch of the proof: The proof connects recent results of Arora et al. <ref> [5] </ref> with the theorem of Section 4 in a simple manner. In [5] the true prover follows a certain algorithm in order to create a string that the verifier can check. First the true prover takes an assignment x with C (x) = 1. This he can choose by his infinite power. <p> This code will be E in the theorem. (We do not care that this code may not be linear.) We now return to defining circuit C 0 : Again, we take the proof system given by Arora et al. <ref> [5] </ref>. Observe that the checks of the verifier are constant size circuits. We build all these cicuits (for each possible random choice of the verifier there is one such a circuit) into C 0 .
Reference: [6] <author> S. Assaf, E. Upfal, </author> <title> "Fault tolerant sorting network", </title> <booktitle> In Proc. of "31-st IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1990, </year> <pages> pp. 275-284. </pages>
Reference-contexts: Then there is a fl-faulty circuit of size O (n) and depth O (log n) computing M aj n k correctly on every input belonging to its domain. Proof: The building blocks of our construction are triplets of *-halvers called sieves. A similar component is used in <ref> [6] </ref>. An m-input sieve will have m=2 outputs. First we apply an m-input *-halver to the m inputs. Let us call it M -halver. Then we apply two m=2-input *-halvers, one to the lower part the other to the upper part of the output of the M -halver.
Reference: [7] <author> L. Babai, </author> <title> "Transparent proofs and limits to approximation," </title> <institution> University of Chicago Technical Report CS93-15, </institution> <year> 1993. </year>
Reference: [8] <author> M. Blum, M. Luby, R. Rubinfeld, </author> <title> "Self-testing/correcting with applications to numerical problems," </title> <booktitle> In Proc. of "22-nd ACM Symposium on Theory of Computing", </booktitle> <year> 1990, </year> <pages> pp. 73-83. </pages>
Reference-contexts: Thus, for practical purposes it can be justified similarily to the previous approaches to handle non-random faults. There is a connection between our model and recently discovered constructions for proof encodings [1], <ref> [8] </ref>, [5]. In Section 5 we show that if small depth circuits for certain Boolean functions can be turned into fault tolerant circuits with constant redundancy, then N P = P CP (log n; log n) [1] follows. Another result of the same section verifies the existence of such circuits.
Reference: [9] <author> R. L. Dobrushin and S. I. Ortyukov, </author> <title> "Lower bound for the redundancy of self-correcting arrangements of unreliable functional elements," </title> <journal> Prob. Inf. Trans. </journal> <volume> 13, </volume> <year> 1977, </year> <pages> pp. 59-65. </pages>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions <ref> [9] </ref>, [11], [18]. Thus, as long as the faults occur randomly and independently, we can build circuits that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [10] <author> R. L. Dobrushin and S. I. Ortyukov, </author> <title> "Upper bound for the redundancy of self-correcting arrangements of unreliable functional elements," </title> <journal> Prob. Inf. Trans. </journal> <volume> 13, </volume> <year> 1977, </year> <pages> pp. 203-218. 10 </pages>
Reference-contexts: Most progress in this area has been achieved considering independent random faults and suggesting constructions that give correct results with high probability. For Boolean circuits in the model of independent random faults it is known [15], <ref> [10] </ref>, [16] that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the funtion without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> The results of [15], <ref> [10] </ref>, [16] give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2.
Reference: [11] <author> P. Gacs and A. Gal, </author> <title> "Lower Bounds for the Complexity of Reliable Boolean Circuits with Noisy Gates," </title> <note> to appear in IEEE Trans. Inform. Theory </note>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions [9], <ref> [11] </ref>, [18]. Thus, as long as the faults occur randomly and independently, we can build circuits that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [12] <author> G. I. Kirienko, </author> <title> "On self-correcting schemes from functional elements," Probl. </title> <journal> Kibern. </journal> <volume> 12, </volume> <year> 1964, </year> <pages> pp. 29-37. </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty <ref> [12] </ref>, [13], [20].
Reference: [13] <author> G. I. Kirienko, </author> <title> "Synthesis of self-correcting schemes from functional elements for the case of growing number of faults in the scheme," </title> <journal> Diskret. Anal. </journal> <volume> 16, </volume> <year> 1970, </year> <pages> pp. 38-43. </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty [12], <ref> [13] </ref>, [20].
Reference: [14] <author> D. E. Muller, </author> <title> "Complexity in electronic switching circuits," </title> <journal> IRE Trans. Electr. Comput. </journal> <volume> 5, </volume> <year> 1956, </year> <pages> pp. 15-19. </pages>
Reference-contexts: Moreover these constructions have exponential size, thus they give small redundancy only for functions that require exponential size circuits even without faults. (Note that almost all Boolean functions require exponential size circuits [19], <ref> [14] </ref>, but there 1 is still no explicit function known to require superlinear size circuits.) To our knowledge, there are no previous results achieving small redundancy tolerating a constant fraction of gates being faulty in the case when the faults are not random.
Reference: [15] <author> J. von Neumann, </author> <title> "Probabilistic logics and the synthesis of reliable organisms from unreliable components," In Automata Studies, </title> <editor> C. E. Shannon and J. McCarthy Eds., </editor> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1956, </year> <pages> pp. 329-378. </pages>
Reference-contexts: Most progress in this area has been achieved considering independent random faults and suggesting constructions that give correct results with high probability. For Boolean circuits in the model of independent random faults it is known <ref> [15] </ref>, [10], [16] that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the funtion without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> The results of <ref> [15] </ref>, [10], [16] give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2.
Reference: [16] <author> N. Pippenger, </author> <title> "On networks of noisy gates," </title> <booktitle> In Proc. of "26-th IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1985, </year> <pages> pp. 30-36. </pages>
Reference-contexts: Most progress in this area has been achieved considering independent random faults and suggesting constructions that give correct results with high probability. For Boolean circuits in the model of independent random faults it is known [15], [10], <ref> [16] </ref> that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the funtion without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> For Boolean circuits in the model of independent random faults it is known [15], [10], <ref> [16] </ref> that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the funtion without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. By redundancy we mean the fraction of the size needed for computation with faults and the size needed to compute the function without faults. <p> The results of [15], [10], <ref> [16] </ref> give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2. The size of C 0 is O (S (C) log S (C)), where S (C) denotes the size of cicuit C. 3.
Reference: [17] <author> N. Pippenger, </author> <title> Developments in "The Synthesis of Reliable Organisms from Unreliable Components", </title> <booktitle> In Proc. of "Symposia in Pure Mathematics", </booktitle> <volume> Vol. 50, </volume> <year> 1990, </year> <pages> pp. 311-324. </pages>
Reference-contexts: For a survey of related results see <ref> [17] </ref>. We propose a new approach to the problem: We consider synchronized (leveled) circuits and let the adversary choose a certain fraction of the gates at each level to be faulty.
Reference: [18] <author> R. Reischuk, B. Schmeltz, </author> <title> "Reliable Computation with Noisy Circuits and Decision Trees A General n log n Lower Bound," </title> <booktitle> In Proc. of "32-nd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1991, </year> <pages> pp. 602-611. </pages>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions [9], [11], <ref> [18] </ref>. Thus, as long as the faults occur randomly and independently, we can build circuits that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [19] <author> C. E. Shannon, </author> <title> "The synthesis of two-terminal switching circuits," </title> <journal> Bell Syst. Techn. J. </journal> <volume> 28, </volume> <year> 1949, </year> <pages> pp. 59-98. </pages>
Reference-contexts: Moreover these constructions have exponential size, thus they give small redundancy only for functions that require exponential size circuits even without faults. (Note that almost all Boolean functions require exponential size circuits <ref> [19] </ref>, [14], but there 1 is still no explicit function known to require superlinear size circuits.) To our knowledge, there are no previous results achieving small redundancy tolerating a constant fraction of gates being faulty in the case when the faults are not random.
Reference: [20] <author> D. Uhlig, </author> <title> "On the synthesis of self-correcting schemes from functional elements with a small number of reliable elements," </title> <journal> Math. Notes. Acad. Sci. </journal> <volume> USSR 15, </volume> <year> 1974, </year> <pages> pp. 558-562. 11 </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty [12], [13], <ref> [20] </ref>.
References-found: 20

