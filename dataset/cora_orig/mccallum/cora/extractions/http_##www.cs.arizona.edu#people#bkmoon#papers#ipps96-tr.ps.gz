URL: http://www.cs.arizona.edu/people/bkmoon/papers/ipps96-tr.ps.gz
Refering-URL: http://www.cs.arizona.edu/people/bkmoon/papers.html
Root-URL: http://www.cs.arizona.edu
Email: fbkmoon, acha, saltzg@cs.umd.edu  
Title: Study of Scalable Declustering Algorithms for Parallel Grid Files  
Author: Bongki Moon Anurag Acharya Joel Saltz 
Address: College Park, MD 20742  
Affiliation: Institute for Advanced Computer Studies and Department of Computer Science University of Maryland  
Web: URL ftp://hpsl.cs.umd.edu/pub/papers/ipps96-tr.ps.Z.  
Note: CS-TR-3589 and UMIACS-TR-96-4. Short version appears in IPPS'96. Available at  
Abstract: Efficient storage and retrieval of large multidimensional datasets is an important concern for large-scale scientific computations such as long-running time-dependent simulations which periodically generate snapshots of the state. The main challenge for efficiently handling such datasets is to minimize response time for multidimensional range queries. The grid file is one of the well known access methods for multidimensional and spatial data. We investigate effective and scalable declustering techniques for grid files with the primary goal of minimizing response time and the secondary goal of maximizing the fairness of data distribution. The main contributions of this paper are (1) analytic and experimental evaluation of existing index-based declustering techniques and their extensions for grid files, and (2) development of a proximity-based declustering algorithm called minimax which is experimentally shown to scale and to consistently achieve better response time compared to available algorithms while maintaining perfect disk distribution. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Bially. </author> <title> Space-filling curves : Their generation and their application to bandwidth reduction. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-15(6):658-664, </volume> <month> Nov. </month> <year> 1969. </year>
Reference-contexts: The Hilbert curve scheme (HCAM) [4] is based on the idea of space filling curves. A space filling curve visits all points in a d-dimensional space exactly once and never crosses itself <ref> [1] </ref>. It can be used to linearize a set of points (or buckets) in d-dimensional space. The buckets are then assigned to disks in a round robin 2 fashion.
Reference: [2] <author> G. A. Bird. </author> <title> Molecular Gas Dynamics and the Direct Simulation of Gas Flows. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1994. </year>
Reference-contexts: Typical examples are long running simulations of time-dependent phenomena which periodically generate snapshots of the state. The sequence of snapshots is later analyzed and/or visualized, often repeatedly, for trends and transients. Examples include Direct Simulation Monte Carlo (DSMC) <ref> [2] </ref>, magneto-hydro dynamics (MHD) simulation of planetary magneto-spheres [28], simulation of a flame sweeping through a volume [23], airplane wake simulations [18] etc. <p> We used two real three-dimensional snapshot datasets and the hot.2d synthetic dataset as benchmarks. DSMC.3d Direct Simulation Monte Carlo (DSMC) is a technique for modelling rarefied gas dynamics via direct particle simulation which has been widely used in aerospace applications <ref> [2] </ref>. This data set is generated from a 3-dimensional DSMC simulation which runs on parallel machines [20]. The dataset consists of one snapshot of a three-dimensional volume. There are 52857 particle records and they are non-uniformly distributed. The x, y and z-coordinates of particles are used as the primary indices.
Reference: [3] <author> H. C. Du and J. S. Sobolewski. </author> <title> Disk allocation for Cartesian product files on multiple-disk systems. </title> <journal> ACM Trans. Database Syst., </journal> <volume> 7(1) </volume> <pages> 82-101, </pages> <month> Mar. </month> <year> 1982. </year>
Reference-contexts: We extend the three best-known schemes, disk modulo (DM) <ref> [3] </ref>, fieldwise xor (FX) [15], and Hilbert curve (HCAM) [4] for grid files. By simulation experiments, we show that the scalability of DM and FX for multidimensional range queries is limited. That is, as the number of disks is increased beyond a threshold, the response time no longer decreases. <p> It has been shown in <ref> [3] </ref> that the disk modulo is strictly optimal for many cases of partial match queries including all partial match queries with only one unspecified attribute.
Reference: [4] <author> C. Faloutsos and P. Bhagwat. </author> <title> Declustering using fractals. </title> <booktitle> In the 2nd International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 18-25, </pages> <address> San Diego, CA, </address> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: We extend the three best-known schemes, disk modulo (DM) [3], fieldwise xor (FX) [15], and Hilbert curve (HCAM) <ref> [4] </ref> for grid files. By simulation experiments, we show that the scalability of DM and FX for multidimensional range queries is limited. That is, as the number of disks is increased beyond a threshold, the response time no longer decreases. This result is corroborated by an analytical study. <p> The Hilbert curve scheme (HCAM) <ref> [4] </ref> is based on the idea of space filling curves. A space filling curve visits all points in a d-dimensional space exactly once and never crosses itself [1]. It can be used to linearize a set of points (or buckets) in d-dimensional space. <p> Faloutsos and Bhagwat <ref> [4] </ref> have shown empirically that HCAM outperforms DM and FX for small queries and large number of disks. 2.1. <p> Also note that even though the performance saturates for both DM and FX, FX saturates at a lower response time than DM. We would like to point out that our results are similar to the conclusion drawn by <ref> [4] </ref> in that the performance of HCAM is the best for uniformly distributed dataset (uniform.2d). However, our result that DM is almost always better than FX for a small number of disks conflicts with their conclusion that FX is always better than DM.
Reference: [5] <author> C. Faloutsos and S. Roseman. </author> <title> Fractals for secondary key retrieval. </title> <booktitle> In the 8th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> Philadelphia, PA, </address> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: As shown by our experiments, the actual scalability of fieldwise xor is even worse than this theorem suggests. It is widely believed that Hilbert curve achieves better clustering among other linearization methods such as column-wise scan, z-curve and Gray coding <ref> [5, 11] </ref>. We are currently working on the analysis of the scalability of HCAM. 3.
Reference: [6] <author> M. T. Fang, R. C. T. Lee, and C. C. Chang. </author> <title> The idea of de-clustering and its applications. </title> <booktitle> In Proceedings of the 12th VLDB Conference, </booktitle> <pages> pages 181-188, </pages> <address> Kyoto, Japan, </address> <year> 1986. </year>
Reference-contexts: This problem is a variant of the well-known Max-Cut problem, which is known to be NP-complete [8]. Several heuristic algorithms have been proposed for the Max-Cut problem and its analogue, the Min-Cut problem. They include Recursive Spectral Bisection [27], Kernighan-Lin partitioning algorithm [14] and similarity-based declustering algorithms <ref> [6, 17] </ref>. Recursive Spectral Bisection is not suitable for this problem since it assumes unit weights on all edges, and there appears to be no obvious way to allow arbitrary edge weights. <p> The similarity graph-based approach proposed by Liu and Shekhar [17] requires no less disk accesses since Kernighan-Lin algorithm is used to find an initial partition. The similarity-based algorithms, minimal spanning tree (MST) and short spanning path (SSP), introduced by Fang et al. <ref> [6] </ref> eliminate the factor p. They attempt to generate partitions that are similar to each other.
Reference: [7] <author> R. A. Finkel and J. L. Bentley. </author> <title> Quad-Trees a data structure for retrieval on composite keys. </title> <journal> Acta Informatica, </journal> <volume> 4 </volume> <pages> 1-9, </pages> <year> 1974. </year>
Reference-contexts: Three classes of approaches have been suggested for storage and retrieval of multidimensional datasets: chunking [25, 26], grid files [21] and tree-based data structures <ref> [7, 10] </ref>. Chunking is usually tied to a single application. It divides the data into disjoint subspaces based on the processing requirements of the associated application and stores the subspaces in an order which directly reflects the structure of this application.
Reference: [8] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: This problem is a variant of the well-known Max-Cut problem, which is known to be NP-complete <ref> [8] </ref>. Several heuristic algorithms have been proposed for the Max-Cut problem and its analogue, the Min-Cut problem. They include Recursive Spectral Bisection [27], Kernighan-Lin partitioning algorithm [14] and similarity-based declustering algorithms [6, 17].
Reference: [9] <author> C. Goodrich. </author> <type> Personal communication, </type> <month> July </month> <year> 1995. </year>
Reference-contexts: Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands <ref> [9, 22] </ref>. Frequent operations on these datasets include volume visualization (including animation), detecting transients, computing trends and averages and composition [9, 22, 29]. For data retrieval, all of these translate to requests for multidimensional subspace from the dataset, that is, to multidimensional range queries. <p> Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22]. Frequent operations on these datasets include volume visualization (including animation), detecting transients, computing trends and averages and composition <ref> [9, 22, 29] </ref>. For data retrieval, all of these translate to requests for multidimensional subspace from the dataset, that is, to multidimensional range queries. Most such datasets are used by a small number of users and the metric of importance is response time.
Reference: [10] <author> A. Guttman. R-Trees: </author> <title> A dynamic index structure for spatial searching. </title> <booktitle> In Proceedings of the 1984 ACM-SIGMOD Conference, </booktitle> <pages> pages 47-57, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: Three classes of approaches have been suggested for storage and retrieval of multidimensional datasets: chunking [25, 26], grid files [21] and tree-based data structures <ref> [7, 10] </ref>. Chunking is usually tied to a single application. It divides the data into disjoint subspaces based on the processing requirements of the associated application and stores the subspaces in an order which directly reflects the structure of this application.
Reference: [11] <author> H. V. Jagadish. </author> <title> Linear clustering of objects with multiple attributes. </title> <booktitle> In Proceedings of the 1990 ACM-SIGMOD Conference, </booktitle> <pages> pages 332-342, </pages> <address> Atlantic City, NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: As shown by our experiments, the actual scalability of fieldwise xor is even worse than this theorem suggests. It is widely believed that Hilbert curve achieves better clustering among other linearization methods such as column-wise scan, z-curve and Gray coding <ref> [5, 11] </ref>. We are currently working on the analysis of the scalability of HCAM. 3.
Reference: [12] <author> I. Kamel and C. Faloutsos. </author> <title> Parallel R-trees. </title> <booktitle> In Proceedings of the 1992 ACM-SIGMOD Conference, </booktitle> <pages> pages 195-204, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, results presented in the next section indicate that this happens rarely (See Table 2 and Table 3). To complete the description of the algorithm, we need to specify a way to generate the edge weights. We have chosen the proximity index proposed by Kamel and Faloutsos <ref> [12] </ref>. The alternative we considered, Euclidean distance is suitable for point objects that occupy zero area in the problem space but does not capture the distinction among pairs of partially overlapped spatial objects such as grid buckets 1 .
Reference: [13] <author> A. Karp. </author> <title> Programming for parallelism. </title> <journal> IEEE Computer, </journal> <volume> 20(5) </volume> <pages> 43-57, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Experiments on shared-nothing architectures We implemented parallel grid files and related access methods on a 16-processor IBM SP-2, which has a typical shared-nothing architecture in which each processing node owns local memory and local disks, and communicates each other by message passing. We adopted Single-Program-Multiple-Data (SPMD) <ref> [13] </ref> as a model of parallelism; one of the participating processors is chosen as a coordinator and the other processors are called workers. We assumed each processor owns only one disk to simplify the model of parallelism.
Reference: [14] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> Feb. </month> <year> 1970. </year>
Reference-contexts: This problem is a variant of the well-known Max-Cut problem, which is known to be NP-complete [8]. Several heuristic algorithms have been proposed for the Max-Cut problem and its analogue, the Min-Cut problem. They include Recursive Spectral Bisection [27], Kernighan-Lin partitioning algorithm <ref> [14] </ref> and similarity-based declustering algorithms [6, 17]. Recursive Spectral Bisection is not suitable for this problem since it assumes unit weights on all edges, and there appears to be no obvious way to allow arbitrary edge weights. <p> Even though the number of passes p is usually low, there is no bound on the number of passes <ref> [14] </ref>. In particular, there is no evidence that it will terminate in a polynomial number of passes and, as a result, may require an unacceptably high number of disk accesses for declustering.
Reference: [15] <author> M.-H. Kim and S. Pramanik. </author> <title> Optimal file distribution for partial match retrieval. </title> <booktitle> In Proceedings of the 1988 ACM-SIGMOD Conference, </booktitle> <pages> pages 173-182, </pages> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: We extend the three best-known schemes, disk modulo (DM) [3], fieldwise xor (FX) <ref> [15] </ref>, and Hilbert curve (HCAM) [4] for grid files. By simulation experiments, we show that the scalability of DM and FX for multidimensional range queries is limited. That is, as the number of disks is increased beyond a threshold, the response time no longer decreases. <p> It has been shown that when the number of disks and the size of each field are power of 2, the set of partial match queries which are optimal for the fieldwise xor scheme is a superset of those for the disk modulo scheme <ref> [15] </ref>. The Hilbert curve scheme (HCAM) [4] is based on the idea of space filling curves. A space filling curve visits all points in a d-dimensional space exactly once and never crosses itself [1]. It can be used to linearize a set of points (or buckets) in d-dimensional space.
Reference: [16] <author> J. Li, J. Srivastava, and D. Rotem. CMD: </author> <title> A multidimensional declustering method for parallel database systems. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <pages> pages 3-14, </pages> <address> Vancouver, British Columbia, Canada, </address> <year> 1992. </year>
Reference-contexts: Given in [19]. Theorem 1 gives closed form expressions of response time as well as the necessary and sufficient condition for the strict optimality of disk modulo algorithm. Theorem 1 (i) is more general than Theorem 3 of Li et al. <ref> [16] </ref> which essentially states only the first clause. Based on this, they reach the conclusion that disk modulo is optimal for range queries on Cartesian product files for almost all cases. <p> In addition, for any M 3, Theorem 1 (ii) gives a tighter upper bound on the response time than R Opt (M ) + M 2 given in Theorem 4 of Li et al. <ref> [16] </ref> when the number of dimensions is two. Theorem 2 For any 2-dimensional 2 m fi 2 m square range query, the following properties are satisfied: (i) R F X (2 n ) = 2 m+(mn) for any n m, (iii) R F X (2 n+1 ) 3 Proof.
Reference: [17] <author> D.-R. Liu and S. Shekhar. </author> <title> A similarity graph-based approach to declustering problems and its application towards parallelizing grid files. </title> <booktitle> In the 11th Inter. Conference on Data Engineering, </booktitle> <pages> pages 373-381, </pages> <address> Taipei, Taiwan, </address> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: This problem is a variant of the well-known Max-Cut problem, which is known to be NP-complete [8]. Several heuristic algorithms have been proposed for the Max-Cut problem and its analogue, the Min-Cut problem. They include Recursive Spectral Bisection [27], Kernighan-Lin partitioning algorithm [14] and similarity-based declustering algorithms <ref> [6, 17] </ref>. Recursive Spectral Bisection is not suitable for this problem since it assumes unit weights on all edges, and there appears to be no obvious way to allow arbitrary edge weights. <p> In particular, there is no evidence that it will terminate in a polynomial number of passes and, as a result, may require an unacceptably high number of disk accesses for declustering. The similarity graph-based approach proposed by Liu and Shekhar <ref> [17] </ref> requires no less disk accesses since Kernighan-Lin algorithm is used to find an initial partition. The similarity-based algorithms, minimal spanning tree (MST) and short spanning path (SSP), introduced by Fang et al. [6] eliminate the factor p. They attempt to generate partitions that are similar to each other.
Reference: [18] <author> K.-L. Ma and Z. Zheng. </author> <title> 3D visualization of unsteady 2D airplane wake vortices. </title> <booktitle> In Proceedings of Visualization'94, </booktitle> <pages> pages 124-31, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: The sequence of snapshots is later analyzed and/or visualized, often repeatedly, for trends and transients. Examples include Direct Simulation Monte Carlo (DSMC) [2], magneto-hydro dynamics (MHD) simulation of planetary magneto-spheres [28], simulation of a flame sweeping through a volume [23], airplane wake simulations <ref> [18] </ref> etc. Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22].
Reference: [19] <author> B. Moon. </author> <title> Scalability analysis of declustering methods for Cartesian product files. </title> <type> Technical Report CS-TR-3590, </type> <institution> University of Maryland, Department of Computer Science and UMIACS, College Park, MD, </institution> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Given in <ref> [19] </ref>. Theorem 1 gives closed form expressions of response time as well as the necessary and sufficient condition for the strict optimality of disk modulo algorithm. Theorem 1 (i) is more general than Theorem 3 of Li et al. [16] which essentially states only the first clause. <p> Theorem 2 For any 2-dimensional 2 m fi 2 m square range query, the following properties are satisfied: (i) R F X (2 n ) = 2 m+(mn) for any n m, (iii) R F X (2 n+1 ) 3 Proof. Given in <ref> [19] </ref>. From property (i) of Theorem 2, it can be shown that fieldwise xor is strictly optimal for any 2 m fi 2 m square range query if M = 2 n and n m.
Reference: [20] <author> B. Moon and J. Saltz. </author> <title> Adaptive runtime support for direct simulation Monte Carlo methods on distributed memory architectures. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference (SHPCC-94), </booktitle> <pages> pages 176-183, </pages> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year> <month> 14 </month>
Reference-contexts: DSMC.3d Direct Simulation Monte Carlo (DSMC) is a technique for modelling rarefied gas dynamics via direct particle simulation which has been widely used in aerospace applications [2]. This data set is generated from a 3-dimensional DSMC simulation which runs on parallel machines <ref> [20] </ref>. The dataset consists of one snapshot of a three-dimensional volume. There are 52857 particle records and they are non-uniformly distributed. The x, y and z-coordinates of particles are used as the primary indices.
Reference: [21] <author> J. Nievergelt and H. Hinterberger. </author> <title> The Grid File: An adaptive, symmetric multikey file structure. </title> <journal> ACM Trans. Database Syst., </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <month> Mar. </month> <year> 1984. </year>
Reference-contexts: Three classes of approaches have been suggested for storage and retrieval of multidimensional datasets: chunking [25, 26], grid files <ref> [21] </ref> and tree-based data structures [7, 10]. Chunking is usually tied to a single application. It divides the data into disjoint subspaces based on the processing requirements of the associated application and stores the subspaces in an order which directly reflects the structure of this application.
Reference: [22] <author> G. Patnaik. </author> <type> Personal communication, </type> <month> September </month> <year> 1995. </year>
Reference-contexts: Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands <ref> [9, 22] </ref>. Frequent operations on these datasets include volume visualization (including animation), detecting transients, computing trends and averages and composition [9, 22, 29]. For data retrieval, all of these translate to requests for multidimensional subspace from the dataset, that is, to multidimensional range queries. <p> Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22]. Frequent operations on these datasets include volume visualization (including animation), detecting transients, computing trends and averages and composition <ref> [9, 22, 29] </ref>. For data retrieval, all of these translate to requests for multidimensional subspace from the dataset, that is, to multidimensional range queries. Most such datasets are used by a small number of users and the metric of importance is response time.
Reference: [23] <author> G. Patnaik, K. Kailasnath, and E. Oran. </author> <title> Effect of gravity on flame instabilities in premixed gases. </title> <journal> AIAA Journal, </journal> <volume> 29(12) </volume> <pages> 2141-8, </pages> <month> Dec </month> <year> 1991. </year>
Reference-contexts: The sequence of snapshots is later analyzed and/or visualized, often repeatedly, for trends and transients. Examples include Direct Simulation Monte Carlo (DSMC) [2], magneto-hydro dynamics (MHD) simulation of planetary magneto-spheres [28], simulation of a flame sweeping through a volume <ref> [23] </ref>, airplane wake simulations [18] etc. Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22].
Reference: [24] <author> R. C. Prim. </author> <title> Shortest connection networks and some generalizations. </title> <journal> Bell System Technical Journal, </journal> <volume> 36(11) </volume> <pages> 1389-1401, </pages> <month> Nov. </month> <year> 1957. </year>
Reference-contexts: The key idea of this algorithm is to extend Prim's minimal spanning tree algorithm <ref> [24] </ref> to generate M partitions. Prim's algorithm expands a minimal spanning tree by incrementally selecting the minimum cost edge between the vertices already in the tree and the vertices not yet in the tree.
Reference: [25] <author> S. Sarawagi and M. Stonebraker. </author> <title> Efficient organizations of large multidimensional arrays. </title> <booktitle> In Proceedings of the Tenth International Conference on Data Engineering, </booktitle> <month> February </month> <year> 1994. </year>
Reference-contexts: In this paper, we investigate effective and scalable data declustering techniques for multidimensional datasets with the primary goal of minimizing response time and the secondary goal of maximizing disk space utilization. Three classes of approaches have been suggested for storage and retrieval of multidimensional datasets: chunking <ref> [25, 26] </ref>, grid files [21] and tree-based data structures [7, 10]. Chunking is usually tied to a single application. It divides the data into disjoint subspaces based on the processing requirements of the associated application and stores the subspaces in an order which directly reflects the structure of this application.
Reference: [26] <author> K. E. Seamons and M. Winslett. </author> <title> Physical schemas for large multidimensional arrays in scientific computing applications. </title> <booktitle> In Proceedings of the Seventh International Working Conference on Scientific and Statistical Database management, </booktitle> <pages> pages 218-227, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In this paper, we investigate effective and scalable data declustering techniques for multidimensional datasets with the primary goal of minimizing response time and the secondary goal of maximizing disk space utilization. Three classes of approaches have been suggested for storage and retrieval of multidimensional datasets: chunking <ref> [25, 26] </ref>, grid files [21] and tree-based data structures [7, 10]. Chunking is usually tied to a single application. It divides the data into disjoint subspaces based on the processing requirements of the associated application and stores the subspaces in an order which directly reflects the structure of this application.
Reference: [27] <author> H. D. Simon. </author> <title> Partitioning of unstructured problems for parallel processing. </title> <booktitle> In Proceedings of the Conference on Parallel Methods on Large Scale Structured Analysis and Physics Applications. </booktitle> <publisher> Pergammon Press, </publisher> <year> 1991. </year>
Reference-contexts: This problem is a variant of the well-known Max-Cut problem, which is known to be NP-complete [8]. Several heuristic algorithms have been proposed for the Max-Cut problem and its analogue, the Min-Cut problem. They include Recursive Spectral Bisection <ref> [27] </ref>, Kernighan-Lin partitioning algorithm [14] and similarity-based declustering algorithms [6, 17]. Recursive Spectral Bisection is not suitable for this problem since it assumes unit weights on all edges, and there appears to be no obvious way to allow arbitrary edge weights.
Reference: [28] <author> T. Tanaka. </author> <title> Configurations of the solar wind flow and magnetic field around the planets with no magnetic field: calculation by a new MHD. </title> <journal> Jounal of Geophysical Research, </journal> <volume> 98(A10):17251-62, </volume> <month> Oct </month> <year> 1993. </year>
Reference-contexts: Typical examples are long running simulations of time-dependent phenomena which periodically generate snapshots of the state. The sequence of snapshots is later analyzed and/or visualized, often repeatedly, for trends and transients. Examples include Direct Simulation Monte Carlo (DSMC) [2], magneto-hydro dynamics (MHD) simulation of planetary magneto-spheres <ref> [28] </ref>, simulation of a flame sweeping through a volume [23], airplane wake simulations [18] etc. Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22].
Reference: [29] <author> R. Wilmoth. </author> <type> Personal communication, </type> <month> March </month> <year> 1995. </year> <month> 15 </month>
Reference-contexts: Volume of data generated per time-step varies from a few megabytes to a few hundred megabytes and the number of time-steps varies from tens to a few thousands [9, 22]. Frequent operations on these datasets include volume visualization (including animation), detecting transients, computing trends and averages and composition <ref> [9, 22, 29] </ref>. For data retrieval, all of these translate to requests for multidimensional subspace from the dataset, that is, to multidimensional range queries. Most such datasets are used by a small number of users and the metric of importance is response time.
References-found: 29

