URL: http://www.cs.huji.ac.il/papers/IP/rep.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Finding the Repeated Median Regression Line  
Author: Andrew Stein Michael Werman 
Address: 91904 Jerusalem Israel  
Affiliation: Department of Computer Science The Hebrew University of Jerusalem  
Abstract: The repeated median regression line is a robust regression estimate, having a maximal 50% breakdown point. This paper presents an O(n(log n) 2 ) algorithm for finding the repeated median regression line through n points in the plane.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in c log n parallel steps. </title> <journal> Combinatorica, </journal> <volume> 3(1) </volume> <pages> 1-19, </pages> <year> 1983. </year> <month> 7 </month>
Reference-contexts: Also the choice of ^u by (3) or (4) is justified in Section 3. The framework within which fl is found is the same as that used by CSSS. The control structure for the sort comes from the O (log n) depth sorting network of Ajtai, Komlos and Szemeredi <ref> [1] </ref>. At each network level, n=2 of the questions Q ij are answered. The network is just a guide for blocking these questions into groups of size n=2, which are then answered in series. <p> The other parts of the algorithm take linear time. In all O (n log n) time is needed to answer Q ij . 4 Implementation The Ajtai, Komlos and Szemeredi network <ref> [1] </ref> may have a theoretical depth of only c log n, but it is a very complicated network and the constant c is very large.
Reference: [2] <author> Richard Cole. </author> <title> Slowing down sorting networks to obtain faster sorting algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 200-208, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: The time complexity of the algorithm is reduced by a factor of O (log n) by using the Cole method <ref> [2] </ref> of weighing "active" questions at each phase, and asking the question corresponding to the weighted median of the active questions. A question is active if both its inputs have been determined, but the question has not yet been answered. <p> This network has a depth of exactly dlog ne (dlog ne + 1) =2, and is so easy to build that it may be built during the run-time of the algorithm with almost no additional cost. In addition, we did not implement the Cole method <ref> [2] </ref> of weighing active questions, but worked one level at a time. These two simplifications increase the theoretical complexity of our algorithm to O (n (log n) 4 ). The running time was improved holding two values z L and z R .
Reference: [3] <author> Richard Cole, Jeffrey S. Salowe, W. L. Steiger, and Endre Szemeredi. </author> <title> An optimal-time algorithm for slope selection. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(4) </volume> <pages> 792-810, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: This paper presents an O (n (log n) 2 ) algorithm for calculating this slope. The algorithm is based on the framework of the Cole, Salowe, Steiger and Szemeredi (henceforth CSSS) algorithm <ref> [3] </ref> for finding the kth smallest element of S = fa ij : 1 i &lt; j ng.
Reference: [4] <author> Donald E. Knuth. </author> <title> The Art of Computer Programming. Volume 3: Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: In other words, b r is the number of inversions in whose second component is r and c s is the number of inversions in whose first component is s. Therefore, b r + c r is the number of inversions involving r. Knuth <ref> [4] </ref> gives an O (n log n) algorithm for calculating b from . A simple modification of this algorithm to calculates both b and c from , also in O (n log n) time. <p> In our implementation we use the Batcher network as described by Knuth <ref> [4] </ref>. This network has a depth of exactly dlog ne (dlog ne + 1) =2, and is so easy to build that it may be built during the run-time of the algorithm with almost no additional cost.
Reference: [5] <author> Nimrod Megiddo. </author> <title> Applying parallel computation algorithms in the design of serial algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 30(4) </volume> <pages> 852-865, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: However, we can answer the n=2 questions on a level calling the sub-algorithm only O (log n) times, by applying Megiddo's technique <ref> [5] </ref> for creating sequential algorithms from parallel ones. This will lead to a O (n (log n) 3 ) algorithm.
Reference: [6] <author> Angelika Reiser. </author> <title> A linear selection algorithm for sets of elements with weights. </title> <journal> Information Processing Letters, </journal> <volume> 7(3) </volume> <pages> 159-162, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: A weight of 1=4 1 is assigned to each active question on level . At each phase the weighted median z w of the intersection points corresponding to the active questions is found in linear time using Reiser's algorithm <ref> [6] </ref>, and the question corresponding to z w is answered by the sub-algorithm.
Reference: [7] <author> Peter J. Rousseeuw. </author> <title> Least median of squares regression. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 79(388) </volume> <pages> 871-880, </pages> <month> December </month> <year> 1984. </year>
Reference-contexts: On the other hand the repeated median estimator has a maximal 50% breakdown point. The other major estimator with a 50% breakdown point is Rousseeuw's least median of squares estimator <ref> [7] </ref>, defined as the value of (a; b) minimizing med i (y i ax i b) 2 . Several algorithms exist for finding this estimate [11] [10], the fastest in O (n 2 ) operations.
Reference: [8] <author> Peter J. Rousseeuw and Annick M. Leroy. </author> <title> Robust Regression and Outlier Detection. </title> <publisher> John Wiley, </publisher> <year> 1987. </year>
Reference-contexts: In short the time complexity our algorithm compares favorably with that of its main competitor. However, it should be pointed out that in many actual computer programs, for example in the PROGRESS package <ref> [8] </ref>, a probabilistic approximation of the least median of squares estimator is found in O (n) or O (n log n) time.
Reference: [9] <author> Andrew F. Siegel. </author> <title> Robust regression using repeated medians. </title> <journal> Biometrika, </journal> <volume> 69(1) </volume> <pages> 242-244, </pages> <year> 1982. </year>
Reference-contexts: The slope of Siegel's repeated median regression line <ref> [9] </ref> is defined as ^a = med med a ij ; (1) where the innermost median is over the a ij which are defined. This paper presents an O (n (log n) 2 ) algorithm for calculating this slope.
Reference: [10] <author> Diane L. Souvaine and J. Michael Steele. </author> <title> Time- and space-efficient algorithms for least median of squares regression. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82(399) </volume> <pages> 794-801, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: The other major estimator with a 50% breakdown point is Rousseeuw's least median of squares estimator [7], defined as the value of (a; b) minimizing med i (y i ax i b) 2 . Several algorithms exist for finding this estimate [11] <ref> [10] </ref>, the fastest in O (n 2 ) operations. This algorithm is very complicated and the fastest practical algorithm has an expected time complexity of O (n 2 (log n) 2 ). In short the time complexity our algorithm compares favorably with that of its main competitor.
Reference: [11] <author> J. M. Steele and W. L. Steiger. </author> <title> Algorithms and complexity for least median of squares regression. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 14 </volume> <pages> 93-100, </pages> <year> 1986. </year> <month> 8 </month>
Reference-contexts: The other major estimator with a 50% breakdown point is Rousseeuw's least median of squares estimator [7], defined as the value of (a; b) minimizing med i (y i ax i b) 2 . Several algorithms exist for finding this estimate <ref> [11] </ref> [10], the fastest in O (n 2 ) operations. This algorithm is very complicated and the fastest practical algorithm has an expected time complexity of O (n 2 (log n) 2 ). In short the time complexity our algorithm compares favorably with that of its main competitor.
References-found: 11

