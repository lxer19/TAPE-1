URL: http://www.cs.berkeley.edu/~alanm/CP/khalidi.tr-93-17.93.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Email: email addresses: yousef.khalidi@eng.sun.com madhusudhan.talluri@eng.sun.com michael.nelson@eng.sun.com dock.williams@eng.sun.com  
Title: Virtual Memory Support for Multiple Pages  
Author: Yousef A. Khalidi Madhusudhan Talluri Michael N. Nelson Dock Williams 
Address: 2550 Garcia Avenue Mountain View, CA 94043  
Affiliation: M/S 29-01  
Date: September 1993  
Pubnum: SMLI TR-93-17  
Abstract: The advent of computers with 64-bit virtual address spaces and gigabytes of physical memory will provide applications with many more orders of magnitude of memory than is possible today. However, to tap the potential of this new hardware, we need to re-examine how virtual memory is traditionally managed. We concentrate in this note on two aspects of virtual memory: software support for multiple page sizes, and memory management policies tuned to large amounts of physical memory. We argue for the need to examine these areas, and we identify several questions that need to be answered. In particular, we show that providing support for multiple page sizes is not as straightforward as may initially appear. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Talluri, Madhusudhan, Shing Kong, Mark D. Hill, and David A. Patterson. </author> <title> Tradeoffs in Supporting Two Page Sizes. </title> <booktitle> Proceedings of the 19th Annual International Symposium on Computer Architecture (May 1992): </booktitle> <pages> 415424. </pages>
Reference-contexts: Technological and architectural trends are leading towards larger main memory sizes and programs with larger working sets, but with the TLB size remaining relatively small. For reasons stated in <ref> [1] </ref> and elsewhere, the TLB size is not expected to increase at the same rate as main memory size, yet the amount of memory mapped by the TLB is an important factor in determining performance. Therefore, there is a need to make the TLB map larger working sets. <p> The case for hardware support for multiple page sizes has been argued by others <ref> [1] </ref>, and there are now several microprocessor architectures that support multiple page Mountain View, CA 94043 USA Multiple page sizes Virtual Memory Support for Multiple Page Sizes 3 sizes, including R4000 [6], Alpha [8], and SuperSPARC [7]. <p> The second bar shows the miss ratio for a 256-entry 2-way set-associative TLB again using only 4K pages. The third bar shows the same configuration as the first bar but the software is using both 4K and 32K pages (the policy for assigning pages is described in <ref> [1] </ref>). Current microprocessor hardware is being designed assuming that the software will use the large page sizes (third bar). However, current operating systems do not support multiple page sizes and end up using only one page size although the TLB can support multiple sizes (first bar). <p> The system should probably wait until enough small pages have been populated before promoting <ref> [1] </ref> the mapping into one using a large page. 2.4.5 Interaction Between Different Mappings When using one page size only, all mappings to the same memory object are done using the same page size.
Reference: [2] <author> Rashid, R., A. Tevanian, M. Young, D. Golub, R. Baron, D. Black, W. Bolosky, and J. Chew. </author> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures. </title> <journal> IEEE Transactions on Computers 37, </journal> <volume> no. </volume> <month> 8 (August </month> <year> 1988): </year> <month> 896908. </month>
Reference-contexts: 1 Introduction Virtual memory implementations in current systems such as UNIX [5], VMS [3], NT TM [13], MACH <ref> [2] </ref>, and CHORUS [4], share two basic assumptions regarding physical memory management: There is one page size. This one size may be a multiple of the MMU page size, but there is only one size and it is typically in the range of 512-8K bytes.
Reference: [3] <author> Kenah, Lawrence J., Ruth E. Goldenberg, and Simon F. Bate. </author> <title> VAX/VMS Internals and Data Structures. </title> <publisher> Digital Press, </publisher> <year> 1988. </year>
Reference-contexts: 1 Introduction Virtual memory implementations in current systems such as UNIX [5], VMS <ref> [3] </ref>, NT TM [13], MACH [2], and CHORUS [4], share two basic assumptions regarding physical memory management: There is one page size. This one size may be a multiple of the MMU page size, but there is only one size and it is typically in the range of 512-8K bytes.
Reference: [4] <author> Abrosimov, Vadim, Marc Rozier, and Marc Shapiro. </author> <title> Generic Memory Management for Operating System Kernels. </title> <booktitle> 12th Symposium on Operating System Principles (SOSP '89) (1989): </booktitle> <pages> 123136. </pages>
Reference-contexts: 1 Introduction Virtual memory implementations in current systems such as UNIX [5], VMS [3], NT TM [13], MACH [2], and CHORUS <ref> [4] </ref>, share two basic assumptions regarding physical memory management: There is one page size. This one size may be a multiple of the MMU page size, but there is only one size and it is typically in the range of 512-8K bytes.
Reference: [5] <author> Gingell, Robert A., Joseph P. Moran, and William A. Shannon. </author> <title> Virtual Memory Architecture in SunOS. </title> <booktitle> Proceedings of Summer '87 USENIX Conference (June 1987). </booktitle>
Reference-contexts: 1 Introduction Virtual memory implementations in current systems such as UNIX <ref> [5] </ref>, VMS [3], NT TM [13], MACH [2], and CHORUS [4], share two basic assumptions regarding physical memory management: There is one page size. <p> the chip area as a set-associative TLB of the same number of entries, with access time being approximately equal. 0% 2% 4% 6% verilog mpsas nasa7 matrix300 64 fa/4K 256 2-way/4K 64 fa/4-32K Miss Ratio Multiple page sizes Virtual Memory Support for Multiple Page Sizes 4 as MACH, SunOS TM <ref> [5] </ref>, and CHORUS is not enough to mitigate the difficulties of supporting multiple page sizes. 2.4 What Needs to be Done? 2.4.1 Choosing a Page Size Current VM interfaces do not have the notion of multiple page sizes.
Reference: [6] <institution> MIPS Computer Systems. </institution> <note> MIPS R4000 Microprocessor Users Manual. </note> <year> 1991. </year>
Reference-contexts: Very large physical memory. 2 Multiple page sizes 2.1 Motivation A Translation Look-aside Buffer (TLB) is a cache of virtual-to-physical address translations, and is typically used to reduce the average address translation time. When a required translation is not in the TLB, a software (e.g., R4000 <ref> [6] </ref>) or a hardware miss handler (e.g., Super-SPARC TM [7]) is executed to enter the translation in the TLB. Technological and architectural trends are leading towards larger main memory sizes and programs with larger working sets, but with the TLB size remaining relatively small. <p> The case for hardware support for multiple page sizes has been argued by others [1], and there are now several microprocessor architectures that support multiple page Mountain View, CA 94043 USA Multiple page sizes Virtual Memory Support for Multiple Page Sizes 3 sizes, including R4000 <ref> [6] </ref>, Alpha [8], and SuperSPARC [7]. For example, the R4000 supports seven page sizes (from 4K to 16M bytes) using a 48-entry fully associative TLB. In general, there are two classes of applications that can benefit from multiple page sizes: The operating system kernel and devices such as frame buffers.
Reference: [7] <author> Blanck, G., and S. Krueger. </author> <title> The SuperSPARC Microprocessor. </title> <note> COMPCON (February 1992): 136141. </note>
Reference-contexts: When a required translation is not in the TLB, a software (e.g., R4000 [6]) or a hardware miss handler (e.g., Super-SPARC TM <ref> [7] </ref>) is executed to enter the translation in the TLB. Technological and architectural trends are leading towards larger main memory sizes and programs with larger working sets, but with the TLB size remaining relatively small. <p> The case for hardware support for multiple page sizes has been argued by others [1], and there are now several microprocessor architectures that support multiple page Mountain View, CA 94043 USA Multiple page sizes Virtual Memory Support for Multiple Page Sizes 3 sizes, including R4000 [6], Alpha [8], and SuperSPARC <ref> [7] </ref>. For example, the R4000 supports seven page sizes (from 4K to 16M bytes) using a 48-entry fully associative TLB. In general, there are two classes of applications that can benefit from multiple page sizes: The operating system kernel and devices such as frame buffers.
Reference: [8] <author> Dobberpuhl, Daniel, et al. </author> <title> A 200 MHz 64b Dual-Issue CMOS Microprocessor. </title> <booktitle> Proceedings of the 39th International Solid-State Circuits Conference (February 1992): </booktitle> <volume> 106 107. </volume>
Reference-contexts: The case for hardware support for multiple page sizes has been argued by others [1], and there are now several microprocessor architectures that support multiple page Mountain View, CA 94043 USA Multiple page sizes Virtual Memory Support for Multiple Page Sizes 3 sizes, including R4000 [6], Alpha <ref> [8] </ref>, and SuperSPARC [7]. For example, the R4000 supports seven page sizes (from 4K to 16M bytes) using a 48-entry fully associative TLB. In general, there are two classes of applications that can benefit from multiple page sizes: The operating system kernel and devices such as frame buffers.
Reference: [9] <author> Hewlett-Packard. </author> <title> PA RISC 1.1 Architecture and Instruction Set Reference Manual. </title> <year> 1990. </year>
Reference-contexts: In general, there are two classes of applications that can benefit from multiple page sizes: The operating system kernel and devices such as frame buffers. In addition to the microprocessors listed above, many other architectures have some limited support for handling these specialized cases, including the PA-Risc TM 1.1 <ref> [9] </ref> and i860 TM [10]. General applications, including multiprogrammed job mixes, and applications with large working sets such as numerical analysis code. Mapping the kernel, or specialized devices such as frame buffers using large mappings, is relatively straightforward.
Reference: [10] <author> Intel Corporation. </author> <title> Overview of the i860 XP Supercomputing Microprocessor. </title> <year> 1991. </year>
Reference-contexts: In addition to the microprocessors listed above, many other architectures have some limited support for handling these specialized cases, including the PA-Risc TM 1.1 [9] and i860 TM <ref> [10] </ref>. General applications, including multiprogrammed job mixes, and applications with large working sets such as numerical analysis code. Mapping the kernel, or specialized devices such as frame buffers using large mappings, is relatively straightforward.
Reference: [11] <author> Chen, J. Bradley, Anita Borg, and Norman P. Jouppi. </author> <title> A Simulation Based Study of TLB Performance. </title> <booktitle> Proceedings of the 19th Annual International Symposium on Computer Architecture (May 1992): </booktitle> <pages> 114123. </pages>
Reference: [12] <author> Wood, David A. and Randy H. Katz. </author> <title> Supporting Reference and Dirty Bits in SPURs Virtual Address Cache. </title> <booktitle> Proceedings of the 16th Annual International Symposium on Computer Architecture (June 1989): </booktitle> <pages> 122130. </pages>
Reference-contexts: Others have recognized the need to re-examine page replacement algorithms in large memory machines. Wood and Katz argued for getting rid of the modified bit <ref> [12] </ref>, though we do not necessarily agree with their conclusions. Harty and Cheriton [15] describe an interface exported by the VM system to external pagers that can be used to control physical memory.
Reference: [13] <author> Custer, Helen. </author> <title> Inside Windows NT. </title> <publisher> Microsoft Press, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Virtual memory implementations in current systems such as UNIX [5], VMS [3], NT TM <ref> [13] </ref>, MACH [2], and CHORUS [4], share two basic assumptions regarding physical memory management: There is one page size. This one size may be a multiple of the MMU page size, but there is only one size and it is typically in the range of 512-8K bytes.
Reference: [14] <author> Kessler, R. E., and Mark D. Hill. </author> <title> Page Placement Algorithms for Large Real-Index Caches. </title> <journal> ACM Transactions on Computer Systems 10, </journal> <volume> no. </volume> <month> 4 (November </month> <year> 1992): </year> <month> 338359. </month>
Reference-contexts: How does arranging the free lists according to size affect page-coloring <ref> [14] </ref> algorithms? Page replacement Virtual Memory Support for Multiple Page Sizes 5 2.4.4 Using Large Mappings Another question to answer is: when should the decision to use a large mapping be made? Should the system allocate and populate a large physical page on the first fault, or should it delay the
Reference: [15] <author> Harty, Kieran, and David R. Cheriton. </author> <title> Application-Controlled Physical Memory using External Page-Cache Management. </title> <booktitle> Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V) (October 1992): </booktitle> <volume> 187 197. </volume>
Reference-contexts: Others have recognized the need to re-examine page replacement algorithms in large memory machines. Wood and Katz argued for getting rid of the modified bit [12], though we do not necessarily agree with their conclusions. Harty and Cheriton <ref> [15] </ref> describe an interface exported by the VM system to external pagers that can be used to control physical memory.
Reference: [16] <author> McVoy, L. W., and S. R. Kleiman. </author> <title> Extent-like Performance from a UNIX File System. </title> <booktitle> Proceedings of Winter 1991 USENIX ( January 1991). </booktitle>
Reference-contexts: As we will show, adding support for multiple page sizes raises many new issues regarding how physical memory is managed, as well as affecting common VM and file system optimizations such as read-ahead, clustering <ref> [16] </ref>, and copy-on-write. It is important to note that supporting multiple page sizes affects both the machine dependent and independent portions of the system. That is, the clean separation of machine independent and dependent code in systems such 1.
Reference: [17] <author> Babaoglu, Ozalp, and William Joy. </author> <title> Converting a Swap-Based Sytem to do Paging in an Architecture Lacking Page-Reference Bits. </title> <booktitle> Proceedings of the 8th Symposium on Operating Systems Principles (1981): </booktitle> <pages> 7886. </pages>
Reference-contexts: This bit is either provided by the hardware or simulated in software. The reference bit is usually used by the VM system to implement page replacement algorithms such as clock <ref> [17] </ref> and Sampled Working Set [18] algorithms. Periodically, the VM system examines all pages in the system, resetting the reference bits, and updating page usage statistics. It is not clear how useful reference bits will be for very large machines.
Reference: [18] <author> Denning, Peter J. </author> <title> The Working Set Model for Program Behavior. </title> <journal> Communications of the ACM 11 (May 1968): </journal> <volume> 323333. </volume>
Reference-contexts: This bit is either provided by the hardware or simulated in software. The reference bit is usually used by the VM system to implement page replacement algorithms such as clock [17] and Sampled Working Set <ref> [18] </ref> algorithms. Periodically, the VM system examines all pages in the system, resetting the reference bits, and updating page usage statistics. It is not clear how useful reference bits will be for very large machines. <p> There is a large body of work from the sixties and seventies in the area of page replacement and paging (see <ref> [18] </ref> and [19] for references). Perhaps now it is time to reexamine the basic assumptions of prior studies in light of very large physical memory and multiple page sizes.

References-found: 18

