URL: ftp://ftp.cs.rochester.edu/pub/papers/theory/97.tr493rev.Two_heads_are_better_than_two_tapes.ps.gz
Refering-URL: http://www.cs.rochester.edu/trs/theory-trs.html
Root-URL: 
Title: Two Heads are Better than Two Tapes  
Author: Tao Jiang, Joel I. Seiferas, and Paul M. B. Vit anyi 
Date: July 26, 1995; revised January 16, 1997  
Address: van Amsterdam  
Affiliation: McMaster University University of Rochester CWI and Universiteit  
Abstract: We show that a Turing machine with two single-head one-dimensional tapes cannot recognize the set in real time, although it can do so with three tapes, two two-dimensional tapes, or one two-head tape, or in linear time with just one tape. In particular, this settles the longstanding conjecture that a two-head Turing machine can recognize more languages in real time if its heads are on the same one-dimensional tape than if they are on separate one-dimensional tapes. f x2x 0 j x 2 f0; 1g fl and x 0 is a prefix of x g
Abstract-found: 1
Intro-found: 1
Reference: [Aa74] <author> S. O. Aanderaa, </author> <title> On k-tape versus (k 1)-tape real time computation, Complexity of Computation (SIAM-AMS Proceedings 7) (R. </title> <editor> M. Karp, ed.), </editor> <publisher> American Mathematical Society, </publisher> <address> Providence, Rhode Island, </address> <year> 1974, </year> <pages> pp. 75-96. </pages>
Reference-contexts: Thus L is another example of a language with "number-of-tapes complexity" 3, rather different from the one first given by Aanderaa <ref> [Aa74, PSS81] </ref>. (For the latter, even a two-head tape, even if enhanced by instantaneous head-to- head jumps and allowed to operate probabilistically, was not enough [PSSN90].) Historically, multihead tapes were introduced in Hartmanis and Stearns' seminal paper [HS65], which outlined a linear -time 1 simulation of an h-head tape, using some <p> Tools Overlap. Part of our strategy will be to find within any computation a sufficiently long subcomputation that is sufficiently well behaved for the rest of our analysis. The behavior we seek involves limitations on repeated access to storage locations, which we call "overlap" <ref> [Aa74, PSSN90] </ref>. Our overlap lemma is purely combinatorial, and does not depend at all on the nature of our computations or the "storage locations" corresponding to their steps. Nor does it depend on the computational significance of the steps designated as "distinguished". <p> that the subsequence can include a quite fair share of a set of "distinguished positions" of our choice in the original sequence. (Without the latter guarantee, the lemma is just a simple corollary (and the essence) of any of the "overlap lemmas" formulated in the work we have already cited <ref> [Aa74, PSSN90] </ref>. The "designated positions" in our setting will be the items in the sequence that correspond to a large "matching"|a notion we define later, especially motivated by computations involving two heads.) Overlap Lemma. Consider any ffi &lt; 1 and any " &gt; 0. <p> Perhaps allowing the "back" head of the defining two-head machine also to move and store random data, JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 14 but much more slowly than the "front" head, would let us combine our arguments with those of Aanderaa <ref> [Aa74, PSS81, Pa82] </ref>. A slightly weaker possibility might be to show that two single-head tapes and a pushdown store do not suffice, and a slightly stronger one might be to show that even three single-head tapes and a pushdown store do not suffice.
Reference: [Be65] <author> J. Becvar, </author> <title> Real-time and complexity problems in automata theory, </title> <type> Kybernetika 1, </type> <month> 6 </month> <year> (1965), </year> <pages> 475-497. </pages> <note> JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 16 </note>
Reference-contexts: Sto [St70] later reduced the number of single-head tapes to just h. Noting the existence of an easy real-time simulation in the other direction, Becvar <ref> [Be65] </ref> explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. Meyer, Rosenberg, and Fischer devised the first such simulation [MRF67]; and others later reduced the number of tapes [FMR72, Be74, LS81], ultimately to just 4h 4.
Reference: [Be74] <author> V. L. Bennison, </author> <title> Saving tapes in the simulation of multihead Turing machines, </title> <journal> SIGACT News 6, </journal> <month> 2 (April, </month> <year> 1974), </year> <pages> 23-26. </pages>
Reference-contexts: Noting the existence of an easy real-time simulation in the other direction, Becvar [Be65] explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. Meyer, Rosenberg, and Fischer devised the first such simulation [MRF67]; and others later reduced the number of tapes <ref> [FMR72, Be74, LS81] </ref>, ultimately to just 4h 4. We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures [FMR72, LS81, Vi84, Pa84]. <p> The early real-time multihead simulations of buffers <ref> [MRF67, FMR72, Be74] </ref> do follow this strategy, but we show that a machine with only two tapes will not be able to afford always to use one in this way for insurance: There will have to be a significant subcomputation in which the heads on both tapes "keep moving", even "essentially
Reference: [CTPR85] <author> F. R. K. Chung, R. E. Tarjan, W. J. Paul, and R. Reischuk, </author> <title> Coding strings by pairs of strings, </title> <note> SIAM Journal on Discrete Mathematics 6, </note> <month> 3 (July, </month> <year> 1985), </year> <pages> 445-461. </pages>
Reference-contexts: And a string x is incompressible or nearly incompressible relative to y if K (xjy) is large in the appropriate sense. If, at the opposite extreme, K (xjy) is so small that jxj K (xjy) is "almost as large as" jxj, then we say that y codes x <ref> [CTPR85] </ref>. There are a few well-known facts about these notions that we will use freely, sometimes only implicitly. Proofs and elaboration, when they are not sufficiently obvious, can be found in the literature [especially LV93]. <p> 's tapes tend to serve as a very redundant representation of prefixes of x, because M has had to be prepared to retrieve them at any time. (Our problem and this observation were motivation for Chung, Tarjan, Paul, and Reischuk's investigation of "robust codings of strings by pairs of strings" <ref> [CTPR85] </ref>.) One way around this would be for M to keep one or the other of its tapes' heads stationed at some stored record of a long prefix of x, as "insurance".
Reference: [DGPR84] <author> P. Duris, Z. Galil, W. J. Paul, and R. Reischuk, </author> <title> Two nonlinear lower bounds for on-line computations, </title> <booktitle> Information and Control 60, </booktitle> <address> 1-3 (January-March, </address> <year> 1984), </year> <pages> 1-11. </pages>
Reference-contexts: This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93].
Reference: [FMR72] <author> P. C. Fischer, A. R. Meyer, and A. L. Rosenberg, </author> <title> Real-time simulation of multihead tape units, </title> <journal> Journal of the Association for Computing Machinery 19, </journal> <month> 4 (October, </month> <year> 1972), </year> <pages> 590-607. </pages>
Reference-contexts: The case of deficiency in the number of heads allowed on each tape has turned out to be the most delicate, because it involves a surprise: A larger number of single- head tapes can compensate for the absence of multihead tapes <ref> [MRF67, FMR72, LS81] </ref>. For example, four single-head tapes suffice for general simulation of a two- head tape unit, without any time loss at all [LS81]. The remaining question is just what, if anything, is the advantage of multihead tapes. <p> Our result incidentally gives us a tight bound on the number of single-head tapes needed to recognize the particular language L in real time, since three do suffice <ref> [MRF67, FMR72] </ref>. <p> Noting the existence of an easy real-time simulation in the other direction, Becvar [Be65] explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. Meyer, Rosenberg, and Fischer devised the first such simulation [MRF67]; and others later reduced the number of tapes <ref> [FMR72, Be74, LS81] </ref>, ultimately to just 4h 4. We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures [FMR72, LS81, Vi84, Pa84]. <p> We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures <ref> [FMR72, LS81, Vi84, Pa84] </ref>. <p> The early real-time multihead simulations of buffers <ref> [MRF67, FMR72, Be74] </ref> do follow this strategy, but we show that a machine with only two tapes will not be able to afford always to use one in this way for insurance: There will have to be a significant subcomputation in which the heads on both tapes "keep moving", even "essentially
Reference: [Gr77] <author> D. Yu. Grigoriev, </author> <title> Imbedding theorems for Turing machines of different dimensions and Kolmogorov's algorithms, </title> <journal> Soviet Mathematics 18, </journal> <volume> 3 (May-June, </volume> <year> 1977), </year> <pages> 588-592. </pages>
Reference: [He66] <author> F. C. Hennie, </author> <title> On-line Turing machine computations, </title> <journal> IEEE Transactions on Electronic Computers EC-15, </journal> <volume> 1 (February, </volume> <year> 1966), </year> <pages> 35-44. </pages>
Reference: [HS65] <author> J. Hartmanis and R. E. Stearns, </author> <title> On the computational complexity of algorithms, </title> <journal> Transactions of the American Mathematical Society 117, </journal> <month> 5 (May, </month> <year> 1965), </year> <pages> 285-306. </pages>
Reference-contexts: 1. Introduction The Turing machines commonly used and studied in computer science have separate tapes for input/output and for storage, so that we can conveniently study both storage as a dynamic resource and the more complex storage structures required for efficient implementation of practical algorithms <ref> [HS65] </ref>. Early researchers [MRF67] asked specifically whether two-head storage is more powerful if both heads are on the same one-dimensional storage tape than if they are on separate one-dimensional tapes, an issue of whether shared sequential storage is more powerful than separate sequential storage. <p> with "number-of-tapes complexity" 3, rather different from the one first given by Aanderaa [Aa74, PSS81]. (For the latter, even a two-head tape, even if enhanced by instantaneous head-to- head jumps and allowed to operate probabilistically, was not enough [PSSN90].) Historically, multihead tapes were introduced in Hartmanis and Stearns' seminal paper <ref> [HS65] </ref>, which outlined a linear -time 1 simulation of an h-head tape, using some larger number of ordinary single-head tapes. Sto [St70] later reduced the number of single-head tapes to just h.
Reference: [Ko65] <author> A. N. </author> <title> Kolmogorov, Three approaches to the quantitative definition of information, Problems of Information Transmission 1, </title> <address> 1 (January-March, </address> <year> 1965), </year> <pages> 1-7. </pages>
Reference-contexts: Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. We define incompressibility in terms of Kolmogorov's robust notion of descrip- tional complexity <ref> [Ko65] </ref>. Informally, the Kolmogorov complexity K (x) of a binary string x is the length of the shortest binary program (for a fixed reference universal machine) that prints x as its only output and then halts.
Reference: [LLV92] <author> M. Li, L. Longpre, and P. M. B. Vitanyi, </author> <title> The power of the queue, </title> <journal> SIAM Journal on Computing 21, </journal> <month> 4 (August, </month> <year> 1992), </year> <pages> 697-712. </pages>
Reference-contexts: This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93].
Reference: [LS81] <author> B. L. Leong and J. I. Seiferas, </author> <title> New real-time simulations of multihead tape units, </title> <journal> Journal of the Association for Computing Machinery 28, </journal> <month> 1 (January, </month> <year> 1981), </year> <pages> 166-180. </pages>
Reference-contexts: The case of deficiency in the number of heads allowed on each tape has turned out to be the most delicate, because it involves a surprise: A larger number of single- head tapes can compensate for the absence of multihead tapes <ref> [MRF67, FMR72, LS81] </ref>. For example, four single-head tapes suffice for general simulation of a two- head tape unit, without any time loss at all [LS81]. The remaining question is just what, if anything, is the advantage of multihead tapes. <p> For example, four single-head tapes suffice for general simulation of a two- head tape unit, without any time loss at all <ref> [LS81] </ref>. The remaining question is just what, if anything, is the advantage of multihead tapes. The simplest version of the question is whether a two-head tape is more powerful than two single-head tapes. In the case of "tapes" that are multidimensional , Paul has shown that it is [Pa84]. <p> Noting the existence of an easy real-time simulation in the other direction, Becvar [Be65] explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. Meyer, Rosenberg, and Fischer devised the first such simulation [MRF67]; and others later reduced the number of tapes <ref> [FMR72, Be74, LS81] </ref>, ultimately to just 4h 4. We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures [FMR72, LS81, Vi84, Pa84]. <p> We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures <ref> [FMR72, LS81, Vi84, Pa84] </ref>. <p> how does a three-head tape compare with three single-head tapes or with one single-head tape and one two-head tape? (Paul's results [Pa84] do answer such questions for tapes of higher dimension.) How tight is the known bound of 4h 4 single-head tapes for real-time simulation of one h-head (one-dimensional) tape <ref> [LS81] </ref>? Perhaps the many-heads setting is the right one for a first proof that even an extra head is not enough to compensate for the loss of sharing; e.g., can a 1000-head tape be simulated in real time by 1001 single-head tapes, or by 1000 single-head tapes and a pushdown store?
Reference: [LV88] <author> M. Li and P. M. B. Vitanyi, </author> <title> Tape versus queue and stacks: the lower bounds, </title> <booktitle> Information and Computation 78, </booktitle> <month> 1 (July, </month> <year> 1988), </year> <pages> 56-85. </pages>
Reference-contexts: This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93].
Reference: [LV93] <author> M. Li and P. M. B. Vitanyi, </author> <title> An Introduction to Kolmogorov Complexity and Its Applications, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere <ref> [PSS81, LV93] </ref>. We define incompressibility in terms of Kolmogorov's robust notion of descrip- tional complexity [Ko65].
Reference: [Ma85] <author> W. Maass, </author> <title> Combinatorial lower bound arguments for deterministic and nondetermin-istic Turing machines, </title> <journal> Transactions of the American Mathematical Society 292, </journal> <month> 2 (December, </month> <year> 1985), </year> <pages> 675-693. </pages>
Reference-contexts: This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93].
Reference: [Me71] <author> A. R. Meyer, </author> <title> An optimal time bound for a one tape on-line Turing machine compu-tation, </title> <note> unpublished manuscript (June, 1971, but earlier version already cited in 1967 [MRF67]). </note>
Reference-contexts: Like the proof of our Large-Matching Lemma above, this part is based on the "bottleneck" argument that Valiev [Va70] (and, independently, Meyer <ref> [Me71] </ref>) used to show that no single-tape Turing machine can accept the simpler language f x2x j x 2 f0; 1g fl g in real time.
Reference: [MRF67] <author> A. R. Meyer, A. L. Rosenberg, and P. C. Fischer, </author> <title> Turing machines with several readwrite heads, preliminary report, </title> <booktitle> IEEE Conference Record of 1967 Eighth Annual Symposium on Switching and Automata Theory, IEEE Computer Society, </booktitle> <address> Long Beach, California, </address> <year> 1967, </year> <pages> pp. 117-127. </pages>
Reference-contexts: 1. Introduction The Turing machines commonly used and studied in computer science have separate tapes for input/output and for storage, so that we can conveniently study both storage as a dynamic resource and the more complex storage structures required for efficient implementation of practical algorithms [HS65]. Early researchers <ref> [MRF67] </ref> asked specifically whether two-head storage is more powerful if both heads are on the same one-dimensional storage tape than if they are on separate one-dimensional tapes, an issue of whether shared sequential storage is more powerful than separate sequential storage. Our result settles the longstanding conjecture that it is. <p> The case of deficiency in the number of heads allowed on each tape has turned out to be the most delicate, because it involves a surprise: A larger number of single- head tapes can compensate for the absence of multihead tapes <ref> [MRF67, FMR72, LS81] </ref>. For example, four single-head tapes suffice for general simulation of a two- head tape unit, without any time loss at all [LS81]. The remaining question is just what, if anything, is the advantage of multihead tapes. <p> Our result incidentally gives us a tight bound on the number of single-head tapes needed to recognize the particular language L in real time, since three do suffice <ref> [MRF67, FMR72] </ref>. <p> Noting the existence of an easy real-time simulation in the other direction, Becvar [Be65] explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. Meyer, Rosenberg, and Fischer devised the first such simulation <ref> [MRF67] </ref>; and others later reduced the number of tapes [FMR72, Be74, LS81], ultimately to just 4h 4. <p> The early real-time multihead simulations of buffers <ref> [MRF67, FMR72, Be74] </ref> do follow this strategy, but we show that a machine with only two tapes will not be able to afford always to use one in this way for insurance: There will have to be a significant subcomputation in which the heads on both tapes "keep moving", even "essentially
Reference: [MSST93] <author> W. Maass, G. Schnitger, E. Szemeredi, and G. Turan, </author> <title> Two tapes versus one for off-line Turing machines, Computational Complexity 3, </title> <booktitle> 4 (1993), </booktitle> <address> 392-401.. </address>
Reference: [Pa82] <author> W. J. Paul, </author> <title> On-line simulation of k + 1 tapes by k tapes requires nonlinear time, </title> <booktitle> Information and Control 53, </booktitle> <address> 1-2 (April-May, </address> <year> 1982), </year> <pages> 1-8. </pages>
Reference-contexts: This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. <p> Perhaps allowing the "back" head of the defining two-head machine also to move and store random data, JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 14 but much more slowly than the "front" head, would let us combine our arguments with those of Aanderaa <ref> [Aa74, PSS81, Pa82] </ref>. A slightly weaker possibility might be to show that two single-head tapes and a pushdown store do not suffice, and a slightly stronger one might be to show that even three single-head tapes and a pushdown store do not suffice.
Reference: [Pa84] <author> W. J. Paul, </author> <title> On heads versus tapes, </title> <booktitle> Theoretical Computer Science 28, </booktitle> <month> 1-2 (January, </month> <year> 1984), </year> <pages> 1-12. </pages>
Reference-contexts: The remaining question is just what, if anything, is the advantage of multihead tapes. The simplest version of the question is whether a two-head tape is more powerful than two single-head tapes. In the case of "tapes" that are multidimensional , Paul has shown that it is <ref> [Pa84] </ref>. His proof involves using the two-head tape to write, and occasionally to retrieve parts of, algorithmically incompressible bit patterns. <p> We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures <ref> [FMR72, LS81, Vi84, Pa84] </ref>. <p> This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. <p> The implications for real-time simulation of one-dimensional tape units with more than two heads remain to be investigated. For example, how does a three-head tape compare with three single-head tapes or with one single-head tape and one two-head tape? (Paul's results <ref> [Pa84] </ref> do answer such questions for tapes of higher dimension.) How tight is the known bound of 4h 4 single-head tapes for real-time simulation of one h-head (one-dimensional) tape [LS81]? Perhaps the many-heads setting is the right one for a first proof that even an extra head is not enough to
Reference: [PSS81] <author> W. J. Paul, J. I. Seiferas, and J. Simon, </author> <title> An information-theoretic approach to time bounds for on-line computation, </title> <journal> Journal of Computer and System Sciences 23, </journal> <month> 2 (October, </month> <year> 1981), </year> <pages> 108-126. </pages>
Reference-contexts: Thus L is another example of a language with "number-of-tapes complexity" 3, rather different from the one first given by Aanderaa <ref> [Aa74, PSS81] </ref>. (For the latter, even a two-head tape, even if enhanced by instantaneous head-to- head jumps and allowed to operate probabilistically, was not enough [PSSN90].) Historically, multihead tapes were introduced in Hartmanis and Stearns' seminal paper [HS65], which outlined a linear -time 1 simulation of an h-head tape, using some <p> This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. <p> Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere <ref> [PSS81, LV93] </ref>. We define incompressibility in terms of Kolmogorov's robust notion of descrip- tional complexity [Ko65]. <p> Perhaps allowing the "back" head of the defining two-head machine also to move and store random data, JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 14 but much more slowly than the "front" head, would let us combine our arguments with those of Aanderaa <ref> [Aa74, PSS81, Pa82] </ref>. A slightly weaker possibility might be to show that two single-head tapes and a pushdown store do not suffice, and a slightly stronger one might be to show that even three single-head tapes and a pushdown store do not suffice.
Reference: [PSSN90] <author> R. Paturi, J. I. Seiferas, J. Simon, and R. E. Newman-Wolfe, </author> <title> Milking the Aanderaa argument, </title> <booktitle> Information and Computation 88, </booktitle> <month> 1 (September, </month> <year> 1990), </year> <pages> 88-104. </pages>
Reference-contexts: Thus L is another example of a language with "number-of-tapes complexity" 3, rather different from the one first given by Aanderaa [Aa74, PSS81]. (For the latter, even a two-head tape, even if enhanced by instantaneous head-to- head jumps and allowed to operate probabilistically, was not enough <ref> [PSSN90] </ref>.) Historically, multihead tapes were introduced in Hartmanis and Stearns' seminal paper [HS65], which outlined a linear -time 1 simulation of an h-head tape, using some larger number of ordinary single-head tapes. Sto [St70] later reduced the number of single-head tapes to just h. <p> Tools Overlap. Part of our strategy will be to find within any computation a sufficiently long subcomputation that is sufficiently well behaved for the rest of our analysis. The behavior we seek involves limitations on repeated access to storage locations, which we call "overlap" <ref> [Aa74, PSSN90] </ref>. Our overlap lemma is purely combinatorial, and does not depend at all on the nature of our computations or the "storage locations" corresponding to their steps. Nor does it depend on the computational significance of the steps designated as "distinguished". <p> that the subsequence can include a quite fair share of a set of "distinguished positions" of our choice in the original sequence. (Without the latter guarantee, the lemma is just a simple corollary (and the essence) of any of the "overlap lemmas" formulated in the work we have already cited <ref> [Aa74, PSSN90] </ref>. The "designated positions" in our setting will be the items in the sequence that correspond to a large "matching"|a notion we define later, especially motivated by computations involving two heads.) Overlap Lemma. Consider any ffi &lt; 1 and any " &gt; 0. <p> This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. <p> Our result rules out general real-time simulation of a two-head tape unit using only a pair of single-head tapes. It remains to be investigated whether the result extends to some notion of probabilistic real-time simulation <ref> [cf., PSSN90] </ref>. Another extension might rule out simulation using three single-head tapes, yielding a tight result; but this would require a more difficult witness language. Perhaps allowing the "back" head of the defining two-head machine also to move and store random data, JIANG, SEIFERAS, AND VIT ANYI, HEADS VS.
Reference: [Ra63] <author> M. O. Rabin, </author> <title> Real time computation, </title> <journal> Israel Journal of Mathematics 1, </journal> <month> 4 (December, </month> <year> 1963), </year> <pages> 203-211. </pages>
Reference: [ST89] <author> W. Schnitzlein and H.-J. Sto, </author> <title> Linear-time simulation of multihead Turing machines, </title> <booktitle> Information and Computation 81, </booktitle> <month> 3 (June, </month> <year> 1989), </year> <pages> 353-363. </pages>
Reference-contexts: In cumulative linear time, in fact, general on-line simulation of a two-head one-dimensional tape is possible using just two single-head tapes [St70]; so real time is a stronger notion of "without time loss". (There is an analogous linear- time simulation for two-dimensional tapes <ref> [ST89] </ref>, but the question is open for higher dimensions.) JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 3 and that of storage structures and simulations on the other. These are actually closely related, however, the choice being only one of emphasis.
Reference: [St70] <author> H.-J. Sto, k-Band-Simulation von k-Kopf-Turing-Maschinen, </author> <note> Computing 6, 3 (1970), 309-317. (German) </note>
Reference-contexts: Sto <ref> [St70] </ref> later reduced the number of single-head tapes to just h. Noting the existence of an easy real-time simulation in the other direction, Becvar [Be65] explicitly raised the question of real- time simulation of an h-head tape using only single-head tapes. <p> In cumulative linear time, in fact, general on-line simulation of a two-head one-dimensional tape is possible using just two single-head tapes <ref> [St70] </ref>; so real time is a stronger notion of "without time loss". (There is an analogous linear- time simulation for two-dimensional tapes [ST89], but the question is open for higher dimensions.) JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 3 and that of storage structures and simulations on the other.
Reference: [Va70] <author> M. K. Valiev, </author> <title> Certain estimates of the time of computations on Turing machines with an input, </title> <booktitle> Cybernetics 6, </booktitle> <month> 6 (June, </month> <year> 1973), </year> <note> 734-741; translated from Kibernetika 6, 6 (November-December, </note> <year> 1970), </year> <pages> 26-32. (Russian) </pages>
Reference-contexts: Like the proof of our Large-Matching Lemma above, this part is based on the "bottleneck" argument that Valiev <ref> [Va70] </ref> (and, independently, Meyer [Me71]) used to show that no single-tape Turing machine can accept the simpler language f x2x j x 2 f0; 1g fl g in real time.
Reference: [Vi84] <author> P. M. B. Vitanyi, </author> <title> On two-tape real-time computation and queues, </title> <journal> Journal of Computer and System Sciences 29, </journal> <month> 3 (December, </month> <year> 1984), </year> <pages> 303-311. </pages>
Reference-contexts: Our argument below does finally get a handle on this elusive "copying" issue, making use of a lemma formulated more than ten years ago with this goal already in mind <ref> [Vi84, Far-Out Lemma below] </ref>. <p> We are the first to show that this number cannot always be reduced to just h, although both the extra power of multihead tapes and the more-than-two-tape complexity of the particular language L have been longstanding conjectures <ref> [FMR72, LS81, Vi84, Pa84] </ref>. <p> This is impossible, so we must find the desired low-overlap sequence at one of these levels. fl Kolmogorov Complexity. A key to the tractability of our arguments (and most of the recent ones we have cited <ref> [Pa82, Pa84, PSS81, DGPR84, Ma85, LV88, LLV92, PSSN90, Vi84] </ref>) is the use of "incompressible data". Input strings that involve such data tend to be the hardest and least subject to special handling. This general approach is discussed in more detail elsewhere [PSS81, LV93]. <p> Proof of Large-Matching Lemma Our proof of the Large-Matching Lemma is based on an earlier theorem of Vitanyi: Far-Out Lemma <ref> [Vi84] </ref> 6 . If a two-tape Turing machine recognizes f x2x 0 j x 2 f0; 1g fl and x 0 is a prefix of x g in real time, then its "worst-case closest head position" 7 on incompressible inputs x 2 f0; 1g n is (n).
Reference: [ZL70] <author> A. K. Zvonkin and L. A. Levin, </author> <title> The complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms, </title> <journal> Russian Mathematical Surveys 25, </journal> <volume> 6 (November-December, </volume> <year> 1970), </year> <pages> 83-124. </pages> <institution> Department of Computer Science, McMaster University, Hamilton, Ontario L8S 4K1, Canada JIANG, SEIFERAS, AND VIT ANYI, HEADS VS. TAPES 17 E-mail address: jiang@maccs.mcmaster.ca Computer Science Department, University of Rochester, Rochester, </institution> <address> New York 14627-0226, </address> <publisher> U. </publisher> <editor> S. A. </editor> <title> E-mail address: </title> <institution> joel@cs.rochester.edu Centre for Mathematics and Computer Science (CWI), </institution> <address> Kruislaan 413, 1098 SJ Amsterdam, The Netherlands E-mail address: paulv@cwi.nl </address>
Reference-contexts: Another easy one is that significantly long substrings of an incompressible string are themselves nearly incompressible, even relative to the rest of the string. More striking is Kolmogorov and Levin's "symmetry of information" <ref> [ZL70] </ref>: K (x) K (xjy) is very nearly equal to K (y) K (yjx) (up to an additive term that is logarithmic in the Kolmogorov complexity of the binary encoding of the pair (x; y)); i.e., y is always approximately as helpful in describing x as vice versa! (Admittedly, the word
References-found: 28

