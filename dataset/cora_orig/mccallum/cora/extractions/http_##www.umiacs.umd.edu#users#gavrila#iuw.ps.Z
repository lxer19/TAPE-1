URL: http://www.umiacs.umd.edu/users/gavrila/iuw.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/lsd/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fgavrila,lsdg@cfar.umd.edu  
Title: Tracking of humans in action: a 3-D model-based approach  
Author: D.M. Gavrila and L.S. Davis 
Web: http://www.umiacs.umd.edu/users/fgavrila,lsdg/  
Address: College Park, MD 20742, U.S.A.  
Affiliation: Computer Vision Laboratory, CfAR, University of Maryland  
Date: Feb. 1996  
Note: ARPA Image Understanding Workshop, Palm Springs,  
Abstract: We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-In-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. The four image streams are synchronized. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango. 
Abstract-found: 1
Intro-found: 1
Reference: [Badler et al., 1993] <author> N.I. Badler, C.B. Phillips, and B.L. Webber, </author> <title> "Simulating Humans," </title> <publisher> Oxford University Press, Oxford, </publisher> <address> UK, </address> <year> 1993. </year>
Reference-contexts: There is a trade-off between the accuracy of representation and the number of parameters used in the model. Many highly accurate surface models have been used in the field of graphics <ref> [Badler et al., 1993] </ref> to model the human body, often containing thousands of polygons obtained from actual body scans. <p> See <ref> [Badler et al., 1993] </ref> for more sophisticated modeling. Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [Hogg, 1983] [Downton and Drouet, 1992] [Rohr, 1994] would not represent body parts such as the head and torso accurately enough.
Reference: [Barrow, 1977] <author> H.G. Barrow et al., </author> <title> "Parametric Correspondence and Chamfer Matching: Two New Techniques For Image Matching," </title> <booktitle> Proc. IJCAI, vol.2, </booktitle> <address> pp.659-663, </address> <year> 1977. </year>
Reference-contexts: Similarity measure In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in [Rohr, 1994], for example); we use a robust variant of chamfer matching <ref> [Barrow, 1977] </ref>. <p> The resulting distance map is the so-called "chamfer image" (see Figures 6b and 6c). It would be efficient if we could use only DD (M; S) during pose search (as done in <ref> [Barrow, 1977] </ref>), where M and S are the projected model edges and scene edges, respectively. In that case, the scene chamfer image would have to be computed only once, followed by fast access for different model projections.
Reference: [Darrell and Pentland, 1993] <author> T. Darrell and A. Pent-land, </author> <title> "Space-Time Gestures," Looking at people, </title> <booktitle> Proc. IJCAI, </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [Goddard, 1994] [Guo et al., 1994] [Leung and Yang, 1995] or not [Polana and Nelson, 1994] <ref> [Darrell and Pentland, 1993] </ref>. Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns.
Reference: [Downton and Drouet, 1992] <author> A.C. Downton and H. Drouet, </author> <title> "Model-Based Image Analysis for Unconstrained Upper-Body Motion," </title> <booktitle> Proc. Int. IEE Conference on Image Processing and its Applications, </booktitle> <pages> pp. 274-277, </pages> <year> 1992. </year>
Reference-contexts: See [Badler et al., 1993] for more sophisticated modeling. Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [Hogg, 1983] <ref> [Downton and Drouet, 1992] </ref> [Rohr, 1994] would not represent body parts such as the head and torso accurately enough. Therefore, we employ the class of tapered super-quadrics [Metaxas and Terzopoulos, 1993]; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. <p> systems which work on real images using this strategy have had limitations: [Perales and Torres, 1994] describe a system which involves input from a human operator. [Hogg, 1983] and [Rohr, 1994] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional. <ref> [Downton and Drouet, 1992] </ref> attempt to track unconstrained upper-body motion, but must conclude that the tracking gets lost due to propagation of errors. [Goncalves et al., 1995] use a Kalman-filtering approach to track arm movement from single-view images where the shoulder remains fixed.
Reference: [Gavrila and Davis, 1995] <author> D. M. Gavrila and L.S. Davis, </author> <title> "Towards 3-D Model-based Tracking and Recognition of Human Movement," </title> <booktitle> Proc. Int. Workshop on Face and Gesture Recognition, </booktitle> <address> Zurich, Switzerland, </address> <year> 1995. </year>
Reference-contexts: The aim of the first component is to reconstruct from the sequence of multi-view frames the (approximate) 3-D body pose of the human (s) at each time instant; this serves as input to the movement recognition component. In an earlier paper <ref> [Gavrila and Davis, 1995] </ref> we considered movement recognition as a classification problem and we used a Dynamic Time Warping method to match a test sequence with several reference sequences representing prototypical activities. The features used for matching were various 3-D joint angles of the human body.
Reference: [Goddard, 1994] <author> N. Goddard, </author> <title> "Incremental Model-Based Discrimination of Articulated Movement Direct from Motion Features," </title> <booktitle> IEEE Workshop on Motion of Non-Rigid and Articulated Objects, </booktitle> <address> Austin, TX, </address> <year> 1994. </year>
Reference-contexts: An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model <ref> [Goddard, 1994] </ref> [Guo et al., 1994] [Leung and Yang, 1995] or not [Polana and Nelson, 1994] [Darrell and Pentland, 1993]. Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns.
Reference: [Goncalves et al., 1995] <author> L. Goncalves et al., </author> <title> "Monocular Tracking of the Human Arm in 3D," </title> <booktitle> Proc. </booktitle> <address> ICCV, pp.764-770, </address> <year> 1995. </year>
Reference-contexts: a human operator. [Hogg, 1983] and [Rohr, 1994] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional. [Downton and Drouet, 1992] attempt to track unconstrained upper-body motion, but must conclude that the tracking gets lost due to propagation of errors. <ref> [Goncalves et al., 1995] </ref> use a Kalman-filtering approach to track arm movement from single-view images where the shoulder remains fixed. Finally, [Rehg and Kanade, 1995] is geared towards finger tracking. We aim to improve the previous approaches, where applicable, along the following lines. <p> We note that other measures could (and) have been used to evaluate a hypothesized model pose, which work directly on the scene image: correlation (see [Rehg and Kanade, 1995] and <ref> [Goncalves et al., 1995] </ref>) and average contrast value along the model edges (a measure commonly used in the snake literature).
Reference: [Guo et al., 1994] <author> Y. Guo, G. Xu and S. Tsuji, </author> <title> "Understanding Human Motion Patterns," </title> <booktitle> Proc. </booktitle> <address> ICPR, </address> <year> 1994. </year>
Reference-contexts: An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [Goddard, 1994] <ref> [Guo et al., 1994] </ref> [Leung and Yang, 1995] or not [Polana and Nelson, 1994] [Darrell and Pentland, 1993]. Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns.
Reference: [Hogg, 1983] <author> D. Hogg, </author> <title> "Model Based Vision: A Program to See a Walking Person," Image and Vision Computing, </title> <type> vol.1, </type> <institution> nr.1, pp.5-20, </institution> <year> 1983. </year>
Reference-contexts: See [Badler et al., 1993] for more sophisticated modeling. Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) <ref> [Hogg, 1983] </ref> [Downton and Drouet, 1992] [Rohr, 1994] would not represent body parts such as the head and torso accurately enough. Therefore, we employ the class of tapered super-quadrics [Metaxas and Terzopoulos, 1993]; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. <p> So far, existing systems which work on real images using this strategy have had limitations: [Perales and Torres, 1994] describe a system which involves input from a human operator. <ref> [Hogg, 1983] </ref> and [Rohr, 1994] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional. [Downton and Drouet, 1992] attempt to track unconstrained upper-body motion, but must conclude that the tracking gets lost due to propagation of errors. [Goncalves et al., 1995]
Reference: [Jolliffe, 1986] <author> I.T. Jolliffe, </author> <title> Principal Component Analysis, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: The determination of the major axis can be achieved robustly by iteratively applying a principal component analysis (PCA) <ref> [Jolliffe, 1986] </ref> on data points sampled from the region of interest. At each iteration the "best" major axis is computed using PCA and the distribution of the distances from data points to this axis is computed.
Reference: [Kakadiaris and Metaxas, 1995] <author> I. Kakadiaris and D. Metaxas, </author> <title> "3D Human Body Model Acquisition from Multiple Views," </title> <booktitle> Proc. </booktitle> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: This involves the human subject facing the camera frontally and sideways. We assume 2-D segmentation in the two orthogonal views; a way to obtain such a segmentation is proposed in <ref> [Kakadiaris and Metaxas, 1995] </ref>. Back-projecting the 2-D projected contours of a quadric gives the 3-D occluding contours, after which a coarse-to-fine search procedure is used over a reasonable range of parameter space to determine the best-fitting quadric.
Reference: [Leung and Yang, 1995] <author> M.K. Leung and Y.H. Yang, </author> <title> "First Sight: A Human Body Outline Labeling System," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, vol.17, no.4, </journal> <volume> pp.359-377, </volume> <year> 1995. </year>
Reference-contexts: An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [Goddard, 1994] [Guo et al., 1994] <ref> [Leung and Yang, 1995] </ref> or not [Polana and Nelson, 1994] [Darrell and Pentland, 1993]. Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns. <p> Self-occlusion makes the 2-D tracking problem hard for arbitrary movements and thus existing systems assume some a-priori knowledge of the type of movement and/or the viewpoint under which it is observed. 2-D labeling and tracking under more general conditions is attempted by <ref> [Leung and Yang, 1995] </ref>. We therefore investigate in this paper the more general-purpose approach of recovering 3-D pose through time, in terms of 3-D joint angles defined with respect to a human-centered [Marr and Nishi-hara, 1978] coordinate system. 3-D motion recovery from 2-D images is often an ill-posed problem.
Reference: [Marr and Nishihara, 1978] <author> D.Marr and H.K. Nishi-hara, </author> <title> "Representation and Recognition of the Spatial Organization of Three Dimensional Shapes," </title> <journal> Proc. Royal Soc. London B, vol.200, </journal> <volume> pp.269-294, </volume> <year> 1978. </year>
Reference: [Metaxas and Terzopoulos, 1993] <author> D. Metaxas and D. Terzopoulos, </author> <title> "Shape and Nonrigid Motion Estimation through Physics-Based Synthesis," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, vol.15, no.6, </journal> <volume> pp.580-591, </volume> <year> 1993. </year>
Reference-contexts: Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [Hogg, 1983] [Downton and Drouet, 1992] [Rohr, 1994] would not represent body parts such as the head and torso accurately enough. Therefore, we employ the class of tapered super-quadrics <ref> [Metaxas and Terzopoulos, 1993] </ref>; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. So far, we have obtained satisfactory modeling results with these primitives alone (see experiments); a more general approach also allows deformations of the shape primitives [Pentland, 1990] [Metaxas and Terzopoulos, 1993]. <p> Therefore, we employ the class of tapered super-quadrics <ref> [Metaxas and Terzopoulos, 1993] </ref>; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. So far, we have obtained satisfactory modeling results with these primitives alone (see experiments); a more general approach also allows deformations of the shape primitives [Pentland, 1990] [Metaxas and Terzopoulos, 1993]. We derive the shape parameters from the projections of occluding contours in two orthogonal views, parallel to the zx- and zy-planes. This involves the human subject facing the camera frontally and sideways.
Reference: [Ohya and Kishino, 1994] <author> J. Ohya and F. Kishino, </author> <title> "Human Posture Estimation from Multiple Images Using Genetic Algorithm," </title> <booktitle> Proc. </booktitle> <address> ICPR, </address> <year> 1994. </year>
Reference-contexts: We synthesize appearances of the human model for all the available views, and evaluate the appropriateness of a 3-D pose based on the similarity measures for the individual views (see Figure 1b). Search Search techniques are used to prune the high dimensional pose parameter space (see also <ref> [Ohya and Kishino, 1994] </ref>). We currently use best-first search; we do this because a reasonable initial state can be provided by a prediction component during tracking or by a bootstrapping method at start-up.
Reference: [Pentland, 1990] <author> A. Pentland, </author> <title> "Automatic Extraction of Deformable Models," </title> <journal> Int. J. Computer Vision, vol.4, </journal> <volume> pp.107-126, </volume> <year> 1990. </year>
Reference-contexts: Therefore, we employ the class of tapered super-quadrics [Metaxas and Terzopoulos, 1993]; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. So far, we have obtained satisfactory modeling results with these primitives alone (see experiments); a more general approach also allows deformations of the shape primitives <ref> [Pentland, 1990] </ref> [Metaxas and Terzopoulos, 1993]. We derive the shape parameters from the projections of occluding contours in two orthogonal views, parallel to the zx- and zy-planes. This involves the human subject facing the camera frontally and sideways.
Reference: [Perales and Torres, 1994] <author> F.J. Perales and J. Tor-res, </author> <title> "A System for Human Motion Matching between Synthetic and Real Images Based on a Biomechanic Graphical Model," </title> <booktitle> IEEE Workshop on Motion of Non-Rigid and Articulated Objects, </booktitle> <address> Austin, TX, </address> <year> 1994. </year>
Reference-contexts: This approach has the advantage that the measure of similarity between synthesized appearance and actual appearance can now be based on whole contours and/or regions rather than on a few points. So far, existing systems which work on real images using this strategy have had limitations: <ref> [Perales and Torres, 1994] </ref> describe a system which involves input from a human operator. [Hogg, 1983] and [Rohr, 1994] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional. [Downton and Drouet, 1992] attempt to track unconstrained upper-body motion, but must conclude
Reference: [Polana and Nelson, 1994] <author> R. Polana and R. Nelson, </author> <title> "Low Level Recognition of Human Motion," </title> <booktitle> IEEE Workshop on Motion of Non-Rigid and Articulated Objects, </booktitle> <address> Austin, TX, </address> <year> 1994. </year>
Reference-contexts: An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [Goddard, 1994] [Guo et al., 1994] [Leung and Yang, 1995] or not <ref> [Polana and Nelson, 1994] </ref> [Darrell and Pentland, 1993]. Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns. <p> Recognition systems using 2-D model-free features have been able to claim early successes in matching human movement patterns. For constrained types of human movement (such as walking parallel to the image plane, involving periodic motion), many of these features have been successfully used for classification, as in <ref> [Polana and Nelson, 1994] </ref>. This may indeed be the easiest and best solution for several applications.
Reference: [Rehg and Kanade, 1995] <author> J. Rehg and T. Kanade, </author> <title> "Model-Based Tracking of Self-Occluding Articulated Objects," </title> <booktitle> Proc. </booktitle> <address> ICCV, pp.612-617, </address> <year> 1995. </year>
Reference-contexts: Finally, <ref> [Rehg and Kanade, 1995] </ref> is geared towards finger tracking. We aim to improve the previous approaches, where applicable, along the following lines. <p> We note that other measures could (and) have been used to evaluate a hypothesized model pose, which work directly on the scene image: correlation (see <ref> [Rehg and Kanade, 1995] </ref> and [Goncalves et al., 1995]) and average contrast value along the model edges (a measure commonly used in the snake literature).
Reference: [Rohr, 1994] <author> K. Rohr, </author> <title> "Towards Model-Based Recognition of Human Movements in Image Sequences," CVGIP: Image Understanding, </title> <address> Vol.59, No.1, pp.94-115, </address> <year> 1994. </year>
Reference-contexts: See [Badler et al., 1993] for more sophisticated modeling. Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [Hogg, 1983] [Downton and Drouet, 1992] <ref> [Rohr, 1994] </ref> would not represent body parts such as the head and torso accurately enough. Therefore, we employ the class of tapered super-quadrics [Metaxas and Terzopoulos, 1993]; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles. <p> So far, existing systems which work on real images using this strategy have had limitations: [Perales and Torres, 1994] describe a system which involves input from a human operator. [Hogg, 1983] and <ref> [Rohr, 1994] </ref> deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional. [Downton and Drouet, 1992] attempt to track unconstrained upper-body motion, but must conclude that the tracking gets lost due to propagation of errors. [Goncalves et al., 1995] use a Kalman-filtering <p> We aim to improve the previous approaches, where applicable, along the following lines. Similarity measure In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in <ref> [Rohr, 1994] </ref>, for example); we use a robust variant of chamfer matching [Barrow, 1977].
Reference: [O'Rourke and Badler, 1994] <author> J. O'Rourke and N.I. Badler, </author> <title> "Model-based image analysis of human motion using constraint propagation," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, vol.2, </journal> <volume> pp.522-536, </volume> <year> 1980. </year>
Reference-contexts: These models are used in the tracking experiments of Section 5. 4 Pose recovery and tracking The general framework for our tracking component is adapted from the early work of <ref> [O'Rourke and Badler, 1994] </ref> and is illustrated in Figure 1a. Four main components are involved: prediction, synthesis, image analysis and state estimation. The prediction component takes into account previous states up to time t to make a prediction for time t + 1.
Reference: [Szeliski and Kang, 1994] <author> R. Szeliski and S.B. Kang, </author> <title> "Recovering 3D Shape and Motion from Image Streams Using Nonlinear Least Squares," J. Visual Communication and Image Reprentation, </title> <address> vol.5, no.1, pp.10-28, </address> <year> 1994. </year>
Reference-contexts: A subset of this data was digitized (properly aligned by its time code (TC)) and makes up the HIA database, which cur rently contains more than 2500 frames in each of the four views. The cameras were calibrated using an iterative, non-linear least squares method described in <ref> [Szeliski and Kang, 1994] </ref> and kindly made available to us. shown in the RIGHT, BACK and LEFT views correspond to the selected points in the FRONT view. One can see that corresponding points lie very close to or on top of the epipolar lines.

References-found: 22

