URL: http://www.cs.cmu.edu/~fgcozman/Research/QuasiBayesian/LearningCredalSets/TechReport97/index.ps
Refering-URL: http://www.cs.cmu.edu/~fgcozman/Research/QuasiBayesian/LearningCredalSets/TechReport97/index.html
Root-URL: http://www.cs.cmu.edu
Email: e-mail: fgcozman@cs.cmu.edu, chrisman@lumina.com  
Title: Learning Convex Sets of Probability from Data  
Author: Fabio Cozman Lonnie Chrisman CMU-RI-TR - 
Note: This research is supported in part by NASA under Grant NAGW-1175. Fabio Cozman was supported under a scholarship from CNPq, Brazil.  
Date: June 20, 1997  
Address: Pittsburgh, PA 15213  
Affiliation: The Robotics Institute Carnegie Mellon University  
Abstract: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of (subjective) belief. This paper investigates a frequentist connection between empirical data and convex sets of probability distributions. Building on earlier work by Walley and Fine, a framework is advanced in which a sequence of random outcomes can be described as being drawn from a convex set of distributions, rather than just from a single distribution. The extra generality can be detected from observable characteristics of the outcome sequence. The paper presents new asymptotic convergence results paralleling the laws of large numbers in probability theory, and concludes with a comparison between this approach and approaches based on prior subjective constraints. c fl1997 Carnegie Mellon University
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. O. Berger. </author> <title> Robust bayesian analysis: Sensitivity to the prior. </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> 25 </volume> <pages> 303-328, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction This paper investigates the possibility of learning convex sets of probability distributions from data. Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics <ref> [1, 10] </ref>, in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty [2, 4, 5, 6, 9, 15, 21, 23, 25]. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic.
Reference: [2] <author> J. Cano, M. Delgado, and S. Moral. </author> <title> An axiomatic framework for propagating uncertainty in directed acyclic networks. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 8 </volume> <pages> 253-280, </pages> <year> 1993. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies.
Reference: [3] <author> L. Chrisman. </author> <title> Independence with lower and upper probabilities. </title> <booktitle> Proc. Twelfth Conference Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 169-177, </pages> <year> 1996. </year>
Reference-contexts: However, due to lack of time or other factors, the assessments are to be completed without elaborating a full detailed model of the interactions or correlations between the variables. This interpretation of convex sets of probability is referred to the ontological interpretation in previous research <ref> [3, 27] </ref>. As 5 actual values for the variables become observed, it is as if the values have been drawn from the perfectly calibrated subjectivist's belief set.
Reference: [4] <author> L. Chrisman. </author> <title> Propagation of 2-monotone lower probabilities on an undirected graph. </title> <booktitle> Proc. Twelfth Conference Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 178-186, </pages> <year> 1996. </year> <month> 16 </month>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies.
Reference: [5] <author> T. L. </author> <title> Fine. Lower probability models for uncertainty and nondeterministic processes. </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> 20 </volume> <pages> 389-411, </pages> <year> 1988. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies. <p> It has been argued that the actual physical behavior of atomic clocks exhibits a similar type of non-stationarity that is most faithfully modeled by these assumptions <ref> [12, 8, 5] </ref>. Rather than view "nature" as actually drawing samples according to credal sets, the subjectivist may view the data generation somewhat differently. There are variables whose outcomes are to be assessed prior to observing the actual outcomes.
Reference: [6] <author> F. J. Giron and S. Rios. </author> <title> Quasi-bayesian behaviour: A more realistic approach to decision making? In J. </title> <editor> M. Bernardo, J. H. DeGroot, D. V. Lindley, and A. F. M. Smith, editors, </editor> <booktitle> Bayesian Statistics, </booktitle> <pages> pages 17-38. </pages> <publisher> University Press, </publisher> <address> Valencia, Spain, </address> <year> 1980. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies. <p> In a sequence of coin flips, the first, third, fifth, and successive odd flips land heads with probability 0.6, while on the second, fourth, sixth, and successive even flips land heads with probability 0.4. 3 In this case, "nature" is choosing the bias of the coin from the probability interval <ref> [0:4; 0; 6] </ref> in a deterministic fashion. An estimation task would be to recover this interval from the infinite series of flips. Example 2 Consider a slightly different sequence of coin flips. Suppose "nature" chooses each distribution for each trial independently from a uniform distribution ranging from 0:4 to 0:6.
Reference: [7] <author> I. J. </author> <title> Good. Good Thinking: The Foundations of Probability and its Applications. </title> <publisher> University of Minnesota Press, </publisher> <address> Minneapolis, </address> <year> 1983. </year>
Reference-contexts: 1 Introduction This paper investigates the possibility of learning convex sets of probability distributions from data. Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs <ref> [7, 20, 24] </ref>, as more flexible and general measures of uncertainty [2, 4, 5, 6, 9, 15, 21, 23, 25]. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic.
Reference: [8] <author> Grize. </author> <title> Towards a Stationary Continuous Lower Probability Based Model for Flicker Noise. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <year> 1984. </year>
Reference-contexts: It has been argued that the actual physical behavior of atomic clocks exhibits a similar type of non-stationarity that is most faithfully modeled by these assumptions <ref> [12, 8, 5] </ref>. Rather than view "nature" as actually drawing samples according to credal sets, the subjectivist may view the data generation somewhat differently. There are variables whose outcomes are to be assessed prior to observing the actual outcomes.
Reference: [9] <author> J. Y. Halpern and R. Fagin. </author> <title> Two views of belief: Belief as generalized probability and belief as evidence. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 275-317, </pages> <year> 1992. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies.
Reference: [10] <author> P. J. Huber. </author> <title> Robust Statistics. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: 1 Introduction This paper investigates the possibility of learning convex sets of probability distributions from data. Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics <ref> [1, 10] </ref>, in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty [2, 4, 5, 6, 9, 15, 21, 23, 25]. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic.
Reference: [11] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 2. </volume> <publisher> Addison-Wesley Pub. Co., </publisher> <address> Reading, Mass., </address> <year> 1973. </year>
Reference-contexts: The definition of a sub-sequence generator that complies with such requirements can be taken from the theory of random numbers, where selection rules are studied to great length. We adopt the definitions of computable selection rules given by Knuth <ref> [11] </ref> to indicate which entities we consider. We assume that sub-sequences are defined such that there are infinitely many elements in each sub-sequence for an infinitely long original sequence.
Reference: [12] <author> Kumar and Fine. </author> <title> Stationary lower probabilities and unstable averages. </title> <journal> Z. Wahrsh. verw Gebiete, </journal> <volume> 69 </volume> <pages> 1-17, </pages> <year> 1984. </year>
Reference-contexts: It has been argued that the actual physical behavior of atomic clocks exhibits a similar type of non-stationarity that is most faithfully modeled by these assumptions <ref> [12, 8, 5] </ref>. Rather than view "nature" as actually drawing samples according to credal sets, the subjectivist may view the data generation somewhat differently. There are variables whose outcomes are to be assessed prior to observing the actual outcomes.
Reference: [13] <author> H. E. Kyburg Jr. </author> <title> The Logical Foundations of Statistical Inference. </title> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: The lack of a similar connection to observable physical outcomes for credal sets is a troublesome deficiency for most existing theories. Only a few works have attempted to make such connections, most notably the work of Kyburg <ref> [13, 14] </ref>, which proposes specific guidelines to transform finite data knowledge into intervals of probabilities; the work of Seidenfeld and Schervish [22] on the convergence properties of beliefs in a group of agents; and the work of Walley and Fine [27] on estimators for sets of distributions.
Reference: [14] <author> H. E. Kyburg Jr. </author> <title> Higher order probabilities and intervals. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 2 </volume> <pages> 195-209, </pages> <year> 1988. </year>
Reference-contexts: The lack of a similar connection to observable physical outcomes for credal sets is a troublesome deficiency for most existing theories. Only a few works have attempted to make such connections, most notably the work of Kyburg <ref> [13, 14] </ref>, which proposes specific guidelines to transform finite data knowledge into intervals of probabilities; the work of Seidenfeld and Schervish [22] on the convergence properties of beliefs in a group of agents; and the work of Walley and Fine [27] on estimators for sets of distributions.
Reference: [15] <author> I. Levi. </author> <title> The Enterprise of Knowledge. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1980. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies. <p> The set of distributions maintained by an agent is called the credal set <ref> [15] </ref>. To simplify terminology, we use the term credal set only when it refers to a set of distributions containing more than one element. Convex sets of conditional distributions are used to represent conditional beliefs. <p> define an expected utility interval for every utility function u (): E [u] = inf E p [u] E [u] = sup E p [u] Since utility functions induce expected utility intervals, it may be the case that decisions are incomparable (the ordering of possible decisions is a partial order) <ref> [15] </ref>. The upper envelopes and expectations can be obtained from the lower envelopes and expectations respectively. We have p (A) = 1 p (A c ) and E [u] = E [u] for any event A and utility u ().
Reference: [16] <author> M. G. Morgan and M. Henrion. </author> <title> Uncertainty: A Guide to Dealing with Uncertainty in Quantitative Risk and Policy Analysis. </title> <address> Cambridge, New York, </address> <year> 1990. </year>
Reference-contexts: The fact that probabilities can be directly related to observed frequencies gives probability a significant advantage over other subjective representations of belief. For example, as a result of this relationship, decision analysts are often able to measure the calibration of an expert's subjective assessments <ref> [16] </ref>. The lack of a similar connection to observable physical outcomes for credal sets is a troublesome deficiency for most existing theories.
Reference: [17] <author> A. Papamarcou and T. </author> <title> Fine. Unstable collectives and envelopes of probability measures. </title> <journal> Annals of Probability, </journal> <volume> 19(2) </volume> <pages> 893-906, </pages> <year> 1991. </year>
Reference-contexts: One may interpret the credal set as the most basic model of uncertainty and the selected distributions just as an explanatory device. A different interpretation is that there is a single distribution regulating the data, and this distribution is contained in the credal set <ref> [17] </ref>. Then our assumptions can be framed as a relaxation of the usual i.i.d. assumption for point probability. In this interpretation, while the trials are independent given the trial distributions, the underlying trial distribution would not have identically distributed marginals, and these marginals would need not be mutually independent.
Reference: [18] <author> K. R. </author> <title> Popper. The logic of scientific discovery. </title> <publisher> Harper, </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: Walley and Fine give estimators that capture this limiting frequency with asymptotic certainty. Popper <ref> [18, Section 63-66] </ref> calls these limiting frequencies "middle frequencies", and points out that sequences may have multiple middle frequencies. Note that example 3 involves exactly this type of construction. Walley and Fine emphasize estimation with this type of sequence.
Reference: [19] <author> M. Ramoni and P. Sebastiani. </author> <title> Robust learning with missing data. </title> <type> Technical Report KMI-TR-28, </type> <institution> Knowledge Media Institute, The Open University, </institution> <month> July </month> <year> 1996. </year> <month> 17 </month>
Reference-contexts: The standard Bayesian assumption is that missing data happens at random; if this assumption is violated, inferences may be biased. Ramoni and Sebastiani propose to lift the "missing at random assumption" <ref> [19] </ref> in a Bayesian network learning scenario. They consider all possible ways in which missing data could have happened, and create a convex set of joint distributions that represent the gamut of possibilities for the data actually collected.
Reference: [20] <author> E. H. Ruspini. </author> <title> The logical foundations of evidential reasoning. </title> <type> Technical Report SRIN408, </type> <institution> SRI International, </institution> <year> 1987. </year>
Reference-contexts: 1 Introduction This paper investigates the possibility of learning convex sets of probability distributions from data. Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs <ref> [7, 20, 24] </ref>, as more flexible and general measures of uncertainty [2, 4, 5, 6, 9, 15, 21, 23, 25]. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic.
Reference: [21] <author> T. Seidenfeld. </author> <title> Outline of a theory of partially ordered preferences. </title> <booktitle> Philosophical Topics, </booktitle> <volume> 21(1) </volume> <pages> 173-188, </pages> <month> Spring </month> <year> 1993. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies.
Reference: [22] <author> T. Seidenfeld and M. Schervish. </author> <title> Two perspectives on consensus for (bayesian) inference and decisions. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 20(1), </volume> <year> 1990. </year>
Reference-contexts: Only a few works have attempted to make such connections, most notably the work of Kyburg [13, 14], which proposes specific guidelines to transform finite data knowledge into intervals of probabilities; the work of Seidenfeld and Schervish <ref> [22] </ref> on the convergence properties of beliefs in a group of agents; and the work of Walley and Fine [27] on estimators for sets of distributions.
Reference: [23] <author> C. A. B. Smith. </author> <title> Consistency in statistical inference and decision. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 23 </volume> <pages> 1-25, </pages> <year> 1961. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies.
Reference: [24] <author> P. Suppes. </author> <title> The measurement of belief. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 2 </volume> <pages> 160-191, </pages> <year> 1974. </year>
Reference-contexts: 1 Introduction This paper investigates the possibility of learning convex sets of probability distributions from data. Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs <ref> [7, 20, 24] </ref>, as more flexible and general measures of uncertainty [2, 4, 5, 6, 9, 15, 21, 23, 25]. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic.
Reference: [25] <author> P. Walley. </author> <title> Statistical Reasoning with Imprecise Probabilities. </title> <publisher> Chapman and Hall, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Several theories of inference and decision employ sets of probability distributions as the fundamental representation of beliefs: in robust Statistics [1, 10], in relation to inner/outer measures for representation of subjective beliefs [7, 20, 24], as more flexible and general measures of uncertainty <ref> [2, 4, 5, 6, 9, 15, 21, 23, 25] </ref>. Usually such sets of distributions represent subjective opinions and preferences, and the indeterminacy of beliefs is epistemic. Frequentist models depart from subjective interpretations and relate probability to observable phenomena, whereby an underlying probability reveals itself by way of asymptotic relative frequencies. <p> Convex sets of distributions are interesting for several reasons, ranging from mathematical elegance to practical considerations of robustness (for an extensive discussion of this topic, consult Walley <ref> [25] </ref>). <p> A lower envelope corresponds to an infinite number of convex sets of distributions, so statements about estimation of convex sets are stronger than statements about lower envelopes. To be able to attack this problem, we note that there is a one-to-one correspondence between credal sets and lower expectations <ref> [25] </ref>. If we can estimate lower expectations, we can recover the underlying (unique) convex set of distributions.
Reference: [26] <author> P. Walley. </author> <title> Inferences from multinomial data: Learning about a bag of marbles. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 58(1) </volume> <pages> 3-57, </pages> <year> 1996. </year>
Reference-contexts: The idea is to avoid using unjustified assumptions and replacing those by sets of distributions, so that the effects of missing data can be evaluated. 8.2 Walley's imprecise Dirichlet prior The imprecise Dirichlet prior has been proposed by Walley <ref> [26] </ref> as a model for inferences associated with multinomial sampling. Here we indicate how this model can be used to learn Bayesian networks associated with convex sets of distributions.
Reference: [27] <author> P. Walley and T. L. </author> <title> Fine. Towards a frequentist theory of upper and lower probability. </title> <journal> The Annals of Statistics, </journal> <volume> 10(3) </volume> <pages> 741-761, </pages> <year> 1982. </year> <month> 18 </month>
Reference-contexts: Our asymptotic results parallel and generalize the laws of large numbers used in probability theory. Existing literature does not provide an organized collection of asymptotic results for convex sets of distributions. The first results of this kind were proposed by Walley and Fine <ref> [27] </ref>, and this paper can be understood as an adaptation of their results to more practical scenarios. The goals of our paper are: 1. To provide background on the theory of convex sets of distributions and motivation (Sections 2 and 3). 2. <p> to make such connections, most notably the work of Kyburg [13, 14], which proposes specific guidelines to transform finite data knowledge into intervals of probabilities; the work of Seidenfeld and Schervish [22] on the convergence properties of beliefs in a group of agents; and the work of Walley and Fine <ref> [27] </ref> on estimators for sets of distributions. <p> Is it possible to relate a convex set of distributions to observable repeated outcomes in a manner analogous to the relationship between probabilities and frequencies? Can credal sets similarly be induced from a limiting series of observations in a meaningful fashion? Results by Walley and Fine <ref> [27] </ref> prove that such a connection is indeed possible. In this paper, we explain, build upon and extend these results, and we present interpretations of the mathematical results that are both useful and understandable. <p> The use of credal sets enriches the basic notion (s) of statistical guarantees, and these generalized notions are discussed in Section 4.2. Section 5 then considers our estimation goal, i.e., what it would mean to estimate that credal set from a sequence of observations. Walley and Fine <ref> [27] </ref> constructed such an estimator; we present their estimator and results in Section 6. 4.1 Data generation assumptions Our data generation assumptions (taken from Walley and Fine) are as follows. <p> However, due to lack of time or other factors, the assessments are to be completed without elaborating a full detailed model of the interactions or correlations between the variables. This interpretation of convex sets of probability is referred to the ontological interpretation in previous research <ref> [3, 27] </ref>. As 5 actual values for the variables become observed, it is as if the values have been drawn from the perfectly calibrated subjectivist's belief set. <p> A weaker notion of convergence is also useful. When lim n!1 p (A c n )=p (A n ) ! 0, where A c n denotes the complement of A n , it is said that A is asymptotically favored (a.f.) <ref> [27] </ref>. For a point probability, asymptotic favorability and asymptotic certainty correspond. In general, asymptotic certainty implies asymptotic favorability; a.f. is much weaker than a.c. <p> In simple terms, this is just because our very loose assumptions about data generation have left totally open the manner in which "nature" selects individual trial distributions. The deeper ramifications of this are reflected in a series of estimation results <ref> [27, Theorems 5.1-5.4] </ref>, which state that it is not possible to detect the full extent of the underlying credal set with asymptotic certainty, although it can be done with asymptotic favorability (i.e., if you happen to be fortunate). <p> an estimator that is guaranteed to dominate the underlying credal set with asymptotic 7 certainty and contains as many distributions as possible. 6 Walley and Fine's estimation task The estimation task that we have identified in the previous section differs somewhat from the estimation problem solved by Walley and Fine <ref> [27] </ref>, although the assumptions behind data generation are identical. The difference is subtle, but important for avoiding confusion and fully understanding the results in this area. <p> The lower envelope formed through Walley and Fine's estimator can be extended to a convex set (the set of all distributions that dominate these estimates). Walley and Fine prove that this set dominates the credal set that generated the data <ref> [27, Theorem 4.1] </ref>. The dual upper envelope estimator is obtained by replacing the infimum with a supremum in (1). <p> When we drop the single distribution and i.i.d. assumptions, the estimates become far richer. Walley and Fine <ref> [27, Theorem 4.1 (a)] </ref> prove that their estimator produces a credal set that dominates the underlying credal set with asymptotic certainty. Their estimator will detect divergence from i.i.d. point probability with asymptotic favorability (their Theorem 4.1 (d)). <p> We assume that sub-sequences are defined such that there are infinitely many elements in each sub-sequence for an infinitely long original sequence. To prove the main theorem, we need the following result from Walley and Fine <ref> [27, Lemma3.2 summarized] </ref>: Lemma 1 Suppose p () is a lower envelope in a space with a finite number of elements, and we choose a collection of events A jn for n 1 and 1 j J , such that the events A jn are a.c. as n ! 1. <p> Now, take each algorithm s j from S. Each s j defines an infinite sequence of trials with probability larger than p (A) for each event A. Now apply Theorem 4.1.a from Walley and Fine <ref> [27] </ref> on each sub-sequence: 8 &gt; 0; A2A n (A) &gt; p (A) ] a.c. as n ! 1 under p 1 (): In other words, for large enough n, the value of r n (A) will (almost always) be within p (A) and p (A).
References-found: 27

