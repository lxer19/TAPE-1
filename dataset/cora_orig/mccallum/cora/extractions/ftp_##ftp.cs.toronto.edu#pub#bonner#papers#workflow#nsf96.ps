URL: ftp://ftp.cs.toronto.edu/pub/bonner/papers/workflow/nsf96.ps
Refering-URL: http://www.cs.toronto.edu/~bonner/papers.html
Root-URL: http://www.cs.toronto.edu
Email: bonner@db.toronto.edu  shrufi@db.toronto.edu  steve@genome.wi.mit.edu  
Phone: 2  
Title: Database Requirements for Workflow Management in a High-Throughput Genome Laboratory 1  
Author: Anthony J. Bonner Adel Shrufi Steve Rozen 
Web: http://www.db.toronto.edu:8020/people/bonner/bonner.html  
Note: Presented at the NSF Workshop on Workflow and Process Automation in Information Systems: State-of-the-Art and Future Directions, May 8-10, 1996, Athens, Georgia. This and related papers are available at the following web page:  
Date: 3 Whitehead/MIT  
Address: 10 King's College Rd Toronto, ON, Canada  One Kendall Square Building 300, Floor 5 Cambridge, MA 02139, USA  
Affiliation: University of Toronto Department of Computer Science  Center for Genome Research  
Pubnum: M5S 1A4  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Standard Guide for Laboratory Information Management Systems (LIMS). American Society for Testing and Materials, </institution> <address> 1916 Race St., Philadelphia PA 19103, U.S.A, </address> <year> 1993. </year>
Reference-contexts: Examples of central materials include insurance claims, loan applications, and laboratory samples. As a central material is processed, workflow activities gather information about it. Production workflow systems include the class of Laboratory Information Management Systems, or LIMS <ref> [21, 1, 19] </ref>. LIMS are found in analytical laboratories in a wide range of industries, including pharmaceuticals, health care, environmental monitoring, food and drug testing, and water and soil management.
Reference: [2] <author> A. Bonner, A. Shrufi, and S. Rozen. LabFlow-1: </author> <title> a database benchmark for high-throughput workflow management. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1995. </year> <pages> 53 pages. </pages> <note> Available at http://www.db.toronto.edu:8020/people/bonner/bonner.html. </note>
Reference-contexts: It can also be used to analyze workflows, to find rate limiting steps or to investigate anomalous results. This paper discusses the requirements of this DBMS. The discussion centers on LabFlow-1 <ref> [3, 2] </ref>, a recently developed database benchmark for high-throughput workflow management systems (WFMSs), i:e:, systems for managing high-volume, mission-critical workflows. LabFlow-1 is based on the data and workflow management needs of a large genome laboratory, and reflects their real-world experience. <p> LabFlow-1 is based on the data and workflow management needs of a large genome laboratory, and reflects their real-world experience. An overview of the benchmark can be found in [3], and a detailed description in <ref> [2] </ref>. Benchmark software is available at the following web site: ftp://db.toronto.edu/pub/bonner/papers/workflow/software/ Although it is based on genome-laboratory workflow, we believe that LabFlow-1 captures the database requirements of a common class workflow management applications: those that require a 1 This work was supported by funds from the U.S. <p> The LabFlow-1 benchmark is intended for such applications. 3 Workflow in LabFlow-1 This section provides an overview of data and workflow management in LabFlow-1 from the perspective of the DBMS. To keep the discussion concrete, we frame it in terms of laboratory workflow. Additional details can be found in <ref> [2] </ref>. The database contains two main kinds of object: materials and steps. In object-oriented terms, the database has a material class and a step class, with subclasses representing different kinds of materials and steps. <p> These queries scour the event history to produce summaries of laboratory activity. The summaries are hierarchically structured, so the query answer is typically a nested set or a nested list (e:g:, a list of lists of lists). 4 Detailed examples of queries and updates are given in <ref> [2] </ref>. The functions described above come largely under the heading of workflow tracking. In addition, a workflow management system must provide a means of workflow modeling [10]. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph [25, 2]. <p> The functions described above come largely under the heading of workflow tracking. In addition, a workflow management system must provide a means of workflow modeling [10]. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph <ref> [25, 2] </ref>. Workflow graphs are based on the idea that each material has a workflow state, and as the material is processed, it moves from one state to another. The workflow graph largely determines the workload for the DBMS. <p> Workflow graphs are based on the idea that each material has a workflow state, and as the material is processed, it moves from one state to another. The workflow graph largely determines the workload for the DBMS. A sample graph is given in <ref> [2] </ref>, one that forms the basis of the workload for the LabFlow-1 benchmark. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, [22, 26, 9]).
Reference: [3] <author> A. Bonner, A. Shrufi, and S. Rozen. LabFlow-1: </author> <title> a database benchmark for high-throughput workflow management. </title> <booktitle> In Proceedings of the International Conference on Extending Database Technology (EDBT), number 1057 in Lecture Notes in Computer Science, </booktitle> <pages> pages 463-478, </pages> <address> Avi-gnon, France, March 25-29 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: It can also be used to analyze workflows, to find rate limiting steps or to investigate anomalous results. This paper discusses the requirements of this DBMS. The discussion centers on LabFlow-1 <ref> [3, 2] </ref>, a recently developed database benchmark for high-throughput workflow management systems (WFMSs), i:e:, systems for managing high-volume, mission-critical workflows. LabFlow-1 is based on the data and workflow management needs of a large genome laboratory, and reflects their real-world experience. <p> LabFlow-1 is based on the data and workflow management needs of a large genome laboratory, and reflects their real-world experience. An overview of the benchmark can be found in <ref> [3] </ref>, and a detailed description in [2].
Reference: [4] <institution> Communications of the ACM, </institution> <month> 34(11), November </month> <year> 1991. </year> <title> Special issue on the Human Genome Project. </title>
Reference-contexts: High-throughput workflows are characteristic of large genome laboratories, such as those operated at the Whitehead/MIT Center for Genome Research (hereafter called "the Genome Center"). Work-flow management is needed to support the Genome Center's large-scale genome-mapping projects <ref> [4, 15, 5] </ref>. <p> These rates are expected to increase by another order of magnitude in the near future if the Genome Center begins large scale sequencing of the Human genome <ref> [4] </ref>. Moreover, unlike the simple banking debit/credit transactions of some TPC benchmarks [23], these transactions involve complex queries, plus updates to complex objects, such as arrays, sequences, and nested sets. The LabFlow-1 benchmark is a first step towards measuring the performance of WFMSs.
Reference: [5] <author> N. G. Copeland et al. </author> <title> A genetic linkage map of the mouse: Current applications and future prospects. </title> <journal> Science, </journal> <volume> 262 </volume> <pages> 57-66, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: High-throughput workflows are characteristic of large genome laboratories, such as those operated at the Whitehead/MIT Center for Genome Research (hereafter called "the Genome Center"). Work-flow management is needed to support the Genome Center's large-scale genome-mapping projects <ref> [4, 15, 5] </ref>.
Reference: [6] <author> U. Dayal, H. Garcia-Molina, M. Hsu, B. Kao, and M.-C. Shan. </author> <title> Third generation TP monitors: A database challenge. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 393-397, </pages> <address> Washington, DD, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10].
Reference: [7] <author> E. Dyson. </author> <title> Workflow. </title> <booktitle> In Forbes, </booktitle> <pages> page 192. </pages> <month> November 23 </month> <year> 1992. </year>
Reference-contexts: Salient examples include clinical drug trials and environmental testing. Dynamic Schema Evolution. A hallmark of modern workflow management is that workflows change frequently, in response to rapidly changing business needs and circumstances <ref> [7, 10] </ref>. Typically, a workflow will acquire new activities and existing activities will evolve. In both cases, the changed workflow generates new kinds of information, which must be recorded in the database.
Reference: [8] <editor> A. K. Elmagarmid, editor. </editor> <title> Database Transaction Models for Advanced Applications. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10].
Reference: [9] <author> H. Garcia-Molina, D. Gawlick, J. Klein, K. Kleissner, and K. Salem. </author> <title> Modeling long-running activities as nested sagas. </title> <journal> Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 14(1), </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: A sample graph is given in [2], one that forms the basis of the workload for the LabFlow-1 benchmark. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [22, 26, 9] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [10] <author> D. Georgakopoulos, M. Hornick, and A. Sheth. </author> <title> An overview of workflow management: From process modeling to infrastructure for automation. </title> <journal> Journal on Distributed and Parallel Database Systems, </journal> <volume> 3(2) </volume> <pages> 119-153, </pages> <month> April </month> <year> 1995. </year> <month> 5 </month>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10]. <p> However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows <ref> [10] </ref>. High-throughput workflows are characteristic of large genome laboratories, such as those operated at the Whitehead/MIT Center for Genome Research (hereafter called "the Genome Center"). Work-flow management is needed to support the Genome Center's large-scale genome-mapping projects [4, 15, 5]. <p> Salient examples include clinical drug trials and environmental testing. Dynamic Schema Evolution. A hallmark of modern workflow management is that workflows change frequently, in response to rapidly changing business needs and circumstances <ref> [7, 10] </ref>. Typically, a workflow will acquire new activities and existing activities will evolve. In both cases, the changed workflow generates new kinds of information, which must be recorded in the database. <p> The functions described above come largely under the heading of workflow tracking. In addition, a workflow management system must provide a means of workflow modeling <ref> [10] </ref>. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph [25, 2].
Reference: [11] <author> N. Goodman. </author> <title> An object oriented DBMS war story: Developing a genome mapping database in C++. </title> <editor> In W. Kim, editor, </editor> <title> Modern Database Management: Object-Oriented and Multidatabase Technologies. </title> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: Because of automation in sample handling and testing, instrumentation, data capture and workflow management, transaction rates at the Genome Center have increased dramatically in the last three years, from processing under 1,000 queries and updates per day in 1992 <ref> [11] </ref>, to over 15,000 on many days in 1995. Of course, peak rates can be much higher, with a rate of 22.5 updates and queries per second recently observed over a 5-minute period.
Reference: [12] <author> J. Gray, </author> <title> editor. The Benchmark Handbook for Database and Transaction Processing Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: [13] <author> M. Hsu, Ed. </author> <title> Special issue on workflow and extended transaction systems. </title> <journal> Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 16(2), </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10].
Reference: [14] <author> M. Hsu, </author> <title> Ed. </title> <journal> Special issue on workflow systems. Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 18(1), </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10].
Reference: [15] <author> T. J. Hudson et al. </author> <title> An STS-based map of the human genome. </title> <journal> Science, </journal> <volume> 270 </volume> <pages> 1945-1954, </pages> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: High-throughput workflows are characteristic of large genome laboratories, such as those operated at the Whitehead/MIT Center for Genome Research (hereafter called "the Genome Center"). Work-flow management is needed to support the Genome Center's large-scale genome-mapping projects <ref> [4, 15, 5] </ref>.
Reference: [16] <author> S. Khoshafian and M. Buckiewicz. </author> <title> Introduction to Groupware, Workflow, and Workgroup Computing. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1995. </year>
Reference-contexts: National Institutes of Health, National Center for Human Genome Research, grant number P50 HG00098, and from the U.S. Department of Energy under contract DE-FG02-95ER62101. 1 production workflow system <ref> [16] </ref>. In production workflow, activities are organized into a kind of production line, involving a mix of human and computer activities. Examples in business include insurance-claim or loan-application processing.
Reference: [17] <author> D. Mattes. </author> <title> LIMS and good laboratory practice. </title> <booktitle> In [19], </booktitle> <pages> pages 332-345. </pages> <year> 1985. </year>
Reference-contexts: The DBMS must therefore support queries and views on an historical database. We note that many commercial laboratories are legally bound to record event histories, since "Accountability is critical in tracking who is responsible for data and its approval for release" <ref> [17] </ref>. Salient examples include clinical drug trials and environmental testing. Dynamic Schema Evolution. A hallmark of modern workflow management is that workflows change frequently, in response to rapidly changing business needs and circumstances [7, 10]. Typically, a workflow will acquire new activities and existing activities will evolve.
Reference: [18] <author> R. McDowall. </author> <title> Introduction to laboratory information management systems. </title> <booktitle> In [19], </booktitle> <pages> pages 1-16. </pages> <year> 1985. </year>
Reference-contexts: In all cases, the laboratory receives a continual stream of samples, each of which is subjected to a battery of tests and analyses. Workflow management is needed to maintain throughput and control quality <ref> [18] </ref>. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment [10, 20, 6, 14, 13, 8, 22]. However, the performance of workflow management systems has so far received little attention.
Reference: [19] <author> R. McDowell, </author> <title> editor. Laboratory Information Management Systems: Concepts, Integration, Implementation. </title> <publisher> Sigma Press, </publisher> <address> Wilmslow, U.K., </address> <year> 1985. </year>
Reference-contexts: Examples of central materials include insurance claims, loan applications, and laboratory samples. As a central material is processed, workflow activities gather information about it. Production workflow systems include the class of Laboratory Information Management Systems, or LIMS <ref> [21, 1, 19] </ref>. LIMS are found in analytical laboratories in a wide range of industries, including pharmaceuticals, health care, environmental monitoring, food and drug testing, and water and soil management.
Reference: [20] <author> C. Mohan. </author> <title> Tutorial: A survey and critique of advanced transaction models. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> page 521, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year> <title> Tutorial. </title>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10].
Reference: [21] <author> A. S. Nakagawa. LIMS: </author> <title> Implementation and Management. </title> <institution> Royal Society of Chemistry, Thomas Granham House, The Science Park, </institution> <address> Cambridge CB4 4WF, England, </address> <year> 1994. </year>
Reference-contexts: Examples of central materials include insurance claims, loan applications, and laboratory samples. As a central material is processed, workflow activities gather information about it. Production workflow systems include the class of Laboratory Information Management Systems, or LIMS <ref> [21, 1, 19] </ref>. LIMS are found in analytical laboratories in a wide range of industries, including pharmaceuticals, health care, environmental monitoring, food and drug testing, and water and soil management.
Reference: [22] <author> M. Rusinkiewicz and A. Sheth. </author> <title> Specification and execution of transactional workflows. </title> <editor> In W. Kim, editor, </editor> <title> Modern Database Systems: The Object Model, Interoperability, and Beyond. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality [18]. 2 Performance and Database Requirements Much of the research on workflow management in computer science has focussed on developing extended transaction models, especially in a heterogeneous environment <ref> [10, 20, 6, 14, 13, 8, 22] </ref>. However, the performance of workflow management systems has so far received little attention. The need to study performance arises because commercial products cannot support applications with high-throughput workflows [10]. <p> A sample graph is given in [2], one that forms the basis of the workload for the LabFlow-1 benchmark. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [22, 26, 9] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [23] <author> O. </author> <title> Serlin. The history of debit credit and the TPC. </title> <booktitle> In [12], chapter 2, </booktitle> <pages> pages 19-117. </pages>
Reference-contexts: These rates are expected to increase by another order of magnitude in the near future if the Genome Center begins large scale sequencing of the Human genome [4]. Moreover, unlike the simple banking debit/credit transactions of some TPC benchmarks <ref> [23] </ref>, these transactions involve complex queries, plus updates to complex objects, such as arrays, sequences, and nested sets. The LabFlow-1 benchmark is a first step towards measuring the performance of WFMSs. It does not account for all the components that affect performance, such as networks, hardware platforms, and operating systems.
Reference: [24] <author> A. Skarra and S. Zdonick. </author> <title> The management of changing types in an object-oriented database. </title> <booktitle> In Proceedings of the Conference on Object-oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 483-495, </pages> <year> 1986. </year>
Reference-contexts: In effect, as a step evolves, new versions of the step are created. Each step object is associated forever with the same version of a step class; so schema changes do not require data re-organization. A similar approach to schema evolution can be found in <ref> [24] </ref>. The data representation described above is event oriented. That is, information about a step is kept in one place, but information about a material is scattered among different steps. This provides a straightforward record of laboratory activity, but an awkward representation of materials.
Reference: [25] <author> L. Stein, S. Rozen, and N. Goodman. </author> <title> Managing laboratory workflow with LabBase. </title> <booktitle> In Proceedings of the 1994 Conference on Computers in Medicine (CompMed94). </booktitle> <publisher> World Scientific Publishing Company, </publisher> <year> 1995. </year> <note> In press. Available at ftp://genome.wi.mit.edu/pub/papers/Y1995/ workflow.ps.Z. </note>
Reference-contexts: The functions described above come largely under the heading of workflow tracking. In addition, a workflow management system must provide a means of workflow modeling [10]. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph <ref> [25, 2] </ref>. Workflow graphs are based on the idea that each material has a workflow state, and as the material is processed, it moves from one state to another. The workflow graph largely determines the workload for the DBMS.
Reference: [26] <author> H. Wachter and A. Reuter. </author> <title> The ConTract model. </title> <editor> In A. K. Elmagarmid, editor, </editor> <booktitle> Database Transaction Models for Advanced Applications, </booktitle> <pages> pages 219-264. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: A sample graph is given in [2], one that forms the basis of the workload for the LabFlow-1 benchmark. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [22, 26, 9] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
References-found: 26

