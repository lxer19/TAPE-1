URL: http://www.santafe.edu/~mm/RoyalRoad.ps.gz
Refering-URL: http://www.santafe.edu/~mm/paper-abstracts.html
Root-URL: 
Email: melaniem@eecs.umich.edu  forrest@unmvax.cs.unm.edu  
Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  
Author: Melanie Mitchell Stephanie Forrest John H. Holland 
Address: Ann Arbor, MI 48109  Albuquerque, NM 87131  Ann Arbor, MI 48109  
Affiliation: University of Michigan  Dept. of Computer Science University of New Mexico  Dept. of Psychology University of Michigan  
Pubnum: AI Laboratory  
Abstract: Genetic algorithms (GAs) play a major role in many artificial-life systems, but there is often little detailed understanding of why the GA performs as it does, and little theoretical basis on which to characterize the types of fitness landscapes that lead to successful GA performance. In this paper we propose a strategy for addressing these issues. Our strategy consists of defining a set of features of fitness landscapes that are particularly relevant to the GA, and experimentally studying how various configurations of these features affect the GA's performance along a number of dimensions. In this paper we informally describe an initial set of proposed feature classes, describe in detail one such class ("Royal Road" functions), and present some initial experimental results concerning the role of crossover and "building blocks" on landscapes constructed from features of this class.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bergman and M. W. Feldman. </author> <title> More on selection for and against recombination. </title> <journal> Theoretical Population Biology, </journal> <volume> 38(1) </volume> <pages> 68-92, </pages> <year> 1990. </year>
Reference-contexts: GA relate to biological systems, including in the following questions: What is the relation of function optimization to adaptation and evolution? What is the relation of our results on the role of crossover to current work in theoretical population genetics on the types of environments in which recombination is favored <ref> [1] </ref>? To what extent can we understand biological environments in terms of the features we are proposing for our fitness landscapes (e.g., hierarchies of building blocks)? We hope that studying the relation of landscape features to GA performance will not only shed light on what types of problems are likely to
Reference: [2] <author> A. D. Bethke. </author> <title> Genetic Algorithms as Function Op-timizers. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1980. </year> <note> Dissertation Abstracts International, 41(9), 3503B (University Microfilms No. 8106101). </note>
Reference-contexts: However, several properties of fitness landscapes have been identified that can make the search for high-fitness values easy or hard for the GA. Most research up to now has concentrated on three types of features: deception, sampling error, and the "ruggedness" of a fitness landscape. Bethke <ref> [2] </ref> defined a class of functions that are "misleading" for the GA and therefore hard to optimize. Goldberg extended this work, defining the class of GA-deceptive functions [7, 8, 10], in which low-order schemas lead the GA away from the fittest higher-order schemas. <p> These are related to cases of "isolated optima" described by Bethke <ref> [2] </ref>.
Reference: [3] <author> R. Das and L. D. Whitley. </author> <title> The only challenging problems are deceptive: Global search by solving order-1 hyperplanes. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Goldberg extended this work, defining the class of GA-deceptive functions [7, 8, 10], in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., <ref> [7, 3, 21] </ref>). Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, [20, 11]).
Reference: [4] <author> K. Deb. </author> <title> Genetic algorithms in multimodal function optimization. Technical report, The Clearinghouse for Genetic Algorithms, </title> <institution> Department of Engineering Mechanics, University of Alabama, Tuscaloosa, AL, </institution> <year> 1989. </year> <type> (Master's Thesis). </type>
Reference-contexts: In functions with conflicting pressures, issues such as crossover disruption [17] and carrying capacity (how many different solutions a population of a given size can maintain) <ref> [4] </ref> are relevant factors. The three categories of features sketched above constitute an initial set from which to construct landscapes for the purpose of studying GA performance.
Reference: [5] <author> S. Forrest and M. Mitchell. </author> <title> The performance of genetic algorithms on Walsh polynomials: Some anomalous results and their explanation. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Kauffman [18] has studied how the degree of ruggedness of a landscape affects the ease of adaptation under mutation and crossover. Finally, Forrest and Mitchell have identified the existence of multiple mutually conflicting partial solutions as a cause of difficulty for GAs <ref> [5] </ref>. In our current research, we are studying param-eterizable landscape features that are more directly connected to the building-block hypothesis. <p> The GA population size was always 128, and in each run the GA was allowed to continue until the optimum string was discovered, and the generation of this discovery was recorded. The GA we used was conventional [9], with single-point crossover and sigma scaling <ref> [26, 5] </ref> with the maximum expected offspring of any string being 1.5.
Reference: [6] <author> S. Forrest and A. S. Perelson. </author> <title> Genetic algorithms and the immune system. </title> <editor> In H. Schwefel and R. Maen-ner, editors, </editor> <title> Parallel Problem Solving from Nature, </title> <address> Berlin, </address> <year> 1990. </year> <note> Springer-Verlag (Lecture Notes in Computer Science). </note>
Reference-contexts: Examples include classifier systems [15] (where genetic operators are used to search for a useful set of rules that collectively performs well) and GA models of the immune system <ref> [6] </ref> (where a population of antibodies is evolving to cover a set of antigens). In functions with conflicting pressures, issues such as crossover disruption [17] and carrying capacity (how many different solutions a population of a given size can maintain) [4] are relevant factors.
Reference: [7] <author> D. E. Goldberg. </author> <title> Simple genetic algorithms and the minimal deceptive problem. </title> <editor> In L. D. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> Research Notes in Artificial Intelligence, </booktitle> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Bethke [2] defined a class of functions that are "misleading" for the GA and therefore hard to optimize. Goldberg extended this work, defining the class of GA-deceptive functions <ref> [7, 8, 10] </ref>, in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., [7, 3, 21]). <p> Goldberg extended this work, defining the class of GA-deceptive functions [7, 8, 10], in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., <ref> [7, 3, 21] </ref>). Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, [20, 11]).
Reference: [8] <author> D. E. Goldberg. </author> <title> Genetic algorithms and Walsh functions: Part II, Deception and its analysis. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 153-171, </pages> <year> 1989. </year>
Reference-contexts: Bethke [2] defined a class of functions that are "misleading" for the GA and therefore hard to optimize. Goldberg extended this work, defining the class of GA-deceptive functions <ref> [7, 8, 10] </ref>, in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., [7, 3, 21]). <p> One hypothesis [14] is that the GA should be better able to search landscapes containing such features because the lower-fitness deserts can be quickly crossed via crossover (here, between instances of 11** and **11). Isolates are a special case of what have been called "partially deceptive functions" <ref> [8] </ref>. The idea of isolated regions of high fitness surrounded by flat deserts of low fitness is similar to the "mesa phenomenon" proposed by Minsky [24] and to the error surfaces identified by Hush et al. for multilayer perceptron neural networks [16].
Reference: [9] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Evolutionary processes are central to our understanding of natural living systems, and will play an equally central role in attempts to create and study artificial life. Genetic algorithms (GAs) <ref> [13, 9] </ref> are an idealized computational model of Darwinian evolution based on the principles of genetic variation and natural selection. GAs have been employed in many artificial-life systems as a means of evolving artificial organisms, simulating ecologies, and modeling population evolution. <p> The GA's operation can be thought of as a search for schemas of high average fitness, carried out by sampling individuals in a population and biasing future samples towards schemas that are estimated to have above-average fitness. Holland's Schema Theorem <ref> [13, 9] </ref> demonstrates that, under certain assumptions, schemas whose estimated average fitness remains above the population's average fitness will receive an exponentially increasing number of samples. That is, schemas judged to be highly fit will be emphasized in the population. <p> However, the Schema Theorem does not address the process by which new schemas are discovered; in fact, crossover appears in the Schema Theorem as a factor that slows the exploitation of good schemas. The "building-blocks hypothesis" <ref> [13, 9] </ref> states that new schemas are discovered via crossover, which combines instances of low-order schemas (partial solutions or "building blocks") of estimated high fitness into higher-order schemas (composite solutions). <p> The suc-cess of the GA on a particular function is certainly related to how the function is "encoded" <ref> [9, 20] </ref> (e.g., using Gray codes for numerical parameters can greatly enhance the performance of the GA on some problems), but since we are interested in biases that pertain directly to the GA, we will simply consider the landscape that the GA "sees." 3 Landscape Features and GA Performance There is <p> The GA population size was always 128, and in each run the GA was allowed to continue until the optimum string was discovered, and the generation of this discovery was recorded. The GA we used was conventional <ref> [9] </ref>, with single-point crossover and sigma scaling [26, 5] with the maximum expected offspring of any string being 1.5. <p> On average, the GA finds the optimum faster on the function with no intermediate schemas. What is the cause of this unexpected phenomenon? Further analysis led us to the conclusion that the intermediate schemas cause a kind of premature-convergence phenomenon <ref> [9] </ref>. For example, suppose that, on the function with intermediate levels, the GA finds 11111111*: : :*, ********11111111*: : : *, and then 1111111111111111*: : :*. <p> The fact that the population loses useful schemas once one of the disjoint good schemas is found suggests that the rate of effective implicit parallelism of the GA <ref> [13, 9] </ref> may need to be reconsidered. It is suggestive that in many biological settings functionality is evolved sequentially rather than in parallel. For example, it is hypothesized that the immune system evolved by learning to recognize a base set of antigens and then successively extended the base set [25].
Reference: [10] <author> D. E. Goldberg. </author> <title> Construction of high-order deceptive functions using low-order Walsh coefficients. </title> <type> Technical Report 90002, </type> <institution> Illinois Genetic Algorithms Laboratory, Dept. of General Engineering, University of Illinois, Urbana, IL, </institution> <year> 1990. </year>
Reference-contexts: Bethke [2] defined a class of functions that are "misleading" for the GA and therefore hard to optimize. Goldberg extended this work, defining the class of GA-deceptive functions <ref> [7, 8, 10] </ref>, in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., [7, 3, 21]).
Reference: [11] <author> D. E. Goldberg and M. Rudnick. </author> <title> Schema variance from Walsh-schema transform. </title> <journal> Complex Systems, </journal> <volume> 5 </volume> <pages> 265-278, </pages> <year> 1991. </year>
Reference-contexts: Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, <ref> [20, 11] </ref>). Kauffman [18] has studied how the degree of ruggedness of a landscape affects the ease of adaptation under mutation and crossover. Finally, Forrest and Mitchell have identified the existence of multiple mutually conflicting partial solutions as a cause of difficulty for GAs [5].
Reference: [12] <author> J. J. Grefenstette and J. E. Baker. </author> <title> How genetic algorithms work: A critical look at implicit parallelism. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Ma-teo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There have been a number of studies of GA performance on deceptive landscapes (e.g., [7, 3, 21]). Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA <ref> [12] </ref>. Other authors also identify sampling error as a problem in GA performance (for example, [20, 11]). Kauffman [18] has studied how the degree of ruggedness of a landscape affects the ease of adaptation under mutation and crossover.
Reference: [13] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction Evolutionary processes are central to our understanding of natural living systems, and will play an equally central role in attempts to create and study artificial life. Genetic algorithms (GAs) <ref> [13, 9] </ref> are an idealized computational model of Darwinian evolution based on the principles of genetic variation and natural selection. GAs have been employed in many artificial-life systems as a means of evolving artificial organisms, simulating ecologies, and modeling population evolution. <p> The GA's operation can be thought of as a search for schemas of high average fitness, carried out by sampling individuals in a population and biasing future samples towards schemas that are estimated to have above-average fitness. Holland's Schema Theorem <ref> [13, 9] </ref> demonstrates that, under certain assumptions, schemas whose estimated average fitness remains above the population's average fitness will receive an exponentially increasing number of samples. That is, schemas judged to be highly fit will be emphasized in the population. <p> However, the Schema Theorem does not address the process by which new schemas are discovered; in fact, crossover appears in the Schema Theorem as a factor that slows the exploitation of good schemas. The "building-blocks hypothesis" <ref> [13, 9] </ref> states that new schemas are discovered via crossover, which combines instances of low-order schemas (partial solutions or "building blocks") of estimated high fitness into higher-order schemas (composite solutions). <p> The fact that the population loses useful schemas once one of the disjoint good schemas is found suggests that the rate of effective implicit parallelism of the GA <ref> [13, 9] </ref> may need to be reconsidered. It is suggestive that in many biological settings functionality is evolved sequentially rather than in parallel. For example, it is hypothesized that the immune system evolved by learning to recognize a base set of antigens and then successively extended the base set [25].
Reference: [14] <author> J. H. Holland. </author> <title> Using classifier systems to study adaptive nonlinear networks. </title> <editor> In D. L. Stein, editor, </editor> <booktitle> Lectures in the Sciences of Complexity, </booktitle> <volume> Volume 1, </volume> <pages> pages 463-499, </pages> <address> Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Isolated High-Fitness Regions A second type of feature is an isolated region of high average fitness (say, containing the global optimum) contained in a larger region of lower average fitness, which is in turn contained in an even larger area of intermediate average fitness <ref> [14] </ref>. These are related to cases of "isolated optima" described by Bethke [2]. <p> A search algorithm such as hillclimbing will reach the largest areas of intermediate fitness (**11 and 11**), but will in general be slow at crossing the intervening "deserts" of lower fitness (*111 and 111*). One hypothesis <ref> [14] </ref> is that the GA should be better able to search landscapes containing such features because the lower-fitness deserts can be quickly crossed via crossover (here, between instances of 11** and **11). Isolates are a special case of what have been called "partially deceptive functions" [8].
Reference: [15] <author> J. H. Holland, K. J. Holyoak, R. E. Nisbett, and P. Thagard. </author> <title> Induction: Processes of Inference, Learning, and Discovery. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Moving away from a strict function-optimization setting, similar difficulties are encountered for any kind of ecological environment in which the population needs to maintain multiple conflicting schemas. Examples include classifier systems <ref> [15] </ref> (where genetic operators are used to search for a useful set of rules that collectively performs well) and GA models of the immune system [6] (where a population of antibodies is evolving to cover a set of antigens).
Reference: [16] <author> D. R. Hush, B. Horne, and J. M. Salas. </author> <title> Error surfaces for multi-layer perceptrons. </title> <type> Technical Report EECE 90-003, </type> <institution> University of New Mexico, Dept. of Electrical and Computer Engineering, </institution> <address> Albuquerque, N.M. 87131, </address> <year> 1990. </year>
Reference-contexts: The idea of isolated regions of high fitness surrounded by flat deserts of low fitness is similar to the "mesa phenomenon" proposed by Minsky [24] and to the error surfaces identified by Hush et al. for multilayer perceptron neural networks <ref> [16] </ref>. Thus, the shape of the surface may be as important to GA performance as the actual direction of the gradient (deceptive functions emphasize direction). This feature allows us to control the shape as well as the direction of the surface the GA is searching.
Reference: [17] <author> K. A. De Jong. </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: In functions with conflicting pressures, issues such as crossover disruption <ref> [17] </ref> and carrying capacity (how many different solutions a population of a given size can maintain) [4] are relevant factors. The three categories of features sketched above constitute an initial set from which to construct landscapes for the purpose of studying GA performance.
Reference: [18] <author> S. A. Kauffman. </author> <title> Adaptation on rugged fitness landscapes. </title> <editor> In D. Stein, editor, </editor> <booktitle> Lectures in the Sciences of Complexity, </booktitle> <pages> pages 527-618, </pages> <address> Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, [20, 11]). Kauffman <ref> [18] </ref> has studied how the degree of ruggedness of a landscape affects the ease of adaptation under mutation and crossover. Finally, Forrest and Mitchell have identified the existence of multiple mutually conflicting partial solutions as a cause of difficulty for GAs [5]. <p> Statistical measures such as correlation length and length of adaptive walks to optima|both defined in terms of Hamming distance|have been applied to various landscapes for this purpose <ref> [18, 22] </ref>.
Reference: [19] <editor> C. G. Langton, C. Taylor, J. D. Farmer, and S. Ras-mussen, editors. </editor> <booktitle> Artificial Life II. Santa Fe Institute Studies in the Sciences of Complexity. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: on Artificial Life Cambridge, MA: MIT Press, 1991. is to search a fitness landscape for high values (where fitness can be either explicitly or implicitly defined), and GAs have been demonstrated to be efficient and powerful search techniques for a range of such problems (e.g., there are several examples in <ref> [19] </ref>). However, the details of how the GA goes about searching a given landscape are not well understood. Consequently, there is little general understanding of what makes a problem hard or easy for a GA, and in particular, of the effects of various landscape features on the GA's performance.
Reference: [20] <author> G. E. Liepins and M. D. Vose. </author> <title> Representational issues in genetic optimization. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 101-115, </pages> <year> 1990. </year>
Reference-contexts: The suc-cess of the GA on a particular function is certainly related to how the function is "encoded" <ref> [9, 20] </ref> (e.g., using Gray codes for numerical parameters can greatly enhance the performance of the GA on some problems), but since we are interested in biases that pertain directly to the GA, we will simply consider the landscape that the GA "sees." 3 Landscape Features and GA Performance There is <p> Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, <ref> [20, 11] </ref>). Kauffman [18] has studied how the degree of ruggedness of a landscape affects the ease of adaptation under mutation and crossover. Finally, Forrest and Mitchell have identified the existence of multiple mutually conflicting partial solutions as a cause of difficulty for GAs [5].
Reference: [21] <author> G. E. Liepins and M. D. Vose. </author> <title> Deceptiveness and genetic algorithm dynamics. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Goldberg extended this work, defining the class of GA-deceptive functions [7, 8, 10], in which low-order schemas lead the GA away from the fittest higher-order schemas. There have been a number of studies of GA performance on deceptive landscapes (e.g., <ref> [7, 3, 21] </ref>). Grefenstette and Baker studied a function in which high variance in the fitness of a correct low-order schema leads to sampling error that misleads the GA [12]. Other authors also identify sampling error as a problem in GA performance (for example, [20, 11]).
Reference: [22] <author> M. Lipsitch. </author> <title> Adaptation on rugged landscapes generated by local interactions of neighboring genes. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Statistical measures such as correlation length and length of adaptive walks to optima|both defined in terms of Hamming distance|have been applied to various landscapes for this purpose <ref> [18, 22] </ref>.
Reference: [23] <author> B. Manderick, M. de Weger, and P. Spiessens. </author> <title> The genetic algorithm and the structure of the fitness landscape. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: has some relation to the GA's expected performance, but we believe that more useful characterizations may require statistical measures that take into account the way crossover operates and measure correlations in terms of some kind of "crossover distance" rather than Hamming distance (a version of this approach was studied in <ref> [23] </ref>).
Reference: [24] <author> M. Minsky. </author> <title> Steps toward artificial intelligence. </title> <editor> In E. A. Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 406-452. </pages> <publisher> McGraw-Hill, </publisher> <year> 1963. </year>
Reference-contexts: Isolates are a special case of what have been called "partially deceptive functions" [8]. The idea of isolated regions of high fitness surrounded by flat deserts of low fitness is similar to the "mesa phenomenon" proposed by Minsky <ref> [24] </ref> and to the error surfaces identified by Hush et al. for multilayer perceptron neural networks [16]. Thus, the shape of the surface may be as important to GA performance as the actual direction of the gradient (deceptive functions emphasize direction).
Reference: [25] <author> A. S. Perelson. </author> <type> Personal communication. </type>
Reference-contexts: It is suggestive that in many biological settings functionality is evolved sequentially rather than in parallel. For example, it is hypothesized that the immune system evolved by learning to recognize a base set of antigens and then successively extended the base set <ref> [25] </ref>. Thus, it may be completely appropriate for the GA to use sequential search (first learning one set of schemas, then another) under certain circumstances.
Reference: [26] <author> R. Tanese. </author> <title> Distributed Genetic Algorithms for Function Optimization. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1989. </year>
Reference-contexts: We also report results of control experiments which compare the GA's performance with a stochastic iterated hillclimbing al-gorithm (see <ref> [26] </ref>) on these functions. For each of these experiments, we used functions with l = 64 (the individuals in the GA population were bit strings of length 64). <p> The GA population size was always 128, and in each run the GA was allowed to continue until the optimum string was discovered, and the generation of this discovery was recorded. The GA we used was conventional [9], with single-point crossover and sigma scaling <ref> [26, 5] </ref> with the maximum expected offspring of any string being 1.5.
Reference: [27] <author> S. W. Wilson. </author> <title> GA-easy does not imply steepest-ascent optimizable. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of The Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This paper extends this work by (1) proposing several new relevant fitness landscape features, (2) studying one of these features in detail, and (3) demonstrating that there are "GA-easy" functions <ref> [27] </ref> which are not necessarily easy for the GA. 2 GAs and Schema Processing In a GA, chromosomes are represented by bit strings, with individual bits representing genes.
References-found: 27

