URL: file://ftp.cc.gatech.edu/pub/groups/architecture/TASS/git.cc.92.10.ps.Z
Refering-URL: http://www.cs.gatech.edu/grads/s/Gautam.Shah/homepage.html
Root-URL: 
Title: An Experimental Approach to the Performance Evaluation of Parallel Algorithms  
Author: Anand Sivasubramaniam Gautam Shah Umakishore Ramachandran H. Venkateswaran 
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Date: February 1992  
Pubnum: Technical Report GIT-CC-92/10  
Abstract: The results of experimenting with three parallel algorithms on the Sequent Symmetry architecture and the BBN Butterfly architecture are reported. The main objective of this study is to understand the impediments to the efficient implementation of parallel algorithms, developed for theoretical models of parallel computation, on realistic parallel architectures. Scheduling, task granularity, and synchronization are the issues that are explored in implementing these algorithms on the two architectures. In the case of theBBN Butterfly, which is a distributed shared memory architecture,data distribution in the distributed memories is also studied. The key findings are that synchronization is not a significant cost for the algorithms we studied on the two architectures; static scheduling outperforms dynamic scheduling for the algorithms studied; the bus is not a bottleneck at higher task granularities for the configuration of the Sequent machine that we experimented with; and a fairly simple minded data distribution may be as good as any other on the BBN Butterfly. These studies also suggest a top-down approach to understanding the scalability of shared memory multiprocessors. fl This paper represents a substantially reworked version of an earlier paper that appeared in the International Symposium on Shared Memory Multiprocessing, Tokyo, Japan [SSL + 91]. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: The results are very similar to the corresponding ones obtained for list ranking (see Figures 12 and 13). 4.3 Optimal Binary Search Tree A standard dynamic programming algorithm for this problem computes a 2-dimensional cost matrix as shown in Figure 3 <ref> [AHU74] </ref>. This algorithm is data oblivious and traverses one diagonal after another (the values for the elements in the current diagonal depend on the values in the previous diagonal). The number of diagonal elements to be computed in each phase decreases by 1 as we step through the diagonals.
Reference: [And90a] <author> Richard J. Anderson. </author> <title> An Experimental Study of Parallel Merge Sort. Preliminary Version 0.1 . University of Washington, </title> <address> Seattle, </address> <year> 1990. </year>
Reference-contexts: If the computation granularity is made small, then there is more synchronization overhead which in turn generates more traffic on 5 the bus. 3 Related Work To our knowledge, there are very few experimental studies that investigate the impact of architectural features on algorithmic performance. Anderson <ref> [And90a] </ref> reports results of an experimental and analytical study of parallel merge sort. In this study, implementation of this algorithm on the Sequent is used to verify the speedup with different number of processors with respect to the analytical model.
Reference: [And90b] <author> Thomas E. Anderson. </author> <title> The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: As the computation granularity is increased further, the effect of contention becomes less significant which explains the observed result. The contention effect is quite similar to what is explained as quiesce 2 time in <ref> [And90b] </ref>.
Reference: [BBN86] <author> BBN Advanced Computers Inc., </author> <title> Massachusetts. The Uniform System Approach to Programming the Butterfly Parallel Processor, </title> <year> 1986. </year>
Reference-contexts: Our work is more general in that we experiment with algorithms that represent classes of problems and study synchronization, scheduling and task granularity issues in implementing these algorithms. 4 Observed Results The implementations of these algorithms use the parallel programming library [Seq87] on the Sequent, and the uniform system <ref> [BBN86] </ref> on the Butterfly. In the experiments, completion time of the program is used as a measure of the performance of the parallel algorithm. The results for the uniprocessor cases are obtained by running the multiprocessor parallel algorithm on a single processor.
Reference: [CSY90] <author> D. Chen, H. Su, and P. Yew. </author> <title> The Impact of Synchronization and Granularity on Parallel Systems. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 239-248, </pages> <year> 1990. </year> <month> 17 </month>
Reference-contexts: Anderson [And90a] reports results of an experimental and analytical study of parallel merge sort. In this study, implementation of this algorithm on the Sequent is used to verify the speedup with different number of processors with respect to the analytical model. Yew et al. <ref> [CSY90] </ref>, analyze specific parallel programs to identify the appropriate grain size of parallelism that exists in these programs. Further they present a simulation study to measure the impact of synchronization overhead on the execution of these programs.
Reference: [KR90] <author> Richard M. Karp and Vijaya Ramachandran. </author> <title> A Survey of Parallel Algorithms for Shared--Memory Machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 869-942. </pages> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: However, the focus of this study is to understand the performance potential of parallel algorithms and hence the earlier definition is used in the rest of the paper. 4.1 List Ranking A parallel algorithm for the list ranking problem is discussed in <ref> [Wyl79, KR90] </ref>. Figure 1 shows the algorithm and Figure 4 shows the corresponding pseudo code. The algorithm is data dependent. 6 The randomness of access of the list elements does not favor data partitioning.
Reference: [LF80] <author> R. E. Ladner and M. J. Fisher. </author> <title> Parallel Prefix Computation. </title> <journal> Journal of Association of Computing Machinery, </journal> <volume> 27(4) </volume> <pages> 831-838, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: This observation reiterates the fact that the bus on the Sequent is a much more shared resource than the switch on the Butterfly. 4.2 Parallel Prefix An algorithm for the parallel prefix problem is discussed in <ref> [LF80] </ref>, and Figure 2 gives the algorithm and Figure 5 shows the pseudo code for this algorithm. The algorithm is data oblivious. Each phase of the parallel part can be performed only after all processors in the previous phase have completed their task.
Reference: [LR90] <author> Joonwon Lee and Umakishore Ramachandran. </author> <title> Synchronization with Multiprocessor Caches. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 27-37, </pages> <year> 1990. </year>
Reference-contexts: Extensive contention for the globally shared queue is the reason for this behavior. The bus does become a bottleneck in this case and hence this poor performance is quite understandable. This experimental result corroborates the simulation result reported in <ref> [LR90] </ref>, 7 wherein they show that lock contention leads to poor performance in bus-based shared memory multiprocessors. It is also the reason why the performance for higher number of processors (8 and 16 in the Figure) is much poorer than lower number of processors for fine grain data granularity.
Reference: [LS90] <author> Calvin Lin and Lawrence Snyder. </author> <title> A Comparison of Programming Models for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages II 163-170, </pages> <year> 1990. </year>
Reference-contexts: Yew et al. [CSY90], analyze specific parallel programs to identify the appropriate grain size of parallelism that exists in these programs. Further they present a simulation study to measure the impact of synchronization overhead on the execution of these programs. Lin and Snyder <ref> [LS90] </ref> compare message passing and shared memory paradigms for implementing specific parallel algorithms on shared memory multiprocessors.
Reference: [LV90] <author> Scott T. Leutenegger and Mary K. Vernon. </author> <title> The Performance of Multiprogrammed Multiprocessor Scheduling Policies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1990 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 226-236, </pages> <year> 1990. </year>
Reference-contexts: For the algorithms discussed in this paper, we simulate the global queue with an atomic counter. To exploit spatial locality which may be important in certain algorithms such as parallel prefix, the chunk of data assigned to a process statically or dynamically is always contiguous. 1 Recently, several researchers <ref> [LV90, TG89, ZM90] </ref> investigate the relative merits of dynamic and static scheduling policies at the operating system and application level for multiprocessors. 4 2.2 Task Granularity Task granularity has two dimensions : computation granularity and data granularity.
Reference: [PK87] <author> Constantine D. Polychronopoulos and David J. Kuck. </author> <title> Guided self-scheduling : A practical scheduling scheme for parallel supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1425-1439, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: However, it is reasonable to expect that this hypothesis may hold for other kernels that exhibit similar memory reference patterns. Alternative strategies 15 for dynamic scheduling such as guided self-scheduling, that rely on some form of compiler support, may help alleviate some of the inherent overhead in dynamic scheduling <ref> [PK87] </ref>. However, such strategies would require careful data dependence analysis at compile time. This is clearly a fruitful direction for extending our work in the scheduling dimension from the point of view of our bigger goals for the whole project.
Reference: [Seq87] <institution> Sequent Computer Systems Inc., Oregon. </institution> <note> Sequent Guide to Parallel Programming, </note> <year> 1987. </year>
Reference-contexts: Our work is more general in that we experiment with algorithms that represent classes of problems and study synchronization, scheduling and task granularity issues in implementing these algorithms. 4 Observed Results The implementations of these algorithms use the parallel programming library <ref> [Seq87] </ref> on the Sequent, and the uniform system [BBN86] on the Butterfly. In the experiments, completion time of the program is used as a measure of the performance of the parallel algorithm. The results for the uniprocessor cases are obtained by running the multiprocessor parallel algorithm on a single processor.
Reference: [SSL + 91] <author> Anand Sivasubramaniam, Gautam Shah, Joonwon Lee, Umakishore Ramachandran, and H. Venkateswaran. </author> <title> Experimental Evaluation of Algorithmic Performance on Two Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the First International Symposium on Shared Memory Multiprocessing, </booktitle> <pages> pages 13-24, </pages> <address> Tokyo, Japan, </address> <month> April </month> <year> 1991. </year>
Reference: [TG89] <author> A. Tucker and A. Gupta. </author> <title> Process Control and Scheduling Issues for Multiprogrammed Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 159-166, </pages> <year> 1989. </year> <month> 18 </month>
Reference-contexts: For the algorithms discussed in this paper, we simulate the global queue with an atomic counter. To exploit spatial locality which may be important in certain algorithms such as parallel prefix, the chunk of data assigned to a process statically or dynamically is always contiguous. 1 Recently, several researchers <ref> [LV90, TG89, ZM90] </ref> investigate the relative merits of dynamic and static scheduling policies at the operating system and application level for multiprocessors. 4 2.2 Task Granularity Task granularity has two dimensions : computation granularity and data granularity.
Reference: [Wyl79] <author> J. C. Wyllie. </author> <title> The Complexity of Parallel Computations. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1979. </year>
Reference-contexts: However, the focus of this study is to understand the performance potential of parallel algorithms and hence the earlier definition is used in the rest of the paper. 4.1 List Ranking A parallel algorithm for the list ranking problem is discussed in <ref> [Wyl79, KR90] </ref>. Figure 1 shows the algorithm and Figure 4 shows the corresponding pseudo code. The algorithm is data dependent. 6 The randomness of access of the list elements does not favor data partitioning.

References-found: 15

