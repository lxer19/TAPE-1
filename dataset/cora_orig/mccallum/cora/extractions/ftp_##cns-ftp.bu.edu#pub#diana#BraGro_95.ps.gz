URL: ftp://cns-ftp.bu.edu/pub/diana/BraGro:95.ps.gz
Refering-URL: http://www.inns.org/Misc-info/Online-pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Fast Learning VIEWNET Architectures for Recognizing 3-D Objects from Multiple 2-D Views Automatic Target Recognition
Author: Gary Bradski and Stephen Grossberg Professor Stephen Grossberg 
Note: To appear in the 1995 Neural Networks special issue on  ySupported in part by the National Science Foundation (NSF IRI-90-24877) and the Office of Naval Research (ONR N00014-92-J-1309). zSupported in part by the Air Force Office of Scientific Research (AFOSR F49620-92-J 0499) and ARPA (AFOSR 90-0083 and ONR N00014-92-J-4015). xAcknowledgments: The authors wish to thank Diana Meyers for her valuable assistance in the preparation of the manuscript.  
Address: 111 Cummington Street Boston, Massachusetts 02215  111 Cummington Street Boston, MA 02215  
Affiliation: Department of Cognitive and Neural Systems and Center for Adaptive Systems Boston University  Boston University Center for Adaptive Systems  
Date: April 20, 1995  January, 1995  
Abstract: Technical Report CAS/CNS-TR-93-053 Boston, MA: Boston University 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arrington, K. </author> <year> (1994). </year> <title> A reduction in the number of directionally selective neurons extends the spatial limit for global motion perception. </title> <journal> Vision Research, </journal> <volume> 24, </volume> <pages> 3241-3251. </pages>
Reference: <author> Asfour, Y. </author> <year> (1994). </year> <title> Neural networks for multi-sensor fusion and classification. </title> <type> Ph.D. thesis, </type> <address> Boston, MA: Boston University. </address>
Reference: <author> Asfour, Y., Carpenter, G., Grossberg, S., & Lesher, G. </author> <year> (1993a). </year> <title> Fusion ARTMAP: A neural network architecture for multi-channel data fusion and classification. </title> <booktitle> In Proceedings of the World Congress on Neural Networks, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 210-215. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum Associates. Boston University Technical Report CAS/CNS-TR-93-05. </publisher>
Reference: <author> Asfour, Y., Carpenter, G., Grossberg, S., & Lesher, G. </author> <year> (1993b). </year> <title> Fusion ARTMAP: An adaptive fuzzy network for multi-channel classification.. </title> <booktitle> In Proceedings of the Third International Conference on Industrial Fuzzy Control and Intelligent Systems, </booktitle> <pages> pp. 155-160. </pages> <address> New York, NY: </address> <publisher> IEEE Service Center. </publisher>
Reference: <author> Bowyer, K., Eggert, D., Stewman, J., & Stark, L. </author> <year> (1989). </year> <title> Developing the aspect graph representation for use in image understanding. </title> <booktitle> In Proceedings of the 1989 Image Understanding Workshop, </booktitle> <pages> pp. 831-849. </pages>
Reference: <author> Bradski, G., Carpenter, G., & Grossberg, S. </author> <year> (1992). </year> <title> Working memory networks for learning temporal order with application to 3-D visual object recognition. </title> <journal> Neural Computation, </journal> <volume> 4, </volume> <pages> 270-286. </pages>
Reference: <author> Bradski, G., Carpenter, G., & Grossberg, S. </author> <year> (1994). </year> <title> STORE working memory networks for storage and recall of arbitrary temporal sequences. </title> <journal> Biological Cybernetics, </journal> <volume> 71, </volume> <pages> 469-4880. </pages>
Reference: <author> Carpenter, G., & Grossberg, S. </author> <year> (1987). </year> <title> ART 2: Self-organization of stable category recognition codes for analog input patterns. </title> <journal> Applied Optics, </journal> <volume> 26, </volume> <pages> 4919-4930. </pages>
Reference-contexts: In order to compress this invariant spectrum and reduce 3-D foreshortening effects, the result was coarse coded (compressed to 5x5 pixels from 128x128) using Gaussian filters. The coarse coded vectors (25 data points) were fed into an ART 2 <ref> (Carpenter and Gross-berg, 1987) </ref> network for unsupervised learning and categorization.
Reference: <author> Carpenter, G., Grossberg, S., & Iizuka, K. </author> <year> (1992). </year> <title> Comparative performance measures of fuzzy artmap, learned vector quantization, and back propagation for handwritten character recognition. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> Vol. I, </volume> <pages> pp. 794-799. </pages> <address> Piscataway, NJ: </address> <publisher> IEEE Service Center. </publisher>
Reference-contexts: The output of this preprocessor is a coarse-coded, invariant spectrum of an illumination-compensated, noise-suppressed boundary segmentation. This representation provides the input vectors to the self-organizing neural network classifier. Fuzzy ARTMAP <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref> was used to categorize the output spectra. This architecture is capable of fast, stable learning of recognition categories in response to nonstationary multidimensional data, and of learning to generate many-to-one output predictions from the recognition categories to output labels. <p> Figure 10 shows the results of processing two F-18 images which are identical except for scaling and rotation. The images become very similar in the centered log-polar domain. An alternative approach to invariance filtering, called the What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref> could also have been used, and has distinct advantages for generalizing the VIEWNET architecture to scene understanding applications, as noted in Section 9. 5 Coarse coding Coarse coding reduces memory requirements, as it compensates for modest 3-D foreshortening effects and inaccuracies of figural alignment in <p> The three column images in Figure 14b show how each image in Figure 14a activates the weights of category 28 according to equation (??), which computes a normalized minimum that is closely related to the measure of fuzzy subsethood <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref>. The patterns for the non-complement coded input (top halves of Figure 14b) are all nearly identical, meaning that they all lie above the template in value. <p> is designed to autonomously search for that combination of input channels that correctly classifies each output prediction. (d) What-and-Where filter: In order to more effectively utilize the form information within the surface representation, a different invariant filter than the log polar filter can be used; for example, a What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref>. The output of log-polar-Fourier preprocessing is an invariant representation, but one that has lost information about the form of the object, as well as about the object's place in a larger scene.
Reference: <author> Carpenter, G., Grossberg, S., & Lesher, G. </author> <year> (1992). </year> <title> A what-and-where neural network for invariant image preprocessing. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> Vol. III, </volume> <pages> pp. 303-308. </pages> <address> Piscatway, NJ: </address> <publisher> IEEE Service Center. </publisher>
Reference-contexts: The output of this preprocessor is a coarse-coded, invariant spectrum of an illumination-compensated, noise-suppressed boundary segmentation. This representation provides the input vectors to the self-organizing neural network classifier. Fuzzy ARTMAP <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref> was used to categorize the output spectra. This architecture is capable of fast, stable learning of recognition categories in response to nonstationary multidimensional data, and of learning to generate many-to-one output predictions from the recognition categories to output labels. <p> Figure 10 shows the results of processing two F-18 images which are identical except for scaling and rotation. The images become very similar in the centered log-polar domain. An alternative approach to invariance filtering, called the What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref> could also have been used, and has distinct advantages for generalizing the VIEWNET architecture to scene understanding applications, as noted in Section 9. 5 Coarse coding Coarse coding reduces memory requirements, as it compensates for modest 3-D foreshortening effects and inaccuracies of figural alignment in <p> The three column images in Figure 14b show how each image in Figure 14a activates the weights of category 28 according to equation (??), which computes a normalized minimum that is closely related to the measure of fuzzy subsethood <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref>. The patterns for the non-complement coded input (top halves of Figure 14b) are all nearly identical, meaning that they all lie above the template in value. <p> is designed to autonomously search for that combination of input channels that correctly classifies each output prediction. (d) What-and-Where filter: In order to more effectively utilize the form information within the surface representation, a different invariant filter than the log polar filter can be used; for example, a What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref>. The output of log-polar-Fourier preprocessing is an invariant representation, but one that has lost information about the form of the object, as well as about the object's place in a larger scene.
Reference: <author> Carpenter, G., Grossberg, S., & Lesher, G. </author> <year> (1993). </year> <title> The what-and-where filter: A spatial mapping neural network for object recognition and image understanding. </title> <type> Tech. rep., </type> <address> Boston, MA: Boston University. Boston University CAS/CNS-TR-93-043. </address>
Reference: <author> Carpenter, G., Grossberg, S., Markuzon, N., Reynolds, J., & Rosen, D. </author> <year> (1992). </year> <title> Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3, </volume> <pages> 698-713. </pages> <note> 46 February 16, 1995 Carpenter, </note> <author> G., Grossberg, S., & Mehanian, C. </author> <year> (1989). </year> <title> Invariant recognition of cluttered scenes by a self-organizing ART architecture: CORT-X boundary segmentation. </title> <booktitle> Neural Networks, </booktitle> <volume> 2, </volume> <pages> 169-181. </pages>
Reference-contexts: The output of this preprocessor is a coarse-coded, invariant spectrum of an illumination-compensated, noise-suppressed boundary segmentation. This representation provides the input vectors to the self-organizing neural network classifier. Fuzzy ARTMAP <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref> was used to categorize the output spectra. This architecture is capable of fast, stable learning of recognition categories in response to nonstationary multidimensional data, and of learning to generate many-to-one output predictions from the recognition categories to output labels. <p> Figure 10 shows the results of processing two F-18 images which are identical except for scaling and rotation. The images become very similar in the centered log-polar domain. An alternative approach to invariance filtering, called the What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref> could also have been used, and has distinct advantages for generalizing the VIEWNET architecture to scene understanding applications, as noted in Section 9. 5 Coarse coding Coarse coding reduces memory requirements, as it compensates for modest 3-D foreshortening effects and inaccuracies of figural alignment in <p> The three column images in Figure 14b show how each image in Figure 14a activates the weights of category 28 according to equation (??), which computes a normalized minimum that is closely related to the measure of fuzzy subsethood <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref>. The patterns for the non-complement coded input (top halves of Figure 14b) are all nearly identical, meaning that they all lie above the template in value. <p> is designed to autonomously search for that combination of input channels that correctly classifies each output prediction. (d) What-and-Where filter: In order to more effectively utilize the form information within the surface representation, a different invariant filter than the log polar filter can be used; for example, a What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref>. The output of log-polar-Fourier preprocessing is an invariant representation, but one that has lost information about the form of the object, as well as about the object's place in a larger scene.
Reference: <author> Carpenter, G., Grossberg, S., & Reynolds, J. </author> <year> (1993). </year> <title> Fuzzy ARTMAP, slow learning and probability estimation. </title> <journal> IEEE Transactions on Neural Networks, </journal> <note> in press. </note> <institution> Boston, MA: Boston University. Boston University Technical Report CAS/CNS-TR-93-014. </institution>
Reference: <author> Carpenter, G., Grossberg, S., & Rosen, D. </author> <year> (1991). </year> <title> Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system. </title> <booktitle> Neural Networks, </booktitle> <volume> 4, </volume> <pages> 493-504. </pages>
Reference-contexts: We utilized the simplified version of the Fuzzy ARTMAP network of Carpenter, Grossberg, Markuzon, Reynolds, and Rosen, (1992) that was employed in Carpenter, Grossberg, and Iizuka (1992). This circuit consists of a Fuzzy ART module <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref> ART a that learns 2-D view categories and a field of 3-D object category output nodes F b . The 2-D view and 3-D object category nodes are linked together by an associative memory F ab that is called the Map Field (Figure 12). <p> Complement coding also normalizes the total input A p to ART a such that k A p k 1 = 1. It thereby prevents a category proliferation problem that could otherwise occur <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref>. Complement coding means intuitively that an input vector turns ON the cells corresponding to a p as it turns OFF the cells corresponding to a c p , much as in the ON and OFF channels of the CORT-X 2 filter.
Reference: <author> Chang, I., & Huang, C. </author> <year> (1992). </year> <title> Aspect graph generation for non-convex polyhedra from perspective projection view. </title> <journal> Pattern Recognition, </journal> <volume> 25, </volume> <pages> 1075. </pages>
Reference: <author> Chen, S., & Freeman, H. </author> <year> (1990). </year> <title> Computing characteristic views of quadric-surfaced solids. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition. </booktitle>
Reference: <author> Dickinson, S., Pentlend, A., & Rosenfeld, A. </author> <year> (1992). </year> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14, </volume> <pages> 174-198. </pages>
Reference: <author> Edelman, S., Bulthoff, H., & Weinshall, D. </author> <year> (1989). </year> <title> Stimulus familiarity determines recognition strategy for novel 3-D objects. </title> <type> Tech. rep., </type> <address> Cambridge, MA: </address> <publisher> MIT. MIT AI Lab Memo no. </publisher> <pages> 1138. </pages>
Reference: <author> Eggert, D., & Bowyer, K. </author> <year> (1993). </year> <title> Computing the perspective projection aspect graph of solids of revolution. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15, </volume> <pages> 109. </pages>
Reference: <author> Fekete, G., & Davis, L. </author> <year> (1984). </year> <title> Property spheres: A new representation for 3-D object recognition. </title> <booktitle> In Proceedings of the 1984 IEEE Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pp. 192-201. </pages>
Reference: <author> Freeman, H., & Chakravarty, I. </author> <year> (1980). </year> <title> The use of characteristic views in the recognition of three-dimensional objects. </title> <editor> In Gelsema, E., & Kanal, L. N. (Eds.), </editor> <booktitle> Pattern Recognition in Practice. </booktitle> <address> New York, NY: </address> <publisher> North-Holland. </publisher>
Reference: <author> Gigus, Z., & Malik, J. </author> <year> (1988). </year> <title> Computing the aspect graph for line drawings of polyhedral objects. </title> <booktitle> In Proceedings of the IEEE Conference on Computing Vision Pattern Recognition, </booktitle> <pages> pp. 654-661. </pages>
Reference: <author> Gigus, Z., & Malik, J. </author> <year> (1990). </year> <title> Computing the aspect graph for line drawings of polyhedral objects. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Vision, </journal> <volume> 12, </volume> <pages> 113. </pages>
Reference: <author> Goodale, M., & Milner, D. </author> <year> (1992). </year> <title> Separate visual pathways for perception and action. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 15, </volume> <pages> 20-25. </pages> <note> 47 February 16, 1995 Grossberg, </note> <author> S. </author> <year> (1978a). </year> <title> Behavioral contrast in short-term memory: Serial binary memory models or parallel continuous memory models?. </title> <journal> Journal of Mathematical Psychology, </journal> <volume> 17, </volume> <pages> 199-219. </pages>
Reference: <author> Grossberg, S. </author> <year> (1978b). </year> <title> A theory of human memory: Self-organization and performance of sensory-motor codes, maps, and plans. </title> <editor> In Rosen, R., & Snell, F. (Eds.), </editor> <booktitle> Progress in Theoretical Biology, </booktitle> <volume> Vol. 5, </volume> <pages> pp. 233-374. </pages> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Grossberg, S. </author> <year> (1987). </year> <title> Cortical dynamics of three-dimensional form, color, and brightness perception. I: </title> <journal> Monocular theory. Perception and Psychophysics, </journal> <volume> 41, </volume> <pages> 87-1116. </pages>
Reference: <author> Grossberg, S. </author> <year> (1994). </year> <title> 3-D vision and figure-ground separation by visual cortex. </title> <journal> Perception and Psychophysics, </journal> <volume> 55, </volume> <pages> 48-120. </pages>
Reference-contexts: VIEWNET architectures may also be upgraded in several ways to handle more complex scene understanding problems. These enhancements could include: (a) Boundary Segmentation: A more powerful boundary segmenter than a CORT-X filter, such as a BCS model <ref> (as in Grossberg, Mingolla, and Williamson, 1994) </ref>, can segment much sparser and noisier images.
Reference: <author> Grossberg, S., & Mingolla, E. </author> <year> (1985). </year> <title> Neural dynamics of perceptual grouping: Boundary completion, illusory figures, and neon color spreading. </title> <journal> Psychological Review, </journal> <volume> 92, </volume> <pages> 173-211. </pages>
Reference: <author> Grossberg, S., Mingolla, E., & Todorovic, D. </author> <year> (1989). </year> <title> A neural network architecture for preattentive vision. </title> <journal> IEEE Transactions on Biomedical Engineering, </journal> <volume> 36, </volume> <pages> 79-102. </pages>
Reference-contexts: This is a feedfor-ward network that detects, regularizes, and completes image boundaries from edge, texture and shading contrasts, while suppressing noise that does not have an underlying anisotropic structure. The CORT-X 2 filter is an enhancement of the original CORT-X filter <ref> (Carpenter, Grossberg, and Mehanian, 1989) </ref>. It generates better boundary segmentations, deals better with noise, and may also be used for figure-ground separation. The figure-ground separation properties were not needed in this research because the data images were already separated from their backgrounds.
Reference: <author> Grossberg, S., Mingolla, E., & Williamson, J. </author> <year> (1994). </year> <title> Synthetic aperture radar processing by a multiple scale neural system for boundary and surface representation. </title> <type> Tech. rep., </type> <institution> Boston, MA: Boston University. Boston University Technical Report CAS/CNS-TR-94-001. </institution>
Reference-contexts: VIEWNET architectures may also be upgraded in several ways to handle more complex scene understanding problems. These enhancements could include: (a) Boundary Segmentation: A more powerful boundary segmenter than a CORT-X filter, such as a BCS model <ref> (as in Grossberg, Mingolla, and Williamson, 1994) </ref>, can segment much sparser and noisier images.
Reference: <author> Grossberg, S., & Todorovic, D. </author> <year> (1988). </year> <title> Neural dynamics of 1-D and 2-D brightness perception: A unified model of classical and recent phenomena. </title> <journal> Perception and Psychophysics, </journal> <volume> 43, </volume> <pages> 241-277. </pages>
Reference: <author> Grossberg, S., & Wyse, L. </author> <year> (1991). </year> <title> A neural network architecture for figure-ground separation of connected scenic figures. </title> <booktitle> Neural Networks, </booktitle> <volume> 4, </volume> <pages> 723-742. </pages>
Reference-contexts: We utilized the simplified version of the Fuzzy ARTMAP network of Carpenter, Grossberg, Markuzon, Reynolds, and Rosen, (1992) that was employed in Carpenter, Grossberg, and Iizuka (1992). This circuit consists of a Fuzzy ART module <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref> ART a that learns 2-D view categories and a field of 3-D object category output nodes F b . The 2-D view and 3-D object category nodes are linked together by an associative memory F ab that is called the Map Field (Figure 12). <p> Complement coding also normalizes the total input A p to ART a such that k A p k 1 = 1. It thereby prevents a category proliferation problem that could otherwise occur <ref> (Carpenter, Grossberg, and Rosen, 1991) </ref>. Complement coding means intuitively that an input vector turns ON the cells corresponding to a p as it turns OFF the cells corresponding to a c p , much as in the ON and OFF channels of the CORT-X 2 filter.
Reference: <author> Grossberg, S., & Wyse, L. </author> <year> (1992). </year> <title> A neural network architecture for figure-ground separation of connected scenic figures. </title> <editor> In Pinter, R., & Nabet, B. (Eds.), </editor> <title> Nonlinear Vision: Determination of Neural Receptive Fields, Function, </title> <booktitle> and Networks, </booktitle> <pages> pp. 516-543. </pages> <address> Boca Raton, FL: </address> <publisher> CRC Press, Inc. </publisher>
Reference-contexts: The output of this preprocessor is a coarse-coded, invariant spectrum of an illumination-compensated, noise-suppressed boundary segmentation. This representation provides the input vectors to the self-organizing neural network classifier. Fuzzy ARTMAP <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref> was used to categorize the output spectra. This architecture is capable of fast, stable learning of recognition categories in response to nonstationary multidimensional data, and of learning to generate many-to-one output predictions from the recognition categories to output labels. <p> Figure 10 shows the results of processing two F-18 images which are identical except for scaling and rotation. The images become very similar in the centered log-polar domain. An alternative approach to invariance filtering, called the What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref> could also have been used, and has distinct advantages for generalizing the VIEWNET architecture to scene understanding applications, as noted in Section 9. 5 Coarse coding Coarse coding reduces memory requirements, as it compensates for modest 3-D foreshortening effects and inaccuracies of figural alignment in <p> The three column images in Figure 14b show how each image in Figure 14a activates the weights of category 28 according to equation (??), which computes a normalized minimum that is closely related to the measure of fuzzy subsethood <ref> (Carpenter, Grossberg, Markuzon, Reynolds and Rosen, 1992) </ref>. The patterns for the non-complement coded input (top halves of Figure 14b) are all nearly identical, meaning that they all lie above the template in value. <p> is designed to autonomously search for that combination of input channels that correctly classifies each output prediction. (d) What-and-Where filter: In order to more effectively utilize the form information within the surface representation, a different invariant filter than the log polar filter can be used; for example, a What-and-Where filter <ref> (Carpenter, Grossberg, and Lesher, 1992, 1993) </ref>. The output of log-polar-Fourier preprocessing is an invariant representation, but one that has lost information about the form of the object, as well as about the object's place in a larger scene.
Reference: <author> Koenderink, J., & van Doorn, A. </author> <year> (1979). </year> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics., </journal> <volume> 32, </volume> <pages> 211-216. </pages>
Reference: <author> Liu, C., & Tsai, W. H. </author> <year> (1990). </year> <title> 3-D curved object recognition from multiple 3-D camera views. Computer Vision, Graphics, </title> <booktitle> Image Processing, </booktitle> <volume> 50, </volume> <pages> 177-187. </pages>
Reference: <author> Logothetis, N., Pauls, J., Buelthoff, H., & Poggio, T. </author> <year> (1994). </year> <title> View-dependent object recognition by monkeys. </title> <booktitle> Current Biology, </booktitle> <volume> 4, </volume> <pages> 401. </pages>
Reference-contexts: A similar type of hierarchical organization from 2-D view to 3-D object has been reported in neurophysiological studies of cell responses in monkey inferotemporal cortex, where some cells respond to individual 2-D views whereas others, like 3-D object nodes, respond to a wide range of views <ref> (Logothetis et al., 1994) </ref>. These studies were motivated by the regularization networks of Poggio and Girosi (1990) which also add up responses from 2-D views at 3-D object nodes. These networks do not, however, incrementally learn their categories in real-time and have not yet been incorporated into a self-organizing architecture.
Reference: <author> Martin, W., & Aggarwal, J. </author> <year> (1983). </year> <title> Volumetric descriptions of objects from multiple views. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5, </volume> <pages> 150-158. </pages> <note> 48 February 16, 1995 Mishkin, </note> <author> M., Ungerleider, L., & Macko, K. </author> <year> (1983). </year> <title> Object vision and spatial vision: two cortical pathways. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 6, </volume> <pages> 414-417. </pages>
Reference: <author> Plantinga, H., & Dyer, C. </author> <year> (1990). </year> <title> Visibility, occlusion, and the aspect graph. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5, </volume> <pages> 137-160. </pages>
Reference: <author> Poggio, T., & Edelman, S. </author> <year> (1990). </year> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343, </volume> <pages> 263-266. </pages>
Reference: <author> Ponce, J., & Kriegman, D. </author> <year> (1990). </year> <title> Computing exact aspect graphs of curved objects: Parametric surfaces. </title> <booktitle> In Proceedings of the 8th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1074-1079. </pages>
Reference: <author> Rieger, J. </author> <year> (1990). </year> <title> The geometry of view space opaque objects bounded by smooth surfaces. </title> <journal> Artificial Intelligence, </journal> <volume> 44, </volume> <pages> 1-40. </pages>
Reference: <author> Rimey, R., & Brown, C. </author> <year> (1991). </year> <title> Hmms and vision: Representing structure and sequences for active vision using hidden markov models. </title> <type> Tech. rep., </type> <institution> Rochester, NY: University of Rochester. University of Rochester Computer Science Department TR-366. </institution>
Reference: <author> Schwartz, E. </author> <year> (1977). </year> <title> Spatial mapping in primate sensory projection: analytic structure and relevance to perception. </title> <journal> Biological Cybernetics, </journal> <volume> 25, </volume> <pages> 181-194. </pages>
Reference-contexts: A log-polar transform is then taken with respect to the center of the image. Each point (x; y) is represented as re i . Taking the logarithm yields coordinates of log radial magnitude and angle. As is well known <ref> (Schwartz, 1977) </ref>, figural sizes and rotations are converted into figural shifts under log-polar transformation. Using these shift parameters to center the log-polar transformed image leads to a figural representation that is invariant under 2-D changes in position, size and rotation.
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1990a). </year> <title> Learning aspect graph representations of 3-D objects in a neural network. </title> <booktitle> In Proceedings of International Joint Conference on Neural Networks (IJCNN-90), Washington, D.C., </booktitle> <volume> Vol. 2, </volume> <pages> pp. 233-236. </pages>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1990b). </year> <title> Learning aspect graph representations from view sequences. </title> <editor> In Touretzky, D. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pp. 258-265. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishing. </publisher>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1991). </year> <title> Learning and recognizing 3-D objects from multiple views in a neural system. </title> <editor> In Wechsler, H. (Ed.), </editor> <title> Neural Networks for Perception. </title> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Seibert, M., & Waxman, A. </author> <year> (1992). </year> <title> Adaptive 3-D-object recognition from multiple views. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11, </volume> <pages> 107-124. </pages>
Reference: <author> Sripradisvarakul, T., & Jain, R. </author> <year> (1989). </year> <title> Generating aspect graphs for curved objects. </title> <booktitle> In Proceedings of the IEEE Workshop Interpretation of 3-D Scenes, </booktitle> <pages> pp. 109-115. </pages>
Reference: <author> Stewmen, J., & Bowyer, K. </author> <year> (1990). </year> <title> Direct construction of the perspective projection aspect graph of convex polyhedra. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 51, </volume> <pages> 20. </pages>
Reference: <author> Underwood, S., & Coates, C. </author> <year> (1975). </year> <title> Visual learning from multiple views. </title> <journal> IEEE Transactions on Computing, </journal> <volume> 24, </volume> <pages> 651-661. </pages>
Reference: <author> Ungerleider, L., & Mishkin, M. </author> <year> (1982). </year> <title> Two cortical visual systems. </title> <editor> In Ingle, D., Goodale, M., & Mansfield, R. (Eds.), </editor> <booktitle> Analysis of Visual Behavior, </booktitle> <pages> pp. 549-586. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <month> 49 February 16, </month> <note> 1995 Winston, </note> <author> P. </author> <year> (1975). </year> <title> The Psychology of Computer Vision. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Zadeh, L. </author> <year> (1965). </year> <title> Fuzzy sets. </title> <journal> Information Control, </journal> <volume> 8, </volume> <pages> 338-353. </pages>
Reference-contexts: (p k ; q k ) (35) February 16, 1995 of input vector a to Fuzzy ART module ART a and the subsequent processing that causes the network to predict the 3-D object represented by the input 2-D view. 43 February 16, 1995 for M -dimensional vectors p and q <ref> (Zadeh, 1965) </ref>. If more than one T a j is maximal, the category j with the smallest index is chosen.
Reference: <author> Zhang, S., Sullivan, G., & Baker, K. </author> <year> (1992). </year> <title> Relational model construction and 3-D object recognition from single 2-D monochromatic images. </title> <journal> Image and Vision Computing, </journal> <volume> 10, </volume> <pages> 313. </pages>
References-found: 53

