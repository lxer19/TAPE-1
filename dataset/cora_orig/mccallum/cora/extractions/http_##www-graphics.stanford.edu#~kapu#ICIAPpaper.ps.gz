URL: http://www-graphics.stanford.edu/~kapu/ICIAPpaper.ps.gz
Refering-URL: http://www-graphics.stanford.edu/~kapu/resume.html
Root-URL: http://www.cs.stanford.edu
Phone: 2  
Title: Surface modeling and display from range and color data  
Author: Kari Pulli Michael Cohen Tom Duchamp Hugues Hoppe John McDonald Linda Shapiro and Werner Stuetzle 
Address: Seattle WA, USA  Redmond WA, USA  
Affiliation: 1 University of Washington,  Microsoft Research,  
Abstract: Two approaches for modeling surfaces from a collection of range maps and associated color images are covered. The first approach presents a method that robustly obtains a closed mesh that approximates the object geometry. The mesh can then be simplified and texture mapped for display. The second approach does not attempt to create a single object model. Instead, a set of models is constructed, one model for each view of the object. several of the view-based models are rendered separately, and their information is combined in a view-dependent manner for display.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. Curless and M. Levoy. </author> <title> A volumetric method for building complex models from range images. </title> <booktitle> In Proceedings of SIGGRAPH '96, </booktitle> <pages> pages 303-312, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Our surface estimate will be the closed boundary between these sets. This definition allows us to create a plausible surface even at locations where we failed to obtain data <ref> [1] </ref>. The boundary is represented as a collection of vertices and triangles that can be easily combined to form a mesh. <p> It is important to notice that holes often can be correctly detected and modeled using only indirect evidence, i.e., using the fact that the scanner can see through the hole. Curless and Levoy suggest using a backdrop <ref> [1] </ref>, placing planes behind the holes that can be detected. However, all range scanning methods based on optical triangulation have limits on how narrow cavities can be scanned. <p> Some methods that employ signed surface distance functions are unable to correctly reconstruct thin objects. Curless and Levoy <ref> [1] </ref>, for example, build a distance function by storing positive distances to voxels in front of the surface and negative distances to voxels behind the surface. In addition to the distance, weights are stored to facilitate combining data from different views.
Reference: 2. <author> P. E. Debevec, C. J. Taylor, and J. Malik. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach. </title> <booktitle> In SIGGRAPH 96 Conference Proceedings, </booktitle> <pages> pages 11-20. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference-contexts: As illustrated by Figure 8 (c), the blend weight linearly increases with distance from the mesh boundary. Like w ' , the weight w fl does not depend on the viewing direction of the virtual camera. A similar weight was used by Debevec et al. <ref> [2] </ref>. Fig. 8. (a) An image of a toy dog. (b) Weight w ' is applied to each face of the triangle mesh. (c) Weight w fl smoothly decreases the influence of the view towards the mesh boundaries.
Reference: 3. <author> M. Garland and P. Heckbert. </author> <title> Fast polygonal approximation of terrains and height fields. </title> <type> Technical Report CMU-CS-95-181, </type> <institution> Dept. of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1995. </year>
Reference-contexts: Points whose position and color match the data scanned from an empty scene can be classified as background. The adding of vertices is easily automated. For example, Garland and Heckbert <ref> [3] </ref> add vertices to image coordinates where the current approximation is worst. The drawback of this approach is that if the data contains step edges due to self-occlusions, the mesh is likely to become unnecessarily dense before a good approximation is achieved.
Reference: 4. <author> S. J. Gortler, R. Grzeszczuk, R. Szeliski, and M. F. Cohen. </author> <booktitle> The lumigraph. In SIGGRAPH 96 Conference Proceedings, </booktitle> <pages> pages 43-54. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference: 5. <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle. </author> <title> Surface reconstruction from unorganized points. </title> <booktitle> In Proceedings of SIGGRAPH '92, </booktitle> <pages> pages 71-78, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: One of the real data sets consisting of eight views of a miniature chair is shown in Fig. 3, along with the data points, and failed surface reconstruction from another algorithm <ref> [5] </ref> that was our original motivation for this method. Even though we have cleaned the data and removed most of the outliers, some noisy measurements close to the surface remain, especially between the spokes of the back support of the chair. The algorithm from [5] works with an unorganized point cloud <p> failed surface reconstruction from another algorithm <ref> [5] </ref> that was our original motivation for this method. Even though we have cleaned the data and removed most of the outliers, some noisy measurements close to the surface remain, especially between the spokes of the back support of the chair. The algorithm from [5] works with an unorganized point cloud and does not use any extra knowledge (such as viewing directions, etc.) in addition to the points. It works quite nicely if the data does not contain outliers and uniformly samples the underlying surface.
Reference: 6. <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle. </author> <title> Mesh optimization. </title> <booktitle> In Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 19-26, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Fig. 5 also shows the results from a synthetic data set. The smoothed result appears above, while the result after applying Hoppe's mesh optimization algorithm <ref> [6] </ref> appears below. Fig. 5: Simulated temple data set, our results and a simplified mesh. 2.5 Discussion The simplicity of the algorithm leads to a fast implementation. This again allows interactive selection of the subdivision level. <p> The drawback of this approach is that if the data contains step edges due to self-occlusions, the mesh is likely to become unnecessarily dense before a good approximation is achieved. For this reason we will perform a mesh simplification step using the mesh optimization methods by Hoppe et al. <ref> [6] </ref>. Rendering. We have built an interactive viewer for viewing the reconstructed images (see Figure 10). For each frame, we calculate the dot product of the camera viewing directions for the stored views and the viewing direction of the virtual camera.
Reference: 7. <author> M. Levoy and P. Hanrahan. </author> <title> Light field rendering. </title> <booktitle> In SIGGRAPH 96 Conference Proceedings, </booktitle> <pages> pages 31-42. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference: 8. <author> K. Pulli, M. Cohen, T. Duchamp, H. Hoppe, L. Shapiro, and W. Stuetzle. </author> <title> View-based rendering: Visualizing real objects from scanned range and color data. </title> <type> Technical Report UW-CSE-97-04-01, </type> <institution> Univ. of Washington, </institution> <address> Seattle WA 98105, </address> <year> 1997. </year> <note> Available through ftp://ftp.cs.washington.edu/tr/1997/04/UW-CSE-97-04-01.d. </note>
Reference-contexts: Our second method shows that it is not necessary to integrate the input data into a single surface model for display purposes. Instead, one can model each view separately and integrate the separate views at display time in the image space. We call this approach view-based rendering <ref> [8] </ref>. Section 2 describes our robust method for modeling object surfaces. Section 3 presents the view-based rendering method. Section 4 concludes the paper. 2 Robust approximate meshes Overview. Our algorithm processes a cubical volume surrounding all the input data in a hierarchical fashion.
Reference: 9. <author> K. Pulli, T. Duchamp, H. Hoppe, John McDonald, L. Shapiro, and W. Stuetzle. </author> <title> Robust meshes from multiple range maps. </title> <booktitle> In Proc. IEEE Int. Conf. on 3-D Imaging and Modeling, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: The first method follows the traditional surface reconstruction approach, where we attempt to create a single surface model that accurately describes the scanned object. Specifically, our algorithm <ref> [9] </ref> emphasizes robust recovery of the object topology from the input data. Holes due to missing data, i.e., unobserved surface regions, are automatically filled so that the model remains consistent with the input data.
Reference: 10. <author> R. Szeliski. </author> <title> Rapid octree construction from image sequences. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 58(1) </volume> <pages> 23-32, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Similarly, a boundary label overrides a previous inside label, in which case the cube's descendants must be recursively tested, potentially up to the maximum subdivision level. Although both processing orders produce the same result, the simultaneous processing order is in general faster <ref> [10] </ref>. In sequential processing the silhouette of the object often creates a visual cone (centered at the sensor) that separates volumes known to be outside from those speculated to be inside. The algorithm would have to recurse up to the finest subdivision level to accurately determine this boundary.
Reference: 11. <author> G. Taubin. </author> <title> A signal processing approach to fair surface design. </title> <booktitle> In Proceedings of SIGGRAPH '95, </booktitle> <pages> pages 351-358, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Fig. 4. Chair after 4, 5, 6, and 7 subdivisions. using the chair data set, displaying the octree after 4, 5, 6, and 7 subdivisions. The final mesh in Fig. 3 was obtained from the level 7 octree. We smooth the mesh before displaying using Taubin's method <ref> [11] </ref>. Notice that the spokes and the holes between them have been robustly recovered despite the large number of outliers and some missing data.
References-found: 11

