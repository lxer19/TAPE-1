URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-324.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: pinhanez bobick@media.mit.edu  
Title: Using Computer Vision to Control TV Cameras  
Author: Claudio S. Pinhanez and Aaron F. Bobick 
Note: Intelligent Studios:  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 324 To appear in the IJCAI'95 Workshop on Entertainment and AI/Alife April 1995 Abstract This paper demonstrates that automatic framing of TV shows is an interesting and tractable domain for both Computer Vision and Artificial Intelligence. Our basic goal is to build intelligent robotic cameras (SmartCams) able to frame subjects and objects in a TV studio upon verbal request from a TV director. To cope with the problem of relating visual imagery to symbolic knowledge about the scene, we propose the use of an architecture based on two levels of representation. High level approximate world models roughly describe the objects and the occurring actions. Low level view representations are obtained by vision routines selected according to the present state of the world, as described by the approximate models. The approximate world models are updated by contextual information extracted from the script of the TV show and by processing the imagery gathered by wide-angle, low-resolution cameras monitoring the studio. Our Intelligent Studio is composed of one or more SmartCams which share the representations of an approximate world model of the studio. A prototype has been implemented, and some examples of the cameras' responses to different requests are shown in the domain of a cooking show.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John Yiannis Aloimonos. </author> <title> Purposive and qualitative active vision. </title> <booktitle> In Proc. of Image Understanding Workshop, </booktitle> <pages> pages 816-828, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: The appropriateness of 3D models and high level knowledge for task control is also subject of debate [3]. Purposive vision has been proposed as the alternative to the reconstructionist approach <ref> [1] </ref>. In this case, the vision algorithms are designed to provide answers for specific task requirements and the information gathered by such routines is hardly usable by any other task or module. <p> The motivation for our approach comes from the observation that many visual tasks can be performed using simple, view-based techniques if certain constraints are known to hold <ref> [14, 1] </ref>. For example, suppose one is trying to maintain the fixation of a camera on a moving person's head. If the system knows approximately where the head is within the view, then fast, simple motion- and template-based methods are sufficient to effectively track the head. <p> We employ a multi-representational system (reminiscent of [2]) where the right representation for a given object is selected depending upon the task and the situation. Our proposal falls between the strict reconstruc-tionist and purely purposive strategies currently debated in the community <ref> [1, 11] </ref>. We have demonstrated encouraging results in the domain of the Intelligent Studio, using SmartCams to interactively respond to a director's request for particular shots of a cooking show. One of our major goals is to eliminate explicit time references from the script.
Reference: [2] <author> Aaron F. Bobick and Robert C. Bolles. </author> <title> Representation space: An approach to the integration of visual information. </title> <booktitle> In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 492-499, </pages> <address> San Diego, California, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Our basic idea is to construct an approximate world model used to determine which vision routines, representations, and control mechanisms should be applied in the current situation. We employ a multi-representational system (reminiscent of <ref> [2] </ref>) where the right representation for a given object is selected depending upon the task and the situation. Our proposal falls between the strict reconstruc-tionist and purely purposive strategies currently debated in the community [1, 11].
Reference: [3] <author> Rodney Brooks. </author> <title> Intelligence without reason. </title> <type> Memo 1293, </type> <institution> MIT A.I. Lab., </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: The appropriateness of 3D models and high level knowledge for task control is also subject of debate <ref> [3] </ref>. Purposive vision has been proposed as the alternative to the reconstructionist approach [1]. In this case, the vision algorithms are designed to provide answers for specific task requirements and the information gathered by such routines is hardly usable by any other task or module.
Reference: [4] <author> Trevor Darrel, Pattie Maes, Bruce Blumberg, and Alex Pentland. </author> <title> A novel environment for situated vision and behavior. </title> <booktitle> In Proc. of CVPR-94 Workshop for Visual Behaviors, </booktitle> <pages> pages 68-72, </pages> <address> Seattle, Washing-ton, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The work of Prokopowicz et al. [12] examines some typical characteristics of such a language. The use of approximate world models can significantly increase the expressiveness of such languages. For commercial SmartCams, a major concern is certainly real-time processing. The project ALIVE <ref> [4] </ref> has shown that real time scene understanding is possible in very constrained domains, with basic vision routines of complexity similar to ours. Our present system runs about one order of magnitude slower than real-time, without using any special hardware for vision processing and doing the reasoning processing in LISP.
Reference: [5] <author> Steven M. </author> <title> Drucker. Intelligent Camera Control for Graphical Environments. </title> <type> PhD thesis, </type> <institution> MIT, Program in Media Arts & Sciences, </institution> <year> 1994. </year>
Reference-contexts: It has been shown by Drucker <ref> [5] </ref> that framing can be mathematically modeled as a minimization process subjected to many constraints, provided that the system has precise knowledge about 3D shape, position and movement of all the objects. His work, however, is mainly concerned with highly mobile cameras, such as those modeled by computer graphics animations.
Reference: [6] <author> Daniel D. Fu, Kristian J. Hammond, and Michael J. Swain. </author> <title> Vision and navigation in man-made environments: Looking for syrup in all right places. </title> <booktitle> In Proc. of CVPR-94 Workshop for Visual Behaviors, </booktitle> <pages> pages 20-26, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference: [7] <author> Ramesh C. Jain and Thomas O. Binford. </author> <title> Ignorance, </title> <booktitle> myopia, and naivete in computer vision systems. CVGIP: Image Understanding, </booktitle> <volume> 53(1) </volume> <pages> 112-117, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Basically, the imagery is extensively analyzed in order to three-dimensionally model the objects in the scene. Any task then refers exclusively to the reconstructed 3D-models to obtain information about the scene. The reconstructionist approach has been criticized on the grounds of feasibility <ref> [7] </ref>, partially due to the fact that reconstruction requires precise algorithms which are quite susceptible to noisy images and to camera calibration. The appropriateness of 3D models and high level knowledge for task control is also subject of debate [3].
Reference: [8] <author> David Kline. </author> <title> Align and conquer. </title> <booktitle> Wired, </booktitle> <pages> pages 110-115;164, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: There are reasons to believe that the demand for TV programs is going to increase in the near future, particularly with the implementation of distribution centers of video on demand <ref> [8] </ref>. The prospect of having an on-line distributor of video in each small town, or each district in larger cities, opens new opportunities for TV programs dedicated to specialized and local communities.
Reference: [9] <author> David Marr and H. K. Nishihara. </author> <title> Representation and recognition of the spatial organization of three-dimensional shapes. </title> <journal> In Proc. R. Soc. Lond. B, </journal> <volume> volume 200, </volume> <pages> pages 269-294, </pages> <year> 1978. </year>
Reference-contexts: The traditional answer of computer vision research for the first two problems is what is known as the reconstruc-tionist approach <ref> [9] </ref>. Basically, the imagery is extensively analyzed in order to three-dimensionally model the objects in the scene. Any task then refers exclusively to the reconstructed 3D-models to obtain information about the scene.
Reference: [10] <author> Darren Newtson, Gretchen Engquist, and Joyce Bois. </author> <title> The objective basis of behavior units. </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> 35(12) </volume> <pages> 847-862, </pages> <month> De-cember </month> <year> 1977. </year>
Reference-contexts: The goal is have the script as a description of the sequence of events that are likely to occur, and a system able to identify the start and the end of actions, and to recognize them. The findings of Newtson et al. <ref> [10] </ref> and Thibadeau [16] show that subjects largely agree about the segmentation points between different actions, and that the expectation about the next action plays a fundamental role in the recognition and in the segmentation processes.
Reference: [11] <author> Claudio S. Pinhanez. </author> <title> Controlling a highly reactive camera using a subsumption architecture. </title> <booktitle> In Proc. of Applications of AI 93: Machine Vision and Robotics, </booktitle> <pages> pages 100-111, </pages> <address> Orlando, Florida, </address> <year> 1993. </year>
Reference-contexts: We employ a multi-representational system (reminiscent of [2]) where the right representation for a given object is selected depending upon the task and the situation. Our proposal falls between the strict reconstruc-tionist and purely purposive strategies currently debated in the community <ref> [1, 11] </ref>. We have demonstrated encouraging results in the domain of the Intelligent Studio, using SmartCams to interactively respond to a director's request for particular shots of a cooking show. One of our major goals is to eliminate explicit time references from the script.
Reference: [12] <author> Peter N. Prokopowicz, Michael J. Swain, and Roger E. Kahn. </author> <title> Task and environment-sensitive tracking. </title> <booktitle> In Proc. of CVPR-94 Workshop for Visual Behaviors, </booktitle> <pages> pages 73-78, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The work of Prokopowicz et al. <ref> [12] </ref> examines some typical characteristics of such a language. The use of approximate world models can significantly increase the expressiveness of such languages. For commercial SmartCams, a major concern is certainly real-time processing.
Reference: [13] <author> Raymond Rimey and Christopher Brown. </author> <title> Control of selective perception using bayes nets and decision theory. </title> <journal> IJCV, </journal> 12(2/3):173-207, 1994. <volume> 7 </volume>
Reference: [14] <author> Thomas M. Strat and Martin A. Fischler. </author> <title> Context--based vision: Recognizing objects using information from both 2-d and 3-d imagery. </title> <journal> IEEE PAMI, </journal> <volume> 13(10) </volume> <pages> 1050-1065, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The motivation for our approach comes from the observation that many visual tasks can be performed using simple, view-based techniques if certain constraints are known to hold <ref> [14, 1] </ref>. For example, suppose one is trying to maintain the fixation of a camera on a moving person's head. If the system knows approximately where the head is within the view, then fast, simple motion- and template-based methods are sufficient to effectively track the head.
Reference: [15] <author> Michael J. Tarr and Michael J. Black. </author> <title> A computational and evolutionary perspective of the role of representation in vision. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 60(1) </volume> <pages> 65-73, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The major problem with this approach is that it is difficult to incorporate high level knowledge into the system, compromising its robustness and adaptability. The reconstructionism vs. purposivism debate is still a central issue in computer vision (see <ref> [15] </ref> and the replies in the same issue). Our proposal combines both approaches by approxi 2 mately reconstructing the world, only to a level such that specific, purposive vision routines can be selected for each task.
Reference: [16] <author> Robert Thibadeau. </author> <title> Artificial perception of actions. </title> <journal> Cognitive Science, </journal> <volume> 10 </volume> <pages> 117-149, </pages> <year> 1986. </year>
Reference-contexts: The goal is have the script as a description of the sequence of events that are likely to occur, and a system able to identify the start and the end of actions, and to recognize them. The findings of Newtson et al. [10] and Thibadeau <ref> [16] </ref> show that subjects largely agree about the segmentation points between different actions, and that the expectation about the next action plays a fundamental role in the recognition and in the segmentation processes.
Reference: [17] <author> H. Zettl. </author> <title> Television Production Handbook. </title> <publisher> Wadsworth Publishing, </publisher> <address> Belmont, California, 4th edition, </address> <year> 1984. </year> <month> 8 </month>
Reference-contexts: The height of the eyes is used, for instance, in a rule of thumb that states that eyes in a close-up should be leveled at two thirds of the height of the screen (see <ref> [17] </ref>, pp.111-122, for this and other simple rules). Moreover, framing changes according to the current action of the subjects. If an object is being manipulated, either it is fully included or it is put outside of the frame.
References-found: 17

