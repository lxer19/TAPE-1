URL: http://www.cs.indiana.edu/l/www/pub/leake/leake/p-97-02.ps.Z
Refering-URL: http://www.cs.indiana.edu/l/www/pub/leake/leake/
Root-URL: http://www.cs.indiana.edu
Email: fleake, kinley, wilsong@cs.indiana.edu  
Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  
Phone: 1997.  215,  
Author: David B. Leake, Andrew Kinley, and David Wilson 
Affiliation: Computer Science Department  Indiana University  
Address: Menlo Park, CA,  Lindley Hall  Bloomington, IN 47405  
Note: Proceedings of the Fourteenth National Conference on Artificial Intelligence, AAAI Press,  
Abstract: Case-based problem-solving systems rely on similarity assessment to select stored cases whose solutions are easily adaptable to fit current problems. However, widely-used similarity assessment strategies, such as evaluation of semantic similarity, can be poor predictors of adaptability. As a result, systems may select cases that are difficult or impossible for them to adapt, even when easily adaptable cases are available in memory. This paper presents a new similarity assessment approach which couples similarity judgments directly to a case library containing the system's adaptation knowledge. It examines this approach in the context of a case-based planning system that learns both new plans and new adaptations. Empirical tests of alternative similarity assessment strategies show that this approach enables better case selection and increases the benefits accrued from learned adaptations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alterman, R. </author> <year> 1988. </year> <title> Adaptive planning. </title> <booktitle> Cognitive Science 12 </booktitle> <pages> 393-422. </pages>
Reference-contexts: Problem detection: Any case-based adaptation system requires a method for determining problems requiring adaptation. Many methods exist, ranging from explanations of problems (Hammond 1989) to pattern-based verification (Leake 1992b). External information may also directly identify needed adaptations. For example, in the planner PLEXIS <ref> (Alterman 1988) </ref>, adaptation to find a replacement object is triggered by failure to find that object during plan execution. DIAL relies on a combination of pattern-based methods|which can detect potential problems at minimal cost (Leake 1992b)|and user feedback for information not available in the system's prior knowledge.
Reference: <author> Barletta, R., and Mark, W. </author> <year> 1988. </year> <title> Explanation-based indexing of cases. </title> <editor> In Kolodner, J., ed., </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> 50-60. </pages> <address> Palo Alto: </address> <publisher> DARPA. </publisher>
Reference-contexts: Ideally, case selection should reflect anticipated usefulness as directly as possible (Kolodner 1988). One approach is to refine similarity criteria to reflect the most relevant similarities. For example, explanation-based indexing <ref> (Barletta & Mark 1988) </ref> and the Prodigy/Analogy (Veloso & Carbonell 1994) system's "foot-print" similarity metric focus attention on goal-relevant features, in order to retrieve cases that refer to the prior problem situations with the most relevant similarities; other approaches do failure-driven learning to refine similarity criteria after detecting retrieval of a
Reference: <author> Berger, J. </author> <year> 1995. </year> <title> ROENTGEN: A Case-based Radiation Therapy Planner. </title> <type> Ph.D. Dissertation, </type> <institution> The University of Chicago. Computer Science Department. </institution>
Reference: <author> Birnbaum, L.; Collins, G.; Brand, M.; Freed, M.; Krulwich, B.; and Pryor, L. </author> <year> 1991. </year> <title> A model-based approach to the construction of adaptive case-based planning systems. In Bareiss, </title> <editor> R., ed., </editor> <booktitle> Proceedings of the DARPA Case-Based Reasoning Workshop, </booktitle> <pages> 215-224. </pages> <address> San Mateo: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fox, S., and Leake, D. </author> <year> 1995. </year> <title> Using introspective reasoning to refine indexing. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 391-397. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hammond, K. </author> <year> 1989. </year> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <address> San Diego: </address> <publisher> Academic Press. </publisher>
Reference-contexts: DIAL performs an initial mapping of the new situation onto the prior situations to generate candidate response plans. Problem detection: Any case-based adaptation system requires a method for determining problems requiring adaptation. Many methods exist, ranging from explanations of problems <ref> (Hammond 1989) </ref> to pattern-based verification (Leake 1992b). External information may also directly identify needed adaptations. For example, in the planner PLEXIS (Alterman 1988), adaptation to find a replacement object is triggered by failure to find that object during plan execution.
Reference: <author> Hanney, K., and Keane, M. </author> <year> 1996. </year> <title> Learning adaptation rules from a case-base. </title> <booktitle> In Proceedings of the Third European Workshop on Case-Based Reasoning. </booktitle> <address> Berlin: </address> <publisher> Springer Verlag. </publisher>
Reference: <author> Kolodner, J. </author> <year> 1988. </year> <title> Retrieving events from a case memory: A parallel implementation. </title> <editor> In Kolodner, J., ed., </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> 233-249. </pages> <address> Palo Alto: </address> <publisher> DARPA. </publisher>
Reference-contexts: Relationship to Prior Research on Linking Similarity and Adaptability Similarity assessment for case-based reasoning systems often relies on semantic similarity or other criteria that may not reflect the difficulty of adaptation. Ideally, case selection should reflect anticipated usefulness as directly as possible <ref> (Kolodner 1988) </ref>. One approach is to refine similarity criteria to reflect the most relevant similarities.
Reference: <author> Leake, D.; Kinley, A.; and Wilson, D. </author> <year> 1996. </year> <title> Acquiring case adaptation knowledge: A hybrid approach. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> 684-689. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This paper examines the first three of these issues; the fourth is briefly summarized here and is addressed in Leake, Kinley, & Wilson (1997). Task Domain and System The RCR similarity method has been applied in the DIAL system, a case-based planner <ref> (Leake, Kinley, & Wilson 1996) </ref>. DIAL's task domain is disaster response planning. Disaster response planning is the initial strategic planning used to determine how to assess damage, evacuate victims, etc., in response to natural and man-made disasters.
Reference: <author> Leake, D.; Kinley, A.; and Wilson, D. </author> <year> 1997. </year> <title> Learning to integrate multiple knowledge sources for case-based reasoning. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. In press. </publisher>
Reference: <author> Leake, D. </author> <year> 1992a. </year> <title> Constructive similarity assessment: Using stored cases to define new situations. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 313-318. </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Leake, D. </author> <year> 1992b. </year> <title> Evaluating Explanations: A Content Theory. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: The system determines correspondences between old and new disasters and does an initial mapping of the prior response plans to the new situation, identifying roles for which this initial simple adaptation fails. 4. Additional problems are identified by a combination of automatic stereotype-based problem detection <ref> (Leake 1992b) </ref> and user feedback (possibly re jecting system mappings). 5. <p> DIAL's adaptation cases package information about the context of an adaptation, the derivation of its solution, and the effort involved in the derivation process. The context information includes characteristics of the problem for which the adaptation was generated, such as the type of problem <ref> (in a problem vocabulary based on Leake, 1992b) </ref>, the value being adapted, and the roles that value fills in the response plan. The derivation records the primitive memory operations needed to find appropriate values in memory. <p> DIAL performs an initial mapping of the new situation onto the prior situations to generate candidate response plans. Problem detection: Any case-based adaptation system requires a method for determining problems requiring adaptation. Many methods exist, ranging from explanations of problems (Hammond 1989) to pattern-based verification <ref> (Leake 1992b) </ref>. External information may also directly identify needed adaptations. For example, in the planner PLEXIS (Alterman 1988), adaptation to find a replacement object is triggered by failure to find that object during plan execution. <p> <ref> (Leake 1992b) </ref>. External information may also directly identify needed adaptations. For example, in the planner PLEXIS (Alterman 1988), adaptation to find a replacement object is triggered by failure to find that object during plan execution. DIAL relies on a combination of pattern-based methods|which can detect potential problems at minimal cost (Leake 1992b)|and user feedback for information not available in the system's prior knowledge. In the disaster response domain, user input might reflect situation-specific information (e.g., that a road is impassable, or that a region is not under the jurisdiction of a particular agency).
Reference: <author> Smyth, B., and Keane, M. </author> <year> 1996. </year> <title> Design a la Deja Vu: Reducing the adaptation overhead. </title> <editor> In Leake, D., ed., </editor> <title> Case-Based Reasoning: Experiences, Lessons, and Future Directions. </title> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: However, it has recently been shown that widely-used similarity assessment criteria, such as semantic similarity of situation features, can be poor predictors of the actual difficulty of adapting prior cases to new needs <ref> (Smyth & Keane 1996) </ref>. When similarity assessment picks an inappropriate case, solution generation will be unnecessarily expensive. If the difficulty of adaptation outstrips the system's adaptation abilities, the choice may even prevent the system from generating a solution. <p> This corresponds closely to the similarity assessment method used in adaptation-guided retrieval <ref> (Smyth & Keane 1996) </ref>, another method for basing case selection on adaptability. * Actual prior costs of retrieved adaptations: The difference is the sum of the actual prior adaptation costs of the retrieved adaptation cases.
Reference: <author> Sycara, K. </author> <year> 1988. </year> <title> Using case-based reasoning for plan adaptation and repair. </title> <editor> In Kolodner, J., ed., </editor> <booktitle> Proceedings of the DARPA Case-Based Reasoning Workshop, </booktitle> <pages> 425-434. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Veloso, M., and Carbonell, J. </author> <year> 1994. </year> <title> Case-based reasoning in PRODIGY. </title> <editor> In Michalski, R., and Tecuci, G., eds., </editor> <title> Machine Learning: A Multistrategy Approach. </title> <publisher> Morgan Kaufmann. </publisher> <pages> chapter 20, 523-548. </pages>
Reference-contexts: This information is used to select the response plan case expected to be easi est to adapt. 6. Problems in the response plan suggested by the selected case are repaired by case adaptation using derivational analogy <ref> (Veloso & Carbonell 1994) </ref>. 7. The resulting response plan case is stored for reuse, as are traces of the adaptations performed, packaged as adaptation cases. This paper will focus on aspects of the system with a direct bearing on step 5, the actual case-based similarity assessment process. <p> Ideally, case selection should reflect anticipated usefulness as directly as possible (Kolodner 1988). One approach is to refine similarity criteria to reflect the most relevant similarities. For example, explanation-based indexing (Barletta & Mark 1988) and the Prodigy/Analogy <ref> (Veloso & Carbonell 1994) </ref> system's "foot-print" similarity metric focus attention on goal-relevant features, in order to retrieve cases that refer to the prior problem situations with the most relevant similarities; other approaches do failure-driven learning to refine similarity criteria after detecting retrieval of a case that is needlessly difficult to adapt
References-found: 15

