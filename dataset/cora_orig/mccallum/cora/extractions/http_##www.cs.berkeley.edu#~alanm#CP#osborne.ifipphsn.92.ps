URL: http://www.cs.berkeley.edu/~alanm/CP/osborne.ifipphsn.92.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Email: osborne@merl.com  
Title: A Hybrid Deposit Model for Low Overhead Communication in High Speed LANs hardware support, the
Author: Randy Osborne 
Address: Cambridge, Massachusetts 02139  
Note: With  To be presented at IFIP Fourth International Workshop on Protocols for High-speed Networks,  Copyright c Mitsubishi Electric Research Laboratories, 1994 201 Broadway,  
Date: June 1994  August 1994  
Affiliation: MITSUBISHI ELECTRIC RESEARCH LABORATORIES CAMBRIDGE RESEARCH CENTER  
Pubnum: TR-94-02v3  
Abstract: This paper presents a new, "hybrid deposit" model for low overhead communication wherein the sender directly deposits messages into the destination user-level memory. The destination address is a function of both sender state and destination state. The motivation is to increase the sender's role in communication in order to simplify the destination's role and thus enable fast, low-cost communication interfaces. The model separates data delivery from synchronization so as to enable the optimization of simple data delivery while leaving more difficult synchronization to other mechanisms. The paper specializes this hybrid deposit idea to ATM LANs and examines implementation methods. We first describe a software implementation with stock workstations and ATM interface cards. This implementation achieves a best case application-to-application latency of 24.5sec. For consistent low latency, high bandwidth, and reduced burden on the host processor, hardware support is required. We describe an interface architecture called DART that provides basic functionality for hybrid deposit. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories of Cambridge, Massachusetts; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories. All rights reserved. 
Abstract-found: 1
Intro-found: 1
Reference: [AI87] <author> Arvind and R. Ianucci. </author> <title> Two Fundamental Issues in Multiprocessing. </title> <booktitle> In Proc. of DFVLR - Conf. on Parallel Processing in Science and Eng., </booktitle> <month> June </month> <year> 1987. </year>
Reference-contexts: Latency, one of the fundamental issues in parallel computing <ref> [AI87] </ref>, limits the maximum parallelism that can be exploited in an application. In distributed computing, low latency can help improve the performance of remote procedure call (RPC) and thereby enhance the performance of the ubiquitous client-server model.
Reference: [Be94] <author> M. Blumrich and et al. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year> <month> MERL-TR-94-02v3 June </month> <year> 1994 </year> <month> 17 </month>
Reference-contexts: Destination-based addressing is the conventional approach in distributed systems and for send-receive models in parallel machines. Sender-based addressing is common in parallel machines, though usually at fine granularities e.g. words. Recently, sender-based addressing has become popular for optimizing messaging passing, as in SHRIMP <ref> [Be94] </ref> which uses virtual memory mapped communication.
Reference: [BP93] <author> D. Banks and M. Prudence. </author> <title> A High-Performance Network Architecture for a PA-RISC Workstation. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 191-202, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction The considerable recent work on workstation network interfaces for high speed LANs (e.g. <ref> [Dav93, BP93, TS93] </ref>) has focussed on achieving high bandwidth. This paper focuses, in contrast, on low overhead communication | by which we mean both low latency and low impact on the host processor | for high speed LANs.
Reference: [Dav93] <author> B. Davie. </author> <title> The Architecture and Implementation of a High-Speed Host Interface. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 228-239, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction The considerable recent work on workstation network interfaces for high speed LANs (e.g. <ref> [Dav93, BP93, TS93] </ref>) has focussed on achieving high bandwidth. This paper focuses, in contrast, on low overhead communication | by which we mean both low latency and low impact on the host processor | for high speed LANs.
Reference: [De87] <author> W. Dally and et al. </author> <title> Architecture of a Message-Driven Processor. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <year> 1987. </year>
Reference-contexts: DART provides a small number of demultiplexing primitives in hardware, along with some simple ways to perform compound multiplexing operations. More complex operations are handled via software exception to the host processor. The per cell processing architecture of DART is similar in principle to the message-driven processor (MDP) <ref> [De87] </ref>. However, we use DART in a filtering role for depositing messages, rather than for direct computation and we provide full protected multiuser communication. The closest related work we know of for LANs are Hamlyn and Axon.
Reference: [DLM94] <author> C. Dubnicki, K. Li, and M. Mesarina. </author> <title> Network Interface Support for User-Level Buffer Management. In Parallel Computer Routing and Comm. </title> <booktitle> Workshop, </booktitle> <institution> Univ. of Washington, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: This provides great flexibility in combining sender and destination information. However, to get low latency these interrupt handlers execute on the host processor and execute in the context of the interrupted task. Thus Active Messages must be combined with a protection mechanism to be useful in a multiuser environment. <ref> [DLM94] </ref> provides a limited form of hybrid addressing in which a message controls whether it is deposited at an address contained in the message or an address stored at the destination. Hybrid-based interrupts are also useful. Pure destination-based interrupts, like in Active Messages, cause an interrupt on every message arrival. <p> Thus, as with addressing, interrupts should be a function of both sender and destination information. This allows the interrupt status to be partially a function of message priorities contributed by processes that the sender may not know exist. [TLL93] and <ref> [DLM94] </ref> describe very limited approximations to hybrid interrupts in which the sender indicates an interrupt in the message and the destination can simply enable or disable all interrupts for a given buffer. Our work combines sender and destination information for both addressing and interrupts.
Reference: [DP93] <author> P. Druschel and L. Peterson. Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility. </title> <booktitle> In Proc. of the Sympos. on Operating System Principles, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: An endpoint may have multiple originating connections and/or multiple terminating connections. All connections associated with a given endpoint use the same virtual memory mapping and protection information. Endpoint buffers can be overlapped or nested to effect different degrees of sharing and isolation between connections (like fbufs <ref> [DP93] </ref>). Different protection schemes can also be realized by mapping the physical pages behind an endpoint buffer to virtual address ranges with different page protections. 3.3 Messages Messages contain a connection ID (which implicitly identifies the endpoint), control information consisting of an operation and some operands, and data.
Reference: [Ke94] <author> P. Keleher and et al. TreadMarks: </author> <title> Distributed Shared Memory on Standard Workstations and Operating Systems. </title> <booktitle> In Proc. of Winter Usenix Conf., </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: This is about 10 times faster than the fastest conventional approach (using Fore Systems' AAL3/4 implementation) on the same hardware <ref> [Ke94] </ref>. With appropriate hardware support, we believe latencies of under 10sec for a 155Mbps ATM LAN and under 3sec for a 622Mbps ATM LAN are possible in the workstation LAN environment. 1 Our interest in low overhead communication is motivated by applications in parallel, distributed, and real-time computing.
Reference: [NPA92] <author> R. Nikhil, G. Papadopoulos, and Arvind. </author> <title> *T: A Multithreaded Massively Parallel Architecture. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <pages> pages 156-169, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Consequently, an asynchronous message arrival incurs overhead in both the communication and whatever application happens to be running at the time. High performance systems sacrifice cost and duplicate resources to bypass the host processor and operating system e.g. parallel machines such as the Intel Paragon and *T <ref> [NPA92] </ref> and real-time systems such as Spring OS [SR91]. These systems devote hardware for the worst case requirements. An intermediate solution is to control asynchronous events by separating events by their need for the host processor.
Reference: [Onv94] <author> R. Onvural. </author> <title> Asynchronous Transfer Mode Networks: Performance Issues. </title> <publisher> Artech House, </publisher> <year> 1994. </year>
Reference-contexts: The check field contains a checksum over the prior control fields so that decoding of these fields can begin before the entire cell arrives. 3 The two byte CRC covers the data field. To take advantage of CRC hardware for AAL5 format cells <ref> [Onv94] </ref>, the CRC field could be extended to 4 bytes and cover the entire payload. The example in Figure 3 is for a write. For a read request to a remote node, the data section contains control fields for the read reply message.
Reference: [Se93] <author> J. Subhlok and et al. </author> <title> Programming Task and Data Parallelism on a Multicomputer. </title> <booktitle> In Proc. of ACM Sympos. on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 13-22, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: address (random access) net and mapping Connection state interrupt and mapping Connection state deposit operating system application 1 application 2 endpoint header e.g. offset operand data operation system operating endpoint application 1 application 2 processor processor interface interface net control, distinguishes our work from previous work. 3 Hybrid Deposit Messaging <ref> [Se93] </ref> introduced the "deposit model" for a form of sender-based addressing used by a compiler in a message passing parallel computing paradigm.
Reference: [Se94] <author> T. Stricker and et al. </author> <title> Decoupling Communication Services for Compiled Parallel Programs. </title> <type> Technical Report CMU-CS-94-139, CMU, </type> <year> 1994. </year>
Reference-contexts: We generalize this appropriately suggestive term to mean demultiplexing messages and depositing them directly where they are needed e.g. depositing data directly in application memory and delivering (significant) control events to the host processor (similar to the ideas in <ref> [Se94] </ref>). To this notion we add hybrid addressing and interrupt generation. 3.1 Overview The application view of hybrid deposit messaging is two "endpoint" buffers linked by a "connection".
Reference: [SP90] <author> J. Sterbenz and G. Parulka. Axon: </author> <title> A High Speed Communication Architecture for Distributed Applications. </title> <booktitle> In Proceedings of IEEE INFOCOM, </booktitle> <year> 1990. </year>
Reference-contexts: Recently, sender-based addressing has become popular for optimizing messaging passing, as in SHRIMP [Be94] which uses virtual memory mapped communication. Three recent works promote sender-based addressing in a LAN environment. [Wil92] describes a high level design of an interface called Hamlyn; <ref> [SP90] </ref> describes an interface design called Axon; and [TLL93] describes a in-kernel implementation of a remote read/write model (a follow-on of Spector's work [Spe82]). The Meiko CS-2 mul-ticomputer also supports a remote read/write model, though with custom co-processors and proprietary network. <p> However Hamlyn differs in some major ways: it supports only direct addressing, one delayed action queue per node (there can be any number in DART), and it pins endpoint pages. Like DART, Axon <ref> [SP90] </ref> has self describing packets for direct deposit at the destination. However, Axon lacks hardware support for flexible sender and destination-based addressing, hybrid interrupt control, and register operations. To date we have developed the model and designed plausible implementations.
Reference: [Spe82] <author> A. Spector. </author> <title> Performing Remote Operations Efficiently on a Local Computer Network. </title> <journal> Communications of the ACM, </journal> <pages> pages 246-260, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Three recent works promote sender-based addressing in a LAN environment. [Wil92] describes a high level design of an interface called Hamlyn; [SP90] describes an interface design called Axon; and [TLL93] describes a in-kernel implementation of a remote read/write model (a follow-on of Spector's work <ref> [Spe82] </ref>). The Meiko CS-2 mul-ticomputer also supports a remote read/write model, though with custom co-processors and proprietary network. Sender-based addressing allows random access transfers and thus is attractive for parallel computing. However, sender-based addressing suffers from two problems in our context of a LAN distributed system.
Reference: [SR91] <author> J. Stankovic and K. Ramamrithm. </author> <title> The Spring Kernel: A New Paradigm for Real-Time Systems. </title> <journal> IEEE Software, </journal> <volume> 8(3), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: High performance systems sacrifice cost and duplicate resources to bypass the host processor and operating system e.g. parallel machines such as the Intel Paragon and *T [NPA92] and real-time systems such as Spring OS <ref> [SR91] </ref>. These systems devote hardware for the worst case requirements. An intermediate solution is to control asynchronous events by separating events by their need for the host processor.
Reference: [TLL93] <author> C. Thekkath, H. Levy, and E. Lazowska. </author> <title> Efficient Support for Multicomputing on ATM Networks. </title> <type> Technical Report TR93-04-03, </type> <institution> Dept. of Computer Science, Univ. of Washington, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Recently, sender-based addressing has become popular for optimizing messaging passing, as in SHRIMP [Be94] which uses virtual memory mapped communication. Three recent works promote sender-based addressing in a LAN environment. [Wil92] describes a high level design of an interface called Hamlyn; [SP90] describes an interface design called Axon; and <ref> [TLL93] </ref> describes a in-kernel implementation of a remote read/write model (a follow-on of Spector's work [Spe82]). The Meiko CS-2 mul-ticomputer also supports a remote read/write model, though with custom co-processors and proprietary network. Sender-based addressing allows random access transfers and thus is attractive for parallel computing. <p> Thus, as with addressing, interrupts should be a function of both sender and destination information. This allows the interrupt status to be partially a function of message priorities contributed by processes that the sender may not know exist. <ref> [TLL93] </ref> and [DLM94] describe very limited approximations to hybrid interrupts in which the sender indicates an interrupt in the message and the destination can simply enable or disable all interrupts for a given buffer. Our work combines sender and destination information for both addressing and interrupts. <p> The operating system is Mach 3.0. We modified the Mach kernel to send a cell via an illegal instruction trap, partly optimized the ATM interface interrupt path, and added hybrid deposit emulation in the kernel. This is similar to the software implementation described in <ref> [TLL93] </ref> except they modified Ultrix and only support simple remote read and write (using only direct addressing). We added more functionality 3 An 8 bit checksum for 11 control bytes gives more protection than the 10 bit CRC in AAL3/4 cells. 4 Conditional interrupts have not been implemented yet.
Reference: [TS93] <author> C. Traw and J. Smith. </author> <title> Hardware/Software Organization of a High-Performance ATM Host Interface. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 240-253, </pages> <month> February </month> <year> 1993. </year> <editor> [von92] von Eicken et al. </editor> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The considerable recent work on workstation network interfaces for high speed LANs (e.g. <ref> [Dav93, BP93, TS93] </ref>) has focussed on achieving high bandwidth. This paper focuses, in contrast, on low overhead communication | by which we mean both low latency and low impact on the host processor | for high speed LANs.
Reference: [Wil92] <author> J. Wilkes. Hamlyn: </author> <title> An Interface for Sender-based Communication. </title> <type> Technical Report HPL-OSR-92-13, </type> <institution> HP Labs, </institution> <month> November </month> <year> 1992. </year> <editor> Acknowledgments MERL colleagues Chia Shen, Richard Waters, John Howard, Hugh Lauer, </editor> <title> and Qin Zheng gave helpful suggestions on the interface ideas and paper presentation. John Kubiatowicz of the MIT Lab for Computer Science gave valuable feedback on the design ideas and presentation in an earlier draft. The development of the hybrid deposit model benefitted from discussions with Peter Steenkiste and Thomas Gross at CMU. </title> <institution> Takushi Kawada and Vu Le Phan of Mitsubishi Electric helped install Mach 3.0. </institution> <month> MERL-TR-94-02v3 June </month> <year> 1994 </year>
Reference-contexts: Sender-based addressing is common in parallel machines, though usually at fine granularities e.g. words. Recently, sender-based addressing has become popular for optimizing messaging passing, as in SHRIMP [Be94] which uses virtual memory mapped communication. Three recent works promote sender-based addressing in a LAN environment. <ref> [Wil92] </ref> describes a high level design of an interface called Hamlyn; [SP90] describes an interface design called Axon; and [TLL93] describes a in-kernel implementation of a remote read/write model (a follow-on of Spector's work [Spe82]). <p> However, we use DART in a filtering role for depositing messages, rather than for direct computation and we provide full protected multiuser communication. The closest related work we know of for LANs are Hamlyn and Axon. Hamlyn <ref> [Wil92] </ref> adopts a similar emphasis on increasing the participation of the sender to minimize the required functionality at the destination. However Hamlyn differs in some major ways: it supports only direct addressing, one delayed action queue per node (there can be any number in DART), and it pins endpoint pages.
References-found: 18

