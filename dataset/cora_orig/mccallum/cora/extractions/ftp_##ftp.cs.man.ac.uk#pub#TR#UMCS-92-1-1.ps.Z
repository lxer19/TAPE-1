URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-92-1-1.ps.Z
Refering-URL: http://www.cs.man.ac.uk/cstechrep/Abstracts/UMCS-92-1-1.html
Root-URL: http://www.cs.man.ac.uk
Title: Load Balancing of Parallel Affine Loops by Unimodular Transformations  
Author: Michael O'Boyle and G.A. Hedayat 
Address: Manchester M13 9PL, England  
Affiliation: Department of Computer Science University of Manchester  
Pubnum: Technical Report Series UMCS-92-1-1  
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> Banerjee U.,Unimodular Transformations of Double Loops, </editor> <booktitle> Proc. of 3rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: an L, U and a form L b , U b , where the iterator j b is in a load balanced form satisfying 11 and 12, find a transformation, p , such that: p : L 7! L b (15) We look at a restricted set of unimodular transformations <ref> [1] </ref> which satisfy 15 and 16 by post multiplication by a unit lower triangular matrix T, which changes the basis of J 7! TJ b . The system of inequalities defined by 1 and 2 remains unchanged by this transformation. <p> Each iteration of j will have exactly the same amount of work to perform and all that is now required is for the n+3 iterations to be divided amongst the processors. 6 Review The properties of unimodular transformations for doubly nested loops with constant bounds have been covered by <ref> [1] </ref>. It has also shown that existing transformations such as the wavefront method [4] can be described in terms of unimodular transformations [3].
Reference: [2] <author> Callahan D. </author> <title> and Kennedy K.,Compiling Programs for Distributed Memory Multiprocessors, </title> <journal> Journal of Supercomputing, </journal> <volume> Vol. 2 No. 2, </volume> <pages> pp 151-207, </pages> <year> 1988. </year>
Reference-contexts: In effect each processor performs a sub-set of some of the loop iterations. This sub-dividing of the iteration space has been referred to as tiling [7]. A similar process has been called loop elimination by <ref> [2] </ref> when applied to distributed memory multiprocessors. Previous work on program restructuring has been mainly focused on revealing program parallelism and exploiting a machine's memory hierarchy efficiently [10].
Reference: [3] <author> Dowling, M. </author> <title> Optimal Code Parallelization using Unimodular Transformations, </title> <journal> Parallel Computing Vol. </journal> <volume> 16, </volume> <pages> pp 157-171, </pages> <year> 1990. </year>
Reference-contexts: It has also shown that existing transformations such as the wavefront method [4] can be described in terms of unimodular transformations <ref> [3] </ref>. Program transformations have mainly been focused on revealing program parallelism, however in [5] unimodular transformations are used as a mechanism to describe distribution of loops across distributed processors.
Reference: [4] <author> Lamport L., </author> <title> The Parallel Execution of DO loops, </title> <journal> CACM Vol. </journal> <volume> 17 No. 2, </volume> <month> Feb </month> <year> 1974. </year>
Reference-contexts: It has also shown that existing transformations such as the wavefront method <ref> [4] </ref> can be described in terms of unimodular transformations [3]. Program transformations have mainly been focused on revealing program parallelism, however in [5] unimodular transformations are used as a mechanism to describe distribution of loops across distributed processors.
Reference: [5] <author> Kulkarni D., Kumar K.G., Basu A., </author> <title> and Paulraj A.,Loop Partitioning for Distributed Memory Multiprocessors as Unimodular Transformations, </title> <booktitle> Proc. of ACM International Conference on Supercomputing, </booktitle> <month> June, </month> <year> 1991. </year>
Reference-contexts: It has also shown that existing transformations such as the wavefront method [4] can be described in terms of unimodular transformations [3]. Program transformations have mainly been focused on revealing program parallelism, however in <ref> [5] </ref> unimodular transformations are used as a mechanism to describe distribution of loops across distributed processors. They study the effect of unimodular transformations by giving a measure of parallelism, load imbalance and volume of communication which are again restricted to the two-dimensional rectangular loop case.
Reference: [6] <author> O'Boyle M.F.P., </author> <title> Program and Data Transformations for Efficient Execution on Distributed Memory Architectures, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Manchester, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: In practice this means that H contains no conditional evaluation. It follows that for perfect load balance, it is sufficient that each processor receives the same number of computation points. More general forms of H are considered in <ref> [6] </ref>. The lower and upper bounds of all loops described by figure 2 may 2 DOALL j 1 = 1 , u 1 DOALL j 2 = L 2 (j 1 ) + l 2 , U 2 (j 1 ) + u 2 . . . <p> By restricting this reordering to DOALL loops which contain no cross-iteration dependencies, all data dependencies are preserved. Additionally after transformation the loop should be in the structure defined by 1 and 2. More general forms of loop structure are studied in <ref> [6] </ref>. 3.1 Change of Basis Given an L, U and a form L b , U b , where the iterator j b is in a load balanced form satisfying 11 and 12, find a transformation, p , such that: p : L 7! L b (15) We look at a <p> Although the polytope notation was developed quite extensively, it was used chiefly to find a legal ordering vector within the polytope so as to maintain program data dependencies. The work presented in this paper forms part of the general mapping of array computation to distributed memory architectures. In <ref> [6] </ref> load balancing for more general programs including serial loops and conditionals and arbitrary nesting is presented.
Reference: [7] <author> Ramanujam J. </author> <title> and Sadyappan P.,Tiling of Iteration Spaces for Multicomputers, </title> <booktitle> Proc. of International Conference on Parallel Processing, </booktitle> <volume> Vol. 2, </volume> <pages> pp 179 -186, </pages> <year> 1990. </year>
Reference-contexts: In effect each processor performs a sub-set of some of the loop iterations. This sub-dividing of the iteration space has been referred to as tiling <ref> [7] </ref>. A similar process has been called loop elimination by [2] when applied to distributed memory multiprocessors. Previous work on program restructuring has been mainly focused on revealing program parallelism and exploiting a machine's memory hierarchy efficiently [10].
Reference: [8] <author> Ribas, </author> <title> H.B.,Automatic Generation of Systolic Programs from Nested Loops, </title> <type> Carnegie-Mellon Tech. Rep. </type> <institution> CMU-CS-90-143, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Thus the points that J m ranges over are the integer lattice points enclosed by the above polytope <ref> [8] </ref>. Due to the restriction on H, the amount of work associated with each point is uniform throughout the lattice. A load balanced mapping is one where the number of computation points assigned to each processor is the same. <p> The unimodular transformations used within our paper are related to loop skewing [9] and loop interchange [10]. The polytope and related notation is based upon the work of <ref> [8] </ref>. The main concern of his thesis was the unification of the systolic framework based on uniform recurrences with data dependency analysis. Although the polytope notation was developed quite extensively, it was used chiefly to find a legal ordering vector within the polytope so as to maintain program data dependencies.
Reference: [9] <author> Wolfe M., </author> <title> Loop Skewing: The Wavefront Method Revisited, </title> <journal> International Journal of Parallel Programming, </journal> <volume> Vol. 15, No. </volume> <pages> 4 pp 279-294, </pages> <month> August </month> <year> 1986. </year> <month> 20 </month>
Reference-contexts: They study the effect of unimodular transformations by giving a measure of parallelism, load imbalance and volume of communication which are again restricted to the two-dimensional rectangular loop case. The unimodular transformations used within our paper are related to loop skewing <ref> [9] </ref> and loop interchange [10]. The polytope and related notation is based upon the work of [8]. The main concern of his thesis was the unification of the systolic framework based on uniform recurrences with data dependency analysis.
Reference: [10] <author> Wolfe M., </author> <title> Massive Parallelism through Program Restructuring, </title> <booktitle> 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp 407-415, </pages> <month> October </month> <year> 1990. </year> <month> 21 </month>
Reference-contexts: This sub-dividing of the iteration space has been referred to as tiling [7]. A similar process has been called loop elimination by [2] when applied to distributed memory multiprocessors. Previous work on program restructuring has been mainly focused on revealing program parallelism and exploiting a machine's memory hierarchy efficiently <ref> [10] </ref>. In this paper it is assumed that the program is already in a form where all parallelism has been revealed, and it is now the task of the compiler to transform the program so as to minimise load imbalance. <p> They study the effect of unimodular transformations by giving a measure of parallelism, load imbalance and volume of communication which are again restricted to the two-dimensional rectangular loop case. The unimodular transformations used within our paper are related to loop skewing [9] and loop interchange <ref> [10] </ref>. The polytope and related notation is based upon the work of [8]. The main concern of his thesis was the unification of the systolic framework based on uniform recurrences with data dependency analysis.
References-found: 10

