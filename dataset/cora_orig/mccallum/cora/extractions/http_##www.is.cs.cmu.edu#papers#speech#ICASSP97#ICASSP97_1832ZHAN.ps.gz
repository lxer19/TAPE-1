URL: http://www.is.cs.cmu.edu/papers/speech/ICASSP97/ICASSP97_1832ZHAN.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: Email: zhan@cs.cmu.edu  Email: westphal@ira.uka.de  
Phone: 2  
Title: SPEAKER NORMALIZATION BASED ON FREQUENCY WARPING  
Author: Puming Zhan Martin Westphal 
Address: University.  Germany.  
Affiliation: Interactive Systems Laboratories 1 Carnegie Mellon  University of Karlsruhe,  
Abstract: In speech recognition, speaker-dependence of a speech recognition system comes from speaker-dependence of the speech feature, and the variation of vocal tract shape is the major source of inter-speaker variations of the speech feature, though there are some other sources which also contribute. In this paper, we address the approaches of speaker normalization which aim at normalizing speaker's vocal tract length based on Frequency WarPing (FWP). The FWP is implemented in the front-end preprocessing of our speech recognition system. We investigate the formant-based and ML-based FWP in linear and nonlinear warping modes, and compare them in detail. All experimental results are based on our JANUS3 large vocabulary continuous speech recognition system and the Spanish Spontaneous Scheduling Task database (SSST). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Christine Tuerk and Tony Robinson. </author> <title> A new frequency shift function for reducing inter-speaker variance. </title> <journal> EuroSpeech-93, </journal> <volume> 1 </volume> <pages> 351-354, </pages> <year> 1993. </year>
Reference-contexts: It is not only related to the physiological differences of speakers, such as vocal tract shape and fundamental pitch, but also related to the linguistic differences, such as accent, dialect and stress, etc., or even the physical and mental conditions of speakers <ref> [1] </ref>. But it is generally agreed that one of the major source of inter-speaker variance is the vocal tract shape, especially the vocal tract length (VTL) [2, 3]. Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. <p> Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel <ref> [1, 2, 3] </ref>. In the recent researches, the FWP was investigated in continuous speech recognition system [4, 5]. In [4], a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP.
Reference: [2] <author> H. Wakita. </author> <title> Normalization of vowels by vocal-tract length and its application to vowel identification. </title> <journal> IEEE Trans. ASSP,, </journal> <volume> 25 </volume> <pages> 183-192, </pages> <year> 1977. </year>
Reference-contexts: But it is generally agreed that one of the major source of inter-speaker variance is the vocal tract shape, especially the vocal tract length (VTL) <ref> [2, 3] </ref>. Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel [1, 2, 3]. <p> Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel <ref> [1, 2, 3] </ref>. In the recent researches, the FWP was investigated in continuous speech recognition system [4, 5]. In [4], a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP. <p> The weakness of this method is that it is relatively expansive in computation. In [5], a parametric approach for FWP was proposed. We refer this method as formant-based FWP. The idea is the same as in <ref> [2, 3] </ref>, i.e., the warping factors were obtained from formant estimation. But they investigated the method in large vocabulary continuous speech recognition system. The advantage of the formant-based FWP is that it is not very expansive in computation. <p> Because Formats are context dependent, it should be better if formants are estimated based on the same context over all speakers. We calculated the average male and female VTL with the formulate in <ref> [2] </ref>, and obtained 16.45cm for male (15.47cm for female) which is near the standard value (17cm) [10]. We found that F 3 is the best one for estimating VTL. This might be that vowel-dependence of the F 3 is not as strong as the first two.
Reference: [3] <author> Yoshio Ono, Hisashi Wakita, and Yunxin Zhao. </author> <title> Speaker normalization using constrained spectra shifts in auditory filter domain. </title> <journal> EuroSpeech-93, </journal> <volume> 1 </volume> <pages> 355-358, </pages> <year> 1993. </year>
Reference-contexts: But it is generally agreed that one of the major source of inter-speaker variance is the vocal tract shape, especially the vocal tract length (VTL) <ref> [2, 3] </ref>. Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel [1, 2, 3]. <p> Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel <ref> [1, 2, 3] </ref>. In the recent researches, the FWP was investigated in continuous speech recognition system [4, 5]. In [4], a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP. <p> The weakness of this method is that it is relatively expansive in computation. In [5], a parametric approach for FWP was proposed. We refer this method as formant-based FWP. The idea is the same as in <ref> [2, 3] </ref>, i.e., the warping factors were obtained from formant estimation. But they investigated the method in large vocabulary continuous speech recognition system. The advantage of the formant-based FWP is that it is not very expansive in computation.
Reference: [4] <author> Li Lee and Richard C. Rose. </author> <title> Speaker normalization using efficient frequency warping procedures. </title> <journal> ICASSP-96, </journal> <volume> 1 </volume> <pages> 353-356, </pages> <year> 1996. </year>
Reference-contexts: Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel [1, 2, 3]. In the recent researches, the FWP was investigated in continuous speech recognition system <ref> [4, 5] </ref>. In [4], a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP. <p> The earlier researches were focused on the identification of isolated vowel [1, 2, 3]. In the recent researches, the FWP was investigated in continuous speech recognition system [4, 5]. In <ref> [4] </ref>, a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP. The advantage of the ML-based FWP is that it guarantees to find the warping factor which is optimal in the ML criterion. <p> In training, we load in the warping factors and use them to warp the power spectrum (as showed in figure 1), and do the iterative training with the warped feature. For the ML-based FWP, the training principle is to find the warping factor which maximums the likelihood <ref> [4] </ref>. We use the following procedure for training: 1. Set the initial warping factor ff s = 1:0 for all speakers 2. Do Viterbi training based on current warping factors 3. <p> The above procedure stops if there is not significant differ ence in the warping factors between two consecutive train ing iterations. 2.4. Testing Procedure For the ML-based FWP, we use a decoding procedure which is a little bit different from <ref> [4] </ref>. The input utterance is first decoded and aligned with the decoding output hypothesis without FWP, then the feature is warped with all possible grid points, and the ML-score is calculated with those warped features on the voiced phonemes in the path of alignment. <p> In that case, we do not need to do forced-alignment for all warping factors. Our experimental result shows that the error rate is almost the same as the test pro-cedure in <ref> [4] </ref>, but reduce the decoding computation. Obviously, compared to the regular test procedure, the FWP test needs to do an extra decoding and forced-alignment plus the calculation of ML score for every warping factor.
Reference: [5] <author> Ellen Eide and Herbert Gish. </author> <title> A parametric approach to vocal tract length normalization. </title> <journal> ICASSP-96, </journal> <volume> 1 </volume> <pages> 346-348, </pages> <year> 1977. </year>
Reference-contexts: Therefore, many researchers have been working on the VTL normalization via FWP in order to compensate for the speaker variation. The earlier researches were focused on the identification of isolated vowel [1, 2, 3]. In the recent researches, the FWP was investigated in continuous speech recognition system <ref> [4, 5] </ref>. In [4], a linear FWP was investigated, and the warping factors were obtained by grid search based on Maximum-Likelihood (ML) criterion. We refer this method as ML-based FWP. <p> We refer this method as ML-based FWP. The advantage of the ML-based FWP is that it guarantees to find the warping factor which is optimal in the ML criterion. The weakness of this method is that it is relatively expansive in computation. In <ref> [5] </ref>, a parametric approach for FWP was proposed. We refer this method as formant-based FWP. The idea is the same as in [2, 3], i.e., the warping factors were obtained from formant estimation. But they investigated the method in large vocabulary continuous speech recognition system. <p> If F is set to F N , then the warping is equal to those in <ref> [5] </ref>. 2.3. Training Procedure For the formant-based FWP, we use the Waves+ software to estimate formants (up to the third formant) of each speaker in the training set.
Reference: [6] <author> Charles. R Jankowski Jr., Hoang-Doan H. Vo, and Richard P. Lippmann. </author> <title> A comparison of signal processing front ends for automatic word recognition. </title> <journal> IEEE transactions on Speech and Audio Processing, </journal> <volume> 3 </volume> <pages> 286-293, </pages> <year> 1995. </year>
Reference-contexts: In the typical front-end processing of speech recognition systems, X (!) is passed through a filterbank with triangular shaped filters spaced according to the Melscale <ref> [6, 7] </ref>. Hence the signal passing through such a filterbank can be formulated as: Y (i) = !=! il Where N is the number of filters, and ! il and ! ih are the lower and upper bound of the i-th filter T i (!).
Reference: [7] <author> Hynek Hermansky, Nelson Morgan, Aruna Bayya, and Phil Kohn. </author> <title> Rasta-plp speech analysis technique. </title> <booktitle> ICASSP-92, </booktitle> <pages> pages I-121-124, </pages> <year> 1992. </year>
Reference-contexts: In the typical front-end processing of speech recognition systems, X (!) is passed through a filterbank with triangular shaped filters spaced according to the Melscale <ref> [6, 7] </ref>. Hence the signal passing through such a filterbank can be formulated as: Y (i) = !=! il Where N is the number of filters, and ! il and ! ih are the lower and upper bound of the i-th filter T i (!). <p> Figure 1 is the block diagram of the JANUS front-end preprocessing. Where x t is warping factors # the input speech signal and z n the output PLP feature vector. FWP represents Frequency Warping, and PLP means Perceptual Linear Predictive <ref> [7] </ref>. The feature we are using in the experiments is the same as in [8], except here we insert a FWP step between FFT and PLP processing. The final feature is a 13-order Perceptual Linear Predictive (PLP) feature plus a power coefficient.
Reference: [8] <author> Puming Zhan, Klaus Ries, Marsal Gavalda, Donna Gates, Alon Lavie, and Alex Waibel. </author> <title> Janus-ii: Towards spontaneous spanish speech recognition. </title> <address> ICSLP-96, </address> <year> 1996. </year>
Reference-contexts: Where x t is warping factors # the input speech signal and z n the output PLP feature vector. FWP represents Frequency Warping, and PLP means Perceptual Linear Predictive [7]. The feature we are using in the experiments is the same as in <ref> [8] </ref>, except here we insert a FWP step between FFT and PLP processing. The final feature is a 13-order Perceptual Linear Predictive (PLP) feature plus a power coefficient. <p> EXPERIMENTS All experiments are based on our new JANUS speech recognition system. Compared to the JANUS-II system in <ref> [8] </ref>, the new system uses polyphone, instead of triphone context in the acoustic model and clusters the models based on a decision-tree. We already used the formant-based FWP on the Switchboard database and reached about 5% relative error reduction. <p> The ML-based FWP was successfully used on the GSST (German SST) before and reduced the error rate by about 12% [9]. In the following sections we report results obtained on the SSST database comparing both methods. Compared to the database in <ref> [8] </ref>, we increased about 4500 cross-talk utterances in the training set, and keep the same Devset. Thus there are 10650 utterances (5785 from 68 female speakers and 4865 from 72 male speakers), which is about 12 hours data, for training.
Reference: [9] <author> Michael Finke, Petra Geutner, Hermann Hild, Thomas Kemp, Klaus Ries, and Martin Westphal. </author> <title> The karlsruhe-verbmobil speech recognition engine. </title> <address> ICASSP-97, </address> <year> 1997. </year>
Reference-contexts: We already used the formant-based FWP on the Switchboard database and reached about 5% relative error reduction. The ML-based FWP was successfully used on the GSST (German SST) before and reduced the error rate by about 12% <ref> [9] </ref>. In the following sections we report results obtained on the SSST database comparing both methods. Compared to the database in [8], we increased about 4500 cross-talk utterances in the training set, and keep the same Devset.
Reference: [10] <author> Fant G. </author> <title> Speech sounds and features. </title> <year> 1973. </year>
Reference-contexts: It means that FWP could not reduce the variations for some of the speakers. We think one of the reason might be the warping functions, linear or exponential, does not reflect the relationship between formants and VTL, because of the context-dependence of such relationship <ref> [10] </ref>. Another reason for the ML-based FWP might be that the warping factor, is only optimal for the models which appear in the alignment path, i.e., increasing their ML-score, it could increase more ML-score for the other models too. <p> Because Formats are context dependent, it should be better if formants are estimated based on the same context over all speakers. We calculated the average male and female VTL with the formulate in [2], and obtained 16.45cm for male (15.47cm for female) which is near the standard value (17cm) <ref> [10] </ref>. We found that F 3 is the best one for estimating VTL. This might be that vowel-dependence of the F 3 is not as strong as the first two.
References-found: 10

