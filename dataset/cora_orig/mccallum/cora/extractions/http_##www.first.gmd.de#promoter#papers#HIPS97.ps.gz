URL: http://www.first.gmd.de/promoter/papers/HIPS97.ps.gz
Refering-URL: http://www.first.gmd.de/promoter/papers/index.html
Root-URL: 
Email: fmb,bi,ens,heber,wilhelmig@first.gmd.de  
Title: HighLevel Data Parallel Programming in Promoter  
Author: Matthias Besch, Hua Bi, Peter Enskonatus, Gerd Heber, Matthias Wilhelmi 
Affiliation: RWCP Massively Parallel Systems GMD Laboratory Berlin, Germany GMD  
Date: April 1-5, 1997,  
Address: Geneva, Switzerland,  FIRST, Rudower Chaussee 5, D12489 Berlin  
Note: In the Proceedings of the Second International Workschop on Highlevel Parallel Program--ming Models and Supportive Environments held in conjunction with and supported bu The 11th International International Processing Symposium (IPPS 97),  pages 47-54, Copyright 1997 IEEE  
Abstract: MOTER pursues a twolevel approach allowing easy and flexible programming at both language and library levels. The core concept of PROMOTER's language model is its highly abstract and unified concept of data and communication structures. The paper briefly addresses the programming model, but focuses on implementation aspects of the compiler and runtime system. Finally, performance results are given, evaluating the efficiency of the PROMOTER system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. P. Allen and D. J. Tildesley. </author> <title> Computer Simulation of Liquids. </title> <publisher> Claredon Press, Oxford, </publisher> <year> 1994. </year>
Reference-contexts: Let us assume for simplicity that our boxes contain at most one particle. The motion of the particles is simulated by a Gear predictor/corrector algorithm <ref> [1] </ref>. Here, the programmer is faced with the problem that particles migrate between boxes, i.e. between processors.
Reference: [2] <author> B. Appelbe and D. Bergmark. </author> <title> Software Tools for High Performance Computing: Survey and Recomendations. </title> <journal> Scientific Programming, </journal> <volume> 5(3), </volume> <year> 1996. </year>
Reference-contexts: Although parallel programming is intrinsically complex, the principal reason why highperformance computing is difficult is the lack of software tools . . . which leads to wasted computer resources and inhibits the use of highperformance parallel computers by scientists <ref> [2] </ref>. 4.1.
Reference: [3] <author> M. Besch and H. W. Pohl. </author> <title> Topographic data mapping by balanced hypersphere tessellation. </title> <booktitle> In Proc. Euro-Par `96, </booktitle> <address> Lyon, France, </address> <month> August </month> <year> 1996, </year> <booktitle> Lecture Notes in Computer Science 1124, </booktitle> <pages> pages 455458. </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: Aside from simple tiling strategies, there are general graphbased multipartitioning algorithms such as an improved and generalized version of the Kernighan&Lin heuristic [15] or spectral bisection, as well as a fast topographic mapping approach called BHT <ref> [3] </ref>. The latter is particularly appropriate for finiteneighborhood communication within a single index spaces. The optimization phase works mainly on the descriptors, which reflect the transformations for the generation of a message passing SPMD program. It tries to reduce the initially generated number of messages and synchronization points.
Reference: [4] <author> H. Bi. </author> <title> Towards abstractin of message passing programming. </title> <booktitle> In Proc. of International Conference on advances in parallel and distributed Computing, </booktitle> <pages> pages 100107, </pages> <address> Shanghai, China, March 1997. </address> <publisher> IEEE CS Press. </publisher>
Reference-contexts: In summary, the runtime library defines a generic interface and allows applicationdependent specialization and optimization applicable by a compiler. Besides, the run-time library is also designed as a userlevel library to support abstract message passing programming that assumes no special support from a compiler <ref> [4] </ref>. 4. Programming in Promoter Applications programming for highperformance computing is notoriously difficult.
Reference: [5] <author> C. Chang, J. Saltz, and A. Sussman. </author> <title> CHAOS++: A Runtime Library for Supporting Distributed Dynamic Data Structure. </title> <type> Technical report, </type> <institution> Center for Res. on Parallel Computation, Rice University, </institution> <month> Nov </month> <year> 1995. </year>
Reference-contexts: By providing valuable applicationspecific information it generally eases the task of mapping for compiler and runtime system. Particularly, in numerical applications spatial structures are often based on geometrical information, which directly can be exploited by the mapping subsystem. Recently, CHAOS++ <ref> [5] </ref> has been released. It subsumes CHAOS and Multiblock Parti, and provides additional support for distributed pointerbased data structures. In PROMOTER, support for distributed pointerbased data structures will be handled by dynamic topologies [18], i. e. a distributed object can change its shape at runtime.
Reference: [6] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <booktitle> Scientific Computing, </booktitle> <address> 1(1):3150, </address> <year> 1992. </year>
Reference-contexts: Data parallel programming languages such as HPF [12], Fortran D [13], Vienna Fortran <ref> [6] </ref>, HPC++ [21], and the like already considerably relax this problem. Intended for the use in scientific computing, these languages focus on dense regular array computations. <p> In recent years, there have been major efforts in developing language and runtime library and compiler support for programming distributed memory machine. Roughly speaking, there are two major directions in those efforts. In the Fortran world, HPF [12], Fortran D [13], Vienna Fortran <ref> [6] </ref> and others are developed, in the C world, HPC [21], ICC++ [7], MPC++ [14], pC++ [16], EC++ [20] and others are in progress. Most of the approaches support twolevel data parallel programming.
Reference: [7] <author> A. A. Chien and J. Dolby. </author> <title> The Illinois Concert System: </title>
Reference-contexts: Roughly speaking, there are two major directions in those efforts. In the Fortran world, HPF [12], Fortran D [13], Vienna Fortran [6] and others are developed, in the C world, HPC [21], ICC++ <ref> [7] </ref>, MPC++ [14], pC++ [16], EC++ [20] and others are in progress. Most of the approaches support twolevel data parallel programming. For example, the Fortran D compiler inserts calls to the Multiblock Parti [19] and Chaos [8] library routines to manage communication.
References-found: 7

