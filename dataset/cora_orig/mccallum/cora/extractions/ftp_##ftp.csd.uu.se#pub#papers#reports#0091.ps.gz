URL: ftp://ftp.csd.uu.se/pub/papers/reports/0091.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Title: SLDR-Resolution: Parallelizing Structural Recursion in Logic Programs compiled in a novel way: the unifications correspond
Author: H-akan Millroth 
Note: Unification in SLDR-resolution can be  which was developed in the context of imperative programming in the early 1970s. To appear in Journal of Logic Programming.  
Date: November 25, 1994  
Affiliation: Uppsala University  
Abstract: We introduce a new operational semantics, SLDR-resolution, for a class of recursive logic programs. We establish the soundness and completeness of SLDR-resolution by showing that one SLDR-resolution inference is equivalent to n 1 SLD-resolution inferences. SLDR-resolution facilitates parallel processing of recursive programs and can exploit parallelism that is not exploitable in SLD-resolution. In contrast to SLD-resolution, where each recursive invocation of a program typically results in a small unification, SLDR-resolution results in large unification computations amenable to optimization and parallelization. Moreover, SLDR-resolution allows a form of AND-parallelism in which the recursive invocations of a procedure start computing simultaneously. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Barklund, </author> <title> Parallel Unification, </title> <type> Ph.D. Thesis, </type> <institution> Uppsala Theses in Computer Science 9/90, Uppsala University, </institution> <year> 1990. </year>
Reference-contexts: Furthermore, a list of n elements can be constructed in dn=pe steps using p processors. Barklund has designed a parallel unification algorithm using these techniques <ref> [1] </ref> that can be exploited with SLDR-resolution. In this paper we restrict the discussion to unification-based logic programming languages. However, SLDR-resolution can also be applied to constraint logic programming. The analog of parallel unification is then parallel constraint solving. <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 <ref> [1; 2; 3; 4] </ref> = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H <p> of Ai is assigned to the scalar variable y. 28 A straight-forward sequential implementation of this operation (for the case when y is a vector) is: n 0; while is list (Ai) do n n + 1; x [n] head (Ai); y [n] tail (Ai); Ai tail (Ai); od Barklund <ref> [1] </ref> defines a data-parallel algorithm for this operation. The algorithm runs in O (log n) time for linear lists (a list is linear if no variable occurs more than once). <p> We assume the following behaviour of the operation hn; x; yi traverse (Ai) when Ai is an unbound variable: Ai is bound to a new list cell cons (x <ref> [1] </ref>; y [1]) and n is set to 1. Other lists with poslist tails Two additional issues that must be dealt with for other lists with poslist tails, such as the list [A j Z] in the append program above. <p> We assume the following behaviour of the operation hn; x; yi traverse (Ai) when Ai is an unbound variable: Ai is bound to a new list cell cons (x <ref> [1] </ref>; y [1]) and n is set to 1. Other lists with poslist tails Two additional issues that must be dealt with for other lists with poslist tails, such as the list [A j Z] in the append program above. First, the list in the call might be only partly constructed. <p> Then y <ref> [1] </ref> is created by head unification and we can also assume that the expansion x [1 : n] of X is available. <p> Our first example is from an insertion sort program. sort ([A|X],Y) :- sort (X,Z), insert (Z,A,Y). Compiled code: hn; a; xi traverse (A1); y <ref> [1] </ref> A2; forall i 2 to n + 1 do y [i] new variable (); call sort (x; y [n + 1]); forall i n downto 1 do call insert (y [i + 1]; a [i]; y [i]); As in the naive reverse example, we store the single needed value of <p> Our final example is from a program that reverses a list using an accumulating parameter. rev ([A|X],Y,Z) :- rev (X,[A|Y],Z). Compiled code: hn; a; xi traverse (A1); y <ref> [1] </ref> A2; for i 2 to n + 1 do y [i] cons (x [i 1]; y [i 1]); z A3; call rev (x; y [n + 1]; z); This code|although sequential|is quite efficient. 2 9 Related work Tarnlund first noted that complete unfolding of the recursion in a logic program
Reference: [2] <author> J. Bevemyr, </author> <title> A Recursion Parallel Prolog Engine, Ph.L. </title> <type> Thesis, </type> <institution> Uppsala Theses in Computer Science 16/93, Uppsala University, </institution> <year> 1993. </year>
Reference-contexts: The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 <ref> [1; 2; 3; 4] </ref> = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; <ref> [2; 3; 4] </ref>) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i <p> SLDR-resolution, and the compilation method described in the present paper, is implemented in the Reform Prolog system <ref> [2, 3, 4, 11] </ref>. The system 34 has been implemented on Sun and Sequent shared-memory multiprocessors.
Reference: [3] <author> J. Bevemyr, T. Lindgren & H. Millroth, </author> <title> Exploiting recursion-parallelism in Prolog, </title> <booktitle> Proc. Int. Conf. </booktitle> <editor> PARLE-93, (eds. A. Bode, M. Reeve & G. Wolf), </editor> <publisher> LNCS 694, Springer-Verlag, </publisher> <year> 1993. </year> <month> 35 </month>
Reference-contexts: The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 <ref> [1; 2; 3; 4] </ref> = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; <ref> [2; 3; 4] </ref>) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; <ref> [3; 4] </ref>) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i i ^ H 0 i <p> SLDR-resolution, and the compilation method described in the present paper, is implemented in the Reform Prolog system <ref> [2, 3, 4, 11] </ref>. The system 34 has been implemented on Sun and Sequent shared-memory multiprocessors.
Reference: [4] <author> J. Bevemyr, T. Lindgren & H. Millroth, </author> <title> Reform Prolog: The language and its implementation, </title> <booktitle> in Proc. 10th Int. Conf. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 <ref> [1; 2; 3; 4] </ref> = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; <ref> [2; 3; 4] </ref>) notin (2; [3; 4]) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; <ref> [3; 4] </ref>) notin (3; [4]) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i i ^ H 0 i <p> The compilation corresponds to obtaining closed-form expressions for this system of equations. 17 Phase Computation 1 [1; 2; 3; 4] = [A1; A2; A3; A4] notin (1; [2; 3; 4]) notin (2; [3; 4]) notin (3; <ref> [4] </ref>) notin (4; []) 3 diffall ([]) 4 | phase 2 are computed in parallel. 18 7.1 Variable expansions Consider a recursive clause H ^ H 0 ^ , where H 0 is the recursive call, and its n variants H i i ^ H 0 i ^ i . <p> SLDR-resolution, and the compilation method described in the present paper, is implemented in the Reform Prolog system <ref> [2, 3, 4, 11] </ref>. The system 34 has been implemented on Sun and Sequent shared-memory multiprocessors.
Reference: [5] <author> K. De Bosschere, S.K. Debray, D. Gudeman & S. Kannan, </author> <title> Call Forwarding: A simple interprocedural optimization technique for dynamically typed languages, </title> <booktitle> Proc. 21st ACM Symp. Principles of Programming Languages, </booktitle> <year> 1994. </year>
Reference-contexts: As discussed in the Introduction, implementing recursion by iteration in this way can avoid redundant type checking and other overheads associated with the recursive procedure calls. However, this effect can also be obtained by the call forwarding optimization technique, described by De Bosschere et al <ref> [5] </ref>, where different entry points of a procedure are derived using information at the call site.
Reference: [6] <author> K.L. Clark, </author> <title> Negation as failure, Logic and Databases (eds. </title> <editor> H. Gallaire & J. Minker), </editor> <publisher> Plenum Press, </publisher> <year> 1978. </year>
Reference-contexts: We fix T to be Clark's syntactic equality theory <ref> [6] </ref>. Let = fx 1 = t 1 ; : : : ; x n = t n g be the solution of a set of equations and let w be a term.
Reference: [7] <author> S.K. Debray, N.-W. Lin & M. Hermenegildo, </author> <title> Task granularity analysis in logic programs, </title> <booktitle> Proc. ACM SIGPLAN Conf. Programming Language Design and Implementation, </booktitle> <year> 1990. </year>
Reference-contexts: We will now consider a method for breaking the data dependencies of this program. Assume that we can compute the relative sizes of certain terms in the program at compile-time (several algorithms for this task are known <ref> [7, 15] </ref>). Hence we can infer that if size ([A j X]) = n + 1, then size (Z) = size (X) = n.
Reference: [8] <author> W.D. Hillis & G.L. Steele, </author> <title> Data parallel algorithms, </title> <journal> Comm. ACM 29, </journal> <volume> 11 (1986): </volume> <pages> 1170-83. </pages>
Reference-contexts: This program involves list traversal and construction that cannot be paral-lelized in SLD-resolution. But it is well-known that, using p processors, a linked list structure with n elements can be traversed in dn (log n)=pe steps given only a pointer to the first list cell <ref> [8] </ref>. Furthermore, a list of n elements can be constructed in dn=pe steps using p processors. Barklund has designed a parallel unification algorithm using these techniques [1] that can be exploited with SLDR-resolution. In this paper we restrict the discussion to unification-based logic programming languages.
Reference: [9] <author> R.A. Kowalski, </author> <title> Predicate logic as a programming language, </title> <booktitle> Information Processing 74, </booktitle> <year> 1974. </year>
Reference: [10] <author> D.J. Kuck, Y. Muraoka & S. Chen, </author> <title> On the number of operations simultaneously executable in Fortran-like programs and their resulting speedup, </title> <journal> IEEE Trans. Computers C-21, </journal> <volume> 12 (1972): </volume> <pages> 1293-1310. </pages>
Reference-contexts: It is possible to run all iterations of a for-loop simultaneously on a 2 parallel computer, a fact that parallelizing Fortran compilers have exploited since the early 1970s <ref> [10] </ref>. Hence this iterative program is as parallel as the unfolded one. We present in this paper a compilation technique for compiling a special case of recursion, where the recursion bound can easily be computed, to for-loops.
Reference: [11] <author> T. Lindgren, </author> <title> The Compilation and Execution of Recursion-Parallel Pro-log on Shared Memory Multiprocessors, Ph.L. </title> <type> Thesis, </type> <institution> Uppsala Theses in Computer Science 18/93, Uppsala University, </institution> <year> 1993. </year>
Reference-contexts: SLDR-resolution, and the compilation method described in the present paper, is implemented in the Reform Prolog system <ref> [2, 3, 4, 11] </ref>. The system 34 has been implemented on Sun and Sequent shared-memory multiprocessors.
Reference: [12] <author> H. Millroth, </author> <title> Reforming Compilation of Logic Programs, </title> <type> Ph.D. Thesis, </type> <institution> Uppsala Theses in Computer Science 10/90, Uppsala University, </institution> <year> 1990. </year>
Reference-contexts: This approach was the initial motivation for the work reported here. The idea to use iteration to represent the completely unfolded recursion at compile-time, as well as a similar technique for nonlinear recursion on e.g. binary trees, first appeared in the author's thesis <ref> [12] </ref>. SLDR-resolution, and the compilation method described in the present paper, is implemented in the Reform Prolog system [2, 3, 4, 11]. The system 34 has been implemented on Sun and Sequent shared-memory multiprocessors.
Reference: [13] <author> D.A. Padua, D.J. Kuck & D. Lawrie, </author> <title> High-speed Multiprocessors and compilation techniques, </title> <journal> IEEE Trans. Comp., C-29, </journal> <volume> 9 (1980): </volume> <pages> 763-76. </pages>
Reference-contexts: E'; the difference matters only if the loops are executed sequentially.) 8.2 Representation of variables How do we represent variables in the compiled program? The idea is that a variable is represented at run-time by its expansion implemented as a vector. (The reader might notice the analogy with scalar expansion <ref> [13] </ref> in compilation of Fortran.) The expansion of a pos-variable X is hT 2 ; : : : ; T n ; X n i, where T i is the ith element of the expansion of some term T .
Reference: [14] <editor> S. A. Tarnlund, </editor> <booktitle> Logic Information Processing, TRITA-IBADB 1034, </booktitle> <institution> Dept. of Information Processing and Computer Science, Royal Institute of Technology and Univ. of Stockholm, </institution> <year> 1975. </year>
Reference-contexts: 1 do y [i] cons (x [i 1]; y [i 1]); z A3; call rev (x; y [n + 1]; z); This code|although sequential|is quite efficient. 2 9 Related work Tarnlund first noted that complete unfolding of the recursion in a logic program vastly increases the potential for AND-parallel execution <ref> [14] </ref>. In later (unpublished) work, Tarnlund devised an algorithm for carrying out the unfolding at runtime, using O (log n) unfolding steps for recursion bound n. This approach was the initial motivation for the work reported here.
Reference: [15] <author> K. Verschaetse & D. De Schreye, </author> <title> Deriving termination proofs for logic programs using abstract procedures, </title> <booktitle> Proc. 8th Int. Conf. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> 36 </month>
Reference-contexts: We will now consider a method for breaking the data dependencies of this program. Assume that we can compute the relative sizes of certain terms in the program at compile-time (several algorithms for this task are known <ref> [7, 15] </ref>). Hence we can infer that if size ([A j X]) = n + 1, then size (Z) = size (X) = n.
Reference: [16] <author> D.H.D. Warren, </author> <title> Implementing Prolog|compiling predicate logic pro-grams, </title> <note> Research Reports 39 and 40, </note> <institution> Dept. of AI, Univ. of Edinburgh, </institution> <year> 1977. </year>
Reference-contexts: In this section we discuss the first phase. We refer to the arguments of the invoking call as A1, A2, etc. Warren's unification scheme We start by reviewing Warren's scheme for unification of terms in the invoking call with terms in the clause head <ref> [16, 17] </ref>. Let us first consider unification of a call argument Ai with a variable X in the clause head.
Reference: [17] <author> D.H.D. Warren, </author> <title> An abstract Prolog instruction set, </title> <type> Report 309, </type> <institution> SRI International, </institution> <address> Menlo Park, CA., </address> <year> 1983. </year> <month> 37 </month>
Reference-contexts: We describe compiled code for recursive clauses only for the case when the recursion argument is instantiated. We assume that a sequential version of the code (e.g., standard WAM <ref> [17] </ref> code) is invoked when the recursion argument is an unbound variable. 8.1 Notation The pseudo-code notation used below is fairly standard. <p> In this section we discuss the first phase. We refer to the arguments of the invoking call as A1, A2, etc. Warren's unification scheme We start by reviewing Warren's scheme for unification of terms in the invoking call with terms in the clause head <ref> [16, 17] </ref>. Let us first consider unification of a call argument Ai with a variable X in the clause head.
References-found: 17

