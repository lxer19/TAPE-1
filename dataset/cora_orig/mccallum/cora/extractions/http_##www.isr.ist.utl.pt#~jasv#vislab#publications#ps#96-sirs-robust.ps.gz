URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/ps/96-sirs-robust.ps.gz
Refering-URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/publications.html
Root-URL: 
Email: fetienne,jasvg@isr.ist.utl.pt  
Title: Robust Affine Flow Estimation with Controlled Computation Cost  
Author: Etienne Grossmann Jose Santos-Victor Torre Norte Piso Av. Rovisco Pais, P Lisboa Codex PORTUGAL 
Affiliation: Instituto de Sistemas e Robotica, Instituto Superior Tecnico  
Abstract: This paper addresses a classical problem -optical flow- for which we propose novel estimation algorithms based on robust regression. Another important aspect of our work is that we are concerned with the computational efficiency of our estimators, in the sense of maximizing its performance, for a chosen computation cost. This concern about efficient estimation appears often in active vision. It poses a much harder problem than estimation alone, and there seem to be very few theoretical results. After discussing the issue of performance assessment, we present a practical method for comparing the performance of different estimators, and the results obtained when comparing our algorithms with a more classical one. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.L.Barron , D.J Fleet, S.S.Beauchemin, </author> <title> "Performance of Optical Flow Techniques" , Proc CVAP 1992 or Robotics and Perception Laboratory (Queen's University Kingston, </title> <address> Ontario, Canada , 1992 </address>
Reference-contexts: A review of different approaches for optic flow estimation can be found in <ref> [1] </ref>.
Reference: 2. <author> William T. Freeman and Edward H. Adelson, </author> <title> "Steerable filters for image analysis", </title> <type> TR 126, </type> <institution> MIT, Media Laboratory, </institution> <year> 1990. </year>
Reference-contexts: This, in conjunction with the use of autoregression time-smoothing, further justifies the term "anisotropic"; the term "steerable" is used with a somewhat similar meaning to qualify spatial image filters that can be oriented according to the image gradient <ref> [2] </ref>. 3.3 Solving for the Affine Flow Parameters Here we discuss how to solve for the six parameters that define the affine flow. We have a sequence of images, and will successively estimate the value of the parameters at all instants.
Reference: 3. <author> Etienne Grossmann, Jose Santos-Victor, </author> <title> "Quality evaluation of optic flow estimators : A need for vision-based robotics", </title> <booktitle> in "Advances in Robotics Research", </booktitle> <publisher> World Scientific Publishing, </publisher> <year> 1996. </year>
Reference-contexts: The norm we used reflects the difference in magnitude of the components of the estimates. We used the empirical expectancy of this measure to assess the quality of an estimator 5 . This quality measure was partly extended in <ref> [3] </ref> to the case when no ground truth is available. The computational cost of the implementation of an estimator is often a crucial consideration, for example in active vision. Thus, being able to characterize the performance in terms of computational cost (or the contrary) appears a central issue.
Reference: 4. <author> Seven short texts by R.M. Haralick; L.Cinque, C.Guerra and S.Levialdi; J.Weng and T.S.Huang; P.Meer; Y. Shirai; B.A.Draper and J.R. </author> <title> Beveridge : Dialogue on "Performance characterisation in computer vision", </title> <booktitle> in CVGIP on Image Understanding v.60 n.2 pp.245-265, </booktitle> <pages> '94. </pages>
Reference-contexts: This method is usually reserved to final development tests. Few options are left between these two extremes, and this is certainly a research issue deserving attention. For a general discussion on performance analysis in computer vision, see <ref> [4] </ref>. When choosing a criterion on the quality of an estimator, one usually starts by addressing the quality of an estimate. As often in computer vision, this choice is difficult because of the non-rigorous definition of the desired output, and many quality measures can be encountered in the literature.
Reference: 5. <author> Berthold Klaus Paul Horn, </author> <title> "Robot vision", </title> <publisher> M.I.T. Press, </publisher> <year> 1985. </year>
Reference-contexts: Thanks to the reviewers for suggestions. Special thanks to Cesar Silva for his help in troubleshooting. 2 Optical Flow The definition of the optical flow is well known (see <ref> [5] </ref>), and it is widely accepted that the optic flow estimation is an ill-posed problem. A review of different approaches for optic flow estimation can be found in [1].
Reference: 6. <author> Peter J. Huber, </author> <title> "Robust statistics", </title> <publisher> John Wiley and sons 1981. </publisher>
Reference-contexts: The robust estimate of the flow parameters, is computed iteratively, through a sequence of estimates which -hopefully- converges to the solution, as shown in Figure 2. We implemented the estimators in two ways : One follow closely the suggestions in <ref> [6] </ref>, and is illustrated on the left side of Figure 2. <p> In our case, a "robust" version of the SSD is minimized. There are different variants of robust regression <ref> [6] </ref>, the choice of which, determines the cost function minimized by the estimate. <p> An interesting study of "performance versus time-cost" appeared recently in [8]. In our case, this is equivalent to "performance versus number of estimates" (when all other parameters are fixed). In turn, one can show theoretically <ref> [6] </ref> |and observe in practice| that the error is inversely proportional to the number of observations. Still more interesting would be a study of "performance versus time-cost" when for each given time-cost value, all the parameters are set to optimize performance (instead of being fixed).
Reference: 7. <author> Jan J. Koenderinck and A.J. </author> <title> Doorn "Invariant properties of the motion parallax field due to the movement of rigid bodies relative to an observer" Optica Ccta 22, </title> <type> pp 773-791, </type> <year> 1975. </year>
Reference-contexts: We consider the optical flow as the projection of the 3D motion in the watched scene onto the image plane. As such, it is a rich source of information about structure and motion.This has been studied in papers by Koenderinck and Doorn,in <ref> [7] </ref>, Longuet-Higgins and Pradzny in [9], or more extensively in Subbarao's book [11]. For example, knowledge |in a single pixel| of the flow and its derivatives gives information about both the relative motion of the camera and the surface "seen" in that pixel, and the orientation of that surface.
Reference: 8. <author> Hongche Liu, Tsai-Hong Hong, Martin Herman and Rama Chellappa, </author> <title> "Accuracy vs. efficiency trade-offs in optical flow algorithms", </title> <booktitle> Proc. of the 4th ECCV, </booktitle> <volume> vol. 2, </volume> <pages> pp. 174-183, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: An interesting study of how the performance of optic flow estimators varies with the available computational resource is given in in <ref> [8] </ref>. As opposed to that paper, we do not consider procedures that compute the optic flow in every pixel, but the affine flow (the flow and its first derivatives). <p> Being able to compare algorithms and parameter setups on specific data does not give us much insight on the reasons of their performance. An interesting study of "performance versus time-cost" appeared recently in <ref> [8] </ref>. In our case, this is equivalent to "performance versus number of estimates" (when all other parameters are fixed). In turn, one can show theoretically [6] |and observe in practice| that the error is inversely proportional to the number of observations.
Reference: 9. <author> H.C. </author> <title> Longuet-Higgins and K.Prazdny "the interpretation of a moving retinal image", </title> <journal> proceedings of the royal society of London, </journal> <volume> B 208, </volume> <pages> pp 385-397, </pages> <year> 1980 </year>
Reference-contexts: We consider the optical flow as the projection of the 3D motion in the watched scene onto the image plane. As such, it is a rich source of information about structure and motion.This has been studied in papers by Koenderinck and Doorn,in [7], Longuet-Higgins and Pradzny in <ref> [9] </ref>, or more extensively in Subbarao's book [11]. For example, knowledge |in a single pixel| of the flow and its derivatives gives information about both the relative motion of the camera and the surface "seen" in that pixel, and the orientation of that surface.
Reference: 10. <author> Shahriar Negahdaripour and Shinhak Lee, </author> <title> "Motion recovery using only first order optical flow information" , IJCV 9:3, </title> <note> pp 163-184 , 1992. </note>
Reference-contexts: In many cases <ref> [10] </ref>, we can approximate the flow by an affine model, which is easier to estimate, and sufficient for many active-vision applications. We will consider this simplified model and study the effect of the approximation.
Reference: 11. <editor> Muralidhara Subbarao "interpretation of visual motion: </editor> <title> a computational approach", </title> <publisher> Morgan Kaufmann publishers,Inc, </publisher> <editor> San Mateo, </editor> <title> California This article was processed using the T E X macro package with SIRS96 style </title>
Reference-contexts: As such, it is a rich source of information about structure and motion.This has been studied in papers by Koenderinck and Doorn,in [7], Longuet-Higgins and Pradzny in [9], or more extensively in Subbarao's book <ref> [11] </ref>. For example, knowledge |in a single pixel| of the flow and its derivatives gives information about both the relative motion of the camera and the surface "seen" in that pixel, and the orientation of that surface.
References-found: 11

