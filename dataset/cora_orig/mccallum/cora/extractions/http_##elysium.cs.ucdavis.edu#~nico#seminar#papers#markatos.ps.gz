URL: http://elysium.cs.ucdavis.edu/~nico/seminar/papers/markatos.ps.gz
Refering-URL: http://elysium.cs.ucdavis.edu/~nico/seminar/samorodin.html
Root-URL: http://www.cs.ucdavis.edu
Email: Email: office@usenix.org  
Title: Implementation of a Reliable Remote Memory Pager  
Phone: 1. Phone: 510 528-8649 2. FAX: 510 548-5738 3.  4.  
Author: Evangelos P. Markatos and George Dramitinos 
Affiliation: Institute of Computer Science, FORTH, Crete  
Web: WWW URL: http://www.usenix.org  
Date: January 1996  
Note: The following paper was originally published in the Proceedings of the USENIX 1996 Annual Technical Conference San Diego, California,  For more information about USENIX Association contact:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. E. Anderson, M. D. Dahlin, J. M. Neefe, D. A. Patterson, D. S. Roselli, and R. Y. Wang. </author> <title> Serverless Network File Systems. </title> <booktitle> In Proc. 15-th Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Previous approaches either ignore workstation failures, or write dirty pages both to the disk and the remote memory, limiting their performance by the available disk throughput. Recently, research groups start to explore the issue of using remote memory to improve file system performance <ref> [11, 1, 8] </ref>. Feeley et. al. have implemented a global memory management system in a workstation cluster, using the idle memory in the cluster to store clean pages of memory loaded workstations [11]. Anderson et. al. have implemented xFS, a serverless network file system [1, 9]. <p> Feeley et. al. have implemented a global memory management system in a workstation cluster, using the idle memory in the cluster to store clean pages of memory loaded workstations [11]. Anderson et. al. have implemented xFS, a serverless network file system <ref> [1, 9] </ref>. Both network memory systems have been incorporated inside the kernel of existing operating systems and their performance has been demonstrated. <p> Finally, we use the network memory for storing both clean and dirty pages using our novel parity-based approach. Thus, page out (write) operations can be acknowledged at the speed of remote memory, while in <ref> [11, 1] </ref> page out operations are acknowledged at the speed of disk. Although the area of reliability in network memory systems is new, it shares several of the ideas developed for other areas of reliable memory management.
Reference: [2] <author> Thomas E. Anderson, David E. Culler, and David A. Patterson. </author> <title> A Case for NOW (Networks of Workstations). </title> <booktitle> IEEE Micro, </booktitle> <month> Febru-ary </month> <year> 1995. </year>
Reference-contexts: Similar ability is provided by Tele-graphos [19], Hamlyn [5], Memory Channel [13], and SHRIMP [4]. Fast remote memory accesses have also been implemented in software using Active Messages <ref> [26, 2] </ref>, programmed network interfaces [16], and trap-based remote invocation [25]. The ability to perform single remote memory accesses efficiently will enhance the performance of a remote memory paging policy, since the application can use them to access infrequently used pages. <p> In this case, a no reliability policy can be used, since all remote memory will be provided by a single host (the supercomputer). 6 Related Work Several research groups have studied the issues in using remote memory in a workstation cluster to improve paging performance <ref> [2, 12, 7, 15, 22, 3] </ref>. Felten and Zahorjian [12] have implemented a remote paging system on top of a traditional Ethernet based system, and presented an analytical model to predict its performance. Their performance results, although preliminary, are encouraging towards using remote memory paging systems. <p> Their results suggest that remote memory paging can be 20% to 100% faster than remote disk paging, depending on the disk access pattern. Anderson et. al. have proposed the use of network memory as backing store <ref> [2] </ref>. Their simulation results suggest that using remote memory over a 155Mbits/s ATM network "is 5 to 10 times faster than thrashing to disk" [2]. In their subsequent work [18], they outline the implementation of a remote memory pager on top of an ATM based network. <p> Anderson et. al. have proposed the use of network memory as backing store <ref> [2] </ref>. Their simulation results suggest that using remote memory over a 155Mbits/s ATM network "is 5 to 10 times faster than thrashing to disk" [2]. In their subsequent work [18], they outline the implementation of a remote memory pager on top of an ATM based network.
Reference: [3] <author> G. Bernard and S. Hamma. </author> <title> Remote Memory Paging in Networks of Workstations. </title> <booktitle> In Proceedings of the SUUG International Conference on Open Systems: Solutions for Open Word, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: In this case, a no reliability policy can be used, since all remote memory will be provided by a single host (the supercomputer). 6 Related Work Several research groups have studied the issues in using remote memory in a workstation cluster to improve paging performance <ref> [2, 12, 7, 15, 22, 3] </ref>. Felten and Zahorjian [12] have implemented a remote paging system on top of a traditional Ethernet based system, and presented an analytical model to predict its performance. Their performance results, although preliminary, are encouraging towards using remote memory paging systems.
Reference: [4] <author> M. Blumrich, K. Li, R. Alpert, C. Dub-nicki, E. Felten, and J. Sandberg. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> In Proceedings of the Twenty-First Int. Symposium on Computer Architecture, </booktitle> <pages> pages 142-153, </pages> <address> Chicago, IL, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: The SCI-to-SBUS interface provides SPARC workstations with the ability to access the memories of other workstations in a network using simple load and store operations [23]. Similar ability is provided by Tele-graphos [19], Hamlyn [5], Memory Channel [13], and SHRIMP <ref> [4] </ref>. Fast remote memory accesses have also been implemented in software using Active Messages [26, 2], programmed network interfaces [16], and trap-based remote invocation [25].
Reference: [5] <author> Greg Buzzard, David Jacobson, Scott Marovich, and John Wilkes. Hamlyn: </author> <title> a high-performance network interface with sender-based memory management. </title> <booktitle> In Proceedings of the Hot Interconnects III Symposium, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: The SCI-to-SBUS interface provides SPARC workstations with the ability to access the memories of other workstations in a network using simple load and store operations [23]. Similar ability is provided by Tele-graphos [19], Hamlyn <ref> [5] </ref>, Memory Channel [13], and SHRIMP [4]. Fast remote memory accesses have also been implemented in software using Active Messages [26, 2], programmed network interfaces [16], and trap-based remote invocation [25].
Reference: [6] <author> Peter M. Chen, Edward K. Lee, Garth A. Gibson, Randy H. Katz, and David A. Patter-son. </author> <title> RAID: High-Performance, Reliable Secondary Storage. </title> <journal> ACM Computing Surveys, </journal> <volume> 26(2) </volume> <pages> 145-185, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: To make matters worse, mirroring wastes half of the remote memory used. Parity: To reduce the main memory waste caused by mirroring, we can use parity-based re dundancy schemes much like the ones used in RAIDS <ref> [6] </ref>. Suppose, for example, that we have S servers, each having P pages. Page (i; j) is the j th page that resides on server i. <p> Although the area of reliability in network memory systems is new, it shares several of the ideas developed for other areas of reliable memory management. For example, parity based methods have been extensively used for Redundant Arrays of Inexpensive Disks (RAIDs) <ref> [6] </ref>. Log based methods have been used for Log based file systems, that send all updates to a file to be written in sequential blocks of the disk [21].
Reference: [7] <author> D. Comer and J. Griffoen. </author> <title> A new design for Distributed Systems: the Remote Memory Model. </title> <booktitle> In Proceedings of the USENIX Summer Conference, </booktitle> <pages> pages 127-135, </pages> <year> 1990. </year>
Reference-contexts: In this case, a no reliability policy can be used, since all remote memory will be provided by a single host (the supercomputer). 6 Related Work Several research groups have studied the issues in using remote memory in a workstation cluster to improve paging performance <ref> [2, 12, 7, 15, 22, 3] </ref>. Felten and Zahorjian [12] have implemented a remote paging system on top of a traditional Ethernet based system, and presented an analytical model to predict its performance. Their performance results, although preliminary, are encouraging towards using remote memory paging systems. <p> According to their measurements, a significant percentage of this time (close to 16 ms) is spend executing Mach IPC and TCP code. Comer and Griffoen <ref> [7] </ref> have implemented and compared remote memory paging vs. remote disk paging, over NFS, on an environment with diskless workstations. Their results suggest that remote memory paging can be 20% to 100% faster than remote disk paging, depending on the disk access pattern.
Reference: [8] <author> T. Cortes, S. Girona, and J. Labarta. </author> <note> PACA: </note>
Reference-contexts: Previous approaches either ignore workstation failures, or write dirty pages both to the disk and the remote memory, limiting their performance by the available disk throughput. Recently, research groups start to explore the issue of using remote memory to improve file system performance <ref> [11, 1, 8] </ref>. Feeley et. al. have implemented a global memory management system in a workstation cluster, using the idle memory in the cluster to store clean pages of memory loaded workstations [11]. Anderson et. al. have implemented xFS, a serverless network file system [1, 9].
References-found: 8

