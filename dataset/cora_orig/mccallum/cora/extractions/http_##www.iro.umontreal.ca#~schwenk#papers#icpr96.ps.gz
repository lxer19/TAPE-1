URL: http://www.iro.umontreal.ca/~schwenk/papers/icpr96.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00224.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: schwenk@robo.jussieu.fr  
Title: Constraint Tangent Distance for On-line Character Recognition  
Author: Holger Schwenk and Maurice Milgram 
Address: Paris 6, bo te 164 75252 Paris cedex 05, France.  
Affiliation: PARC, Universit e  
Date: August 1996  
Note: Published in International Conference on Pattern Recognition, pp. D:515-519,  
Abstract: In on-line character recognition we can observe two kinds of intra-class variations: small geometric deformations and completely different writing styles. We propose a new approach to deal with these problems by defining an extension of tangent distance [9], well known in off-line character recognition. The system has been implemented with a k-nearest neighbor classifier and a so called diabolo classifier [6] respectively. Both classifiers are invariant under transformations like rotation, scale or slope and can deal with variations in stroke order and writing direction. Results are presented for our digit database with more than 200 writers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bengio, Y., LeCun, Y., and Henderson, D. </author> <title> Globally trained handwritten word recognizer using spatial representation, convolutional neural networks and hidden Markov models. </title> <booktitle> In NIPS 6, </booktitle> <pages> pp. 937-944, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: For this reason some authors convert the coordinate sequence to representations which are not sensitive to these parameters. One example is the so called AMAP, low dimensional images containing local information about the properties of the trajectory <ref> [1] </ref>. Another interesting approach uses local 3fi3 pixmaps to improve a TDNN classifier [5]. None of these classifiers, however, incorporates knowledge how to deal with intra-class variations of characters, which are a big problem in a multi-writer environment. <p> The figure 6 gives an idea of the great variety of writing styles of this database (resampled to 11 points). We applied only a simple preprocessing: the characters were resampled, centered and size normalized to a (x,y)- coordinate sequence in <ref> [1; 1] </ref> 2n . Best results were obtained for only 11 points, but the errors increase only slightly for up to 50 points. No further features were extracted. We kept track of penups since they are necessary when calculating the derivatives @x=@t and @y=@t during classification. <p> Current work concentrates on the evaluation of the system on the UNIPEN database and the addition of a seg mentation module. Segmentation can be done by hypothesis generation like in <ref> [1] </ref>, or more classically by a HMM-module and a dictionary. In both cases, the high recognition speed of the diabolo classifier is very useful.
Reference: [2] <author> Garcia-Salicetti, S., Dorizzi, B., Gallinari, P., Mellouk, A. and Fanchon, D. </author> <title> An HMM extension of a neural predictive system for on-line cursive script recognition. </title> <booktitle> In ICDAR, </booktitle> <year> 1995. </year>
Reference-contexts: Most of them are motivated by successful systems in speech processing and exploit the sequential nature of the pen trajectory. Mainly we can find TDNN, for instance [3, 5], or predictive systems like in <ref> [2] </ref>. In on-line character recognition, however, we observe some problems not known in speech recognition, in particular inversion of writing direction and variations in stroke order. For this reason some authors convert the coordinate sequence to representations which are not sensitive to these parameters.
Reference: [3] <author> Guyon, I., Albrecht, P., LeCun, Y., Denker, J., and Weiss-man, H. </author> <title> Design of a neural network recognizer for a touch terminal. </title> <journal> In Pattern Recognition, </journal> <volume> 24(2) </volume> <pages> 105-119, </pages> <year> 1991. </year>
Reference-contexts: 1. Introduction During the last years different neural classification systems have been proposed for on-line character recognition. Most of them are motivated by successful systems in speech processing and exploit the sequential nature of the pen trajectory. Mainly we can find TDNN, for instance <ref> [3, 5] </ref>, or predictive systems like in [2]. In on-line character recognition, however, we observe some problems not known in speech recognition, in particular inversion of writing direction and variations in stroke order.
Reference: [4] <author> Hinton, G., Revow, M., and Dayan, P. </author> <title> Recognizing handwritten digits using mixtures of linear models. </title> <booktitle> In NIPS 7, </booktitle> <pages> pp. 1015-1022, </pages> <publisher> MIT-Press, </publisher> <year> 1995. </year>
Reference-contexts: Classification is done by finding the best fitting model among all classes and subclasses. This architecture can be interpreted as a hierarchical diabolo classifier. It is also very similar to the mixture of linear experts architecture proposed by Hinton et al. for off-line character recognition <ref> [4] </ref>. In our case, however, we incorporate a-priori knowledge by using constraint tangent distance instead of simple Euclidean distance. Our classifier could also be trained by their EM-approach in order to learn the responsibilities of each network for a subset of the learning data of one class (particular writing style).
Reference: [5] <author> Manke, S., M. Finke, M., and Waibel, A. </author> <title> The use of dynamic writing information in a connectionist on-line cursive handwriting recognition system. </title> <booktitle> In NIPS 7, </booktitle> <pages> pp. 1093-1100, </pages> <publisher> MIT-Press, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction During the last years different neural classification systems have been proposed for on-line character recognition. Most of them are motivated by successful systems in speech processing and exploit the sequential nature of the pen trajectory. Mainly we can find TDNN, for instance <ref> [3, 5] </ref>, or predictive systems like in [2]. In on-line character recognition, however, we observe some problems not known in speech recognition, in particular inversion of writing direction and variations in stroke order. <p> One example is the so called AMAP, low dimensional images containing local information about the properties of the trajectory [1]. Another interesting approach uses local 3fi3 pixmaps to improve a TDNN classifier <ref> [5] </ref>. None of these classifiers, however, incorporates knowledge how to deal with intra-class variations of characters, which are a big problem in a multi-writer environment. On the other hand, in off line character recognition efficient methods to deal with such variations have been de veloped.
Reference: [6] <author> Schwenk, H. and Milgram., M. </author> <title> Transformation invariant autoassociation with application to handwritten character recognition. </title> <booktitle> In NIPS 7, </booktitle> <pages> pp. 991-998, </pages> <publisher> MIT-Press, </publisher> <year> 1995. </year>
Reference-contexts: One of the most successful approach is probably tangent distance which is locally invariant under a set of specified transformations [9]. It can be implemented with a k-nearest neighbor classifier, or more efficiently with a so called diabolo classifier <ref> [6, 7] </ref>. In this paper we will show that it is possible to extend tangent distance so that it can be applied to stroke sequences. 2. <p> We have chosen to transform the references (vector p) and to leave the test vector unchanged (vector q). This allows to pre-calculate all tangent vectors and the matrix inversion of equation (6) or (8) respectively. A more efficient approach is the so called diabolo classifier <ref> [6] </ref>. The basic architecture is summarized in figure 5. The idea is to use one autoencoder network, also called di-abolo network, for each class to recognize and to train it only with examples of the corresponding class. Therefore, each network learns a model of one class. <p> Due to the increased input dimension more training data is needed. Again, small random transformations were used to generate 500 examples for learning and 200 for cross-validation. On this data we have trained the same classifiers that had shown excellent results on the NIST database <ref> [9, 6, 7] </ref>. Surprisingly we were not able to get an error rate lower than 1.8 % (15 examples). Therefore, we can say that it seems to be worth to do on-line character recognition. The knowledge how a character has been written helps to distinguish ambiguous examples.
Reference: [7] <author> Schwenk, H. and Milgram., M. </author> <title> Learning Discriminant Tangent Models for Handwritten Character Recognition. </title> <booktitle> In ICANN, </booktitle> <pages> pp. 585-590, </pages> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: One of the most successful approach is probably tangent distance which is locally invariant under a set of specified transformations [9]. It can be implemented with a k-nearest neighbor classifier, or more efficiently with a so called diabolo classifier <ref> [6, 7] </ref>. In this paper we will show that it is possible to extend tangent distance so that it can be applied to stroke sequences. 2. <p> The big advantage of a diabolo classifier in comparison to a k-nn classifier is that we need to calculate only ten (the number of classes) distance measures, independently of the number of learning data. Furthermore we can use a discriminant learning algorithm resulting in very good rejection behavior <ref> [7] </ref>. this example the 1 is correctly classified since the network for this class has the smallest reconstruction error. It is also interesting to see how the other networks find a stroke sequence of their class that is relatively close to the net input (2 and 7 in this example). <p> Due to the increased input dimension more training data is needed. Again, small random transformations were used to generate 500 examples for learning and 200 for cross-validation. On this data we have trained the same classifiers that had shown excellent results on the NIST database <ref> [9, 6, 7] </ref>. Surprisingly we were not able to get an error rate lower than 1.8 % (15 examples). Therefore, we can say that it seems to be worth to do on-line character recognition. The knowledge how a character has been written helps to distinguish ambiguous examples.
Reference: [8] <author> Simard, P., LeCun, Y., Denker, J. and Victorri, B., </author> <title> An Efficient Algorithm For Learning Invariances In Adaptive Classifiers. </title> <booktitle> In ICPR, </booktitle> <pages> pp. 651-655, </pages> <year> 1992. </year>
Reference-contexts: Simard [9]. Tangent distance, however, has been developed for pixel images and not for stroke sequences. In pixel space all the transformations are very non-linear and the calculation of the tangent vectors needs convolutions and is therefore relatively expensive <ref> [8] </ref>. Furthermore we must admit transformations of both vectors for optimal performance: D pq (p; q) = min ~ff; ~ fi (t (p; ~ff) t (q; ~ fi)) 2 .
Reference: [9] <author> Simard, P., LeCun, Y., and Denker, J. </author> <title> Efficient pattern recognition using a new transformation distance. </title> <booktitle> In Neural Information Processing Systems (NIPS 5), </booktitle> <pages> pp. 50-58. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: On the other hand, in off line character recognition efficient methods to deal with such variations have been de veloped. One of the most successful approach is probably tangent distance which is locally invariant under a set of specified transformations <ref> [9] </ref>. It can be implemented with a k-nearest neighbor classifier, or more efficiently with a so called diabolo classifier [6, 7]. In this paper we will show that it is possible to extend tangent distance so that it can be applied to stroke sequences. 2. <p> The thresholds can be chosen independently for each transformation, or it can be the same for all ones. In the second case, of course, the tangent vectors must be normalized. The above defined distance measure is very similar to tangent distance as proposed by P. Simard <ref> [9] </ref>. Tangent distance, however, has been developed for pixel images and not for stroke sequences. In pixel space all the transformations are very non-linear and the calculation of the tangent vectors needs convolutions and is therefore relatively expensive [8]. <p> Due to the increased input dimension more training data is needed. Again, small random transformations were used to generate 500 examples for learning and 200 for cross-validation. On this data we have trained the same classifiers that had shown excellent results on the NIST database <ref> [9, 6, 7] </ref>. Surprisingly we were not able to get an error rate lower than 1.8 % (15 examples). Therefore, we can say that it seems to be worth to do on-line character recognition. The knowledge how a character has been written helps to distinguish ambiguous examples.
References-found: 9

