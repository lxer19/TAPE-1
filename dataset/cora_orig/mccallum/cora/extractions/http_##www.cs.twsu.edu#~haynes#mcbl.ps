URL: http://www.cs.twsu.edu/~haynes/mcbl.ps
Refering-URL: http://adept.cs.twsu.edu/~thomas/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: [haynes,sandip]@euler.mcs.utulsa.edu  
Phone: (918) 631-3234  
Title: Learning Cases to Resolve Conflicts and Improve Group Behavior  
Author: Thomas Haynes and Sandip Sen 
Address: 600 South College Avenue Tulsa, OK 74104-3189  
Affiliation: Department of Mathematical Computer Sciences The University of Tulsa  
Abstract: Groups of agents following fixed behavioral rules can be limited in performance and efficiency. Adaptability and flexibility are key components of intelligent behavior which allow agent groups to improve performance in a given domain using prior problem solving experience. We motivate the usefulness of individual learning by group members in the context of overall group behavior. In particular, we propose a framework in which individual group members learn cases to improve their model of other group members. We use a testbed problem from the distributed AI literature to show that simultaneous learning by group members can lead to significant improvement in group performance and efficiency over agent groups following static behavioral rules.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David W. Aha, Dennis Kibler, and Marc K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6(1) </volume> <pages> 37-66, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: The set of actions corresponding to the most relevant case is then adapted to fit the current situation. Cardie [3] defined case-based learning (CBL) as a machine learning technique used to extend instance-based learning (IBL) <ref> [1] </ref>. The IBL algorithm retrieves the nearest instance (for our purposes, an instance can be thought of a case) to a state, and performs the suggested actions. There is no case adaptation if the retrieved instance is not a direct match to the current state.
Reference: [2] <author> M. Benda, V. Jagannathan, and R. Dodhiawalla. </author> <title> On optimal cooperation of knowledge sources. </title> <type> Technical Report BCS-G2010-28, </type> <institution> Boeing AI Center, Boeing Computer Services, Bellevue, WA, </institution> <month> August </month> <year> 1985. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26].
Reference: [3] <author> Claire Cardie. </author> <title> Using decision trees to improve case-based learning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 25-32. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1993. </year>
Reference-contexts: If there is no such match, then cases that are similar to the current state are retrieved from the case library. The set of actions corresponding to the most relevant case is then adapted to fit the current situation. Cardie <ref> [3] </ref> defined case-based learning (CBL) as a machine learning technique used to extend instance-based learning (IBL) [1]. The IBL algorithm retrieves the nearest instance (for our purposes, an instance can be thought of a case) to a state, and performs the suggested actions.
Reference: [4] <author> Andrew Garland and Richard Alterman. </author> <title> Preparation of multi-agent knowledge for reuse. </title> <editor> In David W. Aha and Ashwin Ram, editors, </editor> <booktitle> Working Notes for the AAAI Symposium on Adaptation of Knowldege for Reuse, </booktitle> <address> Cambridge, MA, </address> <month> November </month> <year> 1995. </year> <note> AAAI. </note>
Reference-contexts: We believe 2 that case based reasoning (CBR) can be used effectively in dealing with such situations. Though researchers have used CBR in multiagent systems [27, 28], little work has been done in learning cases in multiagent systems <ref> [4, 18] </ref>. We propose a learning framework in which agents learn cases to complement behavioral rules. In effect, agents find out through interacting with other agents that their behavior is not appropriate in certain situations. In those situations, they learn exceptions to their behavioral rules.
Reference: [5] <author> Les Gasser, Nicolas Rouquette, Randall W. Hill, and John Lieb. </author> <title> Representing and using organizational knowledge in DAI systems. </title> <editor> In Les Gasser and Michael N. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, volume 2 of Research Notes in Artificial Intelligence, </booktitle> <pages> pages 55-78. </pages> <publisher> Pitman, </publisher> <year> 1989. </year> <month> 13 </month>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26].
Reference: [6] <author> Piotr J. Gmytrasiewicz and Edmund H. Durfee. </author> <title> A rigorous, operational formalization of recursive modeling. </title> <editor> In Victor Lesser, editor, </editor> <booktitle> Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> pages 125-132, </pages> <address> San Francisco, CA, 1995. </address> <publisher> MIT Press. </publisher>
Reference-contexts: A problem in multiagent systems is that the best action for Agent A i might be in conflict with that for another Agent A j . Agent A i , then, should try to model the behavior of A j , and incorporate that into its expected utility calculations <ref> [6] </ref>. In a group of agents, the optimal action for an individual agent might not be the optimal action for the entire group. Every action can be evaluated with respect to both individual and group benefit.
Reference: [7] <author> Andrew R. Golding and Paul S. Rosenbloom. </author> <title> Improving rule-based systems through case-based reasoning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 22-27, </pages> <year> 1991. </year>
Reference-contexts: A 0 = A 00 . Cases can be positive or negative <ref> [7] </ref>. A positive case informs the agent what to do, i.e. it reorders the set of actions. A negative case can reorder the actions and/or delete actions from the set. <p> In effect, the symmetry allows the agent to engage in CBR. Our cases are negative in the sense they tell the agents what not to do. (A positive case would tell the agent what to do in a certain situation <ref> [7] </ref>.) A crucial piece of information in deciding local action is where does the agent believe the other agents are going to move? This is modeled by storing the orientation of the prey's position with respect to the desired direction of movement of the agent.
Reference: [8] <author> Joseph Y. Halpern and Yoram Moses. </author> <title> Knowledge and common knowledge in a distributed environment. </title> <booktitle> In Third ACM Conference on Principles of Distributed Computing, </booktitle> <year> 1984. </year>
Reference-contexts: Even if agents are allowed to communicate, communication delays, improper use of language, different underlying assumptions, etc. can prevent agents from developing a shared common body of knowledge <ref> [8] </ref>. For example, even communicating intentions and negotiating to avoid conflict situations may prove to be too time consuming and impractical in some domains [15]. These and other problems combine to confound an individual in its attempt to predict the behavior of other members of its group.
Reference: [9] <author> Thomas Haynes and Sandip Sen. </author> <title> Evolving behavioral strategies in predators and prey. </title> <editor> In Gerhard Wei and Sandip Sen, editors, </editor> <booktitle> Adaptation and Learning in Multiagent Systems, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <month> Winter </month> <year> 1995. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. <p> The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. Korf [14] claimed that communication is not necessary for capture to take place, and that simple greedy strategies will always lead to a capture. Haynes et. al. <ref> [9, 10] </ref> show that the greedy strategies do not always capture the prey. Most strategies performed poorly against the prey behavior of picking a direction and always move along it (Linear) and the one in which it did not move at all (Still).
Reference: [10] <author> Thomas Haynes, Roger Wainwright, Sandip Sen, and Dale Schoenefeld. </author> <title> Strongly typed genetic programming in evolving cooperation strategies. </title> <editor> In Larry Eshelman, editor, </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms, </booktitle> <pages> pages 271-278, </pages> <address> San Francisco, CA, 1995. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. <p> The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. Korf [14] claimed that communication is not necessary for capture to take place, and that simple greedy strategies will always lead to a capture. Haynes et. al. <ref> [9, 10] </ref> show that the greedy strategies do not always capture the prey. Most strategies performed poorly against the prey behavior of picking a direction and always move along it (Linear) and the one in which it did not move at all (Still).
Reference: [11] <author> Hideki Isozaki. </author> <title> Reasoning about belief based on common knowledge of observability of actions. </title> <editor> In Victor Lesser, editor, </editor> <booktitle> Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> pages 193-200, </pages> <address> San Francisco, CA, 1995. </address> <publisher> MIT Press. </publisher>
Reference: [12] <author> Janet L. Kolodner, </author> <title> editor. </title> <booktitle> Proceedings of a Workshop on Case-Based Reasoning (DARPA). </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Knowledge can be represented as a collection of rules. Humans tend to look for default rules which cover the majority of situations and are employed unless evidence is presented to show an exception holds. The difficulty of detecting such exceptions varies with the domain. Case-based reasoning (CBR) <ref> [12, 13, 24, 30] </ref> is a model of this definition of intelligence, and is a reasoning process for information retrieval and modification of solutions to problems. 3 A case is typically comprised of a representation of a state of a domain and a corresponding set of actions to take to lead
Reference: [13] <author> Janet L. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: The case-based learning (MCBL) algorithm utilizes exceptions to a default ruleset, which describes the behavior of an agent. These exceptions form a case library. The agent does not reason with these cases, as in CBR <ref> [13] </ref>, but rather modifies an inaccurate individual model to approximate a group model. Instead of forming models of other agents, a complimentary method would be to postprocess the output of the agent's model of itself. This postprocessing would only take place if there was a potential interaction with another agent. <p> Knowledge can be represented as a collection of rules. Humans tend to look for default rules which cover the majority of situations and are employed unless evidence is presented to show an exception holds. The difficulty of detecting such exceptions varies with the domain. Case-based reasoning (CBR) <ref> [12, 13, 24, 30] </ref> is a model of this definition of intelligence, and is a reasoning process for information retrieval and modification of solutions to problems. 3 A case is typically comprised of a representation of a state of a domain and a corresponding set of actions to take to lead <p> This analysis explains the surprising lack of captures of the Still prey. The question that arises from these findings is how should the agents manage conflict resolution? An answer can be found in the ways we as humans manage conflict resolution, with cases <ref> [13] </ref>.
Reference: [14] <author> Richard E. Korf. </author> <title> A simple solution to pursuit games. </title> <booktitle> In Working Papers of the 11th International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 183-194, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. <p> The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. Korf <ref> [14] </ref> claimed that communication is not necessary for capture to take place, and that simple greedy strategies will always lead to a capture. Haynes et. al. [9, 10] show that the greedy strategies do not always capture the prey.
Reference: [15] <author> Victor R. Lesser. </author> <title> Multiagent systems: An emerging subdiscipline of AI. </title> <journal> ACM Computing Surveys, </journal> <volume> 27(3) </volume> <pages> 340-342, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: For example, even communicating intentions and negotiating to avoid conflict situations may prove to be too time consuming and impractical in some domains <ref> [15] </ref>. These and other problems combine to confound an individual in its attempt to predict the behavior of other members of its group. In this paper, we investigate a method for allowing agents to improve their model of other members of the group.
Reference: [16] <author> Ran Levy and Jeffrey S. Rosenschein. </author> <title> A game theoretic approach to the pursuit problem. </title> <booktitle> In Working Papers of the 11th International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 195-213, </pages> <month> February </month> <year> 1992. </year>
Reference: [17] <author> Ei-Ichi Osawa. </author> <title> A metalevel coordination strategy for reactive cooperative planning. </title> <editor> In Victor Lesser, editor, </editor> <booktitle> Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> pages 297-303, </pages> <address> San Francisco, CA, 1995. </address> <publisher> MIT Press. </publisher> <pages> 14 </pages>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26].
Reference: [18] <author> M. V. Nagendra Prasad, Victor R. Lesser, and Susan Lander. </author> <title> Reasoning and retrieval in distributed case bases. Journal of Visual Communication and Image Representation, </title> <note> Special Issue on Digital Libraries, 1995. Also as UMASS CS Technical Report 95-27, </note> <year> 1995. </year>
Reference-contexts: We believe 2 that case based reasoning (CBR) can be used effectively in dealing with such situations. Though researchers have used CBR in multiagent systems [27, 28], little work has been done in learning cases in multiagent systems <ref> [4, 18] </ref>. We propose a learning framework in which agents learn cases to complement behavioral rules. In effect, agents find out through interacting with other agents that their behavior is not appropriate in certain situations. In those situations, they learn exceptions to their behavioral rules.
Reference: [19] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction An agent is defined to be rational if when faced with a choice from a set of actions, it chooses the one that maximizes the expected utilities of those actions <ref> [19] </ref>. Implicit in this definition is the assumption that the preference of the agent for different actions is based on the utilities resulting from those actions.
Reference: [20] <editor> Sandip Sen, editor. </editor> <booktitle> Working Notes of the IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems, </booktitle> <address> Montreal Quebec, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Adaptation and learning are key mechanisms by which agents can modify their behavior on-line to maintain a viable performance profile in such scenarios. A number of researchers have recently started investigating learning approaches targeted for multiagent systems. <ref> [20] </ref> Since we eliminate communication between agents, then how is group learning to occur? When the actual outcome of the action of an agent is not consistent with the expected outcome based on the model the agent has of other agents, the agent knows that it has found a case where
Reference: [21] <author> Sandip Sen, Mahendra Sekaran, and John Hale. </author> <title> Learning to coordinate without sharing information. </title> <booktitle> In National Conference on Artificial Intelligence, </booktitle> <pages> pages 426-431, </pages> <year> 1994. </year>
Reference: [22] <author> John W. Sheppard and Steven L. Salzberg. </author> <title> Combining genetic algorithms with memory based reasoning. </title> <editor> In Larry Eshelman, editor, </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms, </booktitle> <pages> pages 452-459, </pages> <address> San Francisco, CA, 1995. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference: [23] <author> Munindar P. Singh. </author> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Working Papers of the 10th International Workshop on Distributed Artificial Intelligence, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26].
Reference: [24] <author> Stephen Slade. </author> <title> Case-based reasoning: A research paradigm. </title> <journal> AI Magazine, </journal> <volume> 12(1) </volume> <pages> 42-55, </pages> <month> Spring </month> <year> 1991. </year>
Reference-contexts: Knowledge can be represented as a collection of rules. Humans tend to look for default rules which cover the majority of situations and are employed unless evidence is presented to show an exception holds. The difficulty of detecting such exceptions varies with the domain. Case-based reasoning (CBR) <ref> [12, 13, 24, 30] </ref> is a model of this definition of intelligence, and is a reasoning process for information retrieval and modification of solutions to problems. 3 A case is typically comprised of a representation of a state of a domain and a corresponding set of actions to take to lead
Reference: [25] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> Agent organization as an effector of DAI system performance. </title> <booktitle> In Working Papers of the 9th International Workshop on Distributed Artificial Intelligence, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. <p> The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal <ref> [25, 26] </ref>. Korf [14] claimed that communication is not necessary for capture to take place, and that simple greedy strategies will always lead to a capture. Haynes et. al. [9, 10] show that the greedy strategies do not always capture the prey.
Reference: [26] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Proceedings of the 1990 Distributed AI Workshop, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26]. <p> The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal <ref> [25, 26] </ref>. Korf [14] claimed that communication is not necessary for capture to take place, and that simple greedy strategies will always lead to a capture. Haynes et. al. [9, 10] show that the greedy strategies do not always capture the prey.
Reference: [27] <author> Katia Sycara. </author> <title> Planning for negotiation: A case-based approach. </title> <booktitle> In DARPA Knowledge-Based Planning Workshop, </booktitle> <pages> pages 11.1-11.10, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: We believe 2 that case based reasoning (CBR) can be used effectively in dealing with such situations. Though researchers have used CBR in multiagent systems <ref> [27, 28] </ref>, little work has been done in learning cases in multiagent systems [4, 18]. We propose a learning framework in which agents learn cases to complement behavioral rules. In effect, agents find out through interacting with other agents that their behavior is not appropriate in certain situations.
Reference: [28] <author> Katia Sycara. </author> <title> Resolving Adversarial Conflicts: An Approach Integrating Case-Based and Analytic Methods. </title> <type> PhD thesis, </type> <institution> School of Information and Computer Science Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <year> 1987. </year>
Reference-contexts: We believe 2 that case based reasoning (CBR) can be used effectively in dealing with such situations. Though researchers have used CBR in multiagent systems <ref> [27, 28] </ref>, little work has been done in learning cases in multiagent systems [4, 18]. We propose a learning framework in which agents learn cases to complement behavioral rules. In effect, agents find out through interacting with other agents that their behavior is not appropriate in certain situations.
Reference: [29] <author> Jose M. Vidal and Edmund H. Durfee. </author> <title> Recursive agent modeling using limited rationality. </title> <editor> In Victor Lesser, editor, </editor> <booktitle> Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> pages 376-383, </pages> <address> San Francisco, CA, 1995. </address> <publisher> MIT Press. </publisher>
Reference-contexts: The predator-prey domain has been widely used in distributed AI research as a testbed for investigating cooperation and conflict resolution <ref> [2, 5, 9, 10, 14, 17, 23, 25, 26, 29] </ref>. The goal is for four predator agents to capture a prey agent by blocking its orthogonal movement. The game is typically played on a 30 by 30 grid world, which is toroidal [25, 26].
Reference: [30] <author> Ian Watson and Farhi Marir. </author> <title> Case-based reasoning: A review. </title> <journal> The Knowledge Engineering Review, </journal> <volume> 9(4), </volume> <year> 1994. </year> <month> 15 </month>
Reference-contexts: Knowledge can be represented as a collection of rules. Humans tend to look for default rules which cover the majority of situations and are employed unless evidence is presented to show an exception holds. The difficulty of detecting such exceptions varies with the domain. Case-based reasoning (CBR) <ref> [12, 13, 24, 30] </ref> is a model of this definition of intelligence, and is a reasoning process for information retrieval and modification of solutions to problems. 3 A case is typically comprised of a representation of a state of a domain and a corresponding set of actions to take to lead
References-found: 30

