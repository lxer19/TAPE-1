URL: http://www.cs.ucl.ac.uk/staff/R.Bordini/Publications/MSMAS-CR600.ps.gz
Refering-URL: http://www.cs.ucl.ac.uk/staff/R.Bordini/
Root-URL: http://www.cs.ucl.ac.uk
Email: bazzan@cs.umass.edu  fR.Bordini, J.Campbellg@cs.ucl.ac.uk  
Phone: 2  
Title: Moral Sentiments in Multi-Agent Systems  
Author: Ana L. C. Bazzan Rafael H. Bordini and John A. Campbell 
Address: Amherst, MA 01003-4610, USA  Gower Street, London WC1E 6BT, U.K.  
Affiliation: 1 Department of Computer Science University of Massachusetts at Amherst  Department of Computer Science University College London  
Abstract: We present a simulation of a society of agents where some of them have "moral sentiments" towards the agents that belong to the same social group, using the Iterated Prisoner's Dilemma as a metaphor for the social interactions. Besides the well-understood phenomenon of short-sighted, self-interested agents performing well in the short-term but ruining their chances of such performance in the long run in a world of reciprocators, the results suggest that, where some agents are more generous than that, these agents have a positive impact on the social group to which they belong, without compromising too much their individual performance (i.e., the group performance improves). The inspiration for this project comes from a discussion on Moral Sentiments by M.Ridley. We describe various simulations where conditions and parameters over determined dimensions were arranged to account for different types and compositions of societies. Further, we indicate several lessons that arise from the analysis of the results and comparison of the different experiments. We also relate this work to our previous anthropological approach to the adaptation of migrant agents, and argue that allowing agents to possess suitably-chosen emotions can have a decisive impact on Multi-Agent Systems. This implies that some common notions of agent autonomy (and related concepts) should be reexamined. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Axelrod, R. </author> <year> 1984. </year> <title> The Evolution of Cooperation. </title> <address> New York: </address> <publisher> Basic Books. </publisher>
Reference: <author> Bates, J. </author> <year> 1994. </year> <title> The role of emotion in believable agents. </title> <journal> Communications of the ACM 37(7) </journal> <pages> 122-125. </pages>
Reference: <author> Bazzan, A. L. C., Bordini, R. H., and Campbell, J. A. </author> <year> 1997. </year> <title> Agents with moral sentiments in an iterated prisoner's dilemma exercise. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Socially Intelligent Agents. </booktitle> <address> Cam-bridge, Massachusetts, </address> <month> 8-10 November, </month> <year> 1997. </year> <note> UCL-CS [RN/97/74]. URL: http://www.cs.ucl.ac.uk/staff/R.Bordini. </note>
Reference-contexts: Further, notions of goal adoption and social norms (Conte and Castelfranchi 1995) also need to be revisited, based on the emotional stance that we propose informally for MAS. We began the work reported here, whose initial result were presented in <ref> (Bazzan, Bordini, and Campbell 1997) </ref>, by introducing (metaphorically) an emotional aspect into simulations using the Iterated Prisoner's Dilemma (IPD). Ironically, IPD originated in the field of Game Theory, an area concerned with rational decisions and self-interest. <p> (Simon 1990) and (Cesta, Miceli, and Rizzo 1996), although these motivations were explored there in rather different contexts and not with this particular issue of emotions in mind. 3 Description of the Experiments: Agents with Moral Sentiments in an IPD Exercise In this paper we extend the initial results in <ref> (Bazzan, Bordini, and Campbell 1997) </ref> to other configurations of the simulations, in which agents interact by playing the IPD. Unlike other experiments reported in the literature, the over-all population of agents here is divided into groups. <p> The notation G n (a=e) means that group n has a agents of which e are egoists. Despite the various configurations of conditions and parameters introduced in the present set of simulations, we were able to confirm the conclusions previously reported <ref> (Bazzan, Bordini, and Campbell 1997) </ref>. These major lessons are: 1.
Reference: <author> Binmore, K. </author> <year> 1998. </year> <title> Review of R. Axelrod's "The complexity of cooperation: Agent-based models of competition and collaboration". Journal of Artificial Societies and Social Simulation 1(1). </title> <publisher> &lt;http://www.soc.surrey.ac.uk/JASSS/1/1/review1.html&gt;. </publisher>
Reference-contexts: For instance, agents do not attempt to modify the mental state of an opponent. There has been marked opposition from game theorists to the widespread use of IPD and TFT as the basis for explaining complex social interactions among humans <ref> (Binmore 1998) </ref>. We have extended the rules of the game so that it can relate to various issues of social agents, including moral and philosophical aspects such as why people are able to keep their promises once they agree to cooperate and why people behave altruistically.
Reference: <author> Bordini, R. H., and Campbell, J. A. </author> <year> 1995. </year> <title> Towards an anthropological approach to agent adaptation. </title> <booktitle> In Proceedings of the First International Workshop on Decentralized Intelligent and Multi-Agent Systems (DIMAS'95), </booktitle> <address> p. II/74 II/83. Krakow, Poland: </address> <publisher> Dom Wydawnictwa Naukowych, </publisher> <month> 22-24 November, </month> <year> 1995. </year> <note> UCL-CS [RN/95/78]. URL: http://www.cs.ucl.ac.uk/staff/R.Bordini. </note>
Reference: <author> Bordini, R. H., Campbell, J. A., and Vieira, R. </author> <year> 1997. </year> <title> Ascription of intensional ontologies in anthropological descriptions of multi-agent systems. </title> <editor> In Kandzia, P., and Klusch, M., eds., </editor> <booktitle> Proceedings of the First International Workshop on Cooperative Information Agents (CIA'97), volume 1202 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> 235-247. </pages> <address> Kiel, Germany: </address> <publisher> Springer-Verlag, </publisher> <month> 26-28 February, </month> <year> 1997. </year> <note> UCL-CS [RN/97/1]. URL: http://www.cs.ucl.ac.uk/staff/R.Bordini. </note>
Reference-contexts: Further, notions of goal adoption and social norms (Conte and Castelfranchi 1995) also need to be revisited, based on the emotional stance that we propose informally for MAS. We began the work reported here, whose initial result were presented in <ref> (Bazzan, Bordini, and Campbell 1997) </ref>, by introducing (metaphorically) an emotional aspect into simulations using the Iterated Prisoner's Dilemma (IPD). Ironically, IPD originated in the field of Game Theory, an area concerned with rational decisions and self-interest. <p> (Simon 1990) and (Cesta, Miceli, and Rizzo 1996), although these motivations were explored there in rather different contexts and not with this particular issue of emotions in mind. 3 Description of the Experiments: Agents with Moral Sentiments in an IPD Exercise In this paper we extend the initial results in <ref> (Bazzan, Bordini, and Campbell 1997) </ref> to other configurations of the simulations, in which agents interact by playing the IPD. Unlike other experiments reported in the literature, the over-all population of agents here is divided into groups. <p> The notation G n (a=e) means that group n has a agents of which e are egoists. Despite the various configurations of conditions and parameters introduced in the present set of simulations, we were able to confirm the conclusions previously reported <ref> (Bazzan, Bordini, and Campbell 1997) </ref>. These major lessons are: 1.
Reference: <author> Brembs, B. </author> <year> 1996. </year> <title> Chaos, cheating and cooperation: Potential solutions to the prisoner's dilemma. </title> <booktitle> OIKOS 76(1) </booktitle> <pages> 14-24. </pages>
Reference-contexts: Ironically, IPD originated in the field of Game Theory, an area concerned with rational decisions and self-interest. It is known that in the IPD, mutual defection is not the only solution, unlike the situation for the one-shot Prisoner's Dilemma (PD), where it is the rational one <ref> (Brembs 1996) </ref>. This was verified in Axelrod's computer tournament (1984), by the use of a tactic referred to as Tit-For-Tat (TFT), whose success is due to its being, in Axelrod's words, nice, retaliatory, forgiving, and clear.
Reference: <author> Castelfranchi, C., de Rosis, F., and Falcone, R. </author> <year> 1997. </year> <title> Social attitudes and personalities in agents. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Socially Intelligent Agents. </booktitle> <address> Cambridge, Massachusetts, </address> <month> 8-10 November, </month> <year> 1997. </year>
Reference: <author> Castelfranchi, C. </author> <year> 1990. </year> <title> Social power: a point missed in multi-agent DAI and HCI. </title>
Reference-contexts: That is why, for all their superficial differences of language and custom, foreign cultures are still immediately comprehensible at the deeper level of motives, emotions and social habits." (Ridley 1996). Further, our view is that an emotional stance is yet another "missing point" <ref> (Castelfranchi 1990) </ref> in present MAS. It should not be considered only for its role in believability, which is the point that most works that consider emotions as being relevant to agents make (see, for example, (Rizzo et al. 1997; Bates 1994)). <p> viewed as `selfish' or `altruistic') will always be adopted so as to satisfy a `selfish' motivation." "The effects of benevolence are possible, but only through self-serving motivations." In terms of the history of MAS, this line of thought seems to have started with the the discussion on social power in <ref> (Castelfranchi 1990) </ref>. The paper was in the right direction at the time, when benevolence was being taken for granted.
Reference: <editor> In Demazeau, Y., and Muller, J.-P., eds., </editor> <booktitle> Decentralized A.I. </booktitle> <address> Amsterdam: </address> <publisher> Elsevier Science Publishers. </publisher> <pages> 49-62. </pages>
Reference: <author> Cesta, A., Miceli, M., and Rizzo, P. </author> <year> 1996. </year> <title> Help under risky conditions: Robustness of the social attitude and system performance. </title> <editor> In Durfee, E., ed., </editor> <booktitle> Second International Conference on Multiagent Systems (ICMAS'96), </booktitle> <address> Kyoto, Japan. Menlo Park, CA: </address> <publisher> AAAI Press. </publisher> <pages> 18-25. </pages>
Reference-contexts: The discussions are much more elaborate in (Ridley 1996, Chapter 7), so we advise the reading of that material for a complete account. Similar motivations are also seen behind the ideas discussed in (Simon 1990) and <ref> (Cesta, Miceli, and Rizzo 1996) </ref>, although these motivations were explored there in rather different contexts and not with this particular issue of emotions in mind. 3 Description of the Experiments: Agents with Moral Sentiments in an IPD Exercise In this paper we extend the initial results in (Bazzan, Bordini, and Campbell
Reference: <author> Conte, R., and Castelfranchi, C. </author> <year> 1995. </year> <title> Cognitive and Social Action. </title> <publisher> London: UCL Press. 215pp. </publisher>
Reference-contexts: Further, notions of goal adoption and social norms <ref> (Conte and Castelfranchi 1995) </ref> also need to be revisited, based on the emotional stance that we propose informally for MAS. <p> This issue should be of interest for those concerned with agent autonomy via the cognitive (as opposed to utilitarian) view of the field (c.f. <ref> (Conte and Castelfranchi 1995) </ref>). The misconception about autonomy and benevolence goes together with the absence of an explicit emotional component in present MAS theories. Motivations do not have to be necessarily self-serving. Consider, e.g., the idea of terminal interest adoption defined by Conte and Castelfranchi (1995).
Reference: <author> Dawkins, R. </author> <year> 1989. </year> <title> The Selfish Gene. </title> <publisher> Oxford: Oxford University Press, </publisher> <address> new edition. </address> <note> d'Inverno, </note> <author> M., and Luck, M. </author> <year> 1996. </year> <title> Understanding autonomous interaction. </title> <editor> In Wahlster, W., ed., </editor> <booktitle> Proceedings of the 12 th European Conference on Artificial Intelligence (ECAI'96). </booktitle>
Reference-contexts: This is a remarkable insight, as it admits some light into the discussion on altruism, which has become so paradoxical and with dangerous consequences since the wide acceptance (followed by misinterpretations) of the "selfish gene" theory <ref> (Dawkins 1989) </ref>.
Reference: <author> Gasser, L. </author> <year> 1987. </year> <title> Distribution and coordination of tasks among intelligent agents. </title> <booktitle> In Proceedings of the First Scandinavian Conference on Artificial Intelligence. </booktitle> <address> Trum-soe, Norway, </address> <month> March, </month> <year> 1987. </year>
Reference-contexts: agents (or emotions or cognitive biases) to reproduce relevant features of human interaction." We believe this should be a new source of guidance for the work on MAS as originally defined as the field of Distributed Artificial Intelligence concerned with coordinated intelligent behaviour among a collection of autonomous intelligent agents <ref> (Gasser 1987) </ref>.
Reference: <author> Ridley, M. </author> <year> 1996. </year> <title> The Origins of Virtue. </title> <publisher> London: Viking Press. </publisher>
Reference-contexts: In the final section we summarise the lessons from the present work and mention possible extensions to it. 2 Moral Sentiments: a Prolific Source of Ideas In a recent publication on "The Origins of Virtue" <ref> (Ridley 1996) </ref>, particularly in its Chapter 7 entitled "Theories of Moral Sentiments" 1 , Ridley makes the point that moral sentiments (emotions like compassion towards others and guilt 1 The reader will notice that this is an important influence on our work. <p> We concentrate, briefly and informally, on these issues in Section 5. These are the general ideas that have inspired the conception of the simulations we describe below. The discussions are much more elaborate in <ref> (Ridley 1996, Chapter 7) </ref>, so we advise the reading of that material for a complete account. <p> They are canalized expressions of our instincts. ... That is why, for all their superficial differences of language and custom, foreign cultures are still immediately comprehensible at the deeper level of motives, emotions and social habits." <ref> (Ridley 1996) </ref>. Further, our view is that an emotional stance is yet another "missing point" (Castelfranchi 1990) in present MAS.
Reference: <author> Rizzo, P., Veloso, M., Miceli, M., and Cesta, A. </author> <year> 1997. </year> <title> Personality-driven social behaviors in believable agents. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Socially Intelligent Agents. </booktitle> <address> Cambridge, Massachusetts, </address> <month> 8-10 November, </month> <year> 1997. </year>
Reference: <author> Rosenschein, J., and Genesereth, M. </author> <year> 1985. </year> <title> Deals among rational agents. </title> <editor> In Joshi, A., ed., </editor> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence (IJCAI-85). </booktitle> <address> Los Angeles, CA: </address> <publisher> AAAI Press / Morgan Kaufmann. </publisher> <pages> 91-99. </pages>
Reference: <author> Rosenschein, J., and Zlotkin, G. </author> <year> 1994. </year> <title> Rules of Encounter. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. 229pp. </publisher>
Reference-contexts: These ideas have been employed in the field of MAS in order to explain the achievement of cooperation and coordination (e.g. in <ref> (Rosenschein and Zlotkin 1994) </ref>). Nevertheless, little work has been devoted to the IPD for social agents, particularly agents with emotions. One reason for this may be the failure of theories based on rational choice to account for social action and choice as claimed by Conte and Castelfranchi (1995). <p> In more practical terms, agents who seek only to maximise a utility function or are overconcerned with self-interest <ref> (Rosenschein and Zlotkin 1994) </ref> can miss good opportunities for themselves that they cannot foresee.
Reference: <author> Simon, H. A. </author> <year> 1990. </year> <title> A mechanism for social selection and successful altruism. </title> <booktitle> Science 250(4988) </booktitle> <pages> 1665-1668. </pages>
Reference-contexts: These are the general ideas that have inspired the conception of the simulations we describe below. The discussions are much more elaborate in (Ridley 1996, Chapter 7), so we advise the reading of that material for a complete account. Similar motivations are also seen behind the ideas discussed in <ref> (Simon 1990) </ref> and (Cesta, Miceli, and Rizzo 1996), although these motivations were explored there in rather different contexts and not with this particular issue of emotions in mind. 3 Description of the Experiments: Agents with Moral Sentiments in an IPD Exercise In this paper we extend the initial results in (Bazzan,
References-found: 19

