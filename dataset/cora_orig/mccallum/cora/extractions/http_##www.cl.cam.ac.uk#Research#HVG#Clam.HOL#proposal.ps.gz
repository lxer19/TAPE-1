URL: http://www.cl.cam.ac.uk/Research/HVG/Clam.HOL/proposal.ps.gz
Refering-URL: http://www.cl.cam.ac.uk/Research/HVG/Clam.HOL/intro.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Automatic Guidance of Mechanically Generated Proofs  
Author: Alan Bundy and M.J.C. Gordon 
Affiliation: University of Edinburgh  
Note: 1 Previous Research and Track Record This proposal comes from two sites: Edinburgh and Cambridge, both of whom have excellent track records and international reputations in this research area. 1.1 The  
Date: November 13, 1995  
Abstract: The mathematical reasoning group in the Department of Artificial Intelligence at the University of Edinburgh has been engaged in research on automated theorem proving since 1971 and has focussed on applications to formal methods for the last decade. It currently consists of: 2 members of academic staff; 2 research fellows; 2 HC&M fellows; 1 Royal Society industrial fellow; 6 PhD students, a computing officer and a part time secretary. It also usually has several masters and undergraduate projects associated with the group. In addition, one lecturer at Napier University and one at Heriot Watt University, both in Edinburgh, are honorary fellows of the Department and co-grant holders of our main research grant. The Edinburgh group invented and developed the technique of proof planning. This requires the analysis of families of related proofs, the identification of common patterns in them (called proof plans) and the use of these proof plans to guide future proofs from the same family. Proof planning has been implemented in the Barnacle-CL A M-Mollusc system, [Bundy et al, 1990, Richards et al, 1994, Lowe et al, 1995]. CL A M builds a proof plan customised to the current conjecture and then gives it to Mollusc to turn into a proof. Mollusc is a generic proof editor. By defining a logic in it, Mollusc is instantiated into a proof editor for that logic. This proof editor can be driven by human interaction or by a proof plan. Barnacle provides a cooperative front-end to CL A M allowing a user to interact at the level of the proof plan. Using CL A M-Mollusc it has been possible to synthesise, verify and transform simple computer programs totally automatically. We have also been able automatically to verify paramet-erised electric circuits, e.g. n-bit multipliers, ALUs, shifters, etc. The development time to verify each circuit is typically of the order of a few weeks. Most of this time is taken up by understanding and formalising the circuit and its specification. The actual planning and proof time is of the order of minutes and is totally automatic. Our proof planner, CL A M, forms a plan of the proof, which it constructs by analysing the conjecture in terms of its known proof methods. CL A M then uses this plan to instruct our theorem prover, Mollusc, how to prove the theorem. All the search is conducted during proof planning; the execution of the proof plan requires no search. Proof plans also provide a better basis for user interaction since the state of the proof can be described and controlled at a higher level than is usually possible. Proof planning is the culmination of work on an SERC/EPSRC funded rolling funding grant which has rolled since 1983. During this period we have received very positive feedback from the SERC/EPSRC visiting panels; our grant proposals have usually been rated at ff 5 level and have frequently been the top rated grant in the round. Our work was featured in SERC Bulletin vol. 5, no. 1, Summer 1993. The most recent visiting panel urged us to accelerate our exploration of practical applications of proof planning, which we have been doing. This proposal is the latest manifestation of our application drive. 
Abstract-found: 1
Intro-found: 1
Reference: [Bundy et al, 1990] <author> Bundy, A., van Harmelen, F., Horn, C. and Smaill, A. </author> <year> (1990). </year> <title> The Oyster-Clam system. </title> <editor> In Stickel, M.E., (ed.), </editor> <booktitle> 10th International Conference on Automated Deduction, </booktitle> <pages> pages 647-648. </pages> <note> Springer-Verlag. Lecture Notes in Artificial Intelligence No. 449. Also available from Edinburgh as DAI Research Paper 507. </note>
Reference-contexts: However, it requires a high level of skill to use. The user must guide the proof process: selecting the logical rules or tactics to be applied; inventing key lemmas; generalising the current problem; etc. CL A M is a proof planner developed at Edinburgh, <ref> [Bundy et al, 1990] </ref>. It builds global plans to guide theorem provers. It has been used to build the plans for the proof obligations that arise when applying formal methods to software and hardware development. <p> This offers a new kind of interaction with theorem proving systems. Our hypothesis is that this will be more congenial for users than the normal interaction at the level of logical rules. CL A M was initially interfaced to the theoren prover Oyster, <ref> [Bundy et al, 1990] </ref>, a Prolog reimplementation of the Cornell, LCF-style prover, Nuprl, [Constable et al, 1986]. Oyster is a theorem prover for intuitionistic type theory, cf. [Martin-Lof, 1984].
Reference: [Constable et al, 1986] <editor> Constable, R.L., Allen, S.F., Bromley, H.M. et al. </editor> <year> (1986). </year> <title> Implementing Mathematics with the Nuprl Proof Development System. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Our hypothesis is that this will be more congenial for users than the normal interaction at the level of logical rules. CL A M was initially interfaced to the theoren prover Oyster, [Bundy et al, 1990], a Prolog reimplementation of the Cornell, LCF-style prover, Nuprl, <ref> [Constable et al, 1986] </ref>. Oyster is a theorem prover for intuitionistic type theory, cf. [Martin-Lof, 1984]. More recently, experiments have been conducted with interfacing CL A M to a variety of logics, via Mollusc, [Richards et al, 1994], a generic version of Oyster.
Reference: [Curzon et al, 1995] <author> Curzon, P., Leslie, I. and Gordon, M. </author> <year> (1995). </year> <title> Conclusions from a study to verify a real network component. In Procs of the Second Workshop on Automated Reasoning: Bridging the Gap Between Theory and Practice,. </title> <type> AISB. </type>
Reference-contexts: time and to simplify the interaction that it takes a HOL user to verify a system. 2.2 Scientific/Technological Relevance Using automated theorem provers, like HOL, it is possible to formally verify industrially significant properties of software and hardware, e.g. correctness properties of microprocessors, [Srivas & Miller, 1995], or communications hardware, <ref> [Curzon et al, 1995] </ref>. However, the user of the prover must be highly skilled and the development time is of the order of man-months | sometimes man-years. Such skill levels and development times preclude widespread industrial use.
Reference: [Gordon et al, 1979] <author> Gordon, M.J., Milner, A.J. and Wadsworth, C.P. </author> <year> (1979). </year> <title> Edinburgh LCF A mechanised logic of computation, </title> <booktitle> volume 78 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: and workshops of talks on our work and demonstrations of the combined system; publication in high quality journals of papers on our work; availability of our system via ftp; availability of papers via WWW. 2.5 The Programme 2.5.1 The HOL and CL A M Systems HOL belongs to the LCF, <ref> [Gordon et al, 1979] </ref>, family of theorem provers. It proves theorems in classical, higher-order logic. It is driven by a user specifying which logical rule or tactic to apply. A tactic is a ML program which applies a sequence of logical rules.
Reference: [Ireland & Bundy, 1994] <author> Ireland, A. and Bundy, A. </author> <year> (1994). </year> <title> Productive use of failure in inductive proof. </title> <type> Technical report, </type> <institution> Dept. of Artificial Intelligence, Edinburgh, </institution> <note> To appear in the JAR Special Issue on Inductive Proof (1995), also available from Edinburgh as DAI Research Paper 716. </note>
Reference-contexts: This composite tactic is then sent to the theorem prover to be applied, whence it produces a proof for the theorem. When a method unexpectedly fails a collection of critics is used to analyse the cause of failure and suggest a patch, <ref> [Ireland & Bundy, 1994] </ref>. Patches might include: a change of induction rule; the introduction of a lemma; the generalisation of the conjecture; a case split; etc.
Reference: [Lowe et al, 1995] <author> Lowe, H., Bundy, A. and McLean, D. </author> <year> (1995). </year> <title> The use of proof planning for co-operative theorem proving. </title> <journal> Research Paper (forthcoming), Dept. of Artificial Intelligence, </journal> <note> Edinburgh, Submitted to the special issue of the Journal of Symbolic Computation on graphical user interfaces and protocols. </note>
Reference-contexts: These critics have enabled CL A M to tackle some of the hardest search control problems that arise in verification proofs and to extend significantly the state of the art of automated proof. Using Barnacle, users can interact with the proof search at the level of the plan, <ref> [Lowe et al, 1995] </ref>. They can get explanations of why methods were or were not applied in terms of their preconditions and can choose to override CL A M's decisions. This offers a new kind of interaction with theorem proving systems.
Reference: [Martin-Lof, 1984] <author> Martin-Lof, Per. </author> <year> (1984). </year> <title> Intuitionistic Type Theory. Bibliopolis, Naples, Notes by Giovanni Sambin of a series of lectures given in Padua, </title> <month> June </month> <year> 1980. </year>
Reference-contexts: CL A M was initially interfaced to the theoren prover Oyster, [Bundy et al, 1990], a Prolog reimplementation of the Cornell, LCF-style prover, Nuprl, [Constable et al, 1986]. Oyster is a theorem prover for intuitionistic type theory, cf. <ref> [Martin-Lof, 1984] </ref>. More recently, experiments have been conducted with interfacing CL A M to a variety of logics, via Mollusc, [Richards et al, 1994], a generic version of Oyster. For instance, it would be possible to implement the HOL logic in Mollusc.
Reference: [Richards et al, 1994] <author> Richards, B.L., Kraan, I., Smaill, A. and Wiggins, G.A. </author> <year> (1994). </year> <title> Mollusc: a general proof development shell for sequent-based logics. </title> <editor> In Bundy, A., (ed.), </editor> <booktitle> 12th Conference on Automated Deduction, </booktitle> <pages> pages 826-30. </pages> <note> Springer-Verlag. Lecture Notes in Artificial Intelligence, vol 814; Also available from Edinburgh as DAI Research paper 723. </note>
Reference-contexts: Oyster is a theorem prover for intuitionistic type theory, cf. [Martin-Lof, 1984]. More recently, experiments have been conducted with interfacing CL A M to a variety of logics, via Mollusc, <ref> [Richards et al, 1994] </ref>, a generic version of Oyster. For instance, it would be possible to implement the HOL logic in Mollusc. This would be useful as an exploratory study, but would not import the full functionality of HOL into CL A M.
Reference: [Srivas & Miller, 1995] <author> Srivas, M. and Miller, S.P. </author> <year> (1995). </year> <title> Applying formal verification to a commercial microprocessor. </title> <booktitle> In Procs of IFIP International Conference on Computer Hardware Description Languages. CHDL-95. </booktitle> <pages> 9 </pages>
Reference-contexts: is: Significantly to reduce the amount of time and to simplify the interaction that it takes a HOL user to verify a system. 2.2 Scientific/Technological Relevance Using automated theorem provers, like HOL, it is possible to formally verify industrially significant properties of software and hardware, e.g. correctness properties of microprocessors, <ref> [Srivas & Miller, 1995] </ref>, or communications hardware, [Curzon et al, 1995]. However, the user of the prover must be highly skilled and the development time is of the order of man-months | sometimes man-years. Such skill levels and development times preclude widespread industrial use.
References-found: 9

