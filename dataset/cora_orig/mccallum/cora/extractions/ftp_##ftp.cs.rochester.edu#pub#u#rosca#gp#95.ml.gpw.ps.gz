URL: ftp://ftp.cs.rochester.edu/pub/u/rosca/gp/95.ml.gpw.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rosca/research.html
Root-URL: 
Email: rosca@cs.rochester.edu  
Title: Entropy-Driven Adaptive Representation  
Author: Justinian P. Rosca 
Address: Rochester, NY 14627  
Affiliation: Computer Science Department University of Rochester  
Abstract: In the first genetic programming (GP) book John Koza noticed that fitness histograms give a highly informative global view of the evolutionary process (Koza, 1992). The idea is further developed in this paper by discussing GP evolution in analogy to a physical system. I focus on three inter-related major goals: (1) Study the the problem of search effort allocation in GP; (2) Develop methods in the GA/GP framework that allow adaptive control of diversity; (3) Study ways of adaptation for faster convergence to optimal solution. An entropy measure based on phenotype classes is introduced which abstracts fitness histograms. In this context, entropy represents a measure of population diversity. An analysis of entropy plots and their correlation with other statistics from the population enables an intelligent adaptation of search control.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bruce H. Weber, D. J. D. and Smith, J. D., </author> <title> editors (1988). Entropy, information, and evolution : new perspectives on physical and biological evolution. </title> <publisher> MIT Press. </publisher>
Reference-contexts: This generalization tendency in interpreting entropy led researchers to search for an unifying view between the statistical interpretations of the second law of thermodynamics in physics and evolutionary principles in biology <ref> (Bruce H. Weber and Smith, 1988) </ref>. Schrodinger (Schrodinger, 1945) and others have noticed the following paradox: The increase in entropy in physical systems brings about a disorganization of the systems. Equivalently, systems evolve from less probable to more probable states. <p> Schrodinger explained the paradox by looking at the flux of energy in a living system and suggesting that it does not conform to the basic assumptions of classical thermodynamics. However, there are various claims about the role of the second law of thermodynamics in biological evolution <ref> (Bruce H. Weber and Smith, 1988) </ref>. For instance Wicken proposed that genetic variation is due to the probabilistic nature of the second law (Wicken, 1988). One measure that quantifies variation is diversity.
Reference: <author> Chaitin, G. J. </author> <year> (1987). </year> <title> Algorithmic information theory. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Shannon used the same formula to define an information measure representing one's ignorance of which of a number of possibilities actually holds, given the a priori probability distribution represented by P (Shan-non, 1949). Yet another interpretation of entropy is complexity <ref> (Chaitin, 1987) </ref> or information content of an individual structure. In this context order means compressibility. Redundancies subtract from an individual's complexity. All these interpretations use the same formula (2) but assign different meanings to the probabilities fed into the formula.
Reference: <editor> Eshelman, L. J. and Schaffer, J. D. </editor> <year> (1993). </year> <title> Crossover's niche. </title> <editor> In Forrest, S., editor, </editor> <booktitle> Proceedings of the International Conference on Genetic Algorithms, </booktitle> <pages> pages 9-14. </pages> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: The problem is how to capture heterogeneity. A straightforward definition of diversity or non-similarity for GA string-based representations is based on the Hamming distance between encodings of individuals. <ref> (Eshelman and Schaffer, 1993) </ref> discusses strategies for maintaining GA population diversity by controlling how mates are selected, how children are created by recombination and how parents are replaced.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The correlation between entropy (i.e. population diversity) and energy (i.e. average fitness) suggests when computational effort is wasted due to local minima. Goldberg discussed the tradeoff between precision, given by better optima, and computational effort, measured simply as running time, in GAs <ref> (Goldberg, 1989) </ref>. He showed that new operators are used in order to maintain diversity in the population and that increased diversity causes decreased performance due to an increase in computational effort. We suggest that this is not necessarily the case in GP.
Reference: <author> Hertz, J., Krogh, A., and Palmer, R. G. </author> <year> (1991). </year> <title> Introduction to the theory of neural computation. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: individual states, according to the fol lowing identity: e F Z X p i = 1 In the free energy formula (1), estimations of H and S would result in an estimation of F which can be interpreted as the probability of finding the system in a subset of states <ref> (Hertz et al., 1991) </ref>. In the next chapters we discuss various interpretations of entropy, relate sampled entropy with diversity and show how diversity and energy are correlated in restricted free entropy. 5 ENTROPY AND INFORMATION MEASURES Entropy is an extensive property of a system's state meaning transformation.
Reference: <author> Holland, J. H. </author> <title> (1st edition, 1975). Adaptation in Natural and Artificial Systems, An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <institution> The University of Michigan. </institution>
Reference: <author> Holland, J. H. </author> <title> (2nd edition, 1992). Adaptation in Natural and Artificial Systems, An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: The "Two armed bandit problem" was concerned with the allocation of trials to two random variables that offer unitary payoff with unknown probabilities, so that cumulative payoff is maximized <ref> (Holland, 1992) </ref>. Holland outlined that at any given time only one of the following strategies can be pursued: exploit the observed best, which runs the risk of perpetuated error or explore for new information which runs the risk of a performance loss.
Reference: <author> Johnson, L. </author> <year> (1988). </year> <title> The Thermodynamic Origin of Ecosystems: A Tale of Broken Symmetry, chapter 5. </title> <publisher> MIT Press. </publisher>
Reference-contexts: One measure that quantifies variation is diversity. Johnson defined diversity in terms of the distribution of the energy within the system based on Shan-non's information entropy measure, but outlined that diversity is not perfectly synonymous with either information or with statistical entropy <ref> (Johnson, 1988) </ref>. 6 DIVERSITY A rule of thumb in the GA literature postulates that population diversity is important for avoiding premature convergence. The problem is how to capture heterogeneity.
Reference: <author> Kaelbling, L. P. </author> <year> (1993). </year> <title> Learning in Embedded Systems. </title> <publisher> MIT Press. </publisher>
Reference: <author> Kirkpatrick, S., Gelatt, C., and Vecchi, M. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> (220):671-680. 
Reference: <author> Koza, J. R. </author> <year> (1992). </year> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press. </publisher>
Reference-contexts: A learning system should have an adaptive policy of balancing exploration and exploitation. Such an adaptive policy is possible in GP with subroutines, also called hierarchical GP (HGP) (Rosca and Ballard, 1995). HGP extensions, such as Automatic Discovery of Functions (ADF) <ref> (Koza, 1992) </ref> or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution (Rosca, 1995). <p> Two individuals are different if they score differently. Figures 1 and 2 present three dimensional plots with the fitness distributions for runs of GP and ADF-GP on the Even-5-Parity problem. These plots offer a compact representation of the fitness histograms used in <ref> (Koza, 1992) </ref>. Koza pointed out that fitness histograms "give a highly informative view of the progress of the learning process for the populations a whole." Note also that Figure 2, corresponding to GP with subroutines (in the ADF model) determines a much wider distribution of values for parity problems. <p> Four examples are presented, from two problem domains: Boolean regression and controlling an agent in a dynamic environment (similar to the Pac-Man problem described in <ref> (Koza, 1992) </ref>). Each example discusses the relationships between the best-of-generation fitness, the average population fit ness (called energy in our earlier discussion) and di-versity, as measured by the entropy formula.
Reference: <author> Koza, J. R. </author> <year> (1994). </year> <title> Genetic Programming II. </title> <publisher> MIT Press. </publisher>
Reference-contexts: HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution (Rosca, 1995). Theoretically, HGP approaches allow to scale up genetic programming (GP) applications <ref> (Koza, 1994) </ref> but practically they face two important problems that confine their efficiency. The "when" problem is that HGP does not employ informed choices to decide when creation or modification of functions is advantageous or necessary. <p> We could make the GP search engine more efficient by teaching it when to employ subroutine definition and what types of crossover to favor in various search phases. 3 COMPUTATIONAL EFFORT IN GP <ref> (Koza, 1994) </ref> estimated the computational effort needed to find a solution with a given probability z as being the minimum number of individuals processed in a number of runs R and a number of generations i which determine a corresponding cumulative probability of success P (i) after i generations: E (z) <p> I used a population size of 4000, and ran the GP system for 50, and in several cases for 200, generations. Other GP parameters were chosen as in <ref> (Koza, 1994) </ref>. The GP termination criterion did not take into account whether a solution was found. The plots showed in this section represent three measures of interest: the best-of-generation individual (hits), the population average fitness (energy) and the population entropy.
Reference: <author> Laarhoven, P. J. M. v. </author> <year> (1988). </year> <title> Theoretical and computational aspects of simulated annealing. </title> <publisher> Cen-trum voor Wiskunde en Informatica Amster-dam, </publisher> <address> Netherlands. </address>
Reference-contexts: Although simulated annealing present the nice theoretical property of convergence towards global optimum under certain conditions, they practically converge very slowly <ref> (Laarhoven, 1988) </ref>. A learning system should have an adaptive policy of balancing exploration and exploitation. Such an adaptive policy is possible in GP with subroutines, also called hierarchical GP (HGP) (Rosca and Ballard, 1995).
Reference: <author> Papadimitriou, C. H. and Steiglitz, K. </author> <year> (1982). </year> <title> Combinatorial optimization: algorithms and complexity. </title> <publisher> Prentice-Hall. </publisher>
Reference-contexts: If the search process acts to gain information or experience then it explores the search space. In the reinforcement learning literature, this tradeoff is made explicit by the control structure of the algorithms. Iterative improvement search algorithms used in combinatorial optimization <ref> (Papadimitriou and Steiglitz, 1982) </ref> attempt to improve search control by distinguishing between local and global search regimes and applying heuristics to decide where and how to search next. Local search is search performed in a neighborhood of a feasible search space point or configuration. <p> The choice of the neighborhood depends critically on the structure of the domain of feasible points and is subject to various heuristics, specifying the size and type of the neighborhood, the order to move in the neighborhood, the acceptance criterion (specifying when an improvement is accepted) etc. <ref> (Papadimitriou and Steiglitz, 1982) </ref> The search effort is specified in terms of bounds on the complexity of the algorithms. <p> Crossover usually has drastical effects, depending on the position of crossover points in the function hierarchy. This is a general problem of the GP represen tation called causality in (Rosca and Ballard, 1995): A "natural" perturbation of a feasible solution (as in <ref> (Papadimitriou and Steiglitz, 1982) </ref>) in not necessarily a smooth one in the fitness landscape.
Reference: <author> Ray, T. S. </author> <year> (1993). </year> <title> Evolution, complexity, entropy, </title> <booktitle> and artificial reality. </booktitle> <address> Physica D. </address>
Reference-contexts: Entropy has been used as a measure of diversity of an evolving ecological community in <ref> (Ray, 1993) </ref>. Partitions were defined as individuals having the same genotype.
Reference: <author> Rosca, J. P. </author> <year> (1995). </year> <title> Genetic programming exploratory power and the discovery of functions. </title> <booktitle> In Proceedings of the Fourth National Conference on Evolutionary Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: A learning system should have an adaptive policy of balancing exploration and exploitation. Such an adaptive policy is possible in GP with subroutines, also called hierarchical GP (HGP) <ref> (Rosca and Ballard, 1995) </ref>. HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution (Rosca, 1995). <p> HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution <ref> (Rosca, 1995) </ref>. Theoretically, HGP approaches allow to scale up genetic programming (GP) applications (Koza, 1994) but practically they face two important problems that confine their efficiency. The "when" problem is that HGP does not employ informed choices to decide when creation or modification of functions is advantageous or necessary. <p> Crossover usually has drastical effects, depending on the position of crossover points in the function hierarchy. This is a general problem of the GP represen tation called causality in <ref> (Rosca and Ballard, 1995) </ref>: A "natural" perturbation of a feasible solution (as in (Papadimitriou and Steiglitz, 1982)) in not necessarily a smooth one in the fitness landscape. <p> The goal is to evolve solutions of minimal size that solve the problem. By directly using the size constraint the GP algorithm would be prevented from finding solutions. In contrast, the disassortative mating algorithm improves convergence to a better optimum while maintaining speed. Two other diversity measures discussed in <ref> (Rosca, 1995) </ref> are the distribution of complexity of individuals (expanded structural complexity) and the distribution of fitness values. The latter is a more direct and easily observable type of variation in the population. Two individuals are different if they score differently. <p> The use of functions determines an increased exploration of the search space <ref> (Rosca, 1995) </ref> which positively affects the efficiency of GP. <p> I suggest that entropy is a suitable measure for controlling the adaptation of the problem representation by creating new functions. While entropy the Pac-Man problem. is a good measure for tracking diversity, the discovery of new functions is the actual mechanism used for increasing diversity and escaping local optima <ref> (Rosca, 1995) </ref>. The definition and use of new functions determines an exploration of the search space of programs. 8 CONCLUSIONS AND FUTURE WORK Two main strategies are at work in GP: exploration and exploitation.
Reference: <author> Rosca, J. P. and Ballard, D. H. </author> <year> (1995). </year> <title> Causality in genetic programming. </title> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms (ICGA95). </booktitle>
Reference-contexts: A learning system should have an adaptive policy of balancing exploration and exploitation. Such an adaptive policy is possible in GP with subroutines, also called hierarchical GP (HGP) <ref> (Rosca and Ballard, 1995) </ref>. HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution (Rosca, 1995). <p> HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) (Rosca and Ballard, 1994), are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution <ref> (Rosca, 1995) </ref>. Theoretically, HGP approaches allow to scale up genetic programming (GP) applications (Koza, 1994) but practically they face two important problems that confine their efficiency. The "when" problem is that HGP does not employ informed choices to decide when creation or modification of functions is advantageous or necessary. <p> Crossover usually has drastical effects, depending on the position of crossover points in the function hierarchy. This is a general problem of the GP represen tation called causality in <ref> (Rosca and Ballard, 1995) </ref>: A "natural" perturbation of a feasible solution (as in (Papadimitriou and Steiglitz, 1982)) in not necessarily a smooth one in the fitness landscape. <p> The goal is to evolve solutions of minimal size that solve the problem. By directly using the size constraint the GP algorithm would be prevented from finding solutions. In contrast, the disassortative mating algorithm improves convergence to a better optimum while maintaining speed. Two other diversity measures discussed in <ref> (Rosca, 1995) </ref> are the distribution of complexity of individuals (expanded structural complexity) and the distribution of fitness values. The latter is a more direct and easily observable type of variation in the population. Two individuals are different if they score differently. <p> The use of functions determines an increased exploration of the search space <ref> (Rosca, 1995) </ref> which positively affects the efficiency of GP. <p> I suggest that entropy is a suitable measure for controlling the adaptation of the problem representation by creating new functions. While entropy the Pac-Man problem. is a good measure for tracking diversity, the discovery of new functions is the actual mechanism used for increasing diversity and escaping local optima <ref> (Rosca, 1995) </ref>. The definition and use of new functions determines an exploration of the search space of programs. 8 CONCLUSIONS AND FUTURE WORK Two main strategies are at work in GP: exploration and exploitation.
Reference: <author> Rosca, J. P. and Ballard, D. H. (Orlando, </author> <year> 1994). </year> <title> Learning by adapting representations in genetic programming. </title> <booktitle> In Proceedings of the IEEE World Congress on Computational Intelligence, </booktitle> <pages> pages 407-412. </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: A learning system should have an adaptive policy of balancing exploration and exploitation. Such an adaptive policy is possible in GP with subroutines, also called hierarchical GP (HGP) (Rosca and Ballard, 1995). HGP extensions, such as Automatic Discovery of Functions (ADF) (Koza, 1992) or Adaptive Representation (AR) <ref> (Rosca and Ballard, 1994) </ref>, are based on the discovery, modification and use of new functions (subroutines) to accelerate evolution (Rosca, 1995). Theoretically, HGP approaches allow to scale up genetic programming (GP) applications (Koza, 1994) but practically they face two important problems that confine their efficiency.
Reference: <author> Ryan, C. O. </author> <year> (1994). </year> <editor> Pygmies and civil servants. In Kinnear, K., editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: However, such a definition is not practically useful. It is computationally expensive to test for tree isomorphisms. Moreover, associativity of functions is extremely difficult to take into account. In contrast, similarity between structures can be easily tested in GAs. <ref> (Ryan, 1994) </ref> uses an intuitive measure of diversity, based on performance, and shows that maintaining increased diversity in GP leads to better performance. His algorithm is called "disassortative mating." It selects parents for crossover from two different lists of individuals.
Reference: <author> Schrodinger, E. </author> <year> (1945). </year> <title> What is life? : the physical aspect of the living cell. </title> <publisher> Macmillan, </publisher> <address> New York. </address>
Reference-contexts: This generalization tendency in interpreting entropy led researchers to search for an unifying view between the statistical interpretations of the second law of thermodynamics in physics and evolutionary principles in biology (Bruce H. Weber and Smith, 1988). Schrodinger <ref> (Schrodinger, 1945) </ref> and others have noticed the following paradox: The increase in entropy in physical systems brings about a disorganization of the systems. Equivalently, systems evolve from less probable to more probable states.
Reference: <author> Shannon, C. E. </author> <year> (1964 [c1949]). </year> <title> The mathematical theory of communication. </title> <publisher> University of Illinois Press. </publisher>
Reference: <author> Thompson, C. J. </author> <year> (1988). </year> <title> Classical equilibrium statistical mechanics. </title> <publisher> Oxford Univ Press. </publisher>
Reference-contexts: to define posterior distributions on state variables of interest and to pose the allocation problem in terms of optimization problems on those variables. 4 ANALOGY WITH A PHYSICAL SYSTEM Ludwig Boltzmann introduced the distinction between micro state and macro state which enabled him to give a statistical interpretation to thermodynamics <ref> (Thompson, 1988) </ref>. The micro state description of a physical system would include a specification of state variables (such as position and velocity) for each particle. Theoretically, this could completely define the state of the system. <p> The entropy has a maximum value when all micro states are equiprobable. Entropy represents the disorder in the system of particles and tends to increase for irreversible processes as the ones in nature, according to the second law of thermodynamics <ref> (Thompson, 1988) </ref>. Shannon used the same formula to define an information measure representing one's ignorance of which of a number of possibilities actually holds, given the a priori probability distribution represented by P (Shan-non, 1949).
Reference: <author> Watkins, C. </author> <year> (1989). </year> <title> Learning from Delayed Rewards. </title> <type> PhD thesis, </type> <institution> Cambridge University. </institution>
Reference-contexts: Another expression of the exploration-exploitation problem appears in the reinforcement learning paradigm. An agent chooses its current action in his interaction with the environment in order to maximize future discounted rewards <ref> (Watkins, 1989) </ref>. If the search process chooses the action prescribed by its current knowledge, then the system exploits its current knowledge by acting in order to gain reward. It occasionally explores actions at random in order to experiment with more state-action pairs and eventually improve its policy.
Reference: <author> Whitehead, S. D. </author> <year> (1992). </year> <title> Reinforcement learning for the adaptive control of perception and action. </title> <type> PhD thesis, </type> <institution> Univ. of Rochester. Computer Science Dept. </institution>
Reference: <author> Wicken, J. S. </author> <year> (1988). </year> <title> Thermodynamics, Evolution, and Emergence: Ingredients for a New Synthesis, chapter 7. </title> <publisher> MIT Press. </publisher>
Reference-contexts: The energy of an individual i is in this case: H (i) = Stdfitness (i) The principle of natural selection is strongly tied to the idea of energy, as individuals in a population compete for the effective utilization of energy resources <ref> (Wicken, 1988) </ref>. Ideally, there would be no uncertainty regarding the state if the entire population were made up of copies of a single individual (one having the minimum energy for a global optimum state). However, genetic search starts with a randomly generated state. <p> However, there are various claims about the role of the second law of thermodynamics in biological evolution (Bruce H. Weber and Smith, 1988). For instance Wicken proposed that genetic variation is due to the probabilistic nature of the second law <ref> (Wicken, 1988) </ref>. One measure that quantifies variation is diversity.
Reference: <author> Wilson, S. W. </author> <year> (1994). </year> <title> Zcs: A zeroth level classifier system. </title> <journal> Evolutionary Computation, </journal> <volume> 2(1) </volume> <pages> 1-18. </pages>
Reference-contexts: In the reinforcement phase of the control loop of a classifier system, matching classifiers that do not get activated are weakened. This lowers the chances of choosing unpromising actions in the near future. The weakening magnitude is usually controlled by an explicit parameter, although more elaborate schemes are possible <ref> (Wilson, 1994) </ref>. In GP one no longer has control over how much is exploitation and how much is exploration, because it is hard to delimit exploration from exploitation. This is one of the weaknesses of GA in general and GP in particular, but is also one of the advantages.
Reference: <author> Wright, S. </author> <year> (1986). </year> <title> Evolution : selected papers / Sewall Wright. </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: Such a situation means on the one hand the retention of a great source of variability in the pop ulation and on the other hand a random drifting of the mean grade of all characters, leading occasionally by chance, to the attainment of exceptionally favorable gene combinations" <ref> (Wright, 1986) </ref>. Genetic heterogeneity, or diversity, is one candidate for a useful statistical measure to be considered in this paper. Although the importance of diversity in genetic search is widely recognized in the GA/GP literature, this topic has not been given the deserved formal attention.
References-found: 27

