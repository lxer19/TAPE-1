URL: http://www.research.digital.com/SRC/personal/Michael_Mitzenmacher/NEWWORK/postscripts/andor-conf.ps.gz
Refering-URL: http://www.research.digital.com/SRC/personal/Michael_Mitzenmacher/NEWWORK/papers.html
Root-URL: http://www.research.digital.com
Title: Analysis of Random Processes via And-Or Tree Evaluation  
Author: Michael G. Luby Michael Mitzenmacher M. Amin Shokrollahi 
Abstract: We introduce a new set of probabilistic analysis tools based on the analysis of And-Or trees with random inputs. These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including random loss-resilient codes, solving random k-SAT formula using the pure literal rule, and the greedy algorithm for matchings in random graphs. In addition, these tools allow generalizations of these problems not previously analyzed to be analyzed in a straightforward manner. We illustrate our methodology on the three problems listed above. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. Edmonds, M. Luby, </author> <title> Linear Time Erasure Codes With Nearly Optimal Recovery, </title> <booktitle> Proc. of the 36 th Annual Symp. on Foundations of Computer Science, </booktitle> <year> 1995, </year> <pages> pp. 512-519. </pages>
Reference: [2] <author> N. Alon, M. Luby, </author> <title> A Linear Time Erasure-Resilient Code With Nearly Optimal Recovery, </title> <journal> IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 17321736. </pages>
Reference: [3] <author> R. Boppana, </author> <title> Amplification of probabilistic Boolean formulas, </title> <booktitle> Advances in Computer Research, </booktitle> <volume> Vol. 5: </volume> <booktitle> Randomness and Computation, </booktitle> <publisher> JAI Press, </publisher> <address> Greenwich, CI, </address> <year> 1989, </year> <pages> pp. 27 45. </pages>
Reference-contexts: OR-AND tree has a critical value of OE = (3 p 5)=2, and that if y `1 = OE + * then y ` &gt; OE + c* for a constant c &gt; 1. (Analogously, if y `1 = OE *, then y ` &lt; OE c*.) In further work, <ref> [3] </ref> and [5] provide beautiful proofs that the construction size of [13] is optimal, this time using amplification analysis to prove a lower bound. Our work has a similar spirit to the amplification work, but it differs in several ways.
Reference: [4] <author> A. Broder, A. Frieze, E. Upfal, </author> <title> `On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas, </title> <booktitle> Proc. of the 4 th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 322-330. </pages>
Reference-contexts: unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including the random loss-resilient codes introduced in [9], the greedy algorithm for matchings in random graphs studied in [7], and the threshold for solving random k-SAT formula using the pure literal rule <ref> [4] </ref>. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. For example, we can analyze generalizations of the loss-resilient codes considered in [9] where the goal is to recover a certain fraction of the message packets. <p> to randomly chosen k-SAT formula ([4, 11]). (See also [6] for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in <ref> [4] </ref> and [11]. With this new analysis, it is also straightforward to analyze distributions that were not previously considered and which would be much harder to analyze using previous techniques applied to this problem. <p> For a specific k we can easily determine the threshold value c for which (5) is satisfied. In particular, for k = 3 we obtain the value c 1:63. This result has been found previously by <ref> [4] </ref> and [11] using a different approach.
Reference: [5] <author> M. Dubiner, U. Zwick, </author> <title> Amplification by Read-Once Formulas, </title> <journal> Siam J. on Computing, </journal> <volume> Vol. 26, No. 1, </volume> <month> Feb. </month> <year> 1997, </year> <pages> pp. 1538. </pages>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by [12] and further developed and used in <ref> [13, 5] </ref>. <p> We say the tree is (d or ,d and )-regular if each OR node has d or children and each AND node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon [12], and continued in several works <ref> [13, 5] </ref>. Consider the probability that the root of the tree evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` . <p> has a critical value of OE = (3 p 5)=2, and that if y `1 = OE + * then y ` &gt; OE + c* for a constant c &gt; 1. (Analogously, if y `1 = OE *, then y ` &lt; OE c*.) In further work, [3] and <ref> [5] </ref> provide beautiful proofs that the construction size of [13] is optimal, this time using amplification analysis to prove a lower bound. Our work has a similar spirit to the amplification work, but it differs in several ways. <p> Starting at the root and working down the tree, each OR node chooses to have i children with probability ff i independent of any other node, and similarly each AND node choose to have j children with probability fi j independent of any other node. (Some previous research, e.g., <ref> [5] </ref>, introduced a variant of this form and used it in a limited way in their construction.) A further generalization is to allow two positive values a and b such that each OR node is independently short circuited to produce the value 1 with probability a, and each AND node is
Reference: [6] <author> A. Frieze, S. Suen, </author> <title> Analysis of Two Simple Heuristics on a Random Instance of k-SAT, </title> <journal> J. of Algorithms, </journal> <volume> Vol. 20, </volume> <year> 1996, </year> <pages> pp. 312355. </pages>
Reference-contexts: The behavior of the pure literal rule has been studied previously with respect to randomly chosen k-SAT formula ([4, 11]). (See also <ref> [6] </ref> for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in [4] and [11].
Reference: [7] <author> R. Karp, M. Sipser, </author> <title> Maximum Matchings in Sparse Random Graphs, </title> <booktitle> FOCS, </booktitle> <year> 1981, </year> <pages> pp. 364375. </pages>
Reference-contexts: These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including the random loss-resilient codes introduced in [9], the greedy algorithm for matchings in random graphs studied in <ref> [7] </ref>, and the threshold for solving random k-SAT formula using the pure literal rule [4]. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. <p> One common technique involved modeling the random process using differential equa 2 tions. This type of approach was pioneered in the analysis of algorithms domain by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in <ref> [7] </ref>. <p> The advantage of the tree analysis approach employed in this paper is that, with little additional difficulty, it is easily possible to analyze substantially different distributions for choosing the formula, merely by establishing the proper functions ae (x) and (x). 4 Greedy Matching Analysis In the paper <ref> [7] </ref>, the analysis of a simple and fast heuristic for finding matchings was described and analyzed with respect to randomly chosen graphs. The tree analysis approach can be used 9 to provide an alternative analysis (of what they call Phase 1).
Reference: [8] <author> T.G. Kurtz, </author> <title> Approximation of Population Processes, </title> <booktitle> CBMS-NSF Regional Conf. Series in Applied Math, </booktitle> <publisher> SIAM, </publisher> <year> 1981. </year>
Reference-contexts: pure literal on random k-SAT formulae [11]. (See also [10, 11] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [9] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem <ref> [8] </ref> to make the connection between the behavior of the random process and that of the polynomial. One of the ingredients lacking in the previous analysis of these codeswas a simple intuitive connection between the polynomial solution and the original process.
Reference: [9] <author> M. Luby, M. Mitzenmacher, M. A. Shokrollahi, D. Spielman, V. Stemann, </author> <title> Practical Loss-Resilient Codes, </title> <booktitle> Proc. 29 th Symp. on Theory of Computing, </booktitle> <year> 1997, </year> <pages> pp. 150159. </pages>
Reference-contexts: These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including the random loss-resilient codes introduced in <ref> [9] </ref>, the greedy algorithm for matchings in random graphs studied in [7], and the threshold for solving random k-SAT formula using the pure literal rule [4]. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. <p> In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. For example, we can analyze generalizations of the loss-resilient codes considered in <ref> [9] </ref> where the goal is to recover a certain fraction of the message packets. As another example, we can analyze the behavior of the pure literal rule on random SAT formulae chosen from distributions not considered by previous analyses. <p> It has also been used to analyze the pure literal on random k-SAT formulae [11]. (See also [10, 11] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in <ref> [9] </ref> was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [8] to make the connection between the behavior of the random process and that of the polynomial. <p> In the next three sections, we apply this simple lemma to the analysis of loss-resilient codes, the pure literal rule for random k-CNF formula, and sketch its application to the greedy matching algorithm for random graphs. 2 Loss-Resilient Code Analysis 2.1 Essentials of the Codes The codes described in <ref> [9] </ref> consist of a cascading sequence of random bipartite graphs. Because the code requires the same properties from all of these bipartite graphs, it is enough consider one generic bipartite graph in the sequence when describing the encoding and decoding process and its analysis. <p> The decoding process terminates successfully with all message bits recovered iff the graph substitution recovery rule ends with no remaining left nodes with label 0. 2.2 New Analysis of the Original Process The paper <ref> [9] </ref> gave an analysis of the decoding process described in the previous subsection using differential equations to model the process, and then solving these equations as polynomials. In this subsection, we obtain the same result using Lemma 1. <p> Let (p 0 ; p 1 ; : : : ; p L ) and (q 0 ; q 1 ; : : : ; q R ) be probability vectors. As in <ref> [9] </ref>, consider choosing a random bipartite graph with n left nodes and m right nodes as follows: each node on the left is chosen to have degree i with probability p i , and each node on the right is chosen to have degree j with probability p j , where <p> This turns out to equivalent to the condition given in <ref> [9] </ref> for this process to end successfully. 2.3 The Overall Analysis It is not hard to argue that the process terminates with all message values successfully recovered if the probability that a message bit is not directly received is ffi and if Condition (1) is fulfilled. <p> Then, using the expansion properties of the random graph, which follows from standard combinatorial arguments as outlined in <ref> [9] </ref>, it is not hard to argue that if at most fl 0 n message bits are left recovered then the decoding process fails to recover more than O (n fl 00 ) message bits with probability at most inverse polynomial in n, for some constant fl 00 &lt; 1. <p> From this it follows that, with high probability, when the decoding process terminates all message bits have been successfully recovered. 2.4 The Dual Inequality In <ref> [9] </ref> a procedure is described for finding (close to) optimal right probabilities ae 1 ; : : : ; ae R for a given set of left probabilities 1 ; : : : ; L using a linear programming approach. However, [9] did not describe how to find the optimal left <p> have been successfully recovered. 2.4 The Dual Inequality In <ref> [9] </ref> a procedure is described for finding (close to) optimal right probabilities ae 1 ; : : : ; ae R for a given set of left probabilities 1 ; : : : ; L using a linear programming approach. However, [9] did not describe how to find the optimal left probabilities for a given set of right probabilities. Using Condition (1), it is easy to see how to use the methodology described in [9] to do exactly this. <p> However, <ref> [9] </ref> did not describe how to find the optimal left probabilities for a given set of right probabilities. Using Condition (1), it is easy to see how to use the methodology described in [9] to do exactly this. In fact, Condition (1) is in some sense the dual of the corresponding condition described in [9], which was ae (1 ffi (1 x)) &gt; x (1 + *) (2) for some constant * &gt; 0 and for all x 2 (0; 1]. <p> Using Condition (1), it is easy to see how to use the methodology described in <ref> [9] </ref> to do exactly this. In fact, Condition (1) is in some sense the dual of the corresponding condition described in [9], which was ae (1 ffi (1 x)) &gt; x (1 + *) (2) for some constant * &gt; 0 and for all x 2 (0; 1]. It is from Condition (2) that [9] shows how to find the optimal right probabilities for a given set of left probabilities. <p> In fact, Condition (1) is in some sense the dual of the corresponding condition described in <ref> [9] </ref>, which was ae (1 ffi (1 x)) &gt; x (1 + *) (2) for some constant * &gt; 0 and for all x 2 (0; 1]. It is from Condition (2) that [9] shows how to find the optimal right probabilities for a given set of left probabilities. We leave it as an exercise how to use the And-Or tree analysis to easily derive Condition (2).
Reference: [10] <author> M. </author> <title> Mitzenmacher, </title> <type> Ph.D. thesis. </type> <institution> University of California, Berkeley, </institution> <year> 1996. </year>
Reference-contexts: This type of approach was pioneered in the analysis of algorithms domain by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [7]. It has also been used to analyze the pure literal on random k-SAT formulae [11]. (See also <ref> [10, 11] </ref> for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [9] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [8] to make the connection between the behavior of the
Reference: [11] <author> M. Mitzenmacher, </author> <title> Tight Thresholds for the Pure Literal Rule, </title> <type> DEC/SRC Technical Note 1997-011, </type> <month> June </month> <year> 1997. </year>
Reference-contexts: This type of approach was pioneered in the analysis of algorithms domain by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [7]. It has also been used to analyze the pure literal on random k-SAT formulae <ref> [11] </ref>. (See also [10, 11] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [9] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [8] to make the connection between the <p> This type of approach was pioneered in the analysis of algorithms domain by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [7]. It has also been used to analyze the pure literal on random k-SAT formulae [11]. (See also <ref> [10, 11] </ref> for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [9] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [8] to make the connection between the behavior of the <p> chosen k-SAT formula ([4, 11]). (See also [6] for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in [4] and <ref> [11] </ref>. With this new analysis, it is also straightforward to analyze distributions that were not previously considered and which would be much harder to analyze using previous techniques applied to this problem. <p> For a specific k we can easily determine the threshold value c for which (5) is satisfied. In particular, for k = 3 we obtain the value c 1:63. This result has been found previously by [4] and <ref> [11] </ref> using a different approach.
Reference: [12] <author> E. Moore, C. Shannon, </author> <title> Reliable circuits using less reliable relays, </title> <journal> J. Franklin Inst., </journal> <volume> 262, </volume> <year> 1956, </year> <pages> pp. </pages> <note> 191208 and 281297. </note>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by <ref> [12] </ref> and further developed and used in [13, 5]. <p> We say the tree is (d or ,d and )-regular if each OR node has d or children and each AND node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon <ref> [12] </ref>, and continued in several works [13, 5]. Consider the probability that the root of the tree evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` .
Reference: [13] <author> L. G. Valiant, </author> <title> Short Monotone Formulae for the Majority Function, </title> <journal> J. of Algorithms, </journal> <volume> Vol. 5, </volume> <year> 1984, </year> <pages> pp. 363366. 10 </pages>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by [12] and further developed and used in <ref> [13, 5] </ref>. <p> We say the tree is (d or ,d and )-regular if each OR node has d or children and each AND node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon [12], and continued in several works <ref> [13, 5] </ref>. Consider the probability that the root of the tree evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` . <p> Of primary interest in these studies is the rate of amplification, i.e., the rate at which y ` goes to either 0 or 1 as a function of `. One work that uses exactly this type of analysis is the elegant randomized construction, given in <ref> [13] </ref>, of a polynomial size monotone boolean formula that computes the majority function. <p> 5)=2, and that if y `1 = OE + * then y ` &gt; OE + c* for a constant c &gt; 1. (Analogously, if y `1 = OE *, then y ` &lt; OE c*.) In further work, [3] and [5] provide beautiful proofs that the construction size of <ref> [13] </ref> is optimal, this time using amplification analysis to prove a lower bound. Our work has a similar spirit to the amplification work, but it differs in several ways. We generalize to allow the number of children of each node to vary in the following way.
References-found: 13

