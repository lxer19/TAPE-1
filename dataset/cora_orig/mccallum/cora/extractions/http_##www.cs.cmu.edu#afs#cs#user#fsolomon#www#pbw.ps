URL: http://www.cs.cmu.edu/afs/cs/user/fsolomon/www/pbw.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/fsolomon/www/home.html
Root-URL: 
Title: 1: Introduction The measurement of shape is a basic object inspection task. This measurement is
Author: Solomon and Katsushi Ikeuchi 
Address: Pittsburgh, PA 15213, USA  
Affiliation: The Robotics Institute Carnegie Mellon University  
Note: Fredric  This research was sponsored in part by the Advanced Research Projects Agency under the Department of the Army, Army Research Office, under grant number DAAH04-94-G-0006.  
Abstract: Computer vision research has produced a number of basic techniques for measuring the shape of an object: stereo vision, range finders, and photometric techniques. Photometric techniques use physically based reectance models [12] to transform image brightness into shape. Image brightness depends on lighting geometry, imaging geometry, and surface shape. If we can control imaging geometry and illumination geometry, we can use a reec-tance model in conjunction with measured image brightness to determine surface shape. Imaging geometry has been explored by a number of researchers. However, very few researchers have investigated how to illuminate an object that they are trying to inspect. In photometric stereo, the position of the light source affects what parts of the object are illuminated and the accuracy with which you can recover the objects shape. The problem is to determine the best place to position light sources in order to inspect a given object. We investigate the illumination problem from two perspectives. First, we determine how to position light sources around an object so that we illuminate a specified set of faces in an efficient manner. In order to solve this problem, we have to determine light source visibility and we have to find some method of efficiently covering the specified set of object faces. Secondly, we determine how to position the light sources so that they give us an accurate measurement of shape. There are two basic types of errors in photometric measurements of lambertian objects: random errors (noise) and fixed errors. Random errors are due to the variance of the camera and digitizer. These are the errors that we try to predict with our planner. Fixed errors include: errors in light source direction, errors in light source radiance, errors in the photometric function . Fixed errors can be accounted for by a careful calibration procedure [19]. Noise causes uncertainty in our shape measurement. The amount of uncertainty that this noise will create in our measurement will depend on light source positions. By using a noise model of the CCD, a CAD model of the object we are inspecting, and the lambertian reectance model we can determine how much uncertainty we can expect in our shape measurement for a given light source configuration. We can find an optimal light source configuration, one that produces a minimum amount of measurement uncertainty. The environments we will study are structured. We will assume that have a CAD model of the object that we want to inspect and that we know the pose of the object. The objects we look at are convex or are simple concavities. We assume orthographic projection and parallel incident light. From a high level, our problem has three major inputs: the CAD model of the object we are trying to inspect, the An Illumination Planner for Convex and Concave Lambertian Polyhedral Objects Abstract The measurement of shape is a basic object inspection task. We use a noncontact method to determine shape called photometric stereo. The method uses three light sources which sequentially illuminate the object under inspection and a video camera for taking intensity images of the object. A significant problem with using photometric stereo is determining where to place the 3 light sources and the video camera. In order to solve this problem, we have developed an illumination planner that determines how to position the three light sources and the video camera around the object. The planner determines how to position light sources around an object so that we illuminate a specified set of faces in an efficient manner, and so that we obtain an accurate measurement. From a high level, our planner has three major inputs: the CAD model of the object to be inspected, a noise model for our sensor, and a reectance model for the object to be inspected. We have experimentally verified that the plans generated by the planner are valid and accurate. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Cowan, </author> <title> Automatic Sensor Placement from Vision Task Requirements, </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 10, No. 3, </volume> <pages> pp. 407-416, </pages> <month> May, </month> <year> 1988. </year>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods <ref> [1, 4, 6, 7] </ref> have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast.
Reference: [2] <author> C. Cowan, </author> <title> Determining the Camera and Light Source Location for a Visual Task, </title> <booktitle> 1989 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pp. 509-514. </pages>
Reference-contexts: Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan <ref> [2] </ref> investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition. In [8, 9], Sakane describes positioning light sources for a photometric stereo system. He tries to optimize the extracted surface normal and the surface coverage for lam-bertian surfaces.
Reference: [3] <author> C. Cowan, </author> <title> Automatic Camera and Light Source Placement Using CAD Models, </title> <booktitle> IEEE Workshop on Directions in Automated CAD-Based Vision, </booktitle> <month> June </month> <year> 1991, </year> <title> Maui, </title> <booktitle> Hawaii, </booktitle> <pages> pp. 22-31. </pages>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods [1, 4, 6, 7] have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane <ref> [3, 10] </ref> have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition.
Reference: [4] <author> R. Tsai and K. Tarabanis, </author> <title> Occlusion Free Sensor Placement, </title> <institution> Yorktown Heights, NY: T.J. Watson Research Center, RC 14593, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods <ref> [1, 4, 6, 7] </ref> have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast.
Reference: [5] <author> S. K. Nayar and H. Murase, </author> <title> Illumination Planning for Object Recognition in Structured Environments, </title> <booktitle> 1994 IEEE International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. </pages> <month> 31-38. </month> <title> Planner Predictions Measurements Face (center of face) Light Sources s(q err ) - Degrees s(q err ) - Degrees A 1,12,6 4.05 4.71 A 1,12,5 1.23 1.42 A 2,11,6 1.14 1.25 A 2,11,5 4.22 3.05 </title>
Reference-contexts: Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar <ref> [5] </ref> investigated illumination planning for object recognition. In [8, 9], Sakane describes positioning light sources for a photometric stereo system. He tries to optimize the extracted surface normal and the surface coverage for lam-bertian surfaces.
Reference: [6] <author> R. Tsai, K. Tarabanis, and P. Allen, </author> <title> Automated Sensor planning for robotic vision tasks, </title> <booktitle> 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pp. 76-82. </pages>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods <ref> [1, 4, 6, 7] </ref> have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast.
Reference: [7] <author> S. Sakane, M. Ishii, and M. Kakikura, </author> <title> Occlusion avoidance of visual sensors based on a hand-eye action simulator system: HEAVEN, </title> <booktitle> Advanced Robotics, </booktitle> <volume> Vol. 2, No 2, </volume> <pages> pp. 149-165. </pages>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods <ref> [1, 4, 6, 7] </ref> have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast.
Reference: [8] <author> S. Sakane, T. Sato, and M. Kakikura, </author> <title> Automatic Planning of Light Source Placement for an Active Photometric Stereo System, </title> <booktitle> 1990 IEEE International Workshop on Intelligent Robots and Systems, </booktitle> <pages> pp. 559-556. </pages>
Reference-contexts: Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition. In <ref> [8, 9] </ref>, Sakane describes positioning light sources for a photometric stereo system. He tries to optimize the extracted surface normal and the surface coverage for lam-bertian surfaces. <p> The noisy normal distribution in the two figures is the same except for a 90 rotation. However, normalization causes the angular orientation errors to be very different. Sakane <ref> [8, 9] </ref> proposes a metric of surface orientation reliability that relies on estimating the unnormalized vector error.
Reference: [9] <author> S. Sakane and T. Sato, </author> <title> Automatic Planning of Light Source Placement and Camera Placement for an Active Photometric Stereo System, </title> <booktitle> 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pp. 1080 - 1087. </pages>
Reference-contexts: Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition. In <ref> [8, 9] </ref>, Sakane describes positioning light sources for a photometric stereo system. He tries to optimize the extracted surface normal and the surface coverage for lam-bertian surfaces. <p> The noisy normal distribution in the two figures is the same except for a 90 rotation. However, normalization causes the angular orientation errors to be very different. Sakane <ref> [8, 9] </ref> proposes a metric of surface orientation reliability that relies on estimating the unnormalized vector error.
Reference: [10] <author> R. Niepold, S. Sakane, T. Sato, and Y. Shiraii, </author> <title> Vision Sensor Set-up for a Hand-Eye System Using Environmental Model, </title> <booktitle> SICE 87, </booktitle> <pages> pp. 1037-1040. </pages>
Reference-contexts: These models are used to generate an illumination plan. 2: Previous Work A number of methods [1, 4, 6, 7] have been developed to position a camera to satisfy requirements such as: visibility, focus, field of view, and resolution. Cowan and Sakane <ref> [3, 10] </ref> have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi [11] investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition.
Reference: [11] <author> S. Yi, R. Haralick, and L. Shapiro, </author> <title> Automatic Sensor and Light Source Placement for Machine Vision, </title> <institution> University of Wash-ington, </institution> <address> Seattle, Washington, CS-89-11-03. </address>
Reference-contexts: Cowan and Sakane [3, 10] have investigated positioning light sources in order to obtain convex lambertian edge contrast. Yi <ref> [11] </ref> investigated convex specular lobe edge contrast. Cowan [2] investigated positioning light sources to satisfy scene radiance and CCD irradiance requirements. Nayar [5] investigated illumination planning for object recognition. In [8, 9], Sakane describes positioning light sources for a photometric stereo system.
Reference: [12] <author> S. K. Nayar, K. Ikeuchi, T. Kanade, </author> <title> Surface Reections: Physical and Geometrical Perspectives, </title> <journal> IEEE Trans. of Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 13, No. 7, </volume> <pages> pp. 611-634, </pages> <month> July, </month> <year> 1991. </year>
Reference-contexts: However, the measurements are usually made manually. Some companies have turned to computer vision techniques. Computer vision research has produced a number of basic techniques for measuring the shape of an object: stereo vision, range finders, and photometric techniques. Photometric techniques use physically based reectance models <ref> [12] </ref> to transform image brightness into shape. Image brightness depends on lighting geometry, imaging geometry, and surface shape. If we can control imaging geometry and illumination geometry, we can use a reec-tance model in conjunction with measured image brightness to determine surface shape.
Reference: [13] <author> J. J. Koenderink and A. J. van Doorn, </author> <title> The Internal Representation of Solid Shape with Respect to Vision, </title> <journal> Biol. Cybernetics, </journal> <volume> Vol. 32, </volume> <pages> pp. 211-216, </pages> <year> 1979. </year>
Reference: [14] <author> K. Ikeuchi and T. Kanade, </author> <title> Automatic Generation of Object Recognition Programs, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 76, No. 8, </volume> <pages> pp. 1016-1035, </pages> <month> August, </month> <year> 1988. </year>
Reference: [15] <author> M. Hebert and T. </author> <title> Kanade, </title> <booktitle> The 3D-Profile Method of Object Recognition,1985 IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 458-463. </pages>
Reference: [16] <author> D. Kriegman and J. Ponce, </author> <title> Computing Exact Aspect Graphs of Curved Objects: Solids of Revolution, </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 5, No. 2, </volume> <pages> pp. 119-135. </pages>
Reference: [17] <author> K. Bowyer and C. Dyer, </author> <title> Aspect Graphs: An Introduction and Survey of Recent Results, </title> <journal> International Journal of Imaging Systems and Technology, </journal> <volume> Vol 2, No. 4, </volume> <year> 1990, </year> <pages> pp. 315-328. </pages>
Reference: [18] <author> G. Healey and R. Kondepudy, </author> <title> CCD Camera Calibration and Noise Estimation, </title> <booktitle> 1992 IEEE International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 90 - 95. </pages>
Reference-contexts: We determine the orientation error, the angle between the nominal unit normal and the noisy unit normal, by having the planner conduct a simulation using s 2 i . s 2 variance of the camera and digitizer. s 2 i is a function of light intensity as shown by Healey <ref> [18] </ref>.
Reference: [19] <author> R. Ray, J. Birk, and R. Kelley, </author> <title> Error Analysis of Surface Normals Determined by Radiometry, </title> <journal> IEEE Trans. of Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 5, No. 6, </volume> <pages> pp. 631-645, </pages> <month> November, </month> <year> 1983. </year>
Reference-contexts: These are the errors that we try to predict with our planner. Fixed errors include: errors in light source direction, errors in light source radiance, errors in the photometric function . Fixed errors can be accounted for by a careful calibration procedure <ref> [19] </ref>. Noise causes uncertainty in our shape measurement. The amount of uncertainty that this noise will create in our measurement will depend on light source positions.
Reference: [20] <author> B. Kumar, J.C. Robert, R. Hoffman, K. Ikeuchi and T. Kanade, Vantage, </author> <title> A Frame Based Geometric Modeling System Programmer/Users Manual V2.0, </title> <address> CMU-RI-TR-91-31, </address> <month> Decem-ber </month> <year> 1991. </year>
Reference-contexts: need to be combined in some manner that provides non-redundant coverage of all the object faces that need to be inspected. (This can be any subset of the set of all object faces.) We generate CAD models of objects that we want to inspect using the Vantage geometric modeling system <ref> [20] </ref>. Using these models and Vantages 3D-to-2D scene generation capabilities, we can generate orthographic projections from various viewpoints of a tessellated icosahedron. We compare the area of each visible object face with its foreshortened projected area.
Reference: [21] <author> F. Solomon and K. </author> <title> Ikeuchi, An Illumination Planner for Convex and Concave Lambertian Polyhedral Objects, </title> <address> CMU-RI-TR-95-04, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: See <ref> [21] </ref> for details. 5: 3D Convex Lambertian Illumination Light source positioning in 3D is similar to light source positioning in 2D. The goal is to find the positions for three light sources that illuminate a given set of object faces while minimizing the total orientation error for the object faces. <p> For n faces: If the three light sources used to determine N do not have the same radiances, the three measured intensity val ues (I1, I2, and I3) need to be normalized. This will affect the value of s (q err ). See <ref> [21] </ref> for details. 5.2: Camera Viewpoint Selection We need to position a camera so that it views all of the faces illuminated by each illumination aspect.
Reference: [22] <author> S. K. Nayar, K. Ikeuchi, T. Kanade, </author> <title> Shape from Interre-ections, </title> <booktitle> Proceedings of the Third International Conference on Computer Vision, </booktitle> <pages> pp. 2-11, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Nayar <ref> [22] </ref> showed that a shape from intensity method, such as photometric stereo, applied to a concavity would produce a pseudo shape which is invariant to light source placement. So, if the pseudo shape is invariant to light source placement, what constitutes the light source placement problem.
Reference: [23] <author> C. Goral, K. Torrance, D. Greenberg, and B. Battaile, </author> <title> Modeling the Interaction of Light Between Diffuse Surfaces, </title> <booktitle> Proceedings of SIGGRAPH 84, </booktitle> <volume> Vol. 18, No. 3, </volume> <pages> pp. 213-221, </pages> <month> July, </month> <year> 1984. </year>
Reference-contexts: The reliability at each point of the pseudo shape only depends on the intensity at that point, not on any other points of the pseudo shape. We can use the forward graphics solution <ref> [23] </ref> to predict the brightness of the concavity for three light sources, S1, S2, and S3. S1 produces the brightness distribution B1.
References-found: 23

