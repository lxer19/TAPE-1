URL: http://www.cs.unr.edu/src/techreports/sushil/andrew_thesis.ps
Refering-URL: http://www.cs.unr.edu/src/techreports/TechReports.html
Root-URL: 
Title: University of Nevada Reno Design Strategies for Evolutionary Robotics  
Author: Andrew Murray Sushil Louis 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Master of Science in Computer Science by  
Date: May 1995  
Abstract-found: 0
Intro-found: 1
Reference: <author> V. </author> <title> Braitenberg. Vehicles. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: made it more difficult to find an effective control strategy because the only way to turn in the opposite direction when sensing an obstacle is to decrease the velocity of the motor opposite to the side of the touch sensor, assuming that full speed ahead is the normal operating state <ref> (Braitenberg 86) </ref>. Switching to a cross mapping, where the left sensors have a higher probability of influencing the right motor, is more effective (see figure 4.1).
Reference: <author> D. Cliff, P. Husbands, and I. Harvey. </author> <title> "Evolving visually guided robots." </title> <type> Technical Report CSRP 220, </type> <institution> School of Cognitive and Computing Science, University of Sussex, </institution> <year> 1992. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 3 In addition, others have been successful in utilizing neural networks by using genetic encoding of node architecture, weight sets, excitor/inhibitor connections etc. to evolve visually guided robots which perform avoidance behavior <ref> (Cliff 92) </ref>. I use a genetic algorithm (GA) to design both the structure and control strategy for my agent (Holland 75; Goldberg 89). In related work, I experimented with traditional neural network architectures using gradient and approximation techniques.
Reference: <author> M. Dorigo and M. Colombetti. </author> <title> "Robot shaping: Developing situated agents through learning." </title> <type> Technical Report TR-92-040 Revised, </type> <institution> International Computer Science Institute, University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Evolving combinational circuits is described in (Louis 91). Another method used to develop adaptive learning in situated agents is by using a classifier system with monolithic and hierarchical architectures <ref> (Dorigo 93) </ref>. CHAPTER 1. INTRODUCTION 3 In addition, others have been successful in utilizing neural networks by using genetic encoding of node architecture, weight sets, excitor/inhibitor connections etc. to evolve visually guided robots which perform avoidance behavior (Cliff 92). <p> The evolution of high level behaviors has yet to be fully explored, but two typical methods that have been researched are combining basic behaviors by simple switching based on heuristic or common sense rules or by prioritizing basic behaviors in some hierarchical manner <ref> (Dorigo 93) </ref>. This thesis deals with the former. Chapter 4 deals with the first behavior to be developed, obstacle avoidance (Mur-ray 95b). The goal of these simbots is to learn to keep moving forward unless confronted with an obstacle.
Reference: <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference: <author> J. Holland. </author> <title> Adaptation In Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbour, </address> <year> 1975. </year>
Reference-contexts: This formula is known as the schema theorem and is the Fundamental Theorem of Genetic Algorithms <ref> (Holland 75) </ref>. The higher the population the more thorough initial exploration of the search space. Hence, there is a greater chance of there being one or more individuals in early generations that will perform fairly well, purely by chance.
Reference: <editor> J. R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: <author> S. J. Louis and G. J. E. Rawlins. </author> <title> "Designer genetic algorithms: </title> <booktitle> Genetic algorithms in structure design." In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 53-60. </pages> <publisher> Morgan Kauffman, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control (Dorigo 93; Koza 92). Evolving combinational circuits is described in <ref> (Louis 91) </ref>. Another method used to develop adaptive learning in situated agents is by using a classifier system with monolithic and hierarchical architectures (Dorigo 93). CHAPTER 1.
Reference: <author> A. Murray and S. J. Louis. </author> <title> "Adapting control strategies for situated autonomous agents." </title> <journal> In Proceedings of the Florida Artificial Intelligence Research Symposium, </journal> <note> page to appear, 1995. 62 BIBLIOGRAPHY 63 A. </note> <author> Murray and S. J. Louis. </author> <title> "Design strategies for evolutionary robotics." </title> <editor> In E. A. Yfantis, editor, </editor> <booktitle> Proceedings of the Third Golden West International Conference on Intelligent Systems, </booktitle> <pages> pages 609 - 616. </pages> <publisher> Kluwer Academic Press, </publisher> <year> 1995. </year>
Reference-contexts: Thus, circular and backwards motion are not rewarded as much and get suppressed. Fast forward motion in free space emerges as the dominant behavior. Chapter 5 discusses the development of the approach behavior <ref> (Murray 95b) </ref>. A number of food sources are placed in an obstacle free environment. These food sources emit simulated sound which allow the simbots to determine relative distances CHAPTER 1. INTRODUCTION 4 and directions to these points by evolving crude triangulation techniques. <p> The results are promising; the simbots develop different sensor characteristics corresponding to differences in the number and spacing of the "food" sources in the environment. I discuss the results of combining the two behaviors in chapter 6 <ref> (Murray 95b) </ref>. At first, the simbots are unable to learn both behaviors simultaneously because of the conflictive nature of approach and avoidance. In order to solve this problem, I establish a short training period for each type of behavior before combining then. <p> The simbots are then able to improve performance even after minimal independent behavior training. Chapter 7 describes the next step of experimentation; developing a switch between the mapping strategies learned in the first two phases <ref> (Murray 95a) </ref>. For this, the low level behaviors developed earlier are hard coded into the simbot's systems. <p> The simbot develops hierarchical behavior such that if there is an obstacle blocking its path, it avoids it. Otherwise it heads straight for the nearest food source. In order to facilitate navigation of more complex environments, I develop a third low level behavior, wall following. <ref> (Murray 95a) </ref>. These experiments are described in chapter 8. Specifically, the goal of these simbots is to move parallel to an obstacle and to turn around corners, if possible.
References-found: 8

