URL: http://www.cs.caltech.edu/~ps/papers/gi97/RothWibowoo-noimages.ps.gz
Refering-URL: http://www.cs.caltech.edu/~ps/papers/gi97/
Root-URL: http://www.cs.caltech.edu
Email: E-mail: roth@iit.nrc.ca  
Title: An Efficient Volumetric Method for Building Closed Triangular Meshes from 3-D Image and Point Data  
Author: Gerhard Roth and Eko Wibowoo 
Keyword: Mesh Creation, Triangular Meshes, Model Building, Range Data, Virtual Reality.  
Web: Web: http://www.iitsg.nrc.ca/~roth  
Address: Building M 50, Montreal Road  Canada, Ottawa, Canada K1A 0R6  
Affiliation: Institute for Information Technology,  National Research Council of  
Abstract: We present a volumetric method that can efficiently create triangular meshes from 3-D geometric data. This data can be presented in the form of images, profiles or unordered points. The mesh model can be created at different resolutions and can also be closed to make a true volumetric model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. J. Besl and R. C. Jain, </author> <title> "Three dimensional object recognition," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 17, </volume> <pages> pp. 75-145, </pages> <month> Mar. </month> <year> 1985. </year>
Reference-contexts: 1 Introduction This paper presents an algorithm to build a geometric model from 3D data of the surface of an object obtained by a range sensor <ref> [1] </ref>. Such sensors are also called geometric sensors because they are able to directly capture the geometry of an object. Typically this is done by using an optical source, such as a laser, to obtain the distance to the object's surface [2]. <p> These two neighbours along with the original data point are then used to compute the local normal estimate. When doing this computation it is important not to use neighbouring points that cross a depth discontinuity, or jump edge <ref> [1] </ref>. For image or profile data the orientation of this computed normal is toward the sensor viewpoint. Computing the normal when the input data consists of 3D points in unordered form (cloud data) is more complex.
Reference: [2] <author> M. Rioux, </author> <title> "Laser rangefinders based on synchronized scanning," </title> <journal> Applied Optics, </journal> <volume> vol. 23, </volume> <pages> pp. 3837-3844, </pages> <year> 1985. </year>
Reference-contexts: Such sensors are also called geometric sensors because they are able to directly capture the geometry of an object. Typically this is done by using an optical source, such as a laser, to obtain the distance to the object's surface <ref> [2] </ref>. Another possibility is the use of X-ray tomography [3] to obtain the cross sections of the object cut by the X-rays. There are an ever increasing number of geometric sensors being developed by different companies and research organizations [4].
Reference: [3] <author> J. C. Russ, </author> <title> The image processing handbook. </title> <publisher> CRC Press, </publisher> <year> 1995. </year>
Reference-contexts: Such sensors are also called geometric sensors because they are able to directly capture the geometry of an object. Typically this is done by using an optical source, such as a laser, to obtain the distance to the object's surface [2]. Another possibility is the use of X-ray tomography <ref> [3] </ref> to obtain the cross sections of the object cut by the X-rays. There are an ever increasing number of geometric sensors being developed by different companies and research organizations [4].
Reference: [4] <author> P. Besl, </author> <title> "Active, optical range imaging sensors," </title> <journal> Machine Vision and Applications, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 127-152, </pages> <year> 1988. </year>
Reference-contexts: Another possibility is the use of X-ray tomography [3] to obtain the cross sections of the object cut by the X-rays. There are an ever increasing number of geometric sensors being developed by different companies and research organizations <ref> [4] </ref>. As is shown in images, others can only acquire a single 3D profile or slice of an object, while still others can only acquire a single point at a time. If the 3D data is produced in point form there is no known neighbour relationship between data points. <p> [12], we believe that large holes should be closed by obtaining more 3D data, and do not expect our hole closing algorithm to handle this case. 4.8 Colour and Intensity mapping For each 3D data point there is sometimes an associated intensity or colour value provided by the 3D sensor <ref> [4] </ref>. In this case we assign to each triangle vertex the colour or intensity value of the closest data point.
Reference: [5] <author> R. Fisher, A. Fitzgibbon, A. Gionis, M. Wright, and D. Egger, </author> <title> "A hand-held optical surface scanner for environment modeling and virtual reality," </title> <type> Tech. Rep. </type> <institution> DAI No.778, University of Edinburgh, </institution> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: If the 3D data is produced in point form there is no known neighbour relationship between data points. Such an unordered set of data points is called cloud data, and is common in industrial practice <ref> [5] </ref>. profiles and images. To scan an entire object the sensor must view the object's surface from a sufficient number of different views. This 3D data from each view must then be registered so that it is all in a single co-ordinate frame.
Reference: [6] <author> H. Gagnon, M. Soucy, R. Bergevin, and D. Lauren-deau, </author> <title> "Registration of multiple range views for automatic 3-d model building," </title> <booktitle> in Proceedings of IEEE Computer Vision and Pattern Recognition Conference, </booktitle> <address> (Seattle, Washington), </address> <pages> pp. 581-586, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: This registration process can be done mechanically, by moving the geometric sensor using an accurate positioning device. It can also be done from the data itself, by minimizing the error between overlapping 3D data regions. Both methods are common and have been shown to work successfully <ref> [6, 7] </ref>. In this paper we will assume that all the 3D data has already been properly registered. In order to make practical use of the registered 3D data it is necessary to construct a geometric model from this data.
Reference: [7] <author> Y. Chen and G. Medioni, </author> <title> "Object modelling by reg-istraion of multiple range images," </title> <journal> Image and Vision Computing, </journal> <volume> vol. 10, </volume> <pages> pp. 145-155, </pages> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: This registration process can be done mechanically, by moving the geometric sensor using an accurate positioning device. It can also be done from the data itself, by minimizing the error between overlapping 3D data regions. Both methods are common and have been shown to work successfully <ref> [6, 7] </ref>. In this paper we will assume that all the 3D data has already been properly registered. In order to make practical use of the registered 3D data it is necessary to construct a geometric model from this data.
Reference: [8] <author> G. Roth and E. Wibowo, </author> <title> "A fast algorithm for making mesh models from multi-view range data," </title> <booktitle> in Proceedings of the DND/CSA Robotics and Knowledge Based Systems Workshop, (St. Hubert, Que-bec), </booktitle> <pages> pp. 349-356, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: However, since there is often considerable overlap between the 3D images from different views, a mesh created in this fashion will have many redundant faces. It is desirable to create a non-redundant mesh, in which there are no overlapping faces. This paper, which is a continuation of previous work <ref> [8] </ref>, describes a voxel-based algorithm which has the following characteristics. * It uses a simple voxel data structure which is very efficient in both space and time. * It is able to process 3D data in image, profile and point cloud format. * It has a number of different ways of <p> The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure.
Reference: [9] <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle, </author> <title> "Surface reconstruction from unorganized data points," </title> <booktitle> in Computer Graphics 26: Siggraph'92 Conference Proceedings, </booktitle> <volume> vol. 26, </volume> <pages> pp. 71-78, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. <p> Surface approaches are limited to processing 3D data in image format. They do not handle cloud data, and it is not clear how any surface approach could ever achieve this goal. In fact, many voxel approaches also do not handle cloud data (the only exception is <ref> [9] </ref>), but the underlying volumetric data structure clearly makes this possible. Another serious problem with the surface approaches is the requirement that all the original data points be in memory while the algorithm is in operation. <p> Wash. <ref> [9] </ref> Point 17K 45, 68, 11 2, 1 6K Star Daimler Point 106K 108, 75, 127 13, 2 36K IMS Part Daimler [26] Point 1.0M 173, 257, 125 137, 21 354K Table 2: The results of running the algorithm on various 3D data sets. the number of voxels.
Reference: [10] <author> C. Bajaj, F. Bernardini, and G. Xu, </author> <title> "Automatic reconstruction of surfaces and scalar fields from 3d scans," </title> <booktitle> in Computer Graphics: Siggraph '95 Proceedings, </booktitle> <pages> pp. 109-118, </pages> <year> 1995. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure.
Reference: [11] <author> A. Hilton, A. Toddart, J. Illingworth, and T. Windeatt, </author> <title> "Reliable surface reconstruction from multiple range images," </title> <booktitle> in Fourth International European Conference on Computer Vision, </booktitle> <volume> vol. 1, </volume> <pages> pp. 117-126, </pages> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. <p> This is because surface methods triangulate the data at the original resolution. By contrast the volumetric methods can not set the size of their volumetric data structure to the same resolution as the 3D data because then each volumetric element would contain too few data points <ref> [11] </ref>. However, in practice we find that more 3D data is collected than is necessary. Therefore the number of data points is typically at least two or three times greater than the number of triangles that we want to have in the final mesh. <p> Then set the voxel size to three times the average of these one hundred minimum inter-point distances. This assures us that the each voxel grid element is likely to contain at least one data point <ref> [11] </ref>. 4.2 Add Each Data Point to the Appro priate Voxel Once the size of the voxel grid has been set it is necessary to add each 3D data point to the appropriate voxel. <p> The triangles that approximate this surface in the voxel are found using a lookup table. One advantage of the marching cubes algorithm is the ability to weight each of these signed distances. In our application it is sensible to weight the individual points according to their estimated accuracy <ref> [25, 12, 11] </ref>. The most significant source of inaccuracy occurs when the surface normal is close to being orthogonal to the line of sight of the sensor. When this happens, the reflected laser spot tends to spread and distort which causes significant errors in the computed depth. <p> It is possible to increase the mesh accuracy by simply reducing the voxel size. As we have noted previously, the voxel grid size must be at two to three times greater than the sampling density of the 3D data <ref> [11] </ref>. This is a limitation of all voxel approaches to mesh creation.
Reference: [12] <author> B. Curless and M. Levoy, </author> <title> "A volumetric method for building complex models from range images," </title> <booktitle> in Computer Graphics: Siggraph '96 Proceedings, </booktitle> <pages> pp. 221-227, </pages> <year> 1996. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. <p> Both types of processing require that the input mesh be closed and topologically correct. Therefore it is essential to be able to produce a mesh which has these characteristics. Achieving this goal is equally difficult for both the volumetric and surface approaches. A recent volumetric method <ref> [12] </ref> is similar to our proposed algorithm. However, there are significant differences. We can handle both cloud and image data, while this method handles only image data. Our way of closing the triangular mesh is less general, but is simpler and more efficient. <p> Therefore these spurious points are often pierced by rays joining valid surface points to the sensor viewpoint, as is shown in Figure 2. This fact has been noted previously and used to deal with the problem of hole closing <ref> [12] </ref> and to increase the measurement confidence of 3D data [20]. We use this principle to remove spurious data points. likely to be spurious. For each data point we walk along the voxel grid from this point towards the the sensor viewpoint. <p> The triangles that approximate this surface in the voxel are found using a lookup table. One advantage of the marching cubes algorithm is the ability to weight each of these signed distances. In our application it is sensible to weight the individual points according to their estimated accuracy <ref> [25, 12, 11] </ref>. The most significant source of inaccuracy occurs when the surface normal is close to being orthogonal to the line of sight of the sensor. When this happens, the reflected laser spot tends to spread and distort which causes significant errors in the computed depth. <p> When this happens, the reflected laser spot tends to spread and distort which causes significant errors in the computed depth. For this reason the Cosine of the angle between the local surface normal and the viewing direction is used as a weighting value <ref> [12] </ref>. 4.7 Closing holes There are often small gaps or holes between the triangles in each voxel. If the data is unevenly sampled, or the size of the voxel grid is too high, then there will be some voxels that do not have any data points. <p> It will also not work if the 3D hole loop is not coplanar. This is rarely the case for small holes, but is sometimes true for large holes. As opposed to some authors <ref> [12] </ref>, we believe that large holes should be closed by obtaining more 3D data, and do not expect our hole closing algorithm to handle this case. 4.8 Colour and Intensity mapping For each 3D data point there is sometimes an associated intensity or colour value provided by the 3D sensor [4]. <p> 177, 99 43, 10 150K Elephant NRCC Image 312K 149, 65, 125 24, 5 98K Teapot NRCC [18] Image 67K 79, 131, 80 8, 5 56K Soldier NRCC [18] Image 91K 116, 60, 49 8, 3 47K Bunny Cyber. [16] Image 354K 169, 167, 131 43, 10 195K Dragon Cyber. <ref> [12] </ref> Image 1.7M 347,420,393 235, 37 642K Club U.
Reference: [13] <author> M.-E. Algorri and F. Scnmitt, </author> <title> "Surface reconstruction from unstructured data," </title> <journal> Computer graphics forum, </journal> <volume> vol. 15, no. 1, </volume> <pages> pp. 47-60, </pages> <year> 1996. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure.
Reference: [14] <author> M. Wheeler, Y. Sato, and K. </author> <title> Ikeuchi, "Consensus surfaces for modelling 3-d objects from multiple range images," </title> <type> Tech. Rep. </type> <institution> CMU-CS-TR-96-168, Carnigie Mellon Univ., School of Computer Science, Pittsburg, </institution> <address> PA, </address> <year> 1996. </year>
Reference-contexts: The volumetric approaches <ref> [9, 10, 8, 11, 12, 13, 14] </ref> store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure.
Reference: [15] <author> W. E. Lorenen and H. E. Cline, </author> <title> "Marching cubes: a high resolution 3d surface reconstruction algorithm," </title> <booktitle> in Computer Graphics: Siggraph'87 Conference Proceedings, </booktitle> <volume> vol. 21, </volume> <pages> pp. 163-169, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The volumetric approaches [9, 10, 8, 11, 12, 13, 14] store the 3D data points into a volumetric data structure, typically a voxel grid or an octree. The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes <ref> [15] </ref>, which operates on this volumetric data structure. The surface approaches [16, 17, 18, 19, 20] create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format. <p> When noise in the original 3D data produces inaccurate normal estimates then this method tends to produce a smoother triangulation. 4.6 Run the Marching Cubes Algorithm Marching cubes is an Iso-Surface algorithm which extracts the zero set of a signed distance function <ref> [15] </ref>. In this application the signed distance function must be created from the 3D data points and their normals.
Reference: [16] <author> G. Turk and M. Levoy, </author> <title> "Zippered polygon meshes from range images," </title> <booktitle> in Computer Graphics (Sig-graph '94), </booktitle> <volume> vol. 26, </volume> <pages> pp. 311-318, </pages> <year> 1994. </year>
Reference-contexts: The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. The surface approaches <ref> [16, 17, 18, 19, 20] </ref> create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format. <p> 96, 73, 51 11, 2 35K Boat NRCC Image 314K 99, 177, 99 43, 10 150K Elephant NRCC Image 312K 149, 65, 125 24, 5 98K Teapot NRCC [18] Image 67K 79, 131, 80 8, 5 56K Soldier NRCC [18] Image 91K 116, 60, 49 8, 3 47K Bunny Cyber. <ref> [16] </ref> Image 354K 169, 167, 131 43, 10 195K Dragon Cyber. [12] Image 1.7M 347,420,393 235, 37 642K Club U.
Reference: [17] <author> M. Rutishauser, M. Stricker, and M. Trobina, </author> <title> "Merging range images of arbitrarily shaped objects," </title> <booktitle> in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 573-580, </pages> <year> 1994. </year>
Reference-contexts: The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. The surface approaches <ref> [16, 17, 18, 19, 20] </ref> create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format.
Reference: [18] <author> M. Soucy and D. Laurendeau, </author> <title> "A general approach to the integration of a set of range views," </title> <journal> IEEE Transactions On Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 17, </volume> <pages> pp. 344-358, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. The surface approaches <ref> [16, 17, 18, 19, 20] </ref> create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format. <p> In general the results validate our claim that our method is an order of magnitude faster than others in the literature. However, not all of these models were closed properly. The soldier and teapot have large regions of the objects surface where there is no 3D data <ref> [18] </ref>. As we have stated previously, our closing algorithm can not handle such large holes. We believe that in such cases more 3D data should be obtained. <p> Name Source Type Points Dimensions Times (secs.) Triangles Duck NRCC Image 68K 96, 73, 51 8, 2 35K Duck NRCC Point 68K 96, 73, 51 11, 2 35K Boat NRCC Image 314K 99, 177, 99 43, 10 150K Elephant NRCC Image 312K 149, 65, 125 24, 5 98K Teapot NRCC <ref> [18] </ref> Image 67K 79, 131, 80 8, 5 56K Soldier NRCC [18] Image 91K 116, 60, 49 8, 3 47K Bunny Cyber. [16] Image 354K 169, 167, 131 43, 10 195K Dragon Cyber. [12] Image 1.7M 347,420,393 235, 37 642K Club U. <p> 68K 96, 73, 51 8, 2 35K Duck NRCC Point 68K 96, 73, 51 11, 2 35K Boat NRCC Image 314K 99, 177, 99 43, 10 150K Elephant NRCC Image 312K 149, 65, 125 24, 5 98K Teapot NRCC <ref> [18] </ref> Image 67K 79, 131, 80 8, 5 56K Soldier NRCC [18] Image 91K 116, 60, 49 8, 3 47K Bunny Cyber. [16] Image 354K 169, 167, 131 43, 10 195K Dragon Cyber. [12] Image 1.7M 347,420,393 235, 37 642K Club U.
Reference: [19] <author> M. Soucy and D. Laurendeau, </author> <title> "A dynamic integration algorithm to model surfaces from multiple range views," </title> <journal> Machine Vision and Applications, </journal> <volume> vol. 8, no. 1, </volume> <pages> pp. 53-62, </pages> <year> 1995. </year>
Reference-contexts: The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. The surface approaches <ref> [16, 17, 18, 19, 20] </ref> create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format.
Reference: [20] <author> R. Pito, </author> <title> "Mesh integration based on co-measurements," </title> <booktitle> in International Conference on Image Processing, </booktitle> <pages> pp. 397-400, </pages> <year> 1996. </year>
Reference-contexts: The triangular mesh is then created using an Iso-Surface extraction algorithm, usually marching cubes [15], which operates on this volumetric data structure. The surface approaches <ref> [16, 17, 18, 19, 20] </ref> create an initial set of triangular regions from the original 3D images. These regions are then stitched together to make the final mesh. Surface approaches are limited to processing 3D data in image format. <p> Therefore these spurious points are often pierced by rays joining valid surface points to the sensor viewpoint, as is shown in Figure 2. This fact has been noted previously and used to deal with the problem of hole closing [12] and to increase the measurement confidence of 3D data <ref> [20] </ref>. We use this principle to remove spurious data points. likely to be spurious. For each data point we walk along the voxel grid from this point towards the the sensor viewpoint. All the occupied voxels along this traversal are voted against.
Reference: [21] <author> R. Aubin, </author> <title> "A world wide assessment of rapid pro-toyping technologies," </title> <booktitle> in Proceedings of the Intelligent Manufacturing Systems International Conference on Rapid Prototyping, </booktitle> <address> (Stuttgart, Germany), </address> <pages> pp. 45-48, </pages> <year> 1994. </year>
Reference-contexts: For both the volumetric and surface methods an issue that has rarely been dealt with in the past is how to close the final mesh. The mesh is often passed to a rapid prototyping system to create a physical duplicate <ref> [21] </ref>, or is decimated further by a compression algorithm [22] for faster display. Both types of processing require that the input mesh be closed and topologically correct. Therefore it is essential to be able to produce a mesh which has these characteristics. <p> These gaps need to be closed in order to create a model which has no holes. Producing a closed model is important for two reasons. The first is that only such a model can be sent to a rapid prototyping machine to make a physical duplicate <ref> [21] </ref>. The second is that a model that has even a small number of holes is difficult to process further by such operations as mesh compression [22]. In the first step of the closing algorithm we find all triangle edges that are not connected to other triangles.
Reference: [22] <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle, </author> <title> "Mesh optimization," </title> <booktitle> in Computer Graphics: Siggraph '93 Proceedings, </booktitle> <pages> pp. 19-25, </pages> <year> 1993. </year>
Reference-contexts: For both the volumetric and surface methods an issue that has rarely been dealt with in the past is how to close the final mesh. The mesh is often passed to a rapid prototyping system to create a physical duplicate [21], or is decimated further by a compression algorithm <ref> [22] </ref> for faster display. Both types of processing require that the input mesh be closed and topologically correct. Therefore it is essential to be able to produce a mesh which has these characteristics. Achieving this goal is equally difficult for both the volumetric and surface approaches. <p> The first is that only such a model can be sent to a rapid prototyping machine to make a physical duplicate [21]. The second is that a model that has even a small number of holes is difficult to process further by such operations as mesh compression <ref> [22] </ref>. In the first step of the closing algorithm we find all triangle edges that are not connected to other triangles. Such edges are called free edges and indicate a hole in the triangulation. A hole loop is a closed sequence of free edges which run in the proper direction.
Reference: [23] <author> G. Wyvill, C. McPheeters, and B. Wyvill, </author> <title> "Data structure for soft objects," </title> <journal> Visual Computer, </journal> <volume> no. 2, </volume> <pages> pp. 227-234, </pages> <year> 1986. </year>
Reference-contexts: This is accomplished by using a lookup table which maps the voxel indices to a voxel pointer <ref> [23] </ref>. If there is a pointer for each possible voxel, then this table would be very large. However, since geometric sensors scan only the surface of an object, only the pointers to the occupied surface voxels need to be stored.
Reference: [24] <author> B. Curless and M. Levoy, </author> <title> "Better optical triangulation through spacetime analysis," </title> <booktitle> in Fifth International Conference on Computer Vision, </booktitle> <address> (Cambridge, Massachusetts), </address> <pages> pp. 987-994, </pages> <year> 1995. </year>
Reference-contexts: Besides the actual 3D data any other relevant information, such as the local surface normal or the colour also must be saved. 4.3 Eliminate Spurious Points There are often spurious points in 3D data due mostly to the problem of edge curl <ref> [24] </ref>. This occurs with optical sensors when the optical source (usually a laser beam) is half on and half off the edge of an object. In this case an invalid 3D point is often the result.
Reference: [25] <author> P. Hebert, D. Laurendeau, and D. Poussart, </author> <title> "Scene reconstruction and description: geometric primitive extraction from multiple view scattered data," </title> <booktitle> in Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> (New York), </address> <pages> pp. 286-293, </pages> <year> 1993. </year>
Reference-contexts: The triangles that approximate this surface in the voxel are found using a lookup table. One advantage of the marching cubes algorithm is the ability to weight each of these signed distances. In our application it is sensible to weight the individual points according to their estimated accuracy <ref> [25, 12, 11] </ref>. The most significant source of inaccuracy occurs when the surface normal is close to being orthogonal to the line of sight of the sensor. When this happens, the reflected laser spot tends to spread and distort which causes significant errors in the computed depth.
Reference: [26] <author> P. Boulanger, G. Roth, and G. Godin, </author> <title> "Applications of 3-d active vision to rapid product development," </title> <booktitle> in Proceedings of the Intelligent Manufacturing Systems International Conference on Rapid Prototyp-ing, </booktitle> <address> (Stuttgart, Germany), </address> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Wash. [9] Point 17K 45, 68, 11 2, 1 6K Star Daimler Point 106K 108, 75, 127 13, 2 36K IMS Part Daimler <ref> [26] </ref> Point 1.0M 173, 257, 125 137, 21 354K Table 2: The results of running the algorithm on various 3D data sets. the number of voxels. Therefore storing only the occupied voxels enables our approach to handle very large 3D data sets.
Reference: [27] <author> R. Seidel, </author> <title> "A simple and fast incrmental randomized algorithm for triangulating polygons," Computational geometry: </title> <journal> theory and applications, </journal> <volume> vol. 1, </volume> <pages> pp. 51-64, </pages> <year> 1991. </year> <title> data (the elephant and dragon), the other (Mercedes-Benz star) created from cloud data. </title>
Reference-contexts: We fit a plane through the 3D vertices of the hole loop edges. Then we project these vertices onto this plane, and check for self intersections in the hole loop. If there are none, then we triangulate the projected hole loop in this plane <ref> [27] </ref>. This same sequence of triangle vertices is then used to triangulate the 3D hole loop. This approach will not work when a hole loop contains a triangle island; that is a number of valid triangles that are inside this loop.
References-found: 27

