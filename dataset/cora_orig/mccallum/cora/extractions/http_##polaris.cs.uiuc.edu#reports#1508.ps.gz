URL: http://polaris.cs.uiuc.edu/reports/1508.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Email: fpaek,hoefling,paduag@csrd.uiuc.edu  
Title: Access Regions: Toward a Powerful Parallelizing Compiler  
Author: Yunheung Paek, Jay Hoeflinger, David Padua 
Keyword: Compilers, Aggregation, Parallelization, Privatization, Run-time test, Region Analysis.  
Address: 1304 West Springfield Avenue, Urbana, IL 61801, USA  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign,  
Abstract: The bulk of the work within a scientific program involves processing data stored in arrays. We present a general and efficient means of representing the region of an array accessed by a section of a program. We introduce a notation for access regions, and a set of region operations for manipulating them. We show how a region processor which implements our region operations can form the basis for a parallelizer which handles array privatization, run-time parallelization, communication generation, and interprocedural analysis.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoeflinger, T. Lawrence, J. Lee, D. Padua, Y. Paek, W. Pottenger, L. Rauchwerger, P. Tu, </author> <title> Advanced Program Restructuring for High-Performance Computers with Polaris, </title> <note> To appear in IEEE Computer, </note> <month> Dec. </month> <year> 1996, </year> <title> OR. </title> <type> Technical Report 1473, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> Jan. </month> <year> 1996 </year>
Reference-contexts: Based on our experience with the Perfect [28] and SPEC benchmarks, and several full scientific codes <ref> [1] </ref>, we have developed a region access representation which takes advantage of the clear structure inherent in the array accesses of most scientific programs. Our design attempts to allow maximum expressiveness without sacrificing efficiency. We are implementing this representation in Polaris [1], which is the parallelizing compiler being developed by the <p> [28] and SPEC benchmarks, and several full scientific codes <ref> [1] </ref>, we have developed a region access representation which takes advantage of the clear structure inherent in the array accesses of most scientific programs. Our design attempts to allow maximum expressiveness without sacrificing efficiency. We are implementing this representation in Polaris [1], which is the parallelizing compiler being developed by the authors and others at Illinois. 2 Motivation The Polaris parallelizer uses a triplet notation for array access patterns in modules such as the priva-tizer [4] and the dependence analyzer [6]. <p> In order to avoid that, we can extract predicates from the array dimension information to produce the region ((2J+(I-1)M)[J=1:N:1][I=1:J:1],MUST,WRITE,1 2J M ): In the operations in Section 3.5, this extra predicate will be used through the range dictionary <ref> [1, 6] </ref> combined with various symbolic manipulation modules to supply accurate symbolic range information. 3.2 Abstract Access Form We have seen that, for the most part, within limited sections of a program, the access regions of interest have a regularity of structure. <p> Similar access patterns also can be commonly found in full scientific programs <ref> [1] </ref>. In these cases of contiguous access, we found that the access pattern made by several indices with various strides can be represented by an access pattern with a single index. For instance, the access region representation ((I+J)[I=1:N:4][J=0:2:2], ) has two indices with strides 2 and 4. <p> The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions 8 under which a certain definition is used. Second, the symbolic manipulation modules in Polaris, such as range propagation and the range dictionary <ref> [1, 6] </ref>, make the value ranges for variables available at any point in the program. These features provide a mechanism which can determine relationships between variables even when their exact values are unknown.
Reference: [2] <author> Y. Paek, D. Padua, </author> <title> Automatic Parallelization for Non-cache Coherent Multiprocessors, </title> <booktitle> Proceedings of 9th Workshop on Language and Compilers for Parallel Computing, </booktitle> <address> OR. </address> <note> To appear in Lecture Notes in Computer Science, </note> <institution> Spring-Verlag, </institution> <address> NY, </address> <month> Aug. </month> <year> 1996 </year>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis [5] is one example for parallelizing compilers, but access region analysis is also crucial for array privatization [4], communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors <ref> [2, 3] </ref>, locality enhancement [8], and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. <p> Although the Polaris dependence analyzer [4, 5] can handle non-affine expressions, it still fails to privatize X and parallelize this loop because of the other complexities involved in these access patterns. In addition, our work on developing compilation techniques <ref> [2, 3] </ref> for NUMA multiprocessor systems such as the Cray T3D and the Convex Exemplar showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories. <p> To make the loop nest parallel, we can eliminate the dependence by privatizing the array V and generating a GET for the upwards exposed use region. do I=1,M do L=I,1+M-I enddo V (K+(I-1)*N) = V (K+(I-1)*N) enddo enddo We also use PUT/GETs to implement the data copying scheme <ref> [2, 3] </ref> in SPMD parallel codes for NUMA multiprocessors. In the scheme, we use shared memory as a repository of values for use in private memory. Before a parallel loop starts, the processors copy all data that is used in the loop from shared memory into private memory.
Reference: [3] <author> Y. Paek, D. Padua, </author> <title> Compiling for Scalable Multiprocessors with Polaris, To appear in Parallel Processing Letters, </title> <publisher> World Scientific Publishing, </publisher> <address> UK, </address> <year> 1997 </year>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis [5] is one example for parallelizing compilers, but access region analysis is also crucial for array privatization [4], communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors <ref> [2, 3] </ref>, locality enhancement [8], and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. <p> Although the Polaris dependence analyzer [4, 5] can handle non-affine expressions, it still fails to privatize X and parallelize this loop because of the other complexities involved in these access patterns. In addition, our work on developing compilation techniques <ref> [2, 3] </ref> for NUMA multiprocessor systems such as the Cray T3D and the Convex Exemplar showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories. <p> In this case, we may convert the access region for V to ((J)[J=VLOW:VHIGH:1],MAY, ) with monotonic function J, if the accuracy loss is tolerable <ref> [3] </ref>. Predicates add precision to R. In Figure 3, even when the compiler cannot determine the value of P, the access region for Q can be represented by ((3I)[I=1:N:1],MUST,WRITE,P). Alternatively, for flow-insensitive analysis, we may represent this as ((3I)[I=1:N:1],MAY,WRITE,T). <p> To make the loop nest parallel, we can eliminate the dependence by privatizing the array V and generating a GET for the upwards exposed use region. do I=1,M do L=I,1+M-I enddo V (K+(I-1)*N) = V (K+(I-1)*N) enddo enddo We also use PUT/GETs to implement the data copying scheme <ref> [2, 3] </ref> in SPMD parallel codes for NUMA multiprocessors. In the scheme, we use shared memory as a repository of values for use in private memory. Before a parallel loop starts, the processors copy all data that is used in the loop from shared memory into private memory.
Reference: [4] <author> P. Tu, D. Padua. </author> <title> Gated SSA-Based Demand-Driven Symbolic Analysis for Parallelizing Compilers. </title> <booktitle> Proceedings of the 9th ACM International Conference on Supercomputing, </booktitle> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995 </year>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis [5] is one example for parallelizing compilers, but access region analysis is also crucial for array privatization <ref> [4] </ref>, communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors [2, 3], locality enhancement [8], and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. <p> for parallelizing compilers, but access region analysis is also crucial for array privatization <ref> [4] </ref>, communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors [2, 3], locality enhancement [8], and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long [11] for message generation. <p> We are implementing this representation in Polaris [1], which is the parallelizing compiler being developed by the authors and others at Illinois. 2 Motivation The Polaris parallelizer uses a triplet notation for array access patterns in modules such as the priva-tizer <ref> [4] </ref> and the dependence analyzer [6]. Polaris has been successfully obtaining speedups for many scientific applications on a variety of shared-memory multiprocessors, but we have seen that Polaris still fails to obtain good speedups for some applications. <p> However, any representation which cannot handle non-affine expressions cannot represent this access region. Although the Polaris dependence analyzer <ref> [4, 5] </ref> can handle non-affine expressions, it still fails to privatize X and parallelize this loop because of the other complexities involved in these access patterns. <p> The condition expressions could be evaluated at runtime, when perfect information is available, to choose between alternative transformations. The work of the Region Processor is supported by two important features of the Polaris compiler. First, the program is represented in Gated Single Assignment (GSA) form <ref> [4] </ref>. The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions 8 under which a certain definition is used.
Reference: [5] <author> W. Blume, R. Eigenmann, </author> <title> The Range Test: A Dependence Test for Symbolic Non-linear Expression, </title> <booktitle> SuperComputing '94 Proceedings, </booktitle> <month> Nov. </month> <year> 1994, </year> <pages> pp. 643-656 </pages>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis <ref> [5] </ref> is one example for parallelizing compilers, but access region analysis is also crucial for array privatization [4], communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors [2, 3], locality enhancement [8], and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. <p> For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long [11] for message generation. Blume and Eigenmann <ref> [5] </ref> excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [21, 22]. <p> However, any representation which cannot handle non-affine expressions cannot represent this access region. Although the Polaris dependence analyzer <ref> [4, 5] </ref> can handle non-affine expressions, it still fails to privatize X and parallelize this loop because of the other complexities involved in these access patterns. <p> In our quest for a better access pattern representation, we considered the convex regions, but forms which represent access patterns by sets of constraints typically must use a more general dependence test [22], which cannot handle non-affine expressions <ref> [5, 6] </ref>. Forms which use the triplet notation cannot handle such complicated access patterns as discussed earlier, but lend themselves to more efficient manipulation in many parts of a compiler. <p> The access function f (I) is the same as s (I), as long as s (I) is a monotonic function [6, 25] within the index ranges. Although many subscript functions encountered in scientific programs may not be affine, most are monotonic <ref> [5] </ref>, and those few which are not monotonic may be converted to a monotonic function with a possible accuracy loss. For instance, in Figure 3, the access region for IV is ((J-2)[J=1:N:1],MUST,READ,T y ), since J-2 is clearly monotonic. <p> This is true because several references to a single array within a loop nest are generally accessed using the same loop indices and with similar subscript expressions. Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of Blume and Eigenmann <ref> [5, 6] </ref>, who note that their dependence test, built to analyze regular access patterns, is essentially as successful as the Omega Test [22], which was built to handle more general patterns. <p> These features provide a mechanism which can determine relationships between variables even when their exact values are unknown. This rich environment was crucial to the success of the Range Test <ref> [5] </ref>, and can enable many of the symbolic operations of the Region Processor. The predicate for an access region R may be thought of as the pertinent information found in the gating information from the GSA and in the value range constraints.
Reference: [6] <author> W. Blume, </author> <title> Symbolic Analysis techniques for Effective Automatic Parallelization, </title> <type> PhD Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> June </month> <year> 1995 </year>
Reference-contexts: We are implementing this representation in Polaris [1], which is the parallelizing compiler being developed by the authors and others at Illinois. 2 Motivation The Polaris parallelizer uses a triplet notation for array access patterns in modules such as the priva-tizer [4] and the dependence analyzer <ref> [6] </ref>. Polaris has been successfully obtaining speedups for many scientific applications on a variety of shared-memory multiprocessors, but we have seen that Polaris still fails to obtain good speedups for some applications. <p> In our quest for a better access pattern representation, we considered the convex regions, but forms which represent access patterns by sets of constraints typically must use a more general dependence test [22], which cannot handle non-affine expressions <ref> [5, 6] </ref>. Forms which use the triplet notation cannot handle such complicated access patterns as discussed earlier, but lend themselves to more efficient manipulation in many parts of a compiler. <p> The predicate is a condition under which R is valid. The access function f (I) is the same as s (I), as long as s (I) is a monotonic function <ref> [6, 25] </ref> within the index ranges. Although many subscript functions encountered in scientific programs may not be affine, most are monotonic [5], and those few which are not monotonic may be converted to a monotonic function with a possible accuracy loss. <p> In order to avoid that, we can extract predicates from the array dimension information to produce the region ((2J+(I-1)M)[J=1:N:1][I=1:J:1],MUST,WRITE,1 2J M ): In the operations in Section 3.5, this extra predicate will be used through the range dictionary <ref> [1, 6] </ref> combined with various symbolic manipulation modules to supply accurate symbolic range information. 3.2 Abstract Access Form We have seen that, for the most part, within limited sections of a program, the access regions of interest have a regularity of structure. <p> This is true because several references to a single array within a loop nest are generally accessed using the same loop indices and with similar subscript expressions. Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of Blume and Eigenmann <ref> [5, 6] </ref>, who note that their dependence test, built to analyze regular access patterns, is essentially as successful as the Omega Test [22], which was built to handle more general patterns. <p> To completely remove all unnecessary indices, we need at most O (m 2 ) coalescings for a region with m stride/span pairs. According to our study, coalescing in many cases <ref> [6] </ref> helps us to remove non-constant strides or spans from the access descriptor in the abstract form. <p> The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions 8 under which a certain definition is used. Second, the symbolic manipulation modules in Polaris, such as range propagation and the range dictionary <ref> [1, 6] </ref>, make the value ranges for variables available at any point in the program. These features provide a mechanism which can determine relationships between variables even when their exact values are unknown.
Reference: [7] <author> L. Rauchwerger, D. Padua, </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Pri-vatization and Reduction Parallelization, </title> <booktitle> Proceedings of ACM SIGPLAN'95 Conference on Programming Language Design and Implementation, </booktitle> <month> Jun. </month> <year> 1995 </year>
Reference-contexts: The triplet notation used by Polaris cannot support this manipulation, and so Polaris simply serializes the loop. Without this mechanism, we might have to employ expensive run-time techniques <ref> [7, 13] </ref>, in order to parallelize this loop. As another example, consider the loop in Figure 2, which can be found in FFT programs such as the TFFT2 benchmark.
Reference: [8] <author> F. Bodin, E. Granston, T. Montaut, </author> <title> Loop Transformations to Prevent False Sharing, </title> <journal> International Journal of Parallel Programming. </journal>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis [5] is one example for parallelizing compilers, but access region analysis is also crucial for array privatization [4], communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors [2, 3], locality enhancement <ref> [8] </ref>, and interprocedural summarization [9]. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation.
Reference: [9] <author> D. Callahan, K. Kennedy, </author> <title> Analysis of Interprocedural Side Effects in a Parallel Programming Environment </title>
Reference-contexts: 1 Introduction Existing compiler techniques depend heavily on the analysis of array subscripting patterns. Dependence analysis [5] is one example for parallelizing compilers, but access region analysis is also crucial for array privatization [4], communication optimization for Non-Uniform Memory Access (NUMA) multiprocessors [2, 3], locality enhancement [8], and interprocedural summarization <ref> [9] </ref>. Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long [11] for message generation.
Reference: [10] <author> C. Tseng, </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines, </title> <type> PhD Thesis, </type> <institution> Rice University, </institution> <month> Jan. </month> <year> 1993 </year>
Reference-contexts: Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. The same notation was used in papers by Tseng <ref> [10] </ref> and Chatterjee, Gilbert and Long [11] for message generation. Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses.
Reference: [11] <author> S. Chatterjee, J. Gilbert, F. </author> <title> Long, Generating Local Address and Communication Sets for Data-Parallel Programs, </title> <booktitle> Proceedings of ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993, </year> <pages> pp. 149-158 </pages>
Reference-contexts: Compiler modules implementing such techniques must represent the array accesses in some standard fashion. For instance, Tu and Padua [4] approximated access regions for array privatization with the triplet notation. The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long <ref> [11] </ref> for message generation. Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [21, 22].
Reference: [12] <author> V. Balasundaram, K. Kennedy, </author> <title> A Techniques for Summarizing Data Access and its Use in Parallelism Enhancing Transformations, </title> <booktitle> Proceedings of ACM SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <month> Jun. </month> <year> 1989 </year>
Reference: [13] <author> J. Saitz, R. Mirchandaney, K Crowley, </author> <title> Run-time Parallelization and Scheduling of Loops, </title> <journal> IEEE Trans. Computers, </journal> <volume> Vol 40, </volume> <month> May </month> <year> 1991 </year> <month> 16 </month>
Reference-contexts: The triplet notation used by Polaris cannot support this manipulation, and so Polaris simply serializes the loop. Without this mechanism, we might have to employ expensive run-time techniques <ref> [7, 13] </ref>, in order to parallelize this loop. As another example, consider the loop in Figure 2, which can be found in FFT programs such as the TFFT2 benchmark.
Reference: [14] <author> R. Triolet, F. Irigoin, P. Feautrier, </author> <title> Direct Parallelization of CALL Statements, </title> <booktitle> Proceedings of ACM SIG--PLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> July </month> <year> 1986, </year> <pages> pp. 176-185 </pages>
Reference-contexts: The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long [11] for message generation. Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions <ref> [14, 17] </ref> express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [21, 22]. Balasundaram and Kennedy [15] simplified the convex region to detect task parallelism. Such representations are designed to strike a balance between the efficiency of using the representation and its expressiveness.
Reference: [15] <author> V. Balasundaram, K. Kennedy, </author> <title> A Technique for Summerizing Data Access and its Use in Parallelism-Enhancing Transformation, </title> <booktitle> Proceedings of ACM SIGPLAN '89 Conf. on Programming Language and Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989 </year>
Reference-contexts: Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [21, 22]. Balasundaram and Kennedy <ref> [15] </ref> simplified the convex region to detect task parallelism. Such representations are designed to strike a balance between the efficiency of using the representation and its expressiveness.
Reference: [16] <author> R. Cytron, J. Ferrante, </author> <title> What's in a Name?, </title> <booktitle> Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <month> Aug. </month> <year> 1987, </year> <pages> pp. 19-27 </pages>
Reference-contexts: A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. PUT/GETs are useful for removing anti and output dependences as illustrated in <ref> [16] </ref>. By using coalesce region and aggregate regions, in the loop shown in Figure 12, the Region Processor calcu lates the region of upwards exposed uses [20] of array V as A 1 for each iteration I = t.
Reference: [17] <author> B. Creusillet, F. Irigoin, </author> <title> Exact vs. Approximate Array Region Analyses, </title> <booktitle> Proceedings of 9th Workshop on Language and Compilers for Parallel Computing, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: The same notation was used in papers by Tseng [10] and Chatterjee, Gilbert and Long [11] for message generation. Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions <ref> [14, 17] </ref> express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [21, 22]. Balasundaram and Kennedy [15] simplified the convex region to detect task parallelism. Such representations are designed to strike a balance between the efficiency of using the representation and its expressiveness.
Reference: [18] <author> MPI-2: </author> <title> Extensions to the Message-Passing Interface, Message Passing Interface Forum, </title> <journal> Jan. </journal> <volume> 12, </volume> <year> 1996 </year>
Reference-contexts: The region test can then produce code which will check the predicate at run time, choosing between a parallel version of the loop and a serial version. 4.2 Communication Analysis Single-sided communication protocols <ref> [18, 19, 23, 27] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris.
Reference: [19] <author> J. Nielocha, R. Harrison, R. Littlefield, </author> <title> Global Arrays: A Portable Shared-Memory Programming Model for Distributed Memory Computers, </title> <booktitle> Supercomputing '94 Proceedings, </booktitle> <year> 1994, </year> <month> pp.340-349 </month>
Reference-contexts: The region test can then produce code which will check the predicate at run time, choosing between a parallel version of the loop and a serial version. 4.2 Communication Analysis Single-sided communication protocols <ref> [18, 19, 23, 27] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris.
Reference: [20] <author> A. Aho, R. Sethi, J. Ullman, </author> <booktitle> Compilers Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> CA, </address> <year> 1986 </year>
Reference-contexts: PUT/GETs are useful for removing anti and output dependences as illustrated in [16]. By using coalesce region and aggregate regions, in the loop shown in Figure 12, the Region Processor calcu lates the region of upwards exposed uses <ref> [20] </ref> of array V as A 1 for each iteration I = t.
Reference: [21] <author> P. Tang, </author> <title> Exact Side Effects for Interprocedural Dependence Analysis, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35, No. 8, </volume> <month> Aug. </month> <year> 1992, </year> <pages> pp. 102-114. </pages>
Reference-contexts: Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests <ref> [21, 22] </ref>. Balasundaram and Kennedy [15] simplified the convex region to detect task parallelism. Such representations are designed to strike a balance between the efficiency of using the representation and its expressiveness. <p> We decided to design the region operations for regions with similar structures. However, if the regions do not meet the similarity constraints, our representation allows us to simplify the regions and still use our operations, or else choose different techniques which might be a better fit <ref> [21, 22] </ref>. Due to the strict word limit and the intrinsic complexity of the operations, we cannot discuss all the algorithms in this abstract, even though we will include them in the full paper.
Reference: [22] <author> W. Pugh, </author> <title> A Practical Algorithm for Exact Array Dependence Analysis, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35, No. 8, </volume> <month> Aug. </month> <year> 1992 </year>
Reference-contexts: Blume and Eigenmann [5] excluded the stride from the triplet notation in their dependence test for simplicity, but at the expense of accuracy. Convex regions [14, 17] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests <ref> [21, 22] </ref>. Balasundaram and Kennedy [15] simplified the convex region to detect task parallelism. Such representations are designed to strike a balance between the efficiency of using the representation and its expressiveness. <p> To meet this requirement, an access region representation must support the notion of accuracy. In our quest for a better access pattern representation, we considered the convex regions, but forms which represent access patterns by sets of constraints typically must use a more general dependence test <ref> [22] </ref>, which cannot handle non-affine expressions [5, 6]. Forms which use the triplet notation cannot handle such complicated access patterns as discussed earlier, but lend themselves to more efficient manipulation in many parts of a compiler. <p> Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of Blume and Eigenmann [5, 6], who note that their dependence test, built to analyze regular access patterns, is essentially as successful as the Omega Test <ref> [22] </ref>, which was built to handle more general patterns. <p> We decided to design the region operations for regions with similar structures. However, if the regions do not meet the similarity constraints, our representation allows us to simplify the regions and still use our operations, or else choose different techniques which might be a better fit <ref> [21, 22] </ref>. Due to the strict word limit and the intrinsic complexity of the operations, we cannot discuss all the algorithms in this abstract, even though we will include them in the full paper. <p> If this is not allowed, then we could convert the region to a form which a different technique <ref> [22] </ref> can handle, since we retain all necessary information in our representation. Subtraction generalizes in a very natural way to the operation R 1 R 2 for multi-stride regions. The non-overlapping parts of R 1 appear in the output just as before, retaining the original shape of R 1 .
Reference: [23] <editor> D. Culler, et al., </editor> <booktitle> Parallel Programming in Split-C,Supercomputing '93 Proceedings, </booktitle> <year> 1993 </year>
Reference-contexts: The region test can then produce code which will check the predicate at run time, choosing between a parallel version of the loop and a serial version. 4.2 Communication Analysis Single-sided communication protocols <ref> [18, 19, 23, 27] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris.
Reference: [24] <author> M. Burke, R. Cytron, </author> <title> Interprocedural Dedependence Analysis and Parallelization, </title> <booktitle> Proceedings of ACM SGIPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> July </month> <year> 1986, </year> <pages> pp 162-175 </pages>
Reference-contexts: If X is multi-dimensional, then the subscript expression is linearized <ref> [24] </ref> to generate s (I).
Reference: [25] <author> H. Zima, B. Chapman, </author> <title> Supercompilers for Parallel and Vector Computers, </title> <publisher> ACM Press, </publisher> <year> 1992 </year>
Reference-contexts: The predicate is a condition under which R is valid. The access function f (I) is the same as s (I), as long as s (I) is a monotonic function <ref> [6, 25] </ref> within the index ranges. Although many subscript functions encountered in scientific programs may not be affine, most are monotonic [5], and those few which are not monotonic may be converted to a monotonic function with a possible accuracy loss.
Reference: [26] <institution> CRAY T3D System Architecture Overview, Cray Research, </institution> <year> 1993 </year>
Reference: [27] <institution> SHMEM Technical Note for Fortran, Cray Research, </institution> <month> Oct. </month> <year> 1994 </year>
Reference-contexts: The region test can then produce code which will check the predicate at run time, choosing between a parallel version of the loop and a serial version. 4.2 Communication Analysis Single-sided communication protocols <ref> [18, 19, 23, 27] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris.
Reference: [28] <author> M. Berry, D. Chen, P. Koss, D. Kuck, L. Pointer, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, J. Martin, </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers, </title> <booktitle> Int'l. Journal of Supercomputer Applications, Fall 1989, </booktitle> <volume> Vol. 3, No. 3, </volume> <month> Fall </month> <year> 1989, </year> <pages> pp. 5-40 </pages>
Reference-contexts: Based on our experience with the Perfect <ref> [28] </ref> and SPEC benchmarks, and several full scientific codes [1], we have developed a region access representation which takes advantage of the clear structure inherent in the array accesses of most scientific programs. Our design attempts to allow maximum expressiveness without sacrificing efficiency.
References-found: 28

