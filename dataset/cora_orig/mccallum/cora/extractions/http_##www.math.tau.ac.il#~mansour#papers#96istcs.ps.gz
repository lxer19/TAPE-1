URL: http://www.math.tau.ac.il/~mansour/papers/96istcs.ps.gz
Refering-URL: 
Root-URL: 
Title: On Learning Conjunctions with Malicious Noise  
Author: Yishay Mansour Michal Parnas 
Affiliation: Computer Science Dept. Tel-Aviv University  
Abstract: We show how to learn monomials in the presence of malicious noise, when the underlined distribution is a product distribution. We show that our results apply not only to product distributions but to a wide class of distributions. 
Abstract-found: 1
Intro-found: 1
Reference: [AL88] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: It is not hard to see that from an information theoretic point of view, there is no inherent problem. In fact, the hypothesis that has the lowest observed error would be a good approximation of the target hypothesis <ref> [AL88] </ref>.
Reference: [D93] <editor> Scott Decatur Statistical querries and faulty PAC oracles. </editor> <booktitle> In Proc. 6th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 262-268. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: A general framework to handle noise is the Statistical Query model [K93], which was originally aimed at the random classification noise model, and later extended to the malicious noise model <ref> [D93] </ref>. (See [Slo88] for a discussion of various noise models). In this paper we study the malicious noise model. <p> The latter result was improved in <ref> [D93] </ref> to O (*=` log 1 We develop an algorithm that is able to tolerate a noise rate of O (* 5=3 =n 2=3 ), which is a substantial improvement over the previous results. Unfortunately, our algorithm requires stronger assumptions about the underlined distribution.
Reference: [K93] <editor> Michael Kearns Efficient noise tolerant learning from statistical querries. </editor> <booktitle> In Proceedings of the 17th Annual ACM Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: A general framework to handle noise is the Statistical Query model <ref> [K93] </ref>, which was originally aimed at the random classification noise model, and later extended to the malicious noise model [D93]. (See [Slo88] for a discussion of various noise models). In this paper we study the malicious noise model.
Reference: [KL88] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Unfortunately, it seems a much more involved task to develop noise tolerant learning algorithms. The problem of learning monomials with malicious noise was already discussed in one of the pioneering papers in computational learning [Val85], which gives a learning algorithm that tolerates a noise rate of O (*=n). Later <ref> [KL88] </ref> improved the result and showed an algorithm that tolerates a noise rate of O ( * n ln n * ) for monomials over n variables, and O (*=` log ` ln n * ), when the target monomial has at most ` literals.
Reference: [KSS92] <author> M. J. Kearns, R. E. Schapire, and L. M. Sellie. </author> <title> Toward efficient agnostic learning. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 341-352. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference: [Lit88] <author> Nick Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: This algorithm can be modified to learn arbitrary monomials c 2 C n , by using the following technique due to Littlestone <ref> [Lit88] </ref>. The algorithm for learning arbitrary monomials will find a positive example y, and modify each example &lt; x; b &gt; to &lt; x y; b &gt;. (We need that y is a true positive example.
Reference: [Slo88] <author> Robert H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <editor> In David Haussler and Leonard Pitt, editors, </editor> <booktitle> First Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96. </pages> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: A general framework to handle noise is the Statistical Query model [K93], which was originally aimed at the random classification noise model, and later extended to the malicious noise model [D93]. (See <ref> [Slo88] </ref> for a discussion of various noise models). In this paper we study the malicious noise model.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: 1 Introduction The Probably Approximately Correct (PAC) Learning model <ref> [Val84] </ref> has been the most widely studied model in Computational Learning Theory. From the beginning of the field, it has been considered of the utmost importance to develop algorithms that are tolerant to noise. A variety of noise models were studied.
Reference: [Val85] <author> Leslie G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <pages> pages 560-566. </pages> <booktitle> International Joint Committee for Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1985. </year> <month> 6 </month>
Reference-contexts: PAC, online, Equivalence Queries). Unfortunately, it seems a much more involved task to develop noise tolerant learning algorithms. The problem of learning monomials with malicious noise was already discussed in one of the pioneering papers in computational learning <ref> [Val85] </ref>, which gives a learning algorithm that tolerates a noise rate of O (*=n).
References-found: 9

