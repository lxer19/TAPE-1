URL: http://www.cs.ucsd.edu/~wgg/Abstracts/gristhesis.ps.gz
Refering-URL: http://www.cs.ucsd.edu/~wgg/Abstracts/griswold.thesis.html
Root-URL: http://www.cs.ucsd.edu
Author: William G. Griswold 
Date: 1991  
Note: c Copyright  
Abstract-found: 0
Intro-found: 1
Reference: [Agrawal & Horgan 90] <author> H. Agrawal and J. R. Horgan. </author> <title> Dynamic program slicing. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Languages Design and Implementation, </booktitle> <month> June </month> <year> 1990. </year> <journal> SIGPLAN Notices 25(6). </journal>
Reference-contexts: However, the programmer still must choose when use of the plan is appropriate. Many program understanding tools, such as slicers for debugging [Weiser 84] <ref> [Agrawal & Horgan 90] </ref>, use PDGs or other flow analysis representations.
Reference: [Aho et al. 86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: Its design is similar to the one described in Chapter 4.2. The AST is a widely used program representation in programming environments. It closely matches a program's textual representation, providing a convenient representation for managing syntactic relationships and the semantics of scoping <ref> [Aho et al. 86] </ref>, as well as modifying the source of the program. It is created from a simple top-down parse of the Scheme program's s-expressions. Each node in the AST is a program object, such as a variable, function definition, or expression. <p> The PDG, as described in Chapter 4.1, is used to reason about data and control flow, and is derived from low-level data-flow and control-flow analysis. The first step in constructing the PDG is to translate the AST with a parser into sequences of statements that are essentially compiler triples <ref> [Aho et al. 86] </ref>: (operation; result; arguments), where operation is either operator call, function call, a jump or a jump label, result is a variable to hold the result, and arguments are the variables that contain the inputs to the operation. <p> From this is computed a graph of the program's control flow, called the Control Flow Graph (CFG) <ref> [Aho et al. 86] </ref>[Ferrante et al. 87][Larus 89]. Abstractly, computing the CFG removes all the jumps and labels and replaces them with explicit edges linking 102 basic-blocks of these triples.
Reference: [Allen & Cocke 72] <author> F. E. Allen and J. Cocke. </author> <title> A catalogue of optimizing transformations. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Design and Optimization of Compilers. </booktitle> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: By definition, subgraphs of a PDG may be modified by the substitution of sequence-congruent vertices without changing a PDG's meaning. For example, a vertex and its incoming edges can be replicated (by definition being sequence-congruent), and the outgoing edges split between the two copies <ref> [Allen & Cocke 72] </ref>. Thus PDGs can be transformed by performing replacement of sequence-congruent vertices in the PDG. This is the technique applied in this thesis for restructuring transformations. The replacements used are described below by a small set of PDG subgraph substitution rules motivated by sequence-congruence.
Reference: [Arnold 86] <author> R. S. Arnold. </author> <title> An introduction to software restructuring. </title> <editor> In R. S. Arnold, editor, </editor> <title> Tutorial on Software Restructuring. </title> <publisher> Society Press (IEEE), </publisher> <address> Washington D.C., </address> <year> 1986. </year>
Reference-contexts: Improving a programmer's understanding of a system makes its existing structure clearer|and hence better|just by making it better understood [Belady & Lehman 71] <ref> [Arnold 86] </ref>. Recall this is modeled by DAL in Belady and Lehman's maintenance cost equation (See Chapter 1.4.2). Although learning has limits on clarifying structure| because of the increasing amount of time required for increasingly complex programs|it requires no change to the system, which is advantageous in the short term.
Reference: [Balzer 85] <author> R. Balzer. </author> <title> Automated enhancement of knowledge representations. </title> <booktitle> In Proceedings of the Ninth International Joint Conference Artificial Intelligence, </booktitle> <pages> pages 203-207, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: The specification and implementation are still separated, but the downside is that the specification language must be lower-level for this technique to produce efficient programs. 131 6.3 Knowledge Representation Enhancement A package of tools for performing structural enhancements of a knowledge representation system <ref> [Balzer 85] </ref> has the same motivations as the research described in this thesis, but in a narrower domain. The tools exploit the highly structured, declarative domain model of a knowledge base to infer the changes to assumptions caused by a structural enhancement.
Reference: [Barstow 85] <author> D. Barstow. </author> <title> On convergence toward a database of program transformations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(1) </volume> <pages> 1-9, </pages> <month> January </month> <year> 1985. </year>
Reference: [Belady & Lehman 71] <author> L. A. Belady and M. M. Lehman. </author> <title> Programming system dynamics or the metadynamics of systems in maintenance and growth. </title> <institution> Research Report RC3546, IBM, </institution> <year> 1971. </year> <note> Page citations from reprint in M. </note> <editor> M. Lehman, L. A. Belady, editors, </editor> <title> Program Evolution: Processes of Software Change, Ch. </title> <booktitle> 5, APIC Studies in Data Processing No. </booktitle> <volume> 27. </volume> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: Repairs also, will tend to cause deviation from structural regularity since, except under conditions of the strictest control, any repair or patch will be made in the simplest and quickest way. No search will be made for a fix that maintains structural integrity <ref> [Belady & Lehman 71, p. 113] </ref>. <p> It also supposes, as Belady and Lehman claim, that structural degradation occurs naturally, and cannot be avoided by forethought or language mechanisms <ref> [Belady & Lehman 71] </ref>. Changes that cross module boundaries are the ones that will be costly to perform [Parnas 72]. This includes manual restructuring. As an example, consider a pair of routines that must always be called in a particular order, such as an allocation function and an initialization function. <p> Based on this evidence, Belady and Lehman defined a model of maintenance cost based on a program's complexity at release i <ref> [Belady & Lehman 71] </ref>: C i = 2 2G (i)DAL (i) G (i) represents the complexity of the system, which as an observable variable can be quantified as the percentage of modules handled in a release interval [Belady & Lehman 76b]. <p> This model for complexity equates to the cost of a change, since to make a correct change requires cross-checking it for consistency for an exponential number of relationships. The exponential growth in complexity is due to stratification of changes during the system's history <ref> [Belady & Lehman 71] </ref>. A way to understand this intuitively is to look at the fault structure of the system relative to changes. <p> 1;3 G 2;3 - - X X X Xz 1 H Q Q Qs G 1;1 G 0;1 R 1;2 Any change that is made by a programmer must be checked for consistency with every element in the strata, requiring exponential work, as well as requiring repair of affected elements <ref> [Belady & Lehman 71] </ref>. If this work is not done, then the error strata are likely 12 to be expanded, requiring greater work in the future to remove generated errors. <p> In essence, the model quantifies|asymptotically|Parnas's claim that it is impossible to maintain locality of change indefinitely. Belady and Lehman concur, concluding that exponential growth in complexity is inevitable, and increasing DAL can only delay the effects <ref> [Belady & Lehman 71] </ref>. They complement their conclusion with the claim that progressive activities such as enhancement require continual anti-regressive effort to maintain the documentation and programmer familiarity on such changes. <p> Another variable not modeled accurately is that relationships between modules are viewed as much more expensive to manage then those within a module. If the restruc 14 turing tool helps to perfectly localize a change, then G goes to zero <ref> [Belady & Lehman 71] </ref>, and thus the cost of a change goes to zero, which is not precise since it ignores the time using the tool. Also reducing G probably has a negative impact on DAL. <p> Unfortunately, no simple enhancement of the model is possible. The original model provides no quantitative definition for functions G and DAL, so it is impossible to enhance them. Also, the Belady and Lehman model is supported by substantial quantitative data [Belady & Lehman 76a] and cogent theory <ref> [Belady & Lehman 71] </ref>[Belady & Lehman 76a]. The change in indexing, effects on G and DAL, and the actual cost of restructuring must be derived in the same manner. <p> Improving a programmer's understanding of a system makes its existing structure clearer|and hence better|just by making it better understood <ref> [Belady & Lehman 71] </ref> [Arnold 86]. Recall this is modeled by DAL in Belady and Lehman's maintenance cost equation (See Chapter 1.4.2). <p> Further, this thesis has proven the novel idea that program structure can be managed by transforming the abstractions of a program without affecting its basic computations. There are several supporting contributions: 159 Using meaning-preserving transformation to automate restructuring. The macro-model of Belady and Lehman <ref> [Belady & Lehman 71] </ref> predicts that manual restructuring will be as costly as any other maintenance activity, primarily because it requires physically distributed, but semantically consistent, changes to the program.
Reference: [Belady & Lehman 76a] <author> L. A. Belady and M. M. Lehman. </author> <title> A model of large program development. </title> <journal> IBM Systems Journal, </journal> <volume> 15(3) </volume> <pages> 225-252, </pages> <year> 1976. </year> <note> Reprinted in M. </note> <editor> M. Lehman, L. A. Belady, editors, </editor> <title> Program Evolution: Processes of Software Change, Ch. </title> <booktitle> 8, APIC Studies in Data Processing No. </booktitle> <volume> 27. </volume> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year> <month> 162 </month>
Reference-contexts: In studies of OS/360 and other large systems, L.A. Belady and M.M. Lehman observed that the cost of a change grew exponentially with respect to a system's age <ref> [Belady & Lehman 76a] </ref>. They associated these rising costs with decaying structure caused by the accumulation of unanticipated changes: The addition of any function not visualized in the original design will inevitably degenerate structure. <p> In their studies of OS/360 and other large systems, Belady and Lehman observed that the cost of maintenance grew exponentially with respect to a system's age <ref> [Belady & Lehman 76a] </ref>. <p> Unfortunately, no simple enhancement of the model is possible. The original model provides no quantitative definition for functions G and DAL, so it is impossible to enhance them. Also, the Belady and Lehman model is supported by substantial quantitative data <ref> [Belady & Lehman 76a] </ref> and cogent theory [Belady & Lehman 71][Belady & Lehman 76a]. The change in indexing, effects on G and DAL, and the actual cost of restructuring must be derived in the same manner.
Reference: [Belady & Lehman 76b] <author> L. A. Belady and M. M. Lehman. </author> <title> Program evolution and its impact on software engineering. </title> <booktitle> In Proceedings of the 2nd International Conference on Software Engineering, </booktitle> <pages> pages 350-357, </pages> <month> October </month> <year> 1976. </year> <note> Reprinted in M. </note> <editor> M. Lehman, L. A. Belady, editors, </editor> <title> Program Evolution: Processes of Software Change, Ch. </title> <booktitle> 9, APIC Studies in Data Processing No. </booktitle> <volume> 27. </volume> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: a model of maintenance cost based on a program's complexity at release i [Belady & Lehman 71]: C i = 2 2G (i)DAL (i) G (i) represents the complexity of the system, which as an observable variable can be quantified as the percentage of modules handled in a release interval <ref> [Belady & Lehman 76b] </ref>. DAL (i) (known as "Documentation, Accessibility, and Learnability") represents the quality of the documentation and programmer comprehension of the system. By improving documentation and increasing programmer familiarity with a system, complexity can be controlled.
Reference: [Boehm 81] <author> B. W. Boehm. </author> <title> Software Engineering Economics. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: Also, given the range of possible future enhancements, it is not economically feasible to accommodate every one <ref> [Boehm 81, pp. 20-21] </ref>[Parnas 79]; given a set of design decisions to hide, there may be conflicting feasible modularizations of a program. One must be chosen in favor of the others. As an example of conflicting modularizations, suppose a programmer is designing an interpreter for a polymorphic programming language. <p> Also, removing an error during maintenance is expensive|as expensive as a typical change during maintenance <ref> [Boehm 81, pp. 40-41] </ref> (See the next paragraph). Unsuitable modularization for a specific enhancement, then, is potentially a high cost of maintenance, and so automated restructuring must support 3 Common coupling gets its name from the FORTRAN COMMON statement, used to share global data between functions. 10 remodularization.
Reference: [Bohm & Jacopini 66] <author> C. Bohm and G. Jacopini. </author> <title> Flow diagrams, Turing machines and languages with only two formation rules. </title> <journal> Communications of the ACM, </journal> <volume> 9(5) </volume> <pages> 366-71, </pages> <month> May </month> <year> 1966. </year>
Reference-contexts: Remodularization requires more than automated removal of gotos or control flow restructuring <ref> [Bohm & Jacopini 66] </ref>[Williams & Ossher 77][Morgan 84]. For example, it requires operations such as adding or removing a function from a module interface, changing a function interface, or hiding exposed representation in a module. <p> These are not examined item-by-item in each discussed work, but the appropriate points are raised as necessary. 6.1 Imposing Block Structure A program using gotos can be automatically transformed into a program using only the structured flow graph operators sequence, branch, and loop <ref> [Bohm & Jacopini 66] </ref>. The intent is to improve a program's structure to lower the cost of maintenance, a shared motivation with the research of this thesis. Most of the solutions involve simulating gotos with structured operators.
Reference: [Burke & Ryder 90] <author> M. Burke and B. G. Ryder. </author> <title> A critical analysis of incremental iterative data-flow algorithms. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-16(7), </volume> <month> July </month> <year> 1990. </year>
Reference-contexts: There is now a significant effort in the compiler and programming environments community to incrementalize flow analysis [Burke 90] <ref> [Burke & Ryder 90] </ref> [Ryder & Paull 88]. Finally, even if poor performance remains a detriment in the future, the flow computation is precisely the kind of effort necessary to assure a given restructuring preserves meaning, but it is more time-consuming and difficult for the engineer than the computer.
Reference: [Burke 90] <author> M. Burke. </author> <title> An interval-based approach to exhaustive and incremental inter-procedural data-flow analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 341-395, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: There is now a significant effort in the compiler and programming environments community to incrementalize flow analysis <ref> [Burke 90] </ref> [Burke & Ryder 90] [Ryder & Paull 88].
Reference: [Burstall & Darlington 77] <author> R. M. Burstall and J. Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: However, the transformations to be shown below have been derived in the process of restructuring programs by hand and with the tool. Some of these have also been suggested as useful in the literature <ref> [Burstall & Darlington 77] </ref>[Hoare et al. 87]. However, the effectiveness of this set in localizing change is being validated in practice. <p> easy to quantify, such as restructuring towards a particular enhancement. 129 6.2 Transformational Programming Introduced in the 1970's, transformational programming, also known as derivational programming, feeds a functional specification of an intended computation to a transformation system that, with guidance from a "programmer", rewrites the specification into an efficient program <ref> [Burstall & Darlington 77] </ref>. Thus most of the development effort is focused on the specification rather than programming, and there is a guarantee that the program satisfies the specification. The use of transformation is the key similarity with the restructuring work.
Reference: [Callahan et al. 90] <author> D. Callahan, S. Carr, and K. Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Languages Design and Implementation, </booktitle> <month> June </month> <year> 1990. </year> <journal> SIGPLAN Notices 25(6). </journal>
Reference-contexts: Also, optimization is typically not required to produce a valid or readable source language representation, working instead on intermediate code or assembler, a simpler task. Exceptions are the transformations described by Loveman [Loveman 77], and recent results in optimizing register accesses in loops <ref> [Callahan et al. 90] </ref>. Still, neither of these require a readable source, nor an interactive user interface.
Reference: [Cartwright & Felleisen 89] <author> R. Cartwright and M. Felleisen. </author> <title> The semantics of program dependence. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Languages Design and Implementation, </booktitle> <month> July </month> <year> 1989. </year> <journal> SIGPLAN Notices 24(7). </journal>
Reference-contexts: The result would be a direct incremental manipulation of the program, rather than batch reconstruction. However, the formal basis for such a lift of program-PDG mappings is in its infancy <ref> [Cartwright & Felleisen 89] </ref>. So rather than lifting m and m 1 using a formal basis, the technique is informally applied in the processing of implementing a transformation, based on the transformation builder's knowledge of the programming language and PDGs. <p> A formal framework might enable a theorem prover to automate the proof that a transformation preserves meaning. There has been some work on this based on denotational <ref> [Cartwright & Felleisen 89] </ref> and operational [Selke 90] semantics of PDGs, but this avenue has not been explored in this restructuring research. <p> A more formal relation between transformations on a PDG and transformations on a program would add strength to this result. As discussed in Chapter 7.5, techniques exploiting recent work on the semantics of PDGs seem promising <ref> [Cartwright & Felleisen 89] </ref>[Selke 90][Venkatesh 91]. Transformational restructuring is low-level. After the software engineer chooses the best structure for the next maintenance step, the transformational approach still requires the engineer to choose the transformations that migrate the program from its existing structure to the new structure.
Reference: [Chambers & Ungar 90] <author> C. Chambers and D. Ungar. </author> <title> Iterative type analysis and extended message splitting: Optimizing dynamically-typed object-oriented programs. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Languages Design and Implementation, </booktitle> <month> June </month> <year> 1990. </year> <journal> SIGPLAN Notices 25(6). </journal>
Reference-contexts: Fortunately, type and data flow information can be used to refine the control-flow graph significantly <ref> [Chambers & Ungar 90] </ref>, eliminating much of the branching effect. Only actual experience will reveal, however, if this will be sufficient. The class hierarchy can complicate the actual transformations, also.
Reference: [Cleveland 89] <author> L. Cleveland. </author> <title> A program understanding support environment. </title> <journal> IBM Systems Journal, </journal> <volume> 28(2), </volume> <year> 1989. </year>
Reference-contexts: Program understanding is an analytic tool-oriented technique for aiding maintenance. Program understanding techniques|also sometimes called reverse engineering|such as graphical display of program structure <ref> [Cleveland 89] </ref>, inferring abstractions [Rich & Waters 88], or assessing modularity [Schwanke 91][Embley & Woodfield 88] are used to extract program information in a more understandable or reusable form [Lewis 90].
Reference: [Collofello & Buck 87] <author> J. S. Collofello and J. J. Buck. </author> <title> Software quality assurance for maintenance. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 46-51, </pages> <month> September </month> <year> 1987. </year> <month> 163 </month>
Reference-contexts: As an example of the subtlety of component relationships, a study of a software product's maintenance revealed that 53% of the defects introduced by adding new product features were to existing features <ref> [Collofello & Buck 87] </ref>. Also, removing an error during maintenance is expensive|as expensive as a typical change during maintenance [Boehm 81, pp. 40-41] (See the next paragraph).
Reference: [Cunnington et al. 90] <author> W. Cunnington, R. Johnson, M. Linton, and TBD. </author> <title> Designing reusable designs|experiences designing object-oriented frameworks. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <pages> page 234, </pages> <month> October </month> <year> 1990. </year> <title> Panel Discussion, Allen Wirfs-Brock, moderator. </title> <journal> SIGPLAN Notices 25(10). </journal>
Reference-contexts: A languages solution entails designing or extending a language to accommodate the evolution of structure in a program. Object-oriented languages are representative of this approach. An object-oriented language permits adding function to a program, if designed properly <ref> [Cunnington et al. 90] </ref>, by incrementally, relatively locally augmenting the existing class structure|modifying existing classes (modules, of a sort) is not necessary.
Reference: [Cytron et al. 88] <author> R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and K. Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Proceedings of the 16th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: The key difference between the PDG and PRG is that the PRG uses normalized variables in the style of static single assignment (SSA) form <ref> [Cytron et al. 88] </ref>. Yang's algorithm determines the equivalence of two PDG components based on three properties, (1) the equivalence of their operators, (2) the equivalence of their inputs, (3) the equivalence of the predicates controlling their evaluation.
Reference: [DeMillo et al. 79] <author> R. DeMillo, R. Lipton, and A. Perlis. </author> <title> Social processes and proofs of theorems and programs. </title> <journal> Communications of the ACM, </journal> <volume> 22(5), </volume> <month> May </month> <year> 1979. </year>
Reference: [Dijkstra 72] <author> E. Dijkstra. </author> <booktitle> Notes on Structured Programming, </booktitle> <pages> pages 1-82. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: To paraphrase Dijkstra, testing can be used to show the absence, but not the presence, of equivalence after restructuring <ref> [Dijkstra 72] </ref>. In contrast, use of a restructuring tool that preserves meaning relieves the engineer from this concern and responsibility. Of course, the tool itself is not, of course, guaranteed to be free of errors.
Reference: [Downey & Sethi 78] <author> P. J. Downey and R. Sethi. </author> <title> Assignment commands with array references. </title> <journal> Journal of the ACM, </journal> <volume> 25(4) </volume> <pages> 652-666, </pages> <month> October </month> <year> 1978. </year>
Reference-contexts: Scope-wide function replacement. This transformation scope-sub-call replaces repeated sequences of the code of an existing function with calls on the function. This is often used following function extraction. To find the repeated codings requires a program equivalence test, which in general is infeasible <ref> [Downey & Sethi 78] </ref>. However, there are conservative techniques that are fast but can abstract away many anomalies [Yang et al. 89] (See Chapter 4.3).
Reference: [Driscoll et al. 89] <author> J. R. Driscoll, N. Sarnak, D. D. Sleator, and R. E. Tarjan. </author> <title> Making data structures persistent. </title> <journal> Journal of Computer and System Science, </journal> <volume> 38(1) </volume> <pages> 86-124, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: A critical concern here is the amount of space required, since PDGs can be rather large [Ferrante et al. 87]. Recently a technique has been derived for making linked data structures retain versions <ref> [Driscoll et al. 89] </ref>. 138 The key advantages of this result is that it applies to all data structures of a node-and-pointer variety (such as PDGs), and the amortized cost of maintaining versions is a small constant for each update to a node.
Reference: [Dybvig 87] <author> R. K. Dybvig. </author> <title> The Scheme Programming Language. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: The following is a more detailed summary of the contents of the thesis. 1.8 Overview Chapter 2 describes the basic meaning-preserving transformations necessary for restructuring programs written in a block-structured imperative programming language, in this case Scheme <ref> [Dybvig 87] </ref>. To show how the transformations restructure, they are used in the prototype to restructure a Scheme matrix multiply program. Scheme was selected because of its rich imperative features, its simple syntax, and the availability of a PDG package for Scheme programs [Larus 89]. <p> over must have only one value in it, because otherwise there would be extra iteration that was not present before. 5 2.6 Restructuring a Matrix Multiply Program Now to show how the remaining transformations are used, and give a better sense of how restructurings are achieved, a matrix multiply program <ref> [Dybvig 87] </ref>, shown in Figure 2.1, is restructured. Matrices in this program are represented as lists of (equal length) vectors, 5 The conditions stated for transformations are conservative, and often can be generalized to improve the likelihood of successful transformation, without affecting correctness.
Reference: [Embley & Woodfield 88] <author> D. W. Embley and S. N. Woodfield. </author> <title> Assessing the quality of abtract data types written in Ada. </title> <booktitle> In Proceedings of the 10th International Conference on Software Engineering, </booktitle> <pages> pages 144-153, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: If errors are introduced into a tracked program, earlier program versions can be retrieved to return to a working version or help find the change that caused the error. Like a language, a tool can make methods easier to follow or apply. A tool that discovers component relationships <ref> [Embley & Woodfield 88] </ref>[Rich & Waters 88][Schwanke 91][Selby & Basili 91] or that automates remodularizing a program can aid an engineer in using Parnas's system decomposition principles to achieve locality of change. 1.3 A Tools Solution|Restructuring This thesis focuses on a tools solution to mitigate the software maintenance problem.
Reference: [Feather 84] <author> M. S. Feather. </author> <title> A system for assisting program transformation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(1) </volume> <pages> 1-20, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: This is not a serious problem in the restructuring domain because the catalogue is practically bounded by the size of the language's syntax. Recent work in derivational programming has attempted to alleviate the tedium of choosing and applying transformations by building up higher-level transformations from primitives <ref> [Feather 84] </ref>[Barstow 85]. For example, M.S. Feather developed a technique that uses a pattern to express the goal of a transformation [Feather 84]. Using a goal pattern, a tool can select the appropriate primitive transformations to compose to achieve the goal. Such techniques might be applicable to restructuring. <p> Recent work in derivational programming has attempted to alleviate the tedium of choosing and applying transformations by building up higher-level transformations from primitives <ref> [Feather 84] </ref>[Barstow 85]. For example, M.S. Feather developed a technique that uses a pattern to express the goal of a transformation [Feather 84]. Using a goal pattern, a tool can select the appropriate primitive transformations to compose to achieve the goal. Such techniques might be applicable to restructuring. <p> A higher level approach, similar to Feather's techniques <ref> [Feather 84] </ref> described in Chapter 6.2, would allow specifying a goal structure, and then tool could use the taxonomy's formal relationships between structures to choose the transformations. Also, the interface of the current tool is command-driven rather than window-based. <p> Chapter 7.1 suggested several techniques for countering these problems, perhaps the most promising being a goal-directed approach to program derivation <ref> [Feather 84] </ref>, which for restructuring would allow the engineer to specify the goal structure and let the system infer the transformations. The relationship between restructuring and preserving meaning is unclear. The preservation of meaning is a central theme of this restructuring work.
Reference: [Feather 90] <author> M. S. Feather. </author> <title> Specification evolution and program (re)transformation. </title> <booktitle> In Proceedings of the 5th RADC Knowledge-Based Software Assistant Conference, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: Using a goal pattern, a tool can select the appropriate primitive transformations to compose to achieve the goal. Such techniques might be applicable to restructuring. Other work has focused on trying to lower the costs of redevelopment by automating rederivation of a program from a modified specification <ref> [Feather 90] </ref>. The basic idea is to reuse the transformation sequence from the initial development to automate the programming tasks of maintenance.
Reference: [Federal Software Management Support Center 87] <author> Federal Software Management Support Center. </author> <title> Parallel test and productivity evaluation of a commercially supplied COBOL restructuring tool. </title> <type> Technical report, </type> <institution> Office of Software Development and Information Technology, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: Some approaches try to preserve the original structure of the program during goto removal [Ramshaw 88]. These techniques use control flow graphs, an early precursor to, and important subrepresentation of, PDGs. Automatic restructuring systems such as SUPERSTRUCTURE [Morgan 84] and RE-CODER <ref> [Federal Software Management Support Center 87] </ref> have successfully exploited 128 const Terminate = 0; const A = 1; const A1 = 2; flag := A; A: while flag ~= Terminate do &lt;e1&gt; case flag of if &lt;b1&gt; then A: goto A; &lt;e1&gt; &lt;e2&gt; if &lt;b1&gt; then if &lt;b2&gt; then flag := <p> A transformation is applied to a single syntactic construct, and the tool can make the compensating changes in the rest of the program to preserve its original meaning. This style of transformation removes the engineer from error-prone activities without sacrificing control over the resulting structure, unlike prior restructuring tools <ref> [Federal Software Management Support Center 87] </ref> [Morgan 84]. In addition to revealing the hazards of manual restructuring, the experiment also confirmed that the tool automates those exact activities that are error-prone: making consistent, physically distributed changes.
Reference: [Feldman 79] <author> S. Feldman. </author> <title> Make|a program for maintaining computer programs. </title> <journal> Software Practice and Experience, </journal> <volume> 9(4), </volume> <month> April </month> <year> 1979. </year> <month> 164 </month>
Reference-contexts: It is assumed here that the some of the best tools are those that automate an activity that users already intuitively understand. 1 (As an example, consider the success of make <ref> [Feldman 79] </ref>.
Reference: [Ferrante et al. 87] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Simple graph algorithms and set operations can extract this information. Another advantage is that the PDG has been a popular program representation for aiding program parallelization [Kuck et al. 81][Larus 89], optimization <ref> [Ferrante et al. 87] </ref>, slicing [Ottenstein & Ottenstein 84][Horwitz et al. 90], and version merging [Horwitz et al. 89]. <p> Most previous applications of PDGs have not required preserving scope properties because they are either non-manipulative [Weiser 84] or the source is not being manipulated, such as in program optimization <ref> [Ferrante et al. 87] </ref> and parallelization [Larus 89]. <p> A critical concern here is the amount of space required, since PDGs can be rather large <ref> [Ferrante et al. 87] </ref>.
Reference: [Garlan 87] <author> D. Garlan. </author> <title> Views for Tools in Integrated Programming Environments. </title> <type> PhD dissertation, </type> <institution> Carnegie-Mellon University, Department of Computer Science, </institution> <year> 1987. </year>
Reference-contexts: Views allow providing multiple abstractions so that two agents may access the same data structure in different fashions, either for convenience or protection <ref> [Garlan 87] </ref>. For views to be effective in restructuring, the tool user must be able to make an arbitrary change to any view and have the changes propagated automatically to the other views. This would be difficult to implement using the current restructuring model.
Reference: [Hoare et al. 87] <author> C. A. R. Hoare, I. J. Hayes, H. Jifeng, C. C. Morgan, A. W. Roscoe, J. W. Sanders, I. H. Sorensen, J. M. Spivey, and B. A. Sufrin. </author> <title> Laws of programming. </title> <journal> Communications of the ACM, </journal> <volume> 30(2) </volume> <pages> 672-686, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: A program written in a functional language has transparency because it has no variables for representing changing state. This allows algebraic manipulation of functional programs. 19 C.A.R. Hoare et al. demonstrated that imperative programming languages also obey powerful and intuitive algebraic laws that permit source-to-source transformation <ref> [Hoare et al. 87] </ref>. For example, there is a law that says a variable reference can be replaced by its defining expression. For example, given expression E, and expression F using x, F (x), then x := E; F (x) is equivalent to F (E). <p> Theoretically, however, the meaning of the program is undefined in either case, so the meaning is not changed <ref> [Hoare et al. 87] </ref>. <p> If the components had been built together, the mappings might not have been as easy to implement. Specifically, independently implemented relations have allowed migrating from 1-1 to 1-many relations as more properties of the AST and PDG relationship needed representation. Chapter 6 Related Work The influence of Hoare's work <ref> [Hoare et al. 87] </ref> on the value of source-to-source transformation was discussed in the introduction, as was the influence of Parnas's work in modularization [Parnas 72] and Belady and Lehman's work on the impact of iterative maintenance on overall system cost. <p> There are two dimensions to this constraint: value-changing operations cannot be changed, and the meaning of the implementation is being preserved. It is possible to augment flow preservation with type-oriented algebraic laws <ref> [Hoare et al. 87] </ref>, which would allow reasoning not only about the identity of flows and operations, but about what operations do to flows. This is not a drastic change in the flow model.
Reference: [Horwitz et al. 88] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> On the adequacy of program dependence graphs for representing programs. </title> <booktitle> In Proceedings of the 15th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 146-157, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: The PDG representation used in the prototype [Larus 89] has anti-dependences (edges denoted by AD in Figure 4.2) and def-order dependences <ref> [Horwitz et al. 88] </ref> (denoted by DO). An anti-dependence relates a vertex u x retrieving from variable x to a subsequent vertex d 2 x defining the same variable, if the definition can overwrite a prior definition d 1 x for u x . <p> This implies that the two definitions cannot be under the same control dependence predecessor, such as the opposite arms of the same conditional expression. Def-order dependence is like output dependence, but it excludes unconditional kills of definitions <ref> [Horwitz et al. 88] </ref>. <p> A dependence can be further classified as loop-carried <ref> [Horwitz et al. 88] </ref>, meaning that the dependence arises only if a loop body is iterated more than once. This classification determines if a two vertices are dependent on the first execution of a loop (a normal dependence), or in subsequent iterations (loop carried). <p> This is the 9 They link only some because def-order dependences apply only when one definition can actually overwrite the other, which means they cannot be in exclusive arms of a conditional <ref> [Horwitz et al. 88] </ref>. 88 converse of data flow-dependence, for which the dependence is removed when reversing the order of evaluation of the linked vertices. <p> Conditional execution does have an impact on def-order dependence, but in fact there is no change for this rule. In fact, since no variable definitions or uses are being modified and meaning is supposed to be preserved, def-order dependences must not change <ref> [Horwitz et al. 88] </ref>. However, it is still useful to show how def-order dependence and the rule interact. Suppose there is DO (w; x) s in G that is missing in G 0 .
Reference: [Horwitz et al. 89] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> Integrating noninterfering versions of programs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <pages> pages 345-387, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: From a performance standpoint, the time required to unparse the PDG after each transformation must be considered, since the programmer cannot be expected to restructure the PDG directly. PDG unparsing is in NP, although in practice this is not considered to be a serious problem <ref> [Horwitz et al. 89] </ref>. However, even a linear algorithm (the quickest possible) may be a problem if rapid restructuring is desired. <p> Since scoping impacts the PDG, a notation called 1 This constraint is applied for ordering statements in program version merging <ref> [Horwitz et al. 89] </ref>, and is implemented using maps between the PDG and AST (Susan Horwitz, Personal Communication, 1991) similar to those discussed in Chapter 5.3. 60 contours is derived from the AST to help reason about transformations in the PDG. <p> Simple graph algorithms and set operations can extract this information. Another advantage is that the PDG has been a popular program representation for aiding program parallelization [Kuck et al. 81][Larus 89], optimization [Ferrante et al. 87], slicing [Ottenstein & Ottenstein 84][Horwitz et al. 90], and version merging <ref> [Horwitz et al. 89] </ref>. <p> Program version merging|a less constrained domain than program restructuring, since the meaning of the merged program will usually be different from the originals|uses unparse techniques to rederive the source representation, but it can fail because the merged PDG cannot always be unparsed into a legal program <ref> [Horwitz et al. 89] </ref>. Scoping is the most semantically critical syntactic property. Other syntactic properties are important, too, but are much more static or are captured more readily in the PDG. <p> These parallel updates can efficiently implement transformations, avoiding the batch reconstruction of the AST or PDG that is normally used to keep these representations consistent <ref> [Horwitz et al. 89] </ref> [Larus 89]. Although incremental update has been implemented for only two transformations, move-expr and rename-variable, there is no inherent problem with applying the idea more broadly.
Reference: [Horwitz et al. 90] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: System 64 := - Z Q Q Qs ? Q Q Q Q Q ? ? ? FD:y FD:x x := y + 1 ) end := x := 2 if x &lt; 5 then 1 if true AD:x local y local x := 1 begin 1 Dependence Graph representation <ref> [Horwitz et al. 90] </ref>, but does not remove spurious transitive dependences due to call sites sharing the same entry and exit to a proce dure's PDG. <p> An enhanced restructuring tool could assure this by checking equivalence with respect to the subset of the program variables residing outside the algorithm's module. In a sense, the tool would be operating on a slice [Weiser 84] <ref> [Horwitz et al. 90] </ref> of the program. It is powerful because it would allow localized enhancement, but globally checks equivalence. <p> Consequently, a source-to-source transformation is applied directly to the program, leaving unchanged those syntactic features of the program that are not explicitly manipulated. This is in contrast to standard PDG unparse techniques <ref> [Horwitz et al. 90] </ref> [Larus 89]. A working implementation of a restructuring tool. Successfully implementing a restructuring tool validated the claim that a restructuring transformation can be invoked locally by the engineer and compensated by a tool to preserve meaning.
Reference: [Johnson & Foote 88] <author> R. E. Johnson and B. Foote. </author> <title> Designing reusable classes. </title> <journal> Journal of Object Oriented Programming, </journal> <pages> pages 22-35, </pages> <month> June/July </month> <year> 1988. </year>
Reference-contexts: The result may be that the hierarchy represents the implementation history of the program. However, it is generally desirable for the hierarchy to represent the type structure of the application domain, in spite of this tendency <ref> [Johnson & Foote 88] </ref>. Automated restructuring can help manage the tension between the two uses [Opdyke & Johnson 90]. Also, discovery of design errors may suggest changing the interface of a superclass method, resulting in restructuring.
Reference: [Kuck et al. 81] <author> D. J. Kuck, R. H. Kuhn, B. Leasure, D. A. Padua, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the 8th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: These problems of imperative programming languages can be overcome by a richer notation that captures program properties not immediately visible in the text. The solution adopted in this thesis is a notation based on control and data flow relationships, represented by the program dependence graph (PDG) <ref> [Kuck et al. 81] </ref>[Ferrante et al. 87]. Among other important properties, the PDG has more of the referential transparency necessary to reason algebraically about a program. This is achieved by representing a variable by edges that explicitly carry values between operations, which are the vertices of the graph. <p> The Program Dependence Graph (PDG) <ref> [Kuck et al. 81] </ref>[Ferrante et al. 87] explicitly represents dependences between the operations of the program. Essentially, a PDG is a graph with the vertices representing program operations, and the edges representing the flow of data and control between operations. <p> Simple graph algorithms and set operations can extract this information. Another advantage is that the PDG has been a popular program representation for aiding program parallelization <ref> [Kuck et al. 81] </ref>[Larus 89], optimization [Ferrante et al. 87], slicing [Ottenstein & Ottenstein 84][Horwitz et al. 90], and version merging [Horwitz et al. 89].
Reference: [Larson 88] <author> P. Larson. </author> <title> Dynamic hash tables. </title> <journal> Communications of the ACM, </journal> <volume> 31(4), </volume> <month> April </month> <year> 1988. </year>
Reference-contexts: The relations can be implemented easily (and efficiently), by a pair of hash tables, one keyed on ast-object, the other on pdg-variable. The cost in space and time for hashing structures is minimal, although it is dependent on the exact implementation of the tables. Self-organizing hash tables <ref> [Larson 88] </ref>, for example, have amortized cost of space linear in the number of elements, and constant time for lookups, insertions and deletions. The relations are constructed by the AST-CFG parser (shown in the diagram as part of AST-PDG consistency).
Reference: [Larus & Hilfinger 88] <author> J. R. Larus and P. N. Hilfinger. </author> <title> Detecting conflicts between structure accesses. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Languages Design and Implementation, </booktitle> <month> June </month> <year> 1988. </year> <journal> SIGPLAN Notices, </journal> <volume> 23(7). </volume>
Reference: [Larus 89] <author> J. R. Larus. </author> <title> Restructuring Symbolic Programs for Concurrent Execution on Multiprocessors. </title> <type> PhD dissertation, </type> <institution> UC Berkeley Computer Science, </institution> <month> May </month> <year> 1989. </year> <note> Also Technical Report No. UCB/CSD 89/502. </note>
Reference-contexts: To show how the transformations restructure, they are used in the prototype to restructure a Scheme matrix multiply program. Scheme was selected because of its rich imperative features, its simple syntax, and the availability of a PDG package for Scheme programs <ref> [Larus 89] </ref>. The implementation is in 21 Common Lisp because of its prototyping flexibility and because it is the implementation language of the PDG package. <p> Each, for a different case, implies that the source vertex is necessarily executed before the destination vertex in the program, even though there is no explicit flow of data or control between them. The PDG representation used in the prototype <ref> [Larus 89] </ref> has anti-dependences (edges denoted by AD in Figure 4.2) and def-order dependences [Horwitz et al. 88] (denoted by DO). <p> The other edges are excluded because they do not represent the flow of values or control in the execution of the program. For the design of the PDG used in this thesis <ref> [Larus 89] </ref>, flow dependence is the same as strong syntactic dependence (SSD) [Podgurski & Clarke 90]. If a vertex u is SSD on v, then u may be (is likely to be) semantically dependent on v. However, there is also a case in which a semantic dependence is not SSD. <p> Most previous applications of PDGs have not required preserving scope properties because they are either non-manipulative [Weiser 84] or the source is not being manipulated, such as in program optimization [Ferrante et al. 87] and parallelization <ref> [Larus 89] </ref>. <p> These parallel updates can efficiently implement transformations, avoiding the batch reconstruction of the AST or PDG that is normally used to keep these representations consistent [Horwitz et al. 89] <ref> [Larus 89] </ref>. Although incremental update has been implemented for only two transformations, move-expr and rename-variable, there is no inherent problem with applying the idea more broadly. Auxiliary to the desire to ease implementing transformations and providing good performance was the wish to design the tool's components with enhanced functional independence. <p> It is implemented in Common Lisp (CL) and the Common Lisp Object System (CLOS). The PDG implementation is a subsystem of Curare <ref> [Larus 89] </ref>. It supports interprocedural analysis, including the aliasing properties of list structure references [Larus & Hilfinger 98 88]. The PDG supports all features of Scheme except eval, first-class functions, continuations, and dynamic scoping. With a more complete PDG implementation the tool could support these features (see Chapter 7.4). <p> Basing the preservation of meaning on the PDG representation and our chosen implementation of it places necessary restrictions on what is practically feasible. Certain dependences, such as those introduced by procedure parameters [Shivers 88] or pointers <ref> [Larus 89] </ref>, have proved costly to model precisely, and require approximate analyses that introduce spurious dependences. Where the power of the particular flow analysis implementation falls short, the system can use other knowledge to augment the analysis. <p> Consequently, a source-to-source transformation is applied directly to the program, leaving unchanged those syntactic features of the program that are not explicitly manipulated. This is in contrast to standard PDG unparse techniques [Horwitz et al. 90] <ref> [Larus 89] </ref>. A working implementation of a restructuring tool. Successfully implementing a restructuring tool validated the claim that a restructuring transformation can be invoked locally by the engineer and compensated by a tool to preserve meaning.
Reference: [Lehman 80] <author> M. M. Lehman. </author> <title> On understanding laws, evolution and conservation in the large-program life cycle. </title> <journal> J. Systems and Software, </journal> <volume> 1(3), </volume> <year> 1980. </year> <note> Page citations from reprint in M. </note> <editor> M. Lehman, L. A. Belady, editors, </editor> <title> Program Evolution: </title> <booktitle> Processes of 165 Software Change, Ch. 18, APIC Studies in Data Processing No. </booktitle> <volume> 27. </volume> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: Planning and control of the 2 maintenance and change process should seek to ensure the most cost-effective balance between functional and structural maintenance over the lifetime of the program. Models, methods and tools are required to facilitate achieving such balance <ref> [Lehman 80, p. 383] </ref>. The structural principle of information hiding is used for the initial design of a system to isolate each design decision that is likely to change in a module. Effective isolation increases software flexibility by reducing the cost of changing these volatile choices [Par-nas 72].
Reference: [Lewis 90] <author> T. Lewis, </author> <title> editor. </title> <journal> IEEE Computer. IEEE Computer Society, </journal> <note> January 1990. Special Issue on Software Engineering, </note> <author> W. M. Osborne, E. J. </author> <note> Chikofsky special Eds. </note>
Reference-contexts: Program understanding techniques|also sometimes called reverse engineering|such as graphical display of program structure [Cleveland 89], inferring abstractions [Rich & Waters 88], or assessing modularity [Schwanke 91][Embley & Woodfield 88] are used to extract program information in a more understandable or reusable form <ref> [Lewis 90] </ref>. Improving a programmer's understanding of a system makes its existing structure clearer|and hence better|just by making it better understood [Belady & Lehman 71] [Arnold 86]. Recall this is modeled by DAL in Belady and Lehman's maintenance cost equation (See Chapter 1.4.2).
Reference: [Lieberherr et al. 88] <author> K. Lieberherr, I. Holland, and A. Riel. </author> <title> Object-oriented programming: an objective sense of style. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <pages> pages 323-334, </pages> <month> November </month> <year> 1988. </year> <journal> SIGPLAN Notices 23(11). </journal>
Reference-contexts: Similar solutions to those in scope-sub-call can be 1 A variation of this example and the ones following were suggested in the context of describing transformations that can be used to assure a program obeys the Law of Demeter <ref> [Lieberherr et al. 88] </ref>. 149 used, such as using the output type or the usage of the initially selected expression (0.5) to narrow the possibilities. These would work for the example above, but since the algorithm is a heuristic, final approval of the tool's choice by the engineer is necessary. <p> One possible conflict for popping a method is that each subclass version of the method has an embedded constant in its version that is different from the others <ref> [Lieberherr et al. 88] </ref>.
Reference: [Lientz & Swanson 80] <author> B. Lientz and E. Swanson. </author> <booktitle> Software Maintenance Management: </booktitle>
Reference-contexts: This section develops a maintenance cost model accommodating restructuring. It is common knowledge that maintenance is the most expensive component of the overall software process, running as high as 70% <ref> [Lientz & Swanson 80] </ref>. Belady and Lehman have related software structure and the cost of maintenance at the macro level of detail, providing an equation that relates system age, structure, and maintenance costs. Parnas's work is less quantitative, but provides guidelines for building structurally robust programs. <p> Chapter 8 Conclusion Maintenance is the most expensive component of the software process <ref> [Lientz & Swanson 80] </ref>. The structure of a program significantly influences the cost of its maintenance. Restructuring a program can isolate a design decision in a module so that changing it will not require costly non-local changes. Automating the non-local activities of restructuring to make it cost-effective shows promise.
References-found: 46

