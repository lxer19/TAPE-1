URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-641.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: MIT/LCS/TR-641 On-Line Algorithms for Robot Navigation and Server Problems  
Author: Jon M. Kleinberg 
Affiliation: MIT Laboratory for Computer Science.  
Note: This document has been made available free of charge via ftp from the  
Date: May 1994  
Abstract-found: 0
Intro-found: 1
Reference: [AA] <author> N. Alon, Y. Azar, </author> <title> "On-line Steiner trees in the Euclidean plane," </title> <booktitle> Proc. 8th ACM Symposium on Computational Geometry, </booktitle> <year> 1992, </year> <pages> pp. 337-343. </pages>
Reference-contexts: Alon and Azar <ref> [AA] </ref> subsequently showed that in the Euclidean plane, no on-line Steiner tree algorithm can be better than ( log n log log n )-competitive, leaving a slight gap between the upper and lower bounds in this case. 2.4 Robot Navigation Maze-solving is an old obsession.
Reference: [AAFPW] <author> J. Aspnes, Y. Azar, A. Fiat, S. Plotkin, O. Waarts, </author> <title> "On-line machine scheduling with applications to load balancing and virtual circuit routing," </title> <booktitle> Proc. 25th ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 623-631. </pages>
Reference-contexts: Typically, A is trying to minimize the congestion in the network; thus, the cost incurred by A could be the maximum amount of bandwidth that passes through any link of G at any point in time. The above description is essentially of the model considered in <ref> [AAFPW] </ref>, and in [AAPW] when the duration of the connection is unknown but re-routing is allowed.
Reference: [AAP] <author> B. Awerbuch, Y. Azar, S. Plotkin, </author> <title> "Throughput-competitive on-line routing," </title> <booktitle> Proc. 34th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1993. </year>
Reference-contexts: An alternative, but similar, scenario is the following: the network does not have sufficient bandwidth to handle all 20 requests; thus the on-line algorithm A must first decide whether to accept the connection, and if so, to route it through the network. This is the set-up considered in <ref> [AAP, ABFR] </ref>; a closely related problem is that of scheduling "intervals" on a line [LT]. One recurring theme in this work is that randomized algorithms often can achieve competitive ratios that are exponentially better than the lower bound for deterministic algorithms.
Reference: [AAPW] <author> B. Awerbuch, Y. Azar, S. Plotkin, O. Waarts, </author> <title> "Competitive routing of virtual circuits with unknown duration," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Typically, A is trying to minimize the congestion in the network; thus, the cost incurred by A could be the maximum amount of bandwidth that passes through any link of G at any point in time. The above description is essentially of the model considered in [AAFPW], and in <ref> [AAPW] </ref> when the duration of the connection is unknown but re-routing is allowed.
Reference: [ABFR] <author> B. Awerbuch, Y. Bartal, A. Fiat, A. Rosen, </author> <title> "Competitive non-preemptive call control," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: An alternative, but similar, scenario is the following: the network does not have sufficient bandwidth to handle all 20 requests; thus the on-line algorithm A must first decide whether to accept the connection, and if so, to route it through the network. This is the set-up considered in <ref> [AAP, ABFR] </ref>; a closely related problem is that of scheduling "intervals" on a line [LT]. One recurring theme in this work is that randomized algorithms often can achieve competitive ratios that are exponentially better than the lower bound for deterministic algorithms.
Reference: [BCR] <author> R. Baeza-Yates, J. Culberson, G. Rawlins, </author> <title> "Searching in the plane," </title> <journal> Information and Computation, </journal> <volume> 106(1993), </volume> <pages> pp. 234-252. </pages>
Reference-contexts: Baeza-Yates, Culberson, and Rawlins <ref> [BCR] </ref>, in one of the first papers in this area, considered the latter type of search problem. <p> In Chapter 3, we consider more geometric versions of this search problem | specifically the problem of a robot searching for a goal in an unknown rectilinear polygon. This differs from the model of <ref> [BCR] </ref> in that the structure of the space to be searched is not known to the robot; the generality of rectilinear polygons also makes possible a much wider class of search spaces. The search algorithm we give is fairly natural, performing exploration on larger and larger regions of the polygon. <p> We argue that localization is a natural setting in which to apply the competitive analysis of on-line algorithms; 10 the distance traveled by the robot is compared to the length of the shortest possible localizing tour. The search strategies of <ref> [BCR] </ref> allow one to obtain a fairly straightforward, and nonoptimal, localization algorithm; our main result here is an algorithm which makes stronger use of the robot's knowledge of the map in order to improve asymptotically on this approach. <p> The recent incorporation of navigation problems into the setting of competitive analysis comes mainly from the work of Baeza-Yates, Culberson, and Rawlins <ref> [BCR] </ref>, and Papadimitriou and Yannakakis [PY]. [BCR] does not speak directly in terms of the competitive ratio, but its focus on the ratio of the robot's distance traveled to the length of the shortest path is clear enough. <p> The recent incorporation of navigation problems into the setting of competitive analysis comes mainly from the work of Baeza-Yates, Culberson, and Rawlins <ref> [BCR] </ref>, and Papadimitriou and Yannakakis [PY]. [BCR] does not speak directly in terms of the competitive ratio, but its focus on the ratio of the robot's distance traveled to the length of the shortest path is clear enough. <p> A fundamental technique introduced in <ref> [BCR] </ref> is that of spiral search | an uncomplicated idea which has proved to be a valuable building block in numerous on-line algorithms. <p> Thus, the robot travels at most 8n times the length of the shortest path. In <ref> [BCR] </ref> it is shown that by modifying these parameters a little, one achieve a competitive ratio of 2en o (n), and that this is optimal up to low-order terms. <p> Recently, it has been used in many of the robot search papers we will discuss below <ref> [BCR, PY, BRaSc, KRT, Kl] </ref>, an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat <p> the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed <ref> [BCR] </ref> and deals with navigation problems that are somewhat less stylized. Specifically, they consider a robot with vision moving around in a plane filled with rectangular obstacles. <p> Less work has been done on geometric problems more in the spirit of <ref> [BCR] </ref> | that is, trying 24 to find a short path to a goal t when neither the map of the environment nor the location of t is known. This will be the subject of Chapter 3. <p> As discussed in the previous chapter, on-line search algorithms have generally been developed for situations in which the geometry is kept to a minimum | for example, the case of searching for a point on one of m concurrent rays <ref> [BCR, KRT, KMSY] </ref>, a line in the plane, or a point in an integer lattice [BCR]. <p> chapter, on-line search algorithms have generally been developed for situations in which the geometry is kept to a minimum | for example, the case of searching for a point on one of m concurrent rays [BCR, KRT, KMSY], a line in the plane, or a point in an integer lattice <ref> [BCR] </ref>. Moreover, the structure of the space to be searched is assumed to be known | only the location of the target is unknown. [BCR] writes, ": : : these problems are (very simple) models of searching in the real-world. <p> of searching for a point on one of m concurrent rays [BCR, KRT, KMSY], a line in the plane, or a point in an integer lattice <ref> [BCR] </ref>. Moreover, the structure of the space to be searched is assumed to be known | only the location of the target is unknown. [BCR] writes, ": : : these problems are (very simple) models of searching in the real-world. <p> identify the number of essential cuts of P [CN, DKP] as a fundamental parameter in determining the best competitive ratio attainable in searching P | it is easy to cast the problem of searching m concurrent rays as a search problem in a polygon with m essential cuts, whence the <ref> [BCR] </ref> lower bound of 2em o (m) on competitive ratio applies (e 26 is being used to denote the base of the natural logarithm here). <p> As mentioned in the introduction, O (m) is the best bound possible on the competitive ratio: if we take the polygon P m of Figure 3-3, make the m "arms" extremely long, and introduce tiny bends to limit visibility, then the <ref> [BCR] </ref> lower bound for searching m concurrent rays applies | no deterministic algorithm can be better than (2em o (m))-competitive. (An (m) lower bound clearly holds for randomized algorithms as well, with a somewhat smaller constant.) We first assemble some basic lemmas that will be useful in analyzing the exploration algo <p> Arguably the most natural way to design a localization algorithm for either of these environments is the spiral search technique of Baeza-Yates, Culberson, and Rawlins <ref> [BCR] </ref>. For our purposes here, spiral search could be implemented by having the robot iteratively explore all points of the environment within distance 1; 2; 4; : : :; 2 j ; : : :, until it knows where it is; the resulting algorithm will be O (n)-competitive. <p> Indeed a great deal of work is often done to determine what these constant factors are <ref> [BCR, KRT, KMSY] </ref>. But the fact remains that no algorithm can be better than (n)-competitive for many of these problems. <p> Step 1: Restricted Spiral Search The robot first wakes up at some initial location fl 0 2 T 0 and begins performing spiral search <ref> [BCR] </ref>. This can be described as follows: the robot starts at fl 0 and performs successive depth-first searches so as to see all points within distance 2 j of Z (fl 0 ), for j = 0; 1; 2; : : :.
Reference: [BBFY] <author> E. Bar-Eli, P. Berman, A. Fiat, P. Yan, </author> <title> "On-line navigation in a room," </title> <booktitle> Proc. 3rd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1992, </year> <pages> pp. 237-249. </pages>
Reference-contexts: somehow reverse this process and find a path to t of length O (n)? [BRaSc] left this as an open question, providing only an algorithm to generate a path of length O (n2 p log n ); the question was answered a year later by Bar-Eli, Berman, Fiat, and Yan <ref> [BBFY] </ref>, who showed by a very complicated argument that no on-line algorithm can be guaranteed to find a path shorter than (n log n), and gave an algorithm with a performance guarantee matching this up to constant factors. <p> If T is an embedded tree, we will use n to denote the number of leaves it has. * Rectangle packings in the plane, comprised of n rectangles <ref> [PY, BRaSc, BBFY, BRiSi] </ref>. Recall from Chapter 2 that we assume all rectangles have at least unit thickness, and that there is always just enough room for the robot to move between neighboring rectangles. <p> As these are the only two cases, this completes the proof of Theorem 4.1. 4.3 The Algorithm for Rectangles Again, to keep complications related to visibility to a minimum, we work with a rectangle packing <ref> [BRaSc, BBFY, BRiSi] </ref>, as defined earlier. By a vertex of the environment, we will mean a corner of some rectangle. So in the spirit of the previous section, one could picture a planar graph embedded in the two-dimensional integer grid, all of whose bounded faces are 57 rectangles. <p> What does it take to build a maze? Specifically, it is interesting to ask oneself what constitutes the difference between the "shortest-path" problems of <ref> [PY, BRaSc, BBFY] </ref>, and the geometric search problems [K, Kl] of the type discussed in Chapter 3.
Reference: [Be] <author> R. Bellman, </author> <title> "A minimization problem," </title> <journal> Bulletin of the AMS, </journal> <volume> 62(1956). </volume>
Reference-contexts: These include, for example, the problem of searching for a point on a line or a collection of lines, and the well-known "lost-at-sea" problem, in which one must determine the optimal search pattern for finding a line (the shore) in the plane (the ocean) <ref> [Be, Is] </ref>. A fundamental technique introduced in [BCR] is that of spiral search | an uncomplicated idea which has proved to be a valuable building block in numerous on-line algorithms.
Reference: [BBKTW] <author> S. Ben-David, A. Borodin, R. Karp, G. Tardos, A. Wigderson, </author> <title> "On the power of randomization in on-line algorithms," </title> <booktitle> Proc. 22nd ACM Symposium on Theory of Computing, </booktitle> <year> 1990, </year> <pages> pp. 379-386. </pages>
Reference-contexts: This was settled by Fiat, Rabani, and Ravid [FRR], who gave a general algorithm with a competitive ratio of at most 2 O (k log k) . Grove improved this bound to 2 O (k) [Gr] using a simple randomized algorithm, and derandomization techniques of Ben-David et. al. <ref> [BBKTW] </ref>. And very recently, Koutsoupias and Papadimitriou [KP] have shown that the "work-function algorithm" proposed by Chrobak and Larmore [CL4], as by well as other researchers, is at most (2k 1)-competitive.
Reference: [BRiSi] <author> M. Betke, R. Rivest, M. Singh, </author> <title> "Piecemeal learning of an unknown environment," </title> <booktitle> Proc. Sixth ACM Conference on Learning Theory, </booktitle> <year> 1993, </year> <pages> pp. 277-286. </pages>
Reference-contexts: Betke, Rivest, and Singh <ref> [BRiSi] </ref> consider compact exploration algorithms: the robot always knows the shortest path back to the origin whenever it reaches a new point. <p> If T is an embedded tree, we will use n to denote the number of leaves it has. * Rectangle packings in the plane, comprised of n rectangles <ref> [PY, BRaSc, BBFY, BRiSi] </ref>. Recall from Chapter 2 that we assume all rectangles have at least unit thickness, and that there is always just enough room for the robot to move between neighboring rectangles. <p> As these are the only two cases, this completes the proof of Theorem 4.1. 4.3 The Algorithm for Rectangles Again, to keep complications related to visibility to a minimum, we work with a rectangle packing <ref> [BRaSc, BBFY, BRiSi] </ref>, as defined earlier. By a vertex of the environment, we will mean a corner of some rectangle. So in the spirit of the previous section, one could picture a planar graph embedded in the two-dimensional integer grid, all of whose bounded faces are 57 rectangles. <p> Fortunately, there is a "compact search" subroutine due to Betke, Rivest, and Singh <ref> [BRiSi] </ref> which accomplishes just this. Thus Step 1 will proceed as follows. For successive values of 2 j (j = 0; 1; 2; : : :) the robot explores all points within 2 j of Z (fl 0 ). <p> For successive values of 2 j (j = 0; 1; 2; : : :) the robot explores all points within 2 j of Z (fl 0 ). We implement stage j of this process using a simple modification of the compact search algorithm of <ref> [BRiSi] </ref> | the robot turns back whenever it is about to move more than 2 j from fl 0 . 58 Lemma 4.12 At the end of Step 1, the robot has traveled O (b (R 0 )) times the length of the optimal solution. Proof. The main result of [BRiSi] <p> <ref> [BRiSi] </ref> | the robot turns back whenever it is about to move more than 2 j from fl 0 . 58 Lemma 4.12 At the end of Step 1, the robot has traveled O (b (R 0 )) times the length of the optimal solution. Proof. The main result of [BRiSi] is that the robot will travel at most 10 times the total length of all edges in the region searched.
Reference: [BC] <author> A. Blum, P. Chalasani, </author> <title> "An on-line algorithm for improving performance in navigation," </title> <booktitle> Proc. 34th IEEE Symposium on Theory of Computing, </booktitle> <year> 1993. </year>
Reference-contexts: Such problems tend to contain interesting structure that can be exploited when designing algorithms, and often provide insight into the value of a map in performing navigation tasks. Another example of this is the k-trip shortest-path problem considered by Blum and Chalasani <ref> [BC] </ref>. Here the robot wishes to make k trips between points s and t while minimizing the average time per trip; thus it can make use of partial maps of the scene on later trips. <p> But many naturally arising robotics problems involve navigation when the robot has some limited information about its relation to the environment. The localization problem is a step in this direction, as are the papers of Donald [Don] and Blum and Chalasani <ref> [BC] </ref>. As in the case of several other on-line problems, there are numerous "design choices" one faces when formulating a navigation problem of the variety studied here. We believe it is important in this process to keep in mind the problems faced by designers of autonomous mobile robots.
Reference: [BCCPRS] <author> A. Blum, P. Chalasani, D. Coppersmith, W. Pulleyblank, P. Raghavan, M. Sudan, </author> <title> "The minimum latency problem," </title> <booktitle> Proc. 26th ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 163-171. </pages>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems <ref> [BCCPRS, TWSY] </ref>. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat less stylized. Specifically, they consider a robot with vision moving around in a plane filled with rectangular obstacles.
Reference: [BRaSc] <author> A. Blum, P. Raghavan, B. Schieber, </author> <title> "Navigating in unfamiliar geometric terrain," </title> <booktitle> Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <year> 1991, </year> <pages> pp. 494-504. </pages>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below <ref> [BCR, PY, BRaSc, KRT, Kl] </ref>, an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat <p> For the case of an arbitrary rectangle packing, no bounded competitive ratio is possible: [PY] shows a lower bound of ( p n) on the best possible competitive ratio. Blum, Raghavan, and Schieber <ref> [BRaSc] </ref> address the same type of shortest-paths problems and give an O ( p n)-competitive algorithm for the s-t path problem in a rectangle packing; this matches the lower bound of [PY] up to constant factors. [BRaSc] also introduced the elegant "room problem" | consider a rectangle packing inside a large <p> Blum, Raghavan, and Schieber <ref> [BRaSc] </ref> address the same type of shortest-paths problems and give an O ( p n)-competitive algorithm for the s-t path problem in a rectangle packing; this matches the lower bound of [PY] up to constant factors. [BRaSc] also introduced the elegant "room problem" | consider a rectangle packing inside a large 2n fi 2n square room (so there is space to move along the walls as well), such that the center of the room is in free space. <p> But can the robot starting at s somehow reverse this process and find a path to t of length O (n)? <ref> [BRaSc] </ref> left this as an open question, providing only an algorithm to generate a path of length O (n2 p log n ); the question was answered a year later by Bar-Eli, Berman, Fiat, and Yan [BBFY], who showed by a very complicated argument that no on-line algorithm can be guaranteed <p> If T is an embedded tree, we will use n to denote the number of leaves it has. * Rectangle packings in the plane, comprised of n rectangles <ref> [PY, BRaSc, BBFY, BRiSi] </ref>. Recall from Chapter 2 that we assume all rectangles have at least unit thickness, and that there is always just enough room for the robot to move between neighboring rectangles. <p> As these are the only two cases, this completes the proof of Theorem 4.1. 4.3 The Algorithm for Rectangles Again, to keep complications related to visibility to a minimum, we work with a rectangle packing <ref> [BRaSc, BBFY, BRiSi] </ref>, as defined earlier. By a vertex of the environment, we will mean a corner of some rectangle. So in the spirit of the previous section, one could picture a planar graph embedded in the two-dimensional integer grid, all of whose bounded faces are 57 rectangles. <p> What does it take to build a maze? Specifically, it is interesting to ask oneself what constitutes the difference between the "shortest-path" problems of <ref> [PY, BRaSc, BBFY] </ref>, and the geometric search problems [K, Kl] of the type discussed in Chapter 3. <p> Thus, the results of <ref> [BRaSc] </ref> show that the class of rectangles is not maze-inducing. On the other hand, it is not difficult to build mazes when F is the set of all rectilinear polygons (with at least unit thickness).
Reference: [BK] <author> M. Blum, D. Kozen, </author> <title> "On the power of the compass (or, Why mazes are easier to search than graphs)," </title> <booktitle> Proc. 19th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1978, </year> <pages> pp. 132-142. </pages>
Reference-contexts: Maze-solving algorithms phrased in the terminology of graphs can be found in work of Tarry and Tremeaux that reaches back a century and more [Ore]. More recently, such questions have been addressed in the contexts of automata theory by Blum and Kozen <ref> [BK] </ref> and robotics by Lumelsky and Stepanov [LuS]. On-line navigation is concerned with questions somewhat more general than maze-solving: the environment will not always be nefarious, the goal not always to escape. <p> Most of the previous theoretical work on multiple robots is somewhat orthogonal to these concerns; it has tended to deal with computation-ally limited robots that use one another mainly for "pebbling" purposes (see e.g. <ref> [BK] </ref> and the references therein). We are interested in the following sort of problem.
Reference: [BIRS] <author> A. Borodin, S. Irani, P. Raghavan, and B. Schieber, </author> <title> "Competitive paging with locality of reference", </title> <booktitle> Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <year> 1991, </year> <pages> pp. 249-259. </pages>
Reference-contexts: Various extensions to the model of [ST] have been proposed <ref> [BIRS, KPR] </ref>, but the question of why on-line paging works so well in real life remains an intriguing one.
Reference: [BLS] <author> A. Borodin, N. Linial, M. Saks, </author> <title> "An optimal on-line algorithm for metrical task systems," </title> <journal> Journal of the ACM, </journal> <volume> 39(1992), </volume> <pages> pp. 745-763. </pages>
Reference-contexts: Following [ST], the paper [KMRS] analyzed additional on-line strategies for cache management (which is essentially the same as paging in this model), and <ref> [BLS] </ref> proposed "metrical task systems" as an abstract model for studying on-line algorithms. The following year, Manasse, McGeoch, and Sleator [MMS] introduced what has become perhaps the most well-known and well-studied on-line problem: the k-server problem. 2.2 The k-Server Problem We imagine the following situation.
Reference: [CN] <author> W. Chin, S. Ntafos, </author> <title> "Shortest watchman routes in simple polygons," </title> <journal> Discrete and Computational Geometry, </journal> <volume> 6(1991), </volume> <pages> pp. 9-31. </pages>
Reference-contexts: The off-line version of this problem (what is the shortest path for exploring a given polygon P ?) is perhaps better motivated as the "Shortest Watchman's Route Problem"; Chin and Ntafos <ref> [CN] </ref> give a polynomial-time algorithm for computing such a route, and some of their definitions are used in the algorithm of [DKP]. Betke, Rivest, and Singh [BRiSi] consider compact exploration algorithms: the robot always knows the shortest path back to the origin whenever it reaches a new point. <p> Thus, the robot must adapt its search pattern as it sees more and more of the polygon. For a given rectilinear polygon P , we identify the number of essential cuts of P <ref> [CN, DKP] </ref> as a fundamental parameter in determining the best competitive ratio attainable in searching P | it is easy to cast the problem of searching m concurrent rays as a search problem in a polygon with m essential cuts, whence the [BCR] lower bound of 2em o (m) on competitive <p> Thus we can show Theorem 3.8 When P is rectilinear, the above algorithm is p 2-competitive, and this is optimal. 3.2 Exploring a Rectilinear Polygon First, we present some basic definitions of <ref> [CN, DKP] </ref> on the structure of rectilinear polygons. In this and the remaining sections, distances will be measured in the L 1 metric. b) Polygon P m s horizon essential cut essential cut a) Let P be a simple rectilinear polygon and s a distinguished point in P . <p> The robot does not know the map of P in advance. As noted in <ref> [CN, DKP] </ref> (see also the discussion above), a closed path through s has this property if and only if it touches all essential cuts in P . In [CN, DKP], it is observed that since any exploration route can be traversed (off-line) without self-crossings, the shortest exploration route will touch the <p> The robot does not know the map of P in advance. As noted in <ref> [CN, DKP] </ref> (see also the discussion above), a closed path through s has this property if and only if it touches all essential cuts in P . In [CN, DKP], it is observed that since any exploration route can be traversed (off-line) without self-crossings, the shortest exploration route will touch the essential cuts in clockwise order. Moreover, by Lemma 3.9, it will touch the cuts in this order using the greedy algorithm.
Reference: [CKPV] <author> M. Chrobak, H. Karloff, T. Payne, S. Vishwanathan, </author> <title> "New results on server problems," </title> <journal> SIAM J. Discrete Math., </journal> <volume> 4(1991), </volume> <pages> pp. 172-181. </pages>
Reference-contexts: This considerably extends the class of metric spaces known to have optimal real-time algorithms; the technique we use can be seen as a higher-dimensional generalization of the elegant "Double-Coverage" algorithm discovered for k servers on a line by Chrobak, Karloff, Payne, and Vishwanathan <ref> [CKPV] </ref>. We also prove a lower bound 11 for 2-server balancing algorithms, a sub-class of the real-time algorithms. Balancing algorithms have been proposed for a number of special cases of the k-server problem; they are so named because they seek to "balance" the distance traveled evenly among the servers. <p> In a separate direction, a number of papers extended the set of metric spaces for which good server algorithms were known. Chrobak, Karloff, Payne, and Vishwanathan <ref> [CKPV] </ref> gave an elegant k-competitive algorithm for k servers on the line (i.e. M = R 1 ). The algorithm works as follows: let [a; b] denote the interval on the line whose left endpoint is the leftmost server and whose right endpoint is the rightmost server. <p> of OP T 's servers, and M min the minimum of s 1 o 1 + s 2 o 2 and s 1 o 2 + s 2 o 1 (i.e. it is the minimum-cost matching between the servers of A and OP T .) The potential function used in <ref> [CKPV] </ref> is an adaptation of one used by Coppersmith, Doyle, Raghavan, and Snir [CDRS]; 18 for our purposes, we can write it as = 2M min + s 1 s 2 : Clearly is always non-negative. <p> First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature [MMS, CL1, CL4] | and a number of constant-time algorithms have been analyzed <ref> [IR, CL2, CKPV] </ref>. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> This result considerably extends the class of metric spaces for which there is known to be a fast, optimal algorithm. Moreover, the original real-time 2-competitive algorithm for trees was based on a very elegant memoryless strategy, "Double-Coverage," that was first discovered for servers on a line <ref> [CKPV] </ref> (this algorithm was discussed in Chapter 2). However, attempts to extend this technique to produce optimal deterministic algorithms in spaces more general than trees had so far not been successful. <p> This rule was shown to be k-competitive for k servers when the cardinality of the request space M is k + 1 [MMS], and for the "weighted 66 cache" problem, which includes the paging problem as a special case <ref> [CKPV] </ref>. However, the algorithm does not achieve any constant competitive ratio, even for two servers, in a general metric space M . Thus it was somewhat surprising that a rule minimizing the quantity D i + 2rs i was shown to be 10-competitive for two servers [IR]. <p> When the adversary moves, paying c, it can raise by at most 2c. 2. When the algorithm moves, paying c 0 , it lowers by at least c 0 . The first of these facts holds in any metric space, and has been proved in earlier papers <ref> [CKPV, CL3, CDRS] </ref>; the argument is simply that the value of the minimum-cost matching goes up by at most c 0 while the first term of is untouched. Now consider the second fact. We break the behavior of the algorithm into two phases.
Reference: [CL1] <author> M. Chrobak, L. Larmore, </author> <title> "A new approach to the server problem," </title> <journal> SIAM J. Discrete Math., </journal> <volume> 4(1991), </volume> <pages> pp. 323-328. </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld [IR] and Chrobak and Larmore [CL2]. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 <ref> [MMS, CL1, CL4] </ref>, the best known competitive ratio for a real-time algorithm is 4 [CL2]. In Chapter 5, we give a real-time 2-server algorithm which is 2-competitive in n-dimensional space under the L 1 ("Manhattan") metric. <p> been known since the origin of the problem that there is a 2-competitive, on-line algorithm for two servers in a general metric space, and that no on-line algorithm can achieve a better ratio. (Other 2-competitive 2-server algorithms, based on quite different techniques, have been given by Chrobak and Larmore in <ref> [CL1, CL4] </ref>.) Thus the emphasis here has been to give competitive algorithms that are as "simple" as possible | simple both in the effort required to analyze them, and in the amount of computation they must perform on each request. <p> The 2-server problem appears to be a good one on which to try out these notions. First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature <ref> [MMS, CL1, CL4] </ref> | and a number of constant-time algorithms have been analyzed [IR, CL2, CKPV]. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> Observe that we make no restrictions whatsoever on the nature of the function f . Our main result is a lower bound of (5 + p 7)=2 (~ 3:82) on the competitive ratio of any such balancing algorithm for two servers. In view of the 2-competitive algorithms of <ref> [MMS, CL1, CL4] </ref>, this shows that no optimal on-line 2-server algorithm can be expressed as a decision rule B f for any f . To our knowledge, this represents one of the first lower bounds for on-line algorithms based solely on computational resources. We use the following notation.
Reference: [CL2] <author> M. Chrobak, L. Larmore, </author> <title> "On fast algorithms for two servers," </title> <journal> J. Algorithms, </journal> <volume> 12(1991), </volume> <pages> pp. 607-614. </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld [IR] and Chrobak and Larmore <ref> [CL2] </ref>. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 [MMS, CL1, CL4], the best known competitive ratio for a real-time algorithm is 4 [CL2]. <p> to the 2-server problem, by Irani and Rubinfeld [IR] and Chrobak and Larmore <ref> [CL2] </ref>. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 [MMS, CL1, CL4], the best known competitive ratio for a real-time algorithm is 4 [CL2]. In Chapter 5, we give a real-time 2-server algorithm which is 2-competitive in n-dimensional space under the L 1 ("Manhattan") metric. <p> A "fast" 2-server algorithm with a competitive ratio of 4 was subsequently given by Chrobak and Larmore <ref> [CL2] </ref>. <p> First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature [MMS, CL1, CL4] | and a number of constant-time algorithms have been analyzed <ref> [IR, CL2, CKPV] </ref>. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> None of the known optimal 2-server algorithms have this property; for example, in an infinite metric space such as R d , they slow down with each additional request. Indeed, currently the best real-time algorithm known has a competitive ratio of 4 <ref> [CL2] </ref> (improving on a 10-competitive algorithm [IR]); and until now, the only known metric spaces in which a fast algorithm could achieve the optimal ratio of 2 were those which could be embedded in a tree. <p> Thus it was somewhat surprising that a rule minimizing the quantity D i + 2rs i was shown to be 10-competitive for two servers [IR]. A later construction showed that this algorithm is no better than 6-competitive <ref> [CL2] </ref>. Here, we show a new lower bound for the class of balancing algorithms in general. <p> It is clear that a very similar construction involving metric space M 2 shows that if f = 1, then B f is not competitive. The final lemma is based on a construction in <ref> [CL2] </ref>. Lemma 5.9 If f = p &gt; 1, then (B f ) 3p=(p 1). Proof.
Reference: [CL3] <author> M. Chrobak, L. Larmore, </author> <title> "An optimal on-line algorithm for k-servers on trees," </title> <journal> SIAM J. Computing, </journal> <volume> 20(1991), </volume> <pages> pp. 144-148. 83 </pages>
Reference-contexts: Subsequently, Chrobak and Larmore showed that a natural generalization of this algorithm for the case in which M is a tree is also k-competitive <ref> [CL3] </ref>. The proof that this algorithm is k-competitive makes use of a short, if somewhat mysterious, 17 potential function argument. We describe the proof for the case of two servers on a line, since it provides a good example of how such a proof proceeds. <p> When the adversary moves, paying c, it can raise by at most 2c. 2. When the algorithm moves, paying c 0 , it lowers by at least c 0 . The first of these facts holds in any metric space, and has been proved in earlier papers <ref> [CKPV, CL3, CDRS] </ref>; the argument is simply that the value of the minimum-cost matching goes up by at most c 0 while the first term of is untouched. Now consider the second fact. We break the behavior of the algorithm into two phases.
Reference: [CL4] <author> M. Chrobak, L. Larmore, </author> <title> "The server problem and on-line games," in On-Line Algo--rithms, </title> <editor> D. Sleator and L. McGeoch, Eds., </editor> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science (vol. </booktitle> <volume> 7), </volume> <year> 1992, </year> <pages> pp. 11-64. </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld [IR] and Chrobak and Larmore [CL2]. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 <ref> [MMS, CL1, CL4] </ref>, the best known competitive ratio for a real-time algorithm is 4 [CL2]. In Chapter 5, we give a real-time 2-server algorithm which is 2-competitive in n-dimensional space under the L 1 ("Manhattan") metric. <p> Grove improved this bound to 2 O (k) [Gr] using a simple randomized algorithm, and derandomization techniques of Ben-David et. al. [BBKTW]. And very recently, Koutsoupias and Papadimitriou [KP] have shown that the "work-function algorithm" proposed by Chrobak and Larmore <ref> [CL4] </ref>, as by well as other researchers, is at most (2k 1)-competitive. In a separate direction, a number of papers extended the set of metric spaces for which good server algorithms were known. <p> been known since the origin of the problem that there is a 2-competitive, on-line algorithm for two servers in a general metric space, and that no on-line algorithm can achieve a better ratio. (Other 2-competitive 2-server algorithms, based on quite different techniques, have been given by Chrobak and Larmore in <ref> [CL1, CL4] </ref>.) Thus the emphasis here has been to give competitive algorithms that are as "simple" as possible | simple both in the effort required to analyze them, and in the amount of computation they must perform on each request. <p> The 2-server problem appears to be a good one on which to try out these notions. First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature <ref> [MMS, CL1, CL4] </ref> | and a number of constant-time algorithms have been analyzed [IR, CL2, CKPV]. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> Observe that we make no restrictions whatsoever on the nature of the function f . Our main result is a lower bound of (5 + p 7)=2 (~ 3:82) on the competitive ratio of any such balancing algorithm for two servers. In view of the 2-competitive algorithms of <ref> [MMS, CL1, CL4] </ref>, this shows that no optimal on-line 2-server algorithm can be expressed as a decision rule B f for any f . To our knowledge, this represents one of the first lower bounds for on-line algorithms based solely on computational resources. We use the following notation.
Reference: [CDRS] <author> D. Coppersmith, P. Doyle, P. Raghavan, M. Snir, </author> <title> "Random walks on weighted graphs, with applications to on-line algorithms," </title> <journal> Journal of the ACM, </journal> <volume> 40(1993), </volume> <pages> pp. 421-453. </pages>
Reference-contexts: o 1 + s 2 o 2 and s 1 o 2 + s 2 o 1 (i.e. it is the minimum-cost matching between the servers of A and OP T .) The potential function used in [CKPV] is an adaptation of one used by Coppersmith, Doyle, Raghavan, and Snir <ref> [CDRS] </ref>; 18 for our purposes, we can write it as = 2M min + s 1 s 2 : Clearly is always non-negative. When OP T moves a distance d, it cannot affect the second term, and it increases the first term by at most 2d. <p> We move both servers toward y until s 1 reaches it; now s 2 is no longer minimal. Theorem 5.2 The above algorithm is 2-competitive in the L 1 plane. Proof. We analyze the algorithm's performance using the cdrs potential function <ref> [CDRS] </ref> = s 1 s 2 + 2M min (S; OP T ); where M min (S; OP T ) denotes the value of the minimum-cost matching between the adversary servers and the on-line servers, and s 1 s 2 is, as before, the distance between s 1 and s 2 <p> When the adversary moves, paying c, it can raise by at most 2c. 2. When the algorithm moves, paying c 0 , it lowers by at least c 0 . The first of these facts holds in any metric space, and has been proved in earlier papers <ref> [CKPV, CL3, CDRS] </ref>; the argument is simply that the value of the minimum-cost matching goes up by at most c 0 while the first term of is untouched. Now consider the second fact. We break the behavior of the algorithm into two phases.
Reference: [Cox] <author> I. Cox, </author> <title> "Blanche an experiment in guidance and navigation of an autonomous robot vehicle," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> 7(1991), </volume> <pages> pp. 193-204. </pages>
Reference-contexts: Thus the robot's path is O (m) times d (s; t), as required. 41 Chapter 4 The Robot Localization Problem A fundamental task for an autonomous mobile robot is that of localization | determining its location in a known environment <ref> [Cox, TPBHSS, Wang] </ref>. <p> One application is in the design of robot vehicles that must perform a certain task repeatedly in the same environment. Here, localization is used to determine the starting location at the beginning of the task, and to maintain positioning information over time <ref> [Cox, Dr, Wang] </ref>. A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers [MAWM, SN].
Reference: [DKP] <author> X. Deng, T. Kameda, C. Papadimitriou, </author> <title> "How to learn an unknown environment I: the rectilinear case," </title> <type> Technical Report CS-93-04, </type> <institution> Department of Computer Science, York University. </institution> <note> (Preliminary version in Proc. 32nd IEEE Symposium on Foundations of Computer Science, </note> <year> 1991, </year> <pages> pp. 298-303.) </pages>
Reference-contexts: The search algorithm we give is fairly natural, performing exploration on larger and larger regions of the polygon. This problem of exploration in a simple rectilinear polygon has been considered separately by Deng, Kameda, and Papadimitriou <ref> [DKP] </ref>, who gave an algorithm with a competitive ratio of 2; we offer a simple randomized variant with competitive ratio 5=4. It is also interesting to consider special cases of the search problem in a polygon | restricting the type of polygon so that better competitive ratios can be obtained. <p> Here, the goal is to traverse a path that sees all parts of the environment, both the obstacles and the free space. For the problem of exploring the interior (or exterior) of a simple rectilinear polygon, Deng, Kameda, and Papadimitriou <ref> [DKP] </ref> give a 2-competitive algorithm. <p> version of this problem (what is the shortest path for exploring a given polygon P ?) is perhaps better motivated as the "Shortest Watchman's Route Problem"; Chin and Ntafos [CN] give a polynomial-time algorithm for computing such a route, and some of their definitions are used in the algorithm of <ref> [DKP] </ref>. Betke, Rivest, and Singh [BRiSi] consider compact exploration algorithms: the robot always knows the shortest path back to the origin whenever it reaches a new point. <p> Thus, the robot must adapt its search pattern as it sees more and more of the polygon. For a given rectilinear polygon P , we identify the number of essential cuts of P <ref> [CN, DKP] </ref> as a fundamental parameter in determining the best competitive ratio attainable in searching P | it is easy to cast the problem of searching m concurrent rays as a search problem in a polygon with m essential cuts, whence the [BCR] lower bound of 2em o (m) on competitive <p> Thus, the natural question is whether there is an algorithm which is O (m)-competitive for the problem of searching an arbitrary simple rectilinear polygon with m essential cuts. In Section 3.3, we present such an algorithm. The algorithm is based on the problem | first considered in <ref> [DKP] </ref> | of exploring a simple rectilinear polygon P , starting from and returning to a fixed point s in P ; we use an exploration algorithm iteratively as the search proceeds. We show in Section 3.2 how an adaptation of the technique in [DKP] gives a randomized algorithm which is <p> the problem | first considered in <ref> [DKP] </ref> | of exploring a simple rectilinear polygon P , starting from and returning to a fixed point s in P ; we use an exploration algorithm iteratively as the search proceeds. We show in Section 3.2 how an adaptation of the technique in [DKP] gives a randomized algorithm which is 5=4-competitive in the L 1 norm when s is any point inside P . <p> Thus we can show Theorem 3.8 When P is rectilinear, the above algorithm is p 2-competitive, and this is optimal. 3.2 Exploring a Rectilinear Polygon First, we present some basic definitions of <ref> [CN, DKP] </ref> on the structure of rectilinear polygons. In this and the remaining sections, distances will be measured in the L 1 metric. b) Polygon P m s horizon essential cut essential cut a) Let P be a simple rectilinear polygon and s a distinguished point in P . <p> The horizons of P which are maximal are called essential cuts; for an essential cut h, it is possible to start at s and follow a path which crosses every horizon except h. See Figure 3-3. A special case of the following lemma is given in <ref> [DKP] </ref>; it is the underlying reason for the success of "greedy" exploration algorithms in rectilinear polygons. Lemma 3.9 Let ff 1 ; : : : ; ff n be a set of horizontal and vertical segments in P , and v a point in P . <p> The robot does not know the map of P in advance. As noted in <ref> [CN, DKP] </ref> (see also the discussion above), a closed path through s has this property if and only if it touches all essential cuts in P . In [CN, DKP], it is observed that since any exploration route can be traversed (off-line) without self-crossings, the shortest exploration route will touch the <p> The robot does not know the map of P in advance. As noted in <ref> [CN, DKP] </ref> (see also the discussion above), a closed path through s has this property if and only if it touches all essential cuts in P . In [CN, DKP], it is observed that since any exploration route can be traversed (off-line) without self-crossings, the shortest exploration route will touch the essential cuts in clockwise order. Moreover, by Lemma 3.9, it will touch the cuts in this order using the greedy algorithm. <p> Moreover, by Lemma 3.9, it will touch the cuts in this order using the greedy algorithm. Consider the case in which the point s lies on the boundary of P , between the endpoints of essential cuts e and e 0 . The on-line algorithm given in <ref> [DKP] </ref> is essentially a greedy strategy which crosses each upcoming horizon as quickly as possible; it is shown in [DKP] that it will traverse the greedy path which touches the essential cuts in clockwise order, beginning with e. <p> The on-line algorithm given in <ref> [DKP] </ref> is essentially a greedy strategy which crosses each upcoming horizon as quickly as possible; it is shown in [DKP] that it will traverse the greedy path which touches the essential cuts in clockwise order, beginning with e. Consequently, this algorithm finds the optimal exploration route on-line; it is 1-competitive when s lies on the boundary of P . <p> It has traveled a distance of 2 to reach A; thus its total distance is 10. On the other hand, the greedy exploration route which visits C first travels a distance of 8. The algorithm given in <ref> [DKP] </ref> is 2-competitive when s is an arbitrary starting point in P , and this is the best known deterministic ratio. In the remainder of this section, we give a simple randomized algorithm whose performance matches the deterministic lower bound of Proposition 3.10. <p> There is some small ffi 0 such that all points within ffi 0 of s are visible from s. By rescaling, we can assume that ffi 0 = 1. For fixed values of ffi, the robot will simulate the algorithm of <ref> [DKP] </ref> in P ffi , as follows. The [DKP] algorithm has the property that at all times, the robot is moving along the coordinate axes, perpendicularly towards an extended edge, and it maintains this direction until it reaches the closest such extended edge e. <p> There is some small ffi 0 such that all points within ffi 0 of s are visible from s. By rescaling, we can assume that ffi 0 = 1. For fixed values of ffi, the robot will simulate the algorithm of <ref> [DKP] </ref> in P ffi , as follows. The [DKP] algorithm has the property that at all times, the robot is moving along the coordinate axes, perpendicularly towards an extended edge, and it maintains this direction until it reaches the closest such extended edge e. <p> By Lemma 3.15, it can see both of the endpoints of the edge e; thus, by Lemma 3.16, it can tell whether e lies in P ffi or not. If e lies in P ffi , the robot moves towards it, as in the <ref> [DKP] </ref> algorithm; otherwise, e is treated as a wall in the simulation. In this way, the exploration route generated by the simulation is the same as the route that the [DKP] algorithm generates in P ffi . Initially, ffi is set to 1. <p> If e lies in P ffi , the robot moves towards it, as in the <ref> [DKP] </ref> algorithm; otherwise, e is treated as a wall in the simulation. In this way, the exploration route generated by the simulation is the same as the route that the [DKP] algorithm generates in P ffi . Initially, ffi is set to 1. Whenever t is first seen, the robot moves directly to it; if the robot explores P ffi without seeing t, then ffi is doubled and the next iteration begins. <p> The results of Chapter 3 apply only to the case of simple rectilinear polygons; i.e. those with no holes. <ref> [DKP] </ref> conjectures that a constant competitive ratio should be attainable 77 for the problem of exploring a rectilinear polygon containing an arbitrary number of rectilinear holes. (They give an algorithm which is O (k)-competitive, where k is the number of holes.) Since a number of variations on this problem are possible,
Reference: [Don] <author> B. Donald, </author> <title> "On information invariants in robotics," </title> <type> Technical Report 93-1341, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1993. </year>
Reference-contexts: For a further perspective on the value of different types of information in performing navigation tasks, see the work of Donald on "information invariants" <ref> [Don] </ref>. The localization algorithm we present is quite natural and simple to state; the difficulty lies in analyzing the competitive ratio. The algorithm performs an initial period of spiral search on a local area which is sufficiently restricted to keep the competitive ratio from getting too large. <p> But many naturally arising robotics problems involve navigation when the robot has some limited information about its relation to the environment. The localization problem is a step in this direction, as are the papers of Donald <ref> [Don] </ref> and Blum and Chalasani [BC]. As in the case of several other on-line problems, there are numerous "design choices" one faces when formulating a navigation problem of the variety studied here.
Reference: [Dr] <author> M. Drumheller, </author> <title> "Mobile robot localization using sonar," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1987), </volume> <pages> pp. 325-331. </pages>
Reference-contexts: One application is in the design of robot vehicles that must perform a certain task repeatedly in the same environment. Here, localization is used to determine the starting location at the beginning of the task, and to maintain positioning information over time <ref> [Cox, Dr, Wang] </ref>. A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers [MAWM, SN].
Reference: [DRW] <author> G. Dudek, K. Romanik, S. Whitesides, </author> <title> "Localizing a robot with minimum travel," </title> <booktitle> Proc. 6th ACM-SIAM Symposium on Discrete Algorithms. </booktitle>
Reference-contexts: Closing this gap remains an interesting open question. In independent work, Dudek, Romanik, and Whitesides <ref> [DRW] </ref> give a geometric implementation of the "shortest-distinguishing-paths" algorithm | which appears as Step 3 in the main algorithm of this chapter | when the environment is a simple polygon.
Reference: [FFKRRV] <author> A. Fiat, D. Foster, H. Karloff, Y. Rabani, Y. Ravid, S. Vishwanathan, </author> <title> "Competitive algorithms for layered graph traversal," </title> <booktitle> Proc. 31st IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 288-197. </pages>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal <ref> [PY, FFKRRV] </ref>, the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat less stylized.
Reference: [FRR] <author> A. Fiat, Y. Rabani, Y. Ravid, </author> <title> "Competitive k-server algorithms," </title> <booktitle> Proc. 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1990. </year>
Reference-contexts: Indeed, it was not known initially whether one could even achieve a constant competitive ratio (depending only on k) in an arbitrary metric space, even for the case of three servers. This was settled by Fiat, Rabani, and Ravid <ref> [FRR] </ref>, who gave a general algorithm with a competitive ratio of at most 2 O (k log k) . Grove improved this bound to 2 O (k) [Gr] using a simple randomized algorithm, and derandomization techniques of Ben-David et. al. [BBKTW].
Reference: [GGU] <author> M. Garey, R. Graham, J. Ullman, </author> <title> "Worst-case analysis of memory allocation algorithms," </title> <booktitle> Proc. 4th ACM Symposium on Theory of Computing, </booktitle> <year> 1972. </year>
Reference-contexts: One such example is First Fit, which puts the object in the first bin in which it will fit, starting a new bin only if necessary. Garey, Graham, and Ullman <ref> [GGU] </ref> proved that the competitive ratio of First Fit is 17 10 , and an almost exact 14 characterization of the performance of First Fit, as well as a number of other approximation algorithms, was given by Johnson in his Ph.D. thesis [J].
Reference: [Gr] <author> E. Grove, </author> <title> "The harmonic on-line k-server algorithm is competitive," </title> <booktitle> Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <year> 1991, </year> <pages> pp. 260-266. 84 </pages>
Reference-contexts: This was settled by Fiat, Rabani, and Ravid [FRR], who gave a general algorithm with a competitive ratio of at most 2 O (k log k) . Grove improved this bound to 2 O (k) <ref> [Gr] </ref> using a simple randomized algorithm, and derandomization techniques of Ben-David et. al. [BBKTW]. And very recently, Koutsoupias and Papadimitriou [KP] have shown that the "work-function algorithm" proposed by Chrobak and Larmore [CL4], as by well as other researchers, is at most (2k 1)-competitive.
Reference: [GMR] <author> L. Guibas, R. Motwani, P. Raghavan, </author> <title> "The robot localization problem in two dimen-sions" Proceedings 3rd ACM-SIAM Symposium on Discrete Algorithms, </title> <booktitle> 1992, </booktitle> <pages> pp 259-268. </pages>
Reference-contexts: Despite the attention that localization has received in the robotics literature, the first theoretical work on it appeared only recently in a paper of Guibas, Motwani, and Raghavan <ref> [GMR] </ref>; they gave geometric algorithms for the first part of the problem | enumerating locations consistent with a view | but did not address the issue of strategies for the second part. <p> Otherwise | if it is in a highly self-repeating environment such as a typical large building | there are a number of different places the robot could be. Guibas, Motwani, and Raghavan <ref> [GMR] </ref> considered the question of enumerating all possible locations for the robot, given a visibility polygon P , when 42 the environment E is itself a simple polygon. <p> In this terminology, we will be considering 44 the latter type of problem. Again, [TPBHSS] describes the role of "reconnaissance" in the localization problem, without providing any concrete algorithms. Theoretical Background The only previous theoretical treatment of the localization problem is the paper of Guibas, Motwani, and Raghavan <ref> [GMR] </ref>, and as mentioned above, it deals only with the "static" version of the question. There has been no previous work on this problem from the perspective of competitive analysis, though there is a straightforward (and non-optimal) algorithm which is not difficult to describe; we will discuss this shortly.
Reference: [HS] <author> M. Halldorsson, M. Szegedy, </author> <title> "Lower bounds for on-line graph coloring," </title> <booktitle> Proc. 3rd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1992, </year> <pages> pp. 211-216. </pages>
Reference-contexts: This question was answered in the affirmative in 1989 by Lovasz, Saks, and Trotter [LST], who gave an on-line algorithm with performance ratio O ( n log fl n ). In terms of lower bounds, Halldorsson and Szegedy <ref> [HS] </ref> showed that for every on-line algorithm A and integer k, there is a graph with at most k (2 k 1) vertices and chromatic number k on which A will use 2 k 1 colors.
Reference: [IK] <author> C. Icking, R. Klein, </author> <title> "The two guards problem," </title> <booktitle> Proc. 7th ACM Symposium on Computational Geometry, </booktitle> <year> 1991. </year>
Reference-contexts: Such an approach has been adopted by Klein in his work on streets. The papers <ref> [IK, K] </ref> introduce the term street to define a class of general (not necessarily rectilinear) polygons with two distinguished points s and t, such that the two st boundary chains are mutually weakly visible (see below for an elaboration on this definition). <p> The removal of s and t would disconnect the boundary into two polygonal chains, L and R. We say that 27 P is a street <ref> [IK, K] </ref> if each point on the boundary of P can see some point on the opposite boundary chain. The goal is for a robot with vision to travel from s to t; neither the map of P nor the coordinates of t are known.
Reference: [IW] <author> M. Imase, B. Waxman, </author> <title> "Dynamic Steiner tree problem," </title> <journal> SIAM J. Discrete Math, </journal> <volume> 4(1991), </volume> <pages> pp. 369-384. </pages>
Reference-contexts: One recurring theme in this work is that randomized algorithms often can achieve competitive ratios that are exponentially better than the lower bound for deterministic algorithms. A somewhat related problem was proposed by Imase and Waxman <ref> [IW] </ref>, though it has been suggested independently in a number of sources. This is the on-line Steiner tree problem: one has a metric space M , and n points in M which must be joined together by a minimum-cost Steiner tree. <p> The on-line/off-line distinction here sort of resembles an "urban growth" phenomenon | after the fact, it is much easier to find a reasonably short spanning network than when the points are appearing one at a time and must be hooked up immediately. <ref> [IW] </ref> shows that the greedy algorithm (when point x is requested, connect it to the existing network via the shortest possible path) is O (log n)-competitive in any metric space; they also present a somewhat contrived metric space M in which no on-line algorithm can be better than (log n)-competitive.
Reference: [Ir] <author> S. Irani, </author> <title> "Coloring inductive graphs on-line," </title> <booktitle> Proc. 31st IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 470-479. </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld <ref> [IR] </ref> and Chrobak and Larmore [CL2]. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 [MMS, CL1, CL4], the best known competitive ratio for a real-time algorithm is 4 [CL2]. <p> Given the nature of the problem, it might not have been unreasonable to have conjectured that this much computation is required to achieve any constant ratio. This is not the case, however. Irani and Rubinfeld <ref> [IR] </ref> gave the first competitive 2-server algorithm which performs only a constant amount of work on each request; its competitive ratio is known to be somewhere between 6 and 10. A "fast" 2-server algorithm with a competitive ratio of 4 was subsequently given by Chrobak and Larmore [CL2]. <p> Thus, no on-line algorithm can be better than ( n log 2 n )-competitive on all graphs. Related work on on-line graph coloring has been done by Irani <ref> [Ir] </ref> and Vishwanathan [Vi]. The problem of virtual circuit routing through a network is naturally on-line, and has been studied from that point of view in a number of recent papers. <p> First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature [MMS, CL1, CL4] | and a number of constant-time algorithms have been analyzed <ref> [IR, CL2, CKPV] </ref>. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> None of the known optimal 2-server algorithms have this property; for example, in an infinite metric space such as R d , they slow down with each additional request. Indeed, currently the best real-time algorithm known has a competitive ratio of 4 [CL2] (improving on a 10-competitive algorithm <ref> [IR] </ref>); and until now, the only known metric spaces in which a fast algorithm could achieve the optimal ratio of 2 were those which could be embedded in a tree. <p> However, the algorithm does not achieve any constant competitive ratio, even for two servers, in a general metric space M . Thus it was somewhat surprising that a rule minimizing the quantity D i + 2rs i was shown to be 10-competitive for two servers <ref> [IR] </ref>. A later construction showed that this algorithm is no better than 6-competitive [CL2]. Here, we show a new lower bound for the class of balancing algorithms in general.
Reference: [IR] <author> S. Irani, R. Rubinfeld, </author> <title> "A competitive 2-server algorithm," </title> <journal> Information Processing Letters, </journal> <volume> 39(1991), </volume> <pages> pp. 85-91. </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld <ref> [IR] </ref> and Chrobak and Larmore [CL2]. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 [MMS, CL1, CL4], the best known competitive ratio for a real-time algorithm is 4 [CL2]. <p> Given the nature of the problem, it might not have been unreasonable to have conjectured that this much computation is required to achieve any constant ratio. This is not the case, however. Irani and Rubinfeld <ref> [IR] </ref> gave the first competitive 2-server algorithm which performs only a constant amount of work on each request; its competitive ratio is known to be somewhere between 6 and 10. A "fast" 2-server algorithm with a competitive ratio of 4 was subsequently given by Chrobak and Larmore [CL2]. <p> Thus, no on-line algorithm can be better than ( n log 2 n )-competitive on all graphs. Related work on on-line graph coloring has been done by Irani <ref> [Ir] </ref> and Vishwanathan [Vi]. The problem of virtual circuit routing through a network is naturally on-line, and has been studied from that point of view in a number of recent papers. <p> First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature [MMS, CL1, CL4] | and a number of constant-time algorithms have been analyzed <ref> [IR, CL2, CKPV] </ref>. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> None of the known optimal 2-server algorithms have this property; for example, in an infinite metric space such as R d , they slow down with each additional request. Indeed, currently the best real-time algorithm known has a competitive ratio of 4 [CL2] (improving on a 10-competitive algorithm <ref> [IR] </ref>); and until now, the only known metric spaces in which a fast algorithm could achieve the optimal ratio of 2 were those which could be embedded in a tree. <p> However, the algorithm does not achieve any constant competitive ratio, even for two servers, in a general metric space M . Thus it was somewhat surprising that a rule minimizing the quantity D i + 2rs i was shown to be 10-competitive for two servers <ref> [IR] </ref>. A later construction showed that this algorithm is no better than 6-competitive [CL2]. Here, we show a new lower bound for the class of balancing algorithms in general.
Reference: [Is] <author> J. Isbell, </author> <title> "An optimal search pattern," </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 4(1957), </volume> <pages> pp. 357-359. </pages>
Reference-contexts: These include, for example, the problem of searching for a point on a line or a collection of lines, and the well-known "lost-at-sea" problem, in which one must determine the optimal search pattern for finding a line (the shore) in the plane (the ocean) <ref> [Be, Is] </ref>. A fundamental technique introduced in [BCR] is that of spiral search | an uncomplicated idea which has proved to be a valuable building block in numerous on-line algorithms.
Reference: [J] <author> D. Johnson, </author> <title> "Fast algorithms for bin packing," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 8(1974), </volume> <pages> pp. 272-314. </pages>
Reference-contexts: Garey, Graham, and Ullman [GGU] proved that the competitive ratio of First Fit is 17 10 , and an almost exact 14 characterization of the performance of First Fit, as well as a number of other approximation algorithms, was given by Johnson in his Ph.D. thesis <ref> [J] </ref>. In a result very much in the spirit of current work in on-line algorithms, Yao proved in 1980 that there is no on-line bin-packing algorithm with a performance ratio better than 3 2 [Yao].
Reference: [KMSY] <author> M. Kao, Y. Ma, M. Sipser, Y. Yin, </author> <title> "Optimal constructions of hybrid algorithms," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms <ref> [KMSY] </ref>, and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat less stylized. Specifically, they consider a robot with vision moving around in a plane filled with rectangular obstacles. <p> As discussed in the previous chapter, on-line search algorithms have generally been developed for situations in which the geometry is kept to a minimum | for example, the case of searching for a point on one of m concurrent rays <ref> [BCR, KRT, KMSY] </ref>, a line in the plane, or a point in an integer lattice [BCR]. <p> Indeed a great deal of work is often done to determine what these constant factors are <ref> [BCR, KRT, KMSY] </ref>. But the fact remains that no algorithm can be better than (n)-competitive for many of these problems.
Reference: [KRT] <author> M. Kao, J. Reif, S. Tate, </author> <title> "Searching in an unknown environment: an optimal randomized algorithm for the cow-path problem," </title> <booktitle> Proc. 4th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 441-447. </pages>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below <ref> [BCR, PY, BRaSc, KRT, Kl] </ref>, an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat <p> As discussed in the previous chapter, on-line search algorithms have generally been developed for situations in which the geometry is kept to a minimum | for example, the case of searching for a point on one of m concurrent rays <ref> [BCR, KRT, KMSY] </ref>, a line in the plane, or a point in an integer lattice [BCR]. <p> Indeed a great deal of work is often done to determine what these constant factors are <ref> [BCR, KRT, KMSY] </ref>. But the fact remains that no algorithm can be better than (n)-competitive for many of these problems.
Reference: [KMRS] <author> A.R. Karlin, M.M. Manasse, L. Rudolph, </author> <title> and D.D. Sleator, </title> <journal> "Competitive snoopy caching" Algorithmica, </journal> <volume> 3(1988), </volume> <pages> pp. 70-119. </pages>
Reference-contexts: Various extensions to the model of [ST] have been proposed [BIRS, KPR], but the question of why on-line paging works so well in real life remains an intriguing one. Following [ST], the paper <ref> [KMRS] </ref> analyzed additional on-line strategies for cache management (which is essentially the same as paging in this model), and [BLS] proposed "metrical task systems" as an abstract model for studying on-line algorithms.
Reference: [KPR] <author> A.R. Karlin, S.J. Phillips, P. Raghavan, </author> <title> "Markov paging", </title> <booktitle> Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1992. </year> <month> 85 </month>
Reference-contexts: Various extensions to the model of [ST] have been proposed <ref> [BIRS, KPR] </ref>, but the question of why on-line paging works so well in real life remains an intriguing one.
Reference: [Kier] <author> H. Kierstead, </author> <title> "The linearity of First-Fit for coloring interval graphs," </title> <journal> SIAM J. Discrete Math, </journal> <volume> 1(1988), </volume> <pages> pp. 526-530. </pages>
Reference-contexts: The survey paper of Kierstead and Trotter [KT] mentions a number of problems related to the First Fit coloring algorithm; for example, Woodall asked in 1974 whether the number of colors used by First Fit was within a constant factor of (G) when G is an interval graph (see also <ref> [Kier] </ref>). In the new language, this is simply the question of whether First Fit achieves a constant competitive ratio for this type of graph.
Reference: [KT] <author> H. Kierstead, W. Trotter, </author> <title> "On-line graph coloring," in On-Line Algorithms, </title> <editor> D. Sleator and L. McGeoch, Eds., </editor> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science (vol. </booktitle> <volume> 7), </volume> <year> 1992, </year> <pages> pp. 85-92. </pages>
Reference-contexts: While First Fit performs abysmally on some classes of graphs, it has long been observed to have relatively good behavior on others. The survey paper of Kierstead and Trotter <ref> [KT] </ref> mentions a number of problems related to the First Fit coloring algorithm; for example, Woodall asked in 1974 whether the number of colors used by First Fit was within a constant factor of (G) when G is an interval graph (see also [Kier]).
Reference: [K] <author> R. Klein, </author> <title> "Walking an unknown street with bounded detour," Computational Geometry: </title> <journal> Theory and Applications, </journal> <volume> 1(1992), </volume> <pages> pp. 325-351. </pages> <note> (Preliminary version in Proc. 32nd IEEE Symposium on Foundations of Computer Science, </note> <year> 1991, </year> <pages> pp. 304-313.) </pages>
Reference-contexts: It is also interesting to consider special cases of the search problem in a polygon | restricting the type of polygon so that better competitive ratios can be obtained. This was the approach taken by Klein <ref> [K] </ref>, who considered the class of streets and gave a search algorithm with competitive ratio at most 1 + 3 2 (~ 5:71). We give an algorithm for streets with competitive ratio at most q p 8 (~ 2:61), improving on this bound by more than a factor of two. <p> Such an approach has been adopted by Klein in his work on streets. The papers <ref> [IK, K] </ref> introduce the term street to define a class of general (not necessarily rectilinear) polygons with two distinguished points s and t, such that the two st boundary chains are mutually weakly visible (see below for an elaboration on this definition). <p> The papers [IK, K] introduce the term street to define a class of general (not necessarily rectilinear) polygons with two distinguished points s and t, such that the two st boundary chains are mutually weakly visible (see below for an elaboration on this definition). In <ref> [K] </ref>, Klein gives a 1 + 3 2 -competitive (~ 5:71-competitive) algorithm for finding t from s in an unknown street P . However, the algorithm and its analysis are quite involved. <p> The removal of s and t would disconnect the boundary into two polygonal chains, L and R. We say that 27 P is a street <ref> [IK, K] </ref> if each point on the boundary of P can see some point on the opposite boundary chain. The goal is for a robot with vision to travel from s to t; neither the map of P nor the coordinates of t are known. <p> it generates, and its competitive ratio is taken with respect to the length of the shortest s-t path in P ; distances are measured in the Euclidean metric. right cavemouth X Y a) Indecision left cavemouth c l b) R cave robot x the corner from either X or Y <ref> [K] </ref>. The robot will incur the best worst-case performance if it moves directly to segment XY , then to t (it will see t when it reaches XY ). This can be at most a factor of p 2 longer than the shortest path. <p> This can be at most a factor of p 2 longer than the shortest path. Curiously, this is the only known lower bound on the competitive ratio achievable for the problem. In <ref> [K] </ref>, an algorithm with a competitive ratio 28 of at most 1 + 3 2 (~ 5:71) is presented. <p> What does it take to build a maze? Specifically, it is interesting to ask oneself what constitutes the difference between the "shortest-path" problems of [PY, BRaSc, BBFY], and the geometric search problems <ref> [K, Kl] </ref> of the type discussed in Chapter 3.
Reference: [Kl] <author> J. Kleinberg, </author> <title> "On-line search in a simple polygon," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below <ref> [BCR, PY, BRaSc, KRT, Kl] </ref>, an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat <p> What does it take to build a maze? Specifically, it is interesting to ask oneself what constitutes the difference between the "shortest-path" problems of [PY, BRaSc, BBFY], and the geometric search problems <ref> [K, Kl] </ref> of the type discussed in Chapter 3.
Reference: [KP] <author> E. Koutsoupias, C. Papadimitriou, </author> <title> "On the k-server conjecture," </title> <booktitle> Proc. 26th ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 507-511. </pages>
Reference-contexts: Based on these special cases, they advanced the k-server conjecture: for every metric space M , there is a k-competitive k-server algorithm. At the time of this writing, the conjecture is still open; however, significant progress has recently been achieved in <ref> [KP] </ref>. One of the tantalizing aspects of this problem is that most natural algorithms | for example, the greedy algorithm (move the closest server) as well as most straightforward generalizations of LRU | do not achieve any bounded competitive ratio in general. <p> Grove improved this bound to 2 O (k) [Gr] using a simple randomized algorithm, and derandomization techniques of Ben-David et. al. [BBKTW]. And very recently, Koutsoupias and Papadimitriou <ref> [KP] </ref> have shown that the "work-function algorithm" proposed by Chrobak and Larmore [CL4], as by well as other researchers, is at most (2k 1)-competitive. In a separate direction, a number of papers extended the set of metric spaces for which good server algorithms were known.
Reference: [LMH] <author> M. Levine, I. Marchon, G. Hanley, </author> <title> "The placement and misplacement of you-are-here maps," Environment and Behavior, </title> <booktitle> 16(1984), </booktitle> <pages> pp. 139-157. </pages>
Reference: [LT] <author> R. Lipton, A. Tomkins, </author> <title> "On-line interval scheduling," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: This is the set-up considered in [AAP, ABFR]; a closely related problem is that of scheduling "intervals" on a line <ref> [LT] </ref>. One recurring theme in this work is that randomized algorithms often can achieve competitive ratios that are exponentially better than the lower bound for deterministic algorithms. A somewhat related problem was proposed by Imase and Waxman [IW], though it has been suggested independently in a number of sources.
Reference: [LoS] <author> L. Lovasz, M. Saks, </author> <title> "Lattices, Mobius functions, and communication complexity," </title> <booktitle> Proc. 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 81-90. </pages>
Reference-contexts: Proposition 4.16 For each tree T , there is a k-marking and a localization algorithm which is O ( n k )-competitive. Proof. This is not difficult to prove directly; and using a lemma from <ref> [LoS] </ref>, we can actually prove the stronger statement that there is, in effect, a single marking which works for all k. Specifically, it is proved in [LoS] that there is a numbering of the n vertices of T (i.e. a bijection from V to f1; : : :; ng) so that <p> Proof. This is not difficult to prove directly; and using a lemma from <ref> [LoS] </ref>, we can actually prove the stronger statement that there is, in effect, a single marking which works for all k. Specifically, it is proved in [LoS] that there is a numbering of the n vertices of T (i.e. a bijection from V to f1; : : :; ng) so that for each k, the removal of the vertices numbered 1 through k results in a forest in which no component has more than 2n k vertices.
Reference: [LST] <author> L. Lovasz, M. Saks, W. Trotter, </author> <title> "An on-line graph coloring algorithm with sublinear performance ratio," </title> <journal> Discrete Math, </journal> <volume> 75(1989), </volume> <pages> pp. 319-325. </pages>
Reference-contexts: This question was answered in the affirmative in 1989 by Lovasz, Saks, and Trotter <ref> [LST] </ref>, who gave an on-line algorithm with performance ratio O ( n log fl n ).
Reference: [LuS] <author> V. Lumelsky, A. Stepanov, </author> <title> "Path-planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape," </title> <journal> Algorithmica, </journal> <pages> 2(1987) pp. 403-430. </pages>
Reference-contexts: Maze-solving algorithms phrased in the terminology of graphs can be found in work of Tarry and Tremeaux that reaches back a century and more [Ore]. More recently, such questions have been addressed in the contexts of automata theory by Blum and Kozen [BK] and robotics by Lumelsky and Stepanov <ref> [LuS] </ref>. On-line navigation is concerned with questions somewhat more general than maze-solving: the environment will not always be nefarious, the goal not always to escape.
Reference: [MMS] <author> M. Manasse, L. McGeoch, D. Sleator, </author> <title> "Competitive algorithms for server problems," </title> <journal> J. Algorithms, </journal> <volume> 11(1990), pp.208-230. </volume> <pages> 86 </pages>
Reference-contexts: This notion has been studied especially with respect to the 2-server problem, by Irani and Rubinfeld [IR] and Chrobak and Larmore [CL2]. In this setting it has been observed that, while there are computationally expensive 2-server algorithms achieving the optimal competitive ratio of 2 <ref> [MMS, CL1, CL4] </ref>, the best known competitive ratio for a real-time algorithm is 4 [CL2]. In Chapter 5, we give a real-time 2-server algorithm which is 2-competitive in n-dimensional space under the L 1 ("Manhattan") metric. <p> Following [ST], the paper [KMRS] analyzed additional on-line strategies for cache management (which is essentially the same as paging in this model), and [BLS] proposed "metrical task systems" as an abstract model for studying on-line algorithms. The following year, Manasse, McGeoch, and Sleator <ref> [MMS] </ref> introduced what has become perhaps the most well-known and well-studied on-line problem: the k-server problem. 2.2 The k-Server Problem We imagine the following situation. An on-line algorithm A controls k mobile servers which are free to move around in some metric space M . <p> Note that LRU or FIFO provides a matching upper bound for the uniform metric space; <ref> [MMS] </ref> also provided a 2-competitive 2-server algorithm and a k-competitive k-server algorithm for any metric space with only k + 1 points. Based on these special cases, they advanced the k-server conjecture: for every metric space M , there is a k-competitive k-server algorithm. <p> Thus, if we let 0 denote the value of on the initial configuration of the servers, then the fact that is always non-negative implies A () c OP T () + 0 : That is, A is c-competitive. It is not difficult to show (see <ref> [MMS] </ref>) that we can assume OP T is a lazy algorithm: it always moves at most one server on each request, and does not move if it already covers the requested point. If x and y are points on the line, let xy denote the distance between them. <p> The 2-server problem appears to be a good one on which to try out these notions. First of all, a fair amount is known about the bounds one can achieve | there are at least three optimal 2-server algorithms in the literature <ref> [MMS, CL1, CL4] </ref> | and a number of constant-time algorithms have been analyzed [IR, CL2, CKPV]. Also, the structure of the 2-server 65 problem is in some sense quite a bit simpler than the structure of the general k-server problem. <p> This rule was shown to be k-competitive for k servers when the cardinality of the request space M is k + 1 <ref> [MMS] </ref>, and for the "weighted 66 cache" problem, which includes the paging problem as a special case [CKPV]. However, the algorithm does not achieve any constant competitive ratio, even for two servers, in a general metric space M . <p> Observe that we make no restrictions whatsoever on the nature of the function f . Our main result is a lower bound of (5 + p 7)=2 (~ 3:82) on the competitive ratio of any such balancing algorithm for two servers. In view of the 2-competitive algorithms of <ref> [MMS, CL1, CL4] </ref>, this shows that no optimal on-line 2-server algorithm can be expressed as a decision rule B f for any f . To our knowledge, this represents one of the first lower bounds for on-line algorithms based solely on computational resources. We use the following notation.
Reference: [MAWM] <author> D. Miller, D. Atkinson, B. Wilcox, A. Mishkin, </author> <title> "Autonomous navigation and control of a Mars rover," in Automatic Control in Aerospace, </title> <editor> T. Nishimura, Ed., </editor> <publisher> Oxford: Pergamon Press, </publisher> <year> 1989, </year> <pages> pp. 111-114. </pages>
Reference-contexts: A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers <ref> [MAWM, SN] </ref>. <p> A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers [MAWM, SN]. For example, <ref> [MAWM] </ref> discusses strategies by which a mobile robot can determine its location after a short period of "reconnaissance": in the model considered there, a rough global map of the Martian terrain is known; the exploring robot relays local information back to Earth, where an obstacle-avoiding path is then planned.
Reference: [Ore] <author> O. </author> <title> Ore Theory of Graphs, </title> <publisher> Providence: AMS, </publisher> <year> 1962. </year>
Reference-contexts: Maze-solving algorithms phrased in the terminology of graphs can be found in work of Tarry and Tremeaux that reaches back a century and more <ref> [Ore] </ref>. More recently, such questions have been addressed in the contexts of automata theory by Blum and Kozen [BK] and robotics by Lumelsky and Stepanov [LuS]. On-line navigation is concerned with questions somewhat more general than maze-solving: the environment will not always be nefarious, the goal not always to escape.
Reference: [PY] <author> C. Papadimitriou, M. Yannakakis, </author> <title> "Shortest paths without a map," </title> <journal> Theoretical Computer Science, </journal> <volume> 84(1991), </volume> <pages> pp. 127-150. </pages>
Reference-contexts: The recent incorporation of navigation problems into the setting of competitive analysis comes mainly from the work of Baeza-Yates, Culberson, and Rawlins [BCR], and Papadimitriou and Yannakakis <ref> [PY] </ref>. [BCR] does not speak directly in terms of the competitive ratio, but its focus on the ratio of the robot's distance traveled to the length of the shortest path is clear enough. <p> Recently, it has been used in many of the robot search papers we will discuss below <ref> [BCR, PY, BRaSc, KRT, Kl] </ref>, an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat <p> Recently, it has been used in many of the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal <ref> [PY, FFKRRV] </ref>, the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems [BCCPRS, TWSY]. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat less stylized. <p> Based on the above definitions, we will say that a rectangle packing is a collection of axis-aligned rectangles, each of which has at least unit thickness, such that there is always just enough room for the robot to pass between neighboring rectangles. <ref> [PY] </ref> deals with shortest-path problems in this setting: the robot starts at a point s and knows the coordinates of a point t that it wants to reach. The point t is assumed to be in free space | i.e not in the middle of an obstacle. <p> The point t is assumed to be in free space | i.e not in the middle of an obstacle. Let n denote the straight-line distance from s to t; note that this could be much less than d (s; t). When all the obstacles in the packing are squares, <ref> [PY] </ref> gives an algorithm with competitive ratio 1 3 26 ~ 1:70, and shows that no on-line algorithm can be better than 3 2 -competitive. For the case of an arbitrary rectangle packing, no bounded competitive ratio is possible: [PY] shows a lower bound of ( p n) on the best <p> When all the obstacles in the packing are squares, <ref> [PY] </ref> gives an algorithm with competitive ratio 1 3 26 ~ 1:70, and shows that no on-line algorithm can be better than 3 2 -competitive. For the case of an arbitrary rectangle packing, no bounded competitive ratio is possible: [PY] shows a lower bound of ( p n) on the best possible competitive ratio. Blum, Raghavan, and Schieber [BRaSc] address the same type of shortest-paths problems and give an O ( p n)-competitive algorithm for the s-t path problem in a rectangle packing; this matches the lower bound of [PY] <p> <ref> [PY] </ref> shows a lower bound of ( p n) on the best possible competitive ratio. Blum, Raghavan, and Schieber [BRaSc] address the same type of shortest-paths problems and give an O ( p n)-competitive algorithm for the s-t path problem in a rectangle packing; this matches the lower bound of [PY] up to constant factors. [BRaSc] also introduced the elegant "room problem" | consider a rectangle packing inside a large 2n fi 2n square room (so there is space to move along the walls as well), such that the center of the room is in free space. <p> If T is an embedded tree, we will use n to denote the number of leaves it has. * Rectangle packings in the plane, comprised of n rectangles <ref> [PY, BRaSc, BBFY, BRiSi] </ref>. Recall from Chapter 2 that we assume all rectangles have at least unit thickness, and that there is always just enough room for the robot to move between neighboring rectangles. <p> What does it take to build a maze? Specifically, it is interesting to ask oneself what constitutes the difference between the "shortest-path" problems of <ref> [PY, BRaSc, BBFY] </ref>, and the geometric search problems [K, Kl] of the type discussed in Chapter 3. <p> In other words, when the obstacles can be sufficiently complex, there is no value in knowing the coordinates of the goal. We can make this more precise as follows. Let F denote a family of rectilinear polygons, which will be used as obstacles in the sense of <ref> [PY] </ref> (e.g. F could be the set of all rectangles, or the set of all L-shaped polygons, and so on).
Reference: [SN] <author> C. Shen, G. Nagy, </author> <title> "Autonomous navigation to provide long-distance surface traverses for Mars rover sample return mission," </title> <booktitle> Proc. IEEE International Symposium on Intelligent Control, </booktitle> <year> 1989, </year> <pages> pp. 362-367. </pages>
Reference-contexts: A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers <ref> [MAWM, SN] </ref>.
Reference: [ST] <author> D. Sleator, R. Tarjan, </author> <title> "Amortized efficiency of list update and paging rules," </title> <journal> Comm. ACM, </journal> <volume> 23(1985), </volume> <pages> pp. 202-208. </pages>
Reference-contexts: In large part this is due to the surprisingly rich structure of the competitive ratio, brought into focus by Sleator and Tarjan <ref> [ST] </ref> in 1985 as a means of analyzing on-line algorithms. At a general level, an on-line algorithm is one which receives its input in a piecemeal fashion; at each step, it must make irrevocable decisions before seeing the remainder of the input. <p> In the following section, we discuss competitive analysis in general, and 13 specifically the paper of Sleator and Tarjan <ref> [ST] </ref>. 2.1 Competitive Analysis Typically, an on-line algorithm is trying to solve some optimization problem (as in the examples cited above). <p> In the last five years, there have been a number of papers on "on-line graph coloring" in the competitive framework; these will be discussed briefly in Section 2.3. But it was the work of Sleator and Tarjan in 1985 <ref> [ST] </ref> which launched the current deluge of papers. [ST] considered two classical problems of computer science, within the setting of competitive analysis: the maintenance of a dynamic data structure, and paging. On the first of these questions, [ST] dealt specifically with the problem of maintaining a linked list under a sequence <p> In the last five years, there have been a number of papers on "on-line graph coloring" in the competitive framework; these will be discussed briefly in Section 2.3. But it was the work of Sleator and Tarjan in 1985 <ref> [ST] </ref> which launched the current deluge of papers. [ST] considered two classical problems of computer science, within the setting of competitive analysis: the maintenance of a dynamic data structure, and paging. On the first of these questions, [ST] dealt specifically with the problem of maintaining a linked list under a sequence of insert, delete, and member? requests. <p> But it was the work of Sleator and Tarjan in 1985 <ref> [ST] </ref> which launched the current deluge of papers. [ST] considered two classical problems of computer science, within the setting of competitive analysis: the maintenance of a dynamic data structure, and paging. On the first of these questions, [ST] dealt specifically with the problem of maintaining a linked list under a sequence of insert, delete, and member? requests. This problem had a long history, and many heuristics had been proposed. <p> The proof was also interesting for its use of a potential function argument, a technique that was to become extremely common in subsequent research in on-line algorithms (we will give an example of such an argument in Section 2.2). 15 The results in <ref> [ST] </ref> concerned with paging gave much stronger lower bounds. Here one pictures a computer with k pages of fast memory and an unlimited number of additional pages of slow memory (e.g. a disk). <p> The goal is to minimize the number of page faults, over the course of a string of memory references. In <ref> [ST] </ref> it was proved that no on-line paging algorithm with k pages can be better than k-competitive, and a number of well-known algorithms such as LRU (evict the least-recently used page) and FIFO (evict the page that was brought in longest ago) match this bound. <p> Various extensions to the model of <ref> [ST] </ref> have been proposed [BIRS, KPR], but the question of why on-line paging works so well in real life remains an intriguing one. Following [ST], the paper [KMRS] analyzed additional on-line strategies for cache management (which is essentially the same as paging in this model), and [BLS] proposed "metrical task systems" <p> Various extensions to the model of <ref> [ST] </ref> have been proposed [BIRS, KPR], but the question of why on-line paging works so well in real life remains an intriguing one. Following [ST], the paper [KMRS] analyzed additional on-line strategies for cache management (which is essentially the same as paging in this model), and [BLS] proposed "metrical task systems" as an abstract model for studying on-line algorithms. <p> By now, many on-line problems have been studied; the following is not meant to be comprehensive. As mentioned above, the surge of activity following <ref> [ST] </ref> led to some new results in on-line graph coloring, already a topic of interest in the 1970's.
Reference: [TPBHSS] <author> W. Thompson, H. Pick, B. Bennett, M. Heinrichs, S. Savitt, K. Smith, </author> <title> "Map-based localization: the `drop-off' problem," </title> <booktitle> Proc. DARPA Image Understanding Workshop, </booktitle> <year> 1990, </year> <pages> pp. 706-719. </pages>
Reference-contexts: Thus the robot's path is O (m) times d (s; t), as required. 41 Chapter 4 The Robot Localization Problem A fundamental task for an autonomous mobile robot is that of localization | determining its location in a known environment <ref> [Cox, TPBHSS, Wang] </ref>. <p> In a related vein, <ref> [TPBHSS] </ref> draws a distinction between localization algorithms for "update" problems, in which there is some rough estimate of the robot's starting location, and "drop-off" problems, in which there is no initial information. In this terminology, we will be considering 44 the latter type of problem. Again, [TPBHSS] describes the role of <p> In a related vein, <ref> [TPBHSS] </ref> draws a distinction between localization algorithms for "update" problems, in which there is some rough estimate of the robot's starting location, and "drop-off" problems, in which there is no initial information. In this terminology, we will be considering 44 the latter type of problem. Again, [TPBHSS] describes the role of "reconnaissance" in the localization problem, without providing any concrete algorithms. Theoretical Background The only previous theoretical treatment of the localization problem is the paper of Guibas, Motwani, and Raghavan [GMR], and as mentioned above, it deals only with the "static" version of the question. <p> Lemmas 4.12, 4.14, and the analogue of Lemma 4.10 for rectangles, we have Theorem 4.15 The above algorithm is O ( n (n) )-competitive for the localization problem in an environment of n rectangles. 4.4 Placing Unique Landmarks Until now, we have been considering the "drop-off" version of the problem <ref> [TPBHSS] </ref>, in which the robot is placed in an environment with very little starting information. But another situation in which localization arises is that of a robot which must repeatedly perform tasks in the same environment, and must begin by determining its current location.
Reference: [TG] <author> C. Thorpe, J. Gowdy, </author> <title> "Annotated maps for autonomous land vehicles," </title> <booktitle> Proc. DARPA Image Understanding Workshop, </booktitle> <year> 1990, </year> <pages> pp. 765-771. </pages>
Reference: [TWSY] <author> J. Turek, J. Wolf, U. Schwiegelshohn, P. Yu, </author> <title> "Scheduling parallel tasks to minimize average response time," </title> <booktitle> Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Recently, it has been used in many of the robot search papers we will discuss below [BCR, PY, BRaSc, KRT, Kl], an abstract kind of navigation problem known as layered graph traversal [PY, FFKRRV], the design of hybrid algorithms [KMSY], and even the approximation of some NP-hard problems <ref> [BCCPRS, TWSY] </ref>. s The work of Papadimitriou and Yannakakis followed [BCR] and deals with navigation problems that are somewhat less stylized. Specifically, they consider a robot with vision moving around in a plane filled with rectangular obstacles.
Reference: [Vi] <author> S. Vishwanathan, </author> <title> "Randomized online graph coloring," </title> <booktitle> Proc. 31st IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 464-469. </pages>
Reference-contexts: Thus, no on-line algorithm can be better than ( n log 2 n )-competitive on all graphs. Related work on on-line graph coloring has been done by Irani [Ir] and Vishwanathan <ref> [Vi] </ref>. The problem of virtual circuit routing through a network is naturally on-line, and has been studied from that point of view in a number of recent papers.
Reference: [Wang] <author> C. Ming Wang, </author> <title> "Location estimation and uncertainty analysis for mobile robots," </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <year> 1988, </year> <pages> pp. 1230-1235. </pages>
Reference-contexts: Thus the robot's path is O (m) times d (s; t), as required. 41 Chapter 4 The Robot Localization Problem A fundamental task for an autonomous mobile robot is that of localization | determining its location in a known environment <ref> [Cox, TPBHSS, Wang] </ref>. <p> One application is in the design of robot vehicles that must perform a certain task repeatedly in the same environment. Here, localization is used to determine the starting location at the beginning of the task, and to maintain positioning information over time <ref> [Cox, Dr, Wang] </ref>. A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken [YD]. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers [MAWM, SN].
Reference: [YD] <author> Y. Yacoob, L. Davis, </author> <title> "Computational ground and airborne localization over rough terrain," </title> <institution> Univ. of Maryland Tech Report CS-TR-2788. </institution>
Reference-contexts: Here, localization is used to determine the starting location at the beginning of the task, and to maintain positioning information over time [Cox, Dr, Wang]. A similar use of localization is in analyzing aerial photographs to determine the location from which they were taken <ref> [YD] </ref>. Another major situation in which localization is used is in the design of autonomous exploration vehicles, such as the current prototypes for Mars rovers [MAWM, SN].
Reference: [Yao] <author> A. Yao, </author> <title> "New algorithms for bin packing," </title> <journal> Journal of the ACM, </journal> <volume> 27(1980), </volume> <pages> pp. 207-227. 87 </pages>
Reference-contexts: In a result very much in the spirit of current work in on-line algorithms, Yao proved in 1980 that there is no on-line bin-packing algorithm with a performance ratio better than 3 2 <ref> [Yao] </ref>. The competitive ratio also appears sporadically (and again not cast in the current terminology) in work on graph-coloring. The First Fit algorithm has a natural meaning in this world as well: proceed through the vertices one at a time, coloring each with the lowest-numbered color possible.
References-found: 67

