URL: ftp://ftp.cs.arizona.edu/reports/1993/TR93-18.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Title: Supporting Fault-Tolerant Parallel Programming in Linda  
Author: David E. Bakken and Richard D. Schlichting 
Address: Tucson, AZ 85721  
Affiliation: Department of Computer Science The University of Arizona  
Note: June  
Date: TR 93-18  8, 1993  
Abstract: Linda is a language for programming parallel applications whose most notable feature is a distributed shared memory called tuple space. While suitable for a wide variety of programs, one shortcoming of the language as commonly defined and implemented is a lack of support for writing programs that can tolerate failures in the underlying computing platform. This paper describes FT-Linda, a version of Linda that addresses this problem by providing two major enhancements that facilitate the writing of fault-tolerant applications: stable tuple spaces and atomic execution of tuple space operations. The former is a type of stable storage in which tuple values are guaranteed to persist across failures, while the latter allows collections of tuple operations to be executed in an all-or-nothing fashion despite failures and concurrency. The design of these enhancements is presented in detail and illustrated by examples drawn from both the Linda and fault-tolerance domains. An implementation of FT-Linda for a network of workstations is also described. The design is based on replicating the contents of stable tuple spaces to provide failure resilience and then updating the copies using atomic multicast. This strategy allows an efficient implementation in which only a single multicast message is needed for each atomic collection of tuple space operations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shakil Ahmed and David Gelernter. </author> <title> A higher-level environment for parallel programming. </title> <type> Technical Report YALEDU/DCS/RR-877, </type> <institution> Yale University Department of Computer Science, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Support for disjunction has also been discussed in [16, 27] and in the context of the Linda Program Builder <ref> [1, 2] </ref>. The Program Builder offers the abstraction of disjunction by mapping it onto ordinary Linda operations and hiding the details from the user.
Reference: [2] <author> Shakil Ahmed and David Gelernter. </author> <title> Program builders as alternatives to high-level languages. </title> <type> Technical Report YALEDU/DCS/RR-887, </type> <institution> Yale University Department of Computer Science, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Support for disjunction has also been discussed in [16, 27] and in the context of the Linda Program Builder <ref> [1, 2] </ref>. The Program Builder offers the abstraction of disjunction by mapping it onto ordinary Linda operations and hiding the details from the user.
Reference: [3] <author> Sudhir Ahuja, Nicholas Carriero, and David Gelernter. </author> <title> Linda and friends. </title> <journal> IEEE Computer, </journal> <volume> 19(8) </volume> <pages> 26-34, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Finally, Section 6 discusses possible extensions and related work, while Section 7 offers some concluding remarks. 2 Linda and Failures 2.1 Linda Overview Linda is a system for constructing parallel programs based on a communication abstraction known as tuple space (TS) <ref> [16, 3, 13] </ref>. Tuple space is an associative (i.e., content-addressable) unordered bag of data elements called tuples. Processes are created in the context of a given TS, which they use as a means for communicating and synchronizing. <p> The problem is due to the inability to execute the in and subsequent out as an atomic unit with respect to failures. Bag-of-Tasks. Linda lends itself nicely to a method of parallel programming called the bag-of-tasks or replicated worker programming paradigm <ref> [3, 12] </ref>. In this paradigm, the task to be solved is partitioned into independent subtasks.
Reference: [4] <author> Brian G. Anderson and Dennis Shasha. </author> <title> Persistent Linda: Linda + transactions + query processing. </title> <editor> In J.P. Ban atre and D. Le M etayer, editors, </editor> <booktitle> Research Directions in High-Level Parallel Programming Languages, number 57 in LNCS, </booktitle> <pages> pages 93-109. </pages> <publisher> Springer, </publisher> <year> 1991. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> First, inp and rdp in our scheme provide absolute guarantees as to whether there is a matching tuple, a property that we call strong inp/rdp semantics. Of all other distributed Linda implementations of which we are aware, only <ref> [4] </ref> offers similar semantics. <p> A few efforts have also extended Linda to provide additional atomicity for fault-tolerance purposes. Our initial report [5] introduced an early version of the atomicity that FT-Linda provides; the construct was similar to an AGS , but allowed only a single operation in the body. Plinda <ref> [4] </ref> allows the programmer to combine Linda tuple space operations in a transaction, and also provides combination commands (e.g., in-out) that allow multiple operations to be done atomically. This design is sufficient for fault toleranceindeed, it is more general than what FT-Linda providesbut the implementation overhead is significant.
Reference: [5] <author> David E. Bakken and Richard D. Schlichting. </author> <title> Tolerating failures in the bag-of-tasks programming paradigm. </title> <booktitle> In Proceedings of the Twenty-First International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 248-255, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Also, unlike our approach, all the designs discussed in this section require multiple messages to update the TS replicas; the sole exception is one special case in [15]. A few efforts have also extended Linda to provide additional atomicity for fault-tolerance purposes. Our initial report <ref> [5] </ref> introduced an early version of the atomicity that FT-Linda provides; the construct was similar to an AGS , but allowed only a single operation in the body.
Reference: [6] <author> H. E. Bal, J. G. Steiner, and A. G. Tanenbaum. </author> <title> Programming languages for distributed computing systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 261-322, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: To help overcome this obstacle, a number of architecture-independent abstractions and languages have been developed <ref> [6] </ref>. One such language is Linda [16, 13, 17], a coordination language that provides a collection of primitives for process creation and interprocess communication that can be added to existing languages.
Reference: [7] <author> Kenneth Birman, Andr e Schiper, and Pat Stepehson. </author> <title> Lightweight causal and atomic group multicast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: The SMA is the basis for a large number of fault-tolerant distributed systems <ref> [7, 30, 34] </ref>. 2 This ordering can be relaxed in some cases; see [37]. 5 Given the use of replication to realize stable TSs, the next step is to consider schemes for implementing atomic execution of multiple tuple operations that use this TS.
Reference: [8] <author> Robert D. Bjornson. </author> <title> Linda on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Thus, tuple space provides for associative access, in which information is retrieved by content rather than address. This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures <ref> [11, 27, 8, 10] </ref> and for a number of different languages [27, 22, 10, 20]. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered. <p> Subsequent columns gives the marginal cost of including different types of in or out operations in the body. We note that the i386 figures compare favorably with results reported elsewhere <ref> [8] </ref>. These figures can be used to derive at least a rough estimate of the total latency of an AGS by adding the time required by Consul to disseminate and totally order the multicast message before passing it up to the TS state machine.
Reference: [9] <author> Scott Cannon and David Dunn. </author> <title> A high-level model for the development of fault-tolerant parallel and distributed systems. </title> <type> Technical Report A0192, </type> <institution> Department of Computer Science, Utah State University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> This design is sufficient for fault toleranceindeed, it is more general than what FT-Linda providesbut the implementation overhead is significant. MOM <ref> [9] </ref> provides a kind of lightweight transaction. It extends in to return a tuple identifier and out to include the identifier of its parent tuple (e.g., the subtask it was generated by).
Reference: [10] <author> N. Carriero, D. Gelernter, and T.G. Mattson. </author> <title> Linda in heterogenous computing environments. </title> <booktitle> In Proceedings of the Workshop on Heterogenous Processing. IEEE, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Thus, tuple space provides for associative access, in which information is retrieved by content rather than address. This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures <ref> [11, 27, 8, 10] </ref> and for a number of different languages [27, 22, 10, 20]. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered. <p> This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures [11, 27, 8, 10] and for a number of different languages <ref> [27, 22, 10, 20] </ref>. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered.
Reference: [11] <author> Nicholas Carriero and David Gelernter. </author> <title> The S/Net's Linda kernel. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(2) </volume> <pages> 110-129, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Thus, tuple space provides for associative access, in which information is retrieved by content rather than address. This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures <ref> [11, 27, 8, 10] </ref> and for a number of different languages [27, 22, 10, 20]. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered.
Reference: [12] <author> Nicholas Carriero and David Gelernter. </author> <title> Applications experience with Linda. </title> <journal> ACM SIGPLAN Notices (Proc. ACM SIGPLAN PPEALS), </journal> <volume> 23(9) </volume> <pages> 173-187, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The problem is due to the inability to execute the in and subsequent out as an atomic unit with respect to failures. Bag-of-Tasks. Linda lends itself nicely to a method of parallel programming called the bag-of-tasks or replicated worker programming paradigm <ref> [3, 12] </ref>. In this paradigm, the task to be solved is partitioned into independent subtasks.
Reference: [13] <author> Nicholas Carriero and David Gelernter. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: To help overcome this obstacle, a number of architecture-independent abstractions and languages have been developed [6]. One such language is Linda <ref> [16, 13, 17] </ref>, a coordination language that provides a collection of primitives for process creation and interprocess communication that can be added to existing languages. <p> Finally, Section 6 discusses possible extensions and related work, while Section 7 offers some concluding remarks. 2 Linda and Failures 2.1 Linda Overview Linda is a system for constructing parallel programs based on a communication abstraction known as tuple space (TS) <ref> [16, 3, 13] </ref>. Tuple space is an associative (i.e., content-addressable) unordered bag of data elements called tuples. Processes are created in the context of a given TS, which they use as a means for communicating and synchronizing.
Reference: [14] <author> Nicholas Carriero, David Gelernter, David Kaminsky, and Jeffery Westbrook. </author> <title> Adaptive parallelism with piranha. </title> <type> Technical Report YALE/DCS/RR-954, </type> <institution> Yale University Department of Computer Science, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Among the advantages of this programming approach are transparent scalability, automatic load balancing, ease of utilizing idle workstation cycles <ref> [18, 14] </ref>, and, as discussed below, easy extension to fault-tolerant operation. Realizing this approach in Linda is done by having the TS function as the bag. The TS is seeded with subtask tuples, where each such tuple contains arguments that describe the given subtask to be solved.
Reference: [15] <author> Shigeru Chiba, Kazuhiko Kato, and Takishi Masuda. </author> <title> Exploiting a weak consistency to implement distributed tuple space. </title> <booktitle> In Proceedings of the 12th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 416-423, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> The design is based on replicating tuples, and then using locks and a general commit protocol to perform updates. [33] also implements a stable TS by replication, but uses centralized algorithms to serialize tuple operations and achieve replica consistency for single TS operations. <ref> [15] </ref> addresses the issue of relaxing the consistency of the TS replicas to improve performance. Another project [23, 24] aims to achieve fault-tolerance by checkpointing TS and process states; the scheme is currently only a design and has not been implemented. <p> Also, unlike our approach, all the designs discussed in this section require multiple messages to update the TS replicas; the sole exception is one special case in <ref> [15] </ref>. A few efforts have also extended Linda to provide additional atomicity for fault-tolerance purposes. Our initial report [5] introduced an early version of the atomicity that FT-Linda provides; the construct was similar to an AGS , but allowed only a single operation in the body.
Reference: [16] <author> David Gelernter. </author> <title> Generative communication in Linda. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(1) </volume> <pages> 80-112, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: To help overcome this obstacle, a number of architecture-independent abstractions and languages have been developed [6]. One such language is Linda <ref> [16, 13, 17] </ref>, a coordination language that provides a collection of primitives for process creation and interprocess communication that can be added to existing languages. <p> Finally, Section 6 discusses possible extensions and related work, while Section 7 offers some concluding remarks. 2 Linda and Failures 2.1 Linda Overview Linda is a system for constructing parallel programs based on a communication abstraction known as tuple space (TS) <ref> [16, 3, 13] </ref>. Tuple space is an associative (i.e., content-addressable) unordered bag of data elements called tuples. Processes are created in the context of a given TS, which they use as a means for communicating and synchronizing. <p> Other features similar to those provided in FT-Linda have also been proposed at various times. [27] discusses the idea of multiple tuple spaces, and some of the properties that might be supported in such a scheme. <ref> [16] </ref> briefly introduces composed statements, which provide a form of disjunction and conjunction. Support for disjunction has also been discussed in [16, 27] and in the context of the Linda Program Builder [1, 2]. <p> Support for disjunction has also been discussed in <ref> [16, 27] </ref> and in the context of the Linda Program Builder [1, 2]. The Program Builder offers the abstraction of disjunction by mapping it onto ordinary Linda operations and hiding the details from the user.
Reference: [17] <author> David Gelernter and Nicholas Carriero. </author> <title> Coordination languages and their significance. </title> <journal> Communications of the ACM, </journal> <volume> 35(2) </volume> <pages> 97-107, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: To help overcome this obstacle, a number of architecture-independent abstractions and languages have been developed [6]. One such language is Linda <ref> [16, 13, 17] </ref>, a coordination language that provides a collection of primitives for process creation and interprocess communication that can be added to existing languages.
Reference: [18] <author> David Gelernter and David Kaminsky. </author> <title> Supercomputing out of recycled garbage: Preliminary experience with piranha. </title> <booktitle> In Proceedings of the Sixth ACM International Conference on Supercomputing, </booktitle> <address> Washington, D.C., </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Among the advantages of this programming approach are transparent scalability, automatic load balancing, ease of utilizing idle workstation cycles <ref> [18, 14] </ref>, and, as discussed below, easy extension to fault-tolerant operation. Realizing this approach in Linda is done by having the TS function as the bag. The TS is seeded with subtask tuples, where each such tuple contains arguments that describe the given subtask to be solved.
Reference: [19] <author> J. N. Gray. </author> <booktitle> Notes on database operating systems. In Operating Systems: An Advanced Course, Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1978. </year>
Reference-contexts: Additionally, other processes must not be allowed concurrent access to TS while an update is in progress. A number of schemes would satisfy these requirements. For example, techniques based on the two-phase commit protocol for implementing general database transactions could be used <ref> [19, 26] </ref>. While sufficient, these techniques are expensive, requiring multiple rounds of message passing between the processors hosting replicas. At least part of the reason for the heavyweight nature of the technique is that it supports atomic execution of essentially arbitrary computations.
Reference: [20] <author> W. Hasselbring. </author> <title> A formal z specification of proset-Linda. </title> <type> Technical Report 04-92, </type> <institution> University of Essen Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures [11, 27, 8, 10] and for a number of different languages <ref> [27, 22, 10, 20] </ref>. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered.
Reference: [21] <author> Norman C. Hutchinson and Larry L. Peterson. </author> <title> The x-kernel: An architecture for implementing network protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-76, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols <ref> [21] </ref>.
Reference: [22] <author> Robert Jellinghaus. </author> <title> Eiffel Linda: An object-oriented Linda dialect. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 25(12) </volume> <pages> 70-84, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures [11, 27, 8, 10] and for a number of different languages <ref> [27, 22, 10, 20] </ref>. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered.
Reference: [23] <author> Srikanth Kambhatla. </author> <title> Recovery with limited replay: Fault-tolerant processes in Linda. </title> <type> Technical Report CS/E 90-019, </type> <institution> Department of Computer Science, Oregon Graduate Institute, </institution> <year> 1990. </year> <month> 28 </month>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> Another project <ref> [23, 24] </ref> aims to achieve fault-tolerance by checkpointing TS and process states; the scheme is currently only a design and has not been implemented.
Reference: [24] <author> Srikanth Kambhatla. </author> <title> Replication issues for a distributed and highly available Linda tuple space. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, Oregon Graduate Institute, </institution> <year> 1991. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> Another project <ref> [23, 24] </ref> aims to achieve fault-tolerance by checkpointing TS and process states; the scheme is currently only a design and has not been implemented.
Reference: [25] <author> Richard Koo and Sam Toueg. </author> <title> Checkpointing and rollback-recovery for distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13(1) </volume> <pages> 23-31, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Moreover, such a stable storage facility is a key requirement for many fault-tolerance techniques. For example, checkpoint and recovery is a technique based on saving key values in stable storage so that an application process can recover to some intermediate state following a failure <ref> [25] </ref>. The second deficiency can be characterized as lack of sufficient atomicity. Informally, a computation that modifies shared state is atomic if, from the perspective of other computations, all its modifications appear to take place instantaneously despite concurrent access and failures.
Reference: [26] <author> B. Lampson. </author> <title> Atomic transactions. </title> <booktitle> In Distributed SystemsArchitecture and Implementation, </booktitle> <pages> pages 246-265. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: To do this, FT-Linda includes two major enhancements: the ability to have stable tuple spaces and support for atomic execution of TS operations. The former is a type of stable storage in which the contents are guaranteed to persist across failures <ref> [26] </ref>; the latter allows collections of tuple operations to be executed in an all-or-nothing fashion despite failures and concurrency. <p> Additionally, other processes must not be allowed concurrent access to TS while an update is in progress. A number of schemes would satisfy these requirements. For example, techniques based on the two-phase commit protocol for implementing general database transactions could be used <ref> [19, 26] </ref>. While sufficient, these techniques are expensive, requiring multiple rounds of message passing between the processors hosting replicas. At least part of the reason for the heavyweight nature of the technique is that it supports atomic execution of essentially arbitrary computations.
Reference: [27] <author> Jerrold Leichter. </author> <title> Shared Tuple Memories, Shared Memories, Buses and LAN'sLinda Implementation Across the Spectrum of Connectivity. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: Thus, tuple space provides for associative access, in which information is retrieved by content rather than address. This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures <ref> [11, 27, 8, 10] </ref> and for a number of different languages [27, 22, 10, 20]. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered. <p> This property, together with the temporal and spatial decoupling inherent in the abstraction, makes it especially easy for use by application programmers. Linda implementations are available on a number of different architectures [11, 27, 8, 10] and for a number of different languages <ref> [27, 22, 10, 20] </ref>. Despite these advantages, one significant deficiency of Linda as originally defined and commercially available is that failures in the underlying computing platform have not been considered. <p> It uses distributed consensus, as well as oldest matching semantics to preserve causality. 11 4.1 Fault-Tolerant Divide and Conquer The basic structure of divide and conquer is similar to the bag-of-tasks, where subtask tuples representing work to be performed are retrieved by worker processes <ref> [27] </ref>. The difference comes in the actions of the worker. Here, upon withdrawing a subtask tuple, the worker first determines if the subtask is small enough, a notion that is, of course, application dependent. If so, the task is performed and the result tuple deposited. <p> is followed by some initial results on the performance of TS operations; given the current status of the implementation, these numbers measure only the overhead of tuple processing on a single processor, yet are instructive nevertheless. 5.2 Implementation Components The FT-Linda precompiler, FT-lcc, is a derivative of the lcc precompiler <ref> [27, 28] </ref>. FT-lcc performs two tasks in particular. First, it analyzes and catalogs the signatures of all patterns used in TS operations within 17 the program. This information consists of an ordered list of the types for each distinct pattern, and is used primarily for matching purposes. <p> It then provides a done (id list) primitive 26 that commits all in operations in id list and all out operations whose parents are in id list. Other features similar to those provided in FT-Linda have also been proposed at various times. <ref> [27] </ref> discusses the idea of multiple tuple spaces, and some of the properties that might be supported in such a scheme. [16] briefly introduces composed statements, which provide a form of disjunction and conjunction. <p> Support for disjunction has also been discussed in <ref> [16, 27] </ref> and in the context of the Linda Program Builder [1, 2]. The Program Builder offers the abstraction of disjunction by mapping it onto ordinary Linda operations and hiding the details from the user.
Reference: [28] <author> LRW Systems. </author> <title> LRW TM LINDA-C for VAX User's Guide, 1991. Order number VLN-UG-102. </title>
Reference-contexts: is followed by some initial results on the performance of TS operations; given the current status of the implementation, these numbers measure only the overhead of tuple processing on a single processor, yet are instructive nevertheless. 5.2 Implementation Components The FT-Linda precompiler, FT-lcc, is a derivative of the lcc precompiler <ref> [27, 28] </ref>. FT-lcc performs two tasks in particular. First, it analyzes and catalogs the signatures of all patterns used in TS operations within 17 the program. This information consists of an ordered list of the types for each distinct pattern, and is used primarily for matching purposes.
Reference: [29] <author> Shivakant Mishra. </author> <title> Consul: A Communication Substrate for Fault-Tolerant Distributed Programs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, The University of Arizona, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda [40, 41, 23, 4, 24, 9, 15, 33]. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems <ref> [30, 29] </ref>, and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> For three replicas executing on Sun-3 workstations connected by a 10 Mb Ethernet, this dissemination and ordering time has been measured as approximately 4.0 msec <ref> [29] </ref>. We expect this number to improve once the port of Consul to a faster processor is completed. <p> Fortunately, Consul's membership service provides exactly the functionality required <ref> [29] </ref>. When a processor P i recovers, a restart message is multicast to the other processors, which then execute a protocol to add P i back into the group.
Reference: [30] <author> Shivakant Mishra, Larry L. Peterson, and Richard D. Schlichting. </author> <title> Consul: A communication substrate for fault-tolerant distributed programs. </title> <type> Technical Report 91-32, </type> <institution> Department of Computer Science, The University of Arizona, </institution> <year> 1991. </year>
Reference-contexts: These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda [40, 41, 23, 4, 24, 9, 15, 33]. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems <ref> [30, 29] </ref>, and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> The SMA is the basis for a large number of fault-tolerant distributed systems <ref> [7, 30, 34] </ref>. 2 This ordering can be relaxed in some cases; see [37]. 5 Given the use of replication to realize stable TSs, the next step is to consider schemes for implementing atomic execution of multiple tuple operations that use this TS.
Reference: [31] <author> B. J. Nelson. </author> <title> Remote Procedure Call. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <year> 1981. </year>
Reference-contexts: For example, Figure 17 demonstrates the differences in the processing of an AGS . Rather than requests being submitted to Consul directly from the FT-Linda library, a remote procedure call (RPC) <ref> [31] </ref> would be used to forward the request to a request handler process on a tuple server. This handler immediately submits it to Consul's multicast service as before.
Reference: [32] <author> Bill Nitzberg and Virginia Lo. </author> <title> Distributed shared memory: A survey of issues and algorithms. </title> <journal> Computer, </journal> <volume> 24(8) </volume> <pages> 52-60, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: One such language is Linda [16, 13, 17], a coordination language that provides a collection of primitives for process creation and interprocess communication that can be added to existing languages. The main abstraction provided by Linda is tuple space (TS), a distributed shared memory <ref> [32] </ref> that can be used by processes to communicate and synchronize despite the lack of physical shared memory. The abstraction is implemented by the Linda runtime system transparently to user processes.
Reference: [33] <author> Lewis I Patterson, Richard S Turner, Robert M. Hyatt, and Kevin D. Reilly. </author> <title> Construction of a fault-tolerant distributed tuple-space. </title> <booktitle> In Proceedings of the 1993 Symposium on Applied Computing, </booktitle> <pages> pages 279-285. </pages> <address> ACM/SIGAPP, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> One class does not extend Linda per se, but rather focuses on adding functionality to the implementation. [41, 40] give a design for making the standard Linda TS stable. The design is based on replicating tuples, and then using locks and a general commit protocol to perform updates. <ref> [33] </ref> also implements a stable TS by replication, but uses centralized algorithms to serialize tuple operations and achieve replica consistency for single TS operations. [15] addresses the issue of relaxing the consistency of the TS replicas to improve performance.
Reference: [34] <editor> D. Powell, editor. Delta-4: </editor> <title> A Generic Architecture for Dependable Distributed Computing. </title> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: The SMA is the basis for a large number of fault-tolerant distributed systems <ref> [7, 30, 34] </ref>. 2 This ordering can be relaxed in some cases; see [37]. 5 Given the use of replication to realize stable TSs, the next step is to consider schemes for implementing atomic execution of multiple tuple operations that use this TS.
Reference: [35] <author> D. Powell, D Seaton, G. Bonn, P. Verissimo, and F. Waeselynk. </author> <title> The Delta-4 approach to dependability in open distributed computing systems. </title> <booktitle> In Proceedings of the Eighteenth Symposium on Fault-Tolerant Computing, </booktitle> <address> Tokyo, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Although the language design is general, the focus in the implementation has been on tolerating so-called processor crash (or fail-silent) failures; such a failure occurs when a processor halts without undergoing any erroneous state transitions <ref> [35] </ref>. Finally, an interesting side effect of our implementation strategy is better semantics for structuring certain Linda applications even when fault-tolerance is not a concern. The remainder of this paper is organized as follows. Section 2 overviews Linda and some of the specific problems that failures can cause.
Reference: [36] <author> Richard D. Schlichting and Fred B. Schneider. </author> <title> Fail-stop processors: An approach to designing fault-tolerant computing systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(3) </volume> <pages> 222-238, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: Processors are assumed to suffer only fail-silent failures, in which execution halts without undergoing any incorrect state transitions or generating spurious messages. The FT-Linda runtime system, in turn, converts such failures into fail-stop failures <ref> [36] </ref> by providing failure notification in the form of a distinguished failure tuple that gets deposited into TS.
Reference: [37] <author> Fred Schneider. </author> <title> Implementing fault-tolerant services using the state machine approach. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(4) </volume> <pages> 299-319, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. Stable TSs are realized using the replicated state machine approach <ref> [37] </ref>, where tuples are replicated on multiple processors to provide failure resilience and then updated using atomic multicast. 1 Atomic execution of multiple tuple operations is achieved by placing some reasonable limits on the type of operations that can be included, and then using a single multicast message to update replicas. <p> In situations where stable values must also be shared among multiple processors as is the case here, replication is a more appropriate choice. To realize a replicated TS, we use a general technique called the replicated state machine approach (SMA) <ref> [37] </ref>. In this technique, an application is represented as a state machine that maintains state variables and makes modifications in response to commands from other state machines or the environment. <p> The SMA is the basis for a large number of fault-tolerant distributed systems [7, 30, 34]. 2 This ordering can be relaxed in some cases; see <ref> [37] </ref>. 5 Given the use of replication to realize stable TSs, the next step is to consider schemes for implementing atomic execution of multiple tuple operations that use this TS.
Reference: [38] <author> Edward Segall. </author> <title> Tuple Space Operations: Multiple-Key Search, On-line Matching, and Wait-free Synchronization. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering, Rutgers University, </institution> <year> 1993. </year>
Reference-contexts: See Section 4.2 for an example. 3 Initialization out (count; value) Inspection rd (count; ?value) Updating in (count; ?oldvalue) out (count; newvalue) consensus with more than two processes in the presence of failures or with arbitrarily slow (or busy) processors <ref> [38] </ref>. The key is lack of sufficient atomicity. Even typical Linda programs cannot be structured to handle failures with only single-op atomicity. To illustrate this, we consider specific problems that arise in two common Linda programming paradigms: the distributed variable and the bag-of-tasks. <p> While all these schemes are undoubtedly useful, we note again that adding only this type of functionality without extending the language has been shown to be inadequate for realizing common fault-tolerance paradigms <ref> [38] </ref>. Also, unlike our approach, all the designs discussed in this section require multiple messages to update the TS replicas; the sole exception is one special case in [15]. A few efforts have also extended Linda to provide additional atomicity for fault-tolerance purposes.
Reference: [39] <author> John Turek and Dennis Shasha. </author> <title> The many faces of consensus in distributed systems. </title> <journal> Computer, </journal> <volume> 25(6) </volume> <pages> 8-17, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Providing a means to execute multiple TS operations atomically is important for using Linda to program fault-tolerant applications. For example, distributed consensus, in which multiple processes in a distributed system reach agreement on some common value, is an important building block for many fault-tolerant systems <ref> [39] </ref>. However, Linda with single-op atomicity has been shown to be insufficient to reach distributed 1 If they do need to know, a process identifier or handle can be included in the tuple.
Reference: [40] <author> Andrew Xu. </author> <title> A fault-tolerant network kernel for Linda. </title> <type> Master's thesis, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> One class does not extend Linda per se, but rather focuses on adding functionality to the implementation. <ref> [41, 40] </ref> give a design for making the standard Linda TS stable.
Reference: [41] <author> Andrew Xu and Barbara Liskov. </author> <title> A design for a fault-tolerant, distributed implementation of Linda. </title> <booktitle> In Proceedings of the Nineteenth International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 199-206, </pages> <month> June </month> <year> 1989. </year> <month> 29 </month>
Reference-contexts: In addition, the design is in keeping with the minimalist philosophy of Linda, and results in an efficient implementation. These features help distinguish FT-Linda from other efforts aimed at introducing fault-tolerance into Linda <ref> [40, 41, 23, 4, 24, 9, 15, 33] </ref>. FT-Linda is being implemented using Consul, a communication substrate for building fault-tolerant systems [30, 29], and the x-kernel, an operating system kernel that provides support for composing network protocols [21]. <p> One class does not extend Linda per se, but rather focuses on adding functionality to the implementation. <ref> [41, 40] </ref> give a design for making the standard Linda TS stable.
References-found: 41

