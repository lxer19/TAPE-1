URL: http://www.ai.mit.edu/~edelman/mirror/cs-tr-95-11.ps.Z
Refering-URL: http://www.ai.mit.edu/~edelman/archive.html
Root-URL: 
Email: [sharon,edelman]@wisdom.weizmann.ac.il  
Title: On Similarity to Prototypes in 3D Object Representation  
Author: Sharon Duvdevani-Bar Shimon Edelman 
Date: July 20, 1995  
Address: Rehovot 76100, Israel  
Affiliation: Dept. of Applied Mathematics and Computer Science The Weizmann Institute of Science  
Abstract: A representational scheme under which the ranking between represented dissimilarities is isomorphic to the ranking between the corresponding shape dissimilarities can support perfect shape classification, because it preserves the clustering of shapes according to the natural kinds prevailing in the external world. We discuss the computational requirements of rank-preserving representation, and examine its plausibility within a prototype-based framework of shape vision. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Adini, Y., Moses, Y., and Ullman, S. </author> <year> (1993). </year> <title> Face recognition: the problem of compensating for changes in illumination direction. </title> <type> CS-TR 93-21, </type> <institution> Weizmann Institute of Science. </institution>
Reference-contexts: It has been pointed out in the past that singularities in M 1 (such as accidents of projection, illumination, etc.) may pose a problem for distance-based recognition systems by mapping disparate objects into similar images <ref> (Adini et al., 1993) </ref>.
Reference: <author> Bellman, R. E. </author> <year> (1961). </year> <title> Adaptive Control Processes. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ. </address>
Reference-contexts: Now, problems formulated in high-dimensional spaces tend to be computationally unmanageable | a phenomenon which came to be known as the curse of dimensionality <ref> (Bellman, 1961) </ref>. In particular, learning and generalization, whether formulated in statistical terms (Stone, 1982) or in terms of training a neural network (Haussler, 1992), require too many examples if attempted in a high-dimensional space.
Reference: <author> Bourgain, J. </author> <year> (1985). </year> <title> On Lipschitz embedding of finite metric spaces in Hilbert space. </title> <journal> Israel J. Math., </journal> <volume> 52 </volume> <pages> 46-52. </pages>
Reference: <author> Bulthoff, H. H. and Edelman, S. </author> <year> (1992). </year> <title> Psychophysical support for a 2-D view interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academy of Science, </booktitle> <volume> 89 </volume> <pages> 60-64. </pages>
Reference: <author> Burns, J., Weiss, R., and Riseman, E. </author> <year> (1993). </year> <title> View variation of point-set and line segment features. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15 </volume> <pages> 51-68. </pages>
Reference-contexts: One may observe (Figure 10, right), however, that projected ratios of segment lengths do tend to stay close to the true ratios <ref> (Burns et al., 1993) </ref>. Thus, one may hope that the set of all pairwise projected distances will carry sufficient information to allow the recovery of the configuration of the points in 3D.
Reference: <author> Cerella, J. </author> <year> (1987). </year> <title> Pigeons and perceptrons. </title> <journal> Pattern Recognition, </journal> <volume> 19 </volume> <pages> 431-438. </pages>
Reference-contexts: Two examples illustrating this point are, on the one hand, the apparent inability of pigeons to learn the distinction between scrambled and intact cartoon characters <ref> (Cerella, 1987) </ref>, and, on the other hand, the striking similarity between patterns of internal representation of shape, recovered using multidimensional scaling from chimpanzee and human behavioral data (Tomonaga and Matsuzawa, 1992). 5.4 Future work We conclude this work by listing a number of directions in which it can be extended.
Reference: <author> Cohn, H. </author> <year> (1967). </year> <title> Conformal mappings on Riemann surfaces. </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: Specifically, a mapping realized by an analytic function with a non-vanishing Jacobian in a given region is conformal there, that is, it preserves angles <ref> (Cohn, 1967) </ref>. Such a function preserves similitude of small triangles; in particular, a scalene triangle formed by a triplet of points will be mapped into a triangle with the same ranking of side lengths (see Figure 1). Conformality in higher dimensions is much more restrictive.
Reference: <author> Cummins, R. </author> <year> (1989). </year> <title> Meaning and mental representation. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Finally, section 5 includes a summary and a discussion of some open issues. 2 First and second-order isomorphism in representation 2.1 The two problems of representation It is possible to distinguish between two problems about mental representation <ref> (Cummins, 1989) </ref>. The first of these, the problem of representations (plural), is basically empirical; two instances of this problem are the unraveling of the representations employed by natural cognitive systems, and the design of the representational substrate for artificial cognitive modules. <p> Suppes, Pavel and Falmagne (1994) state flatly "Representation of something is an image, model, or reproduction of that thing"; this amounts to the Aristotelian idea of representation by resemblance, which happens to have been discredited so strongly as to become a rare point of consensus in the philosophy of mind <ref> (Cummins, 1989) </ref>. The present paper takes a middle path between these two extremes, by abandoning the question "what is representation" in favor of "what can make it work," and by trying to bring certain recent findings in vision to bear on that latter formulation of the Problem of Representation.
Reference: <author> Cutzu, F. and Edelman, S. </author> <year> (1994). </year> <title> Canonical views in object representation and recognition. </title> <journal> Vision Research, </journal> <volume> 34 </volume> <pages> 3037-3056. </pages>
Reference: <author> Cutzu, F. and Edelman, S. </author> <year> (1995). </year> <title> Explorations of shape space. </title> <type> CS-TR 95-01, </type> <institution> Weizmann Institute of Science. </institution>
Reference-contexts: To explore shape space, we employed parameterized animal-like objects, courtesy of F. Cutzu <ref> (Cutzu and Edelman, 1995) </ref>. Each object was encoded by a vector of 70 parameters (a point in R 70 ); the Euclidean distance between two such points is a natural measure of dissimilarity between the two corresponding shapes. <p> In the remainder of this section, we cite psychophysical support for the idea of parametrically faithful representation, discuss a number of open issues, and list directions for future research. the experiments described in <ref> (Cutzu and Edelman, 1995) </ref>. The inset shows an enlargement of one of the objects. Middle: the 2D MDS solution for subject VAL (badness-of-fit 0.04, distance correlation 0.99). The labeling of the individual points is the same as in the diagram on the left. <p> Psychophysics of shape representation. Psychophysical investigations constitute an important source of support for theories of representation. One of our central aims is, therefore, to construct a computational model replicating the psychophysical findings of <ref> (Cutzu and Edelman, 1995) </ref>.
Reference: <author> Dretske, F. </author> <year> (1981). </year> <title> Knowledge and the flow of information. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: filters with radially elongated Gaussian receptive fields, randomly positioned over the image (Weiss and Edelman, 1995); 8 Such a demonstration would substantiate Dretske's remark that sufficiently complex systems relying on representation by covariation can reflect properties of distal objects, and not only of the objects residing in the system's sensorium <ref> (Dretske, 1981) </ref>. 9 Note that the Hausdorff metric does not require the knowledge of point-to-point correspondence between the objects, but is sensitive to the omission of some of the points, such as caused, e.g., by occlusion, and to the presence of outliers, or points wrongly attributed to a given object.
Reference: <author> Duda, R. O. and Hart, P. E. </author> <year> (1973). </year> <title> Pattern classification and scene analysis. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: The Voronoi diagram is a useful geometrical data structure, and is especially suitable for supporting nearest-neighbor classification <ref> (Duda and Hart, 1973) </ref>. Within the Voronoi diagram, the cell V (p i ) containing the i'th prototype is the set of all vectors x for which kx p i k kx p j k; 8j 6= i.
Reference: <author> Edelman, S. </author> <year> (1995a). </year> <title> Class similarity and viewpoint invariance in the recognition of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 72 </volume> <pages> 207-220. </pages>
Reference: <author> Edelman, S. </author> <year> (1995b). </year> <title> Representation of similarity in 3D object discrimination. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 407-422. </pages>
Reference: <author> Edelman, S. </author> <year> (1995c). </year> <title> Representation, Similarity, and the Chorus of Prototypes. </title> <journal> Minds and Machines, </journal> <volume> 5 </volume> <pages> 45-68. </pages>
Reference-contexts: Nevertheless, representations of a sufficient variety of objects, or prototypes, taken together, can serve as a basis for a provably faithful distributed (ensemble) representation of a completely unfamiliar shape, as noted in <ref> (Edelman, 1995c) </ref>. <p> The scheme, called the Chorus of Prototypes, has been proposed in <ref> (Edelman, 1995c) </ref>, and is illustrated in Figures 3 and 4. The basic motivation behind Chorus is to represent the shape of an object by holistic similarities to related shapes, and thus to avoid the need to specify explicitly the object's geometry. <p> Right: The outputs of recognizers correspond to distances between the stimulus and the preferred stimulus of each recognizer. Adapted from <ref> (Edelman, 1995c) </ref>. 8 Consider the mapping M : R n ! R n implemented by such a system. <p> In comparison, the Chorus Transform offers a method for describing the input in terms of holistic features (here, literally, distances to whole objects). Such features have the computational advantage of being directly learnable <ref> (Edelman, 1995c) </ref>.
Reference: <author> Edelman, S. and Bulthoff, H. H. </author> <year> (1992). </year> <title> Orientation dependence in the recognition of familiar and novel views of 3D objects. </title> <journal> Vision Research, </journal> <volume> 32 </volume> <pages> 2385-2400. </pages>
Reference-contexts: A collection of graded and highly overlapping RFs can support fine spatial discrimination (Snippe and Koenderink, 1992), including hyperacuity-level resolution (Weiss et al., 1993) and discrimination among highly complex stimuli such as images of human faces <ref> (Edelman et al., 1992) </ref>. The results of the simulations described in this section illustrate another aspect of the computational power of simple graded-profile RFs: changes in 3D object appearance due to gradual changes in viewing position are reflected monotonically in the high-dimensional space spanned by the activities of the RFs.
Reference: <author> Edelman, S., Reisfeld, D., and Yeshurun, Y. </author> <year> (1992). </year> <title> Learning to recognize faces from examples. </title> <editor> In Sandini, G., editor, </editor> <booktitle> Proc. 2nd European Conf. on Computer Vision, Lecture Notes in Computer Science, </booktitle> <volume> volume 588, </volume> <pages> pages 787-791. </pages> <publisher> Springer Verlag. 26 Edelman, </publisher> <editor> S. and Weinshall, D. </editor> <year> (1991). </year> <title> A self-organizing multiple-view representation of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> <pages> 209-219. </pages>
Reference-contexts: A collection of graded and highly overlapping RFs can support fine spatial discrimination (Snippe and Koenderink, 1992), including hyperacuity-level resolution (Weiss et al., 1993) and discrimination among highly complex stimuli such as images of human faces <ref> (Edelman et al., 1992) </ref>. The results of the simulations described in this section illustrate another aspect of the computational power of simple graded-profile RFs: changes in 3D object appearance due to gradual changes in viewing position are reflected monotonically in the high-dimensional space spanned by the activities of the RFs.
Reference: <author> Goebel, K. and Kirk, W. A. </author> <year> (1990). </year> <title> Topics in metric fixed point theory. Number 28 in Cambridge studies in advanced mathematics. </title> <publisher> Cambridge Univ. Press. </publisher>
Reference: <author> Goldstone, R. L. </author> <year> (1994). </year> <title> The role of similarity in categorization: providing a groundwork. </title> <journal> Cognition, </journal> <volume> 52 </volume> <pages> 125-157. </pages>
Reference: <author> Haussler, D. </author> <year> (1992). </year> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100 </volume> <pages> 78-150. </pages>
Reference-contexts: Now, problems formulated in high-dimensional spaces tend to be computationally unmanageable | a phenomenon which came to be known as the curse of dimensionality (Bellman, 1961). In particular, learning and generalization, whether formulated in statistical terms (Stone, 1982) or in terms of training a neural network <ref> (Haussler, 1992) </ref>, require too many examples if attempted in a high-dimensional space. Dimensionality reduction has been posed in the past as a primary purpose of feature extraction (Intrator, 1992). The concept of a feature in pattern recognition usually refers to relatively simple measurements on the input.
Reference: <author> Humphrey, G. K. and Khan, S. C. </author> <year> (1992). </year> <title> Recognizing novel views of three-dimensional objects. Can. </title>
Reference: <editor> J. Psychol., </editor> <volume> 46 </volume> <pages> 170-190. </pages>
Reference: <author> Intrator, N. </author> <year> (1992). </year> <title> Feature extraction using an unsupervised neural network. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 98-107. </pages>
Reference-contexts: In particular, learning and generalization, whether formulated in statistical terms (Stone, 1982) or in terms of training a neural network (Haussler, 1992), require too many examples if attempted in a high-dimensional space. Dimensionality reduction has been posed in the past as a primary purpose of feature extraction <ref> (Intrator, 1992) </ref>. The concept of a feature in pattern recognition usually refers to relatively simple measurements on the input. In comparison, the Chorus Transform offers a method for describing the input in terms of holistic features (here, literally, distances to whole objects).
Reference: <author> Johnson, W. B. and Lindenstrauss, J. </author> <year> (1984). </year> <title> Extensions of Lipschitz mappings into a Hilbert space. </title> <journal> Contemporary Mathematics, </journal> <volume> 26 </volume> <pages> 189-206. </pages>
Reference-contexts: A typical theorem from this field <ref> (Johnson and Lindenstrauss, 1984) </ref> states that, given n points fv 1 ; v 2 ; : : : ; v n g in any Euclidean space S with distances d ij = d (v i ; v j ), it is possible to find n points fw 1 ; w 2
Reference: <author> Jolicoeur, P. and Humphrey, G. K. </author> <year> (1994). </year> <title> Perception of rotated two-dimensional and three-dimensional objects and visual shapes. In Walsh, </title> <editor> V. and Kulikowski, J., editors, </editor> <title> Perceptual constancies, chapter 10. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK. </address> <publisher> in press. </publisher>
Reference-contexts: the past few years led to the characterization of certain basic limitations of the visual system in generalizing shape-based recognition to novel conditions (Rock and DiVita, 1987; Tarr and Pinker, 1989; Bulthoff and Edelman, 1992; Edelman and Bulthoff, 1992; Humphrey and Khan, 1992; Edelman, 1995a; Cutzu and Edelman, 1994); see <ref> (Jolicoeur and Humphrey, 1994) </ref> for an extensive review and a discussion.
Reference: <author> Kanatani, K. </author> <year> (1990). </year> <title> Group-theoretical methods in image understanding. </title> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference-contexts: The results (Figure 16, left) indicate that RF-space distance generally covaries monotonically with angular rotation distance between 10 The angular rotation distance is the angle ff for which 1 + 2 cos ff = trace (M ), where M is the rotation matrix transforming one view into the other (see <ref> (Kanatani, 1990) </ref>, p.205); other measures of distance can be used as well. 17 Left: views of a cow the Badness-of-Fit criterion (Kruskal, 1964) is 0:08.
Reference: <author> Kruskal, J. B. </author> <year> (1964). </year> <title> Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis. </title> <journal> Psychometrika, </journal> <volume> 29(1) </volume> <pages> 1-27. </pages>
Reference-contexts: distance is the angle ff for which 1 + 2 cos ff = trace (M ), where M is the rotation matrix transforming one view into the other (see (Kanatani, 1990), p.205); other measures of distance can be used as well. 17 Left: views of a cow the Badness-of-Fit criterion <ref> (Kruskal, 1964) </ref> is 0:08. Right: views of a martini the Badness-of-Fit is 0:03. electronically, at URL ftp://avalon.vislab.navy.mil/pub/objects/. 18 Objective and RF-space projective distances for three of the 3D object shown in Figure 14 (left: cannon, middle: mug, right: torus). Bottom: The deviation from monotonicity for each of these objects.
Reference: <author> Kruskal, J. B. and Wish, M. </author> <year> (1978). </year> <title> Multidimensional Scaling. </title> <publisher> Sage Piblications, </publisher> <address> Beverly Hills, CA. </address>
Reference: <author> Lando, M. and Edelman, S. </author> <year> (1995). </year> <title> Generalization from a single view in face recognition. </title> <type> CS-TR 95-02, </type> <institution> Weizmann Institute of Science. </institution>
Reference-contexts: Recent experiments with human face images indicate that this situation can be amended to a considerable extent by the action of an appropriately devised mapping M 2 <ref> (Lando and Edelman, 1995) </ref>; in some cases, simulating the action of the initial stages of primate vision results in satisfactory remapping of the representational space (Weiss and Edelman, 1995). <p> Each object appeared at one of four viewpoints, corresponding to the vertices of a regular tetrahedron centered on the object. In the configuration recovered by MDS, corresponding views of the different objects clustered together, as can be seen in Figure 18 <ref> (cf. Lando and Edelman, 1995) </ref>. It may be noted that RF-space distances, calculated between images of six test shapes and a reference one, covaried monotonically with the parameter-space distances among the corresponding shapes (Figure 19).
Reference: <author> Linial, N., London, E., and Rabinovich, Y. </author> <year> (1994). </year> <title> The geometry of graphs and some of its algorithmic applications. </title> <journal> FOCS, </journal> <volume> 35 </volume> <pages> 577-591. </pages>
Reference-contexts: Finally, distance ranks are preserved under view-space rotation, RF-space transduction and CT application. 11 Any finite set of n points can be isometrically embedded into l n 1 , simply by setting the coordinates of a point to the vector of its distances to all other points in the set <ref> (Linial et al., 1994) </ref>. 19 a mug, plotted against objective (rotation-space) distance between the corresponding views. The error bar denotes the mean standard error of the mean, calculated for 10 random views. Right: Preservation of similarity ranks under rotation, RF-space transduction, and CT application. <p> Characterization of embeddings that preserve distance ranks. Mathematical investigations of mappings with bounded distortion (Reshetnyak, 1989) and of nearly isometric dimensionality-reducing embeddings <ref> (Linial et al., 1994) </ref> are all formulated in terms of distance preservation. It would be interesting to see whether useful results can be derived under the constraint of distance rank preservation, which is directly relevant to the issue of faithful representation. Choice of prototypes in Chorus.
Reference: <author> Manolache, F. and Edelman, S. </author> <year> (1993). </year> <title> Generation of natural-looking 3D shapes by simulated evolution. </title> <type> CS-TR 93-13, </type> <institution> Weizmann Institute of Science. </institution>
Reference: <author> Marr, D. </author> <year> (1982). </year> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Mendenhall, W. and Sincich, T. </author> <year> (1988). </year> <institution> Statistics for the engineering and computer sciences. Macmil lan, </institution> <address> London. </address>
Reference-contexts: formula (which can be reliably employed when the total number of tied measurements is not large relative to n) is r s = 1 i n (n 2 1) , where d i are the differences in the ranks of the i th component of the vectors to be correlated <ref> (Mendenhall and Sincich, 1988) </ref>. In that formula, only the number of mismatches in ranks and their magnitude enter the calculation. In our case, however, we must take into account the positions of the mismatches as well.
Reference: <author> Nicod, J. </author> <year> (1930). </year> <title> Foundations of Geometry and Induction. </title> <publisher> Routledge & Kegan Paul. </publisher>
Reference: <author> Nosofsky, R. M. </author> <year> (1988). </year> <title> Exemplar-based accounts of relations between classification, recognition, and typicality. </title> <journal> Journal of Experimental Psychology: Learning, Memory and Cognition, </journal> <volume> 14 </volume> <pages> 700-708. </pages>
Reference: <author> Palmer, S. E. </author> <year> (1978). </year> <title> Fundamental aspects of cognitive representation. </title> <editor> In Rosch, E. and Lloyd, B. B., editors, </editor> <booktitle> Cognition and Categorization, </booktitle> <pages> pages 259-303. </pages> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ. </address> <note> 27 Poggio, </note> <author> T. </author> <year> (1990). </year> <title> A theory of how the brain might work. </title> <booktitle> Cold Spring Harbor Symposia on Quantitative Biology, </booktitle> <address> LV:899-910. </address>
Reference: <author> Poggio, T. and Edelman, S. </author> <year> (1990). </year> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266. </pages>
Reference-contexts: The Chorus scheme is implemented by a bank of classifiers, each tuned to a particular point in the distal space (its optimal stimulus), with the response falling off gradually and monotonically with distance from the optimal point, as in the hidden-layer units in a radial basis function (RBF) approximation module <ref> (Poggio and Girosi, 1990) </ref>.
Reference: <author> Poggio, T. and Girosi, F. </author> <year> (1990). </year> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247 </volume> <pages> 978-982. </pages>
Reference-contexts: The Chorus scheme is implemented by a bank of classifiers, each tuned to a particular point in the distal space (its optimal stimulus), with the response falling off gradually and monotonically with distance from the optimal point, as in the hidden-layer units in a radial basis function (RBF) approximation module <ref> (Poggio and Girosi, 1990) </ref>.
Reference: <author> Preparata, F. P. and Shamos, M. I. </author> <year> (1985). </year> <title> Computational Geometry. </title> <publisher> Springer Verlag, </publisher> <address> New York. </address>
Reference-contexts: The Voronoi diagram <ref> (Preparata and Shamos, 1985) </ref> of a set S = fp i g n i=1 is a sequence Vor (S) = fV (p i )g n i=1 of convex polyhedra covering d-space, where V (p i ) = fx 2 R d : d (x; p i ) d (x; p j
Reference: <author> Quine, W. V. O. </author> <year> (1969). </year> <title> Natural kinds. </title> <booktitle> In Ontological relativity and other essays, </booktitle> <pages> pages 114-138. </pages> <publisher> Columbia University Press, </publisher> <address> New York, NY. </address>
Reference-contexts: Intuitively, we would like the representation to capture the similarity relationships within and between natural kinds <ref> (Quine, 1969) </ref>. More specifically, similarity is seen to be relevant both to recognition, in which case resemblance between the viewed shape and some previously seen ones is to be assessed, and to classification, where similarities between a shape and a number of shape classes are compared (Nosofsky, 1988; Goldstone, 1994).
Reference: <author> Quine, W. V. O. </author> <year> (1973). </year> <title> The roots of reference. Open Court, </title> <address> La Salle, IL. </address>
Reference: <author> Reshetnyak, Y. G. </author> <year> (1989). </year> <title> Space mappings with bounded distortion, volume 73 of Translations of mathematical monographs. </title> <publisher> Amer. Math. Soc., </publisher> <address> Providence, RI. </address>
Reference-contexts: Consider the simple ratio of x; y; z, defined as hx ; y ; zi = jx yj=jy zj (3) Obviously, a mapping S : R n ! R n preserves distance ranks iff it preserves hx ; y ; zi for any choice of points. As shown in <ref> (Reshetnyak, 1989) </ref>, p.32, a bijective mapping S with this property must be a similitude (that is, a mapping of the form S (x) = P (x), where &gt; 0; 2 R, and P : R n ! R n is an orthogonal transformation). <p> Such mappings, called Mobius transformations, constitute a finite-dimensional Lie group which includes the group of motions in R n and is only slightly broader than that group <ref> (Reshetnyak, 1989) </ref>. 6 2.4.3 Local approximate rank preservation A considerably broader class of mappings emerges if the requirement of conformality is replaced by that of quasiconformality. <p> Intuitively, a regular topological mapping is quasiconformal if there exists a constant q, 1 q 1, such that almost any infinitesimally small sphere is transformed into an ellipsoid for which the ratio of the largest semiaxis to the smallest one does not exceed q <ref> (Reshetnyak, 1989) </ref>. Under such a mapping, the ranks of distances between points are not strictly preserved, but are guaranteed not to change too much, if q is sufficiently close to 1. <p> Characterization of embeddings that preserve distance ranks. Mathematical investigations of mappings with bounded distortion <ref> (Reshetnyak, 1989) </ref> and of nearly isometric dimensionality-reducing embeddings (Linial et al., 1994) are all formulated in terms of distance preservation. It would be interesting to see whether useful results can be derived under the constraint of distance rank preservation, which is directly relevant to the issue of faithful representation.
Reference: <author> Rock, I. and DiVita, J. </author> <year> (1987). </year> <title> A case of viewer-centered object perception. </title> <journal> Cognitive Psychology, </journal> <volume> 19 </volume> <pages> 280-293. </pages>
Reference: <author> Rosch, E. </author> <year> (1978). </year> <title> Principles of categorization. </title> <editor> In Rosch, E. and Lloyd, B., editors, </editor> <booktitle> Cognition and Categorization, </booktitle> <pages> pages 27-48. </pages> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., and Boyes-Braem, P. </author> <year> (1976). </year> <title> Basic objects in natural categories. </title> <journal> Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 382-439. </pages> <note> Sas (1989). SAS/STAT User's Guide, Version 6. </note> <institution> SAS Institute Inc., Cary, NC. </institution>
Reference: <author> Shepard, R. N. </author> <year> (1968). </year> <title> Cognitive psychology: A review of the book by U. </title> <journal> Neisser. Amer. J. Psychol., </journal> <volume> 81 </volume> <pages> 285-289. </pages>
Reference-contexts: Barring resemblance, or "first-order structural isomorphism" <ref> (Shepard, 1968) </ref> between the object and the entity that stands for it internally, what relationship can qualify as representation of something by something else? Shepard (1968) suggests "second-order" isomorphism: ": : : the isomorphism should be sought | not in the first-order relation between (a) an individual object, and (b) its
Reference: <author> Shepard, R. N. </author> <year> (1980). </year> <title> Multidimensional scaling, tree-fitting, and clustering. </title> <journal> Science, </journal> <volume> 210 </volume> <pages> 390-397. </pages>
Reference-contexts: Curiously, the Problem of Representation is rarely discussed in cognitive psychology. Arguments put forward by Marr (1982) prompted cognitive scientists to contemplate the fact that not all representations are computationally equivalent; the classical example here is the difficulty of doing arithmetics 2 Nonmetric MDS <ref> (Shepard, 1980) </ref> is an algorithm for embedding a set of points in a metric space, while preserving as closely as possible the ranking of pairwise distances between the points, specified in advance.
Reference: <author> Shepard, R. N. and Chipman, S. </author> <year> (1970). </year> <title> Second-order isomorphism of internal representations: Shapes of states. </title> <journal> Cognitive Psychology, </journal> <volume> 1 </volume> <pages> 1-17. </pages>
Reference-contexts: Thus, although the internal representation for a square need not itself be square, it should (whatever it is) at least have a closer functional relation to the internal representation for a rectangle than to that, say, for a green flash or the taste of a persimmon," <ref> (Shepard and Chipman, 1970, p.2) </ref>. isomorphism (in this case, isomorphism between distance ranks in the two spaces). 2.2 Conditions for faithful representation Let us now identify mathematical conditions under which isomorphism between distal and proximal relations gives rise to representation which is, in a sense, true to the original. 3 Let
Reference: <author> Snippe, H. P. and Koenderink, J. J. </author> <year> (1992). </year> <title> Discrimination thresholds for channel-coded systems. </title> <journal> Biological Cybernetics, </journal> <volume> 66 </volume> <pages> 543-551. </pages>
Reference-contexts: Second, M is regular, provided that the input space is properly covered by the classifiers so as to avoid metameries <ref> (Snippe and Koenderink, 1992) </ref>. <p> The particular mechanism we used | receptive fields | is described below. 4.2.1 Image transduction by receptive fields Receptive fields (RFs) are probably the most prominent and ubiquitous computational mechanism employed by biological information processing systems. A collection of graded and highly overlapping RFs can support fine spatial discrimination <ref> (Snippe and Koenderink, 1992) </ref>, including hyperacuity-level resolution (Weiss et al., 1993) and discrimination among highly complex stimuli such as images of human faces (Edelman et al., 1992).
Reference: <author> Stone, C. J. </author> <year> (1982). </year> <title> Optimal global rates of convergence for nonparametric regression. </title> <journal> Annals of statistics, </journal> <volume> 10 </volume> <pages> 1040-1053. </pages>
Reference-contexts: Now, problems formulated in high-dimensional spaces tend to be computationally unmanageable | a phenomenon which came to be known as the curse of dimensionality (Bellman, 1961). In particular, learning and generalization, whether formulated in statistical terms <ref> (Stone, 1982) </ref> or in terms of training a neural network (Haussler, 1992), require too many examples if attempted in a high-dimensional space. Dimensionality reduction has been posed in the past as a primary purpose of feature extraction (Intrator, 1992).
Reference: <author> Suppes, P., Pavel, M., and Falmagne, J. </author> <year> (1994). </year> <title> Representations and models in psychology. </title> <journal> Ann. Rev. Psychol., </journal> <volume> 45 </volume> <pages> 517-544. </pages>
Reference: <author> Tarr, M. and Pinker, S. </author> <year> (1989). </year> <title> Mental rotation and orientation-dependence in shape recognition. </title> <journal> Cognitive Psychology, </journal> <volume> 21 </volume> <pages> 233-282. </pages>
Reference: <author> Tomonaga, M. and Matsuzawa, T. </author> <year> (1992). </year> <title> Perception of complex geometric figures in chimpanzees (pan troglodytes) and humans (homo sapiens): analyses of visual similarity on the basis of choice reaction time. </title> <journal> J. Comparative Psychol., </journal> <volume> 106 </volume> <pages> 43-52. </pages> <note> 28 Ullman, </note> <author> S. and Basri, R. </author> <year> (1991). </year> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 13:992-1005. 
Reference-contexts: illustrating this point are, on the one hand, the apparent inability of pigeons to learn the distinction between scrambled and intact cartoon characters (Cerella, 1987), and, on the other hand, the striking similarity between patterns of internal representation of shape, recovered using multidimensional scaling from chimpanzee and human behavioral data <ref> (Tomonaga and Matsuzawa, 1992) </ref>. 5.4 Future work We conclude this work by listing a number of directions in which it can be extended. Characterization of embeddings that preserve distance ranks.
Reference: <author> Weiss, Y. and Edelman, S. </author> <year> (1995). </year> <title> Representation of similarity as a goal of early visual processing. </title> <journal> Network, </journal> <volume> 6 </volume> <pages> 19-41. </pages>
Reference-contexts: with human face images indicate that this situation can be amended to a considerable extent by the action of an appropriately devised mapping M 2 (Lando and Edelman, 1995); in some cases, simulating the action of the initial stages of primate vision results in satisfactory remapping of the representational space <ref> (Weiss and Edelman, 1995) </ref>. <p> In the simulations, 3D objects rotating in space were rendered using the SGI Open Inventor graphics toolkit (see Figure 12). The images were then transduced using a set of 200 filters with radially elongated Gaussian receptive fields, randomly positioned over the image <ref> (Weiss and Edelman, 1995) </ref>; 8 Such a demonstration would substantiate Dretske's remark that sufficiently complex systems relying on representation by covariation can reflect properties of distal objects, and not only of the objects residing in the system's sensorium (Dretske, 1981). 9 Note that the Hausdorff metric does not require the knowledge
Reference: <author> Weiss, Y., Edelman, S., and Fahle, M. </author> <year> (1993). </year> <title> Models of perceptual learning in vernier hyperacuity. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <month> 695-718. </month> <title> 29 approximation to the Lipschitz coefficient L, for which kCT (x) CT (y)k Lkx yk was calculated for 100 points in R 1000 for the non-normalized version of CT (without the factor of p n; solid line) and for the normalized CT (dotted line). Compare the behavior of the resulting Lipschitz coefficient to that of the normalization factor f (n) = p n, where n is the number of prototypes (right). </title>
Reference-contexts: A collection of graded and highly overlapping RFs can support fine spatial discrimination (Snippe and Koenderink, 1992), including hyperacuity-level resolution <ref> (Weiss et al., 1993) </ref> and discrimination among highly complex stimuli such as images of human faces (Edelman et al., 1992).
References-found: 55

