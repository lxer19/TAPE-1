URL: ftp://ftp.cc.gatech.edu/pub/ai/ram/er-98-03.ps.Z
Refering-URL: http://www.cs.gatech.edu/people/home/markd/abstracts/aaai-98.abstract.html
Root-URL: 
Email: markd@cc.gatech.edu ashwin@cc.gatech.edu  
Title: Needles in a Haystack Plan Recognition in Large Spatial Domains Involving Multiple Agents  
Author: Mark Devaney and Ashwin Ram 
Address: Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Note: AAAI-98, Madison, WI, to appear  
Abstract: While plan recognition research has been applied to a wide variety of problems, it has largely made identical assumptions about the number of agents participating in the plan, the observability of the plan execution process, and the scale of the domain. We describe a method for plan recognition in a real-world domain involving large numbers of agents performing spatial maneuvers in concert under conditions of limited observability. These assumptions differ radically from those traditionally made in plan recognition and produce a problem which combines aspects of the fields of plan recognition, pattern recognition, and object tracking. We describe our initial solution which borrows and builds upon research from each of these areas, employing a pattern-directed approach to recognize individual movements and generalizing these to produce inferences of large-scale behavior. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J.F. </author> <year> 1991. </year> <title> Temporal reasoning and planning. </title> <editor> In J.F. Allen, et. al. </editor> <booktitle> Reasoning About Plans, </booktitle> <pages> 1-67. </pages> <address> San Mateo, </address> <publisher> CA : Morgan Kaufmann. </publisher>
Reference-contexts: Work in "multi-agent" plan recognition shares this assumption as well, the distinction being that an agent is considering the possible individual plans of several agents (e.g., Huber and Durfee 1995; Tambe 1995) or that there are other agents active in the world which may be causing changes <ref> (e.g., Traum and Allen 1991) </ref>. Complete and correct information The observations available are correct, i.e., they correspond to Copyright c fl1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. the actual behavior of the observed agent, and they are complete, i.e., no actions were performed which were not noticed.
Reference: <author> Bares, M., et. al. </author> <year> 1994. </year> <title> XPLANS: Case-based reasoning for plan recognition. </title> <booktitle> Applied Artificial Intelligence 8 </booktitle> <pages> 617-643. </pages>
Reference-contexts: A further distinguishing characteristic of a real-world domain is that the data not only arrives in real time, but more importantly, must be processed in real time <ref> (Bares, et. al. 1994) </ref>. A final assumption resulting from the scale of the data is that much of the input does not correspond to any meaningful pattern of activity.
Reference: <author> Clementini, E., Di Felice, P., and Hernandez, D. </author> <year> 1997. </year> <title> Qualitative representation of positional information. </title> <booktitle> Artificial Intelligence 95 </booktitle> <pages> 317-356. </pages>
Reference-contexts: Heading is stored simply as a binary comparison (same/not-same), although it may prove necessary to employ a slightly finer-grained range representation in the future <ref> (such as that described by Clementini, Di Felice, and Hernanandez 1997) </ref>. Finally, relative velocity is stored as a three-attribute feature (both moving, neither moving, different). These properties of agent-pairs are referred to as the "primitive" relationships because they are obtained directly from the low-level data.
Reference: <author> Devaney, M. and Ram, A. </author> <year> 1997. </year> <title> Situation development in a complex real-world domain. </title> <booktitle> In Proceedings ICML '97 Workshop on Applications of ML to the Real World. </booktitle>
Reference-contexts: It is also possible to construct higher-level attributes from raw data using domain-specific knowledge <ref> (e.g., Devaney and Ram, 1997) </ref>, but this, of course, incurs additional computational overhead. Currently we are most interested in what type of success can be achieved using the minimum amount of knowledge, but the processes described here are independent of which attributes are employed.
Reference: <author> Di Eugenio, B. </author> <year> 1995. </year> <title> Plan Recognition and Natural Language Understanding. </title> <booktitle> In Proceedings IJCAI '95 Workshop : The Next Generation of Plan Recognition Systems : Challenges for and Insight from Related Areas of AI. </booktitle>
Reference-contexts: Introduction Plan recognition, the problem of inferring goals, intentions, or future actions given observations of ongoing behavior, has been widely studied in Artificial Intelligence in the context of a number of different applications. Some of these applications include the inference of a user's beliefs in natural language or story understanding <ref> (e.g., Di Eugenio 1995) </ref>, inference of a user's intents in intelligent user interfaces (e.g., Wrn 1996), identification of an autonomous agent's goal in order to coordinate activity (e.g., Huber and Durfee 1995), and for program understanding in the field of software engineering (e.g., Woods and Yang 1998).
Reference: <author> Gahegan, M. </author> <year> 1995. </year> <title> Proximity operators for qualitative spatial reasoning. </title> <editor> In A. U. Frank & W. Kuhn (Eds.), </editor> <title> Spatial Information Theory. A Theoretical Basis for GIS, </title> <booktitle> International Conference (COSIT `95), Lecture Notes in Computer Science 988, </booktitle> <volume> 31 - 43, </volume> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For this reason, the differences are represented qualitatively, with only important distinctions being preserved. Relative distances are computed as a percentage of the maximum possible distance given the bounding rectangle of all units, a representation that has proven useful for spatial reasoning <ref> (Gahegan 1995) </ref>. Heading is stored simply as a binary comparison (same/not-same), although it may prove necessary to employ a slightly finer-grained range representation in the future (such as that described by Clementini, Di Felice, and Hernanandez 1997).
Reference: <author> Hernandez, D. </author> <year> 1994. </year> <title> Qualitative Representation of Spatial Knowledge, </title> <booktitle> Lecture Notes in Computer Science 804, </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: Heading, or direction of travel, is computed from the path of travel which is first smoothed using a non-lookahead smoothing function and then converted to a relative compass orientation, an approach often used in the field of qualitative reasoning <ref> (e.g., Hernandez 1994) </ref>. These are the only features used at this time, although there are additional features which can be constructed such as relative positions (e.g., behind) or qualitative descriptions of movement such as "starting" or "stopping".
Reference: <author> Howarth, R.J. </author> <year> 1994. </year> <title> Spatial Representation, Reasoning and Control for a Surveillance System. </title> <type> Ph.D. </type> <institution> diss., Queen Mary and Westfield College. </institution>
Reference-contexts: Plan recognition The agent-pair relationships described above are best viewed as events, actions which can be described by a verb (Neumann 1991), essentially changes in the relationships between primitive attributes of agents <ref> (Howarth 1994) </ref>. Research in object tracking has been primarily concerned with movements at this level, however we are interested in more complex patterns of action as produced by the execution of plans as well as patterns involving groups rather than single agents.
Reference: <author> Howarth, R.J. and Buxton, H. </author> <year> 1992. </year> <title> Analogical representation of spatial events for understanding traffic behaviour. </title> <booktitle> In Proceedings European Conference on Artificial Intelligence (ECAI), </booktitle> <volume> 785 - 789. </volume>
Reference: <author> Huber, M. J. and Durfee, E. H. </author> <year> 1992. </year> <title> Plan recognition for real-world autonomous robots: </title> <booktitle> Work in progress. In Working Notes AAAI Symposium : Applications of AI to Real-World Autonomous Robots. </booktitle>
Reference: <author> Huber, M. J. and Durfee, E. H. </author> <year> 1995. </year> <title> Deciding when to commit to action during observation-based coordination. </title> <booktitle> Proceedings of the First International Conference on Multi-Agent Systems (ICMAS), </booktitle> <volume> 163 - 170. </volume>
Reference-contexts: Some of these applications include the inference of a user's beliefs in natural language or story understanding (e.g., Di Eugenio 1995), inference of a user's intents in intelligent user interfaces (e.g., Wrn 1996), identification of an autonomous agent's goal in order to coordinate activity <ref> (e.g., Huber and Durfee 1995) </ref>, and for program understanding in the field of software engineering (e.g., Woods and Yang 1998). However, even in these diverse application contexts, three major assumptions are typically made: Single agent The plan is being carried out by a single agent acting alone.
Reference: <author> Mohnhaupt, M. and Neumann, B. </author> <year> 1991. </year> <title> Understanding object motion: Recognition, learning, </title> <booktitle> and spatiotempo-ral reasoning. Robotics and Autonomous Systems 8:65 - 91. </booktitle>
Reference: <author> Neumann, B. </author> <year> 1989. </year> <title> Natural language description of time-varying scenes. </title> <editor> In D. Waltz (Ed.), </editor> <booktitle> Semantic Structures : Advances in Natural Language Processing, </booktitle> <volume> 167 - 204. </volume> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Tambe, M. </author> <year> 1995. </year> <title> Recursive agent and agent-group tracking in a real-time, dynamic environment. </title> <booktitle> In Proceedings of International Conference on Multi-Agent Systems (ICMAS), </booktitle> <pages> 368-375. </pages>
Reference: <author> Traum, D. R. and Allen, J.F. </author> <year> 1991. </year> <title> Causative forces in multi-agent planning. </title> <editor> In Y. Demazeau & J-P. Muller (Eds.), </editor> <booktitle> Decentralized AI, </booktitle> <volume> 89 - 105. </volume> <publisher> Elsevier. </publisher>
Reference-contexts: Work in "multi-agent" plan recognition shares this assumption as well, the distinction being that an agent is considering the possible individual plans of several agents (e.g., Huber and Durfee 1995; Tambe 1995) or that there are other agents active in the world which may be causing changes <ref> (e.g., Traum and Allen 1991) </ref>. Complete and correct information The observations available are correct, i.e., they correspond to Copyright c fl1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. the actual behavior of the observed agent, and they are complete, i.e., no actions were performed which were not noticed.
Reference: <author> Wrn, A. </author> <year> 1996. </year> <title> Recognising human plans: Plan recognition in human-computer interaction. </title> <type> Ph.D. </type> <institution> diss., Swedish Institute of Computer Science. </institution>
Reference-contexts: Some of these applications include the inference of a user's beliefs in natural language or story understanding (e.g., Di Eugenio 1995), inference of a user's intents in intelligent user interfaces <ref> (e.g., Wrn 1996) </ref>, identification of an autonomous agent's goal in order to coordinate activity (e.g., Huber and Durfee 1995), and for program understanding in the field of software engineering (e.g., Woods and Yang 1998).
Reference: <author> Waterman, D.A. and Hayes-Roth, F. eds. </author> <year> 1978. </year> <title> Pattern-directed Inference Systems. </title> <publisher> Academic Press. </publisher>
Reference: <author> Woods, S. </author> <year> 1993. </year> <title> A method of interactive recognition of spatially defined model deployment templates using abstraction. </title> <editor> In H. Merklinger et al. (Eds.), </editor> <booktitle> Proceedings of the Knowledge-based Systems and Robotics Workshop, </booktitle> <pages> 665-675. </pages> <institution> Department of National Defence, Government of Canada. </institution>
Reference: <author> Woods, S. and Yang, Q. </author> <year> 1998. </year> <title> Program understanding as constraint satisfaction. Journal of Automated Software Engineering 5(2). </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: user's beliefs in natural language or story understanding (e.g., Di Eugenio 1995), inference of a user's intents in intelligent user interfaces (e.g., Wrn 1996), identification of an autonomous agent's goal in order to coordinate activity (e.g., Huber and Durfee 1995), and for program understanding in the field of software engineering <ref> (e.g., Woods and Yang 1998) </ref>. However, even in these diverse application contexts, three major assumptions are typically made: Single agent The plan is being carried out by a single agent acting alone.
References-found: 19

