URL: http://www.cs.cornell.edu/Info/People/chandra/podc97/papers/shay.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/chandra/podc97/newProgram.html
Root-URL: 
Email: kutten@ie.technion.ac.il  boaz@ccs.neu.edu  
Title: Time-Adaptive Self Stabilization  
Author: Shay Kutten Boaz Patt-Shamir 
Note: Research supported by DARPA and Rome Laboratory under agreement F30602-96-0239.  
Affiliation: Dept. of Industrial Engineering The Technion and IBM T.J. Watson Research Center  College of Computer Science Northeastern University  
Abstract: We study the scenario where a transient fault hit f of the n nodes of a distributed system by corrupting their state. We consider the basic problem of persistent bit, where the system is required to maintain a value in the face of transient failures by means of replication. We give an algorithm to recover the value quickly: the value of the bit is recovered at all nodes in O(f ) time units for any unknown value of f &lt; n=2. Moreover, complete state quiescence occurs in O(diam) time units, where diam denotes the diameter of the network. This means that the value persists indefinitely so long as any f &lt; n=2 faults are followed by (diam) fault-free time units. We prove lower bounds which show that both time bounds are asymptotically optimal. Using the algorithm for persistent bit, we present a general transformer which takes a distributed nonreactive, non-stabilizing protocol P, and produces a self-stabilizing protocol P 0 which solves the problem P solves, with the additional property that if the number of faults that hit the system after stabilization is f , for any unknown f &lt; n=2, then the output of P 0 regains stability in O(f ) time units, and the state stabilizes in O(diam) time units. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek, S. Kutten, and M. Yung. </author> <title> Memory-efficient self-stabilization on general networks. </title> <booktitle> In Proc. 4th Workshop on Distributed Algorithms, </booktitle> <pages> pages 15-28, </pages> <address> Italy, </address> <month> Sept. </month> <year> 1990. </year> <note> Springer-Verlag (LNCS 486). To appear in Theoretical Comp. Sci. </note>
Reference-contexts: This result is formally stated in Theorem 5.1. Related Work. The study of self-stabilizing protocols was initiated by Dijkstra [5]. Reset-based ap proaches to self-stabilization are described in <ref> [9, 1, 3, 4] </ref>. In reset-based stabilization, the state is constantly monitored; if an error is detected, a special reset protocol is invoked, whose effect is to consistently establish a pre-specified global state from which the system can resume normal operation.
Reference: [2] <author> B. Awerbuch, S. Kutten, Y. Mansour, B. Patt-Shamir, and G. Varghese. </author> <title> Time optimal self-stabilizing synchronization. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <address> San Diego, California, </address> <pages> pages 652-661, </pages> <month> May </month> <year> 1993. </year> <note> Also appeared as IBM Research Report RC-19149(83418). </note>
Reference-contexts: One of the main drawbacks of this approach is that the detection mechanism triggers a system-wide reset in the face of the slightest inconsistency. The distinction between output stabilization and state stabilization has been used and discussed in a number of papers. For example, in <ref> [2] </ref> it is noted that the output stabilizes in O (diam) time, while the state stabilization time may be much larger. Parlati and Yung [12] and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization.
Reference: [3] <author> B. Awerbuch, B. Patt-Shamir, and G. Varghese. </author> <title> Self-stabilization by local checking and correction. </title> <booktitle> In 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <address> San Juan, Puerto Rico, </address> <pages> pages 268-277, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: This result is formally stated in Theorem 5.1. Related Work. The study of self-stabilizing protocols was initiated by Dijkstra [5]. Reset-based ap proaches to self-stabilization are described in <ref> [9, 1, 3, 4] </ref>. In reset-based stabilization, the state is constantly monitored; if an error is detected, a special reset protocol is invoked, whose effect is to consistently establish a pre-specified global state from which the system can resume normal operation.
Reference: [4] <author> B. Awerbuch, B. Patt-Shamir, G. Varghese, and S. Dolev. </author> <title> Self-stabilization by local checking and global reset. </title> <booktitle> In Proc. 8th International Workshop on Distributed Algorithms, </booktitle> <pages> pages 326-339. </pages> <publisher> Springer-Verlag (LNCS 857), </publisher> <year> 1994. </year>
Reference-contexts: This result is formally stated in Theorem 5.1. Related Work. The study of self-stabilizing protocols was initiated by Dijkstra [5]. Reset-based ap proaches to self-stabilization are described in <ref> [9, 1, 3, 4] </ref>. In reset-based stabilization, the state is constantly monitored; if an error is detected, a special reset protocol is invoked, whose effect is to consistently establish a pre-specified global state from which the system can resume normal operation.
Reference: [5] <author> E. W. Dijkstra. </author> <title> Self-stabilizing systems in spite of distributed control. </title> <journal> Comm. ACM, </journal> <volume> 17(11) </volume> <pages> 643-644, </pages> <month> November </month> <year> 1974. </year>
Reference-contexts: This result is formally stated in Theorem 5.1. Related Work. The study of self-stabilizing protocols was initiated by Dijkstra <ref> [5] </ref>. Reset-based ap proaches to self-stabilization are described in [9, 1, 3, 4]. In reset-based stabilization, the state is constantly monitored; if an error is detected, a special reset protocol is invoked, whose effect is to consistently establish a pre-specified global state from which the system can resume normal operation.
Reference: [6] <author> S. Dolev, M. Gouda, and M. Schneider. </author> <title> Memory requirements for silent stabilization. </title> <booktitle> In Proceedings of the 15th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 27-34, </pages> <year> 1996. </year>
Reference-contexts: For example, in [2] it is noted that the output stabilizes in O (diam) time, while the state stabilization time may be much larger. Parlati and Yung [12] and Dolev et al. <ref> [6] </ref> study a few cases where state stabilization coincides with output stabilization. Ghosh et al. [8] explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are [10, 8]. <p> The output stabilization time is the maximum number of steps until the output registers start satisfying the problem specification predicate continuously. We remark that our definition of legal states is in the spirit of <ref> [12, 6] </ref>, and is justified by our separation between output stabilization and state stabilization. For a given global state s, we define the fault number of s to be the minimal number of local states which need to be changed to yield a legal global state.
Reference: [7] <author> S. Dolev and T. Herman. </author> <title> Superstabilizing protocols for dynamic distributed systems. </title> <booktitle> In Proc. of the Second Workshop on Self-Stabilizing Systems, </booktitle> <pages> pages 3.1-3.15, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: In this paper, we use a state-based measure (akin to Hamming distance used in error correcting codes, also used in <ref> [7] </ref>): the number of faults is defined to be the minimum number of processors whose state need be changed to attain a stable global state. Note that according to this definition, a non-faulty node may become faulty as a result of interaction with a faulty neighborhood.
Reference: [8] <author> S. Ghosh, A. Gupta, T. Herman, and S. V. Pe-mamraju. </author> <title> Fault-containing self-stabilizing algorithms. </title> <booktitle> In Proceedings of the 15th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: For example, in [2] it is noted that the output stabilizes in O (diam) time, while the state stabilization time may be much larger. Parlati and Yung [12] and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization. Ghosh et al. <ref> [8] </ref> explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are [10, 8]. <p> Parlati and Yung [12] and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization. Ghosh et al. [8] explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are <ref> [10, 8] </ref>. <p> In a sense, therefore, the state stabilization time of the algorithm of [10] is infinity. In <ref> [8] </ref>, an algorithm for the following problem is presented: given a self-stabilizing non-reactive protocol, produce another version of that protocol which is self-stabilizing, but whose output stabilization time when f = 1 is O (1). <p> The transformed protocol has O (T diam) state stabilization time, where T is the stabilization time of the original protocol (no analysis is provided for output stabilization time when f &gt; 1). The protocol of <ref> [8] </ref> is asynchronous, and its space overhead is O (1) per link. However, it requires a self-stabilizing protocol to start with, and it may suffer a performance penalty when f &gt; 1. Paper organization. In Section 2 we formalize the model and introduce a few notations.
Reference: [9] <author> S. Katz and K. Perry. </author> <title> Self-stabilizing extensions for message-passing systems. </title> <booktitle> In Proceedings of the 10th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Quebec City, Canada, </address> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: This result is formally stated in Theorem 5.1. Related Work. The study of self-stabilizing protocols was initiated by Dijkstra [5]. Reset-based ap proaches to self-stabilization are described in <ref> [9, 1, 3, 4] </ref>. In reset-based stabilization, the state is constantly monitored; if an error is detected, a special reset protocol is invoked, whose effect is to consistently establish a pre-specified global state from which the system can resume normal operation.
Reference: [10] <author> S. Kutten and D. Peleg. </author> <booktitle> Fault-local distributed mending. In Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Did a transient fault hit that outcast processor, or did the fault corrupt the state of all other n 1 processors in a consistent way? An operational approach <ref> [10] </ref> is to select the unknown answer to this question to be the definition. <p> Our results. The main positive result in this paper (Theorem 3.1) is an algorithm for a basic problem called the persistent bit problem <ref> [10] </ref>, where the goal is to retain the value of a common replicated bit across the system in spite of transient faults which may corrupt processors state arbitrarily. <p> Parlati and Yung [12] and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization. Ghosh et al. [8] explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are <ref> [10, 8] </ref>. <p> Parlati and Yung [12] and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization. Ghosh et al. [8] explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are [10, 8]. In <ref> [10] </ref>, the persistent bit problem was introduced, as well as an algorithm with output stabilization time O (f log n) for f = O (n= log n), but the number of faults is cumulative: the algorithm cannot correct more than O (n= log n) faults throughout the execution of the system. <p> In a sense, therefore, the state stabilization time of the algorithm of <ref> [10] </ref> is infinity. In [8], an algorithm for the following problem is presented: given a self-stabilizing non-reactive protocol, produce another version of that protocol which is self-stabilizing, but whose output stabilization time when f = 1 is O (1). <p> Our goal is to find a protocol with the smallest possible output and state stabilization time. It is known how to get close to each requirement separately. <ref> [10] </ref> presents a voting-based protocol which solves the problem in O (f log n) time for f = O ( n log n ), but that protocol is not self-stabilizing, which means (among other things) that the number of faults is counted since system initialization. <p> We remark that the output stabilization time of the regulated broadcast algorithm is better than the output stabilization time of the mending algorithm of <ref> [10] </ref>, but the algorithm of [10] guarantees complete quiescence (which is stronger than output stabilization) after O (f log n) time steps. <p> We remark that the output stabilization time of the regulated broadcast algorithm is better than the output stabilization time of the mending algorithm of <ref> [10] </ref>, but the algorithm of [10] guarantees complete quiescence (which is stronger than output stabilization) after O (f log n) time steps. Observe that the proof of Theorem 3.5 actually shows that the output of each node i stabilizes in at most 1 + 2 min (depth (i); 2f + 1) time units.
Reference: [11] <author> N. Linial, D. Peleg, Y. Rabinovich, and M. Saks. </author> <title> Sphere packing and local majorities in graphs. </title> <booktitle> In Proceedings of the 2nd Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 141-149, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The main component of the output stabilization part is the regulated broadcast protocol, which ensures that in O (f ) time, each node knows the true value of the input bits of sufficiently many nodes. The output bit is computed locally by a simple majority 1 Interestingly, in <ref> [11] </ref> it is shown that there are graphs where a subset of fi (n 2=3 diam 1=3 ) nodes are the majority in all neighborhoods (up to distance about diam 2 ) for all nodes in the graph. rule.
Reference: [12] <author> G. Parlati and M. Yung. </author> <title> Non-exploratory self-stabilization for constant-space symmetry-breaking. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Proceedings of the 2nd Annual European Symposium on Algorithms, </booktitle> <pages> pages 26-28, </pages> <address> Sept. 1994. </address> <publisher> LNCS 855, Springer Verlag. </publisher>
Reference-contexts: The distinction between output stabilization and state stabilization has been used and discussed in a number of papers. For example, in [2] it is noted that the output stabilizes in O (diam) time, while the state stabilization time may be much larger. Parlati and Yung <ref> [12] </ref> and Dolev et al. [6] study a few cases where state stabilization coincides with output stabilization. Ghosh et al. [8] explicitly distinguish between output and state stabilization (called `fault gap' there). The papers most closely related to our work are [10, 8]. <p> The output stabilization time is the maximum number of steps until the output registers start satisfying the problem specification predicate continuously. We remark that our definition of legal states is in the spirit of <ref> [12, 6] </ref>, and is justified by our separation between output stabilization and state stabilization. For a given global state s, we define the fault number of s to be the minimal number of local states which need to be changed to yield a legal global state.
References-found: 12

