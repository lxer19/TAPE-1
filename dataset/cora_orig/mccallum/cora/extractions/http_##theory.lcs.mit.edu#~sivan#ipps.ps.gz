URL: http://theory.lcs.mit.edu/~sivan/ipps.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~sivan/papers.html
Root-URL: 
Title: Performance Prediction with Benchmaps  
Author: Sivan Toledo 
Affiliation: IBM T.J. Watson Research Center  
Abstract: Benchmapping is a performance prediction method for data-parallel programs that is based on modeling the performance of runtime systems. This paper describes a benchmapping system, called BENCHCVL, that predicts the running time of data-parallel programs written in the NESL language on several computer systems. BENCHCVL predicts performance using a set of more than 200 parameterized models. The models quantify the cost of moving data between processors, as well as the cost of moving data within the local memory hierarchy of each processor. The parameters for the models are automatically estimated from measurements of the execution times of runtime system calls on each computer system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Os-trouchov, and D. Sorensen. </author> <title> LAPACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, 2nd edition, </address> <year> 1994. </year>
Reference-contexts: There is plenty of evidence that the data-parallel programming model is suitable for many scientific applications. Data-parallel programming includes not only traditional data-parallel languages such as High Performance Fortran [12], but also sequential and parallel programs that extensively use numerical libraries such as the BLAS, LAPACK <ref> [1] </ref>, and ScaLA-PACK [9]. Benchmaps that model the performance of these numerical libraries should enable accurate prediction of the running time of such programs. Neither PERFSIM nor BENCHCVL predicts performance exactly, but both are accurate enough to be used for program tuning.
Reference: [2] <author> Daya Atapattu and Dennis Gannon. </author> <title> Building analytical models into an interactive performance prediction tool. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 521-530, </pages> <year> 1989. </year>
Reference-contexts: Fahringer and Zima [11] describe a more comprehensive system for guiding compiler optimization, which is a part of the Vienna Fortran Compilation System. They use a simple model with a few parameters to describe a computer system and claim that the predictions are accurate. Atapattu and Gannon <ref> [2] </ref> describe an interactive performance prediction tool for single-threaded Fortran programs running on a bus-based shared memory parallel computer. Performance prediction in their tool is based on a static analysis of the assembly language code of the compiled program.
Reference: [3] <author> Vasanth Balasundaram, Geoffrey Fox, Ken Kennedy, and Ulrich Kremer. </author> <title> A static performance estimator to guide partitioning decisions. </title> <booktitle> In Proceedings of the 3rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 213-223, </pages> <year> 1991. </year>
Reference-contexts: The number models in his system, however, is quite small, and they do not model data caches. Balasundaram et al. <ref> [3] </ref> propose a performance modeling system designed to guide compiler optimizations. Fahringer and Zima [11] describe a more comprehensive system for guiding compiler optimization, which is a part of the Vienna Fortran Compilation System.
Reference: [4] <author> John Louis Bentley. </author> <title> Writing Efficient Programs. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Some researchers have tried to predict the running time of a program based on source-code constructs rather than on constructs in the compiled program <ref> [4, 13] </ref>. In both of these papers the prediction was done by hand. In all the other cases, including ours, a software system predicts performance automatically. The rest of the paper is organized as follows. Section 2 describes the models that BENCHCVL uses.
Reference: [5] <author> Guy E. Blelloch. NESL: </author> <title> A nested data-parallel language (version 2.6). </title> <type> Technical Report CMU-CS-93-129, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: This program measures the execution time of calls to the runtime system and uses the running times of these experiments to estimate the benchmap's parameters. Addressing these issues requires a data-parallel programming system that has been ported to several computer systems. We chose NESL <ref> [5] </ref>, an experimental data-parallel programming language developed at CMU. The NESL programming system uses a runtime system called CVL [6] to execute NESL programs. CVL has been ported to several computers.
Reference: [6] <author> Guy E. Blelloch, Siddhartha Chatterjee, Jonathan C. Hardwick, Margaret Reid-Miller, Jay Sipelstein, and Marco Zagha. </author> <month> CVL: </month>
Reference-contexts: Addressing these issues requires a data-parallel programming system that has been ported to several computer systems. We chose NESL [5], an experimental data-parallel programming language developed at CMU. The NESL programming system uses a runtime system called CVL <ref> [6] </ref> to execute NESL programs. CVL has been ported to several computers. Our performance prediction system, called BENCHCVL, predicts the performance of NESL programs on several computer systems by modeling the performance of CVL on each of them. Several related systems have been described in the literature. <p> We begin the discussion with a brief description of CVL, and then turn to a description of the models themselves. The CVL runtime library <ref> [6] </ref>, which is the runtime system for NESL programs, implements operations on entire and segmented one-dimensional vectors. A segmented vector is partitioned into segments of arbitrary lengths.
References-found: 6

