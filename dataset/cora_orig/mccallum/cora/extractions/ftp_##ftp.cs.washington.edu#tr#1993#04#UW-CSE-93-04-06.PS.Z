URL: ftp://ftp.cs.washington.edu/tr/1993/04/UW-CSE-93-04-06.PS.Z
Refering-URL: http://www.cs.washington.edu/research/compiler/papers.d/data-break.html
Root-URL: 
Title: Fast Data Breakpoints halt program execution when a particular instruction is executed. Data breakpoints halt
Author: David Keppel 
Note: UW CSE TR#  points  however, are notoriously slow. This note describe how data breakpoints can be made fast.  
Date: 3 May 1990, revised 14 April 1993  93-04-06  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [AL91] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual Memory Primitives for User Programs. </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV), </booktitle> <pages> page 96, </pages> <year> 1991. </year>
Reference-contexts: Third, virtual memory has low overhead on references that miss "interesting" memory, but a high overhead per execution for instructions that reference data on the same pages as breakpoint variables. Patch on trap uses virtual memory primitives <ref> [AL91] </ref> to perform patching lazily: memory reference instructions are patched only if they actually reference a protected page. Like code patch, the reference instruction is replaced with a jump in struction to a displaced handler that evaluates the conditional and simulates the displaced instruction.
Reference: [Bed89] <author> Robert Bedichek. </author> <title> Some Efficient Architecture Simulation Techniques. </title> <booktitle> Winter '90 USENIX Conference, </booktitle> <pages> pages 53-63, </pages> <address> 26 Oc-tober, </address> <year> 1989. </year>
Reference-contexts: For each instruction that references memory, the simulation executes code that checks the effective address, which is the data address being referenced. If the effective address matches a breakpoint address, simulation stops and the debugger is restarted. Simulators are typically 5 to 50 times slower than native hardware <ref> [Bed89, CK93] </ref>, plus the cost of checking memory operations. * Single Stepping: Each instruction is checked before it is executed. If the instruction references memory and the effective address matches a breakpoint, the user is notified.
Reference: [CK93] <author> Robert F. Cmelik and David Keppel. Shade: </author> <title> A Fast Instruction-Set Simulator for Execution Profiling. </title> <note> Technical Report (in preparation), </note> <institution> Sun Microsystems Laboratories, Inc. and University of Washing-ton, </institution> <year> 1993. </year>
Reference-contexts: For each instruction that references memory, the simulation executes code that checks the effective address, which is the data address being referenced. If the effective address matches a breakpoint address, simulation stops and the debugger is restarted. Simulators are typically 5 to 50 times slower than native hardware <ref> [Bed89, CK93] </ref>, plus the cost of checking memory operations. * Single Stepping: Each instruction is checked before it is executed. If the instruction references memory and the effective address matches a breakpoint, the user is notified.
Reference: [Cor91] <author> Thinking Machines Corporation. </author> <title> The Connection Machine CM-5 Technical Summary, </title> <year> 1991. </year>
Reference-contexts: Other systems, such as the Connection Machine CM-5, have bits associated with each word of memory; 1 the bits can be set to cause a trap when a particular word is referenced <ref> [Cor91] </ref>. Although hardware is typically fastest [Wah92], it also the most machine-dependent. Further, machines such as the 80386 can only check a small number of breakpoints: it is not possible to set breakpoints simultaneously on 10 locations. * Simulation: The program is run on a virtual machine.
Reference: [Han90] <author> David R. Hanson. </author> <title> Fast Allocation and Deallocation of Memory Based on Object Lifetimes. </title> <journal> Software|Practice and Experience, </journal> <volume> 20(1), </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: When the object is freed, the update point removes the breakpoint. Some allocators free objects implicitly so that, e.g., freeing the root of a graph frees the entire graph <ref> [Han90] </ref>. In these cases, the debugger may need some "deep" understanding of the memory allocator in order to determine when the object is being freed. 5.5 Named Breakpoints The discussion so far has assumed a straightforward mapping from variable name to memory address.
Reference: [Kes90] <author> Peter Kessler. </author> <title> Fast Breakpoints: </title> <booktitle> Design and Implementation. Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation; SIGPLAN Notices, </booktitle> <volume> 25(6) </volume> <pages> 78-84, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The most common command is a code breakpoint, which halts the program when execution reaches a certain instruction. Some debuggers also support conditional breakpoints which evaluate an expression whenever a certain instruction is reached and halt the program only if the expression evaluates to true <ref> [Kes90] </ref>. Some debuggers provide data break-points, which halt the program whenever a variable is referenced; conditional data breakpoints halt the program when a variable is referenced and an expression evaluates to true. Data breakpoints (and conditional data break-points) are notoriously slow. <p> Fast conditional breakpoints save many protection domain crossings by evaluating some debugger code in the context of the debuggee. Fast conditional breakpoints suggest a way that data breakpoints can be implemented more efficiently <ref> [Kes90, Wah92] </ref>: Each load and store instruction is patched with a jump to code that performs a test. The debugger is restarted if an "interesting" address is accessed. Although this mechanism is faster, it still requires patching, and thus slowing, of every memory reference instruction. <p> For example, displacing a memory reference instruction must free up enough space that a jump instruction can be put there. In general, this requires help from the compiler. There are many other cases that need careful attention <ref> [Kes90] </ref>. 5.3 Stack Variables Variables that allocated on the stack pose several challenges. First, the debugger must ensure that breakpoints to the variable have the same lifetime as the variable itself. Second, each time the variable is allocated it may appear at a new location.
Reference: [RHL + 93] <author> Steven K. Reinhardt, Mark D. Hill, James R. Larus, Alvin R. Lebeck, James C. Lewis, and David A. Wood. </author> <title> The Wisconsin Wind Tunnel: Virtual Proto-typing of Parallel Computers. </title> <booktitle> ACM SIG-METRICS, </booktitle> <month> May </month> <year> 1993. </year> <note> REFERENCES 6 </note>
Reference-contexts: This 1 The CM-5 bits are actually associated with each 32 bytes (4 words) of memory. Either distinct variables must be segregated in to different 32-byte regions, or the memory bits are used to implement virtual memory with very small "pages" <ref> [RHL + 93] </ref> and, thus, infrequent traps to the operating system. improves over single stepping because typically only about 30% of instructions are memory reference instructions, and only a third of those are writes. * Virtual Memory: Page (s) with breakpoint variables are reference-protected.
Reference: [Wah92] <author> Robert Wahbe. </author> <title> Efficient Data Break-points. </title> <booktitle> Proceedings of the Fifth International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 200-212, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Fast conditional breakpoints save many protection domain crossings by evaluating some debugger code in the context of the debuggee. Fast conditional breakpoints suggest a way that data breakpoints can be implemented more efficiently <ref> [Kes90, Wah92] </ref>: Each load and store instruction is patched with a jump to code that performs a test. The debugger is restarted if an "interesting" address is accessed. Although this mechanism is faster, it still requires patching, and thus slowing, of every memory reference instruction. <p> Other systems, such as the Connection Machine CM-5, have bits associated with each word of memory; 1 the bits can be set to cause a trap when a particular word is referenced [Cor91]. Although hardware is typically fastest <ref> [Wah92] </ref>, it also the most machine-dependent. Further, machines such as the 80386 can only check a small number of breakpoints: it is not possible to set breakpoints simultaneously on 10 locations. * Simulation: The program is run on a virtual machine. <p> When the program is backed up and restarted from an earlier checkpoint, the interrupt/checkpoint interval is reduced. Eventually, the interval is small enough 2 Alternatively, the trap handler may evaluate the condi tional instead of the debugger <ref> [Wah92] </ref>. 3 In some circumstances, it may be preferable to instrument the code so that it performs polling. 4 AN EXAMPLE 3 that interrupt/checkpoint overhead is very high cost, but the total number of instructions to be executed before a breakpoint is so small that the real execution time is still
Reference: [WM89] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Demonic Memories for Process Histories. </title> <booktitle> Proceedings of the ACM '89 Conference on Programming Language Design and Implementation (PLDI), </booktitle> <pages> pages 330-343, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: If the condition has been reached, execution is restarted from an earlier checkpoint, with a new search breakpoint set between the previous and current search breakpoints. Condtion searc-ing can run the program at or near full speed while it is making forward progress <ref> [WM89] </ref>. Using a binary search means that if interrupts and checkpointing halves the execution speed, the overall slowdown will be at most a factor of four.
References-found: 9

