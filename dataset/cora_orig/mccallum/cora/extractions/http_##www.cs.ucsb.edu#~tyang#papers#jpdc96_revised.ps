URL: http://www.cs.ucsb.edu/~tyang/papers/jpdc96_revised.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/RAPID.html
Root-URL: http://www.cs.ucsb.edu
Email: fcfu,tyangg@cs.ucsb.edu  
Title: Run-time Techniques for Exploiting Irregular Task Parallelism on Distributed Memory Architectures  
Author: Cong Fu and Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: Automatic scheduling for directed acyclic graphs (DAG) and its applications for coarse-grained irregular problems such as large n-body simulation have been studied in the literature. However solving irregular problems with mixed granularities such as sparse matrix factorization is challenging since it requires efficient run-time support to execute a DAG schedule. In this paper, we investigate run-time optimization techniques for executing general asynchronous DAG schedules on distributed memory machines. Our solution tightly integrates the run-time scheme with a fast communication mechanism to eliminate unnecessary overhead in message buffering and copying. We discuss a consistency model incorporating the above optimizations, and taking advantage of task dependence properties to ensure the correctness of execution. We demonstrate the applications of this scheme in sparse factorizations and triangular solver for which actual speedups are hard to obtain. Our experiments on Meiko CS-2 show that the automatically scheduled code has achieved scalable performance for these problems and the run-time overhead is small compared to the total execution time.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Amza, A. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. TreadMarks: </author> <title> Shared Memory Computing on Networks of Workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: We have mentioned Chaos in the introduction. Multipol [34] is a run-time library system which supports distributed data structures for several kinds of scientific applications. Consistency models. The issue of executing a program correctly has been studied in the context of distributed shared memory systems (DSM). For example, TreadMarks <ref> [1] </ref> provides a shared memory programming interface on network of workstations and the main issue is how to maintain the consistency of shared objects in an efficient way. Programmers have to exploit parallelism explicitly.
Reference: [2] <author> C. Ashcraft and R. Grimes. </author> <title> The Influence of Relaxed Supernode Partitions on the Multifrontal Method . ACM Transactions on Mathematical Software, </title> <booktitle> 15(4) </booktitle> <pages> 291-309, </pages> <year> 1989. </year>
Reference-contexts: In order to improve the performance further, our future work is to consider techniques of increasing average supernode sizes, e.g., supernode amalgamation <ref> [2, 26] </ref>. 22 left part is for BCSSTK24 and the right is for BCSSTK15. 6.2 Sparse triangular solver and performance impact of granularities From the discussion in the last section we know that the task granularity of an application is important to the performance of irregular code.
Reference: [3] <author> R. Blumfoe, M. Frigo, C. Joerg, C. Leiserson, and K. Randall. </author> <title> Dag-Consistent Distributed Shared Memory. </title> <booktitle> In Proceeding of 10th International Parallel Processing Symposium, </booktitle> <pages> pages 132-141, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. [9, 23, 28, 38]. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive <ref> [25, 3] </ref>, but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines. Static scheduling can adapt to certain degree of run-time weight variation [16, 37] and its run-time control mechanism is relatively simple. <p> Run-time support for parallel computations. The Charm [31] system adopts a message driven approach for general asynchronous computation. Each processor contains a group of threads and a message queue. A thread can only be triggered by a message and dynamic scheduling is used to balance processor loads. The Cilk <ref> [3] </ref> multi-threaded system aims at applications that have "strict" dependence structures. They use randomized load balancing and work stealing techniques to execute a dynamic DAG. <p> The second protocol supports prefetching, but the system may send data items to processors which do not need them. Hence in a general DSM system overhead is higher than our scheme, which makes it unsuitable for applications such as sparse matrix computations. Recently Cilk <ref> [3] </ref> also addresses the DAG consistency, but it does not incorporate the optimizations used in our model such as eliminating redundant communications. Low overhead communication mechanism.
Reference: [4] <author> E. Brewer, F. Chong, L. Liu, S. Sharma, and J. Kubiatowicz. </author> <title> Remote Queues: Exposing Message Queues for Optimization and Atomicity. </title> <booktitle> In 7th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 42-53, </pages> <year> 1995. </year>
Reference-contexts: And in the situation of task parallelism with mixed granularities, it is not easy to decide where to insert the polling code <ref> [4] </ref>. Thus in our implementation, we use the remote memory access instead of active messages. 8 Conclusions In this paper, we have presented an efficient run-time scheme for supporting task computations and shown its applications in irregular sparse Cholesky, LU factorizations and triangular solvers.
Reference: [5] <author> R. Burden and J. Faires. </author> <title> Numerical Analysis. </title> <publisher> PWS Publishing Company, </publisher> <address> fifth edition, </address> <year> 1993. </year>
Reference-contexts: For such matrices, it can be shown [6] that stable solutions can be obtained by LU (Gaussian Elimination) without pivoting. The proof in [6] is based on a modification to Theorem 6.19 in <ref> [5] </ref>.
Reference: [6] <author> W. Cai. </author> <type> Personal Communication, </type> <year> 1995. </year>
Reference-contexts: For such matrices, it can be shown <ref> [6] </ref> that stable solutions can be obtained by LU (Gaussian Elimination) without pivoting. The proof in [6] is based on a modification to Theorem 6.19 in [5]. <p> For such matrices, it can be shown <ref> [6] </ref> that stable solutions can be obtained by LU (Gaussian Elimination) without pivoting. The proof in [6] is based on a modification to Theorem 6.19 in [5].
Reference: [7] <author> F. T. Chong and R. Schreiber. </author> <title> Parallel Sparse Triangular Solution with Partitioned Inverses and Prescheduled DAGs. </title> <booktitle> In Proc. of 1st IPPS Workshop on Solving Irregular Problems, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: It has been very difficult to obtain actual speedups by hand-made code for these problems, not to mention automatically parallelized code, especially on distributed memory machines. Recently impressive 2 performance is obtained for sparse Cholesky factorization [26, 27] and sparse triangular solver <ref> [7] </ref>. We discuss how we can exploit task parallelism in sparse Cholesky/LU factorizations using our techniques in a general run-time support environment. One difficulty in parallelizing sparse Cholesky factorization is that parallelism also arises from operations that commute.
Reference: [8] <author> F. T. Chong, S. D. Sharma, E. A. Brewer, and J. Saltz. </author> <title> Multiprocessor Runtime Support for Fine-Grained Irregular DAGs. </title> <editor> In Rajiv K. Kalia and Priya Vashishta, editors, </editor> <title> Toward Teraflop Computing and New Grand Challenge Applications., </title> <address> New York, 1995. </address> <publisher> Nova Science Publishers. </publisher>
Reference-contexts: However the run-time overhead for task execution is still large and there is a great deal of room for obtaining better absolute performance. Recently the work by <ref> [8] </ref> demonstrates that using both effective DAG scheduling and low-overhead communication mechanisms, scalable performance can be obtained on fine-grained DAGs for solving sparse triangular systems. Run-time support for parallel computations. The Charm [31] system adopts a message driven approach for general asynchronous computation. <p> An active message usually contains a function handler and a few short data arguments, and the function at the destination processor can be invoked as soon as this message arrives at the destination. Active messages have been used in <ref> [8] </ref> for executing fine-grained triangular solving DAGs. We find that it is not easy to integrate active messages with a general task graph execution scheme because careful network polling is required for efficiently implementing active messages as demonstrated in [8]. <p> Active messages have been used in <ref> [8] </ref> for executing fine-grained triangular solving DAGs. We find that it is not easy to integrate active messages with a general task graph execution scheme because careful network polling is required for efficiently implementing active messages as demonstrated in [8]. And in the situation of task parallelism with mixed granularities, it is not easy to decide where to insert the polling code [4].
Reference: [9] <author> Y-C. Chung and S. Ranka. </author> <title> Applications and Performance Analysis of a Compile-time Optimization Approach for List Scheduling Algorithms on Distributed Memory Multiprocessor. </title> <booktitle> In Proc. of Supercomputing '92, </booktitle> <year> 1992. </year>
Reference-contexts: We have the processor assignment (A) = (B) = (D) = 0, (C) = (E) = 1, and the execution orderings O 0 = fA; B; Dg, O 1 = fC; Eg. Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. <ref> [9, 23, 28, 38] </ref>. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive [25, 3], but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines.
Reference: [10] <author> R. Cytron and J. Ferrante. </author> <title> What's in a name? The Value of Renaming for Parallelism Detection and Storage Allocation. </title> <booktitle> In Proc. of International Conf. on Parallel Processing, </booktitle> <pages> pages 19-27, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: In functional languages, the "single assignment" principle has been used in data flow computation and functional languages [28, 22], i.e., each data item can be written at most once, thus there is neither output nor anti dependence. The renaming techniques <ref> [10] </ref> can eliminate the output and anti dependence in transforming a DDG to a "single assignment" graph. The advantage of such a principle is that dependence enforcement in task execution can be simplified to some degree. The disadvantage is that memory usage and data copying overhead increase accordingly.
Reference: [11] <author> R. Das, M. Uysal, J. Saltz, and Y.-S. Hwang. </author> <title> Communication Optimizations for Irregular Scientific Computations on Distributed Memory Architectures . Journal of Parallel and Distributed Computing, </title> <booktitle> 22(3) </booktitle> <pages> 462-479, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Automatic scheduling and load balancing techniques are useful in exploiting irregular parallelism in unstructured computations [34, 20, 16]. For iterative irregular problems in which communication and computation phases alternate, the CHAOS/PARTI system <ref> [11] </ref> has used the inspector/executor approach to exploit irregular parallelism at each iteration of the computation fl A preliminary version of this work appears in the 10th International Parallel Processing Symposium. 1 phase.
Reference: [12] <author> J. Dongarra, J. Du Croz, S. Hammarling, and R. Hanson. </author> <title> An Extended Set of Basic Linear Algebra Subroutines. </title> <journal> ACM Trans. on Mathematical Software, </journal> <volume> 14 </volume> <pages> 18-32, </pages> <year> 1988. </year> <month> 29 </month>
Reference-contexts: For instance, Figure 12 is a 21 fi 21 sparse matrix with fill-ins. After that we use supernode partitioning [18] so that every basic task operation involves only dense matrix or vector operations which can be implemented using BLAS and LAPACK routines <ref> [12] </ref>. We also partition supernodes into smaller blocks. And for those supernodes smaller than the block size used, they will remain unchanged. In this way we can take the advantage of caching and reduce indexing overhead. In the literature, tasks F kk and S ik are also called DIV operations.
Reference: [13] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis. </author> <title> User's Guide for the Harwell-Boeing Sparse Matrix Collection. </title> <type> Technical report, </type> <year> 1986. </year>
Reference-contexts: Note that LINPACK performance is 8:05 MFLOPS. We have tested a set of benchmark matrices from the Harwell-Boeing collection <ref> [13] </ref>. BCSSTK15 arises from structural engineering analysis for Module of an Offshore Platform, BCSSTK16 is for Corp. of Engineers Dam, BCSSTK17 is for Elevated Pressure Vessel, and BCSSTK24 is for Calgary Olympic Saddledome Arena. Task graphs derived from these matrices are quite large and unstructured. <p> For a sparse matrix, again we use supernode partitioning to divide the matrix and construct the sparse task graph from the partitioned matrix. It can be shown that a LU task graph is dependence-complete. We have tested two benchmark matrices from Boeing-Harwell collection: BCSSTK15 and BCSSTK24 <ref> [13] </ref>. Both matrices have symmetric structures. The purpose of using these matrices is to compare with the performance of Cholesky factorization and analyze the impact of algorithm characteristics on the code performance.
Reference: [14] <author> C. Fu and T. Yang. </author> <title> Run-time Compilation for Parallel Sparse Matrix Computations. </title> <booktitle> In Proceedings of International Conference on Supercomputing, </booktitle> <pages> pages 237-244, </pages> <address> Philadelphia, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: This will become clearer as we discuss in the subsequent sections. More discussion on the above properties and their relationship can be found in [36]. The transformation to convert a DDG to a dependence complete task graph is described in <ref> [14] </ref>. Most task graphs derived from real scientific applications satisfy these properties without renaming. For example, sparse LU graphs discussed in Section 6.1.2 are dependence-complete. 2.3 Handling commutativity One disadvantage of a dependence-complete task graph (or DDG) is that it cannot model parallelism arising from commuting operations. <p> We have developed a set of library functions <ref> [14] </ref> which allow users to specify data access patterns based on a sequential version of the application. We use the PYRROS scheduling algorithms to produce a task schedule and our run-time system will execute such an irregular schedule. <p> The experiments indicate that overhead of run-time data communication is relatively small. The performance of sparse computation is limited by available parallelism, but not the overhead of the system. In <ref> [14] </ref> we have examined the application of these techniques in sparse LU factorization with partial pivoting, which is a more challenging problem and provided an application programming interface (API) for users to parallelize irregular code using our run-time scheme.
Reference: [15] <author> G. A. Geist and E. Ng. </author> <title> Task Scheduling for Parallel Sparse Cholesky Factorization . International Journal of Parallel Programming, </title> <booktitle> 18(4) </booktitle> <pages> 291-314, </pages> <year> 1989. </year>
Reference-contexts: Rothberg and Schreiber [26, 27] show that the supernode-based approach can deliver good performance on both shared and distributed memory machines. Specialized scheduling techniques have been studied for sparse Cholesky factorization in <ref> [15, 21] </ref>. We will examine the performance of applying general task scheduling and executing techniques to this problem. For a dense matrix, the BLAS-3 level Cholesky factorization algorithm 3 is shown in Figure 11.
Reference: [16] <author> A. Gerasoulis, J. Jiao, and T. Yang. </author> <title> Scheduling of Structured and Unstructured Computation . In D. </title> <editor> Hsu, A. Rosenberg, and D. Sotteau, editors, </editor> <title> Interconnections Networks and Mappings and Scheduling Parallel Computation. </title> <journal> American Math. Society, </journal> <year> 1995. </year>
Reference-contexts: The automatic parallelization of such problems on distributed memory machines is extremely difficult and presents a great challenge. Automatic scheduling and load balancing techniques are useful in exploiting irregular parallelism in unstructured computations <ref> [34, 20, 16] </ref>. For iterative irregular problems in which communication and computation phases alternate, the CHAOS/PARTI system [11] has used the inspector/executor approach to exploit irregular parallelism at each iteration of the computation fl A preliminary version of this work appears in the 10th International Parallel Processing Symposium. 1 phase. <p> In a more complicated iterative application, the computation phase may involve task parallelism with irregular dependence structures. For example, in the adaptive n-body simulation using the fast multipole method, parallelism at each time step can be modeled as a directed acyclic task graph (DAG) <ref> [16] </ref>. The DAG schedule can be re-used for a number of iterations before re-scheduling since particle movement is slow. Then good speedups are obtained on nCUBE-2 for large n-body simulation problems after applying PYRROS DAG scheduling techniques [38]. <p> However compared to large n-body simulations, efficient execution of DAG schedules for sparse matrix problems is more challenging because partitioned graphs contain both coarse and fine grained tasks while in the DAGs arising from large n-body simulations, most of tasks are relatively coarse-grained <ref> [16] </ref>. Most of previous work in DAG scheduling has mainly focused on the algorithmic research for mapping tasks onto multi-processors based on the macro task computation model [28, 35]. But little research has been conducted on efficient run-time support for executing task schedules. <p> Static scheduling can adapt to certain degree of run-time weight variation <ref> [16, 37] </ref> and its run-time control mechanism is relatively simple. <p> These two issues make timing among tasks different from what is expected at the static time and tend to increase the processor idle time. The performance becomes even more sensitive when task granularities are small <ref> [16, 37] </ref>. <p> Application of graph scheduling for solving scientific problems. As we discussed before, application of graph scheduling has been used in large n-body simulations <ref> [16] </ref>. In [32], static task and communication scheduling is used for sparse Cholesky, and they found that pre-scheduling improves the performance of distributed factorization by 30% to 40%.
Reference: [17] <author> G. Golub and J. M. Ortega. </author> <title> Scientific Computing: An Introduction with Parallel Computing Compilers . Academic Press, </title> <year> 1993. </year>
Reference-contexts: We choose the sparse triangular solver as an example application. Generally a triangular solver is much less time consuming than factorization. A triangular system with multiple right-hand sides is useful in many scientific applications <ref> [17] </ref>. An interesting property with the triangular solver is that it is very easy to adjust the granularity of tasks by using different number of right-hand sides. Again we first use the supernode partitioning techniques to divide a triangular sparse matrix into N fi N 2-D blocks.
Reference: [18] <author> M. Heath, E. Ng, and B. Peyton. </author> <title> Parallel Algorithms for Sparse Linear Systems . SIAM Review, </title> <booktitle> 33(3) </booktitle> <pages> 420-460, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: However while the task graph derived from sequential semantics satisfies DA1-4, the task graph considering commutativity is not dependence-complete since all commuting tasks in Figure 3 (b) 1 This is called fan-in parallelism in the literature <ref> [18] </ref>. Fan-out parallelism in Cholesky factorization is naturally included in the task graph model as submatrix multi-casting edges. 6 modify the same data item which violates Assumptions DA1 and DA3. In order to correctly execute a commutative task graph, we have to alter the task graph after the scheduling. <p> For instance, Figure 12 is a 21 fi 21 sparse matrix with fill-ins. After that we use supernode partitioning <ref> [18] </ref> so that every basic task operation involves only dense matrix or vector operations which can be implemented using BLAS and LAPACK routines [12]. We also partition supernodes into smaller blocks. And for those supernodes smaller than the block size used, they will remain unchanged.
Reference: [19] <author> N. Karmarkar. </author> <title> A New Parallel Architecture for Sparse Matrix Computation Based on Finite Project Geometries . In Proc. </title> <booktitle> of Supercomputing '91, </booktitle> <pages> pages 358-369, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: In solving nonlinear equations using iterative methods, sparse matrix factorization usually dominates the computation time at each iteration step and the topology of the iteration matrix remains the same but the numerical values change at each step <ref> [19] </ref>. Efficient paral-lelization of sparse factorization requires certain compilation cost, but the optimized solution can be used for many iterations. The sparse matrix factorizations can be modeled as DAGs [30].
Reference: [20] <author> A. Lain and P. Banerjee. </author> <title> Techniques to Overlap Computation and Communication in Irregular Iterative Applications. </title> <booktitle> In Proc. of ACM Inter. Conf. on Supercomputing, </booktitle> <pages> pages 236-245, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The automatic parallelization of such problems on distributed memory machines is extremely difficult and presents a great challenge. Automatic scheduling and load balancing techniques are useful in exploiting irregular parallelism in unstructured computations <ref> [34, 20, 16] </ref>. For iterative irregular problems in which communication and computation phases alternate, the CHAOS/PARTI system [11] has used the inspector/executor approach to exploit irregular parallelism at each iteration of the computation fl A preliminary version of this work appears in the 10th International Parallel Processing Symposium. 1 phase.
Reference: [21] <author> J. W. H. Liu. </author> <title> Computational Models and Task Scheduling for Parallel Sparse Cholesky Factorization . Parallel Computing, </title> <booktitle> 18 </booktitle> <pages> 327-342, </pages> <year> 1986. </year>
Reference-contexts: Rothberg and Schreiber [26, 27] show that the supernode-based approach can deliver good performance on both shared and distributed memory machines. Specialized scheduling techniques have been studied for sparse Cholesky factorization in <ref> [15, 21] </ref>. We will examine the performance of applying general task scheduling and executing techniques to this problem. For a dense matrix, the BLAS-3 level Cholesky factorization algorithm 3 is shown in Figure 11.
Reference: [22] <author> S. Pande, D. P. Agrawal, and J. Mauney. </author> <title> A Scalable Scheduling Scheme for Functional Parallelism on Distributed Memory Multiprocessor Systems . IEEE Transactions on Parallel and Distributed Systems, </title> <booktitle> 6(4) </booktitle> <pages> 388-399, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: With the presence of anti and output dependence, synchronization in run-time support becomes more complicated in order to ensure the correctness of execution. In functional languages, the "single assignment" principle has been used in data flow computation and functional languages <ref> [28, 22] </ref>, i.e., each data item can be written at most once, thus there is neither output nor anti dependence. The renaming techniques [10] can eliminate the output and anti dependence in transforming a DDG to a "single assignment" graph.
Reference: [23] <author> S. Pande and K. Psarris. </author> <title> Scheduling Acylic Task Graphs on Distributed Memory Parallel Architectures, volume 22 of Parallel Processing of Discrete Optimization (Edited by P. </title> <editor> Pardalos, M. Resende and K. G. </editor> <booktitle> Ramakrishnan), </booktitle> <pages> pages 289-304. </pages> <publisher> AMS, </publisher> <year> 1995. </year> <title> DIMACS Series. </title>
Reference-contexts: We have the processor assignment (A) = (B) = (D) = 0, (C) = (E) = 1, and the execution orderings O 0 = fA; B; Dg, O 1 = fC; Eg. Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. <ref> [9, 23, 28, 38] </ref>. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive [25, 3], but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines.
Reference: [24] <author> R. Peyret and T. Taylor. </author> <title> Computational Methods for Fluid Flow . Springer-Verlag, </title> <year> 1983. </year>
Reference-contexts: In general, we have observed 115% performance improvement. 6.1.2 Sparse LU factorization without pivoting LU factorization without pivoting can be used for positive definite or strictly diagonal dominant matrices. Many of algebraic systems arising from the discretization of diffusion and convection problems in fluid dynamics <ref> [24] </ref> are nonsymmetric and diagonal dominant.
Reference: [25] <author> C. D. </author> <title> Polychronopoulos. </title> <publisher> Parallel Programming and Compilers . Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. [9, 23, 28, 38]. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive <ref> [25, 3] </ref>, but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines. Static scheduling can adapt to certain degree of run-time weight variation [16, 37] and its run-time control mechanism is relatively simple. <p> Classical data dependence graphs (DDG) for modeling the interaction between computation statements have three types of dependencies: true, anti and output <ref> [25] </ref>. Task graphs differ from DDG in that they only have true data dependence edges. In a DDG, many of anti or output dependence edges could be redundant if they are subsumed by other true data dependence edges.
Reference: [26] <author> E. Rothberg. </author> <title> Exploiting the Memory Hierarchy in Sequential and Parallel Sparse Cholesky Factorization . PhD thesis, </title> <institution> Dept. of Computer Science, Stanford, </institution> <month> December </month> <year> 1992. </year> <month> 30 </month>
Reference-contexts: We demonstrate the applications of our techniques for sparse matrix computations. It has been very difficult to obtain actual speedups by hand-made code for these problems, not to mention automatically parallelized code, especially on distributed memory machines. Recently impressive 2 performance is obtained for sparse Cholesky factorization <ref> [26, 27] </ref> and sparse triangular solver [7]. We discuss how we can exploit task parallelism in sparse Cholesky/LU factorizations using our techniques in a general run-time support environment. One difficulty in parallelizing sparse Cholesky factorization is that parallelism also arises from operations that commute. <p> Rothberg and Schreiber <ref> [26, 27] </ref> show that the supernode-based approach can deliver good performance on both shared and distributed memory machines. Specialized scheduling techniques have been studied for sparse Cholesky factorization in [15, 21]. We will examine the performance of applying general task scheduling and executing techniques to this problem. <p> Many of algebraic systems arising from the discretization of diffusion and convection problems in fluid dynamics [24] are nonsymmetric and diagonal dominant. The boundary conditions 4 In comparison, Rothberg <ref> [26] </ref> reported that the sequential performance of his code achieved 77% of LINPACK for BCSSTK15 and 71% in average for other matrices on IBM RS/6000 Model 320. 19 Matrix P=2 P=4 P=8 P=16 P=32 BCSSTK15 4% 4% 10% 9% 15% BCSSTK16 6% 8% 4% 3% 7% BCSSTK17 8% 15% 4% -9% <p> In order to improve the performance further, our future work is to consider techniques of increasing average supernode sizes, e.g., supernode amalgamation <ref> [2, 26] </ref>. 22 left part is for BCSSTK24 and the right is for BCSSTK15. 6.2 Sparse triangular solver and performance impact of granularities From the discussion in the last section we know that the task granularity of an application is important to the performance of irregular code.
Reference: [27] <author> E. Rothberg and R. Schreiber. </author> <title> Improved Load Distribution in Parallel Sparse Cholesky Fac--torization. </title> <booktitle> In Proc. of Supercomputing'94, </booktitle> <pages> pages 783-792, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: We demonstrate the applications of our techniques for sparse matrix computations. It has been very difficult to obtain actual speedups by hand-made code for these problems, not to mention automatically parallelized code, especially on distributed memory machines. Recently impressive 2 performance is obtained for sparse Cholesky factorization <ref> [26, 27] </ref> and sparse triangular solver [7]. We discuss how we can exploit task parallelism in sparse Cholesky/LU factorizations using our techniques in a general run-time support environment. One difficulty in parallelizing sparse Cholesky factorization is that parallelism also arises from operations that commute. <p> Rothberg and Schreiber <ref> [26, 27] </ref> show that the supernode-based approach can deliver good performance on both shared and distributed memory machines. Specialized scheduling techniques have been studied for sparse Cholesky factorization in [15, 21]. We will examine the performance of applying general task scheduling and executing techniques to this problem. <p> In average, we have obtained speedup 7 on 16 processors and 11:3 on 32 processors. We will discuss the overhead of run-time execution in Section 6.1.3. The speedup on 32 processors is 11:33 for BCSSTK15 and processor utilization efficiency is 35:4%. In <ref> [27] </ref>, efficiency 25% has been reported for BCSSTK15 on 64 processors (Intel Paragon) after improving the load balancing strategy. This indicates that the parallelism is limited in the sparse problems and our scheduled code has achieved reasonable performance.
Reference: [28] <author> V. Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors . MIT Press, </title> <year> 1989. </year>
Reference-contexts: Most of previous work in DAG scheduling has mainly focused on the algorithmic research for mapping tasks onto multi-processors based on the macro task computation model <ref> [28, 35] </ref>. But little research has been conducted on efficient run-time support for executing task schedules. <p> We have the processor assignment (A) = (B) = (D) = 0, (C) = (E) = 1, and the execution orderings O 0 = fA; B; Dg, O 1 = fC; Eg. Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. <ref> [9, 23, 28, 38] </ref>. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive [25, 3], but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines. <p> With the presence of anti and output dependence, synchronization in run-time support becomes more complicated in order to ensure the correctness of execution. In functional languages, the "single assignment" principle has been used in data flow computation and functional languages <ref> [28, 22] </ref>, i.e., each data item can be written at most once, thus there is neither output nor anti dependence. The renaming techniques [10] can eliminate the output and anti dependence in transforming a DDG to a "single assignment" graph.
Reference: [29] <author> K. E. Schauser and C. J. Scheiman. </author> <title> Experience with Active Messages on the Meiko CS-2. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <pages> pages 140-149, </pages> <year> 1995. </year>
Reference-contexts: We have implemented our system on Meiko CS-2 which provides Direct Memory Access (DMA) as the major way to access non-local memory. Each node of Meiko CS-2 is also equipped with a DMA co-processor for handling communication. It takes the main processor 9 microseconds <ref> [29] </ref> to dispatch the remote memory access descriptor to the co-processor. The co-processor afterwards will be responsible for sending data without interrupting the main processor so that the opportunity of overlapping communication and computation is maximized. <p> The source code of LINPACK is obtained from the public domain. 14 The cost to dispatch a RMA request is 9 microseconds. The communication peak bandwidth of Meiko CS-2 is 40MBytes/Sec. The effective peak bandwidth has been reported as 39MB/Sec, but this is obtained through a ping-pong test <ref> [29] </ref> and message caching improves the performance implicitly. In practice, a message is sent only once at a time. We show the effective bandwidth of a single-message sending or direct memory access in Figure 10 when the sizes of messages vary from 1K to 10K.
Reference: [30] <author> R. Schreiber. </author> <title> Scalability of Sparse Direct Solvers, volume 56 of Graph Theory and Sparse Matrix Computation (Edited by Alan George and John R. </title> <editor> Gilbert and Joseph W.H. </editor> <booktitle> Liu), </booktitle> <pages> pages 191-209. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Efficient paral-lelization of sparse factorization requires certain compilation cost, but the optimized solution can be used for many iterations. The sparse matrix factorizations can be modeled as DAGs <ref> [30] </ref>. However compared to large n-body simulations, efficient execution of DAG schedules for sparse matrix problems is more challenging because partitioned graphs contain both coarse and fine grained tasks while in the DAGs arising from large n-body simulations, most of tasks are relatively coarse-grained [16].
Reference: [31] <author> W. Shu and L. Kale. </author> <title> Chare Kernel A Runtime Support System for Parallel Computations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11(3) </volume> <pages> 198-211, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Recently the work by [8] demonstrates that using both effective DAG scheduling and low-overhead communication mechanisms, scalable performance can be obtained on fine-grained DAGs for solving sparse triangular systems. Run-time support for parallel computations. The Charm <ref> [31] </ref> system adopts a message driven approach for general asynchronous computation. Each processor contains a group of threads and a message queue. A thread can only be triggered by a message and dynamic scheduling is used to balance processor loads.
Reference: [32] <author> S. Venugopal, V. Naik, and J. Saltz. </author> <title> Performance of Distributed Sparse Cholesky Factorization with Pre-scheduling. </title> <booktitle> In Proc. of Supercomputing'92, </booktitle> <pages> pages 52-61, </pages> <address> Minneapolis, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Application of graph scheduling for solving scientific problems. As we discussed before, application of graph scheduling has been used in large n-body simulations [16]. In <ref> [32] </ref>, static task and communication scheduling is used for sparse Cholesky, and they found that pre-scheduling improves the performance of distributed factorization by 30% to 40%. However the run-time overhead for task execution is still large and there is a great deal of room for obtaining better absolute performance.
Reference: [33] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Recently Cilk [3] also addresses the DAG consistency, but it does not incorporate the optimizations used in our model such as eliminating redundant communications. Low overhead communication mechanism. The lower-level communication primitives of our system could be implemented using active messages <ref> [33] </ref> which provide an efficient integrated service for passing data and control on distributed memory machines. An active message usually contains a function handler and a few short data arguments, and the function at the destination processor can be invoked as soon as this message arrives at the destination.
Reference: [34] <author> C.-P. Wen, S. Chakrabarti, E. Deprit, A. Krishnamurthy, and K. Yelick. </author> <title> Runtime Support for Portable Distributed Data Structures, chapter 9. Languages, Compilers, and Runtime Systems for Scalable Computers. </title> <publisher> Kluwer Academic Publishers, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: The automatic parallelization of such problems on distributed memory machines is extremely difficult and presents a great challenge. Automatic scheduling and load balancing techniques are useful in exploiting irregular parallelism in unstructured computations <ref> [34, 20, 16] </ref>. For iterative irregular problems in which communication and computation phases alternate, the CHAOS/PARTI system [11] has used the inspector/executor approach to exploit irregular parallelism at each iteration of the computation fl A preliminary version of this work appears in the 10th International Parallel Processing Symposium. 1 phase. <p> Our work is focusing on the efficient execution of tasks with mixed granularities arising in sparse matrix computations. There are other run-time systems developed for irregular computations. We have mentioned Chaos in the introduction. Multipol <ref> [34] </ref> is a run-time library system which supports distributed data structures for several kinds of scientific applications. Consistency models. The issue of executing a program correctly has been studied in the context of distributed shared memory systems (DSM).
Reference: [35] <author> M. Y. Wu and D. Gajski. Hypertool: </author> <title> A Programming Aid for Message-passing Systems . IEEE Transactions on Parallel and Distributed Systems, </title> <booktitle> 1(3) </booktitle> <pages> 330-343, </pages> <year> 1990. </year>
Reference-contexts: Most of previous work in DAG scheduling has mainly focused on the algorithmic research for mapping tasks onto multi-processors based on the macro task computation model <ref> [28, 35] </ref>. But little research has been conducted on efficient run-time support for executing task schedules.
Reference: [36] <author> T. Yang. </author> <title> Scheduling and Code Generation for Parallel Architectures . PhD thesis, </title> <institution> Dept. of Computer Science, Rutgers University, </institution> <address> New Brunswick, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Most of previous work in DAG scheduling has mainly focused on the algorithmic research for mapping tasks onto multi-processors based on the macro task computation model [28, 35]. But little research has been conducted on efficient run-time support for executing task schedules. The early work in the PYRROS system <ref> [38, 36] </ref> provides a complete framework for general task computation; however, its run-time support system uses the NX/2 level communication interface and the overhead derived from message buffer managing and data copying is significant, which prevents PYRROS from obtaining good performance in executing sparse matrix computations with mixed granularities. <p> This will become clearer as we discuss in the subsequent sections. More discussion on the above properties and their relationship can be found in <ref> [36] </ref>. The transformation to convert a DDG to a dependence complete task graph is described in [14]. Most task graphs derived from real scientific applications satisfy these properties without renaming.
Reference: [37] <author> T. Yang, C. Fu, A. Gerasoulis, and V. Sarkar. </author> <title> Mapping Iterative Task Graphs on Distributed-memory Machines . In International Conf. </title> <booktitle> on Parallel Processing, </booktitle> <pages> pages 151-158, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Static scheduling can adapt to certain degree of run-time weight variation <ref> [16, 37] </ref> and its run-time control mechanism is relatively simple. <p> These two issues make timing among tasks different from what is expected at the static time and tend to increase the processor idle time. The performance becomes even more sensitive when task granularities are small <ref> [16, 37] </ref>.
Reference: [38] <author> T. Yang and A. Gerasoulis. </author> <title> PYRROS: Static Task Scheduling and Code Generation for Message-Passing Multiprocessors . In Proc. </title> <booktitle> of 6th ACM International Conference on Supercomputing, </booktitle> <pages> pages 428-437, </pages> <year> 1992. </year> <month> 31 </month>
Reference-contexts: The DAG schedule can be re-used for a number of iterations before re-scheduling since particle movement is slow. Then good speedups are obtained on nCUBE-2 for large n-body simulation problems after applying PYRROS DAG scheduling techniques <ref> [38] </ref>. Such results demonstrate that graph scheduling can effectively exploit irregular task parallelism to balance loads and overlap computation with communication. <p> Most of previous work in DAG scheduling has mainly focused on the algorithmic research for mapping tasks onto multi-processors based on the macro task computation model [28, 35]. But little research has been conducted on efficient run-time support for executing task schedules. The early work in the PYRROS system <ref> [38, 36] </ref> provides a complete framework for general task computation; however, its run-time support system uses the NX/2 level communication interface and the overhead derived from message buffer managing and data copying is significant, which prevents PYRROS from obtaining good performance in executing sparse matrix computations with mixed granularities. <p> We have the processor assignment (A) = (B) = (D) = 0, (C) = (E) = 1, and the execution orderings O 0 = fA; B; Dg, O 1 = fC; Eg. Algorithms for static scheduling of DAGs have been extensively studied in the literatures, e.g. <ref> [9, 23, 28, 38] </ref>. Dynamic scheduling which is adaptive to run-time change of dependence structures and weights is more attractive [25, 3], but it is still difficult to balance its benefits and the run 3 time control overhead in executing tasks with mixed grains on message-passing machines. <p> Optimizations have to be performed to eliminate redundant messages. Correspondingly, in the destination only one receiving is needed to pull out data from the network. Subsequent receiving operations for this data item should be re-directed to read from the local memory instead. PYRROS <ref> [38] </ref> uses a buffered message-passing mechanism and aggregates communication as much as possible.
References-found: 38

