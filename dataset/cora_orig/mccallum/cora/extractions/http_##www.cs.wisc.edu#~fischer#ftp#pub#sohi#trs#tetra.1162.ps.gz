URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/tetra.1162.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/
Root-URL: http://www.cs.wisc.edu
Email: faustin; sohig@cs.wisc.edu  
Title: Tetra: Evaluation of Serial Program Performance on Fine-Grain Parallel Processors  
Author: Todd M. Austin Gurindar S. Sohi Todd M. Austin and Gurindar S. Sohi. 
Note: c 1993 by  This work was supported by a grant from the National Science Foundation (grant CCR-8919635).  
Date: July 11, 1993  
Address: 1210 W. Dayton Street Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Tetra is a tool for evaluating serial program performance under the resource and control constraints of fine-grain parallel processors. Tetra's primary advantage to the architect is its ability to quickly generate performance metrics for yet to be designed architectures. All the user needs to specify is the capabilities of the architecture (e.g., number of functional units, issue model, etc.), rather than its implementation. Tetra first extracts a canonical form of the program from a serial instruction trace. It then applies control and resource constraint scheduling to produce an execution graph. The control and resource constraint scheduling is directed by a processor model specification supplied to the program. Once scheduled, Tetra provides a number of ways to analyze the program's performance under the specified processor model. These include parallelism profiles, storage demand profiles, data sharing distributions, data lifetime analysis, and control distance (branch, loop, and call stack) distributions. In this report, we present the extraction, scheduling, and analysis methodologies used by Tetra. We detail their implementation and discuss a number of performance optimizations used. The appendix includes the user's documentation for Tetra. 
Abstract-found: 1
Intro-found: 1
Reference: [ACM88] <author> Arvind, D. E. Culler, and G. K. Maa. </author> <title> Assessing the benefits of fine-grained parallelism in dataflow programs. </title> <booktitle> In Conference Proceedings of Supercomputing 88, </booktitle> <pages> pages 60-69, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: We also extend their heuristics to support scheduling of resource with non-deterministic latency, which allows us to examine the effects of limited storage resources. A number of papers from the dataflow literature have included examples of DDG analysis <ref> [CA88, ACM88, AN89, Nik90] </ref>. For example, Culler and Arvind [CA88] provide detailed parallelism profiles and waiting token (or storage demand) profiles for some dataflow programs. Their dataflow processor and language environment lends itself well to DDG analysis. <p> We have found in our research that our results agree with the conclusions of <ref> [ACM88] </ref> and [Kum88] that ordinary programs and algorithms, not intended to execute in parallel 10 environments, do indeed have a significant amount of fine-grain parallelism. Larus performed detailed studies of loop level parallelism for a number of the SPEC benchmarks [Lar91].
Reference: [AJLS92] <author> V. H. Allan, J. Janardhan, R. M. Lee, and M. Srinivas. </author> <title> Enhanced region scheduling on a program dependence graph. </title> <booktitle> In Conference Record of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 72-80, </pages> <address> Portland, OR, </address> <month> December </month> <year> 1992. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: For example, Beckmann [BP92] has proposed hardware support for multithreaded execution of serial programs. The execution conditions that fire off threads are based on the CDG rather than the more restrictive CFG. Compiler examples include PDG based scheduling techniques such as region scheduling <ref> [AJLS92, GS90] </ref>. These techniques implement a CDG based issue model on mundane hardware by applying speculative and non-speculative code motion such that code executes upon resolution of the control dependent predicate, rather than the preceding branch. operation to the time of the last control barrier as defined by the CDG.
Reference: [AN89] <author> Arvind and Rishiyur S. Nikhil. </author> <title> A dataflow approach to general-purpose parallel computing. Computation Structures Group Memo 302, </title> <publisher> MIT, </publisher> <month> July </month> <year> 1989. </year>
Reference-contexts: We also extend their heuristics to support scheduling of resource with non-deterministic latency, which allows us to examine the effects of limited storage resources. A number of papers from the dataflow literature have included examples of DDG analysis <ref> [CA88, ACM88, AN89, Nik90] </ref>. For example, Culler and Arvind [CA88] provide detailed parallelism profiles and waiting token (or storage demand) profiles for some dataflow programs. Their dataflow processor and language environment lends itself well to DDG analysis.
Reference: [AS92] <author> Todd M. Austin and Gurindar S. Sohi. </author> <title> Dynamic dependency analysis of ordinary programs. </title> <booktitle> In Conference Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 342-351. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: The physical storage is reserved for an indeterminate amount of time. We could extend the resource scheduling to include other processor resources, such as result buses, functional unit input buses, or instruction window slots (as in <ref> [AS92] </ref>); the methodologies described here would apply to these cases as well. We study both unconstrained and constrained resource scheduling techniques all of which are detailed in Section 3. The first, topological sorting, is an optimal, resource unconstrained scheduling technique. <p> We extend their work by evaluating the advantages of more computationally frugal scheduling heuristics as well as showing the limitations in their scheduling heuristic. We also examine the smoothability of the storage demand, and combine both control and resource scheduling. We extend our earlier work <ref> [AS92] </ref> in a number of ways. This paper provides a more detailed description of the methodology, and we describe a number of invariants on the algorithm as well as examine its time and storage complexity. <p> The impact to the program's run-time is minimal; for a 21 million instruction analysis of gcc (compiling stmt.c with option -O), run-time bounds checking only increased the run time by 10%. Tetra is our second DDG analyzer implementation. Our first implementation, ParaGraph is described in <ref> [AS92] </ref>. This newer implementation is nearly two orders of magnitude faster than the previous even with more capabilities and run time bounds checking code. This overall speedup comes primarily from optimizations to the hash table, the storage allocator, and the trace regenerator.
Reference: [ASU86] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: A loop is defined as any subgraph of the CFG in which one basic block, the loop header, dominates all basic blocks up to and including one or more blocks that contain a back edge to the loop header <ref> [ASU86] </ref>. This definition suffices unless the CFG contains irreducible loops. 4 While irreducible loops can be created in most languages, they are generally not found in practice. 5 In our DDG analyses, we annotate the instruction trace with loop start, end, and continue "signals". <p> Since the size of the live 4 One "loose" definition of an irreducible loop is: a loop which does not contain jumps into the middle from outside of the loop; a reducible loop can only have entries at the loop header. See <ref> [ASU86] </ref> for a formal definition. 5 The only SPEC benchmark containing irreducible loops is spice2g6.
Reference: [BA92] <author> Scott Breach and Todd Austin. Safe-C: </author> <note> Seat belts for C. available from Todd Austin, austin@cs.wisc.edu, Fall 1992. </note>
Reference-contexts: Tetra is currently targeted to the MIPs architecture (running on DECstations). It is written in C using Safe-C extensions. Safe-C is a set of C++ templates and macros which performs extensive run-time checking of pointer and array accesses <ref> [BA92] </ref>. When using Safe-C, a program cannot access out of the bounds or lifetime of any object without notification (i.e., the program dumps core). If Safe-C is disabled, the program will compile with any vanilla 'C' compiler.
Reference: [BL92] <author> T. Ball and J. R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In Conference Record of the 19th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 59-70, </pages> <address> Albu-querque, NM, </address> <month> January </month> <year> 1992. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Tetra is freely distributable we encourage practitioners and researchers alike to use it or extend it as they see fit. See the epilogue of this report for distribution details. analysis. In the first phase, trace generation, we use QPT (Quick Profiler and Tracer <ref> [BL92] </ref>) to re-write 28 var resHeap: ARRAY [0..MAX RESOURCES-1] of Level; function ResourceSchedule (inst: Inst, earliest: Level): Level; begin schedLevel: Level; resIndex: integer; resIndex := random (MAX RESOURCES); schedLevel := resHeap [resIndex]; schedLevel := max (earliest, schedLevel); resHeap [resIndex] := schedLevel + PLatency (inst); ResourceSchedule := schedLevel; endfunc the program executable
Reference: [BLL92] <author> Allan Bricker, Michael Litzkow, and Miron Livny. </author> <type> Condor technical report. Technical Report 1069, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Tetra interfaces to QPT via a linked call-back function. Our analysis framework also supports CONDOR execution. CONDOR is a collection of software tools and libraries that allow programs to execute remotely on homogeneous architectures, but still access all the program's local resource (via a network layer system call interface) <ref> [BLL92] </ref>. Using CONDOR we are able to save a single trace file, and then "farm" out numerous analyses that will run on idle machines. Tetra is currently targeted to the MIPs architecture (running on DECstations). It is written in C using Safe-C extensions.
Reference: [BP92] <author> Carl J. Beckmann and Constantine D. Polychronopoulos. </author> <title> Microarchitecture support for dynamic scheduling of acyclic task graphs. </title> <booktitle> In Conference Record of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 140-148, </pages> <address> Portland, OR, </address> <month> December </month> <year> 1992. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The CDG issue model can be exploited either by the hardware or the compiler, or both. For example, Beckmann <ref> [BP92] </ref> has proposed hardware support for multithreaded execution of serial programs. The execution conditions that fire off threads are based on the CDG rather than the more restrictive CFG. Compiler examples include PDG based scheduling techniques such as region scheduling [AJLS92, GS90].
Reference: [BYP + 91] <author> M. Butler, T. Yeh, Y. Patt, M. Alsup, H. Scales, and M. Shebanow. </author> <title> Single instruction stream parallelism is greater than two. </title> <booktitle> In Conference Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 276-286. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Before we describe our methodology, we briefly discuss the previous work in this area. 3.1 Previous Work There has been a plethora of work which measured the average parallelism in a (sequential) instruction stream for a particular hardware configuration <ref> [BYP + 91, NF84, SJH89, TF70, Wal91] </ref>.
Reference: [CA88] <author> David E. Culler and Arvind. </author> <title> Resource requirements of dataflow programs. </title> <booktitle> In Conference Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 141-150. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: We also extend their heuristics to support scheduling of resource with non-deterministic latency, which allows us to examine the effects of limited storage resources. A number of papers from the dataflow literature have included examples of DDG analysis <ref> [CA88, ACM88, AN89, Nik90] </ref>. For example, Culler and Arvind [CA88] provide detailed parallelism profiles and waiting token (or storage demand) profiles for some dataflow programs. Their dataflow processor and language environment lends itself well to DDG analysis. <p> We also extend their heuristics to support scheduling of resource with non-deterministic latency, which allows us to examine the effects of limited storage resources. A number of papers from the dataflow literature have included examples of DDG analysis [CA88, ACM88, AN89, Nik90]. For example, Culler and Arvind <ref> [CA88] </ref> provide detailed parallelism profiles and waiting token (or storage demand) profiles for some dataflow programs. Their dataflow processor and language environment lends itself well to DDG analysis. Instrumenting the dataflow processor's execution is sufficient to generate the parallelism profiles and critical path.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and and the control dependence graph. </title> <journal> ACM Transactions on Programming Langauages and Systems, </journal> <volume> 13(3) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: All future operations will be placed after the mis-predicted conditional branch. The second control scheduling model, CDG scheduling, issues operations based on the more relaxed control model as specified by the control dependence graph. (See [FOW87] or <ref> [CFR + 91] </ref> for a complete description and formal definition.) CDG scheduling allows operations to issued as soon as their surrounding predicate is resolved (or correctly speculated). <p> the DDG level for case i, the procedure first calls LastCDNode () which returns the address of the last executed branch upon which inst is control dependent. 6 We employ the computationally efficient dominance frontier technique to annotate all the conditional branches upon which a basic block is control dependent <ref> [CFR + 91] </ref>. This involves first computing the post-dominator tree [LT79]. And then, for each node in the CFG, a depth first traversal is used to identify the nodes in the CFG where some basic block no longer post dominates all of its successors.
Reference: [CSY90] <author> D. K. Chen, H. M. Su, and P. C. Yew. </author> <title> The impact of synchronization and granularity on parallel systems. </title> <booktitle> In Conference Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 239-248. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: By measuring the control distance of dependencies, we can then show for a given level of parallelism, how effective speculation must be to expose that parallelism. MaxPar <ref> [CSY90] </ref> is very similar to Kumar's COMET in that it also rewrites programs. Where Kumar's COMET was limited to scheduling program statements, MaxPar has the ability to schedule at the granularity of operation-level, statement-level, loop-level, or subprogram-level. It can also limit computing resources available during analysis.
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its uses in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Until the branch's predicate has been resolved, it is not known which instructions will be executed after the branch, thus all subsequent instructions share a control dependency with the conditional branch. This view of control dependence is actually over-restrictive, since it has been shown <ref> [FOW87] </ref> that by applying control dependence analysis, it is possible to either remove some control dependencies or re-attribute them to earlier executed instructions. <p> The first model, CFG scheduling, is the traditional issue model where instruction issue is based on control dependencies realized on a traversal of the control flow graph of the program. The second model, CDG scheduling, uses the less restrictive control dependence graph <ref> [FOW87] </ref>. Both scheduling algorithms are described in Section 3.4. In the second phase of scheduling, resource scheduling, the issued operations are allocated to processor resources using a scheduling heuristic. Two processor resources must be allocated before an instruction can be executed functional unit and storage resources. <p> It is reset to the level of the mis-predicted conditional branch (in schedLevel). All future operations will be placed after the mis-predicted conditional branch. The second control scheduling model, CDG scheduling, issues operations based on the more relaxed control model as specified by the control dependence graph. (See <ref> [FOW87] </ref> or [CFR + 91] for a complete description and formal definition.) CDG scheduling allows operations to issued as soon as their surrounding predicate is resolved (or correctly speculated).
Reference: [FS92] <author> Manoj Franklin and Gurindar S. Sohi. </author> <title> The expandable split window paradigm for exploiting fine-grain parallelism. </title> <booktitle> Computer Architecture News, </booktitle> <pages> pages 58-67, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: In the actual execution, the same ordering will result unless the hardware has support for speculative loads (such as in the multiscalar processor <ref> [FS92] </ref>). Control Dependencies: Control dependencies are introduced by conditional branches encountered during the execution of a program. Until the branch's predicate has been resolved, it is not known which instructions will be executed after the branch, thus all subsequent instructions share a control dependency with the conditional branch.
Reference: [FT87] <author> Micheal L. Fredman and Robert Endre Tarjan. </author> <title> Fibonacci heaps and their uses in improved network optimization algorithms. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 34(3) </volume> <pages> 596-615, </pages> <month> July </month> <year> 1987. </year> <month> 34 </month>
Reference-contexts: In our DDG analyzer, we implement the priority queue with a Fibonacci heap <ref> [FT87] </ref>. We selected this structure because it is one the fastest know priority queue implementations. Its asymptotic time complexity is O (1) for access to the minimum value entry (its the root of the heap), O (1) for arbitrary value insertions, and O (log p) for deletions.
Reference: [GGJ78] <author> M. R. Garey, R. L. Graham, and D. S. Johnson. </author> <title> Performance guarantees for scheduling algorithms. </title> <journal> Operations Research, </journal> <volume> 26(1) </volume> <pages> 3-21, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: We define an optimal schedule to be one in which the given supply of resources produces the shortest length schedule. Unfortunately, generating an optimal schedule of a DAG in the presence of resource limitations is an NP-complete problem for even very small resource supplies <ref> [LK78, GGJ78, GJ79] </ref>. Thus no known algorithm can do the task is less than exponential time (exponential with respect to the size of the trace being analyzed!) When resources are limited, a scheduling heuristic must be applied and the resulting schedule will nearly always be sub-optimal. <p> Table 1 summarizes the five resource constrained scheduling heuristics. Because the heuristic schedules only approximate the optimal schedule, a question naturally arises: how close to optimal is the heuristic schedule? This question is typically answered by generating what is called the competitive ratio <ref> [GGJ78] </ref> for the given heuristic. A competitive ratio is a numeric upper bound showing, for the worse case, how much longer the resulting heuristic schedule is compared to the length of the optimal schedule for the same problem instance.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: We define an optimal schedule to be one in which the given supply of resources produces the shortest length schedule. Unfortunately, generating an optimal schedule of a DAG in the presence of resource limitations is an NP-complete problem for even very small resource supplies <ref> [LK78, GGJ78, GJ79] </ref>. Thus no known algorithm can do the task is less than exponential time (exponential with respect to the size of the trace being analyzed!) When resources are limited, a scheduling heuristic must be applied and the resulting schedule will nearly always be sub-optimal.
Reference: [GS90] <author> Rajiv Gupta and Mary Lou Soffa. </author> <title> Region scheduling: An approach for detecting and redistributing parallelism. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4) </volume> <pages> 421-431, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: For example, Beckmann [BP92] has proposed hardware support for multithreaded execution of serial programs. The execution conditions that fire off threads are based on the CDG rather than the more restrictive CFG. Compiler examples include PDG based scheduling techniques such as region scheduling <ref> [AJLS92, GS90] </ref>. These techniques implement a CDG based issue model on mundane hardware by applying speculative and non-speculative code motion such that code executes upon resolution of the control dependent predicate, rather than the preceding branch. operation to the time of the last control barrier as defined by the CDG.
Reference: [Kea74] <author> D. J. Kuck and et al. </author> <title> Measurements of parallelism in ordinary FORTRAN programs. </title> <journal> Computer, </journal> <volume> 27 </volume> <pages> 37-46, </pages> <month> January </month> <year> 1974. </year>
Reference: [Kum88] <author> Manoj Kumar. </author> <title> Measuring parallelism in computation-intensive scientific/engineering applications. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(9) </volume> <pages> 1088-1098, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: An early work measuring total available parallelism is that of Kuck, et al.[Kea74] They statically analyzed (by hand) program dependencies in FORTRAN programs, and the resulting available parallelism was estimated from the analyzed code fragments. Kumar <ref> [Kum88] </ref> presented the first work that gathered exact parallelism profiles in serial FORTRAN programs. Kumar extracted parallelism profiles by rewriting FORTRAN programs (with COMET) such that the profile was generated during the execution of the program. <p> We have found in our research that our results agree with the conclusions of [ACM88] and <ref> [Kum88] </ref> that ordinary programs and algorithms, not intended to execute in parallel 10 environments, do indeed have a significant amount of fine-grain parallelism. Larus performed detailed studies of loop level parallelism for a number of the SPEC benchmarks [Lar91].
Reference: [Lar91] <author> James R. Larus. </author> <title> Estimating the potential parallelism in programs. </title> <editor> In Alexandru Nicolau, David Gelernter, Thomas Gross, and David Padua, editors, </editor> <booktitle> Proceedings of the Third Workshop on Languages and Compilers for Parallel Computing, chapter 17, </booktitle> <pages> pages 331-349. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Larus performed detailed studies of loop level parallelism for a number of the SPEC benchmarks <ref> [Lar91] </ref>. Because the analysis was intended primarily for directing the development and application of compilers capable of parallelizing loops, the analysis was limited to intra-loop parallelism of each lexically top level loop. Our analysis examines parallelism in a more global view, thus allowing inter-loop parallelism to also be analyzed.
Reference: [LK78] <author> J. K. Lenstra and A. H. G. Rinnooy Kan. </author> <title> Complexity of scheduling under precedence constraints. </title> <journal> Operations Research, </journal> <volume> 26(1) </volume> <pages> 22-35, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: We define an optimal schedule to be one in which the given supply of resources produces the shortest length schedule. Unfortunately, generating an optimal schedule of a DAG in the presence of resource limitations is an NP-complete problem for even very small resource supplies <ref> [LK78, GGJ78, GJ79] </ref>. Thus no known algorithm can do the task is less than exponential time (exponential with respect to the size of the trace being analyzed!) When resources are limited, a scheduling heuristic must be applied and the resulting schedule will nearly always be sub-optimal.
Reference: [LT79] <author> T. Lengauer and R. E. Tarjan. </author> <title> A fast algorithm for finding dominators in a flowgraph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 121-141, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: This involves first computing the post-dominator tree <ref> [LT79] </ref>. And then, for each node in the CFG, a depth first traversal is used to identify the nodes in the CFG where some basic block no longer post dominates all of its successors. This is the dominance frontier of the CFG node.
Reference: [LW92] <author> Monica S. Lam and Robert P. Wilson. </author> <title> Limits of control flow on parallelism. </title> <booktitle> In Conference Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 46-57. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Kumar implemented a control model similar to our CDG issue model. Specifically, he did not allow any FORTRAN statement to execute until all surrounding predicates had completed evaluation. Lam and Wilson's work <ref> [LW92] </ref> has shown this assumption to be overly restrictive, as the use of speculation can allow many operations to execute prior to the resolution of their surrounding predicates. <p> This supports our thesis that the DDG of a program is, for the most part, a canonical form of a program. Wilson and Lam <ref> [LW92] </ref> studied the effects of control dependencies on available parallelism. Their primary result showed how combining control dependence analysis, multiple flows of control, and speculative execution could expose a large portion of the total available parallelism found in the unconstrained DDG.
Reference: [MWC + 91] <author> S. K. Mahlke, N. J. Warter, W. Y. Chen, P. P. Chang, and W. W. Hwu. </author> <title> The effect of compiler optimizations on available parallelism in scalar programs. </title> <booktitle> Preceedings of the 20th Annual International Conference on Parallel Processing, </booktitle> <pages> pages 142-146, </pages> <year> 1991. </year>
Reference-contexts: Our analysis examines parallelism in a more global view, thus allowing inter-loop parallelism to also be analyzed. Still, for a number of programs, our results are quantitatively very close to Larus', supporting that for many programs, much of the parallelism is intra-loop parallelism. Mahlke et al. <ref> [MWC + 91] </ref> examined the effects of compiler optimizations on serial program parallelism. They looked specifically at three classes of program optimization: classical, superscalar, and multiprocessor. The superscalar optimizations encompass their superblock global trace scheduling techniques, loop unrolling and peeling, and induction variable expansion.
Reference: [NF84] <author> A. Nicolau and J. Fisher. </author> <title> Measuring the parallelism available for very long instruction word architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 33(11) </volume> <pages> 968-976, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: Before we describe our methodology, we briefly discuss the previous work in this area. 3.1 Previous Work There has been a plethora of work which measured the average parallelism in a (sequential) instruction stream for a particular hardware configuration <ref> [BYP + 91, NF84, SJH89, TF70, Wal91] </ref>.
Reference: [Nik90] <author> Rishiyur S. Nikhil. </author> <title> The parallel programming language id and its compilation for parallel machines. Computation Structures Group Memo 313, </title> <publisher> MIT, </publisher> <month> July </month> <year> 1990. </year>
Reference-contexts: We also extend their heuristics to support scheduling of resource with non-deterministic latency, which allows us to examine the effects of limited storage resources. A number of papers from the dataflow literature have included examples of DDG analysis <ref> [CA88, ACM88, AN89, Nik90] </ref>. For example, Culler and Arvind [CA88] provide detailed parallelism profiles and waiting token (or storage demand) profiles for some dataflow programs. Their dataflow processor and language environment lends itself well to DDG analysis.
Reference: [SJH89] <author> M. D. Smith, M. Johnson, and M. A. Horowitz. </author> <title> Limits on multiple instruction issue. </title> <booktitle> In Conference Proceedings of the Third International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 290-302. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Before we describe our methodology, we briefly discuss the previous work in this area. 3.1 Previous Work There has been a plethora of work which measured the average parallelism in a (sequential) instruction stream for a particular hardware configuration <ref> [BYP + 91, NF84, SJH89, TF70, Wal91] </ref>.
Reference: [Tar83] <author> Robert E. Tarjan. </author> <title> Data Structures and Network Algorithms, </title> <institution> chapter 1.5. Society for Industrial and Applied Mathematics, </institution> <year> 1983. </year>
Reference-contexts: These routines are processor model dependent. We detail the ones implemented by Tetra in Section 3.4. Since there are no control or resource constraints, the routines simply return the passed levels. The resulting execution graph is the topologically sorted <ref> [Tar83] </ref> DDG. The schedule is optimal with respect to length, and it represents an upper bound on the performance that can be attained for the analyzed program. This schedule is also commonly called the eager evaluation schedule, because an operation is scheduled as soon as it its inputs are ready.
Reference: [TF70] <author> G. S. Tjaden and M. J. Flynn. </author> <title> Detection and parallel execution of parallel instructions. </title> <journal> IEEE Transactions on Computers, </journal> 19(10) 889-895, October 1970. 
Reference-contexts: Before we describe our methodology, we briefly discuss the previous work in this area. 3.1 Previous Work There has been a plethora of work which measured the average parallelism in a (sequential) instruction stream for a particular hardware configuration <ref> [BYP + 91, NF84, SJH89, TF70, Wal91] </ref>.
Reference: [TGH92] <author> K. B. Theobald, G. R. Gao, and L. J. Hendren. </author> <title> On the limits of program parallelism and its smoothability. </title> <booktitle> In Conference Record of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 10-19, </pages> <address> Portland, OR, </address> <month> December </month> <year> 1992. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Hence, the critical factor in the development of aggressive fine-grain parallel processors will likely not be control dependence resolution, but rather other factors, like data dependence resolution. We extend their work by providing a framework in which both control and resource constraints can be combined. Theobald, et al. <ref> [TGH92] </ref> examined the smoothability of serial program parallelism. By constraining the available computational resources (via a HISTORY schedule), they were able explore a program's sensitivity to limited functional unit supplies.
Reference: [Wal91] <author> D. W. Wall. </author> <title> Limits of instructional-level parallelism. </title> <booktitle> In Conference Proceedings of the Fourth International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188. </pages> <institution> Association for Computing Machinery, </institution> <month> April </month> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Before we describe our methodology, we briefly discuss the previous work in this area. 3.1 Previous Work There has been a plethora of work which measured the average parallelism in a (sequential) instruction stream for a particular hardware configuration <ref> [BYP + 91, NF84, SJH89, TF70, Wal91] </ref>.
References-found: 33

