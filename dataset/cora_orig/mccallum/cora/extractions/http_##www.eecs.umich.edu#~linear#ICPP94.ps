URL: http://www.eecs.umich.edu/~linear/ICPP94.ps
Refering-URL: http://www.eecs.umich.edu/~linear/resume.html
Root-URL: http://www.eecs.umich.edu
Title: A Hierarchical Approach to Modeling and Improving the Performance of Scientific Applications on the KSR1  
Author: Eric L. Boyd, Waqar Azeem, HsienHsin Lee, TienPao Shih, ShihHao Hung, and Edward S. Davidson 
Keyword: communications based on a memory reference trace).  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science University of Michigan  
Note: The University of Michigan Center for Parallel Computing, site of the KSR1, is partially funded by NSF grant CDA-92-14296. Appeared in Proceedings of the 1994 International Conference on Parallel Processing St. Charles, Illinois, Vol. III, pp. 188-192.  
Abstract: We have developed a hierarchical performance bounding methodology that attempts to explain the performance of loop-dominated scientific applications on particular systems. The Kendall Square Research KSR1 is used as a running example. We model the throughput of key hardware units that are common bottlenecks in concurrent machines. The four units currently used are: memory port, floating-point, instruction issue, and a loopcarried dependence pseudounit. We propose a workload characterization, and derive upper bounds on the performance of specific machine-workload pairs. Comparing delivered performance with bounds focuses attention on areas for improvement and indicates how much improvement might be attainable. We delineate a comprehensive approach to modeling and improving application performance on the KSR1. Application of this approach is being automated for the KSR1 with a series of tools including KMA and K-MACSTAT (which enable the calculation of the MACS hierarchy of performance bounds), KTrace (which allows parallel code to be instrumented to produce a memory reference trace), and KCache (which simulates inter-cache 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. H. McMahon, </author> <title> The Livermore Fortran Kernels: A Computer Test of the Numerical Performance Range, </title> <type> Technical Report UCRL-5375, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> December, </month> <year> 1986. </year>
Reference-contexts: We present a technique for determining and approaching performance bounds for scientific loop-dominated codes, using the Livermore Fortran Kernels <ref> [1] </ref> as a running example to illustrate the method on the Kendall Square Research KSR1, a shared virtual memory Massively Parallel Processor (MPP) with a CacheOnly Memory Architecture (COMA) [2] [3].
Reference: [2] <institution> KSR1 Principles of Operation, Kendall Square Research Corporation, </institution> <address> Waltham, MA, </address> <year> 1991. </year>
Reference-contexts: We present a technique for determining and approaching performance bounds for scientific loop-dominated codes, using the Livermore Fortran Kernels [1] as a running example to illustrate the method on the Kendall Square Research KSR1, a shared virtual memory Massively Parallel Processor (MPP) with a CacheOnly Memory Architecture (COMA) <ref> [2] </ref> [3]. These bounds focus on the latency and bandwidth of specific machine components, particularly memory, instruction issue, and floating-point units, since these units are common bottlenecks. The KSR1 is built as a group of ALLCACHE engines, connected in a fat tree hierarchy of rings.
Reference: [3] <institution> KSR1 Technical Summary, Kendall Square Research Corporation, </institution> <address> Waltham, MA, </address> <year> 1992. </year>
Reference-contexts: We present a technique for determining and approaching performance bounds for scientific loop-dominated codes, using the Livermore Fortran Kernels [1] as a running example to illustrate the method on the Kendall Square Research KSR1, a shared virtual memory Massively Parallel Processor (MPP) with a CacheOnly Memory Architecture (COMA) [2] <ref> [3] </ref>. These bounds focus on the latency and bandwidth of specific machine components, particularly memory, instruction issue, and floating-point units, since these units are common bottlenecks. The KSR1 is built as a group of ALLCACHE engines, connected in a fat tree hierarchy of rings.
Reference: [4] <author> E. L. Boyd, E. S. Davidson, </author> <title> Communication in the KSR1 MPP: Performance Evaluation Using Synthetic Workload Experiments, </title> <booktitle> Proceedings of the 1994 International Conference on Supercomputing , July, </booktitle> <year> 1994. </year>
Reference-contexts: The local cache is 32MB, 128 sets, 16-way, LRU, 16KB page (allocation unit), 128B subpage (ring transaction unit). On subcache miss, average local cache access time was found to be 23.4 cycles (allocated block) or 49.2 (unallocated) or 150 to 180 (local cache miss, single ring transaction). <ref> [4] </ref> [5] Two tools under development, K-MACSTAT , will automatically generate the MACS performance bounds hierarchy for the KSR1 on loopdominated applications.
Reference: [5] <author> D. Windheiser, E. L. Boyd, E. Hao, S. G. Abraham, E. S. Davidson, </author> <title> KSR1 Multiprocessor: Analysis of Latency Hiding Techniques in a Sparse Solver, </title> <booktitle> Proceedings of the 7th International Parallel Processing Symposium, </booktitle> <month> April, </month> <year> 1993, </year> <pages> pp. 454-461. </pages>
Reference-contexts: The local cache is 32MB, 128 sets, 16-way, LRU, 16KB page (allocation unit), 128B subpage (ring transaction unit). On subcache miss, average local cache access time was found to be 23.4 cycles (allocated block) or 49.2 (unallocated) or 150 to 180 (local cache miss, single ring transaction). [4] <ref> [5] </ref> Two tools under development, K-MACSTAT , will automatically generate the MACS performance bounds hierarchy for the KSR1 on loopdominated applications.
Reference: [6] <author> D. Windheiser, </author> <title> Data Locality and Fine Grain Parallelism Optimization , Ph.D. </title> <type> thesis, </type> <institution> Irisa INRIARENNES, </institution> <year> 1992. </year> <note> (Available only in French). </note>
Reference-contexts: Software pipe lining of loop code is made possible through the use of a retargeta ble tool, the Object Code Optimizer ) <ref> [6] </ref>, targeted for the KSR1. 2.
Reference: [7] <author> W. H. MangioneSmith, S. G. Abraham, E. S. </author> <title> Davidson, </title>
Reference-contexts: MACS Performance Bounds Hierarchy The MACS machine-application performance bound methodology provides a series of upper bounds on the best achievable performance and has been used for a variety of loop-dominated applications on vector, superscalar and other architectures <ref> [7] </ref> [8] and extended to the bounds hierarchy used here in [9].
References-found: 7

