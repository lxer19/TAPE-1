URL: http://polaris.cs.uiuc.edu/reports/821.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: THE SIMULATION AND TUNING OF THE GLOBAL MEMORY SUBSYSTEM OF A MULTIPROCESSOR  
Author: BY THOMAS MARTIN CONTE 
Degree: 1986 THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering in the Graduate College of the  
Address: 1988 Urbana, Illinois  
Affiliation: B.E.E., University of Delaware,  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. C. Batcher, </author> <title> "Sorting networks and their applications," </title> <booktitle> in Proc. AFIPS 1968 Spring Joint Comput. Conf., </booktitle> <pages> pp. 307-314, </pages> <year> 1968. </year>
Reference-contexts: INTRODUCTION Multistage interconnection networks (MIN's) have been proposed as a means for hardware sorting <ref> [1] </ref>, data alignment in array (SIMD) machines [2], and for use in shared memory multiprocessor (MIMD) systems [3]. Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM [4], and Cedar by the University of Illinois [5] [6]. <p> It is useful to think of the switch in terms of slices, where each slice is the two input buffers and the output port being requested (by an ACW at the head of the input FIFO). Packet-word notation is used to represent the contents of the buffers. 14 <ref> [1; 0; 0] </ref> - d (1) d When a buffer is empty, "-" is used. The crossbar is represented by "[i]," where i is the output port number requested. <p> The switch-slice notation along with the simulation clock are shown in Figure 2.7. Notice that it takes each packet word one clock tic to pass through a stage. To-network: tic 0 <ref> [0; 2; 1] </ref> - r 0 3 = = [] - () - = = [] - () - To-network: tic 1 [] - () - = = [1; 1; 0] - r 0 3 = = [] - () - To-network: tic 3 [] - () - = = [] <p> Notice that it takes each packet word one clock tic to pass through a stage. To-network: tic 0 [0; 2; 1] - r 0 3 = = [] - () - = = [] - () - To-network: tic 1 [] - () - = = <ref> [1; 1; 0] </ref> - r 0 3 = = [] - () - To-network: tic 3 [] - () - = = [] - () - = = [2; 0; 1] - r 0 3 2.3.2 A contention example An example using a subsystem of dimensions N = 16; K = <p> 3 = = [] - () - = = [] - () - To-network: tic 1 [] - () - = = [1; 1; 0] - r 0 3 = = [] - () - To-network: tic 3 [] - () - = = [] - () - = = <ref> [2; 0; 1] </ref> - r 0 3 2.3.2 A contention example An example using a subsystem of dimensions N = 16; K = 4; M = 2; and B = 4 is now shown. <p> The traffic in the to-network is shown in Figure 2.8. Notice that the requests collide in the first stage of the network. Request r 0 0 is allowed to transmit across the 19 To network: 0 tics <ref> [1; 0; 0] </ref> - r 0 0 = = [] - () - = = 4 (0) r 0 [1; 0; 2] - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = <p> Notice that the requests collide in the first stage of the network. Request r 0 0 is allowed to transmit across the 19 To network: 0 tics [1; 0; 0] - r 0 0 = = [] - () - = = 4 (0) r 0 <ref> [1; 0; 2] </ref> - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; <p> transmit across the 19 To network: 0 tics [1; 0; 0] - r 0 0 = = [] - () - = = 4 (0) r 0 [1; 0; 2] - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics <ref> [1; 0; 1] </ref> - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] <p> 0 [1; 0; 2] - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 <ref> [1; 0; 3] </ref> - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 <p> 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics <ref> [1; 0; 2] </ref> - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 <p> 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics <ref> [1; 0; 3] </ref> - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 tics [] - () - = = [2; 0; 0] - r 0 12 = = crossbar first via the contention resolution policy explained in Section 2.2.3. <p> There is no contention in the from-network, since MU 0 issues requests sequentially and since each packet is destined for a different CE. 20 From network: 8 tics <ref> [1; 0; 0] </ref> - R 0 0 = = [] - () - = = From network: 9 tics [1; 0; 0] - d (0) d = = [2; 0; 0] - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - <p> There is no contention in the from-network, since MU 0 issues requests sequentially and since each packet is destined for a different CE. 20 From network: 8 tics <ref> [1; 0; 0] </ref> - R 0 0 = = [] - () - = = From network: 9 tics [1; 0; 0] - d (0) d = = [2; 0; 0] - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] <p> - () - = = From network: 9 tics <ref> [1; 0; 0] </ref> - d (0) d = = [2; 0; 0] - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = [2; 1; 0] - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - <p> 0; 0] - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics <ref> [1; 0; 0] </ref> - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = [2; 1; 0] - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] <p> network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = <ref> [2; 1; 0] </ref> - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics <p> network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = <ref> [2; 1; 0] </ref> - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = [2; 2; 0] - R 8 0 = = From <p> - () - = = From network: 13 tics <ref> [1; 0; 0] </ref> - d (1) d = = [2; 1; 0] - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = [2; 2; 0] - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] <p> 1; 0] - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics <ref> [1; 0; 0] </ref> - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = [2; 2; 0] - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] <p> - () - = = From network: 17 tics <ref> [1; 0; 0] </ref> - d (2) d = = [2; 2; 0] - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = [2; 3; 0] - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - <p> 2; 0] - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics <ref> [1; 0; 0] </ref> - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = [2; 3; 0] - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - d (0) d = = 21 CHAPTER 3 THE SIMULATOR How the simulator was constructed to match the performance
Reference: [2] <author> D. H. Lawrie, </author> <title> "Access and alignment of data in an array processor," </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. c-24, </volume> <pages> pp. 1145-1155, </pages> <month> Dec. </month> <year> 1975. </year>
Reference-contexts: INTRODUCTION Multistage interconnection networks (MIN's) have been proposed as a means for hardware sorting [1], data alignment in array (SIMD) machines <ref> [2] </ref>, and for use in shared memory multiprocessor (MIMD) systems [3]. Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM [4], and Cedar by the University of Illinois [5] [6]. <p> Finally, at the close of this section operation of the memory units will be described. 8 2.2.1 The architecture of the networks Each network is a generalized Omega network <ref> [2] </ref>. It has a total of N = K M inputs, and the SEs are arrayed into M columns of B = N=K SEs. The stages, S i , are numbered 0; . . . ; M . <p> . . ; N 1 from the top to the bottom of a column, then, IN S i = Shu*e KflB (OUT S i1 ) = (OUT S i1 fl B + b OU T S i1 c) mod N; for all i, 0 &lt; i &lt; M 1 (see <ref> [2] </ref>). <p> The switch-slice notation along with the simulation clock are shown in Figure 2.7. Notice that it takes each packet word one clock tic to pass through a stage. To-network: tic 0 <ref> [0; 2; 1] </ref> - r 0 3 = = [] - () - = = [] - () - To-network: tic 1 [] - () - = = [1; 1; 0] - r 0 3 = = [] - () - To-network: tic 3 [] - () - = = [] <p> 3 = = [] - () - = = [] - () - To-network: tic 1 [] - () - = = [1; 1; 0] - r 0 3 = = [] - () - To-network: tic 3 [] - () - = = [] - () - = = <ref> [2; 0; 1] </ref> - r 0 3 2.3.2 A contention example An example using a subsystem of dimensions N = 16; K = 4; M = 2; and B = 4 is now shown. <p> Notice that the requests collide in the first stage of the network. Request r 0 0 is allowed to transmit across the 19 To network: 0 tics [1; 0; 0] - r 0 0 = = [] - () - = = 4 (0) r 0 <ref> [1; 0; 2] </ref> - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; <p> 0; 0] - r 0 0 = = [] - () - = = 4 (0) r 0 [1; 0; 2] - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = <ref> [2; 0; 0] </ref> - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] <p> = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = <ref> [2; 0; 0] </ref> - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = <p> 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics <ref> [1; 0; 2] </ref> - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 <p> = = <ref> [2; 0; 0] </ref> - r 0 0 = = 8 (0) r 0 0 (0) r 0 [1; 0; 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 tics [] - () - = = [2; 0; <p> 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = <ref> [2; 0; 0] </ref> - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 tics [] - () - = = [2; 0; 0] - r 0 12 = = crossbar first via the contention resolution policy explained in Section 2.2.3. <p> = <ref> [2; 0; 0] </ref> - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics [1; 0; 3] - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 tics [] - () - = = [2; 0; 0] - r 0 12 = = crossbar first via the contention resolution policy explained in Section 2.2.3. During the next clock, r 0 4 is allowed to pass, etc., until all packets waiting have cleared the first stage, at clock tic 4. <p> from-network, since MU 0 issues requests sequentially and since each packet is destined for a different CE. 20 From network: 8 tics [1; 0; 0] - R 0 0 = = [] - () - = = From network: 9 tics [1; 0; 0] - d (0) d = = <ref> [2; 0; 0] </ref> - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics <p> network: 8 tics [1; 0; 0] - R 0 0 = = [] - () - = = From network: 9 tics [1; 0; 0] - d (0) d = = <ref> [2; 0; 0] </ref> - R 0 0 = = From network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = [2; 1; 0] - R 4 0 = = From <p> network: 10 tics [] - () - = = [2; 0; 0] - d (0) d = = From network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = <ref> [2; 1; 0] </ref> - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics <p> network: 12 tics [1; 0; 0] - R 4 0 = = [] - () - = = From network: 13 tics [1; 0; 0] - d (1) d = = <ref> [2; 1; 0] </ref> - R 4 0 = = From network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = [2; 2; 0] - R 8 0 = = From <p> network: 14 tics [] - () - = = [2; 1; 0] - d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = <ref> [2; 2; 0] </ref> - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics <p> d (0) d = = From network: 16 tics [1; 0; 0] - R 8 0 = = [] - () - = = From network: 17 tics [1; 0; 0] - d (2) d = = <ref> [2; 2; 0] </ref> - R 8 0 = = From network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = [2; 3; 0] - <p> network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = <ref> [2; 3; 0] </ref> - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - d (0) d = = 21 CHAPTER 3 THE SIMULATOR How the simulator was constructed to match the performance of the global memory subsystem can now be described. <p> network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = <ref> [2; 3; 0] </ref> - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - d (0) d = = 21 CHAPTER 3 THE SIMULATOR How the simulator was constructed to match the performance of the global memory subsystem can now be described. <p> Attention now turns to the performance of the subsystem under more realistic scenarios. 5.1 Best-Case Scenarios It is useful to have a best-case simultaneous prefetch scenario to evaluate the performance of the subsystem. In <ref> [2] </ref>, Lawrie describes several permutations that an Omega network can pass without contention. The following theorem adapted from [2] will be used, Theorem: [Lawrie] An Omega network passes without contention an access by CE i to MU (i+k)modN ; for all 0 i &lt; N and all integer k. <p> In <ref> [2] </ref>, Lawrie describes several permutations that an Omega network can pass without contention. The following theorem adapted from [2] will be used, Theorem: [Lawrie] An Omega network passes without contention an access by CE i to MU (i+k)modN ; for all 0 i &lt; N and all integer k. For a proof, see [2]. 66 When the vector for each CE i starts in MU i , this will <p> The following theorem adapted from <ref> [2] </ref> will be used, Theorem: [Lawrie] An Omega network passes without contention an access by CE i to MU (i+k)modN ; for all 0 i &lt; N and all integer k. For a proof, see [2]. 66 When the vector for each CE i starts in MU i , this will referred to this as the identity vector scenario, or ID, since it causes a series of identity permutations [2]. Figure 5.1 shows the permutations for the 8 fi 8 subsystem, where L = 10. <p> For a proof, see <ref> [2] </ref>. 66 When the vector for each CE i starts in MU i , this will referred to this as the identity vector scenario, or ID, since it causes a series of identity permutations [2]. Figure 5.1 shows the permutations for the 8 fi 8 subsystem, where L = 10. Note that all the permutations have zero f c , indicating this scenario should not cause any contention in the to-network. <p> In MIMD machines, however, they cannot be. It is proposed that hardware be added to selectively synchronize the initiation of prefetch operations so that the characteristics of Omega networks can be used to improve the performance of prefetch operations, as in <ref> [2] </ref>. 76 CHAPTER 6 CONCLUSIONS 6.1 Summary and Conclusions This thesis reviewed the design of a global memory subsystem, described the algorithm used to simulate it, and then simulated its performance in several scenarios of a simultaneous vector prefetch.
Reference: [3] <author> J. H. Patel, </author> <title> "Processor-memory interconnections for multiprocessors," </title> <booktitle> in Proc. 6th Ann. Symp. on Comput. Arch., </booktitle> <address> New York, N. </address> <publisher> Y., </publisher> <pages> pp. 168-177, </pages> <month> Apr. </month> <year> 1979. </year>
Reference-contexts: INTRODUCTION Multistage interconnection networks (MIN's) have been proposed as a means for hardware sorting [1], data alignment in array (SIMD) machines [2], and for use in shared memory multiprocessor (MIMD) systems <ref> [3] </ref>. Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM [4], and Cedar by the University of Illinois [5] [6]. <p> The performance of multistage interconnection networks has been studied extensively in the literature. Patel introduced the Delta network and commented on its expected bandwidth and cost-effectiveness in <ref> [3] </ref>. Kruskal and Snir used analytical queuing theory techniques to derive the performance of buffered and unbuffered banyan multistage interconnection networks under random traffic. <p> Additionally, there is a K fl B shu*e included before stage S 1 to allow a network to realize an identity permutation (CE i accessing MU i , 0 i &lt; N ) <ref> [3] </ref>. (For a general network, see Figure 2.2.) Routing through a network is distributed and performed by successively resolving the destination address at each stage. Let SOURCE and DEST be the source and destination addresses (respectively), expressed in base-K, for a request sent through a network. <p> 0 [1; 0; 2] - r 0 0 = = [] - () - = = 12 (0) r 0 To network: 1 tics [1; 0; 1] - r 0 4 = = [2; 0; 0] - r 0 0 = = 8 (0) r 0 0 (0) r 0 <ref> [1; 0; 3] </ref> - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 <p> 3] - r 0 4 = = [2; 0; 0] - r 0 0 = = To network: 2 tics [1; 0; 2] - r 0 8 = = [2; 0; 0] - r 0 4 = = 12 (0) r 0 4 (0) r 0 To network: 3 tics <ref> [1; 0; 3] </ref> - r 0 12 = = [2; 0; 0] - r 0 8 = = To network: 4 tics [] - () - = = [2; 0; 0] - r 0 12 = = crossbar first via the contention resolution policy explained in Section 2.2.3. <p> network: 18 tics [2; 2; 0] - d (0) d = = [] - () - = = From network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = <ref> [2; 3; 0] </ref> - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - d (0) d = = 21 CHAPTER 3 THE SIMULATOR How the simulator was constructed to match the performance of the global memory subsystem can now be described. <p> network: 20 tics [1; 0; 0] - R 12 0 = = [] - () - = = From network: 21 tics [1; 0; 0] - d (3) d = = <ref> [2; 3; 0] </ref> - R 12 0 = = From network: 22 tics [] - () - = = [2; 3; 0] - d (0) d = = 21 CHAPTER 3 THE SIMULATOR How the simulator was constructed to match the performance of the global memory subsystem can now be described.
Reference: [4] <author> G. F. Pfister, W. C. Brantley, D. A. George, S. Harvey, W. Kleinfelder, K. McAuliffe, E. Melton, V. Norton, and J. Weiss, </author> <title> "The IBM Research Parallel Processor Prototype (RP3): introduction and architecture," </title> <booktitle> in Proc. Int'l Conf. on Parallel Processing, </booktitle> <address> St. Charles, Il., </address> <pages> pp. 764-771, </pages> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM <ref> [4] </ref>, and Cedar by the University of Illinois [5] [6]. In these MIMD systems, multistage interconnection networks replace the conceptually desirable, yet infeasible, crossbar switch as a means to connect memory modules to processors. The performance of multistage interconnection networks has been studied extensively in the literature.
Reference: [5] <author> D. J. Kuck, E. S. Davidson, D. H. Lawrie, and A. H. Sameh, </author> <title> "Parallel supercomputing today and the Cedar approach," </title> <journal> Science, </journal> <volume> vol. 231, </volume> <pages> pp. 967-974, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM [4], and Cedar by the University of Illinois <ref> [5] </ref> [6]. In these MIMD systems, multistage interconnection networks replace the conceptually desirable, yet infeasible, crossbar switch as a means to connect memory modules to processors. The performance of multistage interconnection networks has been studied extensively in the literature.
Reference: [6] <author> P. Yew, </author> <title> "The architecture of the Cedar parallel supercomputer," </title> <type> Tech. Rep. 609, </type> <institution> University of Illinois Center for Supercomputing Research and Development, Urbana-Champaign, Illinois, </institution> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: Projects to build large-scale shared memory multiprocessors are under way in industry and academia, among them the RP3 by IBM [4], and Cedar by the University of Illinois [5] <ref> [6] </ref>. In these MIMD systems, multistage interconnection networks replace the conceptually desirable, yet infeasible, crossbar switch as a means to connect memory modules to processors. The performance of multistage interconnection networks has been studied extensively in the literature. <p> The CEs in a cluster can communicate between themselves via a crossbar switch and a synchronization bus. All CEs in all clusters have peer-access to a global memory <ref> [6] </ref>. The global memory subsystem is composed of two unidirectional, N fi N Omega networks and N memory units (MUs) [6]. <p> The CEs in a cluster can communicate between themselves via a crossbar switch and a synchronization bus. All CEs in all clusters have peer-access to a global memory <ref> [6] </ref>. The global memory subsystem is composed of two unidirectional, N fi N Omega networks and N memory units (MUs) [6]. The network that takes requests to the memory units is called the to-network , and the network that returns requests from the memory units is called the from-network (See Figure 2.1).
Reference: [7] <author> C. P. Kruskal and M. Snir, </author> <title> "The performance of multistage interconnection networks for multiprocessors," </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. c-32, </volume> <pages> pp. 1091-1098, </pages> <month> Dec. </month> <year> 1983. </year>
Reference-contexts: For the buffered banyan network, they derived an equation for the performance of the first stage of the network and 2 estimate the performance of the network from this first-stage approximation <ref> [7] </ref>. Work done by Dias and Jump [8] used Petri net techniques to analyze the performance of a buffered Delta network. They found that the length of buffers inside the network had a large impact on performance, with an optimal value of one or two buffers per stage.
Reference: [8] <author> D. M. Dias and J. R. </author> <title> Jump, "Analysis and simulation of buffered Delta networks," </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. c-30, </volume> <pages> pp. 273-282, </pages> <month> Apr. </month> <year> 1981. </year>
Reference-contexts: For the buffered banyan network, they derived an equation for the performance of the first stage of the network and 2 estimate the performance of the network from this first-stage approximation [7]. Work done by Dias and Jump <ref> [8] </ref> used Petri net techniques to analyze the performance of a buffered Delta network. They found that the length of buffers inside the network had a large impact on performance, with an optimal value of one or two buffers per stage.
References-found: 8

