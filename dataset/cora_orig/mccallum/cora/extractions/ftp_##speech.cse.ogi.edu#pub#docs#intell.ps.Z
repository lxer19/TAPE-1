URL: ftp://speech.cse.ogi.edu/pub/docs/intell.ps.Z
Refering-URL: http://www.cse.ogi.edu/~wardk/
Root-URL: http://www.cse.ogi.edu
Title: ABSTRACT  
Abstract: We measured the effects of task context on the intelligibility of utterances drawn from a corpus of air traffic control dialogue. Subjects understood more words when the utterances were presented in the form of a dialogue, with the original utterance order preserved. Subjects presented with the same utterances in randomized order understood significantly fewer words. This effect was seen with both domain experts (pilots and air traffic controllers) and domain novices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Cole, D. Novick, M. Fanty, S. Sutton, B. Hansen, & D. Burnett. </author> <title> Rapid Prototyping of Spoken Language Systems: The Year 2000 Census Project, </title> <booktitle> Proceedings of the International Symposium on Spoken Dialogue (ISSD-93), </booktitle> <address> Tokyo, </address> <month> November, </month> <year> 1993, </year> <pages> pp. 19-23. </pages>
Reference: [2] <author> C. Connine. </author> <title> Effects of Sentence Context and Lexical Knowledge in Speech Processing, Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives, </title> <editor> Gerry T. M. Altman (ed.), </editor> <publisher> MIT Press, </publisher> <address> Cam-bridge, Mass., </address> <year> 1990, </year> <pages> pp. 281-294. </pages>
Reference-contexts: That sentence context can affect word recognition is well-documented [7]. Such studies have typically focused on examining the effects of semantic priming or phonetic context on the interpretation of an acoustically obscured or ambiguous word within an otherwise-clear presentation (e.g., <ref> [2] </ref>). Furthermore, Schober and Clark [6] have demonstrated the importance of dialogue-level effects in relating complex descriptions to abstract pictures. In this study, however, we were interested in examining the effect of dialogue-level context on the hearers ability to understand the words in a sentence as a whole.
Reference: [3] <author> Fanty, M., Sutton, S., Novick, D., & Cole, R. </author> <title> Automated Appointment Scheduling, </title> <booktitle> ESCA Workshop on Spoken Dialogue Systems, </booktitle> <address> Vigs, Denmark, </address> <month> May, </month> <year> 1995, </year> <pages> pp. 141-144. </pages>
Reference-contexts: The Minds-II system [9] dynamically generates a recognizer grammar based on context, inferred plans, and goals. The automated scheduling system described in <ref> [3] </ref> maintains contexts for interpreting users utterances and specializes these contexts in a stack-based fashion. These contexts are then used to predict the utterance grammars for both recognizer and parser. The fundamental potential of this technique is unknown, however, particularly for mixed-initiative dialogue.
Reference: [4] <institution> Federal Aviation Administration. Air Traffic Control, 7110.65F, </institution> <year> 1989. </year>
Reference-contexts: Novick, Karen Ward & Benjamin Corliss email: novick@cse.ogi.edu, wardk@cse.ogi.edu Center for Spoken Language Understanding Oregon Graduate Institute of Science & Technology P.O. Box 91000 Portland, Oregon 97291-1000 USA structure <ref> [4, 5] </ref>. The purpose of these constraints is to improve the intelligibility of safety-critical communications but the overall effect can be to make the utterances even less understandable to a domain novice. Also, ATC dialogue is typically delivered at a very fast speaking rate, further decreasing its intelligibility. <p> Controller and pilot are cooperatively performing the task of guiding the aircraft through the controllers airspace to a point from which the pilot can complete the approach and landing without further guidance from the controller. This task is referred to as an Instrument Landing System (ILS) approach procedure <ref> [4, 5] </ref>. 3. EXPERIMENT We hypothesized that utterances in their task context would be more intelligible than the same utterances presented in a decontextualized sequence. As a validation measure, we predicted that the experts should have higher overall intelligibility scores than the novices.
Reference: [5] <institution> Federal Aviation Administration. </institution> <note> Airmans Information Manual, </note> <year> 1991. </year>
Reference-contexts: Novick, Karen Ward & Benjamin Corliss email: novick@cse.ogi.edu, wardk@cse.ogi.edu Center for Spoken Language Understanding Oregon Graduate Institute of Science & Technology P.O. Box 91000 Portland, Oregon 97291-1000 USA structure <ref> [4, 5] </ref>. The purpose of these constraints is to improve the intelligibility of safety-critical communications but the overall effect can be to make the utterances even less understandable to a domain novice. Also, ATC dialogue is typically delivered at a very fast speaking rate, further decreasing its intelligibility. <p> Controller and pilot are cooperatively performing the task of guiding the aircraft through the controllers airspace to a point from which the pilot can complete the approach and landing without further guidance from the controller. This task is referred to as an Instrument Landing System (ILS) approach procedure <ref> [4, 5] </ref>. 3. EXPERIMENT We hypothesized that utterances in their task context would be more intelligible than the same utterances presented in a decontextualized sequence. As a validation measure, we predicted that the experts should have higher overall intelligibility scores than the novices.
Reference: [6] <author> Schober, M. F. & Clark, H. H. </author> <title> Understanding by Addressees and Overhearers, </title> <booktitle> Cognitive Psychology (21), </booktitle> <year> 1989, </year> <pages> pp. 211-232. </pages>
Reference-contexts: That sentence context can affect word recognition is well-documented [7]. Such studies have typically focused on examining the effects of semantic priming or phonetic context on the interpretation of an acoustically obscured or ambiguous word within an otherwise-clear presentation (e.g., [2]). Furthermore, Schober and Clark <ref> [6] </ref> have demonstrated the importance of dialogue-level effects in relating complex descriptions to abstract pictures. In this study, however, we were interested in examining the effect of dialogue-level context on the hearers ability to understand the words in a sentence as a whole.
Reference: [7] <author> L. Tyler. </author> <title> Context and Sensory Input, Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives, </title> <editor> Gerry T. M. Altman (ed.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, Mass. </address> <year> 1990, </year> <pages> pp. 315-323. </pages>
Reference-contexts: By measuring the numbers of words that subjects were able to understand, we hoped to gain some insight into the contribution that task context makes to intelligibility. That sentence context can affect word recognition is well-documented <ref> [7] </ref>. Such studies have typically focused on examining the effects of semantic priming or phonetic context on the interpretation of an acoustically obscured or ambiguous word within an otherwise-clear presentation (e.g., [2]).
Reference: [8] <author> K. Ward, D. G. Novick, & C. Sousa. </author> <title> Air Traffic Control Communications at Portland International Airport, </title> <type> Technical Report No. CS/E 90-025, </type> <institution> Oregon Graduate Institute, Beaverton, </institution> <address> OR, </address> <year> 1990. </year>
Reference-contexts: We therefore turned to a particularly difficult communications task, that of understanding air traffic control (ATC) dialogue. In this study, we presented both domain experts (pilots and air traffic controllers) and domain novices (non-pilots) with recorded utterances drawn from a corpus of ATC dialogue <ref> [8] </ref> and asked them to repeat the words they heard. This proved to be a task that was difficult enough to reveal task context effects. 2.1. Characteristics of ATC Dialogue Air Traffic Control communication takes place over noisy, low-bandwidth radio channels. <p> This excerpt includes two exchanges. The first exchange, utterances 112-113, illustrates a simple instruction-readback pair. In the second exchange, utterances 121-124, the pilot read back only part of the instructions and so a clarification subdialogue ensued. Utterance numbers are from the original transcript <ref> [8] </ref>. domly permuted order consistent across the subjects in this condition. The test corpus comprised a total of 33 utterances with approximately 3400 words. Utterance length ranged from 3 to 31 words, with the average length being 11.4 words.
Reference: [9] <author> S. Young & W. Ward. </author> <title> Semantic and Pragmatically Based Re-recognition of Spontaneous Speech, </title> <address> Euro-speech 93, </address> <year> 1993, </year> <pages> pp. 2243-2246. </pages>
Reference-contexts: To improve system performance, different grammars may be used to constrain speech recognition during different portions of the interaction, reecting the expectation that the user is likely to say different things at different points in the task. The Minds-II system <ref> [9] </ref> dynamically generates a recognizer grammar based on context, inferred plans, and goals. The automated scheduling system described in [3] maintains contexts for interpreting users utterances and specializes these contexts in a stack-based fashion. These contexts are then used to predict the utterance grammars for both recognizer and parser.
References-found: 9

