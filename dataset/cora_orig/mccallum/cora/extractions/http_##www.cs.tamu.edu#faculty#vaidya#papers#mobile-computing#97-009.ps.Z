URL: http://www.cs.tamu.edu/faculty/vaidya/papers/mobile-computing/97-009.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/mobile.html
Root-URL: http://www.cs.tamu.edu
Email: E-mail: fsaadb,vaidyag@cs.tamu.edu  
Title: Using End-to-End Statistics to Distinguish Congestion and Corruption Losses: Web: http://www.cs.tamu.edu/faculty/vaidya/mobile.html past, several proposals require
Note: In the  
Date: August 18, 1997  
Address: College Station, TX 77843-3112, USA  
Affiliation: Department of Computer Science Texas A&M University  
Pubnum: Technical Report 97-009  
Abstract: A Negative Result fl Abstract On wireless links, the rate of corruption losses can be significant, leading to poor TCP performance. The performance gets worse when these losses are mistaken for congestion losses, unduly triggering the TCP congestion control algorithms. To avoid this, techniques to distinguish between corruption and congestion losses without any explicit information from the network (routers or switches) are of interest. If the heuristics developed in the past are good (i.e., accurate much of the time), then one possible mechanism for distinguishing between errors and congestion are as follows: (a) Use a good heuristic that asks TCP sender to reduce window size when congestion is fl Research reported is supported in part by Texas Advanced Technology Program grant 009741-052-C, National Science Foundation grant CDA-9529442 and the Fulbright Program. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ab-Hamid, Waters, </author> <title> A.G., Kalman Prediction Method for Congestion Avoidance in ISDN Frame-Relay Networks, </title> <publisher> IEEE, </publisher> <year> 1991. </year> <pages> pp 565-571. </pages>
Reference: [2] <author> Ahn,J.S, P.B Danzig, Z.Liu and L. Yan, </author> <title> Experience with TCP Vegas : Emulation and experiment, </title> <booktitle> Proc. SIGCOMM'95 Symp. </booktitle> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: For Vegas, you have only to change the thresholds ff and fi. For Vegas, which is a TCP implementation, we were puzzled that the authors [6] claim a throughput enhancement of 40 to 70% and a different team <ref> [2] </ref> confirmed an enhancement of at least 20% in throughput over TCP-Reno. But Vegas contains other enhancements (retransmission schemes) than the congestion avoidance scheme. The authors do not seem to have evaluated the contribution of the new congestion avoidance scheme to the performance improvement.
Reference: [3] <author> B. Bakshi, P. Krishna, N. H.Vaidya, D. K. Pradhan, </author> <title> Improving Performance of TCP over Wireless Networks. </title> <booktitle> In Proceedings of 17th Int. Conf. Distributed Computing Systems, </booktitle> <address> Baltimore, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: All losses are all assumed, by TCP, to be congestion losses [9] and TCP reacts to all losses with congestion control mechanisms. On wired networks, this assumption is good. But on wireless links, losses occur more frequently due to corruption or for reasons other than congestion <ref> [3, 4] </ref>. This can lead to a very poor performance. Fast Recovery and Fast Retransmit [10, 14] alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses.
Reference: [4] <author> Balakrishnan,H., V. N. Padmanabhan, Seshan, S., Katz, R., </author> <title> A Comparison of Mechanisms for Improving TCP Performance over Wireless Links, </title> <booktitle> ACM SIGCOMM'96, </booktitle> <address> CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: All losses are all assumed, by TCP, to be congestion losses [9] and TCP reacts to all losses with congestion control mechanisms. On wired networks, this assumption is good. But on wireless links, losses occur more frequently due to corruption or for reasons other than congestion <ref> [3, 4] </ref>. This can lead to a very poor performance. Fast Recovery and Fast Retransmit [10, 14] alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses.
Reference: [5] <author> Bolot, </author> <title> J.C. Characterizing End-to-End Packet Delay and Loss in the Internet, </title> <journal> Journal of High-Speed Networks, </journal> <volume> vol. 2, no 3, </volume> <pages> pp. 289-298, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: In <ref> [5] </ref>, Bolot reported random losses on his probe packets.
Reference: [6] <author> L.S. Brakmo, S. O'Malley, </author> <title> TCP-Vegas : New Techniques for Congestion Detection and Avoidance, </title> <booktitle> SIGCOMM '94 Conference on Communications Architectures and Protocols, </booktitle> <address> London, U.K, </address> <pages> pp 24-35, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: The idea is to look at what a congestion avoidance scheme would have done just before the loss : if the appropriate action was "decrease the window size" then the loss should be with a high probability a congestion loss. Wang [16] and Brakmo (Vegas) <ref> [6] </ref> look at changes in the throughput to detect congestion. We study the criteria developed by these researchers. <p> If these criteria are predicting congestion, we could then identify the loss as a congestion loss, otherwise, we identify it as a corruption loss. Jain's [11], Wang and Crowcroft [16] and Vegas <ref> [6] </ref> criteria were devised for congestion avoidance : these schemes try to optimize the network usage while avoiding congestion. These schemes are based on the idea that there will be some response from the network to a congestion window size change. <p> If the difference in the throughput is less than T (W 1 ) 2 , then the congestion window is decreased. Using N T G, if N T G &lt; 1 2 then decrease the window size. In Vegas <ref> [6] </ref>, Brakmo et al. maintain a variable BaseRT T which is the minimum of RT T 's measured during the connection. <p> For Vegas, you have only to change the thresholds ff and fi. For Vegas, which is a TCP implementation, we were puzzled that the authors <ref> [6] </ref> claim a throughput enhancement of 40 to 70% and a different team [2] confirmed an enhancement of at least 20% in throughput over TCP-Reno. But Vegas contains other enhancements (retransmission schemes) than the congestion avoidance scheme.
Reference: [7] <author> Cinlar, E., </author> <title> Introduction to Stochastic Processes, </title> <publisher> Prentice-Hall, </publisher> <pages> pp 88-89 1975. </pages>
Reference: [8] <author> Floyd, S., </author> <title> TCP and Explicit Congestion Notification, </title> <journal> ACM Computer Communication Review, V. </journal> <volume> 24, No 5, </volume> <month> October </month> <year> 1994. </year>
Reference-contexts: Fast Recovery and Fast Retransmit [10, 14] alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses. This can be done by receiving explicit messages from the routers when congestion occurs or is imminent <ref> [12, 8] </ref>. This approach has two main drawbacks : first, there may be an additional message overhead, and second, the explicit scheme is protocol-dependent. The second approach would be to consider the network as a black box and try to collect implicit information on the state of the network.
Reference: [9] <author> V. Jacobson, </author> <title> Congestion Avoidance and Control, </title> <booktitle> ACM SIGCOMM'88, </booktitle> <pages> pp 314-329, </pages> <month> Aug. </month> <year> 1988. </year> <note> An update version is available via ftp://ftp.ee.lbl.gov/papers/congavoid.ps.Z. </note>
Reference-contexts: 1 Introduction The TCP protocol can adapt to very different network bandwidth and conditions. But there still exists the problem of recovering from losses other than congestion. All losses are all assumed, by TCP, to be congestion losses <ref> [9] </ref> and TCP reacts to all losses with congestion control mechanisms. On wired networks, this assumption is good. But on wireless links, losses occur more frequently due to corruption or for reasons other than congestion [3, 4]. This can lead to a very poor performance.
Reference: [10] <author> V. Jacobson. </author> <title> modified TCP congestion avoidance algorithm, mailing list, </title> <address> end2end-interest, </address> <month> April 30, </month> <year> 1990. </year>
Reference-contexts: On wired networks, this assumption is good. But on wireless links, losses occur more frequently due to corruption or for reasons other than congestion [3, 4]. This can lead to a very poor performance. Fast Recovery and Fast Retransmit <ref> [10, 14] </ref> alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses. This can be done by receiving explicit messages from the routers when congestion occurs or is imminent [12, 8].
Reference: [11] <author> Jain, R., </author> <title> A Delay-Based Approach for Congestion Avoidance in Interconnected Heterogeneous Computer Networks, Digital Equipment Corporation, </title> <type> Technical Report DEC-TR-566, </type> <month> April 11, </month> <year> 1989. </year>
Reference-contexts: In other words, a user may be able to provoke congestion losses, but not corruption losses. This second approach which considers the network as a black box was introduced by Jain in the excellent paper <ref> [11] </ref>. Jain observes the changes in the round trip delay resulting from changes in the congestion window size. Jain used this approach to develop a congestion avoidance scheme. But there is a natural extension of this approach to develop a tool to distinguish a corruption from a congestion loss. <p> If these criteria are predicting congestion, we could then identify the loss as a congestion loss, otherwise, we identify it as a corruption loss. Jain's <ref> [11] </ref>, Wang and Crowcroft [16] and Vegas [6] criteria were devised for congestion avoidance : these schemes try to optimize the network usage while avoiding congestion. These schemes are based on the idea that there will be some response from the network to a congestion window size change. <p> Wang and Crowcroft base their approach on the changes in throughput as response to congestion window variations. 4 The idea of monitoring round trip time changes due to window variations was suggested by Jain <ref> [11] </ref>. The idea stems from the relation between the load on the network and the observed throughput. If the load is low, throughput will be low. Suppose that you put only one packet at a time on the network. <p> With the information collected, Jain's criterion (J ), the Wang and Crowcroft's Normalized Throughput Gradient (N T G) and the Vegas criteria are computed easily. Jain's criterion is as follows <ref> [11] </ref>: J = (W i W i1 ) fl (RT T n RT T n1 ) where W i and W i1 are respectively the current and the previous congestion window sizes. RT T i and RT T i1 are respectively the current and the previous round trip times.
Reference: [12] <author> Ramakrishnan, K.K., Jain,R., </author> <title> A Binary Feedback scheme for Congestion Avoidance in Computer Networks with a Connectionless Network Layer, </title> <booktitle> In Proceedings of the ACM SIGCOMM '88, </booktitle> <pages> pp 303-313, </pages> <month> August </month> <year> 1988. </year> <month> 21 </month>
Reference-contexts: Fast Recovery and Fast Retransmit [10, 14] alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses. This can be done by receiving explicit messages from the routers when congestion occurs or is imminent <ref> [12, 8] </ref>. This approach has two main drawbacks : first, there may be an additional message overhead, and second, the explicit scheme is protocol-dependent. The second approach would be to consider the network as a black box and try to collect implicit information on the state of the network.
Reference: [13] <author> J. Postel, </author> <title> Transmission Control Protocol, </title> <type> RFC 793, </type> <pages> 85 pages, </pages> <month> Sept </month> <year> 1981. </year>
Reference: [14] <author> W.R. Stevens, </author> <title> TCP/IP Illustrated, Volume 1, The Protocols, </title> <publisher> Addison Wesley, </publisher> <year> 1994. </year>
Reference-contexts: On wired networks, this assumption is good. But on wireless links, losses occur more frequently due to corruption or for reasons other than congestion [3, 4]. This can lead to a very poor performance. Fast Recovery and Fast Retransmit <ref> [10, 14] </ref> alleviate the problem but do not solve it completely. It is then natural to try to distinguish congestion from corruption losses. This can be done by receiving explicit messages from the routers when congestion occurs or is imminent [12, 8]. <p> We interpret these results in Section 6. 2 Measurements The measurements were done using Free BSD. We modified tcp debug to collect the information. This data was processed with a modified version of trpt <ref> [14] </ref>. 2.1 Modifications to tcp debug and trpt The main function in tcp debug is the function tcp trace. This function can be called from many other tcp procedures (e.g tcp input, tcp output, tcp usrreq,..).
Reference: [15] <author> A. Tanenbaum, </author> <title> Computer Networks. </title> <note> Second edition. </note>
Reference: [16] <author> Z. Wang and J. Crowcroft, </author> <title> A New Congestion Control Scheme : Slow Start and Search (Tri-S), </title> <journal> ACM Computer Communication Review, </journal> <volume> vol 21, </volume> <pages> pp 32-43, </pages> <month> January </month> <year> 1991. </year> <month> 22 </month>
Reference-contexts: The idea is to look at what a congestion avoidance scheme would have done just before the loss : if the appropriate action was "decrease the window size" then the loss should be with a high probability a congestion loss. Wang <ref> [16] </ref> and Brakmo (Vegas) [6] look at changes in the throughput to detect congestion. We study the criteria developed by these researchers. <p> If these criteria are predicting congestion, we could then identify the loss as a congestion loss, otherwise, we identify it as a corruption loss. Jain's [11], Wang and Crowcroft <ref> [16] </ref> and Vegas [6] criteria were devised for congestion avoidance : these schemes try to optimize the network usage while avoiding congestion. These schemes are based on the idea that there will be some response from the network to a congestion window size change. <p> We did not find any work which evaluates Jain's criteria under real 5 network conditions. So it was not clear as to what extent Jain's criteria is good/bad under real network conditions. Wang's Normalized Throughput Gradient N T G is defined as <ref> [16] </ref>: N T G = T (W 1 ) where T (W i ) = W i =RT T i is the throughput of the connection with the i th window, whose size is denoted as W i .
References-found: 16

