URL: http://www.neci.nj.nec.com/homepages/oliensis/latejournalpaper.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/oliensis/
Root-URL: 
Email: (oliensis@research.nj.nec.com)  
Title: A Multi-frame Structure from Motion Algorithm under Perspective Projection  
Author: John Oliensis 
Address: 4 Independence Way Princeton, N.J. 08540  
Affiliation: NEC Research Institute  
Abstract: We present an algorithm for multi-frame structure from motion from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. The algorithm applies for general motion and large perspective effects and is fast, with computational complexity linear in the number of image points. Experimental results on synthetic sequences show that the algorithm obtains accuracies essentially equal to those of a maximum likelihood estimate in a second or two of computation on an IRIS 10000 (for 15 images of 30 points). The algorithm's results are significantly better than those obtained from just two images. Surprisingly, in cases when the camera projection is close to scaled orthographic, its results are comparable to those of the Tomasi/Kanade algorithm, and the algorithms are comparably fast. An important reason for the algorithm's speed and robustness is that it explicitly incorporates an analysis of the bas-relief ambiguity for multi-frame sequences. The algorithm assumes that the camera calibration is known, but it is robust to errors in the focal length and camera center. A simple modification of the algorithm can deal with sequences where the focal length is unknown and varies from image to image. In our experiments, we obtain good reconstructions even when the focal length varies considerably. We also study the reliability and accuracy of standard two-frame reconstructions. We find that two-frame algorithms are surprisingly robust and accurate, apart from the bas-relief ambiguity, but we also show explicitly that they do have serious problems with local minima. Lastly, we show that a well-known problem with the Tomasi/Kanade algorithm is often not a significant one. Keywords: Structure from motion, multi-frame structure from motion, rigorous results, optimal estimation, orthographic projection, shape from X, reconstruction, experiments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv, </author> <title> "In herent ambiguities in recovering 3-D motion and structure from a noisy flow field," </title> <type> PAMI 11, </type> <pages> 477-489, </pages> <year> 1989. </year>
Reference: [2] <author> A. Azarbayejani and A. Pentland, </author> <title> "Recursive estimation of motion, structure and focal length", </title> <journal> PAMI, </journal> <pages> pp. 562-575, </pages> <year> 1995. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [3] <author> P. Belhumeur and D. Kriegman, </author> <title> "The generalized bas-relief effect," </title> <month> CVPR </month> <year> 1997. </year>
Reference-contexts: This corre sponds to the extended or generalized bas-relief effect <ref> [31, 3] </ref>. 12 As long as the FOV is moderate, with F t 180 ffi . 11 2.2.9 Step 6: Further Improvements Step 5 still neglects some sources of bias.
Reference: [4] <author> T. J. Broida and R. Chellappa, </author> <title> "Estimating the Kinematics and Structure of a Rigid Object from a Sequence of Monocular Images", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 13, no. 6, </volume> <pages> pp. 497-513, </pages> <year> 1991. </year>
Reference: [5] <author> N. Cui, J. Weng and P. Cohen, </author> <title> "Extended Structure and Motion Analysis from Monocular Image Sequences," </title> <booktitle> Proceedings 3rd IEEE International Conference on Computer Vision, </booktitle> <address> Osaka, Japan, </address> <year> 1990, </year> <pages> pp. 222-229. </pages>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [6] <author> K. Daniilidis and M. E. Spetsakis, </author> <title> "Understanding noise sensitivity in structure from motion," in Visual Navigation, </title> <editor> Y. Aloimonos, ed, Lawrence Erl-baum, </editor> <address> New Jersey, 60-88, </address> <year> 1997. </year>
Reference: [7] <author> K. Daniilidis and H.-H. Nagel, </author> <title> "Analytical results on error sensitivity of motion estimation from two view," </title> <journal> Image and Vision Computing, </journal> <volume> vol 8. no. 4, </volume> <pages> 297-303, </pages> <year> 1990. </year>
Reference: [8] <author> G. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins Press, </publisher> <address> Baltimore, Maryland,1983. </address>
Reference-contexts: Typically there are many more image points than images. 7 From standard results of matrix perturbation theory <ref> [8] </ref>, this procedure com-putes B, S 3 , A up to o (s 4 =s 3 ) corrections, where s 3 ; s 4 are the third and fourth singular values of D CH . <p> Experimentally, however, it seems to add little information beyond that provided by s 4 =s 3 . To compute M T M 's least eigenvector when the number of feature points N p is large, one can use the standard preconditioned conjugate gradient method <ref> [8] </ref>. If started with a good initial estimate, this method will give accurate estimates of the least eigenvector in a small number of iterations. Moreover, due to the way M is defined in terms of H, each iteration has a computational cost linear in N p . <p> We can analyze the bas-relief effect quantitatively within the context of our approach 10 [29][31][46]. Recall that the least eigenvector of M T M gives the structure estimate. When M T M has more than one small eigenvalue, standard results of matrix perturbation theory <ref> [8] </ref> imply that the errors (e.g. noise, approximation error) can contaminate the least eigenvector of M T M by mixing in the eigenvectors associated with the other small eigenvalues. The amount of mixing is scaled roughly by the size of the errors relative to the small eigenvalues.
Reference: [9] <author> C.G. Harris and J.M. Pike, </author> <title> "3D positional integration from image sequences," </title> <journal> Image and Vision Computing, </journal> <volume> vol. 6, </volume> <pages> 87-90, </pages> <year> 1988. </year> <title> 42 Experimentally, we often find that only two of the equations in (34) determine f~g accurately. In practice, it may be better to discard the third equation rather than combining it with the others by the linear technique described here. </title> <type> 62 </type>
Reference: [10] <author> R. I. </author> <title> Hartley, "In Defense of the Eight-Point Algorithm," </title> <journal> PAMI vol. </journal> <volume> 19 No. 6, </volume> <pages> 580-593, </pages> <year> 1995. </year>
Reference-contexts: In particular, the relatively small FOV of 60 ffi biases the "8-point" algorithm toward reconstruct ing ^ T = ^z. We generated a second series of 1000 sequences exactly as before and applied a two-frame algorithm starting with Hartley's improved version of the "8-point" algorithm <ref> [10] </ref>, which approximately compensates for this bias 30 . For 53 of these sequences, the two-frame results for the translation direction deviated by more than 10 ffi (and up to 69 ffi ) from those of brute force two-frame 30 We implemented only the first-stage improvement in [10] and not the <p> the "8-point" algorithm <ref> [10] </ref>, which approximately compensates for this bias 30 . For 53 of these sequences, the two-frame results for the translation direction deviated by more than 10 ffi (and up to 69 ffi ) from those of brute force two-frame 30 We implemented only the first-stage improvement in [10] and not the second. Implementing the second is not completely straightforward in a Euclidean setting, and the first is responsible for most of the improvement in the "8-point" algorithm's performance [10]. 35 optimization starting from the ground truth. <p> up to 69 ffi ) from those of brute force two-frame 30 We implemented only the first-stage improvement in <ref> [10] </ref> and not the second. Implementing the second is not completely straightforward in a Euclidean setting, and the first is responsible for most of the improvement in the "8-point" algorithm's performance [10]. 35 optimization starting from the ground truth. This is better than for the original "8-point" algorithm but still represents a significant local minimum problem.
Reference: [11] <author> R.I. Hartley and P. Sturm, </author> <title> "Triangulation," </title> <address> IUW, (Monterey, CA, Novem-ber 13-16, 1994), </address> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1994, </year> <pages> 957-966. </pages>
Reference-contexts: The weight W is defined by i R ~ T fi ~ P 1i ; W i j i (1 : 2)j + j-i (1 : 2)j After recovering the motion, we used Hartley's triangulation method <ref> [11] </ref> to solve optimally for the 3D structure for the given motion 24 .
Reference: [12] <author> R. </author> <title> Hartley, "Euclidean Reconstruction from Uncalibrated Views," </title> <booktitle> in fnem Second Workshop on Invariantsg, </booktitle> <address> Azores, </address> <year> 1993, </year> <pages> 187-202. </pages>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [13] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7, </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference: [14] <author> B. </author> <title> K.P. Horn, "Relative orientation," </title> <booktitle> IJCV 4, </booktitle> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [15] <author> D. Jacobs, </author> <month> CVPR 206-212, </month> <year> 1997. </year>
Reference-contexts: In this paper we assume no occlusion. The algorithm can be extended to handle occlusion using methods such as in <ref> [15] </ref>. An early version of this algorithm was described in [28]; [31] and [29] describe related algorithms. 1.1 Outline Our algorithm is described in the next section. We experimentally compare it to maximum likelihood reconstruction in Section 3.
Reference: [16] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Linear subspace methods for recovering translational direction," </title> <institution> University of Toronto Technical Report RBCV-TR-92-40,1992. </institution>
Reference-contexts: To further reduce the effects of rotation errors and diminish the influence of outlier images, we use a technique similar to that of Heeger and Jepson for linearly recovering the translation direction from the optical flow <ref> [16, 17] </ref>. The 3 vectors x;y;z give the first-order rotational flow. <p> The factor (ffi hh 0 + 1) appears because the flow D H is defined with respect to the base image. As a result, the noise from the first image appears 7 For Jepson and Heeger's optical flow problem <ref> [16, 17] </ref> it was necessary to eliminate three additional vectors besides the rotational flow. Here we eliminate the exact rotational flow and lose no useful information. 8 We can take H as noiseless in calculating this covariance. <p> The bas-relief ambiguity is usually understood to imply that just a single component of the structure is difficult to recover. In general more than one can be, as pointed out in <ref> [16] </ref> (for constant motions) and [31].
Reference: [17] <author> A.D. </author> <title> Jepson and D.J. Heeger, "A fast subspace algorithm for recovering rigid motion," </title> <booktitle> Motion Workshop , Princeton, N.J., </booktitle> <pages> 124-131, </pages> <year> 1991. </year>
Reference-contexts: To further reduce the effects of rotation errors and diminish the influence of outlier images, we use a technique similar to that of Heeger and Jepson for linearly recovering the translation direction from the optical flow <ref> [16, 17] </ref>. The 3 vectors x;y;z give the first-order rotational flow. <p> The factor (ffi hh 0 + 1) appears because the flow D H is defined with respect to the base image. As a result, the noise from the first image appears 7 For Jepson and Heeger's optical flow problem <ref> [16, 17] </ref> it was necessary to eliminate three additional vectors besides the rotational flow. Here we eliminate the exact rotational flow and lose no useful information. 8 We can take H as noiseless in calculating this covariance.
Reference: [18] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Subspace methods for recovering rigid motion II: Theory," </title> <institution> University of Toronto Technical Report RBCV-TR-90-36, </institution> <year> 1990. </year>
Reference: [19] <author> K. Kanatani, </author> <title> Statistical Optimization for Geometric Computation, </title> <publisher> Elsevier Science, </publisher> <address> Amsterdam, </address> <year> 1996. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [20] <author> K. Kanatani, </author> <title> "Unbiased estimation and statistical analysis of 3-D rigid motion from two view," </title> <type> PAMI 15, </type> <pages> 37-50, </pages> <year> 1993. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [21] <author> J. Koenderink, and A. J. van Doorn, </author> <title> "Affine Structure from Motion," </title> <journal> JOSA-A(8), </journal> <volume> No. 2, </volume> <pages> pp. 377-385, </pages> <year> 1991. </year>
Reference: [22] <author> R. Kumar, P. Anandan, and K. Hanna, </author> <title> "Direct recovery of shape from multiple views: A parallax based approach," </title> <booktitle> 12th IAPR International Conference on Pattern Recognition, Conference A, </booktitle> <address> (Jerusalem, Israel, </address> <month> October 9-13, </month> <title> 1994), </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994, </year> <pages> 685-688. </pages>
Reference-contexts: However, surely Gaussian or uniform noise is a reasonable model for much of the uncertainty in localizing image features. (When the motion is small and the entire image is used to establish correspondence, it can be a very good model <ref> [22] </ref>.) For a strongly overconstrained problem like MFSFM, reconstruction should not depend sensitively on the detailed distribution of image errors when the errors are small, and even occasional large errors should not affect it much. <p> Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [23] <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293: </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery. <p> In practice, if one uses a non-optimal method (such as the third above) for selecting an image pair, the resulting two-image reconstructions will be less accurate and robust than those presented here. For our two-frame algorithm, we first reconstructed the motion using the "8-point" algorithm <ref> [23] </ref>. (The "8-point" algorithm has a 2-fold ambiguity in recovering the translation and rotation; we selected the correct solution by comparing to the ground truth.) We used the "8-point" estimate as the starting guess for a standard algorithm minimizing the weighted coplanarity error as a function of the motion.
Reference: [24] <author> L. Matthies, T. Kanade, and R. Szeliski, </author> <title> "Kalman Filter-Based Algorithms for Estimating Depth from Image Sequences," </title> <journal> International Journal of Computer Vision, </journal> <volume> vol 3, </volume> <pages> pp. 209-236, </pages> <year> 1989. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [25] <author> S. Maybank, </author> <title> "Theory of Reconstruction from Image Motion," </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference: [26] <author> S. Maybank, </author> <title> "A theoretical study of optical flow," </title> <type> PhD thesis, </type> <institution> University of London, </institution> <year> 1987. </year>
Reference: [27] <author> J. Oliensis, </author> <title> "A Critique of Structure from Motion Algorithms," </title> <note> NECI TR 1997, http:nwww.neci.nj.nec.comnhomepagesnoliensis.html. 63 </note>
Reference-contexts: Among previous algorithms, the Tomasi/Kanade approach [49] is designed for sequences where the 3D scene is compact. Standard 2-frame algorithms work well when the 3D scene is extended in depth and the camera translations are large 2 <ref> [27, 30, 28, 29] </ref>. The algorithm described in this paper is designed for a complementary situation, where the depth range of the scene is large but the translations are small or moderate (though it also works well for large translations or small depth range). <p> No previous algorithm deals reliably 3 with this important case, which occurs for instance in outdoor robot navigation. We have argued in <ref> [27, 28, 29] </ref> that there are no general-purpose SFM algorithms: to be effective, an SFM algorithm must exploit the specific conditions of the domain for it is to be applied. <p> Which version of the algorithm to apply can be determined automatically. 2 In fact, we have argued that this situation requires a few-frame algorithm: reconstructing from many frames is effectively impossible, at least for the initial reconstruction <ref> [27] </ref>. 3 Optimization is the most reliable current approach, but how reliable it is starting from a poor initial guess has not been established and is difficult to analyze. 2 is guaranteed to work well. <p> Moreover, if it is applied to sequences that strongly violate these conditions, the data signals this, and the algorithm's own behavior also provides a warning signal. Thus the algorithm is both accurate and trustworthy. We also argued in <ref> [27] </ref> that to achieve the best reconstructions over a broad range of situations one one must use a variety of algorithms. In conjunction with previous approaches, the algorithms proposed here should suffice for dealing with many SFM problems [27, 28, 29]. <p> We also argued in [27] that to achieve the best reconstructions over a broad range of situations one one must use a variety of algorithms. In conjunction with previous approaches, the algorithms proposed here should suffice for dealing with many SFM problems <ref> [27, 28, 29] </ref>. Our algorithm focuses on reconstructing the motions and the depths of the 3D points relative to a fixed camera position. The depths are the most difficult part of the 3D scene to reconstruct accurately. <p> Finally, Section 4 describes how a slight modification of our algorithm can deal with sequences where the focal length is unknown and varying. 2 Algorithm Description Our algorithm is designed to approximate the maximum likelihood estimate (MLE) as closely as possible. It is impossible to do this directly <ref> [27] </ref>. Thus the algorithm reconstructs in a series of steps, begining with quantities that can be estimated robustly and using these to bootstrap toward better estimates. The strategy is: 1. Initially introduce approximations, in effect trading away information to get a reliable reconstruction from the remaining information.
Reference: [28] <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> Workshop on the Representations of Visual Scenes, </booktitle> <pages> 77-84, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Among previous algorithms, the Tomasi/Kanade approach [49] is designed for sequences where the 3D scene is compact. Standard 2-frame algorithms work well when the 3D scene is extended in depth and the camera translations are large 2 <ref> [27, 30, 28, 29] </ref>. The algorithm described in this paper is designed for a complementary situation, where the depth range of the scene is large but the translations are small or moderate (though it also works well for large translations or small depth range). <p> No previous algorithm deals reliably 3 with this important case, which occurs for instance in outdoor robot navigation. We have argued in <ref> [27, 28, 29] </ref> that there are no general-purpose SFM algorithms: to be effective, an SFM algorithm must exploit the specific conditions of the domain for it is to be applied. <p> We also argued in [27] that to achieve the best reconstructions over a broad range of situations one one must use a variety of algorithms. In conjunction with previous approaches, the algorithms proposed here should suffice for dealing with many SFM problems <ref> [27, 28, 29] </ref>. Our algorithm focuses on reconstructing the motions and the depths of the 3D points relative to a fixed camera position. The depths are the most difficult part of the 3D scene to reconstruct accurately. <p> In this paper we assume no occlusion. The algorithm can be extended to handle occlusion using methods such as in [15]. An early version of this algorithm was described in <ref> [28] </ref>; [31] and [29] describe related algorithms. 1.1 Outline Our algorithm is described in the next section. We experimentally compare it to maximum likelihood reconstruction in Section 3.
Reference: [29] <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> IUW, </booktitle> <pages> 1225-1231. </pages> <year> 1994. </year>
Reference-contexts: Among previous algorithms, the Tomasi/Kanade approach [49] is designed for sequences where the 3D scene is compact. Standard 2-frame algorithms work well when the 3D scene is extended in depth and the camera translations are large 2 <ref> [27, 30, 28, 29] </ref>. The algorithm described in this paper is designed for a complementary situation, where the depth range of the scene is large but the translations are small or moderate (though it also works well for large translations or small depth range). <p> No previous algorithm deals reliably 3 with this important case, which occurs for instance in outdoor robot navigation. We have argued in <ref> [27, 28, 29] </ref> that there are no general-purpose SFM algorithms: to be effective, an SFM algorithm must exploit the specific conditions of the domain for it is to be applied. <p> We also argued in [27] that to achieve the best reconstructions over a broad range of situations one one must use a variety of algorithms. In conjunction with previous approaches, the algorithms proposed here should suffice for dealing with many SFM problems <ref> [27, 28, 29] </ref>. Our algorithm focuses on reconstructing the motions and the depths of the 3D points relative to a fixed camera position. The depths are the most difficult part of the 3D scene to reconstruct accurately. <p> In this paper we assume no occlusion. The algorithm can be extended to handle occlusion using methods such as in [15]. An early version of this algorithm was described in [28]; [31] and <ref> [29] </ref> describe related algorithms. 1.1 Outline Our algorithm is described in the next section. We experimentally compare it to maximum likelihood reconstruction in Section 3. In addition, we experimentally compare it to a standard two-frame approach in Sections 3.3, 3.8, and 3.9 and to the Tomasi/Kanade algorithm in Section 3.11.
Reference: [30] <author> J. Oliensis, </author> <title> "Rigorous Bounds for Two-Frame Structure from Motion," </title> <note> ECCV 1996 and NECI TR, October 1995 (expanded version). </note>
Reference-contexts: Among previous algorithms, the Tomasi/Kanade approach [49] is designed for sequences where the 3D scene is compact. Standard 2-frame algorithms work well when the 3D scene is extended in depth and the camera translations are large 2 <ref> [27, 30, 28, 29] </ref>. The algorithm described in this paper is designed for a complementary situation, where the depth range of the scene is large but the translations are small or moderate (though it also works well for large translations or small depth range). <p> Assuming moderate translation, we recover the rotations separately between the base frame and every other frame by a standard technique assuming that the translations are zero. This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate <ref> [30] </ref>. At this stage the small translation assumption is actually not 4 For instance, [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45]. <p> The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 <ref> [30] </ref>.
Reference: [31] <author> J. Oliensis, </author> <title> "Structure from Linear and Planar Motions," </title> <address> CVPR 335-342, </address> <year> 1996. </year>
Reference-contexts: For non-general motion, we can apply the modified versions of our algorithm reported in <ref> [31] </ref>. Note that we can determine from the data whether the general motion criterion is satisfied; see the discussion of Experiment 10. <p> In this paper we assume no occlusion. The algorithm can be extended to handle occlusion using methods such as in [15]. An early version of this algorithm was described in [28]; <ref> [31] </ref> and [29] describe related algorithms. 1.1 Outline Our algorithm is described in the next section. We experimentally compare it to maximum likelihood reconstruction in Section 3. <p> Below, we indicate the qualitative results of our rigorous error analysis in describing each step. Note that Steps 6, 12 explicitly (and Steps 5, 10 implicitly) exploit our analysis of the bas-relief ambiguity for multi-frame sequences to improve the reconstructions <ref> [34, 31, 46] </ref>. Unlike our algorithm, most previous approaches do not guarantee the quality of the initial reconstruction 4 . They do not approximate or otherwise simplify the SFM problem, and thus their errors are difficult to analyze and potentially large. <p> Step 5 eliminates a large part of the bias and significantly improves the structure reconstruction in our experiments. The greatest improvement occurs in the inverse depth component that is intrinsically difficult to reconstruct accurately due to the bas-relief effect (see next section) <ref> [31, 46] </ref>. At worst this Step should do little harm, even if the previous reconstruction has large errors, since it is only adjusting the bias in the previous computation. 2.2.8 The Bas-Relief Effect A few components of the inverse depth are intrinsically more difficult to recover accurately than the rest. <p> It is easy to show 12 from the explicit form of the rotational flows x;y;z that H T has one particularly small eigenvalue and that the corresponding least eigenvector is approximately f1g, the constant component of the inverse depths <ref> [31] </ref>. Experimentally, we always find that BR f1g : Thus BR roughly equals the least eigenvector of H T , and it is the most difficult component to recover precisely because its translational flows are the most confusable with rotational flows. <p> Note that f1g gives the scale of the overall relief of the scene; the difficulty of recovering this component is exactly the usual bas-relief ambiguity <ref> [46, 31] </ref>. The bas-relief ambiguity is usually understood to imply that just a single component of the structure is difficult to recover. In general more than one can be, as pointed out in [16] (for constant motions) and [31]. <p> The bas-relief ambiguity is usually understood to imply that just a single component of the structure is difficult to recover. In general more than one can be, as pointed out in [16] (for constant motions) and <ref> [31] </ref>. But, for the cases considered in this paper, the BR component is more difficult than the others, and we single it out for special treatment. 10 The qualitative conclusions of the analysis are essentially algorithm-independent [34][31]. 11 Typically three eigenvalues (in addition to the least) are potentially small. <p> This corre sponds to the extended or generalized bas-relief effect <ref> [31, 3] </ref>. 12 As long as the FOV is moderate, with F t 180 ffi . 11 2.2.9 Step 6: Further Improvements Step 5 still neglects some sources of bias. <p> The first correction rescales the translations to account approximately for the denominator neglected in (3). This step is based on the observation that, since the inverse depths are positive, f~g is dominated by its constant component f1g. For example, in two real image sequences <ref> [31] </ref> and our current synthetic experiments, the f1g component usually accounts for 90% or more of the magnitude of jf~gj. <p> We experimentally test our algorithm on synthetic sequences. Real-image experiments with a different version of the algorithm can be found in <ref> [31] </ref>. We use synthetic sequences for several reasons. We are primarily interested in the numerical properties of the algorithm and especially in how well it compares to the true MLE. The experiments below are among the first that extensively compare a SFM algorithm to the true MLE 19 . <p> We used both Gaussian and uniform noise. 20 One can determine from the data whether the general motion criterion is satisfied, see Experiment 10 below and footnote 1. When the criterion is not met, one can use the versions of the algorithm described in <ref> [31] </ref>. 20 3.3 Experiment 1. We generated 1000 sequences with the structure in a cone with a base 28 X; Y 28 at Z = 100, and an apex at (0; 0; 17:5) T . Z was restricted to 20 Z 100. <p> 0.276 0.270 0.238 0.224 Rotation Error 0.802 0.639 0.583 0.546 0.537 Table 8: Experiment 7: Number of Trials: 1000; Structure: cone, 28 X; Y 28, 20 Z 100; Noise = 4 pixel; FOV = 60; Translations 8; Iterations (Avg, Max) = (3.26, 5) algorithm followed by fusing should work well <ref> [31] </ref>; an intrinsically multi-frame algorithm like the one presented here is unnecessary. Nevertheless, even though the domain is better suited to other types of algorithms, our algorithm works well. The number of iterations required for convergence in Step 11 is much larger than in the previous experiments. <p> This is not a fundamental problem: one can use the number of large singular values of D CH to automatically detect sequences with non-general translations and then apply the versions of our algorithm specialized for these <ref> [31] </ref>. But this experiment does give a stringent test of our algorithm in its general-motion version. <p> With only 5 images, the main importance of s 3 =s 4 is that it indicates whether or not the translational motion is non-planar, whereas in the previous experiments the motion 39 Two- or three-image sequences can be dealt with by the versions of our algorithm reported in <ref> [31] </ref>, see footnote 1. 53 ERRORS Iteration 1 Iteration 3 Converged Improved MLE Average Depth 2.074 1.883 1.714 1.164 1.052 Constant Component 0.087 0.089 0.076 0.035 0.028 NonConstant Components 0.017 0.011 0.010 0.010 0.009 Translation Error 0.519 0.204 0.173 0.130 0.115 Rotation Error 7.230 0.943 0.610 0.365 0.318 Table 11: Experiment
Reference: [32] <author> J. Oliensis and Venu Govindu, </author> <title> "An Experimental Study of Projective Structure from Motion," </title> <note> NECI TR October 1995, http:nwww.neci.nj.nec.comnhomepagesnoliensis.html. </note>
Reference-contexts: is based on all images, its error is smaller than the noise in any single image and the weighting factor deviates from 1 only by o F : 19 We have established in other work that the true MLE can be computed reliably by LM starting from the ground truth <ref> [32] </ref>. The MLE-comparison gives a more exact performance characterization than the Cramer-Rao lower bound computed from the ground truth. 19 motion must not be restricted to a plane. Such real-image sequences are rare 20 . The disadvantages of synthetic sequences are often overstressed. <p> The "MLE" results are the result of minimizing the true image projection error using the Levenberg-Marquardt algorithm starting from the ground truth. (For better stability and to compactify the search space, we represented the structure by its homogeneous coordinates during the minimization <ref> [32] </ref>.) Note that the Figure also records the average and maximum number of iterations of Step 11 required for convergence. Figures 2 and 3 record the translation and rotation errors.
Reference: [33] <author> J. Oliensis and J. I. Thomas, </author> <title> "Incorporating Motion Error in Multi-frame Structure from Motion," </title> <booktitle> Proceedings IEEE Workshop on Visual Motion, </booktitle> <publisher> Princeton, </publisher> <pages> pp 8-13, </pages> <year> 1991. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [34] <author> J. Oliensis, </author> <note> in preparation. </note>
Reference-contexts: Again, the aim is to ensure that the early steps are reliable since everything afterward is based on them (Section 2.2.10). Each step is designed to be analyzable, so that we can show explicitly that its errors are likely to be small. We have proven in <ref> [34] </ref> that, under reasonable assumptions, the algorithm does converge and that the final reconstruction has small errors. Below, we indicate the qualitative results of our rigorous error analysis in describing each step. <p> Below, we indicate the qualitative results of our rigorous error analysis in describing each step. Note that Steps 6, 12 explicitly (and Steps 5, 10 implicitly) exploit our analysis of the bas-relief ambiguity for multi-frame sequences to improve the reconstructions <ref> [34, 31, 46] </ref>. Unlike our algorithm, most previous approaches do not guarantee the quality of the initial reconstruction 4 . They do not approximate or otherwise simplify the SFM problem, and thus their errors are difficult to analyze and potentially large. <p> One can show theoretically that most 11 of the eigenvalues are of order 1 [31]<ref> [34] </ref>. Additional analysis shows that, in addition to the least eigenvalue corresponding to the inverse-depth estimate, only one of the remaining eigenvalues is likely to be small [34]. Our experiments confirm that typically all but two of the M T M eigenvalues are of order 1; the second-least eigenvalue is usually .01-.04. We denote the eigenvector associated with the second-least eigenvalue as BR . <p> As indicated by our crude error analysis, with each cycle of Step 9 followed by Step 10, the distance of the reconstruction to the converged result decreases roughly by a factor of t . This is born out by a more rigorous error analysis <ref> [34] </ref> and also 16 As described below, we skip Step 4, using the estimated in previous iterations as input for Step 5. 15 by experiment. Thus convergence is rapid: in our experiments we find that convergence to within one part in 10 3 typically takes just 2 or 3 cycles.
Reference: [35] <editor> M. Pollefeys , L. Van Gool, M. Proesmans, </editor> <volume> ECCV vol 1. </volume> <pages> 31-42, </pages> <year> 1996. </year>
Reference: [36] <author> H. S. Sawhney, </author> <title> "Simplifying Motion and Structure Analysis Using Planar Parallax and Image Warping," </title> <address> IAPR 403-408, </address> <year> 1994. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [37] <author> A. Shashua, N. Navab, </author> <title> "Relative Affine Structure: Canonical Model for 3D from 2D Geometry and Applications," </title> <journal> PAMI (18), </journal> <volume> No. 9, </volume> <pages> pp. 873-883, </pages> <year> 1996. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [38] <author> A. Shashua and S. Avidan, </author> <title> "The Rank 4 Constraint in Multiple ( 3) View Geometry," </title> <address> ECCV 196-206, </address> <year> 1996. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [39] <author> A. Shashua, N. </author> <title> Navab "Relative Affine Structure: Theory and Application to 3D Reconstruction from Perspective Views," </title> <address> CVPR 483-489, </address> <year> 1994. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [40] <author> A. Shashua, </author> <title> "Trilinearity in visual recognition by alignment," </title> <booktitle> ECCV Vol. </booktitle> <pages> 1 479-484, </pages> <year> 1994. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [41] <author> S. Soatto and P. </author> <title> Perona "Recursive 3-D Visual-Motion Estimation Using Subspace Constraints," </title> <journal> IJCV vol. </journal> <volume> 22, </volume> <pages> 235-259, </pages> <year> 1997. </year>
Reference: [42] <author> S. Soatto, P. Perona, R. Frezza, and G. Picci, </author> <title> "Recursive motion and structure estimation with complete error characterization," </title> <address> CVPR 428-433, </address> <year> 1993. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [43] <author> M.E.Spetsakis and J.Aloimonos, </author> <title> "Optimal Computing of Structure from Motion Using Point Correspondences in Two Frames," </title> <booktitle> Proceedings 2nd IEEE International Conference on Computer Vision, </booktitle> <address> Tampa, Florida, </address> <month> Dec. </month> <year> 1988, </year> <pages> pp. 449-538. </pages>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [44] <author> M. Spetsakis and J.Aloimonos, </author> <title> "Optimal Visual Motion Estimation: A Note," </title> <journal> IEEE PAMI, </journal> <volume> Vol 14, No. 9, </volume> <pages> 959-964, </pages> <year> 1992. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [45] <author> P. Sturm and B. Triggs, </author> <title> "A factorization based algorithm for multi-image projective structure and motion," </title> <address> ECCV 709-720, </address> <year> 1996. </year> <month> 64 </month>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [46] <author> R. Szeliski and S.B. Kang, </author> <title> "Shape ambiguities in structure from motion," </title> <type> PAMI 19, </type> <pages> 506-512, </pages> <year> 1997. </year>
Reference-contexts: Below, we indicate the qualitative results of our rigorous error analysis in describing each step. Note that Steps 6, 12 explicitly (and Steps 5, 10 implicitly) exploit our analysis of the bas-relief ambiguity for multi-frame sequences to improve the reconstructions <ref> [34, 31, 46] </ref>. Unlike our algorithm, most previous approaches do not guarantee the quality of the initial reconstruction 4 . They do not approximate or otherwise simplify the SFM problem, and thus their errors are difficult to analyze and potentially large. <p> Step 5 eliminates a large part of the bias and significantly improves the structure reconstruction in our experiments. The greatest improvement occurs in the inverse depth component that is intrinsically difficult to reconstruct accurately due to the bas-relief effect (see next section) <ref> [31, 46] </ref>. At worst this Step should do little harm, even if the previous reconstruction has large errors, since it is only adjusting the bias in the previous computation. 2.2.8 The Bas-Relief Effect A few components of the inverse depth are intrinsically more difficult to recover accurately than the rest. <p> Note that f1g gives the scale of the overall relief of the scene; the difficulty of recovering this component is exactly the usual bas-relief ambiguity <ref> [46, 31] </ref>. The bas-relief ambiguity is usually understood to imply that just a single component of the structure is difficult to recover. In general more than one can be, as pointed out in [16] (for constant motions) and [31].
Reference: [47] <author> R. Szeliski and S.B. Kang, </author> <title> "Recovering 3D shape and motion from image streams using non-linear least squares," in Journal of Visual Communication and Image Representation, </title> <journal> vol. </journal> <volume> 5, no. 1, </volume> <pages> 10-28, </pages> <year> 1994. </year>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [48] <author> J. I. Thomas, A. Hanson, J. Oliensis, </author> <title> "Refining 3D Reconstructions: A Theoretical and Experimental Study of the Effect of Cross-Correlations," Computer Vision, Graphics, </title> <booktitle> and Image Processing: Image Understanding, </booktitle> <volume> Vol. 60, </volume> <pages> 1994 pp. 359-370. </pages>
Reference-contexts: This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate [30]. At this stage the small translation assumption is actually not 4 For instance, <ref> [24, 5, 33, 42, 12, 47, 48, 40, 2, 38, 45] </ref>. The Tomasi/Kanade algorithm is one exception: it is guaranteed to work well for distant small moving objects. 4 crucial, since typically one can also recover the rotations accurately for large translations 5 [30].
Reference: [49] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: A simple modification of the algorithm can deal with sequences where the focal length is unknown and varies from image to image. The modified algorithm gives good experimental results even when the focal length changes are considerable. Among previous algorithms, the Tomasi/Kanade approach <ref> [49] </ref> is designed for sequences where the 3D scene is compact. Standard 2-frame algorithms work well when the 3D scene is extended in depth and the camera translations are large 2 [27, 30, 28, 29]. <p> [C 1=2 ] hh 0 = ffi hh 0 N 1 Then E (~; T ) Trace (D CR D T CR ); (7) and the covariances of D CH , D CR are proportional to the identity: D h h 0 E D h h 0 E As in <ref> [49] </ref>, our algorithm minimizes (7) approximately by solving for ~ i , T h x;y;z in two stages. 2.2.5 Step 3: Computing the Leading Singular Vectors of D CH . The first stage computes the best rank three approximation to D CH . <p> Also, in minimizing over U 0 , it in effect treats AU 0 as white over a range of U 0 , whereas this quantity can be (approximately) white only at a single value for U 0 . Lastly, as in <ref> [49] </ref>, this Step is based on a prior computation of A 1;2;3 rather than on the data directly. It is the second half of a two-stage solution, and it freezes in the bias introduced by the first stage's partial neglect of information 13 . <p> We compared our algorithm to the Tomasi/Kanade approach <ref> [49] </ref> on sequences where the camera projection was approximately linear (scaled orthographic). For these experiments, the data does not contain enough information to determine the constant component of the inverse depths reliably|or, correspondingly, the overall average depth.
Reference: [50] <author> J. Weng, N. Ahuja, and T.S. Huang, </author> <title> "Optimal motion and structure estimation," </title> <journal> PAMI vol. </journal> <volume> 15, no. 9, </volume> <pages> 864-884, </pages> <year> 1993. </year>
Reference-contexts: Number of Trials: 1000; 28 X; Y 28, 20 Z 100; Noise = 1 pix Gauss; FOV = 60; Trans. 4; Iterations (Avg, Max) = ( 4.70, 7) For comparison, we also ran a standard two-frame algorithm on these se-quences <ref> [23, 43, 14, 44, 50, 20, 39, 22, 36, 37, 19] </ref>. This requires choosing two images to reconstruct with. We attempted to chose images that would give the best possible structure recovery.
Reference: [51] <author> G.-S.J. Young and R. Chellappa, </author> <title> "Statistical analysis of inherent ambiguities in recovering 3D motion from a noisy flow field," </title> <journal> PAMI, </journal> <volume> vol. 14, no.10, </volume> <pages> 995-1013, </pages> <year> 1992. </year>
References-found: 51

