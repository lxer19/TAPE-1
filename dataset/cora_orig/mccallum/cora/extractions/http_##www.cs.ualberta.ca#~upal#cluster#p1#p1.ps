URL: http://www.cs.ualberta.ca/~upal/cluster/p1/p1.ps
Refering-URL: http://www.cs.ualberta.ca/~upal/cluster/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: upal@cs.ualberta.ca eric@cs.usask.ca  
Title: Comparison of Unsupervised Classifiers  
Author: Muhammad Afzal Upal Eric M Neufeld 
Keyword: Unsupervised classification. Area of Interest: Concept formation and classification.  
Address: Edmonton, Canada. Saskatoon, Canada.  
Affiliation: University of Alberta University of Saskatchewan  
Abstract: The activity of sorting like objects into classes without any help from an omniscient supervisor is known as unsupervised classification. In AI both symbolic and connectionist camps study classification. The statistical classifiers such as Autoclass and Snob search for the theory that can best explain the distribution of given data, whereas neural network classifiers such as Kohonen's networks and ART2 use the vector quantization principle for classifying data. Previously, many studies have compared supervised classification algorithms, but the more challenging problem of comparing unsupervised classifiers has largely been ignored. We performed an empirical comparison of ART2, Autoclass and Snob. We highlight the strengths and weaknesses of the various classifiers. Overall, statistical classifiers, especially Snob, perform better than their neural network counterpart ART2. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Michael R. Anderberg. </author> <title> Cluster Analysis for Applications. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Some well known cluster analysis algorithms are the leader algorithm, the k-means algorithm, ISODATA, and the quick partition algorithm <ref> [1] </ref>. Cluster analysis algorithms require prior specification of the number of classes and/or some distance measure to measure the dis tance between the objects. <p> Many studies [10] [11] [26] [36] compare machine learning and neural network techniques in a supervised environment. Comparing unsupervised classifiers, however, is not as straightforward as comparing supervised classifiers because of the absence of class labels in the experimental classification. Anderberg <ref> [1] </ref> suggests classifying the classification algorithms themselves in order to quantify their similarities and differences. While this approach highlights the similarities and differences among classifiers, it begs the question because we still must determine the rationale for so classifying the algorithms.
Reference: [2] <author> C. K. Bayne, C. L. Beauchmap, C. L. Begovich, and V. E. Kane. </author> <title> Monte Carlo comparison of selected clustering procedures. </title> <journal> Pattern Recognition, </journal> <volume> 12 </volume> <pages> 51-60, </pages> <year> 1980. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] [23] [25] [17] [20] <ref> [2] </ref> focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. <p> ART1 classifies binary input patterns in an unsupervised environment whereas ART2 works in the real pattern space. ART Map and Art Star modify the basic ART architecture for training in a supervised environment. Fuzzy Art performs a fuzzy classification. We used ART2 in our study. (adapted from <ref> [2] </ref>). The basic ART2 network (see Figure 1) has two layers, F1 and F2 (collectively called the attentional gain subsystem), and an orientation subsystem. F1 is used as input/comparison layer (also called the feature representation field) and F2 as output/recognition layer (also called the category representation field). <p> This approach has been used in various comparisons of clustering algorithms <ref> [2] </ref> [3] [4] [9] [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [3] <author> R. K. Blashfield. </author> <title> Mixtures model test of cluster analysis. </title> <journal> Psychological Bulliten, </journal> <volume> 83 </volume> <pages> 377-388, </pages> <year> 1976. </year>
Reference-contexts: This approach has been used in various comparisons of clustering algorithms [2] <ref> [3] </ref> [4] [9] [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [4] <author> R. K. Blashfield, M. S. Aldenderfer, and L. C. Morey. </author> <title> Cluster analysis software. </title> <journal> Handbook of Statistics, </journal> <volume> 2 </volume> <pages> 245-266, </pages> <year> 1982. </year>
Reference-contexts: This approach has been used in various comparisons of clustering algorithms [2] [3] <ref> [4] </ref> [9] [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [5] <author> Peter Cheeseman, James Kelly, Matthew Self, John Stutz, Will Taylor, and Don Freeman. </author> <title> Autoclass: A Bayesian classification system. </title> <editor> In Michael B. Mor-gan, editor, </editor> <booktitle> Proceedings of Fifth International Conference on Machine Learning, </booktitle> <pages> pages 54-64, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: This leads us to formulation of the Bayesian approach to classification <ref> [5] </ref>. An alternative criterion is that best theory is the one that provides least complex explanation of data [31] [34]. Explanation includes both the description of the theory as well as the specification of data given that theory. <p> If H denotes the hypothesis and D the observed data, Bayes' rule states that the probability P (HjD) that the hypothesis explains the data is proportional to the probability P (DjH) of observing the data if the hypothesis were true <ref> [5] </ref>, P (HjD) = P (D) where P (D) is called the prior probability of data and can be obtained as a normalizing constant. In case of classification, the hypothesis is the number and probability distribution of classes. <p> Bayes' rule does not provide an algorithm for classification. The designers of a Bayesian classifier are faced with the computationally intractable problem of searching the hypothesis space for the optimal distribution that produced the observed data and the controversial problem of estimating the priors. Autoclass: Cheeseman et al. <ref> [5] </ref>, [6] implement Bayesian classification in Autoclass. Their strategy involves making simplifying assumptions about the classification model. Rather than searching the entire hypothesis space by considering all possible states of the world they focus on a limited number of possible states thereby reducing the number of possibilities to be analyzed.
Reference: [6] <author> Peter Cheeseman, John Stutz, and Robin Hanson. </author> <title> Bayesian classification with correlation and inheritance. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, Australia, </address> <pages> pages 692-698, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Bayes' rule does not provide an algorithm for classification. The designers of a Bayesian classifier are faced with the computationally intractable problem of searching the hypothesis space for the optimal distribution that produced the observed data and the controversial problem of estimating the priors. Autoclass: Cheeseman et al. [5], <ref> [6] </ref> implement Bayesian classification in Autoclass. Their strategy involves making simplifying assumptions about the classification model. Rather than searching the entire hypothesis space by considering all possible states of the world they focus on a limited number of possible states thereby reducing the number of possibilities to be analyzed.
Reference: [7] <author> Arthur P. Dempster. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Royal Journal of Statistical Society, Series B, </journal> <volume> 39 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: independently of each other to facilitate the calculation of P (Xj; ; m), P (Xj; ; m) = i=1 Autoclass also assumes that the attributes are independent of each other given the classifica tion, which gives, P (Xj; ; m) = i=1 k=1 Autoclass uses the Expectation Maximization (EM) algorithm <ref> [7] </ref> to estimates the class parameters that maximize the posterior probability of the parameters for a given number of classes. 2.1.2 The Minimum Message Length Classification A set X = [X i ] n i=1 of n objects each with q attributes can be represented without loss of any information as
Reference: [8] <author> Richard C. Dubes and Anil K. Jain. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Unsupervised classification seeks a convenient and valid organization of data and not to establish rules for separating future data into categories <ref> [8] </ref>. Early work in the formalization of unsu pervised classification techniques was done by taxonomists for naming new species of animals and plants [15]. Similar requirements arose for naming a variety of phenomena in both social and natural sciences. Statisticians developed tools that employ objective methodology for classification. <p> Another approach adopted by some researchers is to compile a list of generally acceptable criteria (called admissibility criteria) such as correctness and then examine which of the algorithms adhere to these criteria <ref> [8] </ref>. The admissibility approach provides insight into the classification methods but it does not provide any basis for a fair comparison of the systems as one would still need to measure the degree of admissibility of a criterion in order to measure the extent of conformity to a particular criterion [8]. <p> <ref> [8] </ref>. The admissibility approach provides insight into the classification methods but it does not provide any basis for a fair comparison of the systems as one would still need to measure the degree of admissibility of a criterion in order to measure the extent of conformity to a particular criterion [8]. A theoretical comparison of unsupervised classifiers is also not feasible as they are almost impossible to model mathematically in such a way that models can be compared [8]. <p> need to measure the degree of admissibility of a criterion in order to measure the extent of conformity to a particular criterion <ref> [8] </ref>. A theoretical comparison of unsupervised classifiers is also not feasible as they are almost impossible to model mathematically in such a way that models can be compared [8]. As Milligan [22] notes, none of the classifiers in use provide any theoretical proof which ensures that the algorithm will recover the true cluster structure. <p> The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] [23] [25] [17] [20] [2] focus on the cluster analysis techniques. As Dubes et al. <ref> [8] </ref> note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. Lutz Prechelt [28] examined 113 journal articles about neural net learning algorithms.
Reference: [9] <author> C. Edelbrock. </author> <title> Mixture model tests of hierarchical clustering algorithms-problem of classifying everybody. </title> <journal> Multivariate Behavioral Research, </journal> <volume> 14 </volume> <pages> 367-384, </pages> <year> 1979. </year>
Reference-contexts: This approach has been used in various comparisons of clustering algorithms [2] [3] [4] <ref> [9] </ref> [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [10] <author> C. Feng, A. Sutherland, R. King, S. Mug-gleton, and R. Henry. </author> <title> Comparison of machine learning classifiers to statistics and neural networks. </title> <booktitle> In Fourth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 41-52, </pages> <year> 1993. </year>
Reference-contexts: The connectionist researchers model self organizing properties of the brain using networks of neurons. 1.3 Previous Comparative Studies Thus given raw data, there are many choices of classification algorithms, and it is difficult for applied researchers to decide which algo rithm to prefer over the others. Many studies <ref> [10] </ref> [11] [26] [36] compare machine learning and neural network techniques in a supervised environment. Comparing unsupervised classifiers, however, is not as straightforward as comparing supervised classifiers because of the absence of class labels in the experimental classification.
Reference: [11] <author> Douglas H. Fisher and Kathleen B. McKusick. </author> <title> An empirical comparison of ID3 and back propagation. </title> <booktitle> In Proceedings of the Eleventh IJCAI , pages 788-793, </booktitle> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: The connectionist researchers model self organizing properties of the brain using networks of neurons. 1.3 Previous Comparative Studies Thus given raw data, there are many choices of classification algorithms, and it is difficult for applied researchers to decide which algo rithm to prefer over the others. Many studies [10] <ref> [11] </ref> [26] [36] compare machine learning and neural network techniques in a supervised environment. Comparing unsupervised classifiers, however, is not as straightforward as comparing supervised classifiers because of the absence of class labels in the experimental classification.
Reference: [12] <author> E. Fowlkes and C. Mallows. </author> <title> A method for comparing two hierarchical cluster-ings. </title> <journal> Journal of American Statistical Association, </journal> <volume> 78 </volume> <pages> 553-569, </pages> <year> 1983. </year>
Reference-contexts: as, X X 2 ; (3) X 2 i j n ij ! c = i n i: ! X X 2 ; (5) 2 2 @ i 2 + j 2 A : (6) We used Rand R [29], corrected Rand R 0 [16], Fowlkes and Mallows F M <ref> [12] </ref> and Jac card statistic J [24] to compare classifications produced by different algorithms.
Reference: [13] <author> A. L. Gross. </author> <title> Monte Carlo study of the accuracy of a hierarchical grouping procedure. </title> <journal> Multivariate Behavioral Research, </journal> <volume> 7 </volume> <pages> 379-389, </pages> <year> 1972. </year>
Reference-contexts: This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] <ref> [13] </ref> [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [14] <author> Stephen Grossberg and Gail Carpentar. </author> <title> Pattern Recognition by Self-Organizing Neural Networks. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachussets, </address> <year> 1991. </year>
Reference-contexts: Gross-berg's Adaptive Resonance Theory (ART) addresses the problem of instability of learned patterns by adding extensive feedback connections. ART2: ART1, ART2, ART3, ART Map, ART Star and Fuzzy ART are variations on the Adaptive Resonance architecture <ref> [14] </ref>. ART1 classifies binary input patterns in an unsupervised environment whereas ART2 works in the real pattern space. ART Map and Art Star modify the basic ART architecture for training in a supervised environment. Fuzzy Art performs a fuzzy classification. We used ART2 in our study. (adapted from [2]).
Reference: [15] <author> John Hartigan. </author> <title> Clustering Algorithms. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Unsupervised classification seeks a convenient and valid organization of data and not to establish rules for separating future data into categories [8]. Early work in the formalization of unsu pervised classification techniques was done by taxonomists for naming new species of animals and plants <ref> [15] </ref>. Similar requirements arose for naming a variety of phenomena in both social and natural sciences. Statisticians developed tools that employ objective methodology for classification.
Reference: [16] <author> L. J. Hubert and P. Arabie. </author> <title> Comparing partitions. </title> <journal> Journal of Classification, </journal> <volume> 2 </volume> <pages> 193-218, </pages> <year> 1985. </year>
Reference-contexts: define a; b; c and d as, X X 2 ; (3) X 2 i j n ij ! c = i n i: ! X X 2 ; (5) 2 2 @ i 2 + j 2 A : (6) We used Rand R [29], corrected Rand R 0 <ref> [16] </ref>, Fowlkes and Mallows F M [12] and Jac card statistic J [24] to compare classifications produced by different algorithms.
Reference: [17] <author> Anil Jain, A. Indrayan, and L. Goel. </author> <title> Monte Carlo comparison of six hierarchical clustering methods on random data. </title> <journal> Pattern Recognition, </journal> <volume> 19 </volume> <pages> 95-100, </pages> <year> 1986. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] [23] [25] <ref> [17] </ref> [20] [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods.
Reference: [18] <author> F. K. Kuiper and L. Fisher. </author> <title> Monte Carlo comparison of six clustering procedures. </title> <journal> Biometrics, </journal> <volume> 31 </volume> <pages> 777-783, </pages> <year> 1975. </year>
Reference-contexts: This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] <ref> [18] </ref> [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [19] <author> A. S. Lapedes and R. M. Farber. </author> <title> How neural nets work. </title> <editor> In Y. S. Lee, editor, </editor> <title> Evolution, Learning and Cognition. </title> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1988. </year>
Reference-contexts: These networks can learn to approximate arbitrary functions using the appropriate learning algorithm such as competitive learning <ref> [19] </ref>. 2.2.1 The Competitive Learning Model The basic idea behind competitive or winner take all learning is similar to the natural selection principle proposed by Charles Darwin to account for human and animal evolution.
Reference: [20] <author> J. E. Mezzich and H. Solomonoff. </author> <title> Taxonomy and Behavioral Sciences. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1980. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] [23] [25] [17] <ref> [20] </ref> [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods.
Reference: [21] <author> Ryszard S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year>
Reference-contexts: This lets us formulate the classification problem as a problem of inductive inference. 1.2 AI Techniques In AI unsupervised classification is studied by both connectionist and symbolic camps. The symbolic research is carried out by researchers in the traditional machine learning community, under the name of conceptual clustering <ref> [21] </ref>, as well as by those employing methodologies with a statistical flavor. The basic idea behind conceptual clustering is that instead of considering just the similarity between objects, the method uses the conceptual cohesiveness among the objects as a criterion for classification. <p> Conceptual cohesiveness depends not only on those objects and the surrounding objects but also on the information that describes the objects together. Conceptual clustering techniques thus perform a context based clustering and arrange objects in a hierarchical fashion <ref> [21] </ref>. According to the statistical approach properties of objects are distributed according to some probability distribution. This approach suggests estimating the parameters of these distributions based on some assumptions.
Reference: [22] <author> Glenn W. Milligan. </author> <title> An examination of effect of six types of error perturbation algorithms on fifteen clustering algorithms. </title> <journal> Psychometrika, </journal> <volume> 45 </volume> <pages> 325-342, </pages> <year> 1980. </year>
Reference-contexts: A theoretical comparison of unsupervised classifiers is also not feasible as they are almost impossible to model mathematically in such a way that models can be compared [8]. As Milligan <ref> [22] </ref> notes, none of the classifiers in use provide any theoretical proof which ensures that the algorithm will recover the true cluster structure. A reasonable approach then is to evaluate the classifications obtained from the classifiers to establish their characteristics as exhibited on the classification of some data sets. <p> The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] <ref> [22] </ref> [23] [25] [17] [20] [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] <ref> [22] </ref> [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] <ref> [22] </ref> [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes. The user specifies some number k of distinctly non-overlapping classes to be generated. Each class c can have m c objects each embedded in d c dimensional space.
Reference: [23] <author> Glenn W. Milligan. </author> <title> A Monte Carlo comparison of 30 internal criterion measures for cluster analysis. </title> <journal> Psychometrika, </journal> <volume> 46 </volume> <pages> 187-195, </pages> <year> 1981. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] <ref> [23] </ref> [25] [17] [20] [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], <ref> [23] </ref>, [24], [25]. The algorithm generates externally isolated and internally cohesive classes. The user specifies some number k of distinctly non-overlapping classes to be generated. Each class c can have m c objects each embedded in d c dimensional space.
Reference: [24] <author> Glenn W. Milligan and C. Cooper. </author> <title> An examination of the procedures for determining the number of clusters in data. </title> <journal> Psychometrika, </journal> <volume> 50 </volume> <pages> 159-179, </pages> <year> 1985. </year>
Reference-contexts: X 2 i j n ij ! c = i n i: ! X X 2 ; (5) 2 2 @ i 2 + j 2 A : (6) We used Rand R [29], corrected Rand R 0 [16], Fowlkes and Mallows F M [12] and Jac card statistic J <ref> [24] </ref> to compare classifications produced by different algorithms. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], <ref> [24] </ref>, [25]. The algorithm generates externally isolated and internally cohesive classes. The user specifies some number k of distinctly non-overlapping classes to be generated. Each class c can have m c objects each embedded in d c dimensional space.
Reference: [25] <author> Glenn W. Milligan, Lisa M. Sokol, and S. C. Soon. </author> <title> The effect of cluster size, dimensionality, and the number of clusters on recovery of true cluster structure. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(1) </volume> <pages> 40-47, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies [29] [22] [23] <ref> [25] </ref> [17] [20] [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] [22] <ref> [25] </ref>. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] [29] [13] [22] <ref> [25] </ref>. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes. The user specifies some number k of distinctly non-overlapping classes to be generated. Each class c can have m c objects each embedded in d c dimensional space.
Reference: [26] <author> Raymond Mooney, Jude Shavlik, Geof-frey Towell, and Allen Gove. </author> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In Proceedings of the Eleventh IJCAI , pages 775-780, </booktitle> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Many studies [10] [11] <ref> [26] </ref> [36] compare machine learning and neural network techniques in a supervised environment. Comparing unsupervised classifiers, however, is not as straightforward as comparing supervised classifiers because of the absence of class labels in the experimental classification.
Reference: [27] <author> J.D. Patrick. </author> <title> Snob: A program for discriminating between classes. </title> <type> Technical report TR 151, </type> <institution> Dept. of Computer Science, Monash University, Clayton, </institution> <address> Vic-toria 3168, Australia, </address> <year> 1991. </year>
Reference-contexts: comparable to the expected error in the estimate leads us to the Maximum Likelihood estimate for the parameters given as mean = x and variance = s 2 : Snob implements a heuristic search operation with routines such as adjust, random, split, merge and wipe to find the best classification <ref> [27] </ref>. 2.2 Neural-Net Classifiers The neural networks are highly interconnected networks of simple processing units called neurons.
Reference: [28] <author> Lutz Prechelt. </author> <title> A study of experimental evaluations of neural network learning algorithms: Current research practice. </title> <type> Technical Report 19/94, </type> <institution> Fakultat fur In-formatik, Universitat Karlsruhe, Karl-sruhe, Germany, </institution> <month> August 24 </month> <year> 1994. </year>
Reference-contexts: As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. Lutz Prechelt <ref> [28] </ref> examined 113 journal articles about neural net learning algorithms. Only 6% show results for more than one problem using real-world data. One third present no quantitative comparison with any previous algorithm, and one third use no realistic problem at all [28]. 1.4 Objective The objective of the present work is <p> Lutz Prechelt <ref> [28] </ref> examined 113 journal articles about neural net learning algorithms. Only 6% show results for more than one problem using real-world data. One third present no quantitative comparison with any previous algorithm, and one third use no realistic problem at all [28]. 1.4 Objective The objective of the present work is to perform an impartial and systematic comparison of various unsupervised classifiers by measuring the extent of recovery of the true classification using standard statistics. 2 Algorithms Most unsupervised classification algorithms suit a particular application and hence vary in the degree of
Reference: [29] <author> W. M. Rand. </author> <title> Objective criterion for evaluation of clustering methods. </title> <journal> Journal of American Statistical Association, </journal> <volume> 66 </volume> <pages> 846-851, </pages> <year> 1971. </year>
Reference-contexts: The alternative is to perform a Monte Carlo analysis by generating data separated into well defined classes and study the class recovery for various systems. Most of the Monte Carlo studies <ref> [29] </ref> [22] [23] [25] [17] [20] [2] focus on the cluster analysis techniques. As Dubes et al. [8] note that the trend in AI and the pattern recognition literature has been to ignore the problems of validation and comparison, and focus on applications of these methods. <p> of Table 6.2 we can define a; b; c and d as, X X 2 ; (3) X 2 i j n ij ! c = i n i: ! X X 2 ; (5) 2 2 @ i 2 + j 2 A : (6) We used Rand R <ref> [29] </ref>, corrected Rand R 0 [16], Fowlkes and Mallows F M [12] and Jac card statistic J [24] to compare classifications produced by different algorithms. <p> This approach has been used in various comparisons of clustering algorithms [2] [3] [4] [9] [18] <ref> [29] </ref> [13] [22] [25]. We used a modified form of the data generation algorithm that Milligan et al. used to examine the properties of cluster analy sis algorithms [22], [23], [24], [25]. The algorithm generates externally isolated and internally cohesive classes.
Reference: [30] <author> C. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 24 </volume> <pages> 379-423 and 623-656, </pages> <year> 1948. </year>
Reference-contexts: Shannon's information theory states that the probability p of an event can be encoded (for instance, using Huffman encoding) by a message log (p) bits long <ref> [30] </ref>. Therefore, total message length will be the sum of log P (H) and log P (DjH).
Reference: [31] <author> R Solomonoff. </author> <title> Formal theories of inductive inference I and II. </title> <journal> Information and Control, </journal> <volume> 7 </volume> <pages> 1-22 and 224-254, </pages> <year> 1964. </year>
Reference-contexts: This leads us to formulation of the Bayesian approach to classification [5]. An alternative criterion is that best theory is the one that provides least complex explanation of data <ref> [31] </ref> [34]. Explanation includes both the description of the theory as well as the specification of data given that theory. The minimum message length (MML) approach suggests using information theoretic principles to measure lengths of explanations offered by competing theories and preferring the theory that gives a shorter explanation.
Reference: [32] <author> M. Afzal Upal. </author> <title> Monte carlo comparison of non-hierarchical unsupervised classifiers. </title> <type> Master's thesis, </type> <institution> University Of Saskatchewan, </institution> <year> 1995. </year>
Reference-contexts: We used both ordered and unordered data, where ordered data means that patterns from the same class are placed adjacent to each other and unordered data is the result of randomly perturbing ordered data. 4 Results and Discussion In all, 426 experiments were done. Detailed results are reported in <ref> [32] </ref>. Here we present and discuss the general trends (see Table 3). The classification obtained by all three classifiers is affected by the order of data. ART2 is affected by the order because classification of a pattern depends on the current pattern and the weights learned by classifying previous patterns.
Reference: [33] <author> M. Afzal Upal and Eric Neufeld. </author> <title> Comparison of Bayesian and neural net unsupervised classification techniques. </title> <booktitle> In Proceedings of Sixth Annual Symposium on Computational Science, University of Saskatchewan, </booktitle> <pages> pages 152-163. </pages> <year> 1994. </year>
Reference-contexts: A reasonable approach then is to evaluate the classifications obtained from the classifiers to establish their characteristics as exhibited on the classification of some data sets. In an earlier study <ref> [33] </ref> we studied the classification recovery characteristics of Autoclass and ART2 on real life data sets. The problem with this approach, however, is that the validity of the "original" classification, with which we can compare the classification resulting from an algorithm, is open to question.
Reference: [34] <author> C. S. Wallace and M. P. Georgeff. </author> <title> A general selection criterion for inductive inference. </title> <editor> In T. O'Shea, editor, </editor> <booktitle> Proceedings of ECAI-84: Advances in Artificial Intelligence, </booktitle> <pages> pages 473-482. </pages> <publisher> Elsevier, </publisher> <address> Ams-terdam, </address> <year> 1984. </year>
Reference-contexts: This leads us to formulation of the Bayesian approach to classification [5]. An alternative criterion is that best theory is the one that provides least complex explanation of data [31] <ref> [34] </ref>. Explanation includes both the description of the theory as well as the specification of data given that theory. The minimum message length (MML) approach suggests using information theoretic principles to measure lengths of explanations offered by competing theories and preferring the theory that gives a shorter explanation. <p> Although Snob is differently motivated than Autoclass, both employ the same basic principle. But implementation details vary as Snob does not need to employ the two step process used by Autoclass (i.e., estimating the optimal number of classes and estimating classification parameters) <ref> [34] </ref>. Snob: Snob [35] assumes that the attributes are independently distributed given the classification and that each object X i is independently produced by a random process. This assumption facilitates the computation of the posterior probability of data in Equation 2.
Reference: [35] <author> C.S. Wallace and D.L. Dowe. </author> <title> Intrinsic classification by MML the Snob program. </title> <editor> In C. Zhang, J. Debenham, and D Lukose, editors, </editor> <booktitle> Proceedings of the 7th Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 37-44. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1994. </year>
Reference-contexts: Although Snob is differently motivated than Autoclass, both employ the same basic principle. But implementation details vary as Snob does not need to employ the two step process used by Autoclass (i.e., estimating the optimal number of classes and estimating classification parameters) [34]. Snob: Snob <ref> [35] </ref> assumes that the attributes are independently distributed given the classification and that each object X i is independently produced by a random process. This assumption facilitates the computation of the posterior probability of data in Equation 2.
Reference: [36] <author> Sholom M. Weiss and Ioannis Kapouleas. </author> <title> An empirical comparison of pattern recognition, neural nets, and machine learning classification methods. </title> <editor> In N. S. Sridharan, editor, </editor> <booktitle> Proceedings of the Eleventh IJCAI , pages 781-787, </booktitle> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Many studies [10] [11] [26] <ref> [36] </ref> compare machine learning and neural network techniques in a supervised environment. Comparing unsupervised classifiers, however, is not as straightforward as comparing supervised classifiers because of the absence of class labels in the experimental classification.
References-found: 36

