URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1996/umsi-96-14.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1996/
Root-URL: http://www.cs.umn.edu
Title: High order ILU preconditioners for CFD problems  
Author: Andrew Chapman Yousef Saad Larry Wigton 
Keyword: KEY WORDS Preconditioning Incomplete LU Block LU Dropping stategies Krylov subspace methods  
Date: April 18, 1996  
Abstract: This paper tests a number of ILU-type preconditioners for solving indefinite linear systems which arise from complex applications such as Computational Fluid Dynamics. Both point and block preconditioners are considered. The paper focuses on ILU factorization which can be computed with high accuracy by allowing liberal amounts of fill-in. A number of strategies for enhancing the stability of the factorizations are examined. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew Chapman, and Yousef Saad. </author> <title> Deflated and augmented Krylov subspace techniques Technical Report UMSI 95/181, </title> <institution> Minnesota Supercomputer Institute, </institution> <year> 1995. </year>
Reference-contexts: BSSOR refers to a standard block extension of SSOR, see for example [10]. In deflation, the eigenvectors corresponding to the smallest eigenvalues of the preconditioned matrix are estimated as GMRES progresses, and they are added to the Krylov subspace. For further discussion of deflation see <ref> [6, 1] </ref>. 5 5 Numerical tests The numerical experiments are grouped by sets of matrices. 1 We start our experiments with Harwell-Boeing and FIDAP matrices using only point preconditioners. In the tests the accelerator is GMRES, with a Krylov subspace size of 50.
Reference: [2] <author> Edmond Chow, and Mike Heroux. </author> <title> An object oriented framework for block preconditioning. </title> <type> Technical Report UMSI 95/216, </type> <institution> Minnesota Supercomputer Institute, </institution> <year> 1995. </year>
Reference-contexts: One way of doing this is to use SVD to invert the diagonal blocks, and to vary the threshold tolerance for the singular values <ref> [2] </ref>. If B is a diagonal block to be inverted, the strategy is to replace the smallest eigenvalues or singular values by larger quantities.
Reference: [3] <author> E. Chow and Y. Saad. </author> <title> Approximate inverse preconditioners for general sparse matrices. </title> <type> Technical Report UMSI 94-101, </type> <institution> University of Minnesota Supercomputer Institute, </institution> <address> Minneapolis,MN 55415, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: An easily calculated indicator of instability of the ILU factors is the infinity norm condition estimate k (LU ) 1 ek 1 , where e is a vector of all ones <ref> [3, 4] </ref>. In GMRES the residual norm is calculated as the iteration proceeds (see [11] section 3.2). Iteration is terminated if the calculated residual norm is reduced by more than a convergence tolerance *.
Reference: [4] <author> E. Chow and Y. Saad. </author> <title> Stabilized block ILU preconditioners. </title> <type> Technical Report, </type> <institution> University of Minnesota Supercomputer Institute, Minneapolis, MN 55415, </institution> <note> In preparation. </note>
Reference-contexts: An easily calculated indicator of instability of the ILU factors is the infinity norm condition estimate k (LU ) 1 ek 1 , where e is a vector of all ones <ref> [3, 4] </ref>. In GMRES the residual norm is calculated as the iteration proceeds (see [11] section 3.2). Iteration is terminated if the calculated residual norm is reduced by more than a convergence tolerance *. <p> Then before inverting B any singular value which is less than * 1 is replaced by * 1 where * is a tolerance factor, see e.g. <ref> [4] </ref>. This has the effect of perturbing the matrix B by a matrix whose 2-norm is equal to * 1 , so the norm of the perturbation is of order * when measured relatively to the norm of B.
Reference: [5] <author> J. A. Meijerink, and H. A. van der Vorst. </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix. </title> <journal> Math. Comp., </journal> <volume> 31(137) </volume> <year> 148-162,1977. </year>
Reference-contexts: The corresponding subroutines are discussed briefly below. Also discussed are pivoting and block versions of the subroutines. For more details on these algorithms and their theory, see [10]. ILU (k) is a preconditioner based on a dropping strategy which uses the concept of `level of fill' <ref> [5, 13] </ref>. When k = 0, the standard incomplete LU factorization with no fill-in results.
Reference: [6] <author> R. B. </author> <title> Morgan A restarted GMRES method augmented with eigenvectors. </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 16, </volume> <pages> 1154-1171, </pages> <year> 1996. </year>
Reference-contexts: BSSOR refers to a standard block extension of SSOR, see for example [10]. In deflation, the eigenvectors corresponding to the smallest eigenvalues of the preconditioned matrix are estimated as GMRES progresses, and they are added to the Krylov subspace. For further discussion of deflation see <ref> [6, 1] </ref>. 5 5 Numerical tests The numerical experiments are grouped by sets of matrices. 1 We start our experiments with Harwell-Boeing and FIDAP matrices using only point preconditioners. In the tests the accelerator is GMRES, with a Krylov subspace size of 50.
Reference: [7] <author> W. H. Press, B. P. Flannnery, S. A. Teukolsky, and W. T. Vetterling. </author> <title> Numerical Recipes. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference: [8] <author> Y. Saad. </author> <title> Numerical Methods for Large Eigenvalue Problems. </title> <publisher> Halstead Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference: [9] <author> Y. </author> <title> Saad A dual threshold incomplete LU factorization. </title> <journal> Num. Lin. Alg. Appl., </journal> <volume> 1 (1994), </volume> <pages> pp. 387-402. </pages>
Reference-contexts: Entries in the original matrix are defined to have a level of fill of zero. The preconditioner ILU (k) retains entries with level of fill up to, and including, k. The higher the value of k, the more entries retained. ILUT uses a dual truncation dropping strategy developed in <ref> [9] </ref>. This is controlled by two parameters, a threshold drop tolerance tol, and a fill number lf il.
Reference: [10] <author> Y. Saad. </author> <title> Iterative Methods for Sparse Linear Systems. </title> <publisher> PWS publishing, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: The different ILU techniques differ in these dropping strategies. The corresponding subroutines are discussed briefly below. Also discussed are pivoting and block versions of the subroutines. For more details on these algorithms and their theory, see <ref> [10] </ref>. ILU (k) is a preconditioner based on a dropping strategy which uses the concept of `level of fill' [5, 13]. When k = 0, the standard incomplete LU factorization with no fill-in results. <p> These discarded fill-ins are summed up as they are dropped, and in diagonal compensation, a multiple ff of this sum is added to the diagonal entry of U . This is often referred to as Modified ILU, or MILU <ref> [10] </ref>. ILUTP and ILUDP are the same as ILUT and ILUD respectively, but add threshold column pivoting. Here two columns are permuted when ja (i; j)j fl pivthresh &gt; ja (i; i)j, where pivthresh is the pivot threshold. <p> BSSOR refers to a standard block extension of SSOR, see for example <ref> [10] </ref>. In deflation, the eigenvectors corresponding to the smallest eigenvalues of the preconditioned matrix are estimated as GMRES progresses, and they are added to the Krylov subspace.
Reference: [11] <author> Y. Saad and M. H. Schultz. </author> <title> GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7, </volume> <pages> 856-869, </pages> <year> 1986. </year>
Reference-contexts: An easily calculated indicator of instability of the ILU factors is the infinity norm condition estimate k (LU ) 1 ek 1 , where e is a vector of all ones [3, 4]. In GMRES the residual norm is calculated as the iteration proceeds (see <ref> [11] </ref> section 3.2). Iteration is terminated if the calculated residual norm is reduced by more than a convergence tolerance *. The calculation is not always correct, due to roundoff errors, and this can lead to early termination. Examples are given where this occurs.
Reference: [12] <author> Yousef Saad and Kesheng Wu. DQGMRES: </author> <title> a quasi-minimal residual algorithm based on incomplete orthogonalization Technical Report UMSI 93/131, </title> <institution> Minnesota Supercomputer Institute, </institution> <year> 1993. </year>
Reference-contexts: Examples are given where this occurs. For some matrices row and column scaling can significantly improve the performance of the iterative solver, while for others scaling leads to worse performance. It was argued in <ref> [12] </ref> that if scaling results in a deterioration of the degree of normality of the matrix, measured by the number kAA T A T Ak=kAA T k, this will result in worse performance. Examples are given where scaling improves and hinders performance.
Reference: [13] <author> J. W. Watts-III. </author> <title> A conjugate gradient truncated direct method for the iterative solution of the reservoir simulation pressure equation. </title> <journal> Society of Petroleum Engineer Journal, </journal> <volume> 21 </volume> <pages> 345-353, </pages> <year> 1981. </year>
Reference-contexts: The corresponding subroutines are discussed briefly below. Also discussed are pivoting and block versions of the subroutines. For more details on these algorithms and their theory, see [10]. ILU (k) is a preconditioner based on a dropping strategy which uses the concept of `level of fill' <ref> [5, 13] </ref>. When k = 0, the standard incomplete LU factorization with no fill-in results.
References-found: 13

