URL: http://www.eecs.umich.edu/PPP/CSE-TR-111-91.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Title: Efficient Simulation of Multiple Cache Configurations using Binomial Trees  
Author: Rabin A. Sugumar and Santosh G. Abraham 
Keyword: Key Words: Trace-driven simulation, direct mapped caches, set associative caches, binomial tree, inclusion properties, single-pass simulation, cache modeling  
Address: 1991)  Ann Arbor, MI 48109-2122.  
Affiliation: CSE Division, University of Michigan,  Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Pubnum: (Technical Report CSE-TR-111-91,  
Abstract: Simulation time is often the bottleneck in the cache design process. In this paper, algorithms for the efficient simulation of direct mapped and set associative caches are presented. Two classes of direct mapped caches are considered: fixed line size caches and fixed size caches. A binomial tree representation of the caches in each class is introduced. The fixed line size class is considered for set associative caches. A generalization of the binomial tree data structure is introduced and the fixed line size class of set associative caches is represented using the generalized binomial tree. Algorithms are developed that use the data structures to determine miss ratios for the caches in each class. Analytical and empirical comparisons of the algorithms to previously published algorithms such as all-associativity and forest simulation are presented. Analytically it is shown that the new algorithms always perform better than earlier algorithms. Empirically, the new algorithms are shown to outperform earlier ones by factors of 1:0 to 5:0. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Analysis of Cache Performance for Operating Systems and Multiprogramming. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1988. </year> <note> Available as Technical Report CSL-TR-87-332. </note>
Reference-contexts: Table 1. The average number of comparisons approaches 3 as the loop size increases. When the smallest line size is greater than one word, the average number of comparisons is less than two. Practical traces consist of interleaved runs of successive addresses <ref> [1] </ref>. All misses and hits occurring on references to starting addresses of runs may be modeled as random accesses. The loop model may be used for hits that occur on references to second and later references in runs. <p> A duality between spatial and temporal locality is demonstrated. It is argued that the classes of caches considered correspond to different trade-offs: spatial locality temporal locality and locality cost. Considerable research has been done on developing models for program behavior <ref> [14, 16, 15, 1] </ref>. Recent work has focused on access patterns of workloads in order to develop effective memory hierarchies. Many analytic models do not consider the constraints such as bit selection, under which caches and memory hierarchies are designed.
Reference: [2] <author> A. Borg, R. E. Kessler, and D. W. Wall. </author> <title> Generation and analysis of very long address traces. </title> <booktitle> In Proc. of 17th Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 270-279, </pages> <year> 1990. </year>
Reference-contexts: The second factor contributing to big traces is the difference in trace characteristics in different phases of the program. When cache evaluation is done with a small trace representing one phase of the program, the results are not reliable. This is illustrated in <ref> [2] </ref>. Complete traces of workloads, billions of addresses long, are simulated and it is shown that if smaller segments of the complete traces are used, the results can vary greatly depending on which segment of the trace is simulated.
Reference: [3] <author> M. R. Brown. </author> <title> Implementation and analysis of binomial queue algorithms. </title> <journal> SIAM J. of Computing, </journal> <volume> 7 </volume> <pages> 298-319, </pages> <year> 1978. </year>
Reference-contexts: the least significant bit which match in a and b) Initialize () Build 2 S binomial trees from 2 S+M sets (Using the combining procedure, assuming arbitrary ordering) Set all tags to invalid 13 14 Implementation Issues Implementations of binomial forests based on binary trees are given in [17] and <ref> [3] </ref>. But these implementations take up pointer space and incur high overheads for manipulation. Below we describe an array implementation of the binomial forest that is based on Property 1. In the array implementation each binomial tree is represented as a one-dimensional array. The forest is a two-dimensional array.
Reference: [4] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture | A Quantitive Approach. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1990. </year>
Reference-contexts: Since the time to access the cache is usually much lower than the time to access main memory, caches help decrease the effective memory access time. There are excellent discussions on caches in the literature, for instance <ref> [13, 4] </ref>. In this paper new techniques for the efficient simulation of caches are presented. These techniques are expected to be helpful in the cache design process. <p> Such a collection of cache designs is expected to occur frequently in the design process, because important constraints for physical (and virtual) caches fixes the primary cache size to the virtual memory page size <ref> [4] </ref>. The algorithm uses a novel inclusion property between tag stores. A method for simulating set associative caches of varying numbers of sets and varying associativities is described by Mattson et. al. [9]. This algorithm assumes that the set mapping is done by bit selection.
Reference: [5] <author> M. D. Hill. </author> <title> Man page of tycho. </title>
Reference-contexts: On the average GFS performs better than all-associativity simulation. The GBT algorithm outperforms GFS by about a factor of 1:4 on the average. We also did simulation runs using Tycho, which is a software package for doing all-associativity simulation <ref> [5] </ref>. As noted before, there is overhead associated with such packages.
Reference: [6] <author> M. D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1987. </year> <note> Available as Technical Report UCB/CSD 87/381. </note>
Reference-contexts: But the smallest cache containing the line at a set of rank M d is C L S+d , and forest simulation takes at least d + 1 comparisons. 16 In <ref> [6] </ref> the expected number of comparisons required by forest simulation is given as 1 + m 0 + i=1 where m i is the miss ratio for cache C L S+i .
Reference: [7] <author> M. D. Hill and A. J. Smith. </author> <title> Evaluating associativity in CPU caches. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 38(12) </volume> <pages> 1612-1630, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: For each incoming address, caches are examined in increasing order of size. By the inclusion property, once the address is known to hit a cache, the address will also hit in all bigger caches. Hill and Smith present the forest simulation algorithm in <ref> [7] </ref>, for simulating direct mapped caches of varying sizes but fixed line size. This algorithm also uses an inclusion property. Caches are searched from the smallest to the largest for each incoming address and the search is stopped once the address hits in a cache. <p> This algorithm assumes that the set mapping is done by bit selection. This algorithm is generalized to work for set mapping functions other than bit selection by Hill and Smith <ref> [7] </ref> and is referred to as all-associativity simulation in the following. In Section 3 we present an algorithm to simulate the same class of set associative caches using a generalized form of the binomial tree. <p> Corollary 2 [C L S 1 ] lines [C L S 2 ] lines , if S 1 S 2 . Corollary 2 above is the same as Corollary 5 of Theorem 1 in <ref> [7] </ref>. The inclusion property of Corollary 2 is exploited in forest simulation [7]. In forest simulation for each of the caches being simulated, a separate array with the contents of the tag-store is maintained. 3 A hit-array with one entry for each cache is also maintained. <p> Corollary 2 [C L S 1 ] lines [C L S 2 ] lines , if S 1 S 2 . Corollary 2 above is the same as Corollary 5 of Theorem 1 in <ref> [7] </ref>. The inclusion property of Corollary 2 is exploited in forest simulation [7]. In forest simulation for each of the caches being simulated, a separate array with the contents of the tag-store is maintained. 3 A hit-array with one entry for each cache is also maintained. <p> Corollary 2 [C L S 1 (n)] lines [C L S 2 (n)] lines , if S 1 S 2 . Corollary 1 is the sufficient part of Theorem 1 in <ref> [7] </ref> except that bit selection is assumed here. It states an inclusion property between caches in this class. This inclusion property can be used to develop an algorithm similar to forest simulation [7], referred to as generalized forest simulation (GFS) in the following. <p> Corollary 1 is the sufficient part of Theorem 1 in <ref> [7] </ref> except that bit selection is assumed here. It states an inclusion property between caches in this class. This inclusion property can be used to develop an algorithm similar to forest simulation [7], referred to as generalized forest simulation (GFS) in the following. In GFS a separate two-dimensional array is 28 maintained for each cache. The set number varies along one dimension and for each set number there is an array of entries. <p> If it hits at depth one in any cache, then subsequent caches need not be searched. We call this generalized forest simulation (GFS) in the discussion that follows. All-associativity simulation <ref> [9, 7] </ref> is another algorithm for the simulation of this class of set-associative caches. It works as follows: Consider two caches, C L S 1 (n) and C L S 1 &lt; S 2 . <p> Lemma 3 can be used to develop a data structure for the class of set associative caches under consideration using an approach similar to the one in the previous section. Consider 10 This property is called set refinement in <ref> [7] </ref>. 11 Determination of whether a line in C L S 1 (n) maps to the same set as a in C L S 2 (n) is done using the right-match function. 29 30 the lines in a cache C L S+2 (n).
Reference: [8] <author> S. Laha, J. H. Patel, and R. K. Iyer. </author> <title> Accurate low-cost methods for performance evaluation of cache memory systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37(11):1925-1936, </volume> <month> November </month> <year> 1988. </year>
Reference-contexts: Wang and Baer [18] suggest obtaining a universal reduced trace which is a union of reduced traces for various line sizes. They note that this universal reduced trace is only about 50% bigger than a single line size reduced trace. Laha et.al. <ref> [8] </ref> present a sampling technique to obtain reduced traces that approximate the behavior of the original trace. The single-pass simulation approach is complementary to the reduced trace approach.
Reference: [9] <author> R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Traiger. </author> <title> Evaluation techniques for storage hierarchies. </title> <journal> IBM Systems Journal, </journal> <volume> 9(2) </volume> <pages> 78-117, </pages> <year> 1970. </year>
Reference-contexts: The single pass simulation methods reviewed in this section and those introduced in the paper utilize inclusion properties within certain classes of caches and are more efficient than this naive algorithm. The initial work on single pass simulation of memory hierarchies was done by Mattson et al., <ref> [9] </ref> at IBM in the context of virtual-memory systems. They describe an algorithm for simulating a range of fully associative caches of varying sizes but fixed line size. <p> The algorithm uses a novel inclusion property between tag stores. A method for simulating set associative caches of varying numbers of sets and varying associativities is described by Mattson et. al. <ref> [9] </ref>. This algorithm assumes that the set mapping is done by bit selection. This algorithm is generalized to work for set mapping functions other than bit selection by Hill and Smith [7] and is referred to as all-associativity simulation in the following. <p> If it hits at depth one in any cache, then subsequent caches need not be searched. We call this generalized forest simulation (GFS) in the discussion that follows. All-associativity simulation <ref> [9, 7] </ref> is another algorithm for the simulation of this class of set-associative caches. It works as follows: Consider two caches, C L S 1 (n) and C L S 1 &lt; S 2 .
Reference: [10] <author> S. A. Przybylski. </author> <title> Performance Directed Memory hierarchy Design. </title> <type> PhD thesis, </type> <institution> Stan-ford University, </institution> <year> 1988. </year>
Reference-contexts: In Section 3 an algorithm is presented that uses data inclusion properties to simulate multiple configurations of direct mapped caches with fixed line size and varying number of sets. A dual algorithm is then presented that uses tag 1 Line size and fetch size are used as defined in <ref> [10] </ref>. Line (Block) size is the unit of data for which there is an address tag. Fetch size is the number of bytes fetched on a miss. 3 inclusion properties to simulate direct mapped caches with fixed size and varying line size.
Reference: [11] <author> T. R. Puzak. </author> <title> Analysis of Cache Replacement Algorithms. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1985. </year>
Reference-contexts: Another technique for speeding up simulation is to use reduced traces. A reduced trace is obtained by passing the original trace through a filter. The reduced trace is significantly smaller than the original trace but has sufficient information to give accurate results for the caches of interest. In <ref> [11] </ref> a technique along these lines is presented for simulating direct mapped and set associative caches of a fixed line size. But the results are not accurate if caches of a different line size are simulated.
Reference: [12] <author> D. R. Slutz and I. L. Traiger. </author> <title> One pass techniques for the evaluation of memory hierarchies. </title> <type> Technical Report RJ892, </type> <institution> IBM, </institution> <year> 1971. </year> <month> 44 </month>
Reference-contexts: The new algorithm takes fewer comparisons than forest simulation on the average. Single-pass simulation of caches with varying line sizes has not been considered much 4 in the literature. The only work that the authors are aware of is that of Slutz and Traiger <ref> [12] </ref>, where the original algorithm of Mattson et al. is extended to handle multiple line sizes. In Section 2 we present an algorithm based on the binomial tree to simulate direct mapped caches of the same size but varying line sizes in one pass.
Reference: [13] <author> A. J. Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> Sept </month> <year> 1982. </year>
Reference-contexts: Since the time to access the cache is usually much lower than the time to access main memory, caches help decrease the effective memory access time. There are excellent discussions on caches in the literature, for instance <ref> [13, 4] </ref>. In this paper new techniques for the efficient simulation of caches are presented. These techniques are expected to be helpful in the cache design process.
Reference: [14] <author> J. R. Spirn. </author> <title> Program Behaviour: </title> <booktitle> Models and Measurement. </booktitle> <address> New York: Elsevier/North-Holland, </address> <year> 1977. </year>
Reference-contexts: A duality between spatial and temporal locality is demonstrated. It is argued that the classes of caches considered correspond to different trade-offs: spatial locality temporal locality and locality cost. Considerable research has been done on developing models for program behavior <ref> [14, 16, 15, 1] </ref>. Recent work has focused on access patterns of workloads in order to develop effective memory hierarchies. Many analytic models do not consider the constraints such as bit selection, under which caches and memory hierarchies are designed.
Reference: [15] <author> H. S. Stone. </author> <title> High-Performance Computer Architecture. </title> <publisher> Addison-Wesley, </publisher> <address> 2 nd edition, </address> <year> 1987. </year>
Reference-contexts: A duality between spatial and temporal locality is demonstrated. It is argued that the classes of caches considered correspond to different trade-offs: spatial locality temporal locality and locality cost. Considerable research has been done on developing models for program behavior <ref> [14, 16, 15, 1] </ref>. Recent work has focused on access patterns of workloads in order to develop effective memory hierarchies. Many analytic models do not consider the constraints such as bit selection, under which caches and memory hierarchies are designed.
Reference: [16] <author> D. Thiebaut. </author> <title> On the fractal dimension of computer programs and its application to the prediction of the cache miss ratio. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 38(7) </volume> <pages> 1012-1026, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: A duality between spatial and temporal locality is demonstrated. It is argued that the classes of caches considered correspond to different trade-offs: spatial locality temporal locality and locality cost. Considerable research has been done on developing models for program behavior <ref> [14, 16, 15, 1] </ref>. Recent work has focused on access patterns of workloads in order to develop effective memory hierarchies. Many analytic models do not consider the constraints such as bit selection, under which caches and memory hierarchies are designed.
Reference: [17] <author> J. Vuillemin. </author> <title> A data structure for manipulating priority queues. </title> <journal> Comm. of the ACM, </journal> <volume> 21 </volume> <pages> 309-315, </pages> <year> 1978. </year>
Reference-contexts: This combining may be done recursively so that, at each stage the contents of the sets at the top represent the contents of some smaller cache. The structure that results from such a combining procedure is a forest of binomial trees. Binomial trees may be defined inductively as follows <ref> [17] </ref> (Fig. 2): A binomial tree of degree 4 0 (B 0 in Fig. 2) has one node. <p> starting from the least significant bit which match in a and b) Initialize () Build 2 S binomial trees from 2 S+M sets (Using the combining procedure, assuming arbitrary ordering) Set all tags to invalid 13 14 Implementation Issues Implementations of binomial forests based on binary trees are given in <ref> [17] </ref> and [3]. But these implementations take up pointer space and incur high overheads for manipulation. Below we describe an array implementation of the binomial forest that is based on Property 1. In the array implementation each binomial tree is represented as a one-dimensional array.
Reference: [18] <author> W-H. Wang and J-L. Baer. </author> <title> Efficient trace-driven simulation methods for cache performance analysis. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> pages 27-36, </pages> <year> 1990. </year>
Reference-contexts: In [11] a technique along these lines is presented for simulating direct mapped and set associative caches of a fixed line size. But the results are not accurate if caches of a different line size are simulated. Wang and Baer <ref> [18] </ref> suggest obtaining a universal reduced trace which is a union of reduced traces for various line sizes. They note that this universal reduced trace is only about 50% bigger than a single line size reduced trace.
References-found: 18

