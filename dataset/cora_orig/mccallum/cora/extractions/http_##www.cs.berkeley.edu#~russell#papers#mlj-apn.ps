URL: http://www.cs.berkeley.edu/~russell/papers/mlj-apn.ps
Refering-URL: http://www.cs.berkeley.edu/~russell/publications.html
Root-URL: 
Title: Adaptive Probabilistic Networks with Hidden Variables  
Author: JOHN BINDER DAPHNE KOLLER STUART RUSSELL Editor: Padhraic Smyth 
Keyword: Bayesian networks, gradient descent, prior knowledge, dynamic networks, hybrid networks  
Address: Berkeley, CA 94720-1776  Stanford, CA 94305-9010  Berkeley, CA 94720-1776 KEIJI KANAZAWA  One Microsoft Way, Redmond, WA 98052-6399  
Affiliation: Computer Science Division, University of California,  Computer Science Department, Stanford University,  Computer Science Division, University of California,  Microsoft Corporation,  
Note: 1-34 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Email: binder@cs.berkeley.edu  koller@cs.stanford.edu  russell@cs.berkeley.edu  keijik@microsoft.com  
Date: Received July 23, 1996; Revised March 24, 1997  
Abstract: Probabilistic networks (also known as Bayesian belief networks) allow a compact description of complex stochastic relationships among several random variables. They are used widely for uncertain reasoning in artificial intelligence. In this paper, we investigate the problem of learning probabilistic networks with known structure and hidden variables. This is an important problem, because structure is much easier to elicit from experts than numbers, and the world is rarely fully observable. We present a gradient-based algorithm and show that the gradient can be computed locally, using information that is available as a byproduct of standard inference algorithms for probabilistic networks. Our experimental results demonstrate that using prior knowledge about the structure, even with hidden variables, can significantly improve the learning rate of probabilistic networks. We extend the method to networks in which the conditional probability tables are described using a small number of parameters. Examples include noisy-OR nodes and dynamic probabilistic networks. We show how this additional structure can be exploited by our algorithm to speed up the learning even further. We also outline an extension to hybrid networks, in which some of the nodes take on values in a continuous domain. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Andersen, S. K., Olesen, K. G., Jensen, F. V., & Jensen, F. </author> <year> (1989). </year> <title> HUGIN|a shell for building Bayesian belief universes for expert systems. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <volume> Vol. 2, </volume> <pages> pp. 1080-1085. </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This uses repeated line minimizations (with direction chosen by the Polak-Ribiere method) and a heuristic termination condition to signal a maximum. We use the Hugin package <ref> (Andersen, Olesen, Jensen, & Jensen, 1989) </ref>, which uses a clustering algorithm, for most of the inference computations. 5.3. Experimental evaluation In this section, we report on two experiments. The first shows the importance of prestructuring the probabilistic network using hidden variables.
Reference: <author> Apolloni, B. & de Falco, D. </author> <year> (1991). </year> <title> Learning by asymmetric parallel Boltzmann machines. </title> <journal> Neural Computation, </journal> <volume> 3 (3), </volume> <pages> 402-408. </pages>
Reference: <author> Baum, E. B. & Wilczek, F. </author> <year> (1988). </year> <title> Supervised learning of probability distributions by neural networks. </title> <editor> In Anderson, D. Z. (Ed.), </editor> <booktitle> Neural Information Processing Systems, </booktitle> <pages> pp. 52-61. </pages> <institution> American Institute of Physics, </institution> <address> New York. </address>
Reference-contexts: Reported results were then averaged over the ten training sets at each training set size. Prediction performance for the APN algorithm was compared against that of a feedforward neural network. The neural network was trained using the update rule for cross-entropy minimization <ref> (Baum & Wilczek, 1988) </ref>, which allows the output unit values to be interpreted as probabilities. To ensure that the distribution over the output units for each output variable summed to 1, the output layer used the softmax parameterization (Bridle, 1990).
Reference: <author> Bishop, C. M. </author> <year> (1995). </year> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference: <author> Bridle, J. S. </author> <year> (1990). </year> <title> Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. </title> <editor> In Fogelman Soulie, F. & Herault, J. (Eds.), Neurocomputing: </editor> <booktitle> Algorithms, Architectures and Applications. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: To ensure that the distribution over the output units for each output variable summed to 1, the output layer used the softmax parameterization <ref> (Bridle, 1990) </ref>. Because a feedforward neural network 13 does not represent correlations among output nodes, the joint probability on the output variables was approximated by the product of the marginals from the output units. <p> Since the function being maximized is a likelihood, the EM algorithm can also be used, as discussed in Section 7. 4. One can also use the softmax reparameterization <ref> (Bridle, 1990) </ref> which uses exp (fi) instead of fi 2 . 5. It is possible to compute the gradient for the likelihood of specified output variables, rather than for the likelihood of all the variables. This form of optimization is discussed by Spiegelhalter and Cowell (1992). 6.
Reference: <author> Buntine, W. L. </author> <year> (1994). </year> <title> Operations for learning with graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2, </volume> <pages> 159-225. </pages>
Reference: <author> Buntine, W. L. </author> <year> (1996). </year> <title> A guide to the literature on learning probabilistic networks from data. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8, </volume> <pages> 195-210. </pages>
Reference: <author> Cooper, G. & Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 309-347. </pages> <address> 32 Daganzo, C. </address> <year> (1979). </year> <title> Multinomial probit: The theory and its application to demand forecasting. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Dasgupta, S. </author> <year> (1997). </year> <title> The sample complexity of learning Bayesian nets. </title> <journal> Machine Learning, </journal> <note> this issue. </note>
Reference: <author> Dean, T. & Kanazawa, K. </author> <year> (1988). </year> <title> Probabilistic temporal reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> pp. 524-528. </pages> <address> St. Paul, Minnesota: </address> <booktitle> American Association for Artificial Intelligence. </booktitle>
Reference-contexts: As expected, the noisy-OR model results in faster learning than the corresponding model with explicitly represented CPTs. 6.3. Dynamic probabilistic networks One of the most important applications of Equation 5 is in learning the behavior of stochastic temporal processes. Such processes are typically represented using dynamic probabilistic networks (DPNs) <ref> (Dean & Kanazawa, 1988) </ref>. A DPN is structured as a sequence of time slices, where the nodes at each slice encode the state at the corresponding time point. Figure 8 shows the coarse structure of a generic DPN.
Reference: <author> Dempster, A., Laird, N., & Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 39 (Series B), </volume> <pages> 1-38. </pages>
Reference-contexts: Thiesson (1995b) analyzes this class of models, which he calls recursive exponential models (REMs). DPN models can be viewed as a special case of REMs. For the specific case of maximizing likelihood by altering parameters of a probability distribution, the EM (Expectation Maximization) algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref> can be used. This observation was made by Lauritzen (1991, 1995), who discussed its application to general probabilistic networks (see also Spiegel-halter et al., 1993; Olesen et al., 1992; Spiegelhalter & Cowell, 1992; Heckerman, 1995).
Reference: <author> Finney, D. J. </author> <year> (1947). </year> <title> Probit analysis; a statistical treatment of the sigmoid response curve. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: Neal (1992b) has investigated the learning of sigmoid models in belief networks. In statistics, models for discrete choices dependent on continuous variables include both the sigmoid model (often called the logit model) and the probit model, which is the cumulative distribution of the normal density function <ref> (Finney, 1947) </ref>. The use of the probit model in our example can be justified by positing a random, normally distributed noise process that interferes with the consumer's pure price comparison by imposing extra costs or benefits on the purchasing decision.
Reference: <author> Friedman, N., Geiger, D., & Goldszmidt, M. </author> <year> (1997). </year> <title> Bayesian network classifiers. </title> <journal> Machine Learning, </journal> <note> this issue. </note>
Reference: <author> Friedman, N. & Goldszmidt, M. </author> <year> (1996). </year> <title> Learning Bayesian networks with local structure. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Twelfth Conference, </booktitle> <pages> pp. 252-262. </pages> <address> Port-land, Oregon: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Friedman, N. & Yakhini, M. </author> <year> (1996). </year> <title> On the sample complexity of learning Bayesian networks. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Twelfth Conference, </booktitle> <pages> pp. 274-282. </pages> <address> Portland, Oregon: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fung, R. & Chang, K. C. </author> <year> (1989). </year> <title> Weighting and integrating evidence for stochastic simulation in Bayesian networks. </title> <booktitle> In Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI-89). </booktitle> <address> Windsor, Ontario: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Geiger, D., Heckerman, D., & Meek, C. </author> <year> (1996). </year> <title> Asymptotic model selection for directed networks with hidden variables. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Twelfth Conference, </booktitle> <pages> pp. 283-290. </pages> <address> Portland, Oregon: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Ghahramani, Z. & Jordan, M. I. </author> <year> (1997). </year> <title> Factorial hidden Markov models. </title> <journal> Machine Learning, </journal> <note> this issue. </note>
Reference: <author> Golmard, J.-L. & Mallet, A. </author> <year> (1991). </year> <title> Learning probabilities in causal trees from incomplete databases. </title> <journal> Revue d'Intelligence Artificielle, </journal> <volume> 5, </volume> <pages> 93-106. </pages>
Reference: <author> Haddawy, P. </author> <year> (1994). </year> <title> Generating Bayesian networks from probability logic knowledge bases. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <pages> pp. 262-269. </pages> <address> Seattle, Washington: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning with Bayesian networks. </title> <type> Technical report MSR-TR-95-06, </type> <institution> Microsoft Research, </institution> <address> Redmond, Washington. </address> <month> Revised June </month> <year> 1996. </year>
Reference-contexts: Probabilistic networks have been shown to perform well in complex decision-making domains such as medical diagnosis, fault diagnosis, image analysis, natural language understanding, robot control, and real-time monitoring <ref> (see, e.g., Heckerman & Wellman, 1995) </ref>. While the compact and natural representation considerably facilitates knowledge acquisition, the process of eliciting a probabilistic network from experts is still a slow one, largely due to the need to obtain numerical parameters. <p> Like gradient descent, EM can be used to find local maxima on the likelihood surface defined by the network parameters. EM can also be used in the context of maximum a posteriori (MAP) learning, where we have a prior over the set of parameters <ref> (Heckerman, 1995) </ref>. Thiesson (1995a) shows that a similar analysis can be used to do MAP learning with gradient-based methods. EM can be shown to converge faster than simple gradient ascent, but the comparison between EM and conjugate gradient remains unclear.
Reference: <author> Heckerman, D., Geiger, D., & Chickering, M. </author> <year> (1994). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <type> Technical report MSR-TR-94-09, </type> <institution> Microsoft Research, </institution> <address> Redmond, Washington. </address>
Reference: <author> Heckerman, D. & Wellman, M. </author> <year> (1995). </year> <title> Bayesian networks. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 38 (3), </volume> <pages> 27-30. </pages>
Reference-contexts: Probabilistic networks have been shown to perform well in complex decision-making domains such as medical diagnosis, fault diagnosis, image analysis, natural language understanding, robot control, and real-time monitoring <ref> (see, e.g., Heckerman & Wellman, 1995) </ref>. While the compact and natural representation considerably facilitates knowledge acquisition, the process of eliciting a probabilistic network from experts is still a slow one, largely due to the need to obtain numerical parameters. <p> Like gradient descent, EM can be used to find local maxima on the likelihood surface defined by the network parameters. EM can also be used in the context of maximum a posteriori (MAP) learning, where we have a prior over the set of parameters <ref> (Heckerman, 1995) </ref>. Thiesson (1995a) shows that a similar analysis can be used to do MAP learning with gradient-based methods. EM can be shown to converge faster than simple gradient ascent, but the comparison between EM and conjugate gradient remains unclear.
Reference: <author> Koller, D. & Pfeffer, A. </author> <year> (1996). </year> <title> Learning the parameters of first order probabilistic rules. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Learning Complex Behaviors in Adaptive Intelligent Systems Cambridge, </booktitle> <address> Massachusetts. </address>
Reference: <author> Kwoh, C.-K. & Gillies, D. F. </author> <year> (1996). </year> <title> Using hidden nodes in Bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 88 (1-2), </volume> <pages> 1-38. </pages>
Reference: <author> Laskey, K. B. </author> <year> (1990). </year> <title> Adapting connectionist learning to Bayes networks. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4, </volume> <pages> 261-282. </pages>
Reference: <author> Lauritzen, S. L. </author> <year> (1995). </year> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 19, </volume> <pages> 191-201. </pages>
Reference: <author> Lauritzen, S. L. & Wermuth, N. </author> <year> (1989). </year> <title> Graphical models for associations between variables, some of which are qualitative and some quantitative. </title> <journal> Annals of Statistics, </journal> <volume> 17, </volume> <pages> 31-57. </pages>
Reference-contexts: For example, as we mentioned above, probabilistic networks can also contain continuous-valued nodes. The "CPT" for such nodes must be parametrically defined, for example as a Gaussian distribution with parameters for the mean and the variance <ref> (Lauritzen & Wermuth, 1989) </ref>. Dynamic probabilistic networks, which are potentially infinite networks that 17 represent temporal processes, also require a parametrized representation. This is because the parameters that encode the stochastic model of state evolution appear many times in the network. <p> The conditional density is then defined by the parameters of the linear function and the variance. 7 In a conditional Gaussian (CG) distribution <ref> (Lauritzen & Wermuth, 1989) </ref>, which describes the case where a continuous node has both discrete and continuous par ents, one set of parameters is provided for each possible instantiation of the discrete parents.
Reference: <author> Lauritzen, S. L. </author> <year> (1991). </year> <title> The EM algorithm for graphical association models with missing data. </title> <type> Technical report TR-91-05, </type> <institution> Department of Statistics, Aalborg University. </institution>
Reference: <author> Lauritzen, S. L. & Spiegelhalter, D. J. </author> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50 (2), </volume> <pages> 157-224. </pages> <note> 33 MacKay, </note> <author> D. J. C. </author> <year> (1992). </year> <title> A practical Bayesian framework for back-propagation networks. </title> <journal> Neural Computation, </journal> <volume> 4 (3), </volume> <pages> 448-472. </pages>
Reference-contexts: However, a number of algorithms have been developed that take advantage of network structure to perform the inference process effectively, often allowing the solution of large networks in practice. The most widely used algorithms for exact inference are clustering algorithhms <ref> (Lauritzen & Spiegelhalter, 1988) </ref>, which modify the network topology, transforming it into a Markov random field. 1 Stochastic simulation algorithms have also been developed (e.g., Shachter & Peot, 1989; Fung & Chang, 1989), allowing for an anytime approximation of the solution. <p> We are therefore able to use standard probabilistic network packages as a substrate for our learning system. For example, clustering algorithms <ref> (Lauritzen & Spiegelhalter, 1988) </ref> compute a posterior for each clique in the Markov network corresponding to the original probabilistic network. Because a node and its parents always appear together in at least one clique, the required probabilities can be found by summing out the other variables in that clique.
Reference: <author> Neal, R. M. </author> <year> (1992a). </year> <title> Asymmetric parallel Boltzmann machines are belief networks. </title> <journal> Neural Computation, </journal> <volume> 4 (6), </volume> <pages> 832-834. </pages>
Reference: <author> Neal, R. M. </author> <year> (1992b). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56, </volume> <pages> 71-113. </pages>
Reference: <author> Neal, R. M. & Hinton, G. E. </author> <year> (1993). </year> <title> A new view of the EM algorithm that justifies incremental and other variants. </title> <type> Unpublished manuscript. </type>
Reference-contexts: However, for more complex problems with generalized parameters, the M-step may itself require an iterative optimization algorithm. Dempster et al. discuss generalized EM (GEM) algorithms that execute only a partial M-step; as long as this step increases the likelihood, the algorithm will converge <ref> (Neal & Hinton, 1993) </ref>. Thus, a gradient-based approach is closely related to a GEM algorithm. There has also been some work on the more complex problem of learning with hidden variables when the structural properties of the network are not all known.
Reference: <author> Ngo, L., Haddawy, P., & Helwig, J. </author> <year> (1995). </year> <title> A theoretical framework for context-sensitive temporal probability model construction with application to plan projection. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Eleventh Conference, </booktitle> <pages> pp. 419-426. </pages> <address> Montreal, Canada: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Olesen, K. G., Lauritzen, S. L., & Jensen, F. V. </author> <year> (1992). </year> <title> aHUGIN: A system for creating adaptive causal probabilistic networks. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Eighth Conference. </booktitle> <address> Stanford, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: For example, given observations and test results, one can compute the probability that the patient has lung cancer. Unfortunately, an explicit description of the joint distribution requires a number of parameters that is exponential in n, the number of variables. Probabilistic networks <ref> (Pearl, 1988) </ref> derive their power from the ability to represent conditional independences among variables, which allows them to take advantage of the "locality" of causal influences. Intuitively, a variable is independent of its indirect causal influences given its direct causal influences. <p> More precisely, H (P fl ; P w ) = e;y To compute the joint probability of the output variables using a standard probabilistic network inference algorithm, we can decompose it into marginals using the chain rule <ref> (Pearl, 1988, p.226) </ref>: P w (y j e) = i 5.3.2. Methodology and comparison algorithm Data were generated randomly from a target probabilistic network and then partitioned into training and test sets. The training data was used to train probabilistic networks that were initialized with random parameter values.
Reference: <author> Poggio, T. & Girosi, F. </author> <year> (1990). </year> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247, </volume> <pages> 978-982. </pages>
Reference-contexts: It is straightforward to extend the methods described below to solve this problem, as shown by Thiesson (1995a). This extension can also be performed for feedforward neural networks| the so-called regularization method <ref> (e.g., Poggio & Girosi, 1990) </ref>. Finally, it is possible to perform a full Bayesian analysis, which uses the posterior distribution over the weights, P (w j D), to make predictions for new cases by integrating over the predictions made for each possible weight setting.
Reference: <author> Pradhan, M., Provan, G. M., Middleton, B., & Henrion, M. </author> <year> (1994). </year> <title> Knowledge engineering for large belief networks. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <pages> pp. 484-490. </pages> <address> Seattle, Washington: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In very large networks, however, this reduction may not be enough. For example, the CPCS network <ref> (Pradhan, Provan, Middleton, & Henrion, 1994) </ref> would require 133,931,430 parameters if defined using explicit conditional probability tables. Instead, CPCS uses parametric descriptions of the conditional distributions in the network, such as noisy-OR and noisy-MAX, thereby reducing the network to only 8,254 parameters.
Reference: <author> Price, W. H. </author> <year> (1992). </year> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: As discussed above, the algorithm can (and, in many cases, should) be extended to incorporate nonuniform priors over parameters, and to take advantage of more sophisticated methods for function optimization. In the experiments described below, we have adapted the conjugate gradient method <ref> (Price, 1992) </ref> to keep the probabilistic variables in the legal [0,1] range 11 Table 1.
Reference: <author> Russell, S. J. & Grosof, B. </author> <year> (1987). </year> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence (AAAI-87). </booktitle> <address> Seattle, Washington: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Just as for other parameterized representations, the resulting reduction in the number of parameters should allow for significantly faster learning. Koller and Pfeffer (1996) give some preliminary results along these lines. Such an approach transfers into the probabilistic domain the idea of declarative bias <ref> (Russell & Grosof, 1987) </ref>. Results by Tadepalli (1993) show that learning within a structured model derived from a declarative bias can be made much more efficient using membership queries|that is, generating specific experiments on the domain rather than sampling it randomly.
Reference: <author> Shachter, R. D. & Peot, M. A. </author> <year> (1989). </year> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI-89). </booktitle> <address> Windsor, Ontario: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Shachter, R. S. & Kenley, C. R. </author> <year> (1989). </year> <title> Gaussian influence diagrams. </title> <journal> Management Science, </journal> <volume> 35 (5), </volume> <pages> 527-550. </pages>
Reference: <author> Smyth, P., Heckerman, D., & Jordan, M. </author> <year> (1997). </year> <title> Probabilistic independence networks for hidden Markov probability models. </title> <journal> Neural Computation, </journal> <volume> 9(2), </volume> <pages> 227-269. </pages>
Reference: <author> Spiegelhalter, D., Dawid, P., Lauritzen, S., & Cowell, R. </author> <year> (1993). </year> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8, </volume> <pages> 219-282. </pages>
Reference: <author> Spiegelhalter, D. J. & Cowell, R. G. </author> <year> (1992). </year> <title> Learning in probabilistic expert systems. </title> <editor> In Bernardo, J. M., Berger, J. O., Dawid, A. P., & Smith, A. F. M. (Eds.), </editor> <booktitle> Bayesian Statistics 4 Oxford. </booktitle> <publisher> Oxford University Press. </publisher>
Reference: <author> Spirtes, P., Glymour, C., & Scheines, R. </author> <year> (1993). </year> <title> Causation, prediction, and search. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Tadepalli, P. </author> <year> (1993). </year> <title> Learning from queries and examples with tree-structured bias. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning. </booktitle> <address> Amherst, Massachusetts: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Thiesson, B. </author> <year> (1995a). </year> <title> Accelerated quantification of Bayesian networks with incomplete data. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95), </booktitle> <pages> pp. 306-311. </pages> <address> Montreal, Canada: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Thiesson, B. </author> <year> (1995b). </year> <title> Score and information for recursive exponential models with incomplete data. </title> <type> Technical report R-95-2020, </type> <institution> Institute for Electronic Systems, Aalborg University, Den-mark. </institution>
Reference: <author> Titterington, D., Smith, A., & Makov, U. </author> <year> (1985). </year> <title> Statistical analysis of finite mixture distributions. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: There are several reasons for this. First, it is not necessarily the case that any particular variable is hidden in all the observed cases (although we do not rule this out). Second, the hidden variable might be one that we are interested in querying, as in learning mixture models <ref> (Titterington, Smith, & Makov, 1985) </ref>. Finally, networks with hidden variables can be more compact than the corresponding fully observable network (see Figure 2). <p> In this case, knowledge of structure is taken to include knowledge of the number of values of each variable. In other settings, particularly in learning mixture models <ref> (Titterington et al., 1985) </ref>, finding the number of values of a class variable may be part of the learning task. 3. Since the function being maximized is a likelihood, the EM algorithm can also be used, as discussed in Section 7. 4.
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1994). </year> <journal> Knowledge-based artificial neural networks.. Artificial Intelligence, </journal> <volume> 70, </volume> <pages> 119-165. </pages>
Reference: <author> Wellman, M. P. </author> <year> (1990). </year> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 44 (3), </volume> <pages> 257-303. </pages>
Reference-contexts: These results are currently being extended to cover dynamic probabilistic networks and networks with continuous variables. Another possible improvement over the basic APN model is to allow the user or domain expert to prespecify constraints on the conditional distributions. One possibility is to specify a qualitative probabilistic network <ref> (Wellman, 1990) </ref> that provides appropriate monotonicity constraints on the conditional distributions. For example, the higher one's driving skill, the less likely it is that one has had an accident.
Reference: <author> Werbos, P. J. </author> <year> (1990). </year> <title> Backpropagation through time: What it does and how to do it. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78 (10), </volume> <pages> 1550-1560. </pages> <note> 34 Zweig, </note> <author> G. </author> <year> (1996). </year> <title> Methods for learning dynamic probabilistic networks and a comparison with hidden Markov models.. </title> <type> MS report, </type> <institution> Computer Science Division, UC Berkeley. </institution> <note> Received Date Accepted Date Final Manuscript Date </note>
References-found: 53

