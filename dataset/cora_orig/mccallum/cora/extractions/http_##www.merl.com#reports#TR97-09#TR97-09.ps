URL: http://www.merl.com/reports/TR97-09/TR97-09.ps
Refering-URL: http://www.merl.com/reports/TR97-09/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: EM-Cube: An Architecture for Low-Cost Real-Time Volume Rendering  
Author: Randy Osborne, Hanspeter Pfister, Hugh Lauer, Neil McKenzie Sarah Gibson, Wally Hiatt, Hide Ohkami 
Affiliation: Mitsubishi Electric Information Technology Center America,  
Address: Los Angeles, California,  1997 201 Broadway, Cambridge, Massachusetts 02139  
Date: August 1997  August 3-4, 1997  
Web: http://www.merl.com  
Note: MERL A MITSUBISHI ELECTRIC RESEARCH LABORATORY  Presented at The 1997 Siggraph/Eurographics Workshop on Graphics Hardware,  Copyright c  
Pubnum: TR-97-09  
Abstract: EM-Cube is a VLSI architecture for low-cost, high quality volume rendering at full video frame rates. Derived from the Cube-4 architecture developed at SUNY at Stony Brook, EM-Cube computes sample points and gradients on-the-fly to project 3-dimensional volume data onto 2-dimensional images with realistic lighting and shading. A modest rendering system based on EM-Cube consists of a PCI card with four rendering chips, four 64Mbit SDRAMs to hold the volume data, and four SRAMs to capture the rendered image. The performance target for this configuration is to render images from a 256 3 fi 16 bit data set at 30 frames/sec. The EM-Cube architecture can be scaled to larger volume data-sets and/or higher frame rates by adding additional ASICs, SDRAMs, and SRAMs. This paper addresses three major challenges encountered developing EM-Cube into a practical product: exploiting the bandwidth inherent in the SDRAMs containing the volume data, keeping the pin-count between adjacent ASICs at a tractable level, and reducing the on-chip storage required to hold the intermediate results of rendering. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Cabral, N. Cam, and J. Foran. </author> <title> Accelerated volume rendering and tomographic reconstruction using texture mapping hardware. </title> <booktitle> In Workshop on Volume Visualization, </booktitle> <pages> pages 91-98, </pages> <year> 1994. </year>
Reference-contexts: Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13]. Interactive rendering rates have been achieved on the SGI Reality Engine using 3D texturing hardware <ref> [3, 1] </ref>. However, current 3D texturing hardware is expensive and does not support estimation of gradients that is required for high-quality shading and classification. Furthermore, the best volume rendering performance on large general-purpose supercomputers or special-purpose texture mapping hardware is still below 15 frames/sec for 256 3 volumes.
Reference: [2] <author> B. Corrie and P. Mackerras. </author> <title> Parallel volume rendering and data coherence. </title> <booktitle> In Proc. Parallel Rendering Symposium, </booktitle> <pages> pages 23-26, </pages> <year> 1993. </year>
Reference-contexts: Software implementations use acceleration techniques which require pre-computation, additional data storage, or tradeoff image quality for speed. Shear-warp rendering, the currently fastest software algorithm, achieves one projection in a few seconds on a regular workstation [11]. Many researchers have implemented volume rendering algorithms on large general-purpose multiprocessors <ref> [2, 5, 14, 15] </ref>. However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13].
Reference: [3] <author> T. J. Cullip and U. Neumann. </author> <title> Accelerating volume reconstruction with 3D texture mapping hardware. </title> <type> Technical Report TR93-027, </type> <institution> Dept. of Computer Science, Univ. of North Carolina, Chapel Hill, </institution> <year> 1993. </year>
Reference-contexts: Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13]. Interactive rendering rates have been achieved on the SGI Reality Engine using 3D texturing hardware <ref> [3, 1] </ref>. However, current 3D texturing hardware is expensive and does not support estimation of gradients that is required for high-quality shading and classification. Furthermore, the best volume rendering performance on large general-purpose supercomputers or special-purpose texture mapping hardware is still below 15 frames/sec for 256 3 volumes.
Reference: [4] <author> M. de Boer, A. Gropl, J. Hesser, and R. </author> <title> Manner. Latency- and hazard-free volume memory architecture for direct volume rendering. </title> <booktitle> In Proc. MERL-TR-97-09 10 August 1997 11th Eurographics Hardware Workshop, </booktitle> <pages> pages 109-118, </pages> <year> 1996. </year>
Reference-contexts: Thus 32 chips are required. This is far too many chips for a cost effective solution. 7.1 Sectioning A Solution for the On-Chip Buffer Size Problem To reduce the on-chip buffer area to a feasible amount, we use the same approach as in <ref> [4] </ref>: we divide the volume into L horizontal sections as shown in EM-Cube algorithm and then combine the results. This sectioning reduces the slice face area and hence the size of slice buffers: L sections reduce the size of on-chip slice buffers by 1=L.
Reference: [5] <author> K. Ma et al. </author> <title> A data distributed parallel algorithm for ray-traced volume rendering. </title> <booktitle> In Proc. Parallel Rendering Symposium, </booktitle> <pages> pages 15-22. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: Software implementations use acceleration techniques which require pre-computation, additional data storage, or tradeoff image quality for speed. Shear-warp rendering, the currently fastest software algorithm, achieves one projection in a few seconds on a regular workstation [11]. Many researchers have implemented volume rendering algorithms on large general-purpose multiprocessors <ref> [2, 5, 14, 15] </ref>. However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13].
Reference: [6] <author> S. Gibson et al. </author> <title> Simulating arthroscopic knee surgery using volumetric object representations, real-time volume rendering and haptic feedback. </title> <booktitle> In First Joint Conference on Computer Vision, Virtual Reality, and Robotics in Medicine and Medical Robotics and Computer Assisted Surgery, </booktitle> <pages> pages 369-378. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: 1 Introduction Real-time volume rendering is an enabling technology for medical applications including diagnosis, surgical training, and surgical simulation <ref> [6] </ref>. The large computational and memory requirements of real-time volume rendering place it beyond the capabilities of single processor PCs and workstations without dedicated hardware.
Reference: [7] <author> T. Guenther et al. VIRIM: </author> <title> A massively parallel processor for real-time volume visualization in medicine. </title> <booktitle> In Proc. 9th Eurographics Hardware Workshop, </booktitle> <pages> pages 103-108, </pages> <year> 1994. </year>
Reference-contexts: Near real time rates of 20 frames/sec can be achieved by connecting several modules over a ring-connected cubic network [9]. VIRIM, an object-order volume rendering engine, is one of the few research proposals that has been built and tested <ref> [7] </ref>. The machine consists of four VME boards with special-purpose geometry processors for data resampling and programmable ray-casting processors for the final image generation.
Reference: [8] <author> H. Fuchs and J. Poulton. Pixel-planes: </author> <title> A VLSI-oriented design for a graphics engine. </title> <booktitle> VLSI Design, </booktitle> <volume> 2(3) </volume> <pages> 20-28, </pages> <year> 1981. </year>
Reference-contexts: However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering <ref> [18, 8, 13] </ref>. Interactive rendering rates have been achieved on the SGI Reality Engine using 3D texturing hardware [3, 1]. However, current 3D texturing hardware is expensive and does not support estimation of gradients that is required for high-quality shading and classification.
Reference: [9] <author> G. Knittel. </author> <title> A scalable architecture for volume rendering. </title> <booktitle> In Proc. 9th Eurographics Hardware Workshop, </booktitle> <pages> pages 58-69, </pages> <year> 1994. </year>
Reference-contexts: A single board consisting of eight-way interleaved volume memory and four VLSI chips provides 2.5 frames/sec for 256 3 volumes. Near real time rates of 20 frames/sec can be achieved by connecting several modules over a ring-connected cubic network <ref> [9] </ref>. VIRIM, an object-order volume rendering engine, is one of the few research proposals that has been built and tested [7]. The machine consists of four VME boards with special-purpose geometry processors for data resampling and programmable ray-casting processors for the final image generation.
Reference: [10] <author> G. Knittel and W. Strasser. </author> <title> A compact volume rendering accelerator. </title> <booktitle> In Proc. Volume Visualization Symposium, </booktitle> <pages> pages 67-74. </pages> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: In view of these limitations, it is not surprising that a number of researchers have undertaken the development of special-purpose hardware for volume rendering. VOGUE, one of the most concrete proposals, is a compact ray-casting unit which provides interactive rendering speeds at moderate hardware costs <ref> [10] </ref>. A single board consisting of eight-way interleaved volume memory and four VLSI chips provides 2.5 frames/sec for 256 3 volumes. Near real time rates of 20 frames/sec can be achieved by connecting several modules over a ring-connected cubic network [9].
Reference: [11] <author> P. Lacroute and M. Levoy. </author> <title> Fast volume rendering using a shear-warp factorization of the viewing transform. </title> <booktitle> In Proc. SIGGRAPH, </booktitle> <pages> pages 451-457, </pages> <year> 1994. </year>
Reference-contexts: Software implementations use acceleration techniques which require pre-computation, additional data storage, or tradeoff image quality for speed. Shear-warp rendering, the currently fastest software algorithm, achieves one projection in a few seconds on a regular workstation <ref> [11] </ref>. Many researchers have implemented volume rendering algorithms on large general-purpose multiprocessors [2, 5, 14, 15]. However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates.
Reference: [12] <author> J. Lichtermann. </author> <title> Design of a fast voxel processor for parallel volume visualization. </title> <booktitle> In Proc. 10th Eurographics Hardware Workshop, </booktitle> <pages> pages 83-92, </pages> <year> 1995. </year>
Reference-contexts: This capability ensures minimal overhead for the sectioning described in Section 7.1. The maximum block size is b N=C since blocks must be skewed over C chips so that a block-beam can be fetched without conflict for any view direction. A hierarchical blocking scheme is also described in <ref> [12] </ref>. The data volume is divided into subcubes and subcubes are divided into 2x2x2 "supervoxels". However, while the hierarchical division is the same as above, the actual memory blocking is different. <p> For a smaller volume or smaller voxel size, rendering might not access every row every 32msec. However, we do not need full 250Mbytes/sec bandwidth in such cases and thus we can slip in auto-refresh cycles without degrading the bandwidth. <ref> [12] </ref> the eight voxels in a supervoxel are distributed across eight memory modules, i.e. supervoxels are the unit of interleaved memory access. In our blocking, all the voxels comprising a block are located in the same memory and miniblocks are the unit of pipelined burst access.
Reference: [13] <author> S. Molnar, J. Eyles, and J. Poulton. Pixelflow: </author> <title> High-speed rendering using image composition. </title> <journal> Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 231-240, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering <ref> [18, 8, 13] </ref>. Interactive rendering rates have been achieved on the SGI Reality Engine using 3D texturing hardware [3, 1]. However, current 3D texturing hardware is expensive and does not support estimation of gradients that is required for high-quality shading and classification.
Reference: [14] <author> C. Montani, R. Perego, and R. Scopigno. </author> <title> Parallel volume visualization on a hypercube architecture. </title> <booktitle> Workshop on Volume Visualization, </booktitle> <pages> pages 9-16, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Software implementations use acceleration techniques which require pre-computation, additional data storage, or tradeoff image quality for speed. Shear-warp rendering, the currently fastest software algorithm, achieves one projection in a few seconds on a regular workstation [11]. Many researchers have implemented volume rendering algorithms on large general-purpose multiprocessors <ref> [2, 5, 14, 15] </ref>. However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13].
Reference: [15] <author> U. Neumann. </author> <title> Parallel volume-rendering algorithm performance on mesh-connected multi-computers. </title> <booktitle> In Proc. Parallel Rendering Symposium Proceedings, </booktitle> <pages> pages 97-104, </pages> <year> 1993. </year>
Reference-contexts: Software implementations use acceleration techniques which require pre-computation, additional data storage, or tradeoff image quality for speed. Shear-warp rendering, the currently fastest software algorithm, achieves one projection in a few seconds on a regular workstation [11]. Many researchers have implemented volume rendering algorithms on large general-purpose multiprocessors <ref> [2, 5, 14, 15] </ref>. However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering [18, 8, 13].
Reference: [16] <author> H. Pfister and A. Kaufman. </author> <title> Cube-4 A scalable architecture for real-time volume rendering. </title> <booktitle> In ACM/IEEE Sympos. on Volume Visualization, </booktitle> <pages> pages 47-54, </pages> <year> 1996. </year>
Reference-contexts: This paper describes the architecture of the first member of this family, a volume rendering chip currently under development. The architecture is a scalable systolic array based on Cube-4, developed at SUNY at Stony Brook <ref> [16] </ref>. The performance target is a chipset that fits onto a single PCI card and renders volume data sets of size 256 3 fi 16 bit vox-els, at 30 frames/sec. The cost of such an accelerator will be on the order of a low-cost PC. <p> VIRIM achieves 2.5 frames/sec for 256 3 datasets. 3 Cube-4 Architecture Cube-4, developed at SUNY Stony Brook, is a scalable systolic array of rendering pipelines, each connected to its own memory module <ref> [16] </ref>. Figure 1 shows the major functions in each rendering pipeline. Cube-4 uses a modified ray casting algorithm. Instead of processing along each ray in depth-first fashion, Cube-4 processes rays in parallel in a breadth-first fashion.
Reference: [17] <author> J. Scheltinga, J. Smit, and M. Bosma. </author> <title> Design of an on-chip reflectance map. </title> <booktitle> In Proc. 10th Eurographics Hardware Workshop, </booktitle> <pages> pages 51-55, </pages> <year> 1995. </year>
Reference-contexts: Shading is not yet finalized. One possibility is the lookup table method of <ref> [17] </ref> which uses a reflectance map (one 512 byte table per axis direction, for 3x512bytes total) and an arctangent table (one 512 byte table). 5 The total for all lookup tables is 9x512bytes.
Reference: [18] <author> P. Schroder and G. Stoll. </author> <title> Data parallel volume rendering as line drawing. </title> <booktitle> In Workshop on Volume Visualization, </booktitle> <pages> pages 25-31, </pages> <year> 1992. </year> <month> MERL-TR-97-09 11 August </month> <year> 1997 </year>
Reference-contexts: However, this approach requires expensive, typically network-shared machines to achieve acceptable frame rates, and the lack of direct frame-buffer access prohibits real-time output rates. Another approach is to use existing polygon graphics hardware for volume rendering <ref> [18, 8, 13] </ref>. Interactive rendering rates have been achieved on the SGI Reality Engine using 3D texturing hardware [3, 1]. However, current 3D texturing hardware is expensive and does not support estimation of gradients that is required for high-quality shading and classification.
References-found: 18

