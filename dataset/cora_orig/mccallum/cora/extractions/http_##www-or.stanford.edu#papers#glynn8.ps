URL: http://www-or.stanford.edu/papers/glynn8.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: glynn@leland.stanford.edu  
Title: Two Approaches to the Initial Transient Problem  
Author: Peter W. Glynn 
Address: Stanford, CA 94309-4022  
Affiliation: Dept. of Operations Research Stanford University  
Abstract: This paper describes two different approaches to dealing with the initial transient problem. In the first approach, the length of the "warm-up period" is determined by obtaining analytical estimates on the rate of convergence to stationarity. Specifically, we obtain an upper bound on the "second eigenvalue" of the transition matrix of a Markov chain, thereby providing one with a theoretical device that potentially can give estimates of the desired form. The second approach is data-driven, and involves using observed data from the simulation to determine an estimate of the "warm-up period". For the method we study, we are able to use a coupling argument to establish a number of important theoretical properties of the algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Asmussen, S., Glynn, P.W., and Thorisson, H. </author> <year> (1992). </year> <title> Stationarity detection in the initial transient problem. </title> <booktitle> ACM Transactions on Modeling and Computer Simulation 2, </booktitle> <pages> 130-157. 8 </pages>
Reference-contexts: A principal difficulty with this approach is that very few such data-driven methods have come equipped with any theoretical guarantees; see, however, Asmussen, Glynn, and Thorisson <ref> [1] </ref> for some noteworthy exceptions. Here, we analyze a data-driven rule first proposed in Glynn and Iglehart [6], and show that it enjoys some theoretically important properties.
Reference: [2] <author> Conway, R.W. </author> <year> (1963). </year> <title> Some tactical problems in digital simulation. Manage. </title> <journal> Sci. </journal> <volume> 10, </volume> <pages> 47-61. </pages>
Reference-contexts: However, historically, it is fair to say that the most widely used methods for determining the time to stationarity have made such assessments based purely on the observed data obtained by simulating the system itself; see, for example, Conway <ref> [2] </ref> and Gafarian, Ancker, and Morisaku [5]. A principal difficulty with this approach is that very few such data-driven methods have come equipped with any theoretical guarantees; see, however, Asmussen, Glynn, and Thorisson [1] for some noteworthy exceptions.
Reference: [3] <author> Diaconis, P. and Stroock, D. </author> <year> (1991). </year> <title> Geometric bounds for eigenvalues of Markov chains. </title> <journal> Annals of Applied Probability 1, </journal> <pages> 36-61. </pages>
Reference-contexts: In certain settings, probability arguments can then be used to a priori dominate the fi (y)'s. The theorem above complements the many other results that have been developed in recent years to bound the rate of convergence to stationarity; see, for example, Diaconis and Stroock <ref> [3] </ref>, Fill [4], and Meyn and Tweedie [8]. In certain highly structured models, these analytic tools turn out to be quite powerful, and the bounds obtained are relatively tight.
Reference: [4] <author> Fill, J.A. </author> <year> (1991). </year> <title> Eigenvalue bounds on convergence to stationarity for nonreversible Markov chains, with an application to the exclusion process. </title> <booktitle> Applied Probability 1, </booktitle> <pages> 62-87. </pages>
Reference-contexts: In certain settings, probability arguments can then be used to a priori dominate the fi (y)'s. The theorem above complements the many other results that have been developed in recent years to bound the rate of convergence to stationarity; see, for example, Diaconis and Stroock [3], Fill <ref> [4] </ref>, and Meyn and Tweedie [8]. In certain highly structured models, these analytic tools turn out to be quite powerful, and the bounds obtained are relatively tight.
Reference: [5] <author> Gafarian, A.V., Ancker, C.J., Jr., and Morisaku, T. </author> <year> (1978). </year> <title> Evaluation of commonly used rules for detecting "steady state" in computer simulation. </title> <journal> Nav. Res. Logistics Quart. </journal> <volume> 25, </volume> <pages> 511-529. </pages>
Reference-contexts: However, historically, it is fair to say that the most widely used methods for determining the time to stationarity have made such assessments based purely on the observed data obtained by simulating the system itself; see, for example, Conway [2] and Gafarian, Ancker, and Morisaku <ref> [5] </ref>. A principal difficulty with this approach is that very few such data-driven methods have come equipped with any theoretical guarantees; see, however, Asmussen, Glynn, and Thorisson [1] for some noteworthy exceptions.
Reference: [6] <author> Glynn, P.W. and Iglehart, D.L. </author> <year> (1987). </year> <title> A new initial bias deletion rule. </title> <booktitle> Proc. of the 1987 Winter Simulation Conference, </booktitle> <pages> 318-319. </pages>
Reference-contexts: A principal difficulty with this approach is that very few such data-driven methods have come equipped with any theoretical guarantees; see, however, Asmussen, Glynn, and Thorisson [1] for some noteworthy exceptions. Here, we analyze a data-driven rule first proposed in Glynn and Iglehart <ref> [6] </ref>, and show that it enjoys some theoretically important properties. <p> Condition c asserts that X is in approximate stationarity at time T (t), whereas d rules out detection rules that throw out more and more data as t ! 1 (e.g. T (t) = t 1=2 ). The rule proposed in Glynn and Iglehart <ref> [6] </ref> is described by the following algorithm: 1. Simulate X to time t. 2. Generate a uniform r.v. U , independent of X. 3. Set T (t) = inff s 0 : X (s) = X (U t) g. Clearly T (t) t always holds.
Reference: [7] <author> Glynn, P.W. </author> <year> (1995). </year> <title> Asymptotically valid initial transient detection rules. </title> <note> In preparation. </note>
Reference-contexts: Nevertheless, we believe that the algorithm (1)-(3) has sufficient practical merit so as to be worthy of further investigation. Additional properties of this algorithm will be described in a forthcoming paper; see Glynn <ref> [7] </ref>.
Reference: [8] <author> Meyn, S.P. and Tweedie, R.L. </author> <year> (1994). </year> <title> Computable bounds for geometric convergence rates of Markov chains. </title> <journal> Annals of Applied Probability 4, </journal> <pages> 981-1011. </pages>
Reference-contexts: The theorem above complements the many other results that have been developed in recent years to bound the rate of convergence to stationarity; see, for example, Diaconis and Stroock [3], Fill [4], and Meyn and Tweedie <ref> [8] </ref>. In certain highly structured models, these analytic tools turn out to be quite powerful, and the bounds obtained are relatively tight. However, in general, it is probably fair to say that for unstructured systems, the bounds are often quite loose and consequently of less practical value.
References-found: 8

