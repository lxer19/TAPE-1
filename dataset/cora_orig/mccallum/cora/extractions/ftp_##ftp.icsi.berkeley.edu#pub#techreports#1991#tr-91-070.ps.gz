URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1991/tr-91-070.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1991.html
Root-URL: http://www.icsi.berkeley.edu
Title: Connectionist Speech Recognition: Status and Prospects  
Phone: 1-510-642-4274 FAX 1-510-643-7684  
Author: Steve Renals, Nelson Morgan, Herve Bourlard Michael Cohen Horacio Franco Chuck Wooters and Phil Kohn 
Note: L&H Speechproducts, Ieper, B-8900  
Date: December 1991  
Address: I 1947 Center Street Suite 600 Berkeley, California 94704  Menlo Park CA 94025, USA.  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  Belgium. SRI International,  
Pubnum: TR-91-070  
Abstract: We report on recent advances in the ICSI connectionist speech recognition project. Highlights include: Experimental results showing that connectionist methods can improve the performance of a context independent maximum likelihood trained HMM system, resulting in a performance close to that achieved using state of the art context dependent HMM systems of much higher complexity. Mixing (context independent) connectionist probability estimates with maximum likelihood trained context dependent models to improve the performance of a state of the art system The development of a network decomposition method that allows connectionist modelling of context dependent phones efficiently and parsimoniously, with no statistical independence assumptions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and C. J. Wellekens. </author> <title> Links between Markov models and multilayer perceptrons. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-12:1167-1178, </volume> <year> 1990. </year>
Reference-contexts: Since 1988, we have been investigating the use of feed-forward connectionist networks to improve HMM speech recognition systems. The basis of this approach has been a proof that feed-forward networks can be used as probability estimators <ref> [1] </ref>. We have been using such networks to estimate the output probabilities of HMMs [9, 10]. <p> Note that we commonly use a sigmoid transfer function on the output units, which only constrains them to be non-negative. However Bourlard and Wellekens <ref> [1] </ref> demonstrated that at the minimum of a least squares or relative entropy objective function, the sigmoid output units of a `1-from-N' classification network will sum to 1. <p> In practice, we find no significant difference between using a sigmoid transfer function or a normalised exponential (`softmax') transfer function on the output units of a MLP. Furthermore it was shown in <ref> [1] </ref> that `1-from-N' networks (such as multi-layer perceptrons|MLPs) trained to minimise a relative entropy or least squares error function, in a `1-from-N' classification task will output estimates of the posterior probability P (q i |x) of class q i (which corresponds to output unit i) given the input vector x.
Reference: [2] <author> M. Cohen. </author> <title> Phonological Structures for Speech Recognition. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1989. </year>
Reference-contexts: Probabilities of pronunciations are estimated by the forward-backward algorithm, after tying together instances of the same phonological process in different words. Phonological rules can be specified to apply across words, adding initial or final arcs which are constrained to connect only to arcs fulfilling the context of the rule <ref> [2, 3] </ref>. 7 Context dependent phone models include word-specific phone, triphone, gener--alised triphone, cross-word triphone (constrained to connect to appropriate contexts), and left and right biphone (and generalised biphone). All these models are smoothed together, along with context independent models, using the deleted interpolation algorithm.
Reference: [3] <author> M. Cohen, H. Murveit, J. Bernstein, P. Price, and M. Weintraub. </author> <title> The DECIPHER speech recognition system. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 77-80, </pages> <address> Albuquerque, </address> <year> 1990. </year>
Reference-contexts: Our recent experiments have used connectionist methods in both the baseline ICSI continuous speech recognition system and the more complex DECIPHER system developed at SRI International <ref> [3] </ref>. The connectionist systems described here estimate probabilities for context independent phone models. However, advanced continuous speech recognition systems utilise context dependent phone models [13, 7]: multiple models for each phone depending on the surrounding phonetic context. <p> This paper continues this research by integrating such connectionist probability estimators into a large HMM continuous speech recognition system, SRI's DECIPHER <ref> [3] </ref>. DECIPHER is a much richer system than the previous baseline systems we have used. It includes multiple probabilistic word pronunciations, crossword phonological and acoustic modelling, context dependent phone models, and models with multiple densities. Word models are represented as probabilistic networks of phone models, specifying multiple pronunciations. <p> Probabilities of pronunciations are estimated by the forward-backward algorithm, after tying together instances of the same phonological process in different words. Phonological rules can be specified to apply across words, adding initial or final arcs which are constrained to connect only to arcs fulfilling the context of the rule <ref> [2, 3] </ref>. 7 Context dependent phone models include word-specific phone, triphone, gener--alised triphone, cross-word triphone (constrained to connect to appropriate contexts), and left and right biphone (and generalised biphone). All these models are smoothed together, along with context independent models, using the deleted interpolation algorithm.
Reference: [4] <author> H. Hermansky, N. Morgan, A. Bayya, and P. Kohn. </author> <title> RASTA-PLP speech analysis. </title> <type> Technical Report TR-91-069, </type> <institution> International Computer Science Institute, Berkeley CA, </institution> <year> 1991. </year>
Reference-contexts: A particular focus is to integrate our various methods into working, near-real-time systems. The RASTA-PLP (Relative Spectral-Peceptual Linear Prediction) method <ref> [4] </ref>, developed by Hermansky et al. at ICSI, is an analysis technique designed to be robust to steady-state or slowly varying factors in speech, which are assumed to carry little linguistic information. The essential idea, is that part of an analysis should include a bandpass filtering in log spectral domain.
Reference: [5] <author> F. Jelinek. </author> <title> Continuous speech recognition by statistical methods. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 64 </volume> <pages> 532-556, </pages> <year> 1976. </year>
Reference-contexts: INTRODUCTION The dominant approach to automatic continuous speech recognition is statistical <ref> [5, 7] </ref>. The resulting methods, which use crude speech production models, hidden Markov models (HMMs), have been successful largely because of the existence of well-understood, consistent and provably convergent training procedures. Since 1988, we have been investigating the use of feed-forward connectionist networks to improve HMM speech recognition systems.
Reference: [6] <author> Y. Konig, N. Morgan, and C. Chandra. GDNN: </author> <title> A gender dependent neural network for continuous speech recognition. </title> <type> Technical Report TR-91-071, </type> <institution> International Computer Science Institute, Berkeley CA, </institution> <year> 1991. </year>
Reference-contexts: This, and other experiments, seem to indicate that RASTA is an extremely effective approach to adopt for speech recognition in "real world" situations. Much of our current effort is in the area of improved acoustic modelling. Konig et al. <ref> [6] </ref> have added gender models to the acoustic modelling component. A gender-dependent network was trained to estimate the probability of a specker being male or female.
Reference: [7] <author> K.-F. Lee. </author> <title> Large Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX System. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: INTRODUCTION The dominant approach to automatic continuous speech recognition is statistical <ref> [5, 7] </ref>. The resulting methods, which use crude speech production models, hidden Markov models (HMMs), have been successful largely because of the existence of well-understood, consistent and provably convergent training procedures. Since 1988, we have been investigating the use of feed-forward connectionist networks to improve HMM speech recognition systems. <p> The connectionist systems described here estimate probabilities for context independent phone models. However, advanced continuous speech recognition systems utilise context dependent phone models <ref> [13, 7] </ref>: multiple models for each phone depending on the surrounding phonetic context. In part IV, we present a new network decomposition method that allows feed-forward networks to model phones in context efficiently and parsimoniously. <p> Additionally, if c ` and c r represent broad phonetic classes or clusters rather than phonemes, the above results apply to the estimation of "generalised triphones", such as are defined in <ref> [7] </ref>. As done previously the input field containing the acoustic data (e.g., x) may also be supplied with contextual information.
Reference: [8] <author> N. Morgan, J. Beck, P. Kohn, J. Bilmes, E. Allman, and J. Beer. </author> <title> The Ring Array Processor (RAP): A multiprocessing peripheral for connectionist applications. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> page In Press, </note> <year> 1992. </year>
Reference-contexts: Stochastic gradient descent training typically required about 10 passes through the training database of 1.3 million frames. This required less than 24 hours compute time, using a 5-board RAP (Ring Array Processor) <ref> [8] </ref>, containing 20 TI TMS320C30 DSPs, each with 256kB of SRAM and 16MB of DRAM. To train an MLP we require a bootstrap model to produce time-aligned phonetic labels. <p> Even if enough training data were available, networks with millions of parameters can be expected to take impractical amounts of time to train using back-propagation approaches, even with fast special-purpose machines such as our Ring Array Processor (RAP) <ref> [8] </ref>. Here, we present a method for estimating likelihoods for context dependent phone 2. Note, that these probabilities do include an acoustic context, since we typically use a 9 frame window.
Reference: [9] <author> N. Morgan and H. Bourlard. </author> <title> Continuous speech recognition using multi-layer perceptrons with hidden markov models. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 413-416, </pages> <address> Al-buquerque, </address> <year> 1990. </year>
Reference-contexts: The basis of this approach has been a proof that feed-forward networks can be used as probability estimators [1]. We have been using such networks to estimate the output probabilities of HMMs <ref> [9, 10] </ref>. In this paper, we summarise the theory underlying our hybrid connectionist-HMM systems, and present the issues (both theoretical refinements and practical necessities) that we have had to address in order to use these methods successfully.
Reference: [10] <author> N. Morgan, H. Hermansky, H. Bourlard, C. Wooters, and P. Kohn. </author> <title> Continuous speech recognition using PLP analysis with multi-layer perceptrons. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 49-52, </pages> <address> Toronto, </address> <year> 1991. </year> <month> 22 </month>
Reference-contexts: The basis of this approach has been a proof that feed-forward networks can be used as probability estimators [1]. We have been using such networks to estimate the output probabilities of HMMs <ref> [9, 10] </ref>. In this paper, we summarise the theory underlying our hybrid connectionist-HMM systems, and present the issues (both theoretical refinements and practical necessities) that we have had to address in order to use these methods successfully. <p> Training is then halted. 3. Input representation is important. In particular dynamic features (obtained via linear regression estimate of the temporal derivative) should be used in addition to static ones, and a multi-frame input (typically we use - 4 frames of context), offers an improvement over single frame input <ref> [10] </ref>. 4. The word transition penalty used in the Viterbi search should be increased in the case of multi-frame input. This empirical result may be explained in terms of a scaling relationship between the likelihood of a single frame and the joint likelihood of several frames, given the class.
Reference: [11] <author> S. Renals, N. Morgan, and H. Bourlard. </author> <title> Probability estimation by feed--forward networks in continuous speech recognition. </title> <type> Technical Report TR-91-030, </type> <institution> International Computer Science Institute, </institution> <address> Berkeley CA, USA, </address> <year> 1991. </year>
Reference-contexts: Thus we must factor out the data estimates of these priors <ref> [11] </ref>. 2. Cross-validation training is essential for good generalisation and preventing over-training, especially when using large networks. In our training schedule we cross-validate by withholding a certain proportion of the training data (typically 10-20%) and using this to validate the training after each epoch. <p> This gave a statistically significant improvement from 17.2% error to 15.5% error on our baseline system. Renals et al. <ref> [11] </ref> showed how a tied-mixture density estimator may be discriminatively trained using connectionist methods. Work is in progress to determine if this method can improve our current acoustic models, and if it can further improve the performance of an already trained tied mixture density estimator.
Reference: [12] <author> H. Robbins and S. Munro. </author> <title> A stochastic approximation method. </title> <journal> Annals of Mathematical Statisitics, </journal> <volume> 29 </volume> <pages> 400-407, </pages> <year> 1951. </year>
Reference-contexts: This time-dependent reduction in stochastic gradient descent step-size (gain) may be understood in terms of the constraints on the gain sequence given by stochastic approximation theory <ref> [12] </ref> 1 . After each succeeding epoch the step size is further reduced, 1. The conditions given by stochastic approximation theory ( P P n &lt; ) are not, in fact, met by our gain sequence, a n / 1/2 n , since P n 1/2 n &lt; .
Reference: [13] <author> R. Schwartz, Y. Chow, O. Kimball, S. Roucous, M. Krasner, and J. Makhoul. </author> <title> Context-dependent modelling for acoustic-phonetic recognition of continuous speech. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 1205-1208, </pages> <address> Tampa FL, </address> <year> 1985. </year> <month> 23 </month>
Reference-contexts: The connectionist systems described here estimate probabilities for context independent phone models. However, advanced continuous speech recognition systems utilise context dependent phone models <ref> [13, 7] </ref>: multiple models for each phone depending on the surrounding phonetic context. In part IV, we present a new network decomposition method that allows feed-forward networks to model phones in context efficiently and parsimoniously.
References-found: 13

