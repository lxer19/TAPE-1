URL: http://www.ius.cs.cmu.edu/IUS/saradar/Papers/cvpr93.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/rcollins/www/Pub/cvpr93.html
Root-URL: 
Title: Matching Perspective Views of Coplanar Structures using Projective Unwarping and Similarity Matching  
Author: Robert T. Collins J. Ross Beveridge 
Date: February 1994  
Pubnum: CMPSCI TR94-06  
Abstract: This paper was presented at the 1993 IEEE Conference on Computer Vision and Pattern Recognition, New York City, June 1993. This work was funded in part by DARPA/TACOM contract DAAE07-91-C-R035 and by the RADIUS project under DARPA/Army contract TEC DACA76-92-R-0028. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Anandan, </author> <title> "Measuring Visual Motion from Image Sequences," </title> <type> Ph.D. Thesis and COINS Tech Report 87-21, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1987. </year>
Reference-contexts: Fast and reliable matching techniques exist when good initial guesses of pose or camera motion are available [6, 7] or when the distance between views is small <ref> [1] </ref>. What is lacking are good methods for finding matches in monocular images, formed by perspective projection, and taken from arbitrary viewpoints.
Reference: [2] <author> J. Arnspang, </author> <title> "Moving Towards the Horizon of a Planar Curve,"IEEE Workshop on Visual Motion, </title> <booktitle> 1989, </booktitle> <pages> pp. 54-59. </pages>
Reference-contexts: We are also exploring other methods besides vanishing point analysis for detecting the horizon line of an object plane in the image. Possibilities include analyzing texture gradients [13], and exploiting properties of the perspective projection of convex planar curves <ref> [2] </ref>. The techniques presented here may not be adequate to determine feature correspondences when structures are present in the scene that deviate significantly from coplanarity with respect to the viewing distance.
Reference: [3] <author> H.S. Baird, </author> <title> Model-Based Image Matching Using Location, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search <ref> [3, 14, 15] </ref>. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [4] <author> D.H. Ballard, </author> <title> "Generalizing the Hough Transform to Detect Arbitrary Shapes," </title> <journal> Pattern Recognition, </journal> <volume> Vol. 13(2), </volume> <year> 1981, </year> <pages> pp. 111-122. </pages>
Reference-contexts: Most previous approaches to affine matching do not seek optimal matches, and do not allow many-to-many 3 mappings between features. Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms <ref> [4, 17, 24] </ref> and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [5] <author> S.T. Barnard, </author> <title> "Interpreting Perspective Images," </title> <journal> AI Journal, </journal> <volume> Vol. 21(4), </volume> <month> November </month> <year> 1983, </year> <pages> pp. 435-462. </pages>
Reference-contexts: This simple approach works surprisingly well for many man-made scenes, both indoor, outdoor, and aerial. Vanishing points are found using a standard Hough transform approach <ref> [5] </ref>. Each line in the image is entered into a two dimensional Hough array representing the surface of a unit hemisphere. Each image line "votes" in a great (semi)circle of accumulators, and potential vanishing points are detected as peaks in the array where several great circles intersect.
Reference: [6] <author> J.R. Beveridge, R. Weiss and E.M. Riseman, </author> <title> "Combinatorial Optimization Applied to Variable Scale 2D Model Matching," </title> <booktitle> Proceedings IEEE International Conference on Pattern Recognition, </booktitle> <address> Atlantic City, </address> <month> June </month> <year> 1990, </year> <month> pp.18-23. </month>
Reference-contexts: Fast and reliable matching techniques exist when good initial guesses of pose or camera motion are available <ref> [6, 7] </ref> or when the distance between views is small [1]. What is lacking are good methods for finding matches in monocular images, formed by perspective projection, and taken from arbitrary viewpoints. <p> The first step is to rectify both sets of line segments using the techniques described above. This reduces the perspective matching problem to a simpler affine matching problem. The second step is to use a local search matching algorithm <ref> [6, 8] </ref> to find the optimal affine map and correspondence between the two sets of line segments. If both sets of line segments are extracted from images, then an image-to-image matching problem results. <p> However, there is an art to designing small neighborhoods that do not induce a profusion of local optima. New neighborhoods definitions have been developed that are particularly well suited to matching geometric features <ref> [6, 8] </ref>. Despite clever neighborhood definitions, local search can become stuck on local optima. Random sampling offers a probabilistic solution to the local optima problem.
Reference: [7] <author> J.R. </author> <title> Beveridge and E.M. Riseman, "Hybrid Weak-Perspective and Full-Perspective Matching," </title> <booktitle> Proceedings IEEE Computer Vision and Pattern Recognition, </booktitle> <address> Champaign, IL, </address> <month> June </month> <year> 1992, </year> <month> pp.432-438. </month>
Reference-contexts: Fast and reliable matching techniques exist when good initial guesses of pose or camera motion are available <ref> [6, 7] </ref> or when the distance between views is small [1]. What is lacking are good methods for finding matches in monocular images, formed by perspective projection, and taken from arbitrary viewpoints. <p> These correspondences were used to estimate an eight parameter planar projective transformation to bring the model lines into registration with the image data lines, using the least-squares estimation procedure of [12]. the input image lines. 1 There is a full 3D perspective version <ref> [7] </ref>, but it is inappropriate for these matching problems because exact camera parameters and an initial object pose estimate are required. 4.2 Image-to-Image Matching Because it does not rely on computing 3D object pose, this approach extends easily to image-to-image correspondence matching.
Reference: [8] <author> J.R. Beveridge, </author> <title> "Local Search Algorithms for Geometric Object Recognition: Optimal Correspondence and Pose," </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Massachusetts, </institution> <address> Amherst, MA 01003, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: The first step is to rectify both sets of line segments using the techniques described above. This reduces the perspective matching problem to a simpler affine matching problem. The second step is to use a local search matching algorithm <ref> [6, 8] </ref> to find the optimal affine map and correspondence between the two sets of line segments. If both sets of line segments are extracted from images, then an image-to-image matching problem results. <p> However, there is an art to designing small neighborhoods that do not induce a profusion of local optima. New neighborhoods definitions have been developed that are particularly well suited to matching geometric features <ref> [6, 8] </ref>. Despite clever neighborhood definitions, local search can become stuck on local optima. Random sampling offers a probabilistic solution to the local optima problem.
Reference: [9] <author> R.C. Bolles and R.A. Cain, </author> <title> "Recognizing and Locating Partially Visible Objects: the Local-feature-focus Method," </title> <journal> International Journal of Robotics Research, Vol.1, </journal> <volume> No.3, </volume> <year> 1982, </year> <month> pp.57-82. </month>
Reference-contexts: Finding the true match may require piecing together fragments from both images. Most previous approaches to affine matching do not seek optimal matches, and do not allow many-to-many 3 mappings between features. Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms <ref> [9, 21] </ref>, 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [10] <author> J.B. Burns, A.R. Hanson and E.M. Riseman, </author> <title> "Extracting Straight Lines," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 8, No. 4, </volume> <month> July </month> <year> 1986, </year> <month> pp.425-456. </month>
Reference-contexts: focal point from the image until two vectors pointing from the (variable) focal point towards two (fixed) vanishing points in the image are perpendicular. 4.1 Model-to-Image Matching Figures 1a) and b) show a set of straight line segments extracted from an image of a wall poster using the Burns algorithm <ref> [10] </ref>, and a set of model lines to be matched to the image.
Reference: [11] <author> B. Caprile and V. Torre, </author> <title> "Using Vanishing Points for Camera Calibration," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 4, </volume> <year> 1990, </year> <pages> pp. 127-140. </pages>
Reference-contexts: Aspect ratio was determined from the camera manufacturer's specifications, when available, otherwise it was assumed to be one-to-one. The focal length for each experiment was determined from vanishing point information and apriori knowledge that the dominant line directions were perpendicular in the scene <ref> [11] </ref>.
Reference: [12] <author> O.D. Faugeras and F. Lustman, </author> <title> "Motion and Structure from Motion in a Piecewise Planar Environ 8 ment," </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> Vol. 2, </volume> <year> 1988, </year> <pages> pp. 485-508. </pages>
Reference-contexts: These two solutions together constitute matching: a match being a correspondence plus a transformation. For planar structures under a perspective camera model, the relevant set of transformations is the eight parameter projective transformation group <ref> [12] </ref>. More restrictive transformations are worth special attention. Often these transformations are more easily computed, thus making matching easier. One such special case occurs for frontal planes, planar structures viewed "head-on" with the viewing direction of the camera held perpendicular to the object plane. <p> for intrinsic lens effects, the frontal view of an object plane can be described by a four parameter affine similarity mapping. 2.2 Arbitrary Orientations For planes viewed at an angle, the function mapping object coordinates to image coordinates is no longer affine, but is instead a more general projective transformation <ref> [12] </ref>. Lines that are parallel on a tilted object plane appear to converge in the image plane, intersecting at a vanishing point. Two or more vanishing points from different sets of coplanar parallel lines form a line in the image called the vanishing line or horizon line of the plane. <p> These correspondences were used to estimate an eight parameter planar projective transformation to bring the model lines into registration with the image data lines, using the least-squares estimation procedure of <ref> [12] </ref>. the input image lines. 1 There is a full 3D perspective version [7], but it is inappropriate for these matching problems because exact camera parameters and an initial object pose estimate are required. 4.2 Image-to-Image Matching Because it does not rely on computing 3D object pose, this approach extends easily <p> For calibrated cameras, the relative rotation and direction of translation between two camera positions can be computed from the perspective transformation describing how the appearance of a planar structure differs in the two images <ref> [12] </ref>. This reduces the search for other 3D feature correspondences to that of induced stereo, where corresponding feature points lie along known epipolar lines.
Reference: [13] <author> J. Garding, </author> <title> "Shape from Surface Markings," </title> <type> Ph.D. dissertation, </type> <institution> Royal Institute of Technology, </institution> <address> S-100 44 Stockholm, Sweden, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: We are also exploring other methods besides vanishing point analysis for detecting the horizon line of an object plane in the image. Possibilities include analyzing texture gradients <ref> [13] </ref>, and exploiting properties of the perspective projection of convex planar curves [2]. The techniques presented here may not be adequate to determine feature correspondences when structures are present in the scene that deviate significantly from coplanarity with respect to the viewing distance.
Reference: [14] <author> W.E.L. Grimson and T. Lozano-Perez, </author> <title> "Localizing Overlapping Parts by Searching the Interpretation Tree," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 9(3), </volume> <year> 1987, </year> <pages> pp. 469-482. </pages>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search <ref> [3, 14, 15] </ref>. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [15] <author> W.E.L. </author> <title> Grimson, Object Recognition by Computer: The Role of Geometric Constraints, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search <ref> [3, 14, 15] </ref>. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [16] <author> B.K.P. Horn, </author> <title> Robot Vision, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The combined effects of these parameters can be described by a general six parameter affine mapping of the ideal pinhole image onto the observed raster image <ref> [16] </ref>. A more realistic model of the projection of a frontal plane is thus a four parameter affine mapping of object features onto an idealized pinhole image, followed by a six parameter affine mapping onto the observed raster image.
Reference: [17] <author> J. Illingworth and J. Kittler, </author> <title> "A Survey of the Hough Transform," Computer Vision, Graphics, </title> <booktitle> and Image Processing, </booktitle> <address> Vol.44, </address> <year> 1988, </year> <pages> pp. 87-116. </pages>
Reference-contexts: Most previous approaches to affine matching do not seek optimal matches, and do not allow many-to-many 3 mappings between features. Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms <ref> [4, 17, 24] </ref> and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [18] <author> A. Kalvin, E. Schonberg, J.T. Schwartz and M. Sharir, </author> <title> "Two-dimensional, Model-based, Boundary Matching using Footprints," </title> <journal> International Journal of Robotics Research, </journal> <volume> Vol.5(4), </volume> <year> 1986, </year> <pages> pp. 38-55. </pages>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing <ref> [18, 20] </ref>, and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [19] <author> K. Kanatani, </author> <title> "Constraints on Length and Angle," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 41, </volume> <year> 1988, </year> <pages> pp. 28-42. </pages>
Reference-contexts: The effects of this camera rotation on the image can be simulated by an invertible projective transformation in the image plane <ref> [19] </ref>.
Reference: [20] <author> Y. Lamdan and H.J. Wolfson, </author> <title> "Geometric Hashing: A General and Efficient Model-based Recognition Scheme," </title> <booktitle> Proceedings IEEE Second International Conference on Computer Vision, </booktitle> <address> Tampa, </address> <month> December </month> <year> 1988, </year> <month> pp.238-249. </month>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing <ref> [18, 20] </ref>, and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [21] <author> D.G. Lowe, </author> <title> Perceptual Organization and Visual Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1985. </year>
Reference-contexts: Finding the true match may require piecing together fragments from both images. Most previous approaches to affine matching do not seek optimal matches, and do not allow many-to-many 3 mappings between features. Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms <ref> [9, 21] </ref>, 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [22] <author> H.S. Sawhney, </author> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1992. </year>
Reference-contexts: When the intrinsic camera parameters are known, perspective mapping of a frontal plane to its appearance in the image can be described with just four affine pa 1 rameters: an image rotation angle, a 2D translation vector, and an image scale <ref> [22] </ref>. 2.1 Frontal Planes Under the standard pinhole camera model, the image projection of world point (X; Y; Z) is the image point (X=Z; Y =Z).
Reference: [23] <author> G. Stockman, </author> <title> "Object Recognition and Localization via Pose Clustering," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 40, </volume> <year> 1987, </year> <month> pp.361-387. </month>
Reference-contexts: Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms [4, 17, 24] and pose clustering algorithms <ref> [23] </ref>, 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
Reference: [24] <author> D.W. Thompson and J.L. Mundy, </author> <title> "Three-Dimensional Model Matching from an Unconstrained Viewpoint," </title> <booktitle> IEEE Conference on Robotics and Automation, </booktitle> <address> Raleigh, NC, </address> <year> 1987, </year> <pages> pp. 208-220. 9 </pages>
Reference-contexts: Most previous approaches to affine matching do not seek optimal matches, and do not allow many-to-many 3 mappings between features. Common approaches to affine matching roughly fall into one of the following four categories: 1) key-feature algorithms [9, 21], 2) generalized Hough transforms <ref> [4, 17, 24] </ref> and pose clustering algorithms [23], 3) geometric hashing [18, 20], and 4) constraint-based tree search [3, 14, 15]. Key-feature approaches to matching seek some easily identified and distinctive feature which predicts the presence of the model as a whole.
References-found: 24

