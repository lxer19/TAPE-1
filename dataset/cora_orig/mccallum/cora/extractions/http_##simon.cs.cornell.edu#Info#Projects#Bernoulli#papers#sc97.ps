URL: http://simon.cs.cornell.edu/Info/Projects/Bernoulli/papers/sc97.ps
Refering-URL: 
Root-URL: 
Email: fvladimir,pingali,stodghilg@cs.cornell.edu  
Title: Compiling Parallel Code for Sparse Matrix Applications  
Author: Vladimir Kotlyar Keshav Pingali Paul Stodghill 
Keyword: parallelizing compilers, sparse matrix computations  
Date: August 18, 1997  
Address: Ithaca, NY 14853  
Affiliation: Department of Computer Science Cornell University,  
Abstract: We have developed a framework based on relational algebra for compiling efficient sparse matrix code from dense DO-ANY loops and a specification of the representation of the sparse matrix. In this paper, we show how this framework can be used to generate parallel code, and present experimental data that demonstrates that the code generated by our Bernoulli compiler achieves performance competitive with that of hand-written codes for important computational kernels.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Corinne Ancourt, Fabien Coelho, Franois Irigoin, and Ronan Keryell. </author> <title> A linear algebra framework for static hpf code distribution. </title> <booktitle> In CPC'93, </booktitle> <month> November </month> <year> 1993. </year> <note> http://cri.ensmp.fr/doc/A-250.ps.Z. </note>
Reference-contexts: of the COLP and ROWIND arrays in the CCS storage). * Permutations also can be handled by our compiler * The compilation algorithms are independent of any particular set of storage formats and new storage formats can be added to the compiler. 7 3 Generating parallel code Ancourt et al. <ref> [1] </ref> have described how the problem of generating SPMD code for dense HPF programs can be reduced to the computation of expressions in polyhedral algebra. <p> generation algorithm recursively. 3.2.4 Summary Here is the summary of our approach: * We represent distributed arrays as distributed relations. * We represent global-to-local index translation relations as distributed relations. * We represent parallel DOANY loop execution as distributed query evaluation. * For compiling dense HPF programs, Ancourt et al. <ref> [1] </ref> describe how the computation sets, communication sets etc. can be described by expressions in polyhedral algebra. We derive similar results for sparse programs, using relational algebra. 3.3 Compiling for the BlockSolve formats.
Reference: [2] <author> Corinne Ancourt and Franois Irigoin. </author> <title> Scanning polyhedra with do loops. </title> <booktitle> In Principle and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: For these iterations, we need efficient access to the corresponding entries in the matrices and vectors. Since the constraints are not linear and the sets being computed are not convex, we cannot use methods based on polyhedral algebra, such as Fourier-Motzkin elimination <ref> [2] </ref>, to enumerate these sets. Our approach is based on relational algebra, and it models A, X and Y as relations (tables) that hold tuples of array indices and values. Conceptually, the relation corresponding to a sparse matrix contains both zero and non-zero values.
Reference: [3] <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of PLDI'93, </booktitle> <month> June </month> <year> 1993. </year> <note> http://suif.stanford.edu/- papers/anderson93/paper.html. </note>
Reference-contexts: This is nothing 11 more than the statement of the fact that A and Y are aligned <ref> [3, 5] </ref>. So the join between A and Y can be translated into: A (i; j; a) ./ i Y (i; y) = p Notice that the join on the global index i has been translated into the join on the local offsets i 0 = i 00 .
Reference: [4] <institution> Argonne National Laboratory. </institution> <month> PETSc, </month> <title> the Portable, Extensible Toolkit for Scientific Computation. </title> <address> http://www.mcs.anl.gov/petsc/petsc.html. </address>
Reference-contexts: generated by 2D linear finite element model (b) Color/clique reordering in the Block Solve library (c) I-node storage (assuming that the result is stored in a single format)! The lack of extensibility in the sparse BLAS approach has been addressed by object-oriented solver libraries, like the PETSc library from Argonne <ref> [4] </ref>. Such libraries provide templates for a certain class of solvers (for example, Krylov space iterative solvers) and allow a user to add new formats by providing hooks for the implementations of some algebraic operations (such as matrix-vector product).
Reference: [5] <author> David Bau, Induprakas Kodukula, Vladimir Kotlyar, Keshav Pingali, and Paul Stodghil. </author> <title> Solving alignment using elementary linear algebra. </title> <booktitle> In Proceedings of the 7th LCPC Workshop, </booktitle> <month> August </month> <year> 1994. </year> <institution> Available as Cornell Computer Science Dept. </institution> <note> tech report TR95-1478. </note>
Reference-contexts: This is nothing 11 more than the statement of the fact that A and Y are aligned <ref> [3, 5] </ref>. So the join between A and Y can be translated into: A (i; j; a) ./ i Y (i; y) = p Notice that the join on the global index i has been translated into the join on the local offsets i 0 = i 00 .
Reference: [6] <author> Aart J.C. Bik and Harry A.G. Wijshoff. </author> <title> Advanced compiler optimizations for sparse computations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 31 </volume> <pages> 14-24, </pages> <year> 1995. </year>
Reference-contexts: The compiler is given a dense matrix program with declarations about which matrices are actually sparse, and it is responsible for choosing appropriate storage formats and for generating sparse matrix programs. This idea has been explored by Bik and Wijshoff <ref> [6, 7] </ref>, but their approach is limited to simple sparse matrix formats that are not representative of those used in high-performance codes. Intuitively, they trade the ability to handle a variety of formats for the ability to compile arbitrary loop nests. We have taken a different approach. <p> Therefore, the constraints in the third row of (1) can be now rewritten as: The predicate P is called the sparsity predicate. We use the algorithm of Bik and Wijshoff <ref> [6, 7] </ref> to compute the sparsity predicate in general. <p> For our target class of problems sparse DOANY loops our approach results in better quality of parallel code while reducing programming effort. 16 5 Previous work The closest alternative to our work is a combination of Bik's sparse compiler <ref> [6, 7] </ref> and the work on specifying and compiling sparse codes in HPF Fortran [19, 21, 22]). One could use the sparse compiler to translate dense sequential loops into sparse loops. Then, the Fortran D or Vienna Fortran compiler can be used to compile these sparse loops.
Reference: [7] <author> Aart J.C. Bik and Harry A.G. Wijshoff. </author> <title> Automatic data structure selection and transformation for sparse matrix computations. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 7(2):109 - 126, </volume> <year> 1996. </year>
Reference-contexts: The compiler is given a dense matrix program with declarations about which matrices are actually sparse, and it is responsible for choosing appropriate storage formats and for generating sparse matrix programs. This idea has been explored by Bik and Wijshoff <ref> [6, 7] </ref>, but their approach is limited to simple sparse matrix formats that are not representative of those used in high-performance codes. Intuitively, they trade the ability to handle a variety of formats for the ability to compile arbitrary loop nests. We have taken a different approach. <p> Therefore, the constraints in the third row of (1) can be now rewritten as: The predicate P is called the sparsity predicate. We use the algorithm of Bik and Wijshoff <ref> [6, 7] </ref> to compute the sparsity predicate in general. <p> For our target class of problems sparse DOANY loops our approach results in better quality of parallel code while reducing programming effort. 16 5 Previous work The closest alternative to our work is a combination of Bik's sparse compiler <ref> [6, 7] </ref> and the work on specifying and compiling sparse codes in HPF Fortran [19, 21, 22]). One could use the sparse compiler to translate dense sequential loops into sparse loops. Then, the Fortran D or Vienna Fortran compiler can be used to compile these sparse loops.
Reference: [8] <author> R.F. Boisvert, R. Pozo, K. Remington, R.F. Barrett, and J.J. Dongarra. </author> <title> The Quality of Numerical Software: Assessment and Enhancement, chapter Matrix Market: a web resource for test matrix collections, </title> <address> pages 125-137. </address> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1997. </year>
Reference: [9] <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification, </title> <note> version 2.0. http://www.crpc.rice.edu/HPFF/home.html. </note>
Reference-contexts: In the case of regular block/cyclic distributions the distribution relations can be specified by a closed-form formula. This allows ownership information to be computed at compile-time. However, regular distributions might not provide adequate load-balance in many irregularly structured applications. The HPF-2 standard <ref> [9] </ref> provides for two kinds of irregular distributions: generalized block and indirect. In generalized block distribution, each processor receives a single block of continuous rows. It is suggested in the standard that each processor should hold the block sizes for all processors that is the distribution relation should be replicated. <p> The compiler then generates the necessary communication and index translations for the product with A SNL . This mixed specification (both data-parallel and node level programs) is not unique to our approach. For example, HPF allows the programmer to "escape" to the node program level by using extrinsics <ref> [9] </ref>. In general, sophisticated composite sparse formats, such as the one used in the BlockSolve library, might require algorithm specification at a different level than just a dense loop. <p> As the result, the executor in Bernoulli code is about 10% slower than in the Bernoulli-Mixed code. To demonstrate the benefit of exposing structure in distribution relations, we have measured the inspector overhead for using the indirect distribution format from the HPF-2 standard <ref> [9] </ref>. We have implemented two versions of the inspectors using the support for the indirect distribution in the Chaos library [15]: * Indirect-Mixed is the inspector for the mixed local/global specification of (24). 15 * Indirect is the inspector for the fully data parallel specification.
Reference: [10] <author> Alan George and Joseph W-H Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1981. </year>
Reference-contexts: Second, for most algorithms, it takes a lot of code reorganization to produce an efficient sparse program that is tuned to a particular format. We illustrate these points by describing two formats | a classical format called Compressed Column Storage (CCS) <ref> [10] </ref> and a modern one used in the BlockSolve library [11] | which will serve as running examples in this abstract. CCS format is illustrated in Fig. 1. The matrix is compressed along the columns and is stored using three arrays: COLP, VALS and ROWIND.
Reference: [11] <author> Mark T. Jones and Paul E. Plassmann. </author> <title> BlockSolve95 users manual: Scalable library software for the parallel solution of sparse linear systems. </title> <type> Technical Report ANL-95/48, </type> <institution> Argonne National Laboratory, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: We illustrate these points by describing two formats | a classical format called Compressed Column Storage (CCS) [10] and a modern one used in the BlockSolve library <ref> [11] </ref> | which will serve as running examples in this abstract. CCS format is illustrated in Fig. 1. The matrix is compressed along the columns and is stored using three arrays: COLP, VALS and ROWIND. <p> However, it does not exploit any application specific structure in the matrix. The format used in the BlockSolve library exploits structure present in sparse matrices that arise in the solution of PDE's with multiple degrees of freedom. Figure 2 (a) (adapted from <ref> [11] </ref>) illustrates a grid that would arise from 2-D, linear, multi-component finite-element model with three degrees of freedom at each discretization point. The degrees of freedom are illustrated by the three dots at each discretization point.
Reference: [12] <author> D. Kincaid, J. Respess, D. Young, and R Grimes. </author> <title> Algorithm 586 ITPACK 2C: A FORTRAN package for solving large sparse linear systems by adaptive accelerated iterative methods. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 8(3) </volume> <pages> 302-322, </pages> <month> September </month> <year> 1982. </year> <month> 18 </month>
Reference: [13] <author> Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill. </author> <title> Compiling parallel sparse code for user-defined data structures. </title> <booktitle> In Proceedings of Eights SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> March </month> <year> 1997. </year>
Reference-contexts: We have taken a different approach. Previously, we have shown how efficient sparse sequential code can be generated for a variety of storage formats for DOALL loops and loops with reductions <ref> [13, 14] </ref>. Our approach is based on viewing arrays as relations, and the execution of loop nests as evaluation of relational queries. <p> For the details on how the formats are specified to the compiler, see <ref> [13] </ref>. 2.2 Index Translations Some sparse formats such as jagged-diagonal storage involve permutations of row and column indices. Permutations and other kinds of index translations can be easily incorporated into our framework.
Reference: [14] <author> Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill. </author> <title> A relational approach to sparse matrix compilation. </title> <booktitle> In EuroPar, </booktitle> <month> August </month> <year> 1997. </year> <note> Available as Cornell Computer Science Tech. Report 97-1627. </note>
Reference-contexts: We have taken a different approach. Previously, we have shown how efficient sparse sequential code can be generated for a variety of storage formats for DOALL loops and loops with reductions <ref> [13, 14] </ref>. Our approach is based on viewing arrays as relations, and the execution of loop nests as evaluation of relational queries. <p> These methods and their properties are used to determine good join orders and join implementations for each relational query extracted from the program, as described in <ref> [14] </ref>. This way of describing storage formats to the compiler through access methods and properties solves the extensibility problem: a variety of storage formats can be described to the compiler, and the compilation strategy does not depend on a fixed set of formats.
Reference: [15] <author> Ravi Ponnusamy, Joel Saltz, and Alok Choudhary. </author> <title> Runtime-compilation techniques for data partitioning and communication schedule reuse. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 361-370, </pages> <month> November </month> <year> 1993. </year> <month> ftp://hpsl.cs.umd.edu/pub/papers/comp-mapper.ps.Z. </month>
Reference-contexts: The MAP array itself can be distributed a variety of ways. However, this can require communication to determine ownership of non-local data. The Chaos library <ref> [15] </ref> allows the user to specify partitioning information by providing the list of row indices assigned to each processor. The list of indices are transferred into distributed translation table which is equivalent to having a MAP array partitioned block-wise. <p> But there are other situations, when a processors other than p might own the translation information for the fragment stored on p. A good example is the distributed translation table used in the Chaos library <ref> [15] </ref>. Suppose that the global indices fall into the range 0 i N 1 for some N . Also, let P be the number of processors. Let B = dN=P e. <p> The algorithm we studied is a parallel Conjugate Gradient [18] solver with diagonal preconditioning (CG), which solves large sparse systems of linear equations iteratively. Following the terminology from Chaos project, the parallel implementation of the algorithm can be divided into the inspector phase and the executor phase <ref> [15] </ref>. The inspector determines the the set of values to be communicated and performs some other preprocessing. The executor performs the actual computation and communication. In iterative applications the cost of the inspector can usually be amortized over several iterations of the executor. <p> To demonstrate the benefit of exposing structure in distribution relations, we have measured the inspector overhead for using the indirect distribution format from the HPF-2 standard [9]. We have implemented two versions of the inspectors using the support for the indirect distribution in the Chaos library <ref> [15] </ref>: * Indirect-Mixed is the inspector for the mixed local/global specification of (24). 15 * Indirect is the inspector for the fully data parallel specification.
Reference: [16] <author> Raghu Ramakrishnan. </author> <title> Database Management Systems. College Custom Series. </title> <publisher> McGraw-Hill, Inc, </publisher> <address> beta edition, </address> <year> 1996. </year>
Reference-contexts: These decisions depend on the storage formats used for the sparse arrays. 2.1 Describing Storage Formats Following ideas from relational database literature <ref> [16, 20] </ref>, each sparse storage format is described in terms of its access methods and their properties. Unlike database relations, which are usually stored as "flat" collections of tuples, most sparse storage formats have hierarchical structure, which must be exploited for efficiency.
Reference: [17] <author> John R. Rice and Ronald F. Boisvert. </author> <title> Solving Elliptic Problems Using ELLPACK. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference: [18] <author> Youcef Saad. </author> <title> Kyrlov subspace methods on supercomputers. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 10(6) </volume> <pages> 1200-1232, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The algorithm we studied is a parallel Conjugate Gradient <ref> [18] </ref> solver with diagonal preconditioning (CG), which solves large sparse systems of linear equations iteratively. Following the terminology from Chaos project, the parallel implementation of the algorithm can be divided into the inspector phase and the executor phase [15].
Reference: [19] <author> Manuel Ujaldon, Emilio Zapata, Barbara M. Chapman, and Hans P. Zima. </author> <title> New data-parallel language features for sparse matrix computations. </title> <type> Technical report, </type> <institution> Institute for Software Technology and Parallel Systems, University of Vienna, </institution> <year> 1995. </year> <note> http://www.vcpc.univie.ac.at/activities/language. </note>
Reference-contexts: class of problems sparse DOANY loops our approach results in better quality of parallel code while reducing programming effort. 16 5 Previous work The closest alternative to our work is a combination of Bik's sparse compiler [6, 7] and the work on specifying and compiling sparse codes in HPF Fortran <ref> [19, 21, 22] </ref>). One could use the sparse compiler to translate dense sequential loops into sparse loops. Then, the Fortran D or Vienna Fortran compiler can be used to compile these sparse loops.
Reference: [20] <author> Jeffrey D. Ullman. </author> <title> Principles of Database and Knowledge-Base Systems, v. I and II. </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: These decisions depend on the storage formats used for the sparse arrays. 2.1 Describing Storage Formats Following ideas from relational database literature <ref> [16, 20] </ref>, each sparse storage format is described in terms of its access methods and their properties. Unlike database relations, which are usually stored as "flat" collections of tuples, most sparse storage formats have hierarchical structure, which must be exploited for efficiency. <p> In the context of, say, a banking database spread across branches of the bank, the partitioning of the relations is fixed, and may not be optimal for each query submitted to the system. This is why the choice of sites might be non-trivial in such applications. See <ref> [20] </ref> for a detailed discussion of the general distributed query optimization problem. In our case, we expect that the placement of the relations is correlated with the query itself and is given to us by the user.
Reference: [21] <author> Rinhard v. Hanxleden, Ken Kennedy, and Joel Saltz. </author> <title> Value-based distributions and alignments in Fortran D. </title> <type> Technical Report CRPC-TR93365-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: These inconsistencies, in general, can only be detected at runtime. For example, it can only be verified at run-time if a user specified distribution relation IN D in fact provides a 1-1 and onto map. This problem is not unique to our framework - HPF with value-based distributions <ref> [21] </ref> has a similar problem. Basically, if a function is specified by its values at run-time, its properties can only be checked at run-time. <p> class of problems sparse DOANY loops our approach results in better quality of parallel code while reducing programming effort. 16 5 Previous work The closest alternative to our work is a combination of Bik's sparse compiler [6, 7] and the work on specifying and compiling sparse codes in HPF Fortran <ref> [19, 21, 22] </ref>). One could use the sparse compiler to translate dense sequential loops into sparse loops. Then, the Fortran D or Vienna Fortran compiler can be used to compile these sparse loops.
Reference: [22] <author> Janet Wu, Raja Das, Joel Saltz, Harry Berryman, and Seema Hiranandani. </author> <title> Distributed memory compiler design for sparse problems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(6), </volume> <year> 1995. </year> <note> ftp://hyena.cs.umd.edu/pub/papers/ieee toc.ps.Z. </note>
Reference-contexts: class of problems sparse DOANY loops our approach results in better quality of parallel code while reducing programming effort. 16 5 Previous work The closest alternative to our work is a combination of Bik's sparse compiler [6, 7] and the work on specifying and compiling sparse codes in HPF Fortran <ref> [19, 21, 22] </ref>). One could use the sparse compiler to translate dense sequential loops into sparse loops. Then, the Fortran D or Vienna Fortran compiler can be used to compile these sparse loops.
References-found: 22

