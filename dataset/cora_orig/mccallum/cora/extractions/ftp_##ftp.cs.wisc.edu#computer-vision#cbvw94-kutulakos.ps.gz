URL: ftp://ftp.cs.wisc.edu/computer-vision/cbvw94-kutulakos.ps.gz
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: kyros@cs.wisc.edu  seales@ms.uky.edu  dyer@cs.wisc.edu  
Title: Building Global Object Models By Purposive Viewpoint Control  
Author: Kiriakos N. Kutulakos W. Brent Seales Charles R. Dyer 
Address: Madison, WI 53706 USA  Lexington, Kentucky 40536 USA  Madison, WI 53706 USA  
Affiliation: Computer Sciences Department University of Wisconsin  Computer Sciences Department University of Kentucky  Computer Sciences Department University of Wisconsin  
Date: 1994  
Note: In: Proc. 2nd CAD-Based Vision Workshop, Champion, PA,  
Abstract: We present an approach for recovering a global surface model of an object from the deformation of the occluding contour using an active (i.e., mobile) observer able to control its motion. In particular, we consider two problems: (1) How can the observer's viewpoint be controlled in order to generate a dense sequence of images that allows incremental reconstruction of an unknown surface, and (2) how can we construct a global surface model from the generated image sequence? Solving these two problems is crucial for automatically constructing models of objects whose surface is non-convex and self-occludes. We achieve the first goal by purposefully and qualitatively controlling the observer's instantaneous direction of motion in order to control the motion of the visible rim over the surface. We achieve the second goal by using a calibrated trinocular camera rig and a mechanism for controlling the relative position and orientation of the viewed surface with respect to the trinocular rig. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Cipolla and A. Blake, </author> <title> Surface shape from the deformation of apparent contours, </title> <journal> Int. J. Computer Vision, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 83-112, </pages> <year> 1992. </year> <title> (a) (b) </title>
Reference-contexts: 1 Introduction There has been considerable interest in approaches that recover information about the structure of a scene from sequences of images, assuming an observer in motion (e.g., work on optical flow and shape-from-motion <ref> [1] </ref>). One common feature of these approaches is that they use a dense sequence of images produced by an observer undergoing arbitrary, but known, motion. <p> All these tasks require the use of multiple viewpoint control behaviors that must be appropriately integrated. Our work builds directly on work on the occluding contour by Giblin and Weiss [6], Cipolla and Blake <ref> [1] </ref>, Vaillant and Faugeras [7], and Koenderink [8]. <p> Previous shape-recovery approaches using the occluding contour studied how its deformation over a dense sequence of frames can be used to recover local shape information for points projecting to the occluding contour <ref> [1, 7] </ref>. <p> been applied to uncluttered scenes containing geometrically-trivial objects such as ovoids, or has been applied to more complicated objects such as those bounded by surfaces of revolution under the assumption that the motion of the observer was not arbitrary (e.g., the observer moves roughly perpendicular to the axis of revolution <ref> [1] </ref>). unknown, is non-convex, and even self-occludes. 2 Our approach therefore uses a very simple principle: Since any attempt at reconstruction from the occluding contour using arbitrary observer motion will miss parts of the object's surface, we simply let the object itself determine how to view it. <p> It is quite fortunate that the occluding contour provides all the information necessary to achieve the global reconstruction goal: Recent results demonstrate that the occluding contour can be efficiently tracked [10], and that shape information can be recovered from the deformation of the occluding contour even with a monocular observer <ref> [1, 11, 12] </ref>. Furthermore, our experimental results show that the occluding contour can be reliably detected in edge images, can be used to recover quantitative shape information and, moreover, can guide the purposive viewpoint adjustment process. <p> These surface patches can be represented using the epipolar parameterization which describes the motion of the visible rim over the surface (see Figures 2 and 8 (a)). This parameterization has been used by several researchers <ref> [1, 6] </ref> to derive the fundamental forms of the surface for all points lying on these patches from the deformation of the visible rim's projection, i.e., the occluding contour. 3 Local Reconstruction by Purposive Motion In our approach, both global and incremental reconstruction is performed by integrating a collection of qualitative <p> This process involves constructing a surface model based on the surface's deforming occluding contour and is independent of the way the observer's viewpoint is changed. The behaviors described in the previous sections can be combined directly with the reconstruction approach of Cipolla and Blake <ref> [1] </ref> which employs a mobile monocular observer to reconstruct the surface from the deformation of the occluding contour. However, our viewpoint control behaviors are not restricted to this specific method for recovering shape from the occluding contour.
Reference: [2] <author> Y. Aloimonos, </author> <title> Purposive and qualitative active vision, </title> <booktitle> in Proc. Int. Conf. on Pattern Recognition, </booktitle> <pages> pp. 346-360, </pages> <year> 1990. </year>
Reference-contexts: Unfortunately, arbitrary motion implies that the parts of the scene reconstructed are not under the observer's control, limiting the applicability of such approaches to the automated construction of accurate object models for non-convex and self-occluding objects. In this paper we combine the shape-from-motion paradigm with the purposive vision paradigm <ref> [2] </ref> in order to recover a global surface description of an object by The support of the National Science Foundation under Grant No.
Reference: [3] <author> D. H. Ballard and C. M. Brown, </author> <title> Principles of animate vision, in Active Perception (Y. </title> <publisher> Aloimonos, ed.), </publisher> <pages> pp. 245-282, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1993. </year>
Reference-contexts: At the lower, quantitative level we consider the task of building a global object model from the generated sequence. We achieve our higher-level goal by employing simple observer behaviors <ref> [3] </ref> for controlling viewpoint that allow the observer to maintain specific geometric relationships with the viewed scene [4, 5]; we achieve our lower-level goal by using a calibrated trinocular camera rig and a mechanism for controlling the relative position and orientation of the object with respect to the rig.
Reference: [4] <author> S. Hutchinson, </author> <title> Exploiting visual constraints in robot motion planning, </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 1722-1727, </pages> <year> 1991. </year>
Reference-contexts: At the lower, quantitative level we consider the task of building a global object model from the generated sequence. We achieve our higher-level goal by employing simple observer behaviors [3] for controlling viewpoint that allow the observer to maintain specific geometric relationships with the viewed scene <ref> [4, 5] </ref>; we achieve our lower-level goal by using a calibrated trinocular camera rig and a mechanism for controlling the relative position and orientation of the object with respect to the rig.
Reference: [5] <author> K. N. Kutulakos and C. R. Dyer, </author> <title> Recovering shape by purposive viewpoint adjustment, </title> <journal> Int. J. Computer Vision, </journal> <year> 1994. </year> <title> Special Issue on Active Vision II. </title> <note> To appear. </note>
Reference-contexts: At the lower, quantitative level we consider the task of building a global object model from the generated sequence. We achieve our higher-level goal by employing simple observer behaviors [3] for controlling viewpoint that allow the observer to maintain specific geometric relationships with the viewed scene <ref> [4, 5] </ref>; we achieve our lower-level goal by using a calibrated trinocular camera rig and a mechanism for controlling the relative position and orientation of the object with respect to the rig. <p> The behaviors developed follow principles similar to those in <ref> [5] </ref>. These basic behaviors are used in Section 4 to define an incremental reconstruction behavior that guides the observer's motion in order to expand the set of surface points reconstructed. To demonstrate the applicability and effectiveness of our approach, we apply the developed be haviors to synthetic scenes. <p> reconstruct the surface in some neighborhood of p using the epipolar parameterization. 4 Given a collection of basic behaviors that provably perform this task, incremental surface reconstruction is achieved by appropriately combining them (Section 4). 4 The formulation of the local reconstruction task is similar to the one reported in <ref> [5] </ref>, where a visible rim point p was selected and the surface shape at p was recovered by controlling the observer's viewpoint. The difference here is that the shape of the surface in a whole patch around p is recovered, instead of just the shape at p. <p> The main idea is similar to the one in <ref> [5] </ref>: If the observer moves along specific directions on the tangent plane of the selected point p, p will remain on the visible rim but will cease to be the endpoint of the visible rim curve containing it.
Reference: [6] <author> P. Giblin and R. Weiss, </author> <title> Reconstruction of surfaces from profiles, </title> <booktitle> in Proc. 1st Int. Conf. on Computer Vision, </booktitle> <pages> pp. 136-144, </pages> <year> 1987. </year>
Reference-contexts: All these tasks require the use of multiple viewpoint control behaviors that must be appropriately integrated. Our work builds directly on work on the occluding contour by Giblin and Weiss <ref> [6] </ref>, Cipolla and Blake [1], Vaillant and Faugeras [7], and Koenderink [8]. <p> The visible rim and the occluding contour corresponding to the projection of a bean-shaped surface are shown <ref> [6] </ref>. The occluding contour consists of a single curve whose endpoints are a T-junction and a cusp. For simplicity, we show the visible rim projected to a planar image perpendicular to p occ . points at which the line of sight is tangent to the surface. <p> These surface patches can be represented using the epipolar parameterization which describes the motion of the visible rim over the surface (see Figures 2 and 8 (a)). This parameterization has been used by several researchers <ref> [1, 6] </ref> to derive the fundamental forms of the surface for all points lying on these patches from the deformation of the visible rim's projection, i.e., the occluding contour. 3 Local Reconstruction by Purposive Motion In our approach, both global and incremental reconstruction is performed by integrating a collection of qualitative
Reference: [7] <author> R. Vaillant and O. D. Faugeras, </author> <title> Using extremal boundaries for 3-d object modeling, </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 14, no. 2, </volume> <pages> pp. 157-173, </pages> <year> 1992. </year>
Reference-contexts: All these tasks require the use of multiple viewpoint control behaviors that must be appropriately integrated. Our work builds directly on work on the occluding contour by Giblin and Weiss [6], Cipolla and Blake [1], Vaillant and Faugeras <ref> [7] </ref>, and Koenderink [8]. The occluding contour is the projection of the visible rim, the set of visible 1 Image of Projection plane T (S) p cusp T-junction p occ c Visible rim p in the direction of the ray passing through p and the observer's viewpoint, c. <p> Previous shape-recovery approaches using the occluding contour studied how its deformation over a dense sequence of frames can be used to recover local shape information for points projecting to the occluding contour <ref> [1, 7] </ref>. <p> However, our viewpoint control behaviors are not restricted to this specific method for recovering shape from the occluding contour. In particular, we extend the work of Vaillant and Faugeras <ref> [7] </ref> and employ a stationary calibrated trinocular camera rig. The rig allows the surface to be viewed from three viewpoints that are close to each other. <p> each other and to the scene) are sufficient to discriminate between occluding contour edges and surface discontinuities, and enable the recovery of the position, surface normal, and surface curvature for a dense set of points that lie in the vicinity of the visible rim corresponding to the three camera viewpoints <ref> [7] </ref>. Purposive viewpoint control is achieved by appropriately rotating the viewed surface. Such a rotation corresponds to an instantaneous motion vector v.
Reference: [8] <author> J. J. Koenderink, </author> <title> An internal representation for solid shape based on the topological properties of the apparent contour, in Image Understanding 1985-86 (W. </title> <editor> Richards and S. Ullman, </editor> <booktitle> eds.), </booktitle> <pages> pp. 257-285, </pages> <address> Nor-wood, NJ: </address> <publisher> Ablex Publishing Co., </publisher> <year> 1987. </year>
Reference-contexts: All these tasks require the use of multiple viewpoint control behaviors that must be appropriately integrated. Our work builds directly on work on the occluding contour by Giblin and Weiss [6], Cipolla and Blake [1], Vaillant and Faugeras [7], and Koenderink <ref> [8] </ref>. The occluding contour is the projection of the visible rim, the set of visible 1 Image of Projection plane T (S) p cusp T-junction p occ c Visible rim p in the direction of the ray passing through p and the observer's viewpoint, c. <p> Generically, the occluding contour is a collection of open and closed smooth curves for almost all (in a measure-theoretic sense) positions of the observer. 3 The endpoints of open occluding contour curves are either cusps or T-junctions <ref> [8] </ref>. The 3 The occluding contour's topological changes are associated with a collection of special curves on the surface, the visual event curves [9, 16]. <p> Step 2: Compute the surface normal at p. The normal is given by T ^ p occ , where T is the tangent to the occluding contour at p occ <ref> [8] </ref>. Step 3: (Reconstructing the occluded points near p.) Select a direction v that satisfies the inequality n (p)v &gt; 0. Perform a small viewpoint adjustment along v while monitoring the deformation of the occluding contour curve that initially contains p occ . <p> the Appendix for a proof. 7 This strategy gracefully degrades when p approximates parabolic points on the surface, where the angle between the point's asymptotes can tend to zero, or when the line connecting p and c approaches a line with one third-order and one second-order contact with the surface <ref> [8] </ref>. See [9] for a description of a stopping condition that guarantees global reconstruction. 4 Incremental Surface Reconstruction An incremental reconstruction strategy must guide the motion of the observer so that new patches on the surface are reconstructed.
Reference: [9] <author> K. N. Kutulakos and C. R. Dyer, </author> <title> Global surface reconstruction by purposive control of observer motion, </title> <type> Tech. Rep. 1141, </type> <institution> Computer Sciences Department, University of Wisconsin Madison, </institution> <month> April </month> <year> 1993. </year> <note> Available via ftp from ftp.cs.wisc.edu. </note>
Reference-contexts: We show how the motion of the visible rim over the object's surface can be characterized qualitatively and how the observer can control this motion by controlling 2 For a general treatment of the global reconstruction task see <ref> [9] </ref>. p c (t + t) 0 x (s,t + t) 0 D u x (s (t),t) x (s,t ) 0 epipolar plane P s x Curves x (s; t 0 ) and x (s; t 0 + t) are curves on the visible rim of the surface corresponding to observer <p> The 3 The occluding contour's topological changes are associated with a collection of special curves on the surface, the visual event curves <ref> [9, 16] </ref>. In [9] we show that a subset of these curves bounds the reconstructible regions on the surface. (a) v (t) a (b) v (t) L 1 of S with the epipolar plane fl. <p> The 3 The occluding contour's topological changes are associated with a collection of special curves on the surface, the visual event curves [9, 16]. In <ref> [9] </ref> we show that a subset of these curves bounds the reconstructible regions on the surface. (a) v (t) a (b) v (t) L 1 of S with the epipolar plane fl. <p> The special sets for which this cannot be achieved bound the re constructible surface regions <ref> [9] </ref>. <p> In Section 3.2 we only present how the first of these three cases is handled. The other two cases can be handled by following a similar approach <ref> [9] </ref>. 3.1 Local reconstruction around ordinary points This section presents the crucial link between the ability to control the motion of the observer and the problem of guiding the surface reconstruction process. <p> See <ref> [9] </ref> for a description of a stopping condition that guarantees global reconstruction. 4 Incremental Surface Reconstruction An incremental reconstruction strategy must guide the motion of the observer so that new patches on the surface are reconstructed. <p> Point p remains on the rim throughout the motion and can be tracked by tracking the occluding contour point whose tangent is horizontal (middle view). The sequence clearly shows that p becomes an ordinary visible rim point after the viewpoint adjustments. satisfies additional requirements [18]. In <ref> [9] </ref>, where the global reconstruction task is investigated in its generality, we show that the observer must obey a specific rule that grounds this point selection process. 5 Building a Global Surface Model In the previous sections we described a set of viewpoint control behaviors enabling the generation of a sequence
Reference: [10] <author> A. Blake, R. Curwen, and A. Zisserman, </author> <title> A framework for spatio-temporal control in the tracking of visual contours, </title> <journal> Int. J. Computer Vision, </journal> <volume> vol. 11, no. 2, </volume> <year> 1993. </year> <note> Special Issue on Active Vision I. </note>
Reference-contexts: It is quite fortunate that the occluding contour provides all the information necessary to achieve the global reconstruction goal: Recent results demonstrate that the occluding contour can be efficiently tracked <ref> [10] </ref>, and that shape information can be recovered from the deformation of the occluding contour even with a monocular observer [1, 11, 12].
Reference: [11] <author> A. Blake, A. Zisserman, and R. Cipolla, </author> <title> Visual exploration of free-space, in Active Vision (A. </title> <editor> Blake and A. Yuille, </editor> <booktitle> eds.), </booktitle> <pages> pp. 175-188, </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: It is quite fortunate that the occluding contour provides all the information necessary to achieve the global reconstruction goal: Recent results demonstrate that the occluding contour can be efficiently tracked [10], and that shape information can be recovered from the deformation of the occluding contour even with a monocular observer <ref> [1, 11, 12] </ref>. Furthermore, our experimental results show that the occluding contour can be reliably detected in edge images, can be used to recover quantitative shape information and, moreover, can guide the purposive viewpoint adjustment process.
Reference: [12] <author> R. Curwen, A. Blake, and A. Zisserman, </author> <title> Real-time visual tracking for surveillance and path planning, </title> <booktitle> in Proc. 2nd European Conf. on Computer Vision, </booktitle> <pages> pp. 879-883, </pages> <year> 1992. </year>
Reference-contexts: It is quite fortunate that the occluding contour provides all the information necessary to achieve the global reconstruction goal: Recent results demonstrate that the occluding contour can be efficiently tracked [10], and that shape information can be recovered from the deformation of the occluding contour even with a monocular observer <ref> [1, 11, 12] </ref>. Furthermore, our experimental results show that the occluding contour can be reliably detected in edge images, can be used to recover quantitative shape information and, moreover, can guide the purposive viewpoint adjustment process.
Reference: [13] <author> J. Maver and R. </author> <title> Bajcsy, Occlusions as a guide for planning the next view, </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 15, no. 5, </volume> <pages> pp. 417-433, </pages> <year> 1993. </year>
Reference-contexts: Consequently, instead of using mechanisms that require sophisticated sensors (e.g., range sensors or laser scanners) to reconstruct the scene from a single viewpoint or a small number of viewpoints <ref> [13, 14] </ref>, we control viewpoint in a simple and efficient manner that allows us to use the occluding contour for reconstruction.
Reference: [14] <author> P. Whaite and F. P. Ferrie, </author> <title> From uncertainty to visual exploration, </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 13, no. 10, </volume> <pages> pp. 1038-1049, </pages> <year> 1991. </year>
Reference-contexts: Consequently, instead of using mechanisms that require sophisticated sensors (e.g., range sensors or laser scanners) to reconstruct the scene from a single viewpoint or a small number of viewpoints <ref> [13, 14] </ref>, we control viewpoint in a simple and efficient manner that allows us to use the occluding contour for reconstruction.
Reference: [15] <author> M. P. D. Carmo, </author> <title> Differential Geometry of Curves and Surfaces. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall Inc., </publisher> <year> 1976. </year>
Reference-contexts: The local shape of the surface at p is determined by the first and second fundamental forms I (p); I I (p) at p which can be computed from x <ref> [15] </ref>. The rim of S is the set of surface points for which T p (S) contains the line segment connecting p and the observer's viewpoint, c. The visible rim consists of the rim points that are visible.
Reference: [16] <author> S. Petitjean, J. Ponce, and D. J. Kriegman, </author> <title> Computing exact aspect graphs of curved objects: Algebraic surfaces, </title> <journal> Int. J. Computer Vision, </journal> <volume> vol. 9, no. 3, </volume> <pages> pp. 231-255, </pages> <year> 1992. </year>
Reference-contexts: The 3 The occluding contour's topological changes are associated with a collection of special curves on the surface, the visual event curves <ref> [9, 16] </ref>. In [9] we show that a subset of these curves bounds the reconstructible regions on the surface. (a) v (t) a (b) v (t) L 1 of S with the epipolar plane fl.
Reference: [17] <author> J. J. Koenderink, </author> <title> Solid Shape. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The geometry of the intersection of S with the epipolar planes corresponding to visible rim points close to p is also similar to the one shown. shape and topology of this collection of curves depends on S and the observer's viewpoint <ref> [17] </ref>. Under continuous observer motion and when the topology of the visible rim does not change, the visible rim slides over the surface, tracing patches.
Reference: [18] <author> K. Tarabanis and R. Y. Tsai, </author> <title> Computing viewpoints that satisfy optical constraints, </title> <booktitle> in Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 152-158, </pages> <year> 1991. </year>
Reference-contexts: Point p remains on the rim throughout the motion and can be tracked by tracking the occluding contour point whose tangent is horizontal (middle view). The sequence clearly shows that p becomes an ordinary visible rim point after the viewpoint adjustments. satisfies additional requirements <ref> [18] </ref>.
Reference: [19] <author> W. B. Seales and O. D. Faugeras, </author> <title> Global surface reconstruction from the extremal boundary, </title> <type> technical report, </type> <institution> University of Kentucky, Lexington, Kentucky, </institution> <year> 1992. </year>
Reference-contexts: The figure on the right shows the patch traced by the visible rim segment projecting to B 5 . Details of our reconstruction approach and its robustness are described elsewhere <ref> [19] </ref>. <p> We briefly describe our approach to these two problems below. 5.1 Fusing multiple reconstructed patches Since viewpoint is controlled using the viewpoint control behaviors developed in Sections 3 and 4, we assume here that the motion of the viewed surface is known 8 and 8 However, Seales and Faugeras <ref> [19] </ref> describe an alternative approach that discards the known motion assumption and recovers the motion of the surface from the motion of fixed edges on that surface. that the trinocular camera rig is calibrated. <p> The interested reader is referred to recent work by Seales and Faugeras <ref> [19] </ref>. The reconstruction results for two sequences of 15 views are shown in Figure 9. The ceramic owl was placed on a box in order to produce edge images containing both fixed and occluding contour edges.
Reference: [20] <author> J. J. Koenderink and A. J. van Doorn, </author> <title> The shape of smooth objects and the way contours end, in Natural Computation (W. Richards, </title> <publisher> ed.), </publisher> <pages> pp. 115-124, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1988. </year>
References-found: 20

