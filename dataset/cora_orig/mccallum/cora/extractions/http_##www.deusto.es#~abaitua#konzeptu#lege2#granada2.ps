URL: http://www.deusto.es/~abaitua/konzeptu/lege2/granada2.ps
Refering-URL: http://www.deusto.es/~abaitua/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail:abaitua@fil.deusto.es  e-mail:arantza@aut.alcala.es  e-mail:raquel@eucmos.sim.ucm.es  
Title: Value Added Tagging for Multilingual Resource Management  
Author: Joseba Abaitua Arantza Casillas Raquel Martnez 
Address: Deusto, 48080 Bilbao, Spain  28871 Alcala de Henares, Spain  Madrid, 28040 Madrid, Spain  
Affiliation: Facultad de Filosofa Letras Universidad de  Departamento de Automatica. Universidad de Alcala de Henares  Departamento de Informatica Programacion. Facultad de Matematicas Universidad Complutense de  
Abstract: The Legebiduna project brings together state-of-the-art techniques in multilingual corpus management, generic mark-up, text segmentation and alignment, terminological extraction, automatic text cataloguing, and reutilisation of recurrent text in specialised documentation. We report on the experience of a four year project of bilingual corpus mining in a dedicated domain of official bilingual publications. Considerable effort has been made in developing tools for the automatic processing of a collected parallel corpus of 7 million words in both Spanish and Basque. Experiments have been undertaken on a half million word sample of the corpus, and the results are very satisfactory. Legebiduna has now become a prototype of a domain-expert editing tool that helps both institutional writers and translators to carry out their work in an optimal computer oriented environment.
Abstract-found: 1
Intro-found: 1
Reference: <author> Abaitua, J., Casillas, A. and Martnez, R. </author> <year> (1997). </year> <title> Segmentacion de corpus paralelos para memorias de traduccion Procesamiento del Lenguaje Natural 1997. </title>
Reference-contexts: Although the mark-up is normally insufficient, it is possible to enrich existing annotations through various tagging phases. 3 Tagging and Segmentation into Translation Units We have tried to make our approach to bitext processing optimal by the utilisation of a very precise and well-tuned segmentation procedure that recog-nises translation units <ref> (Abaitua et. al., 1997) </ref>. This consists of a set of subtools that perform such processes as: sentences boundary detection, proper noun tagging, recognition of other text entities such as numbers, dates, abbreviations, enumerations, as well as other document internal logic entities. <p> The encoding scheme has been based on TEI's guidelines for SGML based mark-up (Ide & Veronis, 1995) and has been described in (Martnez et al., 1997). The results of the identification of the description levels are shown in Table 2. Following <ref> (Abaitua et al., 1997) </ref>, segmentation into translation units is based on the following classification: 1. Formulaic translation units. These typical multi-clause constructions are very frequent in legal and administrative sublanguages. Recognition is carried out by means of straightforward pattern matching techniques. 2. Terminological translation units.
Reference: <author> Aduriz, I., Aldezabal, I., Artola, X., Ezeiza, N. and Urizar, R. </author> <year> (1996). </year> <title> MultiWord Lexical Units in EUSLEM, </title> <booktitle> a lemmatiser-tagger for Basque Papers in Computational Lexicography COMPLEX'96. </booktitle> <pages> 1-8. </pages> <address> Budapest 1996. </address>
Reference-contexts: All the Span ish proper nouns correspond to this category. * Flexible proper nouns. These are proper nouns that can be separated by intervening text elements such as Administrazio Publikoetarako Min-isteritzaren &lt;date&gt;... &lt;/date&gt; Agindua, where a date splits the tokens of the noun. As has been noticed before <ref> (Aduriz et al., 1996) </ref>, there is a number of Basque multiword expressions that fall under this class.
Reference: <author> Ahonen, H. </author> <year> (1995). </year> <title> Automatic Generation of SGML Content Models Electronic Publishing 8(2-3), </title> <type> 195-206, </type> <note> 1995 Brown, </note> <author> P., Della Pietra, V., Della Pietra, S., Mercer, R. </author> <year> (1993). </year> <title> The mathematics of statistical machine translation: parameter estimation. </title> <booktitle> Computational Linguistics 19(2) </booktitle> <month> 263-301 </month> <year> 1993. </year>
Reference-contexts: Because the documentation in our corpus was not produced using SGML based editing software, and hence does not comply with any DTD, DTDs have been abstracted away from the annotations that were automatically introduced in the corpus. Similar experiments have been reported before in the literature. <ref> (Ahonen, 1995) </ref> uses a method to build document instances from tagged texts that consists of a deterministic finite automaton for each context model. Subsequently, these automata are generalised and converted into regular expressions which are easily transcribed into SGML content models. (Shafer, 1995) combines document instances with simplification rules.
Reference: <author> Catizone, R., Russell, G., Warwick, S. </author> <year> (1993). </year> <title> Deriving Translation Data from Bilingual Texts. </title> <booktitle> Proccedings of the First International Lexical Acquisition Workshop, </booktitle> <address> Detroit, MI, </address> <year> 1993. </year>
Reference: <author> Chang, J. S., Chen, M. H. </author> <year> (1997). </year> <title> An Alignment Method for Noisy Parallel Corpora based on Image Processing Techniques. </title> <booktitle> Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 297-304, </pages> <year> 1997. </year>
Reference: <author> Collins, B., Cunningham, P., Veale, T. </author> <year> (1996). </year> <title> An Example Based Approach to Machine Translation. Expanding MT Hori-zonts: </title> <booktitle> Proceedings of the Second Conference of the Association for Machine Translation in the Americas:AMTA-96, </booktitle> <pages> 125-134, </pages> <year> 1996. </year>
Reference: <author> Daille, B., Gaussier, E., Lange, J.M. </author> <year> (1994). </year> <title> Towards Automatic Extraction of Monolingual and Bilingual Terminology. </title> <booktitle> Proceedings of the 15th International Conference on Computational Linguistics, </booktitle> <pages> 515-521, </pages> <address> Kyoto, Japan. </address>
Reference: <author> Dagan, I., Church, K. </author> <year> (1994). </year> <title> Termigh: Identifying and translating Technical Terminology. </title> <booktitle> Proceedings Fourth Conference on Applied Natural Language Processing (ANLP-94), </booktitle> <address> Stuttgart, Germany, 34-40, </address> <year> 1994. </year> <institution> Association for Computational Linguistics. </institution>
Reference: <author> Eijk, P. van der. </author> <year> (1993). </year> <title> Automating the acquisition of Bilingual Terminology. </title> <booktitle> Proceedings Sixth Conference of the Euro-pean Chapter of the Association for Computational Linguistic, </booktitle> <address> Utrecht, The Netherlands, 113-119, </address> <year> 1993. </year>
Reference: <author> Frantzi, K. T., Ananiadou, S. </author> <year> (1996). </year> <title> Extracting Nested Collocations. </title> <address> NLP+IA96/TAL+AI96. Moncton, Canada, 93-98, </address> <year> 1996. </year>
Reference-contexts: Co-occurring items were later filtered out in consecutive steps. First the algorithm of <ref> (Frantzi & Ananiadou, 1996) </ref> was applied to detect spurious repetitions and nested embedding. Then the results were screened by a stop list (made of prepositions, conjunctions and determiners). Finally, the candidate expressions were POS tagged and matched up against a mini noun phrase grammar.
Reference: <author> Gale, W., Church, K. W. </author> <year> (1991). </year> <title> Identifying Word Correspondences in Parallel Texts. </title> <booktitle> Proceedings of the DARPA SNL Workshop, </booktitle> <year> 1991. </year>
Reference: <author> Gale, W., Church, K. W., Yarowsky, D. </author> <year> (1992). </year> <title> Using Bilingual Materials to Develop Word Sense Disambiguation Methods. </title> <booktitle> Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92), </booktitle> <pages> 101-112, </pages> <address> Montreal, Canada 1992. </address>
Reference: <author> Ide, N., Veronis, J. </author> <year> (1995). </year> <title> The Text Encoding Initiative: Background and Contexts. </title> <publisher> Dordrecht: Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Some of this collection of tags (shown in Table 1) reflect basic structural and referential elements, which appear consistently on both sides of the bitext. The encoding scheme has been based on TEI's guidelines for SGML based mark-up <ref> (Ide & Veronis, 1995) </ref> and has been described in (Martnez et al., 1997). The results of the identification of the description levels are shown in Table 2. Following (Abaitua et al., 1997), segmentation into translation units is based on the following classification: 1. Formulaic translation units.
Reference: <author> Kupiec, J. </author> <year> (1993). </year> <title> An algorithm for finding noun phrase correspondences in bilingual corpora. </title> <booktitle> Proceedings of the 31st Annual Meeting of the ACL, </booktitle> <address> Columbus, </address> <publisher> Ohio, </publisher> <pages> 17-22. </pages> <note> Association for Computational Linguistics 1993. </note>
Reference: <author> Martnez, R., Casillas, A., Abaitua, J. </author> <year> (1997). </year> <title> Bilingual parallel text segmentation and tagging for specialized documentation. </title> <booktitle> Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP'97, </booktitle> <pages> 369-372, </pages> <year> 1997. </year> <note> MtSeg: overview. (1997). Multext Document MSG 1. MtSeg/Overviewhttp://www.lpl.univ-aix.fr/projects/multext/MUL7.html. </note>
Reference-contexts: Some of this collection of tags (shown in Table 1) reflect basic structural and referential elements, which appear consistently on both sides of the bitext. The encoding scheme has been based on TEI's guidelines for SGML based mark-up (Ide & Veronis, 1995) and has been described in <ref> (Martnez et al., 1997) </ref>. The results of the identification of the description levels are shown in Table 2. Following (Abaitua et al., 1997), segmentation into translation units is based on the following classification: 1. Formulaic translation units. These typical multi-clause constructions are very frequent in legal and administrative sublanguages.
References-found: 15

