URL: ftp://rievaulx.dur.ac.uk/pub/tech-reports/1992/13-92.ps.gz
Refering-URL: http://www.progsoc.uts.edu.au/~geldridg/cpp/
Root-URL: 
Email: EMail C.D.Turner@durham.ac.uk  
Title: The Testing of ObjectOriented Programs  
Author: C. D. Turner and D. J. Robson 
Date: 2 February, 1993  
Address: Durham, England  
Affiliation: Computer Science Division School of Engineering and Computer Science (SECS) University of Durham  
Pubnum: Technical Report: TR-13/92  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Cheatham T. J. and Mellinger L., </author> <title> Testing ObjectOriented Systems, </title> <booktitle> in Proceedings of the 18th ACM annual Computer Science Conference, </booktitle> <pages> pp. 161-165, </pages> <publisher> ACM Inc., </publisher> <address> New York, </address> <year> 1990 </year>
Reference-contexts: Generation of Test Cases In this report so far, both substates and data scenarios have been introduced and can now be combined to provide a more general guide to state-based testing. The guide is in the form of a list of tasks to be performed. <ref> [1] </ref> Allocate one substate per data member of the class under test. <p> It is hoped a symbolic evaluator can be used to discover the values within the axioms of the specification, providing the opportunity for the automatic derivation of more test cases. T.J. Cheatham and L. Mellinger in "Testing ObjectOriented Software Systems" <ref> [1] </ref> claim to address the testing of objectoriented programs at the unit level with respect to message passing and inheritance. However, the paper simply mentions some of the problems, and then without justification, states that with a Smalltalk library of tested classes, 40-70% of unit testing is 'free'.
Reference: [2] <author> Chow, T. S., </author> <title> Testing Software Design modelling by FiniteState Machines, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-4, no. 3, </volume> <pages> pp. 178 - 187, </pages> <month> May </month> <year> 1978 </year>
Reference-contexts: Of these, iii) and iv) are definitely errors, and ii) can be an error if the object's response was supposed to be i). Therefore the aim of state-based testing is to detect all occurrences of the erroneous ii), iii), and iv). Chow discusses testing using SA's in <ref> [2] </ref>. However, he discusses the testing of control-structures that can occur within a design, rather than an implementation. His approach of predicting the correct response of a routine according to the SA upon which it is based, is similar to the one described in this document. <p> The guide is in the form of a list of tasks to be performed. [1] Allocate one substate per data member of the class under test. This is done as described earlier. <ref> [2] </ref> Determine the data scenarios from the design of the class. [3] Allocate the extra substates required for the data scenarios to function properly. [4] Determine the specific-values and the general values for all these substates.
Reference: [3] <author> Doong. R. K. and Frankl, P., </author> <title> Case Studies in Testing ObjectOriented Programs, </title> <booktitle> in The 4th Testing, Analysis and Verification Symposium, </booktitle> <pages> pp. 165 - 177, </pages> <publisher> ACM Inc., </publisher> <address> New York, New York, </address> <year> 1991 </year>
Reference-contexts: The guide is in the form of a list of tasks to be performed. [1] Allocate one substate per data member of the class under test. This is done as described earlier. [2] Determine the data scenarios from the design of the class. <ref> [3] </ref> Allocate the extra substates required for the data scenarios to function properly. [4] Determine the specific-values and the general values for all these substates. <p> C.D.Turner - 40 - 02/02/93 The article is concluded by saying that more research is needed into the testing of object--oriented systems. As a follow-up the their earlier article [5], Roong-Ko Doong and Phyllis Frankl in "Case Studies on Testing of ObjectOriented Programs" <ref> [3] </ref> provide experimental details of their method and tools. The first section of the paper just gives a simple introduction to object-oriented programming, and defines the terms that are used throughout the remainder of the report.
Reference: [4] <author> Fiedler, S. P., </author> <title> ObjectOriented Unit Testing, </title> <journal> Hewlett-Packard Journal, pp. </journal> <volume> 69 - 74, </volume> <month> April </month> <year> 1989 </year>
Reference-contexts: This is done as described earlier. [2] Determine the data scenarios from the design of the class. [3] Allocate the extra substates required for the data scenarios to function properly. <ref> [4] </ref> Determine the specific-values and the general values for all these substates. <p> Steven P. Fiedler in "Object-Oriented Unit Testing" <ref> [4] </ref>, describes the application of a more traditional approach. He describes experience gained on a software project at Hewlett Packard. The project applied traditional testing techniques to the testing of software written in C++. <p> They also state that there are no accepted methods for testing the main constructs offered by object oriented programming, including the constructs provided for the reusability of software. These views are contrary to the opinion of Fiedler <ref> [4] </ref> who describes experience of testing objectoriented programming by applying a technique originally designed for the procedural style of programming. This point will be addressed further, later on. Another paper describing the use of formal specifications in the validation of objectoriented programs is "Tools for ObjectOriented Programs" by Phyllis G. <p> The approach makes no direct observation of the exact state that the objects have reached after execution of the test sequences. Although this allows the same set of test cases to be used for different implementations of the same ADT, Fiedler <ref> [4] </ref> states that although the objectoriented paradigm suggests functional testing is required, a more robust testing method including complete path testing is actually required. <p> The testing of objectoriented programs should embrace all methods of testing, from the state-based approach, through functional testing techniques (such as this one), to structural testing techniques (such as the described by Fiedler in <ref> [4] </ref>). The problem which the method they propose (described earlier), is more of a problem with the specification technique chosen, rather than the method itself. Some classes cannot be specified by simply describing the interactions between the features, and therefore would not be suitable for testing with this approach. <p> However, functional testing can be done using the method described by Frankl and Doong [5]. Structural testing is applicable without major modification at the feature level, an example of which is described by Fiedler <ref> [4] </ref>, thus invalidating this claim. The remainder of the paper describes the structure and operation of the framework. This includes the test strategies which are used to guide the actual testing of a class.
Reference: [5] <author> Frankl, P. G. and Doong, R., </author> <title> Tools for Testing ObjectOriented Programs, </title> <booktitle> in proceedings of the 8th Pacific NorthWest Conference on Software Quality, </booktitle> <pages> pp. 309 - 324, </pages> <year> 1990 </year>
Reference-contexts: Include the invalid values that are required when de-referencing a pointer as mentioned in the previous section. <ref> [5] </ref> Add the features to test the for the substate values to the class. [6] Determine which substates a test for a change of value is required. <p> This point will be addressed further, later on. Another paper describing the use of formal specifications in the validation of objectoriented programs is "Tools for ObjectOriented Programs" by Phyllis G. Frankl and R. K. Doong <ref> [5] </ref>. It describes A Set of Tools for ObjectOriented Testing (ASTOOT), written in Eiffel. Their approach is based on the algebraic (axiomatic) specification of ADTs. Test cases are generated, consisting of pairs of sequences of methods (referred to as operations or methods in the paper) along with a tag. <p> He discusses both unit and integration testing without actually defining how it is applied to objectoriented programs. C.D.Turner - 40 - 02/02/93 The article is concluded by saying that more research is needed into the testing of object--oriented systems. As a follow-up the their earlier article <ref> [5] </ref>, Roong-Ko Doong and Phyllis Frankl in "Case Studies on Testing of ObjectOriented Programs" [3] provide experimental details of their method and tools. The first section of the paper just gives a simple introduction to object-oriented programming, and defines the terms that are used throughout the remainder of the report. <p> Also they feel that structural testing is not directly applicable as it is difficult to analyse the control or data flow through a class. However, functional testing can be done using the method described by Frankl and Doong <ref> [5] </ref>. Structural testing is applicable without major modification at the feature level, an example of which is described by Fiedler [4], thus invalidating this claim. The remainder of the paper describes the structure and operation of the framework.
Reference: [6] <author> Harrold M. J., McGregor, J. D. and Fitzpatrick K. J., </author> <title> Incremental Testing of Object-Oriented Class Structure, </title> <booktitle> in 14th International Conference on Software Engineering, ACM, </booktitle> <year> 1992 </year>
Reference-contexts: Include the invalid values that are required when de-referencing a pointer as mentioned in the previous section. [5] Add the features to test the for the substate values to the class. <ref> [6] </ref> Determine which substates a test for a change of value is required. Add features to detect the changes to the class under test. 19 A state description is a list of substates descriptions which when combined form the state of the object. <p> The paper is concluded by discussing that additions that it is hoped will be made to the ASTOOT tool suite in the near future. The first paper to consider the testing of class hierarchies is "Incremental Testing of Object-Oriented Class Structures" by Mary Jean Harrold et al. <ref> [6] </ref>. The paper describes an incremental algorithm for the testing of classes within an inheritance hierarchy. They state: "[inheritance] permits a subclass to inherit attributes 23 from its parent classes and either extend, restrict or redefine them.
Reference: [7] <author> Hennell, M. A., </author> <title> Testing in the Real World, </title> <booktitle> in Proceedings of Software Tools, </booktitle> <pages> pp. 59 - 66, </pages> <year> 1987 </year>
Reference-contexts: Multiple condition coverage - Every clause in the conditional tests within the program must produce both outcomes, that is true and false. LCSAJ 4 coverage - Every LCSAJ (sub-path) through the code must be executed at least once. See [23] and <ref> [7] </ref> for more information. 4 LCSAJ is an acronym for Logical Code Sequence And Jump. <p> Add features to detect the changes to the class under test. 19 A state description is a list of substates descriptions which when combined form the state of the object. A substate description is the declaration of a particular substate's value. C.D.Turner - 29 - 02/02/93 <ref> [7] </ref> From the design of the class, determine which states are the e I i i for each feature. In the majority of cases, both should be the same as s because classes should be written with no implied order for the calling of features [13].
Reference: [8] <author> Herington, D., E., Nichols, P., A. and Lipp, R., D., </author> <title> Software Verification Using Branch Analysis, </title> <journal> Hewlett-Packard Journal, </journal> <volume> vol. 38, no. 6, </volume> <pages> pp. 13 - 23, </pages> <month> June </month> <year> 1987 </year>
Reference-contexts: Both these views are consistent with those presented by Herrington et al. in <ref> [8] </ref>. C.D.Turner - 10 - 02/02/93 2.2. Emphasis of the Testing Process At this point, the difference between classes and objects must be defined. For the purpose of this report, a class is taken to be the static, programmer-defined representation of an object. <p> In the majority of cases, both should be the same as s because classes should be written with no implied order for the calling of features [13]. These sets of states form the basis of the cases. <ref> [8] </ref> Analyse from the design the call graph for inter-features within the same class, that is, the class under test. [9] Start with the features at the bottom of the graph, especially those features which are not called by any other feature within the class under test. [10] For each state
Reference: [9] <editor> IEEE Standard 610.12-1990, </editor> <title> IEEE Standard Glossary of Software Engineering Terminology, </title> <journal> IEEE, </journal> <note> 1990 C.D.Turner - 55 - 02/02/93 </note>
Reference-contexts: These sets of states form the basis of the cases. [8] Analyse from the design the call graph for inter-features within the same class, that is, the class under test. <ref> [9] </ref> Start with the features at the bottom of the graph, especially those features which are not called by any other feature within the class under test. [10] For each state si f such that si f i , calculate from the design which state so f such that so e
Reference: [10] <author> Jalote, P., </author> <title> Testing the completeness of Specifications, </title> <journal> IEEE Transcations on Software Engineering, </journal> <volume> vol. 15, no. 5, </volume> <pages> pp. 526 - 531, </pages> <month> May </month> <year> 1989 </year>
Reference-contexts: of the cases. [8] Analyse from the design the call graph for inter-features within the same class, that is, the class under test. [9] Start with the features at the bottom of the graph, especially those features which are not called by any other feature within the class under test. <ref> [10] </ref> For each state si f such that si f i , calculate from the design which state so f such that so e O for feature i (That is, for each state that the feature is expected to handle as input, calculate the state that the feature should leave the <p> The tag reflects whether the two sequences of methods should leave an object in the same abstract state. The method depends heavily upon the completeness of the ADT's specification (see <ref> [10] </ref> for more details). A class is said to be a correct implementation of an ADT if and only if, for every pair of sequences s1 and s2, applied to a pair of objects, o1 and o2, the objects are put into observationally equivalent states.
Reference: [11] <author> Leavens, G. T., </author> <title> Modular Specification and Verification of ObjectOriented Programs, </title> <journal> IEEE Software, pp. </journal> <volume> 72 - 80, </volume> <month> July </month> <year> 1991 </year>
Reference-contexts: This is done for all significant values that can be passed as parameters to the feature. These significant values are the stimuli of the features. <ref> [11] </ref> Generate the code to create the test case scenario, that is, the starting state of the object. Follow this with test to validate the starting state of the object. After this, add the code for the test, including the call to the feature under test. <p> It is then use for experimentation with the technique. Another paper describing the use of formal specification for the verification of objectoriented programs is "Modular Specification and Verification of ObjectOriented Programs" by Gary T. Leavens <ref> [11] </ref>. It outlines a method of reasoning about objectoriented programs using relationships between the ADTs used. ADTs are referred to as 'types'. If given two types, A and B; if B is the subtype of A, then A is the supertype of B.
Reference: [12] <author> Love, T., </author> <title> The Economics of Reuse, </title> <booktitle> in IEEE Spring COMPCON Conference, </booktitle> <pages> pp. 238 - 241, </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <year> 1988 </year>
Reference-contexts: After this, add the code for the test, including the call to the feature under test. Append to all of this, a test for the final state of the object, and any code required to tidy up after the test. <ref> [12] </ref> Go back to item 10 until there are no more features left to test. 3.5. General Assessment of the Technique State-based testing, like the majority of other techniques, has particular types of classes on which it is more effective than on others. <p> This in turn increases one of the aims of objectoriented programming - that of facilitating the increased use of reusable components, therefore reducing the cost of software production <ref> [12] </ref>. There is one point which has been carefully avoided until now - the emphasis of the test cases.
Reference: [13] <author> Meyer, B., </author> <title> Object Oriented Software Construction, </title> <publisher> Prentice Hall, </publisher> <year> 1988 </year>
Reference-contexts: In the majority of cases, both should be the same as s because classes should be written with no implied order for the calling of features <ref> [13] </ref>.
Reference: [14] <author> Myers, G. J., </author> <title> The Art of Software Testing, </title> <publisher> John Wiley, </publisher> <year> 1979 </year>
Reference-contexts: Another point is the construction of the strategies themselves, there is no description of how they actually function or interact with the framework. C.D.Turner - 47 - 02/02/93 5. Traditional Testing Techniques It is felt that traditional testing techniques (see <ref> [14] </ref> for examples) are easily applicable to objectoriented programs. The data representation must be tested initially by state-based testing, then individual features can be exercised until their required coverage level is achieved. State-based testing has a tendency to ignore the results that are returned by features.
Reference: [15] <author> Olthoff, W. G., </author> <title> Augumentation of Object Oriented Programming by Concepts of Abstract Data Type Theory : The ModPascal Experience, </title> <booktitle> in proceedings of the ObjectOriented Programming: Systems, Languages and Applications Conference, </booktitle> <pages> pp. 429 - 443, </pages> <booktitle> SIGPLAN Notices, </booktitle> <publisher> ACM Inc., </publisher> <year> 1986 </year>
Reference-contexts: As there only a few papers, each will be discussed individually and contrasted with the rest. They are discussed in chronological order. The first paper is "Augmentation of ObjectOriented Programming by Concepts of Abstract Data Type Theory: The ModPascal Experience" by Walter G. Olthoff <ref> [15] </ref>. It described an approach to the validation of objectoriented programs written in a modified version of Pascal that includes constructs for defining classes, and for the inclusion of information connected with the ADT theory.
Reference: [16] <author> Perry, D. E. and Kaiser, G. E., </author> <title> Adequate Testing and Object Oriented Programming, </title> <journal> Journal of ObjectOriented Programming, pp. </journal> <volume> 13 - 19, </volume> <month> January/Febuary </month> <year> 1990 </year>
Reference-contexts: However, it is more practical not to test features in isolation, but to simply concentrate the test cases on exercising each feature in turn to its maximum coverage. This will be addressed further, later on. Dewayne E. Perry and Gail E. Kaiser in "Adequate testing and objectoriented programming" <ref> [16] </ref> discuss the theoretical view of the testing of objectoriented programs. The authors describe the applicability of Elaine Weyuker's test adequacy criteria (described in [21]) to the objectoriented paradigm. <p> They then introduce six types of features covering all ways of defining a feature in a derived class from inheriting it, to defining it afresh. They introduce the work done by Perry and Kaiser <ref> [16] </ref> (see above). This provides their justification for the testing of features both in isolation, and in interaction. For each of the four test adequacy criteria of special significance to objectoriented programming, they briefly describe how they are satisified by their algorithm.
Reference: [17] <author> Smith, M. D. and Robson D. J., </author> <title> ObjectOriented Programming - the Problems of Validation, </title> <booktitle> in proceedings of the 6th International Conference on Software Maintenance, </booktitle> <pages> pp. 272 - 282, </pages> <publisher> IEEE </publisher>
Reference-contexts: A description of some of the problems that might be encountered when considering the testing of objectoriented programs is given by M. D. Smith and D. J. Robson in "Object-Oriented Programming - the Problems of Validation" <ref> [17] </ref>. They discusses validation (in both the development and the maintenance phases of the software life cycle) with respect to object-oriented programming. The authors comment that industry sees objectorientation as the solution to all of its problems (the great white hope), without noticing the new problems introduced.
Reference: [18] <author> Smith, M. D. and Robson, D. J., </author> <title> A Framework for Testing ObjectOriented Programs, </title> <journal> Journal of ObjectOriented Programming, </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 45 - 53, </pages> <month> June </month> <year> 1992 </year>
Reference-contexts: The final paper to be discussed, is "A Framework for Testing ObjectOriented Programs" by M.D. Smith and D.J. Robson <ref> [18] </ref>. It describes both a method and a framework designed for the testing of objectoriented programs. The authors discuss the terms that are normally applied to the testing of software written using traditional approaches. They then redefine the terms for the testing of objectoriented programs.
Reference: [19] <author> Turner, </author> <title> C.D., A Suite of Tools for the State-Based Testing of ObjectOriented Programs, </title> <type> Tech. Rep. TR 14/92, </type> <institution> University of Durham, </institution> <address> England, </address> <year> 1992 </year>
Reference-contexts: For each data member being mirrored, an extra feature is required to test the difference between the original and the mirroring data member, and to update the value of the mirror data members. This is explained in greater detail in a separate report describing the MKTC suite of tools <ref> [19] </ref>. As a simple recommendation, it is advisable to insert statements at the beginning and end of each feature to report to the screen (or to a file) the value of the parameters passed and the values returned by the features. <p> Also, it is possible to generate a file with a description of all the test cases that failed (unless the fail causes a system crash). TESTRUN will also be described in slightly more detail below. A more detailed description of the tools is available in a separate report <ref> [19] </ref>. 24 A file that describes dependencies between the modules of a program. It also describes the command sequences that are required to build the filnal program, or programs. C.D.Turner - 49 - 02/02/93 6.1.
Reference: [20] <author> Wallace, D. R. and Fujii, R. U., </author> <title> Software Verification and Validation : an Overview, </title> <journal> IEEE Software, </journal> <volume> vol. 6, no. 3, </volume> <pages> pp. 10 - 17, </pages> <month> May </month> <year> 1989 </year> <month> C.D.Turner - 56 - 02/02/93 </month>
Reference-contexts: In <ref> [20] </ref>, Wallace and Fujii imply the separation of the validation and verification group (who perform the testing) from the development group. When discussing the testing of classed defined using inheritance, it is stated that the methods of the class that are provided by a parent class only require minimal testing.
Reference: [21] <author> Weyuker, E. J., </author> <title> How to Decide When to Stop Testing, </title> <booktitle> in Proceedings of the 5th Annual Pacific NorthWest Conference on Software Quality, </booktitle> <year> 1987 </year>
Reference-contexts: This will be addressed further, later on. Dewayne E. Perry and Gail E. Kaiser in "Adequate testing and objectoriented programming" [16] discuss the theoretical view of the testing of objectoriented programs. The authors describe the applicability of Elaine Weyuker's test adequacy criteria (described in <ref> [21] </ref>) to the objectoriented paradigm. Originally designed for the procedural style of programming, the criteria are used to determine if a program is adequately tested using the chosen technique.
Reference: [22] <author> Woodfield, S. N., Gibbs, N. E. and Collofello, J. S., </author> <title> Improved Software Reliability Through the Use of Functional and Strcutural Testing, </title> <booktitle> in proceedings of IEEE Phoenix Conference on Computers and Communications, </booktitle> <pages> pp. 154 - 157, </pages> <publisher> IEEE, </publisher> <year> 1983 </year>
Reference-contexts: Data storage can be used either to store information supplied by the caller, or to store the result of a call to another feature, therefore allowing access to information that would otherwise be transient by nature. The traditional testing process should consist of both functional testing and structural testing <ref> [22] </ref>. It is deemed complete when the appropriate coverage level has been achieved. To reach this level, first functional tests are performed, followed by the structural tests to increase the coverage of specific constructs.

References-found: 22

