URL: http://charm.cs.uiuc.edu/version2/papers/RuntimeOptsICS96.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/RuntimeOptsICS96.html
Root-URL: http://www.cs.uiuc.edu
Email: Email fsanjeev,kaleg@cs.uiuc.edu  
Phone: Phone (217) 244-0094  
Title: Automating Parallel Runtime Optimizations Using Post-Mortem Analysis  
Author: Sanjeev Krishnan and Laxmikant V. Kale 
Affiliation: Department of Computer Science, University of Illinois, Urbana-Champaign.  
Abstract: Attaining good performance for parallel programs frequently requires substantial expertise and effort, which can be reduced by automated optimizations. In this paper we concentrate on run-time optimizations and techniques to automate them without programmer intervention, using post-mortem analysis of parallel program execution. We classify the characteristics of parallel programs with respect to object placement (mapping), scheduling and communication, then describe techniques to discover these characteristics by post-mortem analysis, present heuristics to choose appropriate optimizations based on these characteristics, and describe techniques to generate concise hints to runtime optimization libraries. Our ideas have been developed in the framework of the Paradise post-mortem analysis tool for the parallel object-oriented language Charm++. We also present results for optimizing simple parallel programs running on the Thinking Machines CM-5. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. A. Reed et al. </author> <title> Scalable Performance Analysis : The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <pages> pages 104-113. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1993. </year>
Reference-contexts: representation of the program's execution from traces, determines characteristics of the program, uses heuristics to find optimizations that will solve the performance problems, and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data <ref> [1, 2] </ref>, relating performance data to high level language constructs [3, 4], or giving the user insights into performance problems using expert analysis [5, 6].
Reference: [2] <author> L.V. Kale and Amitabh Sinha. </author> <title> Projections : A scalable performance tool. In Parallel Systems Fair, </title> <booktitle> International Parallel Processing Sympo sium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: representation of the program's execution from traces, determines characteristics of the program, uses heuristics to find optimizations that will solve the performance problems, and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data <ref> [1, 2] </ref>, relating performance data to high level language constructs [3, 4], or giving the user insights into performance problems using expert analysis [5, 6]. <p> Issues in collecting trace data, reducing perturbation, and constructing the basic event graph are discussed in [6] and are beyond the scope of this paper. A simple version of the event graph was originally used for the Projections <ref> [2] </ref> performance visualization and analysis tool. The event graph constructed by Paradise consists of vertices representing entry-function executions, edges representing messages between entry functions and edges for dependences between methods (these dependences must be specified in the language or generated by the compiler).
Reference: [3] <author> V. Adve, J. Mellor-Crummey, M. Anderson, K. Kennedy, J. Wang, and D. A. Reed. </author> <title> An integrated compilation and performance analysis environment for data-parallel programs. </title> <booktitle> In Proceedings of Supercomputing 1995, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: the program, uses heuristics to find optimizations that will solve the performance problems, and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data [1, 2], relating performance data to high level language constructs <ref> [3, 4] </ref>, or giving the user insights into performance problems using expert analysis [5, 6].
Reference: [4] <author> B. Mohr, D. Brown, and A. Malony. </author> <title> TAU: A Portable Parallel Program Analysis Environment for pC++. </title> <booktitle> In Proceedings of the 3rd Joint Conference on Parallel Processing: CONPAR 94 - VAPP VI, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: the program, uses heuristics to find optimizations that will solve the performance problems, and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data [1, 2], relating performance data to high level language constructs <ref> [3, 4] </ref>, or giving the user insights into performance problems using expert analysis [5, 6].
Reference: [5] <author> J. Kohn and W. Williams. </author> <title> ATExpert. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18 </volume> <pages> 205-222, </pages> <year> 1993. </year>
Reference-contexts: and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data [1, 2], relating performance data to high level language constructs [3, 4], or giving the user insights into performance problems using expert analysis <ref> [5, 6] </ref>. Our framework aims to go a step further in the direction of automation : Paradise not only finds performance problems, but also solutions in terms of optimizations for the problem areas, and in co-operation with the run-time libraries, incorporates the optimizations in the program without programmer intervention.
Reference: [6] <author> Amitabh B. Sinha. </author> <title> Performance Analysis of Object Based and Message Driven Programs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illi-nois, Urbana-Champaign, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: and generates concise hints which are communicated to runtime libraries by a "hints file". 2.3 Previous work Performance analysis research has concentrated on visually displaying performance data [1, 2], relating performance data to high level language constructs [3, 4], or giving the user insights into performance problems using expert analysis <ref> [5, 6] </ref>. Our framework aims to go a step further in the direction of automation : Paradise not only finds performance problems, but also solutions in terms of optimizations for the problem areas, and in co-operation with the run-time libraries, incorporates the optimizations in the program without programmer intervention. <p> Post-mortem representation: The execution of a Charm++ program is represented as an event graph, which is essentially a task graph constructed using traces collected at run-time. Issues in collecting trace data, reducing perturbation, and constructing the basic event graph are discussed in <ref> [6] </ref> and are beyond the scope of this paper. A simple version of the event graph was originally used for the Projections [2] performance visualization and analysis tool. <p> We first describe some important characteristics which affect object placement, and discuss how they are inferred from the event graph. 4.1.1 Phase structure of program This characteristic tells us if there are repeatedly occurring phases in the program. Separating the program into independent phases helps to focus analysis <ref> [6] </ref>, because each phase can be analyzed independently. The phase structure is also important if all objects are not active in all phases: ignoring the phase structure may result in load imbalance within a phase in which only part of the objects are active. <p> Paradise determines the degree of pipelining for different message types using heuristics which reduce idle time and overheads <ref> [6] </ref>. Message aggregation or combining When a processor sends many small messages to the same remote processor and the messages are not immediately processed, the messages can be combined into one large message before being sent out, and then broken up after being received. This reduces message transmission overhead.
Reference: [7] <author> P. Banerjee et al. </author> <title> The PARADIGM Compiler for Distributed-Memory Multicomputers. </title> <booktitle> IEEE Computer, </booktitle> <month> October </month> <year> 1995. </year>
Reference-contexts: Automatic compiler optimizations have achieved success for automatic data partitioning and communication schedule generation in array-based Fortran programs <ref> [7, 8] </ref>. The use of profile information for compiler optimizations is well-known. Several sequential compilers use profile information to predict branch probabilities (e.g. [9]). Some compilers for data-parallel languages such as HPF [10]) use profile information to accurately find the cost of various computation and communication operations. <p> The first task to be done for array partitioning is to align interacting object arrays of the same dimensions. The strategy here is the one used by Li & Chen [13] and Gupta & Banerjee <ref> [7] </ref> for compilers, involving construction and partitioning of a graph whose vertices represent array dimensions. Each set of aligned arrays represents a template grid (as in HPF), and each object in each array is assigned to a grid point. Next, Paradise partitions the template grids across processors.
Reference: [8] <author> S. Sharma, R. Ponnusamy, B. Moon, Y. Hwang, R. Das, and J. Saltz. </author> <title> Run-time and compile-time support for adaptive irregular problems. </title> <booktitle> In Proceedings of Supercomputing 1994, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Automatic compiler optimizations have achieved success for automatic data partitioning and communication schedule generation in array-based Fortran programs <ref> [7, 8] </ref>. The use of profile information for compiler optimizations is well-known. Several sequential compilers use profile information to predict branch probabilities (e.g. [9]). Some compilers for data-parallel languages such as HPF [10]) use profile information to accurately find the cost of various computation and communication operations.
Reference: [9] <author> P. P. Chang, S. Mahlke, W. Chen, N. Warter, and W. Hwu. </author> <title> IMPACT : An Architectural Framework for Multiple-Instruction Issue Processors. </title> <booktitle> In Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Automatic compiler optimizations have achieved success for automatic data partitioning and communication schedule generation in array-based Fortran programs [7, 8]. The use of profile information for compiler optimizations is well-known. Several sequential compilers use profile information to predict branch probabilities (e.g. <ref> [9] </ref>). Some compilers for data-parallel languages such as HPF [10]) use profile information to accurately find the cost of various computation and communication operations. To the best of our knowledge, our framework is one of the first efforts towards using post-mortem analysis for automating run-time optimizations.
Reference: [10] <author> C.H. Koelbel, D.B. Loveman, R.S. Schreiber, G.L. Steele Jr., and M.E. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The use of profile information for compiler optimizations is well-known. Several sequential compilers use profile information to predict branch probabilities (e.g. [9]). Some compilers for data-parallel languages such as HPF <ref> [10] </ref>) use profile information to accurately find the cost of various computation and communication operations. To the best of our knowledge, our framework is one of the first efforts towards using post-mortem analysis for automating run-time optimizations.
Reference: [11] <author> L.V. Kale and Sanjeev Krishnan. </author> <title> Charm++ : A portable concurrent object oriented system based on C++. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: Again, data-parallel languages such as HPF present a much simpler regular computational model for which optimizations are easier to perform, as compared to a parallel object-oriented model which involves dynamic creation of tasks and asynchronous communication. 3 Program model This work is based on the parallel object-oriented language Charm++, <ref> [11, 12] </ref> which is an extension of C++. The basic unit of work in Charm++ is a chare, which is a medium-grained concurrent C++ object. Chares are dynamically created; there may be thousands of chares per processor.
Reference: [12] <author> L. V. Kale and Sanjeev Krishnan. </author> <title> Charm++ : Parallel Programming with Message-Driven Objects. in Parallel Programming using C++, </title> <publisher> MIT Press, </publisher> <year> 1995. </year> <note> To be published. </note>
Reference-contexts: Again, data-parallel languages such as HPF present a much simpler regular computational model for which optimizations are easier to perform, as compared to a parallel object-oriented model which involves dynamic creation of tasks and asynchronous communication. 3 Program model This work is based on the parallel object-oriented language Charm++, <ref> [11, 12] </ref> which is an extension of C++. The basic unit of work in Charm++ is a chare, which is a medium-grained concurrent C++ object. Chares are dynamically created; there may be thousands of chares per processor.
Reference: [13] <author> J. Li and M. Chen. </author> <title> Index domain alignment : Minimizing the cost of cross-referencing between distributed arrays. </title> <booktitle> In 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: In such cases it is possible for Paradise to automatically infer a precise pattern for mapping objects to processors. The first task to be done for array partitioning is to align interacting object arrays of the same dimensions. The strategy here is the one used by Li & Chen <ref> [13] </ref> and Gupta & Banerjee [7] for compilers, involving construction and partitioning of a graph whose vertices represent array dimensions. Each set of aligned arrays represents a template grid (as in HPF), and each object in each array is assigned to a grid point.
Reference: [14] <author> N. H. Naik, V. K. Naik, and M. Nicoules. </author> <title> Paralleliza-tion of a class of implicit finite difference schemes in computational fluid dynamics. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 5(1), </volume> <year> 1993. </year> <month> 8 </month>
Reference-contexts: Currently, the mapping patterns supported include : * all block-cyclic mappings. E.g. for a 2-D array, this has the form M ap (i; j) = j c M OD d) * the multi-partition mapping scheme <ref> [14] </ref>. E.g. for a 3-D array this has the form M ap (i; j; k) = jk c M OD d) In the above expressions i; j; k are the coordinates of an object, and a; b; c; d are the constants that need to be found by the analyzer.
References-found: 14

