URL: http://www.isi.edu/~shen/agent.ps
Refering-URL: http://www.isi.edu/~shen/papers_by_date.html
Root-URL: 
Email: ftambe,johnson,sheng@isi.edu  
Title: Adaptive Agent Tracking in Real-world Multi-Agent Domains: A Preliminary Report  
Author: Milind Tambe, Lewis Johnson and Wei-Min Shen 
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: In multi-agent environments, the task of agent tracking becomes increasingly difficult when a tracker only has an imperfect model of the trackee. This difficulty is unavoidable in any real-world situation where the amount of perception information is overwhelming in comparison to a tracker's limited resource and response time, and trackees may dynamically change their action models for a number of reasons. In this paper, we analyze this adaptive agent tracking problem in detail and describe an initial solution using discrimination-based learning. The main idea is to identify the deficiency of a model based on prediction failures, and revise the model by using features that are critical in discriminating successful and failed episodes. Our experiments in simulated air-to-air combat environments have shown some interesting results but many problems remain open for future research. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. R.; Boyle, C. F.; Corbett, A. T.; and Lewis, M. W. </author> <year> 1990. </year> <title> Cognitive modeling and intelligent tutoring. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 7-49. </pages>
Reference-contexts: It is appropriate in domains where agents exhibit dynamic behaviors in response to the changing environment and the actions of other agents. This paper focuses on adaptive agent tracking, an important requirement to scale up tracking to real-world domains. In particular, agent tracking is typically based on model tracing <ref> (Anderson et al. 1990) </ref>, where a tracker (tracking agent) executes a runnable model of the trackee (tracked agent), matching the model's predictions with actual observations. However, in real-world domains, a tracker's model of the trackee's behaviors is often imperfect, i.e., incomplete or incorrect.
Reference: <author> Azarewicz, J.; Fala, G.; Fink, R.; and Heithecker, C. </author> <year> 1986. </year> <title> Plan recognition for airborne tactical decision making. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 805-811. </pages> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference: <author> Bates, J.; Loyall, A. B.; and Reilly, W. S. </author> <year> 1992. </year> <title> Integrating reactivity, goals and emotions in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference: <author> Cremer, J.; Kearney, J.; Papelis, Y.; and Romano, R. </author> <title> The software architecture for scenario control in the Iowa driving simulator. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle>
Reference: <author> Gil, Y. </author> <year> 1993. </year> <title> Efficient domain-independent experimentation. Technical Report ISI/RR-93-337, </title> <booktitle> USC / Information Sciences Institute. Appears in the Proceedings of the Tenth International Conference on Machine Learning. </booktitle>
Reference-contexts: Under these circumstances, techniques akin to incremental enlargement (Shen 1993) or learning via experimentation <ref> (Gil 1993) </ref> can be employed to determine which features to discriminate. Incremental enlargement is a heuristic applicable to finding relevant features that are crucial in discriminating two environmental states that contain a large number of differences.
Reference: <author> Hayes-Roth, B.; Brownston, L.; and V., G. R. </author> <year> 1995. </year> <title> Multiagent collaobration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95). </booktitle>
Reference: <author> Johnson, W. </author> <year> 1994. </year> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 1257-1263. </pages> <address> Seattle, WA: </address> <publisher> AAAI. </publisher>
Reference-contexts: The discrimination-based approach is used to locate deficiencies in tracker's model of the trackee. This approach is augmented using discovery learning techniques for explaining successful and unsuccessful agent tracking experiences <ref> (Johnson 1994) </ref>, to further specialize the analysis of such deficiencies. The main idea of discrimination-based learning is the framework of predict-surprise-revise. <p> This process typically identifies a small number of features that are determined to be relevant, even if a decision involves multiple reasoning steps <ref> (Johnson 1994) </ref>. This reduced feature set becomes the focus of discrimination-based learning, instead of the full feature set. <p> First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment (Tambe et al. 1995). To this end, two versions of the pilot agents | one developed for tracking (Tambe & Rosenbloom 1995; Tambe 1995) and one that learns models of decisions for explanation <ref> (Johnson 1994) </ref> | have been integrated.
Reference: <author> Kautz, A., and Allen, J. F. </author> <year> 1986. </year> <title> Generalized plan recognition. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 32-37. </pages> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference: <author> Kuniyoshi, Y.; Rougeaux, S.; Ishii, M.; Kita, N.; Sakane, S.; and Kakikura, M. </author> <year> 1994. </year> <title> Cooperation by observation: the framework and the basic task pattern. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle>
Reference-contexts: Such real-time interaction is also seen in robotic environments <ref> (Kuniyoshi et al. 1994) </ref>. In all these environments, agent tracking is a key capability required for intelligent interaction (Tambe & Rosenbloom 1995; Ward 1991; Rao 1994). It involves monitoring other agents' observable actions and inferring their unobserved actions or high-level goals, plans and behaviors.
Reference: <author> Laird, J. E.; Rosenbloom, P. S.; and Newell, A. </author> <year> 1986. </year> <title> Chunking in soar: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning 1(1) </booktitle> <pages> 11-46. </pages>
Reference-contexts: We are experimenting with this integrated agent to address the 25-degree nose-off example discussed above. (These agents are based on the Soar integrated architecture (Newell 1990), and use chunking, a form of EBL, as the basis of all of their learning <ref> (Laird, Rosenbloom, & Newell 1986) </ref>). We are also in the process of implementing the above approach in a simple test-bed, where agents mimic the behavior of fighter aircraft, and are provided limited information about other agents.
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cam-bridge, Mass.: </address> <publisher> Harvard Univ. Press. </publisher>
Reference-contexts: We are experimenting with this integrated agent to address the 25-degree nose-off example discussed above. (These agents are based on the Soar integrated architecture <ref> (Newell 1990) </ref>, and use chunking, a form of EBL, as the basis of all of their learning (Laird, Rosenbloom, & Newell 1986)).
Reference: <author> Rao, A. S. </author> <year> 1994. </year> <title> Means-end plan recognition: Towards a theory of reactive recognition. </title> <booktitle> In Proceedings of the International Conference on Knowledge Representation and Reasoning (KR-94). </booktitle>
Reference: <author> Shaw, R. L. </author> <year> 1988. </year> <title> Fighter combat: tactics and maneuvers. </title> <type> Annapolis, </type> <institution> Maryland: Naval Institute Press. </institution>
Reference-contexts: This situation may arise due to adaptiveness: an intelligent adversary will very likely adapt its tactics to exploit possible weak nesses in a tracker's behaviors. * Real-time and dynamism: The tracker and trackee interact in real-time; for example, in simulated air-to-air combat, speed is life <ref> (Shaw 1988) </ref> in the real world, and in the simulated combat environment. * Complexity of environment: This is a realistic environment, in which entities and objects have a rich set of properties. * Cost of trial: Trials are not straightforward to run.
Reference: <author> Shen, W. </author> <year> 1993. </year> <title> Discovery as autonomous learning from the environment. </title> <booktitle> Machine Learning 12 </booktitle> <pages> 143-165. </pages>
Reference-contexts: Thus, comparing the feature set where the missile firing was successfully tracked with one where the tracking failed may yield differences in a large number of irrelevant features, e.g., the altitude or speed of the trackee. Under these circumstances, techniques akin to incremental enlargement <ref> (Shen 1993) </ref> or learning via experimentation (Gil 1993) can be employed to determine which features to discriminate. Incremental enlargement is a heuristic applicable to finding relevant features that are crucial in discriminating two environmental states that contain a large number of differences.
Reference: <author> Shen, W. </author> <year> 1994. </year> <title> Autonomous Learning from the Environment. </title> <editor> W. H. </editor> <publisher> Freeman, Computer Science Press. </publisher> <editor> steering committee, T. D. </editor> <year> 1994. </year> <title> The dis vision: A map to the future of distributed simulation. </title> <type> Technical Report IST-SP-94-01, </type> <institution> Institute for simulation and training, University of Central Florida, </institution> <address> Orlando. </address>
Reference: <author> Tambe, M., and Rosenbloom, P. S. </author> <year> 1995. </year> <title> RESC: An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). </booktitle>
Reference-contexts: The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosen-bloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>. To this end, two versions of the pilot agents | one developed for tracking (Tambe & Rosenbloom 1995; Tambe 1995) and one that learns models of decisions for explanation (Johnson 1994) | have been integrated.
Reference: <author> Tambe, M.; Johnson, W. L.; Jones, R.; Koss, F.; Laird, J. E.; Rosenbloom, P. S.; and Schwamb, K. </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16(1). </journal>
Reference-contexts: The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosen-bloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>. To this end, two versions of the pilot agents | one developed for tracking (Tambe & Rosenbloom 1995; Tambe 1995) and one that learns models of decisions for explanation (Johnson 1994) | have been integrated.
Reference: <author> Tambe, M. </author> <year> 1995. </year> <title> Recursive agent and agent-group tracking in a real-time dynamic environment. </title> <booktitle> In Proceedings of the International Conference on Multi-agent systems (ICMAS). </booktitle>
Reference-contexts: The realization of this promise is critically dependent on intelligent automated agents that can act as effective human surrogates | interacting intelligently with humans as well as other agents. Agent tracking is of course one key aspect of such an intelligent interaction <ref> (Tambe & Rosen-bloom 1995) </ref>. Certainly, an adversary will not communicate information regarding its goals and plans to an agent voluntarily | such information must be inferred via tracking. Furthermore, even in collaborative situations, tracking often assumes importance due to communication difficulties. <p> It needs to infer a missile firing from the trackee's observable maneuvers, even though those are often ambiguous. Nonetheless, given a reasonably accurate model of the trackee, the tracker agent can hope to address such ambiguity in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. Given adaptiveness on part of the trackee (static model imperfections), however, the situation becomes much more complex. The tracker cannot necessarily assume its model of the trackee is accurate, or that it will stay accurate over time. <p> This was intended to confuse the participating intelligent pilot agents, and indeed it did <ref> (Tambe et al. 1995) </ref>. Unable to track this changed missile firing tactic, intelligent pilot agents got shot down. Of course, human pilots are bound to come up with novel variations on known maneuvers, and intelligent agents cannot be expected to anticipate them. <p> With respect to other less harmful imperfections, using a flexible tracking strategy | one that can work with an imperfect model of the trackee | would appear to be a more fruitful approach. Such a strategy would need the capability to switch inferences dynamically in real-time <ref> (Tambe & Rosenbloom 1995) </ref>. For instance, if the tracker is not sure if the trackee is performing an offensive maneuver or a defensive maneuver, it may first assume that the maneuver is offensive (worst-case scenario), and then flexibly modify this assumption as soon as warranted by further observations. <p> Experimental Results We are taking a two-pronged approach in implementing the above approach. First, we have begun implementing the approach in intelligent pilot agents for the air-combat simulation environment <ref> (Tambe et al. 1995) </ref>. To this end, two versions of the pilot agents | one developed for tracking (Tambe & Rosenbloom 1995; Tambe 1995) and one that learns models of decisions for explanation (Johnson 1994) | have been integrated.
Reference: <author> Ward, B. </author> <year> 1991. </year> <title> ET-Soar: Toward an ITS for Theory-Based Representations. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Science, Carnegie Mellon Univ. </institution>
Reference-contexts: Many of these multi-agent domains are real-time and dynamic, requiring the interaction to be highly flexible and reactive. For instance, in the education arena, intelligent tutoring systems need to interact with students while they are solving problems <ref> (Ward 1991) </ref>. In the arena of entertainment, recent work has focused on real-time, dynamic interactivity among multiple agents within virtual reality environments (Bates, Loyall, & Reilly 1992; Hayes-Roth, Brownston, & V. 1995).
References-found: 19

