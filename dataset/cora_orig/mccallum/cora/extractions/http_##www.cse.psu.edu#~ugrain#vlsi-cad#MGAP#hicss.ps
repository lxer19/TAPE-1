URL: http://www.cse.psu.edu/~ugrain/vlsi-cad/MGAP/hicss.ps
Refering-URL: http://www.cse.psu.edu/~ugrain/publications.html
Root-URL: 
Email: permissions@acm.org.  
Address: 1515 Broadway, New York, NY 10036 USA  
Affiliation: Inc.  
Note: Copyright c fl1993 by the Association for Computing Machinery, Inc. Publications Dept, ACM  
Abstract: Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works whether directly or by incorporation via a link, requires prior specific permission and/or a fee. Permissions may be requested from 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Avizienis. </author> <title> Signed-digit number representation for fast parallel arithmetic. </title> <journal> IRE Trans. on Electronic Computers, </journal> <pages> page 389, </pages> <year> 1961. </year>
Reference-contexts: The arithmetic operations are done efficiently using a radix-4, fully redundant, signed- digit number system. Thus each digit can assume the values f3; 2; 1; 0; 1; 2; 3g and is represented using 3 bits <ref> [1] </ref>. The arithmetic algorithms as well as the motivation behind using a redundant number system have been elaborated in [9]. The choice of the number system avoids carry propagation and exploits the fine- grain parallelism in an operation.
Reference: [2] <author> R. S. Bajwa, R. M. Owens, and M. J. Irwin. </author> <title> Image Processing with the MGAP: A Cost Effective Approach. </title> <booktitle> In Intl. Parallel Processing Symposium, </booktitle> <pages> pages 439-443, </pages> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: Therefore these tasks are inherently suited for fine-grain parallelism and such implementations offer many advantages over conventional designs, since they are small in size, consume less power and provide very good cost-performance ratio <ref> [2] </ref>. While general purpose computing systems like the CM [6], the DAP [13], the MPP [4] etc. exist, they are very expensive (more than hundreds of thousands of dollars) and very large. <p> 320 1.6ms 75 fi 10 3 Dynamic Time 128 fi 128 425,000 17ms 964 fi 10 3 Warping Table 3: Execution times for DSP applications on the MGAP provides performance comparable to or better than the MPP, the CLIP, the DAP and the GAPP at a fraction of their cost <ref> [2] </ref>. At the same time, the architecture and user support is general enough to be used in a variety of other fields.
Reference: [3] <author> K. E. Batcher. </author> <title> STARAN Parallel Processor System Hardware. </title> <booktitle> In Proc. Natl. Comput. Conf., AIFPS, </booktitle> <pages> pages 405-410, </pages> <year> 1974. </year>
Reference-contexts: All the standard arithmetic operators are overloaded to handle parallel data types. The example shown below adds two 64 fi 64 integer arrays. /* Some library definitions */ class digit - // Array of 3 bits allocated private: // on the same digit processor local bit val <ref> [3] </ref>; public: inline digit sum (digit y) - .... - class word - // 16-digit integer in the // form of a square array private: // with digits in snake order snake digit val [16]; public: word operator+(word x, word y)- .... - class shape - // A 64x64 square array <p> More complex operations like multiplication, division, square-root etc. can be done in O (p) time using innovative digit-systolic algorithms [9]. This is an O (n) speedup over the conventional digit-serial methods of existing fine-grain systems such as the DAP [13], the STARAN <ref> [3] </ref>, the MPP [4] and the CM2 [6]. We also match the performance of the digit-parallel schemes of associative fine-grain processors such as the Massively Parallel Associative Processor [14].
Reference: [4] <author> K. E. Batcher. </author> <title> Design of a Massively Parallel Processor. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 29(9):836840, </volume> <month> Sep. </month> <year> 1980. </year>
Reference-contexts: Therefore these tasks are inherently suited for fine-grain parallelism and such implementations offer many advantages over conventional designs, since they are small in size, consume less power and provide very good cost-performance ratio [2]. While general purpose computing systems like the CM [6], the DAP [13], the MPP <ref> [4] </ref> etc. exist, they are very expensive (more than hundreds of thousands of dollars) and very large. <p> Thus the MGAP which consists of 16K digit processors provides a peak performance of 0.819 teraops (trillion operations per second), where an operation is any three input boolean function. (This definition of an operation is consistent with that used by other fine-grain processors such as the MPP <ref> [4] </ref> and the CM [6].) The array is provided with a wrap-around connection that makes it possible to transpose a large matrix N fiN in O (N ) time merely by taking the wraparound path. Almost all applications have inherently sequential code interspersed with possibly parallel computations. <p> More complex operations like multiplication, division, square-root etc. can be done in O (p) time using innovative digit-systolic algorithms [9]. This is an O (n) speedup over the conventional digit-serial methods of existing fine-grain systems such as the DAP [13], the STARAN [3], the MPP <ref> [4] </ref> and the CM2 [6]. We also match the performance of the digit-parallel schemes of associative fine-grain processors such as the Massively Parallel Associative Processor [14]. The flow of data through the Micro Grain array during the multiplication of two n fi n matrices is shown in Fig 6.
Reference: [5] <author> D.J. Burr, B.D. Ackland, and N Weste. </author> <title> Array Configurations for Dynamic Time Warping. </title> <journal> IEEE Trans. on ASSP, </journal> <volume> ASSP-32(1):119-128, </volume> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: The unknown template U i is compared to a set of reference templates R j to determine the pattern class it belongs to. We use a systolic implementation of the DTW using dynamic programming that is described by Burr et. al. in <ref> [5] </ref>. The unknown pattern is first stored in the array and the reference patterns flow into the array in a skewed fashion as shown in Fig 12. A simple distance measure based on the absolute difference is used.
Reference: [6] <author> W. D. Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Therefore these tasks are inherently suited for fine-grain parallelism and such implementations offer many advantages over conventional designs, since they are small in size, consume less power and provide very good cost-performance ratio [2]. While general purpose computing systems like the CM <ref> [6] </ref>, the DAP [13], the MPP [4] etc. exist, they are very expensive (more than hundreds of thousands of dollars) and very large. <p> the MGAP which consists of 16K digit processors provides a peak performance of 0.819 teraops (trillion operations per second), where an operation is any three input boolean function. (This definition of an operation is consistent with that used by other fine-grain processors such as the MPP [4] and the CM <ref> [6] </ref>.) The array is provided with a wrap-around connection that makes it possible to transpose a large matrix N fiN in O (N ) time merely by taking the wraparound path. Almost all applications have inherently sequential code interspersed with possibly parallel computations. <p> More complex operations like multiplication, division, square-root etc. can be done in O (p) time using innovative digit-systolic algorithms [9]. This is an O (n) speedup over the conventional digit-serial methods of existing fine-grain systems such as the DAP [13], the STARAN [3], the MPP [4] and the CM2 <ref> [6] </ref>. We also match the performance of the digit-parallel schemes of associative fine-grain processors such as the Massively Parallel Associative Processor [14]. The flow of data through the Micro Grain array during the multiplication of two n fi n matrices is shown in Fig 6.
Reference: [7] <author> C. Nagendra, M. Borah, M. Vishwanath, R.M. Owens, and M.J. Irwin. </author> <title> Edge Detection us-ing Fine-grain Parallelism in VLSI. </title> <booktitle> In Proc. ICASSP'93, </booktitle> <volume> volume 1, </volume> <pages> pages 401-404, </pages> <month> Apr </month> <year> 1993. </year>
Reference-contexts: The next subsection gives an overview of the basic parallel operations that can be done using the MGAP. Building on these, algorithms for matrix multiplication, filtering, various transforms, edge detection, pattern matching, finding connected components and others can be derived <ref> [11, 7, 12] </ref>. Most known algorithms for SIMD mesh architectures run on the MGAP with only slight modifications. 4.1 Some basic operations Table 1 gives the complexities of some arithmetic operations on the MGAP. Here p denotes the precision, which is the number of digits in an operand. <p> Hence we developed an algorithm for the Hough transform which is multiplication free and fully systolic. A detailed description of the algorithm and its implementation on the MGAP can be found in <ref> [7] </ref>. An extension to 6 MAC 7 Radon transforms is also discussed in the same pa-per. Fig 11 illustrates the flow of data into the array while computing the Hough Transform on successive images for M different angles ( 1 ; ; M ).
Reference: [8] <author> C. Nagendra, M. J. Irwin, and R. M. Owens. </author> <title> Digit Pipelined Discrete Wavelet Transform. </title> <type> Technical Report CSE-93-006, </type> <institution> Dept. of Comp. Sci. and Eng., Penn State Univ., University Park, </institution> <address> PA, </address> <month> Sep. </month> <year> 1993. </year>
Reference-contexts: The speed disadvantages of serial processing are overcome by pipelining at the digit level. The digit cycle time is independent of the word length. Thus, very high speeds can be achieved for arithmetic operations by pipelining at the digit level. 4.4 DWT In <ref> [8] </ref>, a digit serial, digit pipelined algorithm for computing the Discrete Wavelet transform is described. An N -point DWT takes O (N k) time and requires O (LJ k) area, where L is the filter size, J is the number of octaves and k is the precision.
Reference: [9] <author> C. Nagendra, R.M. Owens, and M.J. Irwin. </author> <title> Digit Systolic Algorithms for Fine-grain Architectures. </title> <booktitle> In Proc. Application Specific Array Processors, </booktitle> <pages> pages 466-477, </pages> <month> Oct </month> <year> 1993. </year>
Reference-contexts: Thus each digit can assume the values f3; 2; 1; 0; 1; 2; 3g and is represented using 3 bits [1]. The arithmetic algorithms as well as the motivation behind using a redundant number system have been elaborated in <ref> [9] </ref>. The choice of the number system avoids carry propagation and exploits the fine- grain parallelism in an operation. It can be seen that digit shift, addition and negation can be done in constant time while word shift, comparison, exchange and min/max take O ( p p) time. <p> It can be seen that digit shift, addition and negation can be done in constant time while word shift, comparison, exchange and min/max take O ( p p) time. More complex operations like multiplication, division, square-root etc. can be done in O (p) time using innovative digit-systolic algorithms <ref> [9] </ref>. This is an O (n) speedup over the conventional digit-serial methods of existing fine-grain systems such as the DAP [13], the STARAN [3], the MPP [4] and the CM2 [6]. <p> That is, computing the function W X +Y to produce a p-digit result, where W , X and Y are p- digit fractions. A MAC (Multiply-Accumulate Com- ponent) is obtained using the optimal time, digit systolic multiplier presented in <ref> [9] </ref>. It takes time T = O (p) and occupies area A = O (p). Fig 8 illustrates the flow of data in a least-significant-digit (lsd) first MAC as well as a most-significant-digit (msd) first MAC. The aim is to avoid broadcast and minimize communication.
Reference: [10] <author> D. Nassimi and S. Sahni. </author> <title> Bitonic sort on a meshconnected parallel computer. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-27:2-7, </volume> <month> Jan. </month> <year> 1979. </year>
Reference-contexts: Length k; k = 1; 2; ; n=2 Row Unshu*es 2 Length k; k = 1; 2; ; n=2 Column Shu*es 2 Length k; k = 1; 2; ; n=2 Column Unshu*es 2 Additions 2 log 2 (n) Multiplications 2 log 2 (n) Squarings log 2 (n) As shown in <ref> [10] </ref> shu*es and unshu*e on two length n sequences can be done in n 1 steps and thus requires (n 1) fi (3 p p + 16) cycles. The algorithm can be computed on the MGAP in 8n (3 p + 16) + log 2 (n)(405p 135) cycles.
Reference: [11] <author> R. M. Owens and M. J. Irwin. </author> <title> A TwoDimensional, Distributed Logic Processor. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40(10) </volume> <pages> 1094-1101, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The next subsection gives an overview of the basic parallel operations that can be done using the MGAP. Building on these, algorithms for matrix multiplication, filtering, various transforms, edge detection, pattern matching, finding connected components and others can be derived <ref> [11, 7, 12] </ref>. Most known algorithms for SIMD mesh architectures run on the MGAP with only slight modifications. 4.1 Some basic operations Table 1 gives the complexities of some arithmetic operations on the MGAP. Here p denotes the precision, which is the number of digits in an operand.
Reference: [12] <author> R. M. Owens, M. J. Irwin, C. Nagendra, and R. S. Bajwa. </author> <booktitle> Computer Vision on the MGAP. In Proc. Computer Architectures for Machine Perception, </booktitle> <pages> pages 337-441, </pages> <month> Dec </month> <year> 1993. </year>
Reference-contexts: The next subsection gives an overview of the basic parallel operations that can be done using the MGAP. Building on these, algorithms for matrix multiplication, filtering, various transforms, edge detection, pattern matching, finding connected components and others can be derived <ref> [11, 7, 12] </ref>. Most known algorithms for SIMD mesh architectures run on the MGAP with only slight modifications. 4.1 Some basic operations Table 1 gives the complexities of some arithmetic operations on the MGAP. Here p denotes the precision, which is the number of digits in an operand.
Reference: [13] <author> S. F. Reddaway. </author> <title> DAP A Distributed Array Processor. </title> <booktitle> In Proc. First Annual Symposium on Computer Architecture, </booktitle> <pages> pages 61-65, </pages> <year> 1973. </year>
Reference-contexts: Therefore these tasks are inherently suited for fine-grain parallelism and such implementations offer many advantages over conventional designs, since they are small in size, consume less power and provide very good cost-performance ratio [2]. While general purpose computing systems like the CM [6], the DAP <ref> [13] </ref>, the MPP [4] etc. exist, they are very expensive (more than hundreds of thousands of dollars) and very large. <p> More complex operations like multiplication, division, square-root etc. can be done in O (p) time using innovative digit-systolic algorithms [9]. This is an O (n) speedup over the conventional digit-serial methods of existing fine-grain systems such as the DAP <ref> [13] </ref>, the STARAN [3], the MPP [4] and the CM2 [6]. We also match the performance of the digit-parallel schemes of associative fine-grain processors such as the Massively Parallel Associative Processor [14].
Reference: [14] <author> I. D. Scherson, D. A. Kramer, and B. D. Alleyne. </author> <title> Bit-Parallel Arithmetic in a MassivelyParallel Associative Processor. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 41(10) </volume> <pages> 1201-1209, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: We also match the performance of the digit-parallel schemes of associative fine-grain processors such as the Massively Parallel Associative Processor <ref> [14] </ref>. The flow of data through the Micro Grain array during the multiplication of two n fi n matrices is shown in Fig 6.
Reference: [15] <institution> Thinking Machines Corporation. </institution> <note> Getting Started in C*, February 1991. 9 </note>
Reference-contexts: For operations on parallel data in general, and matrices in particular, we have introduced the concept of shapes similar to the C* language which is used to program the Connection Machine <ref> [15] </ref>. Only those objects that are explicitly defined to be of type shape will be allocated space on the Micro-Grain array. All the standard arithmetic operators are overloaded to handle parallel data types.
References-found: 15

