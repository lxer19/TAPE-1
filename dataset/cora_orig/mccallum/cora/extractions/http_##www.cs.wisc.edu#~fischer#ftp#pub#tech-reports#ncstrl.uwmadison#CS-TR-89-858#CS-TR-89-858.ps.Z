URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-858/CS-TR-89-858.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-858/
Root-URL: http://www.cs.wisc.edu
Email: maclin@cs.wisc.edu  
Phone: (608) 262-6613  
Title: Using Explanation-Based Learning to Acquire Programs by Analyzing Examples  
Author: Richard Maclin Jude W. Shavlik 
Note: This research was partially supported by a grant from the  
Address: 1210 West Dayton Street Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin  University of Wisconsin-Madison Graduate School.  
Abstract: University of Wisconsin Computer Sciences Technical Report 858 (June 1989) Abstract A number of problems confront standard automatic programming methods. One problem is that the combinatorics of search make automatic programming intractable for most real-world applications. Another problem is that most automatic programming systems require the user to express information in a form that is too complex. Also, most automatic programming systems do not include mechanisms for incorporating and using domain-specific knowledge. One approach that offers the possibility of dealing with these problems is the application of explanation-based learning (EBL). In the form of EBL used for this project, explanation-based learning by observation, the user enters a description of a specific problem and solution to that problem in a form comfortable to him or her. Using domain-specific knowledge, the system constructs an explanation of the solution to the problem using the actions of the user as guidance. Next, the goal stated by the user is generalized with respect to any domain information about possible goals of actions performed by the user in the solution. Then the explanation is reconstructed with respect to the generalized goal. Finally, the explanation is transformed into a general solution which can be used to solve problems that are conceptually similar to the specific problem presented. This approach promises to overcome the problems with standard automatic programming methods discussed above. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh
Abstract-found: 1
Intro-found: 1
Reference: [Balzer77] <author> R. Balzer, N. Goldman and D. Wile, </author> <title> "Informality in Program Specifications," </title> <booktitle> Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <month> August </month> <year> 1977, </year> <pages> pp. 389-397. </pages>
Reference-contexts: The PLEESE approach avoids this problem because the process of creating an explanation of a specific problem is significantly constrained by the solution presented by the user. A second problem with automatic theorem proving is the production of specifications <ref> [Balzer77] </ref>. Since these specifications are logically oriented, even the simplest of procedures may have a large and unwieldy specification, which the user has to construct and enter.
Reference: [Bauer75] <author> M. Bauer, </author> <title> "A Basis for the Acquisition of Procedures from Protocols," </title> <booktitle> Proceedings of the Fourth International Joint Conference on Artificial Intelligence, </booktitle> <address> Tiblisi, Georgia, U.S.S.R., </address> <month> August </month> <year> 1975, </year> <pages> pp. 226-231. </pages>
Reference-contexts: Each step involves generalizing the original problem presented by the user. Related Work in Automatic Programming The approach taken in PLEESE draws on existing automatic programming methods including automatic theorem proving (e.g., [Good84, Manna86]) and program specification using traces (e.g., <ref> [Bauer75, Phillips77] </ref>) or examples [Summers77]. PLEESE addresses a number of the problems encountered by these methods. The PLEESE approach is most like automatic theorem proving in that both involve deriving a proof (explanation) for an algorithm and then using that proof to write a program for the algorithm.
Reference: [DeJong86] <author> G. F. DeJong and R. J. Mooney, </author> <title> "Explanation-Based Learning: An Alternative View," </title> <booktitle> Machine Learning 1, 2 (1986), </booktitle> <pages> pp. 145-176. </pages>
Reference-contexts: Machine learning researchers, especially those in Explanation-Based Learning (EBL), address issues that directly relate to the problems that have hindered automatic programming research. In EBL <ref> [DeJong86, Mitchell86] </ref>, a specific problem's solution is generalized into a form that can be later used to solve conceptually similar problems. The generalization process is driven by the explanation of why the solution worked. <p> EBL algorithms take an explanation of a specific problem and produce a general method for solving similar problems. This process is done by converting constants in the original explanations into constrained variables and then unifying the variables to retain the interactions of the specific problem (see <ref> [DeJong86, Mitchell86] </ref> for details). These algorithms produce a rule that can be used to efficiently solve similar problems. Some EBL algorithms also generalize the structure of their explanations. The BAGGER algorithm [Shavlik87, Shavlik88] is an example of a system that generalizes structure.
Reference: [Good84] <author> D. </author> <title> Good, "Mechanical Proofs About Computer Programs," </title> <journal> Philosophical Transactions of the Royal Society of London 312, </journal> <volume> 1522 (1984), </volume> <pages> pp. 389-409. </pages> <note> (Also appears in Readings in Artificial Intelligence and Software Engineering, </note> <editor> C. Rich (ed.), </editor> <publisher> Morgan-Kaufmann) </publisher>
Reference-contexts: Each step involves generalizing the original problem presented by the user. Related Work in Automatic Programming The approach taken in PLEESE draws on existing automatic programming methods including automatic theorem proving (e.g., <ref> [Good84, Manna86] </ref>) and program specification using traces (e.g., [Bauer75, Phillips77]) or examples [Summers77]. PLEESE addresses a number of the problems encountered by these methods.
Reference: [Hill87] <author> W. L. Hill, </author> <title> "Machine Learning for Software Reuse," </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987, </year> <pages> pp. 338-344. </pages>
Reference: [Manna86] <author> Z. Manna and R. Waldinger, </author> <title> "A Deductive Approach to Program Synthesis," </title> <booktitle> in Readings in Artificial Intelligence and Software Engineering, </booktitle> <editor> C. Rich (ed.), </editor> <publisher> Morgan Kaufman, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986, </year> <pages> pp. 3-34. </pages>
Reference-contexts: Each step involves generalizing the original problem presented by the user. Related Work in Automatic Programming The approach taken in PLEESE draws on existing automatic programming methods including automatic theorem proving (e.g., <ref> [Good84, Manna86] </ref>) and program specification using traces (e.g., [Bauer75, Phillips77]) or examples [Summers77]. PLEESE addresses a number of the problems encountered by these methods.
Reference: [Michalski75] <author> R. S. Michalski, </author> <title> "Synthesis of Optimal and Quasi-optimal Variable Valued Logic Formulas," </title> <booktitle> Proceedings of the 1975 International Symposium on Multiple-Valued Logic, Bloomington, IN, </booktitle> <year> 1975, </year> <pages> pp. 76-87. </pages>
Reference-contexts: It can do this because it has a domain theory with which is is able to explain how these examples can be solved. Previous approaches were much like similarity-based learning algorithms <ref> [Michalski75, Quinlan86] </ref>, in that both require a large number of training examples due to their inability to explain how single examples are solved. Also, the generalizations they make are unjustified, while generalizations in an EBL system are justified by a domain theory.
Reference: [Mitchell86] <author> T. M. Mitchell, R. M. Keller and S. Kedar-Cabelli, </author> <title> "Explanation-Based Generalization: A Unifying View," </title> <booktitle> Machine Learning 1, 1 (1986), </booktitle> <pages> pp. 47-80. </pages>
Reference-contexts: Machine learning researchers, especially those in Explanation-Based Learning (EBL), address issues that directly relate to the problems that have hindered automatic programming research. In EBL <ref> [DeJong86, Mitchell86] </ref>, a specific problem's solution is generalized into a form that can be later used to solve conceptually similar problems. The generalization process is driven by the explanation of why the solution worked. <p> EBL algorithms take an explanation of a specific problem and produce a general method for solving similar problems. This process is done by converting constants in the original explanations into constrained variables and then unifying the variables to retain the interactions of the specific problem (see <ref> [DeJong86, Mitchell86] </ref> for details). These algorithms produce a rule that can be used to efficiently solve similar problems. Some EBL algorithms also generalize the structure of their explanations. The BAGGER algorithm [Shavlik87, Shavlik88] is an example of a system that generalizes structure.
Reference: [Phillips77] <author> J. Phillips, </author> <title> "A Framework for the Synthesis of Programs from Traces using Multiple Knowledge Sources," </title> <booktitle> Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <month> August </month> <year> 1977. </year>
Reference-contexts: Each step involves generalizing the original problem presented by the user. Related Work in Automatic Programming The approach taken in PLEESE draws on existing automatic programming methods including automatic theorem proving (e.g., [Good84, Manna86]) and program specification using traces (e.g., <ref> [Bauer75, Phillips77] </ref>) or examples [Summers77]. PLEESE addresses a number of the problems encountered by these methods. The PLEESE approach is most like automatic theorem proving in that both involve deriving a proof (explanation) for an algorithm and then using that proof to write a program for the algorithm.
Reference: [Quinlan86] <author> J. R. Quinlan, </author> <title> "Induction of Decision Trees," </title> <booktitle> Machine Learning 1, 1 (1986), </booktitle> <pages> pp. 81-106. </pages>
Reference-contexts: It can do this because it has a domain theory with which is is able to explain how these examples can be solved. Previous approaches were much like similarity-based learning algorithms <ref> [Michalski75, Quinlan86] </ref>, in that both require a large number of training examples due to their inability to explain how single examples are solved. Also, the generalizations they make are unjustified, while generalizations in an EBL system are justified by a domain theory.
Reference: [Rich86] <author> C. Rich and R. C. Waters, </author> <booktitle> Readings in Artificial Intelligence and Software Engineering, </booktitle> <publisher> Morgan Kaufman, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Introduction Automatic programming has long been a goal of artificial intelligence (AI) researchers <ref> [Rich86] </ref>. After peaking in the mid-70's this research has been slowed by three critical problems. One, the combinatorics of search have prevented the developed techniques from being applied to realistic programming problems.
Reference: [Shavlik87] <author> J. W. Shavlik and G. F. DeJong, "BAGGER: </author> <title> An EBL System that Extends and Generalizes Explanations," </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1987, </year> <pages> pp. 516-520. </pages>
Reference-contexts: These algorithms produce a rule that can be used to efficiently solve similar problems. Some EBL algorithms also generalize the structure of their explanations. The BAGGER algorithm <ref> [Shavlik87, Shavlik88] </ref> is an example of a system that generalizes structure. BAGGER recognizes cases of implicit recursion or iteration in its explanations and produces solutions containing that recursion or iteration.
Reference: [Shavlik88] <author> J. W. Shavlik, </author> <title> "Generalizing the Structure of Explanations in Explanation-Based Learning," </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL, </institution> <month> January </month> <year> 1988. </year> <note> (Also appears as CSL Technical Report UILU-ENG-87-2276.) </note>
Reference-contexts: The major focus of the PLEESE project is the process of going from explanations of specific solutions to useful general-purpose algorithms. This project builds on previous work on generalizing the structure of explanations <ref> [Shavlik88] </ref>. Most research in EBL involves relaxing constraints on the items in a specific problem's explanation. The internal structure of the explanation itself is not generalized. <p> These algorithms produce a rule that can be used to efficiently solve similar problems. Some EBL algorithms also generalize the structure of their explanations. The BAGGER algorithm <ref> [Shavlik87, Shavlik88] </ref> is an example of a system that generalizes structure. BAGGER recognizes cases of implicit recursion or iteration in its explanations and produces solutions containing that recursion or iteration.
Reference: [Shavlik89] <author> J. W. Shavlik, </author> <title> "Acquiring Recursive Concepts with Explanation-Based Learning," </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <month> August </month> <year> 1989, </year> <pages> pp. 688-693. </pages>
Reference-contexts: However, this precludes the acquisition of concepts where a general iterative or recursive process is implicitly represented by a fixed number of applications in the specific problem's explanation. Since programming so heavily involves iteration and recursion, extensions of the algorithms developed for the BAGGER system <ref> [Shavlik89] </ref> are particularly appropriate for efficiently learning computer programs. PLEESE generates explanations which are used as input to the BAGGER system. The general rules produced by BAGGER can then be converted into general programs. <p> This approach uses the EBL techniques discussed in the last section to generalize the specific problem presented by the user. The process of generalization of the explanation (including structural generalization) is performed by the BAGGER system <ref> [Shavlik89] </ref>. An overview of the PLEESE approach is presented in figure 1, and the following is a description of the steps of the process.
Reference: [Steier87] <author> D. Steier, "CYPRESS-SOAR: </author> <title> A Case Study in Search and Learning in Algorithm Design," </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987, </year> <pages> pp. 327-330. </pages>
Reference: [Summers77] <author> P. D. Summers, </author> <title> "A Methodology for LISP Program Construction from Examples," </title> <journal> Journal of the Association for Computing Machinery 24, </journal> <year> (1977), </year> <pages> pp. 161-175. 14 </pages>
Reference-contexts: Each step involves generalizing the original problem presented by the user. Related Work in Automatic Programming The approach taken in PLEESE draws on existing automatic programming methods including automatic theorem proving (e.g., [Good84, Manna86]) and program specification using traces (e.g., [Bauer75, Phillips77]) or examples <ref> [Summers77] </ref>. PLEESE addresses a number of the problems encountered by these methods. The PLEESE approach is most like automatic theorem proving in that both involve deriving a proof (explanation) for an algorithm and then using that proof to write a program for the algorithm.
References-found: 16

