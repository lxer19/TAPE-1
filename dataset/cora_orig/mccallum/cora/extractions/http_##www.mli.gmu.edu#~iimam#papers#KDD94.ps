URL: http://www.mli.gmu.edu/~iimam/papers/KDD94.ps
Refering-URL: http://www.mli.gmu.edu/~iimam/pap_slct.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: iimam michalski- @aic.gmu.edu  
Title: From Facts to Rules to Decisions: An Overview of the FRD-1 System  
Author: Ibrahim F. Imam and Ryszard S. Michalski 
Address: Fairfax, VA. 22030  
Affiliation: Center for Artificial Intelligence George Mason University  
Abstract: This paper is published in the AAAI-94 Working Notes of the Third International Workshop on Knowledge Discovery in Databases (KDD-93), pp. 264-275, July 11-12, Washington, D.C., 1993. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arciszewski, T, Bloedorn, E., Michalski, R., Mustafa, M., and Wnek, J., </author> <year> (1992). </year> <title> "Constructive Induction in Structural Design", Report of Machine Learning and Inference Labratory, </title> <institution> MLI-92-7, Center for Artificial Intelligence, George Mason University. </institution>
Reference-contexts: The most desirable is the minimal discriminant descriptions, that is a rule with the shortest condition part. To illustrate the AQ15/C rule learning, let us consider a problem of determining a decision structure for wind bracing design <ref> (Arciszewski, et al, 1992) </ref>. The wind bracing data contains four decision classes representing different categories of the buildings: high (C1), medium (C2), low (C3) and infeasible (C4). Examples of design have been expressed in terms of seven attributes that are shown in Table 1.
Reference: <author> Imam, I.F. and Michalski, R.S. </author> , <year> (1993). </year> <title> "Learning Decision Structures from Decision Rules: A method and initial results from a comparative study", </title> <journal> in Journal of Intelligent Information Systems JIIS, </journal> <volume> Vol. 2, No. 3, </volume> <pages> pp. 279-304, </pages> <editor> Kerschberg, L., Ras, Z., & Zemankova, M. (Eds.), </editor> <publisher> Kluwer Academic Pub., </publisher> <address> MA. </address>
Reference-contexts: When there is a need to apply the discoverd knowledge to new data for the purpose of decision making, the AQDT-1 system is used to transform the decision rules into a decision stucture that is tailored to the given decision making situation <ref> (Imam & Michalski, 1993) </ref>. Figure 1 shows an architecture of the FRD-1 methodology. Decision Structure Discovered Rules Data Decision AQDT-1 AQ15/C Training Data New Data Discovering rules from database The decision making process It is assumed that the database is not static, but is regularly updated.
Reference: <author> Imam, I.F. and Michalski, R.S. </author> , <year> (1994), </year> <title> From Data to Knowledge to Optimal Decision Structures: A Methodology and Expriments, Report of Machine Learning and Inference Labratory, </title> <institution> MLI-94-xx, Center for AI, George Mason Un.. </institution> <note> (to appear) Michalski, R.S., </note> <author> Mozetic, I., Hong, J. & Lavrac, N., </author> <year> (1986). </year> <title> The MultiPurpose Incremental Learning System AQ15 and Its Testing Application to Three Medical Domains, </title> <booktitle> Proceedings of AAAI-86 , (pp. </booktitle> <pages> 1041-1045), </pages> <address> Philadelphia, PA. </address>
Reference-contexts: A more detailed description of the methodology and results of various comparative studies are presented in <ref> (Imam and Michalski, 1994) </ref>. 2. AN OVERVIEW OF THE FRD-1 METHODOLOGY The proposed system consists of two subsystems. The first subsystem searches for useful knowledge in the data. Knowledge is represented in the form of decision rules, which are a form of declarative knowledge representation. <p> In this case, decision structure indicates likely decisions of which an estimate of their likelihood. The estimate reflects the frequency of classes when the data points satisfy the conditions on the path from the root to the leaf. Details on how to calculate these frequencies are in <ref> (Imam & Michalski, 1994) </ref>. x6 x5 C3 Complexity No. of nodes: 5 No. of leaves: 7 C2 x2 4 1v2v3 C1 C4 C2 C2 C2 The ratio present the likelyhood of each decision at the given leave.
Reference: <author> Quinlan, J. R. </author> <year> (1990). </year> <title> Probabilistic decision structures, </title> <editor> in Y. Kodratoff and R.S. Michalski (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach , Vol. </booktitle> <address> III , San Mateo, CA, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <pages> (pp. 63-111), </pages> <month> June. </month>
Reference-contexts: Figure 3 shows a decision structure learned in the default setting of FRD-1 parameters from AQ15/C rules. It has 5 nodes and 9 leaves. Testing this decision structure against 115 testing examples results in 102 examples matched correctly and 13 examples mismatched. For comparison, when the C4.5 system <ref> (Quinlan, 90) </ref> for learning decision trees from examples was applied to the same set of examples. It produced a decision structure with 17 nodes and 43 leaves. The decision tree matched correctly 97 and mismatched 18 examples.
References-found: 4

