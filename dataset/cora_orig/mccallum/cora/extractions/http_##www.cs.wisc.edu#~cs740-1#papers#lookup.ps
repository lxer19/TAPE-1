URL: http://www.cs.wisc.edu/~cs740-1/papers/lookup.ps
Refering-URL: 
Root-URL: 
Email: micke@cdt.luth.se, Andrej.Brodnik@IMFM.Uni-Lj.SI, svante@sm.luth.se, steve@sics.se  
Title: Small Forwarding Tables for Fast Routing Lookups forwarding tables are very small, a large routing
Author: Mikael Degermark, Andrej Brodnik, Svante Carlsson, and Stephen Pink 
Note: The  14 bytes.  
Address: S-971 87 Lule-a, Sweden  
Affiliation: Department of Computer Science and Electrical Engineering Lule-a University of Technology  
Abstract: We present a forwarding table data structure designed for quick routing lookups. Forwarding tables are small enough to fit in the cache of a conventional general purpose processor. With the table in cache, a 200 MHz Pentium Pro or a 333 MHz Alpha 21164 can perform a few million lookups per second. This means that it is feasible to do a full routing lookup for each IP packet at gigabit speeds without special hardware. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abhaya Asthana, Catherine Delph, H. V. Jagadish, and Paul Krzyzanowski. </author> <title> Towards a gigabit IP router. </title> <journal> Journal of High Speed Networks, </journal> <volume> 1(4) </volume> <pages> 281-288, </pages> <year> 1993. </year>
Reference-contexts: The main purpose of these shortcuts seems to be to amortize the cost of IP processing over many packets. Again, that would not be necessary if IP processing was fast enough. IP router designs can use special-purpose hardware to do IP processing, as in the IBM router <ref> [1] </ref>. This can be an inflexible solution. Any changes in the IP format or protocol could invalidate such designs. The flexibility of software and the rapid performance increase of general purpose processors makes such solutions preferable. Another hardware approach is to use CAMs to do routing lookups [9].
Reference: [2] <author> A. Brodnik and J.I. Munro. </author> <title> Membership in a constant time and a minimum space. </title> <booktitle> In Proceedings 2 nd European Symposium on Algorithms, volume 855 of Lecture Notes in Computer Science, </booktitle> <pages> pages 72-81. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The current forwarding table sizes of around 150-160 Kbytes for the largest routing tables are still not small enough to fit entirely in the second level cache of Alpha 21164s. The current small size and fast lookups has been realized by applying recent work in algorithm theory <ref> [2, 3, 16] </ref> and by careful tuning of the data structure. There is reason to believe that this field of algorithm theory will develop even further. Moreover, a number of techniques to reduce the table size even further are still untried.
Reference: [3] <author> A. Brodnik and J.I. Munro. </author> <title> Neighbours on a grid. </title> <booktitle> In Proceedings 5 th Scandinavian Workshop on Algorithm Theory, volume 1097 of Lecture Notes in Computer Science, </booktitle> <pages> pages 307-320. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The current forwarding table sizes of around 150-160 Kbytes for the largest routing tables are still not small enough to fit entirely in the second level cache of Alpha 21164s. The current small size and fast lookups has been realized by applying recent work in algorithm theory <ref> [2, 3, 16] </ref> and by careful tuning of the data structure. There is reason to believe that this field of algorithm theory will develop even further. Moreover, a number of techniques to reduce the table size even further are still untried.
Reference: [4] <author> S. Deering and R. Hinden. </author> <title> Internet Protocol, Version 6 (IPv6) Specification. Request for Comments (Proposed Standard) RFC 1883, </title> <institution> Internet Engineering Task Force, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: We have devised a way to build the table that is linear in the number of routing entries and in the size of the resulting forwarding table. The table is built during a single pass over all routing entries. Larger addresses With the coming of IPv6 <ref> [4, 8] </ref> it is desirable to do fast lookups for 128-bit IPv6 addresses as well. With such large addresses, there is a danger of inflating the table size if the address space is sparsely utilized everywhere.
Reference: [5] <author> Willibald Doeringer, Gunter Karjoth, and Mehdi Nassehi. </author> <title> Routing on longest-matching prefixes. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(1) </volume> <pages> 86-97, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: We strongly believe that small forwarding tables and fast routing lookups are possible for IPv6 as well as IPv4. 7 Related work We are not aware of any substantial improvements in the performance of software for full IP routing lookups in recent years. However, <ref> [5] </ref> shows how to extend Pa-tricia trees to deal better with longest matching prefix searches, insertions and deletions. The resulting data structure is called dynamic prefix tries. There are at least as many nodes in a dynamic prefix trie as in the corresponding Patricia tree.
Reference: [6] <institution> Stanford University Workshop on Fast Routing and Switching, </institution> <month> December </month> <year> 1996. </year> <note> http://tiny-tera.stanford.edu/Workshop Dec96/ </note> . 
Reference-contexts: Routing updates can be frequent but since routing protocols need time in the order of minutes to converge, forwarding tables can grow a little stale and need not change more than at most once per second <ref> [6] </ref>. The network processor needs a dynamic routing table designed for fast updates and fast generation of forwarding tables.
Reference: [7] <author> David C. Feldmeier. </author> <title> Improving gateway performance with a routing-table cache. </title> <booktitle> In Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> New Orleans, Louisiana, </address> <month> March </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: However, the insertion and deletion operations appear efficient, so dynamic prefix tries might be a good candidate for the routing table maintained by the network processor. An early work on improving IP routing performance by avoiding full routing lookups <ref> [7] </ref> found that a small destination address cache can improve routing lookup performance by at least 65 per cent. Less than 10 slots was needed to get a hit rate over 90 per cent.
Reference: [8] <author> Robert Hinden. </author> <title> IP Next Generation Home Page. </title> <address> http://playground.sun.com/pub/ipng/html/ ipng-main.html </address> . 
Reference-contexts: We have devised a way to build the table that is linear in the number of routing entries and in the size of the resulting forwarding table. The table is built during a single pass over all routing entries. Larger addresses With the coming of IPv6 <ref> [4, 8] </ref> it is desirable to do fast lookups for 128-bit IPv6 addresses as well. With such large addresses, there is a danger of inflating the table size if the address space is sparsely utilized everywhere.
Reference: [9] <author> A. J. McAuley and P. Francis. </author> <title> Fast routing table lookup using CAMs. </title> <booktitle> In Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <volume> volume 3, </volume> <pages> pages 1382-1391, </pages> <address> San Francisco, </address> <year> 1993. </year>
Reference-contexts: This can be an inflexible solution. Any changes in the IP format or protocol could invalidate such designs. The flexibility of software and the rapid performance increase of general purpose processors makes such solutions preferable. Another hardware approach is to use CAMs to do routing lookups <ref> [9] </ref>. This is a fast but expensive solution. BBN is currently building a pair of multi-gigabit routers that use general purpose processors as forwarding engines [17]. Little information has been published so far.
Reference: [10] <author> Larry McVoy. </author> <note> lmbench home page. http://reality.sgi.com/lm/lmbench/lmbench.html </note> . 
Reference-contexts: The primary 8 Kbyte data cache has a latency of 2 cycles and the secondary cache of 256 Kbytes has a latency of 6 cycles. See Table 2. The latency of the Pentium Pro caches were measured using the tool lmbench <ref> [10, 11] </ref> as we were unable to obtain this information otherwise. during the second lookup for the Pentium Pro with the same forwarding table as in the previous section. The sequence of instructions that fetches the clock cycle counter takes 33 clock cycles.
Reference: [11] <author> Larry McVoy and Carl Staelin. lmbench: </author> <title> Portable tools for performance analysis. </title> <booktitle> In USENIX Winter Conference, </booktitle> <month> January </month> <year> 1996. </year> <note> Available at http://reality.sgi.com/lm/lmbench/ lmbench-usenix.ps </note> . 
Reference-contexts: The primary 8 Kbyte data cache has a latency of 2 cycles and the secondary cache of 256 Kbytes has a latency of 6 cycles. See Table 2. The latency of the Pentium Pro caches were measured using the tool lmbench <ref> [10, 11] </ref> as we were unable to obtain this information otherwise. during the second lookup for the Pentium Pro with the same forwarding table as in the previous section. The sequence of instructions that fetches the clock cycle counter takes 33 clock cycles.
Reference: [12] <author> K. Mehlhorn, S. Naher, and H. Alt. </author> <title> A lower bound on the complexity of the union-split-find problem. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(1) </volume> <pages> 1093-1102, </pages> <month> Decem-ber </month> <year> 1988. </year>
Reference-contexts: The forwarding table can be built during a single pass over all routing entries. A set of routing entries partitions the IP address space into sets of IP addresses. The problem of finding the proper routing information is similar to the more general interval set membership problem <ref> [12] </ref>. However, in our case the intervals are defined by nodes in the complete prefix tree and, therefore, has properties that we can use to obtain an even smaller data structure. For instance, each range of IP addresses has a length that is a power of two.
Reference: [13] <author> Donald R. Morrison. </author> <title> PATRICIA | Practical Algorithm to Retreive Information Coded In Alfanumeric. </title> <journal> Journal of the ACM, </journal> <volume> 15(4) </volume> <pages> 514-534, </pages> <month> October </month> <year> 1968. </year>
Reference-contexts: These caching methods have worked well in the past. However, as the current rapid growth of the Internet increases the required size of address caches, hardware caches might become uneconomical. Traditional implementations of routing tables use a version of Patricia trees <ref> [13] </ref>, a data structure invented almost thirty years ago, with modifications for longest prefix matching. By applying modern results in algorithm theory, routing lookup performance can be improved by orders of magnitude compared to Patricia trees.
Reference: [14] <author> P. Newman, W. L. Edwards, R. Hinden, E. Hoffman, F. Ching Liaw, T. Lyon, and G. Minshall. </author> <title> Ipsilon Flow Management Protocol Specification for IPv4, Version 1.0. Request For Comment RFC 1953, </title> <institution> Internet Engineering Task Force, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Tag switching and flow switching [15] are two IP bypass methods that were originally meant to be operated over ATM. The general idea is to let IP control link-level ATM hardware that performs actual data forwarding. Special purpose protocols <ref> [14] </ref> are needed between routers to agree on what ATM virtual circuit identifiers to use and which packet should use which VCI. If IP processing was fast enough, that extra machinery would not be needed.
Reference: [15] <author> Peter Newman, Tom Lyon, and Greg Minshall. </author> <title> Flow labeled IP: a connectionless approach to ATM. </title> <booktitle> In Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> San Francisco, California, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: Routing lookups must find the routing entry with the longest matching prefix. The belief that IP routing lookups are inherently slow and complex operations has lead to a proliferation of techniques to avoid doing them. Various link layer switching technologies below IP, IP layer bypass methods <ref> [15, 19, 20] </ref> and the development of alternative network layers based on virtual circuit technologies such as ATM, are, to some degree, results of a wish to avoid IP routing lookups. <p> When packets are large, it can be more efficient to make a few IP routing lookups instead of a large number of ATM VCI lookups. If network traffic consists mostly of large packets in the future, IP will be more efficient. Tag switching and flow switching <ref> [15] </ref> are two IP bypass methods that were originally meant to be operated over ATM. The general idea is to let IP control link-level ATM hardware that performs actual data forwarding.
Reference: [16] <author> S. Nilsson. </author> <title> Radix Sorting & Searching. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Lund University, </institution> <year> 1996. </year>
Reference-contexts: The current forwarding table sizes of around 150-160 Kbytes for the largest routing tables are still not small enough to fit entirely in the second level cache of Alpha 21164s. The current small size and fast lookups has been realized by applying recent work in algorithm theory <ref> [2, 3, 16] </ref> and by careful tuning of the data structure. There is reason to believe that this field of algorithm theory will develop even further. Moreover, a number of techniques to reduce the table size even further are still untried.
Reference: [17] <author> C. Partridge, P. Carvey, E. Burgess, I. Castineyra, T. Clarke, L. Graham, M. Hathaway, P. Herman, A. King, S. Kohlami, T. Ma, T. Mendez, W. Mil-liken, R. Osterlind, R. Pettyjohn, J. Rokosz, J. Seeger, M. Sollins, S. Storch, B. Tober, G. Troxel, D. Waitz-man, and S. Winterble. </author> <title> A fifty gigabit per second ip router. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <note> To Appear. </note>
Reference-contexts: The only task of a forwarding engine is to process packet headers. All other tasks such as participating in routing protocols, resource reservation, handling packets that need extra attention, and other administrative duties, are handled by the network processor. The BBN Multigigabit router <ref> [17] </ref> is an example of this design. Another router design is shown in Figure 2. Here, processing elements in the inbound interface decide to which outbound interface packets should be sent. The GRF routers from Ascend communications, for instance, use this design. <p> Another hardware approach is to use CAMs to do routing lookups [9]. This is a fast but expensive solution. BBN is currently building a pair of multi-gigabit routers that use general purpose processors as forwarding engines <ref> [17] </ref>. Little information has been published so far. <p> Less than 100 instructions are necessary according to <ref> [17] </ref>. The secondary cache of the Alpha is used as a large LRU cache of destination addresses. The scheme presumes locality in traffic patterns.
Reference: [18] <author> Craig Partridge. </author> <title> Gigabit networking. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: BBN is currently building a pair of multi-gigabit routers that use general purpose processors as forwarding engines [17]. Little information has been published so far. The idea, however, seems to be to use Alpha processors as forwarding engines and do all IP processing in software. <ref> [18] </ref> shows that it is possible to do IP process ing in no more than 200 instructions, assuming a hit in a route cache. Less than 100 instructions are necessary according to [17]. The secondary cache of the Alpha is used as a large LRU cache of destination addresses.
Reference: [19] <author> Guru Parulkar, Douglas C. Schmidt, and Jonathan Turner. IP/ATM: </author> <title> A strategy for integrating IP with ATM. </title> <journal> Computer Communication Review, </journal> <volume> 25(4) </volume> <pages> 49-58, </pages> <month> October </month> <year> 1995. </year> <booktitle> Proceedings ACM SIGCOMM '95 Conference. </booktitle>
Reference-contexts: Routing lookups must find the routing entry with the longest matching prefix. The belief that IP routing lookups are inherently slow and complex operations has lead to a proliferation of techniques to avoid doing them. Various link layer switching technologies below IP, IP layer bypass methods <ref> [15, 19, 20] </ref> and the development of alternative network layers based on virtual circuit technologies such as ATM, are, to some degree, results of a wish to avoid IP routing lookups. <p> If IP processing was fast enough, that extra machinery would not be needed. Another approach with the same goal of avoiding IP processing is taken in the IP/ATM architecture <ref> [19, 20] </ref>, where an ATM backplane connects a number of line cards and routing cards. IP processing elements located in the routing cards process IP headers.
Reference: [20] <author> Gurudatta Parulkar, Douglas C. Schmidt, and Jonathan S. Turner. GIPR: </author> <title> a gigabit IP router. </title> <booktitle> In Proc. of Gigabit Networking Workshop, </booktitle> <address> Boston, Mas-sachusetts, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Routing lookups must find the routing entry with the longest matching prefix. The belief that IP routing lookups are inherently slow and complex operations has lead to a proliferation of techniques to avoid doing them. Various link layer switching technologies below IP, IP layer bypass methods <ref> [15, 19, 20] </ref> and the development of alternative network layers based on virtual circuit technologies such as ATM, are, to some degree, results of a wish to avoid IP routing lookups. <p> If IP processing was fast enough, that extra machinery would not be needed. Another approach with the same goal of avoiding IP processing is taken in the IP/ATM architecture <ref> [19, 20] </ref>, where an ATM backplane connects a number of line cards and routing cards. IP processing elements located in the routing cards process IP headers.
Reference: [21] <institution> The Routing Arbiter Project. Internet routing and network statistics. </institution> <note> http://www.ra.net/statistics/ </note> . 
Reference-contexts: In the rest of this paper we present a data structure that can represent large routing tables in a very compact form and can be searched quickly using few memory references. For the largest routing tables we have found at key interconnection points in the Internet <ref> [21, 22] </ref>, the data structure is 150 - 160 Kbytes. That is small enough to fit entirely in the secondary cache of Pentium Pro processors, and to almost fit in the secondary cache of Alpha 21164 processors. <p> Internet routing tables are currently available at the web site for the Internet Performance Measurement and Analysis (IPMA) project [22], and were previously made available by the now terminated Routing Arbiter project <ref> [21] </ref>. The collected routing tables are daily snapshots of the routing tables used at various large Internet interconnection points. Some of the routing entries in these tables contain multiple next-hops.
Reference: [22] <institution> Michigan University and Merit Network. Internet Performance Management and Analysis (IPMA) Project. </institution> <note> Details available at http://nic.merit.edu/~ipma/ </note> . 
Reference-contexts: In the rest of this paper we present a data structure that can represent large routing tables in a very compact form and can be searched quickly using few memory references. For the largest routing tables we have found at key interconnection points in the Internet <ref> [21, 22] </ref>, the data structure is 150 - 160 Kbytes. That is small enough to fit entirely in the secondary cache of Pentium Pro processors, and to almost fit in the secondary cache of Alpha 21164 processors. <p> Internet routing tables are currently available at the web site for the Internet Performance Measurement and Analysis (IPMA) project <ref> [22] </ref>, and were previously made available by the now terminated Routing Arbiter project [21]. The collected routing tables are daily snapshots of the routing tables used at various large Internet interconnection points. Some of the routing entries in these tables contain multiple next-hops.
Reference: [23] <institution> Washington University Workshop on Integration of IP and ATM, </institution> <month> November </month> <year> 1996. </year> <note> Proceedings from session 5. Available at http://www.arl.wustl.edu/arl/workshops/atmip/ </note> . 
Reference-contexts: In fact, some believe that IP routing lookups cannot be done quickly at low cost in hardware <ref> [23] </ref>. We present a forwarding table that allows fast IP routing lookups in software. Pessimistic calculations based on experimental data show that Pentium Pro and Alpha 21164 processors can do at least two million full IP routing lookups per second. No traffic locality is assumed.
References-found: 23

