URL: ftp://playfair.stanford.edu/pub/donoho/denoiserelease3.ps.Z
Refering-URL: http://www.mathsoft.com/wavelets.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: DE-NOISING BY reconstruction f n is defined in the wavelet domain by translating all the
Author: SOFT-THRESHOLDING David L. Donoho p 
Keyword: an optimal recovery model. Key Words and Phrases. Empirical Wavelet Transform. Minimax Estimation. Adaptive Estimation. Optimal Recovery.  
Note: i 0; n 1, t i i=n, i iid N(0; 1). The  (on leave).  
Affiliation: Department of Statistics Stanford University  
Abstract: p n. We prove two results about that estimator. [Smooth]: With high probability ^ f fl n is at least as smooth as f , in any of a wide variety of smoothness measures. [Adapt]: The estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. Our proof of these results develops new facts about abstract statistical inference and its connection with Acknowledgements. These results were described at the Symposium on Wavelet Theory, held in connection with the Shanks Lectures at Van-derbilt University, April 3-4 1992. The author would like to thank Professor L.L. Schumaker for hospitality at the conference, and R.A. DeVore, Iain Johnstone, Gerard Kerkyacharian, Bradley Lucier, A.S. Nemirovskii, Ingram Olkin, and Dominique Picard for interesting discussions and correspondence on related topics. The author is also at the University of California, Berkeley 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, T.W. </author> <title> (1955) The integral of a symmetric unimodal function. </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 6, 2, </volume> <pages> 170-176. </pages>
Reference-contexts: Moreover, this "De-Noising" property signals near-complete success in an area where many previous non-wavelets methods have met only partial success. Suppose we wish to recover an unknown function f on <ref> [0; 1] </ref> from noisy data d i = f (t i ) + z i i = 0; : : : ; n 1 (1.1) where t i = i=n, z i iid ~ N (0; 1) is a Gaussian white noise, and is a noise level. <p> To state our results precisely, recall that the pyramidal filtering of [CDJV] corresponds to an orthogonal basis of L 2 <ref> [0; 1] </ref>. Such a basis has elements which are in C R and have, at high resolutions, D vanishing moments. It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a <p> of [CDJV] corresponds to an orthogonal basis of L 2 <ref> [0; 1] </ref>. Such a basis has elements which are in C R and have, at high resolutions, D vanishing moments. It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) [25, 29, 18, 16, 17]. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. <p> of L 2 <ref> [0; 1] </ref>. Such a basis has elements which are in C R and have, at high resolutions, D vanishing moments. It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) [25, 29, 18, 16, 17]. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. <p> Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition. S is the scale of all spaces B p;q and all spaces F p;q which embed continuously in C <ref> [0; 1] </ref>, so that &gt; 1=p, and for which the wavelet basis is an unconditional basis, so that &lt; min (R; D). We now give a precise result concerning [Smooth]. <p> Theorem 1.1 (Smoothing) Let ( ^ f fl n (t i )) n1 i=0 be the vector of estimated function values produced by the algorithm (1)-(3). There exists a special smooth interpolation of these values producing a function ^ f fl n (t) on <ref> [0; 1] </ref>. This func tion is, with probability tending to 1, at least as smooth as f , in the following sense. <p> There are universal constants ( n ) with n ! 1 as n = 2 j 1 ! 1, and constants C 1 (F; ) depending on the function space F <ref> [0; 1] </ref> 2 S and on the wavelet basis, but not on n or f , so that P rob k ^ f fl o In words, ^ f fl n is, with overwhelming probability, simultaneously as smooth as f in every smoothness space F taken from the scale S. <p> Property (1.4) is a strong way of saying that the reconstruction is noise-free. Indeed, as k0k F = 0, the theorem requires that if f is the zero function f (t) 0 8t 2 <ref> [0; 1] </ref> then, with probability at least n , ^ f fl n is also the zero function . <p> We now consider phenomenon [Adapt]. In general the error Ek ^ f f k 2 ` 2 n depends on f . It is traditional to summarize this by considering its maximum over various smoothness classes. Let F <ref> [0; 1] </ref> be a function space (for example one of the Triebel or Besov spaces) and let F C denote the ball of functions ff : kf k F Cg. <p> 1 , j 1 &gt; j 0 , f2F C n f k 2 ^ f F C ` 2 n : (1.7) In words, ^ f fl n is simultaneously within a logarithmic factor of minimax over every Besov, Holder, Sobolev, and Triebel class that is contained in C <ref> [0; 1] </ref> and satisfies 1 p &lt; &lt; min (R; D). No currently known approach to adaptive smoothing (besides wavelet thresholding) is able to give anything nearly as successful, in terms of being nearly minimax over such a wide range of smoothness classes. <p> Thus we will want ultimately to interpret <ref> [1] </ref> ( I ) as the empirical wavelet coefficients of (f (t i )) n1 i=0 ; [2] ( ^ I ) as the empirical wavelet coefficients of an estimate ^ f n [3] (2.2) as a norm equivalent to n 1 P E ( ^ f (t i ) f <p> First, recall the pyramid filtering algorithm for obtaining theoretical wavelet coefficients of functions in L 2 <ref> [0; 1] </ref>, as described in [CDJV]. <p> For each n = 2 j 1 there exists a system of functions ( ~' j 0 ;k ), ( ~ j;k ), 0 k &lt; 2 j , j j 0 with the following character. (1) Every function f 2 C <ref> [0; 1] </ref> has an expansion f ~ k=0 X 2 j 1 X ~ff j;k ~ j;k : The expansion is conditionally convergent over C [0; 1] (i.e. we have a Schauder basis of C [0; 1]). The expansion is unconditionally convergent over various spaces contained in C [0; 1], such <p> ;k ), ( ~ j;k ), 0 k &lt; 2 j , j j 0 with the following character. (1) Every function f 2 C <ref> [0; 1] </ref> has an expansion f ~ k=0 X 2 j 1 X ~ff j;k ~ j;k : The expansion is conditionally convergent over C [0; 1] (i.e. we have a Schauder basis of C [0; 1]). The expansion is unconditionally convergent over various spaces contained in C [0; 1], such as C ff [0; 1] (see (5)). (2) The first n coefficients (n) = result from the pre-conditioned pyramid algorithm U j 1 ;j 0 <p> j , j j 0 with the following character. (1) Every function f 2 C <ref> [0; 1] </ref> has an expansion f ~ k=0 X 2 j 1 X ~ff j;k ~ j;k : The expansion is conditionally convergent over C [0; 1] (i.e. we have a Schauder basis of C [0; 1]). The expansion is unconditionally convergent over various spaces contained in C [0; 1], such as C ff [0; 1] (see (5)). (2) The first n coefficients (n) = result from the pre-conditioned pyramid algorithm U j 1 ;j 0 ffi P D applied to the samples b j;k = <p> 2 C <ref> [0; 1] </ref> has an expansion f ~ k=0 X 2 j 1 X ~ff j;k ~ j;k : The expansion is conditionally convergent over C [0; 1] (i.e. we have a Schauder basis of C [0; 1]). The expansion is unconditionally convergent over various spaces contained in C [0; 1], such as C ff [0; 1] (see (5)). (2) The first n coefficients (n) = result from the pre-conditioned pyramid algorithm U j 1 ;j 0 ffi P D applied to the samples b j;k = n 1=2 f (k=n). (3) The basis functions ~' j 0 ;k ~ <p> expansion f ~ k=0 X 2 j 1 X ~ff j;k ~ j;k : The expansion is conditionally convergent over C <ref> [0; 1] </ref> (i.e. we have a Schauder basis of C [0; 1]). The expansion is unconditionally convergent over various spaces contained in C [0; 1], such as C ff [0; 1] (see (5)). (2) The first n coefficients (n) = result from the pre-conditioned pyramid algorithm U j 1 ;j 0 ffi P D applied to the samples b j;k = n 1=2 f (k=n). (3) The basis functions ~' j 0 ;k ~ j;k are C R functions of <p> n1 k=0 f (k=n)g (k=n), and kf gk n the corresponding seminorm, fl 0 k (n) k ` 2 n kf k n fl 1 k (n) k ` 2 n ; the constants of equivalence do not depend on n or f . (5) Each Besov space B p;q <ref> [0; 1] </ref> with 1=p &lt; &lt; min (R; D) and 0 &lt; p; q 1 is characterized by the coefficients in the sense that k ~ k b p;q k ( ~ fi j 0 ;k ) k k ` p + ( jj 0 X j ~ff j;k j p <p> the coefficients in the sense that k ~ k b p;q k ( ~ fi j 0 ;k ) k k ` p + ( jj 0 X j ~ff j;k j p ) 1=p ) q ) 1=q ; is an equivalent norm to the norm of B p;q <ref> [0; 1] </ref> if s = + 1=2 1=p, with constants of equivalence that do not depend on n, but which may depend on p; q, j 0 and the wavelet basis. <p> Given ~ (n) which is elementwise smaller than (n) , construct a function on <ref> [0; 1] </ref> by zero extension and inversion of the transform: ~ f n = W 1 In words ~ f n is that object whose first n coefficients agree with ~ (n) , and all other coefficients are zero. <p> Theorem 7.1 Let F 2 S be a Besov space B p;q <ref> [0; 1] </ref> or a Triebel space F p;q [0; 1] and let r = (2)=(2 + 1). <p> Theorem 7.1 Let F 2 S be a Besov space B p;q <ref> [0; 1] </ref> or a Triebel space F p;q [0; 1] and let r = (2)=(2 + 1). <p> of f : f = W 1 the sense in which equality holds depending on D. (In the article so far, we have considered the above framework with point sampling on the interval of continuous functions, so that S n f = (f (k=n)= p k=0 and D = C <ref> [0; 1] </ref>. S is the segment of the Besov and Triebel scales belong to C [0; 1]. Further below we will mention somewhat different examples.) To turn these abstract ingredients into a result about de-noising, we need to establish three crucial facts about W n n and W n . <p> D. (In the article so far, we have considered the above framework with point sampling on the interval of continuous functions, so that S n f = (f (k=n)= p k=0 and D = C <ref> [0; 1] </ref>. S is the segment of the Besov and Triebel scales belong to C [0; 1]. Further below we will mention somewhat different examples.) To turn these abstract ingredients into a result about de-noising, we need to establish three crucial facts about W n n and W n . <p> The key identities (8.1), (8.2) and (8.3) all follow for this set-up by arguments en tirely parallel to those behind Theorem 5.1. Hence simple soft thresholding of periodic wavelet coefficients is both smoothing and nearly minimax. Data Observed in <ref> [0; 1] </ref> d . <p> The sampling operator is S n f = (Aveff jQ (i)g= p n) i2K j 1 , with domain D = L 1 <ref> [0; 1] </ref>. The 2-dimensional pyramid filtering operator U j 0 ;j 1 is again based on a tensor product scheme, which requires only the repeated application, in various directions, of the 1-d filters developed by [CDJV]. <p> For each n = 4 j 1 there exists a system of functions ( ~' j 0 ;k ), ( ~ j;k ), k 2 K j , j j 0 , - 2 f1; 2; 3g with the following character. (1) Every function f 2 L 1 <ref> [0; 1] </ref> 2 has an expansion f ~ k2K j 0 X X X ~ff j;k (-) The expansion is conditionally convergent over L 1 [0; 1] 2 (i.e. we have a Schauder basis of L 1 ). <p> k 2 K j , j j 0 , - 2 f1; 2; 3g with the following character. (1) Every function f 2 L 1 <ref> [0; 1] </ref> 2 has an expansion f ~ k2K j 0 X X X ~ff j;k (-) The expansion is conditionally convergent over L 1 [0; 1] 2 (i.e. we have a Schauder basis of L 1 ). <p> 1 Aveff jQ (k)gAvefgjQ (k)g, and kf gk n the corresponding seminorm, fl 0 k (n) k ` 2 n kf k n fl 1 k (n) k ` 2 n ; the constants of equivalence do not depend on n or f . (5) Each Besov space B p;q <ref> [0; 1] </ref> 2 with 2 (1=p 1=2) &lt; min (R; D) and 0 &lt; p; q 1 is characterized by the coefficients in the sense that kk b s p;q is an equivalent norm to the norm of B p;q [0; 1] if s = + 2 (1=2 1=p), with constants <p> n or f . (5) Each Besov space B p;q <ref> [0; 1] </ref> 2 with 2 (1=p 1=2) &lt; min (R; D) and 0 &lt; p; q 1 is characterized by the coefficients in the sense that kk b s p;q is an equivalent norm to the norm of B p;q [0; 1] if s = + 2 (1=2 1=p), with constants of equivalency that do not depend on n, but which may depend on p; q, j 0 and the wavelet basis. Parallel statements hold for Triebel-Lizorkin spaces F p;q with 2 (1=p 1=2) &lt; &lt; min (R; D). <p> There are universal constants ( n ) with n ! 1 as n = 4 j 1 ! 1, and constants C 1 (F; ) depending on the function space F <ref> [0; 1] </ref> 2 S and on the wavelet basis, but not on n or f , so that P rob k ^ f fl o In words, ^ f fl n is simultaneously as smooth as f for every Besov, Holder, Sobolev, and Triebel smoothness measure in a broad scale.
Reference: [2] <author> Cohen, A., Daubechies, I., Feauveau, </author> <title> J.C. (1990) Biorthogonal Bases of Compactly supported wavelets. </title> <journal> Commun. Pure and Applied Math., </journal> <note> to appear. 33 </note>
Reference-contexts: Thus we will want ultimately to interpret [1] ( I ) as the empirical wavelet coefficients of (f (t i )) n1 i=0 ; <ref> [2] </ref> ( ^ I ) as the empirical wavelet coefficients of an estimate ^ f n [3] (2.2) as a norm equivalent to n 1 P E ( ^ f (t i ) f (t i )) 2 ; and [4] (2.3) as a condition guaranteeing that ^ f is smoother
Reference: [3] <author> Cohen, A., Daubechies, I., Jawerth, B., and Vial, P. </author> <year> (1992). </year> <title> Multireso--lution analysis, wavelets, and fast algorithms on an interval. </title> <note> To appear, </note> <institution> Comptes Rendus Acad. Sci. Paris (A). </institution>
Reference-contexts: Thus we will want ultimately to interpret [1] ( I ) as the empirical wavelet coefficients of (f (t i )) n1 i=0 ; [2] ( ^ I ) as the empirical wavelet coefficients of an estimate ^ f n <ref> [3] </ref> (2.2) as a norm equivalent to n 1 P E ( ^ f (t i ) f (t i )) 2 ; and [4] (2.3) as a condition guaranteeing that ^ f is smoother than f .
Reference: [4] <author> Donoho, </author> <title> D.L. (1989) Statistical Estimation and Optimal recovery. </title> <note> To appear, Annals of Statistics. </note>
Reference-contexts: wavelet coefficients of (f (t i )) n1 i=0 ; [2] ( ^ I ) as the empirical wavelet coefficients of an estimate ^ f n [3] (2.2) as a norm equivalent to n 1 P E ( ^ f (t i ) f (t i )) 2 ; and <ref> [4] </ref> (2.3) as a condition guaranteeing that ^ f is smoother than f . We will explain such identifications further in sections 5-6 below. 3 Soft Thresholding and Optimal Recovery Before tackling (2.1)-(2.3), we consider a simpler abstract model, in which noise is deterministic (Compare [31, 41]).
Reference: [5] <author> Donoho, </author> <title> D.L. (1991) Asymptotic minimax risk for sup norm loss; solution via optimal recovery. To appear, Probability Theory and Related Fields. </title>
Reference-contexts: By Theorem 5.1, part <ref> [5] </ref> k ^ f fl n k B p;q is equivalent to the sequence-space norm kE n ^ (n) k b p;q , with constants of equivalence which do not depend on n; similarly for kf k B p;q and kk b p;q .
Reference: [6] <author> Donoho, </author> <title> D.L. (1992a) Nonlinear solution of linear inverse problems via Wavelet-Vaguelette Decomposition. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference: [7] <author> Donoho, </author> <title> D.L. (1992b) Interpolating Wavelet Transforms. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference: [8] <author> Donoho, </author> <title> D.L. (1992c) Smooth wavelet decompositions with blocky coefficient kernels. </title> <type> Manuscript. </type>
Reference: [9] <author> Donoho, </author> <title> D.L. (1992d) Unconditional bases are optimal bases for data compression and for statistical estimation. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference-contexts: This paper therefore gives strong theoretical support to the empirical claims for wavelet De-Noising cited in the first paragraph. Moreover, the theoretical advantages are really due to the wavelet basis. No similarly broad adaptivity is possible by using thresholding or other nonlinearities in the Fourier basis <ref> [9] </ref>. Hence we have a success story for wavelets. The paper to follow proves the above results by an abstract approach in sections 2-6 below.
Reference: [10] <author> Donoho, D.L. & Johnstone, I.M. </author> <year> (1992a). </year> <title> Ideal spatial adaptation via wavelet shrinkage. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference: [11] <author> Donoho, D.L. & Johnstone, I.M. </author> <year> (1992b). </year> <title> New minimax theorems, thresholding, and adaptation. </title> <type> Manuscript. </type>
Reference: [12] <author> Donoho, D.L. & Johnstone, I.M. </author> <year> (1992c). </year> <title> Minimax estimation by wavelet shrinkage. </title> <type> Technical Report, </type> <institution> Department of Statistics, Stanford University. </institution>
Reference-contexts: based on F C are asymptotically minimax [36, 35]; over certain Holder balls, Kernel methods with appropriate bandwidth, chosen with knowledge of F C are nearly minimax [40]; and it is known that no such linear methods can be nearly minimax over certain L p Sobolev balls, p &lt; 2 <ref> [33, 12] </ref>. However, nonlinear methods, such as the nonparametric method of maximum likelihood, are able to behave in a near-minimax way for L p Sobolev balls [32, 19], but they require solution of a general n-dimensional nonlinear programming problem in general.
Reference: [13] <author> Donoho, D.L. & Johnstone, I.M. </author> <year> (1992d). </year> <title> Adapting to unknown smoothness by wavelet shrinkage. </title>
Reference: [14] <author> Donoho, D.L., Liu, R. and MacGibbon, K.B. </author> <year> (1990). </year> <title> Minimax risk over hyperrectangles, and implications. </title> <journal> Ann. Statist. </journal> <volume> 18, </volume> <pages> 1416-1437. 34 </pages>
Reference: [15] <author> Efroimovich, S. Yu. and Pinsker, </author> <title> M.S. (1984) A learning algorithm for nonparametric filtering. </title> <journal> Automat. </journal> <note> i Telemeh. 11 58-65 (in Russian). </note>
Reference-contexts: Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically <ref> [15, 20, 34] </ref>. Unfortunately, such methods, based ultimately on linear procedures, are not able to attain near-minimax behavior over L p Sobolev balls; they exceed the minimax risk by factors growing like n ffi (;p) , where ffi (; p) &gt; 0 whenever p &lt; 2 ([DJ92d]).
Reference: [16] <author> Frazier, M. and Jawerth, B. </author> <year> (1985). </year> <title> Decomposition of Besov spaces. </title> <journal> Indiana Univ. Math. J., </journal> <pages> 777-799. </pages>
Reference-contexts: It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) <ref> [25, 29, 18, 16, 17] </ref>. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition.
Reference: [17] <author> M. Frazier and B. </author> <title> Jawerth (1990) A discrete Transform and Decomposition of Distribution Spaces. </title> <journal> Journal of Functional Analysis 93 34-170. </journal>
Reference-contexts: It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) <ref> [25, 29, 18, 16, 17] </ref>. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition.
Reference: [18] <author> M. Frazier, B. Jawerth, and G. </author> <title> Weiss (1991) Littlewood-Paley Theory and the study of function spaces. </title> <booktitle> NSF-CBMS Regional Conf. Ser in Mathematics, </booktitle> <volume> 79. </volume> <publisher> American Math. Soc.: </publisher> <address> Providence, RI. </address>
Reference-contexts: It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) <ref> [25, 29, 18, 16, 17] </ref>. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition.
Reference: [19] <author> Van de Geer, S. </author> <title> (1988) A new approach to least-squares estimation, with applications. </title> <journal> Annals of Statistics 15, </journal> <pages> 587-602. </pages>
Reference-contexts: However, nonlinear methods, such as the nonparametric method of maximum likelihood, are able to behave in a near-minimax way for L p Sobolev balls <ref> [32, 19] </ref>, but they require solution of a general n-dimensional nonlinear programming problem in general. For general Besov or Triebel balls, wavelet shrinkage estimators which are nearly minimax may be constructed using thresholding of wavelet coefficients with resolution level-dependent thresholds [DJ92c].
Reference: [20] <author> Golubev, G.K. </author> <title> (1987) Adaptive asymptotically minimax estimates of smooth signals. </title> <type> Problemy Peredatsii Informatsii 23 57-67. </type>
Reference-contexts: Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically <ref> [15, 20, 34] </ref>. Unfortunately, such methods, based ultimately on linear procedures, are not able to attain near-minimax behavior over L p Sobolev balls; they exceed the minimax risk by factors growing like n ffi (;p) , where ffi (; p) &gt; 0 whenever p &lt; 2 ([DJ92d]).
Reference: [21] <author> Leadbetter, M. R., Lindgren, G., Rootzen, </author> <title> Holger (1983) Extremes and Related Properties of Random Sequences and Processes. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: If strict inequality never holds, then by (3.20)-(3.21), ^ I (y) = ^ I (ffi) I.e. ^ = ^ (ffi) . 2. 4 Thresholding and Statistical Estimation We now return to the random-noise abstract model (2.1)-(2.3). We will use the following fact <ref> [21] </ref>: Let (z I ) be i.i.d. N (0; 1).
Reference: [22] <author> Johnstone, I.M. and Hall, P.G. </author> <title> (1992) Empirical functionals and efficient smoothing parameter selection. </title> <journal> J. Roy. Stat. Soc. B, </journal> <note> 54, to appear. </note>
Reference-contexts: In all the results about individual balls, the exact fashion in which kernels, bandwidths, spline penalizations, nonlinear programs, thresholds etc. depend on the assumed function space ball F C is rather complicated. There exists a literature in which these parameters are adjusted based on principles like cross-validation <ref> [42, 43, 22, 26] </ref>. Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically [15, 20, 34].
Reference: [23] <author> Johnstone, I.M., Kerkyacharian, G. and Picard, D. </author> <title> (1992) Estimation d'une densite de probabilite par methode d'ondelettes. </title> <note> To appear Comptes Rendus Acad. Sciences Paris (A). </note>
Reference-contexts: There are many parallels with regression estimation. See <ref> [24, 23] </ref>.
Reference: [24] <author> Kerkyacharian, G. and Picard, D. </author> <title> (1992) Density estimation in Besov Spaces. </title> <journal> Statistics and Probability Letters 13 15-24 </journal>
Reference-contexts: There are many parallels with regression estimation. See <ref> [24, 23] </ref>.
Reference: [25] <author> Lemarie, P.G. and Meyer, Y. </author> <title> (1986) Ondelettes et bases Hilbertiennes. </title> <journal> Revista Mathematica Ibero-Americana. </journal> <volume> 2, </volume> <pages> 1-18. </pages>
Reference-contexts: It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) <ref> [25, 29, 18, 16, 17] </ref>. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition.
Reference: [26] <author> Li, K.C. </author> <title> (1985) From Stein's unbiased risk estimates to the method of generalized cross validation. </title> <journal> Ann. Statist. </journal> <volume> 13 1352-1377. </volume> <pages> 35 </pages>
Reference-contexts: In all the results about individual balls, the exact fashion in which kernels, bandwidths, spline penalizations, nonlinear programs, thresholds etc. depend on the assumed function space ball F C is rather complicated. There exists a literature in which these parameters are adjusted based on principles like cross-validation <ref> [42, 43, 22, 26] </ref>. Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically [15, 20, 34].
Reference: [27] <author> Jian Lu, Yansun Xu, John B. Weaver, and Dennis M. Healy, Jr. </author> <title> (1992) Noise reductin by constrained reconstructions in the wavelet-transform domain. </title> <institution> Department of Mathematics, Dartmouth University. </institution>
Reference: [28] <author> Mallat, S. & Hwang, W.L. </author> <title> (1992) Singularity detection and processing with wavelets. </title> <journal> IEEE Trans. Info Theory. </journal> <volume> 38,2, </volume> <pages> 617-643. </pages>
Reference: [29] <author> Meyer, Y. </author> <year> (1990). </year> <title> Ondelettes et operateurs I: Ondelettes. </title> <publisher> Hermann, </publisher> <address> Paris. </address>
Reference-contexts: It acts as an unconditional basis for a very wide range of smoothness spaces: all the Besov classes B p;q [0; 1] and Triebel classes F p;q [0; 1] in a certain range 0 &lt; &lt; min (R; D) <ref> [25, 29, 18, 16, 17] </ref>. Each of these classes has a norm k k B p;q or k k F p;q which measures smoothness. Special cases include the traditional Holder (-Zygmund) classes C = B 1;1 and Sobolev Classes W p = F Definition.
Reference: [30] <author> Meyer, Y. </author> <note> (1991) Ondelettes sur l'intervalle. Revista Mat. Ibero-Americana. </note>
Reference: [31] <author> Micchelli, C. and Rivlin, T. J. </author> <year> (1977). </year> <title> A survey of optimal recovery. In Optimal Estimation in Approximation Theory (Micchelli and Rivlin, </title> <booktitle> eds.), </booktitle> <pages> pp. 1-54, </pages> <publisher> Plenum, </publisher> <address> NY. </address>
Reference-contexts: We will explain such identifications further in sections 5-6 below. 3 Soft Thresholding and Optimal Recovery Before tackling (2.1)-(2.3), we consider a simpler abstract model, in which noise is deterministic (Compare <ref> [31, 41] </ref>).
Reference: [32] <author> Nemirovskii, </author> <title> A.S. (1985) Nonparametric estimation of smooth regression functions. </title> <journal> Izv. Akad. Nauk. SSR Teckhn. Kibernet. 3, 50-60 (in Russian). J. Comput. Syst. Sci. </journal> <volume> 23, 6, </volume> <pages> 1-11, </pages> <note> (1986) (in English). </note>
Reference-contexts: However, nonlinear methods, such as the nonparametric method of maximum likelihood, are able to behave in a near-minimax way for L p Sobolev balls <ref> [32, 19] </ref>, but they require solution of a general n-dimensional nonlinear programming problem in general. For general Besov or Triebel balls, wavelet shrinkage estimators which are nearly minimax may be constructed using thresholding of wavelet coefficients with resolution level-dependent thresholds [DJ92c].
Reference: [33] <author> Nemirovskii, </author> <title> A.S., Polyak, B.T. and Tsybakov, A.B. (1985) Rate of convergence of nonparametric estimates of maximum-likelihood type. </title> <booktitle> Problems of Information Transmission 21, </booktitle> <pages> 258-272. </pages>
Reference-contexts: based on F C are asymptotically minimax [36, 35]; over certain Holder balls, Kernel methods with appropriate bandwidth, chosen with knowledge of F C are nearly minimax [40]; and it is known that no such linear methods can be nearly minimax over certain L p Sobolev balls, p &lt; 2 <ref> [33, 12] </ref>. However, nonlinear methods, such as the nonparametric method of maximum likelihood, are able to behave in a near-minimax way for L p Sobolev balls [32, 19], but they require solution of a general n-dimensional nonlinear programming problem in general.
Reference: [34] <author> Nemirovskii, </author> <title> A.S. </title> <type> (1991) Manuscript, </type> <institution> Mathematical Sciences Research Institute, Berkeley, </institution> <address> CA. </address>
Reference-contexts: Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically <ref> [15, 20, 34] </ref>. Unfortunately, such methods, based ultimately on linear procedures, are not able to attain near-minimax behavior over L p Sobolev balls; they exceed the minimax risk by factors growing like n ffi (;p) , where ffi (; p) &gt; 0 whenever p &lt; 2 ([DJ92d]).
Reference: [35] <author> Nussbaum, M. </author> <year> (1985). </year> <title> Spline smoothing in regression models and asymptotic efficiency in L 2 . Annals of Statistics 13, </title> <type> 984-997. </type>
Reference-contexts: If all that we care about is attaining the minimax bound for a single specific ball F C , a great deal is known. For example, over certain L 2 Sobolev balls, special spline smoothers, with appropriate smoothness penalty terms chosen based on F C are asymptotically minimax <ref> [36, 35] </ref>; over certain Holder balls, Kernel methods with appropriate bandwidth, chosen with knowledge of F C are nearly minimax [40]; and it is known that no such linear methods can be nearly minimax over certain L p Sobolev balls, p &lt; 2 [33, 12].
Reference: [36] <author> Pinsker, </author> <title> M.S. (1980) Optimal filtering of square integrable signals in Gaussian white noise. </title> <note> Problemy Peredatsii Informatsii 16 52-68 (in Rus-sian); Problems of Information Transmission (1980) 120-133 (in English). </note>
Reference-contexts: If all that we care about is attaining the minimax bound for a single specific ball F C , a great deal is known. For example, over certain L 2 Sobolev balls, special spline smoothers, with appropriate smoothness penalty terms chosen based on F C are asymptotically minimax <ref> [36, 35] </ref>; over certain Holder balls, Kernel methods with appropriate bandwidth, chosen with knowledge of F C are nearly minimax [40]; and it is known that no such linear methods can be nearly minimax over certain L p Sobolev balls, p &lt; 2 [33, 12].
Reference: [37] <author> Simoncelli, E.P., W.T. Freeman, </author> <title> E.H. Adelson, and D.J. Heeger. Shiftable multiscale transforms. </title> <journal> IEEE Trans. Info. Theory 38, </journal> <volume> 2, </volume> <pages> 587-607. </pages>
Reference: [38] <author> Silverman, B.W. </author> <title> (1983) Some properties of a test for multimodality based on kernel density estimation. in Probability, Statistics, and Analysis, J.F.C. </title> <editor> Kingman and G.E.H. Reuter, eds. </editor> <publisher> Cambridge: Cambridge Univ. Press. </publisher>
Reference: [39] <author> Stark, P.B. </author> <title> (1992) The Core Mantle Boundary and the Cosmic Microwave Background: a tale of two CMB's. </title> <type> Technical Report, </type> <institution> Department of Statistics, University of California, Berkeley. </institution>
Reference: [40] <author> Stone, C. </author> <year> (1982). </year> <title> Optimal global rates of convergence for nonparametric estimators. </title> <journal> Ann. Statist. </journal> <volume> 10, </volume> <pages> 1040-1053. </pages>
Reference-contexts: For example, over certain L 2 Sobolev balls, special spline smoothers, with appropriate smoothness penalty terms chosen based on F C are asymptotically minimax [36, 35]; over certain Holder balls, Kernel methods with appropriate bandwidth, chosen with knowledge of F C are nearly minimax <ref> [40] </ref>; and it is known that no such linear methods can be nearly minimax over certain L p Sobolev balls, p &lt; 2 [33, 12].
Reference: [41] <author> Traub, J., Wasilkowski, G. </author> <title> and Wozniakowski (1988). Information-Based Complexity. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: We will explain such identifications further in sections 5-6 below. 3 Soft Thresholding and Optimal Recovery Before tackling (2.1)-(2.3), we consider a simpler abstract model, in which noise is deterministic (Compare <ref> [31, 41] </ref>).
Reference: [42] <author> Wahba, G. and Wold, S. </author> <title> (1975) A completely Automatic French Curve. </title> <journal> Commun. Statist. </journal> <pages> 4 pp. 1-17. </pages>
Reference-contexts: In all the results about individual balls, the exact fashion in which kernels, bandwidths, spline penalizations, nonlinear programs, thresholds etc. depend on the assumed function space ball F C is rather complicated. There exists a literature in which these parameters are adjusted based on principles like cross-validation <ref> [42, 43, 22, 26] </ref>. Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically [15, 20, 34].
Reference: [43] <author> Wahba, G. </author> <title> (1990) Spline Methods for Observational Data. </title> <publisher> SIAM: </publisher> <address> Philadelphia. </address> <month> 37 </month>
Reference-contexts: In all the results about individual balls, the exact fashion in which kernels, bandwidths, spline penalizations, nonlinear programs, thresholds etc. depend on the assumed function space ball F C is rather complicated. There exists a literature in which these parameters are adjusted based on principles like cross-validation <ref> [42, 43, 22, 26] </ref>. Such adjustment allows to attain near-minimax behavior across restricted scales of functions. For example, special orthogonal series procedures with adaptively chosen windows attain minimax behavior over a scale of L 2 Sobolev balls automatically [15, 20, 34].
References-found: 43

