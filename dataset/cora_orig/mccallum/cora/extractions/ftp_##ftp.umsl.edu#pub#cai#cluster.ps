URL: ftp://ftp.umsl.edu/pub/cai/cluster.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Cluster Algorithms for Spatial Point Processes with Symmetric and Shift Invariant Interactions  
Author: Haiyan Cai 
Keyword: Key Worlds and Phrases: spatial point process, cluster algorithm, Monte Carlo simulations, convergence of Markov chain.  
Date: March 27, 1998  
Address: St. Louis St. Louis, MO 63121, USA  
Affiliation: Mathematics and Computer Science Department University of Missouri  
Abstract: In this paper, Swendsen-Wang-Wolff algorithms are extended to simulate spatial point processes with symmetric and stationary interactions. Our algorithms are faster in simulating strongly correlated processes. Convergence of these algorithms are considered. Some further generalizations of the algorithms are discussed. The ideas presented in this paper can also be useful in handling some large and complicated systems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gilks, Richardson and Spiegelhalter: </author> <title> Markov Chain Monte Carlo in Practice, </title> <publisher> Chapman & Hall, </publisher> <year> 1996. </year>
Reference-contexts: We then build a cluster inductively starting from x i 0 . Any point x j in x should be in the cluster if there is a point x i in the cluster and an independent uniform random variable U i;j from the interval <ref> [0; 1] </ref> such that minfh (jx i x j j); h (jx i (a x j )j)g h (jx i x j j) Once the cluster C is identified, we update x C by a x C and leave other points in x unchanged.
Reference: [2] <author> Hastings, </author> <title> W.K., Monte Carlo sampling methods using Markov chains and their applications, </title> <journal> Biometrika, </journal> <volume> 57, </volume> <month> 97-109 </month> <year> (1970). </year>
Reference: [3] <author> Ripley, </author> <title> B.D.: Modeling spatial patterns, </title> <journal> J. R. Statist. Soc. B, </journal> <volume> 39. </volume> <month> 172-212 </month> <year> (1977). </year>
Reference: [4] <author> Ripley, </author> <title> B.D.: Algorithm AS137. Simulating spatial patterns: dependent samples from a multivariate density, </title> <journal> Applied Statistics, </journal> <volume> 28, </volume> <month> 109-112 </month> <year> (1979) </year>
Reference-contexts: These were observed when we tried to compare the one-cluster algorithms to the Gibbs sampler first proposed by Ripley in <ref> [4] </ref>. Figure 1 presents a sample of the process obtained from iterations of the one-cluster algorithm. There are n = 400 points in the unit square. We set R = 1= n and = 0:8. The number of iterations is 400. <p> We set R = 1= n and = 0:8. The number of iterations is 400. The average cluster size in these 400 iterations is 19.145. In this example it shows that one-cluster algorithm is many times faster than the Gibbs sampler given in <ref> [4] </ref>. When R is fixed at 1= p n and varies, a pattern emerges from simulations which suggests some kind of critical phenomenon. It is observed that as decreases, it gets harder and harder to break the points into smaller clusters.
Reference: [5] <author> Ripley, </author> <title> B.D.: Statistical Inference for Spatial Processes Cambridge University Press (1988). </title>
Reference: [6] <author> Sokal, </author> <title> A.D.: How to beat critical slowing-down: 1990 update, </title> <journal> Nuclear Phys. B (Proc. </journal> <volume> Suppl.), 20, </volume> <month> 55-67 </month> <year> (1991). </year>
Reference-contexts: introduction of the cluster algorithms (see <ref> [6] </ref>). The cluster algorithms have shown impressive performance in tackling the critical slowing down problems. In this paper we will follow the ideas of SWW to construct similar algorithms for spatial point processes. The algorithms consist of iterations of two major steps. <p> transition probability of the multi-cluster algorithm, it is convenient to introduce a family of 0-1 valued random variables b = fb i;j ; i; j 2 N g such that b i;j = 1 if and only if x i and x j are linked in the earlier construction (see <ref> [6] </ref>). Therefore P (b i;j = 0) = h (jx i x j j) h fl We now can identify the clusters C = fx C 1 ; :::; x C M (b) g through b. Suppose the transition kernel of the Markov chain is P x (dy).
Reference: [7] <author> Swendsen, R.H. and J.S. Wang: </author> <title> Nonuniversal critical dynamics in Monte Carlo simulations, </title> <journal> Phys. Rev. Lett. </journal> <volume> 58, </volume> <month> 86-88 </month> <year> (1987). </year>
Reference: [8] <author> J.S. Wang and R.H. Swendsen: </author> <title> Cluster Monte Carlo algorithms, </title> <journal> Physica A, </journal> <volume> 167, </volume> <month> 565-579 </month> <year> (1990). </year>
Reference: [9] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller and E. Teller: </author> <title> Equations of state calculations by fast computing machines, </title> <journal> Chemical Physics, </journal> <volume> 21, </volume> <month> 1087-1091 </month> <year> (1953). </year>
Reference: [10] <author> U. Wolff: </author> <title> Collective Monte Carlo updating for spin systems, </title> <journal> Phys. Rev. Lett, </journal> <volume> 62, </volume> <month> 361-364 </month> <year> (1989). </year>
Reference: [11] <author> U. Wolff: </author> <title> Comparison between cluster Monte Carlo algorithms in the Ising model, </title> <journal> Physics Letters B, </journal> <volume> 228, </volume> <month> 379-382 </month> <year> (1989). </year> <month> 18 </month>
References-found: 11

