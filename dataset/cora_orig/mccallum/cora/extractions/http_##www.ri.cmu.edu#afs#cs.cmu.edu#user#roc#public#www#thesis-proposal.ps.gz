URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/roc/public/www/thesis-proposal.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/roc/public/www/index.html
Root-URL: 
Title: Scalable Program Analysis and Understanding Based on Type Inference  
Author: Robert OCallahan Daniel Jackson (CMU/MIT) Jeannette Wing (CMU) Frank Pfenning (CMU) Craig Chambers (UW) 
Degree: Thesis Proposal Thesis Committee:  
Abstract: Previous work has shown that techniques based on type inference over enriched type systems can lead to scalable, contextsensitive solutions to whole-program analysis problems, such as alias analysis, binding time analysis, higher-order control flow analysis and approximate dataflow for program understanding [S96, OJ97, TT94]. However, many questions remain open. Work to date has addressed procedural languages such as C or ML, and it is unclear how best to extend the analyses to efficiently handle large object oriented programs. The goal of my thesis is to exhibit one solution to this problem, analyze its performance on realistic programs and analysis tasks, and formally justify the soundness of the results (for a simplified intermediate language). 
Abstract-found: 1
Intro-found: 1
Reference: [A95] <author> O. Agesen. </author> <title> The Cartesian Product Algorithm: Simple and precise type inference of parametric polymorphism. </title> <booktitle> Proceedings of the European Conference on Object Oriented Programming, </booktitle> <year> 1995. </year>
Reference-contexts: Closure Analyses for Object Oriented Programs Grove, Dean, DeFouw and Chambers [GDDC97] survey a number of algorithms for call graph construction for object oriented languages. The algorithms studied include those of Palsberg and Schwartzbach [PS91], Oxhj, Palsberg and Schwartzbach [OPS92], and Agesen <ref> [A95] </ref>. The call graph construction problem is essentially the same as closure analysis: identify the possible targets of an indirect function (or procedure, or method) invocation. They conclude our experiments demonstrated that scalability problems prevent the flowsensitive algorithms from being applied beyond the domain of small benchmark [Cecil] programs.
Reference: [A96] <author> J. Ashley. </author> <title> A practical and flexible flow analysis for higher-order languages. </title> <booktitle> Proceedings of the 23 rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: The Tagged Semantics Flow analyses are often derived as abstractions of instrumented semantics that associate labels with values <ref> [A96, JW95, S88, and lots of others] </ref>. Often, a value is tagged with a label indicating the program point at which it was created. However, it is frequently useful to be able to distinguish between multiple values arising from the same program point. <p> Jagannathan and Weeks [JW95] introduce a framework that encompasses set-based analysis and CFA algorithms. Its simplest instantiation is equivalent to 0CFA and set-based analysis, establishing the equivalence of those two methods. Ashley <ref> [A96] </ref> gives another framework, potentially more general but in practice instantiated to just 0CFA and a simplified version of 0CFA.
Reference: [AW93] <author> A. Aiken and E. Wimmers. </author> <title> Type inclusion constraints and type inference. </title> <booktitle> Proceedings of the International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <year> 1993. </year>
Reference: [BG94] <author> R. Bowdidge and W. Griswold. </author> <title> Automated support for encapsulating abstract data types. </title> <booktitle> Proceedings of the ACM SIGSOFT Conference On Foundations of Software Engineering, </booktitle> <month> December </month> <year> 1994. </year>
Reference-contexts: RMT is independent of the tool used to analyze the source code, and my tools could be used in that role. Bowdidge and Griswolds star diagram tool <ref> [BG94] </ref> aids in encapsulating abstract data types, by presenting a special view of the program that focuses on a particular variable. They assume that there is a single global variable to be abstracted, but they discuss extending their method to operate on data structures with multiple instances.
Reference: [BJ93] <author> A. Bondorf and J. Jrgensen. </author> <title> Efficient analyses for realistic offline partial evaluation. </title> <journal> Journal of Functional Programming, </journal> <volume> Volume 3, Number 3, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: There are no empirical results, and polymorphic type systems are not treated. The type system obtained is very similar to that used for binding time analysis by Bondorf and Jrgensen <ref> [BJ93] </ref>. The analysis is more powerful than Steensgaards, but less powerful than Wright and Cartwrights (and Lackwits). Rmy and Vouillon [RV97] describe the type system of Objective Caml, which provides type inference for an objectoriented extension of ML, without the use of subtype constraints.
Reference: [BS96] <author> D. Bacon and P. Sweeney. </author> <title> Fast static analysis of C++ virtual function calls. </title> <booktitle> Proceedings of the ACM SIGPLAN '96 Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <month> October </month> <year> 1996. </year>
Reference: [CNR90] <author> Y.-F. Chen, M. Nishimoto, and C. Ramamoorthy. </author> <title> The C Information Abstraction System. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> March </month> <year> 1990. </year>
Reference-contexts: My analysis provides an answer to this problem. The C Information Abstraction system <ref> [CNR90] </ref>, and its successors and many other similar systems, essentially treat a program as an abstract syntax tree without assigning meaning to the syntax elements. In CIA, this information is imported into a database, and various relational queries can then be used to extract useful information.
Reference: [DGC95] <author> J. Dean, D. Grove, and C. Chambers. </author> <title> Optimization of objectoriented programs using static class hierarchy analysis. </title> <booktitle> Proceedings of the 9 th European Conference on ObjectOriented Programming ECOOP 95, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: declared for the object reference in a method call; the runtime class of the object must be a subclass of the declared class, and so the possible targets of the dispatch are the method in the declared class (if there is one), and any overriding method declarations in those subclasses <ref> [F95, DGC95; both cited in BS96] </ref>. Diwan, Moss and McKinley [DMM96] extend this basic method with intraprocedural flow analysis and some very simpleminded (context insensitive) interprocedural propagation and handling of data structures, resulting in an analysis that is still linear in practice.
Reference: [DGC98] <author> G. DeFouw, D. Grove and C. Chambers. </author> <title> Fast interprocedural class analysis. Proceedings of the 25 th Annual ACM SIGPLAN-SIGACT Implement Java analysis 3 months Prove soundness 2 months Implement compiler-oriented analyses 2 months Evaluate compiler-oriented analyses 2 months Implement software engineering tool 2 months Evaluate software engineering tool 2 months Write thesis 5 months TOTAL 18 months 33 Symposium on Principles of Programming Languages, </title> <month> January </month> <year> 1998. </year>
Reference-contexts: It will be interesting to compare these results with results for an analysis which is contextsensitive but not flowsensitive, especially for larger programs with more internal code reuse. In more recent work <ref> [DGC98] </ref>, DeFouw, Grove and Chambers consider a framework of fast algorithms ranging from linear to cubic time complexity in the size of the program. These algorithms possess, at best, only very limited contextsensitivity and/or flow-sensitivity.
Reference: [DMM96] <author> A. Diwan, J.E.B. Moss, and K. McKinley. </author> <title> Simple and effective analysis of statically-typed objectoriented programs. </title> <booktitle> Proceedings of the ACM SIGPLAN '96 Conference on ObjectOriented Programming Systems, Languages and Applications, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Diwan, Moss and McKinley <ref> [DMM96] </ref> extend this basic method with intraprocedural flow analysis and some very simpleminded (context insensitive) interprocedural propagation and handling of data structures, resulting in an analysis that is still linear in practice. Their algorithm is quite effective for their benchmarks, but the benchmarks are mostly small.
Reference: [EST95] <author> J. Eifrig, S. Smith, and V. Trifonov. </author> <title> Sound polymorphic type inference for objects. </title> <booktitle> Proceedings of the ACM SIGPLAN '95 Conference on ObjectOriented Programming Systems, Languages and Applications, </booktitle> <month> October </month> <year> 1995. </year>
Reference-contexts: Apart from the conditional types, it is similar in expressive power to set-based analysis. In a followup report [FA96], Fhndrich and Aiken discuss their efforts to make it scale up to large programs; the reported results are inferior to those of Flanagan and Felleisen. 27 Eifrig, Smith and Trifonov <ref> [EST95] </ref> give a type system almost as rich as that of Aiken et al., and apply it to a language with object oriented features (with support for state and records). There is no mention at all of any implementation or its performance.
Reference: [F95] <author> Fernandez, M. </author> <title> Simple and effective link-time optimization of Modula 3 programs. </title> <booktitle> Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1995. </year>
Reference-contexts: declared for the object reference in a method call; the runtime class of the object must be a subclass of the declared class, and so the possible targets of the dispatch are the method in the declared class (if there is one), and any overriding method declarations in those subclasses <ref> [F95, DGC95; both cited in BS96] </ref>. Diwan, Moss and McKinley [DMM96] extend this basic method with intraprocedural flow analysis and some very simpleminded (context insensitive) interprocedural propagation and handling of data structures, resulting in an analysis that is still linear in practice.
Reference: [FF97] <author> C. Flanagan and M. Felleisen. </author> <title> Componential set-based analysis. </title> <booktitle> Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1997. </year>
Reference-contexts: Equality constraints: t = u 4 The linear-time bound is lost, and some kind of constraint simplification algorithm must be used to keep reasonable performance, perhaps similar to Flanagan and Felleisens <ref> [FF97] </ref>. I have discussed this with Nevin and he acknowledges significant difficulties. 14 Component constraints: t comp u This is read as t has u as component comp. <p> Another problem with their method is that extending it with some kind of polyvariance or polymorphism could lead to serious performance problems. Heintze [H94] also introduced set-based analysis. Flanagan and Felleisen <ref> [FF97] </ref> describe an implementation of set-based analysis designed to handle large programs. It analyzes each component separately, generating a collection of set constraints that approximate the behavior of the component, then simplifying the constraints. Finally the sets of simplified constraints are combined and solved.
Reference: [GGDC97] <author> D. Grove, G. DeFouw, J. Dean and C. Chambers. </author> <title> Call graph construction in objectoriented languages. </title> <booktitle> Proceedings of the ACM SIGPLAN '97 Conference on ObjectOriented Programming Systems, Languages and Applications, </booktitle> <month> October </month> <year> 1997. </year>
Reference: [GJLS87] <author> D. Gifford, P. Jouvelot, J. Lucassen, and M. Sheldon. </author> <title> FX-87 reference manual. </title> <type> Technical Report MIT/LCS/TR-407, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: The region inference work can be traced back to previous work on effect inference. FX <ref> [GJLS87] </ref> was an early example of such a system. Talpin and Jouvelot [TJ92] describe an elegant example of such a type system. The comments in the previous paragraph also apply to the relationship between this work and mine.
Reference: [H93] <author> F. Henglein. </author> <title> Type inference with polymorphic recursion. </title> <journal> TOPLAS, </journal> <volume> Volume 15, No. 2, </volume> <year> 1993. </year>
Reference-contexts: My algorithm will use basically the same strategy as Hengleins algorithm for type inference with polymorphic recursion <ref> [H93] </ref>. This means that whenever the left-hand side of a closure rule is satisfied, the required constraint (s) on the right-hand side are added, if necessary.
Reference: [H94] <author> N. Heintze. </author> <title> Set-based analysis of ML programs. </title> <booktitle> Proceedings of the ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1994. </year>
Reference-contexts: Another problem with their method is that extending it with some kind of polyvariance or polymorphism could lead to serious performance problems. Heintze <ref> [H94] </ref> also introduced set-based analysis. Flanagan and Felleisen [FF97] describe an implementation of set-based analysis designed to handle large programs. It analyzes each component separately, generating a collection of set constraints that approximate the behavior of the component, then simplifying the constraints.
Reference: [H95] <author> N. Heintze. </author> <title> Control-flow analysis and type systems. </title> <booktitle> Proceedings of the Static Analysis Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: Wright and Cartwrights soft typing system for Scheme [WC94] handles recursive types, records, and polymorphism, but it cannot distinguish different instances of the same basic type, which is a fundamental requirement for almost all of my applications. Heintze <ref> [H95] </ref> describes extensions of the equivalence results of Palsberg and OKeefe [PO95] that, among other things, show the equivalence of unification-based type inference (i.e. without subtyping) to a simple closure analysis. There are no empirical results, and polymorphic type systems are not treated.
Reference: [HM97] <author> N. Heintze and D. McAllester. </author> <title> Linear-time subtransitive control flow analysis. </title> <booktitle> Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1997. </year>
Reference-contexts: Subtype constraints can express flow sensitive properties; in fact, Palsberg and OKeefe proved one subtyping system equivalent to a flow analysis [PO95]. Theoretically tractable algorithms for flow sensitive analysis in the presence of higher-order functions have only appeared very recently <ref> [HM97] </ref>. It seems clear that the performance of those algorithms will degrade more rapidly than the performance of the Hindley-Milner algorithm as the types of the program grow larger, as they surely will for OO programs. <p> Since then, much work has been done to improve the time and space requirements of his technique, especially when some kind of context sensitivity is required. Heintze and McAllester <ref> [HM97] </ref> describe an implementation of CFA that answers certain questions in linear time for programs that have types that are bounded in size. Unfortunately this approach cannot be directly applied to C and Java programs because its treatment of recursive types is based on ML datatypes.
Reference: [JR94] <author> D. Jackson and E. Rollins. </author> <title> Abstractions of program dependencies for reverse engineering. </title> <booktitle> Proceedings of the ACM SIGSOFT Conference On Foundations of Software Engineering, </booktitle> <month> December </month> <year> 1994. </year>
Reference-contexts: This kind of information may be useful for testing, debugging and other applications. Unfortunately, most efforts to date have failed to achieve any kind of scalability or to operate on realistic languages and programs. One of the most capable tools, Jackson and Rollins Chopshop <ref> [JR94] </ref>, was not demonstrated to work on more than 30,000 lines of code, and did not account for complex aspects of the semantics of C such as aliasing of dynamic data structures. These limitations are typical. 8.
Reference: [JW95] <author> S. Jagannathan and S. Weeks. </author> <title> A unified treatment of flow analysis in higher-order languages. </title> <booktitle> Proceedings of the 22 nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1995. </year> <month> 34 </month>
Reference-contexts: The Tagged Semantics Flow analyses are often derived as abstractions of instrumented semantics that associate labels with values <ref> [A96, JW95, S88, and lots of others] </ref>. Often, a value is tagged with a label indicating the program point at which it was created. However, it is frequently useful to be able to distinguish between multiple values arising from the same program point. <p> The improvement over the basic algorithm is very impressive, 25 but the largest program analyzed is 18,000 lines of Scheme, so it is difficult to draw conclusions about scalability, or about its behavior on object oriented programs. Jagannathan and Weeks <ref> [JW95] </ref> introduce a framework that encompasses set-based analysis and CFA algorithms. Its simplest instantiation is equivalent to 0CFA and set-based analysis, establishing the equivalence of those two methods. Ashley [A96] gives another framework, potentially more general but in practice instantiated to just 0CFA and a simplified version of 0CFA.
Reference: [K97] <author> G. Kiczales. </author> <title> Beyond the black-box: Open Implementation. </title> <journal> IEEE Software, </journal> <month> January </month> <year> 1997. </year>
Reference-contexts: The standard solution is to tear down the abstraction barriers, either in the usual undisciplined ways, which lead to software engineering disaster, or in more structured ways (for example, as advocated by the Open Implementation gurus <ref> [K97] </ref>) that nevertheless reveal implementation details and add complexity to interfaces. A possible alternative is to give components access to global implementation information by furnishing an analysis library that can answer queries about the running program at run time. This does not require any changes to interfaces and preserves abstraction.
Reference: [MN95] <author> G. Murphy and D. Notkin. </author> <title> Lightweight source model extraction. </title> <booktitle> Proceedings of the ACM SIGSOFT Conference On Foundations of Software Engineering, </booktitle> <year> 1995. </year>
Reference-contexts: Our analysis is more powerful than that incorporated in their Rigi tool, but we would certainly benefit greatly from such visualization and manipulation techniques; thus, their work is complementary to mine. Murphy and Notkin have developed some lexical analyses that are particularly efficient and easy to customize <ref> [MN95] </ref>. Due to its lexical nature, their tool can be more flexible (for example, it can analyze programs written in multiple languages), and will be more efficient in most cases. Its strength is also its weakness.
Reference: [MN95B] <author> G. Murphy and D. Notkin. </author> <title> Software reflexion models: bridging the gap between source and high-level models. </title> <booktitle> Proceedings of the ACM SIGSOFT Conference On Foundations of Software Engineering, </booktitle> <year> 1995. </year>
Reference-contexts: Its strength is also its weakness. By operating purely at the lexical level, it cannot address semantic queries with the precision or soundness of semantics-based analysis. 30 The same researchers Reflection Model Tool (RMT) <ref> [MN95B] </ref> allows the results of a static analysis to be presented at a more abstract level than the code, such as an architecture diagram, and to be compared to the expectations that the user has for that level.
Reference: [MTOCM92] <author> H. Mller, S. Tilley, M. Orgun, B. Corrie and N. Madhavji. </author> <title> A reverse engineering environment based on spatial and visual software interconnection models. </title> <booktitle> Proceedings of the Fifth ACM SIGSOFT Symposium on Software Development Environments, </booktitle> <month> December </month> <year> 1992. </year>
Reference: [OJ97] <author> R. OCallahan and D. Jackson. Lackwit: </author> <title> A program understanding tool based on type inference. </title> <booktitle> Proceedings of the International Conference on Software Engineering, </booktitle> <year> 1997 </year>
Reference: [OJ97B] <author> R. OCallahan and D. Jackson. Lackwit: </author> <title> Large-scale analysis of C programs using type inference. </title> <type> Technical Report </type>
Reference-contexts: Summary of Previous Work Previous work on program analysis with nonstandard type systems has focused on standard procedural languages such as C or ML. Perhaps the most powerful and general type inference based analyzer for C code to date is my tool, Lackwit. A report on that work <ref> [OJ97B] </ref> provides a detailed description of the analysis and the implementation of the tool, and a full presentation of the results summarized here. In short, Lackwit classifies variables by assigning them types using Hindley-Milner type inference, including parameteric polymorphism to achieve context sensitivity. <p> In addition, we attempted to quantify the effectiveness of the system. We systematically generated a set of 4304 queries over the Morphin test program (the selection procedure is describes in <ref> [OJ97B] </ref>). We measured the sizes of the graphs that would be presented to the user for each query.
Reference: [OPS92] <author> N. Oxhj, J. Palsberg and M. Schwartzbach. </author> <title> Making type inference practical. </title> <booktitle> Proceedings of the European Conference on Object Oriented Programming, </booktitle> <year> 1992. </year>
Reference-contexts: Closure Analyses for Object Oriented Programs Grove, Dean, DeFouw and Chambers [GDDC97] survey a number of algorithms for call graph construction for object oriented languages. The algorithms studied include those of Palsberg and Schwartzbach [PS91], Oxhj, Palsberg and Schwartzbach <ref> [OPS92] </ref>, and Agesen [A95]. The call graph construction problem is essentially the same as closure analysis: identify the possible targets of an indirect function (or procedure, or method) invocation.
Reference: [P95] <author> J. Palsberg. </author> <title> Efficient inference of object types. </title> <journal> Information and Computation, </journal> <volume> Volume 123, </volume> <year> 1995. </year>
Reference-contexts: Obviously performance problems exhibited by flow analyses will carry over to the equivalent type inference systems, unless we relinquish some expressive power. Context sensitive closure analyses or polymorphic type systems are not treated. Palsberg <ref> [P95] </ref> describes a type inference algorithm for Abadi and Cardellis object calculus. The algorithm incorporates subtype constraints, and requires O (n 3 ) time in the worst case because it computes a transitive closure; empirical results are not reported. It does not incorporate parametric polymorphism.
Reference: [PO95] <author> J. Palsberg and P. O'Keefe. </author> <title> A type system equivalent to flow analysis. </title> <journal> TOPLAS, </journal> <volume> Volume 17, No. 4, </volume> <year> 1995. </year>
Reference-contexts: I think it is important to avoid them because they easily lead to scalability problems in the analysis. Subtype constraints can express flow sensitive properties; in fact, Palsberg and OKeefe proved one subtyping system equivalent to a flow analysis <ref> [PO95] </ref>. Theoretically tractable algorithms for flow sensitive analysis in the presence of higher-order functions have only appeared very recently [HM97]. <p> There is no mention at all of any implementation or its performance. Palsberg and OKeefe <ref> [PO95] </ref> prove that a certain simple type inference system with recursive types and subtyping is equivalent to a standard closure analysis. Obviously performance problems exhibited by flow analyses will carry over to the equivalent type inference systems, unless we relinquish some expressive power. <p> Wright and Cartwrights soft typing system for Scheme [WC94] handles recursive types, records, and polymorphism, but it cannot distinguish different instances of the same basic type, which is a fundamental requirement for almost all of my applications. Heintze [H95] describes extensions of the equivalence results of Palsberg and OKeefe <ref> [PO95] </ref> that, among other things, show the equivalence of unification-based type inference (i.e. without subtyping) to a simple closure analysis. There are no empirical results, and polymorphic type systems are not treated.
Reference: [PP98] <author> J. Palsberg and C. Pavlopoulou. </author> <title> From polyvariant flow information to intersection and union types. </title> <booktitle> Proceedings of the 25 th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1998. </year>
Reference-contexts: The intuition behind context sensitivity is that the information obtained by a context sensitive algorithm will not necessarily be improved by duplicating code that is used multiple times in the analyzed programs. This includes analyses described as polyvariant or polymorphic, and also some uses of intersection types <ref> [PP98] </ref>. Obviously these definitions are rather crude, but they usefully classify most of the related work. Almost all the methods directed at the program analysis tasks I wish to address have historically been formulated as flow analyses rather than type systems.
Reference: [PS91] <author> J. Palsberg and M. Schwartzbach. </author> <title> Objectoriented type inference. </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on ObjectOriented Programming Systems, Languages and Applications, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: Closure Analyses for Object Oriented Programs Grove, Dean, DeFouw and Chambers [GDDC97] survey a number of algorithms for call graph construction for object oriented languages. The algorithms studied include those of Palsberg and Schwartzbach <ref> [PS91] </ref>, Oxhj, Palsberg and Schwartzbach [OPS92], and Agesen [A95]. The call graph construction problem is essentially the same as closure analysis: identify the possible targets of an indirect function (or procedure, or method) invocation.
Reference: [Q97] <author> Z. Qian. </author> <title> A formal specification of Java virtual machine instructions. </title> <address> http://www.informatik.uni-bremen.de/~qian/abs-fsjvm.html </address>
Reference-contexts: Some compilers for other languages (e.g. Ada, Visual Basic, and NESL) have been built to use Java bytecode as a target language. I will get these programs for free. 3.2. The Micro-Java-Bytecode Language The sublanguage formally treated here is based on Qians formalization of a subset of JBC <ref> [Q97] </ref>. Any errors in this revised specification are most likely mine. The full definition of the language, defining programs P, tagged states X, and a transition relation , is given in Appendix B: The Micro-Java-Bytecode Language. <p> However, I believe but have not yet proven that the analysis is sound even for MJB programs that do not correspond to verifiable Java programs. Formally characterizing the verifiable programs is an area of active research <ref> [Q97, SA98] </ref> that I will avoid if at all possible.
Reference: [R95] <author> E. Ruf. </author> <title> Context-insensitive alias analysis reconsidered. </title> <booktitle> Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1995. </year>
Reference-contexts: They give no measurements of the quality of the results of their algorithm. Ruf <ref> [R95] </ref> compared two flowsensitive algorithms, one contextsensitive and the other context-insensitive. The sets of possible locations at each load or store were almost identical, leading him to conclude that for those benchmarks, context sensitivity was worthless.
Reference: [R97] <author> E. Ruf. </author> <title> Partitioning data flow analysis using types. </title> <booktitle> Proceedings of the 24 Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1997. </year> <month> 35 </month>
Reference-contexts: There are also serious problems with the introduction of parametric P 13 polymorphism 4 . Furthermore, the results of the type inference can be used to improve the speed and accuracy of subsequent flow sensitive analyses, if better performance is desired <ref> [R97] </ref>. Therefore, the constraint system I will use is similar to a framework for type inference with polymorphic recursion that admits recursive types (in the form of regular trees). However, it never rejects a program as untypable, since this would mean the program could not be analyzed. <p> Hybrid Analyses Hybrid approaches to closure analysis and alias analysis have been proposed, that combine traditional flow analysis of abstract values with type inference. Ruf <ref> [R97] </ref> and Zhang, Ryder and Landi [ZRL96] suggest similar schemes for alias analysis that first apply a fast type inference analysis, and then use the results to select a subset of the program to be analyzed with a more expensive flow analysis to obtain more precise information for a certain set
Reference: [RV97] <author> D. Rmy and J. Vouillon. </author> <title> Objective ML: A simple objectoriented extension of ML. </title> <booktitle> Proceedings of the 24th Annual ACM SIGPLAN SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: The type system obtained is very similar to that used for binding time analysis by Bondorf and Jrgensen [BJ93]. The analysis is more powerful than Steensgaards, but less powerful than Wright and Cartwrights (and Lackwits). Rmy and Vouillon <ref> [RV97] </ref> describe the type system of Objective Caml, which provides type inference for an objectoriented extension of ML, without the use of subtype constraints.
Reference: [S88] <author> O. Shivers. </author> <title> Control Flow Analysis in Scheme. </title> <booktitle> Proceedings of the ACM SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1988. </year>
Reference-contexts: The Tagged Semantics Flow analyses are often derived as abstractions of instrumented semantics that associate labels with values <ref> [A96, JW95, S88, and lots of others] </ref>. Often, a value is tagged with a label indicating the program point at which it was created. However, it is frequently useful to be able to distinguish between multiple values arising from the same program point. <p> closure analysis, also known as higher-order control flow analysis. (The usual problem of identifying which lambda expressions could be invoked by a function application expression is easily generalized to other problems of discovering information about the values computed by an expression.) A classic approach to CFA is given by Shivers <ref> [S88] </ref>. Since then, much work has been done to improve the time and space requirements of his technique, especially when some kind of context sensitivity is required.
Reference: [S96] <author> B. Steensgaard. </author> <title> Points-to analysis in almost linear time. </title> <booktitle> Proceedings of the 23 Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Alias Analyses One area of analysis where scalability is often an explicit goal is alias analysis and related problems, such as side effect estimation. To date, scalability has not been convincingly demonstrated, except for algorithms based on type inference, such as Steensgaards <ref> [S96] </ref> discussed in Section 7.1.6. (For some reason, few connections have been drawn between closure analysis and alias analysis, even though they both compute the same kind of information.) 26 Stocks, Ryder and Landi [SRL97] give a comparison of the efficiency and accuracy of two of their alias analysis algorithms for <p> Region inference uses the effect information to help guide the allocation and release of memory regions, but requires a significant amount of additional machinery to provide sound and efficient memory management. Steensgaard <ref> [S96] </ref> applied a very simple type inference scheme to analyze aliasing for C programs. My analysis techniques are more sophisticated than anything he published, mostly because they distinguish elements of records, handle recursive types, and use polymorphism to achieve context sensitivity.
Reference: [SA98] <author> R. Stata and M. Abadi. </author> <title> A type system for Java bytecode subroutines. </title> <booktitle> Proceedings of the 25 th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1998. </year>
Reference-contexts: However, I believe but have not yet proven that the analysis is sound even for MJB programs that do not correspond to verifiable Java programs. Formally characterizing the verifiable programs is an area of active research <ref> [Q97, SA98] </ref> that I will avoid if at all possible.
Reference: [SRL97] <author> P. Stocks, B. Ryder, and W. Landi. </author> <title> Comparing Flow and Context sensitivity on the Modificationside-effects Problem. </title> <institution> Department of Computer Science, Rutgers University, Number DCS-TR-335, </institution> <month> August, </month> <year> 1997. </year>
Reference-contexts: Furthermore, those instances all have the same heap allocation point in the program text, so even flow sensitive analyses <ref> [SRL97, WL95] </ref> that identify abstract heap storage locations with malloc call sites will not be able to distinguish such instances. A key claim about Lackwit is that it scales to handle large programs. <p> scalability has not been convincingly demonstrated, except for algorithms based on type inference, such as Steensgaards [S96] discussed in Section 7.1.6. (For some reason, few connections have been drawn between closure analysis and alias analysis, even though they both compute the same kind of information.) 26 Stocks, Ryder and Landi <ref> [SRL97] </ref> give a comparison of the efficiency and accuracy of two of their alias analysis algorithms for first-order C programs, applied to the problem of computing an approximation of the side effects of each procedure.
Reference: [TJ92] <author> J.-P. Talpin and P. Jouvelot. </author> <title> The type and effect discipline. </title> <booktitle> Proceedings of the 1992 Conference on Logic in Computer Science, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: The region inference work can be traced back to previous work on effect inference. FX [GJLS87] was an early example of such a system. Talpin and Jouvelot <ref> [TJ92] </ref> describe an elegant example of such a type system. The comments in the previous paragraph also apply to the relationship between this work and mine. Effect inference extends function types with annotations describing the operation of the function on store locations.
Reference: [TT94] <author> M. Tofte and J.-P. Taplin. </author> <title> Implementation of the Typed Call-By-Value l-Calculus Using a Stack of Regions. </title> <booktitle> Proceedings of the 21st Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1994, </year> <pages> pp. 188-201. </pages>
Reference-contexts: Unification Based Type Inference Many researchers have applied nonstandard type inference systems based on unification to gather information about programs. Tofte and Talpins region inference <ref> [TT94] </ref> is especially similar to my proposal, partly because it uses polymorphic recursion. There are significant differences, however. Their system is unnecessarily complex (for my purposes) because it includes effect inference, which I do not need.
Reference: [WC94] <author> A. Wright and R. Cartwright. </author> <title> A Practical Soft Type System for Scheme. </title> <booktitle> Proceedings of the 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: My analysis techniques are more sophisticated than anything he published, mostly because they distinguish elements of records, handle recursive types, and use polymorphism to achieve context sensitivity. Wright and Cartwrights soft typing system for Scheme <ref> [WC94] </ref> handles recursive types, records, and polymorphism, but it cannot distinguish different instances of the same basic type, which is a fundamental requirement for almost all of my applications.
Reference: [ZRL96] <author> S. Zhang, B. Ryder, and W. Landi. </author> <title> Program decomposition for pointer aliasing: A step towards practical analyses. </title> <booktitle> Proceedings of the 4 th Annual ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Hybrid Analyses Hybrid approaches to closure analysis and alias analysis have been proposed, that combine traditional flow analysis of abstract values with type inference. Ruf [R97] and Zhang, Ryder and Landi <ref> [ZRL96] </ref> suggest similar schemes for alias analysis that first apply a fast type inference analysis, and then use the results to select a subset of the program to be analyzed with a more expensive flow analysis to obtain more precise information for a certain set of values.
Reference: [WL95] <author> R. Wilson and M. Lam. </author> <title> Efficient ContextSensitive Pointer Analysis for C Programs. </title> <booktitle> Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June, </month> <year> 1995. </year> <month> 36 </month>
Reference-contexts: Furthermore, those instances all have the same heap allocation point in the program text, so even flow sensitive analyses <ref> [SRL97, WL95] </ref> that identify abstract heap storage locations with malloc call sites will not be able to distinguish such instances. A key claim about Lackwit is that it scales to handle large programs. <p> Wilson and Lam <ref> [WL95] </ref> give an algorithm for contextsensitive, flowsensitive alias analysis for C programs that computes abstractions of procedures, called partial transfer functions, that depend on the calling context but can often be reused between calling contexts (often, only one PTF is ever computed for a procedure).
References-found: 45

