URL: ftp://ftp.daimi.aau.dk/pub/stud/hhl/sufficient.ps.Z
Refering-URL: http://www.daimi.aau.dk/~hhl/
Root-URL: http://www.daimi.aau.dk
Email: e-mail: henrikl@aifh.ed.ac.uk john@aifh.ed.ac.uk  
Title: Sufficient Neurocontrollers can be Surprisingly Simple.  
Author: Henrik Hautop Lund John Hallam 
Keyword: Evolutionary Robotics, Neurocontroller, Khepera robot, Sufficient  
Note: Requirements, Robotics in Biological Experiments  
Web: http://www.dai.ed.ac.uk/staff/Henrik Lund.html  
Address: Edinburgh, 5 Forrest Hill, Edinburgh EH1 2QL, Scotland, UK  
Affiliation: Department of Artificial Intelligence University of  
Abstract: Behaviors such as exploration and homing, that seemingly demand a complex control system, only require a perceptron that connects a robot's sensors to its motors. This is shown by evolving such neurocontrollers for the Khepera robot. An exploitation of the robot's perception of the environment's geometrical shape allows the robot to encode time, even though explicitly it is not presented with the time and there are no recurrent connections in the neurocontroller. In a biological context, the robotics approach to show sufficient requirements for obtaining specific behaviors suggest that some biological experiments have to be re-done in order for the conclusions drawn from these biological experiments to be valid. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Bains. </author> <title> A robot cricket always get its mate. </title> <booktitle> Science, </booktitle> <address> 266:1809, </address> <year> 1994. </year>
Reference-contexts: Here, our robotics approach represents an alternative: given a specific animal behavior, we can test what is a sufficient processing complexity necessary for obtaining such a behavior. We have used this kind of approach in cricket phonotaxis experiments <ref> [1, 29, 30] </ref>, rat open field box experiments [22], and in other more artificial tasks, as shown in this paper. In Section 2, we will discuss different aspects of making evolution entirely on real robots and possible ways of making simulators of real robots. <p> making a robot implementation of how female crickets find male crickets by walking (or flying) towards a species-specific song that the males produce, we find evidence for our neuroethological hypothesis that the required control system for obtaining such phonotaxis behavior can be much simpler than that traditionally hypothesised by biologists <ref> [1, 29, 30] </ref>. These initial studies were made with a LEGO robot, but we are currently using the Khepera robot, for which we have constructed appropriate ears (i.e. microphones with programmable delays), so that we can perform the robotic experiments in cricket phonotaxis much more precisely with real cricket songs.
Reference: [2] <author> J. M. Baldwin. </author> <title> A new factor in evolution. </title> <journal> American Naturalist, </journal> <volume> 30 </volume> <pages> 441-451, 1896. </pages>
Reference-contexts: As is known from much work on for example evolutionary neural networks, the two approaches can also be combined successfully to result in the Baldwin effect <ref> [2, 15, 31, 27, 14] </ref> In the field of Evolutionary Robotics, there is much discussion about what kind of robot controller to evolve.
Reference: [3] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE J. Robotics and Automation, </journal> <volume> RA-2(1), </volume> <year> 1986. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language <ref> [3, 17] </ref> implementations of classifier systems [6], and a large variety of neural networks [5, 8, 23]. Most of the behaviors that have been evolved on real robots have been fairly simple.
Reference: [4] <author> K. Cheng. </author> <title> A purely geometric module in the rat's spatial representation. </title> <journal> Cognition, </journal> <volume> 23 </volume> <pages> 149-178, </pages> <year> 1986. </year>
Reference-contexts: The amazing effect of perceptrons to solve tasks that apparently demand memory of spatial location and/or timing puts some biological experiments, for example on cognitive maps, into a new context. For instance, biological researchers <ref> [4, 9, 20] </ref> have used the open field box experiments with rats to provide evidence for the hypothesis that rats use cognitive maps to navigate around in the environment.
Reference: [5] <author> D. Cliff, I. Harvey, and P. Husbands. </author> <booktitle> Explorations in Evolutionary Robotics. Adaptive Behavior, </booktitle> <volume> 2 </volume> <pages> 73-110, </pages> <year> 1993. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language [3, 17] implementations of classifier systems [6], and a large variety of neural networks <ref> [5, 8, 23] </ref>. Most of the behaviors that have been evolved on real robots have been fairly simple. Researchers have mainly tried to show the validity of their approaches by evolving behaviors such as obstacle avoidance, light seeking, and wall following.
Reference: [6] <author> M. Dorigo and U. Schnepf. </author> <title> Genetic-based machine learning and behavior based robotics: a new syntesis. </title> <journal> IEEE Transaction on Systems, Man and Cybernetics, </journal> <volume> 23 </volume> <pages> 141-153, </pages> <year> 1993. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language [3, 17] implementations of classifier systems <ref> [6] </ref>, and a large variety of neural networks [5, 8, 23]. Most of the behaviors that have been evolved on real robots have been fairly simple. Researchers have mainly tried to show the validity of their approaches by evolving behaviors such as obstacle avoidance, light seeking, and wall following.
Reference: [7] <author> D. Floreano and F. Mondada. </author> <title> Active Perception, Navigation, Homing, and Grasping: An Autonomous Perspective. </title> <editor> In P. Gaussier and J.-D. Nicoud, editors, </editor> <booktitle> Proceedings of From Perception to Action Conference (PerAc94). </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: This is the approach taken by researchers who do the evolution process entirely on the real robots <ref> [7, 8, 25] </ref>. The approach has the disadvantage of not allowing many testings of each single control system (few actions and only 1 epoch), so the performance of a single control system will be heavily biased by the initial starting position of the robot.
Reference: [8] <author> D. Floreano and F. Mondada. </author> <title> Evolution of Homing Navigation in a Real Mobile Robot. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 26(3), </volume> <year> 1996. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language [3, 17] implementations of classifier systems [6], and a large variety of neural networks <ref> [5, 8, 23] </ref>. Most of the behaviors that have been evolved on real robots have been fairly simple. Researchers have mainly tried to show the validity of their approaches by evolving behaviors such as obstacle avoidance, light seeking, and wall following. <p> This is the approach taken by researchers who do the evolution process entirely on the real robots <ref> [7, 8, 25] </ref>. The approach has the disadvantage of not allowing many testings of each single control system (few actions and only 1 epoch), so the performance of a single control system will be heavily biased by the initial starting position of the robot.
Reference: [9] <author> C. R. Gallistel. </author> <title> The organization of learning. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The amazing effect of perceptrons to solve tasks that apparently demand memory of spatial location and/or timing puts some biological experiments, for example on cognitive maps, into a new context. For instance, biological researchers <ref> [4, 9, 20] </ref> have used the open field box experiments with rats to provide evidence for the hypothesis that rats use cognitive maps to navigate around in the environment.
Reference: [10] <author> T. Gomi. </author> <type> Personal communication. </type> <year> 1996. </year>
Reference-contexts: At least, counting the number of cells visited would demand an external observer. This external observer could, for instance, be a video-camera placed above the arena, and this is indeed the approach taken by Gomi's group at Applied-AI 16 in Canada <ref> [10] </ref>. Yet, it will not always be practical to set up an external ob-server for all kinds of tasks and in more complicated environments. Here, the approach of using a simulator before transferring the evolved control systems to real robots interacting in the real world proves to be very efficient.
Reference: [11] <author> T. Gomi and Ann Griffith. </author> <title> Evolutionary Robotics | An Overview. </title> <booktitle> In Proceedings of IEEE Third International Conference on Evolutionary Computation, </booktitle> <address> NJ, 1996. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: 1 Introduction. In recent years, many researchers have turned to the Artificial Life approach to robotics, named Evolutionary Robotics (see reviews <ref> [21, 11] </ref>). Evolutionary Robotics is a population based methodology that uses a simulated Darwinian evolution process to evolve robot structures which can be both robot controllers and/or robot body plans.
Reference: [12] <author> J. Greffenstette and A. Schultz. </author> <title> An Evolutionary Approach to Learning in Robots. </title> <booktitle> In Proceedings of Machine Learning Workshop on Robot Learning, </booktitle> <address> NJ, 1994. New Brunswick. </address>
Reference-contexts: Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot.
Reference: [13] <author> J. Hallam. </author> <title> Hybrid Problems Need Hybrid Solutions? Tracking and Controlling Toy Cars. </title> <editor> In C. M. Brown and D. Terzopoulos, editors, </editor> <booktitle> Real-Time Computer Vision, </booktitle> <pages> pages 209-229. CUP, </pages> <year> 1994. </year>
Reference-contexts: Further, the ambient light was slightly different than under the construction of the simulator. We are currently building a video-tracking system based on the CARS systems architecture <ref> [13] </ref> using a Matrix Meteor frame-grabber, but since this system is currently not ready, what we did was to manually record the position of the real robot at each time step.
Reference: [14] <author> R. Hightower, S. Forrest, and A. Perelson. </author> <title> The Baldwin effect in the immune system: learning by somatic hypermutation. </title> <editor> In R. K. Belew and M. Mitchell, editors, </editor> <title> Adaptive Individuals in Evolving Populations: Models and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: As is known from much work on for example evolutionary neural networks, the two approaches can also be combined successfully to result in the Baldwin effect <ref> [2, 15, 31, 27, 14] </ref> In the field of Evolutionary Robotics, there is much discussion about what kind of robot controller to evolve.
Reference: [15] <author> G. E. Hinton and S. J. Nowlan. </author> <title> How learning can guide evolution. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 495-502, </pages> <year> 1987. </year>
Reference-contexts: As is known from much work on for example evolutionary neural networks, the two approaches can also be combined successfully to result in the Baldwin effect <ref> [2, 15, 31, 27, 14] </ref> In the field of Evolutionary Robotics, there is much discussion about what kind of robot controller to evolve.
Reference: [16] <author> N. Jakobi, P. Husbands, and I. Harvey. </author> <title> Noise and The Reality Gap: </title> <booktitle> The Use of Simula--tion in Evolutionary Robotics. In Proceedings of 3.rd European Conference on Artificial Life (ECAL'95). </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: The new, reproduced, control systems then constitute the next generation which is tested, selected from, and reproduced. The evolution process might then go on like this for a number of generations | in the order of 100 for the applications we have seen up to date (Jakobi et al. <ref> [16] </ref> let their evolution process run for 1000 generations, but then use a bit smaller (64 as opposed to 100) population size than others). <p> Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot. <p> There have been different approaches towards this. Jakobi et al. <ref> [16] </ref> from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot. <p> Besides reducing the time consumption by using an appropriate simulator, we reduce the time consumption by reducing the search space. Some researchers have reported using 1000 generations of populations of 64 individuals to evolve a task-fulfilling light seeking behavior on the Khepera robot <ref> [16] </ref>. It is notable, that the more complicated task of doing both exploration and homing towards a light source can be evolved in many fewer generations (of 100 individuals, though) when one evolves simpler control systems.
Reference: [17] <author> J. R. Koza. </author> <title> Genetic Programming II: Automatic Discovery of Reusable Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language <ref> [3, 17] </ref> implementations of classifier systems [6], and a large variety of neural networks [5, 8, 23]. Most of the behaviors that have been evolved on real robots have been fairly simple.
Reference: [18] <author> W.-P. Lee, J. Hallam, and H. H. Lund. </author> <title> A Hybrid GP/GA Approach for Co-evolving Controllers and Robot Bodies to Achieve Fitness-Specified Tasks. </title> <booktitle> In Proceedings of IEEE Third International Conference on Evolutionary Computation, </booktitle> <address> NJ, 1996. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: We have used such a mathematical model, where motor responses are decided by differential equations, in our studies of the evolution of robot body plans <ref> [18] </ref>. Here, the immediate goal is not to be able to transfer each single control system and robot body plan to a real robot, but in the end simply that of choosing the best controller plus body plan to be transferred to a robot built according to the evolved parameters.
Reference: [19] <author> H. H. Lund and O. Miglino. </author> <title> From Simulated to Real Robots. </title> <booktitle> In Proceedings of IEEE Third International Conference on Evolutionary Computation, </booktitle> <address> NJ, 1996. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: Even though this can prove difficulty in some applications, the real disadvantage lies in the computational load of the methodology. Imagine the following example, taken from some of our earlier experiments <ref> [19] </ref>. In order to test a single mobile robot, it is allowed to run for 500 actions in an environment. In order to account for initial starting position biases, the mobile robot is run for 3 epochs with different starting positions. <p> Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot. <p> Another methodology to build the simulator for a robot and its environment, is to build look-up tables of the robot's sensor and motor responses environments <ref> [19, 24, 23] </ref>. <p> itself, one can build a quite accurate model of a particular robot-environment dynamics, and by using look-up tables constructed by this sampling instead of mathematical models of the sensor and motor responses, one obtains both very high performance when transferring the evolved control systems from simulation to the real robot <ref> [19, 23] </ref>, and a huge reduction in time consumption. When running the example described above with the look-up 4 table based simulator, the time spent on a Pentium 75 MHz is approximately 40 min.
Reference: [20] <author> J. Margules and C. R. Gallistel. </author> <title> Heading in the rat: Determination by environmental shape. Animal Learning and Behavior, </title> <booktitle> 16 </booktitle> <pages> 404-410, </pages> <year> 1988. </year>
Reference-contexts: The amazing effect of perceptrons to solve tasks that apparently demand memory of spatial location and/or timing puts some biological experiments, for example on cognitive maps, into a new context. For instance, biological researchers <ref> [4, 9, 20] </ref> have used the open field box experiments with rats to provide evidence for the hypothesis that rats use cognitive maps to navigate around in the environment.
Reference: [21] <author> M. Mataric and D. Cliff. </author> <title> Challenges in Evolving Controllers for Physical Robots. </title> <type> Technical Report CS-95-184, </type> <institution> Computer Science, Brandeis University, </institution> <year> 1995. </year>
Reference-contexts: 1 Introduction. In recent years, many researchers have turned to the Artificial Life approach to robotics, named Evolutionary Robotics (see reviews <ref> [21, 11] </ref>). Evolutionary Robotics is a population based methodology that uses a simulated Darwinian evolution process to evolve robot structures which can be both robot controllers and/or robot body plans.
Reference: [22] <author> O. Miglino and H. H. Lund. </author> <title> Open Field Box Experiments with Rats and Robots. </title> <type> Technical report, </type> <institution> C.N.R., Rome, </institution> <year> 1996. </year>
Reference-contexts: Here, our robotics approach represents an alternative: given a specific animal behavior, we can test what is a sufficient processing complexity necessary for obtaining such a behavior. We have used this kind of approach in cricket phonotaxis experiments [1, 29, 30], rat open field box experiments <ref> [22] </ref>, and in other more artificial tasks, as shown in this paper. In Section 2, we will discuss different aspects of making evolution entirely on real robots and possible ways of making simulators of real robots. <p> They further show the same "rotational error" as is know with the rats in the open field box experiments. We will elaborate further on these results in another paper <ref> [22] </ref>. Here, we would only like to stress that the methodology used by behavioral biologists might prove to be deceptive. With the robot experiments we can sometimes show that a minimal processing capability is enough to account for behaviors that are often taken as evidence for complex "thinking" in animals.
Reference: [23] <author> O. Miglino, H. H. Lund, and S. Nolfi. </author> <title> Evolving Mobile Robots in Simulated and Real Environments. </title> <journal> Artificial Life, </journal> <volume> 2(4), </volume> <year> 1996. </year>
Reference-contexts: Some researchers have developed controllers based on explicit programs in high-level language [3, 17] implementations of classifier systems [6], and a large variety of neural networks <ref> [5, 8, 23] </ref>. Most of the behaviors that have been evolved on real robots have been fairly simple. Researchers have mainly tried to show the validity of their approaches by evolving behaviors such as obstacle avoidance, light seeking, and wall following. <p> Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot. <p> It is assumed that the responses of all sensors of a robot have the same characteristics, which is unfortunately not so, as shown in <ref> [23] </ref>. The individual sensors vary quite a lot from each other in identical conditions, so an accurate simulator must take the idiosyncrasies of each sensor into account. <p> Another methodology to build the simulator for a robot and its environment, is to build look-up tables of the robot's sensor and motor responses environments <ref> [19, 24, 23] </ref>. <p> itself, one can build a quite accurate model of a particular robot-environment dynamics, and by using look-up tables constructed by this sampling instead of mathematical models of the sensor and motor responses, one obtains both very high performance when transferring the evolved control systems from simulation to the real robot <ref> [19, 23] </ref>, and a huge reduction in time consumption. When running the example described above with the look-up 4 table based simulator, the time spent on a Pentium 75 MHz is approximately 40 min.
Reference: [24] <author> O. Miglino, K. Nafasi, and C. Taylor. </author> <title> Selection for Wandering Behavior in a Small Robot. </title> <journal> Artificial Life, </journal> <volume> 2(1), </volume> <year> 1995. </year>
Reference-contexts: Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot. <p> Another methodology to build the simulator for a robot and its environment, is to build look-up tables of the robot's sensor and motor responses environments <ref> [19, 24, 23] </ref>.
Reference: [25] <author> F. Mondada and D. Floreano. </author> <title> Evolution of neural control structures: Some experiments on mobile robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 16 </volume> <pages> 183-195, </pages> <year> 1995. </year>
Reference-contexts: This is the approach taken by researchers who do the evolution process entirely on the real robots <ref> [7, 8, 25] </ref>. The approach has the disadvantage of not allowing many testings of each single control system (few actions and only 1 epoch), so the performance of a single control system will be heavily biased by the initial starting position of the robot.
Reference: [26] <author> F. Mondada, E. Franzi, and P. Ienne. </author> <title> Mobile robot miniaturisation: A tool for investigation in control algorithms. </title> <booktitle> In Experimental Robotics III. Lecture Notes in Control and Information Sciences 200, </booktitle> <pages> pages 501-513, </pages> <address> Heidelberg, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: With reference to the calculations made earlier, we would like to make a simulator by building a look-up table of possible sensor and motor responses for the robot used in the exploration and homing experiments. The robot is the Khepera miniature mobile robot <ref> [26] </ref>. Figure 1 shows the Khepera robot, which has become widely used in the field of Evolutionary Robotics during the last couple of years. Its inventors have sold more than 300 copies of the robot to universities and individuals.
Reference: [27] <author> S. Nolfi, J. Elman, and D. Parisi. </author> <title> Learning and Evolution in Neural Networks. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 3(1) </volume> <pages> 5-28, </pages> <year> 1994. </year>
Reference-contexts: As is known from much work on for example evolutionary neural networks, the two approaches can also be combined successfully to result in the Baldwin effect <ref> [2, 15, 31, 27, 14] </ref> In the field of Evolutionary Robotics, there is much discussion about what kind of robot controller to evolve.
Reference: [28] <author> S. Nolfi and D. Parisi. </author> <title> Learning to adapt to changing environments in evolving neural networks. </title> <type> Technical Report 95-15, </type> <institution> C.N.R., Rome, </institution> <year> 1995. </year> <note> To appear in Adaptive Behavior. </note>
Reference-contexts: Section 4 and Section 5 describe two experiments with the Khepera robot that are in the same class as the exploration and navigation task used by Nolfi and Parisi <ref> [28] </ref>. It is shown how the behavioral strategies adapt to the environmental geometry. The two experiments are exploration of the 2 environment and homing towards a light source that "provides energy" for the robot.
Reference: [29] <author> B. Webb. </author> <title> Robotics Experiments in Cricket Phonotaxis. </title> <editor> In D. Cliff, P. Husbands, J. Meyer, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94), </booktitle> <address> Cam-bridge, MA, 1994. </address> <publisher> MIT Press, Bradford Books. </publisher>
Reference-contexts: Here, our robotics approach represents an alternative: given a specific animal behavior, we can test what is a sufficient processing complexity necessary for obtaining such a behavior. We have used this kind of approach in cricket phonotaxis experiments <ref> [1, 29, 30] </ref>, rat open field box experiments [22], and in other more artificial tasks, as shown in this paper. In Section 2, we will discuss different aspects of making evolution entirely on real robots and possible ways of making simulators of real robots. <p> making a robot implementation of how female crickets find male crickets by walking (or flying) towards a species-specific song that the males produce, we find evidence for our neuroethological hypothesis that the required control system for obtaining such phonotaxis behavior can be much simpler than that traditionally hypothesised by biologists <ref> [1, 29, 30] </ref>. These initial studies were made with a LEGO robot, but we are currently using the Khepera robot, for which we have constructed appropriate ears (i.e. microphones with programmable delays), so that we can perform the robotic experiments in cricket phonotaxis much more precisely with real cricket songs.
Reference: [30] <author> B. Webb. </author> <title> Using robots to model animals: a cricket test. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 16 </volume> <pages> 117-134, </pages> <year> 1995. </year>
Reference-contexts: Here, our robotics approach represents an alternative: given a specific animal behavior, we can test what is a sufficient processing complexity necessary for obtaining such a behavior. We have used this kind of approach in cricket phonotaxis experiments <ref> [1, 29, 30] </ref>, rat open field box experiments [22], and in other more artificial tasks, as shown in this paper. In Section 2, we will discuss different aspects of making evolution entirely on real robots and possible ways of making simulators of real robots. <p> making a robot implementation of how female crickets find male crickets by walking (or flying) towards a species-specific song that the males produce, we find evidence for our neuroethological hypothesis that the required control system for obtaining such phonotaxis behavior can be much simpler than that traditionally hypothesised by biologists <ref> [1, 29, 30] </ref>. These initial studies were made with a LEGO robot, but we are currently using the Khepera robot, for which we have constructed appropriate ears (i.e. microphones with programmable delays), so that we can perform the robotic experiments in cricket phonotaxis much more precisely with real cricket songs.
Reference: [31] <author> D. Whitley, S. Gordon, and K. Mathias. </author> <title> Lamarckian Evolution, The Baldwin Effect and Function Optimization. </title> <editor> In Y. Davidor, H. P. Schwefel, and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature-PPSN III, </booktitle> <pages> pages 6-15. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: As is known from much work on for example evolutionary neural networks, the two approaches can also be combined successfully to result in the Baldwin effect <ref> [2, 15, 31, 27, 14] </ref> In the field of Evolutionary Robotics, there is much discussion about what kind of robot controller to evolve.
Reference: [32] <author> B. Yamauchi and R. Beer. </author> <title> Integrating reactive, sequential, and learning behavior using dynamical neural networks. </title> <editor> In D. Cliff, P. Husbands, J. Meyer, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94), </booktitle> <address> Cambridge, MA, 1994. </address> <publisher> MIT Press, Bradford Books. </publisher> <pages> 20 </pages>
Reference-contexts: Because of the problems with on-line evolution mentioned above, a number of researchers working with real robots have tried to build simulators for their robots, and then evolved the control systems in simulation before transferring the evolved control systems to the real robots in the real environments <ref> [19, 23, 24, 12, 16, 32] </ref>. There have been different approaches towards this. Jakobi et al. [16] from Sussex have suggested using a mathematical description of motor and sensor responses of the specific robot.
References-found: 32

