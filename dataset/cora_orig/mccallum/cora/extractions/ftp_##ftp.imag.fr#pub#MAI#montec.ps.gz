URL: ftp://ftp.imag.fr/pub/MAI/montec.ps.gz
Refering-URL: http://www-lmc.imag.fr/MAI/cours.fr.html
Root-URL: http://www.imag.fr
Email: bernard.ycart@imag.fr  
Title: Methodes de Monte-Carlo  
Author: B. Ycart 
Date: 1997  
Address: BP 53, 38041 Grenoble Cedex 09  
Affiliation: LMC/IMAG,  DEA de Mathematiques Appliquees Universite Joseph Fourier  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D.J. Aldous. </author> <title> On the Markov chain simulation method for uniform combinatorial distributions and simulated annealing. </title> <journal> Probab. Eng. and Inf. Sciences, </journal> <volume> 1 </volume> <pages> 33-46, </pages> <year> 1987. </year>
Reference-contexts: Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley [29], Fish man [35]. L'article de Ripley [66] est une bonne introduction. * La simulation des variables aleatoires, ou comment transformer un appel de Random (realisation d'une variable aleatoire de loi uniforme sur <ref> [0; 1] </ref>) en une variable aleatoire de loi donnee. Ce sujet est aborde a niveau elementaire dans de nombreux manuels, par exemple les livres de Bouleau [11], Snell [78] ou Berger [9]. <p> Ce que l'on entend par "nombres au hasard" depend d'abord du type des nombres (booleens, entiers, reels). Nous conviendrons de noter Random la fonction qui "retourne un reel au hasard dans <ref> [0; 1] </ref>". Ce que nous en dirons s'etend de maniere evidente a d'autres formats. La phrase "retourner des reels au hasard dans [0; 1]" recouvre en fait deux proprietes distinctes, que nous admettrons comme postulats. <p> Nous conviendrons de noter Random la fonction qui "retourne un reel au hasard dans <ref> [0; 1] </ref>". Ce que nous en dirons s'etend de maniere evidente a d'autres formats. La phrase "retourner des reels au hasard dans [0; 1]" recouvre en fait deux proprietes distinctes, que nous admettrons comme postulats. Postulats 1. 8a; b ; 0 a &lt; b 1 P rob [ Random 2]a; b] ] = b a. 2. Les appels successifs de Random sont des variables aleatoires independantes. <p> Les appels successifs de Random sont des variables aleatoires independantes. Interpretation Dans le langage courant "au hasard" ne signifie pas seulement aleatoire mais en plus uniformement reparti. Choisir au hasard, c'est donner les m^emes chances a tous les resultats possibles (equiprobabilite). On attend d'un reel "au hasard" dans <ref> [0; 1] </ref> qu'il tombe entre 0; 4 et 0; 5 avec probabilite 1=10, de m^eme qu'entre 0; 8 et 0; 9. Deux intervalles inclus dans [0; 1] ont la m^eme probabilite d'^etre atteints s'ils ont m^eme longueur, et cette probabilite est la longueur des intervalles. <p> Choisir au hasard, c'est donner les m^emes chances a tous les resultats possibles (equiprobabilite). On attend d'un reel "au hasard" dans <ref> [0; 1] </ref> qu'il tombe entre 0; 4 et 0; 5 avec probabilite 1=10, de m^eme qu'entre 0; 8 et 0; 9. Deux intervalles inclus dans [0; 1] ont la m^eme probabilite d'^etre atteints s'ils ont m^eme longueur, et cette probabilite est la longueur des intervalles. Les postulats ci-dessus ont une autre consequence. <p> Les postulats ci-dessus ont une autre consequence. Si on considere des couples successifs d'appels de Random comme des coordonnees de points du plan, ces points sont des "points au hasard" dans <ref> [0; 1] </ref> 2 . <p> Ceci peut evidemment ^etre etendu en dimension quelconque. Des triplets d'appels de Random successifs sont les coordonnees de "points au hasard" dans le cube <ref> [0; 1] </ref> 3 , etc: : : Proposition 2.1 Pour tout k 2 IN fl , soient (R 1 ; : : : ; R k ) k appels successifs de Ran dom. <p> Definition 2.1 Une suite de reels x = (x n ); n 2 IN dans <ref> [0; 1] </ref> est dite k-uniforme si pour tout rectangle D = [a 1 ; b 1 [fi fi [a k ; b k [; 0 a i &lt; b i 1 ; i = 1; : : : ; k ; n!1 n i=0 La notation 11 D (y) (fonction indicatrice <p> Cette definition est passablement utopique. En particulier elle entra^ine que la probabilite que Random tombe sur un point donne est nulle. Comme qu'il n'y a qu'une quantite denombrable de rationnels dans <ref> [0; 1] </ref>, la probabilite de tomber sur un rationnel est egalement nulle. <p> conna^it que les decimaux, et m^eme seulement un nombre fini d'entre eux, donc la fonction Random ne peut retourner que des rationnels: : : Qu'a cela ne tienne, si on sait construire une suite uniforme de chiffres entre 0 et 9, on pourra en deduire des reels au hasard dans <ref> [0; 1] </ref>, approches a la k-eme decimale, en considerant des k-uplets consecutifs de chiffres de la suite initiale. C'est le principe des "tables de nombres au hasard" que l'on trouve encore dans certains livres. La m^eme remarque vaut bien s^ur en base 2. <p> Tout ce que l'on peut faire, c'est verifier que rien d'invraisemblable ne se produit pour la suite finie observee. C'est precisement l'objet des tests statistiques que de distinguer le plausible de ce qui est trop peu vraisemblable. "Definition" Un N uplet de nombres dans <ref> [0; 1] </ref> sera dit pseudo-aleatoire s'il passe avec succes une serie de tests statistiques, chacun etant destine a verifier une consequence de la k-uniformite. Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. <p> Les valeurs de Random sont toujours calculees a partir d'entiers repartis dans f0; 1; : : : ; M g ou M est un grand nombre (de l'ordre 10 8 au moins pour les generateurs usuels). Pour retourner un reel dans <ref> [0; 1] </ref>, il suffit de diviser par M . En pratique, un nombre fini de valeurs peuvent seules ^etre atteintes, et elles le sont avec une probabilite positive. <p> X 6 Repeter 12 fois X X+Random finRepeter Justification Si (R n ) designe la suite des appels de Random (suite de variables independantes de loi uniforme sur <ref> [0; 1] </ref>), on a R 1 + + R n n=2 n 1 L On evite une division et on obtient une approximation deja correcte en prenant n = 12. Cet algorithme n'est cependant pas conseille. <p> Elle consiste a composer un appel de Random avec l'inverse de la fonction de repartition de la loi a simuler. Soit F cette fonction de repartition. C'est une fonction de IR dans <ref> [0; 1] </ref>, croissante au sens large et continue a droite. Nous convenons de definir son inverse de la facon suivante. 8u 2 [0; 1] ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire <p> Soit F cette fonction de repartition. C'est une fonction de IR dans <ref> [0; 1] </ref>, croissante au sens large et continue a droite. Nous convenons de definir son inverse de la facon suivante. 8u 2 [0; 1] ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire de loi uniforme sur [0; 1]. <p> Nous convenons de definir son inverse de la facon suivante. 8u 2 <ref> [0; 1] </ref> ; F 1 (u) = inf fx ; F (x) ug : Proposition 2.2 Soit F une fonction de repartition sur IR et U une variable aleatoire de loi uniforme sur [0; 1]. La variable aleatoire X = F 1 (U ) a pour fonction de repartition F . <p> v (D 0 ) = Une idee recurrente dans les methodes de Monte-Carlo est qu'il est a peu pres equivalent, sur le plan de la complexite algorithmique, d'evaluer la taille d'un do-maine (qu'il s'agisse d'enumeration ou d'un calcul d'integrale) ou de tirer au hasard des elements de ce domaine (voir <ref> [1, 2] </ref>). Nous venons d'en fournir une premiere illustration. L'algorithme qui tire des points au hasard dans D peut calculer en m^eme temps le rapport v (D)=v (D 0 ). Il permet donc aussi de calculer des integrales. <p> Supposons qu'il existe une constante c telle que Soit X une variable aleatoire de loi q et U une variable aleatoire de loi uniforme sur <ref> [0; 1] </ref>, independante de X. Alors la loi conditionnelle de X sachant l'evenement "U cq (X) &lt; p (X) est la loi p. On verifie facilement que la probabilite de l'evenement par lequel on conditionne est 1=c. Le nombre moyen de tirages avant acceptation est donc c. <p> Proposition 2.5 Soient f et g deux densites de probabilite sur IR d telles qu'il existe une constante c verifiant : 8x 2 IR d ; cg (x) f (x) : Soit X une variable aleatoire de densite g et U une variable aleatoire de loi uniforme sur <ref> [0; 1] </ref>, independante de X. Alors la loi conditionnelle de X sachant l'evenement E "cUg (X) &lt; f (X)" a pour densite f . <p> Exemple Soit a simuler la loi de densite f (x) = 1 x 2 11 [1;1] (x) : (loi de l'abscisse d'un point au hasard dans le disque unite). Partons de la loi uniforme sur <ref> [1; 1] </ref>: 1 11 [1;1] (x) : Prenons c = 4 (n'importe quelle constante superieure a 4 conviendrait mais il faut choisir c minimale). Voici l'algorithme. <p> Calculer le nombre d'appels de Random necessaires pour que l'amplitude de l'intervalle de confiance de niveau 0; 95 soit inferieure a 10 3 . 2. On considere le decoupage de = <ref> [0; 1] </ref> 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = [0:5; 1]fi [0:5; 1] : Pour i = 1; : : : ; 4, soit i le maximum de la fonction xy sur i . <p> On considere le decoupage de = [0; 1] 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = <ref> [0:5; 1] </ref>fi [0:5; 1] : Pour i = 1; : : : ; 4, soit i le maximum de la fonction xy sur i . <p> On considere le decoupage de = [0; 1] 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = <ref> [0:5; 1] </ref>fi [0:5; 1] : Pour i = 1; : : : ; 4, soit i le maximum de la fonction xy sur i . <p> Calculer le nombre d'appels de Random necessaires pour que l'amplitude de l'intervalle de confiance de niveau 0; 95 soit inferieure a 10 3 . 4. M^emes questions pour un decoupage irregulier en 4 carres 1 = [0; u]fi [0; u] ; : : : ; 4 = <ref> [u; 1] </ref>fi [u; 1] : 5. Quelle valeur de u est optimale ? 6. <p> Calculer le nombre d'appels de Random necessaires pour que l'amplitude de l'intervalle de confiance de niveau 0; 95 soit inferieure a 10 3 . 4. M^emes questions pour un decoupage irregulier en 4 carres 1 = [0; u]fi [0; u] ; : : : ; 4 = <ref> [u; 1] </ref>fi [u; 1] : 5. Quelle valeur de u est optimale ? 6. <p> Soit f une fonction croissante definie sur <ref> [0; 1] </ref>, et supposons que l'on veuille calculer son integrale. On peut l'approcher par les moyennes empiriques des images par f d'appels de Random successifs, comme nous venons de le voir. <p> Si U designe une variable de loi uniforme sur <ref> [0; 1] </ref> (appel de Random), 1 U a la m^eme loi que U . <p> Calculer le nombre d'appels de Random necessaires pour que l'amplitude de l'intervalle de confiance de niveau 0; 95 soit inferieure a 10 3 . Comparer avec la methode de rejet (voir exercice 2.4.5). 2. On considere le decoupage de = <ref> [0; 1] </ref> 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = [0:5; 1]fi [0:5; 1] : Soient 1 ; : : : ; 4 quatre reels positifs tels que 1 + + 4 = 4. <p> Comparer avec la methode de rejet (voir exercice 2.4.5). 2. On considere le decoupage de = [0; 1] 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = <ref> [0:5; 1] </ref>fi [0:5; 1] : Soient 1 ; : : : ; 4 quatre reels positifs tels que 1 + + 4 = 4. Soit f X la fonction constante par morceaux, valant i sur i . <p> Comparer avec la methode de rejet (voir exercice 2.4.5). 2. On considere le decoupage de = [0; 1] 2 en 4 carres 1 = [0; 0:5]fi [0; 0:5] ; : : : ; 4 = <ref> [0:5; 1] </ref>fi [0:5; 1] : Soient 1 ; : : : ; 4 quatre reels positifs tels que 1 + + 4 = 4. Soit f X la fonction constante par morceaux, valant i sur i . <p> Comparer avec les resultats obtenus dans l'exercice 2.4.5 sur le m^eme decoupage. 36 6. M^emes questions pour un decoupage irregulier en 4 carres 1 = [0; u]fi [0; u] ; : : : ; 4 = <ref> [u; 1] </ref>fi [u; 1] : Quelle valeur de u est optimale ? 7. Reprendre l'exercice pour un decoupage de en 9 carres. 2.7 Suites deterministes On attend des k-uplets consecutifs d'appels de Random qu'ils se comportent comme des points au hasard dans [0; 1] k . <p> Comparer avec les resultats obtenus dans l'exercice 2.4.5 sur le m^eme decoupage. 36 6. M^emes questions pour un decoupage irregulier en 4 carres 1 = [0; u]fi [0; u] ; : : : ; 4 = <ref> [u; 1] </ref>fi [u; 1] : Quelle valeur de u est optimale ? 7. Reprendre l'exercice pour un decoupage de en 9 carres. 2.7 Suites deterministes On attend des k-uplets consecutifs d'appels de Random qu'ils se comportent comme des points au hasard dans [0; 1] k . <p> Reprendre l'exercice pour un decoupage de en 9 carres. 2.7 Suites deterministes On attend des k-uplets consecutifs d'appels de Random qu'ils se comportent comme des points au hasard dans <ref> [0; 1] </ref> k . Nous avons traduit ceci par la notion de k-uniformite. C'est cette propriete qui est utilisee dans la methode de rejet (pour k = d+1) aussi bien que dans le paragraphe precedent. Une suite (u n ) de vecteurs de [0; 1] k est uniforme si 8D =]a <p> comportent comme des points au hasard dans <ref> [0; 1] </ref> k . Nous avons traduit ceci par la notion de k-uniformite. C'est cette propriete qui est utilisee dans la methode de rejet (pour k = d+1) aussi bien que dans le paragraphe precedent. Une suite (u n ) de vecteurs de [0; 1] k est uniforme si 8D =]a 1 ; b 1 ] fi : : : fi]a k ; b k ] ae [0; 1] k ; lim 1 n X 11 D (u i ) = v (D) : Intuitivement, on demande a une suite uniforme dans [0; 1] <p> Une suite (u n ) de vecteurs de <ref> [0; 1] </ref> k est uniforme si 8D =]a 1 ; b 1 ] fi : : : fi]a k ; b k ] ae [0; 1] k ; lim 1 n X 11 D (u i ) = v (D) : Intuitivement, on demande a une suite uniforme dans [0; 1] k de "visiter regulierement" tout [0; 1] k . <p> de <ref> [0; 1] </ref> k est uniforme si 8D =]a 1 ; b 1 ] fi : : : fi]a k ; b k ] ae [0; 1] k ; lim 1 n X 11 D (u i ) = v (D) : Intuitivement, on demande a une suite uniforme dans [0; 1] k de "visiter regulierement" tout [0; 1] k . On exige beaucoup d'un generateur en demandant qu'il soit uniforme pour tout k, si on n'utilise en fait que la k-uniformite pour une valeur precise de k. <p> 8D =]a 1 ; b 1 ] fi : : : fi]a k ; b k ] ae <ref> [0; 1] </ref> k ; lim 1 n X 11 D (u i ) = v (D) : Intuitivement, on demande a une suite uniforme dans [0; 1] k de "visiter regulierement" tout [0; 1] k . On exige beaucoup d'un generateur en demandant qu'il soit uniforme pour tout k, si on n'utilise en fait que la k-uniformite pour une valeur precise de k. <p> Or dans les methodes que nous avons vues jusqu'ici, la valeur de k est fixee par la nature du probleme (k = d ou d + 1). Pour k fixe, il est possible de construire des ensembles de points qui visitent <ref> [0; 1] </ref> k plus regulierement et plus vite que des k-uplets d'appels de Random. Deux methodes sont tres repandues. 2.7.1 Points regulierement repartis Pour k fixe, considerons l'ensemble suivant de m k points regulierement repartis dans [0; 1] k . ae m 1 ; : : : ; m oe Dans <p> Pour k fixe, il est possible de construire des ensembles de points qui visitent <ref> [0; 1] </ref> k plus regulierement et plus vite que des k-uplets d'appels de Random. Deux methodes sont tres repandues. 2.7.1 Points regulierement repartis Pour k fixe, considerons l'ensemble suivant de m k points regulierement repartis dans [0; 1] k . ae m 1 ; : : : ; m oe Dans tous les algorithmes de calculs d'integrales vus precedemment, on peut remplacer les moyennes sur n appels de Random par des moyennes sur les m k points definis ci-dessus. <p> Il est donc souhaitable de disposer d'une suite deterministe de points qui visite <ref> [0; 1] </ref> k plus regulierement que la suite des appels de Random. De telles suites sont dites "a discrepance faible". Les 37 plus courantes sont les suites de Van der Corput, definies comme suit. Pour k fixe, considerons les k premiers nombres premiers (2,3,5,7,11: : : ). <p> i . n = a 0 (n) + a 1 (n) i + + a ` (n) ` avec 0 a j (n) &lt; i : On lui associe u i (n) = i a ` (n) i On definit alors la suite (u (n)); n 2 IN d'elements de <ref> [0; 1] </ref> k par u (n) = (u 1 (n); : : : ; u k (n)) : On peut utiliser cette suite exactement comme une suite de k-uplets consecutifs d'ap-pels de Random. Pour une fonction f definie sur [0; 1] k , on majore l'erreur d'approximation entre la moyenne des <p> definit alors la suite (u (n)); n 2 IN d'elements de <ref> [0; 1] </ref> k par u (n) = (u 1 (n); : : : ; u k (n)) : On peut utiliser cette suite exactement comme une suite de k-uplets consecutifs d'ap-pels de Random. Pour une fonction f definie sur [0; 1] k , on majore l'erreur d'approximation entre la moyenne des f (u (n)) et l'integrale de f sur [0; 1] k comme suit ([11] p. 229). fi fi fi 1 n X f (u (j)) [0;1] k fi fi fi &lt; V (f) i=1 log ( i ) 1 <p> Pour une fonction f definie sur <ref> [0; 1] </ref> k , on majore l'erreur d'approximation entre la moyenne des f (u (n)) et l'integrale de f sur [0; 1] k comme suit ([11] p. 229). fi fi fi 1 n X f (u (j)) [0;1] k fi fi fi &lt; V (f) i=1 log ( i ) 1 ; ou V (f) designe la variation totale de la fonction f . <p> Supposons par exemple que la loi (p ij ) j2E soit simulee par inversion. Notons * U n le n-eme appel de Random. 40 * l'application de E fi <ref> [0; 1] </ref> dans E qui au couple (i; u) associe l'inverse de la fonction de repartition de la loi (p ij ) j2E , evalue en u (voir 2.3.2). L'algorithme calcule bien X n+1 = (X n ; U n ) : Ceci a une portee plutot theorique. <p> 1; : : : ; d : L'ensemble E est naturellement muni d'une structure de graphe G = (E; A), pour laquelle deux sommets j et i sont voisins si et seulement si ils different en une coor-donnee et une seule. fj; ig 2 A () i=1 Soit fi 2 <ref> [0; 1] </ref> un reel fixe. <p> Si on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 4.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous <ref> [1, 2] </ref> (voir aussi [62, 77]). L'importance de la simulation des lois uniformes pour les calculs d'integrales a ete montree dans 2.4 et 2.6.
Reference: [2] <author> D.J. Aldous. </author> <title> Approximate counting via Markov chains. </title> <journal> Statistical Science, </journal> <volume> 8(1) </volume> <pages> 16-19, </pages> <year> 1993. </year>
Reference-contexts: v (D 0 ) = Une idee recurrente dans les methodes de Monte-Carlo est qu'il est a peu pres equivalent, sur le plan de la complexite algorithmique, d'evaluer la taille d'un do-maine (qu'il s'agisse d'enumeration ou d'un calcul d'integrale) ou de tirer au hasard des elements de ce domaine (voir <ref> [1, 2] </ref>). Nous venons d'en fournir une premiere illustration. L'algorithme qui tire des points au hasard dans D peut calculer en m^eme temps le rapport v (D)=v (D 0 ). Il permet donc aussi de calculer des integrales. <p> Si on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 4.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous <ref> [1, 2] </ref> (voir aussi [62, 77]). L'importance de la simulation des lois uniformes pour les calculs d'integrales a ete montree dans 2.4 et 2.6.
Reference: [3] <author> I. Aleksander and H.B. Morton. </author> <title> An introduction to neural computing. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre. Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir <ref> [3, 57, 67] </ref> pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques [37, 42, 16, 17, 18, 6, 59, 60]. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux.
Reference: [4] <editor> A. Antoniadis. Ondelettes et statistique. Cours de DEA UJF, </editor> <year> 1996. </year>
Reference-contexts: Filtrage de Kalman, methodes de fonctions splines (Eubank [32]) ou ondelettes (Antoniadis <ref> [4] </ref>), algo-rithmes de Robbins-Monro ou Kiefer-Wolfowitz, toute une panoplie de techniques permettent de traiter des donnees bruitees (voir Benveniste et al. [8] pour une reference generale, et [84] pour le cas de l'analyse d'images).
Reference: [5] <author> R. Azencott. </author> <title> Simulated annealing. </title> <type> Seminaire Bourbaki, 697 </type> <pages> 161-175, </pages> <year> 1988. </year>
Reference-contexts: Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [5, 10, 26] </ref>. 4.2.1 Mesures de Gibbs Definition 4.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [6] <author> T. </author> <title> Back. Evolutionary algorithms in theory and practice. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1996. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [6, 42, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [7] <author> A.T. Barucha-Reid. </author> <title> Elements of the theory of Markov processes and their Applications. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1960. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid <ref> [7] </ref> et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo.
Reference: [8] <author> A. Benveniste, M. Metivier, and P. Priouret. </author> <title> Algorithmes adaptatifs et approximations stochastiques. </title> <publisher> Masson, </publisher> <address> Paris, </address> <year> 1987. </year>
Reference-contexts: Filtrage de Kalman, methodes de fonctions splines (Eubank [32]) ou ondelettes (Antoniadis [4]), algo-rithmes de Robbins-Monro ou Kiefer-Wolfowitz, toute une panoplie de techniques permettent de traiter des donnees bruitees (voir Benveniste et al. <ref> [8] </ref> pour une reference generale, et [84] pour le cas de l'analyse d'images). La aussi notre separation entre les methodes ou le hasard provient du modele et celles ou il est apporte par l'utilisation de la fonction Random est tout a fait artificielle.
Reference: [9] <author> M.A. Berger. </author> <title> An introduction to probability and stochastic processes. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Ce sujet est aborde a niveau elementaire dans de nombreux manuels, par exemple les livres de Bouleau [11], Snell [78] ou Berger <ref> [9] </ref>. <p> Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger <ref> [9] </ref>, Bouleau [11, 12], Breiman [14], Feller [33, 34], Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45].
Reference: [10] <author> D. Bertsimas and J. Tsitsiklis. </author> <title> Simulated annealing. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 10-15, </pages> <year> 1993. </year>
Reference-contexts: Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [5, 10, 26] </ref>. 4.2.1 Mesures de Gibbs Definition 4.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [11] <author> N. Bouleau. Probabilites de l'ingenieur, </author> <title> variables aleatoires et simulation. </title> <address> Her-mann, Paris, </address> <year> 1985. </year>
Reference-contexts: Ce sujet est aborde a niveau elementaire dans de nombreux manuels, par exemple les livres de Bouleau <ref> [11] </ref>, Snell [78] ou Berger [9]. <p> Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau <ref> [11, 12] </ref>, Breiman [14], Feller [33, 34], Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. <p> Pour un nombre de points n = m k fixe, les calculs seront plus rapides qu'avec des appels de Random. La precision pourra ^etre meilleure dans les cas ou la fonction a integrer est suffisamment reguliere (voir <ref> [11] </ref>, p. 226). 2.7.2 Suites de Van der Corput L'inconvenient de la methode precedente est que pour augmenter le nombre de points (passer de m a m + 1) il faut recalculer tous les points. <p> Il est naturel de se demander s'il existe des cha^ines de Markov non simulables. Il n'en existe pas si E est denombrable, ou si E = IR d , muni de sa tribu de boreliens. On n'en rencontrera donc jamais en pratique (voir Bouleau <ref> [11] </ref> p. 208-211 et p. 225). Exemple : Marches aleatoires sur IR d . Soit (U n ); n 2 IN une suite de variables aleatoires independantes et de m^eme loi sur IR d .
Reference: [12] <author> N. Bouleau. </author> <title> Processus stochastiques et applications. </title> <publisher> Hermann, </publisher> <address> Paris, </address> <year> 1988. </year>
Reference-contexts: Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau <ref> [11, 12] </ref>, Breiman [14], Feller [33, 34], Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [54, 12, 43, 51] </ref>). <p> C'est ce semi-groupe qui decrit la dynamique d'evolution inherente a l'equation dX (t) = (X (t))dt + oe (X (t))dW t : La propriete essentielle est la troisieme. Elle decoule du caractere markovien et de l'homogeneite (voir par exemple <ref> [12] </ref>). Sous les hypotheses du theoreme de Hille-Yoshida, tout semi-groupe admet un gene-rateur qui, formellement, est sa derivee logarithmique. Dans le cas du semi-groupe associe a un processus de diffusion, ce generateur est l'operateur A du paragraphe precedent.
Reference: [13] <author> N. Bouleau and D. Lepingle. </author> <title> Numerical methods for stochastic processes. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle <ref> [13] </ref>. Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres [70, 72, 74, 73, 81, 85]). <p> Il est donc previsible que sur les problemes de tres grande dimension, la suite de Van der Corput ne soit pas concurrentielle par rapport a l'utilisation de Random. Pour plus de details sur les suites a discrepance faible, se reporter a Bouleau <ref> [13] </ref> p. 67-95. 38 3 Methodes markoviennes a temps fini 3.1 Simulation des cha^ines de Markov 3.1.1 Definition algorithmique Une cha^ine de Markov est classiquement definie comme une suite de variables aleatoires pour laquelle la meilleure prediction que l'on puisse faire pour l'etape n+1 si on conna^it toutes les valeurs anterieures <p> Nous ne les aborderons pas (voir [51] p. 511-527). 3.3.3 Problemes de Dirichlet C'est la generalisation du probleme (3.1) que nous considerons ici. La presentation que nous en faisons est celle de [43] p. 364-365 (voir aussi <ref> [13] </ref> p. 237). Les notations sont celles des paragraphes precedents. Supposons que les applications et oe ne dependent pas de t (cas homogene). L'application va de IR d dans IR d , oe va de IR d dans M dfid 0 (IR).
Reference: [14] <author> L. Breiman. </author> <title> Probability. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1968. </year>
Reference-contexts: Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau [11, 12], Breiman <ref> [14] </ref>, Feller [33, 34], Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. <p> Discuter des differentes definitions et caracterisations du mouvement brownien sortirait du cadre de ce cours. Nous renvoyons pour cela au cours de Le Breton [54], et aux tres nombreuses references de la litterature, en particulier <ref> [14, 43] </ref>. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo.
Reference: [15] <author> R. Cairoli and R.C. Dalang. </author> <title> Sequential stochastic optimization. </title> <publisher> Wiley, </publisher> <address> New-York, </address> <year> 1996. </year>
Reference-contexts: La quatrieme partie traite d'un autre type de methodes markoviennes. Ces metho-des, developpees plus recemment, explorent l'espace d'etats soit de maniere homogene pour approcher une mesure d'equilibre donnee (algorithmes de Metropolis [26]), soit de maniere dirigee a la recherche d'un point (extremum d'une fonction <ref> [15] </ref>). Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre.
Reference: [16] <author> R. </author> <type> Cerf. </type> <institution> Une theorie asymptotique des algorithmes genetiques. These, Universite Montpellier II, </institution> <year> 1994. </year> <month> 95 </month>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [6, 42, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [16, 17, 18] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36]. <p> dependant des autres parametres de l'algorithme ainsi que de la fonction f, telle que pour m &gt; m fl , lim max ) = 1 : La demonstration est assez technique et il nous est impossible d'en donner un apercu significatif dans le cadre restreint de ce cours : voir <ref> [16] </ref> p. 27 et p. 72. La valeur critique m fl y est decrite en fonction de a; b; c; et f de maniere relativement precise, mais malheureusement elle n'est pas calculable en pratique.
Reference: [17] <author> R. Cerf. </author> <title> The dynamics of mutation-selection algorithms with large population sizes. </title> <journal> Ann. Inst. H. Poincare, Probab. Stat., </journal> <volume> 32(4) </volume> <pages> 455-508, </pages> <year> 1996. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [6, 42, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [16, 17, 18] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [18] <author> R. Cerf. </author> <title> A new genetic algorithm. </title> <journal> Ann. Appl. Probab., </journal> <volume> 6(3) </volume> <pages> 778-817, </pages> <year> 1996. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [6, 42, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [16, 17, 18] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [19] <author> K.L. Chung. </author> <title> Markov chains with stationary transition probabilities. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau [11, 12], Breiman [14], Feller [33, 34], Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung <ref> [19] </ref> et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. <p> Dans le cas de variables independantes, nous disposions pour cela du theoreme central limite (theoreme 2.1) dont nous pouvions deduire des intervalles de confiance. Un theoreme central limite est vrai pour la suite (f (X n )) (voir <ref> [19] </ref> p. 94). Mais la variance asympto-tique, qui determine l'amplitude des intervalles de confiance, n'est pas V ar p [f]. Elle est en general impossible a calculer, et peut ^etre tres grande.
Reference: [20] <author> E. C inlar. </author> <title> Introduction to stochastic processes. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar <ref> [20] </ref> est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> Ces proprietes du spectre des matrices de transition reversibles sont des cas particuliers de proprietes plus generales que l'on deduit classiquement du theoreme de Perron-Frobenius (voir par exemple <ref> [20] </ref>). Demonstration : Comme DP D 1 est symetrique, ses valeurs propres sont toutes reelles, et ce sont celles de P . Les valeurs propres de I DP D 1 et de I +DP D 1 sont positives ou nulles. Donc celles de P sont comprises entre 1 et 1.
Reference: [21] <author> Y. Colin de Verdiere. Spectres de graphes. Cours de DEA, Universite Joseph Fourier-ENS Lyon, </author> <year> 1994. </year>
Reference-contexts: La cha^ine de Markov de matrice de transition P s'appelle marche aleatoire symetrique sur le graphe G. La matrice P est, a une transformation pres, ce que les combinatoriciens nomment le laplacien du graphe G (voir <ref> [21] </ref>). Cet exemple est a rapprocher de la proposition 3.4. Il existe une analogie etroite entre les cha^ines de Markov symetriques et les reseaux electriques (voir [28]). Les etats de E sont vus comme les sommets d'un reseau, relies par des lignes electriques.
Reference: [22] <author> Y. Colin de Verdiere, Y. Pan, and B. Ycart. </author> <title> Singular limits of schrodinger operators and markov processes. J. Operator Theory, </title> <publisher> Soumis. </publisher>
Reference-contexts: Colin de Verdiere et Y. Pan <ref> [22] </ref>.
Reference: [23] <author> G.H. Cottet and O. Francois. Comportement en taille grande des reseaux de Hopfield. </author> <title> Matapli, </title> <journal> Bull. SMAI, </journal> <volume> 38 </volume> <pages> 53-68, </pages> <year> 1994. </year>
Reference-contexts: Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre. Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois <ref> [23] </ref>), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques [37, 42, 16, 17, 18, 6, 59, 60].
Reference: [24] <author> G.M. Del Corso. </author> <title> Randomization and the parallel solution of linear algebra problems. </title> <journal> J. Comput. Math. Appl., </journal> <volume> 30(11) </volume> <pages> 59-72, </pages> <year> 1995. </year>
Reference-contexts: Signalons enfin que dans de nombreux cas les methodes de Monte-Carlo se pr^etent bien a la parallelisation, sujet que nous n'aborderons pas (voir Shonkwiler et Van Vleck [76], Del Corso <ref> [24] </ref> et Trouve [82]). 1.3 Prerequis et plan Ce cours a un objectif resolument pratique. Il se veut accessible a tout etudiant du DEA de mathematiques appliquees, ayant recu ou non une formation en probabilites. Aucune connaissance particuliere, autre qu'un peu de bon sens, ne sera supposee acquise.
Reference: [25] <author> L. Devroye. </author> <title> Non-uniform random variate generation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Ce sujet est aborde a niveau elementaire dans de nombreux manuels, par exemple les livres de Bouleau [11], Snell [78] ou Berger [9]. Il est traite a fond par Devroye dans <ref> [25] </ref>. * La simulation des processus stochastiques ou comment transformer une suite de variables aleatoires independantes et de m^eme loi (suite d'appels de Random) en un processus quelconque (martingale, cha^ine ou processus de Markov, champ aleatoire, processus de diffusion : : : ). <p> Pour I de 1 a 1 000 Pour J de 1 a 1 000 : : : finPour finPour 17 2.3 Methode d'inversion Nous ne traiterons pas en detail des differentes methodes de simulation des variables aleatoires (voir Devroye <ref> [25] </ref>). Nous donnons simplement quelques idees de base qui sont suffisantes pour la plupart des applications numeriques. 2.3.1 Principe La methode d'inversion est la plus simple des methodes generales de simulation.
Reference: [26] <author> P. Diaconis and L. Saloff-Coste. </author> <title> What do we know about the Metropolis algorithm ? J. </title> <institution> Comp. Sci. Syst., a para^itre. </institution>
Reference-contexts: La quatrieme partie traite d'un autre type de methodes markoviennes. Ces metho-des, developpees plus recemment, explorent l'espace d'etats soit de maniere homogene pour approcher une mesure d'equilibre donnee (algorithmes de Metropolis <ref> [26] </ref>), soit de maniere dirigee a la recherche d'un point (extremum d'une fonction [15]). Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre. <p> la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste [75] ou Diaconis et Saloff-Coste <ref> [26] </ref>). Voici une des plus simples. 68 Proposition 4.5 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [75, 26] </ref>. Au vu de la proposition 4.6, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps. <p> Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [5, 10, 26] </ref>. 4.2.1 Mesures de Gibbs Definition 4.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [27] <author> J. Diebolt. Cha^ines de Markov, methodes MCMC, </author> <title> algorithme EM pour donnees incompletes. </title> <booktitle> Notes, </booktitle> <year> 1996. </year>
Reference-contexts: Les methodes qui seront presentees dans ce cours connaissent un grand succes aupres des statisticiens, qui en ont deduit des versions adaptees a leurs types de probleme (echantillonnage de Gibbs, algorithmes EM, SEM: : : : voir McLach-lan [58] et Diebolt <ref> [27] </ref>). Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo [30, 31] traite d'ailleurs sans distinction les deux types d'applications.
Reference: [28] <author> P. Doyle and J. Snell. </author> <title> Random walks and electric networks. </title> <editor> M. A. A., </editor> <address> Washington, </address> <year> 1984. </year>
Reference-contexts: La matrice P est, a une transformation pres, ce que les combinatoriciens nomment le laplacien du graphe G (voir [21]). Cet exemple est a rapprocher de la proposition 3.4. Il existe une analogie etroite entre les cha^ines de Markov symetriques et les reseaux electriques (voir <ref> [28] </ref>). Les etats de E sont vus comme les sommets d'un reseau, relies par des lignes electriques. L'analogue de la probabilite de transition p ij est la conduc tance (inverse de la resistance) de la ligne reliant i a j.
Reference: [29] <author> E.J. Dudewicz and T.G. Ralley. </author> <title> The handbook of random number generation and testing with TESTRAND computer code. </title> <publisher> American Sciences Press Inc., </publisher> <address> Colum-bus., </address> <year> 1981. </year>
Reference-contexts: C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman [55, 56], bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley <ref> [29] </ref>, Fish man [35]. L'article de Ripley [66] est une bonne introduction. * La simulation des variables aleatoires, ou comment transformer un appel de Random (realisation d'une variable aleatoire de loi uniforme sur [0; 1]) en une variable aleatoire de loi donnee. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [52, 29, 35] </ref>). 9 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs
Reference: [30] <author> M. Duflo. Methodes recursives aleatoires. Masson, Paris, </author> <year> 1990. </year>
Reference-contexts: Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo <ref> [30, 31] </ref> traite d'ailleurs sans distinction les deux types d'applications. Robert [68, 69] montre bien l'importance et l'inter^et des methodes de Monte-Carlo en statistique, en particulier bayesienne. * Les algorithmes de filtrage. <p> Elles ont donne lieu a une intense activite de publication ces 15 dernieres annees (voir le cours recent de Saloff-Coste [75]). Nous n'aborderons ces questions que de maniere assez superficielle dans le cadre des cha^ines reversibles. Les deux livres de Duflo <ref> [30, 31] </ref> constituent une reference de base, d'un niveau sensiblement superieur a celui de ce cours. Un grand merci aux relecteurs, et tout particulierement a Alain Le Breton, Claudine Robert, Francois Robert et Olivier Francois.
Reference: [31] <author> M. Duflo. </author> <title> Algorithmes stochastiques. Mathematiques et applications 23. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo <ref> [30, 31] </ref> traite d'ailleurs sans distinction les deux types d'applications. Robert [68, 69] montre bien l'importance et l'inter^et des methodes de Monte-Carlo en statistique, en particulier bayesienne. * Les algorithmes de filtrage. <p> La aussi notre separation entre les methodes ou le hasard provient du modele et celles ou il est apporte par l'utilisation de la fonction Random est tout a fait artificielle. Les processus stochastiques sous-jacents sont essentiellement les m^emes, comme le montre bien Duflo <ref> [31] </ref>. 2 1.2 Ce qui sera traite Que reste-t-il donc ? Nous designerons dans ce cours par methodes de Monte-Carlo des algorithmes util-isant la fonction Random pour resoudre un probleme numerique deterministe (calcul d'integrale, resolution de systeme, resolution d'equation differentielle, optimisation). <p> Elles ont donne lieu a une intense activite de publication ces 15 dernieres annees (voir le cours recent de Saloff-Coste [75]). Nous n'aborderons ces questions que de maniere assez superficielle dans le cadre des cha^ines reversibles. Les deux livres de Duflo <ref> [30, 31] </ref> constituent une reference de base, d'un niveau sensiblement superieur a celui de ce cours. Un grand merci aux relecteurs, et tout particulierement a Alain Le Breton, Claudine Robert, Francois Robert et Olivier Francois.
Reference: [32] <author> R.L. Eubank. </author> <title> Spline smoothing and nonparametric regression. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Il existe de nombreuses methodes adaptees aux cas ou les donnees du probleme a traiter ne sont pas connues exactement, soit qu'elles proviennent d'un calcul numerique ent^ache d'erreurs importantes, soit qu'elles soient calculees a partir d'un echantillon statistique. Filtrage de Kalman, methodes de fonctions splines (Eubank <ref> [32] </ref>) ou ondelettes (Antoniadis [4]), algo-rithmes de Robbins-Monro ou Kiefer-Wolfowitz, toute une panoplie de techniques permettent de traiter des donnees bruitees (voir Benveniste et al. [8] pour une reference generale, et [84] pour le cas de l'analyse d'images).
Reference: [33] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume I. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1968. </year> <month> 96 </month>
Reference-contexts: Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau [11, 12], Breiman [14], Feller <ref> [33, 34] </ref>, Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo.
Reference: [34] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume II. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1971. </year>
Reference-contexts: Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau [11, 12], Breiman [14], Feller <ref> [33, 34] </ref>, Snell [78]: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair.
Reference: [35] <author> G.S. Fishman. </author> <title> Monte Carlo concepts algorithms and applications. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Chez certains auteurs, elle tend a englober tout ce qui a trait a l'utilisation du hasard dans les programmes informatiques, c'est-a-dire a la fonction Random. Ceci represente un champ beaucoup trop vaste pour le cadre de ce cours (le livre recent de Fishman <ref> [35] </ref> malgre ses 700 pages n'est pas exhaustif), et recouvre de fait des sujets assez distincts. <p> C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman [55, 56], bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley [29], Fish man <ref> [35] </ref>. L'article de Ripley [66] est une bonne introduction. * La simulation des variables aleatoires, ou comment transformer un appel de Random (realisation d'une variable aleatoire de loi uniforme sur [0; 1]) en une variable aleatoire de loi donnee. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [52, 29, 35] </ref>). 9 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs <p> Le probleme avec cette astuce est de l'appliquer valablement en dimension superieu-re (rappelons qu'on ne calcule pas des integrales simples par Monte-Carlo). De nom-breuses heuristiques ont ete avancees, sans pour autant aboutir a des algorithmes op-timises, valables pour tous types de fonctions (voir [49] p. 186-200, <ref> [35] </ref> p. 311-321). 2.6.3 Exercice L'algorithme suivant calcule une valeur approchee de I = [0;1] 2 xy dxdy : I 0 Repeter n fois X Random Y Random I I + X fl Y finRepeter I I=n 1.
Reference: [36] <author> M.I. Freidlin and A.D. Wentzell. </author> <title> Random perturbations of dynamical systems. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Toute valeur propre ` (") est donc d'ordre " h ou h h fl . Les plus petites d'entre elles sont d'ordre " h fl exactement, ce qui justifie la 84 proposition 4.9. Cette description est classiquement deduite de la theorie de Freidlin et Wentzell <ref> [36] </ref>. Nous ne donnerons pas une demonstration complete de la proposition 4.10, mais simplement une idee de justification algebrique. <p> Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell <ref> [36] </ref>. Nous suivons sa presentation sans rentrer dans les details mathematiques, qui sont tres techniques. 4.3.1 Version classique Les algorithmes genetiques s'inspirent des mecanismes de la selection naturelle, comme le recuit simule s'inspire de principes physiques. La fonction a optimiser est ici l'adaptation et c'est son maximum que l'on recherche.
Reference: [37] <author> D. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [6, 42, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [38] <author> C. Graham, T. Kurtz, S. Meleard, P. Protter, M. Pulvirenti, and D. Talay. </author> <title> Probabilistic numerical methods for partial differential equations: Elements of analysis. </title> <editor> In D. Talay and L. Tubaro, editors, </editor> <title> Probabilistic Models for Nonlinear PDE's and Numerical Applications, </title> <editor> L. N. </editor> <booktitle> in Math. </booktitle> <volume> 1627, </volume> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Les quelques exemples que nous donnons ici ne constituent qu'une introduction a un sujet en plein developpement. Les generalisations qui ont ete proposees, et que nous n'aborderons pas, consistent a introduire un certain degre de dependance entre les differentes trajectoires simulees (voir <ref> [80, 38] </ref>). Nous commencons par un exemple, tire de [53]. 3.3.1 Exemple Appliquons la methode du paragraphe 3.2.2 a la discretisation d'un probleme de Dirich-let simple. Soit D le carre unite ouvert, @D son bord.
Reference: [39] <author> R.L. Graham, D.E. Knuth, and O. Patashnik. </author> <title> Concrete mathematics : a foundation for computer science. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1989. </year>
Reference-contexts: Sur cette question, plusieurs references de la litterature informatique sont accessibles au mathematicien applique, parmi lesquelles Graham et al. <ref> [39] </ref> ou le livre de Hofri [41], plus specialise. * Les algorithmes randomises. Ce sujet s'est developpe ces dix dernieres annees sous l'impulsion d'informaticiens theoriciens.
Reference: [40] <author> J.M. </author> <title> Hammersley and Handscomb D.C. Monte-Carlo methods. </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1964. </year>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb <ref> [40] </ref>, Morgan [61], Rubinstein [71], Ripley [65], Kleijnen [49, 50]. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo.
Reference: [41] <author> M. Hofri. </author> <title> Probabilistic analysis of algorithms. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Sur cette question, plusieurs references de la litterature informatique sont accessibles au mathematicien applique, parmi lesquelles Graham et al. [39] ou le livre de Hofri <ref> [41] </ref>, plus specialise. * Les algorithmes randomises. Ce sujet s'est developpe ces dix dernieres annees sous l'impulsion d'informaticiens theoriciens.
Reference: [42] <author> J.H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [6, 42, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [43] <author> I. Karatzas and S.E. Shreve. </author> <title> Brownian motion and stochastic calculus. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Discuter des differentes definitions et caracterisations du mouvement brownien sortirait du cadre de ce cours. Nous renvoyons pour cela au cours de Le Breton [54], et aux tres nombreuses references de la litterature, en particulier <ref> [14, 43] </ref>. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [54, 12, 43, 51] </ref>). <p> Nous ne les aborderons pas (voir [51] p. 511-527). 3.3.3 Problemes de Dirichlet C'est la generalisation du probleme (3.1) que nous considerons ici. La presentation que nous en faisons est celle de <ref> [43] </ref> p. 364-365 (voir aussi [13] p. 237). Les notations sont celles des paragraphes precedents. Supposons que les applications et oe ne dependent pas de t (cas homogene). L'application va de IR d dans IR d , oe va de IR d dans M dfid 0 (IR). <p> Ce qui vient d'^etre dit pour le cas des diffusions homogenes reste valable dans le cas non homogene, m^eme si on perd alors l'interpretation de l'operateur differentiel A comme generateur d'un semi-groupe. Ce qui suit est tire de Karatzas et Shreve <ref> [43] </ref> p. 366-369. Soient et oe deux fonctions de IR + fi IR d dans IR d et M dfid (IR) respectivement. <p> sous lesquelles les affirmations qui vont suivre sont vraies portent sur * la regularite des fonctions et oe, ainsi que des fonctions a et c du probleme (3.12) ci-dessous, * la croissance lineaire ou polynomiale de ces m^emes fonctions, * l'ellipticite uniforme des operateurs A t . (Se reporter a <ref> [43] </ref> pour les enonces precis). On note fX (t) ; t 0g le processus de diffusion, solution du probleme de Cauchy (3.2). Si et oe sont suffisamment regulieres, alors le processus fX (t) ; t 0g admet un noyau de transition, note p (s; x; t; y).
Reference: [44] <author> S. Karlin. </author> <title> A first course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1966. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor <ref> [44, 45] </ref>. C inlar [20] est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo.
Reference: [45] <author> S. Karlin and H.M. Taylor. </author> <title> A second course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1981. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor <ref> [44, 45] </ref>. C inlar [20] est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales.
Reference: [46] <author> F.P. Kelly. </author> <title> Reversibility and Stochastic Networks. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: On dit que p est une mesure reversible pour la cha^ine de Markov de matrice de transition P , ou que la matrice P est p-reversible, si p i p ij = p j p ji ; 8i; j 2 E : (4.1) Le livre de Kelly <ref> [46] </ref> est une bonne reference generale sur la reversibilite et ses applications. La relation (4.1) s'appelle condition de bilan detaille. Observons tout d'abord qu'une mesure reversible est necessairement stationnaire. <p> L'analogue de la probabilite de transition p ij est la conduc tance (inverse de la resistance) de la ligne reliant i a j. Des criteres pour verifier si une matrice de transition donnee admet ou non une mesure reversible ont ete donnes par Kolmogorov (voir <ref> [46] </ref>). Nous nous interesserons plutot ici a la construction d'une matrice de transition p-reversible, quand p est une mesure donnee. Voici une methode generale.
Reference: [47] <author> J.G. Kemeny and J.L. Snell. </author> <title> Finite Markov chains. </title> <publisher> Van Nostrand, Princeton, </publisher> <year> 1960. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell <ref> [47] </ref>. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. <p> x 1 ; x 2 ) = 1 : 61 62 4 Exploration markovienne 4.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [7, 14, 20, 33, 44, 47] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> Ce sont en quelque sorte les boutons de reglage de l'algorithme. La cha^ine de Markov (X T n ) est irreductible et aperiodique. Elle converge donc en loi vers une mesure stationnaire unique p T (voir par exemple <ref> [47] </ref>). On souhaite verifier que lorsque T tend vers 0, cette mesure stationnaire se concentre sur les populations optimales. Contrairement au cas du recuit simule, ce n'est pas toujours vrai.
Reference: [48] <author> W.J. Kennedy and J.E. </author> <title> Gentle. Statistical computing. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle <ref> [48] </ref>, Hammersley et Hand-scomb [40], Morgan [61], Rubinstein [71], Ripley [65], Kleijnen [49, 50].
Reference: [49] <author> J.P.C. Kleijnen. </author> <title> Statistical techniques in simulation, Part I. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1974. </year> <month> 97 </month>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan [61], Rubinstein [71], Ripley [65], Kleijnen <ref> [49, 50] </ref>. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo. <p> Le probleme avec cette astuce est de l'appliquer valablement en dimension superieu-re (rappelons qu'on ne calcule pas des integrales simples par Monte-Carlo). De nom-breuses heuristiques ont ete avancees, sans pour autant aboutir a des algorithmes op-timises, valables pour tous types de fonctions (voir <ref> [49] </ref> p. 186-200, [35] p. 311-321). 2.6.3 Exercice L'algorithme suivant calcule une valeur approchee de I = [0;1] 2 xy dxdy : I 0 Repeter n fois X Random Y Random I I + X fl Y finRepeter I I=n 1.
Reference: [50] <author> J.P.C. Kleijnen and W. Van Groenendaal. </author> <title> Simulation, a statistical perspective. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan [61], Rubinstein [71], Ripley [65], Kleijnen <ref> [49, 50] </ref>. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo.
Reference: [51] <author> P.E. Kloeden and E. Platen. </author> <title> Numerical solution of stochastic differential equations. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen <ref> [51] </ref> est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres [70, 72, 74, 73, 81, 85]). <p> Sur cette coherence entre modelisation deterministe et aleatoire, problemes differentiels et simulation de proces-sus de diffusion, on pourra se reporter a la troisieme partie de Kloeden et Platen <ref> [51] </ref> ainsi qu'a Talay [80] et aux autres articles du m^eme ouvrage. Le rapport entre le mouvement brownien et le laplacien se generalise aux processus de diffusion. Cela fournit le principe de methodes de Monte-Carlo pour la resolution de nombreux problemes differentiels. <p> Nous en donnerons plusieurs exemples dans les paragraphes suivants. Nous examinons tout d'abord la simulation des processus de diffusion. 50 3.3.2 Simulation des processus de diffusion La reference generale sur le sujet est le livre de Kloeden et Platen <ref> [51] </ref>. Nous ne presentons ici que la methode la plus simple, qui est la generalisation aux processus de diffusion de la methode d'Euler pour les solutions d'equations differentielles ordinaires. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [54, 12, 43, 51] </ref>). <p> Ceci ne pose pas de probleme si d 0 est pair, mais peut conduire a doubler les instructions dans la boucle principale (simuler deux pas consecutifs) si d 0 est impair. Il existe de nombreuses autres methodes pour simuler les processus de diffusion (voir Kloeden et Platen <ref> [51] </ref>). La methode d'Euler-Maruyama, si elle est la moins precise de toutes, presente l'avantage d'^etre la plus naturelle, la plus facile a programmer, et la plus rapide a l'execution. <p> Dans le cas deterministe, la methode d'Euler est connue pour "cumuler les erreurs" (au sens ou l'ecart entre la solution exacte et son approximation numerique augmente avec le temps). C'est aussi le cas pour la version stochastique. 53 Le probleme de la stabilite numerique est aborde dans <ref> [51] </ref> p. 331-337. Des techniques de reduction de variance appropriees aux methodes de Monte-Carlo utilisant ce type de simulation ont ete proposees. Nous ne les aborderons pas (voir [51] p. 511-527). 3.3.3 Problemes de Dirichlet C'est la generalisation du probleme (3.1) que nous considerons ici. <p> C'est aussi le cas pour la version stochastique. 53 Le probleme de la stabilite numerique est aborde dans <ref> [51] </ref> p. 331-337. Des techniques de reduction de variance appropriees aux methodes de Monte-Carlo utilisant ce type de simulation ont ete proposees. Nous ne les aborderons pas (voir [51] p. 511-527). 3.3.3 Problemes de Dirichlet C'est la generalisation du probleme (3.1) que nous considerons ici. La presentation que nous en faisons est celle de [43] p. 364-365 (voir aussi [13] p. 237). Les notations sont celles des paragraphes precedents.
Reference: [52] <author> D.E. Knuth. </author> <booktitle> The art of computer programming, volume 2, seminumerical algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1981. </year>
Reference-contexts: C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman [55, 56], bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth <ref> [52] </ref>, Dudewicz et Ralley [29], Fish man [35]. L'article de Ripley [66] est une bonne introduction. * La simulation des variables aleatoires, ou comment transformer un appel de Random (realisation d'une variable aleatoire de loi uniforme sur [0; 1]) en une variable aleatoire de loi donnee. <p> Le nombre de ces tests ainsi que l'entier k sont fonction croissante de l'exigence de l'utilisateur. Des quantites de tests ont ete imagines pour mettre les generateurs a la torture (voir <ref> [52, 29, 35] </ref>). 9 2.1.3 Implementation Parmi les differentes formalisations du hasard qui ont pu ^etre proposees, la notion de suite 1-uniforme est la seule utilisable en pratique : elle est la seule que l'on puisse tester pour un generateur donne et elle suffit a justifier toutes les applications des generateurs
Reference: [53] <author> P. J. Laurent. </author> <title> Les methodes de Monte-Carlo. </title> <institution> Universite Joseph Fourier, Grenoble, </institution> <year> 1966. </year>
Reference-contexts: Les livres de Neuts [63, 64] proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent <ref> [53] </ref>, Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan [61], Rubinstein [71], Ripley [65], Kleijnen [49, 50]. <p> Les generalisations qui ont ete proposees, et que nous n'aborderons pas, consistent a introduire un certain degre de dependance entre les differentes trajectoires simulees (voir [80, 38]). Nous commencons par un exemple, tire de <ref> [53] </ref>. 3.3.1 Exemple Appliquons la methode du paragraphe 3.2.2 a la discretisation d'un probleme de Dirich-let simple. Soit D le carre unite ouvert, @D son bord.
Reference: [54] <author> A. Le Breton. Calcul stochastique. Cours de DEA UJF, </author> <year> 1996. </year>
Reference-contexts: Discuter des differentes definitions et caracterisations du mouvement brownien sortirait du cadre de ce cours. Nous renvoyons pour cela au cours de Le Breton <ref> [54] </ref>, et aux tres nombreuses references de la litterature, en particulier [14, 43]. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (3.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [54, 12, 43, 51] </ref>).
Reference: [55] <author> G. Marsaglia and A. Zaman. </author> <title> Toward a universal random number generator. </title> <journal> Stat. Prob. Lett., </journal> <volume> 8 </volume> <pages> 35-39, </pages> <year> 1990. </year>
Reference-contexts: C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [55, 56] </ref>, bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley [29], Fish man [35]. <p> La solution de l'initialisation par le compteur de temps peut poser un probleme sur les gros systemes ou l'horloge est d'acces reserve. On trouve depuis quelques annees sur le reseau un ensemble de procedures proposees par Marsaglia et Zaman <ref> [55, 56] </ref>. Ces procedures sont presentees sous forme de fichier compresse, selon les systemes d'exploitation (par exemple FSULTRA1.ZIP pour DOS). Une fois decompresse on obtient un ensemble de procedures en Assembleur, Pascal, C, Fortran qui implementent le generateur ULTRA, dont les qualites sont tres superieures a celles des generateurs classiques.
Reference: [56] <author> G. Marsaglia and A. Zaman. </author> <title> A new class of random number generators. </title> <journal> Ann. Appl. Probab., </journal> <volume> 1 </volume> <pages> 462-480, </pages> <year> 1991. </year>
Reference-contexts: C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [55, 56] </ref>, bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley [29], Fish man [35]. <p> La solution de l'initialisation par le compteur de temps peut poser un probleme sur les gros systemes ou l'horloge est d'acces reserve. On trouve depuis quelques annees sur le reseau un ensemble de procedures proposees par Marsaglia et Zaman <ref> [55, 56] </ref>. Ces procedures sont presentees sous forme de fichier compresse, selon les systemes d'exploitation (par exemple FSULTRA1.ZIP pour DOS). Une fois decompresse on obtient un ensemble de procedures en Assembleur, Pascal, C, Fortran qui implementent le generateur ULTRA, dont les qualites sont tres superieures a celles des generateurs classiques.
Reference: [57] <author> T. </author> <title> Masters. Practical neural network recipes in C++. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1993. </year>
Reference-contexts: Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre. Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir <ref> [3, 57, 67] </ref> pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques [37, 42, 16, 17, 18, 6, 59, 60]. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux.
Reference: [58] <author> G.J. McLachlan and T. Krishnan. </author> <title> The EM algorithm and extensions. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: Les methodes qui seront presentees dans ce cours connaissent un grand succes aupres des statisticiens, qui en ont deduit des versions adaptees a leurs types de probleme (echantillonnage de Gibbs, algorithmes EM, SEM: : : : voir McLach-lan <ref> [58] </ref> et Diebolt [27]). Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo [30, 31] traite d'ailleurs sans distinction les deux types d'applications.
Reference: [59] <author> Z. Michalewicz. </author> <title> Genetic algorithms + Data structures = Evolution programs, </title> <publisher> 3rd ed. Springer, </publisher> <address> New-York, </address> <year> 1996. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [6, 42, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [60] <author> M. Mitchell. </author> <title> An introduction to genetic algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir [3, 57, 67] pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques <ref> [37, 42, 16, 17, 18, 6, 59, 60] </ref>. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux. Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [6, 42, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [16, 17, 18] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [36].
Reference: [61] <author> B.J.T. Morgan. </author> <title> Elements of simulation. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1984. </year>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan <ref> [61] </ref>, Rubinstein [71], Ripley [65], Kleijnen [49, 50]. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo.
Reference: [62] <author> R. Motwani and P. Raghavan. </author> <title> Randomized algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: Pour certains de ces derniers, on a pu trouver des algo-rithmes de resolution approchee en temps polynomial, a base essentiellement de cha^ines de Markov. Leur etude devient un domaine important de l'informatique theorique (voir Sinclair [77] ou Motwani et Raghavan <ref> [62] </ref>). * Les methodes de Monte-Carlo en statistique. De nombreuses questions d'estimation, de tests ou de representation de donnees se ramenent a des proble-mes numeriques d'optimisation ou de resolution de systemes de grande taille. <p> on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 4.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous [1, 2] (voir aussi <ref> [62, 77] </ref>). L'importance de la simulation des lois uniformes pour les calculs d'integrales a ete montree dans 2.4 et 2.6. Nous avions donne comme methode generale la methode de rejet et signale le rapport entre l'evaluation du volume d'un domaine et la simulation de la loi uniforme sur ce domaine.
Reference: [63] <author> M.F. Neuts. </author> <title> Matrix-geometric solutions in stochastic models. </title> <publisher> The John Hopkins University Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. Les livres de Neuts <ref> [63, 64] </ref> proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales.
Reference: [64] <author> M.F. Neuts. </author> <title> Algorithmic Probability: a collection of problems. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair. Les livres de Neuts <ref> [63, 64] </ref> proposent une vision systematiquement tournee vers l'outil informatique. La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales.
Reference: [65] <author> B.D. Ripley. </author> <title> Stochastic simulation. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan [61], Rubinstein [71], Ripley <ref> [65] </ref>, Kleijnen [49, 50]. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo.
Reference: [66] <author> B.D. Ripley. </author> <title> Thoughts on pseudorandom numbers. </title> <journal> J. Comput. Appl. Math., </journal> <volume> 31 </volume> <pages> 153-163, </pages> <year> 1990. </year>
Reference-contexts: C'est un probleme que nous con-sidererons arbitrairement comme resolu par Marsaglia et Zaman [55, 56], bien qu'une litterature importante continue a se developper sur la question. Trois references de base sont les livres de Knuth [52], Dudewicz et Ralley [29], Fish man [35]. L'article de Ripley <ref> [66] </ref> est une bonne introduction. * La simulation des variables aleatoires, ou comment transformer un appel de Random (realisation d'une variable aleatoire de loi uniforme sur [0; 1]) en une variable aleatoire de loi donnee.
Reference: [67] <author> B.D. Ripley. </author> <title> Neural networks and pattern recognition. </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Dans ce dernier cas, il s'agit de suivre une trajectoire d'une cha^ine de Markov, qui visite avec une probabilite croissante un voisinage de la cible a atteindre. Parmi ces techniques, on peut ranger les methodes neuronales "thermalisees" (Cottet et Francois [23]), que nous n'aborderons pas (voir <ref> [3, 57, 67] </ref> pour des references generales). Nous traiterons surtout le recuit simule et decrirons l'heuristique des algorithmes genetiques [37, 42, 16, 17, 18, 6, 59, 60]. Ces algorithmes peuvent ^etre vus comme des methodes de descente de gradient, "bruitees" afin d'eviter les pieges d'eventuels minima locaux.
Reference: [68] <author> C.P. Robert. L'Analyse Statistique Bayesienne. Economica, </author> <year> 1992. </year>
Reference-contexts: Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo [30, 31] traite d'ailleurs sans distinction les deux types d'applications. Robert <ref> [68, 69] </ref> montre bien l'importance et l'inter^et des methodes de Monte-Carlo en statistique, en particulier bayesienne. * Les algorithmes de filtrage.
Reference: [69] <editor> C.P. Robert. Methodes de Monte-Carlo par cha^ines de Markov. CREST-INSEE, </editor> <address> Paris, </address> <year> 1996. </year>
Reference-contexts: Il est tres artificiel de couper, comme nous le ferons, les methodes de resolution de problemes deterministes de leurs applications na-turelles en statistique. Duflo [30, 31] traite d'ailleurs sans distinction les deux types d'applications. Robert <ref> [68, 69] </ref> montre bien l'importance et l'inter^et des methodes de Monte-Carlo en statistique, en particulier bayesienne. * Les algorithmes de filtrage.
Reference: [70] <author> T.G. Robertazzi. </author> <title> Computer networks and systems: queuing theory and performance evaluation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
Reference: [71] <author> R.Y. Rubinstein. </author> <title> Simulation and the Monte-Carlo method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: La deuxieme partie traite des methodes a tirages independants pour les calculs d'integrales. Elles sont traitees de maniere plus ou moins detaillee dans de nombreux manuels, comme ceux de Laurent [53], Kennedy et Gentle [48], Hammersley et Hand-scomb [40], Morgan [61], Rubinstein <ref> [71] </ref>, Ripley [65], Kleijnen [49, 50]. Sans surprises sur le plan theorique, elles fourniront surtout l'occasion de rappeler un certain nombre de bases probabilistes et algorithmiques, l'objectif principal etant de developper l'etat d'esprit assez particulier qui preside a une implementation efficace des methodes de Monte-Carlo. <p> Il est m^eme possible de calculer toute la matrice (I A) 1 . Des variantes de cet algorithme ont ete proposees qui n'utilisent qu'une seule trajectoire, suivie suffisamment longtemps (voir Rubinstein <ref> [71] </ref> p. 158-169). Comme on l'aura constate, on dispose d'une grande latitude pour choisir la loi initiale ainsi que les probabilites de transition.
Reference: [72] <author> R.Y. Rubinstein. </author> <title> Monte-Carlo optimization, simulation and sensitivity of queuing networks. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
Reference: [73] <author> R.Y. Rubinstein and B. Melamed. </author> <title> Efficient simulation and Monte-Carlo methods. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
Reference: [74] <author> R.Y. Rubinstein and A. Shapiro. </author> <title> Discrete event systems: sensitivity analysis and stochastic optimization by the score function method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
Reference: [75] <author> L. Saloff-Coste. </author> <title> Lectures on finite Markov chains. </title> <institution> Notes de Cours, Ecole d'ete de probabilites de Saint-Flour, a para^itre, </institution> <year> 1996. </year>
Reference-contexts: Les questions theoriques de convergence et de precision des methodes d'exploration markovienne sont souvent tres difficiles. Elles ont donne lieu a une intense activite de publication ces 15 dernieres annees (voir le cours recent de Saloff-Coste <ref> [75] </ref>). Nous n'aborderons ces questions que de maniere assez superficielle dans le cadre des cha^ines reversibles. Les deux livres de Duflo [30, 31] constituent une reference de base, d'un niveau sensiblement superieur a celui de ce cours. <p> Il existe dans la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste <ref> [75] </ref> ou Diaconis et Saloff-Coste [26]). Voici une des plus simples. 68 Proposition 4.5 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [75, 26] </ref>. Au vu de la proposition 4.6, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps.
Reference: [76] <author> R. Shonkwiler and E. Van-Vleck. </author> <title> Parallel speed-up of Monte-Carlo methods for global optimization. </title> <journal> J. Complexity, </journal> <volume> 10(1) </volume> <pages> 64-95, </pages> <year> 1994. </year>
Reference-contexts: Signalons enfin que dans de nombreux cas les methodes de Monte-Carlo se pr^etent bien a la parallelisation, sujet que nous n'aborderons pas (voir Shonkwiler et Van Vleck <ref> [76] </ref>, Del Corso [24] et Trouve [82]). 1.3 Prerequis et plan Ce cours a un objectif resolument pratique. Il se veut accessible a tout etudiant du DEA de mathematiques appliquees, ayant recu ou non une formation en probabilites.
Reference: [77] <author> A. Sinclair. </author> <title> Algorithms for random generation and counting: a Markov chain approach. </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1993. </year>
Reference-contexts: Pour certains de ces derniers, on a pu trouver des algo-rithmes de resolution approchee en temps polynomial, a base essentiellement de cha^ines de Markov. Leur etude devient un domaine important de l'informatique theorique (voir Sinclair <ref> [77] </ref> ou Motwani et Raghavan [62]). * Les methodes de Monte-Carlo en statistique. De nombreuses questions d'estimation, de tests ou de representation de donnees se ramenent a des proble-mes numeriques d'optimisation ou de resolution de systemes de grande taille. <p> on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 4.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous [1, 2] (voir aussi <ref> [62, 77] </ref>). L'importance de la simulation des lois uniformes pour les calculs d'integrales a ete montree dans 2.4 et 2.6. Nous avions donne comme methode generale la methode de rejet et signale le rapport entre l'evaluation du volume d'un domaine et la simulation de la loi uniforme sur ce domaine.
Reference: [78] <author> J.L. Snell. </author> <title> Introduction to probability. Random House, </title> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Ce sujet est aborde a niveau elementaire dans de nombreux manuels, par exemple les livres de Bouleau [11], Snell <ref> [78] </ref> ou Berger [9]. <p> Les connaissances probabilistes correspondantes figurent dans tous les manuels classiques, qui vont en general bien au-dela (par exemple Berger [9], Bouleau [11, 12], Breiman [14], Feller [33, 34], Snell <ref> [78] </ref>: : : ). Sur les cha^ines de Markov plus particulierement, les references de base restent Chung [19] et Kemeny et Snell [47]. Un point de vue plus applique est celui de Barucha-Reid [7] et Karlin et Taylor [44, 45]. C inlar [20] est particulierement clair.
Reference: [79] <author> W.J. Stewart. </author> <title> Introduction to the numerical solution of Markov chains. </title> <publisher> Princeton University Press, </publisher> <year> 1995. </year>
Reference-contexts: Il peut m^eme se faire que la taille du probleme soit telle que les methodes deterministes echouent pour des raisons de place en memoire. Par exemple, la taille maximale des systemes lineaires que l'on peut resoudre actuellement est de l'ordre de 10 6 (voir Stewart <ref> [79] </ref>). Dans certains cas, une methode de Monte-Carlo ira bien au-dela. Remarquons egalement que les deux approches peuvent ^etre complementaires. De nombreuses methodes numeriques demandent a ^etre initialisees par une valeur deja assez proche de la solution (par 3 exemple Newton-Raphson).
Reference: [80] <author> D. Talay. </author> <title> Simulation and numerical analysis of stochastic differential systems: a review. </title> <editor> In P. Kree and W. Wedig, editors, </editor> <title> Probabilistic Methods in Applied Physics, </title> <editor> L. N. </editor> <booktitle> in Physics 451, chapter 3, </booktitle> <pages> pages 54-96. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Les quelques exemples que nous donnons ici ne constituent qu'une introduction a un sujet en plein developpement. Les generalisations qui ont ete proposees, et que nous n'aborderons pas, consistent a introduire un certain degre de dependance entre les differentes trajectoires simulees (voir <ref> [80, 38] </ref>). Nous commencons par un exemple, tire de [53]. 3.3.1 Exemple Appliquons la methode du paragraphe 3.2.2 a la discretisation d'un probleme de Dirich-let simple. Soit D le carre unite ouvert, @D son bord. <p> Sur cette coherence entre modelisation deterministe et aleatoire, problemes differentiels et simulation de proces-sus de diffusion, on pourra se reporter a la troisieme partie de Kloeden et Platen [51] ainsi qu'a Talay <ref> [80] </ref> et aux autres articles du m^eme ouvrage. Le rapport entre le mouvement brownien et le laplacien se generalise aux processus de diffusion. Cela fournit le principe de methodes de Monte-Carlo pour la resolution de nombreux problemes differentiels. Nous en donnerons plusieurs exemples dans les paragraphes suivants.
Reference: [81] <author> K.S. Trivedi. </author> <title> Probability and Statistics with Reliability, Queuing and Computer Science Applications. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
Reference: [82] <author> A. Trouve. </author> <title> Parallelisation massive du recuit simule. </title> <institution> These, Universite Paris XI, </institution> <year> 1993. </year>
Reference-contexts: Signalons enfin que dans de nombreux cas les methodes de Monte-Carlo se pr^etent bien a la parallelisation, sujet que nous n'aborderons pas (voir Shonkwiler et Van Vleck [76], Del Corso [24] et Trouve <ref> [82] </ref>). 1.3 Prerequis et plan Ce cours a un objectif resolument pratique. Il se veut accessible a tout etudiant du DEA de mathematiques appliquees, ayant recu ou non une formation en probabilites. Aucune connaissance particuliere, autre qu'un peu de bon sens, ne sera supposee acquise.
Reference: [83] <author> K. Watkins. </author> <title> Discrete event simulation in C. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins <ref> [83] </ref>). * L'analyse probabiliste d'algorithmes. Etudier la complexite d'un algorithme (deterministe) dans le pire ou le meilleur des cas, reflete rarement son comporte-ment sur des donnees courantes.
Reference: [84] <author> G. Winkler. </author> <title> Image analysis, random fields and dynamic Monte-Carlo methods. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Filtrage de Kalman, methodes de fonctions splines (Eubank [32]) ou ondelettes (Antoniadis [4]), algo-rithmes de Robbins-Monro ou Kiefer-Wolfowitz, toute une panoplie de techniques permettent de traiter des donnees bruitees (voir Benveniste et al. [8] pour une reference generale, et <ref> [84] </ref> pour le cas de l'analyse d'images). La aussi notre separation entre les methodes ou le hasard provient du modele et celles ou il est apporte par l'utilisation de la fonction Random est tout a fait artificielle.
Reference: [85] <author> R.W. Wolff. </author> <title> Stochastic Modelling and the Theory of Queues. </title> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliff, </address> <year> 1989. </year> <month> 100 </month>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [51] est la reference indispensable. * La construction et la simulation de modeles stochastiques, par exemple en recherche operationnelle ou automatique (reseaux de files d'attente, systemes a evenements discrets: : : : voir entre autres <ref> [70, 72, 74, 73, 81, 85] </ref>). C'est un sujet suffisamment important pour avoir suscite le developpement de langages de programmation specialises comme SIMULA ou plus recemment MODLINE et QNAP (sur les aspects algorithmiques voir aussi Watkins [83]). * L'analyse probabiliste d'algorithmes.
References-found: 85

