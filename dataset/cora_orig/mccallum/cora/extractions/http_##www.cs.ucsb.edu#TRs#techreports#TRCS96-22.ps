URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS96-22.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Browsing and Placement of Multiresolution Images on Secondary Storage  
Author: Sunil Prabhakar Divyakant Agrawal Amr El Abbadi Ambuj Singh Terence R. Smith 
Date: August 21, 1996  
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: With the rapid advances in computer and communication technologies, there is an increasing demand to build and maintain large image repositories. In order to reduce the demands on I/O and network resources, multiresolution representations of images are being proposed for the storage organization of images. Image decomposition techniques such as wavelets can be used to provide multiple resolution images. The image is represented by several coefficients, one of them with visual similarity to the original image but at a lower resolution. Thus, these visually similar coefficients can be thought of as the thumbnails or icons of the original image. This paper addresses the problem of storing these multiresolution coefficients on disk(s) so that thumbnail browsing as well as image reconstruction can be performed efficiently. Several strategies are evaluated to store the image coefficients on parallel disks. These strategies can be classified into two broad classes depending on whether the browsing pattern of the images is used in the placement of image coefficients. Disk simulation is used to evaluate the performance of these strategies. The data used in the simulation are of two types: the texture samples from the Brodatz collection as well as 50,000 real landsat images. The results indicate that significant performance improvements can be achieved with as few as four disks by placing image coefficients based upon the browsing access patterns. 
Abstract-found: 1
Intro-found: 1
Reference: [AE93] <author> Khaled A. S. Abdel-Ghaffar and Amr El Abbadi. </author> <title> Optimal disk allocation for partial match queries. </title> <journal> ACM Transactions of Database Systems, </journal> <volume> 18(1) </volume> <pages> 132-156, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: This is the case in the relational database setting where the data is structured in tables and accesses are via range or partial match queries. Various schemes have been proposed to improve the performance of these queries. In <ref> [AE93] </ref> Abdel-Ghaffar and El Abbadi develop provably optimal allocation algorithms for partial match queries. In [GD90], three alternative declustering schemes are compared for shared-nothing multiprocessor database machines. Another multidimensional declustering method, called Coordinate Modulo Distribution (CMD), is developed in [LSR92].
Reference: [AMEM95] <author> A. D. Alexandrov, W. Y. Ma, A. El Abbadi, and B. S. Manjunath. </author> <title> Adaptive filtering and indexing for image databases. </title> <booktitle> In Proc. of the SPIE Int. Conf. on Storage and Retrieval for Image and Video Databases - III, </booktitle> <pages> pages 12-23, </pages> <address> San Jose, CA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: These vectors have the property that images that are similar in content will be placed closer in the multidimensional space defined by the vectors. 4 Hence the Euclidean distance between a pair of images gives a quantitative measure of the degree of similarity of their image contents <ref> [AMEM95] </ref>. 3 Related Work Data placement has been an important research topic in the context of database systems [AS95, BG88, CABK88]. The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied [PGK88, CP90].
Reference: [AS95] <author> S. Akyurek and K. Salem. </author> <title> Adaptive block rearrangement. </title> <journal> ACM Trans. on Comp. Systems, </journal> <volume> 13(2) </volume> <pages> 89-121, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: closer in the multidimensional space defined by the vectors. 4 Hence the Euclidean distance between a pair of images gives a quantitative measure of the degree of similarity of their image contents [AMEM95]. 3 Related Work Data placement has been an important research topic in the context of database systems <ref> [AS95, BG88, CABK88] </ref>. The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied [PGK88, CP90]. The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently. <p> Another multidimensional declustering method, called Coordinate Modulo Distribution (CMD), is developed in [LSR92]. When the structure of the data or the access patterns are not well understood, other approaches have been taken to improve I/O performance. In these cases data is generally viewed as independent files. In <ref> [AS95] </ref> a technique which dynamically copies blocks that are frequently accessed to a reserved space in the center of the disk to reduce seek delays is described.
Reference: [BG88] <author> D. Bitton and J. Gray. </author> <title> Disk shadowing. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 331-338, </pages> <address> Los Angeles CA., </address> <month> September </month> <year> 1988. </year>
Reference-contexts: closer in the multidimensional space defined by the vectors. 4 Hence the Euclidean distance between a pair of images gives a quantitative measure of the degree of similarity of their image contents [AMEM95]. 3 Related Work Data placement has been an important research topic in the context of database systems <ref> [AS95, BG88, CABK88] </ref>. The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied [PGK88, CP90]. The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently.
Reference: [Bro66] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists & Designers. </title> <publisher> Dover, </publisher> <address> New York, New York, </address> <year> 1966. </year>
Reference-contexts: Experiments with real disks are also conducted to verify some of the simulation results. The data used in the simulation is of two types. The first set of experiments use 1,856 images based on synthetic texture images taken from the Brodatz album <ref> [Bro66] </ref>. The second set of experiments were conducted on 50,000 landsat images from the Map and Imagery Library at UC Santa Barbara. We conducted experiments both in single user as well as in multi-user environments. <p> Table 1: Table of Disk Parameters for HP 97560 5.2 Results and Analysis The dataset for the experiment consisted of 1,856 texture images from the Brodatz album 1 <ref> [Bro66] </ref>. We decomposed each image by one level using the wavelets technique described earlier to yield a thumbnail and three coefficients, each of size 4 Kilobytes. The images were also processed using the Gabor filters to produce feature vectors each with 24 dimensions.
Reference: [CABK88] <author> G. Copeland, W. Alexander, E. Boughter, and T. Keller. </author> <title> Data placement in Bubba. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 99-108, </pages> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: closer in the multidimensional space defined by the vectors. 4 Hence the Euclidean distance between a pair of images gives a quantitative measure of the degree of similarity of their image contents [AMEM95]. 3 Related Work Data placement has been an important research topic in the context of database systems <ref> [AS95, BG88, CABK88] </ref>. The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied [PGK88, CP90]. The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently. <p> The notion of "Disk Cooling" is introduced in [SWZ94], where data is dynamically redistributed based on the access 5 patterns to yield higher I/O performance. Data placement and declustering in highly parallel systems is studied in <ref> [CABK88] </ref>. The authors show that the static data placement problem is NP-complete. They introduce the notion of the heat of a disk and use it to develop a greedy heuristic for data allocation on disks.
Reference: [Cas96] <author> K. R. Castleman. </author> <title> Digital Image Processing. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1996. </year>
Reference-contexts: The Chabot project is an example of such a system. Due to the multiple copies the storage requirements of this scheme are high. A more storage efficient scheme is to use image decomposition techniques such as wavelets <ref> [Cas96] </ref>. Wavelets transform an image into four image coefficients without incurring any additional storage overhead, and one of the coefficients has visual similarity to the original image. Thus, the visually similar coefficient can be thought of as the thumbnail or icon of the original image. <p> This type of interaction can only be supported by incorporating a content-based search and retrieval mechanism. In this section, we first discuss wavelets to store multiresolution representations of images and then briefly describe some image processing techniques to summarize the contents of images. The wavelets transform <ref> [Cas96] </ref> decomposes images into progressively lower resolutions as follows. Beginning with an original image of size N fi M (for simplicity, assume that N and M are powers of 2), the image is decomposed into four parts, each of size N=2 fi M=2, as shown in Figure 1.
Reference: [CK93] <author> T. Chiueh and R. H. Katz. </author> <title> Multi-resolution video representation for parallel disk arrays. </title> <booktitle> ACM Multimedia, </booktitle> <pages> pages 401-409, </pages> <year> 1993. </year>
Reference-contexts: The coefficients of an image are intimately related, and we have some understanding of the access patterns for browsing and multiresolution image access. Hence we can potentially do better than the more general approaches taken above. In a similar setting, Chiueh and Katz <ref> [CK93] </ref> discuss pyramidal coding schemes for multiresolution video data and a storage layout for this data on parallel disk arrays to provide real time jitter-free video retrieval. They do not however discuss the issue of the relative placement of stripes on each disk for better performance.
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> McGraw-Hill MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: This problem in general has been shown to be NP-complete [GJ79]. However, if we limit the maximum degree of each vertex to d max , then we can find a coloring using d max + 1 colors <ref> [CLR90] </ref>. For such a graph a simple greedy algorithm can be used to find such a coloring. This algorithm assigns colors to nodes in a sequential traversal trying to assign the lowest possible color such that it is different from all colors assigned to its neighbors.
Reference: [CP90] <author> P. M. Chen and D. A. Patterson. </author> <title> Maximizing performance in a striped disk-array. </title> <booktitle> In Proc. of the 17th Int. Sym. on Comp. Architecture, </booktitle> <pages> pages 322-331, </pages> <year> 1990. </year> <month> 26 </month>
Reference-contexts: The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied <ref> [PGK88, CP90] </ref>. The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently. Extensive studies of both the performance and fault tolerance aspects of RAID have been conducted.
Reference: [DK93] <author> A. L. Drapeau and R. H. Katz. </author> <title> Striping in large tape libraries. </title> <booktitle> In Proc. of Supercom--puting, </booktitle> <pages> pages 378-387, </pages> <address> Portland, Oregon, 1993. </address> <publisher> ACM. </publisher>
Reference-contexts: Instead of generating four independent requests to the disks in the second phase, Separated generates a single coarser request to the fourth disk. This reduces the level of contention and the average queuing delays. Similar effects were also observed by Drapeau and Katz <ref> [DK93] </ref> in striping experiments with tape libraries. 22 To test this hypothesis, we ran tests where the expansion of the thumbnails was requested one image at a time rather than as a set. We expected that Separated should not perform better than Bundled in this situation.
Reference: [FBF + 94] <author> C. Faloutsos, R. Barber, M. Flickner, J. Hafner, W. Niblack, D. Petkovic, and W. Eq-uitz. </author> <title> Efficient and effective querying by image content. </title> <journal> In Journal of Intelligent Information Systems, </journal> <volume> volume 3, </volume> <pages> pages 231-262, </pages> <year> 1994. </year>
Reference-contexts: This results in relatively fast browsing of thumbnails, at the cost of slower retrieval of higher resolution images. Another similar project, Query by Image Content at IBM Almaden <ref> [NBE + 93, FBF + 94] </ref> handles querying of images by color, shape and texture. It does not however address the issues of image placement for performance improvement. There appears to be a general lack of placement techniques for image data.
Reference: [GD90] <author> S. Ghandeharizadeh and D. J. DeWitt. </author> <title> A multiuser performance analysis of alternative declustering strategies. </title> <booktitle> In Proc. Int. Conf. Data Engineering, </booktitle> <pages> pages 466-475, </pages> <address> Los Angeles, California., </address> <month> February </month> <year> 1990. </year>
Reference-contexts: Various schemes have been proposed to improve the performance of these queries. In [AE93] Abdel-Ghaffar and El Abbadi develop provably optimal allocation algorithms for partial match queries. In <ref> [GD90] </ref>, three alternative declustering schemes are compared for shared-nothing multiprocessor database machines. Another multidimensional declustering method, called Coordinate Modulo Distribution (CMD), is developed in [LSR92]. When the structure of the data or the access patterns are not well understood, other approaches have been taken to improve I/O performance.
Reference: [GHW90] <author> J. Gray, B. Horst, and M. Walker. </author> <title> Parity striping of disc arrays: Low-cost reliable storage with acceptable throughput. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 148-161, </pages> <address> Washington DC., </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently. Extensive studies of both the performance and fault tolerance aspects of RAID have been conducted. In <ref> [GHW90] </ref> for example, a variation of RAID where only the parity and not the data is striped across disks is shown to yield lower response times and higher throughput. Further improvements in performance have been achieved when the structure of the data and the access patterns are well understood.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Similarly the graph k-colorability problem is to assign colors to nodes in a graph such that no two adjacent nodes have the same color using at most k colors. This problem in general has been shown to be NP-complete <ref> [GJ79] </ref>. However, if we limit the maximum degree of each vertex to d max , then we can find a coloring using d max + 1 colors [CLR90]. For such a graph a simple greedy algorithm can be used to find such a coloring.
Reference: [KSR94] <author> D. Kotz, T. B. Song, and S. Radhakrishnan. </author> <title> A detailed simulation of the HP 97560 disk drive. </title> <type> Technical Report TR94-220, </type> <institution> Comp. Sci. Dept., Dartmouth College., </institution> <year> 1994. </year>
Reference-contexts: Once placement strategies have been studied, confirmation of the results will be done using real disks. The simulator that we used has been developed by Kotz et al. <ref> [KSR94] </ref> based on the model developed by Ruemmler and Wilkes of HP laboratories [RW94]. The model is sophisticated and is capable of simulating multiple disks connected to multiple I/O buses. to have a model of the usage patterns. <p> The use of four disks allows us to investigate inter-disk parallelism for seeking. The modeled disk is the HP 97560 disk. Some of the parameters of these disks are given in Table 1. Further details of the disk and the model can be found in [RW94] and <ref> [KSR94] </ref>. Although the specified size of the cache for the HP 97560 is 128 Kilobytes, we limited the cache to 4 Kilobytes, in order to study the placement strategies in the absence of caching. Note that 4 Kilobytes is the size of the thumbnail and each coefficient of the images.
Reference: [LSR92] <author> J. Li, J. Srivastava, and D. Rotem. CMD: </author> <title> a multidimensional declustering method for parallel database systems. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 3-14, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In [AE93] Abdel-Ghaffar and El Abbadi develop provably optimal allocation algorithms for partial match queries. In [GD90], three alternative declustering schemes are compared for shared-nothing multiprocessor database machines. Another multidimensional declustering method, called Coordinate Modulo Distribution (CMD), is developed in <ref> [LSR92] </ref>. When the structure of the data or the access patterns are not well understood, other approaches have been taken to improve I/O performance. In these cases data is generally viewed as independent files.
Reference: [MM94] <author> W. Y. Ma and B. S. Manjunath. </author> <title> Pictorial queries: Combining feature extraction with database search. </title> <type> Technical Report CIPR 94-18, </type> <institution> Univ. of California, Santa Barbara, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content [NBE + 93, OS95]. We used the Gabor Transform <ref> [MM94] </ref> to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space. <p> These images were supplemented with other textures to a total of 116. Each of the images was divided into 16 sub-images <ref> [MM94] </ref>. 12 size. Therefore for each expansion scheme, each strategy and each set size, an aggregate figure was computed which gives the average ratio of access times of the Random placement strategy to the respective strategy.
Reference: [NBE + 93] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, and P. Yanker. </author> <title> The QBIC project: Querying images by content using color, texture and shape. </title> <booktitle> In Proc. of the SPIE Conf. 1908 on Storage and Retrieval for Image and Video Databases, volume 1908, </booktitle> <pages> pages 173-187, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Two examples of such repositories are the fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330 and NSF instrumentation grant CDA-9421978. Chabot project [OS95] and the IBM Almaden Center's QBIC project <ref> [NBE + 93] </ref>. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. The Alexandria project at UC Santa Barbara [SF95] has been initiated to build a digital library for maps and image data, typically stored in raster or vector format. <p> Thus multiresolution image retrieval seems to be the key to providing efficient browsing of image data. This retrieval model is employed both in the QBIC <ref> [NBE + 93] </ref> system as well as the Chabot [OS95] project. One method of providing images at multiple resolutions is storing multiple copies of images at various resolutions. The Chabot project is an example of such a system. <p> In this paper, the process of reconstructing an image by one level is referred to as expansion of the image. Content based browsing refers to retrieving images based on the similarity of the visual information contained in the images <ref> [NBE + 93, OS95] </ref>. For example, having seen a specific hurricane image, a user may want to see similar images of hurricanes. In order to evaluate the similarity of images, one would first quantify the image content using several possible techniques. <p> This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content <ref> [NBE + 93, OS95] </ref>. We used the Gabor Transform [MM94] to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space. <p> This results in relatively fast browsing of thumbnails, at the cost of slower retrieval of higher resolution images. Another similar project, Query by Image Content at IBM Almaden <ref> [NBE + 93, FBF + 94] </ref> handles querying of images by color, shape and texture. It does not however address the issues of image placement for performance improvement. There appears to be a general lack of placement techniques for image data.
Reference: [OS95] <author> V. E. Ogle and M. Stonebraker. Chabot: </author> <title> Retrieval from a relational database of images. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 41-48, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction With the rapid advances in computer and communication technologies, there is an increasing de mand to build and maintain large image repositories. Two examples of such repositories are the fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330 and NSF instrumentation grant CDA-9421978. Chabot project <ref> [OS95] </ref> and the IBM Almaden Center's QBIC project [NBE + 93]. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. <p> Thus multiresolution image retrieval seems to be the key to providing efficient browsing of image data. This retrieval model is employed both in the QBIC [NBE + 93] system as well as the Chabot <ref> [OS95] </ref> project. One method of providing images at multiple resolutions is storing multiple copies of images at various resolutions. The Chabot project is an example of such a system. Due to the multiple copies the storage requirements of this scheme are high. <p> In this paper, the process of reconstructing an image by one level is referred to as expansion of the image. Content based browsing refers to retrieving images based on the similarity of the visual information contained in the images <ref> [NBE + 93, OS95] </ref>. For example, having seen a specific hurricane image, a user may want to see similar images of hurricanes. In order to evaluate the similarity of images, one would first quantify the image content using several possible techniques. <p> This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content <ref> [NBE + 93, OS95] </ref>. We used the Gabor Transform [MM94] to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space. <p> They do not however discuss the issue of the relative placement of stripes on each disk for better performance. This work is not directly applicable outside the context of video data. The Chabot project currently underway at UC Berkeley <ref> [OS95] </ref> is also concerned with the retrieval of multiresolution images (although each image is stored at different resolution levels and thus incurs additional storage overheads when compared to wavelets). <p> The Separated placement strategy differs from the others in that the thumbnails are placed on only three disks and all the other three coefficients are placed together on the fourth disk. This storage organization is similar to the placement of data in the Chabot project at UC Berkeley <ref> [OS95] </ref> where the lowest-resolution images or thumbnails are stored on disks and all higher resolution images are stored in tertiary storage (which is in contrast to the fourth disk in the Separated placement strategy).
Reference: [PGK88] <author> D. A. Patterson, G. Gibson, and R. H. Katz. </author> <title> A case for Redundant Arrays of Inexpensive Disks (RAID). </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 109-116, </pages> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: The technique of striping data across multiple disks to overcome the I/O bottleneck has been extensively studied <ref> [PGK88, CP90] </ref>. The improvements in performance are essentially because large requests are serviced in parallel by multiple disks and multiple small requests are handled concurrently. Extensive studies of both the performance and fault tolerance aspects of RAID have been conducted.
Reference: [RW94] <author> Chris Ruemmler and John Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> March </month> <year> 1994. </year> <month> 27 </month>
Reference-contexts: Once placement strategies have been studied, confirmation of the results will be done using real disks. The simulator that we used has been developed by Kotz et al. [KSR94] based on the model developed by Ruemmler and Wilkes of HP laboratories <ref> [RW94] </ref>. The model is sophisticated and is capable of simulating multiple disks connected to multiple I/O buses. to have a model of the usage patterns. For the experiments conducted on the Texture images, we worked with only a single user. <p> The use of four disks allows us to investigate inter-disk parallelism for seeking. The modeled disk is the HP 97560 disk. Some of the parameters of these disks are given in Table 1. Further details of the disk and the model can be found in <ref> [RW94] </ref> and [KSR94]. Although the specified size of the cache for the HP 97560 is 128 Kilobytes, we limited the cache to 4 Kilobytes, in order to study the placement strategies in the absence of caching.
Reference: [SF95] <author> T. R. Smith and J. Frew. </author> <title> Alexandria digital library. </title> <journal> Communications of the ACM, </journal> <volume> 38(4) </volume> <pages> 61-62, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Chabot project [OS95] and the IBM Almaden Center's QBIC project [NBE + 93]. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. The Alexandria project at UC Santa Barbara <ref> [SF95] </ref> has been initiated to build a digital library for maps and image data, typically stored in raster or vector format.
Reference: [SRH90] <author> M. Stonebraker, L. A. Rowe, and M. Hirohama. </author> <title> The implementation of POSTGRES. </title> <journal> In IEEE Trans. on Knowledge and Data Eng., </journal> <volume> volume 2, </volume> <pages> pages 125-142, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The allocation strategy followed in Chabot is to place all thumbnails and metadata about thumbnails on disk using POSTGRES <ref> [SRH90] </ref>, and all higher resolution images on tertiary storage. This results in relatively fast browsing of thumbnails, at the cost of slower retrieval of higher resolution images.
Reference: [SWZ94] <author> P. Scheuermann, G. Weikum, and P. Zabback. </author> <title> "Disk Cooling" in parallel disk systems. </title> <journal> Bulletin of the Technical Committee on Data Engineering, </journal> <volume> 17(3) </volume> <pages> 29-40, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In these cases data is generally viewed as independent files. In [AS95] a technique which dynamically copies blocks that are frequently accessed to a reserved space in the center of the disk to reduce seek delays is described. The notion of "Disk Cooling" is introduced in <ref> [SWZ94] </ref>, where data is dynamically redistributed based on the access 5 patterns to yield higher I/O performance. Data placement and declustering in highly parallel systems is studied in [CABK88]. The authors show that the static data placement problem is NP-complete.
References-found: 25

