URL: ftp://ftp.cs.umd.edu/pub/realtime/slice_schedule.ps.gz
Refering-URL: http://www.cs.umd.edu/projects/TimeWare/TimeWare-index-no-abs.html
Root-URL: 
Email: rich@cs.umd.edu  sshong@redwood.snu.ac.kr  
Title: Slicing Real-Time Programs for Enhanced Schedulability  
Author: Richard Gerber Seongsoo Hong 
Keyword: Real-time, programming languages, event-based semantics, compiler optimization, program slicing, system-tuning, static priority scheduling, priority assignment.  
Address: College Park, MD 20742  Seoul, 151-742, Korea  
Affiliation: Department of Computer Science University of Maryland  Engineering Research Center (ERC-ACI) School of Electrical Engineering Seoul National University  
Abstract: In this paper we present a compiler-based technique to help develop correct real-time systems. The domain we consider is that of multi-programmed real-time applications, in which periodic tasks control physical systems via interacting with external sensors and actuators. While a system is up and running, these operations must be performed as specified otherwise the system may fail. Correctness depends not only on each program individually, but also on the time-multiplexed behavior of all of the programs running together. Errors due to overloaded resources are exposed very late in a development process, and often at runtime. They are usually remedied by human-intensive activities such as instrumentation, measurement, code tuning and redesign. We describe a static alternative to this process, which relies on well-accepted technologies from optimizing compilers and fixed-priority scheduling. Specifically, when a set of tasks are found to be overloaded, a scheduling analyzer determines candidate tasks to be transformed via program slicing. The slicing engine decomposes each of the selected tasks into two fragments: one that is "time-critical," and the other "unobservable." The unobservable part is then spliced to the end of the time-critical code, with the external semantics being maintained. The benefit is that the scheduler may postpone the unobservable code beyond its original deadline, which can enhance overall schedulability. While the optimization is completely local, the improvement is realized globally, for the entire task set. fl This research is supported in part by ONR grant N00014-94-10228, NSF grant CCR-9209333, an NSF Young Investigator Award CCR-9357850. An earlier version of this paper appeared in preliminary form in the Proceedings of IEEE Real-Time System Symposium, (December 1993). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: In [33] Arnold et al. presented a timing prediction method called static cache simulation to statically analyze memory and cache reference patterns. In [26] Lim et al. describe an timing analysis tool based on a model called the extended timing schema. This approach essentially relies on attribute grammars <ref> [1] </ref> to backward-propagate cache and pipeline information in the program's syntax tree. Using this technique, the tool rules out provably ineligible execution paths from a task, and this streamlines the process of finding its real worst-case paths and hence, bounding its execution time. <p> Note that time of t 0 can easily exceed that of the original t , since (1) control structures are replicated and executed twice; and (2) splitting basic blocks may increase the number of register load and store operations <ref> [1] </ref>. 4.2 Practical Considerations As we have stated, the above presentation of real-time slicing is rather idealized; we abstracted out some of the practical considerations that one would have to face when building a production-quality tool.
Reference: [2] <author> N. Audsley, A. Burns, M. Richardson, K. Tindell, and A. Wellings. </author> <title> Applying new scheduling theory to static priority preemptive scheduling. </title> <journal> Software Engineering Journal, </journal> <month> September </month> <year> 1993. </year>
Reference-contexts: In the above table the row order corresponds to the priority order; i.e., t 1 is assigned the highest priority. We can carry out the response time 2 Variants of this method are presented in <ref> [2, 23] </ref>; proofs of its correctness can be found in these sources. 13 every 16ms f L1: input (Sensor, &data); L2: if (!null (data)) f L3: t1 = F1 (state); L4: t2 = F2 (state, t5); L5: t3 = F3 (data); L6: t4 = F4 (data); L7: t5 = F5 (t1, <p> The proof that conditions (1) and (2) are both necessary and sufficient for schedulability follows directly from the theory of o*ine analysis presented in <ref> [2] </ref>. (Interested readers are encouraged to consult that paper for details.) We combine several of the results from [4] into a single algorithm Feasible in Figure 13, which checks both condition (1) and condition (2) at the same time.
Reference: [3] <author> A. Burns, K. Tindell, and A. Wellings. </author> <title> Effective analysis for engineering real-time fixed priority schedulers. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(5) </volume> <pages> 475-480, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: The online dispatcher makes sure that the highest-priority active task always has use of the CPU; if necessary, this is achieved by preempting a lower-priority task. As depicted in Figure 5, this scheme can easily be implemented by using two kernel-level queues: a run queue and a delay queue <ref> [20, 3] </ref>. The run queue is sorted by priority, and it holds tasks which have been invoked to execute, but are not yet finished where the head of the queue contains the currently running task. <p> There are some simple engineering solutions which can be used to avoid these two simplifications, and they explicitly incorporate kernel overhead into the o*ine scheduling analysis <ref> [20, 3] </ref>. Given our problem components, assigning a static priority ordering to the tasks is easy - Liu and Layland's rate-monotonic result [28] tells us that priorities should be assigned in rate-order, with the highest-rate task getting the highest priority, and so on.
Reference: [4] <author> Alan Burns. </author> <title> Preemptive Priority-Based Scheduling: An Appropriate Engineering Approach, </title> <booktitle> chapter 10, </booktitle> <pages> pages 225-248. </pages> <publisher> Prentice Hall, </publisher> <year> 1994. </year> <title> In Principles of Real-Time Systems, edited by Sang S. </title> <publisher> Son. </publisher>
Reference-contexts: Recently, a group of researchers at the University of York developed a set of analytical techniques which can provide schedulability tests for broad classes of tasks, including those whose deadlines are greater than their periods <ref> [4, 37] </ref>. (Note that the deadline and the period of a task are two distinct timing constraints, e.g., the period denotes the spacing between task instances, whereas the deadline denotes the permissable input-to-output propagation delay for each instance.) But a scheduling analyzer can do little when it determines that a task <p> Its weakness is that the online component lacks the simplicity found in pure, static priority scheduling. The dual-priority scheme mandates a dynamic priority-exchange mechanism, which in turn requires additional kernel support. Burns <ref> [4] </ref> pointed out these limitations, and presented an alternative in which each task is only given a single static priority thereby obviating the extra kernel support necessary. <p> p or below will not affect those above p. 4 For n tasks, n denotes the lowest priority level, and 1 the highest. 24 To determine whether a sliced task t i ( t IO i ; t State i ) can run at priority p, the o*ine analyzer in <ref> [4] </ref> basically checks whether the following conditions hold: (1) There exists some integer k 0, such that the k th complete instance of t i finishes by time (k + 1)T i . <p> The proof that conditions (1) and (2) are both necessary and sufficient for schedulability follows directly from the theory of o*ine analysis presented in [2]. (Interested readers are encouraged to consult that paper for details.) We combine several of the results from <ref> [4] </ref> into a single algorithm Feasible in Figure 13, which checks both condition (1) and condition (2) at the same time. It also incorporates the scheduling analysis for non-sliced tasks, previously presented in Section 3.2. <p> Whereas Burns' algorithm expects that all tasks in are sliced before they are 27 submitted for priority assignment <ref> [4] </ref>, we also need a way to determine whether or not to slice in the first place. It is typically not desirable to blindly slice all tasks, due to execution time overhead incurred.
Reference: [5] <author> R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and F. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13 </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: F4 (data); L7: t5 = F5 (t1, data); L8: state = F6 (t1, t2, t3); L9: cmd = F7 (t1, t4, t5); L10: output (Actuator, cmd); g L11: status dump ("logfile", cmd, state); 22 Such a procedure is called a rename transformation, and is frequently used in many optimizing compilers <ref> [6, 5] </ref>. <p> side of the assignment "x = f (y)" is stored in a temporary variable "x.n," the anti-dependence on "x" is broken. (Note that special care must be taken of such variables that are defined within a loop.) For additional information on issues associated with renaming, we refer the reader to <ref> [6, 5] </ref>. If we slice the code in Figure 12, we obtain a smaller IO slice which includes more statements but takes less time to execute as below.
Reference: [6] <author> R. Cytron, A. Lowry, and K. Zadeck. </author> <title> Code motion of control structures in high-level languages. </title> <booktitle> In Conference Record 13th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 70-85. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1986. </year>
Reference-contexts: F4 (data); L7: t5 = F5 (t1, data); L8: state = F6 (t1, t2, t3); L9: cmd = F7 (t1, t4, t5); L10: output (Actuator, cmd); g L11: status dump ("logfile", cmd, state); 22 Such a procedure is called a rename transformation, and is frequently used in many optimizing compilers <ref> [6, 5] </ref>. <p> The key idea is presented in <ref> [6] </ref>: to (1) split every assignment of form "x = f (y)" into "x.n = f (y); x = x.n" and (2) change all uses of "x" by the corresponding "x.n." Since the left-hand side of the assignment "x = f (y)" is stored in a temporary variable "x.n," the anti-dependence <p> side of the assignment "x = f (y)" is stored in a temporary variable "x.n," the anti-dependence on "x" is broken. (Note that special care must be taken of such variables that are defined within a loop.) For additional information on issues associated with renaming, we refer the reader to <ref> [6, 5] </ref>. If we slice the code in Figure 12, we obtain a smaller IO slice which includes more statements but takes less time to execute as below.
Reference: [7] <author> B. Dasarathy. </author> <title> Timing constraints of real-time systems: Constructs for expressing them, method for validating them. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11(1) </volume> <pages> 80-86, </pages> <month> Jan-uary </month> <year> 1985. </year>
Reference-contexts: Functional specifications define valid translations from inputs into outputs. As such they are realized by a set of programs, which consume CPU time. Temporal requirements, on the other hand, place upper and lower bounds between occurrences of events <ref> [7, 18] </ref>. An example is "the robot arm must receive a next-position update every 10 ms." Such a constraint arises from the system's requirements, or from a detailed analysis of the application environment. Temporal requirements implicitly limit the time that can be provided by the system's resources.
Reference: [8] <author> J. Ferrante and K. Ottenstein. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9 </volume> <pages> 319-345, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Slicing has greatly evolved since its birth in [42], and many newer algorithms effectively address the problems mentioned above. We have chosen a slicing algorithm based a formalism known as the program dependence graph <ref> [8, 17, 30] </ref>. A program dependence graph is a suitable data structure for slicing, mainly because it integrates both data and control flows into a single graph, and thus reduces program slicing into a graph walk problem [30]. <p> As a consequence we will avoid discussing the complications associated with slicing in the presence of unrestricted control-flow. Also, our definition of control dependence can be made simpler than that found in <ref> [8] </ref>. The price we may pay, however, is a lack of generality.
Reference: [9] <author> J. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 30 </volume> <pages> 478-490, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Finally, in [11, 16] we show how to use event-based semantics to help correct faults within a single task. (Such a problem can occur when the task's execution time stretches over its specified deadline.) The transformation algorithm corrects such faults using a variant of Trace Scheduling <ref> [9] </ref>, in which worst-case paths of the infeasible task are selected, and then unobservable code is moved to shorten their execution time. However the approach in [11, 16] is limited to intra-task code scheduling, and does not address the global types of real-time task scheduling issues in this paper.
Reference: [10] <author> R. Gerber and S. Hong. </author> <title> Semantics-based compiler transformations for enhanced schedulabil-ity. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 232-242. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: This fact implies that a rate-monotonic priority assignment may not be the optimal one. Moreover, the response-time equation (Eq 1) in Section 3.2 is no longer the right test for schedulability. (It is overly conservative.) In <ref> [10] </ref> we present a RMS-based method, in which each sliced task is considered as two separate tasks during schedulability analysis. Thus each original task receives two priorities, one for t IO and one for t State .
Reference: [11] <author> R. Gerber and S. Hong. </author> <title> Compiling real-time programs with timing constraint refinement and structural code motion. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(5) </volume> <pages> 389-404, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: In [45] an approach to speculative execution is postulated for distributed real-time systems. The idea is that the speculative "shadow threads" are forked off to execute on available resources. This type of transformation can be viewed as an application of Weiser's slicing-and-splicing technique [41], as described above. Finally, in <ref> [11, 16] </ref> we show how to use event-based semantics to help correct faults within a single task. (Such a problem can occur when the task's execution time stretches over its specified deadline.) The transformation algorithm corrects such faults using a variant of Trace Scheduling [9], in which worst-case paths of the <p> However the approach in <ref> [11, 16] </ref> is limited to intra-task code scheduling, and does not address the global types of real-time task scheduling issues in this paper. <p> All of the above approaches may contribute to achieving schedulability, and some are complementary to ours. E.g., the partial evaluator in [29] will propagate compile-time values through the source, hopefully producing a residual which takes less time. And our prior work on correcting timing faults within single tasks <ref> [11, 16] </ref> is certainly a precondition to achieving global schedulability. But to our knowledge, real-time task slicing is the first method which works hand-in-hand with a scheduling analyzer, with the goal of achieving deterministic, global schedulability of an entire task set. Timing Analysis.
Reference: [12] <author> R. Gerber, S. Hong, and Manas Saksena. </author> <title> Guaranteeing real-time requirements with resource-based calibration of periodic processes. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(7) </volume> <pages> 579-592, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: A real-time scheduler decides when each task gets the CPU. The particular scheduling discipline can either be preemptive or nonpreemptive. Other than that, the tasks are considered mutually independent although non-blocking communication can often be enforced through the assignment of timing constraints, and via copy-in/copy-out operations <ref> [12] </ref>. 1 This traditional model, while very simple, has been the reference point for most advances in the area of real-time systems. It has been generalized to accommodate distributed systems, network protocols, shared databases [19, 34], etc. Real-Time Task Slicing.
Reference: [13] <author> P. Gopinath and R. Gupta. </author> <title> Applying compiler techniques to scheduling in real-time systems. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 247-256. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1990. </year>
Reference-contexts: There has been a variety of work within the category of code transformation for real-time programming. These approaches, while addressing different problems associated with real-time programming, share the goal of enhancing the predictability and schedulability of programs. In <ref> [13] </ref> a compiler tool classifies an application program on the basis of its predictability and monotonicity, and creates partitions which have a higher degree of adaptability.
Reference: [14] <author> M. Harmon, T. Baker, and D. Whalley. </author> <title> A retargetable technique for predicting execution time. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 68-77. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1992. </year>
Reference-contexts: Yet static analysis is developing at a rapid pace, and tools are now being produced which can yield tighter results. The technique reported in [31] is based on a simple source-level timing schema, and it is fairly straightforward to implement in a tool. In <ref> [14] </ref> another approach for more accurate timing is proposed; the resulting tool was able to analyze micro-instruction streams using machine-description rules, and thus it was retargetable to various architectures.
Reference: [15] <author> L. Hendren, J. Hummel, and A. Nicolau. </author> <title> Abstractions for recursive pointer data structures: Improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 249-260. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: And at worst, we will end up with code that appears totally unsliceable when it may, in fact, be amenable to slicing. Fortunately, dependence analyzers are improving at a fast rate (see <ref> [15, 32] </ref>), and our algorithm will improve along with them. Also, as a last resort, a developer can obtain better slices by manually disambiguating some of memory references.
Reference: [16] <author> S. Hong and R. Gerber. </author> <title> Compiling real-time programs into schedulable code. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation. </booktitle> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year> <journal> SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 166-176. </pages>
Reference-contexts: In [45] an approach to speculative execution is postulated for distributed real-time systems. The idea is that the speculative "shadow threads" are forked off to execute on available resources. This type of transformation can be viewed as an application of Weiser's slicing-and-splicing technique [41], as described above. Finally, in <ref> [11, 16] </ref> we show how to use event-based semantics to help correct faults within a single task. (Such a problem can occur when the task's execution time stretches over its specified deadline.) The transformation algorithm corrects such faults using a variant of Trace Scheduling [9], in which worst-case paths of the <p> However the approach in <ref> [11, 16] </ref> is limited to intra-task code scheduling, and does not address the global types of real-time task scheduling issues in this paper. <p> All of the above approaches may contribute to achieving schedulability, and some are complementary to ours. E.g., the partial evaluator in [29] will propagate compile-time values through the source, hopefully producing a residual which takes less time. And our prior work on correcting timing faults within single tasks <ref> [11, 16] </ref> is certainly a precondition to achieving global schedulability. But to our knowledge, real-time task slicing is the first method which works hand-in-hand with a scheduling analyzer, with the goal of achieving deterministic, global schedulability of an entire task set. Timing Analysis.
Reference: [17] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interprocedural slicing using dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12 </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Slicing has greatly evolved since its birth in [42], and many newer algorithms effectively address the problems mentioned above. We have chosen a slicing algorithm based a formalism known as the program dependence graph <ref> [8, 17, 30] </ref>. A program dependence graph is a suitable data structure for slicing, mainly because it integrates both data and control flows into a single graph, and thus reduces program slicing into a graph walk problem [30]. <p> This has the greatest impact when we are confronted with function calls. Note that in this paper we do not treat interprocedural slicing <ref> [17] </ref>, another difficult problem. Rather, our algorithm will either include the entire call within a slice, or not include it and its decision will be based on static dependence analysis.
Reference: [18] <author> F. Jahanian and A. Mok. </author> <title> Safety analysis of timing properties in real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12(9) </volume> <pages> 890-904, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Functional specifications define valid translations from inputs into outputs. As such they are realized by a set of programs, which consume CPU time. Temporal requirements, on the other hand, place upper and lower bounds between occurrences of events <ref> [7, 18] </ref>. An example is "the robot arm must receive a next-position update every 10 ms." Such a constraint arises from the system's requirements, or from a detailed analysis of the application environment. Temporal requirements implicitly limit the time that can be provided by the system's resources.
Reference: [19] <author> K. Jeffay. </author> <title> The real-time producer/consumer paradigm: A paradigm for the construction of efficient, predictable real-time systems. </title> <booktitle> In ACM/SIGAPP Symposium on Applied Computing, </booktitle> <pages> pages 796-804. </pages> <publisher> ACM Press, </publisher> <month> February </month> <year> 1983. </year>
Reference-contexts: It has been generalized to accommodate distributed systems, network protocols, shared databases <ref> [19, 34] </ref>, etc. Real-Time Task Slicing. Consider a construct such as "every 10ms do B," which denotes that the block B is dispatched at times 0, 10, 20, 30, etc.
Reference: [20] <author> D. Katcher, H. Arakawa, and J. Strosnider. </author> <title> Engineering and analysis of fixed priority sched-ulers. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(9), </volume> <month> September </month> <year> 1993. </year>
Reference-contexts: The online dispatcher makes sure that the highest-priority active task always has use of the CPU; if necessary, this is achieved by preempting a lower-priority task. As depicted in Figure 5, this scheme can easily be implemented by using two kernel-level queues: a run queue and a delay queue <ref> [20, 3] </ref>. The run queue is sorted by priority, and it holds tasks which have been invoked to execute, but are not yet finished where the head of the queue contains the currently running task. <p> There are some simple engineering solutions which can be used to avoid these two simplifications, and they explicitly incorporate kernel overhead into the o*ine scheduling analysis <ref> [20, 3] </ref>. Given our problem components, assigning a static priority ordering to the tasks is easy - Liu and Layland's rate-monotonic result [28] tells us that priorities should be assigned in rate-order, with the highest-rate task getting the highest priority, and so on.
Reference: [21] <author> E. Kligerman and A. Stoyenko. </author> <title> Real-Time Euclid: A language for reliable real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12 </volume> <pages> 941-949, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: This type of program is the most common building-block found in real-time applications. In real-time programming environments (e.g., see the experimental languages in <ref> [21, 27, 29, 43] </ref>) a construct such as "every t do B" denotes that the program fragment B is dispatched at times 0, t, 2t, etc. * A task set (denoted = ft 1 ; : : : ; t n g) is a collection of time-multiplexed, periodic tasks, which are
Reference: [22] <author> J. Krause. </author> <title> GN&C domain modeling: Functionality requirements for fixed rate algorithms. </title> <type> Technical Report (DRAFT) version 0.2, </type> <institution> Honeywell Systems and Research Center, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Since discrete control 9 software possesses many representative properties that can be found in other applications (e.g., multimedia, vision, etc.), this discussion has close analogues in other types of real-time systems. 3.1 Characterization of Discrete Control Software Many discrete control algorithms possess computations that fit a fixed-rate algorithm paradigm <ref> [22] </ref>, i.e., control-loops which execute repetitively with fixed periods. During each period, the physical world measurement data are sampled, and then actuator commands are computed. Meanwhile, a set of states is updated based on the current state and the sampled data.
Reference: [23] <author> J. Lehoczky. </author> <title> Fixed-priority scheduling of periodic task sets with arbitrary deadlines. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 201-209. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1990. </year>
Reference-contexts: In the above table the row order corresponds to the priority order; i.e., t 1 is assigned the highest priority. We can carry out the response time 2 Variants of this method are presented in <ref> [2, 23] </ref>; proofs of its correctness can be found in these sources. 13 every 16ms f L1: input (Sensor, &data); L2: if (!null (data)) f L3: t1 = F1 (state); L4: t2 = F2 (state, t5); L5: t3 = F3 (data); L6: t4 = F4 (data); L7: t5 = F5 (t1,
Reference: [24] <author> J. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotonic scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 166-171. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1989. </year>
Reference-contexts: If a task can meet its deadline during this period, it will succeed in all other task phasings, too. (This fact is used in the proof of Liu and Layland's result [28]; it has also led to necessary and sufficient tests for general static-priority schedulers <ref> [24, 37] </ref>.) Using this fact, we can determine the schedulability of the entire task set by incrementally checking whether each task is schedulable.
Reference: [25] <author> J. Leung and M. Merill. </author> <title> A note on the preemptive scheduling of periodic, real-time tasks. </title> <journal> Information Processing Letters, </journal> <volume> 11(3) </volume> <pages> 115-118, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: They also showed that such priority assignment is optimal, in the sense that whenever it fails to find a feasible priority ordering, so will any other static priority ordering. Recent research has generalized this result. In <ref> [25] </ref> Leung and Merrill showed that a deadline-monotonic priority assignment is also optimal where deadlines may be shorter than periods. (This case arises where a task is invoked periodically, but where it also possesses an "internal deadline" within its period.
Reference: [26] <author> S. Lim, Y. Bae, C. Jang, B. Rhee, S. Min, C. Park, H. Shin, K. Park, and C. Kim. </author> <title> An accurate worst case timing analysis for risc processors. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 97-108. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year>
Reference-contexts: In [33] Arnold et al. presented a timing prediction method called static cache simulation to statically analyze memory and cache reference patterns. In <ref> [26] </ref> Lim et al. describe an timing analysis tool based on a model called the extended timing schema. This approach essentially relies on attribute grammars [1] to backward-propagate cache and pipeline information in the program's syntax tree. <p> However, no static timing tool is precise enough to be used with complete confidence for developing production-quality software. Moreover, even sophisticated timing analysis methods such as <ref> [26, 33] </ref> are not appropriate for fine-grained instruction timing. In Section 4.2 we explain how on can use these tools in spite of the limitations, by taking advantage of software profiling, as well as static timing prediction.
Reference: [27] <author> K. Lin and S. Natarajan. </author> <title> Expressing and maintaining timing constraints in FLEX. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1988. </year>
Reference-contexts: This type of program is the most common building-block found in real-time applications. In real-time programming environments (e.g., see the experimental languages in <ref> [21, 27, 29, 43] </ref>) a construct such as "every t do B" denotes that the program fragment B is dispatched at times 0, t, 2t, etc. * A task set (denoted = ft 1 ; : : : ; t n g) is a collection of time-multiplexed, periodic tasks, which are
Reference: [28] <author> C. Liu and J. Layland. </author> <title> Scheduling algorithm for multiprogramming in a hard real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: Then they are fed to the slicer, after which the entire task set is again tested for schedulability. Task Set, Priority Ordering Algorithm (Schedulability Tests) Tasks To Be Sliced Schedulable Priority Order Task Slicer success failure Period Constraints While our use of the "classical real-time model" <ref> [28] </ref> allows us to concentrate on the issue of real-time slicing, it does not reduce the utility of our approach. For example, most distributed scheduling algorithms use uniprocessor algorithms at each node 1 and our method can be adapted there as well. Remainder of the Paper. <p> This provides a quick way to test whether a given priority assignment will work; hence, it can also guide assigning the priorities in the first place. Rate-monotonic scheduling, originally developed by Liu and Layland, was the first well-known result of this kind. In their seminal paper <ref> [28] </ref> they proposed a scheme in which tasks are assigned 5 priorities in inverse-order to their periods (hence the name rate-monotonic scheduling, or RMS). <p> There are some simple engineering solutions which can be used to avoid these two simplifications, and they explicitly incorporate kernel overhead into the o*ine scheduling analysis [20, 3]. Given our problem components, assigning a static priority ordering to the tasks is easy - Liu and Layland's rate-monotonic result <ref> [28] </ref> tells us that priorities should be assigned in rate-order, with the highest-rate task getting the highest priority, and so on. This assignment is optimal, 12 i.e., whenever the tasks can be scheduled with some other priority ordering, the rate-monotonic assignment would have worked, too. <p> If a task can meet its deadline during this period, it will succeed in all other task phasings, too. (This fact is used in the proof of Liu and Layland's result <ref> [28] </ref>; it has also led to necessary and sufficient tests for general static-priority schedulers [24, 37].) Using this fact, we can determine the schedulability of the entire task set by incrementally checking whether each task is schedulable. <p> Note that our new task set relaxes the classical model put forth in <ref> [28] </ref>: now some tasks may finish after their periods are over. This fact implies that a rate-monotonic priority assignment may not be the optimal one. <p> During the interval starting at 0, and ending at the time when instance M ends, all requests that arise for the CPU get satisfied. Recall that the worst-case CPU load is highest within this interval, since all tasks originally get released simultaneously <ref> [28] </ref>. So after instance M ends, either the utilization demand remains at 1, or it drops off. Either way the utilization does not exceed 1. Condition (2) is required by the event-based semantics, in which the IO-handler always must complete within its time frame.
Reference: [29] <author> V. Nirkhe. </author> <title> Application of Partial Evaluation to Hard Real-Time Programming. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland at College Park, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: This type of program is the most common building-block found in real-time applications. In real-time programming environments (e.g., see the experimental languages in <ref> [21, 27, 29, 43] </ref>) a construct such as "every t do B" denotes that the program fragment B is dispatched at times 0, t, 2t, etc. * A task set (denoted = ft 1 ; : : : ; t n g) is a collection of time-multiplexed, periodic tasks, which are <p> Specifically, the tool denotes whether a piece of code belongs in one of four classes; based on this classification, programs are rearranged to help support adaptive run-time scheduling. The objective is to produce a transformed program possessing a smaller variance in its execution time. In <ref> [29] </ref> a partial evaluator is applied to a source program, which produces residual code that is both more optimized and more deterministic. In [45] an approach to speculative execution is postulated for distributed real-time systems. <p> Its transformations are guided by an analytic measure of schedulability, which is used as its primary optimization criterion. All of the above approaches may contribute to achieving schedulability, and some are complementary to ours. E.g., the partial evaluator in <ref> [29] </ref> will propagate compile-time values through the source, hopefully producing a residual which takes less time. And our prior work on correcting timing faults within single tasks [11, 16] is certainly a precondition to achieving global schedulability.
Reference: [30] <author> K. Ottenstein and L. Ottenstein. </author> <title> The program dependence graph in a software development environment. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 177-184, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: As a last resort, entire subsystems may have to be re-designed altogether. In this paper we present a static alternative to this process, which is based on two interrelated components: a compiler transformation known as program slicing <ref> [30, 39, 42] </ref> and priority based scheduling theory. Surprisingly, while our use of static program slicing often leads to longer execution times and even higher utilizations it simultaneously helps achieve real-time correctness and schedulability for the entire system. For this reason we call the transformation real-time task slicing. Programming Model. <p> For this purpose we use a data structure called a program dependence graph (PDG), which represents all essential dependences between statements in a single graph. Since Ottenstein first proposed to use PDGs to help compute program slices <ref> [30] </ref>, PDG-based slicing algorithms have been popular, mainly because the PDG converts slicing computation into a simple graph walk problem. <p> Slicing has greatly evolved since its birth in [42], and many newer algorithms effectively address the problems mentioned above. We have chosen a slicing algorithm based a formalism known as the program dependence graph <ref> [8, 17, 30] </ref>. A program dependence graph is a suitable data structure for slicing, mainly because it integrates both data and control flows into a single graph, and thus reduces program slicing into a graph walk problem [30]. <p> A program dependence graph is a suitable data structure for slicing, mainly because it integrates both data and control flows into a single graph, and thus reduces program slicing into a graph walk problem <ref> [30] </ref>.
Reference: [31] <author> C. Park and A. Shaw. </author> <title> Experimenting with a program timing tool based on source-level timing schema. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 72-81. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1990. </year>
Reference-contexts: But this is also its downside: the result can be a "worst of all worst cases," i.e., an experimentally unachievable measurement. Yet static analysis is developing at a rapid pace, and tools are now being produced which can yield tighter results. The technique reported in <ref> [31] </ref> is based on a simple source-level timing schema, and it is fairly straightforward to implement in a tool. In [14] another approach for more accurate timing is proposed; the resulting tool was able to analyze micro-instruction streams using machine-description rules, and thus it was retargetable to various architectures.
Reference: [32] <author> W. Pugh and D. Wonnacott. </author> <title> Eliminating false data dependences using the Omega test. </title> <booktitle> In Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation. </booktitle> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: And at worst, we will end up with code that appears totally unsliceable when it may, in fact, be amenable to slicing. Fortunately, dependence analyzers are improving at a fast rate (see <ref> [15, 32] </ref>), and our algorithm will improve along with them. Also, as a last resort, a developer can obtain better slices by manually disambiguating some of memory references.
Reference: [33] <author> D. Whalley R. Arnold, F. Mueller. </author> <title> Bounding worst-case instruction cache performance. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 172-181. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year> <month> 33 </month>
Reference-contexts: Zhang et al. [46] presented a timing analyzer based on a mathematical model of the pipelined Intel 80C188 processor. This analysis method is able to take into account the overlap between instruction execution and fetching, which is an improvement over schemes where instruction executions are treated individually. In <ref> [33] </ref> Arnold et al. presented a timing prediction method called static cache simulation to statically analyze memory and cache reference patterns. In [26] Lim et al. describe an timing analysis tool based on a model called the extended timing schema. <p> However, no static timing tool is precise enough to be used with complete confidence for developing production-quality software. Moreover, even sophisticated timing analysis methods such as <ref> [26, 33] </ref> are not appropriate for fine-grained instruction timing. In Section 4.2 we explain how on can use these tools in spite of the limitations, by taking advantage of software profiling, as well as static timing prediction.
Reference: [34] <author> L. Sha, J. Lehoczky, and R. Rajkumar. </author> <title> Solutions for some practical problems in prioritized preemptive scheduling. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 181-191. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1986. </year>
Reference-contexts: It has been generalized to accommodate distributed systems, network protocols, shared databases <ref> [19, 34] </ref>, etc. Real-Time Task Slicing. Consider a construct such as "every 10ms do B," which denotes that the block B is dispatched at times 0, 10, 20, 30, etc.
Reference: [35] <author> L. Sha, R. Rajkumar, and J. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time synchronization. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 39 </volume> <pages> 1175-1185, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The deadline is measured relative to its release time.) In <ref> [35] </ref> Sha et al. presented two protocols which enable tasks to interact via shared resources, while still guaranteeing the tasks' deadlines.
Reference: [36] <author> K. Tindell, A. Burns, and A. Wellings. </author> <title> Allocating real-time tasks (an np-hard problem made easy). </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 4(2) </volume> <pages> 145-165, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: In Section 2 we survey related techniques in both program analysis and real-time systems. In Section 3 we motivate our transformation algorithm via a high-level characterization of discrete-control loops, 1 Multiprocessor scheduling is often accomplished by first solving an allocation sub-problem, and then single-processor scheduling sub-problems for each node <ref> [36] </ref>. 4 and we describe some typical scheduling methods used to dispatch them. In Section 4 we provide a technical treatment of program slicing that forms the crux of our transformation.
Reference: [37] <author> K. Tindell, A. Burns, and A. Wellings. </author> <title> An extendible approach for analysing fixed priority hard real-time tasks. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 6(2) </volume> <pages> 133-152, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Recently, a group of researchers at the University of York developed a set of analytical techniques which can provide schedulability tests for broad classes of tasks, including those whose deadlines are greater than their periods <ref> [4, 37] </ref>. (Note that the deadline and the period of a task are two distinct timing constraints, e.g., the period denotes the spacing between task instances, whereas the deadline denotes the permissable input-to-output propagation delay for each instance.) But a scheduling analyzer can do little when it determines that a task <p> If a task can meet its deadline during this period, it will succeed in all other task phasings, too. (This fact is used in the proof of Liu and Layland's result [28]; it has also led to necessary and sufficient tests for general static-priority schedulers <ref> [24, 37] </ref>.) Using this fact, we can determine the schedulability of the entire task set by incrementally checking whether each task is schedulable. <p> If no such assignment exists, perhaps the programmer may have to go back to the system design step and consider more aggressive system-tuning. For the actual priority assignment, Burns uses the top-level algorithm presented in <ref> [37] </ref>, along with a schedulability test for our event-based model. The algorithm assumes that all tasks have been transformed so that their IO components come first. <p> Since line (1) computes an recurrence equation on f i;q until the recurrence equation converges on a fixpoint, it finds the first time point when the CPU becomes idle. Readers are referred to <ref> [37] </ref> for more a comprehensive treatment on this type of recurrence equation. Consider the case in which t is not sliced. Since q is initially set to 0, lines (1)-(3) represent exactly the same scheduling test described in Section 3.2.
Reference: [38] <author> Frank Tip. </author> <title> A survey of program slicing techniques. </title> <journal> Journal of Programming Languages, </journal> <volume> 3(3) </volume> <pages> 121-189, </pages> <year> 1995. </year>
Reference-contexts: Moreover, our PDGs are representations of the programs themselves, in that they maintain a one-to-one correspondence between a node and a source line. Other algorithms compute program slices using different techniques, such as dataflow equations [42], etc. Tip presents a comprehensive survey on program slicing in <ref> [38] </ref>, which covers a variety of issues including interprocedural slicing, slicing in the presence of gotos and parametric slicing. But in this paper we restrict ourselves to a simple PDG-based slicing algorithm and concentrate only on real-time specific issues. 7 Compiler-based Techniques for Real-Time Programming.
Reference: [39] <author> G. Venkatesh. </author> <title> The semantic approach to program slicing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: As a last resort, entire subsystems may have to be re-designed altogether. In this paper we present a static alternative to this process, which is based on two interrelated components: a compiler transformation known as program slicing <ref> [30, 39, 42] </ref> and priority based scheduling theory. Surprisingly, while our use of static program slicing often leads to longer execution times and even higher utilizations it simultaneously helps achieve real-time correctness and schedulability for the entire system. For this reason we call the transformation real-time task slicing. Programming Model. <p> Since the introduction by Weiser, program slicing has been used in a wide spectrum of applications, and has appeared in several variations. In the taxonomy proposed by Venkatesh <ref> [39] </ref>, slicing may assume eight possible forms anumber computed by altering three 2-valued parameters. Although the taxonomy does not cover every form of program slicing, it provides a means to classify most of the conventional program slicing techniques. First, a slicing algorithm is either static or dynamic.
Reference: [40] <author> M. Weiser. </author> <title> Program Slices: Formal, Psychological, and Practical Investigations of an Automatic Program Astraction Method. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1979. </year>
Reference-contexts: Program Slicing. We have found program slicing a valuable tool for the task transformation problem at hand. Weiser first formulated the definition of program slicing in <ref> [40] </ref> and presented two of its potential applications in [42]: program debugging and parallel program execution [41]. Slicing isolates the statements which (may) affect a value computed at a specific program point - exactly the type of exercise which one often pursues in program debugging.
Reference: [41] <author> M. Weiser. </author> <title> Reconstructing sequential behavior from parallel behavior projections. </title> <journal> Information Processing Letters, </journal> <volume> 17(3) </volume> <pages> 129-135, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: Program Slicing. We have found program slicing a valuable tool for the task transformation problem at hand. Weiser first formulated the definition of program slicing in [40] and presented two of its potential applications in [42]: program debugging and parallel program execution <ref> [41] </ref>. Slicing isolates the statements which (may) affect a value computed at a specific program point - exactly the type of exercise which one often pursues in program debugging. <p> Weiser also proposed slicing as a tool to help convert single-threaded programs into parallel ones. The idea is to independently execute several slices in parallel each corresponding to different parts of the program and then to dynamically correlate their outputs in a way that preserves the original semantics <ref> [41] </ref>. Our task transformation is somewhat influenced by this approach, and it shares the essential code transformation strategy slicing, and then splicing two parts of a program together. <p> In [45] an approach to speculative execution is postulated for distributed real-time systems. The idea is that the speculative "shadow threads" are forked off to execute on available resources. This type of transformation can be viewed as an application of Weiser's slicing-and-splicing technique <ref> [41] </ref>, as described above.
Reference: [42] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10 </volume> <pages> 352-357, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: As a last resort, entire subsystems may have to be re-designed altogether. In this paper we present a static alternative to this process, which is based on two interrelated components: a compiler transformation known as program slicing <ref> [30, 39, 42] </ref> and priority based scheduling theory. Surprisingly, while our use of static program slicing often leads to longer execution times and even higher utilizations it simultaneously helps achieve real-time correctness and schedulability for the entire system. For this reason we call the transformation real-time task slicing. Programming Model. <p> Program Slicing. We have found program slicing a valuable tool for the task transformation problem at hand. Weiser first formulated the definition of program slicing in [40] and presented two of its potential applications in <ref> [42] </ref>: program debugging and parallel program execution [41]. Slicing isolates the statements which (may) affect a value computed at a specific program point - exactly the type of exercise which one often pursues in program debugging. <p> Moreover, our PDGs are representations of the programs themselves, in that they maintain a one-to-one correspondence between a node and a source line. Other algorithms compute program slices using different techniques, such as dataflow equations <ref> [42] </ref>, etc. Tip presents a comprehensive survey on program slicing in [38], which covers a variety of issues including interprocedural slicing, slicing in the presence of gotos and parametric slicing. <p> Slicing has greatly evolved since its birth in <ref> [42] </ref>, and many newer algorithms effectively address the problems mentioned above. We have chosen a slicing algorithm based a formalism known as the program dependence graph [8, 17, 30].
Reference: [43] <author> V. Wolfe, S. Davidson, and I. Lee. RTC: </author> <title> Language support for real-time concurrency. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 43-52. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: This type of program is the most common building-block found in real-time applications. In real-time programming environments (e.g., see the experimental languages in <ref> [21, 27, 29, 43] </ref>) a construct such as "every t do B" denotes that the program fragment B is dispatched at times 0, t, 2t, etc. * A task set (denoted = ft 1 ; : : : ; t n g) is a collection of time-multiplexed, periodic tasks, which are
Reference: [44] <author> J. Xu and D. Parnas. </author> <title> On satisfying timing constraints in hard real-time systems. </title> <booktitle> In ACM SIGSOFT '91 Conference on Software for Critical Systems, </booktitle> <pages> pages 132-146, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Its run-time mechanism is simple and efficient, and it can be implemented in many off-the-shelf operating systems. Also, its associated runtime queues are quite small (i.e., a maximum of one slot for each task). On the other hand, calendar-based scheduling <ref> [44] </ref> may require storing large task schedules (i.e., a maximum of one slot for each instance of each task invocation, up to the least-common-multiple of all periods). Finally, fixed-priority algorithms lend themselves to relatively fast analytical methods for o*ine schedulability tests. The following scenario gets played out at runtime.
Reference: [45] <author> M. Younis, T. Marlowe, and A. Stoyenko. </author> <title> Compiler transformations for speculative execution in a real-time system. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 109-117. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year>
Reference-contexts: The objective is to produce a transformed program possessing a smaller variance in its execution time. In [29] a partial evaluator is applied to a source program, which produces residual code that is both more optimized and more deterministic. In <ref> [45] </ref> an approach to speculative execution is postulated for distributed real-time systems. The idea is that the speculative "shadow threads" are forked off to execute on available resources. This type of transformation can be viewed as an application of Weiser's slicing-and-splicing technique [41], as described above.
Reference: [46] <author> N. Zhang, A. Burns, and M. Nicholson. </author> <title> Pipelined processors and worst case execution times. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 5(4), </volume> <month> October </month> <year> 1993. </year> <month> 34 </month>
Reference-contexts: On the other hand, neither approach addresses the problem of predicting architecture-specific timing behavior due to the various latencies inherent in memory hierarchies and pipelines. New results have begun to account for this timing variance. Zhang et al. <ref> [46] </ref> presented a timing analyzer based on a mathematical model of the pipelined Intel 80C188 processor. This analysis method is able to take into account the overlap between instruction execution and fetching, which is an improvement over schemes where instruction executions are treated individually.
References-found: 46

